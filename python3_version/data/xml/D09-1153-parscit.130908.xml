<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992122">
Chinese Semantic Role Labeling with Shallow Parsing
</title>
<author confidence="0.986752">
Weiwei Sun and Zhifang Sui and Meng Wang and Xin Wang
</author>
<affiliation confidence="0.97727175">
Institute of Computational Linguistics
Peking University
Key Laboratory of Computational Linguistics
Ministry of Education, China
</affiliation>
<email confidence="0.994552">
weiwsun@gmail.com;{szf,wm}@pku.edu.cn;xinwang.cpku@gmail.com;
</email>
<sectionHeader confidence="0.99475" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997854">
Most existing systems for Chinese Seman-
tic Role Labeling (SRL) make use of full
syntactic parses. In this paper, we evalu-
ate SRL methods that take partial parses as
inputs. We first extend the study on Chi-
nese shallow parsing presented in (Chen
et al., 2006) by raising a set of addi-
tional features. On the basis of our shal-
low parser, we implement SRL systems
which cast SRL as the classification of
syntactic chunks with IOB2 representation
for semantic roles (i.e. semantic chunks).
Two labeling strategies are presented: 1)
directly tagging semantic chunks in one-
stage, and 2) identifying argument bound-
aries as a chunking task and labeling their
semantic types as a classification task. For
both methods, we present encouraging re-
sults, achieving significant improvements
over the best reported SRL performance
in the literature. Additionally, we put
forward a rule-based algorithm to auto-
matically acquire Chinese verb formation,
which is empirically shown to enhance
SRL.
</bodyText>
<sectionHeader confidence="0.998881" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999785176470588">
In the last few years, there has been an increas-
ing interest in Semantic Role Labeling (SRL) on
several languages, which consists of recognizing
arguments involved by predicates of a given sen-
tence and labeling their semantic types. Nearly
all previous Chinese SRL research took full syn-
tactic parsing as a necessary pre-processing step,
such as (Sun and Jurafsky, 2004; Xue, 2008; Ding
and Chang, 2008). Many features are extracted to
encode the complex syntactic information. In En-
glish SRL research, there have been some attempts
at relaxing the necessity of using full syntactic
parses; better understanding of SRL with shallow
parsing is achieved by CoNLL-2004 shared task
(Carreras and M`arquez, 2004). However, it is still
unknown how these methods perform on other lan-
guages, such as Chinese.
To date, the best SRL performance reported on
the Chinese Proposition Bank (CPB) corresponds
to a F-measure is 92.0, when using the hand-
crafted parse trees from Chinese Penn Treebank
(CTB). This performance drops to 71.9 when a
real parser is used instead1 (Xue, 2008). Com-
paratively, the best English SRL results reported
drops from 91.2 (Pradhan et al., 2008) to 80.56
(Surdeanu et al., 2007). These results suggest that
as still in its infancy stage, Chinese full parsing
acts as a central bottleneck that severely limits our
ability to solve Chinese SRL. On the contrary, Chi-
nese shallow parsing has gained a promising re-
sult (Chen et al., 2006); hence it is an alternative
choice for Chinese SRL.
This paper addresses the Chinese SRL problem
on the basis of shallow syntactic information at
the level of phrase chunks. We first extend the
study on Chinese chunking presented in (Chen et
al., 2006) by raising a set of additional features.
The new set of features yield improvement over
the strong chunking system described in (Chen et
al., 2006). On the basis of our shallow parser, we
implement lightweight systems which solve SRL
as a sequence labeling problem. This is accom-
plished by casting SRL as the classification of syn-
tactic chunks (e.g. NP-chunk) into one of semantic
labels with IOB2 representation (?). With respect
to the labeling strategy, we distinguish two differ-
ent approaches. The first one directly recognizes
semantic roles by an IOB-type sequence tagging.
The second approach divides the problem into two
independent subtasks: 1) Argument Identification
(AI) and 2) Semantic Role Classification (SRC).
</bodyText>
<footnote confidence="0.9745945">
1This F-measure is evaluated on the basis of hand-crafted
word segmentation and POS tagging.
</footnote>
<page confidence="0.828935">
1475
</page>
<note confidence="0.9966335">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1475–1483,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9997186">
A Chinese word consists of one or more char-
acters, and each character, in most cases, is a mor-
pheme. The problem of how the words are con-
structed from morphemes, known as word for-
mation, is very important for a majority of Chi-
nese language processing tasks. To capture Chi-
nese verb formation information, we introduce a
rule-based algorithm with a number of heuristics.
Experimental results indicate that word formation
features can help both shallow parsing and SRL.
We present encouraging SRL results on CPB2.
The best F-measure performance (74.12) with
gold segmentation and POS tagging can be
achieved by the first method. This result yield
significant improvement over the best reported
SRL performance (71.9) in the literature (Xue,
2008). The best recall performance (71.50) can be
achieved by the second method. This result is also
much higher than the best reported recall (65.6) in
(Xue, 2008).
</bodyText>
<sectionHeader confidence="0.999718" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999786925925926">
Previous work on Chinese SRL mainly focused on
how to implement SRL methods which are suc-
cessful on English, such as (Sun and Jurafsky,
2004; Xue and Palmer, 2005; Xue, 2008; Ding
and Chang, 2008). Sun and Jurafsky (2004) did
the preliminary work on Chinese SRL without
any large semantically annotated corpus of Chi-
nese. Their experiments were evaluated only on
ten specified verbs with a small collection of Chi-
nese sentences. This work made the first attempt
on Chinese SRL and produced promising results.
After the CPB was built, (Xue and Palmer, 2005)
and (Xue, 2008) have produced more complete
and systematic research on Chinese SRL. Ding
and Chang (2008) divided SRC into two sub-tasks
in sequence. Under the hierarchical architecture,
each argument should first be determined whether
it is a core argument or an adjunct, and then be
classified into fine-grained categories. Chen et
al. (2008) introduced an application of transduc-
tive SVM in Chinese SRL. Because their experi-
ments took hand-crafted syntactic trees as input,
how transductive SVMs perform in Chinese SRL
in realistic situations is still unknown.
Most existing systems for automatic Chinese
SRL make use of a full syntactic parse of the sen-
tence in order to define argument boundaries and
</bodyText>
<footnote confidence="0.954488">
2Our system is available at
http://code.google.com/p/csrler/
</footnote>
<bodyText confidence="0.999705944444444">
to extract relevant information for training clas-
sifiers to disambiguate between role labels. On
the contrary, in English SRL research, there have
been some attempts at relaxing the necessity of us-
ing syntactic information derived from full parse
trees. For example, Hacioglu and Ward (2003)
considered SRL as a chunking task; Pradhan et
al. (2005) introduced a new procedure to incor-
porate SRL results predicted respectively on full
and shallow syntactic parses. Previous work on
English suggests that even good labeling perfor-
mance has been achieved by full parse based SRL
systems, partial parse based SRL systems can still
enhance their performance. Though better under-
standing of SRL with shallow parsing on English
is achieved by CoNLL-2004 shared task (Carreras
and M`arquez, 2004), little is known about how
these SRL methods perform on Chinese.
</bodyText>
<sectionHeader confidence="0.988816" genericHeader="method">
3 Chinese Shallow Parsing
</sectionHeader>
<bodyText confidence="0.999740375">
There have been some research on Chinese shal-
low parsing, and a variety of chunk defini-
tions have been proposed. However, most of
these studies did not provide sufficient detail.
In our system, we use chunk definition pre-
sented in (Chen et al., 2006), which provided
a chunk extraction tool. The tool to extract
chunks from CTB was developed by modify-
ing the English tool used in CoNLL-2000 shared
task, Chunklink3, and is publicly available at
http://www.nlplab.cn/chenwl/chunking.html. The
definition of syntactic chunks is illustrated in Line
CH in Figure 1. For example, ”保险公司/the in-
surance company”, consisting of two nouns, is a
noun phrase.
With IOB2 representation (Ramshaw and Mar-
cus, 1995), the problem of Chinese chunking can
be regarded as a sequence labeling task. In this
paper, we first implement the chunking method
described in (Chen et al., 2006) as a strong base-
line. To conveniently illustrate, we denote a word
in focus with a fixed window w−2w−1ww+1w+2,
where w is current token. The baseline features
includes:
</bodyText>
<listItem confidence="0.87269">
• Uni-gram word/POS tag feature: w−2, w−1,
w, w+1, w+2;
• Bi-gram word/POS tag feature: w−2 w−1,
w−1 w, w w+1, w+1 w+2;
</listItem>
<footnote confidence="0.99856">
3http://ilk.uvt.nl/team/sabine/chunklink/chunklink 2-2-
2000 for conll.pl
</footnote>
<page confidence="0.971795">
1476
</page>
<table confidence="0.977683571428572">
WORD: 截止 目前 保险 公司 E V 三峡 工程 提供 保险 服务
POS: [P] [NT] [NN NN] [AD] [P] [NR] [NN] [VP] [NN NN]
CH: [PP NP] [NP] [ADVP] [PP NP NP ] [VP] [NP]
M1: B-A* I-A*4 B-A0 B-AM-ADV B-A2 I-A2 I-A2 B-V B-A1
M2-AI: B-A I-A B-A B-A B-A I-A I-A B-V B-A
M2-SRC: AM-TMP A0 AM-ADV A2 Rel A1
Until now, the insurance company has provided insurance services for the Sanxia Project.
</table>
<figureCaption confidence="0.763015833333333">
Figure 1: An example from Chinese PropBank.
That means 18 features are used to represent a
given token. For instance, the bi-gram Word fea-
tures at 5th word position (”公司/company”) in
Figure 1 are ”, 保险”, ”保险 公司”, ”公司 E”,
”E V”.
</figureCaption>
<bodyText confidence="0.999838333333333">
To improve shallow parsing, we raised an addi-
tional set of features. We will discuss these fea-
tures in section 5.
</bodyText>
<sectionHeader confidence="0.968309" genericHeader="method">
4 SRL with Shallow Parsing
</sectionHeader>
<bodyText confidence="0.999934066666667">
The CPB is a project to add predicate-argument
relations to the syntactic trees of the CTB. Similar
to English PropBank, the semantic arguments of a
predicate are labeled with a contiguous sequence
of integers, in the form of AN (i.e. ArgN); the ad-
juncts are annotated as such with the label AM (i.e.
ArgM) followed by a secondary tag that represents
the semantic classification of the adjunct. The as-
signment of argument labels is illustrated in Figure
1, where the predicate is the verb ”提供/provide”.
For example, the noun phrase ”保险公司/the in-
surance company” is labeled as A0, meaning that it
is the proto-Agent of 提供; the preposition phrase
”截止目前/until now” is labeled as AM-TMP, in-
dicating a temporal component.
</bodyText>
<subsectionHeader confidence="0.999399">
4.1 System Architecture
</subsectionHeader>
<bodyText confidence="0.999967555555556">
SRL is a complex task which has to be decom-
posed into a number of simpler decisions and tag-
ging schemes in order to be addressed by learn-
ing techniques. Regarding the labeling strategy,
we can distinguish at least two different strategies.
The first one consists of performing role identifi-
cation directly as IOB-type sequence tagging. The
second approach consists of dividing the problem
into two independent subtasks.
</bodyText>
<footnote confidence="0.989968">
4The semantic chunk labels here are B-AM-TMP and I-
AM-TMP. Limited to the document length, we cannot put all
detailed chunk labels in one line in Figure 1.
</footnote>
<subsectionHeader confidence="0.525533">
4.1.1 One-stage Strategy
</subsectionHeader>
<bodyText confidence="0.999985214285714">
In the one-stage strategy, on the basis of syntac-
tic chunks, we define semantic chunks which do
not overlap nor embed using IOB2 representation.
Syntactic chunks outside a chunk receive the tag
O. For syntactic chunks forming a chunk of type
A*, the first chunk receives the B-A* tag (Begin),
and the remaining ones receive the tag I-A* (In-
side). Then a SRL system can work directly by
using sequence tagging techinique. Since the se-
mantic annotation in the PropBank corpus does
not have any embedded structure, there is no loss
of information in this representation. The line M1
in Figure 1 illustrates this semantic chunk defini-
tion.
</bodyText>
<subsectionHeader confidence="0.56343">
4.1.2 Two-stage Strategy
</subsectionHeader>
<bodyText confidence="0.999993894736842">
In the two-stage architecture, we divide Chinese
SRL into two subtasks: 1) semantic chunking for
AI, in which the argument boundaries are pre-
dicted, and 2) classification for SRC, in which the
already recognized arguments are assigned role la-
bels. In the first stage, we define semantic chunks
B-A which means begin of an argument and I-A
which means inside of an argument. In the second
stage, we solve SRC problem as a multi-class clas-
sification. The lines M2-AI and M2-SRC in Fig-
ure 1 illustrate this two-stage architecture. For ex-
ample, the noun phrase ”保险公司/the insurance
company” is proto-Agent, and thus should be la-
beled as B-A in the AI chunking phase, and then
be tagged as A0. The phrase ”V三峡工程/for the
Sanxia Project” consists of three chunks, which
should be labeled as B-A, I-A, and I-A respectively
in the AI chunking phase, then these three chunks
as a whole argument should be recognized as A2.
</bodyText>
<subsectionHeader confidence="0.903016">
4.1.3 Chunk-by-Chunk
</subsectionHeader>
<bodyText confidence="0.99997225">
There is also another semantic chunk definition,
where the basic components of a semantic chunk
are words rather than syntactic chunks. A good
election for this problem is chunk-by-chunk pro-
</bodyText>
<page confidence="0.967082">
1477
</page>
<bodyText confidence="0.999776375">
cessing instead of word-by-word. The motivation
is twofold: 1) phrase boundaries are almost always
consistent with argument boundaries; 2) chunk-
by-chunk processing is computationally less ex-
pensive and allows systems to explore a relatively
larger context. This paper performs a chunk-by-
chunk processing, but admitting a processing by
words within the target verb chunks.
</bodyText>
<subsectionHeader confidence="0.884838">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.99998375">
Most of the feature templates are ”standard”,
which have been used in previous SRL research.
We give a brief description of ”standard” features,
but explain our new features in detail.5
</bodyText>
<subsubsectionHeader confidence="0.694674">
4.2.1 Features for Semantic Chunking
</subsubsectionHeader>
<bodyText confidence="0.999957291666667">
In the semantic chunking tasks, i.e. the one-stage
method and the first step in the two-stage method,
we use the same set of features. The features
are extracted from three types of elements: syn-
tactic chunks, target verbs, links between chunks
and target verbs. They are formed making use
of words, POS tags and chunks of the sentence.
Xue (2008) put forward a rough verb classifica-
tion where verb classes are automatically derived
from the frame files, which are verb lexicon for
the CPB annotation. This kind of verb class in-
formation has been shown very useful for Chinese
SRL. Our system also includes this feature. In our
experiments, we represent a verb in two dimen-
sions: 1) number of arguments, and 2) number of
framesets. For example, a verb may belong to the
class ”C1C2,” which means that this verb has two
framesets, with the first frameset having one argu-
ment and the second having two arguments.
To conveniently illustrate, we de-
note a token chunk with a fixed context
wi_1[ckwi...wh...wj]wj+1, where wh is the
head word of this chunk ck. The complete list of
features is listed here.
</bodyText>
<subsectionHeader confidence="0.835139">
Extraction on Syntactic Chunks
</subsectionHeader>
<bodyText confidence="0.976837596153846">
Chunk type: ck.
Length: the number of words in a chunk.
Head word/POS tag. The rules described in
(Sun and Jurafsky, 2004) are used to extract head
word.
IOB chunk tag of head word: chunk tag of head
word with IOB2 representation (e.g. B-NP, I-NP).
5The source code of our system also provides lots of com-
ments for implementation of all features.
Chunk words/POS tags context. Chunk con-
text includes one word before and one word after:
wi_1 and wj+1.
POS tag chain: sequential containers of each
word’s POS tag: wi ... wj. For example, this fea-
ture for ”保险服务” is ”NN NN”.
Position: the position of the phrase with respect
to the predicate. It has three values as before, after
and here.
Extraction on Target Verbs Given a target verb
wv and its context, we extract the following fea-
tures.
Predicate, its POS tag, and its verb class.
Predicate IOB chunk tag context: the chain of
IOB2 chunk tags centered at the predicate within
a window of size -2/+2.
Predicate POS tag context: the POS tags of
the words that immediately precede and follow the
predicate.
Number ofpredicates: the number of predicates
in the sentence.
Extraction on Links To capture syntactic prop-
erties of links between the chunks and the verbs,
we use the following features.
Path: a flat path is defined as a chain of base
phrases between the token and the predicate. At
both ends, the chain is terminated with the POS
tags of the predicate and the headword of the to-
ken.
Distance: we have two notions of distance. The
first is the distance of the token from the predicate
as a number of base phrases, and the second is the
same distance as the number of VP chunks.
Combining Features We also combine above
features as some new features.
Conjunctions of position and head word, tar-
get verb, and verb class, including: position wh,
position wv, position wh wv, position class,
and position wh class.
Conjunctions of position and POS tag of
head word, target verb, and verb class, in-
cluding: position wh wv, position wh, and
position wh class.
</bodyText>
<sectionHeader confidence="0.528445" genericHeader="method">
4.2.2 Features for SRC
</sectionHeader>
<bodyText confidence="0.9999178">
In the SRC stage of the two-stage method, dif-
ferent from previous work, our system only uses
word-based features, i.e. features extracted from
words and POS tags, to represent a given argu-
ment. Experiments show that a good semantic
</bodyText>
<page confidence="0.969428">
1478
</page>
<bodyText confidence="0.960927216216216">
role classifier can be trained by using only word-
based features. To gather all argument position
information predicted in AI stage, we design a
coarse frame feature, which is a sequential collec-
tion of arguments. So far, we do not know the
detailed semantic type of each argument, and we
use XP as each item in the frame. To distinguish
the argument in focus, we use a special symbol
to indicate the corresponding frame item. For in-
stance, the Frame feature for argument 保险服
务 is XP+XP+XP+XP+V+!XP, where !XP means
that it is the argument in focus.
Denote 1) a given argument
wi−2wi−1[wiwi+1...wj−1wj]wj+1wj+2, and
2) a given predicate wv. The features for SRC are
listed as follows.
Words/POS tags context of arguments: the con-
tents and POS tags of the following words: wi,
wi−1, wi−2, wi+1, wi+2, wj, wj+1, wj−1, wj−2,
wj+1, wj+2; the POS tags of the following words:
wi+1, wi+2, wj+1, wj+2.
Token Position.
Predicate, its POS, and its verb class.
Coarse Frame.
Combining features: conjunctions of bound-
ary words, including wi−1 wj+1 and wi−2 wj+2;
conjunction of POS tags of boundary words, in-
cluding wi−1 wj+1 and wi−2 wj+2; conjunction
of token position, boundary words, and predi-
cate word, including position wi wj, wi wj wv;
position wi wj wv; conjunction of token posi-
tion, boundary words’ POS tags, and predicate
word, also including position wi wj, wi wj wv;
position wi wj wv; conjunction of predicate and
frame; conjunction of target verb class and frame;
conjunction of boundary words’ POS tags, and
predicate word.
</bodyText>
<sectionHeader confidence="0.9945405" genericHeader="method">
5 Automatic Chinese Verb Formation
Analyzing
</sectionHeader>
<subsectionHeader confidence="0.993584">
5.1 Introduction to Chinese Word Formation
</subsectionHeader>
<bodyText confidence="0.984507545454545">
Chinese words consist of one or more charac-
ters, and each character, in most cases, is a mor-
pheme which is the smallest meaningful unit of
the language. According to the number of mor-
phemes, the words can be grouped into two sets,
simple words (consisting of one morpheme) and
compound words (consisting of two morphemes
or more). There are 9 kinds of word formation in
Chinese compound words, and table 1 shows the
detail with examples. Note that, attributive-head
and complementarity are not for Chinese verbs.
</bodyText>
<table confidence="0.999154833333333">
Types Examples
reduplication **(look) bb(think)
affixation 激((intensify) 觉V(feel)
subject-verb 耳闻(hear) Q述(dictate)
verb-object 戒烟(quit smoking)
理R(haircut)
verb-complement 通O(inform) 栽培(plant)
verb-result 超出(exceed) 煮沸(boil)
adverbial-head 隐居(retreat) 误用(misuse)
coordinate 爱惜(cherish) 追逐(chase)
attributive-head* 谣言(rumor) K院(hospital)
complementarity* 纸张(paper) 马E(horse)
</table>
<tableCaption confidence="0.999718">
Table 1: Example Words with Formation
</tableCaption>
<bodyText confidence="0.99995052631579">
The internal structure of a word constraints its
external grammatical behavior, and the formation
of a verb can provide very important information
for Chinese SRL. Take ”超出/exceed” as an ex-
ample, the two characters are both verbal mor-
phemes, and the character ”超” means ”pass” and
the character ”出” with the meaning of ”over”
shows the complement of the action of ”超”. In
this word, ”出” is usually collocated with an ob-
ject, and hence a Patient role should comes af-
ter the verb ”超出”. Note that, the verb ”超”,
however, is unlikely to have an object. Take ”理
R/haircut” as another example, the first charac-
ter ”理” is a verbal morpheme with the meaning
of ”cut” and the second character ”R” is a nomi-
nal morpheme with the meaning of ”hair”. In this
word, ”R” acts as the object of ”理”, and the word
”理R” is unlikely to have an Patient any more in
the sentential context.
</bodyText>
<subsectionHeader confidence="0.996763">
5.2 Verb Formation Analyzing Method
</subsectionHeader>
<bodyText confidence="0.9982122">
To automatically analyze verb formation, we in-
troduce a rule-based algorithm. Pseudo code in
Algorithm 1 illustrates our algorithm. This algo-
rithm takes three string (one or more Chinese char-
acters) sets as lexicon knowledge:
</bodyText>
<listItem confidence="0.9867565">
• adverbial suffix set A: strings in A are usu-
ally realized as the modifier in a adverbial-
</listItem>
<bodyText confidence="0.847775">
head type word, e.g. 不/not, 别/not,
总/always, 并/both, 共/all.
</bodyText>
<listItem confidence="0.965382666666667">
• object head set O: strings in O are usually re-
alized as the head in a verb-object type word,
e.g. A/change, 获/get, 谈/talk, R/send.
</listItem>
<page confidence="0.99205">
1479
</page>
<figureCaption confidence="0.304675">
Algorithm 1: Verb Formation Analyzing.
</figureCaption>
<bodyText confidence="0.8712055">
Data: adverbial suffix set A, object head set
O, complement suffix set C
input : word W = c1...cn and its POS P
output: head character h, adverbial character
a, complement character c, object
character o
</bodyText>
<listItem confidence="0.6803875">
• complement suffix set C: strings in C are
usually realized as complement in a verb-
complement type word: e.g. f/out, k/in,
完/finish, 来/come, 不X/not.
</listItem>
<bodyText confidence="0.9998594">
Note that, to date there is no word formation
annotation corpus, so direct evaluation of our rule-
based algorithm is impossible. This paper makes
task-oriented evaluation which measures improve-
ments in SRL.
</bodyText>
<subsectionHeader confidence="0.994282">
5.3 Using Word Formation Information to
improve Shallow Parsing
</subsectionHeader>
<bodyText confidence="0.99967955">
The majority of Chinese nouns are of type
attributive-head. This means that for most nouns
the last character provides very important infor-
mation indicating the head of the noun. For ex-
ample, the word formations of ”桃树/peach”, ”柳
树/willow” and ”黄杨树/boxtree” (three different
kinds of trees), are attributive-head and they have
the same head word ”树/tree”. While for verbs, the
majority are of three types: verb-object, coordi-
nate and adverbial-head. For example, words ”M
大/enlarge”, ”MMPJ/make more drastic” and ”M
快/accelerate” have the same head ”M/add”. The
head morpheme is very useful in alleviating the
data sparseness in word level. However, for any
given word, it is very hard to accurately find the
head. In the shallow paring experiments, we use
a very simple rule to get a pseudo head character:
1) extracting the last word for a noun, and 2) ex-
tracting the first word for a verb. The new features
include:
</bodyText>
<figureCaption confidence="0.997883">
Pattern 1: conjunction of pseudo head of wi−1
and POS tags of wi−1 and wi.
Pattern 2: conjunction of pseudo head of wi and
POS tags of wi−1 and wi.
Pattern 3: conjunction of length/POS tags of
wi−1, wi, wi+1.
</figureCaption>
<subsectionHeader confidence="0.892072">
5.4 Using Verb Formation Information to
improve SRL
</subsectionHeader>
<bodyText confidence="0.946096388888889">
We use some new verb formation features to im-
prove our SRL system. The new features are listed
as follows. The first four are used in semantic
chunking task, and all are used in SRC task.
First/last characters.
Word length.
Conjunction of word length and first/last char-
acter.
Conjunction of token position and first/last
character.
The head string of a verb (e.g. ”理” in ”理发”) .
The adverbial string of a verb (e.g. ”误” in ”误
用”)
.
The complement string of a verb (e.g. ”f” in
”超f”).
The object string of a verb (e.g. ”发” in ”理
发”) .
</bodyText>
<sectionHeader confidence="0.999867" genericHeader="evaluation">
6 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.9942205">
6.1 Experimental Setting
6.1.1 Data
</subsectionHeader>
<bodyText confidence="0.99812425">
Experiments in previous work are mainly based on
CPB and CTB, but the experimental data prepar-
ing procedure does not seem consistent. For ex-
ample, the sum of each semantic role reported in
(Ding and Chang, 2008) is extremely smaller than
the corresponding occurrence statistics in origi-
nal data files in CPB. In this paper, we mod-
ify CoNLL-2005 shared task software6 to pro-
cess CPB and CTB. In our experiments, we use
the CPB 1.0 and CTB 5.0. The data is divided
into three parts: files from chtb 081 to chtb 899
are used as training set; files from chtb 041 to
</bodyText>
<footnote confidence="0.729343">
6http://www.lsi.upc.edu/∼srlconll/soft.html
</footnote>
<figure confidence="0.50764">
begin
h=c=a=o=null;
if n = 4 and c1 = c3 and c2 = c4 then
return Verb formation of W0 = c1c3;
</figure>
<equation confidence="0.980146928571428">
else if n = 3 and c2 = c3 then
h = c1, c = c2;
else if n = 2 and c1 = c2 then
h = c1;
else if n = 1 then
h = c1;
else if cn E C and cn−1cn E C and
P=”VV” then
h = c1, c = cn/cn−1cn;
else if c1 E A then
a = c1, h = c2...cn;
else if c1 E O and P=”VV” then
h = c1,o = c2...cn;
end
</equation>
<page confidence="0.93739">
1480
</page>
<bodyText confidence="0.999682333333333">
chtb 080 as development set; files from chtb 001
to chtb 040, and chtb 900 to chtb 931 as test set.
The data setting is the same as (Xue, 2008). The
results were evaluated for precision, recall and F-
measure numbers using the srl-eval.pl script pro-
vided by CoNLL-2005 shared task.
</bodyText>
<subsectionHeader confidence="0.769214">
6.1.2 Classifier
</subsectionHeader>
<bodyText confidence="0.999206538461539">
For both syntactic and semantic chunking, we
used TinySVM along with YamCha7 (Kudo and
Matsumoto, 2000; Kudo and Matsumoto, 2001).
In the chunking experiments, all SVM classifiers
were realized with a polynomial kernel of de-
gree 2. Pair-wise strategy is used to solve multi-
class classification problem. For the SRC ex-
periments, we use a linear SVM classifier, along
with One-Vs-All approach for multi-class classifi-
cation. SVMlin8, a fast linear SVM solvers, is used
for supervised learning. 12-SVM-MFN (modified
finite newton) method is used to solve the opti-
mization problem (Keerthi and DeCoste, 2005).
</bodyText>
<subsectionHeader confidence="0.985502">
6.2 Shallow Parsing Performance
</subsectionHeader>
<table confidence="0.998416">
P(%) R(%) Fβ=1
Baseline 93.54 93.00 93.27
Ours 93.83 93.39 93.61
</table>
<tableCaption confidence="0.998911">
Table 2: Shallow parsing performance
</tableCaption>
<bodyText confidence="0.99381675">
Table 2 summarizes the overall shallow pars-
ing performance on test set. The first line shows
the performance of baseline. Comparing the best
system performance 94.13 F-measure of CoNLL
2000 shared task (Syntactic Chunking on English),
we can see Chinese shallow parsing has reached
a comparable result, tough the comparison of nu-
meric performance is not very fair, because of dif-
ferent languages, different chunk definition, dif-
ferent training data sizes, etc.. The second line
Ours shows the performance when new features
are added, from which we can see the word for-
mation based features can help shallow parsing.
Table 3 shows the detailed performance of noun
phrase (NP) and verb phrase (VP), which make up
most of phrase chunks in Chinese. Our new fea-
tures help NP more, whereas the effect of new fea-
tures for VP is not significant. That is in part be-
cause most VP chunk recognition error is caused
by long dependency, where word formation fea-
</bodyText>
<footnote confidence="0.9998305">
7http://chasen.org/-taku/index.html.en
8http://people.cs.uchicago.edu/-vikass/svmlin.html
</footnote>
<table confidence="0.9996628">
P(%) R(%) Fβ=1
NP(Baseline) 90.84 90.05 90.44
NP(Ours) 91.42 90.78 91.10
VP(Baseline) 94.44 94.55 94.50
VP(Ours) 94.65 94.74 94.69
</table>
<tableCaption confidence="0.914513333333333">
Table 3: Performance of NP-chunk and VP-chunk
tures do not work. Take the sentences below for
example:
</tableCaption>
<listItem confidence="0.686408">
1. [V P Q k 获 得 胜 利]. (Therefore (we)
achieve victory.) tt---
2. [ADV P Qk] [V P l� `�i现] 的是以前不
曾遇到的. (Therefore the major changes
have not been met before.)
</listItem>
<bodyText confidence="0.99998325">
The contexts of the word ”Qk/therefore” in the
two sentences are similar, where ”Qk” is fol-
lowed by verbal components. In the second sen-
tence, the word ”Qk/therefore” will be correctly
recognized as an adverbial phrase unless classifier
knows the following component is a clause. Un-
fortunately, word formation features cannot sup-
ply this kind of information.
</bodyText>
<subsectionHeader confidence="0.96028">
6.3 SRL Performance
</subsectionHeader>
<table confidence="0.9996067">
P(%) R(%) A(%) Fβ=1
(Xue, 2008) 79.5 65.6 – 71.9
M1− 79.02 69.12 – 73.74
M1+ 79.25 69.61 – 74.12
M2−/AI 80.34 75.11 – 77.63
M2+/AI 80.01 75.15 – 77.51
M2−/SRC – – 92.57 –
M2+wf/SRC – – 93.25 –
M2+/SRC – – 93.42 –
M2−AI+SRC 76.48 71.50 – 73.90
</table>
<tableCaption confidence="0.9643385">
Table 4: Overall SRL performance of different
methods
</tableCaption>
<bodyText confidence="0.9083144">
Table 4 lists the overall SRL performance num-
bers on test set using different methods mentioned
earlier; these results are based on features com-
puted from gold standard segmentation and POS
tagging, but automatic recognized chunks, which
is parsed by our improved shallow parsing sys-
tem. For the AI and the whole SRL tasks, we
report the precision (P), recall (R) and the Fβ=1-
measure scores, and for the SRC task we report
the classification accuracy (A). The first line (Xue,
</bodyText>
<page confidence="0.972304">
1481
</page>
<bodyText confidence="0.99994165">
2008) shows the SRL performance reported in
(Xue, 2008). To the authors’ knowledge, this re-
sult is best SRL performance in the literature. Line
2 and 3 shows the performance of the one-stage
systems: 1) Line M1− is the performance without
word formation features; 2) Line M1+ is the per-
formance when verb formation features are added.
Line 4 to 8 shows the performance of the two-stage
systems: 1) Line M2−/AI and M2+/AI shows the
performance of AI phase without and within word
formation features respectively; 2) Line M2−/SRC
shows the SRC performance with trivial word-
based features (i.e. frame features and verb forma-
tion features are not used); 3) Line M2+wf/SRC is
the improved SRC performance when coarse verb
formation features are added; 4) Line M2+/SRC
is the SRC performance with all features; 5) Line
M2−AI+SRC shows the performance of SRL sys-
tem, which uses baseline features to identify argu-
ments, and use all features to classify arguments.
</bodyText>
<subsectionHeader confidence="0.886098">
6.4 Discussion
</subsectionHeader>
<bodyText confidence="0.999844172413793">
The results summarized in Table 4 indicate that
according to the-state-of-the-art in Chinese pars-
ing, SRL systems based on shallow parsing out-
performs the ones based on full parsing. Com-
parison between one-stage strategy and two-stage
strategy indicates 1) that there is no significant dif-
ference in the F-measure; and 2) that two-stage
strategy method can achieve higher recall while
one-stage strategy method can achieve higher pre-
cision. Both the one-stage strategy and two-stage
strategy methods yield significant improvements
over the best reported SRL performance in the lit-
erature, especially in terms of recall performance.
Comparison SRL performance with full parses
and partial parses indicates that both models have
strong and weak points. The full parse based
method can implement high precision SRL sys-
tems, while the partial parse based methods can
implement high recall SRL systems. This is fur-
ther justification for combination strategies that
combine these independent SRL models.
Generally, Table 4 shows that verb formation
features can enhance Chinese SRL, especially for
fine-grained role classification. The effect of word
formation in formation in both shallow parsing
and SRL suggests that automatic word formation
analyzing is very important for Chinese language
processing. The rule-based algorithm is just a pre-
liminary study on this new topic, which requires
</bodyText>
<table confidence="0.998746666666666">
Num of words P (%) R (%) Fβ=1
Length = 1 84.69% 75.48% 79.82
Length = 2 82.14% 74.21% 77.97
Length = 3 75.43% 63.98% 69.24
Length = 4 75.71% 65.63% 70.32
Length = 5 72.46% 64.38% 68.18
Length = 6 72.97% 66.21% 69.43
Length = 7 77.03% 67.65% 72.04
Length = 8 74.39% 57.28% 64.72
Length = 9 66.67% 51.16% 57.89
Length = 10 68.08% 58.28% 62.80
Length = 11+ 67.40% 57.71% 62.18
</table>
<tableCaption confidence="0.966853">
Table 5: SRL performance with arguments of dif-
ferent length
</tableCaption>
<bodyText confidence="0.997759807692308">
more research effort.
Though our SRC module does not use any pars-
ing information, our system can achieve 93.42%
accuracy, comparing the best gold parse based re-
sult 94.68% in the literature. This result suggests
that Chinese SRC system, even without parsing,
can reach a considerable good performance. The
main reason is that in Chinese, arguments with dif-
ferent semantic types have discriminative bound-
ary words, which can be extracted without pars-
ing. It is very clear that the main bottleneck for
Chinese SRL is to accurately identify arguments
rather than to disambiguate their detailed seman-
tic types.
Table 5 summarizes the labeling performance
for argument of different length. It is not surpris-
ing that arguments are more and more difficult to
rightly recognize as the increase of their length.
But the performance decline slows up when the
length of arguments is larger than 10. In other
words, some of the arguments that are composed
of many words can still be rightly identified. The
main reason for this point is that these arguments
usually have clear collocation words locating at ar-
gument boundaries. Take the sentences below for
example,
</bodyText>
<listItem confidence="0.502599">
3. 包括[A1 ] (including ... etc.)
</listItem>
<bodyText confidence="0.997616">
the object of the verb ”包括/include” has a defi-
nite collocation word ” /etc.”, and therefore this
object is easy to be recognized as a A1.
</bodyText>
<sectionHeader confidence="0.998758" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.988685">
In this paper, we discuss Chinese SRL on the ba-
sis of partial syntactic structure. Our systems ad-
vance the state-of-the-art in Chinese SRL. We first
</bodyText>
<page confidence="0.980091">
1482
</page>
<bodyText confidence="0.999929928571429">
extend the study on Chinese shallow parsing and
implement a good shallow parser. On the ba-
sis of partial parses, SRL are formulated as a se-
quence labeling problem, performing IOB2 deci-
sions on the syntactic chunks of the sentence. We
exploit a wide variety of features based on words,
POS tags, and partial syntax. Additionally, we
discuss a language special problem, i.e. Chinese
word formation. Experimental results show that
coarse word formation information can help shal-
low parsing, especially for NP-chunk recognition.
A rule-based algorithm is put forward to automat-
ically acquire Chinese verb formation, which is
empirically shown to enhance SRL.
</bodyText>
<sectionHeader confidence="0.999024" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9986995">
This work is supported by NSFC Project
60873156, 863 High Technology Project of
China 2006AA01Z144 and the Project of Toshiba
(China) R&amp;D Center.
We would like to thank Weiwei Ding for his
good advice on this research.
We would also like to thank the anonymous re-
viewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998694" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999343975609756">
Xavier Carreras and Llu´ıs M`arquez. 2004. Introduc-
tion to the conll-2004 shared task: Semantic role
labeling. In Hwee Tou Ng and Ellen Riloff, edi-
tors, HLT-NAACL 2004 Workshop: Eighth Confer-
ence on Computational Natural Language Learn-
ing (CoNLL-2004), pages 89–97, Boston, Mas-
sachusetts, USA, May 6 - May 7. Association for
Computational Linguistics.
Wenliang Chen, Yujie Zhang, and Hitoshi Isahara.
2006. An empirical study of Chinese chunking.
In Proceedings of the COLING/ACL 2006 Main
Conference Poster Sessions, pages 97–104, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Yaodong Chen, Ting Wang, Huowang Chen, and Xis-
han Xu. 2008. Semantic role labeling of Chinese
using transductive svm and semantic heuristics. In
Proceedings of the Third International Joint Confer-
ence on Natural Language Processing: Volume-II.
Weiwei Ding and Baobao Chang. 2008. Improv-
ing Chinese semantic role classification with hier-
archical feature selection strategy. In Proceedings
of the 2008 Conference on Empirical Methods in
Natural Language Processing, pages 324–333, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.
Kadri Hacioglu and Wayne Ward. 2003. Target word
detection and semantic role chunking using support
vector machines. In NAACL ’03: Proceedings of
the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 25–27, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
S. Sathiya Keerthi and Dennis DeCoste. 2005. A mod-
ified finite newton method for fast solution of large
scale linear svms. J. Mach. Learn. Res., 6:341–361.
Taku Kudo and Yuji Matsumoto. 2000. Use of support
vector learning for chunk identification. In Proceed-
ings of the 2nd workshop on Learning language in
logic and the 4th conference on Computational natu-
ral language learning, pages 142–144, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Taku Kudo and Yuji Matsumoto. 2001. Chunking
with support vector machines. In NAACL ’01: Sec-
ond meeting of the North American Chapter of the
Association for Computational Linguistics on Lan-
guage technologies 2001, pages 1–8, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
Sameer Pradhan, Kadri Hacioglu, Wayne Ward,
James H. Martin, and Daniel Jurafsky. 2005. Se-
mantic role chunking combining complementary
syntactic views. In Proceedings of the Ninth Confer-
ence on Computational Natural Language Learning
(CoNLL-2005), pages 217–220, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Sameer S. Pradhan, Wayne Ward, and James H. Mar-
tin. 2008. Towards robust semantic role labeling.
Comput. Linguist., 34(2):289–310.
L. A. Ramshaw and M. P. Marcus. 1995. Text chunk-
ing using transformation-based learning. In Pro-
ceedings of the 3rd ACL/SIGDAT Workshop on Very
Large Corpora, Cambridge, Massachusetts, USA,
pages 82–94.
Honglin Sun and Daniel Jurafsky. 2004. Shallow se-
mantc parsing of Chinese. In Daniel Marcu Su-
san Dumais and Salim Roukos, editors, HLT-NAACL
2004: Main Proceedings.
Mihai Surdeanu, Llu´ıs M`arquez, Xavier Carreras, and
Pere Comas. 2007. Combination strategies for se-
mantic role labeling. J. Artif. Intell. Res. (JAIR),
29:105–151.
Nianwen Xue and Martha Palmer. 2005. Automatic
semantic role labeling for Chinese verbs. In in Pro-
ceedings of the 19th International Joint Conference
on Artificial Intelligence, page 2005.
Nianwen Xue. 2008. Labeling chinese predicates
with semantic roles. Computational Linguistics,
34(2):225–255.
</reference>
<page confidence="0.97883">
1483
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.572247">
<title confidence="0.999349">Chinese Semantic Role Labeling with Shallow Parsing</title>
<author confidence="0.998894">Sun Sui Wang</author>
<affiliation confidence="0.9596035">Institute of Computational Peking Key Laboratory of Computational Ministry of Education,</affiliation>
<abstract confidence="0.986653538461538">Most existing systems for Chinese Semantic Role Labeling (SRL) make use of full syntactic parses. In this paper, we evaluate SRL methods that take partial parses as inputs. We first extend the study on Chinese shallow parsing presented in (Chen et al., 2006) by raising a set of additional features. On the basis of our shallow parser, we implement SRL systems which cast SRL as the classification of syntactic chunks with IOB2 representation for semantic roles (i.e. semantic chunks). Two labeling strategies are presented: 1) directly tagging semantic chunks in onestage, and 2) identifying argument boundaries as a chunking task and labeling their semantic types as a classification task. For both methods, we present encouraging results, achieving significant improvements over the best reported SRL performance in the literature. Additionally, we put forward a rule-based algorithm to automatically acquire Chinese verb formation, which is empirically shown to enhance SRL.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Llu´ıs M`arquez</author>
</authors>
<title>Introduction to the conll-2004 shared task: Semantic role labeling.</title>
<date>2004</date>
<booktitle>In Hwee Tou Ng</booktitle>
<volume>6</volume>
<pages>89--97</pages>
<editor>and Ellen Riloff, editors,</editor>
<location>Boston, Massachusetts, USA,</location>
<marker>Carreras, M`arquez, 2004</marker>
<rawString>Xavier Carreras and Llu´ıs M`arquez. 2004. Introduction to the conll-2004 shared task: Semantic role labeling. In Hwee Tou Ng and Ellen Riloff, editors, HLT-NAACL 2004 Workshop: Eighth Conference on Computational Natural Language Learning (CoNLL-2004), pages 89–97, Boston, Massachusetts, USA, May 6 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenliang Chen</author>
<author>Yujie Zhang</author>
<author>Hitoshi Isahara</author>
</authors>
<title>An empirical study of Chinese chunking.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>97--104</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="2751" citStr="Chen et al., 2006" startWordPosition="428" endWordPosition="431">ce reported on the Chinese Proposition Bank (CPB) corresponds to a F-measure is 92.0, when using the handcrafted parse trees from Chinese Penn Treebank (CTB). This performance drops to 71.9 when a real parser is used instead1 (Xue, 2008). Comparatively, the best English SRL results reported drops from 91.2 (Pradhan et al., 2008) to 80.56 (Surdeanu et al., 2007). These results suggest that as still in its infancy stage, Chinese full parsing acts as a central bottleneck that severely limits our ability to solve Chinese SRL. On the contrary, Chinese shallow parsing has gained a promising result (Chen et al., 2006); hence it is an alternative choice for Chinese SRL. This paper addresses the Chinese SRL problem on the basis of shallow syntactic information at the level of phrase chunks. We first extend the study on Chinese chunking presented in (Chen et al., 2006) by raising a set of additional features. The new set of features yield improvement over the strong chunking system described in (Chen et al., 2006). On the basis of our shallow parser, we implement lightweight systems which solve SRL as a sequence labeling problem. This is accomplished by casting SRL as the classification of syntactic chunks (e</context>
<context position="7357" citStr="Chen et al., 2006" startWordPosition="1166" endWordPosition="1169"> labeling performance has been achieved by full parse based SRL systems, partial parse based SRL systems can still enhance their performance. Though better understanding of SRL with shallow parsing on English is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004), little is known about how these SRL methods perform on Chinese. 3 Chinese Shallow Parsing There have been some research on Chinese shallow parsing, and a variety of chunk definitions have been proposed. However, most of these studies did not provide sufficient detail. In our system, we use chunk definition presented in (Chen et al., 2006), which provided a chunk extraction tool. The tool to extract chunks from CTB was developed by modifying the English tool used in CoNLL-2000 shared task, Chunklink3, and is publicly available at http://www.nlplab.cn/chenwl/chunking.html. The definition of syntactic chunks is illustrated in Line CH in Figure 1. For example, ”保险公司/the insurance company”, consisting of two nouns, is a noun phrase. With IOB2 representation (Ramshaw and Marcus, 1995), the problem of Chinese chunking can be regarded as a sequence labeling task. In this paper, we first implement the chunking method described in (Chen</context>
</contexts>
<marker>Chen, Zhang, Isahara, 2006</marker>
<rawString>Wenliang Chen, Yujie Zhang, and Hitoshi Isahara. 2006. An empirical study of Chinese chunking. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 97–104, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaodong Chen</author>
<author>Ting Wang</author>
<author>Huowang Chen</author>
<author>Xishan Xu</author>
</authors>
<title>Semantic role labeling of Chinese using transductive svm and semantic heuristics.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Joint Conference on Natural Language Processing:</booktitle>
<publisher>Volume-II.</publisher>
<contexts>
<context position="5804" citStr="Chen et al. (2008)" startWordPosition="920" endWordPosition="923">antically annotated corpus of Chinese. Their experiments were evaluated only on ten specified verbs with a small collection of Chinese sentences. This work made the first attempt on Chinese SRL and produced promising results. After the CPB was built, (Xue and Palmer, 2005) and (Xue, 2008) have produced more complete and systematic research on Chinese SRL. Ding and Chang (2008) divided SRC into two sub-tasks in sequence. Under the hierarchical architecture, each argument should first be determined whether it is a core argument or an adjunct, and then be classified into fine-grained categories. Chen et al. (2008) introduced an application of transductive SVM in Chinese SRL. Because their experiments took hand-crafted syntactic trees as input, how transductive SVMs perform in Chinese SRL in realistic situations is still unknown. Most existing systems for automatic Chinese SRL make use of a full syntactic parse of the sentence in order to define argument boundaries and 2Our system is available at http://code.google.com/p/csrler/ to extract relevant information for training classifiers to disambiguate between role labels. On the contrary, in English SRL research, there have been some attempts at relaxing</context>
</contexts>
<marker>Chen, Wang, Chen, Xu, 2008</marker>
<rawString>Yaodong Chen, Ting Wang, Huowang Chen, and Xishan Xu. 2008. Semantic role labeling of Chinese using transductive svm and semantic heuristics. In Proceedings of the Third International Joint Conference on Natural Language Processing: Volume-II.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Ding</author>
<author>Baobao Chang</author>
</authors>
<title>Improving Chinese semantic role classification with hierarchical feature selection strategy.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>324--333</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="1704" citStr="Ding and Chang, 2008" startWordPosition="256" endWordPosition="259"> over the best reported SRL performance in the literature. Additionally, we put forward a rule-based algorithm to automatically acquire Chinese verb formation, which is empirically shown to enhance SRL. 1 Introduction In the last few years, there has been an increasing interest in Semantic Role Labeling (SRL) on several languages, which consists of recognizing arguments involved by predicates of a given sentence and labeling their semantic types. Nearly all previous Chinese SRL research took full syntactic parsing as a necessary pre-processing step, such as (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008). Many features are extracted to encode the complex syntactic information. In English SRL research, there have been some attempts at relaxing the necessity of using full syntactic parses; better understanding of SRL with shallow parsing is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004). However, it is still unknown how these methods perform on other languages, such as Chinese. To date, the best SRL performance reported on the Chinese Proposition Bank (CPB) corresponds to a F-measure is 92.0, when using the handcrafted parse trees from Chinese Penn Treebank (CTB). This perform</context>
<context position="5099" citStr="Ding and Chang, 2008" startWordPosition="807" endWordPosition="810">results on CPB2. The best F-measure performance (74.12) with gold segmentation and POS tagging can be achieved by the first method. This result yield significant improvement over the best reported SRL performance (71.9) in the literature (Xue, 2008). The best recall performance (71.50) can be achieved by the second method. This result is also much higher than the best reported recall (65.6) in (Xue, 2008). 2 Related Work Previous work on Chinese SRL mainly focused on how to implement SRL methods which are successful on English, such as (Sun and Jurafsky, 2004; Xue and Palmer, 2005; Xue, 2008; Ding and Chang, 2008). Sun and Jurafsky (2004) did the preliminary work on Chinese SRL without any large semantically annotated corpus of Chinese. Their experiments were evaluated only on ten specified verbs with a small collection of Chinese sentences. This work made the first attempt on Chinese SRL and produced promising results. After the CPB was built, (Xue and Palmer, 2005) and (Xue, 2008) have produced more complete and systematic research on Chinese SRL. Ding and Chang (2008) divided SRC into two sub-tasks in sequence. Under the hierarchical architecture, each argument should first be determined whether it </context>
<context position="22817" citStr="Ding and Chang, 2008" startWordPosition="3770" endWordPosition="3773">. First/last characters. Word length. Conjunction of word length and first/last character. Conjunction of token position and first/last character. The head string of a verb (e.g. ”理” in ”理发”) . The adverbial string of a verb (e.g. ”误” in ”误 用”) . The complement string of a verb (e.g. ”f” in ”超f”). The object string of a verb (e.g. ”发” in ”理 发”) . 6 Results and Discussion 6.1 Experimental Setting 6.1.1 Data Experiments in previous work are mainly based on CPB and CTB, but the experimental data preparing procedure does not seem consistent. For example, the sum of each semantic role reported in (Ding and Chang, 2008) is extremely smaller than the corresponding occurrence statistics in original data files in CPB. In this paper, we modify CoNLL-2005 shared task software6 to process CPB and CTB. In our experiments, we use the CPB 1.0 and CTB 5.0. The data is divided into three parts: files from chtb 081 to chtb 899 are used as training set; files from chtb 041 to 6http://www.lsi.upc.edu/∼srlconll/soft.html begin h=c=a=o=null; if n = 4 and c1 = c3 and c2 = c4 then return Verb formation of W0 = c1c3; else if n = 3 and c2 = c3 then h = c1, c = c2; else if n = 2 and c1 = c2 then h = c1; else if n = 1 then h = c1</context>
</contexts>
<marker>Ding, Chang, 2008</marker>
<rawString>Weiwei Ding and Baobao Chang. 2008. Improving Chinese semantic role classification with hierarchical feature selection strategy. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 324–333, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kadri Hacioglu</author>
<author>Wayne Ward</author>
</authors>
<title>Target word detection and semantic role chunking using support vector machines.</title>
<date>2003</date>
<booktitle>In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>25--27</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6518" citStr="Hacioglu and Ward (2003)" startWordPosition="1029" endWordPosition="1032">ook hand-crafted syntactic trees as input, how transductive SVMs perform in Chinese SRL in realistic situations is still unknown. Most existing systems for automatic Chinese SRL make use of a full syntactic parse of the sentence in order to define argument boundaries and 2Our system is available at http://code.google.com/p/csrler/ to extract relevant information for training classifiers to disambiguate between role labels. On the contrary, in English SRL research, there have been some attempts at relaxing the necessity of using syntactic information derived from full parse trees. For example, Hacioglu and Ward (2003) considered SRL as a chunking task; Pradhan et al. (2005) introduced a new procedure to incorporate SRL results predicted respectively on full and shallow syntactic parses. Previous work on English suggests that even good labeling performance has been achieved by full parse based SRL systems, partial parse based SRL systems can still enhance their performance. Though better understanding of SRL with shallow parsing on English is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004), little is known about how these SRL methods perform on Chinese. 3 Chinese Shallow Parsing There have </context>
</contexts>
<marker>Hacioglu, Ward, 2003</marker>
<rawString>Kadri Hacioglu and Wayne Ward. 2003. Target word detection and semantic role chunking using support vector machines. In NAACL ’03: Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 25–27, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sathiya Keerthi</author>
<author>Dennis DeCoste</author>
</authors>
<title>A modified finite newton method for fast solution of large scale linear svms.</title>
<date>2005</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>6--341</pages>
<contexts>
<context position="24490" citStr="Keerthi and DeCoste, 2005" startWordPosition="4089" endWordPosition="4092">ask. 6.1.2 Classifier For both syntactic and semantic chunking, we used TinySVM along with YamCha7 (Kudo and Matsumoto, 2000; Kudo and Matsumoto, 2001). In the chunking experiments, all SVM classifiers were realized with a polynomial kernel of degree 2. Pair-wise strategy is used to solve multiclass classification problem. For the SRC experiments, we use a linear SVM classifier, along with One-Vs-All approach for multi-class classification. SVMlin8, a fast linear SVM solvers, is used for supervised learning. 12-SVM-MFN (modified finite newton) method is used to solve the optimization problem (Keerthi and DeCoste, 2005). 6.2 Shallow Parsing Performance P(%) R(%) Fβ=1 Baseline 93.54 93.00 93.27 Ours 93.83 93.39 93.61 Table 2: Shallow parsing performance Table 2 summarizes the overall shallow parsing performance on test set. The first line shows the performance of baseline. Comparing the best system performance 94.13 F-measure of CoNLL 2000 shared task (Syntactic Chunking on English), we can see Chinese shallow parsing has reached a comparable result, tough the comparison of numeric performance is not very fair, because of different languages, different chunk definition, different training data sizes, etc.. Th</context>
</contexts>
<marker>Keerthi, DeCoste, 2005</marker>
<rawString>S. Sathiya Keerthi and Dennis DeCoste. 2005. A modified finite newton method for fast solution of large scale linear svms. J. Mach. Learn. Res., 6:341–361.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Use of support vector learning for chunk identification.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning,</booktitle>
<pages>142--144</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="23988" citStr="Kudo and Matsumoto, 2000" startWordPosition="4011" endWordPosition="4014"> 2 and c1 = c2 then h = c1; else if n = 1 then h = c1; else if cn E C and cn−1cn E C and P=”VV” then h = c1, c = cn/cn−1cn; else if c1 E A then a = c1, h = c2...cn; else if c1 E O and P=”VV” then h = c1,o = c2...cn; end 1480 chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. The data setting is the same as (Xue, 2008). The results were evaluated for precision, recall and Fmeasure numbers using the srl-eval.pl script provided by CoNLL-2005 shared task. 6.1.2 Classifier For both syntactic and semantic chunking, we used TinySVM along with YamCha7 (Kudo and Matsumoto, 2000; Kudo and Matsumoto, 2001). In the chunking experiments, all SVM classifiers were realized with a polynomial kernel of degree 2. Pair-wise strategy is used to solve multiclass classification problem. For the SRC experiments, we use a linear SVM classifier, along with One-Vs-All approach for multi-class classification. SVMlin8, a fast linear SVM solvers, is used for supervised learning. 12-SVM-MFN (modified finite newton) method is used to solve the optimization problem (Keerthi and DeCoste, 2005). 6.2 Shallow Parsing Performance P(%) R(%) Fβ=1 Baseline 93.54 93.00 93.27 Ours 93.83 93.39 93.61</context>
</contexts>
<marker>Kudo, Matsumoto, 2000</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2000. Use of support vector learning for chunk identification. In Proceedings of the 2nd workshop on Learning language in logic and the 4th conference on Computational natural language learning, pages 142–144, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In NAACL ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies 2001,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="24015" citStr="Kudo and Matsumoto, 2001" startWordPosition="4015" endWordPosition="4018">; else if n = 1 then h = c1; else if cn E C and cn−1cn E C and P=”VV” then h = c1, c = cn/cn−1cn; else if c1 E A then a = c1, h = c2...cn; else if c1 E O and P=”VV” then h = c1,o = c2...cn; end 1480 chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. The data setting is the same as (Xue, 2008). The results were evaluated for precision, recall and Fmeasure numbers using the srl-eval.pl script provided by CoNLL-2005 shared task. 6.1.2 Classifier For both syntactic and semantic chunking, we used TinySVM along with YamCha7 (Kudo and Matsumoto, 2000; Kudo and Matsumoto, 2001). In the chunking experiments, all SVM classifiers were realized with a polynomial kernel of degree 2. Pair-wise strategy is used to solve multiclass classification problem. For the SRC experiments, we use a linear SVM classifier, along with One-Vs-All approach for multi-class classification. SVMlin8, a fast linear SVM solvers, is used for supervised learning. 12-SVM-MFN (modified finite newton) method is used to solve the optimization problem (Keerthi and DeCoste, 2005). 6.2 Shallow Parsing Performance P(%) R(%) Fβ=1 Baseline 93.54 93.00 93.27 Ours 93.83 93.39 93.61 Table 2: Shallow parsing p</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In NAACL ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies 2001, pages 1–8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Semantic role chunking combining complementary syntactic views.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>217--220</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="6575" citStr="Pradhan et al. (2005)" startWordPosition="1039" endWordPosition="1042">SVMs perform in Chinese SRL in realistic situations is still unknown. Most existing systems for automatic Chinese SRL make use of a full syntactic parse of the sentence in order to define argument boundaries and 2Our system is available at http://code.google.com/p/csrler/ to extract relevant information for training classifiers to disambiguate between role labels. On the contrary, in English SRL research, there have been some attempts at relaxing the necessity of using syntactic information derived from full parse trees. For example, Hacioglu and Ward (2003) considered SRL as a chunking task; Pradhan et al. (2005) introduced a new procedure to incorporate SRL results predicted respectively on full and shallow syntactic parses. Previous work on English suggests that even good labeling performance has been achieved by full parse based SRL systems, partial parse based SRL systems can still enhance their performance. Though better understanding of SRL with shallow parsing on English is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004), little is known about how these SRL methods perform on Chinese. 3 Chinese Shallow Parsing There have been some research on Chinese shallow parsing, and a vari</context>
</contexts>
<marker>Pradhan, Hacioglu, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Wayne Ward, James H. Martin, and Daniel Jurafsky. 2005. Semantic role chunking combining complementary syntactic views. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 217–220, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer S Pradhan</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
</authors>
<title>Towards robust semantic role labeling.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="2463" citStr="Pradhan et al., 2008" startWordPosition="378" endWordPosition="381">ing the necessity of using full syntactic parses; better understanding of SRL with shallow parsing is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004). However, it is still unknown how these methods perform on other languages, such as Chinese. To date, the best SRL performance reported on the Chinese Proposition Bank (CPB) corresponds to a F-measure is 92.0, when using the handcrafted parse trees from Chinese Penn Treebank (CTB). This performance drops to 71.9 when a real parser is used instead1 (Xue, 2008). Comparatively, the best English SRL results reported drops from 91.2 (Pradhan et al., 2008) to 80.56 (Surdeanu et al., 2007). These results suggest that as still in its infancy stage, Chinese full parsing acts as a central bottleneck that severely limits our ability to solve Chinese SRL. On the contrary, Chinese shallow parsing has gained a promising result (Chen et al., 2006); hence it is an alternative choice for Chinese SRL. This paper addresses the Chinese SRL problem on the basis of shallow syntactic information at the level of phrase chunks. We first extend the study on Chinese chunking presented in (Chen et al., 2006) by raising a set of additional features. The new set of fe</context>
</contexts>
<marker>Pradhan, Ward, Martin, 2008</marker>
<rawString>Sameer S. Pradhan, Wayne Ward, and James H. Martin. 2008. Towards robust semantic role labeling. Comput. Linguist., 34(2):289–310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Text chunking using transformation-based learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the 3rd ACL/SIGDAT Workshop on Very Large Corpora,</booktitle>
<pages>82--94</pages>
<location>Cambridge, Massachusetts, USA,</location>
<contexts>
<context position="7806" citStr="Ramshaw and Marcus, 1995" startWordPosition="1233" endWordPosition="1237"> chunk definitions have been proposed. However, most of these studies did not provide sufficient detail. In our system, we use chunk definition presented in (Chen et al., 2006), which provided a chunk extraction tool. The tool to extract chunks from CTB was developed by modifying the English tool used in CoNLL-2000 shared task, Chunklink3, and is publicly available at http://www.nlplab.cn/chenwl/chunking.html. The definition of syntactic chunks is illustrated in Line CH in Figure 1. For example, ”保险公司/the insurance company”, consisting of two nouns, is a noun phrase. With IOB2 representation (Ramshaw and Marcus, 1995), the problem of Chinese chunking can be regarded as a sequence labeling task. In this paper, we first implement the chunking method described in (Chen et al., 2006) as a strong baseline. To conveniently illustrate, we denote a word in focus with a fixed window w−2w−1ww+1w+2, where w is current token. The baseline features includes: • Uni-gram word/POS tag feature: w−2, w−1, w, w+1, w+2; • Bi-gram word/POS tag feature: w−2 w−1, w−1 w, w w+1, w+1 w+2; 3http://ilk.uvt.nl/team/sabine/chunklink/chunklink 2-2- 2000 for conll.pl 1476 WORD: 截止 目前 保险 公司 E V 三峡 工程 提供 保险 服务 POS: [P] [NT] [NN NN] [AD] [P</context>
</contexts>
<marker>Ramshaw, Marcus, 1995</marker>
<rawString>L. A. Ramshaw and M. P. Marcus. 1995. Text chunking using transformation-based learning. In Proceedings of the 3rd ACL/SIGDAT Workshop on Very Large Corpora, Cambridge, Massachusetts, USA, pages 82–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglin Sun</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Shallow semantc parsing of Chinese.</title>
<date>2004</date>
<booktitle>In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings.</booktitle>
<contexts>
<context position="1670" citStr="Sun and Jurafsky, 2004" startWordPosition="250" endWordPosition="253"> achieving significant improvements over the best reported SRL performance in the literature. Additionally, we put forward a rule-based algorithm to automatically acquire Chinese verb formation, which is empirically shown to enhance SRL. 1 Introduction In the last few years, there has been an increasing interest in Semantic Role Labeling (SRL) on several languages, which consists of recognizing arguments involved by predicates of a given sentence and labeling their semantic types. Nearly all previous Chinese SRL research took full syntactic parsing as a necessary pre-processing step, such as (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008). Many features are extracted to encode the complex syntactic information. In English SRL research, there have been some attempts at relaxing the necessity of using full syntactic parses; better understanding of SRL with shallow parsing is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004). However, it is still unknown how these methods perform on other languages, such as Chinese. To date, the best SRL performance reported on the Chinese Proposition Bank (CPB) corresponds to a F-measure is 92.0, when using the handcrafted parse trees from Chinese</context>
<context position="5043" citStr="Sun and Jurafsky, 2004" startWordPosition="797" endWordPosition="800">both shallow parsing and SRL. We present encouraging SRL results on CPB2. The best F-measure performance (74.12) with gold segmentation and POS tagging can be achieved by the first method. This result yield significant improvement over the best reported SRL performance (71.9) in the literature (Xue, 2008). The best recall performance (71.50) can be achieved by the second method. This result is also much higher than the best reported recall (65.6) in (Xue, 2008). 2 Related Work Previous work on Chinese SRL mainly focused on how to implement SRL methods which are successful on English, such as (Sun and Jurafsky, 2004; Xue and Palmer, 2005; Xue, 2008; Ding and Chang, 2008). Sun and Jurafsky (2004) did the preliminary work on Chinese SRL without any large semantically annotated corpus of Chinese. Their experiments were evaluated only on ten specified verbs with a small collection of Chinese sentences. This work made the first attempt on Chinese SRL and produced promising results. After the CPB was built, (Xue and Palmer, 2005) and (Xue, 2008) have produced more complete and systematic research on Chinese SRL. Ding and Chang (2008) divided SRC into two sub-tasks in sequence. Under the hierarchical architectu</context>
<context position="14056" citStr="Sun and Jurafsky, 2004" startWordPosition="2292" endWordPosition="2295">periments, we represent a verb in two dimensions: 1) number of arguments, and 2) number of framesets. For example, a verb may belong to the class ”C1C2,” which means that this verb has two framesets, with the first frameset having one argument and the second having two arguments. To conveniently illustrate, we denote a token chunk with a fixed context wi_1[ckwi...wh...wj]wj+1, where wh is the head word of this chunk ck. The complete list of features is listed here. Extraction on Syntactic Chunks Chunk type: ck. Length: the number of words in a chunk. Head word/POS tag. The rules described in (Sun and Jurafsky, 2004) are used to extract head word. IOB chunk tag of head word: chunk tag of head word with IOB2 representation (e.g. B-NP, I-NP). 5The source code of our system also provides lots of comments for implementation of all features. Chunk words/POS tags context. Chunk context includes one word before and one word after: wi_1 and wj+1. POS tag chain: sequential containers of each word’s POS tag: wi ... wj. For example, this feature for ”保险服务” is ”NN NN”. Position: the position of the phrase with respect to the predicate. It has three values as before, after and here. Extraction on Target Verbs Given a </context>
</contexts>
<marker>Sun, Jurafsky, 2004</marker>
<rawString>Honglin Sun and Daniel Jurafsky. 2004. Shallow semantc parsing of Chinese. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Llu´ıs M`arquez</author>
<author>Xavier Carreras</author>
<author>Pere Comas</author>
</authors>
<title>Combination strategies for semantic role labeling.</title>
<date>2007</date>
<journal>J. Artif. Intell. Res. (JAIR),</journal>
<pages>29--105</pages>
<marker>Surdeanu, M`arquez, Carreras, Comas, 2007</marker>
<rawString>Mihai Surdeanu, Llu´ıs M`arquez, Xavier Carreras, and Pere Comas. 2007. Combination strategies for semantic role labeling. J. Artif. Intell. Res. (JAIR), 29:105–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Automatic semantic role labeling for Chinese verbs. In</title>
<date>2005</date>
<booktitle>in Proceedings of the 19th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>page</pages>
<contexts>
<context position="5065" citStr="Xue and Palmer, 2005" startWordPosition="801" endWordPosition="804"> SRL. We present encouraging SRL results on CPB2. The best F-measure performance (74.12) with gold segmentation and POS tagging can be achieved by the first method. This result yield significant improvement over the best reported SRL performance (71.9) in the literature (Xue, 2008). The best recall performance (71.50) can be achieved by the second method. This result is also much higher than the best reported recall (65.6) in (Xue, 2008). 2 Related Work Previous work on Chinese SRL mainly focused on how to implement SRL methods which are successful on English, such as (Sun and Jurafsky, 2004; Xue and Palmer, 2005; Xue, 2008; Ding and Chang, 2008). Sun and Jurafsky (2004) did the preliminary work on Chinese SRL without any large semantically annotated corpus of Chinese. Their experiments were evaluated only on ten specified verbs with a small collection of Chinese sentences. This work made the first attempt on Chinese SRL and produced promising results. After the CPB was built, (Xue and Palmer, 2005) and (Xue, 2008) have produced more complete and systematic research on Chinese SRL. Ding and Chang (2008) divided SRC into two sub-tasks in sequence. Under the hierarchical architecture, each argument shou</context>
</contexts>
<marker>Xue, Palmer, 2005</marker>
<rawString>Nianwen Xue and Martha Palmer. 2005. Automatic semantic role labeling for Chinese verbs. In in Proceedings of the 19th International Joint Conference on Artificial Intelligence, page 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Labeling chinese predicates with semantic roles.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="1681" citStr="Xue, 2008" startWordPosition="254" endWordPosition="255">mprovements over the best reported SRL performance in the literature. Additionally, we put forward a rule-based algorithm to automatically acquire Chinese verb formation, which is empirically shown to enhance SRL. 1 Introduction In the last few years, there has been an increasing interest in Semantic Role Labeling (SRL) on several languages, which consists of recognizing arguments involved by predicates of a given sentence and labeling their semantic types. Nearly all previous Chinese SRL research took full syntactic parsing as a necessary pre-processing step, such as (Sun and Jurafsky, 2004; Xue, 2008; Ding and Chang, 2008). Many features are extracted to encode the complex syntactic information. In English SRL research, there have been some attempts at relaxing the necessity of using full syntactic parses; better understanding of SRL with shallow parsing is achieved by CoNLL-2004 shared task (Carreras and M`arquez, 2004). However, it is still unknown how these methods perform on other languages, such as Chinese. To date, the best SRL performance reported on the Chinese Proposition Bank (CPB) corresponds to a F-measure is 92.0, when using the handcrafted parse trees from Chinese Penn Treeb</context>
<context position="4727" citStr="Xue, 2008" startWordPosition="744" endWordPosition="745">constructed from morphemes, known as word formation, is very important for a majority of Chinese language processing tasks. To capture Chinese verb formation information, we introduce a rule-based algorithm with a number of heuristics. Experimental results indicate that word formation features can help both shallow parsing and SRL. We present encouraging SRL results on CPB2. The best F-measure performance (74.12) with gold segmentation and POS tagging can be achieved by the first method. This result yield significant improvement over the best reported SRL performance (71.9) in the literature (Xue, 2008). The best recall performance (71.50) can be achieved by the second method. This result is also much higher than the best reported recall (65.6) in (Xue, 2008). 2 Related Work Previous work on Chinese SRL mainly focused on how to implement SRL methods which are successful on English, such as (Sun and Jurafsky, 2004; Xue and Palmer, 2005; Xue, 2008; Ding and Chang, 2008). Sun and Jurafsky (2004) did the preliminary work on Chinese SRL without any large semantically annotated corpus of Chinese. Their experiments were evaluated only on ten specified verbs with a small collection of Chinese senten</context>
<context position="13150" citStr="Xue (2008)" startWordPosition="2138" endWordPosition="2139">in the target verb chunks. 4.2 Features Most of the feature templates are ”standard”, which have been used in previous SRL research. We give a brief description of ”standard” features, but explain our new features in detail.5 4.2.1 Features for Semantic Chunking In the semantic chunking tasks, i.e. the one-stage method and the first step in the two-stage method, we use the same set of features. The features are extracted from three types of elements: syntactic chunks, target verbs, links between chunks and target verbs. They are formed making use of words, POS tags and chunks of the sentence. Xue (2008) put forward a rough verb classification where verb classes are automatically derived from the frame files, which are verb lexicon for the CPB annotation. This kind of verb class information has been shown very useful for Chinese SRL. Our system also includes this feature. In our experiments, we represent a verb in two dimensions: 1) number of arguments, and 2) number of framesets. For example, a verb may belong to the class ”C1C2,” which means that this verb has two framesets, with the first frameset having one argument and the second having two arguments. To conveniently illustrate, we denot</context>
<context position="23732" citStr="Xue, 2008" startWordPosition="3974" endWordPosition="3975"> used as training set; files from chtb 041 to 6http://www.lsi.upc.edu/∼srlconll/soft.html begin h=c=a=o=null; if n = 4 and c1 = c3 and c2 = c4 then return Verb formation of W0 = c1c3; else if n = 3 and c2 = c3 then h = c1, c = c2; else if n = 2 and c1 = c2 then h = c1; else if n = 1 then h = c1; else if cn E C and cn−1cn E C and P=”VV” then h = c1, c = cn/cn−1cn; else if c1 E A then a = c1, h = c2...cn; else if c1 E O and P=”VV” then h = c1,o = c2...cn; end 1480 chtb 080 as development set; files from chtb 001 to chtb 040, and chtb 900 to chtb 931 as test set. The data setting is the same as (Xue, 2008). The results were evaluated for precision, recall and Fmeasure numbers using the srl-eval.pl script provided by CoNLL-2005 shared task. 6.1.2 Classifier For both syntactic and semantic chunking, we used TinySVM along with YamCha7 (Kudo and Matsumoto, 2000; Kudo and Matsumoto, 2001). In the chunking experiments, all SVM classifiers were realized with a polynomial kernel of degree 2. Pair-wise strategy is used to solve multiclass classification problem. For the SRC experiments, we use a linear SVM classifier, along with One-Vs-All approach for multi-class classification. SVMlin8, a fast linear </context>
<context position="26466" citStr="Xue, 2008" startWordPosition="4409" endWordPosition="4410">rk. Take the sentences below for example: 1. [V P Q k 获 得 胜 利]. (Therefore (we) achieve victory.) tt--- 2. [ADV P Qk] [V P l� `�i现] 的是以前不 曾遇到的. (Therefore the major changes have not been met before.) The contexts of the word ”Qk/therefore” in the two sentences are similar, where ”Qk” is followed by verbal components. In the second sentence, the word ”Qk/therefore” will be correctly recognized as an adverbial phrase unless classifier knows the following component is a clause. Unfortunately, word formation features cannot supply this kind of information. 6.3 SRL Performance P(%) R(%) A(%) Fβ=1 (Xue, 2008) 79.5 65.6 – 71.9 M1− 79.02 69.12 – 73.74 M1+ 79.25 69.61 – 74.12 M2−/AI 80.34 75.11 – 77.63 M2+/AI 80.01 75.15 – 77.51 M2−/SRC – – 92.57 – M2+wf/SRC – – 93.25 – M2+/SRC – – 93.42 – M2−AI+SRC 76.48 71.50 – 73.90 Table 4: Overall SRL performance of different methods Table 4 lists the overall SRL performance numbers on test set using different methods mentioned earlier; these results are based on features computed from gold standard segmentation and POS tagging, but automatic recognized chunks, which is parsed by our improved shallow parsing system. For the AI and the whole SRL tasks, we report </context>
</contexts>
<marker>Xue, 2008</marker>
<rawString>Nianwen Xue. 2008. Labeling chinese predicates with semantic roles. Computational Linguistics, 34(2):225–255.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>