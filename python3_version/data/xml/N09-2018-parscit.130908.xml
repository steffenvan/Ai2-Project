<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.312799">
<title confidence="0.958492">
Web and Corpus Methods for Malay Count Classifier Prediction
</title>
<author confidence="0.982403">
Jeremy Nicholson and Timothy Baldwin
</author>
<affiliation confidence="0.9848645">
NICTA Victoria Research Laboratories
University of Melbourne, VIC 3010, Australia
</affiliation>
<email confidence="0.996463">
{jeremymn,tim}@csse.unimelb.edu.au
</email>
<sectionHeader confidence="0.993856" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9985981">
We examine the capacity of Web and corpus
frequency methods to predict preferred count
classifiers for nouns in Malay. The observed
F-score for the Web model of 0.671 consid-
erably outperformed corpus-based frequency
and machine learning models. We expect that
this is a fruitful extension for Web–as–corpus
approaches to lexicons in languages other than
English, but further research is required in
other South-East and East Asian languages.
</bodyText>
<sectionHeader confidence="0.998792" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931625">
The objective of this paper is to extend a Malay
lexicon with count classifier information for nomi-
nal types. This is done under the umbrella of deep
lexical acquisition: the process of automatically or
semi-automatically learning linguistic structures for
use in linguistically rich language resources such as
precision grammars or wordnets (Baldwin, 2007).
One might call Malay a “medium-density” lan-
guage: some NLP resources exist, but substantially
fewer than those for English, and they tend to be
of low complexity. Resources like the Web seem
promising for bootstrapping further resources, aided
in part by simple syntax and a Romanised ortho-
graphic system. The vast size of the Web has been
demonstrated to combat the data sparseness prob-
lem, for example, in Lapata and Keller (2004).
We examine using a similar “first gloss” strategy
to Lapata and Keller (akin to “first sense” in WSD,
in this case, identifying the most basic surface form
that a speaker would use to disambiguate between
possible classes), where the Web is used a corpus to
query a set of candidate surface forms, and the fre-
quencies are used to disambiguate the lexical prop-
erty. Due to the heterogeneity of the Web, we expect
</bodyText>
<page confidence="0.989664">
69
</page>
<bodyText confidence="0.999794285714286">
to observe a significant amount of blocking from In-
donesian, a language with which Malay is some-
what mutually intelligible (Gordon, 2005). Hence,
we contrast this approach with observing the cues
directly from a corpus strictly of Malay, as well as a
corpus-based supervised machine learning approach
which does not rely on a presupplied gloss.
</bodyText>
<sectionHeader confidence="0.995951" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.99915">
2.1 Count Classifiers
</subsectionHeader>
<bodyText confidence="0.9998954">
A count classifier (CL) is a noun that occurs in a
specifier phrase with one of a set of (usually nu-
meric) specifiers; the specifier phrase typically oc-
curs in apposition or as a genitive modifier (GEN) to
the head noun. In many languages, including many
South-East Asian, East Asian, and African families,
almost all nouns are uncountable and can only be
counted through specifier phrases. A Malay exam-
ple, where biji is the count classifier (CL) for fruit, is
given in (1).
</bodyText>
<listItem confidence="0.910812333333333">
(1) tiga biji pisang
three CL banana
“three bananas”
</listItem>
<bodyText confidence="0.999862692307692">
Semantically, a lexical entry for a noun will in-
clude a default (sortal) count classifier which se-
lects for a particular semantic property of the lemma.
Usually this is a conceptual class (e.g. HUMAN or
ANIMAL) or a description of some relative dimen-
sional property (e.g. FLAT or LONG-AND-THIN).
Since each count classifier has a precise seman-
tics, using a classifier other than the default can co-
erce a given lemma into different semantics. For ex-
ample, raja “king” typically takes orang “person”
as a classifier, as in 2 orang raja “2 kings”, but can
take on an animal reading with ekor “animal” in 2
ekor raja “2 kingfishers”. An unintended classifier
</bodyText>
<subsubsectionHeader confidence="0.834453">
Proceedings of NAACL HLT 2009: Short Papers, pages 69–72,
</subsubsectionHeader>
<bodyText confidence="0.965035272727273">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
can lead to highly marked or infelicitious readings,
such as #2 biji raja “2 (chess) kings”.
Most research on count classifiers tends to discuss
generating a hierarchy or taxonomy of the classi-
fiers available in a given language (e.g. Bond and
Paik (1997) for Japanese and Korean, or Shirai et
al. (2008) cross-linguistically) or using language-
specific knowledge to predict tokens (e.g. Bond and
Paik (2000)) or both (e.g. Sornlertlamvanich et al.
(1994)).
</bodyText>
<subsectionHeader confidence="0.999694">
2.2 Malay Data
</subsectionHeader>
<bodyText confidence="0.999940974358975">
Little work has been done on NLP for Malay, how-
ever, a stemmer (Adriani et al., 2007) and a prob-
abilistic parser for Indonesian (Gusmita and Manu-
rung, 2008) have been developed. The mutually in-
telligibility suggests that Malay resources could pre-
sumably be extended from these.
In our experiments, we make use of a Malay–
English translation dictionary, KAMI (Quah et al.,
2001), which annotates about 19K nominal lexical
entries for count classifiers. To limit very low fre-
quency entries, we cross-reference these with a cor-
pus of 1.2M tokens of Malay text, described in Bald-
win and Awab (2006). We further exclude the two
non-sortal count classifiers that are attested as de-
fault classifiers in the lexicon, as their distribution is
heavily skewed and not lexicalised.
In all, 2764 simplex common nouns are attested
at least once in the corpus data. We observe 2984
unique noun–to–default classifier assignments. Pol-
ysemy leads to an average of 1.08 count classifiers
assigned to a given wordform. The most difficult
exemplars to classify, and consequently the most in-
teresting ones, correspond to the dispreferred count
classifiers of the multi-class wordforms: direct as-
signment and frequency thresholding was observed
to perform poorly. Since this task is functionally
equivalent to the subcat learning problem, strategies
from that field might prove helpful (e.g. Korhonen
(2002)).
The final distribution of the most frequent classes
is as follows:
CL: orang buah batang ekor OTHER
Freq: 0.389 0.292 0.092 0.078 0.149
Of the 49 classes, only four have a relative frequency
greater than 3% of the types: orang for people,
batang for long, thin objects, ekor for animals, and
buah, the semantically empty classifier, for when no
other classifiers are suitable (e.g. for abstract nouns);
orang and buah account for almost 70% of the types.
</bodyText>
<sectionHeader confidence="0.995423" genericHeader="method">
3 Experiment
</sectionHeader>
<subsectionHeader confidence="0.989277">
3.1 Methodology
</subsectionHeader>
<bodyText confidence="0.999993">
Lapata and Keller (2004) look at a set of generation
and analysis tasks in English, identify simple surface
cues, and query a Web search engine to approximate
those frequencies. They then use maximum likeli-
hood estimation or a variety of normalisation meth-
ods to choose an output.
For a given Malay noun, we attempt to select the
default count classifier, which is a generation task
under their framework, and semantically most simi-
lar to noun countability detection. Specifier phrases
almost always premodify nouns in Malay, so the set
of surface cues we chose was satu CL NOUN “one/a
NOUN”.1 This was observed to have greater cov-
erage than dua “two” and other non-numeral spec-
ifiers. 49 queries were performed for each head-
word, and maximum likelihood estimation was used
to select the predicted classifier (i.e. taking most fre-
quently observed cue, with a threshold of 0). Fre-
quencies from the same cues were also obtained
from the corpus of Baldwin and Awab (2006).
We contrasted this with a machine learning model
for Malay classifiers, designed to be language-
independent (Nicholson and Baldwin, 2008). A fea-
ture vector is constructed for each headword by con-
catenating context windows of four tokens to the left
and right of each instance of the headword in the cor-
pus (for eight word unigram features per instance).
These are then passed into two kinds of maximum
entropy model: one conditioned on all 49 classes,
and one cascaded into a suite of 49 separate binary
classifiers designed to predict each class separately.
Evaluation is via 10-fold stratified cross-validation.
A majority class baseline was also examined, where
every headword was assigned the orang class.
For the corpus-based methods, if the frequency of
every cue is 0, no prediction of classifier is made.
Similarly, the suite can predict a negative assign-
</bodyText>
<footnote confidence="0.933968">
1satu becomes cliticised to se- in this construction, so that
instead of cues like satu buah raja, satu orang raja, ..., we have
cues like sebuah raja, seorang raja, ....
</footnote>
<page confidence="0.953343">
70
</page>
<table confidence="0.99886725">
Method Web Corpus Suite Entire Base
Prec. .736 .908 .652 .570 .420
Rec. .616 .119 .379 .548 .389
F0 = 1 .671 .210 .479 .559 .404
</table>
<tableCaption confidence="0.994529">
Table 1: Performance of the five systems.
</tableCaption>
<table confidence="0.9997595">
Back-off Web Suite Entire orang buah
Prec. .736 .671 .586 .476 .389
Rec. .616 .421 .561 .441 .360
F0 = 1 .671 .517 .573 .458 .374
</table>
<tableCaption confidence="0.9966185">
Table 2: Performance of corpus frequency assignment
(Corpus in Table 1), backed-off to the other systems.
</tableCaption>
<bodyText confidence="0.999960111111111">
ment for each of the 49 classes. Consequently, pre-
cision is calculated as the fraction of correctly pre-
dicted instances to the number of examplars where
a prediction was made. Only the suite of classifiers
could natively handle multi-assignment of classes:
recall was calculated as the fraction of correctly pre-
dicted instances to all 2984 possible headword–class
assignments, despite the fact that four of the systems
could not make 220 of the classifications.
</bodyText>
<subsectionHeader confidence="0.88615">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999975142857143">
The observed precision, recall, and F-scores of the
various systems are shown in Table 1. The best
F-score is observed for the Web frequency system,
which also had the highest recall. The best precision
was observed for the corpus frequency system, but
with very low recall — about 85% of the wordforms
could not be assigned to a class (the corresponding
figure for the Web system was about 9%). Conse-
quently, we attempted a number of back-off strate-
gies so as to improve the recall of this system.
The results for backing off the corpus frequency
system to the Web model, the two maximum entropy
models, and two baselines (the majority class, and
the semantically empty classifier) are shown in Ta-
ble 2. Using a Web back-off was nearly identical to
the basic Web system: most of the correct assign-
ments being made by the corpus frequency system
were also being captured through Web frequencies,
which indicates that these are the easier, high fre-
quency entries. Backing off to the machine learn-
ing models performed the same or slightly better
than using the machine learning model by itself. It
therefore seems that the most balanced corpus-based
model should take this approach.
The fact that the Web frequency system had the
best performance belies the “noisiness” of the Web,
in that one expects to observe errors caused by
carelessness, laziness (e.g. using buah despite a
more specific classifier being available), or noise
(e.g. Indonesian count classifier attestation; more on
this below). While the corpus of “clean”, hand-
constructed data did have a precision improvement
over the Web system, the back-off demonstrates that
it was not substantially better over those entries that
could be classified from the corpus data.
</bodyText>
<sectionHeader confidence="0.999698" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999993303030303">
As with many classification tasks, the Web-based
model notably outperformed the corpus-based mod-
els when used to predict count classifiers of Malay
noun types, particularly in recall. In a type-wise lex-
icon, precision is probably the more salient evalua-
tion metric, as recall is more meaningful on tokens,
and a low-precision lexicon is often of little utility;
the Web system had at least comparable precision
for the entries able to be classified by the corpus-
based systems.
We expected that the heterogeneity of the Web,
particularly confusion caused by a preponderance of
Indonesian, would cause performance to drop, but
this was not the case. The Ethnologue estimates that
there are more speakers of Indonesian than Malay
(Gordon, 2005), and one would expect the Web dis-
tribution to reflect this. Also, there are systematic
differences in the way count classifiers are used in
the two languages, despite the intelligibility; com-
pare “five photographs”: lima keping foto in Malay
and lima lembar foto, lima foto in Indonesian.
While the use of count classifiers is obligatory in
Malay, it is optional in Indonesian for lower reg-
isters. Also, many classifiers that are available in
Malay are not used in Indonesian, and the small set
of Indonesian count classifiers that are not used in
Malay do not form part of the query set, so no confu-
sion results. Consequently, it seems that greater dif-
ficulty would arise when attempting to predict count
classifiers for Indonesian nouns, as their optional-
ity and blocking from Malay cognates would intro-
duce noise in cases where language identification
has not been used to generate the corpus (like the
</bodyText>
<page confidence="0.996671">
71
</page>
<bodyText confidence="0.999687375">
Web) — hand-constructed corpora might be neces-
sary in that case. Furthermore, the Web system ben-
efits from a very simple surface form, namely se-
CL NOUN: languages that permit floating quantifica-
tion, like Japanese, or require classifiers for stative
verb modification, like Thai, would need many more
queries or lower-precision queries to capture most of
the cues available from the corpus. We intend to ex-
amine these phenomena in future work.
An important contrast is noted between the “un-
supervised” methods of the corpus-frequency sys-
tems and the “supervised” machine learning meth-
ods. One presumed advantage of unsupervised sys-
tems is the lack of pre-annotated training data re-
quired. In this case, a comparable time investment
by a lexicographer would be required to generate the
set of surface forms for the corpus-frequency mod-
els. The performance dictates that the glosses for the
Web system give the most value for lexicographer
input; however, for other languages or other lexical
properties, generating a set of high-precision, high-
recall glosses is often non-trivial. If the Web is not
used, having both training data and high-precision,
low-recall glosses is valuable.
</bodyText>
<sectionHeader confidence="0.998835" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999995666666667">
We examine an approach for using Web and cor-
pus data to predict the preferred generation form for
counting nouns in Malay, and observed greater pre-
cision than machine learning methods that do not
require a presupplied gloss. Most Web–as–corpus
research tends to focus on English; as the Web in-
creases in multilinguality, it becomes an important
resource for medium- and low-density languages.
This task was quite simple, with glosses amenable to
Web approaches, and is promising for automatically
extending the coverage of a Malay lexicon. How-
ever, we expect that the Malay glosses will block
readings of Indonesian classifiers, and classifiers in
other languages will require different strategies; we
intend to examine this in future work.
</bodyText>
<sectionHeader confidence="0.996306" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.997298666666667">
We would like to thank Francis Bond for his valuable in-
put on this research. NICTA is funded by the Australian
government as represented by Department of Broadband,
Communication and Digital Economy, and the Australian
Research Council through the ICT Centre of Excellence
programme.
</bodyText>
<sectionHeader confidence="0.986066" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999365666666666">
M. Adriani, J. Asian, B. Nazief, S.M.M. Tahaghoghi,
and H.E. Williams. 2007. Stemming Indonesian:
A confix-stripping approach. ACM Transactions on
Asian Language Information Processing, 6.
T. Baldwin and S. Awab. 2006. Open source corpus anal-
ysis tools for Malay. In Proc. of the 5th International
Conference on Language Resources and Evaluation,
pages 2212–5, Genoa, Italy.
T. Baldwin. 2007. Scalable deep linguistic processing:
Mind the lexical gap. In Proc. of the 21st Pacific Asia
Conference on Language, Information and Computa-
tion, pages 3–12, Seoul, Korea.
F. Bond and K. Paik. 1997. Classifying correspondence
in Japanese and Korean. In Proc. of the 3rd Confer-
ence of the Pacific Association for Computational Lin-
guistics, pages 58–67, Tokyo, Japan.
F. Bond and K. Paik. 2000. Reusing an ontology to
generate numeral classifiers. In Proc. of the 19th In-
ternational Conference on Computational Linguistics,
pages 90–96, Saarbr¨ucken, Germany.
R.G. Gordon, Jr, editor. 2005. Ethnologue: Languages
of the World, Fifteenth Edition. SIL International.
R.H. Gusmita and Ruli Manurung. 2008. Some initial
experiments with Indonesian probabilistic parsing. In
Proc. of the 2nd International MALINDO Workshop,
Cyberjaya, Malaysia.
A. Korhonen. 2002. Subcategorization Acquisition.
Ph.D. thesis, University of Cambridge, Cambridge,
UK.
M. Lapata and F. Keller. 2004. The web as a base-
line: Evaluating the performance of unsupervised
web-based models for a range of NLP tasks. In Proc.
of the 4th International Conference on Human Lan-
guage Technology Research and 5th Annual Meeting
of the NAACL, pages 121–128, Boston, USA.
J. Nicholson and T. Baldwin. 2008. Learning count
classifier preferences of Malay nouns. In Proc. of the
Australasian Language Technology Association Work-
shop, pages 115–123, Hobart, Australia.
C.K. Quah, F. Bond, and T. Yamazaki. 2001. De-
sign and construction of a machine-tractable Malay-
English lexicon. In Proc. of the 2nd Biennial Confer-
ence of ASIALEX, pages 200–205, Seoul, Korea.
K. Shirai, T. Tokunaga, C-R. Huang, S-K. Hsieh, T-
Y. Kuo, V. Sornlertlamvanich, and T. Charoenporn.
2008. Constructing taxonomy of numerative classi-
fiers for Asian languages. In Proc. of the Third Inter-
national Joint Conference on Natural Language Pro-
cessing, Hyderabad, India.
V. Sornlertlamvanich, W. Pantachat, and S. Meknavin.
1994. Classifier assignment by corpus-based ap-
proach. In Proc. of the 15th International Conference
on Computational Linguistics, pages 556–561, Kyoto,
Japan.
</reference>
<page confidence="0.99872">
72
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.555395">
<title confidence="0.999701">Web and Corpus Methods for Malay Count Classifier Prediction</title>
<author confidence="0.999191">Nicholson Baldwin</author>
<affiliation confidence="0.978984">NICTA Victoria Research</affiliation>
<address confidence="0.573962">University of Melbourne, VIC 3010, Australia</address>
<email confidence="0.997611">jeremymn@csse.unimelb.edu.au</email>
<email confidence="0.997611">tim@csse.unimelb.edu.au</email>
<abstract confidence="0.997373363636364">We examine the capacity of Web and corpus frequency methods to predict preferred count classifiers for nouns in Malay. The observed F-score for the Web model of 0.671 considerably outperformed corpus-based frequency and machine learning models. We expect that this is a fruitful extension for Web–as–corpus approaches to lexicons in languages other than English, but further research is required in other South-East and East Asian languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Adriani</author>
<author>J Asian</author>
<author>B Nazief</author>
<author>S M M Tahaghoghi</author>
<author>H E Williams</author>
</authors>
<title>Stemming Indonesian: A confix-stripping approach.</title>
<date>2007</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>6</volume>
<contexts>
<context position="4147" citStr="Adriani et al., 2007" startWordPosition="665" endWordPosition="668">do, June 2009. c�2009 Association for Computational Linguistics can lead to highly marked or infelicitious readings, such as #2 biji raja “2 (chess) kings”. Most research on count classifiers tends to discuss generating a hierarchy or taxonomy of the classifiers available in a given language (e.g. Bond and Paik (1997) for Japanese and Korean, or Shirai et al. (2008) cross-linguistically) or using languagespecific knowledge to predict tokens (e.g. Bond and Paik (2000)) or both (e.g. Sornlertlamvanich et al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), which annotates about 19K nominal lexical entries for count classifiers. To limit very low frequency entries, we cross-reference these with a corpus of 1.2M tokens of Malay text, described in Baldwin and Awab (2006). We further exclude the two non-sortal count classifiers that are attested as default cla</context>
</contexts>
<marker>Adriani, Asian, Nazief, Tahaghoghi, Williams, 2007</marker>
<rawString>M. Adriani, J. Asian, B. Nazief, S.M.M. Tahaghoghi, and H.E. Williams. 2007. Stemming Indonesian: A confix-stripping approach. ACM Transactions on Asian Language Information Processing, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>S Awab</author>
</authors>
<title>Open source corpus analysis tools for Malay.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>2212--5</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="4657" citStr="Baldwin and Awab (2006)" startWordPosition="748" endWordPosition="752">al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), which annotates about 19K nominal lexical entries for count classifiers. To limit very low frequency entries, we cross-reference these with a corpus of 1.2M tokens of Malay text, described in Baldwin and Awab (2006). We further exclude the two non-sortal count classifiers that are attested as default classifiers in the lexicon, as their distribution is heavily skewed and not lexicalised. In all, 2764 simplex common nouns are attested at least once in the corpus data. We observe 2984 unique noun–to–default classifier assignments. Polysemy leads to an average of 1.08 count classifiers assigned to a given wordform. The most difficult exemplars to classify, and consequently the most interesting ones, correspond to the dispreferred count classifiers of the multi-class wordforms: direct assignment and frequenc</context>
<context position="6902" citStr="Baldwin and Awab (2006)" startWordPosition="1112" endWordPosition="1115">lassifier, which is a generation task under their framework, and semantically most similar to noun countability detection. Specifier phrases almost always premodify nouns in Malay, so the set of surface cues we chose was satu CL NOUN “one/a NOUN”.1 This was observed to have greater coverage than dua “two” and other non-numeral specifiers. 49 queries were performed for each headword, and maximum likelihood estimation was used to select the predicted classifier (i.e. taking most frequently observed cue, with a threshold of 0). Frequencies from the same cues were also obtained from the corpus of Baldwin and Awab (2006). We contrasted this with a machine learning model for Malay classifiers, designed to be languageindependent (Nicholson and Baldwin, 2008). A feature vector is constructed for each headword by concatenating context windows of four tokens to the left and right of each instance of the headword in the corpus (for eight word unigram features per instance). These are then passed into two kinds of maximum entropy model: one conditioned on all 49 classes, and one cascaded into a suite of 49 separate binary classifiers designed to predict each class separately. Evaluation is via 10-fold stratified cro</context>
</contexts>
<marker>Baldwin, Awab, 2006</marker>
<rawString>T. Baldwin and S. Awab. 2006. Open source corpus analysis tools for Malay. In Proc. of the 5th International Conference on Language Resources and Evaluation, pages 2212–5, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
</authors>
<title>Scalable deep linguistic processing: Mind the lexical gap.</title>
<date>2007</date>
<booktitle>In Proc. of the 21st Pacific Asia Conference on Language, Information and Computation,</booktitle>
<pages>3--12</pages>
<location>Seoul,</location>
<contexts>
<context position="1038" citStr="Baldwin, 2007" startWordPosition="146" endWordPosition="147">based frequency and machine learning models. We expect that this is a fruitful extension for Web–as–corpus approaches to lexicons in languages other than English, but further research is required in other South-East and East Asian languages. 1 Introduction The objective of this paper is to extend a Malay lexicon with count classifier information for nominal types. This is done under the umbrella of deep lexical acquisition: the process of automatically or semi-automatically learning linguistic structures for use in linguistically rich language resources such as precision grammars or wordnets (Baldwin, 2007). One might call Malay a “medium-density” language: some NLP resources exist, but substantially fewer than those for English, and they tend to be of low complexity. Resources like the Web seem promising for bootstrapping further resources, aided in part by simple syntax and a Romanised orthographic system. The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in Lapata and Keller (2004). We examine using a similar “first gloss” strategy to Lapata and Keller (akin to “first sense” in WSD, in this case, identifying the most basic surface form that a s</context>
</contexts>
<marker>Baldwin, 2007</marker>
<rawString>T. Baldwin. 2007. Scalable deep linguistic processing: Mind the lexical gap. In Proc. of the 21st Pacific Asia Conference on Language, Information and Computation, pages 3–12, Seoul, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bond</author>
<author>K Paik</author>
</authors>
<title>Classifying correspondence in Japanese and Korean.</title>
<date>1997</date>
<booktitle>In Proc. of the 3rd Conference of the Pacific Association for Computational Linguistics,</booktitle>
<pages>58--67</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="3845" citStr="Bond and Paik (1997)" startWordPosition="615" endWordPosition="618">ent semantics. For example, raja “king” typically takes orang “person” as a classifier, as in 2 orang raja “2 kings”, but can take on an animal reading with ekor “animal” in 2 ekor raja “2 kingfishers”. An unintended classifier Proceedings of NAACL HLT 2009: Short Papers, pages 69–72, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics can lead to highly marked or infelicitious readings, such as #2 biji raja “2 (chess) kings”. Most research on count classifiers tends to discuss generating a hierarchy or taxonomy of the classifiers available in a given language (e.g. Bond and Paik (1997) for Japanese and Korean, or Shirai et al. (2008) cross-linguistically) or using languagespecific knowledge to predict tokens (e.g. Bond and Paik (2000)) or both (e.g. Sornlertlamvanich et al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), whi</context>
</contexts>
<marker>Bond, Paik, 1997</marker>
<rawString>F. Bond and K. Paik. 1997. Classifying correspondence in Japanese and Korean. In Proc. of the 3rd Conference of the Pacific Association for Computational Linguistics, pages 58–67, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bond</author>
<author>K Paik</author>
</authors>
<title>Reusing an ontology to generate numeral classifiers.</title>
<date>2000</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>90--96</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="3997" citStr="Bond and Paik (2000)" startWordPosition="638" endWordPosition="641">with ekor “animal” in 2 ekor raja “2 kingfishers”. An unintended classifier Proceedings of NAACL HLT 2009: Short Papers, pages 69–72, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics can lead to highly marked or infelicitious readings, such as #2 biji raja “2 (chess) kings”. Most research on count classifiers tends to discuss generating a hierarchy or taxonomy of the classifiers available in a given language (e.g. Bond and Paik (1997) for Japanese and Korean, or Shirai et al. (2008) cross-linguistically) or using languagespecific knowledge to predict tokens (e.g. Bond and Paik (2000)) or both (e.g. Sornlertlamvanich et al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), which annotates about 19K nominal lexical entries for count classifiers. To limit very low frequency entries, we cross-reference these with a corpus of 1.2</context>
</contexts>
<marker>Bond, Paik, 2000</marker>
<rawString>F. Bond and K. Paik. 2000. Reusing an ontology to generate numeral classifiers. In Proc. of the 19th International Conference on Computational Linguistics, pages 90–96, Saarbr¨ucken, Germany.</rawString>
</citation>
<citation valid="true">
<title>Ethnologue: Languages of the World, Fifteenth Edition.</title>
<date>2005</date>
<editor>R.G. Gordon, Jr, editor.</editor>
<publisher>SIL International.</publisher>
<marker>2005</marker>
<rawString>R.G. Gordon, Jr, editor. 2005. Ethnologue: Languages of the World, Fifteenth Edition. SIL International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Gusmita</author>
<author>Ruli Manurung</author>
</authors>
<title>Some initial experiments with Indonesian probabilistic parsing.</title>
<date>2008</date>
<booktitle>In Proc. of the 2nd International MALINDO Workshop,</booktitle>
<location>Cyberjaya, Malaysia.</location>
<contexts>
<context position="4218" citStr="Gusmita and Manurung, 2008" startWordPosition="676" endWordPosition="680">an lead to highly marked or infelicitious readings, such as #2 biji raja “2 (chess) kings”. Most research on count classifiers tends to discuss generating a hierarchy or taxonomy of the classifiers available in a given language (e.g. Bond and Paik (1997) for Japanese and Korean, or Shirai et al. (2008) cross-linguistically) or using languagespecific knowledge to predict tokens (e.g. Bond and Paik (2000)) or both (e.g. Sornlertlamvanich et al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), which annotates about 19K nominal lexical entries for count classifiers. To limit very low frequency entries, we cross-reference these with a corpus of 1.2M tokens of Malay text, described in Baldwin and Awab (2006). We further exclude the two non-sortal count classifiers that are attested as default classifiers in the lexicon, as their distribution is heavily skewed and no</context>
</contexts>
<marker>Gusmita, Manurung, 2008</marker>
<rawString>R.H. Gusmita and Ruli Manurung. 2008. Some initial experiments with Indonesian probabilistic parsing. In Proc. of the 2nd International MALINDO Workshop, Cyberjaya, Malaysia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Korhonen</author>
</authors>
<title>Subcategorization Acquisition.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Cambridge,</institution>
<location>Cambridge, UK.</location>
<contexts>
<context position="5447" citStr="Korhonen (2002)" startWordPosition="870" endWordPosition="871"> In all, 2764 simplex common nouns are attested at least once in the corpus data. We observe 2984 unique noun–to–default classifier assignments. Polysemy leads to an average of 1.08 count classifiers assigned to a given wordform. The most difficult exemplars to classify, and consequently the most interesting ones, correspond to the dispreferred count classifiers of the multi-class wordforms: direct assignment and frequency thresholding was observed to perform poorly. Since this task is functionally equivalent to the subcat learning problem, strategies from that field might prove helpful (e.g. Korhonen (2002)). The final distribution of the most frequent classes is as follows: CL: orang buah batang ekor OTHER Freq: 0.389 0.292 0.092 0.078 0.149 Of the 49 classes, only four have a relative frequency greater than 3% of the types: orang for people, batang for long, thin objects, ekor for animals, and buah, the semantically empty classifier, for when no other classifiers are suitable (e.g. for abstract nouns); orang and buah account for almost 70% of the types. 3 Experiment 3.1 Methodology Lapata and Keller (2004) look at a set of generation and analysis tasks in English, identify simple surface cues,</context>
</contexts>
<marker>Korhonen, 2002</marker>
<rawString>A. Korhonen. 2002. Subcategorization Acquisition. Ph.D. thesis, University of Cambridge, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lapata</author>
<author>F Keller</author>
</authors>
<title>The web as a baseline: Evaluating the performance of unsupervised web-based models for a range of NLP tasks.</title>
<date>2004</date>
<booktitle>In Proc. of the 4th International Conference on Human Language Technology Research and 5th Annual Meeting of the NAACL,</booktitle>
<pages>121--128</pages>
<location>Boston, USA.</location>
<contexts>
<context position="1472" citStr="Lapata and Keller (2004)" startWordPosition="216" endWordPosition="219">on: the process of automatically or semi-automatically learning linguistic structures for use in linguistically rich language resources such as precision grammars or wordnets (Baldwin, 2007). One might call Malay a “medium-density” language: some NLP resources exist, but substantially fewer than those for English, and they tend to be of low complexity. Resources like the Web seem promising for bootstrapping further resources, aided in part by simple syntax and a Romanised orthographic system. The vast size of the Web has been demonstrated to combat the data sparseness problem, for example, in Lapata and Keller (2004). We examine using a similar “first gloss” strategy to Lapata and Keller (akin to “first sense” in WSD, in this case, identifying the most basic surface form that a speaker would use to disambiguate between possible classes), where the Web is used a corpus to query a set of candidate surface forms, and the frequencies are used to disambiguate the lexical property. Due to the heterogeneity of the Web, we expect 69 to observe a significant amount of blocking from Indonesian, a language with which Malay is somewhat mutually intelligible (Gordon, 2005). Hence, we contrast this approach with observ</context>
<context position="5958" citStr="Lapata and Keller (2004)" startWordPosition="953" endWordPosition="956">y equivalent to the subcat learning problem, strategies from that field might prove helpful (e.g. Korhonen (2002)). The final distribution of the most frequent classes is as follows: CL: orang buah batang ekor OTHER Freq: 0.389 0.292 0.092 0.078 0.149 Of the 49 classes, only four have a relative frequency greater than 3% of the types: orang for people, batang for long, thin objects, ekor for animals, and buah, the semantically empty classifier, for when no other classifiers are suitable (e.g. for abstract nouns); orang and buah account for almost 70% of the types. 3 Experiment 3.1 Methodology Lapata and Keller (2004) look at a set of generation and analysis tasks in English, identify simple surface cues, and query a Web search engine to approximate those frequencies. They then use maximum likelihood estimation or a variety of normalisation methods to choose an output. For a given Malay noun, we attempt to select the default count classifier, which is a generation task under their framework, and semantically most similar to noun countability detection. Specifier phrases almost always premodify nouns in Malay, so the set of surface cues we chose was satu CL NOUN “one/a NOUN”.1 This was observed to have grea</context>
</contexts>
<marker>Lapata, Keller, 2004</marker>
<rawString>M. Lapata and F. Keller. 2004. The web as a baseline: Evaluating the performance of unsupervised web-based models for a range of NLP tasks. In Proc. of the 4th International Conference on Human Language Technology Research and 5th Annual Meeting of the NAACL, pages 121–128, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nicholson</author>
<author>T Baldwin</author>
</authors>
<title>Learning count classifier preferences of Malay nouns.</title>
<date>2008</date>
<booktitle>In Proc. of the Australasian Language Technology Association Workshop,</booktitle>
<pages>115--123</pages>
<location>Hobart, Australia.</location>
<contexts>
<context position="7040" citStr="Nicholson and Baldwin, 2008" startWordPosition="1132" endWordPosition="1135">phrases almost always premodify nouns in Malay, so the set of surface cues we chose was satu CL NOUN “one/a NOUN”.1 This was observed to have greater coverage than dua “two” and other non-numeral specifiers. 49 queries were performed for each headword, and maximum likelihood estimation was used to select the predicted classifier (i.e. taking most frequently observed cue, with a threshold of 0). Frequencies from the same cues were also obtained from the corpus of Baldwin and Awab (2006). We contrasted this with a machine learning model for Malay classifiers, designed to be languageindependent (Nicholson and Baldwin, 2008). A feature vector is constructed for each headword by concatenating context windows of four tokens to the left and right of each instance of the headword in the corpus (for eight word unigram features per instance). These are then passed into two kinds of maximum entropy model: one conditioned on all 49 classes, and one cascaded into a suite of 49 separate binary classifiers designed to predict each class separately. Evaluation is via 10-fold stratified cross-validation. A majority class baseline was also examined, where every headword was assigned the orang class. For the corpus-based method</context>
</contexts>
<marker>Nicholson, Baldwin, 2008</marker>
<rawString>J. Nicholson and T. Baldwin. 2008. Learning count classifier preferences of Malay nouns. In Proc. of the Australasian Language Technology Association Workshop, pages 115–123, Hobart, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C K Quah</author>
<author>F Bond</author>
<author>T Yamazaki</author>
</authors>
<title>Design and construction of a machine-tractable MalayEnglish lexicon.</title>
<date>2001</date>
<booktitle>In Proc. of the 2nd Biennial Conference of ASIALEX,</booktitle>
<pages>200--205</pages>
<location>Seoul,</location>
<contexts>
<context position="4440" citStr="Quah et al., 2001" startWordPosition="712" endWordPosition="715">g. Bond and Paik (1997) for Japanese and Korean, or Shirai et al. (2008) cross-linguistically) or using languagespecific knowledge to predict tokens (e.g. Bond and Paik (2000)) or both (e.g. Sornlertlamvanich et al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), which annotates about 19K nominal lexical entries for count classifiers. To limit very low frequency entries, we cross-reference these with a corpus of 1.2M tokens of Malay text, described in Baldwin and Awab (2006). We further exclude the two non-sortal count classifiers that are attested as default classifiers in the lexicon, as their distribution is heavily skewed and not lexicalised. In all, 2764 simplex common nouns are attested at least once in the corpus data. We observe 2984 unique noun–to–default classifier assignments. Polysemy leads to an average of 1.08 count classifiers assigned</context>
</contexts>
<marker>Quah, Bond, Yamazaki, 2001</marker>
<rawString>C.K. Quah, F. Bond, and T. Yamazaki. 2001. Design and construction of a machine-tractable MalayEnglish lexicon. In Proc. of the 2nd Biennial Conference of ASIALEX, pages 200–205, Seoul, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sornlertlamvanich Kuo</author>
<author>T Charoenporn</author>
</authors>
<title>Constructing taxonomy of numerative classifiers for Asian languages.</title>
<date>2008</date>
<booktitle>In Proc. of the Third International Joint Conference on Natural Language Processing,</booktitle>
<location>Hyderabad, India.</location>
<marker>Kuo, Charoenporn, 2008</marker>
<rawString>K. Shirai, T. Tokunaga, C-R. Huang, S-K. Hsieh, TY. Kuo, V. Sornlertlamvanich, and T. Charoenporn. 2008. Constructing taxonomy of numerative classifiers for Asian languages. In Proc. of the Third International Joint Conference on Natural Language Processing, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sornlertlamvanich</author>
<author>W Pantachat</author>
<author>S Meknavin</author>
</authors>
<title>Classifier assignment by corpus-based approach.</title>
<date>1994</date>
<booktitle>In Proc. of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>556--561</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="4044" citStr="Sornlertlamvanich et al. (1994)" startWordPosition="645" endWordPosition="648"> kingfishers”. An unintended classifier Proceedings of NAACL HLT 2009: Short Papers, pages 69–72, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics can lead to highly marked or infelicitious readings, such as #2 biji raja “2 (chess) kings”. Most research on count classifiers tends to discuss generating a hierarchy or taxonomy of the classifiers available in a given language (e.g. Bond and Paik (1997) for Japanese and Korean, or Shirai et al. (2008) cross-linguistically) or using languagespecific knowledge to predict tokens (e.g. Bond and Paik (2000)) or both (e.g. Sornlertlamvanich et al. (1994)). 2.2 Malay Data Little work has been done on NLP for Malay, however, a stemmer (Adriani et al., 2007) and a probabilistic parser for Indonesian (Gusmita and Manurung, 2008) have been developed. The mutually intelligibility suggests that Malay resources could presumably be extended from these. In our experiments, we make use of a Malay– English translation dictionary, KAMI (Quah et al., 2001), which annotates about 19K nominal lexical entries for count classifiers. To limit very low frequency entries, we cross-reference these with a corpus of 1.2M tokens of Malay text, described in Baldwin an</context>
</contexts>
<marker>Sornlertlamvanich, Pantachat, Meknavin, 1994</marker>
<rawString>V. Sornlertlamvanich, W. Pantachat, and S. Meknavin. 1994. Classifier assignment by corpus-based approach. In Proc. of the 15th International Conference on Computational Linguistics, pages 556–561, Kyoto, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>