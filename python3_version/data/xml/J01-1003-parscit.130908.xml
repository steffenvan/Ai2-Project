<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.965745">
Bootstrapping Morphological Analyzers
by Combining Human Elicitation and
Machine Learning
</title>
<author confidence="0.991526">
Kemal Oflazer* Sergei Nirenburgt
</author>
<affiliation confidence="0.994686">
Sabana University New Mexico State University
</affiliation>
<author confidence="0.92827">
Marjorie McShane t
</author>
<affiliation confidence="0.919559">
New Mexico State University
</affiliation>
<bodyText confidence="0.99647775">
This paper presents a semiautomatic technique for developing broad-coverage finite-state mor-
phological analyzers for use in natural language processing applications. It consists of three
components—elicitation of linguistic information from humans, a machine learning bootstrap-
ping scheme, and a testing environment. The three components are applied iteratively until a
threshold of output quality is attained. The initial application of this technique is for the mor-
phology of low-density languages in the context of the Expedition project at NMSLI Computing
Research Laboratory. This elicit-build-test technique compiles lexical and inflectional information
elicited from a human into a finite-state transducer lexicon and combines this with a sequence
of morphographemic rewrite rules that is induced using transformation-based learning from
the elicited examples. The resulting morphological analyzer is then tested against a test set,
and any corrections are fed back into the learning procedure, which then builds an improved
analyzer.
</bodyText>
<sectionHeader confidence="0.99218" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.9998291875">
The Expedition project at NMSU Computing Research Laboratory is devoted to the
fast &amp;quot;ramp-up&amp;quot; of machine translation systems from less studied, so-called low-density
languages, into English. One of the components that must be acquired and built dur-
ing this process is a morphological analyzer for the source language. Since language
informants are not expected or required to be well-versed in computational linguistics
in general, or in recent approaches to building morphological analyzers (e.g., Kosken-
niemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and
the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and
Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999;
van Noord and Gerdemann 1999) in particular, the generation of the morphological
analyzer component has to be accomplished semiautomatically. The informant will
be guided through a knowledge elicitation procedure using the elicitation component
of Expedition, the Boas system. As this task is not easy, we expect that the develop-
ment of the morphological analyzer will be an iterative process, whereby the human
informant will revise and/or refine the information previously elicited based on the
feedback from test runs of the nascent analyzer.
</bodyText>
<footnote confidence="0.601831">
* Faculty of Engineering and Natural Sciences, Orhanh, 81474 Tuzla, Istanbul, TURKEY
f Computing Research Laboratory, Las Cruces, NM 88003
</footnote>
<note confidence="0.817855">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.999846357142857">
The work reported in this paper describes the process of building and refining mor-
phological analyzers using data elicited from human informants and machine learning.
The main use of machine learning in our current approach is in the automatic learning
of formal rewrite or replace rules for morphographemic changes derived from the ex-
amples provided by the informant. The subtask of accounting for morphographemic
changes is perhaps one of the more complicated aspects of building an analyzer; by
automating it, we expect to improve productivity.
After a review of related work, we very briefly describe the Boas project, of which
the current work is a part. Subsequent sections describe the details of the approach,
the architecture of the morphological analyzer, the elicited descriptive data, and the
computational processes performed on this data, including segmentation and the in-
duction of morphographemic rules. We then provide a detailed example of applying
this approach to developing a morphological analyzer for Polish. Finally, we provide
some conclusions and ideas for future work.
</bodyText>
<sectionHeader confidence="0.999035" genericHeader="related work">
2. Related Work
</sectionHeader>
<bodyText confidence="0.999928433333333">
Machine learning techniques are widely employed in many aspects of language pro-
cessing. The availability of large, annotated corpora has fueled a significant amount of
work in the application of machine learning techniques to language processing prob-
lems, such as part-of-speech tagging, grammar induction, and sense disambiguation,
as witnessed by recent workshops and journal issues dedicated to this topic.1 The cur-
rent work attempts to contribute to this literature by describing a human-supervised
machine learning approach to the induction of morphological analyzers—a problem
that, surprisingly, has received little attention.
There have been a number of studies on inducing morphographemic rules from a
list of inflected words and a root word list. Johnson (1984) presents a scheme for in-
ducing phonological rules from surface data, mainly in the context of studying certain
aspects of language acquisition. The premise is that languages have a finite number of
alternations to be handled by morphographemic rules and a fixed number of contexts
in which they appear; so if there is enough data, phonological rewrite rules can be
generated to account for the data. Rules are ordered by some notion of &amp;quot;surfaciness&amp;quot;,
and at each stage the most surfacy rule—the rule with the most transparent context—
is selected. Golding and Thompson (1985) describe an approach for inducing rules of
English word formation from a corpus of root forms and the corresponding inflected
forms. The procedure described there generates a sequence of transformation rules,&apos;
each specifying how to perform a particular inflection.
More recently, Theron and Cloete (1997) have presented a scheme for obtaining
two-level morphology rules from a set of aligned segmented and surface pairs. They
use the notion of string edit sequences, assuming that only insertions and deletions
are applied to a root form to get the inflected form. They determine the root form
associated with an inflected form (and consequently the suffixes and prefixes) by ex-
haustively matching the inflected form against all root words. The motivation is that
&amp;quot;real&amp;quot; suffixes will appear frequently in the corpus of inflected forms. Once common
suffixes and prefixes are identified, the segmentation for an inflected word can be
determined by choosing the segmentation with the most frequently occurring affix
segments; the remainder is then considered the root. While this procedure seems to
</bodyText>
<footnote confidence="0.722031666666667">
1 For instance, the CoNLL (Computational Natural Language Learning) Workshops, recent special issues
of Machine Learning Journal (Vol. 34 Issue 1/3, Feb. 1999) and Al Magazine (Vol. 18, No. 4, 1997).
2 Not in the sense in which it is used in transformation-based learning (Brill 1995).
</footnote>
<page confidence="0.99354">
60
</page>
<note confidence="0.849204">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<bodyText confidence="0.999930652173913">
be reasonable for a small root word list, the potential for &amp;quot;noisy&amp;quot; or incorrect align-
ments is quite high when the corpus of inflected forms is large and the procedure
is not given any prior knowledge of possible segmentations. As a result, automati-
cally selecting the &amp;quot;correct&amp;quot; segmentation becomes nontrivial. An additional compli-
cation is that allomorphs show up as distinct affixes and their counts in segmentations
are not accumulated, which might lead to actual segmentations being missed due to
fragmentation. The rules are not induced via a learning scheme: aligned pairs are
compressed into a special data structure and traversals over this data structure gener-
ate morphographemic rules. Theron and Cloete have experimented with pluralization
in Afrikaans, and the resulting system has shown about 94% accuracy on unseen
words.
Goldsmith (1998) has used an unsupervised learning method based on the mini-
mum description length principle to learn the &amp;quot;morphology&amp;quot; of a number of languages.
What is learned is a set of root words and affixes, and common inflectional-pattern
classes. The system requires just a corpus of words in a language. In the absence of
any root word list to use as a scaffolding, the shortest forms that appear frequently
are assumed to be roots, and observed surface forms are then either generated by the
concatenative affixation of suffixes or by rewrite rules.3 Since the system has no notion
of what the roots and their part-of-speech values really are, and what morphological
information is encoded by the affixes, this information needs to be retrofitted manually
by a human, who has to weed through a large number of noisy rules. We feel that this
approach, while quite novel, can be used to build real-world morphological analyzers
only after substantial modifications are made.
</bodyText>
<sectionHeader confidence="0.974949" genericHeader="method">
3. The BOAS Project
</sectionHeader>
<bodyText confidence="0.999780428571429">
Boas (Nirenburg 1998; Nirenburg and Raskin 1998) is a semiautomatic knowledge
elicitation system that guides a team of two people (a language informant and a
programmer) through the process of developing the static knowledge sources required
to produce a moderate-quality, broad-coverage MT system from any &amp;quot;low-density&amp;quot;
language into English. Boas contains knowledge about human language phenomena
and various realizations of these phenomena in a number of specific languages, as
well as extensive pedagogical support, making the system a kind of &amp;quot;linguist in a
box,&amp;quot; intended to help nonprofessional users with the task. In the spirit of the goal-
driven, &amp;quot;demand-side&amp;quot; approach to computational applications of language processing
(Nirenburg and Raskin 1999), the process of acquiring this knowledge has been split
into two steps: (i) acquiring the descriptive, declarative knowledge about a language
and (ii) deriving operational knowledge (content for the processing engines) from this
descriptive knowledge.
An important goal that we strive to achieve regarding these descriptive and op-
erational pieces of information, be they elicited from human informants or acquired
via machine learning, is that they be transparent, human-readable, and, where neces-
sary, human-maintainable and human-extendable, contrary to the opaque and unin-
terpretable representations acquired by various statistical learning paradigms.
Before proceeding any further, we would also like to make explicit the aims and
limitations of our approach. Our main goal is to significantly expedite the develop-
ment of a morphological analyzer. It is clear that for inflectional languages where each
</bodyText>
<footnote confidence="0.6378795">
3 Some of these rules may not make sense, but they are necessary to account for the data: for instance, a
rule like insert a word final y after the root &amp;quot;eas&amp;quot; is used to generate easy.
</footnote>
<page confidence="0.99632">
61
</page>
<note confidence="0.88209">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.999894833333333">
root word can be associated with a finite number of word forms, one can, with a lot of
work, generate a list of word forms with associated morphological features encoded,
then use this as a lookup table to analyze word forms in input texts. Since this pro-
cess is time consuming, expensive, and error-prone, it is something we would like to
avoid. We prefer to capture general morphophonological and morphographemic phe-
nomena using sample paradigms as the basis of lexical abstractions. This reduces the
acquisition process to assigning citation forms to one of the established paradigms;
the automatic generation process described below does the rest of the work.&apos; This
process is still imperfect, as we expect human informants to err in making their
paradigm abstractions and to overlook details and exceptions. So, the whole pro-
cess is an iterative one, with convergence to a wide-coverage analyzer coming slowly
at the beginning (where morphological phenomena and lexicon abstractions are be-
ing defined and tested), but significantly speeding up once wholesale lexical acqui-
sition starts. Since the generation of the operational content (data files to be used
by the morphological analyzer engine) from the elicited descriptions is expected to
take only a few minutes, feedback on operational performance can be provided very
quickly.
Human languages have many diverse morphological phenomena and it is not
our intent at this point to have a universal architecture that can accommodate any
and all phenomena. Rather, we propose an extensible approach that can accommo-
date additional functionality in future incarnations of Boas. We also intend to limit
morphological processing to single tokens and to deal with multitoken phenomena,
such as partial or full word reduplications, with additional machinery that we do not
discuss here.
</bodyText>
<sectionHeader confidence="0.886025" genericHeader="method">
4. The Elicit-Build-Test Loop
</sectionHeader>
<bodyText confidence="0.999713117647059">
In this paper we concentrate on operational content in the context of building a mor-
phological analyzer. To determine this content, we integrate the information provided
by the informant with automatically derived information. The whole process is an
iterative one, as illustrated in Figure 1: the elicited information is transformed into
the operational data required by the generic morphological analyzer engine and the
resulting analyzer is then tested on a test corpus:5&apos;6 Any discrepancies between the
output of the analyzer and the test corpus are then analyzed and potential sources
of errors are given as feedback to the elicitation process. Currently, this feedback is
limited to identifying problems in handling morphographemic processes (such as for
instance the change of word-final -y to -i when the suffix -est is added).
The box in Figure 1 labeled Morphological Analyzer Generation is the main com-
ponent, which takes in the elicited information and generates a series of regular ex-
pressions for describing the morphological lexicon and morphographemic rules. The
morphographemic rules describing changes in spelling as a result of affixation opera-
tions are induced from the examples provided by using transformation-based learning
(Brill 1995; Satta and Henderson 1997). The result is an ordered set of contextual re-
place or rewrite rules, much like those used in phonology.
</bodyText>
<footnote confidence="0.994137166666667">
4 We use the term citation form to refer to the word form that is used to look up a given inflected form
in a dictionary. It may be the root or stem form that affixation is applied to, or it may have additional
morphological markers to indicate its citation form status.
5 We currently use XRCE finite-state tools as our target environment (Karttunen et al. 1996).
6 The test corpus is either elicited from the human informant or compiled from on-line resources for the
language in question.
</footnote>
<page confidence="0.997146">
62
</page>
<table confidence="0.994762764705883">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
Start
,....-..-•
Corpus Human Elicitation
Compilation Process
S. ..0
ir
Description of Morphology
(paradigms, examples, exceptions, etc.)
Morphological Analyzer
Generation
Content for Morphological Analyzer Engine
(lexicons, morphof raphemic rules) -110.
Test • Comparison Errors,
Corpus with Test Corpus Omissions
Engine, Test Engine)
%.(MA
</table>
<figureCaption confidence="0.89114">
Figure 1
</figureCaption>
<bodyText confidence="0.832006">
The elicit-build-test paradigm for bootstrapping a morphological analyzer.
</bodyText>
<subsectionHeader confidence="0.99988">
4.1 Morphological Analyzer Architecture
</subsectionHeader>
<bodyText confidence="0.999204666666667">
We adopt the general approach advocated by Karttunen (1994) and build the morpho-
logical analyzer as the combination of several finite-state transducers, some of which
are constructed directly from the elicited information, and others of which are con-
structed from the output of the machine learning stage. Since the combination of the
transducers is computed at compile-time, there are no run-time overheads. The ba-
sic architecture of the morphological analyzer is depicted in Figure 2. The analyzer
consists of the union of transducers, each of which implements the morphological
analysis process for one paradigm. Each transducer is the composition of a number of
components. These components (from bottom to top) are described below:
</bodyText>
<listItem confidence="0.978122875">
1. The bottom component is an ordered sequence of morphographemic
rules that are learned via transformation-based learning from the sample
inflectional paradigms provided by the human informant. These rules are
then composed into one finite-state transducer (Kaplan and Kay 1994).
2. The citation form and affix lexicon contains the citation forms and the
affixes. We currently assume that all affixation is concatenative and that
the lexicon is described by a regular expression of the sort
[ Prefixes ]* [ CitationForms ] [ Suffixes ]*!
</listItem>
<footnote confidence="0.890837">
7 We currently assume that we have at most one prefix and at most one suffix, but this is not a
fundamental limitation. The elicitation of morphotactics for an agglutinating language like Turkish or
Finnish requires a significantly more sophisticated elicitation machinery.
</footnote>
<page confidence="0.998026">
63
</page>
<table confidence="0.923832318181818">
Volume 27, Number 1
Computational Linguistics
Lemma+Morphological Features (e.g., happy+Adj+Super)
t
Feature Constraints Feature Constraints
o o
, Surfacy-to-Feature
Surfacy-to-Feature Mapping
Mapping
o o
, Lexical &amp; Surfacy Constraints L.) • • • V Lexical &amp; Surfacy Constraints
o o
Morpheme-to-Surfacy-Feature Morpheme-to-Surfacy-Feature
Mapping Mapping
o o
Citation Form and Affix Lexicon Citation Form and Affix Lexicon.&apos;
o o
Morphographemic Rules Morphographemic Rules
....&apos;
Paradigm 1 Paradigm n
t
Surface Form (e.g., happiest)
</table>
<figureCaption confidence="0.832299">
Figure 2
</figureCaption>
<bodyText confidence="0.777759">
General architecture of the morphological analyzer.
</bodyText>
<listItem confidence="0.925846285714286">
3. The morpheme to surfacy feature mapping essentially maps
morphemes to feature names but retains some encoding of the surface
morpheme. Thus, allomorphs that encode the same feature would be
mapped to different surfacy features.
4. The lexical and surfacy constraints specify any conditions to constrain
the possibly overgenerating morphotactics of the citation form and
morpheme lexicons. These constraints can be encoded using the citation
forms and the surfacy features generated by the previous mapping. The
use of surfacy features also enables reference to zero morphemes, which
otherwise could not be used. For instance, if in some paradigm a certain
prefix does not co-occur with a certain suffix, or always occurs with
some other suffix, or if a certain citation form in that paradigm has
exceptional behavior with respect to one or more of the affixes, or if the
affixal allomorph that goes with a certain citation form depends on the
properties of the citation form, these are encoded at this level as
finite-state constraints.
5. The surfacy feature to feature mapping module maps the surfacy
representation of the affixes to symbolic feature names; as a result, no
surface information remains except for the citation form. Thus, for
instance, allomorphs that encode the same feature and map to different
surfacy features now map to the same feature symbol.
</listItem>
<page confidence="0.998166">
64
</page>
<bodyText confidence="0.895698727272727">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
6. The feature constraints specify constraints among the symbolic features.
They are different means of constraining morphotactics than the one
provided by lexical and surfacy constraints. At this level, one refers to
and constrains symbolic morphosyntactic features as opposed to surfacy
features. This may provide a more natural or convenient abstraction,
especially for languages with long-distance morphotactic constraints.
These six finite-state transducers are composed to yield a transducer for the paradigm.
The union of the transducers for all paradigms produces one (possibly large) trans-
ducer for morphological analysis, where surface strings applied at the lower end pro-
duce all possible analyses at the upper end.
</bodyText>
<subsectionHeader confidence="0.998682">
4.2 Information Elicited from Human Informants
</subsectionHeader>
<bodyText confidence="0.9999699">
The Boas environment guides the language informant through a series of questions
leading up to paradigm delineation. The informant indicates the parameters for which
a given part of speech inflects (e.g., Case, Number), the relevant values for those pa-
rameters (e.g., Nominative, Accusative; Singular, Plural), and the licit combinations
of parameter values (e.g., Nominative Singular, Nominative Plural). The informant
then posits any number of paradigms, whose members are expected to show sim-
ilar patterns of inflection. It is assumed that all citation forms that belong to the
same paradigm take essentially the same set of inflectional affixes (perhaps subject
to morphophonological variations). It is expected that the citation forms and/or the
affixes may undergo systematic or idiosyncratic morphographemic changes. It is also
assumed that certain citation forms in a given paradigm may behave in some excep-
tional way (for instance, contrary to all other citation forms, a given citation form
may not have one of the inflected forms.) A paradigm description provides the full
inflectional pattern for one characteristic or distinguished citation form and additional
examples for any other citation forms whose inflectional forms undergo nonstandard
morphographemic changes. If necessary, any lexical and feature constraints can be
encoded. Currently the provisions we have for such constraints are limited to writing
regular expressions (albeit at a much higher level than standard regular expressions);
however, capturing such constraints using a more natural language (e.g., Ranta 1998)
can be incorporated into future versions.
</bodyText>
<subsectionHeader confidence="0.999882">
4.3 Elicited Descriptive Data
</subsectionHeader>
<bodyText confidence="0.9984492">
Figure 3 presents the encoding of the information elicited for one paradigm of a Polish
morphological analyzer, which will be covered in detail later.&apos;
The data elicited using the user interface component of Boas is converted into
a description text file with various components delineated by SGML-like tags. The
components in the description are as follows:
</bodyText>
<listItem confidence="0.9977524">
• The &lt;LANGUAGE—DESCRIPTION... &gt; component lists information about the
language and specifies its vowels and consonants, and other orthographic
symbols that do not fall into those two groups.
• A paradigm description starts with the tag &lt;PARADIGM NAME=. . .&gt;, which
lists the name of the paradigm, its part-of-speech category, and any
</listItem>
<footnote confidence="0.9246255">
8 Our actual system works using unicode character representation. But unicode input and output are not
yet supported in the XRCE xfst tool, hence we employ an ASCII external representation for the unicode
characters during off-line testing. In the following examples, however, we have opted to represent the
actual characters as they should appear on screen.
</footnote>
<page confidence="0.998575">
65
</page>
<figure confidence="0.966917967741935">
Computational Linguistics Volume 27, Number 1
&lt;LANGUAGE-DESCRIPTION TYPE = &amp;quot;morphology&amp;quot;
NAME = &amp;quot;Polish&amp;quot;
ALPHABET= &amp;quot;aabcddeqfghijklImmloOpqrsStuvwxyzW
VOWELS = &amp;quot;ag.egiobuy&amp;quot;
CONSONANTS= &amp;quot;bcdclfghjklImniipqrs6tvwxzte
OTHER =
&lt;PARADIGM NAME=&amp;quot;MascInUStart&amp;quot; POS = &amp;quot;Noun&amp;quot; FEATURES=&amp;quot;Masculine&amp;quot;›
&lt;PRIMARY-EXAMPLE&gt;
&lt;INF-GROUP&gt;
&lt;PRIMARY-CIT-FORM FORM = &amp;quot;telefon&amp;quot;›
&lt;INF-FORM FORM = &amp;quot;telefon&amp;quot; FEATURE = &amp;quot;Nom.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;telefon&amp;quot; FEATURE = &amp;quot;Acc.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;telefonach&amp;quot; FEATURE = &amp;quot;Loc.P1.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;telefonami&amp;quot; FEATURE = &amp;quot;Instr.P1.&amp;quot;&gt;
&lt;/INF-GROUP&gt;
&lt;/PRIMARY-EXAMPLE &gt;
&lt;EXAMPLE&gt;
&lt;INF-GROUP&gt;
&lt;C1T-FORM FORM = &amp;quot;akcentu&gt;
&lt;INF-FORM FORM = &amp;quot;akcent&amp;quot; FEATURE = &amp;quot;Nom.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;akcencie&amp;quot; FEATURE = &amp;quot;Loc.Sg.&amp;quot;&gt;
&lt;/INF-GROUP&gt;
&lt;/EXAMPLE&gt;
&lt;LEXICON&gt;
&lt;CIT-FORM FORM = &amp;quot;stroe&gt;
&lt;CIT-FORM FORM = &amp;quot;klub&amp;quot;›
&lt;CIT-FORM FORM = &amp;quot;sklep&amp;quot;&gt;
&lt;/LEXICON&gt;
&lt;/PARADIGM&gt;
&lt;/LANGUAGE-DESCRIPTION&gt;
</figure>
<figureCaption confidence="0.900916">
Figure 3
</figureCaption>
<bodyText confidence="0.909726285714286">
Sample paradigm description generated by Boas elicitation.
additional morphosyntactic features that are common to all citation
forms in this paradigm. In the example in Figure 3, the paradigm is for
masculine nouns. Everything up to the &lt;/PARADIGM&gt; tag is part of the
descriptive data for the paradigm. This descriptive data consists of a
primary example, a series of zero or more additional examples, and the
lexicon.
</bodyText>
<listItem confidence="0.997022833333333">
• The primary example is given between the &lt;PRIMARY-EXAMPLE&gt; and
&lt;/PRIMARY-EXAMPLE&gt; tags. The description is given as a sequence of one
or more inflection groups between &lt;INF-GROUP&gt; and &lt;/INF-GROUP&gt; tags.
In some instances, a given lexical item can use different citation forms in
different inflectional forms. For example, one citation form might be
used in the present tense and another in the past tense; or one might be
</listItem>
<page confidence="0.951156">
66
</page>
<bodyText confidence="0.990849090909091">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
used with multisyllable affixes and another with single-syllable affixes.
Thus, a given lexical item can have multiple citation forms, each of
which gets associated with a mutually exclusive subset of inflectional
forms. All the citation forms for a given lexical item, plus all its
inflectional forms, are represented in an inflection group. If the
association of citation forms with inflectional forms is predictable (as
indicated by the language informant), the subsets of inflectional forms
are processed separately; if not, we assume that all citation forms can be
used in all inflectional forms and hence overgenerate. Manual constraints
can later be added, if necessary, to constrain this overgeneration.
</bodyText>
<listItem confidence="0.988402111111111">
• Additional examples are provided between &lt;EXAMPLE&gt; and &lt;/EXAMPLE&gt;
tags. Examples contain new citation forms plus any inflectional forms
that are not predictable based on the primary example. Each example is
considered an inflectional group and is enclosed within the
corresponding tags.
• The citation forms given in the primary example and any additional
examples are considered to be a part of the citation form lexicon of the
paradigm definition. Any additional citation forms in this paradigm are
listed between the &lt;LEXICON&gt; and &lt;/LEXICON&gt; tags.
</listItem>
<sectionHeader confidence="0.463289" genericHeader="method">
5. Generating the Morphological Analyzer
</sectionHeader>
<bodyText confidence="0.999733">
The morphological analyzer is a finite-state transducer that is actually the union of
the transducers for each paradigm definition in the description provided. Thus, the
elicited data is processed one paradigm at a time. For each paradigm we proceed as
follows:
</bodyText>
<listItem confidence="0.8094619">
1. The elicited primary citation form and associated inflected forms are
processed to find the &amp;quot;best&amp;quot; segmentation of the forms into stem and
affixes.&apos; Although we allow for inflectional forms to have both a prefix
and a suffix (one of each), we expect only suffixation to be employed by
the inflecting languages with which we are dealing (Sproat 1992).
2. Once the affixes are determined, we segment the inflected forms for the
primary example and any additional examples provided, and pair them
with the corresponding surface forms. The segmented forms are now
based on the citation form plus the affixes (not the stem). The reason is
that we expect the morphological analyzer to generate the citation form
for further access to lexical databases to be used in the applications. The
resulting segmented form—surface form pairs make up the example base
of the paradigm.
3. The citation forms given in the primary example, in additional examples,
and explicitly in the lexicon definition of the elicited data, along with the
mapping from suffix strings to the corresponding morphosyntactic
features, are compiled (by our morphological analyzer generating
system) into suitable regular expressions (expressed using the regular
9 The stem is considered to be that part of the citation form onto which affixes are attached, and in our
context it has no function except for determining the affix strings.
</listItem>
<page confidence="0.993801">
67
</page>
<note confidence="0.428747">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.993203454545455">
expression language of the XRCE finite-state tools Marttunen et al.
19961).&amp;quot;
4. The example base of the paradigm generated in step 2 is then used by a
learning algorithm to generate a sequence of morphographemic rules
(Kaplan and Kay 1994) that handle the morphographemic phenomena.
5. The regular expressions for the lexicon in step 3 and the regular
expressions for the morphographemic rules induced in step 4 are then
compiled into finite-state transducers and combined by composition to
generate the finite-state morphological analyzer for the paradigm.
The resulting finite-state transducers for each paradigm are then unioned to give
the transducer for the complete set of paradigms.
</bodyText>
<subsectionHeader confidence="0.999794">
5.1 Determining Segmentation and Affixes
</subsectionHeader>
<bodyText confidence="0.999887555555556">
The suffixes and prefixes in a paradigm are determined by segmenting the inflected
forms provided for the primary example. This process is complicated by the fact that
the citation form may not correspond to the stem—it may contain a morphological in-
dication that it is the citation form. Furthermore, since the language informant provides
only a small number of examples, statistically motivated approaches like the one sug-
gested by Theron and Cleoete (1997) are not applicable. We have experimented with a
number of approaches and have found that the following approach works quite well.
Using the notion of description length (Rissanen 1989), we try to find a stem and
a set of affixes that account for all the inflected forms of the primary example. Let
</bodyText>
<equation confidence="0.634815">
C = c2, , cc) be the character string for the citation form in the primary example
</equation>
<bodyText confidence="0.997123875">
(c, are symbols in the alphabet of the language). Let Sk = (Ci, C2,.., Ck), 1 &lt; k &lt; c
be a (string) prefix of C length k. We assume that the stem onto which morphological
affixes are attached is Sk for some k.11 The set of inflectional forms given in the primary
example are {Fi, F2, . , Ff }, with each Fi = (f,I are symbols in the alphabet
of the language and 11 is the length of the jth form). The function ed(v,w) (ed for
edit distance), where v and w are strings, measures the minimum number of symbol
insertions and deletions (but not substitutions) that can be applied to v to obtain w
(Damerau 1964).12 We define
</bodyText>
<equation confidence="0.986828333333333">
1=f
d(Sk) = k+ Eed(Sk,Fi)
j=1
</equation>
<bodyText confidence="0.99716">
as a measure of the information needed to account for all the inflected forms. The first
term above, k, is the length of the stem. The second term, the summation, measures
how many symbols must be inserted and deleted to obtain the inflected form. The
Sk with the minimum d(Sk) is then chosen as the stem S. Creating segmentations
based on stem S proceeds as follows: To determine the affixes in each inflected form
Fj Jp, we compute the projection of the stem Pi (f,. ,f1) in Fj, as that
</bodyText>
<footnote confidence="0.6706295">
10 Note that other finite state tools could also be used (e.g., Mohri, Pereira and Riley 1998; van Noord
1999).
11 The stem can also be an arbitrary substring of C, not just some initial prefix. Our approach can
certainly extend to that.
12 The function ed(. . .) assumes that vowels only align with other vowels or are elided, and consonants
only align with consonants or are elided.
</footnote>
<page confidence="0.993652">
68
</page>
<bodyText confidence="0.89836475">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
substring of Fj whose alignment with S provides the minimum edit distance, that is,
P1= argmin
Then we select the substring (4, ,4_1) of Fi (if it exists) as the prefix and (fej+1,...,f1i)
</bodyText>
<listItem confidence="0.687382666666667">
(if it exists) as the suffix. If there are multiple substrings of Fj that give the same
(minimum) edit distance when aligned with S, we prefer the longer substring. We
then create
</listItem>
<bodyText confidence="0.990023444444444">
(0q, ,ft_i -I- (2 -I- (61, ... FJ)
as an aligned segmented form—surface form pair and add it to the example base that
we will use in the learning stage. Note that we now use the citation form C, and not
the stem S. as a part of the segmented form.
Thus, at the end of the process we generate pairs of inflected forms and their
corresponding segmented forms to be used in the derivation of the morphographemic
rules. These pairs come from both the inflected forms given in the primary example
and from any additional examples given.
For example, suppose we have the following primary example:
</bodyText>
<figure confidence="0.570135333333333">
&lt;PRIMARY-EXAMPLE&gt;
&lt;INF-GROUP&gt;
&lt;PRIMARY-CIT-FORM FORM = &amp;quot;strona&amp;quot;›
</figure>
<construct confidence="0.922633214285714">
&lt;INF-FORM FORM = &amp;quot;strona&amp;quot; FEATURE = &amp;quot;Nom.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;strong&amp;quot; FEATURE = &amp;quot;Acc.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;strony&amp;quot; FEATURE = &amp;quot;Gen.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;stronie&amp;quot; FEATURE = &amp;quot;Dat.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;stronie&amp;quot; FEATURE = &amp;quot;Loc.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;strong.&amp;quot; FEATURE = &amp;quot;Instr.Sg.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;strony&amp;quot; FEATURE = &amp;quot;Nom.P1.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;strony&amp;quot; FEATURE = &amp;quot;Acc.P1.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;stron&amp;quot; FEATURE = &amp;quot;Gen.P1.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;stronom&amp;quot; FEATURE = &amp;quot;Dat.P1.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;stronach&amp;quot; FEATURE = &amp;quot;Loc.P1.&amp;quot;&gt;
&lt;INF-FORM FORM = &amp;quot;stronami&amp;quot; FEATURE = &amp;quot;Instr.P1.&amp;quot;&gt;
&lt;/INF-GROUP&gt;
&lt;/PRIMARY-EXAMPLE&gt;
</construct>
<bodyText confidence="0.997982375">
For this example, stems Sk: S, st, str, stro, stron, strona, are considered. Table 1
tabulates d(Sk) considering all the unique inflected forms above. It can be seen that
the value of d(S5) is minimum for S5 = S stron. We then determine suffixes based
on this stem selection. The suffixes are given in this table under k = 5, where the stem
S = stron perfectly aligns with the initial substring stron in each inflected form Fi, with
0 edit distance.
The segmented form—surface form pairs in Table 2 are then generated from the
alignment of the stem with each surface form.
</bodyText>
<subsectionHeader confidence="0.99993">
5.2 Learning Segmentation and Morphographemic Rules
</subsectionHeader>
<bodyText confidence="0.9998855">
The citation form and the affix information elicited and extracted by the process de-
scribed above are used to construct regular expressions for the lexicon component
</bodyText>
<page confidence="0.99632">
69
</page>
<note confidence="0.413472">
Computational Linguistics Volume 27, Number 1
</note>
<tableCaption confidence="0.98835">
Table 1
</tableCaption>
<bodyText confidence="0.855597">
Stems Sk and the corresponding d(Sk)•
Stems Considered, Sk
ed(Sk,F1)
k=1 k = 2 k = 3 k = 4 k = 5 k = 6
Form F1 s st str stro stron Suffix strona
strona 5 4 3 2 1 -a 0
strong 5 4 3 2 1 -e 2
strony 5 4 3 2 1 -y 2
stronie 6 5 4 3 2 -ie 3
strong 5 4 3 2 1 -q 2
stron 4 3 2 1 0 1
</bodyText>
<figureCaption confidence="0.39093425">
stronom 6 5 4 3 2 -om 3
stronach 7 6 5 4 3 -ach 2
stronami 7 6 5 4 3 -ami 2
d(Sk) 51 43 35 27 19 23
</figureCaption>
<tableCaption confidence="0.947788">
Table 2
</tableCaption>
<bodyText confidence="0.985858">
The segmented and surface pair examples obtained.
Segmented Surface
strona+a strona
strona+e strong
strona+y strony
strona+ie stronie
strona+a strong
strona+ stron
strona+om stronom
strona+ach stronach
strona+ami stronami
of each paradigm.13 The example segmentations are fed into the learning module to
induce morphographemic rules.
</bodyText>
<subsubsectionHeader confidence="0.825847">
5.2.1 Generating Candidate Rules from Examples. The preprocessing stage yields
</subsubsectionHeader>
<bodyText confidence="0.92725925">
a list of pairs of segmented lexical forms and surface forms. The segmented forms
contain the citation forms and affixes; the affix boundaries are marked by the + symbol.
This list is then processed by a transformation-based learning paradigm (Brill 1995;
Satta and Henderson 1997), as illustrated in Figure 4. The basic idea is that we consider
the list of segmented words as our input and find transformation rules (expressed as
contextual rewrite rules) to incrementally transform this list into the list of surface
forms. The transformation we choose at every iteration is the one that makes the list
of segmented forms closest to the list of surface forms.
The first step in the learning process is an initial alignment of pairs using a stan-
dard dynamic programming scheme. The only constraints in the alignment are: (i) a +
in the segmented lexical form is always aligned with an empty string on the surface
side, notated by 0; (ii) a consonant on one side is always aligned with a consonant or
0 on the other side, and likewise for vowels; (iii) the alignment must correspond to
13 The result of this process is a script for the XRCE finite-state tool xfst. Large-scale lexicons can be more
efficiently compiled by the XRCE tool lexc. We currently do not generate lexc scripts, but it is trivial to
do so.
</bodyText>
<page confidence="0.976162">
70
</page>
<note confidence="0.55041">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<figure confidence="0.991958166666667">
Segmented
Forms
Surface forms
(Truth)
•
(incrementally)
transformed
segmented
forms
Learner
(Transformation)
Rules
</figure>
<figureCaption confidence="0.989207">
Figure 4
</figureCaption>
<subsectionHeader confidence="0.569314">
Transformation-based learning of morphographemic rules.
</subsectionHeader>
<bodyText confidence="0.997596428571429">
the minimum edit distance between the original lexical and surface forms.&apos; From this
point on, we will use a simple example from English to clarify our points.
Assume that we have the pairs (un+happy+est, unhappiest) and (shop+ed,
shopped) in our example base. We align these and determine the total number of
&amp;quot;errors&amp;quot; in the segmented forms that we have to fix to make all segmented forms
match the corresponding surface forms. The initial alignment produces the aligned
pairs:
</bodyText>
<equation confidence="0.491905">
un ± happy + est shop° ed
</equation>
<bodyText confidence="0.989946181818182">
un 0 happi 0 est shopp 0 ed
with a total of five errors. From each segmented pair we generate rewrite rules of the
sort&apos;
u -&gt; 1 II LeftContext _ RightContext ;
where u(pper) is a symbol in the segmented form, 1(ower) is a symbol in the surface
form. Rules are generated only from those aligned symbol pairs that are different.
LeftContext and RightContext are simple regular expressions describing contexts
in the segmented side (up to some small length), also taking into account the word
boundaries. For instance, from the first aligned-pair example, this procedure would
generate rules such as the following (depending on the amount of left and right context
allowed):
</bodyText>
<equation confidence="0.993511375">
y -&gt; II p_ y -&gt; i I I p _ + e
y -&gt; i I I p _ + e s y -&gt; i I p _ +est
y -&gt; i I I p_ + est # y -&gt; i I I p p _ + e
+ -&gt; 0 I I # u n _ +-&gt;0 H #un _ hap
+ -&gt; 0 I I
_ est
_ e s t #
+ -&gt; 0 I I ppy_ e s t #
</equation>
<footnote confidence="0.797307">
14 We arbitrarily choose one if there are multiple legitimate alignments.
15 We use the XRCE finite-state tools regular expression syntax (Karttunen et al. 1996). For the sake of
readability, we will ignore the escape symbol (%) that should precede any special characters (e.g., +)
used in these rules.
</footnote>
<page confidence="0.991951">
71
</page>
<note confidence="0.636254">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.999782117647059">
The # symbol denotes a word boundary and is intended to capture any word-initial
and word-final phenomena. The segmentation rules (+ -&gt; 0) require at least some
minimal left or right context (usually longer than the minimal context for other rules
in order to produce more accurate segmentation decisions). We disallow contexts that
consist only of a morpheme boundary, as such contexts are usually not informative.
It should be noted that these rules transform a segmented form into a surface form
(contrary to what may be expected for analysis). This lets us capture situations where
multiple segmented forms map to the same surface form, which occurs when the
language has morphological ambiguity. Thus, in a reverse lookup, a given surface
form may be interpreted in multiple ways, if applicable.
Since we have many examples of aligned pairs in our example base, it is likely that
a given rule will be generated from many pairs. For instance, if the pairs (stop+ed,
stopped) and (trip+ed, tripped) were also in the list, the gemination rule 0 -&gt; p
II p_+ed (along with certain others) will also be generated from these examples.
We count how many times a rule is generated and associate this number with the rule
as its promise, meaning that it promises to fix this many &amp;quot;errors&amp;quot; if it is selected to
apply to the current list of segmented forms.
</bodyText>
<subsubsectionHeader confidence="0.913678">
5.2.2 Generalizing Rules. The candidate rules generated by the processes described
</subsubsectionHeader>
<bodyText confidence="0.9991566">
above refer to specific strings of symbols as left and right contexts. It is, however,
possible to obtain more generalized rules by classifying the symbols in the alphabet
into phonologically relevant groups, like vowels and consonants. The benefit of this
approach is that the number of rules thus induced is typically smaller, and more
unseen cases can be covered.
</bodyText>
<equation confidence="0.652358">
For instance, in addition to a rule like 0 -&gt; p II p_+ e, the rules
0 -&gt; p I I CONSONANTS _ + e
0 -&gt; p II p _ + VOWELS
0 -&gt; p I I CONSONANTS _ + VOWELS
</equation>
<bodyText confidence="0.983539">
can be generated, where symbols such as CONSONANTS and VOWELS stand for regu-
lar expressions denoting the union of relevant symbols in the alphabet. The promise
scores of the generalized rules are found by adding the promise scores of the origi-
nal rules generating them. Generalization substantially increases the number of can-
didate rules to be considered during each iteration, but this is not a very serious
issue, as the number of examples per paradigm is expected to be quite small. The
rules thus learned would be the most general set of rules that do not conflict with
the evidence in the examples. It is possible to use a more refined set of classes that
correspond to subclasses of vowels (e.g., high vowels) and consonants (e.g., frica-
tives) but these will substantially increase the number of candidate rules at every
iteration and will have an impact on the iteration time unless examples are chosen
carefully.
5.2.3 Selecting Rules. At each iteration, all the rules along with their promise scores
are generated from the current state of the example pairs. The rules generated are then
ranked based on their promise scores, with the top rule having the highest promise.
Among rules with the same promise score, we rank more general rules higher, with
generality being based on context subsumption (i.e., preference goes to rules using
shorter contexts and/or referring to classes of symbols, like vowels or consonants).
All segmentation rules go to the bottom of the list, though within this group, rules
are still ranked based on decreasing promise and context generality. The reasoning
</bodyText>
<page confidence="0.974528">
72
</page>
<note confidence="0.61056">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<bodyText confidence="0.999929166666667">
for treating Che segmentation rules separately and later in the process is that affixa-
tion boundaries constitute contexts for all morphographemic changes; therefore they
should not be eliminated if there are any (more) morphographemic phenomena to
process.
Starting with Che top-ranked rude, we test each rude on Che segmented compo-
nent of Che pairs. A finite-state engine emulates the replace rules to see hcnv much
the segmented forms are &amp;quot;fixed.&amp;quot; The first rude that fixes as many &amp;quot;errors&amp;quot; as it
promises to fix, and does not generate an interim example base with generation
ambiguity, is selected.&apos; The issue of generation ambiguity refers to cases where Che
same segmented forms are paired with distinct surface forms.&apos; In such cases, find-
ing a rule that fixes both pairs is not possible, so in choosing rules, we avoid any
rules whose tentative application generates an interim example base with such am-
biguities. In this AVX.V, we can account for all the discrepancies between Che sur-
face and segmented forms without falling into a local nth-lima. Although we do net
have formal proof that this simple heuristic avoids such local minima situations, in
our experimentation with a large number of cases we have never seen such an in-
stance.
The complete procedure for rule learning can now be given as follows:
</bodyText>
<listItem confidence="0.929177076923077">
- Align surface and segmented forms in the example base;
- Compute total Error;
- while(Error &gt; 0) {
-Generate all possible rewrite rules subject to context size limits;
-Rank Rules;
-while (there are more rules and a rule has not yet been selected) {
- Tentatively apply the next rule to all the segmented forms;
- Re-align the resulting segmented forms with the
corresponding surface forms to see how many
&amp;quot;errors&amp;quot; have been fixed;
- If the number of errors fixed is equal to what the rule
promised to fix AND the result does not have generation
ambiguity, select this rule;
</listItem>
<bodyText confidence="0.998753555555556">
-Commit the changes performed by the rule on the segmented forms
to the example base;
-Reduce Error by the promise score of the selected rule;
This procedure eventually generates an ordered sequence of two ordered groups
of rewrite rules. The first group of rules is for any morphographemic phenomena
in the given set of examples, and the second group of rules handles segmentation.
All these rules are composed in the order in which they are generated to construct
the Morphographemic Rules transducer at the bottom of each paradigm (see Fig-
ure 2).
</bodyText>
<footnote confidence="0.836108857142857">
16 Note that a rule may actually introduce unintended errors in other pairs, since context checking is
done only on the segmented form side; therefore what a rule delivers may be different than what it
promises, as promise scores also depend on the surface side.
17 Consider a state of the example base where some segmented lexical form L is paired with different
surface forms Si and S2, that is, we have pairs (L, Si) and (L, S2) in our example base. Any rule that
will bring L closer to Si will also change L of the second pair and potentially make it impossible to
bring it closer to S2.
</footnote>
<page confidence="0.992211">
73
</page>
<note confidence="0.599227">
Computational Linguistics Volume 27, Number 1
</note>
<subsectionHeader confidence="0.996761">
5.3 Identifying Errors and Providing Feedback
</subsectionHeader>
<bodyText confidence="0.999979095238095">
Once the Morphographemic Rules transducers are compiled and composed with the
lexicon transducer that is generated automatically from the elicited information, we
obtain an analyzer for the paradigm. The analyzer for the paradigm can be tested by
using the xfst environment of the XRCE finite-state tools. This environment provides
machinery for testing the output of the analyzer by generating all forms involving
a specific citation form, a specific morphosyntactic feature, or the like. This kind of
testing has proved quite sufficient for our purposes.
When the full analyzer is generated by unioning all the analyzers for each para-
digm, one can do a more comprehensive test against a test corpus to see what surface
forms in the test corpus are not recognized by the generated analyzer. Apart from
revealing obvious deficiencies in coverage (e.g., missing citation forms in the lexicon),
such testing provides feedback about minor human errors—the failure to cover cer-
tain morphographemic phenomena, or the incorrect assignment of citation forms to
paradigms, for example.
Our approach is as follows: we use the resulting morphological analyzer with an
error-tolerant finite-state recognizer engine (Oflazer 1996). Using this engine, we try to
find words recognized by the analyzer that are (very) close to a rejected (correct) word
in the test corpus, essentially performing a reverse spelling correction. If the rejection
is due to a small number of errors (1 or 2), the erroneous words recognized by the
recognizer are aligned with the corresponding correct words from the test corpus.
These aligned pairs can then be analyzed to see what the problems may be.
</bodyText>
<subsectionHeader confidence="0.991118">
5.4 Applicability to Infixing, Circumfixing, and Agglutinating Languages
</subsectionHeader>
<bodyText confidence="0.999979592592593">
The machine learning procedure for inducing rewrite rules is not language dependent.
It is applicable to any language whose lexical representation is a concatenation of
free and bound morphemes (or portions thereof). All this stage requires is a set of
pairs of lexical and surface representations of the examples compiled for the example
base.
We have tested the rule learning component above on several other languages in-
cluding Turkish, an agglutinating language, using an example base with lexical forms
produced by a variant of the two-level morphology-based finite-state morphological
analyzer described in Oflazer (1994). The lexical representation for Turkish also in-
volved meta symbols (such as H for high vowels, D for dentals, etc.), which would
be resolved with the appropriate surface symbol by the rules learned. For instance,
vowel harmony rules would learn to resolve H as one of 1, 1, u, ii in the appropriate
context.
Furthermore, the version of the rule learning (sub)system used for Turkish also
made use of context-bound morphophonological distinctions that are not elicited in
Boas, such as high vowels, low unrounded vowels, dentals, etc. The rules generated
were the most general set of rules that did not conflict with the example base. There
were many examples in the example base that involved multiple suffixes, not just
one, as in the inflecting languages we address in this paper. It was quite satisfying
to observe that the system could learn rules for dealing with vowel harmony, de-
voicing, and so on. A caveat is that if there were too many examples and too many
morphophonological classes, the number of candidate rules to be tried increased ex-
ponentially. This could be alleviated to a certain extent by a careful selection of the
example base.
Thus, the rule-learning component is applicable to agglutinative, and also to in-
fixing and circumfixing languages, provided there is a proper representation of the
lexical and surface forms. However, for infixing languages it could be very problem-
</bodyText>
<page confidence="0.989326">
74
</page>
<note confidence="0.582613">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<bodyText confidence="0.997493894736842">
atic to have a linear representation of the infixation, with the lexical root being split
in two and the morphotactics picking up the first part, the infix, and the second part.
To prevent overgeneration, the infix lexicon might have to be replicated for each root,
to enforce the fact that the two parts of the stem go together.&apos; The case for circumfix-
ation is simpler since the number of such morphemes is assumed to be much smaller
than the number of stems, so the circumfixing morphemes can be split up into two
lexicons and treated as a prefix-suffix combination. The co-occurrence restrictions for
the respective pairs can then be manually enforced with finite-state constraints that
can be added to the lexical and surfacy constraints section of the analyzer (see Fig-
ure 2).
Thus, in all three cases, learning the rules is not a problem provided the example
base is in the requisite linear representation. On the other hand, this approach as such
is inapplicable to languages like Arabic, which have radically different word formation
processes (for which a number of other finite-state approaches have been proposed;
(see, for example, Beesley [1996] and Kiraz [2000]).
On the other hand, in contrast to acquiring the rewrite rules, eliciting the mor-
photactics and the affix lexicons for an agglutinating language (semi)automatically
is a very different process and is yet to be addressed. There are three parts to this
problem:
</bodyText>
<listItem confidence="0.9975294">
1. Determining the boundaries of free and bound morphemes, accounting
for any morphographemic variations;
2. Determining the order of morphemes;
3. Determining the &amp;quot;semantics&amp;quot; of the morphemes, that is, the features they
encode.
</listItem>
<bodyText confidence="0.999859166666667">
These are complicated by a number of additional issues such as zero morphemes, local
and long-distance co-occurrence restrictions (e.g., for allomorph selection), exceptions,
productive derivations, circular derivations, and morphemes with the same surface
forms but a totally different morphotactic position and function. Also, in languages
that have a phenomenon like vowel harmony, such as Turkish, even if all harmonic
allomorphs of a certain suffix are somehow automatically grouped into a lexicon with-
out any further abstraction, severe overgeneration would result, unless the all root and
suffix lexicons were split or replicated along vowel lines. In such cases, a human in-
formant (who possesses a certain familiarity with morphographemics and issues of
overgeneration) may have to resort to manual abstraction of the morpheme represen-
tations. Then the process of acquiring the features for inflectional and derivational
morphemes could proceed.
</bodyText>
<subsectionHeader confidence="0.813973">
6. Bootstrapping a Polish Analyzer
</subsectionHeader>
<bodyText confidence="0.770716375">
This section presents a quite extensive example of bootstrapping a morphological an-
alyzer for Polish by iteratively providing examples and testing the morphological an-
alyzer systematically. The idea of this exercise was to have a relatively limited number
of paradigms that bunched words showing slight inflectional variations.&amp;quot; For reasons
18 This is much like what one encounters when dealing with reduplication in the FS framework. Also
note that this is a lexicon issue and not a rule issue.
19 Nonexpert language informants using Boas will be encouraged to split, rather than bunch, paradigms,
for the sake of simplicity.
</bodyText>
<page confidence="0.99631">
75
</page>
<note confidence="0.644839">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.999953428571429">
of space, the exposition is limited to developing four paradigms, of which one will be
covered in detail. The paradigms here cover only a subset of masculine nouns, and
do not treat feminine or neuter nouns at all; however, they cover all the problems that
would be found in words of those genders.
For purposes of testing the learner off-line (i.e., outside the Boas environment), we
tried to keep to a minimum the number of inflected forms given for each additional
citation form. This was a learner-oriented task and intended to determine how robust
the learner could become with a minimum of input. When using the Boas interface, the
language informant will not have the option of selectively providing inflected forms.
The interface works as follows: the informant gives all forms of the primary example
and lists other citation forms that he or she thinks belong to the given paradigm. Hav-
ing learned rules from the primary example, the learner generates all the inflectional
forms for each citation form provided. The informant then corrects all mistakes and
the learner relearns the rules. So, the informant never has the opportunity to say &amp;quot;Well,
I know the learner can&apos;t predict the locative singular for this word, so I will supply
it overtly from the outset.&amp;quot; The informant will just have to wait for the learner to get
the given forms wrong and then correct them. Any other approach would make for
a complex interface and would require a sophisticated language informant—not what
we are expecting.
Polish is a highly inflectional West Slavic language that is written using extended
Latin characters (six consonants and three vowels have diacritics). Certain phonemes
are written using combinations of letters: e.g., sz, cz, and szcz represent phonetic §,
and respectively.&apos; Polish nominals inflect for seven cases: Nominative (Nom.),
Accusative (Acc.), Genitive (Gen.), Dative (Dat.), Locative (Loc.), Instrumental (Instr.),
and Vocative (Voc.); and two numbers: Singular (Sg.) and Plural (PO.&apos; The complex-
ity of Polish declension derives from four sources: (i) certain stem-final consonants
mutate during inflection; these are called &amp;quot;alternating&amp;quot; consonants, and are contrasted
with so-called &amp;quot;nonalternating&amp;quot; consonants (alternating/nonalternating is a crucial
diagnostic for paradigm delineation in Polish); (ii) certain letters are spelled differ-
ently depending on whether they are word-final or word-internal (e.g., word-final
-§ is written -si when followed by a vocalic ending); (iii) final-syllable vowels are
added/deleted in some (not entirely predictable) words; and (iv) declension is not
entirely phonologically driven—semantics and idiosyncrasy affect inflectional end-
ings.
The following practical simplifications have been made for testing purposes:
</bodyText>
<listItem confidence="0.918923">
• Words that are normally capitalized (like names) are not capitalized here.
• Some inflectional form(s) that might not be semantically valid (e.g.,
plurals for collectives) were disregarded. Thus a bit of overgeneration
still remains but can be removed with some additional effort.
</listItem>
<subsectionHeader confidence="0.999061">
6.1 Paradigm 1
</subsectionHeader>
<bodyText confidence="0.999925">
The process starts with the description of Paradigm 1, which describes alternating
inanimate masculine nouns with genitive singular in -u and no vowel shifts. The
</bodyText>
<footnote confidence="0.90982825">
20 We actually treat these as single symbols during learning. Such symbols are indicated in the
description file in a special section that we have omitted in Figure 3.
21 The Vocative case was not included in these tests because it is not expected to occur widely in the
journalistic prose for which the system is being built.
</footnote>
<page confidence="0.970897">
76
</page>
<note confidence="0.5804">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<bodyText confidence="0.927868">
following primary example for the citation form telefon is given in full:
</bodyText>
<figure confidence="0.8916065">
Number
Case Singular Plural
</figure>
<figureCaption confidence="0.957174333333333">
Nom. telefon telefony
Acc. telefon telefony
Gen. telefonu telefonow
Dat. telefonowi telefonom
Loc. telefonie telefonach
Instr. telefonem telefonami
</figureCaption>
<bodyText confidence="0.898012">
All inflectional forms in this paradigm are trivial except:
</bodyText>
<listItem confidence="0.95046">
• The Loc.Sg. depends on the final consonant and induces orthographic
alternations for some alternating consonants:&apos;
</listItem>
<table confidence="0.793872571428571">
Final Consonant(s) Loc.Sg. Ending Consonant Alternations
b, p, f, w, in, n, s, z -ie
t, d, st, zm -ie
I, r, st -e
g, k, ch -u
t--c, d--*clz, st—÷gc, zm—m
1-4, r--q.z, sl--1
</table>
<listItem confidence="0.9980915">
• Instr.Sg. and Nom.P1. depend on the final consonant; two velars have an
idiosyncratic ending:
</listItem>
<subsectionHeader confidence="0.850456">
Final Consonant(s)
</subsectionHeader>
<bodyText confidence="0.725024666666667">
b, p, f, w, m, n, s, z
t, d, st zm, L r, si, ch
g, k
</bodyText>
<figure confidence="0.976855428571429">
Instr.Sg.
Ending
-em
-iem
Nom.P1.
Ending
-37
</figure>
<bodyText confidence="0.86409975">
-i
The following examples were provided in addition to the inflectional forms of the
primary example in order to show Loc.Sg. endings and accompanying consonant al-
ternations that could not be predicted based on the primary example:
</bodyText>
<listItem confidence="0.999213">
1. t-4c: akcent (Nom.Sg.), akcencie (Loc.Sg.)
2. d -p dz: wyktad (Nom.Sg.), wyktadzie (Loc.Sg.)
3. st --÷gc: most (Nom.Sg.), mokie (Loc.Sg.)
4. zm-4±m: komunizm (Nom.Sg.), komunitmie (Loc.Sg.)
5. t-*I: artykut (Nom.Sg.), artykule (Loc.Sg.)
6. r-4rz: teatr (Nom.Sg.), teatrze (Loc.Sg.)
7. st-sl: pomyst (Nom.Sg.), porny§le (Loc.Sg.)
</listItem>
<bodyText confidence="0.927631">
The following additional examples were provided to show velar pecularities:
</bodyText>
<footnote confidence="0.892480666666667">
8. g: pociag (Nom.Sg.), pociagu (Loc.Sg.), pociagiem (Instr.Sg.), pociagi (Nom.PI.)
22 Strictly speaking, the consonants b, p, f, w, m, n, s, and z alternate as well in the Loc.Sg., since
altemating/nonalternating is a phonological distinction, not a graphotactic one. The softening of these
consonants is indicated by the -i that precedes the canonical Loc.Sg. ending -e. However, for our
purposes it is more straightforward to consider the Loc.Sg. ending for these consonants -ie with no
accompanying graphotactic alternation.
</footnote>
<page confidence="0.996588">
77
</page>
<note confidence="0.598327">
Computational Linguistics Volume 27, Number 1
</note>
<tableCaption confidence="0.986119">
Table 3
</tableCaption>
<table confidence="0.919686">
Summary of runs for Paradigm 1.
Citation
Key Forms
0 telefon, stron,
paragraf,
gpiew, sklep,
tlum, adres,
obraz
1 akcent, bilet Nom.Sg.
Loc.Sg.
2 wyklad, sad Nom.Sg.
</table>
<figure confidence="0.942908822222222">
Loc.Sg.
3 most, list Nom.Sg.
Loc.Sg.
4 komunizm, Nom.Sg.
socjalizm Loc.Sg.
5 artykul, Nom.Sg.
kawal Loc.Sg.
6 teatr, numer Nom.Sg.
Loc.Sg.
7 pomysl, Nom.Sg.
zmyst Loc.Sg.
8 poci4g, brzeg Nom.Sg.
Loc.Sg.
Instr.Sg.
Nom.P1.
9 bank, krok Nom.Sg.
Loc.Sg.
Instr.Sg.
Nom.P1.
10 dach, wirch Nom.Sg.
Loc.Sg.
Additional Run 1 Additional Run 2 Additional Run 3
Examples Results Examples Results Examples Results
Vt
mutates all
oblique forms
mutates all
oblique forms
mutates all
oblique forms
mutates all
oblique forms
mutates all
oblique forms
mutates all
oblique forms
mutates all
oblique forms
Vt
Nom.P1.
Nom.P1.
Nom.P1.
Nom.P1.
Nom.P1.
Nom.P1.
Nom.P1.
mutates
Instr.Sg.
mutates
Instr.Sg.
mutates
Instr.Sg.
mutates
Instr.Sg.
mutates
Instr.Sg.
mutates
Instr.Sg.
mutates
Instr.Sg.
Instr.Sg.
Instr.Sg.
Instr.Sg.
Instr.Sg.
Instr.Sg.
Instr.Sg.
Instr.Sg.
missed velar-
specific Loc.Sg.
gave *krokie
not kroku
missed velar-
specific Loc.Sg.
gave *wirchie
not wirchu
Loc.Sg. of Vt
krok;
; Add blysk to
lexicon for
testing
Loc.Sg. of
wirch;
; Add gmiech
to lexicon
for testing
wrong add Vt
Instr.Sg. Instr.Sg.
for wirch, of
gmiech wirch
9. k: bank (Nom.Sg.), banku (Loc.Sg.), bankiem (Instr.Sg.), banki (Nom.P1.)
</figure>
<figureCaption confidence="0.16294">
10. eh: dach (Nom.Sg.), dachu (Loc.Sg.)
</figureCaption>
<bodyText confidence="0.999699230769231">
Table 3 summarizes the first three runs for this paradigm, which were sufficient to
create a relatively robust set of morphological rules that required only slight amend-
ment and further testing in two additional runs. For this and subsequent such tables
we use the following conventions: Key 0 shows the primary citation form and addi-
tional citation forms whose inflectional patterns should be fully covered by the rules
generated for the primary example. The other key numbers correspond to the addi-
tional examples given above. Boldface citation forms under the lexicon column are
those for which some additional inflectional examples were given. The citation forms
given in plain text are for testing purposes. Oblique cases refer to the Genitive, Dative,
Locative, and Instrumental cases.
The original assumption for Paradigm 1 was that it would be sufficient to pro-
vide one unmutated form (the Nom.Sg.) plus the mutated form (the Loc.Sg.) for words
ending in mutating consonants. This led to overgeneralization of the alternation; there-
</bodyText>
<page confidence="0.987782">
78
</page>
<note confidence="0.693949">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<bodyText confidence="0.999950153846154">
fore, another unmutated form had to be added as a &amp;quot;control.&amp;quot; Adding the Nom.P1.
forms fixed most oblique forms for all the words, but it left the Instr.Sg. mutated.
This appears to be because the inflectional ending for the Loc.Sg. (which mutates) and
the Instr.Sg. (which does not) both begin in -e for the words in question. Adding the
Instr.Sg. overtly counters overgeneralization of the alternation. The source of the velar
errors is not immediately evident.
Supplementary testing was carried out after the above-mentioned words were all
correct. Correct forms were produced for all new words showing consonant mutations
and velar peculiarities: samolot, przyklad, pretekst, podziat, kolor, dtug, lek, gmach. One error
for a nonmutating word (in Key 0) occurred. This word, herb, ends in a different
consonant than the primary example and produced the wrong Loc.Sg. form. This was
later added overtly and more words with other nonmutating consonants (postcp, puf,
gniew, film, opis, raz) were tested; all were covered correctly.
</bodyText>
<subsectionHeader confidence="0.999412">
6.2 Paradigm 2
</subsectionHeader>
<bodyText confidence="0.999723666666667">
The paradigm implemented next was Paradigm 2: alternating inanimate masculine
nouns with genitive singular in -u and vowel shifts. The following primary example
for the citation form grab was given in full:
</bodyText>
<figure confidence="0.872489">
Number
Singular Plural
grOb groby
gr6b groby
grobu grobOw
grobowi grobom
grobie grobach
grobem grobami
</figure>
<bodyText confidence="0.8082064">
This paradigm is just like Paradigm 1, except that there are vowel shifts that are
not entirely graphotactically predictable; therefore, words showing these shifts must be
classed separately. The vowel shifts occur in all inflectional forms except the Nom.Sg.
and the Acc.Sg., which are identical. The following vowel shifts occurred in the cases
we considered (0 indicates vowel deletion).
</bodyText>
<table confidence="0.857958461538461">
Vowel in Vowel in
Nom.Sg./Acc.Sg. Other Forms
o
ie
a e*
* This shift only occurs in Loc.Sg.
The following consonant alternations are also observed in this paradigm:
Consonant in Consonant in
Most Forms Loc.Sg.
dz dz
Zdz
1
rz
</table>
<bodyText confidence="0.993399">
Based on the experience of Paradigm 1, the Instr.Sg. forms for all words with
consonant alternation were provided as examples at the outset to avoid the overgen-
eralization of the alternation. The velar pecularities are still in effect and must be dealt
with explicitly.
</bodyText>
<figure confidence="0.998445571428571">
Case
Nom.
Acc.
Gen.
Dat.
Loc.
Instr.
</figure>
<page confidence="0.809243">
79
</page>
<note confidence="0.589236">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.9654155">
The following examples were given to exemplify vowel shifts with an unmutating
consonant:
</bodyText>
<listItem confidence="0.87239">
1. e shift with n: sen(Nom.Sg.), snie (Loc.Sg.)
</listItem>
<bodyText confidence="0.986476">
The following examples were employed to show vowel shifts in combination with
various consonant alternations in the Loc.Sg. forms:
</bodyText>
<listItem confidence="0.925111857142857">
2. 6 —&gt; o and d -4 dz: samochad (Nom.Sg.), samochodzie (Loc.Sg.), samochodem
(Instr.Sg.)
3. a -4 e and zd idz: dojazd (Nom.Sg.), dojegdzie (Loc.Sg.), dojazdem
(Instr.Sg.)
4. 6 o and t -÷ 1: skit (Nom.Sg.), stole (Loc.Sg.), stotem (Instr.Sg.)
5. e -4 and r rz: puder (Nom.Sg.), pudrze (Loc.Sg.), pudrem (Instr.Sg.)
6. ie —&gt; cb and r rz: cukier (Nom.Sg.), cukrze (Loc.Sg.), cukrem (Instr.Sg.)
</listItem>
<bodyText confidence="0.557156">
Finally, the following examples were given to show velar peculiarities:
</bodyText>
<listItem confidence="0.9238565">
7. e —&gt; with k: budynek (Nom.Sg.), budynku (Loc.Sg.), budynkiem (Instr.Sg.),
budynki (Nom.P1.)
</listItem>
<bodyText confidence="0.951852933333333">
8. o with g: Tog (Nom.Sg.), rogu (Loc.Sg.), rogiem (Instr.Sg.), rogi
(Nom.P1.)
At the end of first run for this paradigm only one of the eight groups above
was covered completely. All vowel shifts for all groups came out right. However, the
Nom.P1. and Acc.P1. endings were incorrectly generalized as -i instead of -y, probably
because two &amp;quot;exceptional&amp;quot; velar examples (in -i) were provided in contrast to one
&amp;quot;regular&amp;quot; nonvelar example (in -y). Adding the Nom.P1. forms of three nonvelar words
fixed this error. The results for velars were perfect except for the loss of z in 10 of 12
forms of obowiqzek. Adding the Nom.P1. form obowiqzki fixed this. For shit and dot, the
consonant alternation was incorrectly extended to Gen.Sg. Adding the Gen.Sg. form
of stOt fixed this error for both words. At the end of the second run, all groups were
correctly learned.
Supplementary testing after the above-mentioned words were correct included the
words nawk, dochod, pozor, rozbior, grod, rozchod, narod, wtorek, kierunek; all forms were
correct.
</bodyText>
<subsectionHeader confidence="0.960988">
6.3 Paradigm 3
</subsectionHeader>
<bodyText confidence="0.999372333333333">
Paradigm 3 contains alternating &amp;quot;man&amp;quot; nouns—that is, masculine nouns referring to
human men. The following primary example for the citation form pasierb was given
in full:
</bodyText>
<subsectionHeader confidence="0.769198">
Number
Singular Plural
</subsectionHeader>
<footnote confidence="0.614942785714286">
pasierb pasierbowie
pasierbi
pasierba pasierb6w
pasierba pasierb6w
pasierbowi pasierbom
pasierbie pasierbach
pasierbem pasierbami
Case
Nom.
Acc.
Gen.
Dat.
Loc.
Instr.
</footnote>
<page confidence="0.902909">
80
</page>
<note confidence="0.604973">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<bodyText confidence="0.998486205882353">
In this paradigm, all of the consonant alternations encountered above are still in
effect and some word-final consonants undergo additional alternations in the Nom.P1.
The velar peculiarities remain in effect. One additional complication in this paradigm
is that there may be multiple Nom.P1. forms for a given citation form (e.g., pasierbowie
and pasierbi are both acceptable Nom.P1. forms for pasierb). Furthermore, -i/-y are allo-
morphs in complementary distribution (i.e., the second Nom.P1. form in this paradigm
is realized with -y for certain word-final consonants).
Stem-Final Nom.P1.
Consonant Ending
b, f, w, m, n, z, t
p, ch
d, I
r, k, g
-owie or -i or both
-i only
-owie only
-owie or -y or both
Since the analyzer needs only to analyze (and not generate) forms, there is no need
to split this paradigm into five different ones to account for each Nom.P1. possibility:
-owie, -owie/-i, -i, -owie/-y, -y. We simply permit overgeneration, allowing each word to
have two Nom.P1. forms: the correct one of the -i/-y allomorphs and -owie. Further,
since the analyzer has no way to predict which of the -i/-y allomorphs is used with a
given word-final consonant, explicit examples of each word-final consonant must be
provided.
These considerations lead to splitting the citation forms for this paradigm into
14 groups, which represent the primary example plus 13 inflectional groups added
as supplementary examples. The Nom.Sg., Loc.Sg., and both (or applicable) Nom.P1.
forms were provided for all groups apart from the primary example. After the first
run, 13 of 14 groups were correctly covered. The remaining group was handled cor-
rectly in two additional runs: two more inflectional forms of the example in word-final
r had to be provided to counter overgeneralization of the r ---&gt; rz alternation.
Supplementary testing after the above-mentioned words were correct included
the citation forms drab, piastun, kasztelan, faraon, wojt, mnich, biedak, norweg, wtoch. The
following errors were encountered:
</bodyText>
<listItem confidence="0.990012666666667">
• norweg got the Acc.Sg./Gen.Sg. form *norweda instead of norwega.
Adding the correct Acc.Sg. form fixed this problem.
• wtoch got the Nom.P1. form *wtoci instead of wtosi. This form was added
overtly.
• mnich got the Nom.P1. form *mnici instead of mnisi. This form was added
overtly.
</listItem>
<bodyText confidence="0.9999475">
After these final additions, wtoch and mnich ended up with the Acc.Sg./Gen.Sg.
forms *wtosa and *mnisa instead of wtocha and mnicha (i.e., the alternation was overgen-
eralized again). Overtly adding the correct Acc.Sg. form wtocha solved this problem
for both words and all forms were now correct.
</bodyText>
<subsectionHeader confidence="0.992371">
6.4 Paradigm 4
</subsectionHeader>
<bodyText confidence="0.987982">
Paradigm 4 was for nonalternating inanimate masculine nouns with genitive singular
in -a and no vowel shifts. The following declension for bicz was provided as the
</bodyText>
<page confidence="0.986406">
81
</page>
<figure confidence="0.9883268">
Computational Linguistics Volume 27, Number 1
primary example:
Number
Singular Plural
bicz bicze
bicz bicze
bicza biczy
biczowi biczom
biczu biczach
biczem biczami
</figure>
<bodyText confidence="0.998760733333333">
A spelling rule of Polish comes into play in this paradigm: letters that take a
diacritic word-finally or when followed by a consonant are spelled with no diacritic
plus an -i when followed by a vowel. For instance: ri-Fu niu, niowi, e-Fu
ciu, e+owi ciowi. Some, but not all, word-final letters in this paradigm have diacritics.
In addition, in this paradigm, Gen.Sg. endings depend on the final consonant: they
can be -ow (for j, ch, szcz), -i (for t, §6, ft) or -y (for cz, sz, rz, t). In many instances, more
than one form is possible, but this test covers only the most common form for each
stem-final consonant.
The citation forms in this paradigm broke down into 10 groups based on the final
consonant. The Nom.Sg., Gen.P1., and Instr.P1. forms were provided for the 9 groups
(the tenth is the primary example, for which all forms were provided). Eight of the
10 groups were handled correctly after the first run. The spelling-rule related to -i
required some extra forms to be learned correctly. Otherwise, everything came out as
predicted. Supplementary testing included the citation forms klawisz, bQbel, strumien,
tach, cyrkularz; all inflectional forms were produced correctly.
</bodyText>
<sectionHeader confidence="0.844605" genericHeader="evaluation">
7. Performance Issues
</sectionHeader>
<bodyText confidence="0.999906227272727">
Generating a morphological analyzer once the descriptive data is given can be carried
out very fast. Each paradigm can be processed within tens of seconds on a fast work-
station, including the few tens of iterations of rule learning from the examples. A new
version of the analyzer can be generated within minutes and tested rapidly on any test
data. Thus, none of the processes described in this paper constitutes a bottleneck in the
elicitation process. Figure 5 provides some relevant information from the rims of the
first paradigm in Polish described above. The top graph shows, for different runs, the
number of distinct rules generated from the aligned segmented form—surface-form
pairs generated from the examples provided, using a rule format with at most five
symbols in each of the left and right contexts. The bottom graph shows, for differ-
ent runs, the total number of rules generated and generalized—again, with the same
context size as above.
There are a few interesting things about these graphs. As expected, when more
examples are added, the number of rules and the number of iterations needed for
convergence usually increases. All curves have a steeper initial segment and a steeper
final segment. The steep initial segments result from the initial selection of rules that
fix the largest number of &amp;quot;errors&amp;quot; between the segmented and surface forms. Once
those rules are found, the curves flatten as a number of morphographemic rules are
selected, each dealing with a very small number of errors. Finally, when all the mor-
phographemic changes are accounted for, the segmentation rules kick in and each such
rule fixes a large number of segmentation &amp;quot;errors,&amp;quot; so that a few general rules deal
with all such cases.
</bodyText>
<figure confidence="0.98916119047619">
Case
Nom.
Acc.
Gen.
Dat.
Loc.
Instr.
82
Oflazer, Nirenburg, and McShane
Bootstrapping Morphological Analyzers
Rules generated in each iteration of the learner in sequential runs
1000
900 •
800 •
700 •
/ 600 •
500 •
—E.— Run 3 /
cc 400 •
300 •
200 •
100 •
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
Learning Iteration
Rules generalized in each iteration of the learner in sequential runs
20000
18000
16000 r, a. — 0- — = 0- - - • - - - •
14000 • —
&amp;quot;g 12000 — Ms&apos;
— -Run 2 g 10000
Run 3
g 8000 •
-0-
0-
6000 •
4000 •
2000
• r • • •
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
Learning Iteration
</figure>
<figureCaption confidence="0.965474">
Figure 5
</figureCaption>
<bodyText confidence="0.910594875">
Rule statistics for processing Paradigm 1.
8. Summary and Conclusions
We have presented the highlights of our approach for automatically generating finite-
state morphological analyzers from information elicited from human informants. Our
approach uses transformation-based learning to induce morphographemic rules from
examples and combines these rules with the lexicon information elicited to compile
the morphological analyzer. There are other opportunities for using machine learning
in this process. For instance, one of the important issues in wholesale acquisition of
</bodyText>
<page confidence="0.990349">
83
</page>
<note confidence="0.476418">
Computational Linguistics Volume 27, Number 1
</note>
<bodyText confidence="0.998797333333334">
open-class items is that of determining which paradigm a given citation form belongs
to. From the examples given during the acquisition phase, it is possible to induce a
classifier that can perform this selection to aid the language informant.
We believe that we have presented a viable approach to the automatic generation
of a natural language processor. Since this approach involves a human informant
working in an elicit-generate-test loop, the noise and opaqueness of other induction
schemes can be avoided.
We also feel that the task of analyzing a set of incorrectly generated forms and
automatically offering a diagnosis of what may have gone wrong and what additional
examples can be supplied as remedies is, in itself, an important aspect of this work.
Although we have only scratched the surface of this topic here, we consider it a fruitful
extension of the work described in this paper.
</bodyText>
<sectionHeader confidence="0.999447" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<reference confidence="0.992486666666667">
This research was supported in part by
Contract MDA904-97-C-3976 from the U.S.
Department of Defense. We also thank
XRCE for providing the finite-state tools.
Most of this work was done while the first
author was visiting NMSU Computing
Research Laboratory during the 1998-1999
academic year, on leave from Bilkent
University, Ankara, Turkey.
</reference>
<sectionHeader confidence="0.66558" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999559077922078">
Antworth, Evan L. 1990. PC-KIMMO: A
two-level processor for Morphological Analysis.
Occasional Publications in Academic
Computing, Number 16. Summer
Institute of Linguistics, Dallas, TX.
Beesley, Kenneth R. 1996. Arabic finite-state
morphological analysis and generation. In
Proceedings of the 16th International
Conference on Computational Linguistics
(COLING&apos;96), pages 89-94, Copenhagen,
Denmark.
Brill, Eric. 1995. Transformation-based
error-driven learning and natural
language processing: A case study in
part-of-speech tagging. Computational
Linguistics, 21(4):543-566, December.
Damerau, F. J. 1964. A technique for
computer detection and correction of
spelling errors. Communications of the
Association for Computing Machinery,
7(3):171-176.
Golding, Andrew and Henry S. Thompson.
1985. A morphology component for
language programs. Linguistics,
23:263-284.
Goldsmith, John. 1998. Unsupervised
learning of the morphology of a natural
language. Unpublished manuscript,
available at http : //hurnanities
uchicago . eduif acuity/goldsmith!
index. html.
Johnson, Mark. 1984. A discovery procedure
for certain phonological rules. In
Proceedings of 10th International Conference
on Computational Linguistics (COLING&apos;84),
pages 344-347, Stanford, CA, USA.
Kaplan, Ronald M. and Martin Kay. 1994.
Regular models of phonological rule
systems. Computational Linguistics,
20(3):331-378, September.
Karttunen, Lauri. 1993. Finite-state lexicon
compiler. Technical Report, XEROX, Palo
Alto Research Center, April.
Karttunen, Lauri. 1994. Constructing lexical
transducers. In Proceedings of the 15th
International Conference on Computational
Linguistics (COLING &apos;94), volume 1,
pages 406-411, Kyoto, Japan.
Karttunen, Lauri and Kenneth R. Beesley.
1992. Two-level rule compiler. Technical
Report, XEROX Palo Alto Research
Center.
Karttunen, Lauri, Jean-Pierre Chanod,
Gregory Grefenstette, and Anne Schiller.
1996. Regular expressions for language
engineering. Natural Language Engineering,
2(4):305-328.
Karttunen, Lauri, Ronald M. Kaplan, and
Annie Zaenen. 1992. Two-level
morphology with composition. In
Proceedings of the 14th International
Conference on Computational Linguistics,
volume 1, pages 141-148, Nantes, France.
Kiraz, George Anton. 2000. Multitiered
nonlinear morphology using multitape
finite automata: A case study on Syriac
and Arabic. Computational Linguistics,
26(1):77-105.
Koskenniemi, Kimmo. 1983. Two-level
morphology: A general computational
model for word form recognition and
production. Publication No. 11,
Department of General Linguistics,
University of Helsinki.
Mohri, Mehryar, Fernando Pereira, and
Michael Riley. 1998. A rational design for
a weighted finite-state transducer library.
</reference>
<page confidence="0.973975">
84
</page>
<note confidence="0.604633">
Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers
</note>
<reference confidence="0.999461881355932">
In Lecture Notes in Computer Science, 1436.
Springer Verlag.
Nirenburg, Sergei. 1998. Universal grammar
and lexis for quick ramp-up of MT
systems. In Proceedings of the First
International Conference on Language
Resources and Evaluation, pages 739-746,
Spain.
Nirenburg, Sergei and Victor Raskin. 1998.
Project Boas: &amp;quot;A Linguist in a Box&amp;quot; as a
multi-purpose language resource. In
COLING-ACL &apos;98: 36th Annual Meeting of
the Association for Computational Linguistics
and 17th International Conference on
Computational Linguistics, pages 975-979,
Montreal, Quebec Canada.
Nirenburg, Sergei and Victor Raskin. 1999.
Supply-side and demand-side lexical
semantics. In Evelyne Viegas, editor,
Depth and Breadth of Semantic Lexicons. Text,
Speech, and Language Technology Series.
Kluwer, Dordrecht and Boston.
Oflazer, Kemal. 1994. Two-level description
of Turkish morphology. Literary and
Linguistic Computing, 9(2):137-148.
Oflazer, Kemal. 1996. Error-tolerant
finite-state recognition with applications
to morphological analysis and spelling
correction. Computational Linguistics,
22(1):73-90, March.
Ranta, Aarne. 1998. A multilingual natural
language interface to regular expressions.
In Lauri Karttunen and Kemal Oflazer,
editors, Proceedings of the International
Workshop on Finite State Methods in Natural
Language Processing, FSMNLP&apos;98,
pages 79-90.
Rissanen, Jorma. 1989. Stochastic Complexity
in Statistical Inquiry. World Scientific
Publishing.
Satta, Giorgio and John C. Henderson. 1997.
String transformation learning. In
Proceedings of ACL/EACL&apos;97.
Sproat, Richard. 1992. Morphology and
Computation. MIT Press.
Theron, Pieter and Ian Cloete. 1997.
Automatic acquisition of two-level
morphological rules. In Proceedings of the
5th Conference on Applied Natural Language
Processing.
van Noord, Gertjan. 1999. FSA6: Finite state
automata utilities (version 6) manual.
Available at http:/ /odur.letrug.n1/ van-
noord/Fsa/Manual/.
van Noord, Gertjan and Dale Gerdemann.
1999. An extendible regular expression
compiler for finite-state approaches in
natural language processing. In
Proceedings of WIA 99.
</reference>
<page confidence="0.999697">
85
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.390263">
<title confidence="0.99974">Bootstrapping Morphological Analyzers</title>
<author confidence="0.565246">by Combining Human Elicitation</author>
<title confidence="0.934797">Machine Learning</title>
<author confidence="0.932895">Kemal Oflazer Sergei Nirenburgt</author>
<affiliation confidence="0.998">Sabana University New Mexico State University</affiliation>
<author confidence="0.907135">Marjorie McShane t</author>
<affiliation confidence="0.974515">New Mexico State University</affiliation>
<abstract confidence="0.99100475">This paper presents a semiautomatic technique for developing broad-coverage finite-state morphological analyzers for use in natural language processing applications. It consists of three components—elicitation of linguistic information from humans, a machine learning bootstrapping scheme, and a testing environment. The three components are applied iteratively until a threshold of output quality is attained. The initial application of this technique is for the morphology of low-density languages in the context of the Expedition project at NMSLI Computing Research Laboratory. This elicit-build-test technique compiles lexical and inflectional information elicited from a human into a finite-state transducer lexicon and combines this with a sequence of morphographemic rewrite rules that is induced using transformation-based learning from the elicited examples. The resulting morphological analyzer is then tested against a test set, and any corrections are fed back into the learning procedure, which then builds an improved analyzer.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>This research was supported in part by Contract MDA904-97-C-3976 from the U.S. Department of Defense. We also thank XRCE for providing the finite-state tools. Most of this work was done while the first author was visiting NMSU Computing Research Laboratory during the 1998-1999 academic year, on leave from</title>
<institution>Bilkent University,</institution>
<location>Ankara, Turkey.</location>
<marker></marker>
<rawString>This research was supported in part by Contract MDA904-97-C-3976 from the U.S. Department of Defense. We also thank XRCE for providing the finite-state tools. Most of this work was done while the first author was visiting NMSU Computing Research Laboratory during the 1998-1999 academic year, on leave from Bilkent University, Ankara, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evan L Antworth</author>
</authors>
<title>PC-KIMMO: A two-level processor for Morphological Analysis.</title>
<date>1990</date>
<booktitle>Occasional Publications in Academic Computing, Number 16. Summer Institute of Linguistics,</booktitle>
<location>Dallas, TX.</location>
<contexts>
<context position="1804" citStr="Antworth 1990" startWordPosition="249" endWordPosition="250">to the learning procedure, which then builds an improved analyzer. 1. Introduction The Expedition project at NMSU Computing Research Laboratory is devoted to the fast &amp;quot;ramp-up&amp;quot; of machine translation systems from less studied, so-called low-density languages, into English. One of the components that must be acquired and built during this process is a morphological analyzer for the source language. Since language informants are not expected or required to be well-versed in computational linguistics in general, or in recent approaches to building morphological analyzers (e.g., Koskenniemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; van Noord and Gerdemann 1999) in particular, the generation of the morphological analyzer component has to be accomplished semiautomatically. The informant will be guided through a knowledge elicitation procedure using the elicitation component of Expedition, the Boas system. As this task is not easy, we expect that the development of the morphological analyzer wil</context>
</contexts>
<marker>Antworth, 1990</marker>
<rawString>Antworth, Evan L. 1990. PC-KIMMO: A two-level processor for Morphological Analysis. Occasional Publications in Academic Computing, Number 16. Summer Institute of Linguistics, Dallas, TX.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
</authors>
<title>Arabic finite-state morphological analysis and generation.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING&apos;96),</booktitle>
<pages>89--94</pages>
<location>Copenhagen, Denmark.</location>
<marker>Beesley, 1996</marker>
<rawString>Beesley, Kenneth R. 1996. Arabic finite-state morphological analysis and generation. In Proceedings of the 16th International Conference on Computational Linguistics (COLING&apos;96), pages 89-94, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<pages>21--4</pages>
<contexts>
<context position="6610" citStr="Brill 1995" startWordPosition="983" endWordPosition="984"> suffixes will appear frequently in the corpus of inflected forms. Once common suffixes and prefixes are identified, the segmentation for an inflected word can be determined by choosing the segmentation with the most frequently occurring affix segments; the remainder is then considered the root. While this procedure seems to 1 For instance, the CoNLL (Computational Natural Language Learning) Workshops, recent special issues of Machine Learning Journal (Vol. 34 Issue 1/3, Feb. 1999) and Al Magazine (Vol. 18, No. 4, 1997). 2 Not in the sense in which it is used in transformation-based learning (Brill 1995). 60 Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers be reasonable for a small root word list, the potential for &amp;quot;noisy&amp;quot; or incorrect alignments is quite high when the corpus of inflected forms is large and the procedure is not given any prior knowledge of possible segmentations. As a result, automatically selecting the &amp;quot;correct&amp;quot; segmentation becomes nontrivial. An additional complication is that allomorphs show up as distinct affixes and their counts in segmentations are not accumulated, which might lead to actual segmentations being missed due to fragmentation. The rule</context>
<context position="13549" citStr="Brill 1995" startWordPosition="2055" endWordPosition="2056">. Currently, this feedback is limited to identifying problems in handling morphographemic processes (such as for instance the change of word-final -y to -i when the suffix -est is added). The box in Figure 1 labeled Morphological Analyzer Generation is the main component, which takes in the elicited information and generates a series of regular expressions for describing the morphological lexicon and morphographemic rules. The morphographemic rules describing changes in spelling as a result of affixation operations are induced from the examples provided by using transformation-based learning (Brill 1995; Satta and Henderson 1997). The result is an ordered set of contextual replace or rewrite rules, much like those used in phonology. 4 We use the term citation form to refer to the word form that is used to look up a given inflected form in a dictionary. It may be the root or stem form that affixation is applied to, or it may have additional morphological markers to indicate its citation form status. 5 We currently use XRCE finite-state tools as our target environment (Karttunen et al. 1996). 6 The test corpus is either elicited from the human informant or compiled from on-line resources for t</context>
<context position="33335" citStr="Brill 1995" startWordPosition="5178" endWordPosition="5179">ed Surface strona+a strona strona+e strong strona+y strony strona+ie stronie strona+a strong strona+ stron strona+om stronom strona+ach stronach strona+ami stronami of each paradigm.13 The example segmentations are fed into the learning module to induce morphographemic rules. 5.2.1 Generating Candidate Rules from Examples. The preprocessing stage yields a list of pairs of segmented lexical forms and surface forms. The segmented forms contain the citation forms and affixes; the affix boundaries are marked by the + symbol. This list is then processed by a transformation-based learning paradigm (Brill 1995; Satta and Henderson 1997), as illustrated in Figure 4. The basic idea is that we consider the list of segmented words as our input and find transformation rules (expressed as contextual rewrite rules) to incrementally transform this list into the list of surface forms. The transformation we choose at every iteration is the one that makes the list of segmented forms closest to the list of surface forms. The first step in the learning process is an initial alignment of pairs using a standard dynamic programming scheme. The only constraints in the alignment are: (i) a + in the segmented lexical</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Brill, Eric. 1995. Transformation-based error-driven learning and natural language processing: A case study in part-of-speech tagging. Computational Linguistics, 21(4):543-566, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Damerau</author>
</authors>
<title>A technique for computer detection and correction of spelling errors.</title>
<date>1964</date>
<journal>Communications of the Association for Computing Machinery,</journal>
<pages>7--3</pages>
<contexts>
<context position="28813" citStr="Damerau 1964" startWordPosition="4386" endWordPosition="4387">ample (c, are symbols in the alphabet of the language). Let Sk = (Ci, C2,.., Ck), 1 &lt; k &lt; c be a (string) prefix of C length k. We assume that the stem onto which morphological affixes are attached is Sk for some k.11 The set of inflectional forms given in the primary example are {Fi, F2, . , Ff }, with each Fi = (f,I are symbols in the alphabet of the language and 11 is the length of the jth form). The function ed(v,w) (ed for edit distance), where v and w are strings, measures the minimum number of symbol insertions and deletions (but not substitutions) that can be applied to v to obtain w (Damerau 1964).12 We define 1=f d(Sk) = k+ Eed(Sk,Fi) j=1 as a measure of the information needed to account for all the inflected forms. The first term above, k, is the length of the stem. The second term, the summation, measures how many symbols must be inserted and deleted to obtain the inflected form. The Sk with the minimum d(Sk) is then chosen as the stem S. Creating segmentations based on stem S proceeds as follows: To determine the affixes in each inflected form Fj Jp, we compute the projection of the stem Pi (f,. ,f1) in Fj, as that 10 Note that other finite state tools could also be used (e.g., Moh</context>
</contexts>
<marker>Damerau, 1964</marker>
<rawString>Damerau, F. J. 1964. A technique for computer detection and correction of spelling errors. Communications of the Association for Computing Machinery, 7(3):171-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Golding</author>
<author>Henry S Thompson</author>
</authors>
<title>A morphology component for language programs.</title>
<date>1985</date>
<journal>Linguistics,</journal>
<pages>23--263</pages>
<contexts>
<context position="5227" citStr="Golding and Thompson (1985)" startWordPosition="766" endWordPosition="769">nflected words and a root word list. Johnson (1984) presents a scheme for inducing phonological rules from surface data, mainly in the context of studying certain aspects of language acquisition. The premise is that languages have a finite number of alternations to be handled by morphographemic rules and a fixed number of contexts in which they appear; so if there is enough data, phonological rewrite rules can be generated to account for the data. Rules are ordered by some notion of &amp;quot;surfaciness&amp;quot;, and at each stage the most surfacy rule—the rule with the most transparent context— is selected. Golding and Thompson (1985) describe an approach for inducing rules of English word formation from a corpus of root forms and the corresponding inflected forms. The procedure described there generates a sequence of transformation rules,&apos; each specifying how to perform a particular inflection. More recently, Theron and Cloete (1997) have presented a scheme for obtaining two-level morphology rules from a set of aligned segmented and surface pairs. They use the notion of string edit sequences, assuming that only insertions and deletions are applied to a root form to get the inflected form. They determine the root form asso</context>
</contexts>
<marker>Golding, Thompson, 1985</marker>
<rawString>Golding, Andrew and Henry S. Thompson. 1985. A morphology component for language programs. Linguistics, 23:263-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language. Unpublished manuscript, available at http : //hurnanities uchicago . eduif acuity/goldsmith!</title>
<date>1998</date>
<note>index. html.</note>
<contexts>
<context position="7538" citStr="Goldsmith (1998)" startWordPosition="1123" endWordPosition="1124">lt, automatically selecting the &amp;quot;correct&amp;quot; segmentation becomes nontrivial. An additional complication is that allomorphs show up as distinct affixes and their counts in segmentations are not accumulated, which might lead to actual segmentations being missed due to fragmentation. The rules are not induced via a learning scheme: aligned pairs are compressed into a special data structure and traversals over this data structure generate morphographemic rules. Theron and Cloete have experimented with pluralization in Afrikaans, and the resulting system has shown about 94% accuracy on unseen words. Goldsmith (1998) has used an unsupervised learning method based on the minimum description length principle to learn the &amp;quot;morphology&amp;quot; of a number of languages. What is learned is a set of root words and affixes, and common inflectional-pattern classes. The system requires just a corpus of words in a language. In the absence of any root word list to use as a scaffolding, the shortest forms that appear frequently are assumed to be roots, and observed surface forms are then either generated by the concatenative affixation of suffixes or by rewrite rules.3 Since the system has no notion of what the roots and thei</context>
</contexts>
<marker>Goldsmith, 1998</marker>
<rawString>Goldsmith, John. 1998. Unsupervised learning of the morphology of a natural language. Unpublished manuscript, available at http : //hurnanities uchicago . eduif acuity/goldsmith! index. html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>A discovery procedure for certain phonological rules.</title>
<date>1984</date>
<booktitle>In Proceedings of 10th International Conference on Computational Linguistics (COLING&apos;84),</booktitle>
<pages>344--347</pages>
<location>Stanford, CA, USA.</location>
<contexts>
<context position="4651" citStr="Johnson (1984)" startWordPosition="674" endWordPosition="675"> amount of work in the application of machine learning techniques to language processing problems, such as part-of-speech tagging, grammar induction, and sense disambiguation, as witnessed by recent workshops and journal issues dedicated to this topic.1 The current work attempts to contribute to this literature by describing a human-supervised machine learning approach to the induction of morphological analyzers—a problem that, surprisingly, has received little attention. There have been a number of studies on inducing morphographemic rules from a list of inflected words and a root word list. Johnson (1984) presents a scheme for inducing phonological rules from surface data, mainly in the context of studying certain aspects of language acquisition. The premise is that languages have a finite number of alternations to be handled by morphographemic rules and a fixed number of contexts in which they appear; so if there is enough data, phonological rewrite rules can be generated to account for the data. Rules are ordered by some notion of &amp;quot;surfaciness&amp;quot;, and at each stage the most surfacy rule—the rule with the most transparent context— is selected. Golding and Thompson (1985) describe an approach fo</context>
</contexts>
<marker>Johnson, 1984</marker>
<rawString>Johnson, Mark. 1984. A discovery procedure for certain phonological rules. In Proceedings of 10th International Conference on Computational Linguistics (COLING&apos;84), pages 344-347, Stanford, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--3</pages>
<contexts>
<context position="15729" citStr="Kaplan and Kay 1994" startWordPosition="2382" endWordPosition="2385">e overheads. The basic architecture of the morphological analyzer is depicted in Figure 2. The analyzer consists of the union of transducers, each of which implements the morphological analysis process for one paradigm. Each transducer is the composition of a number of components. These components (from bottom to top) are described below: 1. The bottom component is an ordered sequence of morphographemic rules that are learned via transformation-based learning from the sample inflectional paradigms provided by the human informant. These rules are then composed into one finite-state transducer (Kaplan and Kay 1994). 2. The citation form and affix lexicon contains the citation forms and the affixes. We currently assume that all affixation is concatenative and that the lexicon is described by a regular expression of the sort [ Prefixes ]* [ CitationForms ] [ Suffixes ]*! 7 We currently assume that we have at most one prefix and at most one suffix, but this is not a fundamental limitation. The elicitation of morphotactics for an agglutinating language like Turkish or Finnish requires a significantly more sophisticated elicitation machinery. 63 Volume 27, Number 1 Computational Linguistics Lemma+Morphologic</context>
<context position="26873" citStr="Kaplan and Kay 1994" startWordPosition="4052" endWordPosition="4055">ding morphosyntactic features, are compiled (by our morphological analyzer generating system) into suitable regular expressions (expressed using the regular 9 The stem is considered to be that part of the citation form onto which affixes are attached, and in our context it has no function except for determining the affix strings. 67 Computational Linguistics Volume 27, Number 1 expression language of the XRCE finite-state tools Marttunen et al. 19961).&amp;quot; 4. The example base of the paradigm generated in step 2 is then used by a learning algorithm to generate a sequence of morphographemic rules (Kaplan and Kay 1994) that handle the morphographemic phenomena. 5. The regular expressions for the lexicon in step 3 and the regular expressions for the morphographemic rules induced in step 4 are then compiled into finite-state transducers and combined by composition to generate the finite-state morphological analyzer for the paradigm. The resulting finite-state transducers for each paradigm are then unioned to give the transducer for the complete set of paradigms. 5.1 Determining Segmentation and Affixes The suffixes and prefixes in a paradigm are determined by segmenting the inflected forms provided for the pr</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, Ronald M. and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20(3):331-378, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Finite-state lexicon compiler.</title>
<date>1993</date>
<tech>Technical Report, XEROX,</tech>
<institution>Palo Alto Research Center,</institution>
<contexts>
<context position="1936" citStr="Karttunen 1993" startWordPosition="266" endWordPosition="267">h Laboratory is devoted to the fast &amp;quot;ramp-up&amp;quot; of machine translation systems from less studied, so-called low-density languages, into English. One of the components that must be acquired and built during this process is a morphological analyzer for the source language. Since language informants are not expected or required to be well-versed in computational linguistics in general, or in recent approaches to building morphological analyzers (e.g., Koskenniemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; van Noord and Gerdemann 1999) in particular, the generation of the morphological analyzer component has to be accomplished semiautomatically. The informant will be guided through a knowledge elicitation procedure using the elicitation component of Expedition, the Boas system. As this task is not easy, we expect that the development of the morphological analyzer will be an iterative process, whereby the human informant will revise and/or refine the information previously elicited based on the fe</context>
</contexts>
<marker>Karttunen, 1993</marker>
<rawString>Karttunen, Lauri. 1993. Finite-state lexicon compiler. Technical Report, XEROX, Palo Alto Research Center, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Constructing lexical transducers.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94),</booktitle>
<volume>1</volume>
<pages>406--411</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="1857" citStr="Karttunen 1994" startWordPosition="256" endWordPosition="257">roved analyzer. 1. Introduction The Expedition project at NMSU Computing Research Laboratory is devoted to the fast &amp;quot;ramp-up&amp;quot; of machine translation systems from less studied, so-called low-density languages, into English. One of the components that must be acquired and built during this process is a morphological analyzer for the source language. Since language informants are not expected or required to be well-versed in computational linguistics in general, or in recent approaches to building morphological analyzers (e.g., Koskenniemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; van Noord and Gerdemann 1999) in particular, the generation of the morphological analyzer component has to be accomplished semiautomatically. The informant will be guided through a knowledge elicitation procedure using the elicitation component of Expedition, the Boas system. As this task is not easy, we expect that the development of the morphological analyzer will be an iterative process, whereby the human informan</context>
<context position="14772" citStr="Karttunen (1994)" startWordPosition="2240" endWordPosition="2241">uage in question. 62 Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers Start ,....-..-• Corpus Human Elicitation Compilation Process S. ..0 ir Description of Morphology (paradigms, examples, exceptions, etc.) Morphological Analyzer Generation Content for Morphological Analyzer Engine (lexicons, morphof raphemic rules) -110. Test • Comparison Errors, Corpus with Test Corpus Omissions Engine, Test Engine) %.(MA Figure 1 The elicit-build-test paradigm for bootstrapping a morphological analyzer. 4.1 Morphological Analyzer Architecture We adopt the general approach advocated by Karttunen (1994) and build the morphological analyzer as the combination of several finite-state transducers, some of which are constructed directly from the elicited information, and others of which are constructed from the output of the machine learning stage. Since the combination of the transducers is computed at compile-time, there are no run-time overheads. The basic architecture of the morphological analyzer is depicted in Figure 2. The analyzer consists of the union of transducers, each of which implements the morphological analysis process for one paradigm. Each transducer is the composition of a num</context>
</contexts>
<marker>Karttunen, 1994</marker>
<rawString>Karttunen, Lauri. 1994. Constructing lexical transducers. In Proceedings of the 15th International Conference on Computational Linguistics (COLING &apos;94), volume 1, pages 406-411, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Kenneth R Beesley</author>
</authors>
<title>Two-level rule compiler.</title>
<date>1992</date>
<tech>Technical Report,</tech>
<institution>XEROX Palo Alto Research Center.</institution>
<contexts>
<context position="1964" citStr="Karttunen and Beesley 1992" startWordPosition="268" endWordPosition="271">devoted to the fast &amp;quot;ramp-up&amp;quot; of machine translation systems from less studied, so-called low-density languages, into English. One of the components that must be acquired and built during this process is a morphological analyzer for the source language. Since language informants are not expected or required to be well-versed in computational linguistics in general, or in recent approaches to building morphological analyzers (e.g., Koskenniemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; van Noord and Gerdemann 1999) in particular, the generation of the morphological analyzer component has to be accomplished semiautomatically. The informant will be guided through a knowledge elicitation procedure using the elicitation component of Expedition, the Boas system. As this task is not easy, we expect that the development of the morphological analyzer will be an iterative process, whereby the human informant will revise and/or refine the information previously elicited based on the feedback from test runs of the</context>
</contexts>
<marker>Karttunen, Beesley, 1992</marker>
<rawString>Karttunen, Lauri and Kenneth R. Beesley. 1992. Two-level rule compiler. Technical Report, XEROX Palo Alto Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Jean-Pierre Chanod</author>
<author>Gregory Grefenstette</author>
<author>Anne Schiller</author>
</authors>
<title>Regular expressions for language engineering.</title>
<date>1996</date>
<journal>Natural Language Engineering,</journal>
<pages>2--4</pages>
<contexts>
<context position="1987" citStr="Karttunen et al. 1996" startWordPosition="272" endWordPosition="275">&amp;quot; of machine translation systems from less studied, so-called low-density languages, into English. One of the components that must be acquired and built during this process is a morphological analyzer for the source language. Since language informants are not expected or required to be well-versed in computational linguistics in general, or in recent approaches to building morphological analyzers (e.g., Koskenniemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; van Noord and Gerdemann 1999) in particular, the generation of the morphological analyzer component has to be accomplished semiautomatically. The informant will be guided through a knowledge elicitation procedure using the elicitation component of Expedition, the Boas system. As this task is not easy, we expect that the development of the morphological analyzer will be an iterative process, whereby the human informant will revise and/or refine the information previously elicited based on the feedback from test runs of the nascent analyzer. * Fa</context>
<context position="14045" citStr="Karttunen et al. 1996" startWordPosition="2143" endWordPosition="2146">as a result of affixation operations are induced from the examples provided by using transformation-based learning (Brill 1995; Satta and Henderson 1997). The result is an ordered set of contextual replace or rewrite rules, much like those used in phonology. 4 We use the term citation form to refer to the word form that is used to look up a given inflected form in a dictionary. It may be the root or stem form that affixation is applied to, or it may have additional morphological markers to indicate its citation form status. 5 We currently use XRCE finite-state tools as our target environment (Karttunen et al. 1996). 6 The test corpus is either elicited from the human informant or compiled from on-line resources for the language in question. 62 Oflazer, Nirenburg, and McShane Bootstrapping Morphological Analyzers Start ,....-..-• Corpus Human Elicitation Compilation Process S. ..0 ir Description of Morphology (paradigms, examples, exceptions, etc.) Morphological Analyzer Generation Content for Morphological Analyzer Engine (lexicons, morphof raphemic rules) -110. Test • Comparison Errors, Corpus with Test Corpus Omissions Engine, Test Engine) %.(MA Figure 1 The elicit-build-test paradigm for bootstrappin</context>
<context position="36184" citStr="Karttunen et al. 1996" startWordPosition="5698" endWordPosition="5701">the segmented side (up to some small length), also taking into account the word boundaries. For instance, from the first aligned-pair example, this procedure would generate rules such as the following (depending on the amount of left and right context allowed): y -&gt; II p_ y -&gt; i I I p _ + e y -&gt; i I I p _ + e s y -&gt; i I p _ +est y -&gt; i I I p_ + est # y -&gt; i I I p p _ + e + -&gt; 0 I I # u n _ +-&gt;0 H #un _ hap + -&gt; 0 I I _ est _ e s t # + -&gt; 0 I I ppy_ e s t # 14 We arbitrarily choose one if there are multiple legitimate alignments. 15 We use the XRCE finite-state tools regular expression syntax (Karttunen et al. 1996). For the sake of readability, we will ignore the escape symbol (%) that should precede any special characters (e.g., +) used in these rules. 71 Computational Linguistics Volume 27, Number 1 The # symbol denotes a word boundary and is intended to capture any word-initial and word-final phenomena. The segmentation rules (+ -&gt; 0) require at least some minimal left or right context (usually longer than the minimal context for other rules in order to produce more accurate segmentation decisions). We disallow contexts that consist only of a morpheme boundary, as such contexts are usually not inform</context>
</contexts>
<marker>Karttunen, Chanod, Grefenstette, Schiller, 1996</marker>
<rawString>Karttunen, Lauri, Jean-Pierre Chanod, Gregory Grefenstette, and Anne Schiller. 1996. Regular expressions for language engineering. Natural Language Engineering, 2(4):305-328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
<author>Ronald M Kaplan</author>
<author>Annie Zaenen</author>
</authors>
<title>Two-level morphology with composition.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics,</booktitle>
<volume>1</volume>
<pages>141--148</pages>
<location>Nantes, France.</location>
<marker>Karttunen, Kaplan, Zaenen, 1992</marker>
<rawString>Karttunen, Lauri, Ronald M. Kaplan, and Annie Zaenen. 1992. Two-level morphology with composition. In Proceedings of the 14th International Conference on Computational Linguistics, volume 1, pages 141-148, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Anton Kiraz</author>
</authors>
<title>Multitiered nonlinear morphology using multitape finite automata: A case study</title>
<date>2000</date>
<booktitle>on Syriac and Arabic. Computational Linguistics,</booktitle>
<pages>26--1</pages>
<marker>Kiraz, 2000</marker>
<rawString>Kiraz, George Anton. 2000. Multitiered nonlinear morphology using multitape finite automata: A case study on Syriac and Arabic. Computational Linguistics, 26(1):77-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimmo Koskenniemi</author>
</authors>
<title>Two-level morphology: A general computational model for word form recognition and production.</title>
<date>1983</date>
<journal>Publication</journal>
<volume>11</volume>
<institution>Department of General Linguistics, University of Helsinki.</institution>
<contexts>
<context position="1789" citStr="Koskenniemi 1983" startWordPosition="246" endWordPosition="248">ns are fed back into the learning procedure, which then builds an improved analyzer. 1. Introduction The Expedition project at NMSU Computing Research Laboratory is devoted to the fast &amp;quot;ramp-up&amp;quot; of machine translation systems from less studied, so-called low-density languages, into English. One of the components that must be acquired and built during this process is a morphological analyzer for the source language. Since language informants are not expected or required to be well-versed in computational linguistics in general, or in recent approaches to building morphological analyzers (e.g., Koskenniemi 1983; Antworth 1990; Karttunen, Kaplan, and Zaenen 1992; Karttunen 1994) and the operation of state-of-the-art finite-state tools (e.g., Karttunen 1993; Karttunen and Beesley 1992; Karttunen et al. 1996; Mohri, Pereira, and Riley 1998; van Noord 1999; van Noord and Gerdemann 1999) in particular, the generation of the morphological analyzer component has to be accomplished semiautomatically. The informant will be guided through a knowledge elicitation procedure using the elicitation component of Expedition, the Boas system. As this task is not easy, we expect that the development of the morphologic</context>
</contexts>
<marker>Koskenniemi, 1983</marker>
<rawString>Koskenniemi, Kimmo. 1983. Two-level morphology: A general computational model for word form recognition and production. Publication No. 11, Department of General Linguistics, University of Helsinki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando Pereira</author>
<author>Michael Riley</author>
</authors>
<title>A rational design for a weighted finite-state transducer library.</title>
<date>1998</date>
<marker>Mohri, Pereira, Riley, 1998</marker>
<rawString>Mohri, Mehryar, Fernando Pereira, and Michael Riley. 1998. A rational design for a weighted finite-state transducer library.</rawString>
</citation>
<citation valid="false">
<booktitle>In Lecture Notes in Computer Science,</booktitle>
<pages>1436</pages>
<publisher>Springer Verlag.</publisher>
<marker></marker>
<rawString>In Lecture Notes in Computer Science, 1436. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
</authors>
<title>Universal grammar and lexis for quick ramp-up of MT systems.</title>
<date>1998</date>
<booktitle>In Proceedings of the First International Conference on Language Resources and Evaluation,</booktitle>
<pages>739--746</pages>
<contexts>
<context position="8543" citStr="Nirenburg 1998" startWordPosition="1289" endWordPosition="1290">quently are assumed to be roots, and observed surface forms are then either generated by the concatenative affixation of suffixes or by rewrite rules.3 Since the system has no notion of what the roots and their part-of-speech values really are, and what morphological information is encoded by the affixes, this information needs to be retrofitted manually by a human, who has to weed through a large number of noisy rules. We feel that this approach, while quite novel, can be used to build real-world morphological analyzers only after substantial modifications are made. 3. The BOAS Project Boas (Nirenburg 1998; Nirenburg and Raskin 1998) is a semiautomatic knowledge elicitation system that guides a team of two people (a language informant and a programmer) through the process of developing the static knowledge sources required to produce a moderate-quality, broad-coverage MT system from any &amp;quot;low-density&amp;quot; language into English. Boas contains knowledge about human language phenomena and various realizations of these phenomena in a number of specific languages, as well as extensive pedagogical support, making the system a kind of &amp;quot;linguist in a box,&amp;quot; intended to help nonprofessional users with the tas</context>
</contexts>
<marker>Nirenburg, 1998</marker>
<rawString>Nirenburg, Sergei. 1998. Universal grammar and lexis for quick ramp-up of MT systems. In Proceedings of the First International Conference on Language Resources and Evaluation, pages 739-746, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Victor Raskin</author>
</authors>
<title>Project Boas: &amp;quot;A Linguist in a Box&amp;quot; as a multi-purpose language resource.</title>
<date>1998</date>
<booktitle>In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>975--979</pages>
<location>Montreal, Quebec</location>
<contexts>
<context position="8571" citStr="Nirenburg and Raskin 1998" startWordPosition="1291" endWordPosition="1294">med to be roots, and observed surface forms are then either generated by the concatenative affixation of suffixes or by rewrite rules.3 Since the system has no notion of what the roots and their part-of-speech values really are, and what morphological information is encoded by the affixes, this information needs to be retrofitted manually by a human, who has to weed through a large number of noisy rules. We feel that this approach, while quite novel, can be used to build real-world morphological analyzers only after substantial modifications are made. 3. The BOAS Project Boas (Nirenburg 1998; Nirenburg and Raskin 1998) is a semiautomatic knowledge elicitation system that guides a team of two people (a language informant and a programmer) through the process of developing the static knowledge sources required to produce a moderate-quality, broad-coverage MT system from any &amp;quot;low-density&amp;quot; language into English. Boas contains knowledge about human language phenomena and various realizations of these phenomena in a number of specific languages, as well as extensive pedagogical support, making the system a kind of &amp;quot;linguist in a box,&amp;quot; intended to help nonprofessional users with the task. In the spirit of the goal</context>
</contexts>
<marker>Nirenburg, Raskin, 1998</marker>
<rawString>Nirenburg, Sergei and Victor Raskin. 1998. Project Boas: &amp;quot;A Linguist in a Box&amp;quot; as a multi-purpose language resource. In COLING-ACL &apos;98: 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 975-979, Montreal, Quebec Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergei Nirenburg</author>
<author>Victor Raskin</author>
</authors>
<title>Supply-side and demand-side lexical semantics.</title>
<date>1999</date>
<booktitle>Depth and Breadth of Semantic Lexicons. Text, Speech, and Language Technology Series. Kluwer,</booktitle>
<editor>In Evelyne Viegas, editor,</editor>
<location>Dordrecht and Boston.</location>
<contexts>
<context position="9282" citStr="Nirenburg and Raskin 1999" startWordPosition="1395" endWordPosition="1398">language informant and a programmer) through the process of developing the static knowledge sources required to produce a moderate-quality, broad-coverage MT system from any &amp;quot;low-density&amp;quot; language into English. Boas contains knowledge about human language phenomena and various realizations of these phenomena in a number of specific languages, as well as extensive pedagogical support, making the system a kind of &amp;quot;linguist in a box,&amp;quot; intended to help nonprofessional users with the task. In the spirit of the goaldriven, &amp;quot;demand-side&amp;quot; approach to computational applications of language processing (Nirenburg and Raskin 1999), the process of acquiring this knowledge has been split into two steps: (i) acquiring the descriptive, declarative knowledge about a language and (ii) deriving operational knowledge (content for the processing engines) from this descriptive knowledge. An important goal that we strive to achieve regarding these descriptive and operational pieces of information, be they elicited from human informants or acquired via machine learning, is that they be transparent, human-readable, and, where necessary, human-maintainable and human-extendable, contrary to the opaque and uninterpretable representati</context>
</contexts>
<marker>Nirenburg, Raskin, 1999</marker>
<rawString>Nirenburg, Sergei and Victor Raskin. 1999. Supply-side and demand-side lexical semantics. In Evelyne Viegas, editor, Depth and Breadth of Semantic Lexicons. Text, Speech, and Language Technology Series. Kluwer, Dordrecht and Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Two-level description of Turkish morphology.</title>
<date>1994</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>9--2</pages>
<contexts>
<context position="45498" citStr="Oflazer (1994)" startWordPosition="7241" endWordPosition="7242">earning procedure for inducing rewrite rules is not language dependent. It is applicable to any language whose lexical representation is a concatenation of free and bound morphemes (or portions thereof). All this stage requires is a set of pairs of lexical and surface representations of the examples compiled for the example base. We have tested the rule learning component above on several other languages including Turkish, an agglutinating language, using an example base with lexical forms produced by a variant of the two-level morphology-based finite-state morphological analyzer described in Oflazer (1994). The lexical representation for Turkish also involved meta symbols (such as H for high vowels, D for dentals, etc.), which would be resolved with the appropriate surface symbol by the rules learned. For instance, vowel harmony rules would learn to resolve H as one of 1, 1, u, ii in the appropriate context. Furthermore, the version of the rule learning (sub)system used for Turkish also made use of context-bound morphophonological distinctions that are not elicited in Boas, such as high vowels, low unrounded vowels, dentals, etc. The rules generated were the most general set of rules that did n</context>
</contexts>
<marker>Oflazer, 1994</marker>
<rawString>Oflazer, Kemal. 1994. Two-level description of Turkish morphology. Literary and Linguistic Computing, 9(2):137-148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kemal Oflazer</author>
</authors>
<title>Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<pages>22--1</pages>
<contexts>
<context position="44348" citStr="Oflazer 1996" startWordPosition="7062" endWordPosition="7063">all the analyzers for each paradigm, one can do a more comprehensive test against a test corpus to see what surface forms in the test corpus are not recognized by the generated analyzer. Apart from revealing obvious deficiencies in coverage (e.g., missing citation forms in the lexicon), such testing provides feedback about minor human errors—the failure to cover certain morphographemic phenomena, or the incorrect assignment of citation forms to paradigms, for example. Our approach is as follows: we use the resulting morphological analyzer with an error-tolerant finite-state recognizer engine (Oflazer 1996). Using this engine, we try to find words recognized by the analyzer that are (very) close to a rejected (correct) word in the test corpus, essentially performing a reverse spelling correction. If the rejection is due to a small number of errors (1 or 2), the erroneous words recognized by the recognizer are aligned with the corresponding correct words from the test corpus. These aligned pairs can then be analyzed to see what the problems may be. 5.4 Applicability to Infixing, Circumfixing, and Agglutinating Languages The machine learning procedure for inducing rewrite rules is not language dep</context>
</contexts>
<marker>Oflazer, 1996</marker>
<rawString>Oflazer, Kemal. 1996. Error-tolerant finite-state recognition with applications to morphological analysis and spelling correction. Computational Linguistics, 22(1):73-90, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>A multilingual natural language interface to regular expressions.</title>
<date>1998</date>
<booktitle>In Lauri Karttunen and Kemal Oflazer, editors, Proceedings of the International Workshop on Finite State Methods in Natural Language Processing, FSMNLP&apos;98,</booktitle>
<pages>79--90</pages>
<contexts>
<context position="20674" citStr="Ranta 1998" startWordPosition="3122" endWordPosition="3123">n citation form may not have one of the inflected forms.) A paradigm description provides the full inflectional pattern for one characteristic or distinguished citation form and additional examples for any other citation forms whose inflectional forms undergo nonstandard morphographemic changes. If necessary, any lexical and feature constraints can be encoded. Currently the provisions we have for such constraints are limited to writing regular expressions (albeit at a much higher level than standard regular expressions); however, capturing such constraints using a more natural language (e.g., Ranta 1998) can be incorporated into future versions. 4.3 Elicited Descriptive Data Figure 3 presents the encoding of the information elicited for one paradigm of a Polish morphological analyzer, which will be covered in detail later.&apos; The data elicited using the user interface component of Boas is converted into a description text file with various components delineated by SGML-like tags. The components in the description are as follows: • The &lt;LANGUAGE—DESCRIPTION... &gt; component lists information about the language and specifies its vowels and consonants, and other orthographic symbols that do not fall</context>
</contexts>
<marker>Ranta, 1998</marker>
<rawString>Ranta, Aarne. 1998. A multilingual natural language interface to regular expressions. In Lauri Karttunen and Kemal Oflazer, editors, Proceedings of the International Workshop on Finite State Methods in Natural Language Processing, FSMNLP&apos;98, pages 79-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jorma Rissanen</author>
</authors>
<date>1989</date>
<booktitle>Stochastic Complexity in Statistical Inquiry.</booktitle>
<publisher>World Scientific Publishing.</publisher>
<contexts>
<context position="28009" citStr="Rissanen 1989" startWordPosition="4227" endWordPosition="4228"> paradigm are determined by segmenting the inflected forms provided for the primary example. This process is complicated by the fact that the citation form may not correspond to the stem—it may contain a morphological indication that it is the citation form. Furthermore, since the language informant provides only a small number of examples, statistically motivated approaches like the one suggested by Theron and Cleoete (1997) are not applicable. We have experimented with a number of approaches and have found that the following approach works quite well. Using the notion of description length (Rissanen 1989), we try to find a stem and a set of affixes that account for all the inflected forms of the primary example. Let C = c2, , cc) be the character string for the citation form in the primary example (c, are symbols in the alphabet of the language). Let Sk = (Ci, C2,.., Ck), 1 &lt; k &lt; c be a (string) prefix of C length k. We assume that the stem onto which morphological affixes are attached is Sk for some k.11 The set of inflectional forms given in the primary example are {Fi, F2, . , Ff }, with each Fi = (f,I are symbols in the alphabet of the language and 11 is the length of the jth form). The fu</context>
</contexts>
<marker>Rissanen, 1989</marker>
<rawString>Rissanen, Jorma. 1989. Stochastic Complexity in Statistical Inquiry. World Scientific Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giorgio Satta</author>
<author>John C Henderson</author>
</authors>
<title>String transformation learning.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL/EACL&apos;97.</booktitle>
<contexts>
<context position="13576" citStr="Satta and Henderson 1997" startWordPosition="2057" endWordPosition="2060"> this feedback is limited to identifying problems in handling morphographemic processes (such as for instance the change of word-final -y to -i when the suffix -est is added). The box in Figure 1 labeled Morphological Analyzer Generation is the main component, which takes in the elicited information and generates a series of regular expressions for describing the morphological lexicon and morphographemic rules. The morphographemic rules describing changes in spelling as a result of affixation operations are induced from the examples provided by using transformation-based learning (Brill 1995; Satta and Henderson 1997). The result is an ordered set of contextual replace or rewrite rules, much like those used in phonology. 4 We use the term citation form to refer to the word form that is used to look up a given inflected form in a dictionary. It may be the root or stem form that affixation is applied to, or it may have additional morphological markers to indicate its citation form status. 5 We currently use XRCE finite-state tools as our target environment (Karttunen et al. 1996). 6 The test corpus is either elicited from the human informant or compiled from on-line resources for the language in question. 62</context>
<context position="33362" citStr="Satta and Henderson 1997" startWordPosition="5180" endWordPosition="5183">trona+a strona strona+e strong strona+y strony strona+ie stronie strona+a strong strona+ stron strona+om stronom strona+ach stronach strona+ami stronami of each paradigm.13 The example segmentations are fed into the learning module to induce morphographemic rules. 5.2.1 Generating Candidate Rules from Examples. The preprocessing stage yields a list of pairs of segmented lexical forms and surface forms. The segmented forms contain the citation forms and affixes; the affix boundaries are marked by the + symbol. This list is then processed by a transformation-based learning paradigm (Brill 1995; Satta and Henderson 1997), as illustrated in Figure 4. The basic idea is that we consider the list of segmented words as our input and find transformation rules (expressed as contextual rewrite rules) to incrementally transform this list into the list of surface forms. The transformation we choose at every iteration is the one that makes the list of segmented forms closest to the list of surface forms. The first step in the learning process is an initial alignment of pairs using a standard dynamic programming scheme. The only constraints in the alignment are: (i) a + in the segmented lexical form is always aligned wit</context>
</contexts>
<marker>Satta, Henderson, 1997</marker>
<rawString>Satta, Giorgio and John C. Henderson. 1997. String transformation learning. In Proceedings of ACL/EACL&apos;97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
</authors>
<title>Morphology and Computation.</title>
<date>1992</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="25536" citStr="Sproat 1992" startWordPosition="3841" endWordPosition="3842">e morphological analyzer is a finite-state transducer that is actually the union of the transducers for each paradigm definition in the description provided. Thus, the elicited data is processed one paradigm at a time. For each paradigm we proceed as follows: 1. The elicited primary citation form and associated inflected forms are processed to find the &amp;quot;best&amp;quot; segmentation of the forms into stem and affixes.&apos; Although we allow for inflectional forms to have both a prefix and a suffix (one of each), we expect only suffixation to be employed by the inflecting languages with which we are dealing (Sproat 1992). 2. Once the affixes are determined, we segment the inflected forms for the primary example and any additional examples provided, and pair them with the corresponding surface forms. The segmented forms are now based on the citation form plus the affixes (not the stem). The reason is that we expect the morphological analyzer to generate the citation form for further access to lexical databases to be used in the applications. The resulting segmented form—surface form pairs make up the example base of the paradigm. 3. The citation forms given in the primary example, in additional examples, and e</context>
</contexts>
<marker>Sproat, 1992</marker>
<rawString>Sproat, Richard. 1992. Morphology and Computation. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pieter Theron</author>
<author>Ian Cloete</author>
</authors>
<title>Automatic acquisition of two-level morphological rules.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th Conference on Applied Natural Language Processing.</booktitle>
<contexts>
<context position="5533" citStr="Theron and Cloete (1997)" startWordPosition="811" endWordPosition="814">ixed number of contexts in which they appear; so if there is enough data, phonological rewrite rules can be generated to account for the data. Rules are ordered by some notion of &amp;quot;surfaciness&amp;quot;, and at each stage the most surfacy rule—the rule with the most transparent context— is selected. Golding and Thompson (1985) describe an approach for inducing rules of English word formation from a corpus of root forms and the corresponding inflected forms. The procedure described there generates a sequence of transformation rules,&apos; each specifying how to perform a particular inflection. More recently, Theron and Cloete (1997) have presented a scheme for obtaining two-level morphology rules from a set of aligned segmented and surface pairs. They use the notion of string edit sequences, assuming that only insertions and deletions are applied to a root form to get the inflected form. They determine the root form associated with an inflected form (and consequently the suffixes and prefixes) by exhaustively matching the inflected form against all root words. The motivation is that &amp;quot;real&amp;quot; suffixes will appear frequently in the corpus of inflected forms. Once common suffixes and prefixes are identified, the segmentation </context>
</contexts>
<marker>Theron, Cloete, 1997</marker>
<rawString>Theron, Pieter and Ian Cloete. 1997. Automatic acquisition of two-level morphological rules. In Proceedings of the 5th Conference on Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>FSA6: Finite state automata utilities (version 6) manual. Available at http:/ /odur.letrug.n1/ vannoord/Fsa/Manual/.</title>
<date>1999</date>
<marker>van Noord, 1999</marker>
<rawString>van Noord, Gertjan. 1999. FSA6: Finite state automata utilities (version 6) manual. Available at http:/ /odur.letrug.n1/ vannoord/Fsa/Manual/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
<author>Dale Gerdemann</author>
</authors>
<title>An extendible regular expression compiler for finite-state approaches in natural language processing.</title>
<date>1999</date>
<booktitle>In Proceedings of WIA 99.</booktitle>
<marker>van Noord, Gerdemann, 1999</marker>
<rawString>van Noord, Gertjan and Dale Gerdemann. 1999. An extendible regular expression compiler for finite-state approaches in natural language processing. In Proceedings of WIA 99.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>