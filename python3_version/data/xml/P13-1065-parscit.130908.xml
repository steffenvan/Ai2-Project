<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000178">
<title confidence="0.9937505">
Creating Similarity:
Lateral Thinking for Vertical Similarity Judgments
</title>
<author confidence="0.998559">
Tony Veale Guofu Li
</author>
<affiliation confidence="0.949953333333333">
Web Science and Technology Division, School of Computer Science and Informatics,
Korean Advanced Institute of Science University College Dublin,
and Technology, Yuseong, South Korea Belfield, Dublin D2, Ireland.
</affiliation>
<email confidence="0.994193">
Tony.Veale@gmail.com li.guofu.l@gmail.com
</email>
<sectionHeader confidence="0.998541" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999891695652174">
Just as observing is more than just see-
ing, comparing is far more than mere
matching. It takes understanding, and
even inventiveness, to discern a useful
basis for judging two ideas as similar in a
particular context, especially when our
perspective is shaped by an act of linguis-
tic creativity such as metaphor, simile or
analogy. Structured resources such as
WordNet offer a convenient hierarchical
means for converging on a common
ground for comparison, but offer little
support for the divergent thinking that is
needed to creatively view one concept as
another. We describe such a means here,
by showing how the web can be used to
harvest many divergent views for many
familiar ideas. These lateral views com-
plement the vertical views of WordNet,
and support a system for idea exploration
called Thesaurus Rex. We show also how
Thesaurus Rex supports a novel, genera-
tive similarity measure for WordNet.
</bodyText>
<sectionHeader confidence="0.756654" genericHeader="categories and subject descriptors">
1 Seeing is Believing (and Creating)
</sectionHeader>
<bodyText confidence="0.99990222">
Similarity is a cognitive phenomenon that is both
complex and subjective, yet for practical reasons
it is often modeled as if it were simple and objec-
tive. This makes sense for the many situations
where we want to align our similarity judgments
with those of others, and thus focus on the same
conventional properties that others are also likely
to focus upon. This reliance on the consensus
viewpoint explains why WordNet (Fellbaum,
1998) has proven so useful as a basis for compu-
tational measures of lexico-semantic similarity
(e.g. see Pederson et al. 2004, Budanitsky &amp;
Hirst, 2006; Seco et al. 2006). These measures
reduce the similarity of two lexical concepts to a
single number, by viewing similarity as an objec-
tive estimate of the overlap in their salient quali-
ties. This convenient perspective is poorly suited
to creative or insightful comparisons, but it is
sufficient for the many mundane comparisons we
often perform in daily life, such as when we or-
ganize books or look for items in a supermarket.
So if we do not know in which aisle to locate a
given item (such as oatmeal), we may tacitly
know how to locate a similar product (such as
cornflakes) and orient ourselves accordingly.
Yet there are occasions when the recognition
of similarities spurs the creation of similarities,
when the act of comparison spurs us to invent
new ways of looking at an idea. By placing pop
tarts in the breakfast aisle, food manufacturers
encourage us to view them as a breakfast food
that is not dissimilar to oatmeal or cornflakes.
When ex-PM Tony Blair published his memoirs,
a mischievous activist encouraged others to
move his book from Biography to Fiction in
bookshops, in the hope that buyers would see it
in a new light. Whenever we use a novel meta-
phor to convey a non-obvious viewpoint on a
topic, such as “cigarettes are time bombs”, the
comparison may spur us to insight, to see aspects
of the topic that make it more similar to the vehi-
cle (see Ortony, 1979; Veale &amp; Hao, 2007).
In formal terms, assume agent A has an in-
sight about concept X, and uses the metaphor X
is a Y to also provoke this insight in agent B. To
arrive at this insight for itself, B must intuit what
X and Y have in common. But this commonality
is surely more than a standard categorization of
X, or else it would not count as an insight about
X. To understand the metaphor, B must place X
</bodyText>
<page confidence="0.959226">
660
</page>
<note confidence="0.914">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 660–670,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999991016129033">
in a new category, so that X can be seen as more
similar to Y. Metaphors shape the way we per-
ceive the world by re-shaping the way we make
similarity judgments. So if we want to imbue
computers with the ability to make and to under-
stand creative metaphors, we must first give
them the ability to look beyond the narrow view-
points of conventional resources.
Any measure that models similarity as an ob-
jective function of a conventional worldview
employs a convergent thought process. Using
WordNet, for instance, a similarity measure can
vertically converge on a common superordinate
category of both inputs, and generate a single
numeric result based on their distance to, and the
information content of, this common generaliza-
tion. So to find the most conventional ways of
seeing a lexical concept, one simply ascends a
narrowing concept hierarchy, using a process de
Bono (1970) calls vertical thinking. To find nov-
el, non-obvious and useful ways of looking at a
lexical concept, one must use what Guilford
(1967) calls divergent thinking and what de Bono
calls lateral thinking. These processes cut across
familiar category boundaries, to simultaneously
place a concept in many different categories so
that we can see it in many different ways.
de Bono argues that vertical thinking is selec-
tive while lateral thinking is generative. Whereas
vertical thinking concerns itself with the “right”
way or a single “best” way of looking at things,
lateral thinking focuses on producing alternatives
to the status quo. To be as useful for creative
tasks as they are for conventional tasks, we need
to re-imagine our computational similarity
measures as generative rather than selective, ex-
pansive rather than reductive, divergent as well
as convergent and lateral as well as vertical.
Though WordNet is ideally structured to support
vertical, convergent reasoning, its comprehensive
nature means it can also be used as a solid foun-
dation for building a more lateral and divergent
model of similarity. Here we will use the web as
a source of diverse perspectives on familiar ide-
as, to complement the conventional and often
narrow views codified by WordNet.
Section 2 provides a brief overview of past
work in the area of similarity measurement, be-
fore section 3 describes a simple bootstrapping
loop for acquiring richly diverse perspectives
from the web for a wide variety of familiar ideas.
These perspectives are used to enhance a Word-
Net-based measure of lexico-semantic similarity
in section 4, by broadening the range of informa-
tive viewpoints the measure can select from.
Similarity is thus modeled as a process that is
both generative and selective. This lateral-and-
vertical approach is evaluated in section 5, on the
Miller &amp; Charles (1991) data-set. A web app for
the lateral exploration of diverse viewpoints,
named Thesaurus Rex, is also presented, before
closing remarks are offered in section 6.
</bodyText>
<sectionHeader confidence="0.998912" genericHeader="related work">
2 Related Work and Ideas
</sectionHeader>
<bodyText confidence="0.999734222222223">
WordNet’s taxonomic organization of noun-
senses and verb-senses – in which very general
categories are successively divided into increas-
ingly informative sub-categories or instance-
level ideas – allows us to gauge the overlap in
information content, and thus of meaning, of two
lexical concepts. We need only identify the
deepest point in the taxonomy at which this con-
tent starts to diverge. This point of divergence is
often called the LCS, or least common subsumer,
of two concepts (Pederson et al., 2004). Since
sub-categories add new properties to those they
inherit from their parents – Aristotle called these
properties the differentia that stop a category sys-
tem from trivially collapsing into itself – the
depth of a lexical concept in a taxonomy is an
intuitive proxy for its information content. Wu &amp;
Palmer (1994) use the depth of a lexical concept
in the WordNet hierarchy as such a proxy, and
thereby estimate the similarity of two lexical
concepts as twice the depth of their LCS divided
by the sum of their individual depths.
Leacock and Chodorow (1998) instead use
the length of the shortest path between two con-
cepts as a proxy for the conceptual distance be-
tween them. To connect any two ideas in a
hierarchical system, one must vertically ascend
the hierarchy from one concept, change direction
at a potential LCS, and then descend the hierar-
chy to reach the second concept. (Aristotle was
also first to suggest this approach in his Poetics).
Leacock and Chodorow normalize the length of
this path by dividing its size (in nodes) by twice
the depth of the deepest concept in the hierarchy;
the latter is an upper bound on the distance be-
tween any two concepts in the hierarchy. Negat-
ing the log of this normalized length yields a
corresponding similarity score. While the role of
an LCS is merely implied in Leacock and Cho-
dorow’s use of a shortest path, the LCS is pivotal
nonetheless, and like that of Wu &amp; Palmer, the
approach uses an essentially vertical reasoning
process to identify a single “best” generalization.
Depth is a convenient proxy for information
content, but more nuanced proxies can yield
</bodyText>
<page confidence="0.997033">
661
</page>
<bodyText confidence="0.999876963636364">
more rounded similarity measures. Resnick
(1995) draws on information theory to define the
information content of a lexical concept as the
negative log likelihood of its occurrence in a
corpus, either explicitly (via a direct mention) or
by presupposition (via a mention of any of its
sub-categories or instances). Since the likelihood
of a general category occurring in a corpus is
higher than that of any of its sub-categories or
instances, such categories are more predictable,
and less informative, than rarer categories whose
occurrences are less predictable and thus more
informative. The negative log likelihood of the
most informative LCS of two lexical concepts
offers a reliable estimate of the amount of infor-
mation shared by those concepts, and thus a good
estimate of their similarity. Lin (1998) combines
the intuitions behind Resnick’s metric and that of
Wu and Palmer to estimate the similarity of two
lexical concepts as an information ratio: twice
the information content of their LCS divided by
the sum of their individual information contents.
Jiang and Conrath (1997) consider the con-
verse notion of dissimilarity, noting that two lex-
ical concepts are dissimilar to the extent that
each contains information that is not shared by
the other. So if the information content of their
most informative LCS is a good measure of what
they do share, then the sum of their individual
information contents, minus twice the content of
their most informative LCS, is a reliable estimate
of their dissimilarity.
Seco et al. (2006) presents a minor innova-
tion, showing how Resnick’s notion of infor-
mation content can be calculated without the use
of an external corpus. Rather, when using Res-
nick’s metric (or that of Lin, or Jiang and Con-
rath) for measuring the similarity of lexical
concepts in WordNet, one can use the category
structure of WordNet itself to estimate infor-
mation content. Typically, the more general a
concept, the more descendants it will possess.
Seco et al. thus estimate the information content
of a lexical concept as the log of the sum of all
its unique descendants (both direct and indirect),
divided by the log of the total number of con-
cepts in the entire hierarchy. Not only is this in-
trinsic view of information content convenient to
use, without recourse to an external corpus, Seco
et al. show that it offers a better estimate of in-
formation content than its extrinsic, corpus-based
alternatives, as measured relative to average hu-
man similarity ratings for the 30 word-pairs in
the Miller &amp; Charles (1991) test set.
A similarity measure can draw on other
sources of information besides WordNet’s cate-
gory structures. One might eke out additional
information from WordNet’s textual glosses, as
in Lesk (1986), or use category structures other
than those offered by WordNet. Looking beyond
WordNet, entries in the online encyclopedia
Wikipedia are not only connected by a dense
topology of lateral links, they are also organized
by a rich hierarchy of overlapping categories.
Strube and Ponzetto (2006) show how Wikipedia
can support a measure of similarity (and related-
ness) that better approximates human judgments
than many WordNet-based measures. Nonethe-
less, WordNet can be a valuable component of a
hybrid measure, and Agirre et al. (2009) use an
SVM (support vector machine) to combine in-
formation from WordNet with information har-
vested from the web. Their best similarity
measure achieves a remarkable 0.93 correlation
with human judgments on the Miller &amp; Charles
word-pair set.
Similarity is not always applied to pairs of
concepts; it is sometimes analogically applied to
pairs of pairs of concepts, as in proportional
analogies of the form A is to B as C is to D (e.g.,
hacks are to writers as mercenaries are to sol-
diers, or chisels are to sculptors as scalpels are
to surgeons). In such analogies, one is really as-
sessing the similarity of the unstated relationship
between each pair of concepts: thus, mercenaries
are soldiers whose allegiance is paid for, much as
hacks are writers with income-driven loyalties;
sculptors use chisels to carve stone, while sur-
geons use scalpels to cut or carve flesh. Veale
(2004) used WordNet to assess the similarity of
A:B to C:D as a function of the combined simi-
larity of A to C and of B to D. In contrast, Tur-
ney (2005) used the web to pursue a more
divergent course, to represent the tacit relation-
ships of A to B and of C to D as points in a high-
dimensional space. The dimensions of this space
initially correspond to linking phrases on the
web, before these dimensions are significantly
reduced using singular value decomposition.
In the infamous SAT test, an analogy
A:B::C:D has four other pairs of concepts that
serve as likely distractors (e.g. singer:songwriter
for hack:writer) and the goal is to choose the
most appropriate C:D pair for a given A:B pair-
ing. Using variants of Wu and Palmer (1994) on
the 374 SAT analogies of Turney (2005), Veale
(2004) reports a success rate of 38–44% using
only WordNet-based similarity. In contrast, Tur-
ney (2005) reports up to 55% success on the
same analogies, partly because his approach aims
</bodyText>
<page confidence="0.990187">
662
</page>
<bodyText confidence="0.9999835">
to match implicit relations rather than explicit
concepts, and in part because it uses a divergent
process to gather from the web as rich a perspec-
tive as it can on these latent relationships.
</bodyText>
<subsectionHeader confidence="0.985927">
2.1 Clever Comparisons Create Similarity
</subsectionHeader>
<bodyText confidence="0.999992929577465">
Each of these approaches to similarity is a user
of information, rather than a creator, and each
fails to capture how a creative comparison (such
as a metaphor) can spur a listener to view a topic
from an atypical perspective. Camac &amp; Glucks-
berg (1984) provide experimental evidence for
the claim that “metaphors do not use preexisting
associations to achieve their effects [É] people
use metaphors to create new relations between
concepts.” They also offer a salutary reminder of
an often overlooked fact: every comparison ex-
ploits information, but each is also a source of
new information in its own right. Thus, “this cola
is acid” reveals a different perspective on cola
(e.g. as a corrosive substance or an irritating
food) than “this acid is cola” highlights for acid
(such as e.g., a familiar substance)
Veale &amp; Keane (1994) model the role of simi-
larity in realizing the long-term perlocutionary
effect of an informative comparison. For exam-
ple, to compare surgeons to butchers is to en-
courage one to see all surgeons as more bloody,
crude or careless. The reverse comparison, of
butchers to surgeons, encourages one to see
butchers as more skilled and precise. Veale &amp;
Keane present a network model of memory,
called Sapper, in which activation can spread
between related concepts, thus allowing one con-
cept to prime the properties of a neighbor. To
interpret an analogy, Sapper lays down new acti-
vation-carrying bridges in memory between ana-
logical counterparts, such as between surgeon &amp;
butcher, flesh &amp; meat, and scalpel &amp; cleaver.
Comparisons can thus have lasting effects on
how Sapper sees the world, changing the pattern
of activation that arises when it primes a concept.
Veale (2003) adopts a similarly dynamic view
of similarity in WordNet, showing how an ana-
logical comparison can result in the automatic
addition of new categories and relations to
WordNet itself. Veale considers the problem of
finding an analogical mapping between different
parts of WordNet’s noun-sense hierarchy, such
as between instances of Greek god and Norse
god, or between the letters of different alphabets,
such as of Greek and Hebrew. But no structural
similarity measure for WordNet exhibits enough
discernment to e.g. assign a higher similarity to
Zeus &amp; Odin (each is the supreme deity of its
pantheon) than to a pairing of Zeus and any other
Norse god, just as no structural measure will as-
sign a higher similarity to Alpha &amp; Aleph or to
Beta &amp; Beth than to any random letter pairing.
A fine-grained category hierarchy permits
fine-grained similarity judgments, and though
WordNet is useful, its sense hierarchies are not
especially fine-grained. However, we can auto-
matically make WordNet subtler and more dis-
cerning, by adding new fine-grained categories
to unite lexical concepts whose similarity is not
reflected by any existing categories. Veale
(2003) shows how a property that is found in the
glosses of two lexical concepts, of the same
depth, can be combined with their LCS to yield a
new fine-grained parent category, so e.g. “su-
preme” + deity = Supreme-deity (for Odin, Zeus,
Jupiter, etc.) and “1st” + letter = 1st-letter (for
Alpha, Aleph, etc.) Selected aspects of the textual
similarity of two WordNet glosses – the key to
similarity in Lesk (1986) – can thus be reified
into an explicitly categorical WordNet form.
</bodyText>
<sectionHeader confidence="0.99932" genericHeader="method">
3 Divergent (Re)Categorization
</sectionHeader>
<bodyText confidence="0.990122107142857">
To tap into a richer source of concept properties
than WordNet’s glosses, we can use web n-
grams. Consider these descriptions of a cowboy
from the Google n-grams (Brants &amp; Franz,
2006). The numbers to the right are Google fre-
quency counts.
a lonesome cowboy 432
a mounted cowboy 122
a grizzled cowboy 74
a swaggering cowboy 68
To find the stable properties that can underpin a
meaningful fine-grained category for cowboy, we
must seek out the properties that are so often pre-
supposed to be salient of all cowboys that one
can use them to anchor a simile, such as &amp;quot;swag-
gering like a cowboy” or “as grizzled as a cow-
boy”. So for each property P suggested by
Google n-grams for a lexical concept C, we gen-
erate a like-simile for verbal behaviors such as
swaggering and an as-as-simile for adjectives
such as lonesome. Each is then dispatched to
Google as a phrasal query. We value quality over
size, as these similes will later be used to find
diverse viewpoints on the web via bootstrapping.
We thus manually filter each web simile, to weed
out any that are ill-formed, and those intended to
be seen as ironic by their authors. This gives us a
body of 12,000+ valid web similes.
</bodyText>
<page confidence="0.995885">
663
</page>
<bodyText confidence="0.999753466666667">
Veale (2011, 2012, 2013) notes that web uses
of the pattern “as P as C” are rife with irony. In
contrast, web instances of “P S such as C” –
where S denotes a superordinate of C – are rarely
ironic. Hao &amp; Veale (2010) exploit this fact to
filter ironic comparisons from web similes, by
re-expressing each “as P as C” simile as “P *
such as C” (using a wildcard * to match any val-
ues for S) and looking for attested uses of this
new form on the web. Since each hit will also
yield a value for S via the wildcard *, and a fine-
grained category P-S for C, we use this approach
here to harvest fine-grained categories from the
web from most of our similes.
Once C is seen to be an exemplary member of
the category P-S, such as cola in fizzy-drink, a
targeted web search is used to find other mem-
bers of P-S, via the anchored query “P S such as
* and C”. For example, “fizzy drinks such as *
and cola” will retrieve web texts in which * is
matched to soda or lemonade. Each new member
can then be used to instantiate a further query, as
in “fizzy drinks such as * and soda”, to retrieve
other members of P-S, such as champagne and
root beer. This bootstrapping process runs in
successive cycles, using doubly-anchored pat-
terns that – following Kozareva et al. (2008) and
Veale et al. (2009) – explicitly mention both the
category to be populated (P-S) and a recently
acquired member of this category (C).
As cautioned by Kozareva et al., it is reckless
to bootstrap from members to categories to
members again if each enfilade of queries is like-
ly to return noisy results. A reliable filter must be
applied at each stage, to ensure that any member
C that is placed in a category P-S is a sensible
member of the category S. Only by filtering in
this way can we stop the rapid accumulation of
noise. For instance, a WordNet-based filter dis-
cards any categorization “P S such as X and C”
where X does not denote a WordNet entry for
which S does not denote a valid hypernym. Such
a filter offers no creative latitude, however, since
it forces every pairing of C and P-S to precisely
obey WordNet’s category hierarchy. We thus use
instead the near-miss filter described in Veale et
al. (2009), in which X must denote a descendant
of some direct hypernym of some sense of S. The
filter does not (and cannot) determine whether P
is salient for X. It merely assumes that if P is sa-
lient for C, it is salient for X.
Five successive cycles of bootstrapping are
performed, using the 12,000+ web similes as a
starting point. Consider cola: after 1 cycle, we
acquire 14 new categories, such as effervescent-
beverage and sweet-beverage. After 2 cycles we
acquire 43 categories; after 3 cycles, 72; after 4
cycles, 93; and after 5 cycles, we acquire 102
fine-grained perspectives on cola, such as stimu-
lating-drink and corrosive-substance.
</bodyText>
<figureCaption confidence="0.9543645">
Figure 1. Fine-grained perspectives for cola found by
Thesaurus Rex on the web. See also Figures 3 and 4.
</figureCaption>
<bodyText confidence="0.9999819">
These alternative viewpoints, for a broad array of
concepts, are gleaned from the collective intelli-
gence of the web. Some are more discerning and
informative than others – see for instance war &amp;
divorce in Figure 4 – though as de Bono (1971)
notes, lateral thinking does not privilege a nar-
row set of “correct” viewpoints, rather it gener-
ates a broad array of interesting alternatives,
none of which are ever “wrong”, even if some
prove more useful than others in a given context.
</bodyText>
<sectionHeader confidence="0.989328" genericHeader="method">
4 Measuring and Creating Similarity
</sectionHeader>
<bodyText confidence="0.999979318181818">
Which perspectives will be most useful and in-
formative to a WordNet-based similarity metric?
Simply, a perspective M-Cx for a concept Cy
can be coherently added to WordNet iff Cx de-
notes a hypernym of some sense of Cy in Word-
Net. For purposes of quantifying the similarity of
two terms t1 and t2 – by finding the WordNet
senses of these terms that exhibit the highest sim-
ilarity – we can augment WordNet with the per-
spectives on t1 and t2 that are coherent with
WordNet’s hierarchy. So for t1=cola &amp; t2=acid,
corrosive-substance offers a coherent new per-
spective on each, slotting in beneath the match-
ing WordNet sense of substance.
A category system is a structured feature
space. We estimate the similarity of C1 and C2 as
the cosine of the angle between the feature vec-
tors that are constructed for each. The dimen-
sions of these vectors are the atomic hypernyms
(direct or indirect) of C1 and C2 in WordNet; the
value of a dimension H in a vector is the infor-
mation content (IC) of the WordNet hypernym H:
</bodyText>
<page confidence="0.946643">
664
</page>
<equation confidence="0.976085777777778">
(1) IC(H) = - log size(H) )
(Ic E WN size(c)
category
M-H that is newly added to WordNet is
given by (2):
M-H) = -log ( Σm-h ∈ WN size(m-h))
ICabs(
√
M-H) . IC(H)
</equation>
<bodyText confidence="0.970177095238095">
of concepts
and C2, if at least one fine-grained
perspective M-H has been added to WordNet
between H and
and between H and C2, then
the value of dimension H for
and for C2 is
given by (4):
(4) weight(H) = max(IC(H), maxM IC(M-H))
When no shared perspective M-H can be added
under H, then weight(H) = IC(H).
perspective M-H will thus influence a similarity
judgment between
and C2 only if M-H can be
coherently added to WordNet as a hypernym of
and C2, and if M-H enriches our view of H.
Unlike Resnick (1995), Lin (1998) and Seco et
al. (2006), this vector-space approach does not
hinge on the information content of a single
LCS, so any shared hypernym H or perspective
M-H can
</bodyText>
<equation confidence="0.857498666666667">
C1
C1
C1
A fine-grained
C1
C1
</equation>
<bodyText confidence="0.9642095">
shape a similarity judgment according
to its informativeness.
</bodyText>
<sectionHeader confidence="0.997748" genericHeader="method">
5 Empirical Evaluation
</sectionHeader>
<bodyText confidence="0.998175965517242">
Many fascinating perspectives on familiar ideas
are bootstrapped from the web using similes as a
starting point. These perspectives drive an ex-
ploratory web-aid to lateral thinking we call The-
saurus Rex, while the cosine-distance metric
constructed from WordNet and these many fine-
grained categories is called, simply, Rex. When
Rex provides a numeric estimate of similarity for
two ideas, Thesaurus Rex provides an enhanced
insight into why these ideas are similar, e.g. by
explaining that cola
are not just substanc-
es, they are corrosive substances.
We evaluate Rex by estimating how closely its
judgments correlate with those of human judges
on the 30-pair word set of Miller
(M&amp;C), who aggregated the judgments of multi-
ple human raters into mean ratings for these
pairs. We evaluate three variants of Rex on
M&amp;C: Rex-lat, which combines WordNet with
all of Thesaurus Rex; Rex-wn, which uses only
WordNet, with nothing at all from Thesaurus
Rex; and Rex-pop, which enriches WordNet with
only popular perspectives from Thesaurus Rex.
A perspective is considered popular if it is dis-
or more times in the bootstrapping
process, using 5 different anchors. While corro-
sive-substance is a popular category for acid, it
not so for cola or juice. Popularity thus approxi-
</bodyText>
<figure confidence="0.852903333333333">
&amp; acid
&amp; Charles
5
</figure>
<figureCaption confidence="0.542868">
ony (1979) calls salience.
</figureCaption>
<table confidence="0.996094777777778">
mates what Ort Similarity metric r Similarity metric r
Wu &amp; .74 Seco et al. .84
Palmer’94&amp;quot; ‘06&amp;quot;
Resnick .77 Agirre et al. .93
‘95&amp;quot; ‘09
Leacock/Chod’98&amp;quot; .82 Han et al.’09 .856
Lin ‘98&amp;quot; .80 Rex-wn .84
Jiang/Conrath ‘97&amp;quot; -.81 Rex-lat .89
Li et al. ‘03 .89 Rex-pop .93
</table>
<tableCaption confidence="0.9878206">
Table 1. Product-moment correlations (Pearson’s r)
with mean human ratings on all 30 word pairs of the
Miller &amp; Charles similarity data-set.
* As re-evaluated by Seco et al. (2006) for all 30 pairs
Table 1 lists coefficients of correlation
</tableCaption>
<bodyText confidence="0.815782416666667">
r) with mean human ratings for a range of
WordNet-based metrics. Table 1 includes the
hybrid
metric of Agirre et
al. (2009)
report a correlation of .93
the Mutual-Information-based PMImax metric of
Han et al. (2009). The latter achieves good re-
sults for 27 of the 30 M&amp;C pairs by enriching a
PMI metric with an automatically-generated
(Pear-
son’s
</bodyText>
<equation confidence="0.72685">
WordNet+web+SVM
– who
– and
the-
</equation>
<bodyText confidence="0.998925">
saurus. Yet while informative, this thesaurus is
Here size(H) is the total number of lexical con-
cepts in category H in WordNet, excluding any
instance-level concepts, as these illustrative indi-
viduals are not evenly distributed across Word-
Net categories.
We also want any fine-grained perspective M-
H to influence our similarity metric, provided it
can be coherently tied into WordNet as a shared
hypernym of the two lexical concepts being
compared. The absolute information content of a
</bodyText>
<listItem confidence="0.510868">
(2) ICabs(
</listItem>
<bodyText confidence="0.9009899">
size(M-H)
where size(M-H) is the number of lexical con-
cepts in WordNet for which M-H can be added
as a new hypernym. The denominator in (2) de-
notes the sum total of the size of all fine-grained
categories that can be coherently added to
WordNet for any term.
The IC of M-H relative to H is estimated via
the geometric mean of ICabs(M-H) and IC(H) is
given by (3):
</bodyText>
<listItem confidence="0.710296">
(3) IC(M-H) =
</listItem>
<bodyText confidence="0.520215">
For a shared dimension H in the feature vectors
</bodyText>
<page confidence="0.992317">
665
</page>
<bodyText confidence="0.999973057142857">
not organized as an explanatory system of hier-
archical categories as it is in Thesaurus Rex.
Rex-wn does no better than Seco et al. (2006)
on the M&amp;C dataset, suggesting that Rex’s vec-
tors of IC-weighted hypernyms are no more dis-
cerning than a single informative LCS. However,
such vectors also permit Rex to incorporate addi-
tional, fine-grained perspectives from Thesaurus
Rex, allowing Rex-lat in turn to achieve a com-
parable correlation to that of Li et al. (2003) –
.89. Yet the formulation in (2) favors unusual or
idiosyncratic perspectives that are unlikely to
generalize across independent judges. The mean
ratings of M&amp;C are the stuff of consensus, not
individual creativity, and outside the realm of
creative metaphor it often makes sense to safely
align our judgments with those of others.
By limiting its use of Thesaurus Rex to the
perspectives that other judges are most likely to
use, Rex-pop obtains a correlation of .93 with
mean human ratings on all 30 M&amp;C pairs. This
result is comparable to that reported by Agirre et
al. (2009), who use SVM-based supervised
learning to combine the judgments of two met-
rics, one based on WordNet and another on the
analysis of web contexts of both input terms.
However, Rex has the greater capacity for in-
sight, since it augments the structured category
system of WordNet with structured categories of
its own. At each level of the WordNet hierarchy,
Rex finds the fine-grained category that can best
inform its judgments. Because Rex makes highly
selective use of the diverse products of lateral
thinking, this selectivity also produces concise
explanations for its judgments.
</bodyText>
<subsectionHeader confidence="0.959025">
5.1 Generative Uses of Similarity
</subsectionHeader>
<bodyText confidence="0.999994692307692">
A similarity metric offers a numerical measure of
how closely one idea can cluster with another. It
can also indicate how well one object may serve
as a substitute for another, as when a letter open-
er is used as a knife, or tofu is used instead of
meat. This need for substitution can be grist for
creativity, yet most similarity metrics can only
assess a suggested substitution, rather than sug-
gest one for themselves. If they are to actively
shape a creative decision, our similarity metrics
must be made more generative.
A similarity metric can learn to be generative,
by observing how people typically cluster words
and ideas that are made similar by their contexts
of use. The Google 3-grams contain many in-
stances of the clustering pattern “X+s and Y+s”,
as in “cowboys and pirates” or “doctors and law-
yers”, and so a comprehensive trawl yields many
insights into the pairings of ideas that we implic-
itly see as comparable. We harvest all such
Google 3-grams, to build a symmetric compara-
bility graph in which any two comparable terms
are adjacent nodes. For any node, we can gener-
ate a diverse set of comparable ideas just by
reading off its adjacent nodes. Thesaurus Rex can
be used to find an embracing category for many
such pairs of nodes, while Rex estimates the sim-
ilarity of any two adjacent nodes. A comparabil-
ity graph of 28,000 nodes is produced from the
Google 3-grams, with a sparse adjacency matrix
of just 1,264,827 (0.16%) non-zero entries.
Is this dense enough for a task requiring gen-
erative similarity? Almuhareb &amp; Poesio (2004)
describe one such task: they sample 214 words
from across 13 WordNet categories, and ask if
these 214 words can be partitioned into 13 clus-
ters that mirror the WordNet categories from
which they were drawn. They then collect tens of
thousands of web contexts for these 214 words,
to extract a feature representation of each. We
instead use Rex to generate, as features, a diverse
set of comparable terms for each word. (We also
assume that each word is a feature of itself). The
Rex comparability graph suggests a pool of 8,300
features for all 214 words. The clustering toolkit
CLUTO is used to partition the original 214
words into 13 clusters guided only by these com-
parability features. The resulting 13 clusters have
an average purity of 93.4% relative to WordNet,
suggesting that categorization tasks which re-
quire implicit comparability judgments are well
served by a generative approach to similarity.
</bodyText>
<subsectionHeader confidence="0.999749">
5.2 Learning From Similarity Judgments
</subsectionHeader>
<bodyText confidence="0.999925842105263">
Rex augments the narrow worldview of WordNet
with the more diverse viewpoints it gleans from
the web, not by viewing them as separate
knowledge sources, but by actually updating
WordNet itself. The relative performance of
Rex-pop &gt; Rex-lat &gt; Rex-wn on the M&amp;C da-
taset shows that selective use of a divergent per-
spective permits WordNet to better serve its
popular role as a judge of similarity. It is worth
asking then whether these passing additions to
WordNet should not be made permanent.
Rex estimates a similarity score for each of
the 1,264,827 pairings of comparable terms it
finds in the Google 3-grams. These scores are
then cached to support generative similarity, and
to permit fast lookup of scores for common com-
parisons. This lookup table is a lightweight
means of using Rex in a range of creative substi-
tution or generation tasks. Though the table is
</bodyText>
<page confidence="0.996132">
666
</page>
<bodyText confidence="0.997543444444444">
sparse, §5.1 shows that it implicitly captures key
nuances of category structure. The 39,826 unique
fine-grained categories added by Rex-pop (ver-
sus the 44,238 categories added by Rex-lat) in
the course of its 1,264,827 comparisons thus
suggest credible enhancements to WordNet. Fig-
ure 2 graphs the distribution of new categories
and their membership sizes when Rex-pop is
used on this scale.
</bodyText>
<figureCaption confidence="0.994715">
Figure 2. The number of new categories (Y-axis) with
a given membership size (X-axis) added to WordNet
when Rex-pop/lat are used on a large, web scale.
</figureCaption>
<bodyText confidence="0.999964">
The Goldilocks categories are those that are not
so small as to lack generality, and not so large as
to lack information content. For example, Rex-
pop suggests the addition of 15,125 new fine-
grained categories to WordNet with membership
sizes ranging from 5 to 25. This is a large but
manageable number of categories that should be
further considered for future addition to Word-
Net, or indeed to any similarly curated
knowledge resource.
</bodyText>
<sectionHeader confidence="0.996537" genericHeader="evaluation">
6 Summary and Conclusions
</sectionHeader>
<bodyText confidence="0.991922666666667">
de Bono (1970) argues that the best solutions
arise from using lateral and vertical thinking in
unison. Lateral thinking is divergent and genera-
tive, while vertical thinking is convergent and
analytical. The former can thus be used to create
a pool of interesting candidates for the latter to
selectively consider. Thesaurus Rex uses the web
to generate a rich pool of alternate perspectives
on familiar ideas, and Rex selects from this pool
to perform vertical reasoning with WordNet to
yield precise similarity judgments. Rex also uses
the most informative perspective to concisely
explain each comparison, or – when used in gen-
erative mode – to suggest a creative comparison.
For instance, to highlight the potential toxicity of
coffee, Thesaurus Rex suggests comparisons with
alcohol, tobacco or pesticide, as all have been
categorized as toxic substances on the web. A
web app based on Thesaurus Rex, to support this
kind of lateral thinking, is accessible online at
this URL:
http://boundinanutshell.com/therex2
Screenshots from the Thesaurus Rex application
are provided in Figures 3 and 4 overleaf. Be-
cause Thesaurus Rex targets the acquisition of
fine-grained perspectives, ranging from the off-
beat to the obvious, it acquires an order-of-
magnitude more categories from the web than
can be found in WordNet itself. Rex dips selec-
tively into this wealth of perspectives (and Rex-
pop is more selective still), though many of
Rex’s needs can be anticipated by looking to how
ideas are implicitly grouped into ad-hoc catego-
ries (Barsalou, 1983) in constructions such as
“X+s and Y+s”. Using the Google n-grams as a
source of tacit grouping constructions, we have
created a comprehensive lookup table that pro-
vides Rex similarity scores for the most common
(if often implicit) comparisons.
Comparability is not the same as similarity,
and a non-zero similarity score does not mean
that two concepts would ever be considered
comparable by a human. This poses a problem
for the generation of sensible comparisons.
However, Rex’s lookup table captures the implic-
it pragmatics of comparability, making Rex usa-
ble in generative tasks where a metric must both
suggest and evaluate comparisons. Human simi-
larity mechanisms are evaluative and generative,
convergent and divergent. Our computational
mechanisms should be no less so.
</bodyText>
<sectionHeader confidence="0.998977" genericHeader="conclusions">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.936431285714286">
This research was partly supported by the WCU
(World Class University) program under the Na-
tional Research Foundation of Korea (Ministry
of Education, Science and Technology of Korea,
Project no. R31-30007) and partly funded by
Science Foundation Ireland via the Centre for
Next Generation Localization (CNGL).
</bodyText>
<page confidence="0.990879">
667
</page>
<figureCaption confidence="0.9942365">
Figure 3. A screenshot from the web application Thesaurus Rex, showing the fine-grained categories found by
Thesaurus Rex for the lexical concept creativity on the web.
Figure 4. A screenshot from the web application Thesaurus Rex, showing the shared overlapping categories
found by Thesaurus Rex for the lexical concepts divorce and war.
</figureCaption>
<page confidence="0.99567">
668
</page>
<sectionHeader confidence="0.99609" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999367259615385">
Aristotle (translator: James Hutton). 1982. Aristotle’s
Poetics. New York: Norton.
Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana
Kravalova, Marius Pasca and Aitor Soroa. 2009.
Study on Similarity and Relatedness Using Distri-
butional and WordNet-based Approaches. In Pro-
ceedings of NAACL &apos;09, The 2009 Annual
Conference of the North American Chapter of the
Association for Computational Linguistics, pp.
19—27.
Abdulrahman Almuhareb and Massimo Poesio. 2004.
Attribute-Based and Value-Based Clustering: An
Evaluation. In Proceedings of the Conference on
Empirical Methods in NLP, Barcelona. pp. 158-
165.
Lawrence W. Barsalou. 1983. Ad hoc categories.
Memory and Cognition, 11:211–227.
Thorsten Brants and Alex Franz. 2006. Web 1T 5-
gram Ver. 1. Philadelphia: Linguistic Data Consor-
tium.
Alexander Budanitsky and Graeme Hirst. 2006.
Evaluating WordNet-based Measures of Lexical
Semantic Relatedness. Computational Linguistics,
32(1):13-47.
Mary K. Camac, and Sam Glucksberg. 1984.
Metaphors do not use associations between
concepts, they are used to create them. Journal of
Psycholinguistic Research, 13, 443-455.
de Bono, Edward. 1970. Lateral thinking: creativity
step by step. New York: Harper &amp; Row.
de Bono, Edward. 1971. Lateral thinking for
management: a handbook for creativity. New
York: McGraw Hill.
Christiane Fellbaum (ed.). 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
MA.
J. Paul Guilford. 1967. The Nature of Human
Intelligence. New York: McGraw Hill.
Lushan Han, Tim Finin, Paul McNamee, Anupam
Joshi and Yelena Yesha. 2012. Improving Word
Similarity by Augmenting PMI with Estimates of
Word Polysemy. IEEE Transactions on Data and
Knowledge Engineering (13 Feb. 2012).
Yanfen Hao and Tony Veale. 2010. An Ironic Fist in a
Velvet Glove: Creative Mis-Representation in the
Construction of Ironic Similes. Minds and
Machines 20(4), pp. 635–650.
Jay Y. Jiang and David W. Conrath. 1997. Semantic
similarity based on corpus statistics and lexical
taxonomy. In Proceedings of the 10th International
Conference on Research in Computational
Linguistics, pp. 19-33.
Zornitsa Kozareva, Eileen Riloff and Eduard Hovy.
2008. Semantic Class Learning from the Web with
Hyponym Pattern Linkage Graphs. In Proc. of the
46th Annual Meeting of the ACL, pp 1048-1056.
Claudia Leacock and Martin Chodorow. 1998.
Combining local context and WordNet similarity
for word sense identification. In Fellbaum, C. (ed.),
WordNet: An Electronic Lexical Database, 265–
283.
Yuhua Li, Zuhair A. Bandar and David McLean.
2003. An Approach for Measuring Semantic Simi-
larity between Words Using Multiple Information
Sources. IEEE Transactions on Knowledge and
Data Engineering, vol. 15, no. 4, pp. 871-882.
Dekang Lin. 1998. An information-theoretic
definition of similarity. In Proceedings of the 15th
ICML, the International Conference on Machine
Learning, Morgan Kaufmann, San Francisco CA,
pp. 296– 304.
Michael Lesk. 1986 Automatic sense disambiguation
using machine readable dictionaries: how to tell a
pine cone from an ice cream cone. In Proceedings
of ACM SigDoc, ACM, 24–26.
George A. Miller and Walter. G. Charles. 1991. Con-
textual correlates of semantic similarity. Language
and Cognitive Processes 6(1):1-28.
Andrew Ortony. 1979. Beyond literal similarity. Psy-
chological Review, 86, pp. 161-180.
Ted Pederson, Siddarth Patwardhan and Jason
Michelizzi. 2004. WordNet::Similarity: measuring
the relatedness of concepts. In Proceedings of
HLT-NAACL’04 (Demonstration Papers) the 2004
annual Conference of the North American Chapter
of the Association for Computational Linguistics,
pp. 38-41.
Philip Resnick. 1995. Using Information Content to
Evaluate Semantic Similarity in a Taxonomy. In
Proceedings of IJCAI’95, the 14th International
Joint Conference on Artificial Intelligence.
Nuno Seco, Tony Veale and Jer Hayes, 2004. An In-
trinsic Information Content Metric for Semantic
Similarity in WordNet. In Proceedings of ECAI’04,
the European Conference on Artificial Intelligence.
Michael Strube and Simone Paolo Ponzetto. 2006.
WikiRelate! Computing Semantic Relatedness
Using Wikipedia. In Proceedings of AAAI-06, the
2006 Conference of the Association for the
Advancement of AI, pp. 1419–1424.
Peter Turney. 2005. Measuring semantic similarity by
latent relational analysis. Proceedings of the 19th
International Joint Conference on Artificial Intelli-
gence, 1136-1141.
</reference>
<page confidence="0.983091">
669
</page>
<reference confidence="0.99976047826087">
Tony Veale and Mark T. Keane. 1994. Belief Model-
ing, Intentionality and Perlocution in Metaphor
Comprehension. In Proceedings of the 16th Annual
Meeting of the Cognitive Science Society, Atlanta,
Georgia. Hillsdale, NJ: Lawrence Erlbaum.
Tony Veale. 2003. The analogical thesaurus: An
emerging application at the juncture of lexical
metaphor and information retrieval. In Proceedings
of IAAI’03, the 1Sth International Conference on
Innovative Applications of Artificial Intelligence,
Mexico.
Tony Veale. 2004. WordNet sits the SAT: A
knowledge-based approach to lexical analogy.
Proceedings of ECAI&apos;04, the European Conference
on Artificial Intelligence, 606-612.
Tony Veale and Yanfen Hao. 2007. Comprehending
and Generating Apt Metaphors: A Web-driven,
Case-based Approach to Figurative Language. In
proceedings of AAAI 2007, the 22nd AAAI Con-
ference on Artificial Intelligence. Vancouver, Can-
ada.
Tony Veale, Guofu Li and Yanfen Hao. 2009. Grow-
ing Finely-Discriminating Taxonomies from Seeds
of Varying Quality and Size. In Proc. of EACL’09,
the 12th Conference of the European Chapter of the
Association for Computational Linguistics pp. 835-
842.
Tony Veale. 2011. Creative Language Retrieval: A
Robust Hybrid of Information Retrieval and Lin-
guistic Creativity. In Proceedings of ACL’2011,
the 49th Annual Meeting of the Association for
Computational Linguistics: Human Language
Technologies.
Tony Veale. 2012. Exploding the Creativity Myth:
The computational foundations of linguistic crea-
tivity. London: Bloomsbury Academic.
Tony Veale. 2013. Humorous Similes. Humor: The
International Journal of Humor Research, 21(l):3-
22.
1(1):3-
22.
Zhibiao Wu and Martha Palmer. 1994. Verb seman-
tics and lexical selection. In Proceedings of
ACL’94, 32nd annual meeting of the Association for
Computational Linguistics, Las Cruces, New Mexi-
co,. pp. 133-138.
</reference>
<page confidence="0.99794">
670
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9980265">Creating Similarity: Lateral Thinking for Vertical Similarity Judgments</title>
<author confidence="0.999791">Tony Veale Guofu Li</author>
<affiliation confidence="0.833707666666667">Web Science and Technology Division, School of Computer Science and Informatics, Korean Advanced Institute of Science University College Dublin, and Technology, Yuseong, South Korea Belfield, Dublin D2, Ireland.</affiliation>
<email confidence="0.99425">Tony.Veale@gmail.comli.guofu.l@gmail.com</email>
<abstract confidence="0.999235907020873">as more than just seefar more than mere It takes understanding, and even inventiveness, to discern a useful basis for judging two ideas as similar in a particular context, especially when our perspective is shaped by an act of linguistic creativity such as metaphor, simile or analogy. Structured resources such as WordNet offer a convenient hierarchical means for converging on a common ground for comparison, but offer little support for the divergent thinking that is needed to creatively view one concept as another. We describe such a means here, by showing how the web can be used to harvest many divergent views for many familiar ideas. These lateral views complement the vertical views of WordNet, and support a system for idea exploration We show also how Rex a novel, generative similarity measure for WordNet. Seeing is Believing Similarity is a cognitive phenomenon that is both complex and subjective, yet for practical reasons it is often modeled as if it were simple and objective. This makes sense for the many situations where we want to align our similarity judgments with those of others, and thus focus on the same conventional properties that others are also likely to focus upon. This reliance on the consensus viewpoint explains why WordNet (Fellbaum, 1998) has proven so useful as a basis for computational measures of lexico-semantic similarity see Pederson 2004, Budanitsky &amp; 2006; Seco al. These measures reduce the similarity of two lexical concepts to a single number, by viewing similarity as an objective estimate of the overlap in their salient qualities. This convenient perspective is poorly suited to creative or insightful comparisons, but it is sufficient for the many mundane comparisons we often perform in daily life, such as when we organize books or look for items in a supermarket. So if we do not know in which aisle to locate a item (such as we may tacitly know how to locate a similar product (such as and orient ourselves accordingly. Yet there are occasions when the recognition similarities spurs the similarities, when the act of comparison spurs us to invent ways of looking at an idea. By placing the breakfast aisle, food manufacturers encourage us to view them as a breakfast food is not dissimilar to When ex-PM Tony Blair published his memoirs, a mischievous activist encouraged others to his book from bookshops, in the hope that buyers would see it in a new light. Whenever we use a novel metaphor to convey a non-obvious viewpoint on a such as are time the comparison may spur us to insight, to see aspects the topic that more similar to the vehicle (see Ortony, 1979; Veale &amp; Hao, 2007). In formal terms, assume agent A has an inabout concept X, and uses the metaphor a Y also provoke this insight in agent B. To arrive at this insight for itself, B must intuit what X and Y have in common. But this commonality is surely more than a standard categorization of X, or else it would not count as an insight about X. To understand the metaphor, B must place X 660 of the 51st Annual Meeting of the Association for Computational pages Bulgaria, August 4-9 2013. Association for Computational Linguistics in a new category, so that X can be seen as more similar to Y. Metaphors shape the way we perceive the world by re-shaping the way we make similarity judgments. So if we want to imbue computers with the ability to make and to understand creative metaphors, we must first give them the ability to look beyond the narrow viewpoints of conventional resources. Any measure that models similarity as an objective function of a conventional worldview a process. Using WordNet, for instance, a similarity measure can vertically converge on a common superordinate category of both inputs, and generate a single numeric result based on their distance to, and the information content of, this common generalization. So to find the most conventional ways of seeing a lexical concept, one simply ascends a narrowing concept hierarchy, using a process de (1970) calls To find novel, non-obvious and useful ways of looking at a lexical concept, one must use what Guilford calls thinking what de Bono These processes cut across familiar category boundaries, to simultaneously place a concept in many different categories so that we can see it in many different ways. de Bono argues that vertical thinking is selective while lateral thinking is generative. Whereas vertical thinking concerns itself with the “right” way or a single “best” way of looking at things, lateral thinking focuses on producing alternatives to the status quo. To be as useful for creative tasks as they are for conventional tasks, we need to re-imagine our computational similarity measures as generative rather than selective, expansive rather than reductive, divergent as well as convergent and lateral as well as vertical. Though WordNet is ideally structured to support vertical, convergent reasoning, its comprehensive nature means it can also be used as a solid foundation for building a more lateral and divergent model of similarity. Here we will use the web as a source of diverse perspectives on familiar ideas, to complement the conventional and often narrow views codified by WordNet. Section 2 provides a brief overview of past work in the area of similarity measurement, before section 3 describes a simple bootstrapping loop for acquiring richly diverse perspectives from the web for a wide variety of familiar ideas. These perspectives are used to enhance a Word- Net-based measure of lexico-semantic similarity in section 4, by broadening the range of informative viewpoints the measure can select from. Similarity is thus modeled as a process that is generative This lateral-andvertical approach is evaluated in section 5, on the Miller &amp; Charles (1991) data-set. A web app for the lateral exploration of diverse viewpoints, is also presented, before closing remarks are offered in section 6. 2 Related Work and Ideas WordNet’s taxonomic organization of nounsenses and verb-senses – in which very general categories are successively divided into increasingly informative sub-categories or instancelevel ideas – allows us to gauge the overlap in information content, and thus of meaning, of two lexical concepts. We need only identify the deepest point in the taxonomy at which this content starts to diverge. This point of divergence is called the common two concepts (Pederson 2004). Since sub-categories add new properties to those they inherit from their parents – Aristotle called these the stop a category system from trivially collapsing into itself – the depth of a lexical concept in a taxonomy is an intuitive proxy for its information content. Wu &amp; Palmer (1994) use the depth of a lexical concept in the WordNet hierarchy as such a proxy, and thereby estimate the similarity of two lexical concepts as twice the depth of their LCS divided by the sum of their individual depths. Leacock and Chodorow (1998) instead use the length of the shortest path between two concepts as a proxy for the conceptual distance between them. To connect any two ideas in a hierarchical system, one must vertically ascend the hierarchy from one concept, change direction at a potential LCS, and then descend the hierarchy to reach the second concept. (Aristotle was first to suggest this approach in his Leacock and Chodorow normalize the length of this path by dividing its size (in nodes) by twice the depth of the deepest concept in the hierarchy; the latter is an upper bound on the distance between any two concepts in the hierarchy. Negating the log of this normalized length yields a corresponding similarity score. While the role of an LCS is merely implied in Leacock and Chouse of a path, LCS is pivotal nonetheless, and like that of Wu &amp; Palmer, the approach uses an essentially vertical reasoning process to identify a single “best” generalization. Depth is a convenient proxy for information content, but more nuanced proxies can yield 661 more rounded similarity measures. Resnick (1995) draws on information theory to define the information content of a lexical concept as the negative log likelihood of its occurrence in a corpus, either explicitly (via a direct mention) or by presupposition (via a mention of any of its sub-categories or instances). Since the likelihood of a general category occurring in a corpus is higher than that of any of its sub-categories or instances, such categories are more predictable, and less informative, than rarer categories whose occurrences are less predictable and thus more informative. The negative log likelihood of the most informative LCS of two lexical concepts offers a reliable estimate of the amount of information shared by those concepts, and thus a good estimate of their similarity. Lin (1998) combines the intuitions behind Resnick’s metric and that of Wu and Palmer to estimate the similarity of two lexical concepts as an information ratio: twice the information content of their LCS divided by the sum of their individual information contents. Jiang and Conrath (1997) consider the connotion of noting that two lexical concepts are dissimilar to the extent that each contains information that is not shared by the other. So if the information content of their most informative LCS is a good measure of what then the sum of their individual information contents, minus twice the content of their most informative LCS, is a reliable estimate of their dissimilarity. al. presents a minor innovation, showing how Resnick’s notion of information content can be calculated without the use of an external corpus. Rather, when using Resnick’s metric (or that of Lin, or Jiang and Conrath) for measuring the similarity of lexical concepts in WordNet, one can use the category structure of WordNet itself to estimate information content. Typically, the more general a concept, the more descendants it will possess. thus estimate the information content of a lexical concept as the log of the sum of all its unique descendants (both direct and indirect), divided by the log of the total number of conin the entire hierarchy. Not only is this inof information content convenient to use, without recourse to an external corpus, Seco show that it offers a better estimate of information content than its extrinsic, corpus-based alternatives, as measured relative to average human similarity ratings for the 30 word-pairs in the Miller &amp; Charles (1991) test set. A similarity measure can draw on other sources of information besides WordNet’s category structures. One might eke out additional information from WordNet’s textual glosses, as in Lesk (1986), or use category structures other than those offered by WordNet. Looking beyond WordNet, entries in the online encyclopedia Wikipedia are not only connected by a dense topology of lateral links, they are also organized by a rich hierarchy of overlapping categories. Strube and Ponzetto (2006) show how Wikipedia can support a measure of similarity (and relatedness) that better approximates human judgments than many WordNet-based measures. Nonetheless, WordNet can be a valuable component of a measure, and Agirre al. use an SVM (support vector machine) to combine information from WordNet with information harvested from the web. Their best similarity achieves a remarkable with human judgments on the Miller &amp; Charles word-pair set. Similarity is not always applied to pairs of concepts; it is sometimes analogically applied to pairs concepts, as in proportional of the form is to B as C is to D hacks are to writers as mercenaries are to solor are to sculptors as scalpels are In such analogies, one is really assessing the similarity of the unstated relationship between each pair of concepts: thus, mercenaries are soldiers whose allegiance is paid for, much as hacks are writers with income-driven loyalties; sculptors use chisels to carve stone, while surgeons use scalpels to cut or carve flesh. Veale (2004) used WordNet to assess the similarity of A:B to C:D as a function of the combined similarity of A to C and of B to D. In contrast, Turney (2005) used the web to pursue a more divergent course, to represent the tacit relationships of A to B and of C to D as points in a highdimensional space. The dimensions of this space initially correspond to linking phrases on the web, before these dimensions are significantly using value In the infamous SAT test, an analogy four other pairs of concepts that as likely distractors (e.g. and the goal is to choose the appropriate for a given pairing. Using variants of Wu and Palmer (1994) on the 374 SAT analogies of Turney (2005), Veale (2004) reports a success rate of 38–44% using only WordNet-based similarity. In contrast, Turney (2005) reports up to 55% success on the same analogies, partly because his approach aims 662 to match implicit relations rather than explicit concepts, and in part because it uses a divergent process to gather from the web as rich a perspective as it can on these latent relationships. Comparisons of these approaches to similarity is a information, rather than a and each fails to capture how a creative comparison (such as a metaphor) can spur a listener to view a topic from an atypical perspective. Camac &amp; Glucksberg (1984) provide experimental evidence for the claim that “metaphors do not use preexisting associations to achieve their effects [É] people use metaphors to create new relations between concepts.” They also offer a salutary reminder of an often overlooked fact: every comparison exploits information, but each is also a source of new information in its own right. Thus, “this cola acid” reveals a different perspective on as a substance an than “this acid is cola” highlights for as e.g., a Veale &amp; Keane (1994) model the role of similarity in realizing the long-term perlocutionary effect of an informative comparison. For example, to compare surgeons to butchers is to enone to see all surgeons as more The reverse comparison, of butchers to surgeons, encourages one to see as more Veale &amp; Keane present a network model of memory, in which activation can spread between related concepts, thus allowing one concept to prime the properties of a neighbor. To an analogy, down new activation-carrying bridges in memory between anacounterparts, such as between and Comparisons can thus have lasting effects on the world, changing the pattern of activation that arises when it primes a concept. Veale (2003) adopts a similarly dynamic view of similarity in WordNet, showing how an analogical comparison can result in the automatic addition of new categories and relations to WordNet itself. Veale considers the problem of finding an analogical mapping between different parts of WordNet’s noun-sense hierarchy, such between instances of god or between the letters of different alphabets, such as of Greek and Hebrew. But no structural similarity measure for WordNet exhibits enough discernment to e.g. assign a higher similarity to is the supreme deity of its than to a pairing of any other just as no structural measure will asa higher similarity to to to any random letter pairing. A fine-grained category hierarchy permits fine-grained similarity judgments, and though WordNet is useful, its sense hierarchies are not especially fine-grained. However, we can automatically make WordNet subtler and more discerning, by adding new fine-grained categories to unite lexical concepts whose similarity is not reflected by any existing categories. Veale (2003) shows how a property that is found in the glosses of two lexical concepts, of the same depth, can be combined with their LCS to yield a new fine-grained parent category, so e.g. “su- + Zeus, etc.) and “1st” + etc.) Selected aspects of the textual similarity of two WordNet glosses – the key to similarity in Lesk (1986) – can thus be reified into an explicitly categorical WordNet form. 3 Divergent (Re)Categorization To tap into a richer source of concept properties than WordNet’s glosses, we can use web n- Consider these descriptions of a from the Google n-grams (Brants &amp; Franz, 2006). The numbers to the right are Google frequency counts. a lonesome cowboy 432 a mounted cowboy 122 a grizzled cowboy 74 a swaggering cowboy 68 To find the stable properties that can underpin a fine-grained category for we must seek out the properties that are so often presupposed to be salient of all cowboys that one use them to anchor a simile, such as like a or grizzled as a cow- So for each property by n-grams for a lexical concept we gena for verbal behaviors such as an for adjectives as Each is then dispatched to Google as a phrasal query. We value quality over size, as these similes will later be used to find diverse viewpoints on the web via bootstrapping. We thus manually filter each web simile, to weed out any that are ill-formed, and those intended to be seen as ironic by their authors. This gives us a body of 12,000+ valid web similes. 663 Veale (2011, 2012, 2013) notes that web uses the pattern P as are rife with irony. In web instances of S such as – a superordinate of are rarely ironic. Hao &amp; Veale (2010) exploit this fact to filter ironic comparisons from web similes, by each P as simile as * as (using a wildcard * to match any valfor and looking for attested uses of this new form on the web. Since each hit will also a value for the wildcard *, and a finecategory we use this approach here to harvest fine-grained categories from the web from most of our similes. seen to be an exemplary member of category such as a targeted web search is used to find other memof via the anchored query S such as and For example, drinks such as * will retrieve web texts in which * is to Each new member can then be used to instantiate a further query, as drinks such as * and to retrieve members of such as This bootstrapping process runs in successive cycles, using doubly-anchored patthat – following Kozareva al. and al. – explicitly mention both the to be populated and a recently member of this category cautioned by Kozareva it is reckless to bootstrap from members to categories to members again if each enfilade of queries is likely to return noisy results. A reliable filter must be applied at each stage, to ensure that any member is placed in a category a sensible of the category Only by filtering in this way can we stop the rapid accumulation of noise. For instance, a WordNet-based filter disany categorization S such as X and not denote a WordNet entry for which S does not denote a valid hypernym. Such a filter offers no creative latitude, however, since forces every pairing of precisely obey WordNet’s category hierarchy. We thus use the described in Veale in which denote a descendant some direct hypernym of some sense of The does not (and cannot) determine whether salient for It merely assumes that if safor it is salient for Five successive cycles of bootstrapping are performed, using the 12,000+ web similes as a point. Consider after 1 cycle, we 14 new categories, such as effervescent- After 2 cycles we acquire 43 categories; after 3 cycles, 72; after 4 cycles, 93; and after 5 cycles, we acquire 102 perspectives on such as stimu- Fine-grained perspectives for cola found by Thesaurus Rex on the web. See also Figures 3 and 4. These alternative viewpoints, for a broad array of concepts, are gleaned from the collective intelligence of the web. Some are more discerning and than others – see for instance Figure 4 – though as de Bono (1971) notes, lateral thinking does not privilege a narrow set of “correct” viewpoints, rather it generates a broad array of interesting alternatives, none of which are ever “wrong”, even if some prove more useful than others in a given context. Measuring and Which perspectives will be most useful and informative to a WordNet-based similarity metric? a perspective a concept be coherently added to WordNet Cx dea hypernym of some sense of Word- Net. For purposes of quantifying the similarity of terms by finding the WordNet senses of these terms that exhibit the highest similarity – we can augment WordNet with the peron are coherent with hierarchy. So for a coherent new perspective on each, slotting in beneath the match- WordNet sense of A category system is a structured feature We estimate the similarity of the cosine of the angle between the feature vectors that are constructed for each. The dimensions of these vectors are the atomic hypernyms or indirect) of WordNet; the value of a dimension H in a vector is the information content (IC) of the WordNet hypernym H: 664 = log ) category M-H is newly added to WordNet is given by (2): = -log ICabs( √ M-H) . IC(H) of concepts and if at least one fine-grained been added to WordNet and between then value of dimension and for given by (4): = max(IC(H), IC(M-H)) no shared perspective be added then = IC(H). thus influence a similarity judgment between and if be coherently added to WordNet as a hypernym of and and if our view of Resnick (1995), Lin (1998) and Seco (2006), this vector-space approach does not hinge on the information content of a single so any shared hypernym perspective can</abstract>
<note confidence="0.778115">C1 C1 C1 A fine-grained C1 C1</note>
<abstract confidence="0.986725490774907">shape a similarity judgment according to its informativeness. 5 Empirical Evaluation Many fascinating perspectives on familiar ideas are bootstrapped from the web using similes as a starting point. These perspectives drive an exweb-aid to lateral thinking we call The- Rex, the cosine-distance metric constructed from WordNet and these many finecategories is called, simply, When a numeric estimate of similarity for ideas, Rex an enhanced insight into why these ideas are similar, e.g. by that are not just substancthey are evaluate estimating how closely its judgments correlate with those of human judges on the 30-pair word set of Miller (M&amp;C), who aggregated the judgments of multiple human raters into mean ratings for these We evaluate three variants of which combines WordNet with of which uses only with nothing at all from and which enriches WordNet with from perspective is considered popular if it is disor more times in the bootstrapping using 5 different anchors. While corroa popular category for it so for Popularity thus approxiacid &amp; Charles (1979) calls mates what Ort Similarity metric r Similarity metric r Wu &amp; .74 Seco al. .84 Palmer’94&amp;quot; ‘06&amp;quot; Resnick .77 Agirre al. .93 ‘95&amp;quot; ‘09 Leacock/Chod’98&amp;quot; .82 Han et al.’09 .856 Lin ‘98&amp;quot; .80 Rex-wn .84 Jiang/Conrath ‘97&amp;quot; -.81 Rex-lat .89 Li et al. ‘03 .89 Rex-pop .93 correlations (Pearson’s with mean human ratings on all 30 word pairs of the Miller &amp; Charles similarity data-set. * As re-evaluated by Seco et al. (2006) for all 30 pairs Table 1 lists coefficients of correlation with mean human ratings for a range of WordNet-based metrics. Table 1 includes the hybrid metric of Agirre report a correlation of Mutual-Information-based of (2009). The latter achieves good results for 27 of the 30 M&amp;C pairs by enriching a PMI metric with an automatically-generated (Pearson’s WordNet+web+SVM – who – and thesaurus. Yet while informative, this thesaurus is is the total number of lexical conin category WordNet, excluding any instance-level concepts, as these illustrative individuals are not evenly distributed across Word- Net categories. also want any fine-grained perspective Minfluence our similarity metric, provided it can be coherently tied into WordNet as a shared hypernym of the two lexical concepts being compared. The absolute information content of a (2) ICabs( is the number of lexical conin WordNet for which be added as a new hypernym. The denominator in (2) dethe sum total of the size of categories that can be coherently added to for IC of to estimated via geometric mean of and IC(H) is given by (3): (3) IC(M-H) = a shared dimension the feature vectors 665 not organized as an explanatory system of hiercategories as it is in no better than Seco al. the M&amp;C dataset, suggesting that vectors of IC-weighted hypernyms are no more discerning than a single informative LCS. However, vectors also permit incorporate addifine-grained perspectives from allowing turn to achieve a comcorrelation to that of Li al. – Yet the formulation in (2) favors unusual or idiosyncratic perspectives that are unlikely to generalize across independent judges. The mean ratings of M&amp;C are the stuff of consensus, not individual creativity, and outside the realm of creative metaphor it often makes sense to safely align our judgments with those of others. limiting its use of Rex the perspectives that other judges are most likely to a correlation of mean human ratings on all 30 M&amp;C pairs. This is comparable to that reported by Agirre (2009), who use SVM-based supervised learning to combine the judgments of two metrics, one based on WordNet and another on the analysis of web contexts of both input terms. the greater capacity for insight, since it augments the structured category system of WordNet with structured categories of its own. At each level of the WordNet hierarchy, the fine-grained category that can best its judgments. Because highly selective use of the diverse products of lateral thinking, this selectivity also produces concise explanations for its judgments. Uses of Similarity A similarity metric offers a numerical measure of how closely one idea can cluster with another. It can also indicate how well one object may serve a substitute for another, as when a openused as a or used instead of This need for substitution can be grist for creativity, yet most similarity metrics can only assess a suggested substitution, rather than suggest one for themselves. If they are to actively shape a creative decision, our similarity metrics must be made more generative. A similarity metric can learn to be generative, by observing how people typically cluster words and ideas that are made similar by their contexts of use. The Google 3-grams contain many inof the clustering pattern and as in “cowboys and pirates” or “doctors and lawyers”, and so a comprehensive trawl yields many insights into the pairings of ideas that we implicitly see as comparable. We harvest all such 3-grams, to build a symmetric comparagraph which any two comparable terms are adjacent nodes. For any node, we can generate a diverse set of comparable ideas just by off its adjacent nodes. Rex be used to find an embracing category for many pairs of nodes, while the similarity of any two adjacent nodes. A comparability graph of 28,000 nodes is produced from the Google 3-grams, with a sparse adjacency matrix of just 1,264,827 (0.16%) non-zero entries. Is this dense enough for a task requiring generative similarity? Almuhareb &amp; Poesio (2004) describe one such task: they sample 214 words from across 13 WordNet categories, and ask if these 214 words can be partitioned into 13 clusters that mirror the WordNet categories from which they were drawn. They then collect tens of thousands of web contexts for these 214 words, to extract a feature representation of each. We use generate, as features, a diverse set of comparable terms for each word. (We also assume that each word is a feature of itself). The graph suggests a pool of 8,300 features for all 214 words. The clustering toolkit CLUTO is used to partition the original 214 words into 13 clusters guided only by these comparability features. The resulting 13 clusters have average purity of to WordNet, suggesting that categorization tasks which require implicit comparability judgments are well served by a generative approach to similarity. From Similarity Judgments the narrow worldview of WordNet with the more diverse viewpoints it gleans from the web, not by viewing them as separate knowledge sources, but by actually updating WordNet itself. The relative performance of the M&amp;C dataset shows that selective use of a divergent perspective permits WordNet to better serve its popular role as a judge of similarity. It is worth asking then whether these passing additions to WordNet should not be made permanent. a similarity score for each of the 1,264,827 pairings of comparable terms it finds in the Google 3-grams. These scores are then cached to support generative similarity, and to permit fast lookup of scores for common comparisons. This lookup table is a lightweight of using a range of creative substitution or generation tasks. Though the table is 666 sparse, §5.1 shows that it implicitly captures key nuances of category structure. The 39,826 unique categories added by (verthe 44,238 categories added by in the course of its 1,264,827 comparisons thus suggest credible enhancements to WordNet. Figure 2 graphs the distribution of new categories their membership sizes when used on this scale. 2. number of new categories (Y-axis) with a given membership size (X-axis) added to WordNet used on a large, web scale. categories those that are not so small as to lack generality, and not so large as lack information content. For example, the addition of 15,125 new finegrained categories to WordNet with membership sizes ranging from 5 to 25. This is a large but manageable number of categories that should be further considered for future addition to Word- Net, or indeed to any similarly curated knowledge resource. 6 Summary and Conclusions de Bono (1970) argues that the best solutions from using lateral and vertical thinking Lateral thinking is divergent and generative, while vertical thinking is convergent and analytical. The former can thus be used to create a pool of interesting candidates for the latter to consider. Rex the web to generate a rich pool of alternate perspectives familiar ideas, and from this pool to perform vertical reasoning with WordNet to precise similarity judgments. uses the most informative perspective to concisely comparison, or – when used in genmode – to creative comparison. For instance, to highlight the potential toxicity of Rex comparisons with as all have been categorized as toxic substances on the web. A app based on to support this kind of lateral thinking, is accessible online at this URL: http://boundinanutshell.com/therex2 from the Rex are provided in Figures 3 and 4 overleaf. Be- Rex the acquisition of fine-grained perspectives, ranging from the offbeat to the obvious, it acquires an order-ofmagnitude more categories from the web than be found in WordNet itself. selecinto this wealth of perspectives (and more selective still), though many of needs can be anticipated by looking to how are implicitly grouped into catego- 1983) in constructions such as and Using the Google n-grams as a source of tacit grouping constructions, we have created a comprehensive lookup table that proscores for the most common (if often implicit) comparisons. Comparability is not the same as similarity, and a non-zero similarity score does not mean that two concepts would ever be considered comparable by a human. This poses a problem for the generation of sensible comparisons. lookup table captures the implicpragmatics of comparability, making usable in generative tasks where a metric must both suggest and evaluate comparisons. Human simimechanisms are evaluative Our computational mechanisms should be no less so.</abstract>
<note confidence="0.918736833333333">7 Acknowledgements This research was partly supported by the WCU (World Class University) program under the National Research Foundation of Korea (Ministry of Education, Science and Technology of Korea, Project no. R31-30007) and partly funded by</note>
<title confidence="0.783137">Foundation Ireland via the for Generation Localization</title>
<note confidence="0.852438528571428">667 3. screenshot from the web application Thesaurus Rex, showing the fine-grained categories found by Rex for the lexical concept the web. 4. screenshot from the web application Thesaurus Rex, showing the shared overlapping categories by Thesaurus Rex for the lexical concepts 668 References (translator: James Hutton). 1982. New York: Norton. Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pasca and Aitor Soroa. 2009. Study on Similarity and Relatedness Using Distriand WordNet-based Approaches. Proceedings of NAACL &apos;09, The 2009 Annual Conference of the North American Chapter of the for Computational pp. 19—27. Abdulrahman Almuhareb and Massimo Poesio. 2004. Attribute-Based and Value-Based Clustering: An In of the Conference on Methods in NLP, pp. 158- 165. Lawrence W. Barsalou. 1983. Ad hoc categories. Memory and Cognition, 11:211–227. Brants and Alex Franz. 2006. 1T 5- Ver. Philadelphia: Linguistic Data Consortium. Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based Measures of Lexical Relatedness. Linguistics, 32(1):13-47. Mary K. Camac, and Sam Glucksberg. 1984. Metaphors do not use associations between they are used to create them. of 443-455. Bono, Edward. 1970. thinking: creativity by New York: Harper &amp; Row. Bono, Edward. 1971. thinking for a handbook for New York: McGraw Hill. Fellbaum (ed.). 1998. An Elec- Lexical MIT Press, Cambridge, MA. Paul Guilford. 1967. Nature of Human New York: McGraw Hill. Lushan Han, Tim Finin, Paul McNamee, Anupam Joshi and Yelena Yesha. 2012. Improving Word Similarity by Augmenting PMI with Estimates of Polysemy. Transactions on Data and Engineering Feb. 2012). Yanfen Hao and Tony Veale. 2010. An Ironic Fist in a Velvet Glove: Creative Mis-Representation in the of Ironic Similes. and pp. 635–650. Jay Y. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical In of the International Conference on Research in Computational pp. 19-33. Zornitsa Kozareva, Eileen Riloff and Eduard Hovy. 2008. Semantic Class Learning from the Web with Pattern Linkage Graphs. Proc. of the Annual Meeting of the ACL, 1048-1056. Claudia Leacock and Martin Chodorow. 1998. Combining local context and WordNet similarity for word sense identification. In Fellbaum, C. (ed.), An Electronic Lexical Database, 283. Yuhua Li, Zuhair A. Bandar and David McLean. 2003. An Approach for Measuring Semantic Simi-</note>
<title confidence="0.5933325">larity between Words Using Multiple Information Transactions on Knowledge and</title>
<abstract confidence="0.668372444444445">vol. 15, no. 4, pp. 871-882. Dekang Lin. 1998. An information-theoretic of similarity. In of the ICML, the International Conference on Machine Morgan Kaufmann, San Francisco CA, pp. 296– 304. Michael Lesk. 1986 Automatic sense disambiguation using machine readable dictionaries: how to tell a cone from an ice cream cone. In</abstract>
<note confidence="0.765593142857143">ACM SigDoc, 24–26. George A. Miller and Walter. G. Charles. 1991. Concorrelates of semantic Language Cognitive Processes Ortony. 1979. Beyond literal similarity. Psy- Review, 86, 161-180. Ted Pederson, Siddarth Patwardhan and Jason Michelizzi. 2004. WordNet::Similarity: measuring relatedness of concepts. In of HLT-NAACL’04 (Demonstration Papers) the 2004 annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 38-41. Philip Resnick. 1995. Using Information Content to Evaluate Semantic Similarity in a Taxonomy. In of IJCAI’95, the International Joint Conference on Artificial Intelligence. Nuno Seco, Tony Veale and Jer Hayes, 2004. An Intrinsic Information Content Metric for Semantic in WordNet. In of the European Conference on Artificial Intelligence. Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate! Computing Semantic Relatedness Wikipedia. In of AAAI-06, the 2006 Conference of the Association for the of AI, 1419–1424. Peter Turney. 2005. Measuring semantic similarity by relational analysis. of the International Joint Conference on Artificial Intelli- 1136-1141. 669 Tony Veale and Mark T. Keane. 1994. Belief Modeling, Intentionality and Perlocution in Metaphor In Proceedings of the Annual Meeting of the Cognitive Science Society, Atlanta, Georgia. Hillsdale, NJ: Lawrence Erlbaum. Tony Veale. 2003. The analogical thesaurus: An emerging application at the juncture of lexical and information retrieval. In IAAI’03, the International Conference on Applications of Artificial Mexico. Tony Veale. 2004. WordNet sits the SAT: A knowledge-based approach to lexical analogy. Proceedings of ECAI&apos;04, the European Conference Artificial 606-612. Tony Veale and Yanfen Hao. 2007. Comprehending and Generating Apt Metaphors: A Web-driven, Case-based Approach to Figurative Language. In proceedings of AAAI 2007, the 22nd AAAI Conference on Artificial Intelligence. Vancouver, Canada. Tony Veale, Guofu Li and Yanfen Hao. 2009. Growing Finely-Discriminating Taxonomies from Seeds Varying Quality and Size. In of EACL’09, Conference of the European Chapter of the for Computational Linguistics 835- 842. Tony Veale. 2011. Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity. In Proceedings of ACL’2011, Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Tony Veale. 2012. Exploding the Creativity Myth: The computational foundations of linguistic crea- Bloomsbury Academic. Veale. 2013. Humorous Similes. The Journal of Humor Research, 22. 22. Zhibiao Wu and Martha Palmer. 1994. Verb semanand lexical selection. In of annual meeting of the Association for Computational Linguistics, Las Cruces, New Mexi- 133-138. 670</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Aristotle</author>
</authors>
<title>Aristotle’s Poetics.</title>
<date>1982</date>
<location>New York: Norton.</location>
<marker>Aristotle, 1982</marker>
<rawString>Aristotle (translator: James Hutton). 1982. Aristotle’s Poetics. New York: Norton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Enrique Alfonseca</author>
<author>Keith Hall</author>
<author>Jana Kravalova</author>
<author>Marius Pasca</author>
<author>Aitor Soroa</author>
</authors>
<title>Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches.</title>
<date>2009</date>
<booktitle>In Proceedings of NAACL &apos;09, The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>pp.</pages>
<contexts>
<context position="12211" citStr="Agirre et al. (2009)" startWordPosition="2016" endWordPosition="2019">ght eke out additional information from WordNet’s textual glosses, as in Lesk (1986), or use category structures other than those offered by WordNet. Looking beyond WordNet, entries in the online encyclopedia Wikipedia are not only connected by a dense topology of lateral links, they are also organized by a rich hierarchy of overlapping categories. Strube and Ponzetto (2006) show how Wikipedia can support a measure of similarity (and relatedness) that better approximates human judgments than many WordNet-based measures. Nonetheless, WordNet can be a valuable component of a hybrid measure, and Agirre et al. (2009) use an SVM (support vector machine) to combine information from WordNet with information harvested from the web. Their best similarity measure achieves a remarkable 0.93 correlation with human judgments on the Miller &amp; Charles word-pair set. Similarity is not always applied to pairs of concepts; it is sometimes analogically applied to pairs of pairs of concepts, as in proportional analogies of the form A is to B as C is to D (e.g., hacks are to writers as mercenaries are to soldiers, or chisels are to sculptors as scalpels are to surgeons). In such analogies, one is really assessing the simil</context>
<context position="26198" citStr="Agirre et al. (2009)" startWordPosition="4460" endWordPosition="4463">at Ort Similarity metric r Similarity metric r Wu &amp; .74 Seco et al. .84 Palmer’94&amp;quot; ‘06&amp;quot; Resnick .77 Agirre et al. .93 ‘95&amp;quot; ‘09 Leacock/Chod’98&amp;quot; .82 Han et al.’09 .856 Lin ‘98&amp;quot; .80 Rex-wn .84 Jiang/Conrath ‘97&amp;quot; -.81 Rex-lat .89 Li et al. ‘03 .89 Rex-pop .93 Table 1. Product-moment correlations (Pearson’s r) with mean human ratings on all 30 word pairs of the Miller &amp; Charles similarity data-set. * As re-evaluated by Seco et al. (2006) for all 30 pairs Table 1 lists coefficients of correlation r) with mean human ratings for a range of WordNet-based metrics. Table 1 includes the hybrid metric of Agirre et al. (2009) report a correlation of .93 the Mutual-Information-based PMImax metric of Han et al. (2009). The latter achieves good results for 27 of the 30 M&amp;C pairs by enriching a PMI metric with an automatically-generated (Pearson’s WordNet+web+SVM – who – and thesaurus. Yet while informative, this thesaurus is Here size(H) is the total number of lexical concepts in category H in WordNet, excluding any instance-level concepts, as these illustrative individuals are not evenly distributed across WordNet categories. We also want any fine-grained perspective MH to influence our similarity metric, provided i</context>
<context position="28428" citStr="Agirre et al. (2009)" startWordPosition="4841" endWordPosition="4844">correlation to that of Li et al. (2003) – .89. Yet the formulation in (2) favors unusual or idiosyncratic perspectives that are unlikely to generalize across independent judges. The mean ratings of M&amp;C are the stuff of consensus, not individual creativity, and outside the realm of creative metaphor it often makes sense to safely align our judgments with those of others. By limiting its use of Thesaurus Rex to the perspectives that other judges are most likely to use, Rex-pop obtains a correlation of .93 with mean human ratings on all 30 M&amp;C pairs. This result is comparable to that reported by Agirre et al. (2009), who use SVM-based supervised learning to combine the judgments of two metrics, one based on WordNet and another on the analysis of web contexts of both input terms. However, Rex has the greater capacity for insight, since it augments the structured category system of WordNet with structured categories of its own. At each level of the WordNet hierarchy, Rex finds the fine-grained category that can best inform its judgments. Because Rex makes highly selective use of the diverse products of lateral thinking, this selectivity also produces concise explanations for its judgments. 5.1 Generative U</context>
</contexts>
<marker>Agirre, Alfonseca, Hall, Kravalova, Pasca, Soroa, 2009</marker>
<rawString>Eneko Agirre, Enrique Alfonseca, Keith Hall, Jana Kravalova, Marius Pasca and Aitor Soroa. 2009. Study on Similarity and Relatedness Using Distributional and WordNet-based Approaches. In Proceedings of NAACL &apos;09, The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 19—27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abdulrahman Almuhareb</author>
<author>Massimo Poesio</author>
</authors>
<title>Attribute-Based and Value-Based Clustering: An Evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in NLP, Barcelona.</booktitle>
<pages>158--165</pages>
<contexts>
<context position="30599" citStr="Almuhareb &amp; Poesio (2004)" startWordPosition="5209" endWordPosition="5212">. We harvest all such Google 3-grams, to build a symmetric comparability graph in which any two comparable terms are adjacent nodes. For any node, we can generate a diverse set of comparable ideas just by reading off its adjacent nodes. Thesaurus Rex can be used to find an embracing category for many such pairs of nodes, while Rex estimates the similarity of any two adjacent nodes. A comparability graph of 28,000 nodes is produced from the Google 3-grams, with a sparse adjacency matrix of just 1,264,827 (0.16%) non-zero entries. Is this dense enough for a task requiring generative similarity? Almuhareb &amp; Poesio (2004) describe one such task: they sample 214 words from across 13 WordNet categories, and ask if these 214 words can be partitioned into 13 clusters that mirror the WordNet categories from which they were drawn. They then collect tens of thousands of web contexts for these 214 words, to extract a feature representation of each. We instead use Rex to generate, as features, a diverse set of comparable terms for each word. (We also assume that each word is a feature of itself). The Rex comparability graph suggests a pool of 8,300 features for all 214 words. The clustering toolkit CLUTO is used to par</context>
</contexts>
<marker>Almuhareb, Poesio, 2004</marker>
<rawString>Abdulrahman Almuhareb and Massimo Poesio. 2004. Attribute-Based and Value-Based Clustering: An Evaluation. In Proceedings of the Conference on Empirical Methods in NLP, Barcelona. pp. 158-165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence W Barsalou</author>
</authors>
<title>Ad hoc categories. Memory and Cognition,</title>
<date>1983</date>
<pages>11--211</pages>
<contexts>
<context position="34974" citStr="Barsalou, 1983" startWordPosition="5927" endWordPosition="5928">teral thinking, is accessible online at this URL: http://boundinanutshell.com/therex2 Screenshots from the Thesaurus Rex application are provided in Figures 3 and 4 overleaf. Because Thesaurus Rex targets the acquisition of fine-grained perspectives, ranging from the offbeat to the obvious, it acquires an order-ofmagnitude more categories from the web than can be found in WordNet itself. Rex dips selectively into this wealth of perspectives (and Rexpop is more selective still), though many of Rex’s needs can be anticipated by looking to how ideas are implicitly grouped into ad-hoc categories (Barsalou, 1983) in constructions such as “X+s and Y+s”. Using the Google n-grams as a source of tacit grouping constructions, we have created a comprehensive lookup table that provides Rex similarity scores for the most common (if often implicit) comparisons. Comparability is not the same as similarity, and a non-zero similarity score does not mean that two concepts would ever be considered comparable by a human. This poses a problem for the generation of sensible comparisons. However, Rex’s lookup table captures the implicit pragmatics of comparability, making Rex usable in generative tasks where a metric m</context>
</contexts>
<marker>Barsalou, 1983</marker>
<rawString>Lawrence W. Barsalou. 1983. Ad hoc categories. Memory and Cognition, 11:211–227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<date>2006</date>
<booktitle>Web 1T 5-gram Ver. 1. Philadelphia: Linguistic Data Consortium.</booktitle>
<contexts>
<context position="17850" citStr="Brants &amp; Franz, 2006" startWordPosition="2962" endWordPosition="2965">oncepts, of the same depth, can be combined with their LCS to yield a new fine-grained parent category, so e.g. “supreme” + deity = Supreme-deity (for Odin, Zeus, Jupiter, etc.) and “1st” + letter = 1st-letter (for Alpha, Aleph, etc.) Selected aspects of the textual similarity of two WordNet glosses – the key to similarity in Lesk (1986) – can thus be reified into an explicitly categorical WordNet form. 3 Divergent (Re)Categorization To tap into a richer source of concept properties than WordNet’s glosses, we can use web ngrams. Consider these descriptions of a cowboy from the Google n-grams (Brants &amp; Franz, 2006). The numbers to the right are Google frequency counts. a lonesome cowboy 432 a mounted cowboy 122 a grizzled cowboy 74 a swaggering cowboy 68 To find the stable properties that can underpin a meaningful fine-grained category for cowboy, we must seek out the properties that are so often presupposed to be salient of all cowboys that one can use them to anchor a simile, such as &amp;quot;swaggering like a cowboy” or “as grizzled as a cowboy”. So for each property P suggested by Google n-grams for a lexical concept C, we generate a like-simile for verbal behaviors such as swaggering and an as-as-simile fo</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1T 5-gram Ver. 1. Philadelphia: Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating WordNet-based Measures of Lexical Semantic Relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<pages>32--1</pages>
<contexts>
<context position="1885" citStr="Budanitsky &amp; Hirst, 2006" startWordPosition="292" endWordPosition="295">. 1 Seeing is Believing (and Creating) Similarity is a cognitive phenomenon that is both complex and subjective, yet for practical reasons it is often modeled as if it were simple and objective. This makes sense for the many situations where we want to align our similarity judgments with those of others, and thus focus on the same conventional properties that others are also likely to focus upon. This reliance on the consensus viewpoint explains why WordNet (Fellbaum, 1998) has proven so useful as a basis for computational measures of lexico-semantic similarity (e.g. see Pederson et al. 2004, Budanitsky &amp; Hirst, 2006; Seco et al. 2006). These measures reduce the similarity of two lexical concepts to a single number, by viewing similarity as an objective estimate of the overlap in their salient qualities. This convenient perspective is poorly suited to creative or insightful comparisons, but it is sufficient for the many mundane comparisons we often perform in daily life, such as when we organize books or look for items in a supermarket. So if we do not know in which aisle to locate a given item (such as oatmeal), we may tacitly know how to locate a similar product (such as cornflakes) and orient ourselves</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based Measures of Lexical Semantic Relatedness. Computational Linguistics, 32(1):13-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary K Camac</author>
<author>Sam Glucksberg</author>
</authors>
<title>Metaphors do not use associations between concepts, they are used to create them.</title>
<date>1984</date>
<journal>Journal of Psycholinguistic Research,</journal>
<volume>13</volume>
<pages>443--455</pages>
<contexts>
<context position="14553" citStr="Camac &amp; Glucksberg (1984)" startWordPosition="2421" endWordPosition="2425">WordNet-based similarity. In contrast, Turney (2005) reports up to 55% success on the same analogies, partly because his approach aims 662 to match implicit relations rather than explicit concepts, and in part because it uses a divergent process to gather from the web as rich a perspective as it can on these latent relationships. 2.1 Clever Comparisons Create Similarity Each of these approaches to similarity is a user of information, rather than a creator, and each fails to capture how a creative comparison (such as a metaphor) can spur a listener to view a topic from an atypical perspective. Camac &amp; Glucksberg (1984) provide experimental evidence for the claim that “metaphors do not use preexisting associations to achieve their effects [É] people use metaphors to create new relations between concepts.” They also offer a salutary reminder of an often overlooked fact: every comparison exploits information, but each is also a source of new information in its own right. Thus, “this cola is acid” reveals a different perspective on cola (e.g. as a corrosive substance or an irritating food) than “this acid is cola” highlights for acid (such as e.g., a familiar substance) Veale &amp; Keane (1994) model the role of si</context>
</contexts>
<marker>Camac, Glucksberg, 1984</marker>
<rawString>Mary K. Camac, and Sam Glucksberg. 1984. Metaphors do not use associations between concepts, they are used to create them. Journal of Psycholinguistic Research, 13, 443-455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward de Bono</author>
</authors>
<title>Lateral thinking: creativity step by step.</title>
<date>1970</date>
<location>New York: Harper &amp; Row.</location>
<marker>de Bono, 1970</marker>
<rawString>de Bono, Edward. 1970. Lateral thinking: creativity step by step. New York: Harper &amp; Row.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward de Bono</author>
</authors>
<title>Lateral thinking for management: a handbook for creativity.</title>
<date>1971</date>
<publisher>McGraw Hill.</publisher>
<location>New York:</location>
<marker>de Bono, 1971</marker>
<rawString>de Bono, Edward. 1971. Lateral thinking for management: a handbook for creativity. New York: McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1739" citStr="Fellbaum, 1998" startWordPosition="270" endWordPosition="271">tem for idea exploration called Thesaurus Rex. We show also how Thesaurus Rex supports a novel, generative similarity measure for WordNet. 1 Seeing is Believing (and Creating) Similarity is a cognitive phenomenon that is both complex and subjective, yet for practical reasons it is often modeled as if it were simple and objective. This makes sense for the many situations where we want to align our similarity judgments with those of others, and thus focus on the same conventional properties that others are also likely to focus upon. This reliance on the consensus viewpoint explains why WordNet (Fellbaum, 1998) has proven so useful as a basis for computational measures of lexico-semantic similarity (e.g. see Pederson et al. 2004, Budanitsky &amp; Hirst, 2006; Seco et al. 2006). These measures reduce the similarity of two lexical concepts to a single number, by viewing similarity as an objective estimate of the overlap in their salient qualities. This convenient perspective is poorly suited to creative or insightful comparisons, but it is sufficient for the many mundane comparisons we often perform in daily life, such as when we organize books or look for items in a supermarket. So if we do not know in w</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum (ed.). 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Paul Guilford</author>
</authors>
<title>The Nature of Human Intelligence.</title>
<date>1967</date>
<publisher>McGraw Hill.</publisher>
<location>New York:</location>
<contexts>
<context position="4881" citStr="Guilford (1967)" startWordPosition="816" endWordPosition="817">jective function of a conventional worldview employs a convergent thought process. Using WordNet, for instance, a similarity measure can vertically converge on a common superordinate category of both inputs, and generate a single numeric result based on their distance to, and the information content of, this common generalization. So to find the most conventional ways of seeing a lexical concept, one simply ascends a narrowing concept hierarchy, using a process de Bono (1970) calls vertical thinking. To find novel, non-obvious and useful ways of looking at a lexical concept, one must use what Guilford (1967) calls divergent thinking and what de Bono calls lateral thinking. These processes cut across familiar category boundaries, to simultaneously place a concept in many different categories so that we can see it in many different ways. de Bono argues that vertical thinking is selective while lateral thinking is generative. Whereas vertical thinking concerns itself with the “right” way or a single “best” way of looking at things, lateral thinking focuses on producing alternatives to the status quo. To be as useful for creative tasks as they are for conventional tasks, we need to re-imagine our com</context>
</contexts>
<marker>Guilford, 1967</marker>
<rawString>J. Paul Guilford. 1967. The Nature of Human Intelligence. New York: McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lushan Han</author>
<author>Tim Finin</author>
<author>Paul McNamee</author>
<author>Anupam Joshi</author>
<author>Yelena Yesha</author>
</authors>
<title>Improving Word Similarity by Augmenting PMI with Estimates of Word Polysemy.</title>
<date>2012</date>
<journal>IEEE Transactions on Data and Knowledge Engineering</journal>
<marker>Han, Finin, McNamee, Joshi, Yesha, 2012</marker>
<rawString>Lushan Han, Tim Finin, Paul McNamee, Anupam Joshi and Yelena Yesha. 2012. Improving Word Similarity by Augmenting PMI with Estimates of Word Polysemy. IEEE Transactions on Data and Knowledge Engineering (13 Feb. 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanfen Hao</author>
<author>Tony Veale</author>
</authors>
<title>An Ironic Fist in a Velvet Glove: Creative Mis-Representation in the Construction of Ironic Similes.</title>
<date>2010</date>
<journal>Minds and Machines</journal>
<volume>20</volume>
<issue>4</issue>
<pages>635--650</pages>
<contexts>
<context position="19064" citStr="Hao &amp; Veale (2010)" startWordPosition="3188" endWordPosition="3191">e for adjectives such as lonesome. Each is then dispatched to Google as a phrasal query. We value quality over size, as these similes will later be used to find diverse viewpoints on the web via bootstrapping. We thus manually filter each web simile, to weed out any that are ill-formed, and those intended to be seen as ironic by their authors. This gives us a body of 12,000+ valid web similes. 663 Veale (2011, 2012, 2013) notes that web uses of the pattern “as P as C” are rife with irony. In contrast, web instances of “P S such as C” – where S denotes a superordinate of C – are rarely ironic. Hao &amp; Veale (2010) exploit this fact to filter ironic comparisons from web similes, by re-expressing each “as P as C” simile as “P * such as C” (using a wildcard * to match any values for S) and looking for attested uses of this new form on the web. Since each hit will also yield a value for S via the wildcard *, and a finegrained category P-S for C, we use this approach here to harvest fine-grained categories from the web from most of our similes. Once C is seen to be an exemplary member of the category P-S, such as cola in fizzy-drink, a targeted web search is used to find other members of P-S, via the anchor</context>
</contexts>
<marker>Hao, Veale, 2010</marker>
<rawString>Yanfen Hao and Tony Veale. 2010. An Ironic Fist in a Velvet Glove: Creative Mis-Representation in the Construction of Ironic Similes. Minds and Machines 20(4), pp. 635–650.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Y Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of the 10th International Conference on Research in Computational Linguistics,</booktitle>
<pages>pp.</pages>
<contexts>
<context position="10015" citStr="Jiang and Conrath (1997)" startWordPosition="1654" endWordPosition="1657">ore predictable, and less informative, than rarer categories whose occurrences are less predictable and thus more informative. The negative log likelihood of the most informative LCS of two lexical concepts offers a reliable estimate of the amount of information shared by those concepts, and thus a good estimate of their similarity. Lin (1998) combines the intuitions behind Resnick’s metric and that of Wu and Palmer to estimate the similarity of two lexical concepts as an information ratio: twice the information content of their LCS divided by the sum of their individual information contents. Jiang and Conrath (1997) consider the converse notion of dissimilarity, noting that two lexical concepts are dissimilar to the extent that each contains information that is not shared by the other. So if the information content of their most informative LCS is a good measure of what they do share, then the sum of their individual information contents, minus twice the content of their most informative LCS, is a reliable estimate of their dissimilarity. Seco et al. (2006) presents a minor innovation, showing how Resnick’s notion of information content can be calculated without the use of an external corpus. Rather, whe</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay Y. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of the 10th International Conference on Research in Computational Linguistics, pp. 19-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eileen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs.</title>
<date>2008</date>
<booktitle>In Proc. of the 46th Annual Meeting of the ACL,</booktitle>
<pages>1048--1056</pages>
<contexts>
<context position="20107" citStr="Kozareva et al. (2008)" startWordPosition="3389" endWordPosition="3392"> our similes. Once C is seen to be an exemplary member of the category P-S, such as cola in fizzy-drink, a targeted web search is used to find other members of P-S, via the anchored query “P S such as * and C”. For example, “fizzy drinks such as * and cola” will retrieve web texts in which * is matched to soda or lemonade. Each new member can then be used to instantiate a further query, as in “fizzy drinks such as * and soda”, to retrieve other members of P-S, such as champagne and root beer. This bootstrapping process runs in successive cycles, using doubly-anchored patterns that – following Kozareva et al. (2008) and Veale et al. (2009) – explicitly mention both the category to be populated (P-S) and a recently acquired member of this category (C). As cautioned by Kozareva et al., it is reckless to bootstrap from members to categories to members again if each enfilade of queries is likely to return noisy results. A reliable filter must be applied at each stage, to ensure that any member C that is placed in a category P-S is a sensible member of the category S. Only by filtering in this way can we stop the rapid accumulation of noise. For instance, a WordNet-based filter discards any categorization “P </context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Eileen Riloff and Eduard Hovy. 2008. Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs. In Proc. of the 46th Annual Meeting of the ACL, pp 1048-1056.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification.</title>
<date>1998</date>
<pages>265--283</pages>
<editor>In Fellbaum, C. (ed.),</editor>
<contexts>
<context position="7863" citStr="Leacock and Chodorow (1998)" startWordPosition="1298" endWordPosition="1301"> or least common subsumer, of two concepts (Pederson et al., 2004). Since sub-categories add new properties to those they inherit from their parents – Aristotle called these properties the differentia that stop a category system from trivially collapsing into itself – the depth of a lexical concept in a taxonomy is an intuitive proxy for its information content. Wu &amp; Palmer (1994) use the depth of a lexical concept in the WordNet hierarchy as such a proxy, and thereby estimate the similarity of two lexical concepts as twice the depth of their LCS divided by the sum of their individual depths. Leacock and Chodorow (1998) instead use the length of the shortest path between two concepts as a proxy for the conceptual distance between them. To connect any two ideas in a hierarchical system, one must vertically ascend the hierarchy from one concept, change direction at a potential LCS, and then descend the hierarchy to reach the second concept. (Aristotle was also first to suggest this approach in his Poetics). Leacock and Chodorow normalize the length of this path by dividing its size (in nodes) by twice the depth of the deepest concept in the hierarchy; the latter is an upper bound on the distance between any tw</context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow. 1998. Combining local context and WordNet similarity for word sense identification. In Fellbaum, C. (ed.), WordNet: An Electronic Lexical Database, 265– 283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuhua Li</author>
<author>Zuhair A Bandar</author>
<author>David McLean</author>
</authors>
<title>An Approach for Measuring Semantic Similarity between Words Using Multiple Information Sources.</title>
<date>2003</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>15</volume>
<pages>871--882</pages>
<contexts>
<context position="27847" citStr="Li et al. (2003)" startWordPosition="4743" endWordPosition="4746"> to H is estimated via the geometric mean of ICabs(M-H) and IC(H) is given by (3): (3) IC(M-H) = For a shared dimension H in the feature vectors 665 not organized as an explanatory system of hierarchical categories as it is in Thesaurus Rex. Rex-wn does no better than Seco et al. (2006) on the M&amp;C dataset, suggesting that Rex’s vectors of IC-weighted hypernyms are no more discerning than a single informative LCS. However, such vectors also permit Rex to incorporate additional, fine-grained perspectives from Thesaurus Rex, allowing Rex-lat in turn to achieve a comparable correlation to that of Li et al. (2003) – .89. Yet the formulation in (2) favors unusual or idiosyncratic perspectives that are unlikely to generalize across independent judges. The mean ratings of M&amp;C are the stuff of consensus, not individual creativity, and outside the realm of creative metaphor it often makes sense to safely align our judgments with those of others. By limiting its use of Thesaurus Rex to the perspectives that other judges are most likely to use, Rex-pop obtains a correlation of .93 with mean human ratings on all 30 M&amp;C pairs. This result is comparable to that reported by Agirre et al. (2009), who use SVM-based</context>
</contexts>
<marker>Li, Bandar, McLean, 2003</marker>
<rawString>Yuhua Li, Zuhair A. Bandar and David McLean. 2003. An Approach for Measuring Semantic Similarity between Words Using Multiple Information Sources. IEEE Transactions on Knowledge and Data Engineering, vol. 15, no. 4, pp. 871-882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>An information-theoretic definition of similarity.</title>
<date>1998</date>
<booktitle>In Proceedings of the 15th ICML, the International Conference on Machine Learning,</booktitle>
<pages>296--304</pages>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco CA,</location>
<contexts>
<context position="9736" citStr="Lin (1998)" startWordPosition="1612" endWordPosition="1613">r explicitly (via a direct mention) or by presupposition (via a mention of any of its sub-categories or instances). Since the likelihood of a general category occurring in a corpus is higher than that of any of its sub-categories or instances, such categories are more predictable, and less informative, than rarer categories whose occurrences are less predictable and thus more informative. The negative log likelihood of the most informative LCS of two lexical concepts offers a reliable estimate of the amount of information shared by those concepts, and thus a good estimate of their similarity. Lin (1998) combines the intuitions behind Resnick’s metric and that of Wu and Palmer to estimate the similarity of two lexical concepts as an information ratio: twice the information content of their LCS divided by the sum of their individual information contents. Jiang and Conrath (1997) consider the converse notion of dissimilarity, noting that two lexical concepts are dissimilar to the extent that each contains information that is not shared by the other. So if the information content of their most informative LCS is a good measure of what they do share, then the sum of their individual information c</context>
<context position="23985" citStr="Lin (1998)" startWordPosition="4092" endWordPosition="4093">dded to WordNet is given by (2): M-H) = -log ( Σm-h ∈ WN size(m-h)) ICabs( √ M-H) . IC(H) of concepts and C2, if at least one fine-grained perspective M-H has been added to WordNet between H and and between H and C2, then the value of dimension H for and for C2 is given by (4): (4) weight(H) = max(IC(H), maxM IC(M-H)) When no shared perspective M-H can be added under H, then weight(H) = IC(H). perspective M-H will thus influence a similarity judgment between and C2 only if M-H can be coherently added to WordNet as a hypernym of and C2, and if M-H enriches our view of H. Unlike Resnick (1995), Lin (1998) and Seco et al. (2006), this vector-space approach does not hinge on the information content of a single LCS, so any shared hypernym H or perspective M-H can C1 C1 C1 A fine-grained C1 C1 shape a similarity judgment according to its informativeness. 5 Empirical Evaluation Many fascinating perspectives on familiar ideas are bootstrapped from the web using similes as a starting point. These perspectives drive an exploratory web-aid to lateral thinking we call Thesaurus Rex, while the cosine-distance metric constructed from WordNet and these many finegrained categories is called, simply, Rex. Wh</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. An information-theoretic definition of similarity. In Proceedings of the 15th ICML, the International Conference on Machine Learning, Morgan Kaufmann, San Francisco CA, pp. 296– 304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of ACM SigDoc, ACM,</booktitle>
<pages>24--26</pages>
<contexts>
<context position="11675" citStr="Lesk (1986)" startWordPosition="1935" endWordPosition="1936"> the log of the total number of concepts in the entire hierarchy. Not only is this intrinsic view of information content convenient to use, without recourse to an external corpus, Seco et al. show that it offers a better estimate of information content than its extrinsic, corpus-based alternatives, as measured relative to average human similarity ratings for the 30 word-pairs in the Miller &amp; Charles (1991) test set. A similarity measure can draw on other sources of information besides WordNet’s category structures. One might eke out additional information from WordNet’s textual glosses, as in Lesk (1986), or use category structures other than those offered by WordNet. Looking beyond WordNet, entries in the online encyclopedia Wikipedia are not only connected by a dense topology of lateral links, they are also organized by a rich hierarchy of overlapping categories. Strube and Ponzetto (2006) show how Wikipedia can support a measure of similarity (and relatedness) that better approximates human judgments than many WordNet-based measures. Nonetheless, WordNet can be a valuable component of a hybrid measure, and Agirre et al. (2009) use an SVM (support vector machine) to combine information from</context>
<context position="17568" citStr="Lesk (1986)" startWordPosition="2918" endWordPosition="2919">er, we can automatically make WordNet subtler and more discerning, by adding new fine-grained categories to unite lexical concepts whose similarity is not reflected by any existing categories. Veale (2003) shows how a property that is found in the glosses of two lexical concepts, of the same depth, can be combined with their LCS to yield a new fine-grained parent category, so e.g. “supreme” + deity = Supreme-deity (for Odin, Zeus, Jupiter, etc.) and “1st” + letter = 1st-letter (for Alpha, Aleph, etc.) Selected aspects of the textual similarity of two WordNet glosses – the key to similarity in Lesk (1986) – can thus be reified into an explicitly categorical WordNet form. 3 Divergent (Re)Categorization To tap into a richer source of concept properties than WordNet’s glosses, we can use web ngrams. Consider these descriptions of a cowboy from the Google n-grams (Brants &amp; Franz, 2006). The numbers to the right are Google frequency counts. a lonesome cowboy 432 a mounted cowboy 122 a grizzled cowboy 74 a swaggering cowboy 68 To find the stable properties that can underpin a meaningful fine-grained category for cowboy, we must seek out the properties that are so often presupposed to be salient of a</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986 Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone. In Proceedings of ACM SigDoc, ACM, 24–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes</booktitle>
<pages>6--1</pages>
<contexts>
<context position="6610" citStr="Charles (1991)" startWordPosition="1093" endWordPosition="1094"> codified by WordNet. Section 2 provides a brief overview of past work in the area of similarity measurement, before section 3 describes a simple bootstrapping loop for acquiring richly diverse perspectives from the web for a wide variety of familiar ideas. These perspectives are used to enhance a WordNet-based measure of lexico-semantic similarity in section 4, by broadening the range of informative viewpoints the measure can select from. Similarity is thus modeled as a process that is both generative and selective. This lateral-andvertical approach is evaluated in section 5, on the Miller &amp; Charles (1991) data-set. A web app for the lateral exploration of diverse viewpoints, named Thesaurus Rex, is also presented, before closing remarks are offered in section 6. 2 Related Work and Ideas WordNet’s taxonomic organization of nounsenses and verb-senses – in which very general categories are successively divided into increasingly informative sub-categories or instancelevel ideas – allows us to gauge the overlap in information content, and thus of meaning, of two lexical concepts. We need only identify the deepest point in the taxonomy at which this content starts to diverge. This point of divergenc</context>
<context position="11473" citStr="Charles (1991)" startWordPosition="1904" endWordPosition="1905">cept, the more descendants it will possess. Seco et al. thus estimate the information content of a lexical concept as the log of the sum of all its unique descendants (both direct and indirect), divided by the log of the total number of concepts in the entire hierarchy. Not only is this intrinsic view of information content convenient to use, without recourse to an external corpus, Seco et al. show that it offers a better estimate of information content than its extrinsic, corpus-based alternatives, as measured relative to average human similarity ratings for the 30 word-pairs in the Miller &amp; Charles (1991) test set. A similarity measure can draw on other sources of information besides WordNet’s category structures. One might eke out additional information from WordNet’s textual glosses, as in Lesk (1986), or use category structures other than those offered by WordNet. Looking beyond WordNet, entries in the online encyclopedia Wikipedia are not only connected by a dense topology of lateral links, they are also organized by a rich hierarchy of overlapping categories. Strube and Ponzetto (2006) show how Wikipedia can support a measure of similarity (and relatedness) that better approximates human </context>
</contexts>
<marker>Charles, 1991</marker>
<rawString>George A. Miller and Walter. G. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes 6(1):1-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Ortony</author>
</authors>
<title>Beyond literal similarity.</title>
<date>1979</date>
<journal>Psychological Review,</journal>
<volume>86</volume>
<pages>161--180</pages>
<contexts>
<context position="3270" citStr="Ortony, 1979" startWordPosition="538" endWordPosition="539">ing at an idea. By placing pop tarts in the breakfast aisle, food manufacturers encourage us to view them as a breakfast food that is not dissimilar to oatmeal or cornflakes. When ex-PM Tony Blair published his memoirs, a mischievous activist encouraged others to move his book from Biography to Fiction in bookshops, in the hope that buyers would see it in a new light. Whenever we use a novel metaphor to convey a non-obvious viewpoint on a topic, such as “cigarettes are time bombs”, the comparison may spur us to insight, to see aspects of the topic that make it more similar to the vehicle (see Ortony, 1979; Veale &amp; Hao, 2007). In formal terms, assume agent A has an insight about concept X, and uses the metaphor X is a Y to also provoke this insight in agent B. To arrive at this insight for itself, B must intuit what X and Y have in common. But this commonality is surely more than a standard categorization of X, or else it would not count as an insight about X. To understand the metaphor, B must place X 660 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 660–670, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics in a</context>
</contexts>
<marker>Ortony, 1979</marker>
<rawString>Andrew Ortony. 1979. Beyond literal similarity. Psychological Review, 86, pp. 161-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pederson</author>
<author>Siddarth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT-NAACL’04 (Demonstration Papers) the 2004 annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>38--41</pages>
<contexts>
<context position="1859" citStr="Pederson et al. 2004" startWordPosition="288" endWordPosition="291">ty measure for WordNet. 1 Seeing is Believing (and Creating) Similarity is a cognitive phenomenon that is both complex and subjective, yet for practical reasons it is often modeled as if it were simple and objective. This makes sense for the many situations where we want to align our similarity judgments with those of others, and thus focus on the same conventional properties that others are also likely to focus upon. This reliance on the consensus viewpoint explains why WordNet (Fellbaum, 1998) has proven so useful as a basis for computational measures of lexico-semantic similarity (e.g. see Pederson et al. 2004, Budanitsky &amp; Hirst, 2006; Seco et al. 2006). These measures reduce the similarity of two lexical concepts to a single number, by viewing similarity as an objective estimate of the overlap in their salient qualities. This convenient perspective is poorly suited to creative or insightful comparisons, but it is sufficient for the many mundane comparisons we often perform in daily life, such as when we organize books or look for items in a supermarket. So if we do not know in which aisle to locate a given item (such as oatmeal), we may tacitly know how to locate a similar product (such as cornfl</context>
<context position="7302" citStr="Pederson et al., 2004" startWordPosition="1203" endWordPosition="1206">, named Thesaurus Rex, is also presented, before closing remarks are offered in section 6. 2 Related Work and Ideas WordNet’s taxonomic organization of nounsenses and verb-senses – in which very general categories are successively divided into increasingly informative sub-categories or instancelevel ideas – allows us to gauge the overlap in information content, and thus of meaning, of two lexical concepts. We need only identify the deepest point in the taxonomy at which this content starts to diverge. This point of divergence is often called the LCS, or least common subsumer, of two concepts (Pederson et al., 2004). Since sub-categories add new properties to those they inherit from their parents – Aristotle called these properties the differentia that stop a category system from trivially collapsing into itself – the depth of a lexical concept in a taxonomy is an intuitive proxy for its information content. Wu &amp; Palmer (1994) use the depth of a lexical concept in the WordNet hierarchy as such a proxy, and thereby estimate the similarity of two lexical concepts as twice the depth of their LCS divided by the sum of their individual depths. Leacock and Chodorow (1998) instead use the length of the shortest</context>
</contexts>
<marker>Pederson, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pederson, Siddarth Patwardhan and Jason Michelizzi. 2004. WordNet::Similarity: measuring the relatedness of concepts. In Proceedings of HLT-NAACL’04 (Demonstration Papers) the 2004 annual Conference of the North American Chapter of the Association for Computational Linguistics, pp. 38-41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnick</author>
</authors>
<title>Using Information Content to Evaluate Semantic Similarity in a Taxonomy.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI’95, the 14th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="8975" citStr="Resnick (1995)" startWordPosition="1490" endWordPosition="1491">h of the deepest concept in the hierarchy; the latter is an upper bound on the distance between any two concepts in the hierarchy. Negating the log of this normalized length yields a corresponding similarity score. While the role of an LCS is merely implied in Leacock and Chodorow’s use of a shortest path, the LCS is pivotal nonetheless, and like that of Wu &amp; Palmer, the approach uses an essentially vertical reasoning process to identify a single “best” generalization. Depth is a convenient proxy for information content, but more nuanced proxies can yield 661 more rounded similarity measures. Resnick (1995) draws on information theory to define the information content of a lexical concept as the negative log likelihood of its occurrence in a corpus, either explicitly (via a direct mention) or by presupposition (via a mention of any of its sub-categories or instances). Since the likelihood of a general category occurring in a corpus is higher than that of any of its sub-categories or instances, such categories are more predictable, and less informative, than rarer categories whose occurrences are less predictable and thus more informative. The negative log likelihood of the most informative LCS o</context>
<context position="23973" citStr="Resnick (1995)" startWordPosition="4090" endWordPosition="4091"> that is newly added to WordNet is given by (2): M-H) = -log ( Σm-h ∈ WN size(m-h)) ICabs( √ M-H) . IC(H) of concepts and C2, if at least one fine-grained perspective M-H has been added to WordNet between H and and between H and C2, then the value of dimension H for and for C2 is given by (4): (4) weight(H) = max(IC(H), maxM IC(M-H)) When no shared perspective M-H can be added under H, then weight(H) = IC(H). perspective M-H will thus influence a similarity judgment between and C2 only if M-H can be coherently added to WordNet as a hypernym of and C2, and if M-H enriches our view of H. Unlike Resnick (1995), Lin (1998) and Seco et al. (2006), this vector-space approach does not hinge on the information content of a single LCS, so any shared hypernym H or perspective M-H can C1 C1 C1 A fine-grained C1 C1 shape a similarity judgment according to its informativeness. 5 Empirical Evaluation Many fascinating perspectives on familiar ideas are bootstrapped from the web using similes as a starting point. These perspectives drive an exploratory web-aid to lateral thinking we call Thesaurus Rex, while the cosine-distance metric constructed from WordNet and these many finegrained categories is called, sim</context>
</contexts>
<marker>Resnick, 1995</marker>
<rawString>Philip Resnick. 1995. Using Information Content to Evaluate Semantic Similarity in a Taxonomy. In Proceedings of IJCAI’95, the 14th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuno Seco</author>
<author>Tony Veale</author>
<author>Jer Hayes</author>
</authors>
<title>An Intrinsic Information Content Metric for Semantic Similarity in WordNet.</title>
<date>2004</date>
<booktitle>In Proceedings of ECAI’04, the European Conference on Artificial Intelligence.</booktitle>
<marker>Seco, Veale, Hayes, 2004</marker>
<rawString>Nuno Seco, Tony Veale and Jer Hayes, 2004. An Intrinsic Information Content Metric for Semantic Similarity in WordNet. In Proceedings of ECAI’04, the European Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Strube</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>WikiRelate! Computing Semantic Relatedness Using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI-06, the 2006 Conference of the Association for the Advancement of AI,</booktitle>
<pages>1419--1424</pages>
<contexts>
<context position="11968" citStr="Strube and Ponzetto (2006)" startWordPosition="1978" endWordPosition="1981">s-based alternatives, as measured relative to average human similarity ratings for the 30 word-pairs in the Miller &amp; Charles (1991) test set. A similarity measure can draw on other sources of information besides WordNet’s category structures. One might eke out additional information from WordNet’s textual glosses, as in Lesk (1986), or use category structures other than those offered by WordNet. Looking beyond WordNet, entries in the online encyclopedia Wikipedia are not only connected by a dense topology of lateral links, they are also organized by a rich hierarchy of overlapping categories. Strube and Ponzetto (2006) show how Wikipedia can support a measure of similarity (and relatedness) that better approximates human judgments than many WordNet-based measures. Nonetheless, WordNet can be a valuable component of a hybrid measure, and Agirre et al. (2009) use an SVM (support vector machine) to combine information from WordNet with information harvested from the web. Their best similarity measure achieves a remarkable 0.93 correlation with human judgments on the Miller &amp; Charles word-pair set. Similarity is not always applied to pairs of concepts; it is sometimes analogically applied to pairs of pairs of c</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Michael Strube and Simone Paolo Ponzetto. 2006. WikiRelate! Computing Semantic Relatedness Using Wikipedia. In Proceedings of AAAI-06, the 2006 Conference of the Association for the Advancement of AI, pp. 1419–1424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Measuring semantic similarity by latent relational analysis.</title>
<date>2005</date>
<booktitle>Proceedings of the 19th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1136--1141</pages>
<contexts>
<context position="13240" citStr="Turney (2005)" startWordPosition="2198" endWordPosition="2200"> as C is to D (e.g., hacks are to writers as mercenaries are to soldiers, or chisels are to sculptors as scalpels are to surgeons). In such analogies, one is really assessing the similarity of the unstated relationship between each pair of concepts: thus, mercenaries are soldiers whose allegiance is paid for, much as hacks are writers with income-driven loyalties; sculptors use chisels to carve stone, while surgeons use scalpels to cut or carve flesh. Veale (2004) used WordNet to assess the similarity of A:B to C:D as a function of the combined similarity of A to C and of B to D. In contrast, Turney (2005) used the web to pursue a more divergent course, to represent the tacit relationships of A to B and of C to D as points in a highdimensional space. The dimensions of this space initially correspond to linking phrases on the web, before these dimensions are significantly reduced using singular value decomposition. In the infamous SAT test, an analogy A:B::C:D has four other pairs of concepts that serve as likely distractors (e.g. singer:songwriter for hack:writer) and the goal is to choose the most appropriate C:D pair for a given A:B pairing. Using variants of Wu and Palmer (1994) on the 374 S</context>
</contexts>
<marker>Turney, 2005</marker>
<rawString>Peter Turney. 2005. Measuring semantic similarity by latent relational analysis. Proceedings of the 19th International Joint Conference on Artificial Intelligence, 1136-1141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
<author>Mark T Keane</author>
</authors>
<title>Belief Modeling, Intentionality and Perlocution in Metaphor Comprehension.</title>
<date>1994</date>
<booktitle>In Proceedings of the 16th Annual Meeting of the Cognitive Science Society,</booktitle>
<location>Atlanta, Georgia. Hillsdale, NJ: Lawrence Erlbaum.</location>
<contexts>
<context position="15132" citStr="Veale &amp; Keane (1994)" startWordPosition="2516" endWordPosition="2519">al perspective. Camac &amp; Glucksberg (1984) provide experimental evidence for the claim that “metaphors do not use preexisting associations to achieve their effects [É] people use metaphors to create new relations between concepts.” They also offer a salutary reminder of an often overlooked fact: every comparison exploits information, but each is also a source of new information in its own right. Thus, “this cola is acid” reveals a different perspective on cola (e.g. as a corrosive substance or an irritating food) than “this acid is cola” highlights for acid (such as e.g., a familiar substance) Veale &amp; Keane (1994) model the role of similarity in realizing the long-term perlocutionary effect of an informative comparison. For example, to compare surgeons to butchers is to encourage one to see all surgeons as more bloody, crude or careless. The reverse comparison, of butchers to surgeons, encourages one to see butchers as more skilled and precise. Veale &amp; Keane present a network model of memory, called Sapper, in which activation can spread between related concepts, thus allowing one concept to prime the properties of a neighbor. To interpret an analogy, Sapper lays down new activation-carrying bridges in</context>
</contexts>
<marker>Veale, Keane, 1994</marker>
<rawString>Tony Veale and Mark T. Keane. 1994. Belief Modeling, Intentionality and Perlocution in Metaphor Comprehension. In Proceedings of the 16th Annual Meeting of the Cognitive Science Society, Atlanta, Georgia. Hillsdale, NJ: Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
</authors>
<title>The analogical thesaurus: An emerging application at the juncture of lexical metaphor and information retrieval.</title>
<date>2003</date>
<booktitle>In Proceedings of IAAI’03, the 1Sth International Conference on Innovative Applications of Artificial Intelligence,</booktitle>
<location>Mexico.</location>
<contexts>
<context position="16002" citStr="Veale (2003)" startWordPosition="2661" endWordPosition="2662">tchers to surgeons, encourages one to see butchers as more skilled and precise. Veale &amp; Keane present a network model of memory, called Sapper, in which activation can spread between related concepts, thus allowing one concept to prime the properties of a neighbor. To interpret an analogy, Sapper lays down new activation-carrying bridges in memory between analogical counterparts, such as between surgeon &amp; butcher, flesh &amp; meat, and scalpel &amp; cleaver. Comparisons can thus have lasting effects on how Sapper sees the world, changing the pattern of activation that arises when it primes a concept. Veale (2003) adopts a similarly dynamic view of similarity in WordNet, showing how an analogical comparison can result in the automatic addition of new categories and relations to WordNet itself. Veale considers the problem of finding an analogical mapping between different parts of WordNet’s noun-sense hierarchy, such as between instances of Greek god and Norse god, or between the letters of different alphabets, such as of Greek and Hebrew. But no structural similarity measure for WordNet exhibits enough discernment to e.g. assign a higher similarity to Zeus &amp; Odin (each is the supreme deity of its panth</context>
</contexts>
<marker>Veale, 2003</marker>
<rawString>Tony Veale. 2003. The analogical thesaurus: An emerging application at the juncture of lexical metaphor and information retrieval. In Proceedings of IAAI’03, the 1Sth International Conference on Innovative Applications of Artificial Intelligence, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
</authors>
<title>WordNet sits the SAT: A knowledge-based approach to lexical analogy.</title>
<date>2004</date>
<booktitle>Proceedings of ECAI&apos;04, the European Conference on Artificial Intelligence,</booktitle>
<pages>606--612</pages>
<contexts>
<context position="13095" citStr="Veale (2004)" startWordPosition="2167" endWordPosition="2168">ied to pairs of concepts; it is sometimes analogically applied to pairs of pairs of concepts, as in proportional analogies of the form A is to B as C is to D (e.g., hacks are to writers as mercenaries are to soldiers, or chisels are to sculptors as scalpels are to surgeons). In such analogies, one is really assessing the similarity of the unstated relationship between each pair of concepts: thus, mercenaries are soldiers whose allegiance is paid for, much as hacks are writers with income-driven loyalties; sculptors use chisels to carve stone, while surgeons use scalpels to cut or carve flesh. Veale (2004) used WordNet to assess the similarity of A:B to C:D as a function of the combined similarity of A to C and of B to D. In contrast, Turney (2005) used the web to pursue a more divergent course, to represent the tacit relationships of A to B and of C to D as points in a highdimensional space. The dimensions of this space initially correspond to linking phrases on the web, before these dimensions are significantly reduced using singular value decomposition. In the infamous SAT test, an analogy A:B::C:D has four other pairs of concepts that serve as likely distractors (e.g. singer:songwriter for </context>
</contexts>
<marker>Veale, 2004</marker>
<rawString>Tony Veale. 2004. WordNet sits the SAT: A knowledge-based approach to lexical analogy. Proceedings of ECAI&apos;04, the European Conference on Artificial Intelligence, 606-612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
<author>Yanfen Hao</author>
</authors>
<title>Comprehending and Generating Apt Metaphors: A Web-driven, Case-based Approach to Figurative Language.</title>
<date>2007</date>
<booktitle>In proceedings of AAAI 2007, the 22nd AAAI Conference on Artificial Intelligence.</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="3290" citStr="Veale &amp; Hao, 2007" startWordPosition="540" endWordPosition="543">. By placing pop tarts in the breakfast aisle, food manufacturers encourage us to view them as a breakfast food that is not dissimilar to oatmeal or cornflakes. When ex-PM Tony Blair published his memoirs, a mischievous activist encouraged others to move his book from Biography to Fiction in bookshops, in the hope that buyers would see it in a new light. Whenever we use a novel metaphor to convey a non-obvious viewpoint on a topic, such as “cigarettes are time bombs”, the comparison may spur us to insight, to see aspects of the topic that make it more similar to the vehicle (see Ortony, 1979; Veale &amp; Hao, 2007). In formal terms, assume agent A has an insight about concept X, and uses the metaphor X is a Y to also provoke this insight in agent B. To arrive at this insight for itself, B must intuit what X and Y have in common. But this commonality is surely more than a standard categorization of X, or else it would not count as an insight about X. To understand the metaphor, B must place X 660 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 660–670, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics in a new category, so th</context>
</contexts>
<marker>Veale, Hao, 2007</marker>
<rawString>Tony Veale and Yanfen Hao. 2007. Comprehending and Generating Apt Metaphors: A Web-driven, Case-based Approach to Figurative Language. In proceedings of AAAI 2007, the 22nd AAAI Conference on Artificial Intelligence. Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
<author>Guofu Li</author>
<author>Yanfen Hao</author>
</authors>
<title>Growing Finely-Discriminating Taxonomies from Seeds of Varying Quality and Size.</title>
<date>2009</date>
<booktitle>In Proc. of EACL’09, the 12th Conference of the European Chapter of the Association for Computational Linguistics</booktitle>
<pages>835--842</pages>
<contexts>
<context position="20131" citStr="Veale et al. (2009)" startWordPosition="3394" endWordPosition="3397">n to be an exemplary member of the category P-S, such as cola in fizzy-drink, a targeted web search is used to find other members of P-S, via the anchored query “P S such as * and C”. For example, “fizzy drinks such as * and cola” will retrieve web texts in which * is matched to soda or lemonade. Each new member can then be used to instantiate a further query, as in “fizzy drinks such as * and soda”, to retrieve other members of P-S, such as champagne and root beer. This bootstrapping process runs in successive cycles, using doubly-anchored patterns that – following Kozareva et al. (2008) and Veale et al. (2009) – explicitly mention both the category to be populated (P-S) and a recently acquired member of this category (C). As cautioned by Kozareva et al., it is reckless to bootstrap from members to categories to members again if each enfilade of queries is likely to return noisy results. A reliable filter must be applied at each stage, to ensure that any member C that is placed in a category P-S is a sensible member of the category S. Only by filtering in this way can we stop the rapid accumulation of noise. For instance, a WordNet-based filter discards any categorization “P S such as X and C” where</context>
</contexts>
<marker>Veale, Li, Hao, 2009</marker>
<rawString>Tony Veale, Guofu Li and Yanfen Hao. 2009. Growing Finely-Discriminating Taxonomies from Seeds of Varying Quality and Size. In Proc. of EACL’09, the 12th Conference of the European Chapter of the Association for Computational Linguistics pp. 835-842.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
</authors>
<title>Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL’2011, the 49th Annual Meeting of the Association</booktitle>
<contexts>
<context position="18858" citStr="Veale (2011" startWordPosition="3147" endWordPosition="3148"> cowboy” or “as grizzled as a cowboy”. So for each property P suggested by Google n-grams for a lexical concept C, we generate a like-simile for verbal behaviors such as swaggering and an as-as-simile for adjectives such as lonesome. Each is then dispatched to Google as a phrasal query. We value quality over size, as these similes will later be used to find diverse viewpoints on the web via bootstrapping. We thus manually filter each web simile, to weed out any that are ill-formed, and those intended to be seen as ironic by their authors. This gives us a body of 12,000+ valid web similes. 663 Veale (2011, 2012, 2013) notes that web uses of the pattern “as P as C” are rife with irony. In contrast, web instances of “P S such as C” – where S denotes a superordinate of C – are rarely ironic. Hao &amp; Veale (2010) exploit this fact to filter ironic comparisons from web similes, by re-expressing each “as P as C” simile as “P * such as C” (using a wildcard * to match any values for S) and looking for attested uses of this new form on the web. Since each hit will also yield a value for S via the wildcard *, and a finegrained category P-S for C, we use this approach here to harvest fine-grained categorie</context>
</contexts>
<marker>Veale, 2011</marker>
<rawString>Tony Veale. 2011. Creative Language Retrieval: A Robust Hybrid of Information Retrieval and Linguistic Creativity. In Proceedings of ACL’2011, the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
</authors>
<title>Exploding the Creativity Myth: The computational foundations of linguistic creativity.</title>
<date>2012</date>
<publisher>Bloomsbury Academic.</publisher>
<location>London:</location>
<marker>Veale, 2012</marker>
<rawString>Tony Veale. 2012. Exploding the Creativity Myth: The computational foundations of linguistic creativity. London: Bloomsbury Academic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Veale</author>
</authors>
<title>Humorous Similes. Humor:</title>
<date>2013</date>
<journal>The International Journal of Humor Research,</journal>
<pages>21--3</pages>
<marker>Veale, 2013</marker>
<rawString>Tony Veale. 2013. Humorous Similes. Humor: The International Journal of Humor Research, 21(l):3-22. 22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of ACL’94, 32nd annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<location>Las Cruces, New</location>
<contexts>
<context position="13827" citStr="Wu and Palmer (1994)" startWordPosition="2298" endWordPosition="2301"> to D. In contrast, Turney (2005) used the web to pursue a more divergent course, to represent the tacit relationships of A to B and of C to D as points in a highdimensional space. The dimensions of this space initially correspond to linking phrases on the web, before these dimensions are significantly reduced using singular value decomposition. In the infamous SAT test, an analogy A:B::C:D has four other pairs of concepts that serve as likely distractors (e.g. singer:songwriter for hack:writer) and the goal is to choose the most appropriate C:D pair for a given A:B pairing. Using variants of Wu and Palmer (1994) on the 374 SAT analogies of Turney (2005), Veale (2004) reports a success rate of 38–44% using only WordNet-based similarity. In contrast, Turney (2005) reports up to 55% success on the same analogies, partly because his approach aims 662 to match implicit relations rather than explicit concepts, and in part because it uses a divergent process to gather from the web as rich a perspective as it can on these latent relationships. 2.1 Clever Comparisons Create Similarity Each of these approaches to similarity is a user of information, rather than a creator, and each fails to capture how a creati</context>
<context position="7619" citStr="Wu &amp; Palmer (1994)" startWordPosition="1255" endWordPosition="1258"> gauge the overlap in information content, and thus of meaning, of two lexical concepts. We need only identify the deepest point in the taxonomy at which this content starts to diverge. This point of divergence is often called the LCS, or least common subsumer, of two concepts (Pederson et al., 2004). Since sub-categories add new properties to those they inherit from their parents – Aristotle called these properties the differentia that stop a category system from trivially collapsing into itself – the depth of a lexical concept in a taxonomy is an intuitive proxy for its information content. Wu &amp; Palmer (1994) use the depth of a lexical concept in the WordNet hierarchy as such a proxy, and thereby estimate the similarity of two lexical concepts as twice the depth of their LCS divided by the sum of their individual depths. Leacock and Chodorow (1998) instead use the length of the shortest path between two concepts as a proxy for the conceptual distance between them. To connect any two ideas in a hierarchical system, one must vertically ascend the hierarchy from one concept, change direction at a potential LCS, and then descend the hierarchy to reach the second concept. (Aristotle was also first to s</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. 1994. Verb semantics and lexical selection. In Proceedings of ACL’94, 32nd annual meeting of the Association for Computational Linguistics, Las Cruces, New Mexico,. pp. 133-138.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>