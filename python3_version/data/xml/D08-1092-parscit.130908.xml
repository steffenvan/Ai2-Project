<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000283">
<title confidence="0.806547">
Two Languages are Better than One (for Syntactic Parsing)
</title>
<author confidence="0.993866">
David Burkett and Dan Klein
</author>
<affiliation confidence="0.9982455">
Computer Science Division
University of California, Berkeley
</affiliation>
<email confidence="0.999378">
{dburkett,klein}@cs.berkeley.edu
</email>
<sectionHeader confidence="0.994813" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999556157894737">
We show that jointly parsing a bitext can sub-
stantially improve parse quality on both sides.
In a maximum entropy bitext parsing model,
we define a distribution over source trees, tar-
get trees, and node-to-node alignments be-
tween them. Features include monolingual
parse scores and various measures of syntac-
tic divergence. Using the translated portion
of the Chinese treebank, our model is trained
iteratively to maximize the marginal likeli-
hood of training tree pairs, with alignments
treated as latent variables. The resulting bi-
text parser outperforms state-of-the-art mono-
lingual parser baselines by 2.5 Fl at predicting
English side trees and 1.8 Fl at predicting Chi-
nese side trees (the highest published numbers
on these corpora). Moreover, these improved
trees yield a 2.4 BLEU increase when used in
a downstream MT evaluation.
</bodyText>
<sectionHeader confidence="0.998752" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99992337254902">
Methods for machine translation (MT) have increas-
ingly leveraged not only the formal machinery of
syntax (Wu, 1997; Chiang, 2007; Zhang et al.,
2008), but also linguistic tree structures of either the
source side (Huang et al., 2006; Marton and Resnik,
2008; Quirk et al., 2005), the target side (Yamada
and Knight, 2001; Galley et al., 2004; Zollmann et
al., 2006; Shen et al., 2008), or both (Och et al.,
2003; Aue et al., 2004; Ding and Palmer, 2005).
These methods all rely on automatic parsing of one
or both sides of input bitexts and are therefore im-
pacted by parser quality. Unfortunately, parsing gen-
eral bitexts well can be a challenge for newswire-
trained treebank parsers for many reasons, including
out-of-domain input and tokenization issues.
On the other hand, the presence of translation
pairs offers a new source of information: bilin-
gual constraints. For example, Figure 1 shows a
case where a state-of-the-art English parser (Petrov
and Klein, 2007) has chosen an incorrect structure
which is incompatible with the (correctly chosen)
output of a comparable Chinese parser. Smith and
Smith (2004) previously showed that such bilin-
gual constraints can be leveraged to transfer parse
quality from a resource-rich language to a resource-
impoverished one. In this paper, we show that bilin-
gual constraints and reinforcement can be leveraged
to substantially improve parses on both sides of a
bitext, even for two resource-rich languages.
Formally, we present a log-linear model over
triples of source trees, target trees, and node-to-
node tree alignments between them. We consider
a set of core features which capture the scores of
monolingual parsers as well as measures of syntactic
alignment. Our model conditions on the input sen-
tence pair and so features can and do reference input
characteristics such as posterior distributions from a
word-level aligner (Liang et al., 2006; DeNero and
Klein, 2007).
Our training data is the translated section of the
Chinese treebank (Xue et al., 2002; Bies et al.,
2007), so at training time correct trees are observed
on both the source and target side. Gold tree align-
ments are not present and so are induced as latent
variables using an iterative training procedure. To
make the process efficient and modular to existing
monolingual parsers, we introduce several approxi-
mations: use of k-best lists in candidate generation,
an adaptive bound to avoid considering all k2 com-
binations, and Viterbi approximations to alignment
posteriors.
</bodyText>
<page confidence="0.965012">
877
</page>
<note confidence="0.990124">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 877–886,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<figureCaption confidence="0.959243">
Figure 1: Two possible parse pairs for a Chinese-English sentence pair. The parses in a) are chosen by independent
monolingual statistical parsers, but only the Chinese side is correct. The gold English parse shown in b) is further down
in the 100-best list, despite being more consistent with the gold Chinese parse. The circles show where the two parses
differ. Note that in b), the ADVP and PP nodes correspond nicely to Chinese tree nodes, whereas the correspondence
for nodes in a), particularly the SBAR node, is less clear.
</figureCaption>
<bodyText confidence="0.9998778">
We evaluate our system primarily as a parser and
secondarily as a component in a machine translation
pipeline. For both English and Chinese, we begin
with the state-of-the-art parsers presented in Petrov
and Klein (2007) as a baseline. Joint parse selection
improves the English trees by 2.5 F1 and the Chi-
nese trees by 1.8 F1. While other Chinese treebank
parsers do not have access to English side transla-
tions, this Chinese figure does outperform all pub-
lished monolingual Chinese treebank results on an
equivalent split of the data.
As MT motivates this work, another valuable
evaluation is the effect of joint selection on down-
stream MT quality. In an experiment using a
syntactic MT system, we find that rules extracted
from joint parses results in an increase of 2.4
BLEU points over rules extracted from independent
parses.1 In sum, jointly parsing bitexts improves
parses substantially, and does so in a way that that
carries all the way through the MT pipeline.
</bodyText>
<sectionHeader confidence="0.981179" genericHeader="introduction">
2 Model
</sectionHeader>
<bodyText confidence="0.9993606">
In our model, we consider pairs of sentences (s, s&apos;),
where we use the convention that unprimed vari-
ables are source domain and primed variables are
target domain. These sentences have parse trees t
(respectively t&apos;) taken from candidate sets T (T&apos;).
</bodyText>
<footnote confidence="0.990307333333333">
1It is anticipated that in some applications, such as tree trans-
ducer extraction, the alignments themselves may be of value,
but in the present work they are not evaluated.
</footnote>
<bodyText confidence="0.913555166666667">
Non-terminal nodes in trees will be denoted by n
(n&apos;) and we abuse notation by equating trees with
their node sets. Alignments a are simply at-most-
one-to-one matchings between a pair of trees t and
t&apos; (see Figure 2a for an example). Note that we will
also mention word alignments in feature definitions;
a and the unqualified term alignment will always re-
fer to node alignments. Words in a sentence are de-
noted by v (v&apos;).
Our model is a general log-linear (maximum en-
tropy) distribution over triples (t, a, t&apos;) for sentence
pairs (s, s&apos;):
</bodyText>
<equation confidence="0.651818">
P(t, a, t s, s&apos;) a exp(wT0(t, a, t&apos;))
</equation>
<bodyText confidence="0.9460765">
Features are thus defined over (t, a, t&apos;) triples; we
discuss specific features below.
</bodyText>
<sectionHeader confidence="0.999328" genericHeader="method">
3 Features
</sectionHeader>
<bodyText confidence="0.9997294">
To use our model, we need features of a triple
(t, a, t&apos;) which encode both the monolingual quality
of the trees as well as the quality of the alignment
between them. We introduce a variety of features in
the next sections.
</bodyText>
<subsectionHeader confidence="0.998933">
3.1 Monolingual Features
</subsectionHeader>
<bodyText confidence="0.99423725">
To capture basic monolingual parse quality, we be-
gin with a single source and a single target feature
whose values are the log likelihood of the source
tree t and the target tree t&apos;, respectively, as given
</bodyText>
<page confidence="0.996671">
878
</page>
<bodyText confidence="0.999763222222222">
by our baseline monolingual parsers. These two fea-
tures are called SOURCELL and TARGETLL respec-
tively. It is certainly possible to augment these sim-
ple features with what would amount to monolin-
gual reranking features, but we do not explore that
option here. Note that with only these two features,
little can be learned: all positive weights w cause the
jointly optimal parse pair (t, t&apos;) to comprise the two
top-1 monolingual outputs (the baseline).
</bodyText>
<subsectionHeader confidence="0.99913">
3.2 Word Alignment Features
</subsectionHeader>
<bodyText confidence="0.9875265">
All other features in our model reference the entire
triple (t, a, t&apos;). In this work, such features are de-
fined over aligned node pairs for efficiency, but gen-
eralizations are certainly possible.
Bias: The first feature is simply a bias feature
which has value 1 on each aligned node pair (n, n&apos;).
This bias allows the model to learn a general prefer-
ence for denser alignments.
Alignment features: Of course, some alignments
are better than others. One indicator of a good node-
to-node alignment between n and n&apos; is that a good
word alignment model thinks that there are many
word-to-word alignments in their bispan. Similarly,
there should be few alignments that violate that bis-
pan. To compute such features, we define a(v, v&apos;)
to be the posterior probability assigned to the word
alignment between v and v&apos; by an independent word
aligner.2
Before defining alignment features, we need to
define some additional variables. For any node n E t
(n&apos; E t&apos;), the inside span i(n) (i(n&apos;)) comprises
the input tokens of s (s&apos;) dominated by that node.
Similarly, the complement, the outside span, will be
denoted o(n) (o(n&apos;)), and comprises the tokens not
dominated by that node. See Figure 2b,c for exam-
ples of the resulting regions.
</bodyText>
<equation confidence="0.99422125">
�INSIDEBOTH =
INSRCOUTTRG =
INTRGOUTSRC =
vEo(n) v0Ei(n0)
</equation>
<footnote confidence="0.99051525">
2It is of course possible to learn good alignments using lexi-
cal indicator functions or other direct techniques, but given our
very limited training data, it is advantageous to leverage counts
from an unsupervised alignment system.
</footnote>
<bodyText confidence="0.914497">
Hard alignment features: We also define the
hard versions of these features, which take counts
from the word aligner’s hard top-1 alignment output
S:
</bodyText>
<equation confidence="0.99960525">
�HARDINSIDEBOTH =
HARDINSRCOUTTRG =
HARDINTRGOUTSRC =
vEo(n) v0Ei(n0)
</equation>
<bodyText confidence="0.999877777777778">
Scaled alignment features: Finally, undesirable
larger bispans can be relatively sparse at the word
alignment level, yet still contain many good word
alignments simply by virtue of being large. We
therefore define a scaled count which measures den-
sity rather than totals. The geometric mean of span
lengths was a superior measure of bispan “area” than
the true area because word-level alignments tend to
be broadly one-to-one in our word alignment model.
</bodyText>
<equation confidence="0.984303833333333">
INSIDEBOTH
V ji(n)j - ji(n&apos; )j
INSRCOUTTRG
V ji(n)j - jo(n&apos;)j
INTRGOUTSRC
V jo(n)j - ji(n&apos;)j
</equation>
<bodyText confidence="0.999844625">
Head word alignment features: When consider-
ing a node pair (n, n&apos;), especially one which dom-
inates a large area, the above measures treat all
spanned words as equally important. However, lex-
ical heads are generally more representative than
other spanned words. Let h select the headword of
a node according to standard head percolation rules
(Collins, 2003; Bikel and Chiang, 2000).
</bodyText>
<equation confidence="0.9804455">
ALIGNHEADWORD = a(h(n), h(n&apos;))
HARDALIGNHEADWORD = S(h(n), h(n&apos;))
</equation>
<subsectionHeader confidence="0.999272">
3.3 Tree Structure Features
</subsectionHeader>
<bodyText confidence="0.9986958">
We also consider features that measure correspon-
dences between the tree structures themselves.
Span difference: We expect that, in general,
aligned nodes should dominate spans of roughly the
same length, and so we allow the model to learn to
</bodyText>
<equation confidence="0.999886846153846">
vEi(n) � a(v, v&apos;)
v0Ei(n0)
� � a(v, v&apos;)
vEi(n) v0Eo(n0)
� � a(v, v&apos;)
� S(v, v&apos;)
vEi(n) v0Ei(n0)
� � S(v, v&apos;)
vEi(n) v0Eo(n0)
� � S(v, v&apos;)
SCALEDINSIDEBOTH =
SCALEDINSRCOUTTRG =
SCALEDINTRGOUTSRC =
</equation>
<page confidence="0.996912">
879
</page>
<figureCaption confidence="0.98906475">
Figure 2: a) An example of a legal alignment on a Chinese-English sentence fragment with one good and one bad node
pair, along with sample word alignment posteriors. Hard word alignments are bolded. b) The word alignment regions
for the good NP-NP alignment. InsideBoth regions are shaded in black, InSrcOutTrg in light grey, and InTrgOutSrc in
grey. c) The word alignment regions for the bad PP-NP alignment.
</figureCaption>
<bodyText confidence="0.99693">
penalize node pairs whose inside span lengths differ
greatly.
</bodyText>
<equation confidence="0.885451">
SPANDIFF = ||i(n) |− |i(n&apos;)||
</equation>
<bodyText confidence="0.976940142857143">
Number of children: We also expect that there
will be correspondences between the rules of the
CFGs that generate the trees in each language. To
encode some of this information, we compute in-
dicators of the number of children c that the nodes
have in t and t&apos;.
NUMCHILDREN(|c(n)|, |c(n&apos;)|) = 1
</bodyText>
<subsectionHeader confidence="0.981358">
3.4 Typed vs untyped features
</subsectionHeader>
<bodyText confidence="0.999845">
For each feature above (except monolingual fea-
tures), we create label-specific versions by conjoin-
ing the label pair (`(n), `(n&apos;)). We use both the
typed and untyped variants of all features.
</bodyText>
<sectionHeader confidence="0.993151" genericHeader="method">
4 Training
</sectionHeader>
<bodyText confidence="0.984637823529412">
Recall that our data condition supplies sentence
pairs (s, s&apos;) along with gold parse pairs (g, g&apos;). We
do not observe the alignments a which link these
parses. In principle, we want to find weights which
maximize the marginal log likelihood of what we do
observe given our sentence pairs:3
Child labels: In addition, we also encode whether w∗ = arg max EP(g,a,g0|s,s0,w) (1)
certain label pairs occur as children of matched w a
nodes. Let c(n, `) select the children of n with la- = arg max Ea exp(w&gt;φ(g, a, g0))
bel `. w � �a exp(w&gt;φ(t, a, t0)) (2)
(t,t&apos;)
CHILDLABEL(`, `&apos;) = |c(n, `) |· |c(n&apos;, `&apos;)|
Note that the corresponding “self labels” feature
is not listed because it arises in the next section as a
typed variant of the bias feature.
There are several challenges. First, the space of
symmetric at-most-one-to-one matchings is #P-hard
</bodyText>
<footnote confidence="0.968643">
3In this presentation, we only consider a single sentence pair
for the sake of clarity, but our true objective was multiplied over
all sentence pairs in the training data.
</footnote>
<page confidence="0.994856">
880
</page>
<bodyText confidence="0.999959769230769">
to sum over exactly (Valiant, 1979). Second, even
without matchings to worry about, standard meth-
ods for maximizing the above formulation would re-
quire summation over pairs of trees, and we want
to assume a fairly generic interface to independent
monolingual parsers (though deeper joint modeling
and/or training is of course a potential extension).
As we have chosen to operate in a reranking mode
over monolingual k-best lists, we have another is-
sue: our k-best outputs on the data which trains
our model may not include the gold tree pair. We
therefore make several approximations and modifi-
cations, which we discuss in turn.
</bodyText>
<subsectionHeader confidence="0.979589">
4.1 Viterbi Alignments
</subsectionHeader>
<bodyText confidence="0.999927363636364">
Because summing over alignments a is intractable,
we cannot evaluate (2) or its derivatives. However,
if we restrict the space of possible alignments, then
we can make this optimization more feasible. One
way to do this is to stipulate in advance that for each
tree pair, there is a canonical alignment a0(t, t0). Of
course, we want a0 to reflect actual correspondences
between t and t0, so we want a reasonable definition
that ensures the alignments are of reasonable qual-
ity. Fortunately, it turns out that we can efficiently
optimize a given a fixed tree pair and weight vector:
</bodyText>
<figure confidence="0.532890666666667">
a∗ = arg max P(aIt, t0, s, s0, w)
a
= arg max P(t, a, t0|s, s0, w)
a
= arg max exp(w&gt;O(t, a, t0))
a
</figure>
<bodyText confidence="0.9982815">
This optimization requires only that we search for
an optimal alignment. Because all our features can
be factored to individual node pairs, this can be done
with the Hungarian algorithm in cubic time.4 Note
that we do not enforce any kind of domination con-
sistency in the matching: for example, the optimal
alignment might in principle have the source root
aligning to a target non-root and vice versa.
We then define a0(t, t0) as the alignment that
maximizes w&gt;0 O(t, a, t0), where w0 is a fixed initial
weight vector with a weight of 1 for INSIDEBOTH,
-1 for INSRCOUTTRG and INTRGOUTSRC, and 0
</bodyText>
<footnote confidence="0.99208825">
4There is a minor modification to allow nodes not to match.
Any alignment link which has negative score is replaced by a
zero-score link, and any zero-score link in the solution is con-
sidered a pair of unmatched nodes.
</footnote>
<bodyText confidence="0.9924065">
for all other features. Then, we simplify (2) by fix-
ing the alignments a0:
</bodyText>
<equation confidence="0.9808035">
w* = arg w E(t,t,) exp(wTO(t,a0(t,t&apos;),t&apos;)) max exp(wT O(g, a0 (g, g&apos;), g&apos;)) 3
)
</equation>
<bodyText confidence="0.9999328">
This optimization has no latent variables and is
therefore convex and straightforward. However,
while we did use this as a rapid training procedure
during development, fixing the alignments a priori is
both unsatisfying and also less effective than a pro-
cedure which allows the alignments a to adapt dur-
ing training.
Again, for fixed alignments a, optimizing w is
easy. Similarly, with a fixed w, finding the optimal
a for any particular tree pair is also easy. Another
option is therefore to use an iterative procedure that
alternates between choosing optimal alignments for
a fixed w, and then reoptimizing w for those fixed
alignments according to (3). By iterating, we per-
form the following optimization:
</bodyText>
<equation confidence="0.984696">
(4)
E(t,t,) maxa exp(wT O(t, a, t&apos;))
</equation>
<bodyText confidence="0.999775333333333">
Note that (4) is just (2) with summation replaced
by maximization. Though we do not know of any
guarantees for this EM-like algorithm, in practice
it converges after a few iterations given sufficient
training data. We initialize the procedure by setting
w0 as defined above.
</bodyText>
<subsectionHeader confidence="0.879851">
4.2 Pseudo-gold Trees
</subsectionHeader>
<bodyText confidence="0.9999686">
When training our model, we approximate the sets
of all trees with k-best lists, T and T0, produced
by monolingual parsers. Since these sets are not
guaranteed to contain the gold trees g and g0, our
next approximation is to define a set of pseudo-gold
trees, following previous work in monolingual parse
reranking (Charniak and Johnson, 2005). We define
Tˆ ( Tˆ0) as the F1-optimal subset of T (T0). We then
modify (4) to reflect the fact that we are seeking to
maximize the likelihood of trees in this subset:
</bodyText>
<equation confidence="0.917262333333333">
P(t, t0|s, s0, w) (5)
where P(t, t0|s, s0, w) =
maxa exp(w&gt;O(t, a, t0)) 6
E(¯t ¯t,)∈(T T,) maxa exp(w&gt;O(¯t, a, t0)) ( )
w* = arg max
w
maxa exp(wTO(g, a, g&apos;))
w∗ = arg max �
w (t,t,)∈( Tˆ , Tˆ
</equation>
<page confidence="0.987859">
881
</page>
<subsectionHeader confidence="0.994849">
4.3 Training Set Pruning
</subsectionHeader>
<bodyText confidence="0.989761666666667">
To reduce the time and space requirements for train-
ing, we do not always use the full k-best lists. To
prune the set T, we rank all the trees in T from 1 to
k, according to their log likelihood under the base-
line parsing model, and find the rank of the least
likely pseudo-gold tree:
</bodyText>
<table confidence="0.9996354">
Training Dev Test
Articles 1-270 301-325 271-300
Ch Sentences 3480 352 348
Eng Sentences 3472 358 353
Bilingual Pairs 2298 270 288
</table>
<tableCaption confidence="0.9609375">
Table 1: Sentence counts from bilingual Chinese tree-
bank corpus.
</tableCaption>
<equation confidence="0.9970155">
r∗ = min
t∈ T�
</equation>
<bodyText confidence="0.981889">
Finally, we restrict T based on rank:
To prune the list of tree pairs, first we rank them
according to the metric:
</bodyText>
<equation confidence="0.97723">
rank(t)
Tpruned = It E T |rank(t) c r∗ + E}
</equation>
<bodyText confidence="0.9998638">
where E is a free parameter of the pruning procedure.
The restricted set T0pruned is constructed in the same
way. When training, we replace the sum over all tree
pairs in (T, T0) in the denominator of (6) with a sum
over all tree pairs in (Tpruned, T0pruned).
The parameter E can be set to any value from 0
to k, with lower values resulting in more efficient
training, and higher values resulting in better perfor-
mance. We set E by empirically determining a good
speed/performance tradeoff (see §6.2).
</bodyText>
<sectionHeader confidence="0.982834" genericHeader="method">
5 Joint Selection
</sectionHeader>
<bodyText confidence="0.99993475">
At test time, we have a weight vector w and so
selecting optimal trees for the sentence pair (s, s0)
from a pair of k best lists, (T, T0) is straightforward.
We just find:
</bodyText>
<equation confidence="0.99445175">
(t∗, t0∗) =arg max
(t,t&apos;)∈(T,T&apos;)
= arg max
(t,t&apos;)∈(T,T&apos;)
</equation>
<bodyText confidence="0.927749">
Note that with no additional cost, we can also find
the optimal alignment between t∗ and t0∗:
</bodyText>
<equation confidence="0.6085955">
a∗ = arg max w&gt;φ(t∗, a, t0∗)
a
</equation>
<subsectionHeader confidence="0.997627">
5.1 Test Set Pruning
</subsectionHeader>
<bodyText confidence="0.999444833333333">
Because the size of (T, T0) grows as O(k�), the time
spent iterating through all these tree pairs can grow
unreasonably long, particularly when reranking a set
of sentence pairs the size of a typical MT corpus. To
combat this, we use a simple pruning technique to
limit the number of tree pairs under consideration.
</bodyText>
<equation confidence="0.658599">
wSOURCELL · SOURCELL + wTARGETLL · TARGETLL
</equation>
<bodyText confidence="0.9998922">
Then, we simply remove all tree pairs whose rank-
ing falls below some empirically determined cutoff.
As we show in §6.3, by using this technique we are
able to speed up reranking by a factor of almost 20
without an appreciable loss of performance.
</bodyText>
<sectionHeader confidence="0.985044" genericHeader="method">
6 Statistical Parsing Experiments
</sectionHeader>
<bodyText confidence="0.99990388">
All the data used to train the joint parsing model and
to evaluate parsing performance were taken from ar-
ticles 1-325 of the Chinese treebank, which all have
English translations with gold-standard parse trees.
The articles were split into training, development,
and test sets according to the standard breakdown for
Chinese parsing evaluations. Not all sentence pairs
could be included for various reasons, including
one-to-many Chinese-English sentence alignments,
sentences omitted from the English translations, and
low-fidelity translations. Additional sentence pairs
were dropped from the training data because they
had unambiguous parses in at least one of the two
languages. Table 1 shows how many sentences were
included in each dataset.
We had two training setups: rapid and full. In the
rapid training setup, only 1000 sentence pairs from
the training set were used, and we used fixed align-
ments for each tree pair rather than iterating (see
§4.1). The full training setup used the iterative train-
ing procedure on all 2298 training sentence pairs.
We used the English and Chinese parsers in
Petrov and Klein (2007)5 to generate all k-best lists
and as our evaluation baseline. Because our bilin-
gual data is from the Chinese treebank, and the data
</bodyText>
<footnote confidence="0.989678">
5Available at http://nlp.cs.berkeley.edu.
</footnote>
<figure confidence="0.792057333333333">
P(t, a, t0|s, s0, w)
w&gt;φ(t, a, t0)
max
a
max
a
</figure>
<page confidence="0.993303">
882
</page>
<bodyText confidence="0.999926161290322">
typically used to train a Chinese parser contains the
Chinese side of our bilingual training data, we had
to train a new Chinese grammar using only articles
400-1151 (omitting articles 1-270). This modified
grammar was used to generate the k-best lists that
we trained our model on. However, as we tested on
the same set of articles used for monolingual Chi-
nese parser evaluation, there was no need to use
a modified grammar to generate k-best lists at test
time, and so we used a regularly trained Chinese
parser for this purpose.
We also note that since all parsing evaluations
were performed on Chinese treebank data, the Chi-
nese test sentences were in-domain, whereas the
English sentences were very far out-of-domain for
the Penn Treebank-trained baseline English parser.
Hence, in these evaluations, Chinese scores tend to
be higher than English ones.
Posterior word alignment probabilities were ob-
tained from the word aligner of Liang et al. (2006)
and DeNero and Klein (2007)6, trained on approxi-
mately 1.7 million sentence pairs. For our alignment
model we used an HMM in each direction, trained to
agree (Liang et al., 2006), and we combined the pos-
teriors using DeNero and Klein’s (2007) soft union
method.
Unless otherwise specified, the maximum value
of k was set to 100 for both training and testing, and
all experiments used a value of 25 as the c parameter
for training set pruning and a cutoff rank of 500 for
test set pruning.
</bodyText>
<subsectionHeader confidence="0.999221">
6.1 Feature Ablation
</subsectionHeader>
<bodyText confidence="0.999864727272727">
To verify that all our features were contributing to
the model’s performance, we did an ablation study,
removing one group of features at a time. Table 2
shows the F1 scores on the bilingual development
data resulting from training with each group of fea-
tures removed.7 Note that though head word fea-
tures seemed to be detrimental in our rapid train-
ing setup, earlier testing had shown a positive effect,
so we reran the comparison using our full training
setup, where we again saw an improvement when
including these features.
</bodyText>
<footnote confidence="0.992483">
6Available at http://nlp.cs.berkeley.edu.
7We do not have a test with the basic alignment features
removed because they are necessary to compute ao(t, t&apos;).
</footnote>
<table confidence="0.9998379375">
Features Baseline Parsers
Ch F1 Eng F1 Tot F1
Monolingual 84.95 76.75 81.15
Rapid Training
Features Ch F1 Eng F1 Tot F1
All 86.37 78.92 82.91
−Hard align 85.83 77.92 82.16
−Scaled align 86.21 78.62 82.69
−Head word 86.47 79.00 83.00
−Span diff 86.00 77.49 82.07
−Num children 86.26 78.56 82.69
−Child labels 86.35 78.45 82.68
Full Training
Features Ch F1 Eng F1 Tot F1
All 86.76 79.41 83.34
−Head word 86.42 79.53 83.22
</table>
<tableCaption confidence="0.992140333333333">
Table 2: Feature ablation study. Fl on dev set after train-
ing with individual feature groups removed. Performance
with individual baseline parsers included for reference.
</tableCaption>
<table confidence="0.999208625">
c Ch F1 Eng F1 Tot F1 Tree Pairs
15 85.78 77.75 82.05 1,463,283
20 85.88 77.27 81.90 1,819,261
25 86.37 78.92 82.91 2,204,988
30 85.97 79.18 82.83 2,618,686
40 86.10 78.12 82.40 3,521,423
50 85.95 78.50 82.50 4,503,554
100 86.28 79.02 82.91 8,997,708
</table>
<tableCaption confidence="0.984967333333333">
Table 3: Training set pruning study. Fl on dev set after
training with different values of the c parameter for train-
ing set pruning.
</tableCaption>
<subsectionHeader confidence="0.999909">
6.2 Training Set Pruning
</subsectionHeader>
<bodyText confidence="0.99982125">
To find a good value of the c parameter for train-
ing set pruning we tried several different values, us-
ing our rapid training setup and testing on the dev
set. The results are shown in Table 3. We selected
25 as it showed the best performance/speed trade-
off, on average performing as well as if we had done
no pruning at all, while requiring only a quarter the
memory and CPU time.
</bodyText>
<subsectionHeader confidence="0.999716">
6.3 Test Set Pruning
</subsectionHeader>
<bodyText confidence="0.971242">
We also tried several different values of the rank cut-
off for test set pruning, using the full training setup
</bodyText>
<page confidence="0.997029">
883
</page>
<table confidence="0.999669875">
Cutoff Ch F1 Eng F1 Tot F1 Time (s)
50 86.34 79.26 83.04 174
100 86.61 79.31 83.22 307
200 86.67 79.39 83.28 509
500 86.76 79.41 83.34 1182
1000 86.80 79.39 83.35 2247
2000 86.78 79.35 83.33 4476
10,000 86.71 79.37 83.30 20,549
</table>
<tableCaption confidence="0.967629">
Table 4: Test set pruning study. Fl on dev set obtained
using different cutoffs for test set pruning.
</tableCaption>
<bodyText confidence="0.999929714285714">
and testing on the dev set. The results are in Table 4.
For F1 evaluation, which is on a very small set of
sentences, we selected 500 as the value with the best
speed/performance tradeoff. However, when rerank-
ing our entire MT corpus, we used a value of 200,
sacrificing a tiny bit of performance for an extra fac-
tor of 2 in speed.8
</bodyText>
<subsectionHeader confidence="0.999294">
6.4 Sensitivity to k
</subsectionHeader>
<bodyText confidence="0.999982769230769">
Since our bitext parser currently operates as a
reranker, the quality of the trees is limited by the
quality of the k-best lists produced by the baseline
parsers. To test this limitation, we evaluated perfor-
mance on the dev set using baseline k-best lists of
varying length. Training parameters were fixed (full
training setup with k = 100) and test set pruning was
disabled for these experiments. The results are in Ta-
ble 5. The relatively modest gains with increasing k,
even as the oracle scores continue to improve, indi-
cate that performance is limited more by the model’s
reliance on the baseline parsers than by search errors
that result from the reranking approach.
</bodyText>
<subsectionHeader confidence="0.989646">
6.5 Final Results
</subsectionHeader>
<bodyText confidence="0.9999615">
Our final evaluation was done using the full training
setup. Here, we report F1 scores on two sets of data.
First, as before, we only include the sentence pairs
from our bilingual corpus to fully demonstrate the
gains made by joint parsing. We also report scores
on the full test set to allow easier comparison with
</bodyText>
<footnote confidence="0.9814535">
8Using a rank cutoff of 200, the reranking step takes slightly
longer than serially running both baseline parsers, and generat-
ing k-best lists takes slightly longer than getting 1-best parses,
so in total, joint parsing takes about 2.3 times as long as mono-
lingual parsing. With a rank cutoff of 500, total parsing time is
scaled by a factor of around 3.8.
</footnote>
<table confidence="0.9995785">
k Joint Parsing Oracle
Ch F1 Eng F1 Ch F1 Eng F1
1 84.95 76.75 84.95 76.75
10 86.23 78.43 90.05 81.99
25 86.64 79.27 90.99 83.37
50 86.61 79.10 91.82 84.14
100 86.71 79.37 92.23 84.73
150 86.67 79.47 92.49 85.17
</table>
<tableCaption confidence="0.983406666666667">
Table 5: Sensitivity to k study. Joint parsing and oracle
Fl obtained on dev set using different maximum values
of k when generating baseline k-best lists.
</tableCaption>
<table confidence="0.9999075">
Parser F1 on bilingual data only
Ch F1 Eng F1 Tot F1
Baseline 83.50 79.25 81.44
Joint 85.25 81.72 83.52
F1 on full test set
Parser Ch F1 Eng F1 Tot F1
Baseline 82.91 78.93 81.00
Joint 84.24 80.87 82.62
</table>
<tableCaption confidence="0.983258">
Table 6: Final evaluation. Comparison of Fl on test set
between baseline parsers and joint parser.
</tableCaption>
<bodyText confidence="0.999939888888889">
past work on Chinese parsing. For the latter evalu-
ation, sentences that were not in the bilingual cor-
pus were simply parsed with the baseline parsers.
The results are in Table 6. Joint parsing improves
F1 by 2.5 points on out-of-domain English sentences
and by 1.8 points on in-domain Chinese sentences;
this represents the best published Chinese treebank
parsing performance, even after sentences that lack
a translation are taken into account.
</bodyText>
<sectionHeader confidence="0.996036" genericHeader="method">
7 Machine Translation
</sectionHeader>
<bodyText confidence="0.999886272727273">
To test the impact of joint parsing on syntactic MT
systems, we compared the results of training an MT
system with two different sets of trees: those pro-
duced by the baseline parsers, and those produced by
our joint parser. For this evaluation, we used a syn-
tactic system based on Galley et al. (2004) and Gal-
ley et al. (2006), which extracts tree-to-string trans-
ducer rules based on target-side trees. We trained the
system on 150,000 Chinese-English sentence pairs
from the training corpus of Wang et al. (2007), and
used a large (close to 5 billion tokens) 4-gram lan-
</bodyText>
<page confidence="0.994982">
884
</page>
<table confidence="0.969303">
Baseline Joint Moses
BLEU 18.7 21.1 18.8
</table>
<tableCaption confidence="0.994181">
Table 7: MT comparison on a syntactic system trained
</tableCaption>
<bodyText confidence="0.9524715">
with trees output from either baseline monolingual
parsers or our joint parser. To facilitate relative compari-
son, the Moses (Koehn et al., 2007) number listed reflects
the default Moses configuration, including its full distor-
tion model, and standard training pipeline.
guage model for decoding. We tuned and evaluated
BLEU (Papineni et al., 2001) on separate held-out
sets of sentences of up to length 40 from the same
corpus. The results are in Table 7, showing that joint
parsing yields a BLEU increase of 2.4.9
</bodyText>
<sectionHeader confidence="0.999247" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999984307692308">
By jointly parsing (and aligning) sentences in a
translation pair, it is possible to exploit mutual con-
straints that improve the quality of syntactic analy-
ses over independent monolingual parsing. We pre-
sented a joint log-linear model over source trees,
target trees, and node-to-node alignments between
them, which is used to select an optimal tree pair
from a k-best list. On Chinese treebank data, this
procedure improves F1 by 1.8 on Chinese sentences
and by 2.5 on out-of-domain English sentences. Fur-
thermore, by using this joint parsing technique to
preprocess the input to a syntactic MT system, we
obtain a 2.4 BLEU improvement.
</bodyText>
<sectionHeader confidence="0.994207" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999448">
We would like to thank the anonymous reviewers for
helpful comments on an earlier draft of this paper
and Adam Pauls and Jing Zheng for help in running
our MT experiments.
</bodyText>
<sectionHeader confidence="0.999237" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987238183333334">
Anthony Aue, Arul Menezes, Bob Moore, Chris Quirk,
and Eric Ringger. 2004. Statistical machine trans-
lation using labeled semantic dependency graphs. In
TMI.
9Note that all numbers are single-reference BLEU scores
and are not comparable to multiple reference scores or scores
on other corpora.
Ann Bies, Martha Palmer, Justin Mott, and Colin Warner.
2007. English chinese translation treebank v 1.0. Web
download. LDC2007T02.
Daniel M. Bikel and David Chiang. 2000. Two statisti-
cal parsing models applied to the chinese treebank. In
Second Chinese Language Processing Workshop.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and maxent discriminative rerank-
ing. In ACL.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational Linguis-
tics, 29(4):589–637.
John DeNero and Dan Klein. 2007. Tailoring word
alignments to syntactic machine translation. In ACL.
Yuan Ding and Martha Palmer. 2005. Machine trans-
lation using probabilistic synchronous dependency in-
sertion grammars. In ACL.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In HLT-
NAACL.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training
of context-rich syntactic translation models. In
COLING-ACL.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In HLT-NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In ACL.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In HLT-NAACL.
Yuval Marton and Philip Resnik. 2008. Soft syntactic
constraints for hierarchical phrase-based translation.
In ACL.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar
Kumar, Libin Shen, David Smith, Katherine Eng,
Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syn-
tax for statistical machine translation. Technical re-
port, CLSP, Johns Hopkins University.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. Bleu: a method for automatic eval-
uation of machine translation. Research report, IBM.
RC22176.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In HLT-NAACL.
</reference>
<page confidence="0.986093">
885
</page>
<reference confidence="0.99951384375">
Chris Quirk, Arul Menezes, and Colin Cherry. 2005. De-
pendency treelet translation: Syntactically informed
phrasal smt. In ACL.
Libin Shen, Jinxi Xu, and Ralph Weishedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
ACL.
David A. Smith and Noah A. Smith. 2004. Bilin-
gual parsing with factored estimation: using english
to parse korean. In EMNLP.
Leslie G. Valiant. 1979. The complexity of computing
the permanent. In Theoretical Computer Science 8.
Wen Wang, Andreas Stolcke, and Jing Zheng. 2007.
Reranking machine translation hypotheses with struc-
tured and web-based language models. In IEEEASRU
Workshop.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–404.
Nianwen Xue, Fu-Dong Chiou, and Martha Palmer.
2002. Building a large-scale annotated chinese cor-
pus. In COLING.
Kenji Yamada and Kevin Knight. 2001. A syntax-based
statistical translation model. In ACL.
Hao Zhang, Chris Quirk, Robert C. Moore, and
Daniel Gildea. 2008. Bayesian learning of non-
compositional phrases with synchronous parsing. In
ACL.
Andreas Zollmann, Ashish Venugopal, Stephan Vogel,
and Alex Waibel. 2006. The cmu-aka syntax aug-
mented machine translation system for iwslt-06. In
IWSLT.
</reference>
<page confidence="0.998816">
886
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.912783">
<title confidence="0.999378">Two Languages are Better than One (for Syntactic Parsing)</title>
<author confidence="0.999663">David Burkett</author>
<author confidence="0.999663">Dan</author>
<affiliation confidence="0.99992">Computer Science University of California,</affiliation>
<abstract confidence="0.99538595">We show that jointly parsing a bitext can substantially improve parse quality on both sides. In a maximum entropy bitext parsing model, we define a distribution over source trees, target trees, and node-to-node alignments between them. Features include monolingual parse scores and various measures of syntactic divergence. Using the translated portion of the Chinese treebank, our model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables. The resulting bitext parser outperforms state-of-the-art monoparser baselines by 2.5 predicting side trees and 1.8 predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anthony Aue</author>
<author>Arul Menezes</author>
<author>Bob Moore</author>
<author>Chris Quirk</author>
<author>Eric Ringger</author>
</authors>
<title>Statistical machine translation using labeled semantic dependency graphs.</title>
<date>2004</date>
<booktitle>In TMI.</booktitle>
<contexts>
<context position="1470" citStr="Aue et al., 2004" startWordPosition="227" endWordPosition="230">ting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parser (Petrov and Klein, 2007) has chosen an incorrect structure which is incompatible with </context>
</contexts>
<marker>Aue, Menezes, Moore, Quirk, Ringger, 2004</marker>
<rawString>Anthony Aue, Arul Menezes, Bob Moore, Chris Quirk, and Eric Ringger. 2004. Statistical machine translation using labeled semantic dependency graphs. In TMI.</rawString>
</citation>
<citation valid="false">
<title>9Note that all numbers are single-reference BLEU scores and are not comparable to multiple reference scores or scores on other corpora.</title>
<marker></marker>
<rawString>9Note that all numbers are single-reference BLEU scores and are not comparable to multiple reference scores or scores on other corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Martha Palmer</author>
<author>Justin Mott</author>
<author>Colin Warner</author>
</authors>
<title>English chinese translation treebank v 1.0. Web download.</title>
<date>2007</date>
<pages>2007--02</pages>
<contexts>
<context position="3064" citStr="Bies et al., 2007" startWordPosition="480" endWordPosition="483">itext, even for two resource-rich languages. Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments between them. We consider a set of core features which capture the scores of monolingual parsers as well as measures of syntactic alignment. Our model conditions on the input sentence pair and so features can and do reference input characteristics such as posterior distributions from a word-level aligner (Liang et al., 2006; DeNero and Klein, 2007). Our training data is the translated section of the Chinese treebank (Xue et al., 2002; Bies et al., 2007), so at training time correct trees are observed on both the source and target side. Gold tree alignments are not present and so are induced as latent variables using an iterative training procedure. To make the process efficient and modular to existing monolingual parsers, we introduce several approximations: use of k-best lists in candidate generation, an adaptive bound to avoid considering all k2 combinations, and Viterbi approximations to alignment posteriors. 877 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 877–886, Honolulu, October 2008.c</context>
</contexts>
<marker>Bies, Palmer, Mott, Warner, 2007</marker>
<rawString>Ann Bies, Martha Palmer, Justin Mott, and Colin Warner. 2007. English chinese translation treebank v 1.0. Web download. LDC2007T02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
<author>David Chiang</author>
</authors>
<title>Two statistical parsing models applied to the chinese treebank.</title>
<date>2000</date>
<booktitle>In Second Chinese Language Processing Workshop.</booktitle>
<contexts>
<context position="9926" citStr="Bikel and Chiang, 2000" startWordPosition="1618" endWordPosition="1621"> was a superior measure of bispan “area” than the true area because word-level alignments tend to be broadly one-to-one in our word alignment model. INSIDEBOTH V ji(n)j - ji(n&apos; )j INSRCOUTTRG V ji(n)j - jo(n&apos;)j INTRGOUTSRC V jo(n)j - ji(n&apos;)j Head word alignment features: When considering a node pair (n, n&apos;), especially one which dominates a large area, the above measures treat all spanned words as equally important. However, lexical heads are generally more representative than other spanned words. Let h select the headword of a node according to standard head percolation rules (Collins, 2003; Bikel and Chiang, 2000). ALIGNHEADWORD = a(h(n), h(n&apos;)) HARDALIGNHEADWORD = S(h(n), h(n&apos;)) 3.3 Tree Structure Features We also consider features that measure correspondences between the tree structures themselves. Span difference: We expect that, in general, aligned nodes should dominate spans of roughly the same length, and so we allow the model to learn to vEi(n) � a(v, v&apos;) v0Ei(n0) � � a(v, v&apos;) vEi(n) v0Eo(n0) � � a(v, v&apos;) � S(v, v&apos;) vEi(n) v0Ei(n0) � � S(v, v&apos;) vEi(n) v0Eo(n0) � � S(v, v&apos;) SCALEDINSIDEBOTH = SCALEDINSRCOUTTRG = SCALEDINTRGOUTSRC = 879 Figure 2: a) An example of a legal alignment on a Chinese-Eng</context>
</contexts>
<marker>Bikel, Chiang, 2000</marker>
<rawString>Daniel M. Bikel and David Chiang. 2000. Two statistical parsing models applied to the chinese treebank. In Second Chinese Language Processing Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and maxent discriminative reranking.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="16203" citStr="Charniak and Johnson, 2005" startWordPosition="2685" endWordPosition="2688"> is just (2) with summation replaced by maximization. Though we do not know of any guarantees for this EM-like algorithm, in practice it converges after a few iterations given sufficient training data. We initialize the procedure by setting w0 as defined above. 4.2 Pseudo-gold Trees When training our model, we approximate the sets of all trees with k-best lists, T and T0, produced by monolingual parsers. Since these sets are not guaranteed to contain the gold trees g and g0, our next approximation is to define a set of pseudo-gold trees, following previous work in monolingual parse reranking (Charniak and Johnson, 2005). We define Tˆ ( Tˆ0) as the F1-optimal subset of T (T0). We then modify (4) to reflect the fact that we are seeking to maximize the likelihood of trees in this subset: P(t, t0|s, s0, w) (5) where P(t, t0|s, s0, w) = maxa exp(w&gt;O(t, a, t0)) 6 E(¯t ¯t,)∈(T T,) maxa exp(w&gt;O(¯t, a, t0)) ( ) w* = arg max w maxa exp(wTO(g, a, g&apos;)) w∗ = arg max � w (t,t,)∈( Tˆ , Tˆ 881 4.3 Training Set Pruning To reduce the time and space requirements for training, we do not always use the full k-best lists. To prune the set T, we rank all the trees in T from 1 to k, according to their log likelihood under the basel</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and maxent discriminative reranking. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="1169" citStr="Chiang, 2007" startWordPosition="174" endWordPosition="175">treebank, our model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables. The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain inp</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="9901" citStr="Collins, 2003" startWordPosition="1616" endWordPosition="1617">of span lengths was a superior measure of bispan “area” than the true area because word-level alignments tend to be broadly one-to-one in our word alignment model. INSIDEBOTH V ji(n)j - ji(n&apos; )j INSRCOUTTRG V ji(n)j - jo(n&apos;)j INTRGOUTSRC V jo(n)j - ji(n&apos;)j Head word alignment features: When considering a node pair (n, n&apos;), especially one which dominates a large area, the above measures treat all spanned words as equally important. However, lexical heads are generally more representative than other spanned words. Let h select the headword of a node according to standard head percolation rules (Collins, 2003; Bikel and Chiang, 2000). ALIGNHEADWORD = a(h(n), h(n&apos;)) HARDALIGNHEADWORD = S(h(n), h(n&apos;)) 3.3 Tree Structure Features We also consider features that measure correspondences between the tree structures themselves. Span difference: We expect that, in general, aligned nodes should dominate spans of roughly the same length, and so we allow the model to learn to vEi(n) � a(v, v&apos;) v0Ei(n0) � � a(v, v&apos;) vEi(n) v0Eo(n0) � � a(v, v&apos;) � S(v, v&apos;) vEi(n) v0Ei(n0) � � S(v, v&apos;) vEi(n) v0Eo(n0) � � S(v, v&apos;) SCALEDINSIDEBOTH = SCALEDINSRCOUTTRG = SCALEDINTRGOUTSRC = 879 Figure 2: a) An example of a legal a</context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring word alignments to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="2957" citStr="DeNero and Klein, 2007" startWordPosition="461" endWordPosition="464">at bilingual constraints and reinforcement can be leveraged to substantially improve parses on both sides of a bitext, even for two resource-rich languages. Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments between them. We consider a set of core features which capture the scores of monolingual parsers as well as measures of syntactic alignment. Our model conditions on the input sentence pair and so features can and do reference input characteristics such as posterior distributions from a word-level aligner (Liang et al., 2006; DeNero and Klein, 2007). Our training data is the translated section of the Chinese treebank (Xue et al., 2002; Bies et al., 2007), so at training time correct trees are observed on both the source and target side. Gold tree alignments are not present and so are induced as latent variables using an iterative training procedure. To make the process efficient and modular to existing monolingual parsers, we introduce several approximations: use of k-best lists in candidate generation, an adaptive bound to avoid considering all k2 combinations, and Viterbi approximations to alignment posteriors. 877 Proceedings of the 2</context>
<context position="21118" citStr="DeNero and Klein (2007)" startWordPosition="3544" endWordPosition="3547">e parser evaluation, there was no need to use a modified grammar to generate k-best lists at test time, and so we used a regularly trained Chinese parser for this purpose. We also note that since all parsing evaluations were performed on Chinese treebank data, the Chinese test sentences were in-domain, whereas the English sentences were very far out-of-domain for the Penn Treebank-trained baseline English parser. Hence, in these evaluations, Chinese scores tend to be higher than English ones. Posterior word alignment probabilities were obtained from the word aligner of Liang et al. (2006) and DeNero and Klein (2007)6, trained on approximately 1.7 million sentence pairs. For our alignment model we used an HMM in each direction, trained to agree (Liang et al., 2006), and we combined the posteriors using DeNero and Klein’s (2007) soft union method. Unless otherwise specified, the maximum value of k was set to 100 for both training and testing, and all experiments used a value of 25 as the c parameter for training set pruning and a cutoff rank of 500 for test set pruning. 6.1 Feature Ablation To verify that all our features were contributing to the model’s performance, we did an ablation study, removing one </context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Ding</author>
<author>Martha Palmer</author>
</authors>
<title>Machine translation using probabilistic synchronous dependency insertion grammars.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1494" citStr="Ding and Palmer, 2005" startWordPosition="231" endWordPosition="234">trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parser (Petrov and Klein, 2007) has chosen an incorrect structure which is incompatible with the (correctly chosen) o</context>
</contexts>
<marker>Ding, Palmer, 2005</marker>
<rawString>Yuan Ding and Martha Palmer. 2005. Machine translation using probabilistic synchronous dependency insertion grammars. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In HLTNAACL.</booktitle>
<contexts>
<context position="1382" citStr="Galley et al., 2004" startWordPosition="209" endWordPosition="212">onolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parse</context>
<context position="27287" citStr="Galley et al. (2004)" startWordPosition="4630" endWordPosition="4633">. The results are in Table 6. Joint parsing improves F1 by 2.5 points on out-of-domain English sentences and by 1.8 points on in-domain Chinese sentences; this represents the best published Chinese treebank parsing performance, even after sentences that lack a translation are taken into account. 7 Machine Translation To test the impact of joint parsing on syntactic MT systems, we compared the results of training an MT system with two different sets of trees: those produced by the baseline parsers, and those produced by our joint parser. For this evaluation, we used a syntactic system based on Galley et al. (2004) and Galley et al. (2006), which extracts tree-to-string transducer rules based on target-side trees. We trained the system on 150,000 Chinese-English sentence pairs from the training corpus of Wang et al. (2007), and used a large (close to 5 billion tokens) 4-gram lan884 Baseline Joint Moses BLEU 18.7 21.1 18.8 Table 7: MT comparison on a syntactic system trained with trees output from either baseline monolingual parsers or our joint parser. To facilitate relative comparison, the Moses (Koehn et al., 2007) number listed reflects the default Moses configuration, including its full distortion m</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In COLING-ACL.</booktitle>
<contexts>
<context position="27312" citStr="Galley et al. (2006)" startWordPosition="4635" endWordPosition="4639">e 6. Joint parsing improves F1 by 2.5 points on out-of-domain English sentences and by 1.8 points on in-domain Chinese sentences; this represents the best published Chinese treebank parsing performance, even after sentences that lack a translation are taken into account. 7 Machine Translation To test the impact of joint parsing on syntactic MT systems, we compared the results of training an MT system with two different sets of trees: those produced by the baseline parsers, and those produced by our joint parser. For this evaluation, we used a syntactic system based on Galley et al. (2004) and Galley et al. (2006), which extracts tree-to-string transducer rules based on target-side trees. We trained the system on 150,000 Chinese-English sentence pairs from the training corpus of Wang et al. (2007), and used a large (close to 5 billion tokens) 4-gram lan884 Baseline Joint Moses BLEU 18.7 21.1 18.8 Table 7: MT comparison on a syntactic system trained with trees output from either baseline monolingual parsers or our joint parser. To facilitate relative comparison, the Moses (Koehn et al., 2007) number listed reflects the default Moses configuration, including its full distortion model, and standard traini</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="1273" citStr="Huang et al., 2006" startWordPosition="190" endWordPosition="193">irs, with alignments treated as latent variables. The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of </context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="27799" citStr="Koehn et al., 2007" startWordPosition="4715" endWordPosition="4718">produced by our joint parser. For this evaluation, we used a syntactic system based on Galley et al. (2004) and Galley et al. (2006), which extracts tree-to-string transducer rules based on target-side trees. We trained the system on 150,000 Chinese-English sentence pairs from the training corpus of Wang et al. (2007), and used a large (close to 5 billion tokens) 4-gram lan884 Baseline Joint Moses BLEU 18.7 21.1 18.8 Table 7: MT comparison on a syntactic system trained with trees output from either baseline monolingual parsers or our joint parser. To facilitate relative comparison, the Moses (Koehn et al., 2007) number listed reflects the default Moses configuration, including its full distortion model, and standard training pipeline. guage model for decoding. We tuned and evaluated BLEU (Papineni et al., 2001) on separate held-out sets of sentences of up to length 40 from the same corpus. The results are in Table 7, showing that joint parsing yields a BLEU increase of 2.4.9 8 Conclusions By jointly parsing (and aligning) sentences in a translation pair, it is possible to exploit mutual constraints that improve the quality of syntactic analyses over independent monolingual parsing. We presented a joi</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="2932" citStr="Liang et al., 2006" startWordPosition="457" endWordPosition="460">is paper, we show that bilingual constraints and reinforcement can be leveraged to substantially improve parses on both sides of a bitext, even for two resource-rich languages. Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments between them. We consider a set of core features which capture the scores of monolingual parsers as well as measures of syntactic alignment. Our model conditions on the input sentence pair and so features can and do reference input characteristics such as posterior distributions from a word-level aligner (Liang et al., 2006; DeNero and Klein, 2007). Our training data is the translated section of the Chinese treebank (Xue et al., 2002; Bies et al., 2007), so at training time correct trees are observed on both the source and target side. Gold tree alignments are not present and so are induced as latent variables using an iterative training procedure. To make the process efficient and modular to existing monolingual parsers, we introduce several approximations: use of k-best lists in candidate generation, an adaptive bound to avoid considering all k2 combinations, and Viterbi approximations to alignment posteriors.</context>
<context position="21090" citStr="Liang et al. (2006)" startWordPosition="3539" endWordPosition="3542">d for monolingual Chinese parser evaluation, there was no need to use a modified grammar to generate k-best lists at test time, and so we used a regularly trained Chinese parser for this purpose. We also note that since all parsing evaluations were performed on Chinese treebank data, the Chinese test sentences were in-domain, whereas the English sentences were very far out-of-domain for the Penn Treebank-trained baseline English parser. Hence, in these evaluations, Chinese scores tend to be higher than English ones. Posterior word alignment probabilities were obtained from the word aligner of Liang et al. (2006) and DeNero and Klein (2007)6, trained on approximately 1.7 million sentence pairs. For our alignment model we used an HMM in each direction, trained to agree (Liang et al., 2006), and we combined the posteriors using DeNero and Klein’s (2007) soft union method. Unless otherwise specified, the maximum value of k was set to 100 for both training and testing, and all experiments used a value of 25 as the c parameter for training set pruning and a cutoff rank of 500 for test set pruning. 6.1 Feature Ablation To verify that all our features were contributing to the model’s performance, we did an a</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Soft syntactic constraints for hierarchical phrase-based translation.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1298" citStr="Marton and Resnik, 2008" startWordPosition="194" endWordPosition="197"> treated as latent variables. The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual co</context>
</contexts>
<marker>Marton, Resnik, 2008</marker>
<rawString>Yuval Marton and Philip Resnik. 2008. Soft syntactic constraints for hierarchical phrase-based translation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Daniel Gildea</author>
</authors>
<title>Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar,</title>
<date>2003</date>
<tech>Technical report, CLSP,</tech>
<institution>Johns Hopkins University.</institution>
<location>Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen</location>
<marker>Och, Gildea, 2003</marker>
<rawString>Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin, and Dragomir Radev. 2003. Syntax for statistical machine translation. Technical report, CLSP, Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<tech>Research report, IBM. RC22176.</tech>
<contexts>
<context position="28002" citStr="Papineni et al., 2001" startWordPosition="4745" endWordPosition="4748">e trees. We trained the system on 150,000 Chinese-English sentence pairs from the training corpus of Wang et al. (2007), and used a large (close to 5 billion tokens) 4-gram lan884 Baseline Joint Moses BLEU 18.7 21.1 18.8 Table 7: MT comparison on a syntactic system trained with trees output from either baseline monolingual parsers or our joint parser. To facilitate relative comparison, the Moses (Koehn et al., 2007) number listed reflects the default Moses configuration, including its full distortion model, and standard training pipeline. guage model for decoding. We tuned and evaluated BLEU (Papineni et al., 2001) on separate held-out sets of sentences of up to length 40 from the same corpus. The results are in Table 7, showing that joint parsing yields a BLEU increase of 2.4.9 8 Conclusions By jointly parsing (and aligning) sentences in a translation pair, it is possible to exploit mutual constraints that improve the quality of syntactic analyses over independent monolingual parsing. We presented a joint log-linear model over source trees, target trees, and node-to-node alignments between them, which is used to select an optimal tree pair from a k-best list. On Chinese treebank data, this procedure im</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. Bleu: a method for automatic evaluation of machine translation. Research report, IBM. RC22176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="2008" citStr="Petrov and Klein, 2007" startWordPosition="312" endWordPosition="315">ollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parser (Petrov and Klein, 2007) has chosen an incorrect structure which is incompatible with the (correctly chosen) output of a comparable Chinese parser. Smith and Smith (2004) previously showed that such bilingual constraints can be leveraged to transfer parse quality from a resource-rich language to a resourceimpoverished one. In this paper, we show that bilingual constraints and reinforcement can be leveraged to substantially improve parses on both sides of a bitext, even for two resource-rich languages. Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments b</context>
<context position="4463" citStr="Petrov and Klein (2007)" startWordPosition="699" endWordPosition="702">tatistical parsers, but only the Chinese side is correct. The gold English parse shown in b) is further down in the 100-best list, despite being more consistent with the gold Chinese parse. The circles show where the two parses differ. Note that in b), the ADVP and PP nodes correspond nicely to Chinese tree nodes, whereas the correspondence for nodes in a), particularly the SBAR node, is less clear. We evaluate our system primarily as a parser and secondarily as a component in a machine translation pipeline. For both English and Chinese, we begin with the state-of-the-art parsers presented in Petrov and Klein (2007) as a baseline. Joint parse selection improves the English trees by 2.5 F1 and the Chinese trees by 1.8 F1. While other Chinese treebank parsers do not have access to English side translations, this Chinese figure does outperform all published monolingual Chinese treebank results on an equivalent split of the data. As MT motivates this work, another valuable evaluation is the effect of joint selection on downstream MT quality. In an experiment using a syntactic MT system, we find that rules extracted from joint parses results in an increase of 2.4 BLEU points over rules extracted from independ</context>
<context position="19909" citStr="Petrov and Klein (2007)" startWordPosition="3343" endWordPosition="3346">translations, and low-fidelity translations. Additional sentence pairs were dropped from the training data because they had unambiguous parses in at least one of the two languages. Table 1 shows how many sentences were included in each dataset. We had two training setups: rapid and full. In the rapid training setup, only 1000 sentence pairs from the training set were used, and we used fixed alignments for each tree pair rather than iterating (see §4.1). The full training setup used the iterative training procedure on all 2298 training sentence pairs. We used the English and Chinese parsers in Petrov and Klein (2007)5 to generate all k-best lists and as our evaluation baseline. Because our bilingual data is from the Chinese treebank, and the data 5Available at http://nlp.cs.berkeley.edu. P(t, a, t0|s, s0, w) w&gt;φ(t, a, t0) max a max a 882 typically used to train a Chinese parser contains the Chinese side of our bilingual training data, we had to train a new Chinese grammar using only articles 400-1151 (omitting articles 1-270). This modified grammar was used to generate the k-best lists that we trained our model on. However, as we tested on the same set of articles used for monolingual Chinese parser evalu</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Quirk</author>
<author>Arul Menezes</author>
<author>Colin Cherry</author>
</authors>
<title>Dependency treelet translation: Syntactically informed phrasal smt.</title>
<date>2005</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1319" citStr="Quirk et al., 2005" startWordPosition="198" endWordPosition="201">les. The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For exampl</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>Chris Quirk, Arul Menezes, and Colin Cherry. 2005. Dependency treelet translation: Syntactically informed phrasal smt. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weishedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1425" citStr="Shen et al., 2008" startWordPosition="217" endWordPosition="220">dicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parser (Petrov and Klein, 2007) has chosen an in</context>
</contexts>
<marker>Shen, Xu, Weishedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weishedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Noah A Smith</author>
</authors>
<title>Bilingual parsing with factored estimation: using english to parse korean.</title>
<date>2004</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="2154" citStr="Smith and Smith (2004)" startWordPosition="334" endWordPosition="337">parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parser (Petrov and Klein, 2007) has chosen an incorrect structure which is incompatible with the (correctly chosen) output of a comparable Chinese parser. Smith and Smith (2004) previously showed that such bilingual constraints can be leveraged to transfer parse quality from a resource-rich language to a resourceimpoverished one. In this paper, we show that bilingual constraints and reinforcement can be leveraged to substantially improve parses on both sides of a bitext, even for two resource-rich languages. Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments between them. We consider a set of core features which capture the scores of monolingual parsers as well as measures of syntactic alignment. Our mo</context>
</contexts>
<marker>Smith, Smith, 2004</marker>
<rawString>David A. Smith and Noah A. Smith. 2004. Bilingual parsing with factored estimation: using english to parse korean. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leslie G Valiant</author>
</authors>
<title>The complexity of computing the permanent.</title>
<date>1979</date>
<journal>In Theoretical Computer Science</journal>
<volume>8</volume>
<contexts>
<context position="12548" citStr="Valiant, 1979" startWordPosition="2063" endWordPosition="2064">(n, `) select the children of n with la- = arg max Ea exp(w&gt;φ(g, a, g0)) bel `. w � �a exp(w&gt;φ(t, a, t0)) (2) (t,t&apos;) CHILDLABEL(`, `&apos;) = |c(n, `) |· |c(n&apos;, `&apos;)| Note that the corresponding “self labels” feature is not listed because it arises in the next section as a typed variant of the bias feature. There are several challenges. First, the space of symmetric at-most-one-to-one matchings is #P-hard 3In this presentation, we only consider a single sentence pair for the sake of clarity, but our true objective was multiplied over all sentence pairs in the training data. 880 to sum over exactly (Valiant, 1979). Second, even without matchings to worry about, standard methods for maximizing the above formulation would require summation over pairs of trees, and we want to assume a fairly generic interface to independent monolingual parsers (though deeper joint modeling and/or training is of course a potential extension). As we have chosen to operate in a reranking mode over monolingual k-best lists, we have another issue: our k-best outputs on the data which trains our model may not include the gold tree pair. We therefore make several approximations and modifications, which we discuss in turn. 4.1 Vi</context>
</contexts>
<marker>Valiant, 1979</marker>
<rawString>Leslie G. Valiant. 1979. The complexity of computing the permanent. In Theoretical Computer Science 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen Wang</author>
<author>Andreas Stolcke</author>
<author>Jing Zheng</author>
</authors>
<title>Reranking machine translation hypotheses with structured and web-based language models.</title>
<date>2007</date>
<booktitle>In IEEEASRU Workshop.</booktitle>
<contexts>
<context position="27499" citStr="Wang et al. (2007)" startWordPosition="4664" endWordPosition="4667"> performance, even after sentences that lack a translation are taken into account. 7 Machine Translation To test the impact of joint parsing on syntactic MT systems, we compared the results of training an MT system with two different sets of trees: those produced by the baseline parsers, and those produced by our joint parser. For this evaluation, we used a syntactic system based on Galley et al. (2004) and Galley et al. (2006), which extracts tree-to-string transducer rules based on target-side trees. We trained the system on 150,000 Chinese-English sentence pairs from the training corpus of Wang et al. (2007), and used a large (close to 5 billion tokens) 4-gram lan884 Baseline Joint Moses BLEU 18.7 21.1 18.8 Table 7: MT comparison on a syntactic system trained with trees output from either baseline monolingual parsers or our joint parser. To facilitate relative comparison, the Moses (Koehn et al., 2007) number listed reflects the default Moses configuration, including its full distortion model, and standard training pipeline. guage model for decoding. We tuned and evaluated BLEU (Papineni et al., 2001) on separate held-out sets of sentences of up to length 40 from the same corpus. The results are </context>
</contexts>
<marker>Wang, Stolcke, Zheng, 2007</marker>
<rawString>Wen Wang, Andreas Stolcke, and Jing Zheng. 2007. Reranking machine translation hypotheses with structured and web-based language models. In IEEEASRU Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="1155" citStr="Wu, 1997" startWordPosition="172" endWordPosition="173">e Chinese treebank, our model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables. The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fu-Dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>Building a large-scale annotated chinese corpus.</title>
<date>2002</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="3044" citStr="Xue et al., 2002" startWordPosition="476" endWordPosition="479"> both sides of a bitext, even for two resource-rich languages. Formally, we present a log-linear model over triples of source trees, target trees, and node-tonode tree alignments between them. We consider a set of core features which capture the scores of monolingual parsers as well as measures of syntactic alignment. Our model conditions on the input sentence pair and so features can and do reference input characteristics such as posterior distributions from a word-level aligner (Liang et al., 2006; DeNero and Klein, 2007). Our training data is the translated section of the Chinese treebank (Xue et al., 2002; Bies et al., 2007), so at training time correct trees are observed on both the source and target side. Gold tree alignments are not present and so are induced as latent variables using an iterative training procedure. To make the process efficient and modular to existing monolingual parsers, we introduce several approximations: use of k-best lists in candidate generation, an adaptive bound to avoid considering all k2 combinations, and Viterbi approximations to alignment posteriors. 877 Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 877–886, Hono</context>
</contexts>
<marker>Xue, Chiou, Palmer, 2002</marker>
<rawString>Nianwen Xue, Fu-Dong Chiou, and Martha Palmer. 2002. Building a large-scale annotated chinese corpus. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1361" citStr="Yamada and Knight, 2001" startWordPosition="205" endWordPosition="208">rforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntax-based statistical translation model. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Chris Quirk</author>
<author>Robert C Moore</author>
<author>Daniel Gildea</author>
</authors>
<title>Bayesian learning of noncompositional phrases with synchronous parsing.</title>
<date>2008</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1190" citStr="Zhang et al., 2008" startWordPosition="176" endWordPosition="179">model is trained iteratively to maximize the marginal likelihood of training tree pairs, with alignments treated as latent variables. The resulting bitext parser outperforms state-of-the-art monolingual parser baselines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization i</context>
</contexts>
<marker>Zhang, Quirk, Moore, Gildea, 2008</marker>
<rawString>Hao Zhang, Chris Quirk, Robert C. Moore, and Daniel Gildea. 2008. Bayesian learning of noncompositional phrases with synchronous parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Ashish Venugopal</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>The cmu-aka syntax augmented machine translation system for iwslt-06.</title>
<date>2006</date>
<booktitle>In IWSLT.</booktitle>
<contexts>
<context position="1405" citStr="Zollmann et al., 2006" startWordPosition="213" endWordPosition="216">elines by 2.5 Fl at predicting English side trees and 1.8 Fl at predicting Chinese side trees (the highest published numbers on these corpora). Moreover, these improved trees yield a 2.4 BLEU increase when used in a downstream MT evaluation. 1 Introduction Methods for machine translation (MT) have increasingly leveraged not only the formal machinery of syntax (Wu, 1997; Chiang, 2007; Zhang et al., 2008), but also linguistic tree structures of either the source side (Huang et al., 2006; Marton and Resnik, 2008; Quirk et al., 2005), the target side (Yamada and Knight, 2001; Galley et al., 2004; Zollmann et al., 2006; Shen et al., 2008), or both (Och et al., 2003; Aue et al., 2004; Ding and Palmer, 2005). These methods all rely on automatic parsing of one or both sides of input bitexts and are therefore impacted by parser quality. Unfortunately, parsing general bitexts well can be a challenge for newswiretrained treebank parsers for many reasons, including out-of-domain input and tokenization issues. On the other hand, the presence of translation pairs offers a new source of information: bilingual constraints. For example, Figure 1 shows a case where a state-of-the-art English parser (Petrov and Klein, 20</context>
</contexts>
<marker>Zollmann, Venugopal, Vogel, Waibel, 2006</marker>
<rawString>Andreas Zollmann, Ashish Venugopal, Stephan Vogel, and Alex Waibel. 2006. The cmu-aka syntax augmented machine translation system for iwslt-06. In IWSLT.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>