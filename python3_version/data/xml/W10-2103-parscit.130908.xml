<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.279458">
<title confidence="0.990091">
On the Role of NLP in Linguistics
</title>
<author confidence="0.992869">
Dipti Misra Sharma
</author>
<affiliation confidence="0.9707445">
Language Technologies Research Centre
IIIT-H, Hyderabad, India
</affiliation>
<email confidence="0.984866">
dipti@iiit.ac.in
</email>
<sectionHeader confidence="0.993614" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998734">
This paper summarizes some of the appli-
cations of NLP techniques in various lin-
guistic sub-fields, and presents a few ex-
amples that call for a deeper engagement
between the two fields.
</bodyText>
<sectionHeader confidence="0.999267" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891333333333">
The recent success of data-driven approaches in
NLP has raised important questions as to what role
linguistics must now seek to play in further ad-
vancing the field. Perhaps, it is also time to pose
the same question from the other direction: As
to how NLP techniques can help linguists make
informed decisions? And how can the advances
made in one field be applied to the other?
Although, there has been some work on in-
corporating NLP techniques for linguistic field-
work and language documentation (Bird, 2009),
the wider use of NLP in linguistic studies is still
fairly limited. However, it is possible to deepen
the engagement between the two fields in a num-
ber of possible areas (as we shall see in the follow-
ing sections), and gain new insights even during
the formulation of linguistic theories and frame-
works.
</bodyText>
<sectionHeader confidence="0.984947" genericHeader="introduction">
2 Historical Linguistics and Linguistic
Typology
</sectionHeader>
<bodyText confidence="0.999485181818182">
Computational techniques have been successfully
used to classify languages and to generate phylo-
genetic trees. This has been tried not just with
handcrafted word lists (Atkinson et al., 2005;
Atkinson and Gray, 2006; Huelsenbeck et al.,
2001) or syntactic data (Barbac¸on et al., 2007) but
with lists extracted from written corpus with com-
parable results (Rama and Singh, 2009; Singh and
Surana, 2007). These techniques are inspired from
the work in computational phylogenetics, which
was aimed at constructing evolutionary trees of
</bodyText>
<figureCaption confidence="0.984967">
Figure 1: Phylogenetic tree using feature n-grams
</figureCaption>
<bodyText confidence="0.99990396">
biological species. Constructing a phylogenetic
tree for languages usually requires the calcula-
tion of distances between pairs of languages (usu-
ally based on word lists). These distances are
then given as input to a computational phyloge-
netic algorithm. Their successful use for lan-
guages has opened the possibility of using compu-
tational techniques for studying historical linguis-
tics. They have already been used for estimating
divergence times of language families (Atkinson
et al., 2005). Figure 1 shows a phylogenetic tree
created using feature n-grams (Rama and Singh,
2009).
Another area for the application of NLP tech-
niques is language typology. For example, lin-
guistic similarity and its estimation can be seen as
fundamental ideas in NLP. The systematic study
of different kinds of linguistic similarity offers
insights towards the theoretical studies of lan-
guages (Singh, 2010). In brief, the typology of
linguistic similarity for computational purposes
is related to linguistic levels (depth), differences
among languages (linguality) and linguistic units
(granularity). Thus, language can be seen as a
system of symbols whose meanings are defined
</bodyText>
<page confidence="0.991466">
18
</page>
<note confidence="0.6327475">
Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 18–21,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999764166666667">
in terms of their estimated similarity and distance
with other symbols. Can this, together with what
Cognitive Linguists have been studying (Robin-
son and Ellis, 2008), which also involves linguistic
similarity, often directly, have some relevance for
linguists?
</bodyText>
<sectionHeader confidence="0.899265" genericHeader="method">
3 Lexical Correspondence and Linguistic
Units
</sectionHeader>
<bodyText confidence="0.999923777777778">
A further case in point is lexical correspondence
across languages, which poses a problem for
cross-lingual and multilingual applications. To
address this and some other issues, a linguistic
unit that behaves similarly across languages can
be conceptualized. Such a unit, may include
morphological variation (inflectional and deriva-
tional), compounds, multi word expressions etc.
as in the Hindi and Telugu examples below:
</bodyText>
<listItem confidence="0.998568470588235">
• Single token content words: raama, raama
(Ram); vah, atanu (he); vyakti, manishii (per-
son) etc.
• Nouns with inflections: bacce, pillalu (chil-
dren); bacce ko, pillalaki (to the child);
raama se, raamudunundii (from Rama) etc.
• Verbs with inflections and tense, aspect and
modality (TAM) markers: karnaa-caahiye,
cayiyaalii (should do); ho sakataa thaa,
ayyiyedemo (could have happened) etc.
• Multi word expressions such as idioms,
phrasal verbs and ‘frozen expressions’: pa-
haaD toDanaa (breaking mountains); muNha
ki khaana (getting defeated) etc.
• Compounds: jaati-prathaa (caste system);
vesh-bhuushaaoN (dresses); akkaDaa-
ikkaDaa (here and there) etc.
</listItem>
<bodyText confidence="0.889327">
This unit might, among other things, form the
basis of the structure of lexical resources, such
that these resources have a direct correspondence
across languages. This can further facilitate com-
parative study of languages (Singh, 2010).
</bodyText>
<sectionHeader confidence="0.995912" genericHeader="method">
4 Applications
</sectionHeader>
<bodyText confidence="0.999982909090909">
Computational techniques can also be used to de-
sign tools and material for language learning and
teaching. Here games can play a useful role. Al-
though, a large number of online games are avail-
able, most of them do not use the latest language
processing techniques. Games can also be used to
generate language resources.
The core idea in Human Computa-
tion (Von Ahn, 2005) is that computers should
do what they do best and that humans seamlessly
work with them to do what computers cannot.
One of the ways to merge the two is in the form of
carefully designed games.
Another insight comes from Machine Transla-
tion. More than any other sub-field in NLP, it is
the data-driven approaches to machine translation
that have proven to be particularly successful over
the past few years. We have been exploring vari-
ous approaches towards hybridization of our rule-
based MT system. Building the transfer-grammar
of such systems is perhaps one of the most time-
intensive tasks that involves careful analysis of test
data. However, data driven techniques can come
to the aid of linguists in this case. The recent
work on automatic acquisition of rules from par-
allel corpora (Lavie et al., 2004) can help iden-
tify a large number of common syntactic transfor-
mations across a pair of languages, and help un-
earth those transformations that might otherwise
be missed by a rule-based grammar. They can be
further used to prioritize the application of rules
based on the observed frequencies of certain syn-
tactic transformations.
</bodyText>
<sectionHeader confidence="0.984699" genericHeader="method">
5 NLP Tools and Linguistics
</sectionHeader>
<bodyText confidence="0.999962142857143">
NLP techniques draw features from annotated cor-
pora which are a rich linguistic resource. How-
ever, these corpora can also be used to extract
grammars, which on one hand feed the parser
with features (Xia, 2001), and on the other, act
as a resource for linguistic studies. For exam-
ple, in Hindi dependency parsing the use of vib-
hakti (post-positions) and TAM labels has proven
to be particularly useful even in the absence of
large amounts of annotated corpora (Ambati et al.,
2010). This also helped bring to light those fea-
tures of the grammar that govern certain struc-
ture choices and brought to notice some previously
overlooked linguistic constructions. Thus, the re-
sult is an iterative process, where both the gram-
mar and the features are refined.
Discourse Processing is another rapidly emerg-
ing research area with considerable potential for
interaction and collaboration between NLP and
Linguistics. In the absence of fully developed the-
ories/frameworks on both sides, focus on syner-
</bodyText>
<page confidence="0.998257">
19
</page>
<bodyText confidence="0.99999202">
gizing research efforts in the two disciplines (such
as devising novel ways to empirically test linguis-
tic hypotheses) from the initial stage itself, can
yield a substantially richer account of Discourse.
Linguistic theories are formalized based on ob-
servations and abstractions of existing linguistic
facts. These theories are then applied to vari-
ous languages to test their validity. However, lan-
guages throw up new problems and issues before
theoreticians. Hence, there are always certain phe-
nomena in languages which remain a point of dis-
cussion since satisfactory solutions are not avail-
able. The facts of a language are accounted for
by applying various techniques and methods that
are offered by a linguistic framework. For exam-
ple, syntactic diagnostics have been a fairly re-
liable method of identifying/classifying construc-
tion types in languages. They work fairly well for
most cases. But in some cases even these tests fail
to classify certain elements. For example, Indian
languages show a highly productive use of com-
plex predicates (Butt, 1995; Butt, 2003). How-
ever, till date there are no satisfactory methods to
decide when a noun verb sequence is a ‘complex
predicate’ and when a ‘verb argument’ case. To
quote an example from our experience while de-
veloping a Hindi Tree Bank, annotators had to be
provided with guidelines to mark a N V sequence
as a complex predicate based on some linguistic
tests. However, there are instances when the na-
tive speaker/annotator is quite confident of a con-
struction being a complex predicate, even though
most syntactic tests might not apply to it.
Although, various theories provide frames to
classify linguistic patterns/items but none of them
enables us to (at least to my knowledge) handle
‘transient/graded’ or rather ‘evolving’ elements.
So, as of now it looks like quite an arbitrary/ad-
hoc approach whether to classify something as a
complex predicate or not. In the above cited ex-
ample, the decision is left to the annotator’s in-
tuition, since linguists don’t agree on the classfi-
cation of these elements or on a set of uniform
tests either. Can the insights gained from inter-
annotator agreement further help theory refine the
diagnostics used in these cases? And can NLP
techniques or advanced NLP tools come to the aid
of linguists here? Perhaps in the form of tools that
can (to an extent) help automate the application of
syntactic diagnostics over large corpora?
</bodyText>
<sectionHeader confidence="0.985646" genericHeader="conclusions">
6 Collaborations
</sectionHeader>
<bodyText confidence="0.999991185185185">
Interdisciplinary areas such as Computational
Linguistics/NLP need a much broader collabo-
ration between linguists and computer scientists.
Experts working within their respective fields
tend to be deeply grounded in their approaches
towards particular problems. Also, they tend
to speak different ‘languages’. Therefore, it
becomes imperative that efforts be made to
bridge the gaps in communication between the
two disciplines. This problem is all the more
acute in India, since the separation of disciplines
happens at a very early stage. Objectives, goals,
methods and training are so different that starting
a communication line proves to be very difficult.
Thus, it is important for those people who have
synthesised the knowledge of the two disciplines
to a large degree, to take the lead and help
establish the initial communication channels. Our
own experiences while devising common tagsets
for Indian languages, made us realize the need
for both linguistic and computational perspectives
towards such problems. While a linguist’s instinct
is to look for exceptions in the grammar (or any
formalism), a computer scientist tends to look for
rules that can be abstracted away and modeled.
However, at the end, both ways of looking at data
help us make informed decisions.
</bodyText>
<sectionHeader confidence="0.995294" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.926386">
Many thanks to Dr. Rajeev Sangal, Anil Kumar
Singh, Arafat Ahsan, Bharath Ambati, Rafiya Be-
gum, Samar Husain and Sudheer Kolachina for the
discussions and inputs.
</bodyText>
<sectionHeader confidence="0.994795" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.960023857142857">
B.R. Ambati, S. Husain, J. Nivre, and R. Sangal. 2010.
On the role of morphosyntactic features in Hindi de-
pendency parsing. In The First Workshop on Sta-
tistical Parsing of Morphologically Rich Languages
(SPMRL 2010), page 94.
QD Atkinson and RD Gray. 2006. How old is the
Indo-European language family? Progress or more
moths to the flame. Phylogenetic Methods and the
Prehistory ofLanguages (Forster P, Renfrew C, eds),
pages 91–109.
Q. Atkinson, G. Nicholls, D. Welch, and R. Gray.
2005. From words to dates: water into wine, math-
emagic or phylogenetic inference? Transactions of
the Philological Society, 103(2):193–219.
</reference>
<page confidence="0.958977">
20
</page>
<reference confidence="0.9996096">
S. Bird. 2009. Natural language processing and
linguistic fieldwork. Computational Linguistics,
35(3):469–474.
M. Butt. 1995. The structure of complex predicates in
Urdu. Center for the Study of Language and Infor-
mation.
M. Butt. 2003. The light verb jungle. In Workshop on
Multi-Verb Constructions. Citeseer.
J.P. Huelsenbeck, F. Ronquist, R. Nielsen, and J.P.
Bollback. 2001. Bayesian inference of phylogeny
and its impact on evolutionary biology. Science,
294(5550):2310–2314.
A. Lavie, K. Probst, E. Peterson, S. Vogel, L. Levin,
A. Font-Llitjos, and J. Carbonell. 2004. A trainable
transfer-based machine translation approach for lan-
guages with limited resources. In Proceedings of
Workshop of the European Association for Machine
Translation. Citeseer.
Taraka Rama and Anil Kumar Singh. 2009. From
bag of languages to family trees from noisy corpus.
In Proceedings of the Conference on Recent Ad-
vances in Natural Language Processing, Borovets,
Bulgaria.
Peter Robinson and Nick Ellis. 2008. Handbook of
Cognitive Linguistics and Second Language Acqui-
sition. Routledge, New York and London.
Anil Kumar Singh and Harshit Surana. 2007. Can cor-
pus based measures be used for comparative study
of languages? In Proceedings of the Ninth Meet-
ing ofACL Special Interest Group on Computational
Phonology and Morphology, Prague, Czech Repub-
lic. Association for Computational Linguistics.
Anil Kumar Singh. 2010. Modeling and Application of
Linguistic Similarity. Ph.D. thesis, IIIT, Hyderabad,
India.
Luis Von Ahn. 2005. Human computation. Ph.D. the-
sis, Pittsburgh, PA, USA. Adviser-Blum, Manuel.
Fei Xia. 2001. Automatic Grammar Generation from
Two Different Perspectives. Ph.D. thesis, University
of Pennsylvania.
</reference>
<page confidence="0.999438">
21
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.910626">
<title confidence="0.999806">On the Role of NLP in Linguistics</title>
<author confidence="0.993167">Dipti Misra</author>
<affiliation confidence="0.991099">Language Technologies Research</affiliation>
<address confidence="0.928188">IIIT-H, Hyderabad,</address>
<email confidence="0.995036">dipti@iiit.ac.in</email>
<abstract confidence="0.999762166666667">This paper summarizes some of the applications of NLP techniques in various linguistic sub-fields, and presents a few examples that call for a deeper engagement between the two fields.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B R Ambati</author>
<author>S Husain</author>
<author>J Nivre</author>
<author>R Sangal</author>
</authors>
<title>On the role of morphosyntactic features in Hindi dependency parsing.</title>
<date>2010</date>
<booktitle>In The First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010),</booktitle>
<pages>94</pages>
<contexts>
<context position="6802" citStr="Ambati et al., 2010" startWordPosition="1068" endWordPosition="1071">to prioritize the application of rules based on the observed frequencies of certain syntactic transformations. 5 NLP Tools and Linguistics NLP techniques draw features from annotated corpora which are a rich linguistic resource. However, these corpora can also be used to extract grammars, which on one hand feed the parser with features (Xia, 2001), and on the other, act as a resource for linguistic studies. For example, in Hindi dependency parsing the use of vibhakti (post-positions) and TAM labels has proven to be particularly useful even in the absence of large amounts of annotated corpora (Ambati et al., 2010). This also helped bring to light those features of the grammar that govern certain structure choices and brought to notice some previously overlooked linguistic constructions. Thus, the result is an iterative process, where both the grammar and the features are refined. Discourse Processing is another rapidly emerging research area with considerable potential for interaction and collaboration between NLP and Linguistics. In the absence of fully developed theories/frameworks on both sides, focus on syner19 gizing research efforts in the two disciplines (such as devising novel ways to empirical</context>
</contexts>
<marker>Ambati, Husain, Nivre, Sangal, 2010</marker>
<rawString>B.R. Ambati, S. Husain, J. Nivre, and R. Sangal. 2010. On the role of morphosyntactic features in Hindi dependency parsing. In The First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010), page 94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>QD Atkinson</author>
<author>RD Gray</author>
</authors>
<title>How old is the Indo-European language family? Progress or more moths to the flame.</title>
<date>2006</date>
<booktitle>Phylogenetic Methods and the Prehistory ofLanguages</booktitle>
<pages>91--109</pages>
<contexts>
<context position="1422" citStr="Atkinson and Gray, 2006" startWordPosition="229" endWordPosition="232">tic fieldwork and language documentation (Bird, 2009), the wider use of NLP in linguistic studies is still fairly limited. However, it is possible to deepen the engagement between the two fields in a number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks. 2 Historical Linguistics and Linguistic Typology Computational techniques have been successfully used to classify languages and to generate phylogenetic trees. This has been tried not just with handcrafted word lists (Atkinson et al., 2005; Atkinson and Gray, 2006; Huelsenbeck et al., 2001) or syntactic data (Barbac¸on et al., 2007) but with lists extracted from written corpus with comparable results (Rama and Singh, 2009; Singh and Surana, 2007). These techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of Figure 1: Phylogenetic tree using feature n-grams biological species. Constructing a phylogenetic tree for languages usually requires the calculation of distances between pairs of languages (usually based on word lists). These distances are then given as input to a computational ph</context>
</contexts>
<marker>Atkinson, Gray, 2006</marker>
<rawString>QD Atkinson and RD Gray. 2006. How old is the Indo-European language family? Progress or more moths to the flame. Phylogenetic Methods and the Prehistory ofLanguages (Forster P, Renfrew C, eds), pages 91–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Atkinson</author>
<author>G Nicholls</author>
<author>D Welch</author>
<author>R Gray</author>
</authors>
<title>From words to dates: water into wine, mathemagic or phylogenetic inference?</title>
<date>2005</date>
<journal>Transactions of the Philological Society,</journal>
<volume>103</volume>
<issue>2</issue>
<contexts>
<context position="1397" citStr="Atkinson et al., 2005" startWordPosition="225" endWordPosition="228"> techniques for linguistic fieldwork and language documentation (Bird, 2009), the wider use of NLP in linguistic studies is still fairly limited. However, it is possible to deepen the engagement between the two fields in a number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks. 2 Historical Linguistics and Linguistic Typology Computational techniques have been successfully used to classify languages and to generate phylogenetic trees. This has been tried not just with handcrafted word lists (Atkinson et al., 2005; Atkinson and Gray, 2006; Huelsenbeck et al., 2001) or syntactic data (Barbac¸on et al., 2007) but with lists extracted from written corpus with comparable results (Rama and Singh, 2009; Singh and Surana, 2007). These techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of Figure 1: Phylogenetic tree using feature n-grams biological species. Constructing a phylogenetic tree for languages usually requires the calculation of distances between pairs of languages (usually based on word lists). These distances are then given as in</context>
</contexts>
<marker>Atkinson, Nicholls, Welch, Gray, 2005</marker>
<rawString>Q. Atkinson, G. Nicholls, D. Welch, and R. Gray. 2005. From words to dates: water into wine, mathemagic or phylogenetic inference? Transactions of the Philological Society, 103(2):193–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bird</author>
</authors>
<title>Natural language processing and linguistic fieldwork.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="852" citStr="Bird, 2009" startWordPosition="138" endWordPosition="139">and presents a few examples that call for a deeper engagement between the two fields. 1 Introduction The recent success of data-driven approaches in NLP has raised important questions as to what role linguistics must now seek to play in further advancing the field. Perhaps, it is also time to pose the same question from the other direction: As to how NLP techniques can help linguists make informed decisions? And how can the advances made in one field be applied to the other? Although, there has been some work on incorporating NLP techniques for linguistic fieldwork and language documentation (Bird, 2009), the wider use of NLP in linguistic studies is still fairly limited. However, it is possible to deepen the engagement between the two fields in a number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks. 2 Historical Linguistics and Linguistic Typology Computational techniques have been successfully used to classify languages and to generate phylogenetic trees. This has been tried not just with handcrafted word lists (Atkinson et al., 2005; Atkinson and Gray, 2006; Huelsenbeck et al., 2001) or</context>
</contexts>
<marker>Bird, 2009</marker>
<rawString>S. Bird. 2009. Natural language processing and linguistic fieldwork. Computational Linguistics, 35(3):469–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
</authors>
<title>The structure of complex predicates in Urdu. Center for the Study of Language and Information.</title>
<date>1995</date>
<contexts>
<context position="8371" citStr="Butt, 1995" startWordPosition="1316" endWordPosition="1317">eoreticians. Hence, there are always certain phenomena in languages which remain a point of discussion since satisfactory solutions are not available. The facts of a language are accounted for by applying various techniques and methods that are offered by a linguistic framework. For example, syntactic diagnostics have been a fairly reliable method of identifying/classifying construction types in languages. They work fairly well for most cases. But in some cases even these tests fail to classify certain elements. For example, Indian languages show a highly productive use of complex predicates (Butt, 1995; Butt, 2003). However, till date there are no satisfactory methods to decide when a noun verb sequence is a ‘complex predicate’ and when a ‘verb argument’ case. To quote an example from our experience while developing a Hindi Tree Bank, annotators had to be provided with guidelines to mark a N V sequence as a complex predicate based on some linguistic tests. However, there are instances when the native speaker/annotator is quite confident of a construction being a complex predicate, even though most syntactic tests might not apply to it. Although, various theories provide frames to classify l</context>
</contexts>
<marker>Butt, 1995</marker>
<rawString>M. Butt. 1995. The structure of complex predicates in Urdu. Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
</authors>
<title>The light verb jungle.</title>
<date>2003</date>
<booktitle>In Workshop on Multi-Verb Constructions. Citeseer.</booktitle>
<contexts>
<context position="8384" citStr="Butt, 2003" startWordPosition="1318" endWordPosition="1319"> Hence, there are always certain phenomena in languages which remain a point of discussion since satisfactory solutions are not available. The facts of a language are accounted for by applying various techniques and methods that are offered by a linguistic framework. For example, syntactic diagnostics have been a fairly reliable method of identifying/classifying construction types in languages. They work fairly well for most cases. But in some cases even these tests fail to classify certain elements. For example, Indian languages show a highly productive use of complex predicates (Butt, 1995; Butt, 2003). However, till date there are no satisfactory methods to decide when a noun verb sequence is a ‘complex predicate’ and when a ‘verb argument’ case. To quote an example from our experience while developing a Hindi Tree Bank, annotators had to be provided with guidelines to mark a N V sequence as a complex predicate based on some linguistic tests. However, there are instances when the native speaker/annotator is quite confident of a construction being a complex predicate, even though most syntactic tests might not apply to it. Although, various theories provide frames to classify linguistic pat</context>
</contexts>
<marker>Butt, 2003</marker>
<rawString>M. Butt. 2003. The light verb jungle. In Workshop on Multi-Verb Constructions. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Huelsenbeck</author>
<author>F Ronquist</author>
<author>R Nielsen</author>
<author>J P Bollback</author>
</authors>
<title>Bayesian inference of phylogeny and its impact on evolutionary biology.</title>
<date>2001</date>
<journal>Science,</journal>
<volume>294</volume>
<issue>5550</issue>
<contexts>
<context position="1449" citStr="Huelsenbeck et al., 2001" startWordPosition="233" endWordPosition="236">e documentation (Bird, 2009), the wider use of NLP in linguistic studies is still fairly limited. However, it is possible to deepen the engagement between the two fields in a number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks. 2 Historical Linguistics and Linguistic Typology Computational techniques have been successfully used to classify languages and to generate phylogenetic trees. This has been tried not just with handcrafted word lists (Atkinson et al., 2005; Atkinson and Gray, 2006; Huelsenbeck et al., 2001) or syntactic data (Barbac¸on et al., 2007) but with lists extracted from written corpus with comparable results (Rama and Singh, 2009; Singh and Surana, 2007). These techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of Figure 1: Phylogenetic tree using feature n-grams biological species. Constructing a phylogenetic tree for languages usually requires the calculation of distances between pairs of languages (usually based on word lists). These distances are then given as input to a computational phylogenetic algorithm. Their</context>
</contexts>
<marker>Huelsenbeck, Ronquist, Nielsen, Bollback, 2001</marker>
<rawString>J.P. Huelsenbeck, F. Ronquist, R. Nielsen, and J.P. Bollback. 2001. Bayesian inference of phylogeny and its impact on evolutionary biology. Science, 294(5550):2310–2314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Lavie</author>
<author>K Probst</author>
<author>E Peterson</author>
<author>S Vogel</author>
<author>L Levin</author>
<author>A Font-Llitjos</author>
<author>J Carbonell</author>
</authors>
<title>A trainable transfer-based machine translation approach for languages with limited resources.</title>
<date>2004</date>
<booktitle>In Proceedings of Workshop of the European Association for Machine Translation.</booktitle>
<publisher>Citeseer.</publisher>
<contexts>
<context position="5964" citStr="Lavie et al., 2004" startWordPosition="927" endWordPosition="930">es. Another insight comes from Machine Translation. More than any other sub-field in NLP, it is the data-driven approaches to machine translation that have proven to be particularly successful over the past few years. We have been exploring various approaches towards hybridization of our rulebased MT system. Building the transfer-grammar of such systems is perhaps one of the most timeintensive tasks that involves careful analysis of test data. However, data driven techniques can come to the aid of linguists in this case. The recent work on automatic acquisition of rules from parallel corpora (Lavie et al., 2004) can help identify a large number of common syntactic transformations across a pair of languages, and help unearth those transformations that might otherwise be missed by a rule-based grammar. They can be further used to prioritize the application of rules based on the observed frequencies of certain syntactic transformations. 5 NLP Tools and Linguistics NLP techniques draw features from annotated corpora which are a rich linguistic resource. However, these corpora can also be used to extract grammars, which on one hand feed the parser with features (Xia, 2001), and on the other, act as a reso</context>
</contexts>
<marker>Lavie, Probst, Peterson, Vogel, Levin, Font-Llitjos, Carbonell, 2004</marker>
<rawString>A. Lavie, K. Probst, E. Peterson, S. Vogel, L. Levin, A. Font-Llitjos, and J. Carbonell. 2004. A trainable transfer-based machine translation approach for languages with limited resources. In Proceedings of Workshop of the European Association for Machine Translation. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taraka Rama</author>
<author>Anil Kumar Singh</author>
</authors>
<title>From bag of languages to family trees from noisy corpus.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Recent Advances in Natural Language Processing,</booktitle>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="1583" citStr="Rama and Singh, 2009" startWordPosition="255" endWordPosition="258">agement between the two fields in a number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks. 2 Historical Linguistics and Linguistic Typology Computational techniques have been successfully used to classify languages and to generate phylogenetic trees. This has been tried not just with handcrafted word lists (Atkinson et al., 2005; Atkinson and Gray, 2006; Huelsenbeck et al., 2001) or syntactic data (Barbac¸on et al., 2007) but with lists extracted from written corpus with comparable results (Rama and Singh, 2009; Singh and Surana, 2007). These techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of Figure 1: Phylogenetic tree using feature n-grams biological species. Constructing a phylogenetic tree for languages usually requires the calculation of distances between pairs of languages (usually based on word lists). These distances are then given as input to a computational phylogenetic algorithm. Their successful use for languages has opened the possibility of using computational techniques for studying historical linguistics. They h</context>
</contexts>
<marker>Rama, Singh, 2009</marker>
<rawString>Taraka Rama and Anil Kumar Singh. 2009. From bag of languages to family trees from noisy corpus. In Proceedings of the Conference on Recent Advances in Natural Language Processing, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Robinson</author>
<author>Nick Ellis</author>
</authors>
<date>2008</date>
<booktitle>Handbook of Cognitive Linguistics and Second Language Acquisition.</booktitle>
<location>Routledge, New York and London.</location>
<contexts>
<context position="3307" citStr="Robinson and Ellis, 2008" startWordPosition="511" endWordPosition="515">n brief, the typology of linguistic similarity for computational purposes is related to linguistic levels (depth), differences among languages (linguality) and linguistic units (granularity). Thus, language can be seen as a system of symbols whose meanings are defined 18 Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 18–21, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics in terms of their estimated similarity and distance with other symbols. Can this, together with what Cognitive Linguists have been studying (Robinson and Ellis, 2008), which also involves linguistic similarity, often directly, have some relevance for linguists? 3 Lexical Correspondence and Linguistic Units A further case in point is lexical correspondence across languages, which poses a problem for cross-lingual and multilingual applications. To address this and some other issues, a linguistic unit that behaves similarly across languages can be conceptualized. Such a unit, may include morphological variation (inflectional and derivational), compounds, multi word expressions etc. as in the Hindi and Telugu examples below: • Single token content words: raama</context>
</contexts>
<marker>Robinson, Ellis, 2008</marker>
<rawString>Peter Robinson and Nick Ellis. 2008. Handbook of Cognitive Linguistics and Second Language Acquisition. Routledge, New York and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil Kumar Singh</author>
<author>Harshit Surana</author>
</authors>
<title>Can corpus based measures be used for comparative study of languages?</title>
<date>2007</date>
<booktitle>In Proceedings of the Ninth Meeting ofACL Special Interest Group on Computational Phonology and Morphology,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1608" citStr="Singh and Surana, 2007" startWordPosition="259" endWordPosition="262">o fields in a number of possible areas (as we shall see in the following sections), and gain new insights even during the formulation of linguistic theories and frameworks. 2 Historical Linguistics and Linguistic Typology Computational techniques have been successfully used to classify languages and to generate phylogenetic trees. This has been tried not just with handcrafted word lists (Atkinson et al., 2005; Atkinson and Gray, 2006; Huelsenbeck et al., 2001) or syntactic data (Barbac¸on et al., 2007) but with lists extracted from written corpus with comparable results (Rama and Singh, 2009; Singh and Surana, 2007). These techniques are inspired from the work in computational phylogenetics, which was aimed at constructing evolutionary trees of Figure 1: Phylogenetic tree using feature n-grams biological species. Constructing a phylogenetic tree for languages usually requires the calculation of distances between pairs of languages (usually based on word lists). These distances are then given as input to a computational phylogenetic algorithm. Their successful use for languages has opened the possibility of using computational techniques for studying historical linguistics. They have already been used for</context>
</contexts>
<marker>Singh, Surana, 2007</marker>
<rawString>Anil Kumar Singh and Harshit Surana. 2007. Can corpus based measures be used for comparative study of languages? In Proceedings of the Ninth Meeting ofACL Special Interest Group on Computational Phonology and Morphology, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anil Kumar Singh</author>
</authors>
<title>Modeling and Application of Linguistic Similarity.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>IIIT, Hyderabad, India.</institution>
<contexts>
<context position="2679" citStr="Singh, 2010" startWordPosition="422" endWordPosition="423">r languages has opened the possibility of using computational techniques for studying historical linguistics. They have already been used for estimating divergence times of language families (Atkinson et al., 2005). Figure 1 shows a phylogenetic tree created using feature n-grams (Rama and Singh, 2009). Another area for the application of NLP techniques is language typology. For example, linguistic similarity and its estimation can be seen as fundamental ideas in NLP. The systematic study of different kinds of linguistic similarity offers insights towards the theoretical studies of languages (Singh, 2010). In brief, the typology of linguistic similarity for computational purposes is related to linguistic levels (depth), differences among languages (linguality) and linguistic units (granularity). Thus, language can be seen as a system of symbols whose meanings are defined 18 Proceedings of the 2010 Workshop on NLP and Linguistics: Finding the Common Ground, ACL 2010, pages 18–21, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics in terms of their estimated similarity and distance with other symbols. Can this, together with what Cognitive Linguists have been studyin</context>
<context position="4767" citStr="Singh, 2010" startWordPosition="724" endWordPosition="725"> (TAM) markers: karnaa-caahiye, cayiyaalii (should do); ho sakataa thaa, ayyiyedemo (could have happened) etc. • Multi word expressions such as idioms, phrasal verbs and ‘frozen expressions’: pahaaD toDanaa (breaking mountains); muNha ki khaana (getting defeated) etc. • Compounds: jaati-prathaa (caste system); vesh-bhuushaaoN (dresses); akkaDaaikkaDaa (here and there) etc. This unit might, among other things, form the basis of the structure of lexical resources, such that these resources have a direct correspondence across languages. This can further facilitate comparative study of languages (Singh, 2010). 4 Applications Computational techniques can also be used to design tools and material for language learning and teaching. Here games can play a useful role. Although, a large number of online games are available, most of them do not use the latest language processing techniques. Games can also be used to generate language resources. The core idea in Human Computation (Von Ahn, 2005) is that computers should do what they do best and that humans seamlessly work with them to do what computers cannot. One of the ways to merge the two is in the form of carefully designed games. Another insight co</context>
</contexts>
<marker>Singh, 2010</marker>
<rawString>Anil Kumar Singh. 2010. Modeling and Application of Linguistic Similarity. Ph.D. thesis, IIIT, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luis Von Ahn</author>
</authors>
<title>Human computation.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<publisher>Adviser-Blum, Manuel.</publisher>
<location>Pittsburgh, PA, USA.</location>
<marker>Von Ahn, 2005</marker>
<rawString>Luis Von Ahn. 2005. Human computation. Ph.D. thesis, Pittsburgh, PA, USA. Adviser-Blum, Manuel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
</authors>
<title>Automatic Grammar Generation from Two Different Perspectives.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="6531" citStr="Xia, 2001" startWordPosition="1023" endWordPosition="1024"> from parallel corpora (Lavie et al., 2004) can help identify a large number of common syntactic transformations across a pair of languages, and help unearth those transformations that might otherwise be missed by a rule-based grammar. They can be further used to prioritize the application of rules based on the observed frequencies of certain syntactic transformations. 5 NLP Tools and Linguistics NLP techniques draw features from annotated corpora which are a rich linguistic resource. However, these corpora can also be used to extract grammars, which on one hand feed the parser with features (Xia, 2001), and on the other, act as a resource for linguistic studies. For example, in Hindi dependency parsing the use of vibhakti (post-positions) and TAM labels has proven to be particularly useful even in the absence of large amounts of annotated corpora (Ambati et al., 2010). This also helped bring to light those features of the grammar that govern certain structure choices and brought to notice some previously overlooked linguistic constructions. Thus, the result is an iterative process, where both the grammar and the features are refined. Discourse Processing is another rapidly emerging research</context>
</contexts>
<marker>Xia, 2001</marker>
<rawString>Fei Xia. 2001. Automatic Grammar Generation from Two Different Perspectives. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>