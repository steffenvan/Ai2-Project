<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005640">
<title confidence="0.986249">
Adding semantic role annotation to a corpus of written Dutch
</title>
<author confidence="0.996855">
Paola Monachesi, Gerwert Stevens and Jantine Trapman
</author>
<affiliation confidence="0.994854">
Utrecht University, Uil-OTS, Trans 10, 3512 JK Utrecht, The Netherlands
</affiliation>
<email confidence="0.98406">
{Paola.Monachesi, Gerwert.Stevens, Jantine.Trapman}@let.uu.nl
</email>
<sectionHeader confidence="0.995502" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979882352941">
We present an approach to automatic se-
mantic role labeling (SRL) carried out in
the context of the Dutch Language Corpus
Initiative (D-Coi) project. Adapting ear-
lier research which has mainly focused on
English to the Dutch situation poses an in-
teresting challenge especially because there
is no semantically annotated Dutch corpus
available that can be used as training data.
Our automatic SRL approach consists of
three steps: bootstrapping from a syntacti-
cally annotated corpus by means of a rule-
based tagger developed for this purpose,
manual correction on the basis of the Prop-
Bank guidelines which have been adapted to
Dutch and training a machine learning sys-
tem on the manually corrected data.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998944">
The creation of semantically annotated corpora has
lagged dramatically behind. As a result, the need for
such resources has now become urgent. Several ini-
tiatives have been launched at the international level
in the last years, however, they have focused almost
entirely on English and not much attention has been
dedicated to the creation of semantically annotated
Dutch corpora.
Within the Dutch Language Corpus Initiative (D-
Coi)1, a recently completed Dutch project, guide-
lines have been developed for the annotation of a
Dutch written corpus. In particular, a pilot corpus
</bodyText>
<footnote confidence="0.983965">
1http://lands.let.ru.nl/projects/d-coi/
</footnote>
<page confidence="0.995057">
77
</page>
<bodyText confidence="0.999827794117647">
has been compiled, parts of which have been en-
riched with (verified) linguistic annotations.
One of the innovative aspects of the D-Coi project
with respect to previous initiatives, such as the Spo-
ken Dutch Corpus (CGN - Corpus Gesproken Ned-
erlands) (Oostdijk, 2002), was the development of a
protocol for a semantic annotation layer. In particu-
lar, two types of semantic annotation have been ad-
dressed, that is semantic role assignment and tempo-
ral and spatial semantics (Schuurman and Monach-
esi, 2006). The reason for this choice lies in the fact
that semantic role assignment (i.e. the semantic rela-
tionships identified between items in the text such as
the agents or patients of particular actions), is one of
the most attested and feasible types of semantic an-
notation within corpora. On the other hand, tempo-
ral and spatial annotation was chosen because there
is a clear need for such a layer of annotation in ap-
plications like information retrieval or question an-
swering.
The focus of this paper is on semantic role an-
notation. We analyze the choices we have made
in selecting an appropriate annotation protocol by
taking into consideration existing initiatives such
as FrameNet (Johnson et al., 2002) and PropBank
(Kingsbury et al., 2002) (cf. also the Chinese and
Arabic PropBank). We motivate our choice for the
PropBank annotation scheme on the basis of the
promising results with respect to automatic seman-
tic role labeling (SRL) which have been obtained for
English. Furthermore, we discuss how the SRL re-
search could be adapted to the Dutch situation given
that no semantically annotated corpus was available
that could be used as training data.
</bodyText>
<note confidence="0.76494">
Proceedings of the Linguistic Annotation Workshop, pages 77–84,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.926942" genericHeader="method">
2 Existing projects
</sectionHeader>
<bodyText confidence="0.998171902777778">
During the last few years, corpora enriched with se-
mantic role information have received much atten-
tion, since they offer rich data both for empirical in-
vestigations in lexical semantics and large-scale lex-
ical acquisition for NLP and Semantic Web applica-
tions. Several initiatives are emerging at the inter-
national level to develop annotation systems of ar-
gument structure. Within our project we have tried
to exploit existing results as much as possible and
to set the basis for a common standard. We want
to profit from earlier experiences and contribute to
existing work by making it more complete with our
own (language specific) contribution given that most
resources have been developed for English.
The PropBank and FrameNet projects have been
evaluated in order to assess whether the approach
and the methodology they have developed for the
annotation of semantic roles could be adopted for
our purposes. Given the results they have achieved,
we have taken their insights and experiences as our
starting point.
FrameNet reaches a level of granularity in the
specification of the semantic roles which might
be desirable for certain applications (i.e. Ques-
tion Answering). Moreover, the predicates are
linked to an underlying frame ontology that clas-
sifies the verbs within a semantic hierarchy. On
the other hand, despite the relevant work of
Gildea and Jurafsky (2002), it is still an open
issue whether FrameNet classes and frame ele-
ments can be obtained and used automatically be-
cause of the richness of the semantic structures em-
ployed (Dzikovska et al., 2004). Furthermore, the
FrameNet approach might raise problems with re-
spect to uniformity of role labeling even if human
annotators are involved. Incompleteness, however,
constitutes the biggest problem, i.e. several frames
and relations among frames are missing mainly be-
cause FrameNet is still under development. Adopt-
ing the FrameNet lexicon for semantic annotation
means contributing to its development with the ad-
dition of (language specific) and missing frames.
In our study, we have assumed that the FrameNet
classification even though it is based on English
could be applicable to Dutch as well. This as-
sumption is supported by the fact that the German
project Saarbr¨ucken Lexical Semantics Annotation
and analysis (SALSA) (K. Erk and Pinkal, 2003)
has adopted FrameNet with good results. Although
Dutch and English are quite similar, there are differ-
ences on both sides. For example, in the case of the
Spanish FrameNet it turned out that frames may dif-
fer in their number of elements across languages (cf.
(Subirats and Sato, 2004)).
The other alternative was to employ the Prop-
Bank approach which has the advantage of provid-
ing clear role labels and thus a transparent anno-
tation for both annotators and users. Furthermore,
there are promising results with respect to automatic
semantic role labeling for English thus the annota-
tion process could be at least semi-automatic. A dis-
advantage of this approach is that we would have to
give up the classification of frames in an ontology,
as is the case in FrameNet, which could be very use-
ful for certain applications, especially those related
to the Semantic Web. However, in (Monachesi and
Trapman, 2006) suggestions are given on how the
two approaches could be reconciled.
The prospect of semi-automatic annotation was
the decisive factor in the decision to adopt the Prop-
Bank approach for the annotation of semantic roles
within the D-Coi project.
</bodyText>
<sectionHeader confidence="0.9439285" genericHeader="method">
3 Automatic SRL: bootstrapping a corpus
with semantic roles
</sectionHeader>
<bodyText confidence="0.999438777777778">
Ever since the pioneering article of Gildea and Ju-
rafsky (2002), there has been an increasing inter-
est in automatic semantic role labeling (SRL). How-
ever, previous research has focused mainly on En-
glish. Adapting earlier research to the Dutch situ-
ation poses an interesting challenge especially be-
cause there is no semantically annotated Dutch cor-
pus available that can be used as training data. Fur-
thermore, no PropBank frame files for Dutch exist.
To solve the problem of the unavailability of train-
ing data, we have developed a rule-based tagger to
bootstrap a syntactically annotated corpus with se-
mantic roles. After manual correction, this corpus
was used as training data for a machine learning
SRL system. The input data for our SRL approach
consists of Dutch sentences, syntactically annotated
by the Dutch dependency parser Alpino (Bouma et
al., 2000).
</bodyText>
<page confidence="0.996771">
78
</page>
<bodyText confidence="0.999843644444445">
Syntactic annotation of our corpus is based on the
Spoken Dutch Corpus (CGN) dependency graphs
(Moortgat et al., 2000). A CGN dependency graph
is a tree-structured directed acyclic graph in which
nodes and edges are labeled with respectively c-
labels (category-labels) and d-labels (dependency
labels). C-labels of nodes denote phrasal categories,
such as NP (noun phrase) and PP, c-labels of leafs
denote POS tags. D-Labels describe the grammati-
cal (dependency) relation between the node and its
head. Examples of such relations are SU (subject),
OBJ (direct object) and MOD (modifier).
Intuitively, dependency structures are a great re-
source for a rule-based semantic tagger, for they di-
rectly encode the argument structure of lexical units,
e.g. the relation between constituents. Our goal was
to make optimal use of this information in an au-
tomatic SRL system. In order to achieve this, we
first defined a basic mapping between nodes in a
dependency graph and PropBank roles. This map-
ping forms the basis of our rule-based SRL system
(Stevens, 2006).
Mapping subject and object complements to
PropBank arguments is straightforward: subjects are
mapped to ARG0 (proto-typical agent), direct ob-
jects to ARG1 (proto-typical patient) and indirect ob-
jects to ARG2. An exception is made for ergatives
and passives, for which the subject is labeled with
ARG1.
Devising a consistent mapping for higher num-
bered arguments is more difficult, since their label-
ing depends in general on the frame entry of the
corresponding predicate. Since we could not use
frame information, we used a heuristic method. This
heuristic strategy entails that after numbering sub-
ject/object complements with the rules stated above,
other complements are labeled in a left-to-right or-
der, starting with the first available argument num-
ber. For example, if the subject is labeled with
ARG0 and there are no object complements, the first
available argument number is ARG1.
Finally, a mapping for several types of modifiers
was defined. We refrained from the disambiguation
task, and concentrated on those modifiers that can be
mapped consistently. These modifiers are:
</bodyText>
<listItem confidence="0.965953076923077">
• ArgM-NEG -Negation markers.
• ArgM-REC - Reflexives and reciprocals.
• ArgM-PRD - Markers of secondary predi-
cation: modifiers with the dependency label
PREDM
• ArgM-PNC - Purpose clauses: modifiers that
start with om te . These modifiers are marked
by Alpino with the c-label OTI.
• ArgM-LOC - Locative modifiers: modifiers
with the dependency label LD, the LD label is
used by Alpino to mark modifiers that indicate
a location of direction.
4 XARA: a rule based SRL tagger
</listItem>
<bodyText confidence="0.99985621875">
With the help of the mappings discussed above, we
developed a rule-based semantic role tagger, which
is able to bootstrap an unannotated corpus with se-
mantic roles. We used this rule-based tagger to re-
duce the manual annotation effort. After all, starting
manual annotation from scratch is time consuming
and therefore expensive. A possible solution is to
start from a (partially) automatically annotated cor-
pus.
The system we developed for this purpose is
called XARA (XML-based Automatic Role-labeler
for Alpino-trees) (Stevens, 2006). 2 XARA is
written in Java, the cornerstone of its rule-based
approach is formed by XPath expressions; XPath
(Clark and DeRose, 1999) is a powerful query lan-
guage for the XML format.
The corpus format we used in our experiments is
the Alpino XML format. This format is designed to
support a range of linguistic queries on the depen-
dency trees in XPath directly (Bouma and Kloost-
erman, 2002). The structure of Alpino XML doc-
uments directly corresponds to the structure of the
dependency tree: dependency nodes are represented
by NODE elements, attributes of the node elements
are the properties of the corresponding dependency
node, e.g. c-label, d-label, pos-tag, lemma, etc.
A rule in XARA consist of an XPath expression
that addresses a node in the dependency tree, and a
target label for that node, i.e. a rule is a (path,label)
pair. For example, a rule that selects direct object
nodes and labels them with ARG1 can be formulated
as:
</bodyText>
<footnote confidence="0.833154333333333">
(//node[@rel=’obj1’], 1)
2The system is available at:
http://www.let.uu.nl/∼Paola.Monachesi/personal/dcoi/index.html
</footnote>
<page confidence="0.998099">
79
</page>
<bodyText confidence="0.939389538461538">
In this example, a numeric label is used to label a
numbered argument. For ARGMs, string value can
be used as target label.
After their definition, rules can be applied to local
dependency domains, i.e. subtrees of a dependency
tree. The local dependency domain to which a rule
is applied, is called the rule’s context. A context is
defined by an XPath expression that selects a group
of nodes. Contexts for which we defined rules in
XARA are verbal domains, that is, local dependency
structures with a verb as head.
Table 1 shows the performance of XARA on our
treebank.
</bodyText>
<tableCaption confidence="0.999775">
Table 1: Results of SRL with XARA
</tableCaption>
<table confidence="0.999892083333333">
Label Precision Recall F,a—i
Overall 65,11% 45,83% 53,80
Arg0 98.97% 94.95% 96.92
Arg1 70.08% 64.83% 67.35
Arg2 47.41% 36.07% 40.97
Arg3 13.89% 6.85% 9.17
Arg4 1.56% 1.35% 1.45
ArgM-LOC 83.49% 13.75% 23.61
ArgM-NEG 72.79% 58.79% 65.05
ArgM-PNC 91.94% 39.31% 55.07
ArgM-PRD 63.64% 26.25% 37.17
ArgM-REC 85.19% 69.70% 76.67
</table>
<bodyText confidence="0.99703675">
Notice XARA’s performance on highered num-
bered arguments, especially ARG4. Manual inspec-
tion of the manual labeling reveals that ARG4 argu-
ments often occur in propositions without ARG2 and
ARG3 arguments. Since our current heuristic label-
ing method always chooses the first available argu-
ment number, this method will have to be modified
in order achieve a better score for ARG4 arguments.
</bodyText>
<sectionHeader confidence="0.991186" genericHeader="method">
5 Manual correction
</sectionHeader>
<bodyText confidence="0.999986166666667">
The annotation by XARA of our tree bank, was
manually corrected by one human annotator, how-
ever, in order to deal with a Dutch corpus, the Prop-
Bank annotation guidelines needed to be revised.
Notice that both PropBank and D-Coi share the
assumption that consistent argument labels should
be provided across different realizations of the same
verb and that modifiers of the verb should be as-
signed functional tags. However, they adopt a dif-
ferent approach with respect to the treatment of
traces since PropBank creates co-reference chains
for empty categories while within D-coi, empty cat-
egories are almost non existent and in those few
cases in which they are attested, a coindexation has
been established already at the syntactic level. Fur-
thermore, D-coi assumes dependency structures for
the syntactic representation of its sentences while
PropBank employs phrase structure trees. In addi-
tion, Dutch behaves differently from English with
respect to certain constructions and these differences
should be spelled out.
In order to annotate our corpus, the PropBank
guidelines needed a revision because they have been
developed for English and to add a semantic layer
to the Penn TreeBank. Besides the adaption (and
extension) of the guidelines to Dutch (Trapman and
Monachesi, 2006), we also have to consider a Dutch
version of the PropBank frameindex. In PropBank,
frame files provide a verb specific description of all
possible semantic roles and illustrate these roles by
examples. The lack of example sentences makes
consistent annotation difficult. Since defining a set
of frame files from scratch is very time consuming,
we decided to attempt an alternative approach, in
which we annotated Dutch verbs with the same ar-
gument structure as their English counterparts, thus
use English frame files instead of creating Dutch
ones. Although this causes some problems, for ex-
ample, not all Dutch verbs can be translated to a
100% equivalent English counterpart, such prob-
lems proved to be relatively rare. In most cases ap-
plying the PropBank argument structure to Dutch
verbs was straightforward. If translation was not
possible, an ad hoc decision was made on how to
label the verb.
In order to verify the correctness of the annota-
tion carried out automatically by XARA, we have
proceeded in the following way:
</bodyText>
<listItem confidence="0.995317">
1. localize the verb and translate it to English;
only the argument structure of verbs is consid-
ered in our annotation while that of NPs, PPs
and other constituents has been neglected for
the moment.
2. check the verb’s frames file in Prop-
Bank; the appropriate roles for each
</listItem>
<page confidence="0.995171">
80
</page>
<bodyText confidence="0.996776">
verb could be identified in PropBank
(http://verbs.colorado.edu/framesets/).
</bodyText>
<listItem confidence="0.78177975">
3. localize the arguments of the verb; arguments
are usually NPs, PPs and sentential comple-
ments.
4. localize the modifiers; in addition to the argu-
</listItem>
<bodyText confidence="0.983365675675676">
ments of a verb, modifiers of place, time, man-
ner etc. are marked as well.
An appropriate tool has been selected to carry out
the manual correction. We have made an investiga-
tion to evaluate three different tools for this purpose:
CLaRK3, Salto4 and TrEd5. On the basis of our main
requirements, that is whether the tool is able to han-
dle the xml-structure we have adopted and whether
it provides a user-friendly graphical interface and we
have come to the conclusion that the TrEd tool was
the most appropriate for our needs.
During the manual correction process, some prob-
lems have emerged, as for example the fact that
we have encountered some phenomena, such as the
interpretation of modifiers, for which linguistic re-
search doesn’t provide a standard solution yet, we
have discarded these cases for the moment but it
would be desirable to address them in the future.
Furthermore, the interaction among levels should
be taken more into consideration. Even though the
Alpino parser has an accuracy on our corpus of
81%−90% (van Noord, 2006) and the syntactic cor-
pus which has been employed for the annotation of
the semantic roles had been manually corrected, we
have encountered examples in which the annotation
provided by the syntactic parser was not appropri-
ate. This is the case of a PP which was labeled as
modifier by the syntactic parser but which should
be labeled as argument according to the PropBank
guidelines. There should thus be an agreement in
these cases so that the syntactic structure can be cor-
rected. Furthermore, we have encountered problems
with respect to PP attachment, that is the syntactic
representation gives us correct and incorrect struc-
tures and at the semantic level we are able to disam-
biguate. More research is necessary about how to
deal with the incorrect representations.
</bodyText>
<footnote confidence="0.999959333333333">
3http://www.bultreebank.org/clark/index.html
4http://www.coli.uni-saarland.de/projects/salsa/
5http://ufal.mff.cuni.cz/ pajas/tred/
</footnote>
<sectionHeader confidence="0.958906" genericHeader="method">
6 The TiMBL classification system
</sectionHeader>
<bodyText confidence="0.999825448275862">
The manually corrected sentences have been used
as training and test data for an SRL classification
system. For this learning system we have em-
ployed a Memory Based Learning (MBL) approach,
implemented in the Tilburg Memory based learner
(TiMBL) (Daelemans et al., 2004).
TiMBL assigns class labels to training instances
on the basis of features and the feature set plays
an important role in the performance of a classi-
fier. In choosing the feature set for our system, we
mainly looked at previous research, especially sys-
tems that participated in the 2004 and 2005 CoNLL
shared tasks on semantic role labeling (Carreras and
M`arquez, 2005).
It is worth noting that none of the systems in the
CoNLL shared tasks used features extracted from
dependency structures. However, we encountered
one system (Hacioglu, 2004) that did not participate
in the CoNLL-shared task but did use the same data
and was based on dependency structures. The main
difference with our system is that Hacioglu did not
use a dependency parser to create the dependency
trees, instead existing constituent trees were con-
verted to dependency structures. Furthermore, the
system was trained and tested on English sentences.
From features used in previous systems and some
experimentation with TiMBL, we derived the fol-
lowing feature set. The first group of features de-
scribes the predicate (verb):
</bodyText>
<listItem confidence="0.9962025">
(1) Predicate stem - The verb stem, provided by
Alpino.
(2) Predicate voice - A binary feature indicating
the voice of the predicate (passive/active).
</listItem>
<bodyText confidence="0.576677">
The second group of features describes the candi-
date argument:
</bodyText>
<listItem confidence="0.998960777777778">
(3) Argument c-label - The category label (phrasal
tag) of the node, e.g. NP or PP.
(4) Argument d-label - The dependency label of
the node, e.g. MOD or SU.
(5) Argument POS-tag - POS tag of the node if the
node is a leaf node, null otherwise.
(6) Argument head-word - The head word of the
relation if the node is an internal node or the
lexical item (word) if it is a leaf.
</listItem>
<page confidence="0.931056">
81
</page>
<listItem confidence="0.92396">
(7) Argument head-word - The head word of the
relation if the node is an internal node or the
lexical item (word) if it is a leaf.
(8) Head-word POS tag - The POS tag of the head
word.
(9) c-label pattern of argument - The left to right
chain of c-labels of the argument and its sib-
lings.
(10) d-label pattern - The left to right chain of d-
labels of the argument and its siblings.
(11) c-label &amp; d-label of argument combined -
The c-label of the argument concatenated with
its d-label.
</listItem>
<bodyText confidence="0.9999714">
The training set consists of predicate/argument
pairs encoded in training instances. Each instance
contains features of a predicate and its candidate
argument. Candidate arguments are nodes (con-
stituents) in the dependency tree. This pair-wise
approach is analogous to earlier work by van den
Bosch et al. (2004) and Tjong Kim Sang et al. (2005)
in which instances were build from verb/phrase pairs
from which the phrase parent is an ancestor of the
verb. We adopted their approach to dependency
trees: only siblings of the verb (predicate) are con-
sidered as candidate arguments.
In comparison to experiments in earlier work, we
had relatively few training data available: our train-
ing corpus consisted of 2,395 sentences which com-
prise 3066 verbs, 5271 arguments and 3810 modi-
fiers.6 To overcome our data sparsity problem, we
trained the classifier using the leave one out (LOO)
method (-t leave_one_out option in TiMBL).
With this option set, every data item in turn is se-
lected once as a test item, and the classifier is trained
on all remaining items. Except for the LOO op-
tion, we only used the default TiMBL settings dur-
ing training, to prevent overfitting because of data
sparsity.
</bodyText>
<sectionHeader confidence="0.998432" genericHeader="evaluation">
7 Results &amp; Evaluation
</sectionHeader>
<bodyText confidence="0.999183666666667">
Table 2 shows the performance of the TiMBL clas-
sifier on our annotated dependency treebank. From
these sentences, 12,113 instances were extracted. To
</bodyText>
<footnote confidence="0.920386">
6We refer to (Oostdijk and Boves, 2006) for general infor-
mation about the domain of the D-Coi corpus and its design.
</footnote>
<bodyText confidence="0.999472333333333">
measure the performance of the systems, the auto-
matically assigned labels were compared to the la-
bels assigned by a human annotator.
</bodyText>
<tableCaption confidence="0.997009">
Table 2: Results of TiMBL classification
</tableCaption>
<table confidence="0.999795105263158">
Label Precision Recall F&apos;3=1
Overall 70.27% 70.59% 70.43
Arg0 90.44% 86.82% 88.59
Arg1 87.80% 84.63% 86.18
Arg2 63.34% 59.10% 61.15
Arg3 21.21% 19.18% 20.14
Arg4 54.05% 54.05% 54.05
ArgM-ADV 54.98% 51.85% 53.37
ArgM-CAU 47.24% 43.26% 45.16
ArgM-DIR 36.36% 33.33% 34.78
ArgM-DIS 74.27% 70.71% 72.45
ArgM-EXT 29.89% 28.57% 29.21
ArgM-LOC 57.95% 54.53% 56.19
ArgM-MNR 52.07% 47.57% 49.72
ArgM-NEG 68.00% 65.38% 66.67
ArgM-PNC 68.61% 64.83% 66.67
ArgM-PRD 45.45% 40.63% 42.90
ArgM-REC 86.15% 84.85% 85.50
ArgM-TMP 55.95% 53.29% 54.58
</table>
<bodyText confidence="0.999854818181818">
It is difficult to compare our results with those
obtained with other existing systems, since our sys-
tem is the first one to be applied to Dutch sentences.
Moreover, our data format, data size and evalua-
tion methods (separate test/train/develop sets ver-
sus LOO) are different from earlier research. How-
ever, to put our results somewhat in perspective, we
looked mainly at systems that participated in the
CoNLL shared tasks on semantic role labeling.
The best performing system that participated in
CoNLL 2005 reached an F1 of 80. There were seven
systems with an F1 performance in the 75-78 range,
seven more with performances in the 70-75 range
and five with a performance between 65 and 70 (Car-
reras and M`arquez, 2005).
A system that did not participate in the CoNLL
task, but still provides interesting material for com-
parison since it is also based on dependency struc-
tures, is the system by Hacioglu (2004). This system
scored 85,6% precision, 83,6% recall and 84,6 F1 on
the CoNLL data set, which is even higher than the
best results published so far on the PropBank data
</bodyText>
<page confidence="0.995532">
82
</page>
<bodyText confidence="0.999963102564103">
sets (Pradhan et al., 2005): 84% precision, 75% re-
call and 79 Fl. These results support our claim that
dependency structures can be very useful in the SRL
task.
As one would expect, the overall precision and
recall scores of the classifier are higher than those
of the XARA rule-based system. Yet, we expected
a better performance of the classifier on the lower
numbered arguments (ARG0 and ARG1). Our hy-
pothesis is that performance on these arguments can
be improved by by adding semantic features to our
feature set.
Examples of such features are the subcategoriza-
tion frame of the predicate and the semantic category
(e.g. WordNet synset) of the candidate argument.
We expect that such semantic features will improve
the performance of the classifier for certain types of
verbs and arguments, especially the lower numbered
arguments ARG0 and ARG1 and temporal and spa-
tial modifiers. For example, the Dutch preposition
over can either head a phrase indicating a location
or a time-span. The semantic category of the neigh-
boring noun phrase might be helpful in such cases to
choose the right PropBank label. Thanks to new lex-
ical resources, such as Cornetto (Vossen, 2006), and
clustering techniques based on dependency struc-
tures (van de Cruys, 2005), we might be able to add
lexical semantic information about noun phrases in
future research.
Performance of the classifier can also be im-
proved by automatically optimizing the feature set.
The optimal set of features for a classifier can
be found by employing bi-directional hill climbing
(van den Bosch et al., 2004). There is a wrapper
script (Paramsearch) available that can be used with
TiMBL and several other learning systems that im-
plements this approach7. In addition, iterative deep-
ening (ID) can be used as a heuristic way of finding
the optimal algorithm parameters for TiMBL.
</bodyText>
<sectionHeader confidence="0.998505" genericHeader="conclusions">
8 Conclusions &amp; Future work
</sectionHeader>
<bodyText confidence="0.9998794">
We have presented an approach to automatic seman-
tic role labeling based on three steps: bootstrapping
from a syntactically annotated Dutch corpus with a
rule-based tagger developed for this purpose, man-
ual correction and training a machine learning sys-
</bodyText>
<footnote confidence="0.860516">
7URL: http://ilk.uvt.nl/software.html#paramsearch
</footnote>
<bodyText confidence="0.999637464285714">
tem on the manually corrected data.
The promising results in this area obtained for En-
glish on the basis of PropBank role labels was a de-
cisive factor for our choice to adopt the PropBank
annotation scheme which has been adapted for the
annotation of the Dutch corpus. However, we would
like to adopt the conceptual structure of FrameNet,
even though not necessarily the granularity of its
role assignment approach, to this end we are link-
ing manually the predicates annotated with the Prop-
Bank semantic roles to the FrameNet ontology.
Only a small part of the D-Coi corpus has been an-
notated with semantic information, in order to yield
information with respect to its feasibility. We be-
lieve that a more substantial annotation task will be
carried out in the framework of a follow-up project
aiming at the construction of a 500 million word cor-
pus, in which one million words will be annotated
with semantic information. Hopefully, in the follow-
up project, it will be possible to carry out experi-
ments and measure inter-annotator agreement since
due to financial constraints only one annotator has
annotated the current corpus.
Finally, it would be interesting to see how the
classifier would perform on larger collections and
new genres of data. The follow-up of the D-Coi
project will provide new semantically annotated data
to facilitate research in this area.
</bodyText>
<sectionHeader confidence="0.998579" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999182777777778">
G. Bouma and G. Kloosterman. 2002. Querying depen-
dency treebanks in xml. In Proceedings of the Third
international conference on Language Resources and
Evaluation (LREC). Gran Canaria.
G. Bouma, G. van Noord, and R. Malouf. 2000. Alpino:
wide-coverage computational analysis of dutch.
X. Carreras and L. M`arquez. 2005. Introduction to
the conll-2005 shared task: Semantic role labeling.
In Proceedings of the Eighth Conference on Compu-
tational Natural Language Learning (CoNLL-2005).
Boston, MA, USA.
J. Clark and S. DeRose. 1999. Xml path language
(xpath). W3C Recommendation 16 November 1999.
URL: http://www.w3.org/TR/xpath.
D. Daelemans, D. Zavrel, K. van der Sloot, and
A. van den Bosch. 2004. Timbl: Tilburg memory
based learner, version 5.1, reference guide. ILK Tech-
nical Report Series 04-02, Tilburg University.
</reference>
<page confidence="0.986049">
83
</page>
<reference confidence="0.999208666666667">
M. Dzikovska, M. Swift, and J. Allen. 2004. Building
a computational lexicon and ontology with framenet.
In Proceedings of the workshop Building Lexi-
cal Resources with Semantically Annotated Corpora
(LREC) 2004. Lisbon.
D. Gildea and D. Jurafsky. 2002. Automatic labeling of
semantic roles. Comput. Linguist., 28(3):245–288.
K. Hacioglu. 2004. Semantic role labeling using de-
pendency trees. In COLING ’04: Proceedings of the
20th international conference on Computational Lin-
guistics, page 1273. August 2004.
C. R. Johnson, C. J. Fillmore, M. R. L. Petruck, C. F.
Baker, M. J. Ellsworth, J. Ruppenhofer, and E. J.
Wood. 2002. FrameNet:Theory and Practice.
S. Pado K. Erk, A. Kowalski and M. Pinkal. 2003. To-
wards a resource for lexical semantics: A large ger-
man corpus with extensive semantic annotation. In
Proceedings of ACL 2003. Sapporo.
P. Kingsbury, M. Palmer, and M. Marcus. 2002. Adding
semantic annotation to the penn treebank. In Proceed-
ings of the Human Language Technology Conference
(HLT’02).
P. Monachesi and J. Trapman. 2006. Merging framenet
and propbank in a corpus of written dutch. In Proceed-
ings of (LREC) 2006. Genoa.
M. Moortgat, I. Schuurman, and T. van der Wouden.
2000. CGN syntactische annotatie. Internal report
Corpus Gesproken Nederlands.
N. Oostdijk and L. Boves. 2006. User requirements
analysis for the design of a reference corpus of writ-
ten dutch. In Proceedings of (LREC) 2006. Genoa.
N. Oostdijk. 2002. The design of the spoken dutch cor-
pus. In P. Peters, P. Collins, and A. Smith, editors, New
Frontiers of Corpus Research, pages 105–112. Ams-
terdam: Rodopi.
S. Pradhan, K., V. Krugler, W. Ward, J. H. Martin, and
D. Jurafsky. 2005. Support vector learning for seman-
tic argument classification. Machine Learning Jour-
nal, 1-3(60):11–39.
E. Tjong Kim Sang, S. Canisius, A. van den Bosch, and
T. Bogers. 2005. Applying spelling error correction
techniques for improving semantic role labeling. In
Proceedings of the Ninth Conference on Natural Lan-
guage Learning (CoNLL-2005). Ann Arbor, MI, USA.
I. Schuurman and P. Monachesi. 2006. The contours of a
semantic annotation scheme for dutch. In Proceedings
of Computational Linguistics in the Netherlands 2005.
University of Amsterdam. Amsterdam.
G. Stevens. 2006. Automatic semantic role labeling in a
dutch corpus. Master’s thesis, Universiteit Utrecht.
C. Subirats and H. Sato. 2004. Spanish framenet and
framesql. In 4th International Conference on Lan-
guage Resources and Evaluation. Workshop on Build-
ing Lexical Resources from Semantically Annotated
Corpora. Lisbon (Portugal), May 2004.
J. Trapman and P. Monachesi. 2006. Manual for the
annotation of semantic roles in d-coi. Technical report,
University of Utecht.
Tim van de Cruys. 2005. Semantic clustering in dutch.
In Proceedings of CLIN 2005.
A. van den Bosch, S. Canisius, W. Daelemans, I. Hen-
drickx, and E. Tjong Kim Sang. 2004. Memory-
based semantic role labeling: Optimizing features, al-
gorithm, and output. In H.T. Ng and E. Riloff, edi-
tors, Proceedings of the Eighth Conference on Compu-
tational Natural Language Learning (CoNLL-2004).
Boston, MA, USA.
G. van Noord. 2006. At last parsing is now operational.
In Proceedings of TALN 06. Leuven.
P. Vossen. 2006. Cornetto: Een lexicaal-semantische
database voor taaltechnologie. Dixit Special Issue.
Stevin.
</reference>
<page confidence="0.999208">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.358022">
<title confidence="0.99273">Adding semantic role annotation to a corpus of written Dutch</title>
<author confidence="0.960303">Paola Monachesi</author>
<author confidence="0.960303">Gerwert Stevens</author>
<author confidence="0.960303">Jantine</author>
<affiliation confidence="0.94723">Utrecht University, Uil-OTS, Trans 10, 3512 JK Utrecht, The</affiliation>
<address confidence="0.392501">Gerwert.Stevens,</address>
<abstract confidence="0.997160777777778">We present an approach to automatic semantic role labeling (SRL) carried out in the context of the Dutch Language Corpus Initiative (D-Coi) project. Adapting earlier research which has mainly focused on English to the Dutch situation poses an interesting challenge especially because there is no semantically annotated Dutch corpus available that can be used as training data. Our automatic SRL approach consists of three steps: bootstrapping from a syntactically annotated corpus by means of a rulebased tagger developed for this purpose, manual correction on the basis of the Prop- Bank guidelines which have been adapted to Dutch and training a machine learning system on the manually corrected data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Bouma</author>
<author>G Kloosterman</author>
</authors>
<title>Querying dependency treebanks in xml.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third international conference on Language Resources and Evaluation (LREC). Gran Canaria.</booktitle>
<contexts>
<context position="11352" citStr="Bouma and Kloosterman, 2002" startWordPosition="1805" endWordPosition="1809">uming and therefore expensive. A possible solution is to start from a (partially) automatically annotated corpus. The system we developed for this purpose is called XARA (XML-based Automatic Role-labeler for Alpino-trees) (Stevens, 2006). 2 XARA is written in Java, the cornerstone of its rule-based approach is formed by XPath expressions; XPath (Clark and DeRose, 1999) is a powerful query language for the XML format. The corpus format we used in our experiments is the Alpino XML format. This format is designed to support a range of linguistic queries on the dependency trees in XPath directly (Bouma and Kloosterman, 2002). The structure of Alpino XML documents directly corresponds to the structure of the dependency tree: dependency nodes are represented by NODE elements, attributes of the node elements are the properties of the corresponding dependency node, e.g. c-label, d-label, pos-tag, lemma, etc. A rule in XARA consist of an XPath expression that addresses a node in the dependency tree, and a target label for that node, i.e. a rule is a (path,label) pair. For example, a rule that selects direct object nodes and labels them with ARG1 can be formulated as: (//node[@rel=’obj1’], 1) 2The system is available a</context>
</contexts>
<marker>Bouma, Kloosterman, 2002</marker>
<rawString>G. Bouma and G. Kloosterman. 2002. Querying dependency treebanks in xml. In Proceedings of the Third international conference on Language Resources and Evaluation (LREC). Gran Canaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bouma</author>
<author>G van Noord</author>
<author>R Malouf</author>
</authors>
<title>Alpino: wide-coverage computational analysis of dutch.</title>
<date>2000</date>
<marker>Bouma, van Noord, Malouf, 2000</marker>
<rawString>G. Bouma, G. van Noord, and R. Malouf. 2000. Alpino: wide-coverage computational analysis of dutch.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Carreras</author>
<author>L M`arquez</author>
</authors>
<title>Introduction to the conll-2005 shared task: Semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2005).</booktitle>
<location>Boston, MA, USA.</location>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>X. Carreras and L. M`arquez. 2005. Introduction to the conll-2005 shared task: Semantic role labeling. In Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2005). Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clark</author>
<author>S DeRose</author>
</authors>
<title>Xml path language (xpath).</title>
<date>1999</date>
<journal>W3C Recommendation</journal>
<volume>16</volume>
<note>URL: http://www.w3.org/TR/xpath.</note>
<contexts>
<context position="11095" citStr="Clark and DeRose, 1999" startWordPosition="1759" endWordPosition="1762">we developed a rule-based semantic role tagger, which is able to bootstrap an unannotated corpus with semantic roles. We used this rule-based tagger to reduce the manual annotation effort. After all, starting manual annotation from scratch is time consuming and therefore expensive. A possible solution is to start from a (partially) automatically annotated corpus. The system we developed for this purpose is called XARA (XML-based Automatic Role-labeler for Alpino-trees) (Stevens, 2006). 2 XARA is written in Java, the cornerstone of its rule-based approach is formed by XPath expressions; XPath (Clark and DeRose, 1999) is a powerful query language for the XML format. The corpus format we used in our experiments is the Alpino XML format. This format is designed to support a range of linguistic queries on the dependency trees in XPath directly (Bouma and Kloosterman, 2002). The structure of Alpino XML documents directly corresponds to the structure of the dependency tree: dependency nodes are represented by NODE elements, attributes of the node elements are the properties of the corresponding dependency node, e.g. c-label, d-label, pos-tag, lemma, etc. A rule in XARA consist of an XPath expression that addres</context>
</contexts>
<marker>Clark, DeRose, 1999</marker>
<rawString>J. Clark and S. DeRose. 1999. Xml path language (xpath). W3C Recommendation 16 November 1999. URL: http://www.w3.org/TR/xpath.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Daelemans</author>
<author>D Zavrel</author>
<author>K van der Sloot</author>
<author>A van den Bosch</author>
</authors>
<title>Timbl: Tilburg memory based learner, version 5.1, reference guide.</title>
<date>2004</date>
<tech>ILK Technical Report Series 04-02,</tech>
<institution>Tilburg University.</institution>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2004</marker>
<rawString>D. Daelemans, D. Zavrel, K. van der Sloot, and A. van den Bosch. 2004. Timbl: Tilburg memory based learner, version 5.1, reference guide. ILK Technical Report Series 04-02, Tilburg University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dzikovska</author>
<author>M Swift</author>
<author>J Allen</author>
</authors>
<title>Building a computational lexicon and ontology with framenet.</title>
<date>2004</date>
<booktitle>In Proceedings of the workshop Building Lexical Resources with Semantically Annotated Corpora (LREC)</booktitle>
<location>Lisbon.</location>
<contexts>
<context position="4978" citStr="Dzikovska et al., 2004" startWordPosition="782" endWordPosition="785">d, we have taken their insights and experiences as our starting point. FrameNet reaches a level of granularity in the specification of the semantic roles which might be desirable for certain applications (i.e. Question Answering). Moreover, the predicates are linked to an underlying frame ontology that classifies the verbs within a semantic hierarchy. On the other hand, despite the relevant work of Gildea and Jurafsky (2002), it is still an open issue whether FrameNet classes and frame elements can be obtained and used automatically because of the richness of the semantic structures employed (Dzikovska et al., 2004). Furthermore, the FrameNet approach might raise problems with respect to uniformity of role labeling even if human annotators are involved. Incompleteness, however, constitutes the biggest problem, i.e. several frames and relations among frames are missing mainly because FrameNet is still under development. Adopting the FrameNet lexicon for semantic annotation means contributing to its development with the addition of (language specific) and missing frames. In our study, we have assumed that the FrameNet classification even though it is based on English could be applicable to Dutch as well. T</context>
</contexts>
<marker>Dzikovska, Swift, Allen, 2004</marker>
<rawString>M. Dzikovska, M. Swift, and J. Allen. 2004. Building a computational lexicon and ontology with framenet. In Proceedings of the workshop Building Lexical Resources with Semantically Annotated Corpora (LREC) 2004. Lisbon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gildea</author>
<author>D Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Comput. Linguist.,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="4783" citStr="Gildea and Jurafsky (2002)" startWordPosition="748" endWordPosition="751"> evaluated in order to assess whether the approach and the methodology they have developed for the annotation of semantic roles could be adopted for our purposes. Given the results they have achieved, we have taken their insights and experiences as our starting point. FrameNet reaches a level of granularity in the specification of the semantic roles which might be desirable for certain applications (i.e. Question Answering). Moreover, the predicates are linked to an underlying frame ontology that classifies the verbs within a semantic hierarchy. On the other hand, despite the relevant work of Gildea and Jurafsky (2002), it is still an open issue whether FrameNet classes and frame elements can be obtained and used automatically because of the richness of the semantic structures employed (Dzikovska et al., 2004). Furthermore, the FrameNet approach might raise problems with respect to uniformity of role labeling even if human annotators are involved. Incompleteness, however, constitutes the biggest problem, i.e. several frames and relations among frames are missing mainly because FrameNet is still under development. Adopting the FrameNet lexicon for semantic annotation means contributing to its development wit</context>
<context position="7007" citStr="Gildea and Jurafsky (2002)" startWordPosition="1108" endWordPosition="1112">s approach is that we would have to give up the classification of frames in an ontology, as is the case in FrameNet, which could be very useful for certain applications, especially those related to the Semantic Web. However, in (Monachesi and Trapman, 2006) suggestions are given on how the two approaches could be reconciled. The prospect of semi-automatic annotation was the decisive factor in the decision to adopt the PropBank approach for the annotation of semantic roles within the D-Coi project. 3 Automatic SRL: bootstrapping a corpus with semantic roles Ever since the pioneering article of Gildea and Jurafsky (2002), there has been an increasing interest in automatic semantic role labeling (SRL). However, previous research has focused mainly on English. Adapting earlier research to the Dutch situation poses an interesting challenge especially because there is no semantically annotated Dutch corpus available that can be used as training data. Furthermore, no PropBank frame files for Dutch exist. To solve the problem of the unavailability of training data, we have developed a rule-based tagger to bootstrap a syntactically annotated corpus with semantic roles. After manual correction, this corpus was used a</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>D. Gildea and D. Jurafsky. 2002. Automatic labeling of semantic roles. Comput. Linguist., 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Hacioglu</author>
</authors>
<title>Semantic role labeling using dependency trees.</title>
<date>2004</date>
<booktitle>In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>1273</pages>
<contexts>
<context position="18972" citStr="Hacioglu, 2004" startWordPosition="3028" endWordPosition="3029"> in the Tilburg Memory based learner (TiMBL) (Daelemans et al., 2004). TiMBL assigns class labels to training instances on the basis of features and the feature set plays an important role in the performance of a classifier. In choosing the feature set for our system, we mainly looked at previous research, especially systems that participated in the 2004 and 2005 CoNLL shared tasks on semantic role labeling (Carreras and M`arquez, 2005). It is worth noting that none of the systems in the CoNLL shared tasks used features extracted from dependency structures. However, we encountered one system (Hacioglu, 2004) that did not participate in the CoNLL-shared task but did use the same data and was based on dependency structures. The main difference with our system is that Hacioglu did not use a dependency parser to create the dependency trees, instead existing constituent trees were converted to dependency structures. Furthermore, the system was trained and tested on English sentences. From features used in previous systems and some experimentation with TiMBL, we derived the following feature set. The first group of features describes the predicate (verb): (1) Predicate stem - The verb stem, provided by</context>
<context position="23699" citStr="Hacioglu (2004)" startWordPosition="3823" endWordPosition="3824"> However, to put our results somewhat in perspective, we looked mainly at systems that participated in the CoNLL shared tasks on semantic role labeling. The best performing system that participated in CoNLL 2005 reached an F1 of 80. There were seven systems with an F1 performance in the 75-78 range, seven more with performances in the 70-75 range and five with a performance between 65 and 70 (Carreras and M`arquez, 2005). A system that did not participate in the CoNLL task, but still provides interesting material for comparison since it is also based on dependency structures, is the system by Hacioglu (2004). This system scored 85,6% precision, 83,6% recall and 84,6 F1 on the CoNLL data set, which is even higher than the best results published so far on the PropBank data 82 sets (Pradhan et al., 2005): 84% precision, 75% recall and 79 Fl. These results support our claim that dependency structures can be very useful in the SRL task. As one would expect, the overall precision and recall scores of the classifier are higher than those of the XARA rule-based system. Yet, we expected a better performance of the classifier on the lower numbered arguments (ARG0 and ARG1). Our hypothesis is that performan</context>
</contexts>
<marker>Hacioglu, 2004</marker>
<rawString>K. Hacioglu. 2004. Semantic role labeling using dependency trees. In COLING ’04: Proceedings of the 20th international conference on Computational Linguistics, page 1273. August 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Johnson</author>
<author>C J Fillmore</author>
<author>M R L Petruck</author>
<author>C F Baker</author>
<author>M J Ellsworth</author>
<author>J Ruppenhofer</author>
<author>E J Wood</author>
</authors>
<title>FrameNet:Theory and Practice.</title>
<date>2002</date>
<contexts>
<context position="2802" citStr="Johnson et al., 2002" startWordPosition="435" endWordPosition="438">e semantic relationships identified between items in the text such as the agents or patients of particular actions), is one of the most attested and feasible types of semantic annotation within corpora. On the other hand, temporal and spatial annotation was chosen because there is a clear need for such a layer of annotation in applications like information retrieval or question answering. The focus of this paper is on semantic role annotation. We analyze the choices we have made in selecting an appropriate annotation protocol by taking into consideration existing initiatives such as FrameNet (Johnson et al., 2002) and PropBank (Kingsbury et al., 2002) (cf. also the Chinese and Arabic PropBank). We motivate our choice for the PropBank annotation scheme on the basis of the promising results with respect to automatic semantic role labeling (SRL) which have been obtained for English. Furthermore, we discuss how the SRL research could be adapted to the Dutch situation given that no semantically annotated corpus was available that could be used as training data. Proceedings of the Linguistic Annotation Workshop, pages 77–84, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Existing proje</context>
</contexts>
<marker>Johnson, Fillmore, Petruck, Baker, Ellsworth, Ruppenhofer, Wood, 2002</marker>
<rawString>C. R. Johnson, C. J. Fillmore, M. R. L. Petruck, C. F. Baker, M. J. Ellsworth, J. Ruppenhofer, and E. J. Wood. 2002. FrameNet:Theory and Practice.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pado K Erk</author>
<author>A Kowalski</author>
<author>M Pinkal</author>
</authors>
<title>Towards a resource for lexical semantics: A large german corpus with extensive semantic annotation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL 2003.</booktitle>
<location>Sapporo.</location>
<marker>Erk, Kowalski, Pinkal, 2003</marker>
<rawString>S. Pado K. Erk, A. Kowalski and M. Pinkal. 2003. Towards a resource for lexical semantics: A large german corpus with extensive semantic annotation. In Proceedings of ACL 2003. Sapporo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kingsbury</author>
<author>M Palmer</author>
<author>M Marcus</author>
</authors>
<title>Adding semantic annotation to the penn treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Human Language Technology Conference (HLT’02).</booktitle>
<contexts>
<context position="2840" citStr="Kingsbury et al., 2002" startWordPosition="441" endWordPosition="444">between items in the text such as the agents or patients of particular actions), is one of the most attested and feasible types of semantic annotation within corpora. On the other hand, temporal and spatial annotation was chosen because there is a clear need for such a layer of annotation in applications like information retrieval or question answering. The focus of this paper is on semantic role annotation. We analyze the choices we have made in selecting an appropriate annotation protocol by taking into consideration existing initiatives such as FrameNet (Johnson et al., 2002) and PropBank (Kingsbury et al., 2002) (cf. also the Chinese and Arabic PropBank). We motivate our choice for the PropBank annotation scheme on the basis of the promising results with respect to automatic semantic role labeling (SRL) which have been obtained for English. Furthermore, we discuss how the SRL research could be adapted to the Dutch situation given that no semantically annotated corpus was available that could be used as training data. Proceedings of the Linguistic Annotation Workshop, pages 77–84, Prague, June 2007. c�2007 Association for Computational Linguistics 2 Existing projects During the last few years, corpora</context>
</contexts>
<marker>Kingsbury, Palmer, Marcus, 2002</marker>
<rawString>P. Kingsbury, M. Palmer, and M. Marcus. 2002. Adding semantic annotation to the penn treebank. In Proceedings of the Human Language Technology Conference (HLT’02).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Monachesi</author>
<author>J Trapman</author>
</authors>
<title>Merging framenet and propbank in a corpus of written dutch.</title>
<date>2006</date>
<booktitle>In Proceedings of (LREC)</booktitle>
<location>Genoa.</location>
<contexts>
<context position="6638" citStr="Monachesi and Trapman, 2006" startWordPosition="1050" endWordPosition="1053">2004)). The other alternative was to employ the PropBank approach which has the advantage of providing clear role labels and thus a transparent annotation for both annotators and users. Furthermore, there are promising results with respect to automatic semantic role labeling for English thus the annotation process could be at least semi-automatic. A disadvantage of this approach is that we would have to give up the classification of frames in an ontology, as is the case in FrameNet, which could be very useful for certain applications, especially those related to the Semantic Web. However, in (Monachesi and Trapman, 2006) suggestions are given on how the two approaches could be reconciled. The prospect of semi-automatic annotation was the decisive factor in the decision to adopt the PropBank approach for the annotation of semantic roles within the D-Coi project. 3 Automatic SRL: bootstrapping a corpus with semantic roles Ever since the pioneering article of Gildea and Jurafsky (2002), there has been an increasing interest in automatic semantic role labeling (SRL). However, previous research has focused mainly on English. Adapting earlier research to the Dutch situation poses an interesting challenge especially</context>
</contexts>
<marker>Monachesi, Trapman, 2006</marker>
<rawString>P. Monachesi and J. Trapman. 2006. Merging framenet and propbank in a corpus of written dutch. In Proceedings of (LREC) 2006. Genoa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
<author>I Schuurman</author>
<author>T van der Wouden</author>
</authors>
<title>CGN syntactische annotatie. Internal report Corpus Gesproken Nederlands.</title>
<date>2000</date>
<marker>Moortgat, Schuurman, van der Wouden, 2000</marker>
<rawString>M. Moortgat, I. Schuurman, and T. van der Wouden. 2000. CGN syntactische annotatie. Internal report Corpus Gesproken Nederlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Oostdijk</author>
<author>L Boves</author>
</authors>
<title>User requirements analysis for the design of a reference corpus of written dutch.</title>
<date>2006</date>
<booktitle>In Proceedings of (LREC)</booktitle>
<location>Genoa.</location>
<contexts>
<context position="22004" citStr="Oostdijk and Boves, 2006" startWordPosition="3548" endWordPosition="3551">ifiers.6 To overcome our data sparsity problem, we trained the classifier using the leave one out (LOO) method (-t leave_one_out option in TiMBL). With this option set, every data item in turn is selected once as a test item, and the classifier is trained on all remaining items. Except for the LOO option, we only used the default TiMBL settings during training, to prevent overfitting because of data sparsity. 7 Results &amp; Evaluation Table 2 shows the performance of the TiMBL classifier on our annotated dependency treebank. From these sentences, 12,113 instances were extracted. To 6We refer to (Oostdijk and Boves, 2006) for general information about the domain of the D-Coi corpus and its design. measure the performance of the systems, the automatically assigned labels were compared to the labels assigned by a human annotator. Table 2: Results of TiMBL classification Label Precision Recall F&apos;3=1 Overall 70.27% 70.59% 70.43 Arg0 90.44% 86.82% 88.59 Arg1 87.80% 84.63% 86.18 Arg2 63.34% 59.10% 61.15 Arg3 21.21% 19.18% 20.14 Arg4 54.05% 54.05% 54.05 ArgM-ADV 54.98% 51.85% 53.37 ArgM-CAU 47.24% 43.26% 45.16 ArgM-DIR 36.36% 33.33% 34.78 ArgM-DIS 74.27% 70.71% 72.45 ArgM-EXT 29.89% 28.57% 29.21 ArgM-LOC 57.95% 54.53</context>
</contexts>
<marker>Oostdijk, Boves, 2006</marker>
<rawString>N. Oostdijk and L. Boves. 2006. User requirements analysis for the design of a reference corpus of written dutch. In Proceedings of (LREC) 2006. Genoa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Oostdijk</author>
</authors>
<title>The design of the spoken dutch corpus.</title>
<date>2002</date>
<booktitle>New Frontiers of Corpus Research,</booktitle>
<pages>105--112</pages>
<editor>In P. Peters, P. Collins, and A. Smith, editors,</editor>
<location>Amsterdam: Rodopi.</location>
<contexts>
<context position="1860" citStr="Oostdijk, 2002" startWordPosition="280" endWordPosition="281">on English and not much attention has been dedicated to the creation of semantically annotated Dutch corpora. Within the Dutch Language Corpus Initiative (DCoi)1, a recently completed Dutch project, guidelines have been developed for the annotation of a Dutch written corpus. In particular, a pilot corpus 1http://lands.let.ru.nl/projects/d-coi/ 77 has been compiled, parts of which have been enriched with (verified) linguistic annotations. One of the innovative aspects of the D-Coi project with respect to previous initiatives, such as the Spoken Dutch Corpus (CGN - Corpus Gesproken Nederlands) (Oostdijk, 2002), was the development of a protocol for a semantic annotation layer. In particular, two types of semantic annotation have been addressed, that is semantic role assignment and temporal and spatial semantics (Schuurman and Monachesi, 2006). The reason for this choice lies in the fact that semantic role assignment (i.e. the semantic relationships identified between items in the text such as the agents or patients of particular actions), is one of the most attested and feasible types of semantic annotation within corpora. On the other hand, temporal and spatial annotation was chosen because there </context>
</contexts>
<marker>Oostdijk, 2002</marker>
<rawString>N. Oostdijk. 2002. The design of the spoken dutch corpus. In P. Peters, P. Collins, and A. Smith, editors, New Frontiers of Corpus Research, pages 105–112. Amsterdam: Rodopi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pradhan</author>
<author>V Krugler K</author>
<author>W Ward</author>
<author>J H Martin</author>
<author>D Jurafsky</author>
</authors>
<title>Support vector learning for semantic argument classification.</title>
<date>2005</date>
<journal>Machine Learning Journal,</journal>
<pages>1--3</pages>
<contexts>
<context position="23896" citStr="Pradhan et al., 2005" startWordPosition="3857" endWordPosition="3860">ipated in CoNLL 2005 reached an F1 of 80. There were seven systems with an F1 performance in the 75-78 range, seven more with performances in the 70-75 range and five with a performance between 65 and 70 (Carreras and M`arquez, 2005). A system that did not participate in the CoNLL task, but still provides interesting material for comparison since it is also based on dependency structures, is the system by Hacioglu (2004). This system scored 85,6% precision, 83,6% recall and 84,6 F1 on the CoNLL data set, which is even higher than the best results published so far on the PropBank data 82 sets (Pradhan et al., 2005): 84% precision, 75% recall and 79 Fl. These results support our claim that dependency structures can be very useful in the SRL task. As one would expect, the overall precision and recall scores of the classifier are higher than those of the XARA rule-based system. Yet, we expected a better performance of the classifier on the lower numbered arguments (ARG0 and ARG1). Our hypothesis is that performance on these arguments can be improved by by adding semantic features to our feature set. Examples of such features are the subcategorization frame of the predicate and the semantic category (e.g. W</context>
</contexts>
<marker>Pradhan, K, Ward, Martin, Jurafsky, 2005</marker>
<rawString>S. Pradhan, K., V. Krugler, W. Ward, J. H. Martin, and D. Jurafsky. 2005. Support vector learning for semantic argument classification. Machine Learning Journal, 1-3(60):11–39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Tjong Kim Sang</author>
<author>S Canisius</author>
<author>A van den Bosch</author>
<author>T Bogers</author>
</authors>
<title>Applying spelling error correction techniques for improving semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Natural Language Learning (CoNLL-2005).</booktitle>
<location>Ann Arbor, MI, USA.</location>
<marker>Sang, Canisius, van den Bosch, Bogers, 2005</marker>
<rawString>E. Tjong Kim Sang, S. Canisius, A. van den Bosch, and T. Bogers. 2005. Applying spelling error correction techniques for improving semantic role labeling. In Proceedings of the Ninth Conference on Natural Language Learning (CoNLL-2005). Ann Arbor, MI, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Schuurman</author>
<author>P Monachesi</author>
</authors>
<title>The contours of a semantic annotation scheme for dutch.</title>
<date>2006</date>
<booktitle>In Proceedings of Computational Linguistics in the Netherlands</booktitle>
<institution>University of Amsterdam.</institution>
<location>Amsterdam.</location>
<contexts>
<context position="2097" citStr="Schuurman and Monachesi, 2006" startWordPosition="316" endWordPosition="320">veloped for the annotation of a Dutch written corpus. In particular, a pilot corpus 1http://lands.let.ru.nl/projects/d-coi/ 77 has been compiled, parts of which have been enriched with (verified) linguistic annotations. One of the innovative aspects of the D-Coi project with respect to previous initiatives, such as the Spoken Dutch Corpus (CGN - Corpus Gesproken Nederlands) (Oostdijk, 2002), was the development of a protocol for a semantic annotation layer. In particular, two types of semantic annotation have been addressed, that is semantic role assignment and temporal and spatial semantics (Schuurman and Monachesi, 2006). The reason for this choice lies in the fact that semantic role assignment (i.e. the semantic relationships identified between items in the text such as the agents or patients of particular actions), is one of the most attested and feasible types of semantic annotation within corpora. On the other hand, temporal and spatial annotation was chosen because there is a clear need for such a layer of annotation in applications like information retrieval or question answering. The focus of this paper is on semantic role annotation. We analyze the choices we have made in selecting an appropriate anno</context>
</contexts>
<marker>Schuurman, Monachesi, 2006</marker>
<rawString>I. Schuurman and P. Monachesi. 2006. The contours of a semantic annotation scheme for dutch. In Proceedings of Computational Linguistics in the Netherlands 2005. University of Amsterdam. Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Stevens</author>
</authors>
<title>Automatic semantic role labeling in a dutch corpus. Master’s thesis,</title>
<date>2006</date>
<institution>Universiteit Utrecht.</institution>
<contexts>
<context position="8862" citStr="Stevens, 2006" startWordPosition="1409" endWordPosition="1410">rammatical (dependency) relation between the node and its head. Examples of such relations are SU (subject), OBJ (direct object) and MOD (modifier). Intuitively, dependency structures are a great resource for a rule-based semantic tagger, for they directly encode the argument structure of lexical units, e.g. the relation between constituents. Our goal was to make optimal use of this information in an automatic SRL system. In order to achieve this, we first defined a basic mapping between nodes in a dependency graph and PropBank roles. This mapping forms the basis of our rule-based SRL system (Stevens, 2006). Mapping subject and object complements to PropBank arguments is straightforward: subjects are mapped to ARG0 (proto-typical agent), direct objects to ARG1 (proto-typical patient) and indirect objects to ARG2. An exception is made for ergatives and passives, for which the subject is labeled with ARG1. Devising a consistent mapping for higher numbered arguments is more difficult, since their labeling depends in general on the frame entry of the corresponding predicate. Since we could not use frame information, we used a heuristic method. This heuristic strategy entails that after numbering sub</context>
<context position="10961" citStr="Stevens, 2006" startWordPosition="1739" endWordPosition="1740">ifiers that indicate a location of direction. 4 XARA: a rule based SRL tagger With the help of the mappings discussed above, we developed a rule-based semantic role tagger, which is able to bootstrap an unannotated corpus with semantic roles. We used this rule-based tagger to reduce the manual annotation effort. After all, starting manual annotation from scratch is time consuming and therefore expensive. A possible solution is to start from a (partially) automatically annotated corpus. The system we developed for this purpose is called XARA (XML-based Automatic Role-labeler for Alpino-trees) (Stevens, 2006). 2 XARA is written in Java, the cornerstone of its rule-based approach is formed by XPath expressions; XPath (Clark and DeRose, 1999) is a powerful query language for the XML format. The corpus format we used in our experiments is the Alpino XML format. This format is designed to support a range of linguistic queries on the dependency trees in XPath directly (Bouma and Kloosterman, 2002). The structure of Alpino XML documents directly corresponds to the structure of the dependency tree: dependency nodes are represented by NODE elements, attributes of the node elements are the properties of th</context>
</contexts>
<marker>Stevens, 2006</marker>
<rawString>G. Stevens. 2006. Automatic semantic role labeling in a dutch corpus. Master’s thesis, Universiteit Utrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Subirats</author>
<author>H Sato</author>
</authors>
<title>Spanish framenet and framesql.</title>
<date>2004</date>
<booktitle>In 4th International Conference on Language Resources and Evaluation. Workshop on Building Lexical Resources from Semantically Annotated Corpora.</booktitle>
<location>Lisbon</location>
<contexts>
<context position="6015" citStr="Subirats and Sato, 2004" startWordPosition="946" endWordPosition="949">dition of (language specific) and missing frames. In our study, we have assumed that the FrameNet classification even though it is based on English could be applicable to Dutch as well. This assumption is supported by the fact that the German project Saarbr¨ucken Lexical Semantics Annotation and analysis (SALSA) (K. Erk and Pinkal, 2003) has adopted FrameNet with good results. Although Dutch and English are quite similar, there are differences on both sides. For example, in the case of the Spanish FrameNet it turned out that frames may differ in their number of elements across languages (cf. (Subirats and Sato, 2004)). The other alternative was to employ the PropBank approach which has the advantage of providing clear role labels and thus a transparent annotation for both annotators and users. Furthermore, there are promising results with respect to automatic semantic role labeling for English thus the annotation process could be at least semi-automatic. A disadvantage of this approach is that we would have to give up the classification of frames in an ontology, as is the case in FrameNet, which could be very useful for certain applications, especially those related to the Semantic Web. However, in (Monac</context>
</contexts>
<marker>Subirats, Sato, 2004</marker>
<rawString>C. Subirats and H. Sato. 2004. Spanish framenet and framesql. In 4th International Conference on Language Resources and Evaluation. Workshop on Building Lexical Resources from Semantically Annotated Corpora. Lisbon (Portugal), May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Trapman</author>
<author>P Monachesi</author>
</authors>
<title>Manual for the annotation of semantic roles in d-coi.</title>
<date>2006</date>
<tech>Technical report,</tech>
<institution>University of Utecht.</institution>
<contexts>
<context position="14642" citStr="Trapman and Monachesi, 2006" startWordPosition="2329" endWordPosition="2332">y are attested, a coindexation has been established already at the syntactic level. Furthermore, D-coi assumes dependency structures for the syntactic representation of its sentences while PropBank employs phrase structure trees. In addition, Dutch behaves differently from English with respect to certain constructions and these differences should be spelled out. In order to annotate our corpus, the PropBank guidelines needed a revision because they have been developed for English and to add a semantic layer to the Penn TreeBank. Besides the adaption (and extension) of the guidelines to Dutch (Trapman and Monachesi, 2006), we also have to consider a Dutch version of the PropBank frameindex. In PropBank, frame files provide a verb specific description of all possible semantic roles and illustrate these roles by examples. The lack of example sentences makes consistent annotation difficult. Since defining a set of frame files from scratch is very time consuming, we decided to attempt an alternative approach, in which we annotated Dutch verbs with the same argument structure as their English counterparts, thus use English frame files instead of creating Dutch ones. Although this causes some problems, for example, </context>
</contexts>
<marker>Trapman, Monachesi, 2006</marker>
<rawString>J. Trapman and P. Monachesi. 2006. Manual for the annotation of semantic roles in d-coi. Technical report, University of Utecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim van de Cruys</author>
</authors>
<title>Semantic clustering in dutch.</title>
<date>2005</date>
<booktitle>In Proceedings of CLIN</booktitle>
<marker>van de Cruys, 2005</marker>
<rawString>Tim van de Cruys. 2005. Semantic clustering in dutch. In Proceedings of CLIN 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A van den Bosch</author>
<author>S Canisius</author>
<author>W Daelemans</author>
<author>I Hendrickx</author>
<author>E Tjong Kim Sang</author>
</authors>
<title>Memorybased semantic role labeling: Optimizing features, algorithm, and output.</title>
<date>2004</date>
<booktitle>Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004).</booktitle>
<editor>In H.T. Ng and E. Riloff, editors,</editor>
<location>Boston, MA, USA.</location>
<marker>van den Bosch, Canisius, Daelemans, Hendrickx, Sang, 2004</marker>
<rawString>A. van den Bosch, S. Canisius, W. Daelemans, I. Hendrickx, and E. Tjong Kim Sang. 2004. Memorybased semantic role labeling: Optimizing features, algorithm, and output. In H.T. Ng and E. Riloff, editors, Proceedings of the Eighth Conference on Computational Natural Language Learning (CoNLL-2004). Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G van Noord</author>
</authors>
<title>At last parsing is now operational.</title>
<date>2006</date>
<booktitle>In Proceedings of TALN 06.</booktitle>
<location>Leuven.</location>
<marker>van Noord, 2006</marker>
<rawString>G. van Noord. 2006. At last parsing is now operational. In Proceedings of TALN 06. Leuven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>Cornetto: Een lexicaal-semantische database voor taaltechnologie.</title>
<date>2006</date>
<journal>Dixit Special Issue. Stevin.</journal>
<contexts>
<context position="25042" citStr="Vossen, 2006" startWordPosition="4049" endWordPosition="4050">gorization frame of the predicate and the semantic category (e.g. WordNet synset) of the candidate argument. We expect that such semantic features will improve the performance of the classifier for certain types of verbs and arguments, especially the lower numbered arguments ARG0 and ARG1 and temporal and spatial modifiers. For example, the Dutch preposition over can either head a phrase indicating a location or a time-span. The semantic category of the neighboring noun phrase might be helpful in such cases to choose the right PropBank label. Thanks to new lexical resources, such as Cornetto (Vossen, 2006), and clustering techniques based on dependency structures (van de Cruys, 2005), we might be able to add lexical semantic information about noun phrases in future research. Performance of the classifier can also be improved by automatically optimizing the feature set. The optimal set of features for a classifier can be found by employing bi-directional hill climbing (van den Bosch et al., 2004). There is a wrapper script (Paramsearch) available that can be used with TiMBL and several other learning systems that implements this approach7. In addition, iterative deepening (ID) can be used as a h</context>
</contexts>
<marker>Vossen, 2006</marker>
<rawString>P. Vossen. 2006. Cornetto: Een lexicaal-semantische database voor taaltechnologie. Dixit Special Issue. Stevin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>