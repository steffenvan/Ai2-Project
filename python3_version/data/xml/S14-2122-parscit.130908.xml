<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004811">
<title confidence="0.992795">
UBham: Lexical Resources and Dependency Parsing for Aspect-Based
Sentiment Analysis
</title>
<author confidence="0.995987">
Viktor Pekar
</author>
<affiliation confidence="0.997923">
School of Computer Science
University of Birmingham
</affiliation>
<address confidence="0.82632">
Birmingham, UK
</address>
<email confidence="0.998185">
v.pekar@cs.bham.ac.uk
</email>
<author confidence="0.623324">
Naveed Afzal
</author>
<affiliation confidence="0.604588">
FCIT, North Branch
King Abdulaziz University
</affiliation>
<address confidence="0.574931">
Jeddah, KSA
</address>
<email confidence="0.988283">
nafzal@kau.edu.sa
</email>
<author confidence="0.991455">
Bernd Bohnet
</author>
<affiliation confidence="0.9978815">
School of Computer Science
University of Birmingham
</affiliation>
<address confidence="0.82657">
Birmingham, UK
</address>
<email confidence="0.998718">
b.bohnet@cs.bham.ac.uk
</email>
<sectionHeader confidence="0.993892" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999785">
This paper describes the system devel-
oped by the UBham team for the SemEval-
2014 Aspect-Based Sentiment Analysis
task (Task 4). We present an approach
based on deep linguistic processing tech-
niques and resources, and explore the pa-
rameter space of these techniques applied
to the different stages in this task and ex-
amine possibilities to exploit interdepen-
dencies between them.
</bodyText>
<sectionHeader confidence="0.998693" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997383">
Aspect-Based Sentiment Analysis (ASBA) is con-
cerned with detection of the author’s sentiment to-
wards different issues discussed in a document,
such as aspects or features of a product in a cus-
tomer review. The specific ASBA scenario we ad-
dress in this paper is as follows. Given a sentence
from a review, identify (1) aspect terms, specific
words or multiword expressions denoting aspects
of the product; (2) aspect categories, categories of
issues being commented on; (3) aspect term po-
larity, the polarity of the sentiment associated with
each aspect term; and (4) aspect category polarity,
the polarity associated with each aspect category
found in the sentence. For example, in:
I liked the service and the staff, but not the food.
aspect terms are service, staff and food, where the
first two are evaluated positively and the last one
negatively; and aspect categories are SERVICE and
FOOD, where the former is associated with pos-
itive sentiment and the latter with negative. It
should be noted that a given sentence may contain
</bodyText>
<footnote confidence="0.562339428571429">
This work is licenced under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
The research was partially supported by FP7 ICT project
“Workbench for Interactive Contrastive Analysis of Patent
Documentation” under grant no. FP7-SME-606163.
</footnote>
<bodyText confidence="0.999675818181818">
one, several, or no aspect terms, one, several, or no
aspect categories, and may express either positive,
negative, neutral, or conflicted sentiment.
While the ASBA task is usually studied in the
context of documents (e.g., online reviews), pecu-
liarities of this scenario are short input texts, com-
plex categorization schemas, and a limited amount
of annotated data. Therefore we focused on ways
to exploit deep linguistic processing techniques,
which we use for both creating complex classifi-
cation features and rule-based processing.
</bodyText>
<sectionHeader confidence="0.999909" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.999628">
2.1 Aspect Term Extraction
</subsectionHeader>
<bodyText confidence="0.99997775">
To recognize terms that express key notions in a
product or service review, a common general ap-
proach has been to extract nouns and noun phrases
as potential terms and then apply a certain filtering
technique to ensure only the most relevant terms
remain. These techniques include statistical asso-
ciation tests (Yi et al., 2003), associative mining
rules with additional rule-based post-processing
steps (Hu and Liu, 2004), and measures of asso-
ciation with certain pre-defined classes of words,
such as part-whole relation indicators (Popescu
and Etzioni, 2005).
</bodyText>
<subsectionHeader confidence="0.999653">
2.2 Aspect Category Recognition
</subsectionHeader>
<bodyText confidence="0.99892525">
Aspect category recognition is often addressed as
a text classification problem, where a classifier
is learned from reviews manually tagged for as-
pects (e.g., Snyder and Barzilay, 2007, Ganu et al.,
2009). Titov and McDonald (2008) present an ap-
proach which jointly detects aspect categories and
their sentiment using a classifier trained on top-
ics discovered via Multi-Grain LDA and star rat-
ings available in training data. Zhai et al. (2010)
presented an approach based on Expectation-
Maximization to group aspect expressions into
user-defined aspect categories.
</bodyText>
<page confidence="0.988475">
683
</page>
<note confidence="0.7889275">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 683–687,
Dublin, Ireland, August 23-24, 2014.
</note>
<subsectionHeader confidence="0.998799">
2.3 Sentence Sentiment
</subsectionHeader>
<bodyText confidence="0.999968">
Lexicon-based approaches to detecting sentiment
in a sentence rely on a lexicon where words and
phrases are provided with sentiment labels as well
as on techniques to recognize “polarity shifters”,
phrases causing the polarity of a lexical item
to reverse. Early work on detection of polarity
shifters used surface-level patterns (Yu and Hatzi-
vassilouglu, 2003; Hu and Liu, 2004). Moila-
nen and Pulman (2007) provide a logic-oriented
framework to compute the polarity of grammatical
structures, that is capable of dealing with phenom-
ena such as sentiment propagation, polarity rever-
sal, and polarity conflict. Several papers looked at
different ways to use syntactic dependency infor-
mation in a machine learning framework, to better
account for negations and their scope (Nakagawa
et al., 2010; Socher et al., 2013).
To adapt a generic sentiment lexicon to a new
application domain, previous work exploited se-
mantic relations encoded in WordNet (Kim and
Hovy, 2006), unannotated data (Li et al, 2012), or
queries to a search engine (Taboada et al., 2006).
</bodyText>
<sectionHeader confidence="0.975473" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.99993675">
In the following sections, we will describe our ap-
proach to each stage of the Shared Task, reporting
experiments on the provided training data using a
10-fold cross-validation.
</bodyText>
<subsectionHeader confidence="0.999586">
3.1 Aspect Term Extraction
</subsectionHeader>
<bodyText confidence="0.999929125">
During pre-processing training data was parsed
using a dependency parser (Bohnet and Nivre,
2012), and sentiment words were recognized in it
using a sentiment lexicon (see Section 6.1). Can-
didate terms were extracted as single nouns, noun
phrases, adjectives and verbs, enforcing certain
exceptions as detailed in the annotation guidelines
for the Shared Task (Pontiki et al., 2014), namely:
</bodyText>
<listItem confidence="0.983457666666667">
• Sentiment words were not allowed as part of
terms;
• Noun phrases with all elements capitalized
and acronyms were excluded, under the as-
sumption they refer to brands rather than
product aspects;
• Nouns referring to the product class as a
whole (“restaurant”, “laptop”, etc) were ex-
cluded.
</listItem>
<bodyText confidence="0.998873115384615">
Candidate terms that exactly overlapped with
manually annotated terms were discarded, while
those that did not were used as negative examples
of aspect terms.
In order to provide the term extraction process
with additional lexical knowledge, from the train-
ing data we extracted those manually annotated
terms that corresponded to a single aspect cate-
gory. Then the set of terms belonging to each
category was augmented using WordNet: first we
determined the 5 most prominent hyperonyms of
these terms in the WordNet hierarchy using Resnik
(1992)’s algorithm for learning a class in a seman-
tic hierarchy that best represents selectional pref-
erences of a verb, additionally requiring that each
hypernym is at least 7 nodes away from the root, to
make them sufficiently specific. Then we obtained
all lexical items that belong to children synsets of
these hypernyms, and further extended these lexi-
cal items with their meronyms and morphological
derivatives. The resulting set of lexical items was
later used as an extended aspect term lexicon. We
additionally created a list of all individual lemmas
of content words found in this lexicon.
For each term, we extracted the following fea-
tures to be used for automatic classification:
</bodyText>
<listItem confidence="0.999820235294118">
• Normalized form: the surface form of the
term after normalization;
• Term lemmas: lemmas of content words
found in the term;
• Lexicon term: if the term is in the lexicon;
• Lexicon lemmas ratio: the ratio of lexicon
lemmas in the term;
• Unigram: 3 unigrams on either side of the
term;
• Bigrams: The two bigrams around the term;
• Adj+term: If an adjective depends on the
term1 or related to it via a link verb (“be”,
“get”, “become”, etc);
• Sentiment+term: If a sentiment word de-
pends on the term or related via a link verb;
• Be+term: If the term depends on a link verb;
• Subject term: If the term is a subject;
</listItem>
<footnote confidence="0.9948345">
1In case the term was a multi-word expression, the rela-
tion to the head of the phrase was used.
</footnote>
<page confidence="0.988922">
684
</page>
<listItem confidence="0.99901">
• Object term: If the term is an object.
</listItem>
<bodyText confidence="0.979509363636363">
We first look at how well the manually designed
patterns extracted potential terms. We are primar-
ily interested in recall at this stage, since after that
potential terms are classified into terms and non-
terms with an automatic classifier. The recall on
the restaurants was 70.5, and on the laptops −
56.9. These are upper limits on recall for the over-
all task of aspect term recognition.
Table 1 and Table 2 compare the performance of
several learning algorithms on the restaurants and
the laptops dataset, respectively2.
</bodyText>
<table confidence="0.9996752">
P R F
Linear SVM 94.42 95.51 94.96
Decision Tree 94.24 92.90 93.56
Naive Bayes 84.97 95.67 89.99
kNN (k=5) 82.71 93.50 87.76
</table>
<tableCaption confidence="0.986499">
Table 1: Learning algorithms on the aspect term
</tableCaption>
<table confidence="0.936290166666667">
extraction task, restaurants dataset.
P R F
Linear SVM 88.14 94.07 91.00
Naive Bayes 93.61 79.46 85.92
Decision Tree 83.87 82.99 83.39
kNN (k=5) 82.83 83.31 83.03
</table>
<tableCaption confidence="0.897463">
Table 2: Learning algorithms on the aspect term
extraction task, laptops dataset.
</tableCaption>
<bodyText confidence="0.995069117647059">
On both datasets, linear SVMs performed best,
and so they were used in the subsequent experi-
ments on term recognition. To examine the qual-
ity of each feature used for term classification, we
ran experiments where a classifier was built and
tested without that feature, see Tables 3 and 4, for
the restaurants and laptops datasets respectively,
where a greater drop in performance compared to
the entire feature set, indicates a more informative
feature.
The results show the three most useful features
are the same in both datasets: the occurrence of the
candidate term in the constructed sentiment lexi-
con, the lemmas found in the term, and the nor-
malized form of the term account.
We ran further experiments manually selecting
several top-performing features, but none of the
</bodyText>
<footnote confidence="0.588474666666667">
2This and the following experiments were run on the train
data supplied by the shared task organizers using 10-fold
cross-validation.
</footnote>
<table confidence="0.999802571428572">
P R F
Lexicon term 91.74 95.01 93.33
Term lemmas 92.43 95.00 93.69
Normalized form 93.45 95.36 94.39
Be+term 93.99 95.28 94.63
Left bigram 94.21 95.09 94.64
All features 94.42 95.51 94.96
</table>
<tableCaption confidence="0.883977">
Table 3: Top 5 most informative features for the
term extraction subtask, restaurants dataset.
</tableCaption>
<table confidence="0.999911857142857">
P R F
Lexicon term 88.82 88.61 88.69
Term lemmas 85.02 95.16 89.79
Normalized form 87.79 92.13 89.89
Left bigram 87.83 93.62 90.62
Term is obj 87.79 94.43 90.97
All features 88.14 94.07 91.00
</table>
<tableCaption confidence="0.8969655">
Table 4: Top 5 most informative features for the
term extraction subtask, laptops dataset.
</tableCaption>
<bodyText confidence="0.995887777777778">
configurations produced significant improvements
on the use of the whole feature set.
Table 5 shows the results of evaluation of the as-
pect term extraction on the test data of the Shared
Task (baseline algorithms were provided by the or-
ganizers). The results correspond to what can be
expected based on the upper limits on recall for
the pattern-based extraction of candidate terms as
well as precision and recall for the classifier.
</bodyText>
<table confidence="0.99943">
P R F
Restaurants 77.9 61.1 68.5
Restaurants, baseline 53.9 51.4 52.6
Laptops 60.3 39.1 47.5
Laptops, baseline 40.1 38.1 39.1
</table>
<tableCaption confidence="0.9505345">
Table 5: Aspect term extraction on the test data of
the Shared Task.
</tableCaption>
<subsectionHeader confidence="0.999321">
3.2 Aspect Category Recognition
</subsectionHeader>
<bodyText confidence="0.999996">
To recognize aspect categories in a sentence, we
classified individual clauses found in it, assuming
that each aspect category would be discussed in
a separate clause. Features used for classification
were lemmas of content words; to account for the
fact that aspect terms are more indicative of aspect
categories than other words, we additionally used
entire terms as features, weighting them twice as
much as other features. Table 6 compares the per-
</bodyText>
<page confidence="0.998234">
685
</page>
<bodyText confidence="0.99986925">
formance of several learning algorithms when au-
tomatically recognized aspect terms were not used
as an additional feature; Table 7 shows results
when terms were used as features.
</bodyText>
<table confidence="0.9995202">
P R F
Linear SVM 66.37 58.07 60.69
Decision Tree 58.07 51.22 53.05
Naive Bayes 74.34 46.07 48.63
kNN (k=5) 58.65 43.77 46.57
</table>
<tableCaption confidence="0.98545">
Table 6: Learning algorithms on the aspect cate-
gory recognition task, aspect terms not weighted.
</tableCaption>
<table confidence="0.999957">
P R F
Linear SVM 67.23 59.43 61.90
Decision Tree 64.41 55.84 58.36
Naive Bayes 78.02 49.57 52.87
kNN (k=5) 67.92 47.91 51.94
</table>
<tableCaption confidence="0.897851">
Table 7: Learning algorithms on the aspect cate-
gory recognition task, aspect terms weighted.
</tableCaption>
<bodyText confidence="0.9977705">
The addition of aspect terms as separate features
increased F-scores for all the learning methods,
sometimes by as much as 5%. Based on these re-
sults, we used the linear SVM method for the task
submission. Table 8 reports results achieved on
the test data of the Shared Task.
</bodyText>
<table confidence="0.999457666666667">
P R F
Restaurants 81.8 67.9 74.2
Baseline 64.8 52.5 58.0
</table>
<tableCaption confidence="0.819101">
Table 8: Aspect category extraction on the test
data of the Shared Task.
</tableCaption>
<subsectionHeader confidence="0.999603">
3.3 Aspect Term Sentiment
</subsectionHeader>
<bodyText confidence="0.999986333333333">
To recognize sentiment in a sentence, we take a
lexicon-based approach. The sentiment lexicon
we used encodes the lemma, the part-of-speech
tag, and the polarity of the sentiment word. It was
built by combining three resources: lemmas from
SentiWordNet (Baccianella et al., 2010), which do
not belong to more than 3 synsets; the General
Inquirer lexicon (Stone et al., 1966), and a sub-
section of the Roget thesaurus annotated for sen-
timent (Heng, 2004). In addition, we added sen-
timent expressions that are characteristic of the
restaurants and laptop domains, obtained based on
manual analysis of the restaurants corpus used in
(Snyder and Barzilay (2007) and the laptop re-
views corpus used in (Jindal and Liu, 2008).
To detect negated sentiment, we used a list of
negating phrases such as “not”, “never”, etc., and
two types of patterns to determine the scope of a
negation. The first type detected negations on the
sentence level, checking for negative phrases at
the start of the sentence; negations detected on the
sentence level were propagated to the clause level.
The second type of patterns detected negated sen-
timent within a clause, using patterns specific to
the part-of-speech of the sentiment word (e.g.,
“AUXV + negation + VB + MAINV”, where
MAINV is a sentiment verb). The output of this
algorithm is the sentence split into clauses, with
each clause being assigned one of four sentiment
labels: “positive”, “negative”, “neutral”, “con-
flict”. Thus, each term was associated with the
sentiment of the clause it appeared in.
On the test data of the Shared Task, the algo-
rithm achieved the accuracy scores of 76.0 (the
restaurants data, for the baseline of 64.3) and 63.6
(the laptops data, for the baseline of 51.1).
</bodyText>
<subsectionHeader confidence="0.992836">
3.4 Category Sentiment
</subsectionHeader>
<bodyText confidence="0.9999775">
Recall that aspect categories were recognized in a
sentence by classifying its individual clauses. Cat-
egory sentiment was determined from the senti-
ment of the clauses where the category was found.
In case more than one clause was assigned to the
same category and at least one clause expressed
positive sentiment and at least one − negative,
such cases were classified as conflicted sentiment.
This method achieved the accuracy of 72.8 (on the
restaurants data), with the baseline being 65.65.
</bodyText>
<sectionHeader confidence="0.999331" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999933785714286">
Our study has shown that aspect terms can be de-
tected with a high accuracy using a domain lexicon
derived from WordNet, and a set of classification
features created with the help of deep linguistic
processing techniques. However, the overall accu-
racy of aspect term recognition is greatly affected
by the extraction patterns that are used to extract
initial candidate terms. We also found that au-
tomatically extracted aspect terms are useful fea-
tures in the aspect category recognition task. With
regards to sentiment detection, our results suggest
that reasonable performance can be achieved with
a lexicon-based approach coupled with carefully
designed rules for the detection of polarity shifts.
</bodyText>
<page confidence="0.99832">
686
</page>
<sectionHeader confidence="0.988991" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997456310344828">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SENTIWORDNET 3.0: An Enhanced
Lexical Resource for Sentiment Analysis and Opin-
ion Mining. Proceedings of LREC-2010.
Bernd Bohnet and Joakim Nivre. 2012. A Transition-
Based System for Joint Part-of-Speech Tagging and
Labeled Non-Projective Dependency Parsing. Pro-
ceedings of EMNLP-CoNLL.
Gayatree Ganu, No´emie Elhadad, and Ameli´e Mar-
ian. 2009. Beyond the Stars: Improving Rating
Predictions using Review Text Content. Proceedings
of Twelfth International Workshop on the Web and
Databases (WebDB 2009).
Adrian Heng. 2004. An exploratory study into the use
offaceted classification for emotional words. Mas-
ter Thesis. Nanyang Technological University, Sin-
gapore.
Minqing Hu and Bing Liu. 2004. Mining opinion
features in customer reviews. Proceedings of the
9th National Conference on Artificial Intelligence
(AAAI-2004).
Nitin Jindal and Bing Liu. 2008. Opinion Spam and
Analysis Proceedings of WWW-2008.
Soo-Min Kim and Eduard Hovy. 2006. Identifying
and analyzing judgment opinions. Proceedings of
HLT/NAACL-2006.
Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang and
Xiaoyan Zhu. 2012. Cross-Domain Co-Extraction
of Sentiment and Topic Lexicons. Proceedings of
ACL-2012.
Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi.
2010. Dependency tree-based sentiment classifica-
tion using CRFs with hidden variables. Proceedings
of NAACL/HLT-2010.
Karo Moilanen and Stephen Pulman. 2007. Sentiment
composition. Proceedings of the Recent Advances
in Natural Language Processing (RANLP 2007).
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Haris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. SemEval-2014 Task 4:
Aspect Based Sentiment Analysis. Proceedings of
the 8th International Workshop on Semantic Evalu-
ation (SemEval 2014).
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing productfeatures and opinions from reviews. Pro-
ceedings HLT/EMNLP-2005.
Philip Resnik. 1992. A class-based approach to lexi-
cal discovery Proceedings of the Proceedings of the
30th Annual Meeting of the Association for Compu-
tational Linguists.
Benjamin Snyder and Regina Barzilay 2007. Multi-
ple Aspect Ranking using the Good GriefAlgorithm.
Proceedings of NAACL-2007.
Richard Socher, Alex Perelygin, Jean Y. Wu, Jason
Chuang, Christopher D. Manning, Andrew Y. Ng
and Christopher Potts 2013. Recursive Deep Mod-
els for Semantic Compositionality Over a Sentiment
Treebank. Proceedings of EMNLP-2013.
Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith,
and Daniel M. Ogilvie. 1966. The General In-
quirer: A Computer Approach to Content Analysis.
Cambridge, MA: The MIT Press.
Maite Taboada, Caroline Anthony, and Kimberly Voll.
2006. Creating semantic orientation dictionaries
Proceedings of 5th International Conference on Lan-
guage Resources and Evaluation (LREC).
Ivan Titov and Ryan McDonald. 2008. A joint model
of text and aspect ratings for sentiment summariza-
tion. Proceedings of ACL-2008.
Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen and Jun
Zhao. 2013. Mining Opinion Words and Opinion
Targets in a Two-Stage Framework. Proceedings of
ACL-2013.
Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, and
Wayne Niblack. 2003. Sentiment analyzer: Ex-
tracting sentiments about a given topic using natural
language processing techniques. Proceedings of the
3rd IEEE International Conference on Data Mining
(ICDM-2003), pp. 423-434.
Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards Answering Opinion Questions: Separating
Facts from Opinions and Identifying the Polarity of
Opinion Sentences. Proceedings of EMNLP-03.
Zhongwu Zhai, Bing Liu, Hua Xu and Peifa Jia. 2011.
Clustering productfeatures for opinion mining. Pro-
ceedings of the 4th ACM International Conference
on Web Search and Data Mining, ACM, pp 347354.
</reference>
<page confidence="0.997786">
687
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.033429">
<title confidence="0.9991805">UBham: Lexical Resources and Dependency Parsing for Sentiment Analysis</title>
<author confidence="0.913771">Viktor</author>
<affiliation confidence="0.9996915">School of Computer University of</affiliation>
<address confidence="0.557647">Birmingham,</address>
<email confidence="0.986517">v.pekar@cs.bham.ac.uk</email>
<title confidence="0.4100905">Naveed FCIT, North</title>
<author confidence="0.968659">King Abdulaziz</author>
<affiliation confidence="0.769585">Jeddah,</affiliation>
<email confidence="0.740843">nafzal@kau.edu.sa</email>
<author confidence="0.562094">Bernd</author>
<affiliation confidence="0.999835">School of Computer University of</affiliation>
<address confidence="0.612017">Birmingham,</address>
<email confidence="0.999469">b.bohnet@cs.bham.ac.uk</email>
<abstract confidence="0.995038636363636">This paper describes the system developed by the UBham team for the SemEval- 2014 Aspect-Based Sentiment Analysis task (Task 4). We present an approach based on deep linguistic processing techniques and resources, and explore the parameter space of these techniques applied to the different stages in this task and examine possibilities to exploit interdependencies between them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SENTIWORDNET 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining.</title>
<date>2010</date>
<booktitle>Proceedings of LREC-2010.</booktitle>
<contexts>
<context position="12900" citStr="Baccianella et al., 2010" startWordPosition="2070" endWordPosition="2073">ing methods, sometimes by as much as 5%. Based on these results, we used the linear SVM method for the task submission. Table 8 reports results achieved on the test data of the Shared Task. P R F Restaurants 81.8 67.9 74.2 Baseline 64.8 52.5 58.0 Table 8: Aspect category extraction on the test data of the Shared Task. 3.3 Aspect Term Sentiment To recognize sentiment in a sentence, we take a lexicon-based approach. The sentiment lexicon we used encodes the lemma, the part-of-speech tag, and the polarity of the sentiment word. It was built by combining three resources: lemmas from SentiWordNet (Baccianella et al., 2010), which do not belong to more than 3 synsets; the General Inquirer lexicon (Stone et al., 1966), and a subsection of the Roget thesaurus annotated for sentiment (Heng, 2004). In addition, we added sentiment expressions that are characteristic of the restaurants and laptop domains, obtained based on manual analysis of the restaurants corpus used in (Snyder and Barzilay (2007) and the laptop reviews corpus used in (Jindal and Liu, 2008). To detect negated sentiment, we used a list of negating phrases such as “not”, “never”, etc., and two types of patterns to determine the scope of a negation. Th</context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SENTIWORDNET 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining. Proceedings of LREC-2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Joakim Nivre</author>
</authors>
<title>A TransitionBased System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing.</title>
<date>2012</date>
<booktitle>Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="5458" citStr="Bohnet and Nivre, 2012" startWordPosition="826" endWordPosition="829">tions and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated data (Li et al, 2012), or queries to a search engine (Taboada et al., 2006). 3 Our Approach In the following sections, we will describe our approach to each stage of the Shared Task, reporting experiments on the provided training data using a 10-fold cross-validation. 3.1 Aspect Term Extraction During pre-processing training data was parsed using a dependency parser (Bohnet and Nivre, 2012), and sentiment words were recognized in it using a sentiment lexicon (see Section 6.1). Candidate terms were extracted as single nouns, noun phrases, adjectives and verbs, enforcing certain exceptions as detailed in the annotation guidelines for the Shared Task (Pontiki et al., 2014), namely: • Sentiment words were not allowed as part of terms; • Noun phrases with all elements capitalized and acronyms were excluded, under the assumption they refer to brands rather than product aspects; • Nouns referring to the product class as a whole (“restaurant”, “laptop”, etc) were excluded. Candidate ter</context>
</contexts>
<marker>Bohnet, Nivre, 2012</marker>
<rawString>Bernd Bohnet and Joakim Nivre. 2012. A TransitionBased System for Joint Part-of-Speech Tagging and Labeled Non-Projective Dependency Parsing. Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gayatree Ganu</author>
<author>No´emie Elhadad</author>
<author>Ameli´e Marian</author>
</authors>
<title>Beyond the Stars: Improving Rating Predictions using Review Text Content.</title>
<date>2009</date>
<booktitle>Proceedings of Twelfth International Workshop on the Web and Databases (WebDB</booktitle>
<contexts>
<context position="3563" citStr="Ganu et al., 2009" startWordPosition="535" endWordPosition="538">certain filtering technique to ensure only the most relevant terms remain. These techniques include statistical association tests (Yi et al., 2003), associative mining rules with additional rule-based post-processing steps (Hu and Liu, 2004), and measures of association with certain pre-defined classes of words, such as part-whole relation indicators (Popescu and Etzioni, 2005). 2.2 Aspect Category Recognition Aspect category recognition is often addressed as a text classification problem, where a classifier is learned from reviews manually tagged for aspects (e.g., Snyder and Barzilay, 2007, Ganu et al., 2009). Titov and McDonald (2008) present an approach which jointly detects aspect categories and their sentiment using a classifier trained on topics discovered via Multi-Grain LDA and star ratings available in training data. Zhai et al. (2010) presented an approach based on ExpectationMaximization to group aspect expressions into user-defined aspect categories. 683 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 683–687, Dublin, Ireland, August 23-24, 2014. 2.3 Sentence Sentiment Lexicon-based approaches to detecting sentiment in a sentence rely on a lexi</context>
</contexts>
<marker>Ganu, Elhadad, Marian, 2009</marker>
<rawString>Gayatree Ganu, No´emie Elhadad, and Ameli´e Marian. 2009. Beyond the Stars: Improving Rating Predictions using Review Text Content. Proceedings of Twelfth International Workshop on the Web and Databases (WebDB 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Heng</author>
</authors>
<title>An exploratory study into the use offaceted classification for emotional words. Master Thesis.</title>
<date>2004</date>
<institution>Nanyang Technological University, Singapore.</institution>
<contexts>
<context position="13073" citStr="Heng, 2004" startWordPosition="2103" endWordPosition="2104">k. P R F Restaurants 81.8 67.9 74.2 Baseline 64.8 52.5 58.0 Table 8: Aspect category extraction on the test data of the Shared Task. 3.3 Aspect Term Sentiment To recognize sentiment in a sentence, we take a lexicon-based approach. The sentiment lexicon we used encodes the lemma, the part-of-speech tag, and the polarity of the sentiment word. It was built by combining three resources: lemmas from SentiWordNet (Baccianella et al., 2010), which do not belong to more than 3 synsets; the General Inquirer lexicon (Stone et al., 1966), and a subsection of the Roget thesaurus annotated for sentiment (Heng, 2004). In addition, we added sentiment expressions that are characteristic of the restaurants and laptop domains, obtained based on manual analysis of the restaurants corpus used in (Snyder and Barzilay (2007) and the laptop reviews corpus used in (Jindal and Liu, 2008). To detect negated sentiment, we used a list of negating phrases such as “not”, “never”, etc., and two types of patterns to determine the scope of a negation. The first type detected negations on the sentence level, checking for negative phrases at the start of the sentence; negations detected on the sentence level were propagated t</context>
</contexts>
<marker>Heng, 2004</marker>
<rawString>Adrian Heng. 2004. An exploratory study into the use offaceted classification for emotional words. Master Thesis. Nanyang Technological University, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinion features in customer reviews.</title>
<date>2004</date>
<booktitle>Proceedings of the 9th National Conference on Artificial Intelligence (AAAI-2004).</booktitle>
<contexts>
<context position="3186" citStr="Hu and Liu, 2004" startWordPosition="479" endWordPosition="482">used on ways to exploit deep linguistic processing techniques, which we use for both creating complex classification features and rule-based processing. 2 Related Work 2.1 Aspect Term Extraction To recognize terms that express key notions in a product or service review, a common general approach has been to extract nouns and noun phrases as potential terms and then apply a certain filtering technique to ensure only the most relevant terms remain. These techniques include statistical association tests (Yi et al., 2003), associative mining rules with additional rule-based post-processing steps (Hu and Liu, 2004), and measures of association with certain pre-defined classes of words, such as part-whole relation indicators (Popescu and Etzioni, 2005). 2.2 Aspect Category Recognition Aspect category recognition is often addressed as a text classification problem, where a classifier is learned from reviews manually tagged for aspects (e.g., Snyder and Barzilay, 2007, Ganu et al., 2009). Titov and McDonald (2008) present an approach which jointly detects aspect categories and their sentiment using a classifier trained on topics discovered via Multi-Grain LDA and star ratings available in training data. Zh</context>
<context position="4466" citStr="Hu and Liu, 2004" startWordPosition="670" endWordPosition="673">mization to group aspect expressions into user-defined aspect categories. 683 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 683–687, Dublin, Ireland, August 23-24, 2014. 2.3 Sentence Sentiment Lexicon-based approaches to detecting sentiment in a sentence rely on a lexicon where words and phrases are provided with sentiment labels as well as on techniques to recognize “polarity shifters”, phrases causing the polarity of a lexical item to reverse. Early work on detection of polarity shifters used surface-level patterns (Yu and Hatzivassilouglu, 2003; Hu and Liu, 2004). Moilanen and Pulman (2007) provide a logic-oriented framework to compute the polarity of grammatical structures, that is capable of dealing with phenomena such as sentiment propagation, polarity reversal, and polarity conflict. Several papers looked at different ways to use syntactic dependency information in a machine learning framework, to better account for negations and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated d</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining opinion features in customer reviews. Proceedings of the 9th National Conference on Artificial Intelligence (AAAI-2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Opinion Spam and Analysis</title>
<date>2008</date>
<booktitle>Proceedings of WWW-2008.</booktitle>
<contexts>
<context position="13338" citStr="Jindal and Liu, 2008" startWordPosition="2144" endWordPosition="2147"> used encodes the lemma, the part-of-speech tag, and the polarity of the sentiment word. It was built by combining three resources: lemmas from SentiWordNet (Baccianella et al., 2010), which do not belong to more than 3 synsets; the General Inquirer lexicon (Stone et al., 1966), and a subsection of the Roget thesaurus annotated for sentiment (Heng, 2004). In addition, we added sentiment expressions that are characteristic of the restaurants and laptop domains, obtained based on manual analysis of the restaurants corpus used in (Snyder and Barzilay (2007) and the laptop reviews corpus used in (Jindal and Liu, 2008). To detect negated sentiment, we used a list of negating phrases such as “not”, “never”, etc., and two types of patterns to determine the scope of a negation. The first type detected negations on the sentence level, checking for negative phrases at the start of the sentence; negations detected on the sentence level were propagated to the clause level. The second type of patterns detected negated sentiment within a clause, using patterns specific to the part-of-speech of the sentiment word (e.g., “AUXV + negation + VB + MAINV”, where MAINV is a sentiment verb). The output of this algorithm is </context>
</contexts>
<marker>Jindal, Liu, 2008</marker>
<rawString>Nitin Jindal and Bing Liu. 2008. Opinion Spam and Analysis Proceedings of WWW-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying and analyzing judgment opinions.</title>
<date>2006</date>
<booktitle>Proceedings of HLT/NAACL-2006.</booktitle>
<contexts>
<context position="5051" citStr="Kim and Hovy, 2006" startWordPosition="761" endWordPosition="764">ssilouglu, 2003; Hu and Liu, 2004). Moilanen and Pulman (2007) provide a logic-oriented framework to compute the polarity of grammatical structures, that is capable of dealing with phenomena such as sentiment propagation, polarity reversal, and polarity conflict. Several papers looked at different ways to use syntactic dependency information in a machine learning framework, to better account for negations and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated data (Li et al, 2012), or queries to a search engine (Taboada et al., 2006). 3 Our Approach In the following sections, we will describe our approach to each stage of the Shared Task, reporting experiments on the provided training data using a 10-fold cross-validation. 3.1 Aspect Term Extraction During pre-processing training data was parsed using a dependency parser (Bohnet and Nivre, 2012), and sentiment words were recognized in it using a sentiment lexicon (see Section 6.1). Candidate terms were extracted as single nouns, noun phrases, adjectives and verbs, enforcing certain ex</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Identifying and analyzing judgment opinions. Proceedings of HLT/NAACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
</authors>
<title>Sinno Jialin Pan, Ou Jin, Qiang Yang and Xiaoyan Zhu.</title>
<date>2012</date>
<booktitle>Proceedings of ACL-2012.</booktitle>
<marker>Li, 2012</marker>
<rawString>Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang and Xiaoyan Zhu. 2012. Cross-Domain Co-Extraction of Sentiment and Topic Lexicons. Proceedings of ACL-2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tetsuji Nakagawa</author>
<author>Kentaro Inui</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using CRFs with hidden variables.</title>
<date>2010</date>
<booktitle>Proceedings of NAACL/HLT-2010.</booktitle>
<contexts>
<context position="4879" citStr="Nakagawa et al., 2010" startWordPosition="733" endWordPosition="736">gnize “polarity shifters”, phrases causing the polarity of a lexical item to reverse. Early work on detection of polarity shifters used surface-level patterns (Yu and Hatzivassilouglu, 2003; Hu and Liu, 2004). Moilanen and Pulman (2007) provide a logic-oriented framework to compute the polarity of grammatical structures, that is capable of dealing with phenomena such as sentiment propagation, polarity reversal, and polarity conflict. Several papers looked at different ways to use syntactic dependency information in a machine learning framework, to better account for negations and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated data (Li et al, 2012), or queries to a search engine (Taboada et al., 2006). 3 Our Approach In the following sections, we will describe our approach to each stage of the Shared Task, reporting experiments on the provided training data using a 10-fold cross-validation. 3.1 Aspect Term Extraction During pre-processing training data was parsed using a dependency parser (Bohnet and Nivre, 2012), and sentiment words</context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Tetsuji Nakagawa, Kentaro Inui, and Sadao Kurohashi. 2010. Dependency tree-based sentiment classification using CRFs with hidden variables. Proceedings of NAACL/HLT-2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment composition.</title>
<date>2007</date>
<booktitle>Proceedings of the Recent Advances in Natural Language Processing (RANLP</booktitle>
<contexts>
<context position="4494" citStr="Moilanen and Pulman (2007)" startWordPosition="674" endWordPosition="678">spect expressions into user-defined aspect categories. 683 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 683–687, Dublin, Ireland, August 23-24, 2014. 2.3 Sentence Sentiment Lexicon-based approaches to detecting sentiment in a sentence rely on a lexicon where words and phrases are provided with sentiment labels as well as on techniques to recognize “polarity shifters”, phrases causing the polarity of a lexical item to reverse. Early work on detection of polarity shifters used surface-level patterns (Yu and Hatzivassilouglu, 2003; Hu and Liu, 2004). Moilanen and Pulman (2007) provide a logic-oriented framework to compute the polarity of grammatical structures, that is capable of dealing with phenomena such as sentiment propagation, polarity reversal, and polarity conflict. Several papers looked at different ways to use syntactic dependency information in a machine learning framework, to better account for negations and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated data (Li et al, 2012), or que</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Karo Moilanen and Stephen Pulman. 2007. Sentiment composition. Proceedings of the Recent Advances in Natural Language Processing (RANLP 2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Haris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>SemEval-2014 Task 4: Aspect Based Sentiment Analysis.</title>
<date>2014</date>
<booktitle>Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="5743" citStr="Pontiki et al., 2014" startWordPosition="870" endWordPosition="873">oada et al., 2006). 3 Our Approach In the following sections, we will describe our approach to each stage of the Shared Task, reporting experiments on the provided training data using a 10-fold cross-validation. 3.1 Aspect Term Extraction During pre-processing training data was parsed using a dependency parser (Bohnet and Nivre, 2012), and sentiment words were recognized in it using a sentiment lexicon (see Section 6.1). Candidate terms were extracted as single nouns, noun phrases, adjectives and verbs, enforcing certain exceptions as detailed in the annotation guidelines for the Shared Task (Pontiki et al., 2014), namely: • Sentiment words were not allowed as part of terms; • Noun phrases with all elements capitalized and acronyms were excluded, under the assumption they refer to brands rather than product aspects; • Nouns referring to the product class as a whole (“restaurant”, “laptop”, etc) were excluded. Candidate terms that exactly overlapped with manually annotated terms were discarded, while those that did not were used as negative examples of aspect terms. In order to provide the term extraction process with additional lexical knowledge, from the training data we extracted those manually annot</context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Haris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. SemEval-2014 Task 4: Aspect Based Sentiment Analysis. Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting productfeatures and opinions from reviews.</title>
<date>2005</date>
<booktitle>Proceedings HLT/EMNLP-2005.</booktitle>
<contexts>
<context position="3325" citStr="Popescu and Etzioni, 2005" startWordPosition="499" endWordPosition="502">rule-based processing. 2 Related Work 2.1 Aspect Term Extraction To recognize terms that express key notions in a product or service review, a common general approach has been to extract nouns and noun phrases as potential terms and then apply a certain filtering technique to ensure only the most relevant terms remain. These techniques include statistical association tests (Yi et al., 2003), associative mining rules with additional rule-based post-processing steps (Hu and Liu, 2004), and measures of association with certain pre-defined classes of words, such as part-whole relation indicators (Popescu and Etzioni, 2005). 2.2 Aspect Category Recognition Aspect category recognition is often addressed as a text classification problem, where a classifier is learned from reviews manually tagged for aspects (e.g., Snyder and Barzilay, 2007, Ganu et al., 2009). Titov and McDonald (2008) present an approach which jointly detects aspect categories and their sentiment using a classifier trained on topics discovered via Multi-Grain LDA and star ratings available in training data. Zhai et al. (2010) presented an approach based on ExpectationMaximization to group aspect expressions into user-defined aspect categories. 68</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting productfeatures and opinions from reviews. Proceedings HLT/EMNLP-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>A class-based approach to lexical discovery</title>
<date>1992</date>
<booktitle>Proceedings of the Proceedings of the 30th Annual Meeting of the Association for Computational Linguists.</booktitle>
<contexts>
<context position="6590" citStr="Resnik (1992)" startWordPosition="1008" endWordPosition="1009">oduct class as a whole (“restaurant”, “laptop”, etc) were excluded. Candidate terms that exactly overlapped with manually annotated terms were discarded, while those that did not were used as negative examples of aspect terms. In order to provide the term extraction process with additional lexical knowledge, from the training data we extracted those manually annotated terms that corresponded to a single aspect category. Then the set of terms belonging to each category was augmented using WordNet: first we determined the 5 most prominent hyperonyms of these terms in the WordNet hierarchy using Resnik (1992)’s algorithm for learning a class in a semantic hierarchy that best represents selectional preferences of a verb, additionally requiring that each hypernym is at least 7 nodes away from the root, to make them sufficiently specific. Then we obtained all lexical items that belong to children synsets of these hypernyms, and further extended these lexical items with their meronyms and morphological derivatives. The resulting set of lexical items was later used as an extended aspect term lexicon. We additionally created a list of all individual lemmas of content words found in this lexicon. For eac</context>
</contexts>
<marker>Resnik, 1992</marker>
<rawString>Philip Resnik. 1992. A class-based approach to lexical discovery Proceedings of the Proceedings of the 30th Annual Meeting of the Association for Computational Linguists.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Multiple Aspect Ranking using the Good GriefAlgorithm.</title>
<date>2007</date>
<booktitle>Proceedings of NAACL-2007.</booktitle>
<contexts>
<context position="3543" citStr="Snyder and Barzilay, 2007" startWordPosition="531" endWordPosition="534">ial terms and then apply a certain filtering technique to ensure only the most relevant terms remain. These techniques include statistical association tests (Yi et al., 2003), associative mining rules with additional rule-based post-processing steps (Hu and Liu, 2004), and measures of association with certain pre-defined classes of words, such as part-whole relation indicators (Popescu and Etzioni, 2005). 2.2 Aspect Category Recognition Aspect category recognition is often addressed as a text classification problem, where a classifier is learned from reviews manually tagged for aspects (e.g., Snyder and Barzilay, 2007, Ganu et al., 2009). Titov and McDonald (2008) present an approach which jointly detects aspect categories and their sentiment using a classifier trained on topics discovered via Multi-Grain LDA and star ratings available in training data. Zhai et al. (2010) presented an approach based on ExpectationMaximization to group aspect expressions into user-defined aspect categories. 683 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 683–687, Dublin, Ireland, August 23-24, 2014. 2.3 Sentence Sentiment Lexicon-based approaches to detecting sentiment in a sen</context>
<context position="13277" citStr="Snyder and Barzilay (2007)" startWordPosition="2132" endWordPosition="2135">ntence, we take a lexicon-based approach. The sentiment lexicon we used encodes the lemma, the part-of-speech tag, and the polarity of the sentiment word. It was built by combining three resources: lemmas from SentiWordNet (Baccianella et al., 2010), which do not belong to more than 3 synsets; the General Inquirer lexicon (Stone et al., 1966), and a subsection of the Roget thesaurus annotated for sentiment (Heng, 2004). In addition, we added sentiment expressions that are characteristic of the restaurants and laptop domains, obtained based on manual analysis of the restaurants corpus used in (Snyder and Barzilay (2007) and the laptop reviews corpus used in (Jindal and Liu, 2008). To detect negated sentiment, we used a list of negating phrases such as “not”, “never”, etc., and two types of patterns to determine the scope of a negation. The first type detected negations on the sentence level, checking for negative phrases at the start of the sentence; negations detected on the sentence level were propagated to the clause level. The second type of patterns detected negated sentiment within a clause, using patterns specific to the part-of-speech of the sentiment word (e.g., “AUXV + negation + VB + MAINV”, where</context>
</contexts>
<marker>Snyder, Barzilay, 2007</marker>
<rawString>Benjamin Snyder and Regina Barzilay 2007. Multiple Aspect Ranking using the Good GriefAlgorithm. Proceedings of NAACL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Y Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank.</title>
<date>2013</date>
<booktitle>Proceedings of EMNLP-2013.</booktitle>
<contexts>
<context position="4901" citStr="Socher et al., 2013" startWordPosition="737" endWordPosition="740">s”, phrases causing the polarity of a lexical item to reverse. Early work on detection of polarity shifters used surface-level patterns (Yu and Hatzivassilouglu, 2003; Hu and Liu, 2004). Moilanen and Pulman (2007) provide a logic-oriented framework to compute the polarity of grammatical structures, that is capable of dealing with phenomena such as sentiment propagation, polarity reversal, and polarity conflict. Several papers looked at different ways to use syntactic dependency information in a machine learning framework, to better account for negations and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated data (Li et al, 2012), or queries to a search engine (Taboada et al., 2006). 3 Our Approach In the following sections, we will describe our approach to each stage of the Shared Task, reporting experiments on the provided training data using a 10-fold cross-validation. 3.1 Aspect Term Extraction During pre-processing training data was parsed using a dependency parser (Bohnet and Nivre, 2012), and sentiment words were recognized in it</context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng and Christopher Potts 2013. Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank. Proceedings of EMNLP-2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Stone</author>
<author>Dexter C Dunphy</author>
<author>Marshall S Smith</author>
<author>Daniel M Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="12995" citStr="Stone et al., 1966" startWordPosition="2087" endWordPosition="2090">e task submission. Table 8 reports results achieved on the test data of the Shared Task. P R F Restaurants 81.8 67.9 74.2 Baseline 64.8 52.5 58.0 Table 8: Aspect category extraction on the test data of the Shared Task. 3.3 Aspect Term Sentiment To recognize sentiment in a sentence, we take a lexicon-based approach. The sentiment lexicon we used encodes the lemma, the part-of-speech tag, and the polarity of the sentiment word. It was built by combining three resources: lemmas from SentiWordNet (Baccianella et al., 2010), which do not belong to more than 3 synsets; the General Inquirer lexicon (Stone et al., 1966), and a subsection of the Roget thesaurus annotated for sentiment (Heng, 2004). In addition, we added sentiment expressions that are characteristic of the restaurants and laptop domains, obtained based on manual analysis of the restaurants corpus used in (Snyder and Barzilay (2007) and the laptop reviews corpus used in (Jindal and Liu, 2008). To detect negated sentiment, we used a list of negating phrases such as “not”, “never”, etc., and two types of patterns to determine the scope of a negation. The first type detected negations on the sentence level, checking for negative phrases at the sta</context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>Philip J. Stone, Dexter C. Dunphy, Marshall S. Smith, and Daniel M. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. Cambridge, MA: The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Caroline Anthony</author>
<author>Kimberly Voll</author>
</authors>
<title>Creating semantic orientation dictionaries</title>
<date>2006</date>
<booktitle>Proceedings of 5th International Conference on Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="5140" citStr="Taboada et al., 2006" startWordPosition="777" endWordPosition="780"> framework to compute the polarity of grammatical structures, that is capable of dealing with phenomena such as sentiment propagation, polarity reversal, and polarity conflict. Several papers looked at different ways to use syntactic dependency information in a machine learning framework, to better account for negations and their scope (Nakagawa et al., 2010; Socher et al., 2013). To adapt a generic sentiment lexicon to a new application domain, previous work exploited semantic relations encoded in WordNet (Kim and Hovy, 2006), unannotated data (Li et al, 2012), or queries to a search engine (Taboada et al., 2006). 3 Our Approach In the following sections, we will describe our approach to each stage of the Shared Task, reporting experiments on the provided training data using a 10-fold cross-validation. 3.1 Aspect Term Extraction During pre-processing training data was parsed using a dependency parser (Bohnet and Nivre, 2012), and sentiment words were recognized in it using a sentiment lexicon (see Section 6.1). Candidate terms were extracted as single nouns, noun phrases, adjectives and verbs, enforcing certain exceptions as detailed in the annotation guidelines for the Shared Task (Pontiki et al., 20</context>
</contexts>
<marker>Taboada, Anthony, Voll, 2006</marker>
<rawString>Maite Taboada, Caroline Anthony, and Kimberly Voll. 2006. Creating semantic orientation dictionaries Proceedings of 5th International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>A joint model of text and aspect ratings for sentiment summarization.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-2008.</booktitle>
<contexts>
<context position="3590" citStr="Titov and McDonald (2008)" startWordPosition="539" endWordPosition="542">chnique to ensure only the most relevant terms remain. These techniques include statistical association tests (Yi et al., 2003), associative mining rules with additional rule-based post-processing steps (Hu and Liu, 2004), and measures of association with certain pre-defined classes of words, such as part-whole relation indicators (Popescu and Etzioni, 2005). 2.2 Aspect Category Recognition Aspect category recognition is often addressed as a text classification problem, where a classifier is learned from reviews manually tagged for aspects (e.g., Snyder and Barzilay, 2007, Ganu et al., 2009). Titov and McDonald (2008) present an approach which jointly detects aspect categories and their sentiment using a classifier trained on topics discovered via Multi-Grain LDA and star ratings available in training data. Zhai et al. (2010) presented an approach based on ExpectationMaximization to group aspect expressions into user-defined aspect categories. 683 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 683–687, Dublin, Ireland, August 23-24, 2014. 2.3 Sentence Sentiment Lexicon-based approaches to detecting sentiment in a sentence rely on a lexicon where words and phrases</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. A joint model of text and aspect ratings for sentiment summarization. Proceedings of ACL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liheng Xu</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Yubo Chen</author>
<author>Jun Zhao</author>
</authors>
<title>Mining Opinion Words and Opinion Targets in a Two-Stage Framework.</title>
<date>2013</date>
<booktitle>Proceedings of ACL-2013.</booktitle>
<marker>Xu, Liu, Lai, Chen, Zhao, 2013</marker>
<rawString>Liheng Xu, Kang Liu, Siwei Lai, Yubo Chen and Jun Zhao. 2013. Mining Opinion Words and Opinion Targets in a Two-Stage Framework. Proceedings of ACL-2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeonghee Yi</author>
<author>Tetsuya Nasukawa</author>
<author>Razvan Bunescu</author>
<author>Wayne Niblack</author>
</authors>
<title>Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques.</title>
<date>2003</date>
<booktitle>Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM-2003),</booktitle>
<pages>423--434</pages>
<contexts>
<context position="3092" citStr="Yi et al., 2003" startWordPosition="467" endWordPosition="470">xts, complex categorization schemas, and a limited amount of annotated data. Therefore we focused on ways to exploit deep linguistic processing techniques, which we use for both creating complex classification features and rule-based processing. 2 Related Work 2.1 Aspect Term Extraction To recognize terms that express key notions in a product or service review, a common general approach has been to extract nouns and noun phrases as potential terms and then apply a certain filtering technique to ensure only the most relevant terms remain. These techniques include statistical association tests (Yi et al., 2003), associative mining rules with additional rule-based post-processing steps (Hu and Liu, 2004), and measures of association with certain pre-defined classes of words, such as part-whole relation indicators (Popescu and Etzioni, 2005). 2.2 Aspect Category Recognition Aspect category recognition is often addressed as a text classification problem, where a classifier is learned from reviews manually tagged for aspects (e.g., Snyder and Barzilay, 2007, Ganu et al., 2009). Titov and McDonald (2008) present an approach which jointly detects aspect categories and their sentiment using a classifier tr</context>
</contexts>
<marker>Yi, Nasukawa, Bunescu, Niblack, 2003</marker>
<rawString>Jeonghee Yi, Tetsuya Nasukawa, Razvan Bunescu, and Wayne Niblack. 2003. Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques. Proceedings of the 3rd IEEE International Conference on Data Mining (ICDM-2003), pp. 423-434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences.</title>
<date>2003</date>
<booktitle>Proceedings of EMNLP-03.</booktitle>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards Answering Opinion Questions: Separating Facts from Opinions and Identifying the Polarity of Opinion Sentences. Proceedings of EMNLP-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongwu Zhai</author>
<author>Bing Liu</author>
<author>Hua Xu</author>
<author>Peifa Jia</author>
</authors>
<title>Clustering productfeatures for opinion mining.</title>
<date>2011</date>
<booktitle>Proceedings of the 4th ACM International Conference on Web Search and Data Mining, ACM,</booktitle>
<pages>347354</pages>
<marker>Zhai, Liu, Xu, Jia, 2011</marker>
<rawString>Zhongwu Zhai, Bing Liu, Hua Xu and Peifa Jia. 2011. Clustering productfeatures for opinion mining. Proceedings of the 4th ACM International Conference on Web Search and Data Mining, ACM, pp 347354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>