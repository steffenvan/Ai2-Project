<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014847">
<title confidence="0.941921">
DFKI KeyWE: Ranking keyphrases extracted from scientific articles
</title>
<author confidence="0.965759">
Kathrin Eichler G¨unter Neumann
</author>
<affiliation confidence="0.867696">
DFKI - Language Technology DFKI - Language Technology
</affiliation>
<address confidence="0.71614">
Berlin, Germany Saarbr¨ucken, Germany
</address>
<email confidence="0.986823">
kathrin.eichler@dfki.de neumann@dfki.de
</email>
<sectionHeader confidence="0.993555" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999534352941177">
A central issue for making the content
of a scientific document quickly acces-
sible to a potential reader is the extrac-
tion of keyphrases, which capture the main
topic of the document. Keyphrases can
be extracted automatically by generating a
list of keyphrase candidates, ranking these
candidates, and selecting the top-ranked
candidates as keyphrases. We present the
KeyWE system, which uses an adapted
nominal group chunker for candidate ex-
traction and a supervised ranking algo-
rithm based on support vector machines
for ranking the extracted candidates. The
system was evaluated on data provided
for the SemEval 2010 Shared Task on
Keyphrase Extraction.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998776363636364">
Keyphrases capture the main topic of the docu-
ment in which they appear and can be useful for
making the content of a document quickly ac-
cessible to a potential reader. They can be pre-
sented to the reader directly, in order to provide
a short overview of the document, but can also
be processed further, e.g. for text summarization,
document clustering, question-answering or rela-
tion extraction. The task of extracting keyphrases
automatically can be performed by generating a
list of keyphrase candidates, ranking these can-
didates, and selecting the top-ranked candidates
as keyphrases. In the KeyWE system, candidates
are generated based on an adapted nominal group
chunker described in section 3 and ranked using
the SVMrank algorithm (Joachims, 2006), as de-
scribed in section 4. The used features are spec-
ified in section 5. In section 6, we present the
results achieved on the test data provided for the
SemEval 2010 Shared Task on Keyphrase Extrac-
tion1 by selecting as keyphrases the top 5, 10, and
15 top-ranked candidates, respectively.
</bodyText>
<sectionHeader confidence="0.999651" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9998528125">
The task of keyphrase extraction came up in the
1990s and was first treated as a supervised learn-
ing problem in the GenEx system (Turney, 1999).
Since then, the task has evolved and various new
approaches have been proposed. The task is usu-
ally performed in two steps: 1. candidate ex-
traction (or generation) and 2. keyphrase selec-
tion. The most common approach towards can-
didate extraction is to generate all n-grams up to
a particular length and filter them using stopword
lists. Lately, more sophisticated candidate extrac-
tion methods, usually based on additional linguis-
tic information (e.g. POS tags), have been pro-
posed and shown to produce better results (e.g.
Hulth (2004)). Liu et al. (2009) restrict their can-
didate list to verb, noun and adjective words. Kim
and Kan (2009) generate regular expression rules
to extract simplex nouns and nominal phrases. As
the majority of technical terms is in nominal group
positions2, we assume that the same holds true for
keyphrases and apply an adapted nominal group
chunker to extract keyphrase candidates.
The selection process is usually based on some
supervised learning algorithm, e.g. Naive Bayes
(Frank et al., 1999), genetic algorithms (Turney,
1999), neural networks (Wang et al., 2005) or de-
cision trees (Medelyan et al., 2009). Unsuper-
vised approaches have also been proposed, e.g. by
Mihalcea and Tarau (2004) and Liu et al. (2009).
However, as for the shared task, annotated train-
ing data was available, we opted for an approach
based on supervised learning.
</bodyText>
<footnote confidence="0.996071">
1http://semeval2.fbk.eu/semeval2.php?location=tasks#T6
2Experiments on 100 manually annotated scientific ab-
stracts from the biology domain showed that 94% of technical
terms are in nominal group position (Eichler et al., 2009).
</footnote>
<page confidence="0.93216">
150
</page>
<note confidence="0.5519855">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 150–153,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.971207" genericHeader="method">
3 Candidate extraction
</sectionHeader>
<bodyText confidence="0.999983893617021">
Rather than extracting candidates from the full text
of the article, we restrict our search for candidates
to the first 2000 characters starting with the ab-
stract3. We also extract title and general terms
for use in the feature construction process. From
the reduced input text, we extract keyphrase candi-
dates based on the output of a nominal group chun-
ker.
This approach is inspired by findings from cog-
nitive linguistics. Talmy (2000) divides the con-
cepts expressed in language into two subsystems:
the grammatical subsystem and the lexical sub-
system. Concepts associated with the grammati-
cal subsystem provide a structuring function and
are expressed using so-called closed-class forms
(function words, such as conjunctions, determin-
ers, pronouns, and prepositions, but also suf-
fixes such as plural markers and tense markers).
Closed-class elements (CCEs) provide a scaffold-
ing, across which concepts associated with the lex-
ical subsystem (i.e. nouns, verbs, adjectives and
adverbs) can be draped (Evans and Pourcel, 2009).
Spurk (2006) developed a nominal group (NG)
chunker that makes use of this grammatical sub-
system. Using a finite list of CCEs and learned
word class models for identifying verbs and ad-
verbs, a small set of linguistically motivated ex-
traction patterns is stated to extract NGs. The rules
are based on the following four types of occur-
rences of NGs in English: 1. at the sentence be-
ginning, 2. within a determiner phrase, 3. follow-
ing a preposition and 4. following a verb. Not
being trained on a particular corpus, the chunker
works in a domain-independent way. In addition,
it scales well to large amounts of textual data.
In order to use the chunker for keyphrase extrac-
tion, we manually analysed annotated keyphrases
in scientific texts, and, based on the outcome of the
evaluation, made some adaptations to the chun-
ker, which take care of the fact that the boundaries
of a keyphrase do not always coincide with the
boundaries of a NG. In particular, we remove de-
terminers, split NGs on conjunctions, and process
text within parentheses separately from the main
text. An evaluation on the provided training data
showed that the adapted chunker extracts 80% of
the reader-annotated keyphrases found in the text.
</bodyText>
<footnote confidence="0.955163666666667">
3This usually covers the introductory part of the article
and is assumed to contain most of the keyphrases. Partial
sentences at the end of this input are cut off.
</footnote>
<sectionHeader confidence="0.893348" genericHeader="method">
4 Candidate ranking
</sectionHeader>
<bodyText confidence="0.99990632">
The problem of ranking keyphrase candidates can
be formalized as follows: For a document d and
a collection of n keyword candidates C = c1...cn,
the goal is to compute a ranking r that orders
the candidates in C according to their degree of
keyphraseness in d.
The problem can be transformed into an ordinal
regression problem. In ordinal regression, the la-
bel assigned to an example indicates a rank (rather
than a nominal class, as in classification prob-
lems). The ranking algorithm we use is SVMrank,
developed by Joachims (2006). This algorithm
learns a linear ranking function and has shown to
outperform classification algorithms in keyphrase
extraction (Jiang et al., 2009).
The target (i.e. rank) value defines the order of
the examples (i.e. keyphrase candidates). Dur-
ing training, the target values are used to gener-
ate pairwise preference constraints. A preference
constraint is included for all pairs of examples in
the training file, for which the target value differs.
Two examples are considered for a pairwise pref-
erence constraint only if they appear within the
same document.
The model that is learned from the training data
is then used to make predictions on the test ex-
amples. For each line in the test data, the model
predicts a ranking score, from which the ranking
of the test examples can be recovered via sorting.
For ranking the candidates, they are transformed
into vectors based on the features described in sec-
tion 5.
During training, the set of candidates is made up
of the annotated reader and author keywords as
well as all NG chunks extracted from the text.
These candidates are mapped to three different
ranking values: All annotated keywords are given
a ranking value of 2; all extracted NG chunks
that were annotated somewhere else in the train-
ing data are given a ranking value of 1; all other
NG chunks are assigned a ranking value of 0.
Giving a special ranking value to chunks an-
notated somewhere else in the corpus is a way
of exploiting domain-specific information about
keyphrases. Even though not annotated in this par-
ticular document, a candidate that has been anno-
tated in some other document of the domain, is
more likely to be a keyphrase than a candidate that
has never been annotated before (cf. Frank et al.
(1999)).
</bodyText>
<page confidence="0.997259">
151
</page>
<sectionHeader confidence="0.999176" genericHeader="method">
5 Features
</sectionHeader>
<bodyText confidence="0.999969625">
We used two types of features: term-specific
features and document-specific features. Term-
specific features cover properties of the candidate
term itself (e.g. term length). Document-specific
features relate properties of the candidate to the
text, in which it appears (e.g. frequency of the
term in the document). Our term-specific features
concern the following properties:
</bodyText>
<listItem confidence="0.99037625">
• Term length refers to the length of a can-
didate in number of tokens. We express
this property in terms of five boolean fea-
tures: has1token, has2tokens, has3tokens,
has4tokens, hasSorMoreTokens. The advan-
tage over expressing term length as a nu-
meric value is that using binary features, we
allow the algorithm to learn that candidates
of medium lengths are more likely to be
keyphrases than very short or very long can-
didates.
• The MSN score of a candidate refers to the
</listItem>
<bodyText confidence="0.8586859">
number of results retrieved when querying
the candidate string using the MSN search
engine4. The usefulness of MSN scores for
technical term extraction has been shown by
Eichler et al. (2009). We normalize the MSN
scores based on the number of digits of the
score and store the normalized value in the
feature normalizedMsn. We also use a binary
feature isZeroMsn expressing whether query-
ing the candidate returns no results at all.
</bodyText>
<listItem confidence="0.999171">
• Special characters can indicate whether a
candidate is (un)likely to be a keyphrase. We
use two features concerning special charac-
ters: containsDigit and containsHyphen.
• Wikipedia has shown to be a valuable source
</listItem>
<bodyText confidence="0.548137666666667">
for extracting keywords (Medelyan et al.,
2009). We use a feature isWikipediaTerm,
expressing whether the term candidate corre-
sponds to an entry in Wikipedia.
In addition, we use the following document-
specific features:
</bodyText>
<listItem confidence="0.9984725">
• TFIDF, a commonly used feature introduced
by Salton and McGill (1983), relates the fre-
quency of a candidate in a document to its
frequency in other documents of the corpus.
</listItem>
<footnote confidence="0.671331">
4http://de.msn.com/
</footnote>
<listItem confidence="0.98097121875">
• Term position relates the position of the first
appearance of the candidate in the document
to the length of the document. In addition,
our feature appearsInTitle covers the fact that
candidates appearing in the document title
are very likely to be keyphrases.
• Average token count measures the average
occurrence of the individual (lemmatized) to-
kens of the term in the document. Our
assumption is that candidates with a high
average token count are more likely to be
keyphrases.
• Point-wise mutual information (PMI,
Church and Hanks (1989)) is used to capture
the semantic relatedness of the candidate to
the topic of the document. A similar feature
is introduced by Turney (2003), who, in
a first pass, ranks the candidates based on
a base feature set, and then reranks them
by calculating the statistical association
between the given candidate and the top K
candidates from the first pass. To avoid the
two-pass method, rather than calculating
inter-candidate association, we calculate the
association of each candidate to the terms
specified in the General Terms section of
the paper. Like Turney, we calculate PMI
based on web search results (in our case,
using MSN). The feature maxPmi captures
the maximum PMI score achieved with the
lemmatized candidate and any of the general
terms.
</listItem>
<sectionHeader confidence="0.986806" genericHeader="evaluation">
6 Results and critical evaluation
</sectionHeader>
<bodyText confidence="0.9999435">
Table 1 presents the results achieved by applying
the KeyWE system on the data set of scientific
articles provided by the organizers of the shared
task along with two sets of manually assigned
keyphrases for each article (reader-assigned and
author-assigned keyphrases). Our model was
trained on the trial and training data (144 articles)
and evaluated on the test data set (100 articles).
The evaluation is based on stemmed keyphrases,
where stemming is performed using the Porter
stemmer (Porter, 1980).
Since SVMrank learns a linear function, one can
analyze the individual features by studying the
learned weights. Roughly speaking, a high pos-
itive (negative) weight indicates that candidates
with this feature should be higher (lower) in the
</bodyText>
<page confidence="0.99498">
152
</page>
<table confidence="0.999578857142857">
Top Set P R F
5 reader 24.40% 10.13% 14.32%
combined 29.20% 9.96% 14.85%
10 reader 19.80% 16.45% 17.97%
combined 23.30% 15.89% 18.89%
15 reader 17.40% 21.68% 19.31%
combined 20.27% 20.74% 20.50%
</table>
<tableCaption confidence="0.789359666666667">
Table 1: Results on the two keyword sets:
reader (reader-assigned keyphrases) and combined
(reader- and author-assigned keyphrases)
</tableCaption>
<bodyText confidence="0.999504071428572">
ranking. In our learned model, the four most im-
portant features (i.e. those with the highest ab-
solute weight) were containsDigit (-1.17), isZe-
roMsn (-1.12), normalizedMsn (-1.00), and avgTo-
kenCount (+0.97). This result confirms that web
frequencies can be used as a valuable source for
ranking keyphrases. It also validates our assump-
tion that a high average token count indicates a
good keyphrase candidate. The maxPMI feature
turned out to be of minor importance (-0.16). This
may be due to the fact that we used the terms from
the General Terms section of the paper to calculate
the association scores, which may be too general
for this purpose.
</bodyText>
<sectionHeader confidence="0.997475" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999943">
We thank Angela Schneider for her adaptations to
the chunker and helpful evaluations. The research
project DiLiA is co-funded by the European Re-
gional Development Fund (ERDF) in the context
of Investitionsbank Berlins ProFIT program under
grant number 10140159. We gratefully acknowl-
edge this support.
</bodyText>
<sectionHeader confidence="0.997778" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998221296875">
K. W. Church and P. Hanks. 1989. Word associa-
tion norms, mutual information and lexicography. In
Proceedings of the 27th Annual Conference of the
Association of Computational Linguistics.
K. Eichler, H. Hemsen, and G. Neumann. 2009. Un-
supervised and domain-independent extraction of
technical terms from scientifc articles in digital li-
braries. In Proceedings of the LWA Information Re-
trieval Workshop, TU Darmstadt, Germany.
V. Evans and S. Pourcel. 2009. New Directions in Cog-
nitive Linguistics. John Benjamins Publishing Com-
pany.
E. Frank, G. W. Paynter, I. H. Witten, C. Gutwin,
and C. G. Nevill-Manning. 1999. Domain-specific
keyphrase extraction. In Proceedings of the 16th
International Joint Conference on Artificial Intelli-
gence.
A. Hulth. 2004. Combining Machine Learning and
Natural Language Processing for Automatic Key-
word Extraction. Ph.D. thesis, Department of Com-
puter and Systems Sciences, Stockholm University.
X. Jiang, Y. Hu, and H. Li. 2009. A ranking ap-
proach to keyphrase extraction. In Proceedings of
the 32nd Annual International ACM SIGIR Confer-
ence on Research and Development in Information
Retrieval.
T. Joachims. 2006. Training linear svms in linear time.
In Proceedings of the ACM Conference on Knowl-
edge Discovery and Data Mining.
S. N. Kim and M. Y. Kan. 2009. Re-examining auto-
matic keyphrase extraction approaches in scientific
articles. In Proceedings of the ACL/IJCNLP Multi-
word Expressions Workshop.
F. Liu, D. Pennell, F. Liu, and Y. Liu. 2009. Unsu-
pervised approaches for automatic keyword extrac-
tion using meeting transcripts. In Proceedings of the
Conference of the NAACL, HLT.
O. Medelyan, E. Frank, and I.H. Witten. 2009.
Human-competitive tagging using automatic
keyphrase extraction. In Proceedings of the Interna-
tional Conference of Empirical Methods in Natural
Language Processing (EMNLP).
R. Mihalcea and P. Tarau. 2004. TextRank: Bringing
order into texts. In Proceedings of the EMNLP.
M. F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.
G. Salton and M. J. McGill. 1983. Introduction to
modern information retrieval. McGraw-Hill.
C. Spurk. 2006. Ein minimal ¨uberwachtes Verfahren
zur Erkennung generischer Eigennamen in freien
Texten. Diplomarbeit, Saarland University, Ger-
many.
L. Talmy. 2000. Towards a cognitive semantics. MIT
Press, Cambridge, MA.
P. D. Turney. 1999. Learning to extract keyphrases
from text. Technical report, National Research
Council, Institute for Information Technology.
P. D. Turney. 2003. Coherent keyphrase extraction via
web mining. In Proceedings of the Eighteenth Inter-
national Joint Conference on Artificial Intelligence.
J.-B. Wang, H. Peng, and J.-S. Hu. 2005. Automatic
keyphrases extraction from document using back-
propagation. In Proceedings of 2005 international
conference on Machine Learning and Cybernetics.
</reference>
<page confidence="0.999212">
153
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.570938">
<title confidence="0.998313">DFKI KeyWE: Ranking keyphrases extracted from scientific articles</title>
<author confidence="0.999216">Kathrin Eichler G¨unter Neumann</author>
<affiliation confidence="0.989498">DFKI - Language Technology DFKI - Language Technology</affiliation>
<address confidence="0.991404">Berlin, Germany Saarbr¨ucken, Germany</address>
<email confidence="0.97565">kathrin.eichler@dfki.deneumann@dfki.de</email>
<abstract confidence="0.998353176470588">A central issue for making the content of a scientific document quickly accessible to a potential reader is the extraction of keyphrases, which capture the main topic of the document. Keyphrases can be extracted automatically by generating a list of keyphrase candidates, ranking these candidates, and selecting the top-ranked candidates as keyphrases. We present the KeyWE system, which uses an adapted nominal group chunker for candidate extraction and a supervised ranking algorithm based on support vector machines for ranking the extracted candidates. The system was evaluated on data provided for the SemEval 2010 Shared Task on</abstract>
<intro confidence="0.612495">Keyphrase Extraction.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K W Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information and lexicography.</title>
<date>1989</date>
<booktitle>In Proceedings of the 27th Annual Conference of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="11095" citStr="Church and Hanks (1989)" startWordPosition="1787" endWordPosition="1790">cument to its frequency in other documents of the corpus. 4http://de.msn.com/ • Term position relates the position of the first appearance of the candidate in the document to the length of the document. In addition, our feature appearsInTitle covers the fact that candidates appearing in the document title are very likely to be keyphrases. • Average token count measures the average occurrence of the individual (lemmatized) tokens of the term in the document. Our assumption is that candidates with a high average token count are more likely to be keyphrases. • Point-wise mutual information (PMI, Church and Hanks (1989)) is used to capture the semantic relatedness of the candidate to the topic of the document. A similar feature is introduced by Turney (2003), who, in a first pass, ranks the candidates based on a base feature set, and then reranks them by calculating the statistical association between the given candidate and the top K candidates from the first pass. To avoid the two-pass method, rather than calculating inter-candidate association, we calculate the association of each candidate to the terms specified in the General Terms section of the paper. Like Turney, we calculate PMI based on web search </context>
</contexts>
<marker>Church, Hanks, 1989</marker>
<rawString>K. W. Church and P. Hanks. 1989. Word association norms, mutual information and lexicography. In Proceedings of the 27th Annual Conference of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Eichler</author>
<author>H Hemsen</author>
<author>G Neumann</author>
</authors>
<title>Unsupervised and domain-independent extraction of technical terms from scientifc articles in digital libraries.</title>
<date>2009</date>
<booktitle>In Proceedings of the LWA Information Retrieval Workshop,</booktitle>
<location>TU Darmstadt, Germany.</location>
<contexts>
<context position="3719" citStr="Eichler et al., 2009" startWordPosition="578" endWordPosition="581">gorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervised approaches have also been proposed, e.g. by Mihalcea and Tarau (2004) and Liu et al. (2009). However, as for the shared task, annotated training data was available, we opted for an approach based on supervised learning. 1http://semeval2.fbk.eu/semeval2.php?location=tasks#T6 2Experiments on 100 manually annotated scientific abstracts from the biology domain showed that 94% of technical terms are in nominal group position (Eichler et al., 2009). 150 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 150–153, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics 3 Candidate extraction Rather than extracting candidates from the full text of the article, we restrict our search for candidates to the first 2000 characters starting with the abstract3. We also extract title and general terms for use in the feature construction process. From the reduced input text, we extract keyphrase candidates based on the output of a nominal group chunker. This approach is inspired by findi</context>
<context position="9675" citStr="Eichler et al. (2009)" startWordPosition="1558" endWordPosition="1561">didate in number of tokens. We express this property in terms of five boolean features: has1token, has2tokens, has3tokens, has4tokens, hasSorMoreTokens. The advantage over expressing term length as a numeric value is that using binary features, we allow the algorithm to learn that candidates of medium lengths are more likely to be keyphrases than very short or very long candidates. • The MSN score of a candidate refers to the number of results retrieved when querying the candidate string using the MSN search engine4. The usefulness of MSN scores for technical term extraction has been shown by Eichler et al. (2009). We normalize the MSN scores based on the number of digits of the score and store the normalized value in the feature normalizedMsn. We also use a binary feature isZeroMsn expressing whether querying the candidate returns no results at all. • Special characters can indicate whether a candidate is (un)likely to be a keyphrase. We use two features concerning special characters: containsDigit and containsHyphen. • Wikipedia has shown to be a valuable source for extracting keywords (Medelyan et al., 2009). We use a feature isWikipediaTerm, expressing whether the term candidate corresponds to an e</context>
</contexts>
<marker>Eichler, Hemsen, Neumann, 2009</marker>
<rawString>K. Eichler, H. Hemsen, and G. Neumann. 2009. Unsupervised and domain-independent extraction of technical terms from scientifc articles in digital libraries. In Proceedings of the LWA Information Retrieval Workshop, TU Darmstadt, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Evans</author>
<author>S Pourcel</author>
</authors>
<title>New Directions in Cognitive Linguistics.</title>
<date>2009</date>
<publisher>John Benjamins Publishing Company.</publisher>
<contexts>
<context position="4952" citStr="Evans and Pourcel, 2009" startWordPosition="764" endWordPosition="767">cognitive linguistics. Talmy (2000) divides the concepts expressed in language into two subsystems: the grammatical subsystem and the lexical subsystem. Concepts associated with the grammatical subsystem provide a structuring function and are expressed using so-called closed-class forms (function words, such as conjunctions, determiners, pronouns, and prepositions, but also suffixes such as plural markers and tense markers). Closed-class elements (CCEs) provide a scaffolding, across which concepts associated with the lexical subsystem (i.e. nouns, verbs, adjectives and adverbs) can be draped (Evans and Pourcel, 2009). Spurk (2006) developed a nominal group (NG) chunker that makes use of this grammatical subsystem. Using a finite list of CCEs and learned word class models for identifying verbs and adverbs, a small set of linguistically motivated extraction patterns is stated to extract NGs. The rules are based on the following four types of occurrences of NGs in English: 1. at the sentence beginning, 2. within a determiner phrase, 3. following a preposition and 4. following a verb. Not being trained on a particular corpus, the chunker works in a domain-independent way. In addition, it scales well to large </context>
</contexts>
<marker>Evans, Pourcel, 2009</marker>
<rawString>V. Evans and S. Pourcel. 2009. New Directions in Cognitive Linguistics. John Benjamins Publishing Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Frank</author>
<author>G W Paynter</author>
<author>I H Witten</author>
<author>C Gutwin</author>
<author>C G Nevill-Manning</author>
</authors>
<title>Domain-specific keyphrase extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="3144" citStr="Frank et al., 1999" startWordPosition="493" endWordPosition="496">n additional linguistic information (e.g. POS tags), have been proposed and shown to produce better results (e.g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, noun and adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervised approaches have also been proposed, e.g. by Mihalcea and Tarau (2004) and Liu et al. (2009). However, as for the shared task, annotated training data was available, we opted for an approach based on supervised learning. 1http://semeval2.fbk.eu/semeval2.php?location=tasks#T6 2Experiments on 100 manually annotated scientific abstracts from the biology domain showed that 94% of technical terms are in nominal group position (Eichler et al., 2009). 150 Proceedings of the </context>
<context position="8617" citStr="Frank et al. (1999)" startWordPosition="1388" endWordPosition="1391">values: All annotated keywords are given a ranking value of 2; all extracted NG chunks that were annotated somewhere else in the training data are given a ranking value of 1; all other NG chunks are assigned a ranking value of 0. Giving a special ranking value to chunks annotated somewhere else in the corpus is a way of exploiting domain-specific information about keyphrases. Even though not annotated in this particular document, a candidate that has been annotated in some other document of the domain, is more likely to be a keyphrase than a candidate that has never been annotated before (cf. Frank et al. (1999)). 151 5 Features We used two types of features: term-specific features and document-specific features. Termspecific features cover properties of the candidate term itself (e.g. term length). Document-specific features relate properties of the candidate to the text, in which it appears (e.g. frequency of the term in the document). Our term-specific features concern the following properties: • Term length refers to the length of a candidate in number of tokens. We express this property in terms of five boolean features: has1token, has2tokens, has3tokens, has4tokens, hasSorMoreTokens. The advant</context>
</contexts>
<marker>Frank, Paynter, Witten, Gutwin, Nevill-Manning, 1999</marker>
<rawString>E. Frank, G. W. Paynter, I. H. Witten, C. Gutwin, and C. G. Nevill-Manning. 1999. Domain-specific keyphrase extraction. In Proceedings of the 16th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hulth</author>
</authors>
<title>Combining Machine Learning and Natural Language Processing for Automatic Keyword Extraction.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer and Systems Sciences, Stockholm University.</institution>
<contexts>
<context position="2651" citStr="Hulth (2004)" startWordPosition="416" endWordPosition="417">treated as a supervised learning problem in the GenEx system (Turney, 1999). Since then, the task has evolved and various new approaches have been proposed. The task is usually performed in two steps: 1. candidate extraction (or generation) and 2. keyphrase selection. The most common approach towards candidate extraction is to generate all n-grams up to a particular length and filter them using stopword lists. Lately, more sophisticated candidate extraction methods, usually based on additional linguistic information (e.g. POS tags), have been proposed and shown to produce better results (e.g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, noun and adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al.</context>
</contexts>
<marker>Hulth, 2004</marker>
<rawString>A. Hulth. 2004. Combining Machine Learning and Natural Language Processing for Automatic Keyword Extraction. Ph.D. thesis, Department of Computer and Systems Sciences, Stockholm University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Jiang</author>
<author>Y Hu</author>
<author>H Li</author>
</authors>
<title>A ranking approach to keyphrase extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="7031" citStr="Jiang et al., 2009" startWordPosition="1114" endWordPosition="1117"> as follows: For a document d and a collection of n keyword candidates C = c1...cn, the goal is to compute a ranking r that orders the candidates in C according to their degree of keyphraseness in d. The problem can be transformed into an ordinal regression problem. In ordinal regression, the label assigned to an example indicates a rank (rather than a nominal class, as in classification problems). The ranking algorithm we use is SVMrank, developed by Joachims (2006). This algorithm learns a linear ranking function and has shown to outperform classification algorithms in keyphrase extraction (Jiang et al., 2009). The target (i.e. rank) value defines the order of the examples (i.e. keyphrase candidates). During training, the target values are used to generate pairwise preference constraints. A preference constraint is included for all pairs of examples in the training file, for which the target value differs. Two examples are considered for a pairwise preference constraint only if they appear within the same document. The model that is learned from the training data is then used to make predictions on the test examples. For each line in the test data, the model predicts a ranking score, from which the</context>
</contexts>
<marker>Jiang, Hu, Li, 2009</marker>
<rawString>X. Jiang, Y. Hu, and H. Li. 2009. A ranking approach to keyphrase extraction. In Proceedings of the 32nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Training linear svms in linear time.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="1665" citStr="Joachims, 2006" startWordPosition="249" endWordPosition="250">sible to a potential reader. They can be presented to the reader directly, in order to provide a short overview of the document, but can also be processed further, e.g. for text summarization, document clustering, question-answering or relation extraction. The task of extracting keyphrases automatically can be performed by generating a list of keyphrase candidates, ranking these candidates, and selecting the top-ranked candidates as keyphrases. In the KeyWE system, candidates are generated based on an adapted nominal group chunker described in section 3 and ranked using the SVMrank algorithm (Joachims, 2006), as described in section 4. The used features are specified in section 5. In section 6, we present the results achieved on the test data provided for the SemEval 2010 Shared Task on Keyphrase Extraction1 by selecting as keyphrases the top 5, 10, and 15 top-ranked candidates, respectively. 2 Related work The task of keyphrase extraction came up in the 1990s and was first treated as a supervised learning problem in the GenEx system (Turney, 1999). Since then, the task has evolved and various new approaches have been proposed. The task is usually performed in two steps: 1. candidate extraction (</context>
<context position="6883" citStr="Joachims (2006)" startWordPosition="1095" endWordPosition="1096">rases. Partial sentences at the end of this input are cut off. 4 Candidate ranking The problem of ranking keyphrase candidates can be formalized as follows: For a document d and a collection of n keyword candidates C = c1...cn, the goal is to compute a ranking r that orders the candidates in C according to their degree of keyphraseness in d. The problem can be transformed into an ordinal regression problem. In ordinal regression, the label assigned to an example indicates a rank (rather than a nominal class, as in classification problems). The ranking algorithm we use is SVMrank, developed by Joachims (2006). This algorithm learns a linear ranking function and has shown to outperform classification algorithms in keyphrase extraction (Jiang et al., 2009). The target (i.e. rank) value defines the order of the examples (i.e. keyphrase candidates). During training, the target values are used to generate pairwise preference constraints. A preference constraint is included for all pairs of examples in the training file, for which the target value differs. Two examples are considered for a pairwise preference constraint only if they appear within the same document. The model that is learned from the tra</context>
</contexts>
<marker>Joachims, 2006</marker>
<rawString>T. Joachims. 2006. Training linear svms in linear time. In Proceedings of the ACM Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>M Y Kan</author>
</authors>
<title>Re-examining automatic keyphrase extraction approaches in scientific articles.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL/IJCNLP Multiword Expressions Workshop.</booktitle>
<contexts>
<context position="2755" citStr="Kim and Kan (2009)" startWordPosition="433" endWordPosition="436">has evolved and various new approaches have been proposed. The task is usually performed in two steps: 1. candidate extraction (or generation) and 2. keyphrase selection. The most common approach towards candidate extraction is to generate all n-grams up to a particular length and filter them using stopword lists. Lately, more sophisticated candidate extraction methods, usually based on additional linguistic information (e.g. POS tags), have been proposed and shown to produce better results (e.g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, noun and adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervised approaches have also been proposed, e.g. by Mihalcea and Tarau (2004) and Liu et a</context>
</contexts>
<marker>Kim, Kan, 2009</marker>
<rawString>S. N. Kim and M. Y. Kan. 2009. Re-examining automatic keyphrase extraction approaches in scientific articles. In Proceedings of the ACL/IJCNLP Multiword Expressions Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Liu</author>
<author>D Pennell</author>
<author>F Liu</author>
<author>Y Liu</author>
</authors>
<title>Unsupervised approaches for automatic keyword extraction using meeting transcripts.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference of the NAACL, HLT.</booktitle>
<contexts>
<context position="2671" citStr="Liu et al. (2009)" startWordPosition="418" endWordPosition="421">pervised learning problem in the GenEx system (Turney, 1999). Since then, the task has evolved and various new approaches have been proposed. The task is usually performed in two steps: 1. candidate extraction (or generation) and 2. keyphrase selection. The most common approach towards candidate extraction is to generate all n-grams up to a particular length and filter them using stopword lists. Lately, more sophisticated candidate extraction methods, usually based on additional linguistic information (e.g. POS tags), have been proposed and shown to produce better results (e.g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, noun and adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervise</context>
</contexts>
<marker>Liu, Pennell, Liu, Liu, 2009</marker>
<rawString>F. Liu, D. Pennell, F. Liu, and Y. Liu. 2009. Unsupervised approaches for automatic keyword extraction using meeting transcripts. In Proceedings of the Conference of the NAACL, HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Medelyan</author>
<author>E Frank</author>
<author>I H Witten</author>
</authors>
<title>Human-competitive tagging using automatic keyphrase extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference of Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="3258" citStr="Medelyan et al., 2009" startWordPosition="511" endWordPosition="514">g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, noun and adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervised approaches have also been proposed, e.g. by Mihalcea and Tarau (2004) and Liu et al. (2009). However, as for the shared task, annotated training data was available, we opted for an approach based on supervised learning. 1http://semeval2.fbk.eu/semeval2.php?location=tasks#T6 2Experiments on 100 manually annotated scientific abstracts from the biology domain showed that 94% of technical terms are in nominal group position (Eichler et al., 2009). 150 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 150–153, Uppsala, Sweden, 15-16 July 2010. c�20</context>
<context position="10182" citStr="Medelyan et al., 2009" startWordPosition="1640" endWordPosition="1643"> search engine4. The usefulness of MSN scores for technical term extraction has been shown by Eichler et al. (2009). We normalize the MSN scores based on the number of digits of the score and store the normalized value in the feature normalizedMsn. We also use a binary feature isZeroMsn expressing whether querying the candidate returns no results at all. • Special characters can indicate whether a candidate is (un)likely to be a keyphrase. We use two features concerning special characters: containsDigit and containsHyphen. • Wikipedia has shown to be a valuable source for extracting keywords (Medelyan et al., 2009). We use a feature isWikipediaTerm, expressing whether the term candidate corresponds to an entry in Wikipedia. In addition, we use the following documentspecific features: • TFIDF, a commonly used feature introduced by Salton and McGill (1983), relates the frequency of a candidate in a document to its frequency in other documents of the corpus. 4http://de.msn.com/ • Term position relates the position of the first appearance of the candidate in the document to the length of the document. In addition, our feature appearsInTitle covers the fact that candidates appearing in the document title are</context>
</contexts>
<marker>Medelyan, Frank, Witten, 2009</marker>
<rawString>O. Medelyan, E. Frank, and I.H. Witten. 2009. Human-competitive tagging using automatic keyphrase extraction. In Proceedings of the International Conference of Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>TextRank: Bringing order into texts.</title>
<date>2004</date>
<journal>Program,</journal>
<booktitle>In Proceedings of the</booktitle>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="3342" citStr="Mihalcea and Tarau (2004)" startWordPosition="524" endWordPosition="527">nd adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervised approaches have also been proposed, e.g. by Mihalcea and Tarau (2004) and Liu et al. (2009). However, as for the shared task, annotated training data was available, we opted for an approach based on supervised learning. 1http://semeval2.fbk.eu/semeval2.php?location=tasks#T6 2Experiments on 100 manually annotated scientific abstracts from the biology domain showed that 94% of technical terms are in nominal group position (Eichler et al., 2009). 150 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 150–153, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics 3 Candidate extraction Rather than extr</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>R. Mihalcea and P. Tarau. 2004. TextRank: Bringing order into texts. In Proceedings of the EMNLP. M. F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>M J McGill</author>
</authors>
<title>Introduction to modern information retrieval.</title>
<date>1983</date>
<publisher>McGraw-Hill.</publisher>
<contexts>
<context position="10426" citStr="Salton and McGill (1983)" startWordPosition="1678" endWordPosition="1681">edMsn. We also use a binary feature isZeroMsn expressing whether querying the candidate returns no results at all. • Special characters can indicate whether a candidate is (un)likely to be a keyphrase. We use two features concerning special characters: containsDigit and containsHyphen. • Wikipedia has shown to be a valuable source for extracting keywords (Medelyan et al., 2009). We use a feature isWikipediaTerm, expressing whether the term candidate corresponds to an entry in Wikipedia. In addition, we use the following documentspecific features: • TFIDF, a commonly used feature introduced by Salton and McGill (1983), relates the frequency of a candidate in a document to its frequency in other documents of the corpus. 4http://de.msn.com/ • Term position relates the position of the first appearance of the candidate in the document to the length of the document. In addition, our feature appearsInTitle covers the fact that candidates appearing in the document title are very likely to be keyphrases. • Average token count measures the average occurrence of the individual (lemmatized) tokens of the term in the document. Our assumption is that candidates with a high average token count are more likely to be keyp</context>
</contexts>
<marker>Salton, McGill, 1983</marker>
<rawString>G. Salton and M. J. McGill. 1983. Introduction to modern information retrieval. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Spurk</author>
</authors>
<date>2006</date>
<booktitle>Ein minimal ¨uberwachtes Verfahren zur Erkennung generischer Eigennamen in freien Texten. Diplomarbeit,</booktitle>
<location>Saarland University, Germany.</location>
<contexts>
<context position="4966" citStr="Spurk (2006)" startWordPosition="768" endWordPosition="769">my (2000) divides the concepts expressed in language into two subsystems: the grammatical subsystem and the lexical subsystem. Concepts associated with the grammatical subsystem provide a structuring function and are expressed using so-called closed-class forms (function words, such as conjunctions, determiners, pronouns, and prepositions, but also suffixes such as plural markers and tense markers). Closed-class elements (CCEs) provide a scaffolding, across which concepts associated with the lexical subsystem (i.e. nouns, verbs, adjectives and adverbs) can be draped (Evans and Pourcel, 2009). Spurk (2006) developed a nominal group (NG) chunker that makes use of this grammatical subsystem. Using a finite list of CCEs and learned word class models for identifying verbs and adverbs, a small set of linguistically motivated extraction patterns is stated to extract NGs. The rules are based on the following four types of occurrences of NGs in English: 1. at the sentence beginning, 2. within a determiner phrase, 3. following a preposition and 4. following a verb. Not being trained on a particular corpus, the chunker works in a domain-independent way. In addition, it scales well to large amounts of tex</context>
</contexts>
<marker>Spurk, 2006</marker>
<rawString>C. Spurk. 2006. Ein minimal ¨uberwachtes Verfahren zur Erkennung generischer Eigennamen in freien Texten. Diplomarbeit, Saarland University, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Talmy</author>
</authors>
<title>Towards a cognitive semantics.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4363" citStr="Talmy (2000)" startWordPosition="680" endWordPosition="681">ernational Workshop on Semantic Evaluation, ACL 2010, pages 150–153, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics 3 Candidate extraction Rather than extracting candidates from the full text of the article, we restrict our search for candidates to the first 2000 characters starting with the abstract3. We also extract title and general terms for use in the feature construction process. From the reduced input text, we extract keyphrase candidates based on the output of a nominal group chunker. This approach is inspired by findings from cognitive linguistics. Talmy (2000) divides the concepts expressed in language into two subsystems: the grammatical subsystem and the lexical subsystem. Concepts associated with the grammatical subsystem provide a structuring function and are expressed using so-called closed-class forms (function words, such as conjunctions, determiners, pronouns, and prepositions, but also suffixes such as plural markers and tense markers). Closed-class elements (CCEs) provide a scaffolding, across which concepts associated with the lexical subsystem (i.e. nouns, verbs, adjectives and adverbs) can be draped (Evans and Pourcel, 2009). Spurk (20</context>
</contexts>
<marker>Talmy, 2000</marker>
<rawString>L. Talmy. 2000. Towards a cognitive semantics. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Learning to extract keyphrases from text.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>National Research Council, Institute for Information Technology.</institution>
<contexts>
<context position="2114" citStr="Turney, 1999" startWordPosition="329" endWordPosition="330"> the KeyWE system, candidates are generated based on an adapted nominal group chunker described in section 3 and ranked using the SVMrank algorithm (Joachims, 2006), as described in section 4. The used features are specified in section 5. In section 6, we present the results achieved on the test data provided for the SemEval 2010 Shared Task on Keyphrase Extraction1 by selecting as keyphrases the top 5, 10, and 15 top-ranked candidates, respectively. 2 Related work The task of keyphrase extraction came up in the 1990s and was first treated as a supervised learning problem in the GenEx system (Turney, 1999). Since then, the task has evolved and various new approaches have been proposed. The task is usually performed in two steps: 1. candidate extraction (or generation) and 2. keyphrase selection. The most common approach towards candidate extraction is to generate all n-grams up to a particular length and filter them using stopword lists. Lately, more sophisticated candidate extraction methods, usually based on additional linguistic information (e.g. POS tags), have been proposed and shown to produce better results (e.g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, nou</context>
</contexts>
<marker>Turney, 1999</marker>
<rawString>P. D. Turney. 1999. Learning to extract keyphrases from text. Technical report, National Research Council, Institute for Information Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P D Turney</author>
</authors>
<title>Coherent keyphrase extraction via web mining.</title>
<date>2003</date>
<booktitle>In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="11236" citStr="Turney (2003)" startWordPosition="1813" endWordPosition="1814">date in the document to the length of the document. In addition, our feature appearsInTitle covers the fact that candidates appearing in the document title are very likely to be keyphrases. • Average token count measures the average occurrence of the individual (lemmatized) tokens of the term in the document. Our assumption is that candidates with a high average token count are more likely to be keyphrases. • Point-wise mutual information (PMI, Church and Hanks (1989)) is used to capture the semantic relatedness of the candidate to the topic of the document. A similar feature is introduced by Turney (2003), who, in a first pass, ranks the candidates based on a base feature set, and then reranks them by calculating the statistical association between the given candidate and the top K candidates from the first pass. To avoid the two-pass method, rather than calculating inter-candidate association, we calculate the association of each candidate to the terms specified in the General Terms section of the paper. Like Turney, we calculate PMI based on web search results (in our case, using MSN). The feature maxPmi captures the maximum PMI score achieved with the lemmatized candidate and any of the gen</context>
</contexts>
<marker>Turney, 2003</marker>
<rawString>P. D. Turney. 2003. Coherent keyphrase extraction via web mining. In Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-B Wang</author>
<author>H Peng</author>
<author>J-S Hu</author>
</authors>
<title>Automatic keyphrases extraction from document using backpropagation.</title>
<date>2005</date>
<booktitle>In Proceedings of 2005 international conference on Machine Learning and Cybernetics.</booktitle>
<contexts>
<context position="3216" citStr="Wang et al., 2005" startWordPosition="503" endWordPosition="506">nd shown to produce better results (e.g. Hulth (2004)). Liu et al. (2009) restrict their candidate list to verb, noun and adjective words. Kim and Kan (2009) generate regular expression rules to extract simplex nouns and nominal phrases. As the majority of technical terms is in nominal group positions2, we assume that the same holds true for keyphrases and apply an adapted nominal group chunker to extract keyphrase candidates. The selection process is usually based on some supervised learning algorithm, e.g. Naive Bayes (Frank et al., 1999), genetic algorithms (Turney, 1999), neural networks (Wang et al., 2005) or decision trees (Medelyan et al., 2009). Unsupervised approaches have also been proposed, e.g. by Mihalcea and Tarau (2004) and Liu et al. (2009). However, as for the shared task, annotated training data was available, we opted for an approach based on supervised learning. 1http://semeval2.fbk.eu/semeval2.php?location=tasks#T6 2Experiments on 100 manually annotated scientific abstracts from the biology domain showed that 94% of technical terms are in nominal group position (Eichler et al., 2009). 150 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 150–1</context>
</contexts>
<marker>Wang, Peng, Hu, 2005</marker>
<rawString>J.-B. Wang, H. Peng, and J.-S. Hu. 2005. Automatic keyphrases extraction from document using backpropagation. In Proceedings of 2005 international conference on Machine Learning and Cybernetics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>