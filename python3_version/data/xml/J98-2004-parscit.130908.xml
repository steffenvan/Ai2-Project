<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997899">
New Figures of Merit for
Best-First Probabilistic Chart Parsing
</title>
<author confidence="0.994786">
Sharon A. Caraballo* Eugene Charniak*
</author>
<affiliation confidence="0.996607">
Brown University Brown University
</affiliation>
<bodyText confidence="0.975148857142857">
Best-first parsing methods for natural language try to parse efficiently by considering the most
likely constituents first. Some figure of merit is needed by which to compare the likelihood of
constituents, and the choice of this figure has a substantial impact on the efficiency of the parser.
While several parsers described in the literature have used such techniques, there is little published
data on their efficacy, much less attempts to judge their relative merits. We propose and evaluate
several figures of merit for best-first parsing, and we identify an easily computable figure of merit
that provides excellent performance on various measures and two different grammars.
</bodyText>
<sectionHeader confidence="0.990235" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.99993744">
Chart parsing is a commonly used algorithm for parsing natural language texts. The
chart is a data structure that contains all of the constituents for which subtrees have
been found, that is, constituents for which a derivation has been found and which may
therefore appear in some complete parse of the sentence. The agenda is a structure that
stores a list of constituents for which a derivation has been found but which have not
yet been combined with other constituents. Initially, the agenda contains the terminal
symbols from the sentence to be parsed. A constituent is removed from the agenda
and added to the chart, and the system considers how this constituent can be used
to extend its current structural hypothesis by combining with other constituents in
the chart according to the grammar rules. (We will often refer to these expansions of
rules as &amp;quot;edges&amp;quot;) In general this can lead to the creation of new, more encompassing
constituents, which themselves are then added to the agenda. When one constituent
has been processed, a new one is chosen to be removed from the agenda, and so
on. Traditionally, the agenda is represented as a stack, so that the last item added
to the agenda is the next one removed. Chart parsing is described extensively in the
literature; for one such discussion see &apos;Section 1.4 of Charniak (1993).
Best-first probabilistic chart parsing is a variation of chart parsing that attempts
to find the most likely parses first, by adding constituents to the chart in order of
the likelihood that they will appear in a correct parse, rather than simply popping
constituents off of a stack. Some probabilistic figure of merit is assigned to the con-
stituents on the agenda, and the constituent maximizing this value is the next to be
added to the chart.
In this paper we consider probabilities primarily based on probabilistic context-
free grammars, though in principle, other, more complicated schemes could be used.
The purpose of this work is to compare how well several figures of merit select
</bodyText>
<note confidence="0.902393">
* Computer Science Department, Box 1910, Brown University, Providence, RI 02912. E-mail: {sc,
</note>
<email confidence="0.879042">
ec}@cs.brown.edu
</email>
<figure confidence="0.771178">
© 1998 Association for Computational Linguistics
Computational Linguistics Volume 24, Number 2
j,k
. . t
0 ttJ k— It k t n-1
</figure>
<figureCaption confidence="0.96674">
Figure 1
</figureCaption>
<bodyText confidence="0.9324405">
Constituent Nj&apos;A in a sentence ton.
constituents to be moved from the agenda to the chart. Ideally, we would like to use
as our figure of merit the conditional probability of that constituent, given the entire
sentence, in order to choose a constituent that not only appears likely in isolation,
but is most likely given the sentence as a whole; that is, we would like to pick the
constituent that maximizes the following quantity:
</bodyText>
<equation confidence="0.391866">
p(N),k I t,,,)
</equation>
<bodyText confidence="0.9827115">
where to, is the sequence of the n tags, or parts of speech, in the sentence (numbered
to,. • • tn-1), and Nip( is a nonterminal of type i covering terms tj tk_i. (See Figure 1.)
In our experiments, we use only tag sequences (as given in the test data) for pars-
ing. More accurate probability estimates should be attainable using lexical information
in future experiments, as more detail usually leads to better statistics, but lexicalized
figures of merit are beyond the scope of the research described here.
Note that our &amp;quot;ideal&amp;quot; figure is simply a heuristic, since there is no guarantee
that a constituent that scores well on this measure will appear in the correct parse
of a sentence. For example, there may be a very large number of low-probability
derivations of N&apos; 1c, which are combined here to give a high value, but a parse of the
1,
sentence can only include one of these derivations, making it unlikely that 1\141,k appears
in the most probable parse of the sentence. On the other hand, there is no reason to
believe that such cases are common in practice.
We cannot calculate p(Nk I to,), since in order to do so, we would need to com-
pletely parse the sentence. In this paper, we examine the performance of several pro-
posed figures of merit that approximate it in one way or another, using two different
grammars. We identify a figure of merit that gives superior results on all of our per-
formance measures and on both grammars.
Section 2 of this paper describes the method we used to determine the effectiveness
of figures of merit, that is, to compare how well they choose constituents to be moved
from the agenda to the chart. Section 2.1 explains the experiment, Section 2.2 describes
the measures we used to compare the performance of the figures of merit, and Section
2.3 describes a model we used to represent the performance of a traditional parser
using a simple stack as an agenda.
In Section 3, we describe and compare three simple and easily computable figures
of merit based on inside probability. Sections 3.1 through 3.3 describe each figure
in detail, and Section 3.4 presents the results of an experiment comparing these three
figures. Sections 4 and 5 have a similar structure to Section 3, with Section 4 evaluating
two figures of merit using statistics on the left-side context of the constituent, and
</bodyText>
<page confidence="0.992333">
276
</page>
<note confidence="0.905018">
Caraballo and Charniak Figures of Merit
</note>
<bodyText confidence="0.999937545454546">
Section 5 evaluating three additional figures of merit using statistics on the context on
both sides of the constituent. Section 6 contains a table summarizing the results from
Sections 3, 4, and 5.
In Section 7, we use another grammar in the experiment, to verify that our results
are not an artifact of the grammar used for parsing. Section 8 describes previous work
in this area, and Section 9 presents our conclusions and recommendations.
There are also three appendices to this paper. Appendix A gives our method for
computing inside probability estimates while maintaining parser speed. Appendix B
explains how we obtained our boundary statistics used in Section 5. Appendix C
presents data comparing the parsing accuracy obtained by each of our parsers as the
number of edges they create increases.
</bodyText>
<sectionHeader confidence="0.987697" genericHeader="keywords">
2. Comparing Figures of Merit
</sectionHeader>
<subsectionHeader confidence="0.998639">
2.1 The Experiment
</subsectionHeader>
<bodyText confidence="0.999940235294118">
We used as our first grammar a probabilistic context-free grammar learned from the
Brown corpus (see Francis and Kiera [1982] for a description of the Brown Cor-
pus, and Carroll and Charniak [1992a, 199213], and Charniak and Carroll [1994] for
grammar and training details). This grammar contains about 5,000 rules using 32 ter-
minal and nonterminal symbols. We parsed 500 sentences of length 3 to 30 (including
punctuation) from the Penn Treebank Wall Street Journal corpus (Marcus, Santorini,
and Marcinkiewicz 1993) using a best-first parsing method and various estimates for
p(I\/;), to,n ) as the figure of merit.
For each figure of merit, we compared the performance of best-first parsing using
that figure of merit to exhaustive parsing. By exhaustive parsing, we mean continuing
to parse until there are no more constituents available to be added to the chart. We
parse exhaustively to determine the total probability of a sentence, that is, the sum of
the probabilities of all parses found for that sentence.
We then computed several quantities for best-first parsing with each figure of merit
at the point where the best-first parsing method has found parses contributing at least
95% of the probability mass of the sentence. The 95% figure is simply a convenience;
see Appendix C for a discussion of speed versus accuracy.
</bodyText>
<subsectionHeader confidence="0.999643">
2.2 Measures Used
</subsectionHeader>
<bodyText confidence="0.999914">
We compared the figures of merit using the following measures:
</bodyText>
<listItem confidence="0.972106076923077">
1. %E: The percentage of edges, or rule expansions, in the exhaustive parse
that have been used by the best-first parse to get 95% of the probability
mass. Edge creation is a good measure of CFG parser effort, since it is
independent of platform and implementation.
2. %non-0 E: The percentage of nonzero-length edges used by the best-first
parse to get 95%. Zero-length edges are required by our parser as a
bookkeeping measure, and, as such, virtually cannot be eliminated. We
anticipated that removing them from consideration would highlight the
&amp;quot;true&amp;quot; differences in the figures of merit.
3. %popped: The percentage of constituents in the exhaustive parse that
were used by the best-first parse to get 95% of the probability mass. This
measure was included to confirm that a figure of merit that is efficient in
terms of edge creation is also efficient in terms of constituent creation.
</listItem>
<page confidence="0.979855">
277
</page>
<figure confidence="0.9961675">
Computational Linguistics Volume 24, Number 2
to t n-1
</figure>
<figureCaption confidence="0.979766">
Figure 2
</figureCaption>
<bodyText confidence="0.924625">
includes only words within the constituent.
</bodyText>
<listItem confidence="0.7052">
4. CPU time: The total CPU time (in seconds) needed to get 95% of the
probability mass for all of the 500 sentences.
</listItem>
<bodyText confidence="0.999985571428572">
The statistics converged to their final values quickly. The edge-count percentages
were generally within .01 of their final values after processing only 200 sentences, so
the results were quite stable by the end of our 500-sentence test corpus.
We gathered statistics for each sentence length from 3 to 30. Sentence length was
limited to a maximum of 30 because of the huge number of edges that are generated
in doing a full parse of long sentences; using this grammar, sentences in this length
range have produced up to 130,000 edges.
</bodyText>
<subsectionHeader confidence="0.999212">
2.3 The &amp;quot;Stack&amp;quot; Model
</subsectionHeader>
<bodyText confidence="0.999915714285714">
As a basis for comparison, we measured the CPU time for a non-best-first version of
the parser to completely parse all 500 sentences. The CPU time needed by this version
of the parser was 4,882 seconds. For a best-first version of the parser to be useful, it
must be able to find the most probable parse (or a reasonably good parse, depending
on the application) in less than this amount of time. Here, for the best-first parsers, we
will use for convenience the time needed to get 95% of the sentence&apos;s total probability
mass.
</bodyText>
<sectionHeader confidence="0.899445" genericHeader="introduction">
3. Simple Figures of Merit
</sectionHeader>
<subsectionHeader confidence="0.999815">
3.1 Straight 13
</subsectionHeader>
<bodyText confidence="0.998280857142857">
It seems reasonable to base a figure of merit on the inside probability 0 of the con-
stituent. Inside probability is defined as the probability of the words or tags in the con-
stituent given that the constituent is dominated by a particular nonterminal symbol;
see Figure 2. This seems to be a reasonable basis for comparing constituent probabili-
ties, and has the additional advantage that it is easy to compute during chart parsing.
Appendix A gives details of our on-line computation of 0.
The inside probability of the constituent Nip( is defined as:
</bodyText>
<equation confidence="0.698668">
/3(Mk) p(tbk I Ni)
</equation>
<bodyText confidence="0.84098">
where Ni represents the ith nonterminal symbol.
</bodyText>
<page confidence="0.989516">
278
</page>
<figure confidence="0.7970965">
Caraballo and Charniak Figures of Merit
Nj;k
</figure>
<figureCaption confidence="0.757119">
Figure 3
</figureCaption>
<bodyText confidence="0.8253975">
a includes the entire context of the constituent.
In terms of our earlier discussion, our &amp;quot;ideal&amp;quot; figure of merit can be rewritten as:
</bodyText>
<equation confidence="0.999534142857143">
P(Mk I ton) =- p(1\t,k, tom)
P(to,n)
p(N.4, tk,n)
p(to,n)
P(ki, tk)p(ti,k I to,i, N1, t km)
,n
p(to,n)
</equation>
<bodyText confidence="0.767693">
We apply the usual independence assumption that given a nonterminal, the tag
sequence it generates depends only on that nonterminal, giving:
</bodyText>
<equation confidence="0.9911605">
P(Nii,kI tom) •=z-•-&apos; p(to,i,M,k,tk,n)P(ti,k I N)
p(to,n)
tk,n)13(M,k)
p(to,n)
</equation>
<bodyText confidence="0.9988935">
The first term in the numerator is just the definition of the outside probability a of
the constituent. Outside probability a of a constituent Nip&lt; is defined as the probability
of that constituent and the rest of the words in the sentence (or rest of the tags in the
tag sequence, in our case); see Figure 3.
</bodyText>
<equation confidence="0.932120166666667">
a(1\11j ) ,J, p(to 1\11 tk )
,k — ,n •
We can therefore rewrite our ideal figure of merit as:
a(N&apos; k)0(N )
P(Kk tom) j&apos; •
P(to,n)
</equation>
<bodyText confidence="0.99989">
In this equation, we can see that a(Nihk) and p(to,n) represent the influence of the
surrounding words. Thus using 13 alone assumes that a and p(to,n) can be ignored.
We will refer to this figure of merit as straight 0.
</bodyText>
<subsectionHeader confidence="0.991409">
3.2 Normalized 13
</subsectionHeader>
<bodyText confidence="0.983899">
One side effect of omitting the a and p(to,n) terms in the straight j3 figure above is
that inside probability alone tends to prefer shorter constituents to longer ones, as the
</bodyText>
<page confidence="0.993524">
279
</page>
<note confidence="0.437278">
Computational Linguistics Volume 24, Number 2
</note>
<bodyText confidence="0.9512134">
inside probability of a longer constituent involves the product of more probabilities.
This can result in a &amp;quot;thrashing&amp;quot; effect as noted in Chitrao and Grishman (1990), where
the system parses short constituents, even very low-probability ones, while avoiding
combining them into longer constituents. To avoid thrashing, some technique is used
to normalize the inside probability for use as a figure of merit. One approach is to take
the geometric mean of the inside probability, to obtain a per-word inside probability.
(In the &amp;quot;ideal&amp;quot; model, the p(to,n) term acts as a normalizing factor.)
The per-word inside probability of the constituent Nip( is calculated as:
k-0(N.11,k).
We will refer to this figure as normalized 13.
</bodyText>
<subsectionHeader confidence="0.999837">
3.3 Trigram Estimate
</subsectionHeader>
<bodyText confidence="0.998757">
An alternative way to rewrite the &amp;quot;ideal&amp;quot; figure of merit is as follows:
</bodyText>
<equation confidence="0.996009">
P(Nk = p(1&apos;J1,k, to,)
p(to,n)
P(to„i, tk,n)P(NI,k I tO,j, tk,n)P(tj,k I NIA, to,j, tk,n)
tk,n)P(t j,k I tO,j, tk,n)
</equation>
<bodyText confidence="0.996267666666667">
Once again applying the usual independence assumption that given a nonterminal,
the tag sequence it generates depends only on that nonterminal, we can rewrite the
figure of merit as follows:
</bodyText>
<equation confidence="0.947159666666667">
p(N&apos; k I to ptk n)0(1\111,k)
P(M,k I 1.0,n)
p(tj,k I tovtk,n)
</equation>
<bodyText confidence="0.98223">
To derive an estimate of this quantity for practical use as a figure of merit, we make
some additional independence assumptions. We assume that p(Kk I tod, tk,n) 19(1\111,k),
that is, that the probability of a nonterminal is independent of the tags before and
after it in the sentence. We also use a trigram model for the tags themselves, giving
</bodyText>
<equation confidence="0.992474">
/3(ti,k I top tk,n) P(thk I tj-2, t3_1). Then we have:
p(N1),13(Ni. )
1,k
P(Nk I tO,n) rilf If
■.j,k .)-2,
</equation>
<bodyText confidence="0.981312125">
We can calculate 13(Nk) as usual.
The p(N1) term is estimated from our PCFG and the training data from which the
grammar was learned. We estimate p(N9 as the sum of the counts for all rules having
N&apos; as their left-hand side, divided by the sum of the counts for all rules.1
The p(ti,k I ti-2,t1_1) term is just the probability of the tag sequence t1. tk_i ac-
cording to a trigram model. (Technically, this is not a trigram model but a tritag
model, since we are considering sequences of tags, not words.) Our tritag probabili-
ties p(ta I ta-2, ta_i ) were learned from the training data used for the grammar, using
</bodyText>
<footnote confidence="0.852233">
1 Our results show that the p(Ni) term can be omitted from this figure of merit without much effect.
</footnote>
<page confidence="0.995076">
280
</page>
<note confidence="0.893888">
Caraballo and Charniak Figures of Merit
</note>
<tableCaption confidence="0.682301571428572">
Table 1
Results for the )3 estimates.
Figure of Merit
straight 13
normalized )3
trigram estimate
&amp;quot;stack&amp;quot;
</tableCaption>
<table confidence="0.416785">
100 —
%E %non-0 E %popped CPU Time
97.6 97.5 93.8 3,966
34.7 31.6 61.5 1,631
25.2 21.7 44.3 1,547
4,882
</table>
<figure confidence="0.927936631578947">
a
..............................
80 —
x% A
,
vI.
• / •
•\
/
straight beta
----• normalized beta
— — — • trigram estimate
60 —
40
, „
— —
20 —
10 20 30
Sentence Length
</figure>
<figureCaption confidence="0.83677">
Figure 4
</figureCaption>
<bodyText confidence="0.966865">
Nonzero-length edges for 95% of the probability mass for the 0 estimates.
the deleted interpolation method for smoothing. Our figure of merit uses:
</bodyText>
<equation confidence="0.995611333333333">
k-1
P(ti,k p(ta I ta-2, ta—i)
a=1
</equation>
<bodyText confidence="0.997622">
We refer to this figure of merit as the trigram estimate.
</bodyText>
<subsectionHeader confidence="0.833721">
3.4 Results
</subsectionHeader>
<bodyText confidence="0.999612333333333">
The results for the three figures of merit introduced in the last section according to
the measurements given in Section 2.2 are shown in Table 1 (the time to fully parse
using the &amp;quot;stack&amp;quot; model is included for easy reference).
Figure 4 expands the %non-0 E data to show the percent of nonzero-length edges
needed to get 95% of the probability mass for each sentence length.
Straight 13 performs quite poorly on this measure. In order to find 95% of the
probability mass for a sentence, a parser using this figure of merit typically needs to
do over 90% of the work. On the other hand, normalized 13 and the trigram estimate
both result in substantial savings of work. However, while these two models produce
</bodyText>
<page confidence="0.978261">
281
</page>
<figure confidence="0.832779">
Computational Linguistics Volume 24, Number 2
</figure>
<figureCaption confidence="0.942737">
Figure 5
</figureCaption>
<bodyText confidence="0.988082222222222">
Average CPU time for 95% of the probability mass for the 0 estimates.
near-equivalent performance for short sentences, for longer sentences, with length
greater than about 15 words, the trigram estimate gains a clear advantage. In fact, the
performance of normalized 13 appears to level off in this range, while the amount of
work done using the trigram estimate shows a continuing downward trend.
Figure 5 shows the average CPU time to get 95% of the probability mass for
each estimate and each sentence length. Each estimate averaged below 1 second on
sentences of fewer than 7 words. (The y-axis has been restricted so that the normalized
0 and trigram estimates can be better compared).
Note that while straight 0 does perform better than the &amp;quot;stack&amp;quot; model in CPU time,
the two models approach equivalent performance as sentence length increases, which
is what would be expected from the edge count measures. The other two models
provide a real time savings over the &amp;quot;stack&amp;quot; model, as can be seen from Figure 5
and from the total CPU times given earlier. Through most of the length range, the
CPU time needed by the normalized 0 and the trigram estimate is quite close, but at
the upper end of the range we can see better performance by the trigram estimate.
(This improvement comes later than in the edge count statistics because of the small
additional amount of overhead work needed to use the trigram estimate.)
</bodyText>
<sectionHeader confidence="0.937623" genericHeader="method">
4. Figures Involving Left Outside Probability
</sectionHeader>
<subsectionHeader confidence="0.99413">
4.1 Normalized aii3
</subsectionHeader>
<bodyText confidence="0.992844">
Earlier, we showed that our ideal figure of merit can be written as:
</bodyText>
<equation confidence="0.99567">
oi(Np;,k(t) 00x()N11,k)
p(1\111,k I tO,n) •
</equation>
<bodyText confidence="0.964944">
However, the a term, representing outside probability, cannot be calculated di-
</bodyText>
<figure confidence="0.9882175">
10 15 20 25
Sentence Length
30
10-
5-&apos;
— &amp;quot;stack&amp;quot;
straight beta
—•--• normalized beta
— — — • trigram estimate
I,
0
282
Caraballo and Charniak Figures of Merit
0 j-- t k— It k n-1
</figure>
<figureCaption confidence="0.953771">
Figure 6
</figureCaption>
<subsectionHeader confidence="0.490351">
Left outside context.
</subsectionHeader>
<bodyText confidence="0.9983999">
rectly during a parse, since we need the full parse of the sentence to compute it. In
some of our figures of merit, we use the quantity p(Mhk, 44), which is closely related
to outside probability. We call this quantity the left outside probability, and denote it
aL (see Figure 6).
The following recursive formula can be used to compute aL. Let Elk be the set of
all edges, or rule expansions, in which the nonterminal 1\1k appears. For each edge e
in E&apos; we compute the product of cti, of the nonterminal appearing on the left-hand
pc,
side (lhs) of the rule, the probability of the rule itself, and 13 of each nonterminal Ks
appearing to the left of NI hk in the rule. Then aL(Nk) is the sum of these products:
</bodyText>
<equation confidence="0.954961333333333">
,m•Ihs(e)
OL (M,k) E °L l&apos;start(e),end(e))p(rule(e))110(1\11,$).
eEek
</equation>
<bodyText confidence="0.9807622">
Given a complete parse of the sentence, the formula above gives an exact value
for aL. During parsing, the set Elk is not complete, and so the formula gives an ap-
proximation of aL.
This formula can be infinitely recursive, depending on the properties of the gram-
mar. A method for calculating aL more efficiently can be derived from the calculations
given in Jelinek and Lafferty (1991).
A simple extension to the normalized 0 model allows us to estimate the per-
word probability of all tags in the sentence through the end of the constituent under
consideration. This allows us to take advantage of information already obtained in a
left-right parse. We calculate this quantity as follows:
1VaL(1\li,k)0(Nli,k).
We are again taking the geometric mean to avoid thrashing by compensating for
the aL13 quantity&apos;s preference for shorter constituents, as explained in the previous
section.
We refer to this figure of merit as normalized at.13.
</bodyText>
<subsectionHeader confidence="0.998376">
4.2 Prefix Estimate
</subsectionHeader>
<bodyText confidence="0.9999475">
We also derived an estimate of the ideal figure of merit that takes advantage of statistics
on the first j — 1 tags of the sentence as well as ti,k. This estimate represents the
</bodyText>
<page confidence="0.995105">
283
</page>
<figure confidence="0.305598666666667">
Computational Linguistics Volume 24, Number 2
Table 2
Results for the a/43 estimates.
</figure>
<figureCaption confidence="0.568908666666667">
Figure of Merit %E %non-0 E %popped CPU Time
normalized ai.13 39.7 36.4 57.3 68,660
prefix estimate 21.8 17.4 38.3 26,520
</figureCaption>
<bodyText confidence="0.9534">
probability of the constituent in the context of the preceding tags.
</bodyText>
<equation confidence="0.997860333333333">
p(Nk,to,n)
p(to,,i)
P(tk,n)P(Nihk,to,i I tk,n )p(tp, Nij,„, to, tk,n)
P(tk,n)P(t0,k I tk,n)
p(Nihk, to,i I tk,n)P(ti,k I to, tk,n)
p(to,k I tk,n)
</equation>
<bodyText confidence="0.8313215">
We again make the independence assumption that p(t),k I NjA, to,i, ti) 13(NJ,k)*
Additionally, we assume that p(Mk,to,i) and p(to,k) are independent of p(tk,n), giving:
</bodyText>
<equation confidence="0.996826">
p(1\1j,k, to,j))3(Nk)
to,)
p(to,k)
</equation>
<bodyText confidence="0.999588666666667">
The denominator, p(to,k), is once again calculated from a tritag model. The p(Nihk,to,i)
term is just au defined above in the discussion of the normalized al,13 model. Thus
this figure of merit can be written as:
</bodyText>
<equation confidence="0.985133">
aL (N;*)0(Nj,k)
p(to,k)
</equation>
<bodyText confidence="0.998776">
We will refer to this as the prefix estimate.
</bodyText>
<subsectionHeader confidence="0.977856">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.995985">
The results for the figures of merit introduced in the previous section according to the
measurements given in Section 2.2 are shown in Table 2.
</bodyText>
<figureCaption confidence="0.933668333333333">
Figure 7 shows a graph of %non-0 E for each sentence length for the two al, models
and the related 13 models.
Figure 7 illustrates two main points. First, the deterioration of the performance of
</figureCaption>
<bodyText confidence="0.918364818181818">
the geometric-mean-based models with sentence length can be seen clearly. Second,
when we consider only the two conditional-probability models, we can see that the
additional information obtained from context in the prefix estimate gives a substantial
improvement in this measure as compared to the trigram estimate.
However, the CPU time needed to compute the aL term exceeds the time saved
by processing fewer edges. Note that using this estimate, the parser took over 26,000
seconds to get 95% of the probability mass, while the &amp;quot;stack&amp;quot; model can exhaustively
parse the test data in less than 5,000 seconds. Figure 8 shows the average CPU time
for each sentence length.
While chart parsing and calculations of 13 can be done in 0(n3) time (see Ap-
pendix A), we have been unable to find an algorithm to compute the aL terms faster
</bodyText>
<equation confidence="0.89268">
P(1\1j,k I ton )
=_
</equation>
<page confidence="0.918295">
284
</page>
<figure confidence="0.982757625">
Caraballo and Chamiak
Figures of Merit
- - normalized beta
normalized alphaL beta
— — — trigram estimate
--- prefix estimate
•
,
ics.■ A •
•
‘1!: •-• • •
„
100 —
80 —
60 —
4.▪ 1
t:&gt;
40 —
20-
\ \
•
0
0 10 20 30
Sentence Length
</figure>
<figureCaption confidence="0.997221">
Figure 7
</figureCaption>
<table confidence="0.8251617">
Nonzero-length edges for 95% of the probability mass for the aL0 estimates.
- &amp;quot;stack&amp;quot;
---- normalized beta
normalized alphaL beta
— — — trigtam estimate
--- prefix estimate
10 15 20 30
Sentence Length
Figure 8
Average CPU time for 95% of the probability mass for the 04,0 estimates.
</table>
<page confidence="0.930854">
285
</page>
<figure confidence="0.94049">
Computational Linguistics Volume 24, Number 2
tk- Itk tn-1
</figure>
<figureCaption confidence="0.7430245">
Figure 9
Left boundary context.
</figureCaption>
<bodyText confidence="0.999885333333333">
than 0(n5). When a constituent is removed from the agenda, it only affects the 1 val-
ues of its ancestors in the parse trees; however, al., values are propagated to all of the
constituent&apos;s siblings to the right and all of its descendants. Recomputing the aL terms
when a constituent is removed from the agenda can be done in 0(n3) time, and since
there are 0(n2) possible constituents, the total time needed to compute the at, terms
in this manner is 0(n5).
</bodyText>
<sectionHeader confidence="0.97682" genericHeader="method">
5. Figures Using Boundary Statistics
</sectionHeader>
<subsectionHeader confidence="0.987216">
5.1 Left Boundary Trigram Estimate
</subsectionHeader>
<bodyText confidence="0.999614666666667">
Although the aL-based models seem impractical, the edge-count and constituent-count
statistics show that contextual information is useful. We can derive an estimate similar
to the prefix estimate but containing a much simpler model of the context as follows:
</bodyText>
<equation confidence="0.98828775">
p(Nk, to,)
p(to,n)
P(to4, tk,n)P(M,k I to,j, tk,n)P(thk I 1\111,k, to,), tk,n)
tk,n)P(thk I kJ, tk,n)
</equation>
<bodyText confidence="0.997848666666667">
Once again applying the usual independence assumption that given a nonterminal,
the tag sequence it generates depends only on that nonterminal, we can rewrite the
figure of merit as follows:
</bodyText>
<equation confidence="0.9863485">
p(mk I tom) P(Nihk I to,j,tk,n)/3(Mhk)
P(tbk I to,j,tk,n) •
</equation>
<bodyText confidence="0.7448904">
As usual, we use a trigram model for the tags, giving p(thk I to,prk,n) p(thk
tj_2,
Now, we assume that p(Mhk I kJ, tk,n) r-z•, p(Mhk I tj_i), that is, that the probability
of a nonterminal is dependent on the tag immediately before it in the sentence (see
Figure 9). Then we have:
</bodyText>
<footnote confidence="0.716294666666667">
P(1\11* I tO,n) p(I\I! I t i)o(N! )
1,k I— j,k
p(ri,k I ti-2, t1-1) •
</footnote>
<bodyText confidence="0.9025925">
We can calculate /3(Nk) and the tritag probabilities as usual. The p(Ivihk I
probabilities are estimated from our training data by parsing the training data and
</bodyText>
<page confidence="0.952632">
286
</page>
<figure confidence="0.474701">
P(1\1j,k I k,n) =
Caraballo and Charniak Figures of Merit
Nikk
17)t. t
t0 n-1
</figure>
<figureCaption confidence="0.59905">
Figure 10
Boundary context.
</figureCaption>
<bodyText confidence="0.997466">
counting the occurrences of the nonterminal and the tag weighted by their probability
in the parse. (Further details are provided in Appendix B.)
We will refer to this figure as the left boundary trigram estimate.
</bodyText>
<subsectionHeader confidence="0.999443">
5.2 Boundary Trigram Estimate
</subsectionHeader>
<bodyText confidence="0.9998675">
We can derive a similar estimate using context on both sides of the constituent as
follows:
</bodyText>
<equation confidence="0.975818142857143">
P(Ni,k
p(Mk, to,fl)
P(to,n)
p(to,i)p(Mk to,i)p(ti,k Nip to,i)p(tk I to,),Mk,11,011(4+1,n to,p1\11,k, tj,k, tk)
P(to,i)P(ti,k I to,i)P(tk to,k)P(tk+Ln I to,k+i)
p(MkI to,i)p(tj,k I Mk, to,j)11(tk I t0,j,1\11,k,tj,k)P(tk+1,n tO,k+i,NiA)
P(t),k I tO,j)P(tk I 1.0,14(44-1,n I tO,k+1)
</equation>
<bodyText confidence="0.9802166">
Once again applying the usual independence assumption that given a nonterminal,
the tag sequence it generates depends only on that nonterminal and also assuming
that the probability of t
depends only on the previous tags, we can rewrite the
figure of merit as follows:
</bodyText>
<equation confidence="0.998768666666667">
P(N1 k tod)0(Nk)P(tk tO,k, Nk)
P(1\11),k I t0,n) r=-•&apos; •
p(thk+iI to,j)
</equation>
<bodyText confidence="0.999757">
Now we add some new independence assumptions. We assume that the proba-
bility of the nonterminal depends only on the immediately preceding tag, and that
the probability of the tag immediately following the nonterminal depends only on the
nonterminal (see Figure 10), giving:
</bodyText>
<equation confidence="0.94802625">
p(1\1j, ti_i)0(Ni)k)p(tk I APhk)
P(Nj,k I tom)
p(ti,k+i I kJ)
As usual, we use a trigram model for the tags, giving p(I-)A I to, ptk,n) P(t),ic
t 1_2, 11-i). Then we have:
P(Mk I ti-1)13(N),k)P(tk I Mk)
P(N1,k
P(tj,k+1 I tj-2, ti-1)
</equation>
<page confidence="0.990418">
287
</page>
<note confidence="0.611038">
Computational Linguistics Volume 24, Number 2
</note>
<bodyText confidence="0.989481">
We can calculate 0(1\711,k) and the tritag probabilities as usual. The p(1\1`bk I tj_i) and
p(tk Nihk) probabilities are estimated from our training data by parsing the training
data and counting the occurrences of the nonterminal and the tag weighted by their
probability in the parse. Again, see Appendix B for details of how these estimates
were obtained.
We will refer to this figure as the boundary trigram estimate.
</bodyText>
<subsectionHeader confidence="0.999716">
5.3 Boundary Statistics Only
</subsectionHeader>
<bodyText confidence="0.999872333333333">
We also wished to examine whether contextual information by itself is sufficient as a
figure of merit. We can derive an estimate based only on easily computable contextual
information as follows:
</bodyText>
<equation confidence="0.982263">
P(Nii,kI to,n)
p(M,1„ to,n)
p(to,n)
p(t0d)p(Ni,k I tO,j)P(tj,k I Ni,k, tO,j)P(tk I t04, 1\11,k, tj,k)P(4-1-1,nI tb,j,Nii,k, tj,k, tk)
p(to,i)p(ti,k Ito,i)p(tk I to,k)p(tk+Ln I t0A+1
p(M), to,i)p(thk I Mk, to)p(tk I kJ, thk)p(tk+1,n I tO)+1, )
P(thk I toi)P(tk I to,k)P(tk+i, I to,k+i) •
</equation>
<bodyText confidence="0.999975666666667">
Most of the independence assumptions we make are the same as in the boundary
trigram estimate. We assume that the probability of the nonterminal depends only on
the previous tag, that the probability of the immediately following tag depends only
on the nonterminal, and that the probability of the tags following that depend only
on the previous tags. However, we make one independence assumption that differs
from all of our previous estimates. Rather than assuming that the probability of the
tags within the constituent depends on the nonterminal, giving an inside probability
term, we assume that the probability of these tags depends only on the previous tags.
Then we have
</bodyText>
<equation confidence="0.93997325">
p(M,k to,n) P(M,k I to,i)P(ti,k I t)P(tk I Ni,k)P(tk+i,n to,k+i)
P(ti,k I to,i)P(tk I to,k)P(tk+i,n I to,k+i)
P(Nii,k I to,j)P(tk
p(tk I to,k)
In the denominator, we take p(tk I to,k) p(tk), giving:
P(Ni k tO,l)P(tk I N)
19(1\li I to,)
1,p(tk)
</equation>
<bodyText confidence="0.938019666666667">
which is simply the product of the two boundary statistics described in the previous
section.
We refer to this estimate as boundary statistics only.
</bodyText>
<equation confidence="0.7248395">
2 Actually, in our implementation, the p(tk) in the denominator is included in the following-tag statistic,
ktkIN&apos;,)
</equation>
<bodyText confidence="0.641912">
for which we use 1- . Then at run time we only use the trigram probabilities for tO,k•
</bodyText>
<equation confidence="0.905966">
P(4)
</equation>
<page confidence="0.997094">
288
</page>
<tableCaption confidence="0.856509333333333">
Caraballo and Charniak Figures of Merit
Table 3
Results for the boundary estimates.
</tableCaption>
<figure confidence="0.988116352941177">
Figure of Merit
%E %non-0 E %popped
50.8 59.6
18.4 39.6
13.9 31.2
/-
CPU Time
2,759
1,700
1,111
53.2
22.1
18.2
boundary statistics only
left boundary trigram estimate
boundary trigram estimate
100 —
80 —
60 —
— — — trigram estimate
--- prefix estimate
left boundary trigram
---- boundary trigram
— ---- boundary stats only
40 —
20-
1%
A A
: \
/ V
• &apos;NI /
0
10 20 30
Sentence Length
</figure>
<figureCaption confidence="0.990815">
Figure 11
</figureCaption>
<bodyText confidence="0.967813">
Nonzero-length edges for 95% of the probability mass for the boundary estimates.
</bodyText>
<sectionHeader confidence="0.632297" genericHeader="method">
5.4 Results
</sectionHeader>
<bodyText confidence="0.9999818125">
The results for the figures of merit introduced in the previous section according to the
measurements given in Section 2.2 are shown in Table 3.
Figure 11 shows a graph of %non-0 E for each sentence length for the boundary
models and the trigram and prefix estimates. This graph shows that the contextual
information gained from using oL in the prefix estimate is almost completely included
in just the previous tag, as illustrated by the left boundary trigram estimate. Adding
right contextual information in the boundary trigram estimate gives us the best per-
formance on this measure of any of our figures of merit.
We can consider the left boundary trigram estimate to be an approximation of the
prefix estimate, where the effect of the left context is approximated by the effect of the
single tag to the left. Similarly, the boundary trigram estimate is an approximation to
an estimate involving the full context, i.e., an estimate involving the outside probability
a. However, the parser cannot compute the outside probability of a constituent during
a parse, and so in order to use context on both sides of the constituent, we need to use
something like our boundary statistics. Our results suggest that a single tag before or
after the constituent can be used as a reasonable approximation to the full context on
</bodyText>
<page confidence="0.990813">
289
</page>
<figure confidence="0.9393661">
Computational Linguistics Volume 24, Number 2
10 15 20 30
Sentence Length
10
— &amp;quot;stack&amp;quot;
— — trigram estimate
--- prefix estimate
left boundary trigram
-- -- boundary trigram
----- boundary stets only
</figure>
<figureCaption confidence="0.928897">
Figure 12
</figureCaption>
<bodyText confidence="0.979546529411765">
Average CPU time for 95% of the probability mass for the boundary estimates.
that side of the constituent. Figure 12 shows the average CPU time for each sentence
length.
Since the boundary trigram estimate has none of the overhead associated with the
prefix estimate, it is the best performer in terms of CPU time as well. We can also
see that using just the boundary statistics, which can be precomputed and require no
extra processing during parsing, still results in a substantial improvement over the
non-best-first &amp;quot;stack&amp;quot; model.
As another method of comparison between the two best-performing estimates,
the context-dependent boundary trigram model and the context-independent trigram
model, we compared the number of edges needed to find the first parse for average-
length sentences. The average length of a sentence in our test data is about 22 words.
Figure 13 shows the percentage of sentences of length 18 through 26 for which a
parse could be found within 2,500 edges. For this experiment, we used a separate
test set from the Wall Street Journal corpus, containing approximately 570 sentences in
the desired length range. This measure also shows a real advantage of the boundary
trigram estimate over the trigram estimate.
</bodyText>
<sectionHeader confidence="0.989868" genericHeader="method">
6. Results Summary
</sectionHeader>
<bodyText confidence="0.911604">
Table 4 summarizes the results obtained for each figure of merit.
</bodyText>
<subsectionHeader confidence="0.6877035">
7. Comparing Figures of Merit Using a Treebank Grammar
7.1 Background
</subsectionHeader>
<bodyText confidence="0.9296065">
To verify that our results are not an artifact of the particular grammar we chose for
testing, we also tested using a treebank grammar introduced in Charniak (1996). This
</bodyText>
<page confidence="0.985758">
290
</page>
<figure confidence="0.446909529411765">
Caraballo Cl) and Charniak .1 e tee e e e e Figures of Merit
y, 1.0 - / ! t e eeee ee&apos; - -- • boundary trigram
0.8 - / ! e t ee e - - - • trigram
0.6- ./ /
0 .1 e
0.2 - / e
0.0 1 t
I e
I
I
I
I
I
II
eee
500 1000 1500 2000 1
# Edges 2500
</figure>
<figureCaption confidence="0.68135">
Figure 13
</figureCaption>
<bodyText confidence="0.595634">
% of the 18- to 26-word sentences finding a parse in a fixed number of edges.
</bodyText>
<tableCaption confidence="0.997668">
Table 4
</tableCaption>
<table confidence="0.963146272727273">
Results for all figures of merit.
%E %non-0 E %popped CPU Time
4,882
97.6 97.5 93.8 3,966
34.7 31.6 61.5 1,631
25.2 21.7 44.3 1,547
39.7 36.4 57.3 68,660
21.8 17.4 38.3 26,520
53.2 50.8 59.6 2,759
22.1 18.4 39.6 1,700
18.2 13.9 31.2 1,111
</table>
<figureCaption confidence="0.5398861">
Figure of Merit
&amp;quot;stack&amp;quot; model
straight
normalized
trigram estimate
normalized aL0
prefix estimate
boundary statistics only
left boundary trigram estimate
boundary trigram estimate
</figureCaption>
<bodyText confidence="0.999753333333333">
grammar was trained in a straightforward way by reading the grammar directly (with
minor modifications) from a portion of the Penn Treebank Wall Street Journal data com-
prised of about 300,000 words. The boundary statistics were counted directly from the
training data as well. The treebank grammar is much larger and more ambiguous than
our original grammar, containing about 16,000 rules and 78 terminal and nonterminal
symbols, and it was impractical to parse sentences to exhaustion using our existing
hardware, so the figures based on 95% of the probability mass could not be computed.
We were able to use this grammar to compare the number of edges needed to find
the first parse using the trigram and boundary trigram estimates.
</bodyText>
<page confidence="0.98993">
291
</page>
<figure confidence="0.997822777777778">
Volume 24, Number 2
Computational Linguistics
1.0 —
0.8 —
I!
----• boundary trigram
— — — • trigram
5000 10000 15000 20000
# Edges
</figure>
<figureCaption confidence="0.939172">
Figure 14
</figureCaption>
<bodyText confidence="0.914683">
% of the 18- to 26-word sentences finding a parse in a fixed number of edges for a treebank
grammar.
</bodyText>
<subsectionHeader confidence="0.344461">
7.2 Results
</subsectionHeader>
<bodyText confidence="0.4742996">
Figure 14 shows the percentage of sentences of length 18 through 26 for which a parse
could be found within 20,000 edges. Again, we used a test set of approximately 570
sentences of the appropriate length from the Wall Street Journal corpus. Although the
x-axis covers a much wider range than in Figure 13, the relationship between the two
estimates is quite similar.
</bodyText>
<sectionHeader confidence="0.544103" genericHeader="method">
8. Previous Work
</sectionHeader>
<bodyText confidence="0.99978525">
In an earlier version of this paper (Caraballo and Charniak 1996), we presented the
results for several of these models using our original grammar. The treebank grammar
was introduced in Charniak (1996), and the parser in, that paper is a best-first parser
using the boundary trigram figure of merit.
The literature shows many implementations of best-first parsing, but none of the
previous work shares our goal of explicitly comparing figures of merit.
Bobrow (1990) and Chitrao and Grishman (1990) introduced statistical agenda-
based parsing techniques. Chitrao and Grishman implemented a best-first probabilistic
parser and noted the parser&apos;s tendency to prefer shorter constituents. They proposed
a heuristic solution of penalizing shorter constituents by a fixed amount per word.
Miller and Fox (1994) compare the performance of parsers using three different
types of grammars, and show that a probabilistic context-free grammar using inside
probability (unnormalized) as a figure of merit outperforms both a context-free gram-
mar and a context-dependent grammar.
Kochman and Kupin (1991) propose a figure of merit closely related to our prefix
estimate. They do not actually incorporate this figure into a best-first parser.
</bodyText>
<figure confidence="0.8824905">
0.6
0.4 —
0.2 —
0.0
</figure>
<page confidence="0.989654">
292
</page>
<note confidence="0.781097">
Caraballo and Charniak Figures of Merit
</note>
<bodyText confidence="0.995575666666667">
Magerman and Marcus (1991) use the geometric mean to compute a figure of
merit that is independent of constituent length. Magerman and Weir (1992) use a
similar model with a different parsing algorithm.
</bodyText>
<sectionHeader confidence="0.846285" genericHeader="method">
9. Conclusions
</sectionHeader>
<bodyText confidence="0.999980846153846">
We have presented and evaluated several figures of merit for best-first parsing. The
best performer according to all of our measures was the parser using the boundary
trigram estimate as a figure of merit, and this result holds for two different grammars.
This figure has the additional advantage that it can be easily incorporated into existing
best-first parsers using a figure of merit based on inside probability. (As mentioned
earlier, the efficient online computation of # is described in Appendix A.) We strongly
recommend this figure of merit as the basis for best-first statistical parsers.
The measurements presented here almost certainly underestimate the true benefits
of this model. We restricted sentence length to a maximum of 30 words, in order to
keep the number of edges in the exhaustive parse to a practical size; however, since the
percentage of edges needed by the best-first parse decreases with increasing sentence
length, we assume that the improvement would be even more dramatic for sentences
longer than 30 words.
</bodyText>
<sectionHeader confidence="0.742588" genericHeader="method">
Appendix A: Efficient On-Line Computation of
</sectionHeader>
<bodyText confidence="0.9999926">
We compute estimates of the inside probability for each proposed constituent in-
crementally as new constituents are added to the chart. Initially, # is set to 1 for each
terminal symbol, since our input is given as a stream of tags, which are our terminals.
When a new proposed constituent is added to the agenda, its [3 estimate is set to its
current inside probability according to the constituents already in the chart. However,
as more constituents are added to the chart, we may find a new way to build up a
proposed constituent, i.e., additional evidence for that proposed constituent, so we
need to update the 13 for the proposed constituent (and also for affected constituents
already in the chart, since these may in turn affect other proposed constituents).
These updates can be quite expensive in terms of CPU time. However, many of
the updates are quite small, and do not affect the relative ordering of the proposed
constituents on the agenda. Instead of propagating every change to 0, then, we only
want to propagate those changes that we expect to have an effect on this ordering.
What we have done is to have each constituent store not only its # value, but also
an increment. Increases to the inside probability are added not to # itself, but to this
increment, until the increment exceeds some threshold. Experimentally we have found
that we can avoid propagating increments until they exceed 1% of the current value
of with very little effect on the parser&apos;s selection of constituents from the agenda.
This thresholding on the propagation of # allows us to update the values on
line while still keeping the performance of the parser as 0(n3) empirically.
</bodyText>
<sectionHeader confidence="0.833945" genericHeader="method">
Appendix B: Estimation of Boundary Statistics
</sectionHeader>
<bodyText confidence="0.948907">
Our figures of merit incorporating boundary statistics use the figures p(Mk ti_i) to
</bodyText>
<subsubsectionHeader confidence="0.713791">
P(tk
</subsubsectionHeader>
<bodyText confidence="0.99845825">
represent the effect of the left context and p(to to represent the effect of the right
context. For our experiments with the first grammar, which was learned from training
data taken from the Brown corpus, we estimated these statistics from the same training
data.
</bodyText>
<page confidence="0.993843">
293
</page>
<note confidence="0.702501">
Computational Linguistics Volume 24, Number 2
</note>
<bodyText confidence="0.999882222222222">
First, we parsed the training data according to our grammar. (It was necessary
to do this, rather than using the hand-annotated parses of the training data, because
our grammar does not use the same set of nonterminals as the corpus; see Carroll
and Charniak [1992a, 1992b] and Charniak and Carroll [1994] for details.) Since we
use the tags as our input, the probability of a nonterminal appearing with a particular
previous tag is the same as the probability of that nonterminal appearing in any
sentence containing that tag.
We can then count the probability-weighted occurrences of a nonterminal given
the previous tag as follows:
</bodyText>
<equation confidence="0.88749825">
C(Nj,k, = Epcm,kI wo,,i)
wo,„ containing
a(Nk))3(N11,k)
P(WO,n)
</equation>
<bodyText confidence="0.99979175">
That is, for each sentence that contains the previous tag tj_i, we increment our count
by the probability of the nonterminal Nk occurring immediately following ti_i in that
sentence.
Since we have a complete parse, the inside and outside probabilities and the
sentence probability can be easily computed. We can also obtain the count C(ti_i)
simply by counting the number of sentences in which that tag appears in position
j - 1. We then obtain the conditional probability for the left boundary statistic as
follows:
</bodyText>
<equation confidence="0.980962666666667">
QAT; ti-1)
P(1\11,k I t
Ohl)
</equation>
<bodyText confidence="0.99843275">
The right boundary statistic is computed in the corresponding way.
For the experiment using the treebank grammar, these statistics were obtained by
counting directly from the Wall Street Journal treebank corpus, just as the grammar
rules and trigram statistics were.
</bodyText>
<sectionHeader confidence="0.655309" genericHeader="discussions">
Appendix C: Speed vs. Accuracy
</sectionHeader>
<bodyText confidence="0.997593555555556">
As an additional verification of our results, we gathered data on speed versus accuracy.
For this experiment, we used the probabilistic context-free grammar learned from the
Brown corpus and the average-length test sentences described in Section 5.4. For each
figure of merit, we computed the average precision and recall of the best parse found
as compared to the number of edges created. We computed unlabeled precision and
recall only, since our grammar uses a different set of nonterminals from those used in
the test data.
Precision is defined as the percentage of the constituents proposed by our parser
that are actually correct according to the treebank. For each edge count, we measured
the precision of the best parse of each sentence found within that number of edges.
Figure 15 is a graph of the average precision for the 0 figures of merit from Section 3,
plotted against edge counts.
The fluctuations at the low edge counts are due to the small amount of data at this
level. At a low edge count, very few sentences have actually been parsed, and since
these sentences tend to be short and simple, the parses are likely to be correct. The
sentences that could not be parsed do not contribute to the measurement of precision.
As more sentences are parsed, precision settles at about 47%, the highest precision
attainable by our particular test grammar, and remains there as edge counts increase.
</bodyText>
<page confidence="0.99117">
294
</page>
<figure confidence="0.975612583333333">
Caraballo and Charniak
Figures of Merit
straight beta
- --• normalized beta
— — — • trigram estimate
0.6 —
0.5 —
0.4
10000 20000 30000
# Edges
Figure 15
Precision of the best parse found in a fixed number of edges for the estimates.
0.6—
7, 0.4—
at
0.2 —
&amp;quot;stack&amp;quot;
straight beta
- — -• normalized beta
— — — • tngram estimate
I
0.0
2000 4(100 6000 8000
# Edges
</figure>
<figureCaption confidence="0.955647">
Figure 16
</figureCaption>
<bodyText confidence="0.60694">
Recall of the best parse found in a fixed number of edges for the estimates.
</bodyText>
<page confidence="0.971865">
295
</page>
<figure confidence="0.9877725">
Computational Linguistics Volume 24, Number 2
0.6 —
= 0.4
sif
,
— - —• • normalized beta
normalized alphaL beta
— — — trigram estimate
--- prefix estimate
I ,1
0.2
•
ii
//I
0.0
•
6c00
8000
20100
4000
4 Edges
Figure 17
Recall of the best parse found in a fixed number of edges for the al43 estimates.
— — —. trigram estimate
--- prefix estimate
left boundary trigram
— - — • • boundary Ingram
— ---- boundary mats only
2000 4060 1,000 0000
Edges
</figure>
<figureCaption confidence="0.975848">
Figure 18
</figureCaption>
<bodyText confidence="0.652485">
Recall of the best parse found in a fixed number of edges for the boundary estimates.
</bodyText>
<page confidence="0.963225">
296
</page>
<bodyText confidence="0.976678727272727">
Caraballo and Charniak Figures of Merit
This level of precision is independent of the figure of merit used, so measurement of
precision does not help evaluate our figures of merit.
A much more useful measure is recall. Recall is defined as the percentage of
constituents in the treebank test data that are found by our parser. Again, we measured
the recall of the best parse of each sentence found within each number of edges.
Figure 16 shows the results for the figures of merit from Section 3.
Straight beta clearly shows little or no improvement over the &amp;quot;stack&amp;quot; parser using
no figure of merit at all. The other figures of merit increase quickly to about 64%,
the maximum recall attainable with our test grammar. The &amp;quot;stack&amp;quot; parser and the
one using straight beta, on the other hand, do not reach this maximum level until
about 50,000 edges. We have no explanation for the relatively poor performance of the
parser using the trigram estimate compared to the other best-first parsers, as shown
in Figures 16, 17, and 18. Figure 17 shows the recall values for the aL0 figures of merit
from Section 4, and Figure 18 shows recall for the boundary figures of merit from
Section 5. Since precision is not a useful measure, we have not included precision data
for these figures of merit.
These data confirm that the parser using the boundary trigram figure of merit
performs better than any of the others. Recall using this figure of merit is consistently
higher than any of the others at low edge counts, and it reaches the maximum value
in fewer than 2,000 edges, with the nearest competitors approaching the maximum at
about 3,000 edges.
</bodyText>
<sectionHeader confidence="0.991476" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999912">
The authors are very grateful to Heidi Fox
for obtaining the speed vs. accuracy data
discussed in Appendix C. We also wish to
thank the anonymous reviewers for their
comments and suggestions. This research
was supported in part by NSF grant
IRI-9319516 and by ONR grant
N0014-96-1-0549.
</bodyText>
<sectionHeader confidence="0.995706" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999896178571429">
Bobrow, Robert J. 1990. Statistical agenda
parsing. In DARPA Speech and Language
Workshop, pages 222-224.
Caraballo, Sharon and Eugene Charniak.
1996. Figures of merit for best-first
probabilistic chart parsing. In Proceedings
of the Conference on Empirical Methods in
Natural Language Processing, pages
127-132.
Carroll, Glenn and Eugene Charniak. 1992a.
Learning probabilistic dependency
grammars from labeled text. In Working
Notes, Fall Symposium Series, pages
25-32. AAAI.
Carroll, Glenn and Eugene Chamiak. 1992b.
Two experiments on learning probabilistic
dependency grammars from corpora. In
Workshop Notes, Statistically-Based NLP
Techniques, pages 1-13. AAAI.
Charniak, Eugene. 1993. Statistical Language
Learning. MIT Press.
Charniak, Eugene. 1996. Tree-bank
grammars. In Proceedings of the Thirteenth
National Conference on Artificial Intelligence,
pages 1031-1036. AAAI.
Charniak, Eugene and Glenn Carroll. 1994.
Context-sensitive statistics for improved
grammatical language models. In
Proceedings of the Twelfth National Conference
on Artificial Intelligence, pages 728-733.
Chitrao, Mahesh V. and Ralph Grishman.
1990. Statistical parsing of messages. In
DARPA Speech and Language Workshop,
pages 263-266.
Francis, W. Nelson and Henry Kutera. 1982.
Frequency Analysis of English Usage: Lexicon
and Grammar. Houghton Mifflin.
Jelinek, Frederick and John D. Lafferty. 1991.
Computation of the probability of initial
substring generation by stochastic
context-free grammars. Computational
Linguisitics, 17:315-323.
Kochman, Fred and Joseph Kupin. 1991.
Calculating the probability of a partial
parse of sentence. In DARPA Speech and
Language Workshop, pages 237-240.
Magerman, David M. and Mitchell P.
Marcus. 1991. Parsing the Voyager
domain using Pearl. In DARPA Speech and
Language Workshop, pages 231-236.
Magerman, David M. and Carl Weir. 1992.
Efficiency, robustness and accuracy in
Picky chart parsing. In Proceedings of the
30th Annual Meeting, Association for
Computational Linguistics, pages 40-47.
Association for Computational
</reference>
<page confidence="0.93226">
297
</page>
<note confidence="0.289749">
Computational Linguistics Volume 24, Number 2
</note>
<reference confidence="0.9812327">
Linguistics.
Marcus, Mitchell P., Beatrice Santorini, and
Mary Ann Marcinkiewicz. 1993. Building
a large annotated corpus of English: The
Penn treebank. Computational Linguistics,
19:313-330.
Miller, Scott and Heidi Fox. 1994. Automatic
grammar acquisition. In Proceedings of the
Human Language Technology Workshop,
pages 268-271.
</reference>
<page confidence="0.997088">
298
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.951860">
<title confidence="0.998583">New Figures of Merit for Best-First Probabilistic Chart Parsing</title>
<author confidence="0.997837">Sharon A Caraballo Eugene Charniak</author>
<affiliation confidence="0.999803">Brown University Brown University</affiliation>
<abstract confidence="0.993641571428571">Best-first parsing methods for natural language try to parse efficiently by considering the most likely constituents first. Some figure of merit is needed by which to compare the likelihood of constituents, and the choice of this figure has a substantial impact on the efficiency of the parser. While several parsers described in the literature have used such techniques, there is little published data on their efficacy, much less attempts to judge their relative merits. We propose and evaluate several figures of merit for best-first parsing, and we identify an easily computable figure of merit that provides excellent performance on various measures and two different grammars.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert J Bobrow</author>
</authors>
<title>Statistical agenda parsing.</title>
<date>1990</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>222--224</pages>
<contexts>
<context position="34597" citStr="Bobrow (1990)" startWordPosition="5877" endWordPosition="5878">s. Although the x-axis covers a much wider range than in Figure 13, the relationship between the two estimates is quite similar. 8. Previous Work In an earlier version of this paper (Caraballo and Charniak 1996), we presented the results for several of these models using our original grammar. The treebank grammar was introduced in Charniak (1996), and the parser in, that paper is a best-first parser using the boundary trigram figure of merit. The literature shows many implementations of best-first parsing, but none of the previous work shares our goal of explicitly comparing figures of merit. Bobrow (1990) and Chitrao and Grishman (1990) introduced statistical agendabased parsing techniques. Chitrao and Grishman implemented a best-first probabilistic parser and noted the parser&apos;s tendency to prefer shorter constituents. They proposed a heuristic solution of penalizing shorter constituents by a fixed amount per word. Miller and Fox (1994) compare the performance of parsers using three different types of grammars, and show that a probabilistic context-free grammar using inside probability (unnormalized) as a figure of merit outperforms both a context-free grammar and a context-dependent grammar. </context>
</contexts>
<marker>Bobrow, 1990</marker>
<rawString>Bobrow, Robert J. 1990. Statistical agenda parsing. In DARPA Speech and Language Workshop, pages 222-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Caraballo</author>
<author>Eugene Charniak</author>
</authors>
<title>Figures of merit for best-first probabilistic chart parsing.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>127--132</pages>
<contexts>
<context position="34195" citStr="Caraballo and Charniak 1996" startWordPosition="5812" endWordPosition="5815">trigram — — — • trigram 5000 10000 15000 20000 # Edges Figure 14 % of the 18- to 26-word sentences finding a parse in a fixed number of edges for a treebank grammar. 7.2 Results Figure 14 shows the percentage of sentences of length 18 through 26 for which a parse could be found within 20,000 edges. Again, we used a test set of approximately 570 sentences of the appropriate length from the Wall Street Journal corpus. Although the x-axis covers a much wider range than in Figure 13, the relationship between the two estimates is quite similar. 8. Previous Work In an earlier version of this paper (Caraballo and Charniak 1996), we presented the results for several of these models using our original grammar. The treebank grammar was introduced in Charniak (1996), and the parser in, that paper is a best-first parser using the boundary trigram figure of merit. The literature shows many implementations of best-first parsing, but none of the previous work shares our goal of explicitly comparing figures of merit. Bobrow (1990) and Chitrao and Grishman (1990) introduced statistical agendabased parsing techniques. Chitrao and Grishman implemented a best-first probabilistic parser and noted the parser&apos;s tendency to prefer s</context>
</contexts>
<marker>Caraballo, Charniak, 1996</marker>
<rawString>Caraballo, Sharon and Eugene Charniak. 1996. Figures of merit for best-first probabilistic chart parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 127-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Carroll</author>
<author>Eugene Charniak</author>
</authors>
<title>Learning probabilistic dependency grammars from labeled text.</title>
<date>1992</date>
<booktitle>In Working Notes, Fall Symposium Series,</booktitle>
<pages>25--32</pages>
<publisher>AAAI.</publisher>
<marker>Carroll, Charniak, 1992</marker>
<rawString>Carroll, Glenn and Eugene Charniak. 1992a. Learning probabilistic dependency grammars from labeled text. In Working Notes, Fall Symposium Series, pages 25-32. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glenn Carroll</author>
<author>Eugene Chamiak</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<booktitle>In Workshop Notes, Statistically-Based NLP Techniques,</booktitle>
<pages>1--13</pages>
<publisher>AAAI.</publisher>
<marker>Carroll, Chamiak, 1992</marker>
<rawString>Carroll, Glenn and Eugene Chamiak. 1992b. Two experiments on learning probabilistic dependency grammars from corpora. In Workshop Notes, Statistically-Based NLP Techniques, pages 1-13. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Statistical Language Learning.</title>
<date>1993</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2173" citStr="Charniak (1993)" startWordPosition="349" endWordPosition="350">is by combining with other constituents in the chart according to the grammar rules. (We will often refer to these expansions of rules as &amp;quot;edges&amp;quot;) In general this can lead to the creation of new, more encompassing constituents, which themselves are then added to the agenda. When one constituent has been processed, a new one is chosen to be removed from the agenda, and so on. Traditionally, the agenda is represented as a stack, so that the last item added to the agenda is the next one removed. Chart parsing is described extensively in the literature; for one such discussion see &apos;Section 1.4 of Charniak (1993). Best-first probabilistic chart parsing is a variation of chart parsing that attempts to find the most likely parses first, by adding constituents to the chart in order of the likelihood that they will appear in a correct parse, rather than simply popping constituents off of a stack. Some probabilistic figure of merit is assigned to the constituents on the agenda, and the constituent maximizing this value is the next to be added to the chart. In this paper we consider probabilities primarily based on probabilistic contextfree grammars, though in principle, other, more complicated schemes coul</context>
</contexts>
<marker>Charniak, 1993</marker>
<rawString>Charniak, Eugene. 1993. Statistical Language Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>Tree-bank grammars.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth National Conference on Artificial Intelligence,</booktitle>
<pages>1031--1036</pages>
<publisher>AAAI.</publisher>
<contexts>
<context position="31990" citStr="Charniak (1996)" startWordPosition="5406" endWordPosition="5407">parse could be found within 2,500 edges. For this experiment, we used a separate test set from the Wall Street Journal corpus, containing approximately 570 sentences in the desired length range. This measure also shows a real advantage of the boundary trigram estimate over the trigram estimate. 6. Results Summary Table 4 summarizes the results obtained for each figure of merit. 7. Comparing Figures of Merit Using a Treebank Grammar 7.1 Background To verify that our results are not an artifact of the particular grammar we chose for testing, we also tested using a treebank grammar introduced in Charniak (1996). This 290 Caraballo Cl) and Charniak .1 e tee e e e e Figures of Merit y, 1.0 - / ! t e eeee ee&apos; - -- • boundary trigram 0.8 - / ! e t ee e - - - • trigram 0.6- ./ / 0 .1 e 0.2 - / e 0.0 1 t I e I I I I I II eee 500 1000 1500 2000 1 # Edges 2500 Figure 13 % of the 18- to 26-word sentences finding a parse in a fixed number of edges. Table 4 Results for all figures of merit. %E %non-0 E %popped CPU Time 4,882 97.6 97.5 93.8 3,966 34.7 31.6 61.5 1,631 25.2 21.7 44.3 1,547 39.7 36.4 57.3 68,660 21.8 17.4 38.3 26,520 53.2 50.8 59.6 2,759 22.1 18.4 39.6 1,700 18.2 13.9 31.2 1,111 Figure of Merit &amp;quot;s</context>
<context position="34195" citStr="Charniak 1996" startWordPosition="5814" endWordPosition="5815">• trigram 5000 10000 15000 20000 # Edges Figure 14 % of the 18- to 26-word sentences finding a parse in a fixed number of edges for a treebank grammar. 7.2 Results Figure 14 shows the percentage of sentences of length 18 through 26 for which a parse could be found within 20,000 edges. Again, we used a test set of approximately 570 sentences of the appropriate length from the Wall Street Journal corpus. Although the x-axis covers a much wider range than in Figure 13, the relationship between the two estimates is quite similar. 8. Previous Work In an earlier version of this paper (Caraballo and Charniak 1996), we presented the results for several of these models using our original grammar. The treebank grammar was introduced in Charniak (1996), and the parser in, that paper is a best-first parser using the boundary trigram figure of merit. The literature shows many implementations of best-first parsing, but none of the previous work shares our goal of explicitly comparing figures of merit. Bobrow (1990) and Chitrao and Grishman (1990) introduced statistical agendabased parsing techniques. Chitrao and Grishman implemented a best-first probabilistic parser and noted the parser&apos;s tendency to prefer s</context>
</contexts>
<marker>Charniak, 1996</marker>
<rawString>Charniak, Eugene. 1996. Tree-bank grammars. In Proceedings of the Thirteenth National Conference on Artificial Intelligence, pages 1031-1036. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Glenn Carroll</author>
</authors>
<title>Context-sensitive statistics for improved grammatical language models.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Artificial Intelligence,</booktitle>
<pages>728--733</pages>
<marker>Charniak, Carroll, 1994</marker>
<rawString>Charniak, Eugene and Glenn Carroll. 1994. Context-sensitive statistics for improved grammatical language models. In Proceedings of the Twelfth National Conference on Artificial Intelligence, pages 728-733.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahesh V Chitrao</author>
<author>Ralph Grishman</author>
</authors>
<title>Statistical parsing of messages.</title>
<date>1990</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>263--266</pages>
<contexts>
<context position="12658" citStr="Chitrao and Grishman (1990)" startWordPosition="2124" endWordPosition="2127">his equation, we can see that a(Nihk) and p(to,n) represent the influence of the surrounding words. Thus using 13 alone assumes that a and p(to,n) can be ignored. We will refer to this figure of merit as straight 0. 3.2 Normalized 13 One side effect of omitting the a and p(to,n) terms in the straight j3 figure above is that inside probability alone tends to prefer shorter constituents to longer ones, as the 279 Computational Linguistics Volume 24, Number 2 inside probability of a longer constituent involves the product of more probabilities. This can result in a &amp;quot;thrashing&amp;quot; effect as noted in Chitrao and Grishman (1990), where the system parses short constituents, even very low-probability ones, while avoiding combining them into longer constituents. To avoid thrashing, some technique is used to normalize the inside probability for use as a figure of merit. One approach is to take the geometric mean of the inside probability, to obtain a per-word inside probability. (In the &amp;quot;ideal&amp;quot; model, the p(to,n) term acts as a normalizing factor.) The per-word inside probability of the constituent Nip( is calculated as: k-0(N.11,k). We will refer to this figure as normalized 13. 3.3 Trigram Estimate An alternative way t</context>
<context position="34629" citStr="Chitrao and Grishman (1990)" startWordPosition="5880" endWordPosition="5883">axis covers a much wider range than in Figure 13, the relationship between the two estimates is quite similar. 8. Previous Work In an earlier version of this paper (Caraballo and Charniak 1996), we presented the results for several of these models using our original grammar. The treebank grammar was introduced in Charniak (1996), and the parser in, that paper is a best-first parser using the boundary trigram figure of merit. The literature shows many implementations of best-first parsing, but none of the previous work shares our goal of explicitly comparing figures of merit. Bobrow (1990) and Chitrao and Grishman (1990) introduced statistical agendabased parsing techniques. Chitrao and Grishman implemented a best-first probabilistic parser and noted the parser&apos;s tendency to prefer shorter constituents. They proposed a heuristic solution of penalizing shorter constituents by a fixed amount per word. Miller and Fox (1994) compare the performance of parsers using three different types of grammars, and show that a probabilistic context-free grammar using inside probability (unnormalized) as a figure of merit outperforms both a context-free grammar and a context-dependent grammar. Kochman and Kupin (1991) propose</context>
</contexts>
<marker>Chitrao, Grishman, 1990</marker>
<rawString>Chitrao, Mahesh V. and Ralph Grishman. 1990. Statistical parsing of messages. In DARPA Speech and Language Workshop, pages 263-266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Nelson Francis</author>
<author>Henry Kutera</author>
</authors>
<title>Frequency Analysis of English Usage: Lexicon and Grammar.</title>
<date>1982</date>
<publisher>Houghton Mifflin.</publisher>
<marker>Francis, Kutera, 1982</marker>
<rawString>Francis, W. Nelson and Henry Kutera. 1982. Frequency Analysis of English Usage: Lexicon and Grammar. Houghton Mifflin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
<author>John D Lafferty</author>
</authors>
<title>Computation of the probability of initial substring generation by stochastic context-free grammars.</title>
<date>1991</date>
<journal>Computational Linguisitics,</journal>
<pages>17--315</pages>
<contexts>
<context position="19350" citStr="Jelinek and Lafferty (1991)" startWordPosition="3294" endWordPosition="3297"> (lhs) of the rule, the probability of the rule itself, and 13 of each nonterminal Ks appearing to the left of NI hk in the rule. Then aL(Nk) is the sum of these products: ,m•Ihs(e) OL (M,k) E °L l&apos;start(e),end(e))p(rule(e))110(1\11,$). eEek Given a complete parse of the sentence, the formula above gives an exact value for aL. During parsing, the set Elk is not complete, and so the formula gives an approximation of aL. This formula can be infinitely recursive, depending on the properties of the grammar. A method for calculating aL more efficiently can be derived from the calculations given in Jelinek and Lafferty (1991). A simple extension to the normalized 0 model allows us to estimate the perword probability of all tags in the sentence through the end of the constituent under consideration. This allows us to take advantage of information already obtained in a left-right parse. We calculate this quantity as follows: 1VaL(1\li,k)0(Nli,k). We are again taking the geometric mean to avoid thrashing by compensating for the aL13 quantity&apos;s preference for shorter constituents, as explained in the previous section. We refer to this figure of merit as normalized at.13. 4.2 Prefix Estimate We also derived an estimate</context>
</contexts>
<marker>Jelinek, Lafferty, 1991</marker>
<rawString>Jelinek, Frederick and John D. Lafferty. 1991. Computation of the probability of initial substring generation by stochastic context-free grammars. Computational Linguisitics, 17:315-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fred Kochman</author>
<author>Joseph Kupin</author>
</authors>
<title>Calculating the probability of a partial parse of sentence.</title>
<date>1991</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>237--240</pages>
<contexts>
<context position="35221" citStr="Kochman and Kupin (1991)" startWordPosition="5963" endWordPosition="5966"> and Chitrao and Grishman (1990) introduced statistical agendabased parsing techniques. Chitrao and Grishman implemented a best-first probabilistic parser and noted the parser&apos;s tendency to prefer shorter constituents. They proposed a heuristic solution of penalizing shorter constituents by a fixed amount per word. Miller and Fox (1994) compare the performance of parsers using three different types of grammars, and show that a probabilistic context-free grammar using inside probability (unnormalized) as a figure of merit outperforms both a context-free grammar and a context-dependent grammar. Kochman and Kupin (1991) propose a figure of merit closely related to our prefix estimate. They do not actually incorporate this figure into a best-first parser. 0.6 0.4 — 0.2 — 0.0 292 Caraballo and Charniak Figures of Merit Magerman and Marcus (1991) use the geometric mean to compute a figure of merit that is independent of constituent length. Magerman and Weir (1992) use a similar model with a different parsing algorithm. 9. Conclusions We have presented and evaluated several figures of merit for best-first parsing. The best performer according to all of our measures was the parser using the boundary trigram estim</context>
</contexts>
<marker>Kochman, Kupin, 1991</marker>
<rawString>Kochman, Fred and Joseph Kupin. 1991. Calculating the probability of a partial parse of sentence. In DARPA Speech and Language Workshop, pages 237-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Parsing the Voyager domain using Pearl.</title>
<date>1991</date>
<booktitle>In DARPA Speech and Language Workshop,</booktitle>
<pages>231--236</pages>
<contexts>
<context position="35449" citStr="Magerman and Marcus (1991)" startWordPosition="6002" endWordPosition="6005">oposed a heuristic solution of penalizing shorter constituents by a fixed amount per word. Miller and Fox (1994) compare the performance of parsers using three different types of grammars, and show that a probabilistic context-free grammar using inside probability (unnormalized) as a figure of merit outperforms both a context-free grammar and a context-dependent grammar. Kochman and Kupin (1991) propose a figure of merit closely related to our prefix estimate. They do not actually incorporate this figure into a best-first parser. 0.6 0.4 — 0.2 — 0.0 292 Caraballo and Charniak Figures of Merit Magerman and Marcus (1991) use the geometric mean to compute a figure of merit that is independent of constituent length. Magerman and Weir (1992) use a similar model with a different parsing algorithm. 9. Conclusions We have presented and evaluated several figures of merit for best-first parsing. The best performer according to all of our measures was the parser using the boundary trigram estimate as a figure of merit, and this result holds for two different grammars. This figure has the additional advantage that it can be easily incorporated into existing best-first parsers using a figure of merit based on inside pro</context>
</contexts>
<marker>Magerman, Marcus, 1991</marker>
<rawString>Magerman, David M. and Mitchell P. Marcus. 1991. Parsing the Voyager domain using Pearl. In DARPA Speech and Language Workshop, pages 231-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Magerman</author>
<author>Carl Weir</author>
</authors>
<title>Efficiency, robustness and accuracy in Picky chart parsing.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting, Association for Computational Linguistics,</booktitle>
<pages>40--47</pages>
<contexts>
<context position="35569" citStr="Magerman and Weir (1992)" startWordPosition="6022" endWordPosition="6025">he performance of parsers using three different types of grammars, and show that a probabilistic context-free grammar using inside probability (unnormalized) as a figure of merit outperforms both a context-free grammar and a context-dependent grammar. Kochman and Kupin (1991) propose a figure of merit closely related to our prefix estimate. They do not actually incorporate this figure into a best-first parser. 0.6 0.4 — 0.2 — 0.0 292 Caraballo and Charniak Figures of Merit Magerman and Marcus (1991) use the geometric mean to compute a figure of merit that is independent of constituent length. Magerman and Weir (1992) use a similar model with a different parsing algorithm. 9. Conclusions We have presented and evaluated several figures of merit for best-first parsing. The best performer according to all of our measures was the parser using the boundary trigram estimate as a figure of merit, and this result holds for two different grammars. This figure has the additional advantage that it can be easily incorporated into existing best-first parsers using a figure of merit based on inside probability. (As mentioned earlier, the efficient online computation of # is described in Appendix A.) We strongly recommen</context>
</contexts>
<marker>Magerman, Weir, 1992</marker>
<rawString>Magerman, David M. and Carl Weir. 1992. Efficiency, robustness and accuracy in Picky chart parsing. In Proceedings of the 30th Annual Meeting, Association for Computational Linguistics, pages 40-47.</rawString>
</citation>
<citation valid="false">
<institution>Association for Computational Linguistics.</institution>
<marker></marker>
<rawString>Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--313</pages>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn treebank. Computational Linguistics, 19:313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Miller</author>
<author>Heidi Fox</author>
</authors>
<title>Automatic grammar acquisition.</title>
<date>1994</date>
<booktitle>In Proceedings of the Human Language Technology Workshop,</booktitle>
<pages>268--271</pages>
<contexts>
<context position="34935" citStr="Miller and Fox (1994)" startWordPosition="5922" endWordPosition="5925">in Charniak (1996), and the parser in, that paper is a best-first parser using the boundary trigram figure of merit. The literature shows many implementations of best-first parsing, but none of the previous work shares our goal of explicitly comparing figures of merit. Bobrow (1990) and Chitrao and Grishman (1990) introduced statistical agendabased parsing techniques. Chitrao and Grishman implemented a best-first probabilistic parser and noted the parser&apos;s tendency to prefer shorter constituents. They proposed a heuristic solution of penalizing shorter constituents by a fixed amount per word. Miller and Fox (1994) compare the performance of parsers using three different types of grammars, and show that a probabilistic context-free grammar using inside probability (unnormalized) as a figure of merit outperforms both a context-free grammar and a context-dependent grammar. Kochman and Kupin (1991) propose a figure of merit closely related to our prefix estimate. They do not actually incorporate this figure into a best-first parser. 0.6 0.4 — 0.2 — 0.0 292 Caraballo and Charniak Figures of Merit Magerman and Marcus (1991) use the geometric mean to compute a figure of merit that is independent of constituen</context>
</contexts>
<marker>Miller, Fox, 1994</marker>
<rawString>Miller, Scott and Heidi Fox. 1994. Automatic grammar acquisition. In Proceedings of the Human Language Technology Workshop, pages 268-271.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>