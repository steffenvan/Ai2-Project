<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.031956">
<title confidence="0.994568">
Hybrid Stemmer for Gujarati
</title>
<author confidence="0.994272">
Pratikkumar Patel Kashyap Popat
</author>
<affiliation confidence="0.9820705">
Department of Computer Engineering
Dharmsinh Desai University
</affiliation>
<email confidence="0.9678325">
pratikpat88@gmail.com
kan.pop@gmail.com
</email>
<sectionHeader confidence="0.993721" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999118428571429">
In this paper we present a lightweight
stemmer for Gujarati using a hybrid ap-
proach. Instead of using a completely
unsupervised approach, we have har-
nessed linguistic knowledge in the form
of a hand-crafted Gujarati suffix list in
order to improve the quality of the stems
and suffixes learnt during the training
phase. We used the EMILLE corpus for
training and evaluating the stemmer’s
performance. The use of hand-crafted
suffixes boosted the accuracy of our
stemmer by about 17% and helped us
achieve an accuracy of 67.86 %.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999116095238095">
Stemming is the process of conflating related
words to a common stem by chopping off the
inflectional and derivational endings. Stemming
plays an important role in Information Retrieval
(IR) systems by reducing the index size and in-
creasing the recall by retrieving results contain-
ing any of the various possible forms of a word
present in the query. This is especially true in
case of a morphologically rich language like
Gujarati, where a single word may take many
forms. The aim is to ensure that related words
map to common stem, irrespective of whether or
not the stem is a meaningful word in the voca-
bulary of the language.
Current state of the art approaches to stem-
ming can be classified into three categories, viz.,
rule based, unsupervised and hybrid. Building a
rule based stemmer for a morphologically rich
language is an uphill task considering the dif-
ferent inflectional and morphological variations
possible. Purely unsupervised approaches on the
</bodyText>
<author confidence="0.701775">
Pushpak Bhattacharyya
</author>
<affiliation confidence="0.955885">
Department of Computer Science and
Engineering
Indian Institute of Technology Bombay
</affiliation>
<email confidence="0.943318">
pb@cse.iitb.ac.in
</email>
<bodyText confidence="0.999934833333333">
other hand fail to take advantage of some lan-
guage phenomenon which can be easily ex-
pressed by simple rules. We thus follow a hybr-
id approach by enhancing an unsupervised sys-
tem with a list of hand-crafted Gujarati suffixes.
The remainder of this paper is organized as
follows. We describe related work in section 2.
Section 3 explains the morphological structure
of Gujarati. We describe our approach in section
4. The experiments and results are described in
section 5. Section 6 concludes the paper hig-
hlighting the future work.
</bodyText>
<sectionHeader confidence="0.811507" genericHeader="introduction">
2 Background and Related Work
</sectionHeader>
<bodyText confidence="0.999277846153846">
The earliest English stemmer was developed by
Julie Beth Lovins in 1968. The Porter stemming
algorithm (Martin Porter, 1980), which was
published later, is perhaps the most widely used
algorithm for English stemming. Both of these
stemmers are rule based and are best suited for
less inflectional languages like English.
A lot of work has been done in the field of
unsupervised learning of morphology.
Goldsmith (2001, 2006) proposed an unsuper-
vised algorithm for learning the morphology of
a language based on the minimum description
length (MDL) framework which focuses on
representing the data in as compact manner as
possible. Creutz (2005, 2007) uses probabilistic
maximum a posteriori (MAP) formulation for
unsupervised morpheme segmentation.
Not much work has been reported for stem-
ming for Indian languages compared to English
and other European languages. The earliest
work reported by Ramanathan and Rao (2003)
used a hand crafted suffix list and performed
longest match stripping for building a Hindi
stemmer. Majumder et al. (2007) developed
YASS: Yet Another Suffix Stripper which uses
a clustering based approach based on string dis-
</bodyText>
<page confidence="0.978024">
51
</page>
<bodyText confidence="0.983438333333333">
Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 51–55,
the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010
tance measures and requires no linguistic know-
ledge. They concluded that stemming improves
recall of IR systems for Indian languages like
Bengali. Dasgupta and Ng (2007) worked on
unsupervised morphological parsing for Benga-
li. Pandey and Siddiqui (2008) proposed an un-
supervised stemming algorithm for Hindi based
on Goldsmith&apos;s (2001) approach.
Unlike previous approaches for Indian lan-
guages which are either rule based or complete-
ly unsupervised, we propose a hybrid approach
which harnesses linguistic knowledge in the
form of a hand-crafted suffix list.
</bodyText>
<sectionHeader confidence="0.988229" genericHeader="method">
3 Gujarati Morphology
</sectionHeader>
<bodyText confidence="0.999989941176471">
Gujarati has three genders (masculine, neuter
and feminine), two numbers (singular and plur-
al) and three cases (nominative, obli-
que/vocative and locative) for nouns. The gend-
er of a noun is determined either by its meaning
or by its termination. The nouns get inflected on
the basis of the word ending, number and case.
The Gujarati adjectives are of two types – dec-
linable and indeclinable. The declinable adjec-
tives have the termination -ũ (◌ુ◌ં) in neuter ab-
solute. The masculine absolute of these adjec-
tives ends in -o (◌ો) and the feminine absolute in
-ī (◌ી). For example, the adjective સાἘં (sārũ -
good) takes the form સાἘં (sārũ), સારો (sāro) and
સારી (sārī) when used for a neuter, masculine
and feminine object respectively. These adjec-
tives agree with the noun they qualify in gender,
number and case. The adjectives that do not end
in -ũ in neuter absolute singular are classified as
indeclinable and remain unaltered when affixed
to a noun.
The Gujarati verbs are inflected based upon a
combination of gender, number, person, aspect,
tense and mood.
There are several postpositions in Gujarati
which get bound to the nouns or verbs which
they postposition. e.g. -nũ (નું : genitive marker),
-mā̃ (માં : in), -e (◌ે : ergative marker), etc. These
postpositions get agglutinated to the nouns or
verbs and not merely follow them.
We created a list of hand crafted Gujarati suf-
fixes which contains the postpositions and the
inflectional suffixes for nouns, adjectives and
verbs for use in our approach.
</bodyText>
<sectionHeader confidence="0.969641" genericHeader="method">
4 Our Approach
</sectionHeader>
<bodyText confidence="0.999975769230769">
Our approach is based on Goldsmith&apos;s (2001)
take-all-splits method. Goldsmith&apos;s method was
purely unsupervised, but we have used a list of
hand crafted Gujarati suffixes in our approach
to learn a better set of stems and suffixes during
the training phase. In our approach, we make
use of a list of Gujarati words extracted from
EMILLE corpus for the purpose of learning the
probable stems and suffixes for Gujarati during
the training phase. This set of stems and suffix-
es will be used for stemming any word provided
to the stemmer. We have described the details
of our approach below.
</bodyText>
<subsectionHeader confidence="0.997361">
4.1 Training Phase
</subsectionHeader>
<bodyText confidence="0.999994">
During the training phase, we try to obtain the
optimal split position for each word present in
the Gujarati word list provided for training. We
obtain the optimal split for any word by taking
all possible splits of the word (see Figure 1) and
choosing the split which maximizes the function
given in Eqn 1 as the optimal split position. The
suffix corresponding to the optimal split
position is verified against the list of 59 Gujarati
suffixes created by us. If it cannot be generated
by agglutination of the hand crafted suffixes,
then the length of the word is chosen as the
optimal split position. i.e. the entire word is
treated as a stem with no suffix.
</bodyText>
<equation confidence="0.9368975">
{stem1+suffix1,stem2+suffix2, ... ,stemL+suffixL}
ઘરના= {ઘ + રના, ઘર + ના, ઘરન + ◌ા,ઘરના + NULL}
</equation>
<figureCaption confidence="0.896428">
Figure 1. All Possible Word Segmentations
</figureCaption>
<equation confidence="0.8843385">
f(i) = i*log(freq(stemi)) + (L-i)*log(freq(suffixi))
(Eqn 1)
</equation>
<bodyText confidence="0.938361166666667">
i: split position (varies from 1 to L)
L: Length of the word
The function used for finding the optimal
split position reflects the probability of a partic-
ular split since the probability of any split is
determined by the frequencies of the stem and
suffix generated by that split. The frequency of
shorter stems and suffixes is very high when
compared to the slightly longer ones. Thus the
multipliers i (length of stemi) and L-i (length of
suffixi) have been introduced in the function in
order to compensate for this disparity.
</bodyText>
<page confidence="0.992571">
52
</page>
<bodyText confidence="0.999965857142857">
Once we obtain the optimal split of any word,
we update the frequencies of the stem and suffix
generated by that split. We iterate over the word
list and re-compute the optimal split position
until the optimal split positions of all the words
remain unchanged. The training phase was ob-
served to take three iterations typically.
</bodyText>
<subsectionHeader confidence="0.928628">
4.2 Signatures
</subsectionHeader>
<bodyText confidence="0.9056054">
After the training phase, we have a list of stems
and suffixes along with their frequencies. We
use this list to create signatures. As shown in
Figure 2, each signature contains a list of stems
and a list of suffixes appearing with these stems.
</bodyText>
<table confidence="0.982532">
Stems Suffixes
IUL (pashu - animal) -l (nd)
6iA (fang - war) -.l (no)
-� (ne)
-�i (nũ)
- (nī)
</table>
<figureCaption confidence="0.998599">
Figure 2. Sample Signature
</figureCaption>
<bodyText confidence="0.999113375">
The signatures which contain very few stems
or very few suffixes may not be useful in stem-
ming of unknown words, thus we eliminate the
signatures containing at most one stem or at
most one suffix. The stems and suffixes in the
remaining signatures will be used to stem new
words. An overview of the training algorithm is
shown in Figure 3.
</bodyText>
<figureCaption confidence="0.998805181818182">
Step 1: Obtain the optimal split position for each
word in the word list provided for training
using Eqn 1 and the list of hand crafted suf-
fixes
Step 2: Repeat Step 1 until the optimal split posi-
tions of all the words remain unchanged
Step 3: Generate signatures using the stems and
suffixes generated from the training phase
Step 4: Discard the signatures which contain either
only one stem or only one suffix
Figure 3. Overview of training algorithm
</figureCaption>
<subsectionHeader confidence="0.998136">
4.3 Stemming of any unknown word
</subsectionHeader>
<bodyText confidence="0.999946333333333">
For stemming of any word given to the stemmer,
we evaluate the function in Eqn 1 for each poss-
ible split using the frequencies of stems and suf-
fixes obtained from the training process. The
word is stemmed at the position for which the
value of the function is maximum.
</bodyText>
<sectionHeader confidence="0.985755" genericHeader="evaluation">
5 Experiments and Result
</sectionHeader>
<bodyText confidence="0.999980142857143">
We performed various experiments to evaluate
the performance of the stemmer using EMILLE
Corpus for Gujarati. We extracted around ten
million words from the corpus. These words
also contained Gujarati transliterations of Eng-
lish words. We tried to filter out these words by
using a Gujarati to English transliteration engine
and an English dictionary. We obtained
8,525,649 words after this filtering process.
We have used five-fold cross validation for
evaluating the performance. We divided the ex-
tracted words into five equal parts of which four
were used for training and one for testing. In
order to create gold standard data, we extracted
thousand words from the corpus randomly and
tagged the ideal stem for these words manually.
For each of the five test sets, we measured
the accuracy of stemming the words which are
present in the test set as well as gold standard
data. Accuracy is defined as the percentage of
words stemmed correctly.
The experiments were aimed at studying the
impact of (i) using a hand-crafted suffix list, (ii)
fixing the minimum permissible stem size and
(iii) provide unequal weightage to the stem and
suffix for deciding the optimal split position.
Various results based on these experiments are
described in the following subsections.
</bodyText>
<subsectionHeader confidence="0.999498">
5.1 Varying Minimum Stem Size
</subsectionHeader>
<bodyText confidence="0.999955">
We varied the minimum stem size from one to
six and observed its impact on the system per-
formance. We performed the experiment with
and without using the hand-crafted suffix list.
The results of this experiment are shown in Ta-
ble 1 and Figure 4.
The results of this experiment clearly indicate
that there is a large improvement in the perfor-
mance of the stemmer with the use of hand-
crafted suffixes and the performance degrades if
we keep a restriction on the minimum stem size.
For higher values of minimum stem size, all the
valid stems which are shorter than the minimum
stem size do not get generated leading to a de-
cline in accuracy.
</bodyText>
<page confidence="0.996145">
53
</page>
<table confidence="0.997061181818182">
Min Stem Accuracy
Size
With hand- Without hand-
crafted suffixes crafted suffix-
es
1 67.86 % 50.04 %
2 67.70 % 49.80 %
3 66.43 % 49.60 %
4 59.46 % 46.35 %
5 51.65 % 41.22 %
6 43.81 % 36.89 %
</table>
<tableCaption confidence="0.990904">
Table 1. Effect of use of hand-crafted suffixes and
fixing min. stem size on stemmer’s performance
</tableCaption>
<figureCaption confidence="0.9876855">
Figure 4. Variation stemmer’s accuracy with the var-
iation in min. stem size
</figureCaption>
<bodyText confidence="0.99998675">
There are several spurious suffixes which get
generated during the training phase and degrade
the performance of the stemmer when we don’t
use the hand-crafted suffix list. e.g. ‘ક’ is not a
valid inflectional Gujarati suffix but it does get
generated if we don’t use the hand-crafted suf-
fix list due to words such as ‘અનેક’ (anek - many)
and ‘અને’ (ane - and). A simple validation of the
suffixes generated during training against the
hand-crafted suffix list leads to learning of bet-
ter suffixes and in turn better stems during the
training phase thereby improving the system’s
performance.
Thus we decided to make use of the hand-
crafted suffix list during training phase and not
to put any restriction on the minimum stem size.
</bodyText>
<subsectionHeader confidence="0.991856">
5.2 Providing unequal weightage to stem
and suffix
</subsectionHeader>
<bodyText confidence="0.9998706">
We have provided equal weightage to stem and
suffix in Eqn 1 which is responsible for deter-
mining the optimal split position of any word.
We obtained Eqn 2 from Eqn 1 by introducing a
parameter ‘α’ in order to provide unequal
weightage to the stem and suffix and observe its
effect on system performance. We used Eqn 2
instead of Eqn 1 and varied α from 0.1 to 0.9 in
this experiment. The results of this experiment
are shown in Table 2.
</bodyText>
<equation confidence="0.892038666666667">
f(i) = α * i * log(freq(stemi)) +
(1-α) * (L-i) * log(freq(suffixi))
(Eqn 2)
</equation>
<table confidence="0.9204572">
α Accuracy
0.1 53.52 %
0.2 61.71 %
0.3 65.43 %
0.4 67.30 %
0.5 67.86 %
0.6 67.48 %
0.7 67.49 %
0.8 67.72 %
0.9 66.45 %
</table>
<tableCaption confidence="0.99811">
Table 2. Effect of α on the stemmer’s performance
</tableCaption>
<bodyText confidence="0.999929">
The accuracy was found to be maximum
when value of α was fixed to 0.5 i.e. stem and
suffix were given equal weightage for determin-
ing the optimal split of any word.
</bodyText>
<sectionHeader confidence="0.996168" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999894">
We developed a lightweight stemmer for Guja-
rati using a hybrid approach which has an accu-
racy of 67.86 %. We observed that use of a
hand-crafted Gujarati suffix list boosts the accu-
racy by about 17 %. We also found that fixing
the minimum stem size and providing unequal
weightage to stem and suffix degrades the per-
formance of the system.
Our stemmer is lightweight and removes only
the inflectional endings as we have developed it
for use in IR system. The list of hand-crafted
suffixes can be extended to include derivational
suffixes for performing full fledged stemming
which may be required in applications such as
displaying words in a user interface.
We have measured the performance of the
stemmer in terms of accuracy as of now. We
plan to evaluate the stemmer in terms of the in-
dex compression achieved and the impact on
precision and recall of Gujarati IR system.
</bodyText>
<page confidence="0.994967">
54
</page>
<note confidence="0.814379">
The EMILLE Corpus,
http://www.lancs.ac.uk/fass/projects/corpus/emille/
</note>
<sectionHeader confidence="0.983574" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999508081632653">
Creutz, Mathis, and Krista Lagus. 2005. Unsuper-
vised morpheme segmentation and morphology
induction from text corpora using Morfessor 1.0.
Technical Report A81, Publications in Computer
and Information Science, Helsinki University of
Technology.
Creutz, Mathis, and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and
morphology learning. Association for Computing
Machinery Transactions on Speech and Language
Processing, 4(1):1-34.
Dasgupta, Sajib, and Vincent Ng. 2006. Unsuper-
vised Morphological Parsing of Bengali. Lan-
guage Resources and Evaluation, 40(3-4):311-
330.
Goldsmith, John A. 2001. Unsupervised learning of
the morphology of a natural language. Computa-
tional Linguistics, 27(2):153-198
Goldsmith, John A. 2006. An algorithm for the un-
supervised learning of morphology. Natural Lan-
guage Engineering, 12(4):353-371
Jurafsky, Daniel, and James H. Martin. 2009. Speech
and Language Processing: An Introduction to
Natural Language Processing, Speech Recogni-
tion, and Computational Linguistics. 2nd edition.
Prentice-Hall, Englewood Cliffs, NJ.
Lovins, Julie B. 1968. Development of a stemming
algorithm. Mechanical Translation and Computa-
tional Linguistics, 11:22-31
Majumder, Prasenjit, Mandar Mitra, Swapan K. Pa-
rui, Gobinda Kole, Pabitra Mitra, and Kalyanku-
mar Datta. 2007. YASS: Yet another suffix strip-
per. Association for Computing Machinery Trans-
actions on Information Systems, 25(4):18-38.
Pandey, Amaresh K., and Tanveer J. Siddiqui. 2008.
An unsupervised Hindi stemmer with heuristic
improvements. In Proceedings of the Second
Workshop on Analytics For Noisy Unstructured
Text Data, 303:99-105.
Porter, Martin F. 1980. An algorithm for suffix strip-
ping. Program, 14(3):130-137.
Ramanathan, Ananthakrishnan, and Durgesh D. Rao,
A Lightweight Stemmer for Hindi, Workshop on
Computational Linguistics for South-Asian Lan-
guages, EACL, 2003.
Tisdall, William St. Clair. 1892. A simplified gram-
mar of the Gujarati language : together with A
short reading book and vocabulary. D. B. Tarapo-
revala Sons &amp; Company, Bombay.
</reference>
<page confidence="0.999058">
55
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.929463">
<title confidence="0.998176">Hybrid Stemmer for Gujarati</title>
<author confidence="0.995419">Pratikkumar Patel Kashyap Popat</author>
<affiliation confidence="0.9964075">Department of Computer Engineering Dharmsinh Desai University</affiliation>
<email confidence="0.988519">pratikpat88@gmail.comkan.pop@gmail.com</email>
<abstract confidence="0.997413066666667">In this paper we present a lightweight stemmer for Gujarati using a hybrid approach. Instead of using a completely unsupervised approach, we have harnessed linguistic knowledge in the form of a hand-crafted Gujarati suffix list in order to improve the quality of the stems and suffixes learnt during the training phase. We used the EMILLE corpus for training and evaluating the stemmer’s performance. The use of hand-crafted suffixes boosted the accuracy of our stemmer by about 17% and helped us achieve an accuracy of 67.86 %.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mathis Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0.</title>
<date>2005</date>
<tech>Technical Report A81,</tech>
<institution>Publications in Computer and Information Science, Helsinki University of Technology.</institution>
<marker>Creutz, Lagus, 2005</marker>
<rawString>Creutz, Mathis, and Krista Lagus. 2005. Unsupervised morpheme segmentation and morphology induction from text corpora using Morfessor 1.0. Technical Report A81, Publications in Computer and Information Science, Helsinki University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathis Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning.</title>
<date>2007</date>
<journal>Association for Computing Machinery Transactions on Speech and Language Processing,</journal>
<pages>4--1</pages>
<marker>Creutz, Lagus, 2007</marker>
<rawString>Creutz, Mathis, and Krista Lagus. 2007. Unsupervised models for morpheme segmentation and morphology learning. Association for Computing Machinery Transactions on Speech and Language Processing, 4(1):1-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sajib Dasgupta</author>
<author>Vincent Ng</author>
</authors>
<title>Unsupervised Morphological Parsing of Bengali. Language Resources and Evaluation,</title>
<date>2006</date>
<pages>40--3</pages>
<marker>Dasgupta, Ng, 2006</marker>
<rawString>Dasgupta, Sajib, and Vincent Ng. 2006. Unsupervised Morphological Parsing of Bengali. Language Resources and Evaluation, 40(3-4):311-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Goldsmith</author>
</authors>
<title>Unsupervised learning of the morphology of a natural language.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<pages>27--2</pages>
<contexts>
<context position="2781" citStr="Goldsmith (2001" startWordPosition="440" endWordPosition="441">of Gujarati. We describe our approach in section 4. The experiments and results are described in section 5. Section 6 concludes the paper highlighting the future work. 2 Background and Related Work The earliest English stemmer was developed by Julie Beth Lovins in 1968. The Porter stemming algorithm (Martin Porter, 1980), which was published later, is perhaps the most widely used algorithm for English stemming. Both of these stemmers are rule based and are best suited for less inflectional languages like English. A lot of work has been done in the field of unsupervised learning of morphology. Goldsmith (2001, 2006) proposed an unsupervised algorithm for learning the morphology of a language based on the minimum description length (MDL) framework which focuses on representing the data in as compact manner as possible. Creutz (2005, 2007) uses probabilistic maximum a posteriori (MAP) formulation for unsupervised morpheme segmentation. Not much work has been reported for stemming for Indian languages compared to English and other European languages. The earliest work reported by Ramanathan and Rao (2003) used a hand crafted suffix list and performed longest match stripping for building a Hindi stemm</context>
</contexts>
<marker>Goldsmith, 2001</marker>
<rawString>Goldsmith, John A. 2001. Unsupervised learning of the morphology of a natural language. Computational Linguistics, 27(2):153-198</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Goldsmith</author>
</authors>
<title>An algorithm for the unsupervised learning of morphology.</title>
<date>2006</date>
<journal>Natural Language Engineering,</journal>
<pages>12--4</pages>
<marker>Goldsmith, 2006</marker>
<rawString>Goldsmith, John A. 2006. An algorithm for the unsupervised learning of morphology. Natural Language Engineering, 12(4):353-371</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics. 2nd edition. Prentice-Hall,</title>
<date>2009</date>
<location>Englewood Cliffs, NJ.</location>
<marker>Jurafsky, Martin, 2009</marker>
<rawString>Jurafsky, Daniel, and James H. Martin. 2009. Speech and Language Processing: An Introduction to Natural Language Processing, Speech Recognition, and Computational Linguistics. 2nd edition. Prentice-Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julie B Lovins</author>
</authors>
<title>Development of a stemming algorithm.</title>
<date>1968</date>
<journal>Mechanical Translation and Computational Linguistics,</journal>
<pages>11--22</pages>
<marker>Lovins, 1968</marker>
<rawString>Lovins, Julie B. 1968. Development of a stemming algorithm. Mechanical Translation and Computational Linguistics, 11:22-31</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prasenjit Majumder</author>
<author>Mandar Mitra</author>
<author>Swapan K Parui</author>
<author>Gobinda Kole</author>
<author>Pabitra Mitra</author>
<author>Kalyankumar Datta</author>
</authors>
<title>YASS: Yet another suffix stripper.</title>
<date>2007</date>
<journal>Association for Computing Machinery Transactions on Information Systems,</journal>
<pages>25--4</pages>
<contexts>
<context position="3407" citStr="Majumder et al. (2007)" startWordPosition="533" endWordPosition="536">06) proposed an unsupervised algorithm for learning the morphology of a language based on the minimum description length (MDL) framework which focuses on representing the data in as compact manner as possible. Creutz (2005, 2007) uses probabilistic maximum a posteriori (MAP) formulation for unsupervised morpheme segmentation. Not much work has been reported for stemming for Indian languages compared to English and other European languages. The earliest work reported by Ramanathan and Rao (2003) used a hand crafted suffix list and performed longest match stripping for building a Hindi stemmer. Majumder et al. (2007) developed YASS: Yet Another Suffix Stripper which uses a clustering based approach based on string dis51 Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 51–55, the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010 tance measures and requires no linguistic knowledge. They concluded that stemming improves recall of IR systems for Indian languages like Bengali. Dasgupta and Ng (2007) worked on unsupervised morphological parsing for Bengali. Pandey and Siddiqui (2008) proposed an unsupervised stemmin</context>
</contexts>
<marker>Majumder, Mitra, Parui, Kole, Mitra, Datta, 2007</marker>
<rawString>Majumder, Prasenjit, Mandar Mitra, Swapan K. Parui, Gobinda Kole, Pabitra Mitra, and Kalyankumar Datta. 2007. YASS: Yet another suffix stripper. Association for Computing Machinery Transactions on Information Systems, 25(4):18-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amaresh K Pandey</author>
<author>Tanveer J Siddiqui</author>
</authors>
<title>An unsupervised Hindi stemmer with heuristic improvements.</title>
<date>2008</date>
<booktitle>In Proceedings of the Second Workshop on Analytics For Noisy Unstructured Text Data,</booktitle>
<pages>303--99</pages>
<contexts>
<context position="3974" citStr="Pandey and Siddiqui (2008)" startWordPosition="615" endWordPosition="618">ipping for building a Hindi stemmer. Majumder et al. (2007) developed YASS: Yet Another Suffix Stripper which uses a clustering based approach based on string dis51 Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 51–55, the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010 tance measures and requires no linguistic knowledge. They concluded that stemming improves recall of IR systems for Indian languages like Bengali. Dasgupta and Ng (2007) worked on unsupervised morphological parsing for Bengali. Pandey and Siddiqui (2008) proposed an unsupervised stemming algorithm for Hindi based on Goldsmith&apos;s (2001) approach. Unlike previous approaches for Indian languages which are either rule based or completely unsupervised, we propose a hybrid approach which harnesses linguistic knowledge in the form of a hand-crafted suffix list. 3 Gujarati Morphology Gujarati has three genders (masculine, neuter and feminine), two numbers (singular and plural) and three cases (nominative, oblique/vocative and locative) for nouns. The gender of a noun is determined either by its meaning or by its termination. The nouns get inflected on</context>
</contexts>
<marker>Pandey, Siddiqui, 2008</marker>
<rawString>Pandey, Amaresh K., and Tanveer J. Siddiqui. 2008. An unsupervised Hindi stemmer with heuristic improvements. In Proceedings of the Second Workshop on Analytics For Noisy Unstructured Text Data, 303:99-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<tech>Program,</tech>
<pages>14--3</pages>
<contexts>
<context position="2488" citStr="Porter, 1980" startWordPosition="392" endWordPosition="393">e easily expressed by simple rules. We thus follow a hybrid approach by enhancing an unsupervised system with a list of hand-crafted Gujarati suffixes. The remainder of this paper is organized as follows. We describe related work in section 2. Section 3 explains the morphological structure of Gujarati. We describe our approach in section 4. The experiments and results are described in section 5. Section 6 concludes the paper highlighting the future work. 2 Background and Related Work The earliest English stemmer was developed by Julie Beth Lovins in 1968. The Porter stemming algorithm (Martin Porter, 1980), which was published later, is perhaps the most widely used algorithm for English stemming. Both of these stemmers are rule based and are best suited for less inflectional languages like English. A lot of work has been done in the field of unsupervised learning of morphology. Goldsmith (2001, 2006) proposed an unsupervised algorithm for learning the morphology of a language based on the minimum description length (MDL) framework which focuses on representing the data in as compact manner as possible. Creutz (2005, 2007) uses probabilistic maximum a posteriori (MAP) formulation for unsupervise</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>Porter, Martin F. 1980. An algorithm for suffix stripping. Program, 14(3):130-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ananthakrishnan Ramanathan</author>
<author>Durgesh D Rao</author>
</authors>
<title>A Lightweight Stemmer for Hindi,</title>
<date>2003</date>
<booktitle>Workshop on Computational Linguistics for South-Asian Languages, EACL,</booktitle>
<contexts>
<context position="3284" citStr="Ramanathan and Rao (2003)" startWordPosition="513" endWordPosition="516">l languages like English. A lot of work has been done in the field of unsupervised learning of morphology. Goldsmith (2001, 2006) proposed an unsupervised algorithm for learning the morphology of a language based on the minimum description length (MDL) framework which focuses on representing the data in as compact manner as possible. Creutz (2005, 2007) uses probabilistic maximum a posteriori (MAP) formulation for unsupervised morpheme segmentation. Not much work has been reported for stemming for Indian languages compared to English and other European languages. The earliest work reported by Ramanathan and Rao (2003) used a hand crafted suffix list and performed longest match stripping for building a Hindi stemmer. Majumder et al. (2007) developed YASS: Yet Another Suffix Stripper which uses a clustering based approach based on string dis51 Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 51–55, the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010 tance measures and requires no linguistic knowledge. They concluded that stemming improves recall of IR systems for Indian languages like Bengali. Dasgupta and Ng (</context>
</contexts>
<marker>Ramanathan, Rao, 2003</marker>
<rawString>Ramanathan, Ananthakrishnan, and Durgesh D. Rao, A Lightweight Stemmer for Hindi, Workshop on Computational Linguistics for South-Asian Languages, EACL, 2003.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Clair</author>
</authors>
<title>A simplified grammar of the Gujarati language : together with A short reading book and vocabulary.</title>
<journal>D. B. Taraporevala Sons</journal>
<publisher>Company,</publisher>
<location>Bombay.</location>
<marker>Clair, </marker>
<rawString>Tisdall, William St. Clair. 1892. A simplified grammar of the Gujarati language : together with A short reading book and vocabulary. D. B. Taraporevala Sons &amp; Company, Bombay.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>