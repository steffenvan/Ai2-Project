<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003438">
<title confidence="0.992835">
Chinese Novelty Mining
</title>
<author confidence="0.997716">
Yi Zhang
</author>
<affiliation confidence="0.994815">
Nanyang Technological University
</affiliation>
<address confidence="0.9397245">
50 Nanyang Avenue
Singapore 639798
</address>
<email confidence="0.9964">
yizhang@ntu.edu.sg
</email>
<author confidence="0.781941">
Flora S. Tsai
</author>
<affiliation confidence="0.838258">
Nanyang Technological University
</affiliation>
<address confidence="0.879733">
50 Nanyang Avenue
Singapore 639798
</address>
<email confidence="0.997873">
fst1@columbia.edu
</email>
<sectionHeader confidence="0.994753" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999476090909091">
Automated mining of novel documents
or sentences from chronologically ordered
documents or sentences is an open chal-
lenge in text mining. In this paper, we
describe the preprocessing techniques for
detecting novel Chinese text and discuss
the influence of different Part of Speech
(POS) filtering rules on the detection per-
formance. Experimental results on AP-
WSJ and TREC 2004 Novelty Track data
show that the Chinese novelty mining per-
formance is quite different when choosing
two dissimilar POS filtering rules. Thus,
the selection of words to represent Chinese
text is of vital importance to the success of
the Chinese novelty mining. Moreover, we
compare the Chinese novelty mining per-
formance with that of English and investi-
gate the impact of preprocessing steps on
detecting novel Chinese text, which will
be very helpful for developing a Chinese
novelty mining system.
</bodyText>
<sectionHeader confidence="0.998889" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999809321428572">
The bloom of information nowadays brings us rich
useful information as well as tons of redundant in-
formation in news articles, social networks (Tsai et
al., 2009), and blogs (Chen et al., 2008). Novelty
mining (NM), or novelty detection, aims at mining
novel information from a chronologically ordered
list of relevant documents/sentences. It can facil-
itate users to quickly get useful information with-
out going through a lot of redundant information,
which is usually a tedious and time-consuming
task.
The process of detecting novel text contains
three main steps, (i) preprocessing, (ii) cate-
gorization, and (iii) novelty mining. The first
step preprocesses the text documents/sentences
by removing stop words, performing word stem-
ming, implementing POS tagging etc. Categoriza-
tion classifies each incoming document/sentence
into its relevant topic bin. Then, within each
topic bin containing a group of relevant docu-
ments/sentences, novelty mining searches through
the time sequence of documents/sentences and re-
trieves only those with “novel” information. This
paper focuses on applying document/sentence-
level novelty mining on Chinese. In this task,
we need to identify all novel Chinese text given
groups of relevant documents/sentences.
Novelty mining has been performed at three dif-
ferent levels: event level, sentence level and doc-
ument level (Li and Croft, 2005). Works on nov-
elty mining at the event level originated from re-
search on Topic Detection and Tracking (TDT),
which is concerned with online new event detec-
tion/first story detection (Allan et al., 1998; Yang
et al., 2002; Stokes and Carthy, 2001; Franz et
al., 2001; Brants et al., 2003). Research on doc-
ument and sentence-level novelty mining aims to
find relevant and novel documents/sentences given
a stream of documents/sentences. Previous stud-
ies on document and sentence-level novelty min-
ing tend to apply some promising content-oriented
techniques (Li and Croft, 2005; Allan et al., 1998;
Yang et al., 1998; Zhang and Tsai, 2009). Simi-
larity metrics that can be used for detecting novel
text are word overlap, cosine similarity (Yang et
al., 1998), new word count (Brants et al., 2003),
etc. Other works utilize ontological knowledge,
especially taxonomy, such as WordNet (Zhang et
al., 2002; Allan et al., 2003), synonym dictionary
(Franz et al., 2001), HowNet (Eichmann and Srini-
vasan, 2002), etc.
Previous studies for novelty mining have been
conducted on the English and Malay languages
(Kwee et al., 2009; Tang et al., 2009; Tang and
Tsai, 2009). Novelty mining studies on the Chi-
nese language have been performed on topic de-
</bodyText>
<page confidence="0.935">
1561
</page>
<note confidence="0.9965685">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99987085">
tection and tracking, which identifies and collects
relevant stories on certain topics from information
stream (Zheng et al., 2008; Hong et al., 2008).
Also many works have discussed the issues, such
as word segmentation, POS tagging etc, between
English and Chinese (Wang et al., 2006; Wu et
al., 2003). However, to the best of our knowledge,
no studies have been reported on discussing pre-
processing techniques on Chinese document and
sentence-level novelty mining, which is the focus
of our paper.
The rest of this paper is organized as follows.
Section 2 gives a brief overview of related work on
detecting novel documents and sentences on En-
glish and Chinese. Section 3 introduces the details
of preprocessing steps for English and Chinese.
A general novelty mining algorithm is described
in Section 4. Section 5 reports experimental re-
sults. Section 6 summarizes the research findings
and discusses issues for further research.
</bodyText>
<sectionHeader confidence="0.999719" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998149966666666">
In the pioneering work for detecting novel doc-
uments (Zhang et al., 2002), document novelty
was predicted based on the distance between the
new document and the previously delivered doc-
uments in history. The detected document which
is very similar to any of its history documents is
regarded as a redundant document. To serve users
better, it could be more helpful to further highlight
novel information at the sentence level. Therefore,
later studies focused on detecting novel sentences,
such as those reported in TREC 2002-2004 Nov-
elty Tracks (Harman, 2002; Soboroff and Harman,
2003; Soboroff, 2004), which compared various
novelty metrics (Allan et al., 2003), and integrated
different natural language techniques (Ng et al.,
2007; Li and Croft, 2008).
Although novelty mining studies have mainly
been conducted on the English language, stud-
ies on the Chinese language have been performed
on topic detection and tracking. A prior study
(Zheng et al., 2008) proposed an improved rel-
evance model to detect the novelty information
in topic tracking feedback and modified the topic
model based on this information. Experimental
results on Chinese datasets TDT4 and TDT2003
proved the effectiveness in topic tracking. Another
study proposed a method of applying semantic do-
main language model to link detection, based on
the structure relation among contents and the se-
mantic distribution in a story (Hong et al., 2008).
</bodyText>
<sectionHeader confidence="0.984735" genericHeader="method">
3 Preprocessing for English and Chinese
</sectionHeader>
<subsectionHeader confidence="0.9945">
3.1 English
</subsectionHeader>
<bodyText confidence="0.98750655">
Since the focus of this paper is on novelty min-
ing, we begin from a list of relevant documents or
sentences that have already undergone the catego-
rization process.
The first step for English preprocessing is to re-
move all stop words from documents or sentences,
such as conjunctions, prepositions, and articles.
Stop words are words that are too common to
be informative. These words should be removed,
otherwise it will influence the novelty prediction
of documents or sentences. After stop words re-
moval, the remaining words are then stemmed.
The inflected (or sometimes derived) words are
reduced to their root forms. This paper used
Porter stemming algorithm (Porter, 1997) for En-
glish word stemming. This algorithm removes the
commoner morphological and inflexional endings
from the words in English. The entire preprocess-
ing steps in English novelty mining can be seen in
Figure 1.
</bodyText>
<subsectionHeader confidence="0.999146">
3.2 Chinese
</subsectionHeader>
<bodyText confidence="0.99951664">
In Chinese, the word is the smallest independent
meaningful element. There is no obvious bound-
ary between words so that Chinese lexical anal-
ysis, such as Chinese word segmentation, is the
prerequisite for novelty mining.
Unlike English, Chinese word segmentation
is a very challenging problem because of the
difficulties in defining what constitutes a word
(Gao et al., 2005). While each criteria pro-
vides valuable insights into “word-hood” in Chi-
nese, they do not consistently lead us to the
same conclusions. Moreover, there is no white
space between Chinese words or expressions
and there are many ambiguities in the Chinese
language, such as: ‘主 板 和 服 务 器’ (means
‘mainboard and server’ in English) might be ‘主
板/和/服务器’ (means ‘mainboard/and/server’ in
English) or ‘主 板/和 服/务/器’ (means ‘main-
board/kimono/task/utensil’ in English). This am-
biguity is a great challenge for Chinese word seg-
mentation. In addition, there is no obvious in-
flected or derived words in Chinese so that word
stemming is not applicable.
Therefore, in order to reduce the noise brought
by Chinese word segmentation and get a better
</bodyText>
<page confidence="0.991197">
1562
</page>
<figure confidence="0.9994371">
Relevant documents /
sentences
Novelty Mining
Remove Stop
Words
Stem Words
Preprocessing
steps
Novel documents /
sentences
</figure>
<figureCaption confidence="0.999972">
Figure 1: Preprocessing steps on English.
</figureCaption>
<bodyText confidence="0.999882957446809">
word list for one document or sentence, we firstly
apply word segmentation on the Chinese text and
then utilize Part-of-Speech (POS) tagging to se-
lect the meaningful candidate words. Figure 2
shows the preprocessing steps on the Chinese text
for novelty mining. POS tagging is a process of
marking up the word in a text as corresponding
to a particular part of speech. It is learnt that the
idea of a text mainly relies on some meaningful
words, such as nouns and verbs, so that we can get
the main content by extracting these meaningful
words. Moreover, it will decrease the impact of
the errors in Chinese word segmentation on nov-
elty mining because only meaningful words are
considered and other words (including stop words)
such as ‘虽然’ (means ‘although’ in English) will
not appear in the word list for the following sim-
ilarity computation in novelty mining. Losee also
mentioned that POS tagging shows a great poten-
tial to avoid lexical ambiguity and it can help to
improve the performance of information retrieval
(Losee, 2001).
ICTCLAS is used when performing word seg-
mentation and POS tagging in our experiments
(ICTCLAS, 2008). It is an open source project
and achieves a better precision in Chinese word
segmentation and POS tagging than other Chi-
nese POS tagging softwares (ICTCLAS, 2008).
First, we apply word segmentation on the relevant
Chinese documents/sentences. Chinese word seg-
mentation includes atom segmentation, N-shortest
path based rough segmentation and unknown
words recognition (see Figure 3). Atom segmen-
tation is an initial step of the Chinese language
segmentation process, where atom is defined to
be the minimal unit that cannot be split further.
The atom can be a Chinese character, punctua-
tion, symbol string, etc. Then, rough segmentation
tries to discover the correct segmentation with as
few candidates as possible. The N-Shortest Path
(NSP) method (Zhang and Liu, 2002) is applied
for rough segmentation. Next, we detect some un-
known words such as person name, location name
so as to optimize the segmentation result. Finally,
we POS tag the words and keep some kinds of
words in the word list according to the selective
rule, which are used in novelty mining.
</bodyText>
<sectionHeader confidence="0.980649" genericHeader="method">
4 Novelty Mining
</sectionHeader>
<bodyText confidence="0.999967">
From the output of preprocessing, we can obtain a
bag of words. The corresponding term-document
matrix (TDM)/term-sentence matrix (TSM) can be
constructed by counting the term frequency (TF)
of each word. The novelty mining system predicts
any incoming document/sentence by comparing it
with its history documents/sentences in this vector
space. Therefore, given a Chinese TDM/TSM, the
novelty mining system designed for English can
also be applied to Chinese.
In novelty mining, the novelty of a docu-
ment/sentence can be quantitatively measured by a
novelty metric and represented by a novelty score.
The most popular novelty metric, i.e. cosine sim-
ilarity (see (Allan et al., 2003)), is adopted. This
metric first calculates the similarities between the
current document/sentence dt and each of its his-
</bodyText>
<page confidence="0.854209">
1563
</page>
<figure confidence="0.9996117">
Relevant documents /
sentences
Novelty Mining
Word
Segmentation
POS Tagging
Preprocessing
steps
Novel documents /
sentences
</figure>
<figureCaption confidence="0.999562">
Figure 2: Preprocessing steps on Chinese.
</figureCaption>
<bodyText confidence="0.996088">
tory documents/sentences di (1 &lt; i &lt; t − 1).
Then, the novelty score is simply one minus the
maximum of these cosine similarities, as shown in
Eq.(1).
</bodyText>
<equation confidence="0.938928666666667">
Novelty 5core(dt) = 1 − max cos(dt, di) (1)
1&lt;i&lt;t−1
tll - lldill
</equation>
<bodyText confidence="0.999990090909091">
where N,os(d) denotes the cosine similarity score
of the document/sentence d and wk(d) is the
weight of kth element in the document/sentence
weighted vector d. The term weighting function
used in our work is TF(term frequency).
The final decision on whether a docu-
ment/sentence is novel or not depends on whether
the novelty score falls above or below a thresh-
old. The document/sentence predicted as “novel”
will be placed into the list of history docu-
ments/sentences.
</bodyText>
<sectionHeader confidence="0.99158" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.935812">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.998020444444444">
Two public datasets APWSJ (Zhang et al., 2002)
and TREC Novelty Track 2004 (Soboroff, 2004)
are selected as our experimental datasets for the
document-level and the sentence-level novelty
mining respectively. APWSJ data consists of
news articles from Associated Press (AP) and Wall
Street Journal (WSJ). There are 50 topics from
Q101 to Q150 in APWSJ and 5 topics (Q131,
Q142, Q145, Q147, Q150) are excluded from the
</bodyText>
<tableCaption confidence="0.999401">
Table 1: Statistics of experimental data
</tableCaption>
<table confidence="0.974143666666667">
Dataset Novel Non-novel
APWSJ 10839(91.10%) 1057(8.90%)
TREC2004 3454(41.40%) 4889(58.60%)
</table>
<bodyText confidence="0.999805083333333">
experiments because they lack non-novel docu-
ments (Zhao et al., 2006). The assessors provide
two degrees of judgements on non-novel docu-
ments, absolute redundant and somewhat redun-
dant. In our experiments, we adopt the strict defi-
nition used in (Zhang et al., 2002) where only ab-
solute redundant documents are regarded as non-
novel. TREC 2004 Novelty Track data is devel-
oped from AQUAINT collection. Both relevant
and novel sentences are selected by TREC’s asses-
sors. The statistics of these two datasets are sum-
marized in Table 1.
</bodyText>
<subsectionHeader confidence="0.996083">
5.2 Evaluation Measures
</subsectionHeader>
<bodyText confidence="0.999934615384615">
From many previous works, redundancy precision
(RP), redundancy recall (RR) and redundancy F
Score (RF) are used to evaluate the performance
of document-level novelty mining (Zhang et al.,
2002). Precision (P), recall (R) and F Score (F)
are mainly used in evaluating the performance for
sentence-level novelty mining (Allan et al., 2003).
Therefore, we use RP, RR, RF and redundancy
precision-recall (R-PR) curve to evaluate our ex-
perimental results on the document level. P, R, F
and precision-recall (PR) curve are used to eval-
uate the performance on the sentence-level nov-
elty mining. The larger the area under the R-PR
</bodyText>
<equation confidence="0.899760666666667">
�� k=1 wk(dt) - wk(di)
cos(dt, di) =
lld
</equation>
<page confidence="0.901242">
1564
</page>
<figure confidence="0.9871426875">
Document/
Sentence
String
Atom
Segmentation
Atom Sequence
NSP-based
Rough
Segmentation
Top N Sequence
Unknown
Word
Recognition
Revised N Result
POS Tagging
POS Sequence
</figure>
<figureCaption confidence="0.995436">
Figure 3: Word segmentation on Chinese.
</figureCaption>
<bodyText confidence="0.940323">
Novelty Mining
curve/PR curve, the better the algorithm. Also
we drew the standard redundancy F Score/F Score
contours (Soboroff, 2004), which indicate the F
Score values when setting precision and recall
from 0 to 1 with a step of 0.1. These contours can
facilitate us to compare redundancy F Scores/F
Scores in R-PR curves/PR curves. Redundancy
precision, redundancy recall, precision and recall
on a certain topic are defined as:
</bodyText>
<equation confidence="0.998914727272727">
R−
Redundancy Precision = (2)
R− + N−
Redundancy Recall = R−(3)
R− + R+
N+
Precision = (4)
N+ + R+
N+
Recall = (5)
N+ + N−
</equation>
<bodyText confidence="0.999964444444444">
where R+,R−,N+,N− correspond to the number
of documents/sentences that fall into each cate-
gory (see Table 2).
Based on all the topics’ RP/P and RR/R, we
could get the average RP/P and average RR/R by
calculating the arithmetic mean of these scores on
all topics. Then, the average redundancy F Score
(RF)/F Score (F) is obtained by the harmonic av-
erage of the average RP/P and average RR/R.
</bodyText>
<tableCaption confidence="0.611439">
Table 2: Categories for evaluation
</tableCaption>
<table confidence="0.999194">
Non-novel Novel
Delivered R+ N+
Not Delivered R− N−
</table>
<subsectionHeader confidence="0.981625">
5.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.990507285714286">
In this experimental study, the focus was novelty
mining rather than relevant documents/sentences
categorization. Therefore, our experiments started
with all given relevant Chinese text, from which
the novel text should be identified.
Since the datasets that we used for document-
level novelty mining and sentence-level novelty
mining both were written in English, we first trans-
lated them into Chinese. During this process,
we investigated issues on machine translation vs.
manually corrected translation.
We compared the novelty mining performance
on 107 text in TREC 2004 Novelty Track between
automatically translated using Google Translate
API1 and the manually corrected translation. For
example, here is an English sentence in Topic 51:
According to a Chilean government report, a
total of 4,299 political opponents died or disap-
peared during Pinochet’s term.
After machine translation using Google Trans-
lator, the above sentence is translated as:
</bodyText>
<footnote confidence="0.639387">
根据智利政府的报告,共有4299政敌的死亡
或失踪期间,皮诺切特的任期
1http://code.google.com/p/google-api-translate-java
</footnote>
<page confidence="0.9542705">
。
1565
</page>
<bodyText confidence="0.9993275">
Then we manually corrected the machine trans-
lation and obtained the corrected translation:
</bodyText>
<equation confidence="0.8068825">
根据智利政府的报告,在皮诺切特的任期期
间,共有4299政敌死亡或失踪。
</equation>
<bodyText confidence="0.999979363636364">
After novelty mining on the machine transla-
tion sentences and the humanly corrected transla-
tion sentences individually, we found that there is
a slight difference (&lt;2%) in precision and F Score.
Thus, we used machine translation to translate the
remaining documents/sentences to Chinese. This
indicates that the noise in machine translation for
Chinese had little impact on our actual results.
Then on English text, we applied the prepro-
cessing steps discussed in Section 3.1, includ-
ing stop word removing and word stemming.
For Chinese datasets, we segmented the docu-
ments/sentences into words and then performed
POS filtering to acquire the candidate words for
the space vector.
Based on the vectors of Chinese text, we
calculated the similarities between docu-
ments/sentences and predicted the novelty
for each document/sentence in the Chinese and
English datasets. An incoming Chinese/English
document will be compared with all the system
delivered 10 novel documents. If the novelty score
is above the novelty score threshold, the document
is considered to be novel. Thresholds used were
between 0.05 and 0.65. We also performed
Chinese/English sentence-level novelty mining.
Whether an incoming Chinese/English sentence
is novel is predicted by comparing with the most
recent system-delivered 1000 novel sentences.
Thresholds adopted were between 0.05 and 0.95
with an equal step of 0.10. Then, we evaluated the
Chinese/English novel text detection performance
by setting a series of novelty score thresholds.
</bodyText>
<subsectionHeader confidence="0.650778">
5.3.1 POS Filtering Rule
</subsectionHeader>
<bodyText confidence="0.9999665">
We adopted two different rules to select the can-
didate words to represent one document/sentence
and investigated the POS filtering influence on de-
tecting the novel Chinese text.
</bodyText>
<listItem confidence="0.99199675">
• Rule1: only some non-meaningful words,
including pronouns (‘r’ in Peking Univer-
sity/Chinese Academy of Sciences Chinese
POS tagging criterions (PKU and CAS,
1999)), auxiliary words (‘u’), tone words
(‘y’), conjunctions (‘c’), prepositions (‘p’)
and punctuation words (‘w’) are removed.
• Rule2: fewer kinds of words are selected to
</listItem>
<bodyText confidence="0.994759973684211">
represent a document/sentence. Only nouns
(including ‘n’ short for common nouns, ‘nr’
short for person name, ‘ns’ short for location
name, ‘nt’ short for organization name, ‘nz’
short for other proper nouns), verbs (‘v’), ad-
jectives (‘a’) and adverbs (‘d’) are kept.
For example, here is a simple Chinese sen-
tence: “墙上挂着一幅画。” (There is a picture
on the wall). After POS filtering using Rule1,
the words we keep are: “墙(‘n’), 上(‘v’), 挂(‘v’),
一(‘m’), 幅(‘q’), 画(‘n’)”. After POS filtering
using Rule2, the remaining words are: “墙(‘n’),
上(‘v’), 挂(‘v’), 画(‘n’)”. It is noticed that by
using Rule2, we can remove more non-important
words.
Figure 4 and Figure 5 show the performances
on the document and sentence-level novelty min-
ing when choosing the stricter rule (Rule2) and
the less strict rule (Rule1) in POS filtering. The
grey dashed lines show contours at intervals of 0.1
points of F Score.
From Figure 4 and Figure 5, we learn that the
Chinese novelty mining performance varies when
choosing the stricter rule (Rule2) and the less strict
rule (Rule1) in POS filtering. We can obtain a
better performance when choosing a stricter rule
(Rule2). Therefore, it is necessary to perform POS
filtering in the preprocessing steps on Chinese and
just removing some non-meaningful words (like
stop words) may not be enough. POS filtering
can help to remove the less meaningful words so
that each vector is represented better. Compared to
choosing more kinds of words (Rule1), only keep-
ing nouns, verbs, adjectives and adverbs (Rule2)
will be a better choice for novelty mining. We
also noticed that the selection of words to repre-
sent Chinese text is of vital importance to the suc-
cess of Chinese novelty mining.
</bodyText>
<subsectionHeader confidence="0.957623">
5.3.2 Comparison with English
</subsectionHeader>
<bodyText confidence="0.999884181818182">
We compared the novelty mining performance
on the English and Chinese documents/sentences
datasets. For Chinese, we chose Rule2 to select
the candidate words. Figure 6 and Figure 7 show
the R-PR and PR curves of document/sentence-
level novelty mining in English and Chinese when
given a series of novelty score thresholds.
From Figure 6 and Figure 7, we observe that
the performance on detecting novel Chinese docu-
ments is slightly lower than that on English. This
may be due to the different linguistical characteris-
</bodyText>
<page confidence="0.982579">
1566
</page>
<figure confidence="0.933344">
Document−Level Novelty Mining on APWSJ
Redundancy−Recall
</figure>
<figureCaption confidence="0.984885">
Figure 4: R-PR curves for document-level novelty mining on Chinese when choosing different rules on
APWSJ. The grey dashed lines show contours at intervals of 0.1 points of RF.
</figureCaption>
<figure confidence="0.896561">
Sentence−Level Novelty Mining on TREC 2004
Recall
</figure>
<figureCaption confidence="0.9995435">
Figure 5: PR curves for sentence-level novelty mining on Chinese when choosing different rules on
TREC 2004. The grey dashed lines show contours at intervals of 0.1 points of F.
</figureCaption>
<figure confidence="0.996470714285715">
1
RF score
0.9
Chinese D_NM_Rule2
Chinese D_NM_Rule1
0.9
0.8
0.6
0.7
0.15
0.5
0.2
0.25
0.4
0.3
0.2
0.2
0.35
0.1
0.1
Threshold=0.15
0.25
0.35
0.45
0.45 0.55
0.55
0
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Threshold=0.05
0.8
0.7
0.6
0.5
0.4
0.3
0.2
F score
0.8
0.7
0.65
Chinese S_NM_Rule2
Chinese S_NM_Rule1
0.2 0.3 0.4
0.5
Threshold=0.95
Threshold=0.95
0.85
0.85
0.75
0.75 0.65
0.65
0.55
0.55
0.6
0.55
0.5
0.45
0.7
0.6
0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1567
Document−Level Novelty Mining on APWSJ
Redundancy−Recall
</figure>
<figureCaption confidence="0.9761695">
Figure 6: R-PR curves for document-level novelty mining on Chinese and English on APWSJ. The grey
dashed lines show contours at intervals of 0.1 points of RF.
</figureCaption>
<figure confidence="0.8874705">
Sentence−Level Novelty Mining on TREC 2004
Recall
</figure>
<figureCaption confidence="0.9783795">
Figure 7: PR curves for sentence-level novelty mining on Chinese and English on TREC 2004. The grey
dashed lines show contours at intervals of 0.1 points of F.
</figureCaption>
<figure confidence="0.999892183333334">
0.25
0.35
0.55
0.45
0.65
Chinese D_NM_Rule2
English D_NM
0.8
0.6
0.7
Threshold
=0.05 0.15
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
1
0.9
RF score
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.5
0.4
0.3
0.2
0.1
0
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
F score
0.9
Threshold
=0.95
0.8
0.65
0.7
0.55
0.6
0.5
0.4
0.3
0.2
0.1
0.85 0.75
Chinese S_NM_Rule2
English S_NM
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
</figure>
<page confidence="0.975193">
1568
</page>
<bodyText confidence="0.999994944444445">
tics of each language so that the preprocessing in-
fluence on each language’s novelty mining is dis-
similar. Furthermore, the Chinese preprocessing
quality is not as good as that on English so that it
is difficult to obtain a good “bag of words” from
a document. Moreover, the errors in word seg-
mentation will influence the result of POS tagging.
These issues make tokenizing and POS tagging
extremely difficult for the Chinese text.
However, the performance of Chinese sentence-
level novelty mining is almost the same as that on
English. The reason is that the novelty mining per-
formance at the sentence level is not so sensitive
to the preprocessing steps as that at the document
level. If the similarity computation is based on the
sentence level, the word segmentation and POS
tagging errors actually will not have a big influ-
ence on the result as that on documents.
</bodyText>
<sectionHeader confidence="0.999439" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999274333333333">
This paper studied the preprocessing issues on
mining novel Chinese text, which, to the best
of our knowledge, have not been sufficiently
addressed in previous studies. We described
the Chinese preprocessing steps and discussed
the influence when choosing different Part-of-
Speech (POS) filtering rules. Then we applied
novelty mining on Chinese and English docu-
ments/sentences and compared their performance.
The experimental results on APWSJ and TREC
2004 Novelty Track showed that after adopting
a stricter POS filtering rule, the Chinese nov-
elty mining performed better on both documents
and sentences. This is because non-meaningful
words have a negative influence on detecting novel
text. However, compared to English, Chinese per-
formed worse on the document level and similarly
on the sentence level. The reason may be due to
the lower sensitivity of preprocessing at the sen-
tence level. The main contributions of this work
are as follows:
1) We investigated the preprocessing techniques
for detecting novel Chinese text on both doc-
ument and sentence level.
2) The POS filtering rule, telling how to select
words to represent one document/sentence,
was discussed.
3) Several experiments were conducted to com-
pare the novelty mining performance be-
tween Chinese and English. The novelty
mining performance on Chinese can be im-
proved as good as that on English if we can
increase the preprocessing precision on Chi-
nese text.
Our findings will be very helpful for develop-
ing a real-time Chinese novelty mining system at
both the document and sentence level. In future
work, we will try other word combinations and in-
vestigate better ways to represent the Chinese text.
In addition, we will explore how to utilize the bet-
ter Chinese sentence-level novelty mining result to
improve the detection performance on documents.
</bodyText>
<page confidence="0.994918">
1569
</page>
<sectionHeader confidence="0.982821" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999895345794393">
James Allan, Ron Papka, and Victor Lavrenko. 1998. On-
line new event detection and tracking. In SIGIR 1998,
Melbourne, Australia, pages 37–45.
James Allan, Courtney Wade, and Alvaro Bolivar. 2003. Re-
trieval and novelty detection at the sentence level. In SI-
GIR 2003, Toronto, Canada, pages 314–321. ACM, Au-
gust.
Thorsten Brants, Francine Chen, and Ayman Farahat. 2003.
A system for new event detection. In SIGIR 2003,
Toronto, Canada, pages 330–337.
Yun Chen, Flora S. Tsai, and Kap Luk Chan. 2008. Machine
learning techniques for business blog search and mining.
Expert Syst. Appl., 35(3):581–590.
D. Eichmann and P. Srinivasan. 2002. Novel results and
some answers. In TREC 2002 - the 11th Text REtrieval
Conference.
Martin Franz, Abraham Ittycheriah, J.Scott McCarley, and
Todd Ward. 2001. First story detection: combining simi-
larity and novelty based approach. In Topic Detection and
Tracking Workshop.
Jianfeng Gao, Mu Li, Andi Wu, and Chang-Ning Huang.
2005. Chinese word segmentation and named entity
recognition: A pragmatic approach. Computational Lin-
guistics, 31(4):531–574, December.
D. Harman. 2002. Overview of the TREC 2002 Novelty
Track. In TREC 2002 - the 11th Text Retrieval Confer-
ence, pages 46–55.
Yu Hong, Yu Zhang, Jili Fan, Ting Liu, and Sheng Li. 2008.
Chinese topic link detection based on semantic domain
language model. Journal of Software, 19(9):2265–2275.
ICTCLAS. 2008. http://ictclas.org/index.html.
Agus Trisnajaya Kwee, Flora S Tsai, and Wenyin Tang.
2009. Sentence-level novelty detection in English and
Malay. In Lecture Notes in Computer Science (LNCS),
volume 5476, pages 40–51.
Xiaoyong Li and W. Bruce Croft. 2005. Novelty detection
based on sentence level patterns. In CIKM 2005, pages
744–751.
Xiaoyong Li and W. Bruce Croft. 2008. An information-
pattern-based approach to novelty detection. Information
Processing and Management: an International Journal,
44(3):1159–1188, May.
Robert M. Losee. 2001. Natural language processing in sup-
port of decision making: Phrases and part-of-speech tag-
ging. Information Processing and Management: an Inter-
national Journal, 37(6).
Kok Wah Ng, Flora S. Tsai, Kiat Chong Goh, and Lihui Chen.
2007. Novelty detection for text documents using named
entity recognition. In Information, Communications and
Signal Processing, 2007 6th International Conference on,
pages 1–5, December.
PKU and CAS. 1999. Chinese POS tagging criterion.
http://icl.pku.edu.cn/icl groups/corpus/addition.htm.
M.F. Porter. 1997. An algorithm for suffix stripping. Read-
ings in information retrieval, pages 313–316.
Ian Soboroff and D. Harman. 2003. Overview of the TREC
2003 Novelty Track. In TREC 2003 - the 12th Text Re-
trieval Conference.
Ian Soboroff. 2004. Overview of the TREC 2004 Novelty
Track. In TREC 2004 - the 13th Text Retrieval Confer-
ence.
N. Stokes and J. Carthy. 2001. First story detection using a
composite document representation. In HLT 2001, pages
134–141.
Wenyin Tang and Flora S Tsai. 2009. Threshold setting and
performance monitoring for novel text mining. In SIAM
International Conference on Data Mining Workshop on
Text Mining.
Wenyin Tang, Agus Trisnajaya Kwee, and Flora S Tsai.
2009. Accessing contextual information for interactive
novelty detection. In European Conference on Informa-
tion Retrieval (ECIR) Workshop on Contextual Informa-
tion Access, Seeking and Retrieval Evaluation.
Flora S. Tsai, Wenchou Han, Junwei Xu, and Hock Chuan
Chua. 2009. Design and development of a mobile peer-
to-peer social networking application. Expert Syst. Appl.,
36(8):11077 – 11087.
Mengqiu Wang, Kenji Sagae, and Teruko Mitamura. 2006.
A fast, accurate deterministic parser for Chinese. In ACL
2006, Sydney, Australia, pages 425 – 432.
Youzheng Wu, Jun Zhao, and Bo Xu. 2003. Chinese named
entity recognition combining a statistical model with hu-
man knowledge. In ACL 2003 workshop on Multilingual
and mixed-language named entity recognition, pages 65–
72.
Yiming Yang, Tom Pierce, and Jaime Carbonell. 1998. A
study on retrospective and on-line event detection. pages
28–36. ACM Press.
Yiming Yang, Jian Zhang, Jaime Carbonell, and Chun Jin.
2002. Topic-conditioned novelty detection. In SIGKDD
2002, pages 688 – 693.
Huaping Zhang and Qun Liu. 2002. Model of Chinese words
rough segmentation based on n-shortest paths method.
Journal of Chinese Information Processing, 15:1–7.
Yi Zhang and Flora S. Tsai. 2009. Combining named enti-
ties and tags for novel sentence detection. In ESAIR ’09:
Proceedings of the WSDM ’09 Workshop on Exploiting
Semantic Annotations in Information Retrieval, pages 30–
34.
Yi Zhang, Jamie Callan, and Thomas Minka. 2002. Novelty
and redundancy detection in adaptive filtering. In ACM
SIGIR 2002, Tampere, Finland, pages 81–88.
Le Zhao, Min Zheng, and Shaoping Ma. 2006. The nature of
novelty detection. Information Retrieval, 9:527–541.
Wei Zheng, Yu Zhang, Bowei Zou, Yu Hong, and Ting Liu.
2008. Research of Chinese topic tracking based on rele-
vance model.
</reference>
<page confidence="0.989417">
1570
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.362599">
<title confidence="0.999543">Chinese Novelty Mining</title>
<author confidence="0.986455">Yi</author>
<affiliation confidence="0.983349">Nanyang Technological</affiliation>
<address confidence="0.97326">50 Nanyang Singapore</address>
<email confidence="0.987321">yizhang@ntu.edu.sg</email>
<affiliation confidence="0.769906">Flora S. Nanyang Technological</affiliation>
<address confidence="0.853839">50 Nanyang Singapore</address>
<email confidence="0.99968">fst1@columbia.edu</email>
<abstract confidence="0.999682086956522">Automated mining of novel documents or sentences from chronologically ordered documents or sentences is an open challenge in text mining. In this paper, we describe the preprocessing techniques for detecting novel Chinese text and discuss the influence of different Part of Speech (POS) filtering rules on the detection performance. Experimental results on AP- WSJ and TREC 2004 Novelty Track data show that the Chinese novelty mining performance is quite different when choosing two dissimilar POS filtering rules. Thus, the selection of words to represent Chinese text is of vital importance to the success of the Chinese novelty mining. Moreover, we compare the Chinese novelty mining performance with that of English and investigate the impact of preprocessing steps on detecting novel Chinese text, which will be very helpful for developing a Chinese novelty mining system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allan</author>
<author>Ron Papka</author>
<author>Victor Lavrenko</author>
</authors>
<title>Online new event detection and tracking.</title>
<date>1998</date>
<booktitle>In SIGIR 1998,</booktitle>
<pages>37--45</pages>
<location>Melbourne, Australia,</location>
<contexts>
<context position="2694" citStr="Allan et al., 1998" startWordPosition="404" endWordPosition="407">ches through the time sequence of documents/sentences and retrieves only those with “novel” information. This paper focuses on applying document/sentencelevel novelty mining on Chinese. In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences. Novelty mining has been performed at three different levels: event level, sentence level and document level (Li and Croft, 2005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Ot</context>
</contexts>
<marker>Allan, Papka, Lavrenko, 1998</marker>
<rawString>James Allan, Ron Papka, and Victor Lavrenko. 1998. Online new event detection and tracking. In SIGIR 1998, Melbourne, Australia, pages 37–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allan</author>
<author>Courtney Wade</author>
<author>Alvaro Bolivar</author>
</authors>
<title>Retrieval and novelty detection at the sentence level.</title>
<date>2003</date>
<booktitle>In SIGIR 2003,</booktitle>
<pages>314--321</pages>
<publisher>ACM,</publisher>
<location>Toronto, Canada,</location>
<contexts>
<context position="3412" citStr="Allan et al., 2003" startWordPosition="519" endWordPosition="522"> document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al</context>
<context position="5502" citStr="Allan et al., 2003" startWordPosition="852" endWordPosition="855">cuments (Zhang et al., 2002), document novelty was predicted based on the distance between the new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the effectiveness in topic tracking. Another study proposed a method of applying se</context>
<context position="11389" citStr="Allan et al., 2003" startWordPosition="1800" endWordPosition="1803">The corresponding term-document matrix (TDM)/term-sentence matrix (TSM) can be constructed by counting the term frequency (TF) of each word. The novelty mining system predicts any incoming document/sentence by comparing it with its history documents/sentences in this vector space. Therefore, given a Chinese TDM/TSM, the novelty mining system designed for English can also be applied to Chinese. In novelty mining, the novelty of a document/sentence can be quantitatively measured by a novelty metric and represented by a novelty score. The most popular novelty metric, i.e. cosine similarity (see (Allan et al., 2003)), is adopted. This metric first calculates the similarities between the current document/sentence dt and each of its his1563 Relevant documents / sentences Novelty Mining Word Segmentation POS Tagging Preprocessing steps Novel documents / sentences Figure 2: Preprocessing steps on Chinese. tory documents/sentences di (1 &lt; i &lt; t − 1). Then, the novelty score is simply one minus the maximum of these cosine similarities, as shown in Eq.(1). Novelty 5core(dt) = 1 − max cos(dt, di) (1) 1&lt;i&lt;t−1 tll - lldill where N,os(d) denotes the cosine similarity score of the document/sentence d and wk(d) is th</context>
<context position="13847" citStr="Allan et al., 2003" startWordPosition="2189" endWordPosition="2192">ly absolute redundant documents are regarded as nonnovel. TREC 2004 Novelty Track data is developed from AQUAINT collection. Both relevant and novel sentences are selected by TREC’s assessors. The statistics of these two datasets are summarized in Table 1. 5.2 Evaluation Measures From many previous works, redundancy precision (RP), redundancy recall (RR) and redundancy F Score (RF) are used to evaluate the performance of document-level novelty mining (Zhang et al., 2002). Precision (P), recall (R) and F Score (F) are mainly used in evaluating the performance for sentence-level novelty mining (Allan et al., 2003). Therefore, we use RP, RR, RF and redundancy precision-recall (R-PR) curve to evaluate our experimental results on the document level. P, R, F and precision-recall (PR) curve are used to evaluate the performance on the sentence-level novelty mining. The larger the area under the R-PR �� k=1 wk(dt) - wk(di) cos(dt, di) = lld 1564 Document/ Sentence String Atom Segmentation Atom Sequence NSP-based Rough Segmentation Top N Sequence Unknown Word Recognition Revised N Result POS Tagging POS Sequence Figure 3: Word segmentation on Chinese. Novelty Mining curve/PR curve, the better the algorithm. Al</context>
</contexts>
<marker>Allan, Wade, Bolivar, 2003</marker>
<rawString>James Allan, Courtney Wade, and Alvaro Bolivar. 2003. Retrieval and novelty detection at the sentence level. In SIGIR 2003, Toronto, Canada, pages 314–321. ACM, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Francine Chen</author>
<author>Ayman Farahat</author>
</authors>
<title>A system for new event detection.</title>
<date>2003</date>
<booktitle>In SIGIR 2003,</booktitle>
<pages>330--337</pages>
<location>Toronto, Canada,</location>
<contexts>
<context position="2780" citStr="Brants et al., 2003" startWordPosition="420" endWordPosition="423">“novel” information. This paper focuses on applying document/sentencelevel novelty mining on Chinese. In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences. Novelty mining has been performed at three different levels: event level, sentence level and document level (Li and Croft, 2005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang e</context>
</contexts>
<marker>Brants, Chen, Farahat, 2003</marker>
<rawString>Thorsten Brants, Francine Chen, and Ayman Farahat. 2003. A system for new event detection. In SIGIR 2003, Toronto, Canada, pages 330–337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun Chen</author>
<author>Flora S Tsai</author>
<author>Kap Luk Chan</author>
</authors>
<title>Machine learning techniques for business blog search and mining. Expert Syst.</title>
<date>2008</date>
<journal>Appl.,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="1313" citStr="Chen et al., 2008" startWordPosition="197" endWordPosition="200">n choosing two dissimilar POS filtering rules. Thus, the selection of words to represent Chinese text is of vital importance to the success of the Chinese novelty mining. Moreover, we compare the Chinese novelty mining performance with that of English and investigate the impact of preprocessing steps on detecting novel Chinese text, which will be very helpful for developing a Chinese novelty mining system. 1 Introduction The bloom of information nowadays brings us rich useful information as well as tons of redundant information in news articles, social networks (Tsai et al., 2009), and blogs (Chen et al., 2008). Novelty mining (NM), or novelty detection, aims at mining novel information from a chronologically ordered list of relevant documents/sentences. It can facilitate users to quickly get useful information without going through a lot of redundant information, which is usually a tedious and time-consuming task. The process of detecting novel text contains three main steps, (i) preprocessing, (ii) categorization, and (iii) novelty mining. The first step preprocesses the text documents/sentences by removing stop words, performing word stemming, implementing POS tagging etc. Categorization classifi</context>
</contexts>
<marker>Chen, Tsai, Chan, 2008</marker>
<rawString>Yun Chen, Flora S. Tsai, and Kap Luk Chan. 2008. Machine learning techniques for business blog search and mining. Expert Syst. Appl., 35(3):581–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Eichmann</author>
<author>P Srinivasan</author>
</authors>
<title>Novel results and some answers.</title>
<date>2002</date>
<booktitle>In TREC 2002 - the 11th Text REtrieval Conference.</booktitle>
<contexts>
<context position="3493" citStr="Eichmann and Srinivasan, 2002" startWordPosition="530" endWordPosition="534">novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as w</context>
</contexts>
<marker>Eichmann, Srinivasan, 2002</marker>
<rawString>D. Eichmann and P. Srinivasan. 2002. Novel results and some answers. In TREC 2002 - the 11th Text REtrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Franz</author>
<author>Abraham Ittycheriah</author>
<author>J Scott McCarley</author>
<author>Todd Ward</author>
</authors>
<title>First story detection: combining similarity and novelty based approach. In Topic Detection and Tracking Workshop.</title>
<date>2001</date>
<contexts>
<context position="2758" citStr="Franz et al., 2001" startWordPosition="416" endWordPosition="419">ves only those with “novel” information. This paper focuses on applying document/sentencelevel novelty mining on Chinese. In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences. Novelty mining has been performed at three different levels: event level, sentence level and document level (Li and Croft, 2005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, su</context>
</contexts>
<marker>Franz, Ittycheriah, McCarley, Ward, 2001</marker>
<rawString>Martin Franz, Abraham Ittycheriah, J.Scott McCarley, and Todd Ward. 2001. First story detection: combining similarity and novelty based approach. In Topic Detection and Tracking Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Mu Li</author>
<author>Andi Wu</author>
<author>Chang-Ning Huang</author>
</authors>
<title>Chinese word segmentation and named entity recognition: A pragmatic approach.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>4</issue>
<contexts>
<context position="7586" citStr="Gao et al., 2005" startWordPosition="1184" endWordPosition="1187">ithm (Porter, 1997) for English word stemming. This algorithm removes the commoner morphological and inflexional endings from the words in English. The entire preprocessing steps in English novelty mining can be seen in Figure 1. 3.2 Chinese In Chinese, the word is the smallest independent meaningful element. There is no obvious boundary between words so that Chinese lexical analysis, such as Chinese word segmentation, is the prerequisite for novelty mining. Unlike English, Chinese word segmentation is a very challenging problem because of the difficulties in defining what constitutes a word (Gao et al., 2005). While each criteria provides valuable insights into “word-hood” in Chinese, they do not consistently lead us to the same conclusions. Moreover, there is no white space between Chinese words or expressions and there are many ambiguities in the Chinese language, such as: ‘主 板 和 服 务 器’ (means ‘mainboard and server’ in English) might be ‘主 板/和/服务器’ (means ‘mainboard/and/server’ in English) or ‘主 板/和 服/务/器’ (means ‘mainboard/kimono/task/utensil’ in English). This ambiguity is a great challenge for Chinese word segmentation. In addition, there is no obvious inflected or derived words in Chinese so</context>
</contexts>
<marker>Gao, Li, Wu, Huang, 2005</marker>
<rawString>Jianfeng Gao, Mu Li, Andi Wu, and Chang-Ning Huang. 2005. Chinese word segmentation and named entity recognition: A pragmatic approach. Computational Linguistics, 31(4):531–574, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Harman</author>
</authors>
<title>Overview of the TREC</title>
<date>2002</date>
<booktitle>In TREC 2002 - the 11th Text Retrieval Conference,</booktitle>
<pages>46--55</pages>
<contexts>
<context position="5397" citStr="Harman, 2002" startWordPosition="839" endWordPosition="840">iscusses issues for further research. 2 Related Work In the pioneering work for detecting novel documents (Zhang et al., 2002), document novelty was predicted based on the distance between the new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TD</context>
</contexts>
<marker>Harman, 2002</marker>
<rawString>D. Harman. 2002. Overview of the TREC 2002 Novelty Track. In TREC 2002 - the 11th Text Retrieval Conference, pages 46–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Hong</author>
<author>Yu Zhang</author>
<author>Jili Fan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Chinese topic link detection based on semantic domain language model.</title>
<date>2008</date>
<journal>Journal of Software,</journal>
<volume>19</volume>
<issue>9</issue>
<contexts>
<context position="4039" citStr="Hong et al., 2008" startWordPosition="618" endWordPosition="621"> dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (Wang et al., 2006; Wu et al., 2003). However, to the best of our knowledge, no studies have been reported on discussing preprocessing techniques on Chinese document and sentence-level novelty mining, which is the focus of our paper. The rest of this paper is organized as follows. Section 2 gives a brief overview of related work on detecting novel documents and sentences on English and Chinese. Section 3 introduces the details of preprocessing steps for English and Chinese. A ge</context>
<context position="6257" citStr="Hong et al., 2008" startWordPosition="971" endWordPosition="974"> been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the effectiveness in topic tracking. Another study proposed a method of applying semantic domain language model to link detection, based on the structure relation among contents and the semantic distribution in a story (Hong et al., 2008). 3 Preprocessing for English and Chinese 3.1 English Since the focus of this paper is on novelty mining, we begin from a list of relevant documents or sentences that have already undergone the categorization process. The first step for English preprocessing is to remove all stop words from documents or sentences, such as conjunctions, prepositions, and articles. Stop words are words that are too common to be informative. These words should be removed, otherwise it will influence the novelty prediction of documents or sentences. After stop words removal, the remaining words are then stemmed. T</context>
</contexts>
<marker>Hong, Zhang, Fan, Liu, Li, 2008</marker>
<rawString>Yu Hong, Yu Zhang, Jili Fan, Ting Liu, and Sheng Li. 2008. Chinese topic link detection based on semantic domain language model. Journal of Software, 19(9):2265–2275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ICTCLAS</author>
</authors>
<title>http://ictclas.org/index.html. Agus Trisnajaya Kwee,</title>
<date>2008</date>
<booktitle>In Lecture Notes in Computer Science (LNCS),</booktitle>
<volume>5476</volume>
<pages>40--51</pages>
<location>Flora</location>
<contexts>
<context position="9625" citStr="ICTCLAS, 2008" startWordPosition="1523" endWordPosition="1524">hese meaningful words. Moreover, it will decrease the impact of the errors in Chinese word segmentation on novelty mining because only meaningful words are considered and other words (including stop words) such as ‘虽然’ (means ‘although’ in English) will not appear in the word list for the following similarity computation in novelty mining. Losee also mentioned that POS tagging shows a great potential to avoid lexical ambiguity and it can help to improve the performance of information retrieval (Losee, 2001). ICTCLAS is used when performing word segmentation and POS tagging in our experiments (ICTCLAS, 2008). It is an open source project and achieves a better precision in Chinese word segmentation and POS tagging than other Chinese POS tagging softwares (ICTCLAS, 2008). First, we apply word segmentation on the relevant Chinese documents/sentences. Chinese word segmentation includes atom segmentation, N-shortest path based rough segmentation and unknown words recognition (see Figure 3). Atom segmentation is an initial step of the Chinese language segmentation process, where atom is defined to be the minimal unit that cannot be split further. The atom can be a Chinese character, punctuation, symbol</context>
</contexts>
<marker>ICTCLAS, 2008</marker>
<rawString>ICTCLAS. 2008. http://ictclas.org/index.html. Agus Trisnajaya Kwee, Flora S Tsai, and Wenyin Tang. 2009. Sentence-level novelty detection in English and Malay. In Lecture Notes in Computer Science (LNCS), volume 5476, pages 40–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyong Li</author>
<author>W Bruce Croft</author>
</authors>
<title>Novelty detection based on sentence level patterns. In CIKM</title>
<date>2005</date>
<pages>744--751</pages>
<contexts>
<context position="2493" citStr="Li and Croft, 2005" startWordPosition="370" endWordPosition="373">OS tagging etc. Categorization classifies each incoming document/sentence into its relevant topic bin. Then, within each topic bin containing a group of relevant documents/sentences, novelty mining searches through the time sequence of documents/sentences and retrieves only those with “novel” information. This paper focuses on applying document/sentencelevel novelty mining on Chinese. In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences. Novelty mining has been performed at three different levels: event level, sentence level and document level (Li and Croft, 2005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang</context>
</contexts>
<marker>Li, Croft, 2005</marker>
<rawString>Xiaoyong Li and W. Bruce Croft. 2005. Novelty detection based on sentence level patterns. In CIKM 2005, pages 744–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyong Li</author>
<author>W Bruce Croft</author>
</authors>
<title>An informationpattern-based approach to novelty detection.</title>
<date>2008</date>
<journal>Information Processing and Management: an International Journal,</journal>
<volume>44</volume>
<issue>3</issue>
<contexts>
<context position="5594" citStr="Li and Croft, 2008" startWordPosition="866" endWordPosition="869">he new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the effectiveness in topic tracking. Another study proposed a method of applying semantic domain language model to link detection, based on the structure relation among conten</context>
</contexts>
<marker>Li, Croft, 2008</marker>
<rawString>Xiaoyong Li and W. Bruce Croft. 2008. An informationpattern-based approach to novelty detection. Information Processing and Management: an International Journal, 44(3):1159–1188, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Losee</author>
</authors>
<title>Natural language processing in support of decision making: Phrases and part-of-speech tagging.</title>
<date>2001</date>
<booktitle>Information Processing and Management: an International Journal,</booktitle>
<volume>37</volume>
<issue>6</issue>
<contexts>
<context position="9523" citStr="Losee, 2001" startWordPosition="1507" endWordPosition="1508"> some meaningful words, such as nouns and verbs, so that we can get the main content by extracting these meaningful words. Moreover, it will decrease the impact of the errors in Chinese word segmentation on novelty mining because only meaningful words are considered and other words (including stop words) such as ‘虽然’ (means ‘although’ in English) will not appear in the word list for the following similarity computation in novelty mining. Losee also mentioned that POS tagging shows a great potential to avoid lexical ambiguity and it can help to improve the performance of information retrieval (Losee, 2001). ICTCLAS is used when performing word segmentation and POS tagging in our experiments (ICTCLAS, 2008). It is an open source project and achieves a better precision in Chinese word segmentation and POS tagging than other Chinese POS tagging softwares (ICTCLAS, 2008). First, we apply word segmentation on the relevant Chinese documents/sentences. Chinese word segmentation includes atom segmentation, N-shortest path based rough segmentation and unknown words recognition (see Figure 3). Atom segmentation is an initial step of the Chinese language segmentation process, where atom is defined to be t</context>
</contexts>
<marker>Losee, 2001</marker>
<rawString>Robert M. Losee. 2001. Natural language processing in support of decision making: Phrases and part-of-speech tagging. Information Processing and Management: an International Journal, 37(6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kok Wah Ng</author>
<author>Flora S Tsai</author>
<author>Kiat Chong Goh</author>
<author>Lihui Chen</author>
</authors>
<title>Novelty detection for text documents using named entity recognition.</title>
<date>2007</date>
<booktitle>In Information, Communications and Signal Processing, 2007 6th International Conference on,</booktitle>
<pages>1--5</pages>
<contexts>
<context position="5573" citStr="Ng et al., 2007" startWordPosition="862" endWordPosition="865">istance between the new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the effectiveness in topic tracking. Another study proposed a method of applying semantic domain language model to link detection, based on the structure </context>
</contexts>
<marker>Ng, Tsai, Goh, Chen, 2007</marker>
<rawString>Kok Wah Ng, Flora S. Tsai, Kiat Chong Goh, and Lihui Chen. 2007. Novelty detection for text documents using named entity recognition. In Information, Communications and Signal Processing, 2007 6th International Conference on, pages 1–5, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>PKU</author>
<author>CAS</author>
</authors>
<title>Chinese POS tagging criterion. http://icl.pku.edu.cn/icl</title>
<date>1999</date>
<pages>313--316</pages>
<contexts>
<context position="18506" citStr="PKU and CAS, 1999" startWordPosition="2903" endWordPosition="2906"> the most recent system-delivered 1000 novel sentences. Thresholds adopted were between 0.05 and 0.95 with an equal step of 0.10. Then, we evaluated the Chinese/English novel text detection performance by setting a series of novelty score thresholds. 5.3.1 POS Filtering Rule We adopted two different rules to select the candidate words to represent one document/sentence and investigated the POS filtering influence on detecting the novel Chinese text. • Rule1: only some non-meaningful words, including pronouns (‘r’ in Peking University/Chinese Academy of Sciences Chinese POS tagging criterions (PKU and CAS, 1999)), auxiliary words (‘u’), tone words (‘y’), conjunctions (‘c’), prepositions (‘p’) and punctuation words (‘w’) are removed. • Rule2: fewer kinds of words are selected to represent a document/sentence. Only nouns (including ‘n’ short for common nouns, ‘nr’ short for person name, ‘ns’ short for location name, ‘nt’ short for organization name, ‘nz’ short for other proper nouns), verbs (‘v’), adjectives (‘a’) and adverbs (‘d’) are kept. For example, here is a simple Chinese sentence: “墙上挂着一幅画。” (There is a picture on the wall). After POS filtering using Rule1, the words we keep are: “墙(‘n’), 上(‘v’</context>
</contexts>
<marker>PKU, CAS, 1999</marker>
<rawString>PKU and CAS. 1999. Chinese POS tagging criterion. http://icl.pku.edu.cn/icl groups/corpus/addition.htm. M.F. Porter. 1997. An algorithm for suffix stripping. Readings in information retrieval, pages 313–316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Soboroff</author>
<author>D Harman</author>
</authors>
<title>Novelty Track.</title>
<date>2003</date>
<journal>Overview of the TREC</journal>
<booktitle>In TREC 2003 - the 12th Text Retrieval Conference.</booktitle>
<contexts>
<context position="5424" citStr="Soboroff and Harman, 2003" startWordPosition="841" endWordPosition="844">s for further research. 2 Related Work In the pioneering work for detecting novel documents (Zhang et al., 2002), document novelty was predicted based on the distance between the new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the e</context>
</contexts>
<marker>Soboroff, Harman, 2003</marker>
<rawString>Ian Soboroff and D. Harman. 2003. Overview of the TREC 2003 Novelty Track. In TREC 2003 - the 12th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Soboroff</author>
</authors>
<title>Overview of the TREC</title>
<date>2004</date>
<booktitle>In TREC 2004 - the 13th Text Retrieval Conference.</booktitle>
<contexts>
<context position="5441" citStr="Soboroff, 2004" startWordPosition="845" endWordPosition="846">elated Work In the pioneering work for detecting novel documents (Zhang et al., 2002), document novelty was predicted based on the distance between the new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the effectiveness in t</context>
<context position="12496" citStr="Soboroff, 2004" startWordPosition="1981" endWordPosition="1982">−1 tll - lldill where N,os(d) denotes the cosine similarity score of the document/sentence d and wk(d) is the weight of kth element in the document/sentence weighted vector d. The term weighting function used in our work is TF(term frequency). The final decision on whether a document/sentence is novel or not depends on whether the novelty score falls above or below a threshold. The document/sentence predicted as “novel” will be placed into the list of history documents/sentences. 5 Experiments and Results 5.1 Datasets Two public datasets APWSJ (Zhang et al., 2002) and TREC Novelty Track 2004 (Soboroff, 2004) are selected as our experimental datasets for the document-level and the sentence-level novelty mining respectively. APWSJ data consists of news articles from Associated Press (AP) and Wall Street Journal (WSJ). There are 50 topics from Q101 to Q150 in APWSJ and 5 topics (Q131, Q142, Q145, Q147, Q150) are excluded from the Table 1: Statistics of experimental data Dataset Novel Non-novel APWSJ 10839(91.10%) 1057(8.90%) TREC2004 3454(41.40%) 4889(58.60%) experiments because they lack non-novel documents (Zhao et al., 2006). The assessors provide two degrees of judgements on non-novel documents,</context>
<context position="14523" citStr="Soboroff, 2004" startWordPosition="2298" endWordPosition="2299">l (R-PR) curve to evaluate our experimental results on the document level. P, R, F and precision-recall (PR) curve are used to evaluate the performance on the sentence-level novelty mining. The larger the area under the R-PR �� k=1 wk(dt) - wk(di) cos(dt, di) = lld 1564 Document/ Sentence String Atom Segmentation Atom Sequence NSP-based Rough Segmentation Top N Sequence Unknown Word Recognition Revised N Result POS Tagging POS Sequence Figure 3: Word segmentation on Chinese. Novelty Mining curve/PR curve, the better the algorithm. Also we drew the standard redundancy F Score/F Score contours (Soboroff, 2004), which indicate the F Score values when setting precision and recall from 0 to 1 with a step of 0.1. These contours can facilitate us to compare redundancy F Scores/F Scores in R-PR curves/PR curves. Redundancy precision, redundancy recall, precision and recall on a certain topic are defined as: R− Redundancy Precision = (2) R− + N− Redundancy Recall = R−(3) R− + R+ N+ Precision = (4) N+ + R+ N+ Recall = (5) N+ + N− where R+,R−,N+,N− correspond to the number of documents/sentences that fall into each category (see Table 2). Based on all the topics’ RP/P and RR/R, we could get the average RP/P</context>
</contexts>
<marker>Soboroff, 2004</marker>
<rawString>Ian Soboroff. 2004. Overview of the TREC 2004 Novelty Track. In TREC 2004 - the 13th Text Retrieval Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Stokes</author>
<author>J Carthy</author>
</authors>
<title>First story detection using a composite document representation.</title>
<date>2001</date>
<booktitle>In HLT</booktitle>
<pages>134--141</pages>
<contexts>
<context position="2738" citStr="Stokes and Carthy, 2001" startWordPosition="412" endWordPosition="415">ents/sentences and retrieves only those with “novel” information. This paper focuses on applying document/sentencelevel novelty mining on Chinese. In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences. Novelty mining has been performed at three different levels: event level, sentence level and document level (Li and Croft, 2005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, esp</context>
</contexts>
<marker>Stokes, Carthy, 2001</marker>
<rawString>N. Stokes and J. Carthy. 2001. First story detection using a composite document representation. In HLT 2001, pages 134–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenyin Tang</author>
<author>Flora S Tsai</author>
</authors>
<title>Threshold setting and performance monitoring for novel text mining.</title>
<date>2009</date>
<booktitle>In SIAM International Conference on Data Mining Workshop on Text Mining.</booktitle>
<contexts>
<context position="3650" citStr="Tang and Tsai, 2009" startWordPosition="558" endWordPosition="561">iented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (Wang et al., 2006; Wu et al., 2003). However, to the best of our knowledge, no studies have b</context>
</contexts>
<marker>Tang, Tsai, 2009</marker>
<rawString>Wenyin Tang and Flora S Tsai. 2009. Threshold setting and performance monitoring for novel text mining. In SIAM International Conference on Data Mining Workshop on Text Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenyin Tang</author>
<author>Agus Trisnajaya Kwee</author>
<author>Flora S Tsai</author>
</authors>
<title>Accessing contextual information for interactive novelty detection.</title>
<date>2009</date>
<booktitle>In European Conference on Information Retrieval (ECIR) Workshop on Contextual Information Access, Seeking and Retrieval Evaluation.</booktitle>
<contexts>
<context position="3628" citStr="Tang et al., 2009" startWordPosition="554" endWordPosition="557">romising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (Wang et al., 2006; Wu et al., 2003). However, to the best of our knowle</context>
</contexts>
<marker>Tang, Kwee, Tsai, 2009</marker>
<rawString>Wenyin Tang, Agus Trisnajaya Kwee, and Flora S Tsai. 2009. Accessing contextual information for interactive novelty detection. In European Conference on Information Retrieval (ECIR) Workshop on Contextual Information Access, Seeking and Retrieval Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flora S Tsai</author>
<author>Wenchou Han</author>
<author>Junwei Xu</author>
<author>Hock Chuan Chua</author>
</authors>
<title>Design and development of a mobile peerto-peer social networking application. Expert Syst.</title>
<date>2009</date>
<journal>Appl.,</journal>
<volume>36</volume>
<issue>8</issue>
<pages>11087</pages>
<contexts>
<context position="1282" citStr="Tsai et al., 2009" startWordPosition="191" endWordPosition="194">formance is quite different when choosing two dissimilar POS filtering rules. Thus, the selection of words to represent Chinese text is of vital importance to the success of the Chinese novelty mining. Moreover, we compare the Chinese novelty mining performance with that of English and investigate the impact of preprocessing steps on detecting novel Chinese text, which will be very helpful for developing a Chinese novelty mining system. 1 Introduction The bloom of information nowadays brings us rich useful information as well as tons of redundant information in news articles, social networks (Tsai et al., 2009), and blogs (Chen et al., 2008). Novelty mining (NM), or novelty detection, aims at mining novel information from a chronologically ordered list of relevant documents/sentences. It can facilitate users to quickly get useful information without going through a lot of redundant information, which is usually a tedious and time-consuming task. The process of detecting novel text contains three main steps, (i) preprocessing, (ii) categorization, and (iii) novelty mining. The first step preprocesses the text documents/sentences by removing stop words, performing word stemming, implementing POS taggi</context>
</contexts>
<marker>Tsai, Han, Xu, Chua, 2009</marker>
<rawString>Flora S. Tsai, Wenchou Han, Junwei Xu, and Hock Chuan Chua. 2009. Design and development of a mobile peerto-peer social networking application. Expert Syst. Appl., 36(8):11077 – 11087.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Kenji Sagae</author>
<author>Teruko Mitamura</author>
</authors>
<title>A fast, accurate deterministic parser for Chinese.</title>
<date>2006</date>
<booktitle>In ACL 2006,</booktitle>
<pages>425--432</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="4174" citStr="Wang et al., 2006" startWordPosition="640" endWordPosition="643">n the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (Wang et al., 2006; Wu et al., 2003). However, to the best of our knowledge, no studies have been reported on discussing preprocessing techniques on Chinese document and sentence-level novelty mining, which is the focus of our paper. The rest of this paper is organized as follows. Section 2 gives a brief overview of related work on detecting novel documents and sentences on English and Chinese. Section 3 introduces the details of preprocessing steps for English and Chinese. A general novelty mining algorithm is described in Section 4. Section 5 reports experimental results. Section 6 summarizes the research fin</context>
</contexts>
<marker>Wang, Sagae, Mitamura, 2006</marker>
<rawString>Mengqiu Wang, Kenji Sagae, and Teruko Mitamura. 2006. A fast, accurate deterministic parser for Chinese. In ACL 2006, Sydney, Australia, pages 425 – 432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youzheng Wu</author>
<author>Jun Zhao</author>
<author>Bo Xu</author>
</authors>
<title>Chinese named entity recognition combining a statistical model with human knowledge.</title>
<date>2003</date>
<booktitle>In ACL 2003 workshop on Multilingual and mixed-language named entity recognition,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="4192" citStr="Wu et al., 2003" startWordPosition="644" endWordPosition="647">alay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (Wang et al., 2006; Wu et al., 2003). However, to the best of our knowledge, no studies have been reported on discussing preprocessing techniques on Chinese document and sentence-level novelty mining, which is the focus of our paper. The rest of this paper is organized as follows. Section 2 gives a brief overview of related work on detecting novel documents and sentences on English and Chinese. Section 3 introduces the details of preprocessing steps for English and Chinese. A general novelty mining algorithm is described in Section 4. Section 5 reports experimental results. Section 6 summarizes the research findings and discusse</context>
</contexts>
<marker>Wu, Zhao, Xu, 2003</marker>
<rawString>Youzheng Wu, Jun Zhao, and Bo Xu. 2003. Chinese named entity recognition combining a statistical model with human knowledge. In ACL 2003 workshop on Multilingual and mixed-language named entity recognition, pages 65– 72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Tom Pierce</author>
<author>Jaime Carbonell</author>
</authors>
<title>A study on retrospective and on-line event detection.</title>
<date>1998</date>
<pages>28--36</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="3106" citStr="Yang et al., 1998" startWordPosition="469" endWordPosition="472">005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have be</context>
</contexts>
<marker>Yang, Pierce, Carbonell, 1998</marker>
<rawString>Yiming Yang, Tom Pierce, and Jaime Carbonell. 1998. A study on retrospective and on-line event detection. pages 28–36. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Jian Zhang</author>
<author>Jaime Carbonell</author>
<author>Chun Jin</author>
</authors>
<title>Topic-conditioned novelty detection.</title>
<date>2002</date>
<booktitle>In SIGKDD 2002,</booktitle>
<pages>688--693</pages>
<contexts>
<context position="2713" citStr="Yang et al., 2002" startWordPosition="408" endWordPosition="411">e sequence of documents/sentences and retrieves only those with “novel” information. This paper focuses on applying document/sentencelevel novelty mining on Chinese. In this task, we need to identify all novel Chinese text given groups of relevant documents/sentences. Novelty mining has been performed at three different levels: event level, sentence level and document level (Li and Croft, 2005). Works on novelty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize o</context>
</contexts>
<marker>Yang, Zhang, Carbonell, Jin, 2002</marker>
<rawString>Yiming Yang, Jian Zhang, Jaime Carbonell, and Chun Jin. 2002. Topic-conditioned novelty detection. In SIGKDD 2002, pages 688 – 693.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huaping Zhang</author>
<author>Qun Liu</author>
</authors>
<title>Model of Chinese words rough segmentation based on n-shortest paths method.</title>
<date>2002</date>
<journal>Journal of Chinese Information Processing,</journal>
<pages>15--1</pages>
<contexts>
<context position="10397" citStr="Zhang and Liu, 2002" startWordPosition="1640" endWordPosition="1643">TCLAS, 2008). First, we apply word segmentation on the relevant Chinese documents/sentences. Chinese word segmentation includes atom segmentation, N-shortest path based rough segmentation and unknown words recognition (see Figure 3). Atom segmentation is an initial step of the Chinese language segmentation process, where atom is defined to be the minimal unit that cannot be split further. The atom can be a Chinese character, punctuation, symbol string, etc. Then, rough segmentation tries to discover the correct segmentation with as few candidates as possible. The N-Shortest Path (NSP) method (Zhang and Liu, 2002) is applied for rough segmentation. Next, we detect some unknown words such as person name, location name so as to optimize the segmentation result. Finally, we POS tag the words and keep some kinds of words in the word list according to the selective rule, which are used in novelty mining. 4 Novelty Mining From the output of preprocessing, we can obtain a bag of words. The corresponding term-document matrix (TDM)/term-sentence matrix (TSM) can be constructed by counting the term frequency (TF) of each word. The novelty mining system predicts any incoming document/sentence by comparing it with</context>
</contexts>
<marker>Zhang, Liu, 2002</marker>
<rawString>Huaping Zhang and Qun Liu. 2002. Model of Chinese words rough segmentation based on n-shortest paths method. Journal of Chinese Information Processing, 15:1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Flora S Tsai</author>
</authors>
<title>Combining named entities and tags for novel sentence detection.</title>
<date>2009</date>
<booktitle>In ESAIR ’09: Proceedings of the WSDM ’09 Workshop on Exploiting Semantic Annotations in Information Retrieval,</booktitle>
<pages>30--34</pages>
<contexts>
<context position="3129" citStr="Zhang and Tsai, 2009" startWordPosition="473" endWordPosition="476">lty mining at the event level originated from research on Topic Detection and Tracking (TDT), which is concerned with online new event detection/first story detection (Allan et al., 1998; Yang et al., 2002; Stokes and Carthy, 2001; Franz et al., 2001; Brants et al., 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic d</context>
</contexts>
<marker>Zhang, Tsai, 2009</marker>
<rawString>Yi Zhang and Flora S. Tsai. 2009. Combining named entities and tags for novel sentence detection. In ESAIR ’09: Proceedings of the WSDM ’09 Workshop on Exploiting Semantic Annotations in Information Retrieval, pages 30– 34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Jamie Callan</author>
<author>Thomas Minka</author>
</authors>
<title>Novelty and redundancy detection in adaptive filtering.</title>
<date>2002</date>
<booktitle>In ACM SIGIR 2002,</booktitle>
<pages>81--88</pages>
<location>Tampere, Finland,</location>
<contexts>
<context position="3391" citStr="Zhang et al., 2002" startWordPosition="515" endWordPosition="518">, 2003). Research on document and sentence-level novelty mining aims to find relevant and novel documents/sentences given a stream of documents/sentences. Previous studies on document and sentence-level novelty mining tend to apply some promising content-oriented techniques (Li and Croft, 2005; Allan et al., 1998; Yang et al., 1998; Zhang and Tsai, 2009). Similarity metrics that can be used for detecting novel text are word overlap, cosine similarity (Yang et al., 1998), new word count (Brants et al., 2003), etc. Other works utilize ontological knowledge, especially taxonomy, such as WordNet (Zhang et al., 2002; Allan et al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from informatio</context>
<context position="4911" citStr="Zhang et al., 2002" startWordPosition="760" endWordPosition="763">echniques on Chinese document and sentence-level novelty mining, which is the focus of our paper. The rest of this paper is organized as follows. Section 2 gives a brief overview of related work on detecting novel documents and sentences on English and Chinese. Section 3 introduces the details of preprocessing steps for English and Chinese. A general novelty mining algorithm is described in Section 4. Section 5 reports experimental results. Section 6 summarizes the research findings and discusses issues for further research. 2 Related Work In the pioneering work for detecting novel documents (Zhang et al., 2002), document novelty was predicted based on the distance between the new document and the previously delivered documents in history. The detected document which is very similar to any of its history documents is regarded as a redundant document. To serve users better, it could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and int</context>
<context position="12451" citStr="Zhang et al., 2002" startWordPosition="1972" endWordPosition="1975">Novelty 5core(dt) = 1 − max cos(dt, di) (1) 1&lt;i&lt;t−1 tll - lldill where N,os(d) denotes the cosine similarity score of the document/sentence d and wk(d) is the weight of kth element in the document/sentence weighted vector d. The term weighting function used in our work is TF(term frequency). The final decision on whether a document/sentence is novel or not depends on whether the novelty score falls above or below a threshold. The document/sentence predicted as “novel” will be placed into the list of history documents/sentences. 5 Experiments and Results 5.1 Datasets Two public datasets APWSJ (Zhang et al., 2002) and TREC Novelty Track 2004 (Soboroff, 2004) are selected as our experimental datasets for the document-level and the sentence-level novelty mining respectively. APWSJ data consists of news articles from Associated Press (AP) and Wall Street Journal (WSJ). There are 50 topics from Q101 to Q150 in APWSJ and 5 topics (Q131, Q142, Q145, Q147, Q150) are excluded from the Table 1: Statistics of experimental data Dataset Novel Non-novel APWSJ 10839(91.10%) 1057(8.90%) TREC2004 3454(41.40%) 4889(58.60%) experiments because they lack non-novel documents (Zhao et al., 2006). The assessors provide two </context>
<context position="13703" citStr="Zhang et al., 2002" startWordPosition="2166" endWordPosition="2169">l documents, absolute redundant and somewhat redundant. In our experiments, we adopt the strict definition used in (Zhang et al., 2002) where only absolute redundant documents are regarded as nonnovel. TREC 2004 Novelty Track data is developed from AQUAINT collection. Both relevant and novel sentences are selected by TREC’s assessors. The statistics of these two datasets are summarized in Table 1. 5.2 Evaluation Measures From many previous works, redundancy precision (RP), redundancy recall (RR) and redundancy F Score (RF) are used to evaluate the performance of document-level novelty mining (Zhang et al., 2002). Precision (P), recall (R) and F Score (F) are mainly used in evaluating the performance for sentence-level novelty mining (Allan et al., 2003). Therefore, we use RP, RR, RF and redundancy precision-recall (R-PR) curve to evaluate our experimental results on the document level. P, R, F and precision-recall (PR) curve are used to evaluate the performance on the sentence-level novelty mining. The larger the area under the R-PR �� k=1 wk(dt) - wk(di) cos(dt, di) = lld 1564 Document/ Sentence String Atom Segmentation Atom Sequence NSP-based Rough Segmentation Top N Sequence Unknown Word Recogniti</context>
</contexts>
<marker>Zhang, Callan, Minka, 2002</marker>
<rawString>Yi Zhang, Jamie Callan, and Thomas Minka. 2002. Novelty and redundancy detection in adaptive filtering. In ACM SIGIR 2002, Tampere, Finland, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zheng Le Zhao</author>
<author>Shaoping Ma</author>
</authors>
<title>The nature of novelty detection. Information Retrieval,</title>
<date>2006</date>
<pages>9--527</pages>
<marker>Le Zhao, Ma, 2006</marker>
<rawString>Le Zhao, Min Zheng, and Shaoping Ma. 2006. The nature of novelty detection. Information Retrieval, 9:527–541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Zheng</author>
<author>Yu Zhang</author>
<author>Bowei Zou</author>
<author>Yu Hong</author>
<author>Ting Liu</author>
</authors>
<date>2008</date>
<note>Research of Chinese topic tracking based on relevance model.</note>
<contexts>
<context position="4019" citStr="Zheng et al., 2008" startWordPosition="614" endWordPosition="617"> al., 2003), synonym dictionary (Franz et al., 2001), HowNet (Eichmann and Srinivasan, 2002), etc. Previous studies for novelty mining have been conducted on the English and Malay languages (Kwee et al., 2009; Tang et al., 2009; Tang and Tsai, 2009). Novelty mining studies on the Chinese language have been performed on topic de1561 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1561–1570, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP tection and tracking, which identifies and collects relevant stories on certain topics from information stream (Zheng et al., 2008; Hong et al., 2008). Also many works have discussed the issues, such as word segmentation, POS tagging etc, between English and Chinese (Wang et al., 2006; Wu et al., 2003). However, to the best of our knowledge, no studies have been reported on discussing preprocessing techniques on Chinese document and sentence-level novelty mining, which is the focus of our paper. The rest of this paper is organized as follows. Section 2 gives a brief overview of related work on detecting novel documents and sentences on English and Chinese. Section 3 introduces the details of preprocessing steps for Engli</context>
<context position="5799" citStr="Zheng et al., 2008" startWordPosition="899" endWordPosition="902"> could be more helpful to further highlight novel information at the sentence level. Therefore, later studies focused on detecting novel sentences, such as those reported in TREC 2002-2004 Novelty Tracks (Harman, 2002; Soboroff and Harman, 2003; Soboroff, 2004), which compared various novelty metrics (Allan et al., 2003), and integrated different natural language techniques (Ng et al., 2007; Li and Croft, 2008). Although novelty mining studies have mainly been conducted on the English language, studies on the Chinese language have been performed on topic detection and tracking. A prior study (Zheng et al., 2008) proposed an improved relevance model to detect the novelty information in topic tracking feedback and modified the topic model based on this information. Experimental results on Chinese datasets TDT4 and TDT2003 proved the effectiveness in topic tracking. Another study proposed a method of applying semantic domain language model to link detection, based on the structure relation among contents and the semantic distribution in a story (Hong et al., 2008). 3 Preprocessing for English and Chinese 3.1 English Since the focus of this paper is on novelty mining, we begin from a list of relevant doc</context>
</contexts>
<marker>Zheng, Zhang, Zou, Hong, Liu, 2008</marker>
<rawString>Wei Zheng, Yu Zhang, Bowei Zou, Yu Hong, and Ting Liu. 2008. Research of Chinese topic tracking based on relevance model.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>