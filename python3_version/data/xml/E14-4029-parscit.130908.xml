<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008179">
<title confidence="0.998543">
Integrating an Unsupervised Transliteration Model into
Statistical Machine Translation
</title>
<author confidence="0.991485">
Nadir Durrani Hassan Sajjad
</author>
<affiliation confidence="0.999128">
University of Edinburgh Qatar Computing Research Institute
</affiliation>
<email confidence="0.977987">
dnadir@inf.ed.ac.uk hsajjad@@qf.org.qa
</email>
<author confidence="0.996324">
Hieu Hoang Philipp Koehn
</author>
<affiliation confidence="0.998836">
University of Edinburgh
</affiliation>
<email confidence="0.996637">
hieu.hoang,pkoehn@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.997364" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999696">
We investigate three methods for integrat-
ing an unsupervised transliteration model
into an end-to-end SMT system. We in-
duce a transliteration model from parallel
data and use it to translate OOV words.
Our approach is fully unsupervised and
language independent. In the methods
to integrate transliterations, we observed
improvements from 0.23-0.75 (Δ 0.41)
BLEU points across 7 language pairs. We
also show that our mined transliteration
corpora provide better rule coverage and
translation quality compared to the gold
standard transliteration corpora.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999930437500001">
All machine translation (MT) systems suffer from
the existence of out-of-vocabulary (OOV) words,
irrespective of the amount of data available for
training. OOV words are mostly named entities,
technical terms or foreign words that can be trans-
lated to the target language using transliteration.
Much work (Al-Onaizan and Knight, 2002;
Zhao et al., 2007; Kashani et al., 2007; Habash,
2009) has been done on transliterating named enti-
ties and OOVs, and transliteration has been shown
to improve MT quality. Transliteration has also
shown to be useful for translating closely related
language pairs (Durrani et al., 2010; Nakov and
Tiedemann, 2012), and for disambiguation (Her-
mjakob et al., 2008; Azab et al., 2013). How-
ever, despite its utility, a transliteration module
does not exist in the commonly used MT toolk-
its, such as Moses (Koehn et al., 2007). One of the
main reasons is that the training data, a corpus of
transliteration pairs, required to build a translitera-
tion system, is not readily available for many lan-
guage pairs. Even if such a training data is avail-
able, mechanisms to integrate transliterated words
into MT pipelines are unavailable in these toolkits.
Generally, a supervised transliteration system is
trained separately outside of an MT pipeline, and
a naive approach, to replace OOV words with their
1-best transliterations in the post/pre-processing
step of decoding is commonly used.
In this work i) we use an unsupervised model
based on Expectation Maximization (EM) to in-
duce transliteration corpus from word aligned par-
allel data, which is then used to train a translitera-
tion model, ii) we investigate three different meth-
ods for integrating transliteration during decoding,
that we implemented within the Moses toolkit. To
the best of our knowledge, our work is the fore-
most attempt to integrate unsupervised translitera-
tion model into SMT.
This paper is organized as follows. Section 2
describes the unsupervised transliteration mining
system, which automatically mines transliteration
pairs from the same word-aligned parallel corpus
as used for training the MT system. Section 3 de-
scribes the transliteration model that is trained us-
ing the automatically extracted pairs. Section 4
presents three methods for incorporating translit-
eration into the MT pipeline, namely: i) replac-
ing OOVs with the 1-best transliteration in a post-
decoding step, ii) selecting the best translitera-
tion from the list of n-best transliterations using
transliteration and language model features in a
post-decoding step, iii) providing a transliteration
phrase-table to the decoder on the fly where it
can consider all features to select the best translit-
eration of OOV words. Section 5 presents re-
sults. Our integrations achieved an average im-
provement of 0.41 BLEU points over a competi-
tive baseline across 7 language pairs (Arabic, Ben-
gali, Farsi, Hindi, Russian, Telugu and Urdu-into-
English). An additional experiment showed that
our system provides better rule coverage as op-
posed to another built from gold standard translit-
eration corpus and produces better translations.
</bodyText>
<page confidence="0.95664">
148
</page>
<note confidence="0.900311">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 148–153,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.920964" genericHeader="method">
2 Transliteration Mining
</sectionHeader>
<bodyText confidence="0.999960884615385">
The main bottleneck in building a transliteration
system is the lack of availability of translitera-
tion training pairs. It is, however, fair to assume
that any parallel data would contain a reasonable
number of transliterated word pairs. Transliter-
ation mining can be used to extract such word
pairs from the parallel corpus. Most previous
techniques on transliteration mining generally use
supervised and semi-supervised methods (Sherif
and Kondrak, 2007; Jiampojamarn et al., 2010;
Darwish, 2010; Kahki et al., 2012). This con-
strains the mining solution to language pairs for
which training data (seed data) is available. A few
researchers proposed unsupervised approaches to
mine transliterations (Lee and Choi, 1998; Sajjad
et al., 2011; Lin et al., 2011). We adapted the work
of Sajjad et al. (2012) as summarized below.
Model: The transliteration mining model is a
mixture of two sub-models, namely: a translit-
eration and a non-transliteration sub-model. The
idea is that the transliteration model would as-
sign higher probabilities to transliteration pairs
compared to the probabilities assigned by a non-
transliteration model to the same pairs. Consider a
word pair (e, f), the transliteration model prob-
ability for the word pair is defined as follows:
</bodyText>
<equation confidence="0.978424">
ptr(e, f) _ E � |a |p(qj)
a∈Align(e,f) j=1
</equation>
<bodyText confidence="0.999955285714286">
where Align(e, f) is the set of all possible se-
quences of character alignments, a is one align-
ment sequence and qj is a character alignment.
The non-transliteration model deals with the
word pairs that have no character relationship be-
tween them. It is modeled by multiplying source
and target character unigram models:
</bodyText>
<equation confidence="0.714112">
pntr(e, f) _
</equation>
<bodyText confidence="0.9981349">
The transliteration mining model is defined
as an interpolation of the transliteration sub-model
and the non-transliteration sub-model:
p(e, f) _ (1 − λ)ptr(e, f) + λpntr(e, f)
λ is the prior probability of non-transliteration.
The non-transliteration model does not change
during training. We compute it in a pre-processing
step. The transliteration model learns character
alignment using expectation maximization (EM).
See Sajjad et al. (2012) for more details.
</bodyText>
<sectionHeader confidence="0.997642" genericHeader="method">
3 Transliteration Model
</sectionHeader>
<bodyText confidence="0.999944692307692">
Now that we have transliteration word pairs, we
can learn a transliteration model. We segment the
training corpus into characters and learn a phrase-
based system over character pairs. The translitera-
tion model assumes that source and target charac-
ters are generated monotonically.1 Therefore we
do not use any reordering models. We use 4 basic
phrase-translation features (direct, inverse phrase-
translation, and lexical weighting features), lan-
guage model feature (built from the target-side of
mined transliteration corpus), and word and phrase
penalties. The feature weights are tuned2 on a dev-
set of 1000 transliteration pairs.
</bodyText>
<sectionHeader confidence="0.989561" genericHeader="method">
4 Integration to Machine Translation
</sectionHeader>
<bodyText confidence="0.999784548387097">
We experimented with three methods for integrat-
ing transliterations, described below:
Method 1: involves replacing OOVs in the out-
put with the 1-best transliteration. The success of
Method 1 is solely contingent on the accuracy of
the transliteration model. Also, it ignores con-
text which may lead to incorrect transliteration.
For example, the Arabic word transliterates
to “Bill” when followed by “Clinton” and “Bell”
if preceded by “Alexander Graham”.
Method 2: provides n-best transliterations to
a monotonic decoder that uses a monolingual
language model and a transliteration phrase-
translation table to rescore transliterations. We
carry forward the 4 translation model features used
in the transliteration system to build a transliter-
ation phrase-table. We additionally use an LM-
OOV feature which counts the number of words
in a hypothesis that are unknown to the lan-
guage model. Smoothing methods such as Kneser-
Ney assign significant probability mass to unseen
events, which may cause the decoder to make in-
correct transliteration selection. The LM-OOV
feature acts as a prior to penalize such hypotheses.
Method 3: Method 2 can not benefit from all in-
decoding features and phenomenon like reorder-
ing. It transliterates Urdu compound
(Arabian Sea) to “Sea Arabian”, if is an un-
known word. In method 3, we feed the translitera-
tion phrase-table directly into the first-pass decod-
ing which allows reordering of UNK words. We
</bodyText>
<footnote confidence="0.995283">
1Mining algorithm also makes this assumption.
2Tuning data is subtracted from the training corpus while
tuning to avoid over-fitting. After the weights are tuned, we
add it back, retrain GIZA, and estimate new models.
</footnote>
<equation confidence="0.998931333333333">
� |f|
i=1
pF(fi)
pE(ei)
� |e|
i=1
</equation>
<page confidence="0.981286">
149
</page>
<bodyText confidence="0.99877575">
use the decoding-graph-backoff option in Moses,
that allows multiple translation phrase tables and
back-off models. As in method 2, we also use the
LM-OOV feature in method 3.3
</bodyText>
<sectionHeader confidence="0.996686" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999074">
Data: We experimented with 7 language pairs,
namely: Arabic, Bengali, Farsi, Hindi, Russian,
Telugu and Urdu-into-English. For Arabic4 and
Farsi, we used the TED talks data (Cettolo et al.,
2012) made available for IWSLT-13, and we used
the dev2010 set for tuning and the test2011 and
test2012 sets for evaluation. For Indian languages
we used the Indic multi-parallel corpus (Post et
al., 2012), and we used the dev and test sets pro-
vided with the parallel corpus. For Russian, we
used WMT-13 data (Bojar et al., 2013), and we
used half of the news-test2012 for tuning and other
half for testing. We also evaluated on the news-
test2013 set. For all, we trained the language
model using the monolingual WMT-13 data. See
</bodyText>
<tableCaption confidence="0.574858">
Table 1 for data statistics.
</tableCaption>
<table confidence="0.999531571428572">
6795 887 1434 1704
1916 775 1000
4039 852 1185 1116
4719 1000 1000
302K 1501 1502 3000
4924 1000 1000
9131 980 883
</table>
<tableCaption confidence="0.962174">
Table 1: No. of sentences in Training Data and
Mined Transliteration Corpus (Types) (Mraintr)
</tableCaption>
<bodyText confidence="0.949131117647059">
Baseline Settings: We trained a Moses system
replicating the settings used in competition-grade
systems (Durrani et al., 2013b; Birch et al., 2013):
a maximum sentence length of 80, GDFA sym-
metrization of GIZA++ alignments (Och and Ney,
2003), an interpolated Kneser-Ney smoothed 5-
gram language model with KenLM (Heafield,
2011) used at runtime, a 5-gram OSM (Dur-
rani et al., 2013a), msd-bidirectional-fe lexical-
3Method 3 is desirable in cases where the decoder can
translate or transliterate a word. For example Hindi word
can be translated to “Border” and also transliterated
to name “Seema”. Identifying such candidates that can be
translated or transliterated is a challenge. Machine learning
techniques (Goldwasser and Roth, 2008; Kirschenbaum and
Wintner, 2009) and named entity recognizers (Klementiev
and Roth, 2006; Hermjakob et al., 2008) have been used for
</bodyText>
<footnote confidence="0.91027775">
this purpose. Though, we only focus on OOV words, method
3 can be used if such a classifier/NE tagger is available.
4Arabic and Urdu are segmented using MADA (Habash
and Sadat, 2006) and UWS (Durrani and Hussain, 2010).
</footnote>
<bodyText confidence="0.994773344827586">
ized reordering, sparse lexical and domain fea-
tures (Hasler et al., 2012), a distortion limit of
6, 100-best translation options, MBR decoding
(Kumar and Byrne, 2004), Cube Pruning (Huang
and Chiang, 2007), and the no-reordering-over-
punctuation heuristic. We tuned with the k-best
batch MIRA (Cherry and Foster, 2012).5
Transliteration Miner: The miner extracts
transliterations from a word-aligned parallel cor-
pus. We only used word pairs with 1-to-1 align-
ments.6 Before feeding the list into the miner, we
cleaned it by removing digits, symbols, word pairs
where source or target is composed from less than
3 characters, and words containing foreign char-
acters that do not belong to this scripts. We ran
the miner with 10 iterations of EM. The number
of transliteration pairs (types) extracted for each
language pair is shown in Table 1 (Mraintr).
Transliteration System: Before evaluating our
integrations into the SMT system, we performed
an intrinsic evaluation of the transliteration system
that we built from the mined pairs. We formed
test data for Arabic–English (1799 pairs), Hindi–
English (2394 pairs) and Russian–English (1859
pairs) by concatenating the seed data and gold
standard transliteration pairs both provided for the
Shared Task on Transliteration mining (Kumaran
et al., 2010). Table 2 shows precision and recall of
the mined transliteration system (MTS).
</bodyText>
<table confidence="0.999902">
Precision (1-best Accuracy) 20.0% 25.3% 46.1%
Recall (100-best Accuracy) 80.2% 79.3% 87.5%
</table>
<tableCaption confidence="0.999419">
Table 2: Precision and Recall of MTS
</tableCaption>
<bodyText confidence="0.991019153846154">
The precision (1-best accuracy) of the translit-
eration model is quite low. This is because the
transliteration corpus is noisy and contains imper-
fect transliteration pairs. For example, the miner
extracted the pair ( , Australasia), while
the correct transliteration is “Australia”. We can
improve the precision by tightening the mining
threshold probability. However, our end goal is to
improve end-to-end MT and not the transliteration
system. We observed that recall is more important
than precision for overall MT quality. We provide
an empirical justification for this when discussing
the final experiments.
</bodyText>
<footnote confidence="0.971227">
5Retuning the transliteration features was not helpful, de-
fault weights are used.
6M-N/1-N alignments are less likely to be transliterations.
</footnote>
<figure confidence="0.961208266666667">
AR HI RU
Lang Traint. Traint, Dev Test, Testa
AR 152K
24K
BN
79K
FA
39K
HI
2M
RU
45K
TE
87K
UR
</figure>
<page confidence="0.976616">
150
</page>
<bodyText confidence="0.999165294117647">
MT Experiments: Table 3 gives a comprehen-
sive evaluation of the three methods of integra-
tion discussed in Section 4 along with the num-
ber7 of OOV words (types) in different tests. We
report BLEU gains (Papineni et al., 2002) obtained
by each method. Method 1 (M1), that replaces
OOV words with 1-best transliteration gave an av-
erage improvement of +0.13. This result can be at-
tributed to the low precision of the transliteration
system (Table 2). Method 2 (M2), that translit-
erates OOVs in second pass monotonic decoding,
gave an average improvement of +0.39. Slightly
higher gains were obtained using Method 3 (M3),
that integrates transliteration phrase-table inside
decoder on the fly. However, the efficacy of M3 in
comparison to M2 is not as apparent, as M2 pro-
duced better results than M3 in half of the cases.
</bodyText>
<table confidence="0.98048375">
HI jhu12 15.64 +0.21 +0.35 +0.47 1629
TE jhu12 11.04 -0.09 +0.40 +0.75 2343
UR jhu12 23.25 +0.24 +0.54 +0.60 827
Avg 21.9 +0.13 +0.39 +0.41 950
</table>
<tableCaption confidence="0.996059">
Table 3: End-to-End MT Evaluation – B0 =
</tableCaption>
<bodyText confidence="0.976760823529412">
Baseline, M1 = Method1, M2 = Method2, M3 =
Method3, BLEU gains shown for each method
In an effort to test whether improving translit-
eration precision would improve end-to-end SMT
results, we carried out another experiment. Instead
of building a transliteration system from mined
corpus, we built it using the gold standard corpus
(for Arabic, Hindi and Russian), that we also used
previously to do an intrinsic evaluation. We then
replaced our mined transliteration systems with
the gold standard transliteration systems, in the
best performing SMT systems for these languages.
Table 4 shows a comparison of performances. Al-
though the differences are small, systems using
mined transliteration system (MTS) outperformed
its counterpart that uses gold standard translitera-
tion system (GTS), except in Hindi–English where
</bodyText>
<footnote confidence="0.9073135">
7Note that not all OOVs can be transliterated. This num-
ber is therefore an upper bound what can be transliterated.
</footnote>
<table confidence="0.8504994">
both systems were equal.
AR HI RU
iwslt11 iwslt12 jhu12 wmt12 iwslt13
MTS 27.11 29.33 16.11 34.50 26.38
GST 26.99 29.20 16.11 34.33 26.22
</table>
<tableCaption confidence="0.917587">
Table 4: Comparing Gold Standard Transliteration
(GST) and Mined Transliteration Systems
</tableCaption>
<bodyText confidence="0.955195444444444">
In the error analysis we found that the GST
system suffered from sparsity and did not pro-
vide enough coverage of rules to produce right
transliterations. For example, Arabic drops the
determiner (al), but such additions were not
observed in gold transliteration pairs. Arabic
word (Gigapixel) is therefore translit-
erated to “algegabksl”. Similarly the GST system
learned no transliteration pairs to account for the
rule “b → p” and therefore erroneously translit-
erated (Spurlock) to “Sbrlok”. Similar
observations were true for the case of Russian–
English. The rules “a → u” and “y → c” were not
observed in the gold set, and hence
(hurricane) was transliterated to “herricane” and
(Talbot) to “Talboty”. This shows that
better recall obtained from the mined pairs led to
overall improvement.
</bodyText>
<sectionHeader confidence="0.998723" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999978692307692">
We incorporated unsupervised transliteration min-
ing model into standard MT pipeline to automati-
cally transliterate OOV words without needing ad-
ditional resources. We evaluated three methods
for integrating transliterations on 7 language pairs
and showed improvements ranging from 0.23-0.75
(Δ 0.41) BLEU points. We also showed that our
mined transliteration corpus provide better recall
and overall translation quality compared to the
gold standard transliteration corpus. The unsu-
pervised transliteration miner and its integration
to SMT has been made available to the research
community via the Moses toolkit.
</bodyText>
<sectionHeader confidence="0.99752" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.991858">
We wish to thank the anonymous reviewers and
Kareem Darwish for their valuable feedback on
an earlier draft of this paper. The research lead-
ing to these results has received funding from
the European Union Seventh Framework Pro-
gramme (FP7/2007-2013) under grant agreement
n◦ 287658. This publication only reflects the au-
thors’ views.
</bodyText>
<figure confidence="0.998291033333333">
Lang Test B0 M1 M2 M3 OOV
AR
iwslt11
iwslt12
26.75
29.03
+0.12
+0.10
+0.36
+0.30
+0.25
+0.27
587
682
BN jhu12 16.29 +0.12 +0.42 +0.46 1239
FA
iwslt11
iwslt12
20.85
16.26
+0.10
+0.04
+0.40
+0.20
+0.31
+0.26
559
400
RU wmt12 33.95 +0.24 +0.55 +0.49 434
wmt13 25.98 +0.25 +0.40 +0.23 799
</figure>
<page confidence="0.98917">
151
</page>
<sectionHeader confidence="0.981265" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999303345454546">
Yaser Al-Onaizan and Kevin Knight. 2002. Translat-
ing Named Entities Using Monolingual and Bilin-
gual Resources. In Proceedings of the 40th Annual
Meeting of the Association for Computational Lin-
guistics.
Mahmoud Azab, Houda Bouamor, Behrang Mohit, and
Kemal Oflazer. 2013. Dudley North visits North
London: Learning When to Transliterate to Arabic.
In Proceedings of the 2013 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 439–444, Atlanta, Georgia, June. Association
for Computational Linguistics.
Alexandra Birch, Nadir Durrani, and Philipp Koehn.
2013. Edinburgh SLT and MT System Description
for the IWSLT 2013 Evaluation. In Proceedings
of the 10th International Workshop on Spoken Lan-
guage Translation, pages 40–48, Heidelberg, Ger-
many, December.
Ondrej Bojar, Christian Buck, Chris Callison-Burch,
Christian Federmann, Barry Haddow, Philipp
Koehn, Christof Monz, Matt Post, Radu Soricut,
and Lucia Specia. 2013. Findings of the 2013
Workshop on Statistical Machine Translation. In
Eighth Workshop on Statistical Machine Transla-
tion, WMT-2013, pages 1–44, Sofia, Bulgaria.
Mauro Cettolo, Christian Girardi, and Marcello Fed-
erico. 2012. WIT3: Web Inventory of Transcribed
and Translated Talks. In Proceedings of the 16th
Conference of the European Association for Ma-
chine Translation (EAMT), pages 261–268, Trento,
Italy, May.
Colin Cherry and George Foster. 2012. Batch Tun-
ing Strategies for Statistical Machine Translation. In
Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
pages 427–436, Montr´eal, Canada, June. Associa-
tion for Computational Linguistics.
Kareem Darwish. 2010. Transliteration Mining with
Phonetic Conflation and Iterative Training. In Pro-
ceedings of the 2010 Named Entities Workshop, Up-
psala, Sweden.
Nadir Durrani and Sarmad Hussain. 2010. Urdu Word
Segmentation. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 528–536, Los Angeles, California,
June. Association for Computational Linguistics.
Nadir Durrani, Hassan Sajjad, Alexander Fraser, and
Helmut Schmid. 2010. Hindi-to-Urdu Machine
Translation through Transliteration. In Proceedings
of the 48th Annual Conference of the Association for
Computational Linguistics, Uppsala, Sweden.
Nadir Durrani, Alexander Fraser, Helmut Schmid,
Hieu Hoang, and Philipp Koehn. 2013a. Can
Markov Models Over Minimal Translation Units
Help Phrase-Based SMT? In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, Sofia, Bulgaria, August. Asso-
ciation for Computational Linguistics.
Nadir Durrani, Barry Haddow, Kenneth Heafield, and
Philipp Koehn. 2013b. Edinburgh’s Machine Trans-
lation Systems for European Language Pairs. In
Proceedings of the Eighth Workshop on Statistical
Machine Translation, Sofia, Bulgaria, August. As-
sociation for Computational Linguistics.
Dan Goldwasser and Dan Roth. 2008. Active Sam-
ple Selection for Named Entity Transliteration. In
Proceedings of ACL-08: HLT, Short Papers, pages
53–56, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Nizar Habash and Fatiha Sadat. 2006. Arabic Pre-
processing Schemes for Statistical Machine Transla-
tion. In Proceedings of the Human Language Tech-
nology Conference of the NAACL, Companion Vol-
ume: Short Papers, pages 49–52, New York City,
USA, June. Association for Computational Linguis-
tics.
Nizar Habash. 2009. REMOOV: A Tool for Online
Handling of Out-of-Vocabulary Words in Machine
Translation. In Proceedings of the Second Interna-
tional Conference on Arabic Language Resources
and Tools, Cairo, Egypt, April. The MEDAR Con-
sortium.
Eva Hasler, Barry Haddow, and Philipp Koehn. 2012.
Sparse Lexicalised Features and Topic Adaptation
for SMT. In Proceedings of the seventh Interna-
tional Workshop on Spoken Language Translation
(IWSLT), pages 268–275.
Kenneth Heafield. 2011. KenLM: Faster and Smaller
Language Model Queries. In Proceedings of the
Sixth Workshop on Statistical Machine Translation,
pages 187–197, Edinburgh, Scotland, United King-
dom, 7.
Ulf Hermjakob, Kevin Knight, and Hal Daum´e III.
2008. Name Translation in Statistical Machine
Translation - Learning When to Transliterate. In
Proceedings of the 46th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, Columbus, Ohio.
Liang Huang and David Chiang. 2007. Forest Rescor-
ing: Faster Decoding with Integrated Language
Models. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 144–151, Prague, Czech Republic, June. As-
sociation for Computational Linguistics.
Sittichai Jiampojamarn, Kenneth Dwyer, Shane
Bergsma, Aditya Bhargava, Qing Dou, Mi-Young
Kim, and Grzegorz Kondrak. 2010. Transliteration
</reference>
<page confidence="0.991163">
152
</page>
<reference confidence="0.998574823529412">
Generation and Mining with Limited Training Re-
sources. In Proceedings of the 2010 Named Entities
Workshop, Uppsala, Sweden.
Ali El Kahki, Kareem Darwish, Ahmed Saad El Din,
and Mohamed Abd El-Wahab. 2012. Transliter-
ation Mining Using Large Training and Test Sets.
In Proceedings of the 2012 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics: Human Language Technologies,
NAACL HLT ’12.
Mehdi M. Kashani, Eric Joanis, Roland Kuhn, George
Foster, and Fred Popowich. 2007. Integration of
an Arabic Transliteration Module into a Statistical
Machine Translation System. In Proceedings of the
Second Workshop on Statistical Machine Transla-
tion, Prague, Czech Republic.
Amit Kirschenbaum and Shuly Wintner. 2009. Lightly
Supervised Transliteration for Machine Translation.
In Proceedings of the 12th Conference of the Euro-
pean Chapter of the ACL (EACL 2009), pages 433–
441, Athens, Greece, March. Association for Com-
putational Linguistics.
Alexandre Klementiev and Dan Roth. 2006. Named
entity transliteration and discovery from multilin-
gual comparable corpora. In Proceedings of the
Human Language Technology Conference of the
NAACL, Main Conference, pages 82–88, New York
City, USA, June. Association for Computational
Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
In Proceedings of the 45th Annual Meeting of the
Association for Computational Linguistics, Demon-
stration Program, Prague, Czech Republic.
Shankar Kumar and William J. Byrne. 2004. Mini-
mum Bayes-Risk Decoding for Statistical Machine
Translation. In HLT-NAACL, pages 169–176.
A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010.
Whitepaper of news 2010 shared task on transliter-
ation mining. In Proceedings of the 2010 Named
Entities Workshop, pages 29–38, Uppsala, Sweden,
July. Association for Computational Linguistics.
Jae-Sung Lee and Key-Sun Choi. 1998. English
to Korean Statistical Transliteration for Information
Retrieval. Computer Processing of Oriental Lan-
guages, 12(1):17–37.
Wen-Pin Lin, Matthew Snover, and Heng Ji. 2011.
Unsupervised Language-Independent Name Trans-
lation Mining from Wikipedia Infoboxes. In Pro-
ceedings of the First workshop on Unsupervised
Learning in NLP, pages 43–52, Edinburgh, Scot-
land, July. Association for Computational Linguis-
tics.
Preslav Nakov and J¨org Tiedemann. 2012. Com-
bining Word-Level and Character-Level Models for
Machine Translation Between Closely-Related Lan-
guages. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 301–305, Jeju
Island, Korea, July. Association for Computational
Linguistics.
Franz J. Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Mod-
els. Computational Linguistics, 29(1).
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Compu-
tational Linguistics, ACL ’02, pages 311–318, Mor-
ristown, NJ, USA.
Matt Post, Chris Callison-Burch, and Miles Osborne.
2012. Constructing Parallel Corpora for Six Indian
Languages via Crowdsourcing. In Proceedings of
the Seventh Workshop on Statistical Machine Trans-
lation, pages 401–409, Montr´eal, Canada, June. As-
sociation for Computational Linguistics.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2011. An Algorithm for Unsupervised Translitera-
tion Mining with an Application to Word Alignment.
In Proceedings of the 49th Annual Conference of
the Association for Computational Linguistics, Port-
land, USA.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2012. A Statistical Model for Unsupervised and
Semi-supervised Transliteration Mining. In Pro-
ceedings of the 50th Annual Conference of the Asso-
ciation for Computational Linguistics, Jeju, Korea.
Tarek Sherif and Grzegorz Kondrak. 2007. Bootstrap-
ping a Stochastic Transducer for Arabic-English
Transliteration Extraction. In Proceedings of the
45th Annual Meeting of the Association for Compu-
tational Linguistics, Prague, Czech Republic.
Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vo-
gel. 2007. A Log-Linear Block Transliteration
Model based on Bi-Stream HMMs. In Human
Language Technologies 2007: The Conference of
the North American Chapter of the Association for
Computational Linguistics, Rochester, New York.
</reference>
<page confidence="0.999231">
153
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.597746">
<title confidence="0.999216">Integrating an Unsupervised Transliteration Model into Statistical Machine Translation</title>
<author confidence="0.997424">Nadir Durrani Hassan Sajjad</author>
<affiliation confidence="0.99987">University of Edinburgh Qatar Computing Research Institute</affiliation>
<email confidence="0.613646">dnadir@inf.ed.ac.ukhsajjad@@qf.org.qa</email>
<author confidence="0.996535">Hieu Hoang Philipp Koehn</author>
<affiliation confidence="0.999949">University of Edinburgh</affiliation>
<email confidence="0.995894">hieu.hoang,pkoehn@inf.ed.ac.uk</email>
<abstract confidence="0.998879066666667">We investigate three methods for integrating an unsupervised transliteration model into an end-to-end SMT system. We induce a transliteration model from parallel data and use it to translate OOV words. Our approach is fully unsupervised and language independent. In the methods to integrate transliterations, we observed from 0.23-0.75 BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yaser Al-Onaizan</author>
<author>Kevin Knight</author>
</authors>
<title>Translating Named Entities Using Monolingual and Bilingual Resources.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1205" citStr="Al-Onaizan and Knight, 2002" startWordPosition="160" endWordPosition="163">s to integrate transliterations, we observed improvements from 0.23-0.75 (Δ 0.41) BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora. 1 Introduction All machine translation (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteratio</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Yaser Al-Onaizan and Kevin Knight. 2002. Translating Named Entities Using Monolingual and Bilingual Resources. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mahmoud Azab</author>
<author>Houda Bouamor</author>
<author>Behrang Mohit</author>
<author>Kemal Oflazer</author>
</authors>
<title>Dudley North visits North London: Learning When to Transliterate to Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>439--444</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="1586" citStr="Azab et al., 2013" startWordPosition="222" endWordPosition="225"> irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliteration system, is not readily available for many language pairs. Even if such a training data is available, mechanisms to integrate transliterated words into MT pipelines are unavailable in these toolkits. Generally, a supervised transliteration system is trained separately outside of an MT pipeline, and a naive approach, to replace OOV word</context>
</contexts>
<marker>Azab, Bouamor, Mohit, Oflazer, 2013</marker>
<rawString>Mahmoud Azab, Houda Bouamor, Behrang Mohit, and Kemal Oflazer. 2013. Dudley North visits North London: Learning When to Transliterate to Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 439–444, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Nadir Durrani</author>
<author>Philipp Koehn</author>
</authors>
<date>2013</date>
<booktitle>Edinburgh SLT and MT System Description for the IWSLT 2013 Evaluation. In Proceedings of the 10th International Workshop on Spoken Language Translation,</booktitle>
<pages>40--48</pages>
<location>Heidelberg, Germany,</location>
<contexts>
<context position="9975" citStr="Birch et al., 2013" startWordPosition="1540" endWordPosition="1543">d WMT-13 data (Bojar et al., 2013), and we used half of the news-test2012 for tuning and other half for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses system replicating the settings used in competition-grade systems (Durrani et al., 2013b; Birch et al., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenb</context>
</contexts>
<marker>Birch, Durrani, Koehn, 2013</marker>
<rawString>Alexandra Birch, Nadir Durrani, and Philipp Koehn. 2013. Edinburgh SLT and MT System Description for the IWSLT 2013 Evaluation. In Proceedings of the 10th International Workshop on Spoken Language Translation, pages 40–48, Heidelberg, Germany, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ondrej Bojar</author>
<author>Christian Buck</author>
<author>Chris Callison-Burch</author>
<author>Christian Federmann</author>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Matt Post</author>
<author>Radu Soricut</author>
<author>Lucia Specia</author>
</authors>
<date>2013</date>
<booktitle>Findings of the 2013 Workshop on Statistical Machine Translation. In Eighth Workshop on Statistical Machine Translation, WMT-2013,</booktitle>
<pages>1--44</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="9390" citStr="Bojar et al., 2013" startWordPosition="1440" endWordPosition="1443">bles and back-off models. As in method 2, we also use the LM-OOV feature in method 3.3 5 Evaluation Data: We experimented with 7 language pairs, namely: Arabic, Bengali, Farsi, Hindi, Russian, Telugu and Urdu-into-English. For Arabic4 and Farsi, we used the TED talks data (Cettolo et al., 2012) made available for IWSLT-13, and we used the dev2010 set for tuning and the test2011 and test2012 sets for evaluation. For Indian languages we used the Indic multi-parallel corpus (Post et al., 2012), and we used the dev and test sets provided with the parallel corpus. For Russian, we used WMT-13 data (Bojar et al., 2013), and we used half of the news-test2012 for tuning and other half for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses system replicating the settings used in competition-grade systems (Durrani et al., 2013b; Birch et al., 2013): a maximum sen</context>
</contexts>
<marker>Bojar, Buck, Callison-Burch, Federmann, Haddow, Koehn, Monz, Post, Soricut, Specia, 2013</marker>
<rawString>Ondrej Bojar, Christian Buck, Chris Callison-Burch, Christian Federmann, Barry Haddow, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2013. Findings of the 2013 Workshop on Statistical Machine Translation. In Eighth Workshop on Statistical Machine Translation, WMT-2013, pages 1–44, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Christian Girardi</author>
<author>Marcello Federico</author>
</authors>
<title>WIT3: Web Inventory of Transcribed and Translated Talks.</title>
<date>2012</date>
<booktitle>In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT),</booktitle>
<pages>261--268</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="9066" citStr="Cettolo et al., 2012" startWordPosition="1383" endWordPosition="1386">so makes this assumption. 2Tuning data is subtracted from the training corpus while tuning to avoid over-fitting. After the weights are tuned, we add it back, retrain GIZA, and estimate new models. � |f| i=1 pF(fi) pE(ei) � |e| i=1 149 use the decoding-graph-backoff option in Moses, that allows multiple translation phrase tables and back-off models. As in method 2, we also use the LM-OOV feature in method 3.3 5 Evaluation Data: We experimented with 7 language pairs, namely: Arabic, Bengali, Farsi, Hindi, Russian, Telugu and Urdu-into-English. For Arabic4 and Farsi, we used the TED talks data (Cettolo et al., 2012) made available for IWSLT-13, and we used the dev2010 set for tuning and the test2011 and test2012 sets for evaluation. For Indian languages we used the Indic multi-parallel corpus (Post et al., 2012), and we used the dev and test sets provided with the parallel corpus. For Russian, we used WMT-13 data (Bojar et al., 2013), and we used half of the news-test2012 for tuning and other half for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 </context>
</contexts>
<marker>Cettolo, Girardi, Federico, 2012</marker>
<rawString>Mauro Cettolo, Christian Girardi, and Marcello Federico. 2012. WIT3: Web Inventory of Transcribed and Translated Talks. In Proceedings of the 16th Conference of the European Association for Machine Translation (EAMT), pages 261–268, Trento, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch Tuning Strategies for Statistical Machine Translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>427--436</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="11235" citStr="Cherry and Foster, 2012" startWordPosition="1736" endWordPosition="1739">ity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus. We only used word pairs with 1-to-1 alignments.6 Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs where source or target is composed from less than 3 characters, and words containing foreign characters that do not belong to this scripts. We ran the miner with 10 iterations of EM. The number of transliteration pairs (types) extracted for each language pair is shown in Table 1 (Mraintr). Transliteration System: Before evaluating our integrations into the</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch Tuning Strategies for Statistical Machine Translation. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 427–436, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
</authors>
<title>Transliteration Mining with Phonetic Conflation and Iterative Training.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="4702" citStr="Darwish, 2010" startWordPosition="701" endWordPosition="702">53, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Transliteration Mining The main bottleneck in building a transliteration system is the lack of availability of transliteration training pairs. It is, however, fair to assume that any parallel data would contain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteration pairs compared to the probabilities assi</context>
</contexts>
<marker>Darwish, 2010</marker>
<rawString>Kareem Darwish. 2010. Transliteration Mining with Phonetic Conflation and Iterative Training. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Sarmad Hussain</author>
</authors>
<title>Urdu Word Segmentation. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>528--536</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="10916" citStr="Durrani and Hussain, 2010" startWordPosition="1688" endWordPosition="1691">r can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus. We only used word pairs with 1-to-1 alignments.6 Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs where source or target is composed from</context>
</contexts>
<marker>Durrani, Hussain, 2010</marker>
<rawString>Nadir Durrani and Sarmad Hussain. 2010. Urdu Word Segmentation. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 528–536, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>Hindi-to-Urdu Machine Translation through Transliteration.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Conference of the Association for Computational Linguistics,</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="1490" citStr="Durrani et al., 2010" startWordPosition="206" endWordPosition="209">n All machine translation (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliteration system, is not readily available for many language pairs. Even if such a training data is available, mechanisms to integrate transliterated words into MT pipelines are unavailable in these toolkits. Generally, a supervised transliteration s</context>
</contexts>
<marker>Durrani, Sajjad, Fraser, Schmid, 2010</marker>
<rawString>Nadir Durrani, Hassan Sajjad, Alexander Fraser, and Helmut Schmid. 2010. Hindi-to-Urdu Machine Translation through Transliteration. In Proceedings of the 48th Annual Conference of the Association for Computational Linguistics, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
<author>Hieu Hoang</author>
<author>Philipp Koehn</author>
</authors>
<title>Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT?</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="9953" citStr="Durrani et al., 2013" startWordPosition="1536" endWordPosition="1539">us. For Russian, we used WMT-13 data (Bojar et al., 2013), and we used half of the news-test2012 for tuning and other half for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses system replicating the settings used in competition-grade systems (Durrani et al., 2013b; Birch et al., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and</context>
</contexts>
<marker>Durrani, Fraser, Schmid, Hoang, Koehn, 2013</marker>
<rawString>Nadir Durrani, Alexander Fraser, Helmut Schmid, Hieu Hoang, and Philipp Koehn. 2013a. Can Markov Models Over Minimal Translation Units Help Phrase-Based SMT? In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Barry Haddow</author>
<author>Kenneth Heafield</author>
<author>Philipp Koehn</author>
</authors>
<title>Edinburgh’s Machine Translation Systems for European Language Pairs.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="9953" citStr="Durrani et al., 2013" startWordPosition="1536" endWordPosition="1539">us. For Russian, we used WMT-13 data (Bojar et al., 2013), and we used half of the news-test2012 for tuning and other half for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses system replicating the settings used in competition-grade systems (Durrani et al., 2013b; Birch et al., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and</context>
</contexts>
<marker>Durrani, Haddow, Heafield, Koehn, 2013</marker>
<rawString>Nadir Durrani, Barry Haddow, Kenneth Heafield, and Philipp Koehn. 2013b. Edinburgh’s Machine Translation Systems for European Language Pairs. In Proceedings of the Eighth Workshop on Statistical Machine Translation, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Goldwasser</author>
<author>Dan Roth</author>
</authors>
<title>Active Sample Selection for Named Entity Transliteration.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT, Short Papers,</booktitle>
<pages>53--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="10564" citStr="Goldwasser and Roth, 2008" startWordPosition="1630" endWordPosition="1633">i et al., 2013b; Birch et al., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation h</context>
</contexts>
<marker>Goldwasser, Roth, 2008</marker>
<rawString>Dan Goldwasser and Dan Roth. 2008. Active Sample Selection for Named Entity Transliteration. In Proceedings of ACL-08: HLT, Short Papers, pages 53–56, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Fatiha Sadat</author>
</authors>
<title>Arabic Preprocessing Schemes for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,</booktitle>
<pages>49--52</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="10880" citStr="Habash and Sadat, 2006" startWordPosition="1682" endWordPosition="1685">sirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus. We only used word pairs with 1-to-1 alignments.6 Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs whe</context>
</contexts>
<marker>Habash, Sadat, 2006</marker>
<rawString>Nizar Habash and Fatiha Sadat. 2006. Arabic Preprocessing Schemes for Statistical Machine Translation. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 49–52, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>REMOOV: A Tool for Online Handling of Out-of-Vocabulary Words in Machine Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Second International Conference on Arabic Language Resources and Tools,</booktitle>
<publisher>The MEDAR Consortium.</publisher>
<location>Cairo, Egypt,</location>
<contexts>
<context position="1261" citStr="Habash, 2009" startWordPosition="172" endWordPosition="173">75 (Δ 0.41) BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora. 1 Introduction All machine translation (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliteration system, is </context>
</contexts>
<marker>Habash, 2009</marker>
<rawString>Nizar Habash. 2009. REMOOV: A Tool for Online Handling of Out-of-Vocabulary Words in Machine Translation. In Proceedings of the Second International Conference on Arabic Language Resources and Tools, Cairo, Egypt, April. The MEDAR Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hasler</author>
<author>Barry Haddow</author>
<author>Philipp Koehn</author>
</authors>
<title>Sparse Lexicalised Features and Topic Adaptation for SMT.</title>
<date>2012</date>
<booktitle>In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<pages>268--275</pages>
<contexts>
<context position="10991" citStr="Hasler et al., 2012" startWordPosition="1700" endWordPosition="1703"> to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus. We only used word pairs with 1-to-1 alignments.6 Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs where source or target is composed from less than 3 characters, and words containing foreign characters that do no</context>
</contexts>
<marker>Hasler, Haddow, Koehn, 2012</marker>
<rawString>Eva Hasler, Barry Haddow, and Philipp Koehn. 2012. Sparse Lexicalised Features and Topic Adaptation for SMT. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 268–275.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and Smaller Language Model Queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>187--197</pages>
<location>Edinburgh, Scotland, United Kingdom,</location>
<contexts>
<context position="10158" citStr="Heafield, 2011" startWordPosition="1570" endWordPosition="1571">e model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses system replicating the settings used in competition-grade systems (Durrani et al., 2013b; Birch et al., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 c</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and Smaller Language Model Queries. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 187–197, Edinburgh, Scotland, United Kingdom, 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Hermjakob</author>
<author>Kevin Knight</author>
<author>Hal Daum´e</author>
</authors>
<title>Name Translation in Statistical Machine Translation - Learning When to Transliterate.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Columbus, Ohio.</location>
<marker>Hermjakob, Knight, Daum´e, 2008</marker>
<rawString>Ulf Hermjakob, Kevin Knight, and Hal Daum´e III. 2008. Name Translation in Statistical Machine Translation - Learning When to Transliterate. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest Rescoring: Faster Decoding with Integrated Language Models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>144--151</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="11123" citStr="Huang and Chiang, 2007" startWordPosition="1720" endWordPosition="1723">hallenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus. We only used word pairs with 1-to-1 alignments.6 Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs where source or target is composed from less than 3 characters, and words containing foreign characters that do not belong to this scripts. We ran the miner with 10 iterations of EM. The number of transliteration pairs (types) extracted for each </context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest Rescoring: Faster Decoding with Integrated Language Models. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 144–151, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sittichai Jiampojamarn</author>
<author>Kenneth Dwyer</author>
<author>Shane Bergsma</author>
<author>Aditya Bhargava</author>
<author>Qing Dou</author>
<author>Mi-Young Kim</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Transliteration Generation and Mining with Limited Training Resources.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<location>Uppsala, Sweden.</location>
<contexts>
<context position="4687" citStr="Jiampojamarn et al., 2010" startWordPosition="697" endWordPosition="700">al Linguistics, pages 148–153, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Transliteration Mining The main bottleneck in building a transliteration system is the lack of availability of transliteration training pairs. It is, however, fair to assume that any parallel data would contain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteration pairs compared to the pro</context>
</contexts>
<marker>Jiampojamarn, Dwyer, Bergsma, Bhargava, Dou, Kim, Kondrak, 2010</marker>
<rawString>Sittichai Jiampojamarn, Kenneth Dwyer, Shane Bergsma, Aditya Bhargava, Qing Dou, Mi-Young Kim, and Grzegorz Kondrak. 2010. Transliteration Generation and Mining with Limited Training Resources. In Proceedings of the 2010 Named Entities Workshop, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ali El Kahki</author>
<author>Kareem Darwish</author>
<author>Ahmed Saad El Din</author>
<author>Mohamed Abd El-Wahab</author>
</authors>
<title>Transliteration Mining Using Large Training and Test Sets.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12.</booktitle>
<marker>El Kahki, Darwish, El Din, El-Wahab, 2012</marker>
<rawString>Ali El Kahki, Kareem Darwish, Ahmed Saad El Din, and Mohamed Abd El-Wahab. 2012. Transliteration Mining Using Large Training and Test Sets. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehdi M Kashani</author>
<author>Eric Joanis</author>
<author>Roland Kuhn</author>
<author>George Foster</author>
<author>Fred Popowich</author>
</authors>
<title>Integration of an Arabic Transliteration Module into a Statistical Machine Translation System.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1246" citStr="Kashani et al., 2007" startWordPosition="168" endWordPosition="171">rovements from 0.23-0.75 (Δ 0.41) BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora. 1 Introduction All machine translation (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliterat</context>
</contexts>
<marker>Kashani, Joanis, Kuhn, Foster, Popowich, 2007</marker>
<rawString>Mehdi M. Kashani, Eric Joanis, Roland Kuhn, George Foster, and Fred Popowich. 2007. Integration of an Arabic Transliteration Module into a Statistical Machine Translation System. In Proceedings of the Second Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Kirschenbaum</author>
<author>Shuly Wintner</author>
</authors>
<title>Lightly Supervised Transliteration for Machine Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL</booktitle>
<pages>433--441</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="10597" citStr="Kirschenbaum and Wintner, 2009" startWordPosition="1634" endWordPosition="1637">l., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-bes</context>
</contexts>
<marker>Kirschenbaum, Wintner, 2009</marker>
<rawString>Amit Kirschenbaum and Shuly Wintner. 2009. Lightly Supervised Transliteration for Machine Translation. In Proceedings of the 12th Conference of the European Chapter of the ACL (EACL 2009), pages 433– 441, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>82--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="10653" citStr="Klementiev and Roth, 2006" startWordPosition="1642" endWordPosition="1645">n of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Named entity transliteration and discovery from multilingual comparable corpora. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 82–88, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Demonstration Program,</booktitle>
<location>Alexandra</location>
<contexts>
<context position="1726" citStr="Koehn et al., 2007" startWordPosition="247" endWordPosition="250">be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliteration system, is not readily available for many language pairs. Even if such a training data is available, mechanisms to integrate transliterated words into MT pipelines are unavailable in these toolkits. Generally, a supervised transliteration system is trained separately outside of an MT pipeline, and a naive approach, to replace OOV words with their 1-best transliterations in the post/pre-processing step of decoding is commonly used. In this work i) we use an unsupervised mo</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Demonstration Program, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William J Byrne</author>
</authors>
<title>Minimum Bayes-Risk Decoding for Statistical Machine Translation. In</title>
<date>2004</date>
<booktitle>HLT-NAACL,</booktitle>
<pages>169--176</pages>
<contexts>
<context position="11084" citStr="Kumar and Byrne, 2004" startWordPosition="1714" endWordPosition="1717">be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al., 2008) have been used for this purpose. Though, we only focus on OOV words, method 3 can be used if such a classifier/NE tagger is available. 4Arabic and Urdu are segmented using MADA (Habash and Sadat, 2006) and UWS (Durrani and Hussain, 2010). ized reordering, sparse lexical and domain features (Hasler et al., 2012), a distortion limit of 6, 100-best translation options, MBR decoding (Kumar and Byrne, 2004), Cube Pruning (Huang and Chiang, 2007), and the no-reordering-overpunctuation heuristic. We tuned with the k-best batch MIRA (Cherry and Foster, 2012).5 Transliteration Miner: The miner extracts transliterations from a word-aligned parallel corpus. We only used word pairs with 1-to-1 alignments.6 Before feeding the list into the miner, we cleaned it by removing digits, symbols, word pairs where source or target is composed from less than 3 characters, and words containing foreign characters that do not belong to this scripts. We ran the miner with 10 iterations of EM. The number of transliter</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William J. Byrne. 2004. Minimum Bayes-Risk Decoding for Statistical Machine Translation. In HLT-NAACL, pages 169–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Mitesh M Khapra</author>
<author>Haizhou Li</author>
</authors>
<title>Whitepaper of news 2010 shared task on transliteration mining.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<pages>29--38</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="12218" citStr="Kumaran et al., 2010" startWordPosition="1888" endWordPosition="1891">ng to this scripts. We ran the miner with 10 iterations of EM. The number of transliteration pairs (types) extracted for each language pair is shown in Table 1 (Mraintr). Transliteration System: Before evaluating our integrations into the SMT system, we performed an intrinsic evaluation of the transliteration system that we built from the mined pairs. We formed test data for Arabic–English (1799 pairs), Hindi– English (2394 pairs) and Russian–English (1859 pairs) by concatenating the seed data and gold standard transliteration pairs both provided for the Shared Task on Transliteration mining (Kumaran et al., 2010). Table 2 shows precision and recall of the mined transliteration system (MTS). Precision (1-best Accuracy) 20.0% 25.3% 46.1% Recall (100-best Accuracy) 80.2% 79.3% 87.5% Table 2: Precision and Recall of MTS The precision (1-best accuracy) of the transliteration model is quite low. This is because the transliteration corpus is noisy and contains imperfect transliteration pairs. For example, the miner extracted the pair ( , Australasia), while the correct transliteration is “Australia”. We can improve the precision by tightening the mining threshold probability. However, our end goal is to impr</context>
</contexts>
<marker>Kumaran, Khapra, Li, 2010</marker>
<rawString>A Kumaran, Mitesh M. Khapra, and Haizhou Li. 2010. Whitepaper of news 2010 shared task on transliteration mining. In Proceedings of the 2010 Named Entities Workshop, pages 29–38, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jae-Sung Lee</author>
<author>Key-Sun Choi</author>
</authors>
<title>English to Korean Statistical Transliteration for Information Retrieval.</title>
<date>1998</date>
<booktitle>Computer Processing of Oriental Languages,</booktitle>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="4924" citStr="Lee and Choi, 1998" startWordPosition="733" endWordPosition="736">on training pairs. It is, however, fair to assume that any parallel data would contain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteration pairs compared to the probabilities assigned by a nontransliteration model to the same pairs. Consider a word pair (e, f), the transliteration model probability for the word pair is defined as follows: ptr(e, f) _ E � |a |p(qj) a∈Align(e,f) j=1 where Align(e, f)</context>
</contexts>
<marker>Lee, Choi, 1998</marker>
<rawString>Jae-Sung Lee and Key-Sun Choi. 1998. English to Korean Statistical Transliteration for Information Retrieval. Computer Processing of Oriental Languages, 12(1):17–37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wen-Pin Lin</author>
<author>Matthew Snover</author>
<author>Heng Ji</author>
</authors>
<title>Unsupervised Language-Independent Name Translation Mining from Wikipedia Infoboxes.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP,</booktitle>
<pages>43--52</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="4964" citStr="Lin et al., 2011" startWordPosition="741" endWordPosition="744">o assume that any parallel data would contain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteration pairs compared to the probabilities assigned by a nontransliteration model to the same pairs. Consider a word pair (e, f), the transliteration model probability for the word pair is defined as follows: ptr(e, f) _ E � |a |p(qj) a∈Align(e,f) j=1 where Align(e, f) is the set of all possible sequences of</context>
</contexts>
<marker>Lin, Snover, Ji, 2011</marker>
<rawString>Wen-Pin Lin, Matthew Snover, and Heng Ji. 2011. Unsupervised Language-Independent Name Translation Mining from Wikipedia Infoboxes. In Proceedings of the First workshop on Unsupervised Learning in NLP, pages 43–52, Edinburgh, Scotland, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>301--305</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="1518" citStr="Nakov and Tiedemann, 2012" startWordPosition="210" endWordPosition="213">ion (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required to build a transliteration system, is not readily available for many language pairs. Even if such a training data is available, mechanisms to integrate transliterated words into MT pipelines are unavailable in these toolkits. Generally, a supervised transliteration system is trained separately </context>
</contexts>
<marker>Nakov, Tiedemann, 2012</marker>
<rawString>Preslav Nakov and J¨org Tiedemann. 2012. Combining Word-Level and Character-Level Models for Machine Translation Between Closely-Related Languages. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 301–305, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="10070" citStr="Och and Ney, 2003" startWordPosition="1556" endWordPosition="1559">alf for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses system replicating the settings used in competition-grade systems (Durrani et al., 2013b; Birch et al., 2013): a maximum sentence length of 80, GDFA symmetrization of GIZA++ alignments (Och and Ney, 2003), an interpolated Kneser-Ney smoothed 5- gram language model with KenLM (Heafield, 2011) used at runtime, a 5-gram OSM (Durrani et al., 2013a), msd-bidirectional-fe lexical3Method 3 is desirable in cases where the decoder can translate or transliterate a word. For example Hindi word can be translated to “Border” and also transliterated to name “Seema”. Identifying such candidates that can be translated or transliterated is a challenge. Machine learning techniques (Goldwasser and Roth, 2008; Kirschenbaum and Wintner, 2009) and named entity recognizers (Klementiev and Roth, 2006; Hermjakob et al</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>311--318</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="13504" citStr="Papineni et al., 2002" startWordPosition="2095" endWordPosition="2098">d that recall is more important than precision for overall MT quality. We provide an empirical justification for this when discussing the final experiments. 5Retuning the transliteration features was not helpful, default weights are used. 6M-N/1-N alignments are less likely to be transliterations. AR HI RU Lang Traint. Traint, Dev Test, Testa AR 152K 24K BN 79K FA 39K HI 2M RU 45K TE 87K UR 150 MT Experiments: Table 3 gives a comprehensive evaluation of the three methods of integration discussed in Section 4 along with the number7 of OOV words (types) in different tests. We report BLEU gains (Papineni et al., 2002) obtained by each method. Method 1 (M1), that replaces OOV words with 1-best transliteration gave an average improvement of +0.13. This result can be attributed to the low precision of the transliteration system (Table 2). Method 2 (M2), that transliterates OOVs in second pass monotonic decoding, gave an average improvement of +0.39. Slightly higher gains were obtained using Method 3 (M3), that integrates transliteration phrase-table inside decoder on the fly. However, the efficacy of M3 in comparison to M2 is not as apparent, as M2 produced better results than M3 in half of the cases. HI jhu1</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 311–318, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Post</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Constructing Parallel Corpora for Six Indian Languages via Crowdsourcing.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>401--409</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="9266" citStr="Post et al., 2012" startWordPosition="1416" endWordPosition="1419"> i=1 pF(fi) pE(ei) � |e| i=1 149 use the decoding-graph-backoff option in Moses, that allows multiple translation phrase tables and back-off models. As in method 2, we also use the LM-OOV feature in method 3.3 5 Evaluation Data: We experimented with 7 language pairs, namely: Arabic, Bengali, Farsi, Hindi, Russian, Telugu and Urdu-into-English. For Arabic4 and Farsi, we used the TED talks data (Cettolo et al., 2012) made available for IWSLT-13, and we used the dev2010 set for tuning and the test2011 and test2012 sets for evaluation. For Indian languages we used the Indic multi-parallel corpus (Post et al., 2012), and we used the dev and test sets provided with the parallel corpus. For Russian, we used WMT-13 data (Bojar et al., 2013), and we used half of the news-test2012 for tuning and other half for testing. We also evaluated on the newstest2013 set. For all, we trained the language model using the monolingual WMT-13 data. See Table 1 for data statistics. 6795 887 1434 1704 1916 775 1000 4039 852 1185 1116 4719 1000 1000 302K 1501 1502 3000 4924 1000 1000 9131 980 883 Table 1: No. of sentences in Training Data and Mined Transliteration Corpus (Types) (Mraintr) Baseline Settings: We trained a Moses </context>
</contexts>
<marker>Post, Callison-Burch, Osborne, 2012</marker>
<rawString>Matt Post, Chris Callison-Burch, and Miles Osborne. 2012. Constructing Parallel Corpora for Six Indian Languages via Crowdsourcing. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 401–409, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Conference of the Association for Computational Linguistics,</booktitle>
<location>Portland, USA.</location>
<contexts>
<context position="4945" citStr="Sajjad et al., 2011" startWordPosition="737" endWordPosition="740">t is, however, fair to assume that any parallel data would contain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteration pairs compared to the probabilities assigned by a nontransliteration model to the same pairs. Consider a word pair (e, f), the transliteration model probability for the word pair is defined as follows: ptr(e, f) _ E � |a |p(qj) a∈Align(e,f) j=1 where Align(e, f) is the set of all po</context>
</contexts>
<marker>Sajjad, Fraser, Schmid, 2011</marker>
<rawString>Hassan Sajjad, Alexander Fraser, and Helmut Schmid. 2011. An Algorithm for Unsupervised Transliteration Mining with an Application to Word Alignment. In Proceedings of the 49th Annual Conference of the Association for Computational Linguistics, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Conference of the Association for Computational Linguistics,</booktitle>
<location>Jeju,</location>
<contexts>
<context position="5009" citStr="Sajjad et al. (2012)" startWordPosition="750" endWordPosition="753">ain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteration pairs compared to the probabilities assigned by a nontransliteration model to the same pairs. Consider a word pair (e, f), the transliteration model probability for the word pair is defined as follows: ptr(e, f) _ E � |a |p(qj) a∈Align(e,f) j=1 where Align(e, f) is the set of all possible sequences of character alignments, a is one alignment seq</context>
<context position="6285" citStr="Sajjad et al. (2012)" startWordPosition="949" endWordPosition="952">ration model deals with the word pairs that have no character relationship between them. It is modeled by multiplying source and target character unigram models: pntr(e, f) _ The transliteration mining model is defined as an interpolation of the transliteration sub-model and the non-transliteration sub-model: p(e, f) _ (1 − λ)ptr(e, f) + λpntr(e, f) λ is the prior probability of non-transliteration. The non-transliteration model does not change during training. We compute it in a pre-processing step. The transliteration model learns character alignment using expectation maximization (EM). See Sajjad et al. (2012) for more details. 3 Transliteration Model Now that we have transliteration word pairs, we can learn a transliteration model. We segment the training corpus into characters and learn a phrasebased system over character pairs. The transliteration model assumes that source and target characters are generated monotonically.1 Therefore we do not use any reordering models. We use 4 basic phrase-translation features (direct, inverse phrasetranslation, and lexical weighting features), language model feature (built from the target-side of mined transliteration corpus), and word and phrase penalties. T</context>
</contexts>
<marker>Sajjad, Fraser, Schmid, 2012</marker>
<rawString>Hassan Sajjad, Alexander Fraser, and Helmut Schmid. 2012. A Statistical Model for Unsupervised and Semi-supervised Transliteration Mining. In Proceedings of the 50th Annual Conference of the Association for Computational Linguistics, Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek Sherif</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Bootstrapping a Stochastic Transducer for Arabic-English Transliteration Extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="4660" citStr="Sherif and Kondrak, 2007" startWordPosition="693" endWordPosition="696">ssociation for Computational Linguistics, pages 148–153, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics 2 Transliteration Mining The main bottleneck in building a transliteration system is the lack of availability of transliteration training pairs. It is, however, fair to assume that any parallel data would contain a reasonable number of transliterated word pairs. Transliteration mining can be used to extract such word pairs from the parallel corpus. Most previous techniques on transliteration mining generally use supervised and semi-supervised methods (Sherif and Kondrak, 2007; Jiampojamarn et al., 2010; Darwish, 2010; Kahki et al., 2012). This constrains the mining solution to language pairs for which training data (seed data) is available. A few researchers proposed unsupervised approaches to mine transliterations (Lee and Choi, 1998; Sajjad et al., 2011; Lin et al., 2011). We adapted the work of Sajjad et al. (2012) as summarized below. Model: The transliteration mining model is a mixture of two sub-models, namely: a transliteration and a non-transliteration sub-model. The idea is that the transliteration model would assign higher probabilities to transliteratio</context>
</contexts>
<marker>Sherif, Kondrak, 2007</marker>
<rawString>Tarek Sherif and Grzegorz Kondrak. 2007. Bootstrapping a Stochastic Transducer for Arabic-English Transliteration Extraction. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Nguyen Bach</author>
<author>Ian Lane</author>
<author>Stephan Vogel</author>
</authors>
<title>A Log-Linear Block Transliteration Model based on Bi-Stream HMMs.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<location>Rochester, New York.</location>
<contexts>
<context position="1224" citStr="Zhao et al., 2007" startWordPosition="164" endWordPosition="167">ns, we observed improvements from 0.23-0.75 (Δ 0.41) BLEU points across 7 language pairs. We also show that our mined transliteration corpora provide better rule coverage and translation quality compared to the gold standard transliteration corpora. 1 Introduction All machine translation (MT) systems suffer from the existence of out-of-vocabulary (OOV) words, irrespective of the amount of data available for training. OOV words are mostly named entities, technical terms or foreign words that can be translated to the target language using transliteration. Much work (Al-Onaizan and Knight, 2002; Zhao et al., 2007; Kashani et al., 2007; Habash, 2009) has been done on transliterating named entities and OOVs, and transliteration has been shown to improve MT quality. Transliteration has also shown to be useful for translating closely related language pairs (Durrani et al., 2010; Nakov and Tiedemann, 2012), and for disambiguation (Hermjakob et al., 2008; Azab et al., 2013). However, despite its utility, a transliteration module does not exist in the commonly used MT toolkits, such as Moses (Koehn et al., 2007). One of the main reasons is that the training data, a corpus of transliteration pairs, required t</context>
</contexts>
<marker>Zhao, Bach, Lane, Vogel, 2007</marker>
<rawString>Bing Zhao, Nguyen Bach, Ian Lane, and Stephan Vogel. 2007. A Log-Linear Block Transliteration Model based on Bi-Stream HMMs. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, Rochester, New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>