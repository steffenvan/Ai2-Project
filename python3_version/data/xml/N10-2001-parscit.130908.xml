<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003392">
<title confidence="0.977884">
Camtology: Intelligent Information Access for Science
</title>
<author confidence="0.9923625">
Ted Briscoe1,2, Karl Harrison5, Andrew Naish-Guzman4, Andy Parker1,
Advaith Siddharthan3, David Sinclair4, Mark Slater5 and Rebecca Watson2
</author>
<affiliation confidence="0.997917">
&apos;University of Cambridge 2iLexIR Ltd 4Camtology Ltd 5University of Birmingham
</affiliation>
<email confidence="0.699502666666667">
ejb1@cl.cam.ac.uk, rfw@ilexir.co.uk david.sinclair@imense.co.uk, kh@hep.ph.bham.ac.uk,
parker@hep.phy.cam.ac.uk, 3University of Aberdeen a.naish@gmail.com mws@hep.ph.bham.ac.uk
advaith@abdn.ac.uk
</email>
<sectionHeader confidence="0.993678" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947727272727">
We describe a novel semantic search engine
for scientific literature. The Camtology sys-
tem allows for sentence-level searches of PDF
files and combines text and image searches,
thus facilitating the retrieval of information
present in tables and figures. It allows the user
to generate complex queries for search terms
that are related through particular grammati-
cal/semantic relations in an intuitive manner.
The system uses Grid processing to parallelise
the analysis of large numbers of papers.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999154375">
Scientific, technological, engineering and medi-
cal (STEM) research is entering the so-called 4th
Paradigm of “data-intensive scientific discovery”, in
which advanced data mining and pattern discovery
techniques need to be applied to vast datasets in or-
der to drive further discoveries. A key component
of this process is efficient search and exploitation of
the huge repository of information that only exists in
textual or visual form within the “bibliome”, which
itself continues to grow exponentially.
Today’s computationally driven research methods
have outgrown traditional methods of searching for
scientific data, creating a widespread and unfulfilled
need for advanced search and information extrac-
tion. Camtology combines text and image process-
ing to create a unique solution to this problem.
</bodyText>
<sectionHeader confidence="0.994304" genericHeader="introduction">
2 Status
</sectionHeader>
<bodyText confidence="0.997517">
Camtology has developed a search and information
extraction system which is currently undergoing us-
ability testing with the curation team for FlyBase1,
a $1m/year NIH-funded curated database covering
the functional genomics of the fruit fly. To provide
a scalable solution capable of analysing the entire
STEM bibliome of over 20m electronic journal and
</bodyText>
<footnote confidence="0.944396">
1http://flybase.org/
</footnote>
<bodyText confidence="0.999736578947369">
conference papers, we have developed a robust sys-
tem that can be used with a grid of computers run-
ning distributed job management software.
This system has been deployed and tested using
a subset of the resources provided by the UK Grid
for Particle Physics (Britton et al., 2009), part of the
worldwide Grid of around 200000 CPU cores as-
sembled to allow analysis of the petabyte-scale data
volumes to be recorded each year by experiments at
the Large Hadron Collider in Geneva. Processing
of the FlyBase archive of around 15000 papers re-
quired about 8000 hours of CPU time, and has been
successfully completed in about 3 days, with up to a
few hundred jobs run in parallel. A distributed spi-
der for collecting open-source PDF documents has
also been developed. This has been run concurrently
on over 2000 cores cores, and has been used to re-
trieve over 350000 subject-specific papers, but these
are not considered in the present demo.
</bodyText>
<sectionHeader confidence="0.997922" genericHeader="method">
3 Functionality
</sectionHeader>
<bodyText confidence="0.999744166666667">
Camtology’s search and extraction engine is the first
to integrate a full structural analysis of a scientific
paper in PDF format (identifying headings, sections,
captions and associated figures, citations and ref-
erences) with a sentence-by-sentence grammatical
analysis of the text and direct visual search over
figures. Combining these capabilities allows us to
transform paper search from keyword based paper
retrieval, where the end result is a set of putatively
relevant PDF files which need to be read, to informa-
tion extraction based on the ability to interactively
specify a rich variety of linguistic patterns which
return sentences in specific document locales, and
which combine text with image-based constraints;
for instance:
“all sentences in figure captions which contain
any gene name as the theme of the action ‘ex-
press’ where the figure is a picture of an eye”
</bodyText>
<page confidence="0.698614">
1
</page>
<subsubsectionHeader confidence="0.358613">
Proceedings of the NAACL HLT 2010: Demonstration Session, pages 1–4,
</subsubsectionHeader>
<bodyText confidence="0.977969628571428">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
Camtology allows the user to build up such com-
plex queries quickly though an intuitive process of
query refinement.
Figures often convey information crucial to the
understanding of the content of a paper and are typ-
ically not available to search. Camtology’s search
engine integrates text search to the figure and cap-
tion level with the ability to re-rank search returns on
the basis of visual similarity to a chosen archetype
(ambiguities in textual relevance are often resolved
by visual appearance). Figure 1 provides a compact
overview of the search functionality supported by
our current demonstrator. Interactively, constructing
and running such complex queries takes a few sec-
onds in our intuitive user interface, and allows the
user to quickly browse and then aggregate informa-
tion across the entire collection of papers indexed by
the system. For instance, saving the search result
from the example above would yield a computer-
readable list of gene names involved in eye develop-
ment (in fruit flies in our demonstrator) in a second
or so. With existing web portals and keyword based
selection of PDF files (for example, Google Scholar,
ScienceDirect, DeepDyve or PubGet), a query like
this would typically take many hours to open and
read each one, using cut and paste to extract gene
names (and excludes the possibility of ordering re-
sults on a visual basis). The only other alterna-
tive would require expensive bespoke adaptation of
a text mining system by IT professionals using li-
censed software (such as Ariadne Genomics, Temis
or Linguamatics). This option is only available to a
tiny minority of researchers working for large well-
funded corporations.
</bodyText>
<sectionHeader confidence="0.988829" genericHeader="method">
4 Summary of Technology
</sectionHeader>
<subsectionHeader confidence="0.997393">
4.1 PDF to SciXML
</subsectionHeader>
<bodyText confidence="0.998069354838709">
The PDF format represents a document in a
manner designed to facilitate printing. In short,
it provides information on font and position for
textual and graphical units. To enable informa-
tion retrieval and extraction, we need to convert
this typographic representation into a logical one
that reflects the structure of scientific documents.
We use an XML schema called SciXML (first
introduced in Teufel et al. (1999)) that we extend
to include images. We linearise the textual ele-
ments in the PDF, representing these as &lt;div&gt;
elements in XML and classify these divisions as
{Title|Author|Affiliation|Abstract|Footnote|Caption|
Heading|Citation |References|Text} in a constraint
satisfaction framework.
In addition, we identify all graphics in the PDF,
including lines and images. We then identify ta-
bles by looking for specific patterns of text and
lines. A bounding box is identified for a table and
an image is generated that overlays the text on the
lines. Similarly we overlay text onto images that
have been identified and identify bounding boxes
for figures. This representation allows us to re-
trieve figures and tables that consist of text and
graphics. Once bounding boxes for tables or fig-
ures have been identified, we identify a one-to-one
association between captions and boxes that min-
imises the total distance between captions and their
associated figures or tables. The image is then ref-
erenced from the caption using a “SRC” attribute;
for example, in (abbreviated for space constraints):
</bodyText>
<equation confidence="0.610764">
&lt;CAPTION SRC=
”FBrf0174566 fig 6 o.png”&gt;
</equation>
<bodyText confidence="0.968401">
&lt;b&gt;Fig. 6. &lt;/b&gt; Phenotypic
analysis of denticle belt fusions
during embryogenesis. (A)
The denticle belt fusion phe-
notype resulted in folds around
the surrounding fused... ...(G)
...the only cuticle phenotype
of the DN-EGFR-expressing
embryos was strong denticle
belt fusions in alternating
parasegments (&lt;i&gt;paired
&lt;/i&gt;domains).&lt;/CAPTION&gt;
Note how informative the caption is, and the value
of being able to search this caption in conjunction
with the corresponding image (also shown above).
</bodyText>
<subsectionHeader confidence="0.992321">
4.2 Natural Language Processing
</subsectionHeader>
<bodyText confidence="0.999991">
Every sentence, including those in abstracts, titles
and captions, is run through our named-entity recog-
niser and syntactic parser. The output of these sys-
tems is then indexed, enabling semantic search.
</bodyText>
<subsectionHeader confidence="0.954959">
Named Entity Recognition
</subsectionHeader>
<bodyText confidence="0.999921727272727">
NER in the biomedical domain was implemented
as described in Vlachos (2007). Gene Mention
tagging was performed using Conditional Random
Fields and syntactic parsing, using features derived
from grammatical relations to augment the tagging.
We also use a probabilistic model for resolution of
non-pronominal anaphora in biomedical texts. The
model focuses on biomedical entities and seeks to
find the antecedents of anaphora, both coreferent
and associative ones, and also to identify discourse-
new expressions (Gasperin and Briscoe, 2008).
</bodyText>
<page confidence="0.984282">
2
</page>
<subsectionHeader confidence="0.773259">
Parsing
</subsectionHeader>
<bodyText confidence="0.999937625">
The RASP toolkit (Briscoe et al., 2006) is used
for sentence boundary detection, tokenisation, PoS
tagging and finding grammatical relations (GR) be-
tween words in the text. GRs are triplets consisting
of a relation-type and two arguments and also en-
code morphology, word position and part-of-speech;
for example, parsing “John likes Mary.” gives us a
subject relation and a direct object relation:
</bodyText>
<equation confidence="0.9825805">
(|ncsubj ||like+s:2 VVZ ||John:1 NP1|)
(|dobj ||like+s:2 VVZ ||Mary:3 NP1|)
</equation>
<bodyText confidence="0.997397333333333">
Representing a parse as a set of flat triplets allows
us to index on grammatical relations, thus enabling
complex relational queries.
</bodyText>
<subsectionHeader confidence="0.998439">
4.3 Image Processing
</subsectionHeader>
<bodyText confidence="0.999981083333333">
We build a low-dimensional feature vector to sum-
marise the content of each extracted image. Colour
and intensity histograms are encoded in a short bit
string which describes the image globally; this is
concatenated with a description of the image derived
from a wavelet decomposition (Jacobs et al., 1995)
that captures finer-scale edge information. Efficient
similar image search is achieved by projecting these
feature vectors onto a small number of randomly-
generated hyperplanes and using the signs of the
projections as a key for locality-sensitive hashing
(Gionis et al., 1999).
</bodyText>
<subsectionHeader confidence="0.999466">
4.4 Indexing and Search
</subsectionHeader>
<bodyText confidence="0.995277558139535">
We use Lucene (Goetz, 2002) for indexing and re-
trieving sentences and images. Lucene is an open
source indexing and information retrieval library
that has been shown to scale up efficiently and han-
dle large numbers of queries. We index using fields
derived from word-lemmas, grammatical relations
and named entities. At the same time, these complex
representations are hidden from the user, who, as a
first step, performs a simple keyword search; for ex-
ample “express Vnd”. This returns all sentences that
contain the words “express” and “Vnd” (search is
on lemmatised words, so morphological variants of
“express” will be retrieved). Different colours rep-
resent different types of biological entities and pro-
cesses (green for a gene), and blue shows the entered
search terms in the result sentences. An example
sentence retrieved for the above query follows:
It is possible that like ac , sc and l’sc
vnd is expressed initially in cell clusters and
then restricted to single cells .
Next, the user can select specific words in the
returned sentences to indirectly specify a relation.
Clicking on a word will select it, indicated by un-
derlining of the word. In the example above, the
words “vnd” and “expressed” have been selected by
the user. This creates a new query that returns sen-
tences where “vnd” is the subject of “express” and
the clause is in passive voice. This retrieval is based
on a sophisticated grammatical analysis of the text,
and can retrieve sentences where the words in the
relation are far apart. An example of a sentence re-
trieved for the refined query is shown below:
First , vnd might be spatially regulated in a
manner similar to ac and sc and selectively
expressed in these clusters .
Camtology offers two other functionalities. The
user can browse the MeSH (Medical Subject Head-
ings) ontology and retrieve papers relevant to a
MeSH term. Also, for both search and MeSH brows-
ing, retrieved papers are plotted on a world map; this
is done by converting the affiliations of the authors
into geospatial coordinates. The user can then di-
rectly access papers from a particular site.
</bodyText>
<sectionHeader confidence="0.989527" genericHeader="method">
5 Script Outline
</sectionHeader>
<bodyText confidence="0.698888">
I Quick overview of existing means of searching sci-
ence (PubMed, FlyBase, Google Scholar).
II Walk through the functionality of Camtology (these
are numbered in Figure 1:
</bodyText>
<listItem confidence="0.9553023">
• (1) Initial query through textual search box; (2)
Retrieval of relevant sentences; (3) Query re-
finement by clicking on words; (4) Using im-
plicit grammatical relations for new search;
• Alternative to search: (5) Browse MeSH On-
tology to retrieve papers with MeSH terms.
• (6) Specifically searching for tables/figures
• (7) Viewing the affiliation of the authors of re-
trieved papers on a world map.
• (8) Image search using similarity of image.
</listItem>
<sectionHeader confidence="0.998684" genericHeader="conclusions">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.997008">
This work was supported in part by a STFC miniP-
IPSS grant to the University of Cambridge and
iLexIR Ltd.
</bodyText>
<sectionHeader confidence="0.999395" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9989152">
T. Briscoe, J. Carroll, and R. Watson. 2006. The second
release of the RASP system. In Proc. ACL 2006.
D. Britton, AJ Cass, PEL Clarke, et al. 2009. GridPP:
the UK grid for particle physics. Philosophical Trans-
actions A, 367(1897):2447.
</reference>
<page confidence="0.9750055">
,
3
</page>
<reference confidence="0.990607722222222">
C. Gasperin and T. Briscoe. 2008. Statistical anaphora
resolution in biomedical texts. In Proc. COLING’08.
A. Gionis, P. Indyk, and R. Motwani. 1999. Similarity
search in high dimensions via hashing. In Proc. 25th
ACM Internat. Conf. on Very Large Data Bases.
B. Goetz. 2002. The Lucene search engine: Powerful,
flexible, and free. Javaworld http://www. javaworld.
com/javaworld/jw-09-2000/jw-0915-lucene. html.
C.E. Jacobs, A. Finkelstein, and D.H. Salesin. 1995. Fast
multiresolution image querying. In Proc. 22nd ACM
annual conference on Computer graphics and interac-
tive techniques.
S. Teufel, J. Carletta, and M. Moens. 1999. An annota-
tion scheme for discourse-level argumentation in re-
search articles. In Proc. EACL’99.
A. Vlachos. 2007. Tackling the BioCreative2 gene men-
tion task with CRFs and syntactic parsing. In Proc.
2nd BioCreative Challenge Evaluation Workshop.
</reference>
<figureCaption confidence="0.998764">
Figure 1: Screenshots showing functionality of the Camtology search engine.
</figureCaption>
<page confidence="0.987651">
4
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.705806">
<title confidence="0.999405">Camtology: Intelligent Information Access for Science</title>
<author confidence="0.9971835">Karl Andrew Andy David Mark</author>
<author confidence="0.9971835">Rebecca</author>
<affiliation confidence="0.98163">of Cambridge Ltd Ltd of Birmingham</affiliation>
<address confidence="0.827969">ejb1@cl.cam.ac.uk, rfw@ilexir.co.uk david.sinclair@imense.co.uk, kh@hep.ph.bham.ac.uk, of Aberdeen a.naish@gmail.com</address>
<email confidence="0.977735">advaith@abdn.ac.uk</email>
<abstract confidence="0.99587925">We describe a novel semantic search engine for scientific literature. The Camtology system allows for sentence-level searches of PDF files and combines text and image searches, thus facilitating the retrieval of information present in tables and figures. It allows the user to generate complex queries for search terms that are related through particular grammatical/semantic relations in an intuitive manner. The system uses Grid processing to parallelise the analysis of large numbers of papers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Briscoe</author>
<author>J Carroll</author>
<author>R Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proc. ACL</booktitle>
<contexts>
<context position="8757" citStr="Briscoe et al., 2006" startWordPosition="1325" endWordPosition="1328">earch. Named Entity Recognition NER in the biomedical domain was implemented as described in Vlachos (2007). Gene Mention tagging was performed using Conditional Random Fields and syntactic parsing, using features derived from grammatical relations to augment the tagging. We also use a probabilistic model for resolution of non-pronominal anaphora in biomedical texts. The model focuses on biomedical entities and seeks to find the antecedents of anaphora, both coreferent and associative ones, and also to identify discoursenew expressions (Gasperin and Briscoe, 2008). 2 Parsing The RASP toolkit (Briscoe et al., 2006) is used for sentence boundary detection, tokenisation, PoS tagging and finding grammatical relations (GR) between words in the text. GRs are triplets consisting of a relation-type and two arguments and also encode morphology, word position and part-of-speech; for example, parsing “John likes Mary.” gives us a subject relation and a direct object relation: (|ncsubj ||like+s:2 VVZ ||John:1 NP1|) (|dobj ||like+s:2 VVZ ||Mary:3 NP1|) Representing a parse as a set of flat triplets allows us to index on grammatical relations, thus enabling complex relational queries. 4.3 Image Processing We build a</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>T. Briscoe, J. Carroll, and R. Watson. 2006. The second release of the RASP system. In Proc. ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Britton</author>
<author>AJ Cass</author>
<author>PEL Clarke</author>
</authors>
<title>GridPP: the UK grid for particle physics.</title>
<date>2009</date>
<journal>Philosophical Transactions A,</journal>
<volume>367</volume>
<issue>1897</issue>
<contexts>
<context position="2456" citStr="Britton et al., 2009" startWordPosition="340" endWordPosition="343">nd information extraction system which is currently undergoing usability testing with the curation team for FlyBase1, a $1m/year NIH-funded curated database covering the functional genomics of the fruit fly. To provide a scalable solution capable of analysing the entire STEM bibliome of over 20m electronic journal and 1http://flybase.org/ conference papers, we have developed a robust system that can be used with a grid of computers running distributed job management software. This system has been deployed and tested using a subset of the resources provided by the UK Grid for Particle Physics (Britton et al., 2009), part of the worldwide Grid of around 200000 CPU cores assembled to allow analysis of the petabyte-scale data volumes to be recorded each year by experiments at the Large Hadron Collider in Geneva. Processing of the FlyBase archive of around 15000 papers required about 8000 hours of CPU time, and has been successfully completed in about 3 days, with up to a few hundred jobs run in parallel. A distributed spider for collecting open-source PDF documents has also been developed. This has been run concurrently on over 2000 cores cores, and has been used to retrieve over 350000 subject-specific pa</context>
</contexts>
<marker>Britton, Cass, Clarke, 2009</marker>
<rawString>D. Britton, AJ Cass, PEL Clarke, et al. 2009. GridPP: the UK grid for particle physics. Philosophical Transactions A, 367(1897):2447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gasperin</author>
<author>T Briscoe</author>
</authors>
<title>Statistical anaphora resolution in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proc. COLING’08.</booktitle>
<contexts>
<context position="8706" citStr="Gasperin and Briscoe, 2008" startWordPosition="1316" endWordPosition="1319">put of these systems is then indexed, enabling semantic search. Named Entity Recognition NER in the biomedical domain was implemented as described in Vlachos (2007). Gene Mention tagging was performed using Conditional Random Fields and syntactic parsing, using features derived from grammatical relations to augment the tagging. We also use a probabilistic model for resolution of non-pronominal anaphora in biomedical texts. The model focuses on biomedical entities and seeks to find the antecedents of anaphora, both coreferent and associative ones, and also to identify discoursenew expressions (Gasperin and Briscoe, 2008). 2 Parsing The RASP toolkit (Briscoe et al., 2006) is used for sentence boundary detection, tokenisation, PoS tagging and finding grammatical relations (GR) between words in the text. GRs are triplets consisting of a relation-type and two arguments and also encode morphology, word position and part-of-speech; for example, parsing “John likes Mary.” gives us a subject relation and a direct object relation: (|ncsubj ||like+s:2 VVZ ||John:1 NP1|) (|dobj ||like+s:2 VVZ ||Mary:3 NP1|) Representing a parse as a set of flat triplets allows us to index on grammatical relations, thus enabling complex </context>
</contexts>
<marker>Gasperin, Briscoe, 2008</marker>
<rawString>C. Gasperin and T. Briscoe. 2008. Statistical anaphora resolution in biomedical texts. In Proc. COLING’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gionis</author>
<author>P Indyk</author>
<author>R Motwani</author>
</authors>
<title>Similarity search in high dimensions via hashing.</title>
<date>1999</date>
<booktitle>In Proc. 25th ACM Internat. Conf. on Very Large Data Bases.</booktitle>
<contexts>
<context position="9929" citStr="Gionis et al., 1999" startWordPosition="1504" endWordPosition="1507">ational queries. 4.3 Image Processing We build a low-dimensional feature vector to summarise the content of each extracted image. Colour and intensity histograms are encoded in a short bit string which describes the image globally; this is concatenated with a description of the image derived from a wavelet decomposition (Jacobs et al., 1995) that captures finer-scale edge information. Efficient similar image search is achieved by projecting these feature vectors onto a small number of randomlygenerated hyperplanes and using the signs of the projections as a key for locality-sensitive hashing (Gionis et al., 1999). 4.4 Indexing and Search We use Lucene (Goetz, 2002) for indexing and retrieving sentences and images. Lucene is an open source indexing and information retrieval library that has been shown to scale up efficiently and handle large numbers of queries. We index using fields derived from word-lemmas, grammatical relations and named entities. At the same time, these complex representations are hidden from the user, who, as a first step, performs a simple keyword search; for example “express Vnd”. This returns all sentences that contain the words “express” and “Vnd” (search is on lemmatised words</context>
</contexts>
<marker>Gionis, Indyk, Motwani, 1999</marker>
<rawString>A. Gionis, P. Indyk, and R. Motwani. 1999. Similarity search in high dimensions via hashing. In Proc. 25th ACM Internat. Conf. on Very Large Data Bases.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Goetz</author>
</authors>
<title>The Lucene search engine: Powerful, flexible, and free.</title>
<date>2002</date>
<note>Javaworld http://www. javaworld. com/javaworld/jw-09-2000/jw-0915-lucene. html.</note>
<contexts>
<context position="9982" citStr="Goetz, 2002" startWordPosition="1515" endWordPosition="1516">nal feature vector to summarise the content of each extracted image. Colour and intensity histograms are encoded in a short bit string which describes the image globally; this is concatenated with a description of the image derived from a wavelet decomposition (Jacobs et al., 1995) that captures finer-scale edge information. Efficient similar image search is achieved by projecting these feature vectors onto a small number of randomlygenerated hyperplanes and using the signs of the projections as a key for locality-sensitive hashing (Gionis et al., 1999). 4.4 Indexing and Search We use Lucene (Goetz, 2002) for indexing and retrieving sentences and images. Lucene is an open source indexing and information retrieval library that has been shown to scale up efficiently and handle large numbers of queries. We index using fields derived from word-lemmas, grammatical relations and named entities. At the same time, these complex representations are hidden from the user, who, as a first step, performs a simple keyword search; for example “express Vnd”. This returns all sentences that contain the words “express” and “Vnd” (search is on lemmatised words, so morphological variants of “express” will be retr</context>
</contexts>
<marker>Goetz, 2002</marker>
<rawString>B. Goetz. 2002. The Lucene search engine: Powerful, flexible, and free. Javaworld http://www. javaworld. com/javaworld/jw-09-2000/jw-0915-lucene. html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C E Jacobs</author>
<author>A Finkelstein</author>
<author>D H Salesin</author>
</authors>
<title>Fast multiresolution image querying.</title>
<date>1995</date>
<booktitle>In Proc. 22nd ACM annual conference on Computer graphics and interactive techniques.</booktitle>
<contexts>
<context position="9652" citStr="Jacobs et al., 1995" startWordPosition="1463" endWordPosition="1466">arsing “John likes Mary.” gives us a subject relation and a direct object relation: (|ncsubj ||like+s:2 VVZ ||John:1 NP1|) (|dobj ||like+s:2 VVZ ||Mary:3 NP1|) Representing a parse as a set of flat triplets allows us to index on grammatical relations, thus enabling complex relational queries. 4.3 Image Processing We build a low-dimensional feature vector to summarise the content of each extracted image. Colour and intensity histograms are encoded in a short bit string which describes the image globally; this is concatenated with a description of the image derived from a wavelet decomposition (Jacobs et al., 1995) that captures finer-scale edge information. Efficient similar image search is achieved by projecting these feature vectors onto a small number of randomlygenerated hyperplanes and using the signs of the projections as a key for locality-sensitive hashing (Gionis et al., 1999). 4.4 Indexing and Search We use Lucene (Goetz, 2002) for indexing and retrieving sentences and images. Lucene is an open source indexing and information retrieval library that has been shown to scale up efficiently and handle large numbers of queries. We index using fields derived from word-lemmas, grammatical relations </context>
</contexts>
<marker>Jacobs, Finkelstein, Salesin, 1995</marker>
<rawString>C.E. Jacobs, A. Finkelstein, and D.H. Salesin. 1995. Fast multiresolution image querying. In Proc. 22nd ACM annual conference on Computer graphics and interactive techniques.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Teufel</author>
<author>J Carletta</author>
<author>M Moens</author>
</authors>
<title>An annotation scheme for discourse-level argumentation in research articles.</title>
<date>1999</date>
<booktitle>In Proc. EACL’99.</booktitle>
<contexts>
<context position="6288" citStr="Teufel et al. (1999)" startWordPosition="957" endWordPosition="960">re (such as Ariadne Genomics, Temis or Linguamatics). This option is only available to a tiny minority of researchers working for large wellfunded corporations. 4 Summary of Technology 4.1 PDF to SciXML The PDF format represents a document in a manner designed to facilitate printing. In short, it provides information on font and position for textual and graphical units. To enable information retrieval and extraction, we need to convert this typographic representation into a logical one that reflects the structure of scientific documents. We use an XML schema called SciXML (first introduced in Teufel et al. (1999)) that we extend to include images. We linearise the textual elements in the PDF, representing these as &lt;div&gt; elements in XML and classify these divisions as {Title|Author|Affiliation|Abstract|Footnote|Caption| Heading|Citation |References|Text} in a constraint satisfaction framework. In addition, we identify all graphics in the PDF, including lines and images. We then identify tables by looking for specific patterns of text and lines. A bounding box is identified for a table and an image is generated that overlays the text on the lines. Similarly we overlay text onto images that have been ide</context>
</contexts>
<marker>Teufel, Carletta, Moens, 1999</marker>
<rawString>S. Teufel, J. Carletta, and M. Moens. 1999. An annotation scheme for discourse-level argumentation in research articles. In Proc. EACL’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Vlachos</author>
</authors>
<title>Tackling the BioCreative2 gene mention task with CRFs and syntactic parsing.</title>
<date>2007</date>
<booktitle>In Proc. 2nd BioCreative Challenge Evaluation Workshop.</booktitle>
<contexts>
<context position="8243" citStr="Vlachos (2007)" startWordPosition="1252" endWordPosition="1253">the DN-EGFR-expressing embryos was strong denticle belt fusions in alternating parasegments (&lt;i&gt;paired &lt;/i&gt;domains).&lt;/CAPTION&gt; Note how informative the caption is, and the value of being able to search this caption in conjunction with the corresponding image (also shown above). 4.2 Natural Language Processing Every sentence, including those in abstracts, titles and captions, is run through our named-entity recogniser and syntactic parser. The output of these systems is then indexed, enabling semantic search. Named Entity Recognition NER in the biomedical domain was implemented as described in Vlachos (2007). Gene Mention tagging was performed using Conditional Random Fields and syntactic parsing, using features derived from grammatical relations to augment the tagging. We also use a probabilistic model for resolution of non-pronominal anaphora in biomedical texts. The model focuses on biomedical entities and seeks to find the antecedents of anaphora, both coreferent and associative ones, and also to identify discoursenew expressions (Gasperin and Briscoe, 2008). 2 Parsing The RASP toolkit (Briscoe et al., 2006) is used for sentence boundary detection, tokenisation, PoS tagging and finding gramma</context>
</contexts>
<marker>Vlachos, 2007</marker>
<rawString>A. Vlachos. 2007. Tackling the BioCreative2 gene mention task with CRFs and syntactic parsing. In Proc. 2nd BioCreative Challenge Evaluation Workshop.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>