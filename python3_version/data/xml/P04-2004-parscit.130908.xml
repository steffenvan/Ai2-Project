<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000669">
<title confidence="0.996496">
Temporal Context: Applications and Implications
for Computational Linguistics
</title>
<author confidence="0.994368">
Robert A. Liebscher
</author>
<affiliation confidence="0.9984265">
Department of Cognitive Science
University of California, San Diego
</affiliation>
<address confidence="0.947649">
La Jolla, CA 92037
</address>
<email confidence="0.999442">
rliebsch@cogsci.ucsd.edu
</email>
<sectionHeader confidence="0.995649" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998495">
This paper describes several ongoing
projects that are united by the theme of
changes in lexical use over time. We
show that paying attention to a docu-
ment’s temporal context can lead to im-
provements in information retrieval and
text categorization. We also explore a
potential application in document clus-
tering that is based upon different types
of lexical changes.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.95434134">
Tasks in computational linguistics (CL) normally
focus on the content of a document while paying
little attention to the context in which it was pro-
duced. The work described in this paper considers
the importance of temporal context. We show that
knowing one small piece of information–a docu-
ment’s publication date–can be beneficial for a va-
riety of CL tasks, some familiar and some novel.
The field of historical linguistics attempts to cat-
egorize changes at all levels of language use, typ-
ically relying on data that span centuries (Hock,
1991). The recent availability of very large tex-
tual corpora allows for the examination of changes
that take place across shorter time periods. In par-
ticular, we focus on lexical change across decades
in corpora of academic publications and show that
the changes can be fairly dramatic during a rela-
tively short period of time.
As a preview, consider Table 1, which lists the
top five unigrams that best distinguished the field
of computational linguistics at different points in
time, as derived from the ACL proceedings1 using
the odds ratio measure (see Section 3). One can
quickly glean that the field has become increas-
ingly empirical through time.
1979-84 1985-90 1991-96 1997-02
system phrase discourse word
natural plan tree corpus
language structure algorithm training
knowledge logical unification model
database interpret plan data
Table 1: ACL’s most characteristic terms for four
time periods, as measured by the odds ratio
With respect to academic publications, the very
nature of the enterprise forces the language used
within a discipline to change. An author’s word
choice is shaped by the preceding literature, as she
must say something novel while placing her con-
tribution in the context of what has already been
said. This begets neologisms, new word senses,
and other types of changes.
This paper is organized as follows: In Section
2, we introduce temporal term weighting, a tech-
nique that implicitly encodes time into keyword
weights to enhance information retrieval. Section
3 describes the technique of temporal feature mod-
ification, which exploits temporal information to
improve the text categorization task. Section 4 in-
troduces several types of lexical changes and a po-
tential application in document clustering.
</bodyText>
<footnote confidence="0.989131">
1The details of each corpus used in this paper can be found
in the appendix.
</footnote>
<figure confidence="0.921201">
Frequency per 1000
Year
</figure>
<figureCaption confidence="0.999236">
Figure 1: Changing frequencies in AI abstracts
</figureCaption>
<sectionHeader confidence="0.784845" genericHeader="method">
2 Time in information retrieval
</sectionHeader>
<bodyText confidence="0.965090260869565">
In the task of retrieving relevant documents based
upon keyword queries, it is customary to treat
each document as a vector of terms with associ-
ated “weights”. One notion of term weight simply
counts the occurrences of each term. Of more util-
ity is the scheme known as term frequency-inverse
document frequency (TF.IDF):
where is the weight of term k in document
d, is the frequency of k in d, N is the total num-
ber of documents in the corpus, and is the total
number of documents containing k. Very frequent
terms (such as function words) that occur in many
documents are downweighted, while those that are
fairly unique have their weights boosted.
Many variations of TF.IDF have been suggested
(Singhal, 1997). Our variation, temporal term
weighting (TTW), incorporates a term’s IDF at
different points in time:
Under this scheme, the document collection is
divided into T time slices, and N and are com-
puted for each slice t. Figure 1 illustrates why
such a modification is useful. It depicts the fre-
quency of the terms neural networks and ex-
pert system for each year in a collection of Ar-
tificial Intelligence-related dissertation abstracts.
Both terms follow a fairly linear trend, moving in
opposite directions.
As was demonstrated for CL in Section 1,
the terms which best characterize AI have also
changed through time. Table 2 lists the top
five “rising” and “falling” bigrams in this cor-
pus, along with their least-squares fit to a linear
trend. Lexical variants (such as plurals) are omit-
ted. Using an atemporal TF.IDF, both rising and
falling terms would be assigned weights propor-
tional only to . A novice user issuing a query
would be given a temporally random scattering of
documents, some of which might be state-of-the-
art, others very outdated.
But with TTW, the weights are proportional to
the collective “community interest” in the term at
a given point in time. In academic research docu-
ments, this yields two benefits. If a term rises from
obscurity to popularity over the duration of a cor-
pus, it is not unreasonable to assume that this term
originated in one or a few seminal articles. The
term is not very frequent across documents when
these articles are published, so its weight in the
seminal articles will be amplified. Similarly, the
term will be downweighted in articles when it has
become ubiquitous throughout the literature.
For a falling term, its weight in early documents
will be dampened, while its later use will be em-
phasized. If a term is very frequent in a docu-
ment after it has been relegated to obscurity, this
is likely to be an historical review article. Such an
article would be a good place to start an investiga-
tion for someone who is unfamiliar with the term.
Term r
neural network 0.9283
fuzzy logic 0.9035
genetic algorithm 0.9624
real world 0.8509
reinforcement learning 0.8447
artificial intelligence -0.9309
expert system -0.9241
knowledge base -0.9144
problem solving -0.9490
knowledge representation -0.9603
</bodyText>
<tableCaption confidence="0.992957">
Table 2: Rising and falling AI terms, 1986-1997
</tableCaption>
<figure confidence="0.995324166666667">
4
expert system
3
2.5
2
1.5
1
neural networks
0.5
0
1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997
3.5
</figure>
<subsectionHeader confidence="0.528628">
2.1 Future work
</subsectionHeader>
<bodyText confidence="0.9999759375">
We have discovered clear frequency trends over
time in several corpora. Given this, TTW seems
beneficial for use in information retrieval, but is in
an embryonic stage. The next step will be the de-
velopment and implementation of empirical tests.
IR systems typically are evaluated by measures
such as precision and recall, but a different test
is necessary to compare TTW to an atemporal
TF.IDF. One idea we are exploring is to have a
system explicitly tag seminal and historical review
articles that are centered around a query term, and
then compare the results with those generated by
bibliometric methods. Few bibliometric analyses
have gone beyond examinations of citation net-
works and the keywords associated with each arti-
cle. We would consider the entire text.
</bodyText>
<sectionHeader confidence="0.972729" genericHeader="method">
3 Time in text categorization
</sectionHeader>
<bodyText confidence="0.997992236842105">
Text categorization (TC) is the problem of assign-
ing documents to one or more pre-defined cat-
egories. As Section 2 demonstrated, the terms
which best characterize a category can change
through time, so intelligent use of temporal con-
text may prove useful in TC.
Consider the example of sorting newswire doc-
uments into the categories ENTERTAINMENT, BUSI-
NESS, SPORTS, POLITICS, and WEATHER. Suppose
we come across the term athens in a training doc-
ument. We might expect a fairly uniform distri-
bution of this term throughout the five categories;
that is, Cathens = 0.20 for each C. How-
ever, in the summer of 2004, we would expect
SPORTSathens to be greatly increased rela-
tive to the other categories due to the city’s hosting
of the Olympic games.
Documents with “temporally perturbed” terms
like athens contain potentially valuable informa-
tion, but this is lost in a statistical analysis based
purely on the content of each document, irrespec-
tive of its temporal context. This information can
be recovered with a technique we call temporal
feature modification (TFM). We first outline a for-
mal model of its use.
Each term k is assumed to have a generator Gk
that produces a “true” distribution Ck across
all categories. External events at time y can per-
turb k’s generator, causing Ck to be differ-
ent relative to the background Ck computed
over the entire corpus. If the perturbation is sig-
nificant, we want to separate the instances of k
at time y from all other instances. We thus treat
athens and “athens+summer2004” as though they
were actually different terms, because they came
from two different generators.
TFM is a two step process that is captured by
this pseudocode:
</bodyText>
<equation confidence="0.973274166666667">
VOCABULARY ADDITIONS:
for each class C:
for each year y:
PreModList(C,y,L) = OddsRatio(C,y,L)
ModifyList(y) =
DecisionRule(PreModList(C,y,L))
</equation>
<table confidence="0.551861111111111">
for each term k in ModifyList(y):
Add pseudo-term &amp;quot;k+y&amp;quot; to Vocab
DOCUMENT MODIFICATIONS:
for each document:
y = year of doc
for each term k:
if &amp;quot;k+y&amp;quot; in Vocab:
replace k with &amp;quot;k+y&amp;quot;
classify modified document
</table>
<bodyText confidence="0.997047631578947">
PreModList(C,y,L) is a list of the top L lexemes
that, by the odds ratio measure2, are highly asso-
ciated with category C in year y. We test the hy-
pothesis that these come from a perturbed gener-
ator in year y, as opposed to the atemporal gen-
erator Gk, by comparing the odds ratios of term-
category pairs in a PreModList in year y with the
same pairs across the entire corpus. Terms which
pass this test are added to the final ModifyList(y)
for year y. For the results that we report, Decision-
Rule is a simple ratio test with threshold factor f.
Suppose f is 2.0: if the odds ratio between C and
k is twice as great in year y as it is atemporally,
the decision rule is “passed”. The generator Gkis
considered perturbed in year y and k is added to
ModifyList(y). In the training and testing phases,
the documents are modified so that a term k is re-
placed with the pseudo-term “k+y” if it passed the
ratio test.
</bodyText>
<subsectionHeader confidence="0.978231">
3.1 ACM Classifications
</subsectionHeader>
<bodyText confidence="0.9969565">
We tested TFM on corpora representing genres
from academic publications to Usenet postings,
</bodyText>
<footnote confidence="0.907893">
2Odds ratio is defined as , wherep is
</footnote>
<tableCaption confidence="0.3688545">
Pr(k|C), the probability that term k is present given category
C, and q is Pr(k|!C).
</tableCaption>
<table confidence="0.9991954">
Percent accuracy improvement
Corpus Vocab size No. docs No. cats
SIGCHI 4542 1910 20
SIGPLAN 6744 3123 22
DAC 6311 2707 20
</table>
<tableCaption confidence="0.997316">
Table 3: Corpora characteristics. Terms occurring
at least twice are included in the vocabulary.
</tableCaption>
<bodyText confidence="0.999113217391304">
and it improved classification accuracy in every
case. The results reported here are for abstracts
from the proceedings of several of the Asso-
ciation for Computing Machinery’s conferences:
SIGCHI, SIGPLAN, and DAC. TFM can benefit
the ACM community through retrospective cate-
gorization in two ways: (1) 7.73% of abstracts
(nearly 6000) across the entire ACM corpus that
are expected to have category labels do not have
them; (2) When a group of terms becomes popu-
lar enough to induce the formation of a new cat-
egory, a frequent occurrence in the computing lit-
erature, TFM would separate the “old” uses from
the “new” ones.
The ACM classifies its documents in a hierar-
chy of four levels; we used an aggregating pro-
cedure to “flatten” these. The characteristics of
each corpus are described in Table 3. The “TC
minutiae” used in these experiments are: Stoplist,
Porter stemming, 90/10% train/test split, Lapla-
cian smoothing. Parameters such as type of clas-
sifier (Naïve Bayes, KNN, TF.IDF, Probabilistic
indexing) and threshold factor f were varied.
</bodyText>
<subsectionHeader confidence="0.868618">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.9997836">
Figure 2 shows the improvement in classification
accuracy for different percentages of terms mod-
ified, using the best parameter combinations for
each corpus, which are noted in Table 4. A base-
line of 0.0 indicates accuracy without any tempo-
ral modifications. Despite the relative paucity of
data in terms of document length, TFM still per-
forms well on the abstracts. The actual accuracies
when no terms are modified are less than stellar,
ranging from 30.7% (DAC) to 33.7% (SIGPLAN)
when averaged across all conditions, due to the
difficulty of the task (20-22 categories; each doc-
ument can only belong to one). Our aim is simply
to show improvement.
In most cases, the technique performs best when
</bodyText>
<figure confidence="0.995473058823529">
0.45
SIGCHI
0.4
0.35
0.3
DAC
0.25
0.2
0.15
SIGPLAN
0.1
0.05
Atemporal baseline
0
−0.05
0 5 10 15 20 25
Percent terms modified
</figure>
<figureCaption confidence="0.884003">
Figure 2: Improvement in categorization perfor-
mance with TFM, using the best parameter com-
binations for each corpus
</figureCaption>
<bodyText confidence="0.9999485">
making relatively few modifications: the left side
of Figure 2 shows a rapid performance increase,
particularly for SIGCHI, followed by a period of
diminishing returns as more terms are modified.
After requiring the one-time computation of odds
ratios in the training set for each category/year,
TFM is very fast and requires negligible extra stor-
age space.
</bodyText>
<subsectionHeader confidence="0.964119">
3.3 Future work
</subsectionHeader>
<bodyText confidence="0.99987325">
The “bare bones” version of TFM presented here
is intended as a proof-of-concept. Many of the
parameters and procedures can be set arbitrar-
ily. For initial feature selection, we used odds
ratio because it exhibits good performance in TC
(Mladenic, 1998), but it could be replaced by an-
other method such as information gain. The ra-
tio test is not a very sophisticated way to choose
which terms should be modified, and presently
only detects the surges in the use of a term, while
ignoring the (admittedly rare) declines.
Using TFM on a Usenet corpus that was more
balanced in terms of documents per category and
per year, we found that allowing different terms
to “compete” for modification was more effective
than the egalitarian practice of choosing L terms
from each category/year. There is no reason to be-
lieve that each category/year is equally likely to
contribute temporally perturbed terms.
Finally, we would like to exploit temporal con-
</bodyText>
<table confidence="0.99875925">
Corpus Improvement Classifier n-gram size Vocab frequency min. Ratio threshold f
SIGCHI 41.0% TF.IDF Bigram 10 1.0
SIGPLAN 19.4% KNN Unigram 10 1.0
DAC 23.3% KNN Unigram 2 1.0
</table>
<tableCaption confidence="0.982546">
Table 4: Top parameter combinations for TFM by improvement in classification accuracy. Vocab fre-
</tableCaption>
<bodyText confidence="0.97094775">
quency min. is the minimum number of times a term must appear in the corpus in order to be included.
tiguity. The present implementation treats time
slices as independent entities, which precludes the
possibility of discovering temporal trends in the
data. One way to incorporate trends implicitly
is to run a smoothing filter across the temporally
aligned frequencies. Also, we treat each slice at
annual resolution. Initial tests show that aggre-
gating two or more years into one slice improves
performance for some corpora, particularly those
with temporally sparse data such as DAC.
Frequency per 1000 tokens
</bodyText>
<sectionHeader confidence="0.998689" genericHeader="method">
4 Future work
</sectionHeader>
<bodyText confidence="0.999966294117647">
A third part of this research program, presently
in the exploratory stage, concerns lexical (seman-
tic) change, the broad class of phenomena in
which words and phrases are coined or take on
new meanings (Bauer, 1994; Jeffers and Lehiste,
1979). Below we describe an application in doc-
ument clustering and point toward a theoretical
framework for lexical change based upon recent
advances in network analysis.
Consider a scenario in which a user queries
a document database for the term artificial
intelligence. We would like to create a system
that will cluster the returned documents into three
categories, corresponding to the types of change
the query has undergone. These responses illus-
trate the three categories, which are not necessar-
ily mutually exclusive:
</bodyText>
<listItem confidence="0.929520375">
1. “This term is now more commonly referred
to as AI in this collection”,
2. “These documents are about artificial
intelligence, though it is now more com-
monly called machine learning”,
3. “The following documents are about
artificial intelligence, though in this
collection its use has become tacit”.
</listItem>
<figureCaption confidence="0.961997">
Figure 3: Frequencies in the first (left bar) and sec-
ond (right bar) halves of an AI discussion forum
</figureCaption>
<subsectionHeader confidence="0.975416">
4.1 Acronym formation
</subsectionHeader>
<bodyText confidence="0.999547615384615">
In Section 2, we introduced the notions of “ris-
ing” and “falling” terms. Figure 3 shows rela-
tive frequencies of two common terms and their
acronyms in the first and second halves of a cor-
pus of AI discussion board postings collected from
1983-1988. While the acronyms increased in
frequency, the expanded forms decreased or re-
mained the same. A reasonable conjecture is that
in this informal register, the acronyms AI and CS
largely replaced the expansions. During the same
time period, the more formal register of disser-
tation abstracts did not show this pattern for any
acronym/expansion pairs.
</bodyText>
<subsectionHeader confidence="0.973557">
4.2 Lexical replacement
</subsectionHeader>
<bodyText confidence="0.9983932">
Terms can be replaced by their acronyms, or
by other terms. In Table 1, database was
listed among the top five terms that were most
characteristic of the ACL proceedings in 1979-
1984. Bisecting this time slice and including bi-
</bodyText>
<figure confidence="0.996811571428572">
1 2 3 4
3.5
2.5
0.5
1.5
4
3
2
0
1
AI
artificial intelligence
CS
computer science
</figure>
<bodyText confidence="0.9999609">
grams in the analysis, data base ranks higher
than database in 1979-1981, but drops much
lower in 1982-1984. Within this brief period of
time, we see a lexical replacement event taking
hold. In the AI dissertation abstracts, artificial
intelligence shows the greatest decline, while
the conceptually similar terms machine learning
and pattern recognition rank sixth and twelfth
among the top rising terms.
There are social, geographic, and linguistic
forces that influence lexical change. One exam-
ple stood out as having an easily identified cause:
political correctness. In a corpus of dissertation
abstracts on communication disorders from 1982-
2002, the term subject showed the greatest rel-
ative decrease in frequency, while participant
showed the greatest increase. Among the top ten
bigrams showing the sharpest declines were three
terms that included the word impaired and two
that included disabled.
</bodyText>
<subsectionHeader confidence="0.99757">
4.3 “Tacit” vocabulary
</subsectionHeader>
<bodyText confidence="0.999881653846154">
Another, more subtle lexical change involves the
gradual disappearance of terms due to their in-
creasingly “tacit” nature within a particular com-
munity of discourse. Their existence becomes so
obvious that they need not be mentioned within the
community, but would be necessary for an outsider
to fully understand the discourse.
Take, for example, the terms backpropagation
and hidden layer. If a researcher of neural net-
works uses these terms in an abstract, then neural
network does not even warrant printing, because
they have come to imply the presence of neural
network within this research community.
Applied to IR, one might call this “retrieval by
implication”. Discovering tacit terms is no simple
matter, as many of them will not follow simple is-a
relationships (e.g. terrier is a dog). The example
of the previous paragraph seems to contain a hier-
archical relation, but it is difficult to define. We
believe that examining the temporal trajectories of
closely related networks of terms may be of use
here, and is also part of a more general project that
we hope to undertake. Our intention is to improve
existing models of lexical change using recent ad-
vances in network analysis (Barabasi et al., 2002;
Dorogovtsev and Mendes, 2001).
</bodyText>
<sectionHeader confidence="0.996384" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.986083477272727">
A. Barabasi, H. Jeong, Z. Neda, A. Schubert, and
T. Vicsek. 2002. Evolution of the social network of
scientific collaborations. Physica A, 311:590–614.
L. Bauer. 1994. Watching English Change. Longman
Press, London.
S. N. Dorogovtsev and J. F. F. Mendes. 2001. Lan-
guage as an evolving word web. Proceedings of The
Royal Society ofLondon, Series B, 268(1485):2603–
2606.
H. H. Hock. 1991. Principles ofHistorical Lingusitics.
Mouton de Gruyter, Berlin.
R. J. Jeffers and I. Lehiste. 1979. Principles and Meth-
odsfor Historical Lingusitics. The MIT Press, Cam-
bridge, MA.
D. Mladenic. 1998. Machine Learning on non-
homogeneous, distributed text data. Ph.D. thesis,
University of Ljubljana, Slovenia.
A. Singhal. 1997. Term weighting revisited. Ph.D.
thesis, Cornell University.
Appendix: Corpora
The corpora used in this paper, preceded by the
section in which they were introduced:
1: The annual proceedings of the Association
for Computational Linguistics conference (1978-
2002). Accessible at http://acl.ldc.upenn.edu/.
2: Over 5000 PhD and Masters dissertation
abstracts related to Artificial Intelligence, 1986-
1997. Supplied by University Microfilms Inc.
3.1: Abstracts from the ACM-IEEE Design Au-
tomation Conference (DAC; 1964-2002), Special
Interest Groups in Human Factors in Computing
Systems (SIGCHI; 1982-2003) and Programming
Languages (SIGPLAN; 1973-2003). Supplied by
the ACM. See also Table 3.
3.3: Hand-collected corpus of six dis-
cussion groups: misc.consumers, alt.atheism,
rec.arts.books, comp.{arch, graphics.algorithms,
lang.c}. Each group contains 1000 docu-
ments per year from 1993-2002. Viewable at
http://groups.google.com/.
4.2: Over 4000 PhD and Masters disserta-
tion abstracts related to communication disorders,
1982-2002. Supplied by University Microfilms
Inc.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.985623">
<title confidence="0.997308">Temporal Context: Applications and Implications for Computational Linguistics</title>
<author confidence="0.999956">Robert A Liebscher</author>
<affiliation confidence="0.9999785">Department of Cognitive Science University of California, San Diego</affiliation>
<address confidence="0.998223">La Jolla, CA 92037</address>
<email confidence="0.999659">rliebsch@cogsci.ucsd.edu</email>
<abstract confidence="0.999317727272727">This paper describes several ongoing projects that are united by the theme of changes in lexical use over time. We show that paying attention to a document’s temporal context can lead to improvements in information retrieval and text categorization. We also explore a potential application in document clustering that is based upon different types of lexical changes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Barabasi</author>
<author>H Jeong</author>
<author>Z Neda</author>
<author>A Schubert</author>
<author>T Vicsek</author>
</authors>
<title>Evolution of the social network of scientific collaborations.</title>
<date>2002</date>
<pages>311--590</pages>
<publisher>Physica A,</publisher>
<marker>Barabasi, Jeong, Neda, Schubert, Vicsek, 2002</marker>
<rawString>A. Barabasi, H. Jeong, Z. Neda, A. Schubert, and T. Vicsek. 2002. Evolution of the social network of scientific collaborations. Physica A, 311:590–614.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Bauer</author>
</authors>
<date>1994</date>
<publisher>Watching English Change. Longman Press,</publisher>
<location>London.</location>
<contexts>
<context position="14831" citStr="Bauer, 1994" startWordPosition="2457" endWordPosition="2458">emporal trends in the data. One way to incorporate trends implicitly is to run a smoothing filter across the temporally aligned frequencies. Also, we treat each slice at annual resolution. Initial tests show that aggregating two or more years into one slice improves performance for some corpora, particularly those with temporally sparse data such as DAC. Frequency per 1000 tokens 4 Future work A third part of this research program, presently in the exploratory stage, concerns lexical (semantic) change, the broad class of phenomena in which words and phrases are coined or take on new meanings (Bauer, 1994; Jeffers and Lehiste, 1979). Below we describe an application in document clustering and point toward a theoretical framework for lexical change based upon recent advances in network analysis. Consider a scenario in which a user queries a document database for the term artificial intelligence. We would like to create a system that will cluster the returned documents into three categories, corresponding to the types of change the query has undergone. These responses illustrate the three categories, which are not necessarily mutually exclusive: 1. “This term is now more commonly referred to as </context>
</contexts>
<marker>Bauer, 1994</marker>
<rawString>L. Bauer. 1994. Watching English Change. Longman Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Dorogovtsev</author>
<author>J F F Mendes</author>
</authors>
<title>Language as an evolving word web.</title>
<date>2001</date>
<journal>Proceedings of The Royal Society ofLondon, Series B,</journal>
<volume>268</volume>
<issue>1485</issue>
<pages>2606</pages>
<marker>Dorogovtsev, Mendes, 2001</marker>
<rawString>S. N. Dorogovtsev and J. F. F. Mendes. 2001. Language as an evolving word web. Proceedings of The Royal Society ofLondon, Series B, 268(1485):2603– 2606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Hock</author>
</authors>
<title>Principles ofHistorical Lingusitics. Mouton de Gruyter,</title>
<date>1991</date>
<location>Berlin.</location>
<contexts>
<context position="1149" citStr="Hock, 1991" startWordPosition="177" endWordPosition="178">s based upon different types of lexical changes. 1 Introduction Tasks in computational linguistics (CL) normally focus on the content of a document while paying little attention to the context in which it was produced. The work described in this paper considers the importance of temporal context. We show that knowing one small piece of information–a document’s publication date–can be beneficial for a variety of CL tasks, some familiar and some novel. The field of historical linguistics attempts to categorize changes at all levels of language use, typically relying on data that span centuries (Hock, 1991). The recent availability of very large textual corpora allows for the examination of changes that take place across shorter time periods. In particular, we focus on lexical change across decades in corpora of academic publications and show that the changes can be fairly dramatic during a relatively short period of time. As a preview, consider Table 1, which lists the top five unigrams that best distinguished the field of computational linguistics at different points in time, as derived from the ACL proceedings1 using the odds ratio measure (see Section 3). One can quickly glean that the field</context>
</contexts>
<marker>Hock, 1991</marker>
<rawString>H. H. Hock. 1991. Principles ofHistorical Lingusitics. Mouton de Gruyter, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Jeffers</author>
<author>I Lehiste</author>
</authors>
<title>Principles and Methodsfor Historical Lingusitics.</title>
<date>1979</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="14859" citStr="Jeffers and Lehiste, 1979" startWordPosition="2459" endWordPosition="2462">s in the data. One way to incorporate trends implicitly is to run a smoothing filter across the temporally aligned frequencies. Also, we treat each slice at annual resolution. Initial tests show that aggregating two or more years into one slice improves performance for some corpora, particularly those with temporally sparse data such as DAC. Frequency per 1000 tokens 4 Future work A third part of this research program, presently in the exploratory stage, concerns lexical (semantic) change, the broad class of phenomena in which words and phrases are coined or take on new meanings (Bauer, 1994; Jeffers and Lehiste, 1979). Below we describe an application in document clustering and point toward a theoretical framework for lexical change based upon recent advances in network analysis. Consider a scenario in which a user queries a document database for the term artificial intelligence. We would like to create a system that will cluster the returned documents into three categories, corresponding to the types of change the query has undergone. These responses illustrate the three categories, which are not necessarily mutually exclusive: 1. “This term is now more commonly referred to as AI in this collection”, 2. “</context>
</contexts>
<marker>Jeffers, Lehiste, 1979</marker>
<rawString>R. J. Jeffers and I. Lehiste. 1979. Principles and Methodsfor Historical Lingusitics. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mladenic</author>
</authors>
<title>Machine Learning on nonhomogeneous, distributed text data.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Ljubljana, Slovenia.</institution>
<contexts>
<context position="13028" citStr="Mladenic, 1998" startWordPosition="2161" endWordPosition="2162">ively few modifications: the left side of Figure 2 shows a rapid performance increase, particularly for SIGCHI, followed by a period of diminishing returns as more terms are modified. After requiring the one-time computation of odds ratios in the training set for each category/year, TFM is very fast and requires negligible extra storage space. 3.3 Future work The “bare bones” version of TFM presented here is intended as a proof-of-concept. Many of the parameters and procedures can be set arbitrarily. For initial feature selection, we used odds ratio because it exhibits good performance in TC (Mladenic, 1998), but it could be replaced by another method such as information gain. The ratio test is not a very sophisticated way to choose which terms should be modified, and presently only detects the surges in the use of a term, while ignoring the (admittedly rare) declines. Using TFM on a Usenet corpus that was more balanced in terms of documents per category and per year, we found that allowing different terms to “compete” for modification was more effective than the egalitarian practice of choosing L terms from each category/year. There is no reason to believe that each category/year is equally like</context>
</contexts>
<marker>Mladenic, 1998</marker>
<rawString>D. Mladenic. 1998. Machine Learning on nonhomogeneous, distributed text data. Ph.D. thesis, University of Ljubljana, Slovenia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Singhal</author>
</authors>
<title>Term weighting revisited.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Cornell University.</institution>
<contexts>
<context position="3777" citStr="Singhal, 1997" startWordPosition="604" endWordPosition="605"> each document as a vector of terms with associated “weights”. One notion of term weight simply counts the occurrences of each term. Of more utility is the scheme known as term frequency-inverse document frequency (TF.IDF): where is the weight of term k in document d, is the frequency of k in d, N is the total number of documents in the corpus, and is the total number of documents containing k. Very frequent terms (such as function words) that occur in many documents are downweighted, while those that are fairly unique have their weights boosted. Many variations of TF.IDF have been suggested (Singhal, 1997). Our variation, temporal term weighting (TTW), incorporates a term’s IDF at different points in time: Under this scheme, the document collection is divided into T time slices, and N and are computed for each slice t. Figure 1 illustrates why such a modification is useful. It depicts the frequency of the terms neural networks and expert system for each year in a collection of Artificial Intelligence-related dissertation abstracts. Both terms follow a fairly linear trend, moving in opposite directions. As was demonstrated for CL in Section 1, the terms which best characterize AI have also chang</context>
</contexts>
<marker>Singhal, 1997</marker>
<rawString>A. Singhal. 1997. Term weighting revisited. Ph.D. thesis, Cornell University.</rawString>
</citation>
<citation valid="false">
<title>Appendix: Corpora The corpora used in this paper, preceded by the section in which they were introduced: 1: The annual proceedings of the Association for Computational Linguistics conference (1978-2002). Accessible at http://acl.ldc.upenn.edu/.</title>
<marker></marker>
<rawString>Appendix: Corpora The corpora used in this paper, preceded by the section in which they were introduced: 1: The annual proceedings of the Association for Computational Linguistics conference (1978-2002). Accessible at http://acl.ldc.upenn.edu/.</rawString>
</citation>
<citation valid="false">
<title>2: Over 5000 PhD and Masters dissertation abstracts related to Artificial Intelligence, 1986-1997. Supplied by</title>
<booktitle>Inc. 3.1: Abstracts from the ACM-IEEE Design Automation Conference (DAC; 1964-2002), Special Interest Groups in Human Factors in Computing Systems (SIGCHI; 1982-2003) and Programming Languages (SIGPLAN; 1973-2003). Supplied by the ACM. See also Table 3.</booktitle>
<institution>University Microfilms</institution>
<marker></marker>
<rawString>2: Over 5000 PhD and Masters dissertation abstracts related to Artificial Intelligence, 1986-1997. Supplied by University Microfilms Inc. 3.1: Abstracts from the ACM-IEEE Design Automation Conference (DAC; 1964-2002), Special Interest Groups in Human Factors in Computing Systems (SIGCHI; 1982-2003) and Programming Languages (SIGPLAN; 1973-2003). Supplied by the ACM. See also Table 3.</rawString>
</citation>
<citation valid="false">
<title>3.3: Hand-collected corpus of six discussion groups: misc.consumers, alt.atheism, rec.arts.books, comp.{arch, graphics.algorithms, lang.c}. Each group contains 1000 documents per year from 1993-2002. Viewable at http://groups.google.com/.</title>
<marker></marker>
<rawString>3.3: Hand-collected corpus of six discussion groups: misc.consumers, alt.atheism, rec.arts.books, comp.{arch, graphics.algorithms, lang.c}. Each group contains 1000 documents per year from 1993-2002. Viewable at http://groups.google.com/.</rawString>
</citation>
<citation valid="false">
<title>4.2: Over 4000 PhD and Masters dissertation abstracts related to communication disorders,</title>
<pages>1982--2002</pages>
<institution>University Microfilms Inc.</institution>
<note>Supplied by</note>
<marker></marker>
<rawString>4.2: Over 4000 PhD and Masters dissertation abstracts related to communication disorders, 1982-2002. Supplied by University Microfilms Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>