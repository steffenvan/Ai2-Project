<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000523">
<title confidence="0.949103">
Sentiment Analysis of Conditional Sentences
</title>
<author confidence="0.981523">
Ramanathan Narayanan Bing Liu * Alok Choudhary
</author>
<affiliation confidence="0.959577">
Dept. of EECS Dept. of Computer Science Dept. of EECS
Northwestern University Univ. of Illinois at Chicago Northwestern University
</affiliation>
<email confidence="0.995342">
ramanathan.an@gmail.com liub@cs.uic.edu alokchoudhary01@gmail.com
</email>
<sectionHeader confidence="0.993837" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999525448275862">
This paper studies sentiment analysis of condi-
tional sentences. The aim is to determine
whether opinions expressed on different topics
in a conditional sentence are positive, negative
or neutral. Conditional sentences are one of the
commonly used language constructs in text. In
a typical document, there are around 8% of
such sentences. Due to the condition clause,
sentiments expressed in a conditional sentence
can be hard to determine. For example, in the
sentence, if your Nokia phone is not good, buy
this great Samsung phone, the author is posi-
tive about “Samsung phone” but does not ex-
press an opinion on “Nokia phone” (although
the owner of the “Nokia phone” may be nega-
tive about it). However, if the sentence does
not have “if”, the first clause is clearly nega-
tive. Although “if” commonly signifies a con-
ditional sentence, there are many other words
and constructs that can express conditions.
This paper first presents a linguistic analysis of
such sentences, and then builds some super-
vised learning models to determine if senti-
ments expressed on different topics in a condi-
tional sentence are positive, negative or neu-
tral. Experimental results on conditional sen-
tences from 5 diverse domains are given to
demonstrate the effectiveness of the proposed
approach.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996454">
Sentiment analysis (also called opinion mining)
has been an active research area in recent years.
There are many research directions, e.g., senti-
ment classification (classifying an opinion doc-
ument as positive or negative) (e.g., Pang, Lee
and Vaithyanathan, 2002; Turney, 2002), subjec-
tivity classification (determining whether a sen-
tence is subjective or objective, and its associated
opinion) (Wiebe and Wilson, 2002; Yu and Hat-
zivassiloglou, 2003; Wilson et al, 2004; Kim and
</bodyText>
<footnote confidence="0.907199">
* This work was done when Bing Liu was on sabbatical
leave at Northwestern University.
</footnote>
<bodyText confidence="0.998023372093024">
Hovy, 2004; Riloff and Wiebe, 2005), fea-
ture/topic-based sentiment analysis (assigning
positive or negative sentiments to topics or prod-
uct features) (Hu and Liu 2004; Popescu and Et-
zioni, 2005; Carenini et al., 2005; Ku et al.,
2006; Kobayashi, Inui and Matsumoto, 2007;
Titov and McDonald. 2008). Formal definitions
of different aspects of the sentiment analysis
problem and discussions of major research direc-
tions and algorithms can be found in (Liu, 2006;
Liu, 2009). A comprehensive survey of the field
can be found in (Pang and Lee, 2008).
Our work is in the area of topic/feature-based
sentiment analysis or opinion mining (Hu and
Liu, 2004). The existing research focuses on
solving the general problem. However, we argue
that it is unlikely to have a one-technique-fit-all
solution because different types of sentences ex-
press sentiments/opinions in different ways. A
divide-and-conquer approach is needed, e.g., fo-
cused studies on different types of sentences.
This paper focuses on one type of sentences, i.e.,
conditional sentences, which have some unique
characteristics that make it hard to determine the
orientation of sentiments on topics/features in
such sentences. By sentiment orientation, we
mean positive, negative or neutral opinions. By
topic, we mean the target on which an opinion
has been expressed. In the product domain, a top-
ic is usually a product feature (i.e., a component
or attribute). For example, in the sentence, I do
not like the sound quality, but love the design of
this MP3 player, the product features (topics) are
“sound quality” and “design” of the MP3 player
as opinions have been expressed on them. The
sentiment is positive on “design” but negative on
“sound quality”.
Conditional sentences are sentences that de-
scribe implications or hypothetical situations and
their consequences. In the English language, a
variety of conditional connectives can be used to
form these sentences. A conditional sentence
contains two clauses: the condition clause and
</bodyText>
<page confidence="0.967289">
180
</page>
<note confidence="0.9965975">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 180–189,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.987390933333333">
the consequent clause, that are dependent on
each other. Their relationship has significant im-
plications on whether the sentence describes an
opinion. One simple observation is that senti-
ment words (also known as opinion words) (e.g.,
great, beautiful, bad) alone cannot distinguish an
opinion sentence from a non-opinion one. A
conditional sentence may contain many senti-
ment words or phrases, but express no opinion.
Example 1: If someone makes a beautiful and
reliable car, I will buy it expresses no sentiment
towards any particular car, although “beautiful”
and “reliable” are positive sentiment words.
This, however, does not mean that a condition-
al sentence cannot express opinions/sentiments.
</bodyText>
<subsubsectionHeader confidence="0.746721">
Example 2: If your Nokia phone is not good,
</subsubsectionHeader>
<bodyText confidence="0.976396741935484">
buy this great Samsung phone is positive about
the “Samsung phone” but does not express an
opinion on the “Nokia phone” (although the
owner of the “Nokia phone” may be negative
about it). Clearly, if the sentence does not have
“if”, the first clause is negative. Hence, a method
for determining sentiments in normal sentences
will not work for conditional sentences. The ex-
amples below further illustrate the point.
In many cases, both the condition and conse-
quent together determine the opinion.
Example 3: If you are looking for a phone
with good voice quality, don’t buy this Nokia
phone is negative about the “voice quality” of the
“Nokia phone”, although there is a positive sen-
timent word “good” in the conditional clause
modifying “voice quality”. However, in the fol-
lowing example, the opinion is just the opposite.
Example 4: If you want a phone with good
voice quality, buy this Nokia phone is positive
about the “voice quality” of the “Nokia phone”.
As we can see, sentiment analysis of condi-
tional sentences is a challenging problem.
One may ask whether there is a large percen-
tage of conditional sentences to warrant a fo-
cused study. Indeed, there is a fairly large pro-
portion of such sentences in evaluative text. They
can have a major impact on the sentiment analy-
sis accuracy. Table 1 shows the percentage of
conditional sentences (sentences containing the
words if, unless, assuming, etc) and also the total
</bodyText>
<tableCaption confidence="0.999586">
Table 1: Percent of conditional sentences
</tableCaption>
<table confidence="0.909322">
Source % of cond. (total #. of sent.)
Cellphone 8.6 (47711)
Automobile 5.0 (8113)
LCD TV 9.92 (258078)
Audio Systems 8.1 (5702)
Medicine 8.29 (160259)
</table>
<bodyText confidence="0.999632890909091">
number of sentences from which we computed
the percentage in several user-forums. The fig-
ures definitely suggest that there is considerable
benefit to be gained by developing techniques
that can analyze conditional sentences.
To the best of our knowledge, there is no fo-
cused study on conditional sentences. This paper
makes such an attempt. Specifically, we deter-
mine whether a conditional sentence (which is
also called a conditional in the linguistic litera-
ture) expresses positive, negative or neutral opi-
nions on some topics/features. Since our focus is
on studying how conditions and consequents af-
fect sentiments, we assume that topics are given,
which are product attributes since our data sets
are user comments on different products.
Our study is conducted from two perspectives.
We start with the linguistic angle to gain a good
understanding of existing work on different types
of conditionals. As conditionals can be expressed
with other words or phrases than if, we will study
how they behave compared to if. We will also
show that the distribution of these conditionals
based on our data sets.
With the linguistic knowledge, we perform a
computational study using machine learning. A
set of features for learning is designed to capture
the essential determining information. Note that
the features here are data attributes used in learn-
ing rather than product attributes or features.
Three classification strategies are designed to
study how to best perform the classification task
due to the complex situation of two clauses and
their interactions in conditional sentences. These
three classification strategies are clause-based,
consequent-based and whole-sentence-based.
Clause-based classification classifies each clause
separately and then combines their results. Con-
sequent-based classification only uses conse-
quents for classification as it is observed that in
conditional sentences, it is often the consequents
that decide the opinion. Whole-sentence-based
classification treats the entire sentence as a whole
in classification. Experimental results on condi-
tional sentences from diverse domains demon-
strate the effectiveness of these classification
models. The results indicate that the whole-
sentence-based classifier performs the best.
Since this paper only studies conditional sen-
tences, a natural question is whether the pro-
posed technique can be easily integrated into an
overall sentiment analysis or opinion mining sys-
tem. The answer is yes because a large propor-
tion of conditional sentences can be detected us-
ing conditional connectives. Keyword search is
</bodyText>
<page confidence="0.997544">
181
</page>
<bodyText confidence="0.999938666666667">
thus sufficient to identify such sentences for spe-
cial handling using the proposed approach. There
are, however, some subtle conditionals which do
not use normal conditional connectives and will
need an additional module to identify them, but
such sentences are very rare as Table 2 indicates.
</bodyText>
<sectionHeader confidence="0.979948" genericHeader="method">
2 The Problem Statement
</sectionHeader>
<bodyText confidence="0.999966033333333">
The paper follows the feature-based sentiment
analysis model in (Hu and Liu 2004; Popescu
and Etzioni, 2005). We are particularly interested
in sentiments on products and services, which are
called objects or entities. Each object is de-
scribed by its parts and attributes, which are col-
lectively called features in (Hu and Liu, 2004;
Liu, 2006). For example, in the sentence, If this
camera has great picture quality, I will buy it,
“picture quality” is a feature of the camera. For
formal definitions of objects and features, please
refer to (Liu, 2006; Liu, 2009). In this paper, we
use the term topic to mean feature as the feature
here can confuse with the feature used in ma-
chine learning. The term topic has also been used
by some researchers (e.g., Kim and Hovy, 2004;
Stoyanov and Cardie, 2008).
Our objective is to predict the sentiment
orientation (positive, negative or neutral) on each
topic that has been commented on in a sentence.
The problem of automatically identifying fea-
tures or topics being spoken about in a sentence
has been studied in (Hu and Liu, 2004; Popescu
and Etzioni, 2005; Stoyanov and Cardie, 2008).
In this work, we do not attempt to identify such
topics automatically. Instead, we assume that
they are given because our objective is to study
how the interaction of the condition and conse-
quent clauses affects sentiments. For this pur-
pose, we manually identify all the topics.
</bodyText>
<sectionHeader confidence="0.984818" genericHeader="method">
3 Conditional Sentences
</sectionHeader>
<bodyText confidence="0.910103">
This section presents the linguistic perspective of
conditional sentences.
</bodyText>
<tableCaption confidence="0.992766">
Table 2: Percentage of sentences with some main
conditional connectives
</tableCaption>
<table confidence="0.982405">
Conditional Connective % of sentences
If 6.42
Unless 0.32
Even if 0.17
Until 0.10
As (so) long as 0.09
Assuming/supposing 0.04
In case 0.04
Only if 0.03
</table>
<subsectionHeader confidence="0.997051">
3.1 Conditional Connectives
</subsectionHeader>
<bodyText confidence="0.994423867924528">
A large majority of conditional sentences are
introduced by the subordinating conjunction If.
However, there are also many other conditional
connectives, e.g., even if, unless, in case, assum-
ing/supposing, as long as, etc. Table 2 shows the
distribution of conditional sentences with various
connectives in our data. Detailed linguistic dis-
cussions of them are beyond the scope of this
paper. Interested readers, please refer to (Dec-
lerck and Reed, 2001). Below, we briefly discuss
some important ones and their interpretations.
If: This is the most commonly used conditional
connective. In addition to its own usage, it can
also be used to replace other conditional connec-
tives, except some semantically richer connec-
tives (Declerck and Reed, 2001). Most (but not
all) conditional sentences can be logically ex-
pressed in the form ‘If P then Q’, where P is the
condition clause and Q is the consequent clause.
For practical purposes, we can automatically
segment the condition and consequent clauses
using simple rules generated by observing
grammatical and linguistic patterns.
Unless: Most conditional sentences containing
unless can be replaced with equivalent sentences
with an if and a not. For example, the sentence
Unless you need clarity, buy the cheaper model
can be expressed with If you don’t need clarity,
buy the cheaper model.
Even if: Linguistic theories claim that even if is
a special case of a conditional which may not
always imply an if-then relationship (Gauker
2005). However, in our datasets, we have ob-
served that the usage of even if almost always
translates into a conditional. Replacing even if by
if will yield a sentence that is semantically simi-
lar enough for the purpose of sentiment analysis.
Only if, provided/providing that, on condition
that: Conditionals involving these phrases typi-
cally express a necessary condition, e.g., I will
buy this camera only if they can reduce the price.
In such sentences, only usually does not affect
whether the sentence is opinionated or not.
In case: Conditional sentences containing in
case usually describe a precaution (I will close
the window in case it rains), prevention (I wore
sunglasses in case I was recognized), or a relev-
ance conditional (In case you need a car, you can
rent one). Identifying the conditional and conse-
quent clauses is not straightforward in many cas-
es. Further, in these instances, replacing in case
with if may not convey the intended meaning of
the conditional. We have ignored these cases in
</bodyText>
<page confidence="0.991379">
182
</page>
<bodyText confidence="0.999977411764706">
our analysis as we believe that they need a sepa-
rate study, and also such sentences are rare.
As (so) long as: Sentences with these connec-
tives behave similarly to if and can usually be
replaced with if.
Assuming/Supposing: These are a category of
conditionals that behave quite differently. The
participles supposing and assuming create condi-
tional sentences where the conditional clause and
the consequent clause can be syntactically inde-
pendent. It is quite difficult to distinguish those
conditional sentences which contain an explicit
consequent clause and fit within our analysis
framework. In our data, most of such sentences
have no consequent, thus representing assump-
tions rather than opinions. We omit these sen-
tences in our study (they are also rare).
</bodyText>
<subsectionHeader confidence="0.999903">
3.2 Types of Conditionals
</subsectionHeader>
<bodyText confidence="0.999802375">
There are extensive studies of conditional sen-
tences (also known as conditionals) in linguis-
tics. Various theories have led to a number of
classification systems. Popular types of condi-
tionals include actualization conditionals, infe-
rential conditionals, implicative conditionals, etc
(Declerck and Reed, 2001). However, these clas-
sifications are mainly based on semantic mean-
ings which are difficult to recognize by a com-
puter program. To build classification models,
we instead exploit canonical tense patterns of
conditionals, which are often used in pedagogic
grammar books. They are defined based on tense
and are associated with general meanings. How-
ever, as described in (Declerck and Reed, 2001),
their meanings are much more complex and nu-
merous than their associated general meanings.
However, the advantage of this classification is
that different types can be detected easily be-
cause they depend on tense which can be pro-
duced by a part-of-speech tagger. As we will see
in Section 5, canonical tense patterns help senti-
ment classification significantly. Below, we in-
troduce the four canonical tense patterns.
</bodyText>
<listItem confidence="0.837612142857143">
Zero Conditional: This conditional form is
used to describe universal statements like facts,
rules and certainties. In a zero conditional, both
the condition and consequent clauses are in the
simple present tense. An example of such sen-
tences is: If you heat water, it boils.
First Conditional: Conditional sentences of
</listItem>
<bodyText confidence="0.992347863636363">
this type are also called potential or indicative
conditionals. They are used to express a hypo-
thetical situation that is probably true, but the
truth of which is unverified. In the first condi-
tional, the condition is in the simple present
tense, and the consequent can be either in past
tense or present tense, usually with a modal aux-
iliary verb preceding the main verb, e.g., If the
acceleration is good, I will buy it.
Second Conditional: This is usually used to
describe less probable situations, for stating pre-
ferences and imaginary events. The condition
clause of a second conditional sentence is in the
past subjunctive (past tense), and the consequent
clause contains a conditional verb modifier (like
would, should, might), in addition to the main
verb, e.g., If the cell phone was robust, I would
consider buying it.
Third conditional: This is usually used to de-
scribe contrary-to-fact (impossible) past events.
The past perfect tense is used in the condition
clause, and the consequent clause is in the
present perfect tense, e.g., If I had bought the
a767, I would have hated it.
Based on the above definitions, we have devel-
oped approximate part-of-speech (POS) tags 1 for
the condition and the consequent of each pattern
(Table 3), which do not cover all sentences, but
overall they cover a majority of the sentences.
For those not covered cases, the problem is
mainly due to incomplete sentences and wrong
grammars, which are typical for informal writ-
ings in forum postings and blogs. For example,
the sentence, Great car if you need powerful ac-
celeration, does not fall into any category, but it
actually means It is a great car if you need po-
werful acceleration, which is a zero conditional.
To handle such sentences, we designed a set of
rules to assign them some default types:
If condition contains VB/VBP/VBZ → 0 conditional
If consequent contains VB/VBP/VBS → 0 conditional
If condition contains VBG → 1st conditional
If condition contains VBD → 2nd conditional
If conditional contains VBN → 3rd conditional.
</bodyText>
<tableCaption confidence="0.970363">
Table 3: Tenses for identifying conditional types
</tableCaption>
<table confidence="0.9994969">
Type Linguistic Rule Condition Consequent
POS tags POS tags
0 If + simple present VB/VBP/VBZ VB/VBP/
→ simple present VBZ
1 If + simple present VB/VBP/VBZ MD + VB
→ will + bare infinitive /VBG
2 If + past tense VBD MD + VB
→ would + infinitive
3 If + past perfect VBD+VBN MD + VBD
→ present perfect
</table>
<footnote confidence="0.985520333333333">
1 The list of Part-Of-Speech (POS) tags can be found at:
http://www.ling.upenn.edu/courses/Fall_2003/ling001/
penn_treebank_pos.html
</footnote>
<page confidence="0.997844">
183
</page>
<bodyText confidence="0.9978695">
By using these rules, we can increase the sen-
tence coverage from 73% to 95%.
</bodyText>
<sectionHeader confidence="0.972293" genericHeader="method">
4 Sentiment Analysis of Conditionals
</sectionHeader>
<bodyText confidence="0.99996225">
We now describe our computational study. We
take a machine learning approach to predict sen-
timent orientations. Below, we first describe fea-
tures used and then classification strategies.
</bodyText>
<subsectionHeader confidence="0.99152">
4.1 Feature construction
</subsectionHeader>
<bodyText confidence="0.778524166666667">
I. Sentiment words/phrases and their locations:
Sentiment words are words used to express
positive or negative opinions, which are in-
strumental for sentiment classification for ob-
vious reasons. We obtained a list of over 6500
sentiment words gathered from various
sources. The bulk of it is from
http://www.cs.pitt.edu/mpqa. We also added
some of our own. Our list is mainly from the
work in (Hu and Liu, 2004; Ding, Liu and Yu,
2008). In addition to words, there are phrases
that describe opinions. We have identified a
set of such phrases. Although obtaining these
phrases was time-consuming, it was only a
one-time effort. We will make this list availa-
ble as a community resource. It is possible
that there is a better automated method for
finding such phrases, such as the methods in
(Kanayama and Nasukawa, 2006; Breck, Choi
and Cardie, 2007). However, automatically
generating sentiment phrases has not been the
focus of this work as our objective is to study
how the two clauses interact to determine
opinions given the sentiment words and
phrases are known. Our list of phrases is by
no means complete and we will continue to
expand it in the future.
For each sentence, we also identify wheth-
er it contains sentiment words/phrases in its
condition or consequent clause. It was ob-
served that the presence of a sentiment
word/phrase in the consequent clause has
more effect on the sentiment of a sentence.
II. POS tags of sentiment words: Sentiment
words may be used in several contexts, not all
of which may correspond to an opinion. For
example, I trust Motorola and He has a trust
fund both contain the word trust. But only the
former contains an opinion. In such cases, the
POS tags can provide useful information.
III. Words indicating no opinion: Similar to how
sentiment words are related to opinions, there
are also a number of words which imply the
opposite. Words like wondering, thinking, de-
bating are used when the user is posing a
question or expressing doubts. Thus such
phrases usually do not contribute an opinion,
especially if they are in the vicinity of the if
connective. We search a window of 3 words
on either side of if to determine if there is any
such word. We have compiled a list of these
words as well and use it in our experiments.
IV. Tense patterns: These are the canonical tense
patterns in Section 3.2. They are used to gen-
erate a set of features. We identify the first
verb in both the condition and consequent
clauses by searching for the relevant POS tags
in Table 3. We also search for the words pre-
ceding the main verb to find modal auxiliary
verbs, which are also used as features.
</bodyText>
<listItem confidence="0.797595666666667">
V. Special characters: The presence or absence
of ‘?’ and ‘!’.
VI. Conditional connectives: The conditional
connective used in the sentence (if, even if,
unless, only if, etc) is also taken as a feature.
VII. Length of condition and consequent clauses:
</listItem>
<bodyText confidence="0.979850238095238">
Using simple linguistic and punctuation rules,
we automatically segment a sentence into
condition and consequent clauses. The num-
bers of words in the condition and consequent
clauses are then used as features. We ob-
served that when the condition clause is short,
it usually has no impact on whether the sen-
tence expresses an opinion.
VIII. Negation words: The use of negation words
like not, don’t, never, etc, often alter the sen-
timent orientation of a sentence. For example,
the addition of not before a sentiment word
can change the orientation of a sentence from
positive to negative. We consider a window of
3-6 words before an opinion word, and search
for these kinds of words.
The following two features are singled out for
easy reference later. They are only used in one
classification strategy. The first feature is an in-
dicator, and the second feature has a parameter
(which will be evaluated separately).
</bodyText>
<listItem confidence="0.951053833333333">
(1). Topic location: This feature indicates wheth-
er the topic is in the conditional clause or the
consequent clause.
(2). Opinion weight: This feature considers only
sentiment words in the vicinity of the topic,
since they are more likely to influence the
opinion on the topic. A window size is used
to control what we mean by vicinity. The fol-
lowing formula is used to assign a weight to
each sentiment word, which is inversely pro-
portional to the distance (Dop) of the senti-
ment word to the topic mention. Sentiment
</listItem>
<page confidence="0.998308">
184
</page>
<bodyText confidence="0.96413225">
value is +1 for a positive word and -1 for a
negative word. Sentwords are the set of
known sentiment words and phrases.
e {sentwords}
</bodyText>
<subsectionHeader confidence="0.995753">
4.2 Classification Strategies
</subsectionHeader>
<bodyText confidence="0.999404657534247">
Since we are interested in topic-based sentiment
analysis, how to perform classification becomes
an interesting issue. Due to the two clauses, it
may not be sufficient to classify the whole sen-
tence as positive or negative as in the same sen-
tence, some topics may be positive and some
may be negative. We propose three strategies.
Clause-based classification: Since there are two
clauses in a conditional sentence, in this case
we build two classifiers, one for the condition
and one for the consequent.
Condition classifier: This method classifies the
condition clause as expressing positive, nega-
tive or neutral opinion.
Training data: Each training sentence is
represented as a feature vector. Its class is posi-
tive, negative or neutral depending on whether
the conditional clause is positive, negative or
neutral while considering both clauses.
Testing: For each test sentence, the resulting
classifier predicts the opinion of the condition
clause.
Topic class prediction: To predict the opi-
nion on a topic, if the topic is in the condition
clause, it takes the predicted class of the
clause.
Consequent classifier: This classifier classi-
fies the consequent clause as expressing posi-
tive, negative or neutral opinion.
Training data: Each training sentence is
represented as a feature vector. Its class is posi-
tive, negative or neutral depending on whether
the consequent clause is positive, negative or
neutral while considering both clauses.
Testing: For each test sentence, the resulting
classifier predicts the opinion of the conse-
quent clause.
Topic class prediction: To predict the opi-
nion on a topic, if the topic is in the consequent
clause, it takes the predicted class of the
clause.
The combination of these two classifiers is
called the clause-based classifier. It works as
follows: If a topic is in the conditional clause,
the condition classifier is used, and if a topic is
in the consequent clause, the consequent clas-
sifier is used.
Consequent-based classification: It is observed
that in most cases, the condition clause con-
tains no opinion whereas the consequent clause
reflects the sentiment of the entire sentence.
Thus, this method uses (in a different way) on-
ly the above consequent classifier. If it classi-
fies the consequent of a testing conditional
sentence as positive, all the topics in the whole
sentence are assigned the positive orientation,
and likewise for negative and neutral.
Whole-sentence-based classification: In this
case, a single classifier is built to predict the
opinion on each topic in a sentence.
Training data: In addition to the normal fea-
tures, the two features (1) and (2) in Section
4.1 are used for this classifier. If a sentence
contains multiple topics, multiple training in-
stances of the same sentence are created in the
training data. Each instance represents one
specific topic. The class of the instance de-
pends on whether the opinion on the topic is
positive, negative or neutral.
Testing: For each topic in each test sentence,
the resulting classifier predicts its opinion.
Topic class prediction: This is not needed as
the prediction has been done in testing.
</bodyText>
<sectionHeader confidence="0.999502" genericHeader="evaluation">
5 Results and Discussions
</sectionHeader>
<subsectionHeader confidence="0.985816">
5.1 Data sets
</subsectionHeader>
<bodyText confidence="0.99997732">
Our data consists of conditional sentences from 5
different user forums: Cellphone, Automobile,
LCD TV, Audio systems and Medicine. We ob-
tained user postings from these forums and ex-
tracted the conditional sentences. We then ma-
nually annotated 1378 sentences from this cor-
pus. We also annotated the conditional and con-
sequent clauses and identified the topics (or
product features) being commented upon, and
their sentiment orientations. In our annotation,
we observed that sentences with no sentiment
words or phrases almost never express opinions,
i.e., only around 3% of them express opinions.
There are around 26% sentences containing no
sentiment words or phrases in our data. To make
the problem challenging, we restrict our attention
to only those sentences that contain at least one
sentiment word or phrase. We have annotated
topics from around 900 such sentences. Table 4
shows the class distributions of this data. At the
clause level (topics are not considered), we ob-
serve that conditional clauses contain few opi-
nions. At the topic-level, 43.5% of the topics
have positive opinions, 26.4% of the topics have
negative opinions, and the rest have no opinions.
</bodyText>
<figure confidence="0.915240571428572">
1
±
=E
weight
,V op
op op
D
</figure>
<page confidence="0.995676">
185
</page>
<tableCaption confidence="0.992198">
Table 4: Distribution of classes
</tableCaption>
<table confidence="0.99754375">
Positive Negative Neutral
Condition 6.9% 6.7% 86.4%
Consequent 49.3% 16.5% 34%
Topic-level 43.5% 26.4% 29.9%
</table>
<bodyText confidence="0.999473785714286">
For the annotation of data, we assume that
topics are known. One student annotated the top-
ics first. Then two students annotated the senti-
ments on the topics. If a student found that a top-
ic annotation is wrong, he will let us know. Some
mistakes and missing topics were found but there
were mainly due to oversights rather than disa-
greements. The agreement on sentiment annota-
tions were computed using the Kappa score. We
achieved the Kappa score of 0.63, which indi-
cates strong agreements. The conflicting cases
were then solved through discussion to reach
consensus. We did not find anything that the an-
notators absolutely disagree with each other.
</bodyText>
<subsectionHeader confidence="0.997737">
5.2 Experimental results
</subsectionHeader>
<bodyText confidence="0.93757161627907">
We now present the results for different combi-
nations of features and classification strategies.
For model building, we used Support Vector
Machines (SVM), and the LIBSVM implementa-
tion (Chang and Lin, 2001) with a Gaussian ker-
nel, which produces the best results. All the re-
sults are obtained via 10-fold cross validation.
Two-class classification: We first discuss the
results for a simpler version of the problem that
involves only sentences with positive or negative
orientations on some topics (at least one of the
clauses must have a positive/negative opinion on
a topic). Neutral sentences are not used (~28% of
the total). The results of all three classifiers are
given in Table 5. The feature sets have been de-
scribed in Section 4.1. For all the experiments
below, features (1) and (2) are only used by the
whole-sentence-based classifier, but not used by
the other two classifiers for obvious reasons.
{I+II}: This setting uses sentiment words and
phrases, their positions and POS tags as features
(we used Brill’s POS tagger). This can be seen as
the baseline. We observe that both the conse-
quent-based and whole-sentence-based classifiers
perform dramatically better than the clause-based
classifier. The consequent-based classifier and
the whole-sentence-based classifier perform si-
milarly (with the latter being slightly better). The
precision, recall, and F-score are computed as the
average of the two classes.
{I+II+III}: In this setting, the list of special
non-sentiment related words is added to the fea-
ture set. All three classifiers improve slightly.
{I+II+III+IV}: This setting includes all the ca-
nonical tense based features. We see marked im-
provements for the consequent-based and whole-
sentence-based classifiers both in term of accura-
cy and F-score, which are statistically significant
compared to those of {I+II+III} at the 95% con-
fidence level based on paired t-test.
All: When all the features are used, the results
of all the classifiers improve further.
Two main observations worth mentioning:
1. Both the consequent-based and whole-
sentence-based classifiers outperform the
clause-based classifier dramatically. This con-
firms our observation that the consequent
usually plays the key role in determining the
sentiment of the sentence. This is further rein-
forced by the fact that the consequent-based
classifier actually performs similarly to the
whole-sentence-based classifier. The condi-
tion clause seems to give no help.
2. The second observation is that the linguistic
knowledge of canonical tense patterns helps
significantly. This shows that the linguistic
knowledge is very useful.
We also noticed that many misclassifications are
caused by grammatical errors, use of slang
phrases and improper punctuations, which are
typical of postings on the Web. Due to language
irregularities (e.g., wrong grammar, missing
punctuations, sarcasm, exclamations), the POS
tagger makes many mistakes as well causing
some errors in the tense based features.
Three-class classification: We now move to the
more difficult and realistic case of three classes:
positive, negative and neutral (no-opinion). Ta-
ble 6 shows the results. The trend is similar ex-
cept that the whole-sentence-based classifier now
performs markedly better than the consequent-
based classifier. We believe that this is because
the neutral class needs information from both the
condition and consequent clauses. This is evident
from the fact that there is little or no improve-
ment after {I+II} for the consequent-based clas-
sifier. We also observe that the accuracies and F-
scores for the three-class classification are lower
than those for the two-class classification. This is
understandable due to the difficulty of determin-
ing whether a sentence has opinion or not. Again,
statistical test shows that the canonical tense-
based features help significantly.
As mentioned in Section 4.1, the whole-
sentence-based classifier only considers those
sentiment words in the vicinity of the topic under
</bodyText>
<page confidence="0.999049">
186
</page>
<tableCaption confidence="0.99828">
Table 5: Two-class classification – positive and negative
</tableCaption>
<table confidence="0.999358857142857">
Clause-based Consequent-based Whole-sentence-based
classifier classifier classifier
Acc. Prec. Rec. F Acc. Prec. Rec. F Acc. Prec. Rec. F
I+II (senti. words+POS) 39.9 42.8 34.0 37.9 69.1 72.9 67.1 69.8 68.9 73.7 68.13 70.8
I+II+III (+ non-senti. words) 41.5 44.9 37.1 40.6 69.3 73.9 66.3 69.9 69.2 73.7 63.5 71.0
I+II+III+IV (+ tenses) 42.7 45.2 38.5 41.6 72.7 76.4 72.0 74.1 71.1 77.9 72.2 74.9
All 43.2 46.1 38.9 42.2 73.3 77.0 72.7 74.8 72.3 77.8 73.6 75.6
</table>
<tableCaption confidence="0.927196">
Table 6: Three-class classification – positive, negative and neutral (no opinion)
</tableCaption>
<table confidence="0.999111142857143">
Clause-based Consequent-based Whole-sentence-based
classifier classifier classifier
Acc. Prec. Rec. F Acc. Prec. Rec. F Acc. Prec. Rec. F
I+II (senti. words+POS) 45.2 41.3 35.1 37.9 54.6 57.7 52.9 55.2 59.1 58.1 56.4 57.2
I+II+III (+ non-senti. words) 46.9 42.8 37.8 40.1 55.3 60.0 51.3 55.3 61.4 60.1 60.8 60.4
I+II+III+IV (+ tenses) 50.3 48.7 40.9 44.5 57.3 64.0 50.0 56.1 64.6 63.3 63.9 63.6
All 53.3 49.8 44.1 46.8 58.7 64.5 50.1 56.4 67.8 66.9 65.1 66.0
</table>
<tableCaption confidence="0.997432">
Table 7: Accuracy of the whole-sentence-based classifier with varying window sizes (n)
</tableCaption>
<bodyText confidence="0.96850452173913">
Window size 1 2 3 4 5 6 7 8 9 10
Accuracy 66.1 62.6 64.1 64.8 65.3 65.7 66.3 67.3 66.9 66.8
investigation. For this, we search a window of n
words on either side of the topic mention. To
study the effect of varying n, we performed an
experiment with various values of the window
size and measured the overall accuracy for each
case. Table 7 shows how the accuracy changes as
we increase the window size. We found that a
window size of 6-10 yielded good accuracies.
This is because lower values of n lead to loss of
information regarding sentiment words as some
sentiment words could be far from the topic. We
finally used 8, which gave the best results.
We also investigated ways of using the nega-
tion word in the sentence to correctly predict the
sentiment. One method is to use the negation
word as a feature, as described in Section 4.1.
Another technique is to reverse the orientation of
the prediction for those sentences which contain
negation words. We found that the former tech-
nique yielded better results. The results reported
so far are based on the former approach.
</bodyText>
<sectionHeader confidence="0.999982" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999262921052632">
There are several research directions in sentiment
analysis (or opinion mining). One of the main
directions is sentiment classification, which clas-
sifies the whole opinion document (e.g., a prod-
uct review) as positive or negative (e.g., Pang et
al, 2002; Turney, 2002; Dave et al, 2003; Ng et
al. 2006; McDonald et al, 2007). It is clearly dif-
ferent from our work as we are interested in con-
ditional sentences.
Another important direction is classifying
sentences as subjective or objective, and classify-
ing subjective sentences or clauses as positive or
negative (Wiebe et al, 1999; Wiebe and Wilson,
2002, Yu and Hatzivassiloglou, 2003; Wilson et
al, 2004; Kim and Hovy, 2004; Riloff and
Wiebe, 2005; Gamon et al 2005; McDonald et al,
2007). Although these works deal with sen-
tences, they aim to solve the general problem.
This paper argues that there is unlikely a one-
technique-fit-all solution, and advocates dealing
with specific types of sentences differently by
exploiting their unique characteristics. Condi-
tional sentences are the focus of this paper. To
the best of our knowledge, there is no focused
study on them.
Several researchers also studied feature/topic-
based sentiment analysis (e.g., Hu and Liu, 2004;
Popescu and Etzioni, 2005; Ku et al, 2006; Care-
nini et al, 2006; Mei et al, 2007; Ding, Liu and
Yu, 2008; Titov and R. McDonald, 2008; Stoya-
nov and Cardie, 2008; Lu and Zhai, 2008). Their
objective is to extract topics or product features
in sentences and determine whether the senti-
ments expressed on them are positive or nega-
tive. Again, no focused study has been made to
handle conditional sentences. Effectively han-
dling of conditional sentences can help their ef-
fort significantly.
</bodyText>
<page confidence="0.993588">
187
</page>
<bodyText confidence="0.999976928571429">
In this work, we used many sentiment words
and phrases. These words and phrases are usually
compiled using different approaches (Hatzivassi-
loglou and McKeown, 1997; Kaji and Kitsure-
gawa, 2006; Kanayama and Nasukawa, 2006;
Esuli and Sebastiani, 2006; Breck et al, 2007;
Ding, Liu and Yu. 2008; Qiu et al, 2009). There
are several existing lists produced by researchers.
We used the one from the MPQA corpus
(http://www.cs.pitt.edu/mpqa) with added phras-
es of our own from (Ding, Liu and Yu. 2008). In
our work, we also assume that the topics are
known. (Hu and Liu, 2004; Popescu and Etzioni,
2005; Kobayashi, Inui and Matsumoto, 2007;
Stoyanov and Cardie, 2008) have studied top-
ic/feature extraction.
One existing focused study is on comparative
and superlative sentences (Jindal and Liu, 2006;
Bos and Nissim, 2006; Fiszman et al, 2007; Ga-
napathibhotla and Liu, 2008). Their work identi-
fies comparative sentences, extracts comparative
relations in the sentences and analyzes compara-
tive opinions (Ganapathibhotla and Liu, 2008).
An example comparative sentence is “Honda
looks better than Toyota”. As we can see, com-
parative sentences are entirely different from
conditional sentences. Thus, their methods can-
not be directly applied to conditional sentences.
</bodyText>
<sectionHeader confidence="0.998377" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99998484">
To perform sentiment analysis accurately, we
argue that a divide-and-conquer approach is
needed, i.e., focused study on each type of sen-
tences. It is unlikely that there is a one-size-fit-all
solution. This paper studied one type, i.e., condi-
tional sentences, which have some unique cha-
racteristics that need special handling. Our study
was carried out from both the linguistic and
computational perspectives. In the linguistic
study, we focused on canonical tense patterns,
which have been showed useful in classification.
In the computational study, we built SVM mod-
els to automatically predict whether opinions on
topics are positive, negative or neutral. Experi-
mental results have shown the effectiveness of
the models.
In our future work, we will further improve
the classification accuracy and study related
problems, e.g., identifying topics/features. Al-
though there are some special conditional sen-
tences that do not use easily recognizable condi-
tional connectives and identifying them are use-
ful, such sentences are very rare and spending
time and effort on them may not be cost-effective
at the moment.
</bodyText>
<sectionHeader confidence="0.990872" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.915005285714286">
This work was supported in part by DOE SCI-
DAC-2: Scientific Data Management Center for
Enabling Technologies (CET) grant DE-FC02-
07ER25808, DOE FASTOS award number DE-
FG02-08ER25848, NSF HECURA CCF-
0621443, NSF SDCI OCI-0724599, and NSF
ST-HEC CCF-0444405.
</bodyText>
<sectionHeader confidence="0.992532" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999767263157895">
J. Bos, and M. Nissim. 2006. An Empirical Ap-
proach to the Interpretation of Superlatives.
EMNLP-2006.
E. Breck, Y. Choi, and C. Cardie. 2007. Identify-
ing expressions of opinion in context, IJCAI-
2007.
C.-C. Chang and C.-J. Lin. 2001. LIBSVM: a
library for support vector machines.
http://www.csie.ntu.edu.tw /~cjlin/libsvm
G. Carenini, R. Ng, and A. Pauls. 2006. Interac-
tive Multimedia Summaries of Evaluative
Text. IUI-2006.
C. Gauker. 2005. Conditionals in Context. MIT
Press.
D. Dave, A. Lawrence, and D. Pennock. 2003.
Mining the Peanut Gallery: Opinion Extrac-
tion and Semantic Classification of Product
Reviews. WWW-2003.
R. Declerck, and S. Reed. 2001. Conditionals: A
Comprehensive Empirical Analysis. Berlin:
Mouton de Gruyter.
X. Ding, B. Liu, and P. S. Yu. 2008. A holistic
lexicon-based approach to opinion mining.
WSDM-2008.
A. Esuli, and F. 2006. Sebastiani. Determining
term subjectivity and term orientation for opi-
nion mining, EACL-2006.
M. Fiszman, D. Demner-Fushman, F. Lang, P.
Goetz, and T. Rindflesch. 2007. Interpreting
Comparative Constructions in Biomedical
Text. BioNLP-2007.
M. Gamon, A. Aue, S. Corston-Oliver, S. and E.
Ringger. 2005. Pulse: Mining customer opi-
nions from free text. IDA-2005.
G. Ganapathibhotla and B. Liu. 2008. Identifying
Preferred Entities in Comparative Sentences.
COLING-2008.
V. Hatzivassiloglou, and K. McKeown, K. 1997.
</reference>
<page confidence="0.982311">
188
</page>
<reference confidence="0.999230524390244">
Predicting the Semantic Orientation of Adjec-
tives. ACL-EACL-1997.
M. Hu and B. Liu. 2004. Mining and summariz-
ing customer reviews. KDD-2004.
N. Jindal, and B. Liu. 2006. Mining Comparative
Sentences and Relations. AAAI-2006.
N. Kaji, and M. Kitsuregawa. 2006. Automatic
construction of polarity-tagged corpus from
HTML documents. ACL-2006.
H. Kanayama, and T. Nasukawa. 2006. Fully
Automatic Lexicon Expansion for Domain-
Oriented Sentiment Analysis. EMNLP-2006.
S. Kim and E. Hovy. 2004. Determining the Sen-
timent of Opinions. COLING-2004.
N. Kobayashi, K. Inui and Y. Matsumoto. 2007.
Extracting Aspect-Evaluation and Aspect-of
Relations in Opinion Mining. EMNLP-2007.
L.-W. Ku, Y.-T. Liang, and H.-H. Chen. 2006,
Opinion Extraction, Summarization and
Tracking in News and Blog Corpora. AAAI-
CAAW.
B. Liu. 2006. Web Data Mining: Exploring
Hyperlinks, Content and Usage Data. Sprin-
ger.
B. Liu. 2009. Sentiment Analysis and Subjectivi-
ty. To appear in Handbook of Natural Lan-
guage Processing, Second Edition, (editors:
N. Indurkhya and F. J. Damerau), 2009 or
2010.
Y. Lu, and C. X. Zhai. 2008. Opinion integration
through semi-supervised topic modeling.
WWW-2008.
R. McDonald, K. Hannan, T. Neylon, M. Wells,
and J. Reynar. 2007. Structured models for
fine-to-coarse sentiment analysis. ACL-2007
Q. Mei, X. Ling, M. Wondra, H. Su, and C. X.
Zhai. 2007. Topic Sentiment Mixture: Model-
ing Facets and Opinions in Weblogs. WWW-
2007.
V. Ng, S. Dasgupta, and S. M. Niaz Arifin. 2006.
Examining the role of linguistic knowledge
sources in the automatic identification and
classification of reviews. ACL-2006.
B. Pang and L. Lee. 2008. Opinion Mining and
Sentiment Analysis. Foundations and Trends
in Information Retrieval 2(1-2), pp. 1–135,
2008.
B. Pang, L. Lee. and S. Vaithyanathan. 2002.
Thumbs up? Sentiment Classification Using
Machine Learning Techniques. EMNLP-
2002.
A-M. Popescu, and O. Etzioni. 2005. Extracting
Product Features and Opinions from Reviews.
EMNLP-2005.
G. Qiu, B. Liu, J. Bu and C. Chen. 2009. Ex-
panding Domain Sentiment Lexicon through
Double Propagation. IJCAI-2009.
E. Riloff, and J. Wiebe. 2003. Learning extrac-
tion patterns for subjective expressions.
EMNLP-2003.
V. Stoyanov, and C. Cardie. 2008. Topic Identi-
fication for fine-grained opinion analysis.
COLING-2008.
I. Titov and R. McDonald. 2008. A Joint Model
of Text and Aspect Ratings for Sentiment
Summarization. ACL-2008.
P. Turney. 2002. Thumbs Up or Thumbs Down?
Semantic Orientation Applied to Unsuper-
vised Classification of Reviews. ACL-2002.
J. Wiebe, R. Bruce, and T. O’Hara. 1999. Devel-
opment and use of a gold standard data set for
subjectivity classifications. ACL-1999.
J. Wiebe, and T. Wilson. 2002. Learning to Dis-
ambiguate Potentially Subjective Expressions.
CoNLL-2002.
T. Wilson, J. Wiebe. and R. Hwa. 2004. Just how
mad are you? Finding strong and weak
opinion clauses. AAAI-2004.
H. Yu, and Y. Hatzivassiloglou. 2003. Towards
answering opinion questions: Separating facts
from opinions and identifying the polarity of
opinion sentences. EMNLP-2003.
</reference>
<page confidence="0.99892">
189
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.892987">
<title confidence="0.999814">Sentiment Analysis of Conditional Sentences</title>
<author confidence="0.998519">Narayanan Bing Liu Choudhary</author>
<affiliation confidence="0.996694">Dept. of EECS Dept. of Computer Science Dept. of EECS Northwestern University Univ. of Illinois at Chicago Northwestern</affiliation>
<email confidence="0.999448">liub@cs.uic.edu</email>
<abstract confidence="0.996669366666667">This paper studies sentiment analysis of conditional sentences. The aim is to determine whether opinions expressed on different topics in a conditional sentence are positive, negative or neutral. Conditional sentences are one of the commonly used language constructs in text. In a typical document, there are around 8% of such sentences. Due to the condition clause, sentiments expressed in a conditional sentence can be hard to determine. For example, in the your Nokia phone is not good, buy great Samsung the author is posiabout phone” does not exan opinion on phone” owner of the may be negative about it). However, if the sentence does have the first clause is clearly nega- Although commonly signifies a conditional sentence, there are many other words and constructs that can express conditions. This paper first presents a linguistic analysis of such sentences, and then builds some supervised learning models to determine if sentiments expressed on different topics in a conditional sentence are positive, negative or neutral. Experimental results on conditional sentences from 5 diverse domains are given to demonstrate the effectiveness of the proposed approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Bos</author>
<author>M Nissim</author>
</authors>
<title>An Empirical Approach to the Interpretation of Superlatives.</title>
<date>2006</date>
<contexts>
<context position="37346" citStr="Bos and Nissim, 2006" startWordPosition="6027" endWordPosition="6030">nayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008). Their work identifies comparative sentences, extracts comparative relations in the sentences and analyzes comparative opinions (Ganapathibhotla and Liu, 2008). An example comparative sentence is “Honda looks better than Toyota”. As we can see, comparative sentences are entirely different from conditional sentences. Thus, their methods cannot be directly applied to conditional sentences. 7 Conclusion To perform sentiment analysis accurately, we argue that a divide-and-conquer approach is needed, i.e., focused study on each type of sentences</context>
</contexts>
<marker>Bos, Nissim, 2006</marker>
<rawString>J. Bos, and M. Nissim. 2006. An Empirical Approach to the Interpretation of Superlatives. EMNLP-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Breck</author>
<author>Y Choi</author>
<author>C Cardie</author>
</authors>
<title>Identifying expressions of opinion in context,</title>
<date>2007</date>
<pages>2007</pages>
<contexts>
<context position="36798" citStr="Breck et al, 2007" startWordPosition="5937" endWordPosition="5940">ov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008</context>
</contexts>
<marker>Breck, Choi, Cardie, 2007</marker>
<rawString>E. Breck, Y. Choi, and C. Cardie. 2007. Identifying expressions of opinion in context, IJCAI2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-C Chang</author>
<author>C-J Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines.</title>
<date>2001</date>
<note>http://www.csie.ntu.edu.tw /~cjlin/libsvm</note>
<contexts>
<context position="28800" citStr="Chang and Lin, 2001" startWordPosition="4651" endWordPosition="4654">s were found but there were mainly due to oversights rather than disagreements. The agreement on sentiment annotations were computed using the Kappa score. We achieved the Kappa score of 0.63, which indicates strong agreements. The conflicting cases were then solved through discussion to reach consensus. We did not find anything that the annotators absolutely disagree with each other. 5.2 Experimental results We now present the results for different combinations of features and classification strategies. For model building, we used Support Vector Machines (SVM), and the LIBSVM implementation (Chang and Lin, 2001) with a Gaussian kernel, which produces the best results. All the results are obtained via 10-fold cross validation. Two-class classification: We first discuss the results for a simpler version of the problem that involves only sentences with positive or negative orientations on some topics (at least one of the clauses must have a positive/negative opinion on a topic). Neutral sentences are not used (~28% of the total). The results of all three classifiers are given in Table 5. The feature sets have been described in Section 4.1. For all the experiments below, features (1) and (2) are only use</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>C.-C. Chang and C.-J. Lin. 2001. LIBSVM: a library for support vector machines. http://www.csie.ntu.edu.tw /~cjlin/libsvm</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>R Ng</author>
<author>A Pauls</author>
</authors>
<title>Interactive Multimedia Summaries of Evaluative Text.</title>
<date>2006</date>
<contexts>
<context position="36103" citStr="Carenini et al, 2006" startWordPosition="5822" endWordPosition="5826">d Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji an</context>
</contexts>
<marker>Carenini, Ng, Pauls, 2006</marker>
<rawString>G. Carenini, R. Ng, and A. Pauls. 2006. Interactive Multimedia Summaries of Evaluative Text. IUI-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Gauker</author>
</authors>
<title>Conditionals in Context.</title>
<date>2005</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="12837" citStr="Gauker 2005" startWordPosition="2020" endWordPosition="2021">e and Q is the consequent clause. For practical purposes, we can automatically segment the condition and consequent clauses using simple rules generated by observing grammatical and linguistic patterns. Unless: Most conditional sentences containing unless can be replaced with equivalent sentences with an if and a not. For example, the sentence Unless you need clarity, buy the cheaper model can be expressed with If you don’t need clarity, buy the cheaper model. Even if: Linguistic theories claim that even if is a special case of a conditional which may not always imply an if-then relationship (Gauker 2005). However, in our datasets, we have observed that the usage of even if almost always translates into a conditional. Replacing even if by if will yield a sentence that is semantically similar enough for the purpose of sentiment analysis. Only if, provided/providing that, on condition that: Conditionals involving these phrases typically express a necessary condition, e.g., I will buy this camera only if they can reduce the price. In such sentences, only usually does not affect whether the sentence is opinionated or not. In case: Conditional sentences containing in case usually describe a precaut</context>
</contexts>
<marker>Gauker, 2005</marker>
<rawString>C. Gauker. 2005. Conditionals in Context. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Dave</author>
<author>A Lawrence</author>
<author>D Pennock</author>
</authors>
<title>Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews.</title>
<date>2003</date>
<tech>WWW-2003.</tech>
<contexts>
<context position="35103" citStr="Dave et al, 2003" startWordPosition="5659" endWordPosition="5662"> method is to use the negation word as a feature, as described in Section 4.1. Another technique is to reverse the orientation of the prediction for those sentences which contain negation words. We found that the former technique yielded better results. The results reported so far are based on the former approach. 6 Related Work There are several research directions in sentiment analysis (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>D. Dave, A. Lawrence, and D. Pennock. 2003. Mining the Peanut Gallery: Opinion Extraction and Semantic Classification of Product Reviews. WWW-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Declerck</author>
<author>S Reed</author>
</authors>
<title>Conditionals: A Comprehensive Empirical Analysis.</title>
<date>2001</date>
<location>Berlin: Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="11803" citStr="Declerck and Reed, 2001" startWordPosition="1851" endWordPosition="1855"> Connective % of sentences If 6.42 Unless 0.32 Even if 0.17 Until 0.10 As (so) long as 0.09 Assuming/supposing 0.04 In case 0.04 Only if 0.03 3.1 Conditional Connectives A large majority of conditional sentences are introduced by the subordinating conjunction If. However, there are also many other conditional connectives, e.g., even if, unless, in case, assuming/supposing, as long as, etc. Table 2 shows the distribution of conditional sentences with various connectives in our data. Detailed linguistic discussions of them are beyond the scope of this paper. Interested readers, please refer to (Declerck and Reed, 2001). Below, we briefly discuss some important ones and their interpretations. If: This is the most commonly used conditional connective. In addition to its own usage, it can also be used to replace other conditional connectives, except some semantically richer connectives (Declerck and Reed, 2001). Most (but not all) conditional sentences can be logically expressed in the form ‘If P then Q’, where P is the condition clause and Q is the consequent clause. For practical purposes, we can automatically segment the condition and consequent clauses using simple rules generated by observing grammatical </context>
<context position="14948" citStr="Declerck and Reed, 2001" startWordPosition="2355" endWordPosition="2358">stinguish those conditional sentences which contain an explicit consequent clause and fit within our analysis framework. In our data, most of such sentences have no consequent, thus representing assumptions rather than opinions. We omit these sentences in our study (they are also rare). 3.2 Types of Conditionals There are extensive studies of conditional sentences (also known as conditionals) in linguistics. Various theories have led to a number of classification systems. Popular types of conditionals include actualization conditionals, inferential conditionals, implicative conditionals, etc (Declerck and Reed, 2001). However, these classifications are mainly based on semantic meanings which are difficult to recognize by a computer program. To build classification models, we instead exploit canonical tense patterns of conditionals, which are often used in pedagogic grammar books. They are defined based on tense and are associated with general meanings. However, as described in (Declerck and Reed, 2001), their meanings are much more complex and numerous than their associated general meanings. However, the advantage of this classification is that different types can be detected easily because they depend on</context>
</contexts>
<marker>Declerck, Reed, 2001</marker>
<rawString>R. Declerck, and S. Reed. 2001. Conditionals: A Comprehensive Empirical Analysis. Berlin: Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ding</author>
<author>B Liu</author>
<author>P S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<pages>2008</pages>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>X. Ding, B. Liu, and P. S. Yu. 2008. A holistic lexicon-based approach to opinion mining. WSDM-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Esuli</author>
<author>F</author>
</authors>
<title>Sebastiani. Determining term subjectivity and term orientation for opinion mining,</title>
<date>2006</date>
<pages>2006</pages>
<marker>Esuli, F, 2006</marker>
<rawString>A. Esuli, and F. 2006. Sebastiani. Determining term subjectivity and term orientation for opinion mining, EACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Fiszman</author>
<author>D Demner-Fushman</author>
<author>F Lang</author>
<author>P Goetz</author>
<author>T Rindflesch</author>
</authors>
<date>2007</date>
<booktitle>Interpreting Comparative Constructions in Biomedical Text. BioNLP-2007.</booktitle>
<contexts>
<context position="37367" citStr="Fiszman et al, 2007" startWordPosition="6031" endWordPosition="6034">006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008). Their work identifies comparative sentences, extracts comparative relations in the sentences and analyzes comparative opinions (Ganapathibhotla and Liu, 2008). An example comparative sentence is “Honda looks better than Toyota”. As we can see, comparative sentences are entirely different from conditional sentences. Thus, their methods cannot be directly applied to conditional sentences. 7 Conclusion To perform sentiment analysis accurately, we argue that a divide-and-conquer approach is needed, i.e., focused study on each type of sentences. It is unlikely that</context>
</contexts>
<marker>Fiszman, Demner-Fushman, Lang, Goetz, Rindflesch, 2007</marker>
<rawString>M. Fiszman, D. Demner-Fushman, F. Lang, P. Goetz, and T. Rindflesch. 2007. Interpreting Comparative Constructions in Biomedical Text. BioNLP-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gamon</author>
<author>A Aue</author>
<author>S Corston-Oliver</author>
<author>S</author>
<author>E Ringger</author>
</authors>
<title>Pulse: Mining customer opinions from free text.</title>
<date>2005</date>
<pages>2005</pages>
<contexts>
<context position="35537" citStr="Gamon et al 2005" startWordPosition="5732" endWordPosition="5735">ions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Y</context>
</contexts>
<marker>Gamon, Aue, Corston-Oliver, S, Ringger, 2005</marker>
<rawString>M. Gamon, A. Aue, S. Corston-Oliver, S. and E. Ringger. 2005. Pulse: Mining customer opinions from free text. IDA-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Ganapathibhotla</author>
<author>B Liu</author>
</authors>
<title>Identifying Preferred Entities in Comparative Sentences.</title>
<date>2008</date>
<contexts>
<context position="37399" citStr="Ganapathibhotla and Liu, 2008" startWordPosition="6035" endWordPosition="6039">iani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008). Their work identifies comparative sentences, extracts comparative relations in the sentences and analyzes comparative opinions (Ganapathibhotla and Liu, 2008). An example comparative sentence is “Honda looks better than Toyota”. As we can see, comparative sentences are entirely different from conditional sentences. Thus, their methods cannot be directly applied to conditional sentences. 7 Conclusion To perform sentiment analysis accurately, we argue that a divide-and-conquer approach is needed, i.e., focused study on each type of sentences. It is unlikely that there is a one-size-fit-all sol</context>
</contexts>
<marker>Ganapathibhotla, Liu, 2008</marker>
<rawString>G. Ganapathibhotla and B. Liu. 2008. Identifying Preferred Entities in Comparative Sentences. COLING-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hatzivassiloglou</author>
<author>K McKeown</author>
<author>K</author>
</authors>
<title>Predicting the Semantic Orientation of Adjectives.</title>
<date>1997</date>
<pages>1997</pages>
<marker>Hatzivassiloglou, McKeown, K, 1997</marker>
<rawString>V. Hatzivassiloglou, and K. McKeown, K. 1997. Predicting the Semantic Orientation of Adjectives. ACL-EACL-1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hu</author>
<author>B Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<pages>2004</pages>
<contexts>
<context position="2322" citStr="Hu and Liu 2004" startWordPosition="353" endWordPosition="356">rch directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehensive survey of the field can be found in (Pang and Lee, 2008). Our work is in the area of topic/feature-based sentiment analysis or opinion mining (Hu and Liu, 2004). The existing research focuses on solving the general problem. However, we argue that it is unlikely to have a one-t</context>
<context position="9665" citStr="Hu and Liu 2004" startWordPosition="1504" endWordPosition="1507">asily integrated into an overall sentiment analysis or opinion mining system. The answer is yes because a large proportion of conditional sentences can be detected using conditional connectives. Keyword search is 181 thus sufficient to identify such sentences for special handling using the proposed approach. There are, however, some subtle conditionals which do not use normal conditional connectives and will need an additional module to identify them, but such sentences are very rare as Table 2 indicates. 2 The Problem Statement The paper follows the feature-based sentiment analysis model in (Hu and Liu 2004; Popescu and Etzioni, 2005). We are particularly interested in sentiments on products and services, which are called objects or entities. Each object is described by its parts and attributes, which are collectively called features in (Hu and Liu, 2004; Liu, 2006). For example, in the sentence, If this camera has great picture quality, I will buy it, “picture quality” is a feature of the camera. For formal definitions of objects and features, please refer to (Liu, 2006; Liu, 2009). In this paper, we use the term topic to mean feature as the feature here can confuse with the feature used in mac</context>
<context position="19333" citStr="Hu and Liu, 2004" startWordPosition="3074" endWordPosition="3077">w describe our computational study. We take a machine learning approach to predict sentiment orientations. Below, we first describe features used and then classification strategies. 4.1 Feature construction I. Sentiment words/phrases and their locations: Sentiment words are words used to express positive or negative opinions, which are instrumental for sentiment classification for obvious reasons. We obtained a list of over 6500 sentiment words gathered from various sources. The bulk of it is from http://www.cs.pitt.edu/mpqa. We also added some of our own. Our list is mainly from the work in (Hu and Liu, 2004; Ding, Liu and Yu, 2008). In addition to words, there are phrases that describe opinions. We have identified a set of such phrases. Although obtaining these phrases was time-consuming, it was only a one-time effort. We will make this list available as a community resource. It is possible that there is a better automated method for finding such phrases, such as the methods in (Kanayama and Nasukawa, 2006; Breck, Choi and Cardie, 2007). However, automatically generating sentiment phrases has not been the focus of this work as our objective is to study how the two clauses interact to determine o</context>
<context position="36038" citStr="Hu and Liu, 2004" startWordPosition="5810" endWordPosition="5813">02, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using </context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>M. Hu and B. Liu. 2004. Mining and summarizing customer reviews. KDD-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Jindal</author>
<author>B Liu</author>
</authors>
<title>Mining Comparative Sentences and Relations.</title>
<date>2006</date>
<contexts>
<context position="37324" citStr="Jindal and Liu, 2006" startWordPosition="6023" endWordPosition="6026"> Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008). Their work identifies comparative sentences, extracts comparative relations in the sentences and analyzes comparative opinions (Ganapathibhotla and Liu, 2008). An example comparative sentence is “Honda looks better than Toyota”. As we can see, comparative sentences are entirely different from conditional sentences. Thus, their methods cannot be directly applied to conditional sentences. 7 Conclusion To perform sentiment analysis accurately, we argue that a divide-and-conquer approach is needed, i.e., focused study on </context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>N. Jindal, and B. Liu. 2006. Mining Comparative Sentences and Relations. AAAI-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kaji</author>
<author>M Kitsuregawa</author>
</authors>
<title>Automatic construction of polarity-tagged corpus from HTML documents.</title>
<date>2006</date>
<pages>2006</pages>
<contexts>
<context position="36722" citStr="Kaji and Kitsuregawa, 2006" startWordPosition="5924" endWordPosition="5928">l, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 20</context>
</contexts>
<marker>Kaji, Kitsuregawa, 2006</marker>
<rawString>N. Kaji, and M. Kitsuregawa. 2006. Automatic construction of polarity-tagged corpus from HTML documents. ACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kanayama</author>
<author>T Nasukawa</author>
</authors>
<title>Fully Automatic Lexicon Expansion for DomainOriented Sentiment Analysis.</title>
<date>2006</date>
<contexts>
<context position="19740" citStr="Kanayama and Nasukawa, 2006" startWordPosition="3143" endWordPosition="3146">ons. We obtained a list of over 6500 sentiment words gathered from various sources. The bulk of it is from http://www.cs.pitt.edu/mpqa. We also added some of our own. Our list is mainly from the work in (Hu and Liu, 2004; Ding, Liu and Yu, 2008). In addition to words, there are phrases that describe opinions. We have identified a set of such phrases. Although obtaining these phrases was time-consuming, it was only a one-time effort. We will make this list available as a community resource. It is possible that there is a better automated method for finding such phrases, such as the methods in (Kanayama and Nasukawa, 2006; Breck, Choi and Cardie, 2007). However, automatically generating sentiment phrases has not been the focus of this work as our objective is to study how the two clauses interact to determine opinions given the sentiment words and phrases are known. Our list of phrases is by no means complete and we will continue to expand it in the future. For each sentence, we also identify whether it contains sentiment words/phrases in its condition or consequent clause. It was observed that the presence of a sentiment word/phrase in the consequent clause has more effect on the sentiment of a sentence. II. </context>
<context position="36751" citStr="Kanayama and Nasukawa, 2006" startWordPosition="5929" endWordPosition="5932">ng, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fis</context>
</contexts>
<marker>Kanayama, Nasukawa, 2006</marker>
<rawString>H. Kanayama, and T. Nasukawa. 2006. Fully Automatic Lexicon Expansion for DomainOriented Sentiment Analysis. EMNLP-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>E Hovy</author>
</authors>
<title>Determining the Sentiment of Opinions.</title>
<date>2004</date>
<contexts>
<context position="10359" citStr="Kim and Hovy, 2004" startWordPosition="1625" endWordPosition="1628">n products and services, which are called objects or entities. Each object is described by its parts and attributes, which are collectively called features in (Hu and Liu, 2004; Liu, 2006). For example, in the sentence, If this camera has great picture quality, I will buy it, “picture quality” is a feature of the camera. For formal definitions of objects and features, please refer to (Liu, 2006; Liu, 2009). In this paper, we use the term topic to mean feature as the feature here can confuse with the feature used in machine learning. The term topic has also been used by some researchers (e.g., Kim and Hovy, 2004; Stoyanov and Cardie, 2008). Our objective is to predict the sentiment orientation (positive, negative or neutral) on each topic that has been commented on in a sentence. The problem of automatically identifying features or topics being spoken about in a sentence has been studied in (Hu and Liu, 2004; Popescu and Etzioni, 2005; Stoyanov and Cardie, 2008). In this work, we do not attempt to identify such topics automatically. Instead, we assume that they are given because our objective is to study how the interaction of the condition and consequent clauses affects sentiments. For this purpose,</context>
<context position="35495" citStr="Kim and Hovy, 2004" startWordPosition="5724" endWordPosition="5727"> (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et </context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>S. Kim and E. Hovy. 2004. Determining the Sentiment of Opinions. COLING-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kobayashi</author>
<author>K Inui</author>
<author>Y Matsumoto</author>
</authors>
<date>2007</date>
<booktitle>Extracting Aspect-Evaluation and Aspect-of Relations in Opinion Mining. EMNLP-2007.</booktitle>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>N. Kobayashi, K. Inui and Y. Matsumoto. 2007. Extracting Aspect-Evaluation and Aspect-of Relations in Opinion Mining. EMNLP-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L-W Ku</author>
<author>Y-T Liang</author>
<author>H-H Chen</author>
</authors>
<title>Opinion Extraction, Summarization and Tracking in News and Blog Corpora.</title>
<date>2006</date>
<publisher>AAAICAAW.</publisher>
<contexts>
<context position="2389" citStr="Ku et al., 2006" startWordPosition="366" endWordPosition="369">ion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehensive survey of the field can be found in (Pang and Lee, 2008). Our work is in the area of topic/feature-based sentiment analysis or opinion mining (Hu and Liu, 2004). The existing research focuses on solving the general problem. However, we argue that it is unlikely to have a one-technique-fit-all solution because different types of sentences expr</context>
<context position="36081" citStr="Ku et al, 2006" startWordPosition="5818" endWordPosition="5821">al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and </context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>L.-W. Ku, Y.-T. Liang, and H.-H. Chen. 2006, Opinion Extraction, Summarization and Tracking in News and Blog Corpora. AAAICAAW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Web Data Mining: Exploring Hyperlinks, Content and Usage Data.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="2615" citStr="Liu, 2006" startWordPosition="402" endWordPosition="403">02; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehensive survey of the field can be found in (Pang and Lee, 2008). Our work is in the area of topic/feature-based sentiment analysis or opinion mining (Hu and Liu, 2004). The existing research focuses on solving the general problem. However, we argue that it is unlikely to have a one-technique-fit-all solution because different types of sentences express sentiments/opinions in different ways. A divide-and-conquer approach is needed, e.g., focused studies on different types of sentences. This paper focuses on one type of sentences, i.e., conditional sentences, which have so</context>
<context position="9929" citStr="Liu, 2006" startWordPosition="1549" endWordPosition="1550">al handling using the proposed approach. There are, however, some subtle conditionals which do not use normal conditional connectives and will need an additional module to identify them, but such sentences are very rare as Table 2 indicates. 2 The Problem Statement The paper follows the feature-based sentiment analysis model in (Hu and Liu 2004; Popescu and Etzioni, 2005). We are particularly interested in sentiments on products and services, which are called objects or entities. Each object is described by its parts and attributes, which are collectively called features in (Hu and Liu, 2004; Liu, 2006). For example, in the sentence, If this camera has great picture quality, I will buy it, “picture quality” is a feature of the camera. For formal definitions of objects and features, please refer to (Liu, 2006; Liu, 2009). In this paper, we use the term topic to mean feature as the feature here can confuse with the feature used in machine learning. The term topic has also been used by some researchers (e.g., Kim and Hovy, 2004; Stoyanov and Cardie, 2008). Our objective is to predict the sentiment orientation (positive, negative or neutral) on each topic that has been commented on in a sentence</context>
<context position="37324" citStr="Liu, 2006" startWordPosition="6025" endWordPosition="6026">a, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008). Their work identifies comparative sentences, extracts comparative relations in the sentences and analyzes comparative opinions (Ganapathibhotla and Liu, 2008). An example comparative sentence is “Honda looks better than Toyota”. As we can see, comparative sentences are entirely different from conditional sentences. Thus, their methods cannot be directly applied to conditional sentences. 7 Conclusion To perform sentiment analysis accurately, we argue that a divide-and-conquer approach is needed, i.e., focused study on </context>
</contexts>
<marker>Liu, 2006</marker>
<rawString>B. Liu. 2006. Web Data Mining: Exploring Hyperlinks, Content and Usage Data. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Liu</author>
</authors>
<title>Sentiment Analysis and Subjectivity. To appear</title>
<date>2009</date>
<booktitle>in Handbook of Natural Language Processing, Second Edition,</booktitle>
<editor>(editors: N. Indurkhya and F. J. Damerau),</editor>
<contexts>
<context position="2627" citStr="Liu, 2009" startWordPosition="404" endWordPosition="405">Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehensive survey of the field can be found in (Pang and Lee, 2008). Our work is in the area of topic/feature-based sentiment analysis or opinion mining (Hu and Liu, 2004). The existing research focuses on solving the general problem. However, we argue that it is unlikely to have a one-technique-fit-all solution because different types of sentences express sentiments/opinions in different ways. A divide-and-conquer approach is needed, e.g., focused studies on different types of sentences. This paper focuses on one type of sentences, i.e., conditional sentences, which have some unique ch</context>
<context position="10150" citStr="Liu, 2009" startWordPosition="1587" endWordPosition="1588">s Table 2 indicates. 2 The Problem Statement The paper follows the feature-based sentiment analysis model in (Hu and Liu 2004; Popescu and Etzioni, 2005). We are particularly interested in sentiments on products and services, which are called objects or entities. Each object is described by its parts and attributes, which are collectively called features in (Hu and Liu, 2004; Liu, 2006). For example, in the sentence, If this camera has great picture quality, I will buy it, “picture quality” is a feature of the camera. For formal definitions of objects and features, please refer to (Liu, 2006; Liu, 2009). In this paper, we use the term topic to mean feature as the feature here can confuse with the feature used in machine learning. The term topic has also been used by some researchers (e.g., Kim and Hovy, 2004; Stoyanov and Cardie, 2008). Our objective is to predict the sentiment orientation (positive, negative or neutral) on each topic that has been commented on in a sentence. The problem of automatically identifying features or topics being spoken about in a sentence has been studied in (Hu and Liu, 2004; Popescu and Etzioni, 2005; Stoyanov and Cardie, 2008). In this work, we do not attempt </context>
</contexts>
<marker>Liu, 2009</marker>
<rawString>B. Liu. 2009. Sentiment Analysis and Subjectivity. To appear in Handbook of Natural Language Processing, Second Edition, (editors: N. Indurkhya and F. J. Damerau), 2009 or 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lu</author>
<author>C X Zhai</author>
</authors>
<title>Opinion integration through semi-supervised topic modeling.</title>
<date>2008</date>
<pages>2008</pages>
<contexts>
<context position="36220" citStr="Lu and Zhai, 2008" startWordPosition="5846" endWordPosition="5849">, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 20</context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Y. Lu, and C. X. Zhai. 2008. Opinion integration through semi-supervised topic modeling. WWW-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Hannan</author>
<author>T Neylon</author>
<author>M Wells</author>
<author>J Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<pages>2007</pages>
<contexts>
<context position="35142" citStr="McDonald et al, 2007" startWordPosition="5667" endWordPosition="5670">d as a feature, as described in Section 4.1. Another technique is to reverse the orientation of the prediction for those sentences which contain negation words. We found that the former technique yielded better results. The results reported so far are based on the former approach. 6 Related Work There are several research directions in sentiment analysis (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing wit</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>R. McDonald, K. Hannan, T. Neylon, M. Wells, and J. Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. ACL-2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Mei</author>
<author>X Ling</author>
<author>M Wondra</author>
<author>H Su</author>
<author>C X Zhai</author>
</authors>
<title>Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs.</title>
<date>2007</date>
<contexts>
<context position="36120" citStr="Mei et al, 2007" startWordPosition="5827" endWordPosition="5830">nd Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 20</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Q. Mei, X. Ling, M. Wondra, H. Su, and C. X. Zhai. 2007. Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs. WWW2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>S Dasgupta</author>
<author>S M Niaz Arifin</author>
</authors>
<title>Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews.</title>
<date>2006</date>
<pages>2006</pages>
<contexts>
<context position="35119" citStr="Ng et al. 2006" startWordPosition="5663" endWordPosition="5666">the negation word as a feature, as described in Section 4.1. Another technique is to reverse the orientation of the prediction for those sentences which contain negation words. We found that the former technique yielded better results. The results reported so far are based on the former approach. 6 Related Work There are several research directions in sentiment analysis (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, an</context>
</contexts>
<marker>Ng, Dasgupta, Arifin, 2006</marker>
<rawString>V. Ng, S. Dasgupta, and S. M. Niaz Arifin. 2006. Examining the role of linguistic knowledge sources in the automatic identification and classification of reviews. ACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion Mining and Sentiment Analysis. Foundations and Trends</title>
<date>2008</date>
<booktitle>in Information Retrieval 2(1-2),</booktitle>
<pages>1--135</pages>
<contexts>
<context position="2701" citStr="Pang and Lee, 2008" startWordPosition="416" endWordPosition="419">as done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehensive survey of the field can be found in (Pang and Lee, 2008). Our work is in the area of topic/feature-based sentiment analysis or opinion mining (Hu and Liu, 2004). The existing research focuses on solving the general problem. However, we argue that it is unlikely to have a one-technique-fit-all solution because different types of sentences express sentiments/opinions in different ways. A divide-and-conquer approach is needed, e.g., focused studies on different types of sentences. This paper focuses on one type of sentences, i.e., conditional sentences, which have some unique characteristics that make it hard to determine the orientation of sentiments</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>B. Pang and L. Lee. 2008. Opinion Mining and Sentiment Analysis. Foundations and Trends in Information Retrieval 2(1-2), pp. 1–135, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment Classification Using Machine Learning Techniques.</title>
<date>2002</date>
<tech>EMNLP2002.</tech>
<contexts>
<context position="1852" citStr="Vaithyanathan, 2002" startWordPosition="282" endWordPosition="283">nguistic analysis of such sentences, and then builds some supervised learning models to determine if sentiments expressed on different topics in a conditional sentence are positive, negative or neutral. Experimental results on conditional sentences from 5 diverse domains are given to demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis (also called opinion mining) has been an active research area in recent years. There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008</context>
</contexts>
<marker>Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee. and S. Vaithyanathan. 2002. Thumbs up? Sentiment Classification Using Machine Learning Techniques. EMNLP2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-M Popescu</author>
<author>O Etzioni</author>
</authors>
<date>2005</date>
<booktitle>Extracting Product Features and Opinions from Reviews. EMNLP-2005.</booktitle>
<contexts>
<context position="2349" citStr="Popescu and Etzioni, 2005" startWordPosition="357" endWordPosition="361">.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehensive survey of the field can be found in (Pang and Lee, 2008). Our work is in the area of topic/feature-based sentiment analysis or opinion mining (Hu and Liu, 2004). The existing research focuses on solving the general problem. However, we argue that it is unlikely to have a one-technique-fit-all solution b</context>
<context position="9693" citStr="Popescu and Etzioni, 2005" startWordPosition="1508" endWordPosition="1511">into an overall sentiment analysis or opinion mining system. The answer is yes because a large proportion of conditional sentences can be detected using conditional connectives. Keyword search is 181 thus sufficient to identify such sentences for special handling using the proposed approach. There are, however, some subtle conditionals which do not use normal conditional connectives and will need an additional module to identify them, but such sentences are very rare as Table 2 indicates. 2 The Problem Statement The paper follows the feature-based sentiment analysis model in (Hu and Liu 2004; Popescu and Etzioni, 2005). We are particularly interested in sentiments on products and services, which are called objects or entities. Each object is described by its parts and attributes, which are collectively called features in (Hu and Liu, 2004; Liu, 2006). For example, in the sentence, If this camera has great picture quality, I will buy it, “picture quality” is a feature of the camera. For formal definitions of objects and features, please refer to (Liu, 2006; Liu, 2009). In this paper, we use the term topic to mean feature as the feature here can confuse with the feature used in machine learning. The term topi</context>
<context position="36065" citStr="Popescu and Etzioni, 2005" startWordPosition="5814" endWordPosition="5817">ssiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzi</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>A-M. Popescu, and O. Etzioni. 2005. Extracting Product Features and Opinions from Reviews. EMNLP-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Qiu</author>
<author>B Liu</author>
<author>J Bu</author>
<author>C Chen</author>
</authors>
<date>2009</date>
<booktitle>Expanding Domain Sentiment Lexicon through Double Propagation. IJCAI-2009.</booktitle>
<contexts>
<context position="36840" citStr="Qiu et al, 2009" startWordPosition="5946" endWordPosition="5949">eir objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; Ding, Liu and Yu. 2008; Qiu et al, 2009). There are several existing lists produced by researchers. We used the one from the MPQA corpus (http://www.cs.pitt.edu/mpqa) with added phrases of our own from (Ding, Liu and Yu. 2008). In our work, we also assume that the topics are known. (Hu and Liu, 2004; Popescu and Etzioni, 2005; Kobayashi, Inui and Matsumoto, 2007; Stoyanov and Cardie, 2008) have studied topic/feature extraction. One existing focused study is on comparative and superlative sentences (Jindal and Liu, 2006; Bos and Nissim, 2006; Fiszman et al, 2007; Ganapathibhotla and Liu, 2008). Their work identifies comparative sente</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2009</marker>
<rawString>G. Qiu, B. Liu, J. Bu and C. Chen. 2009. Expanding Domain Sentiment Lexicon through Double Propagation. IJCAI-2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<pages>2003</pages>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>E. Riloff, and J. Wiebe. 2003. Learning extraction patterns for subjective expressions. EMNLP-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Stoyanov</author>
<author>C Cardie</author>
</authors>
<title>Topic Identification for fine-grained opinion analysis.</title>
<date>2008</date>
<pages>2008</pages>
<contexts>
<context position="10387" citStr="Stoyanov and Cardie, 2008" startWordPosition="1629" endWordPosition="1632">ces, which are called objects or entities. Each object is described by its parts and attributes, which are collectively called features in (Hu and Liu, 2004; Liu, 2006). For example, in the sentence, If this camera has great picture quality, I will buy it, “picture quality” is a feature of the camera. For formal definitions of objects and features, please refer to (Liu, 2006; Liu, 2009). In this paper, we use the term topic to mean feature as the feature here can confuse with the feature used in machine learning. The term topic has also been used by some researchers (e.g., Kim and Hovy, 2004; Stoyanov and Cardie, 2008). Our objective is to predict the sentiment orientation (positive, negative or neutral) on each topic that has been commented on in a sentence. The problem of automatically identifying features or topics being spoken about in a sentence has been studied in (Hu and Liu, 2004; Popescu and Etzioni, 2005; Stoyanov and Cardie, 2008). In this work, we do not attempt to identify such topics automatically. Instead, we assume that they are given because our objective is to study how the interaction of the condition and consequent clauses affects sentiments. For this purpose, we manually identify all th</context>
<context position="36200" citStr="Stoyanov and Cardie, 2008" startWordPosition="5841" endWordPosition="5845">e works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etzioni, 2005; Ku et al, 2006; Carenini et al, 2006; Mei et al, 2007; Ding, Liu and Yu, 2008; Titov and R. McDonald, 2008; Stoyanov and Cardie, 2008; Lu and Zhai, 2008). Their objective is to extract topics or product features in sentences and determine whether the sentiments expressed on them are positive or negative. Again, no focused study has been made to handle conditional sentences. Effectively handling of conditional sentences can help their effort significantly. 187 In this work, we used many sentiment words and phrases. These words and phrases are usually compiled using different approaches (Hatzivassiloglou and McKeown, 1997; Kaji and Kitsuregawa, 2006; Kanayama and Nasukawa, 2006; Esuli and Sebastiani, 2006; Breck et al, 2007; </context>
</contexts>
<marker>Stoyanov, Cardie, 2008</marker>
<rawString>V. Stoyanov, and C. Cardie. 2008. Topic Identification for fine-grained opinion analysis. COLING-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Titov</author>
<author>R McDonald</author>
</authors>
<title>A Joint Model of Text and Aspect Ratings for Sentiment Summarization.</title>
<date>2008</date>
<marker>Titov, McDonald, 2008</marker>
<rawString>I. Titov and R. McDonald. 2008. A Joint Model of Text and Aspect Ratings for Sentiment Summarization. ACL-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews.</title>
<date>2002</date>
<contexts>
<context position="1867" citStr="Turney, 2002" startWordPosition="284" endWordPosition="285">such sentences, and then builds some supervised learning models to determine if sentiments expressed on different topics in a conditional sentence are positive, negative or neutral. Experimental results on conditional sentences from 5 diverse domains are given to demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis (also called opinion mining) has been an active research area in recent years. There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal defin</context>
<context position="35085" citStr="Turney, 2002" startWordPosition="5657" endWordPosition="5658">sentiment. One method is to use the negation word as a feature, as described in Section 4.1. Another technique is to reverse the orientation of the prediction for those sentences which contain negation words. We found that the former technique yielded better results. The results reported so far are based on the former approach. 6 Related Work There are several research directions in sentiment analysis (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs Up or Thumbs Down? Semantic Orientation Applied to Unsupervised Classification of Reviews. ACL-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>R Bruce</author>
<author>T O’Hara</author>
</authors>
<title>Development and use of a gold standard data set for subjectivity classifications.</title>
<date>1999</date>
<pages>1999</pages>
<marker>Wiebe, Bruce, O’Hara, 1999</marker>
<rawString>J. Wiebe, R. Bruce, and T. O’Hara. 1999. Development and use of a gold standard data set for subjectivity classifications. ACL-1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wiebe</author>
<author>T Wilson</author>
</authors>
<title>Learning to Disambiguate Potentially Subjective Expressions.</title>
<date>2002</date>
<publisher>CoNLL-2002.</publisher>
<contexts>
<context position="2008" citStr="Wiebe and Wilson, 2002" startWordPosition="302" endWordPosition="305">ional sentence are positive, negative or neutral. Experimental results on conditional sentences from 5 diverse domains are given to demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis (also called opinion mining) has been an active research area in recent years. There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Li</context>
<context position="35424" citStr="Wiebe and Wilson, 2002" startWordPosition="5712" endWordPosition="5715"> 6 Related Work There are several research directions in sentiment analysis (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu</context>
</contexts>
<marker>Wiebe, Wilson, 2002</marker>
<rawString>J. Wiebe, and T. Wilson. 2002. Learning to Disambiguate Potentially Subjective Expressions. CoNLL-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
</authors>
<title>Just how mad are you? Finding strong and weak opinion clauses.</title>
<date>2004</date>
<pages>2004</pages>
<marker>Hwa, 2004</marker>
<rawString>T. Wilson, J. Wiebe. and R. Hwa. 2004. Just how mad are you? Finding strong and weak opinion clauses. AAAI-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yu</author>
<author>Y Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<pages>2003</pages>
<contexts>
<context position="2039" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="306" endWordPosition="310">ive, negative or neutral. Experimental results on conditional sentences from 5 diverse domains are given to demonstrate the effectiveness of the proposed approach. 1 Introduction Sentiment analysis (also called opinion mining) has been an active research area in recent years. There are many research directions, e.g., sentiment classification (classifying an opinion document as positive or negative) (e.g., Pang, Lee and Vaithyanathan, 2002; Turney, 2002), subjectivity classification (determining whether a sentence is subjective or objective, and its associated opinion) (Wiebe and Wilson, 2002; Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and * This work was done when Bing Liu was on sabbatical leave at Northwestern University. Hovy, 2004; Riloff and Wiebe, 2005), feature/topic-based sentiment analysis (assigning positive or negative sentiments to topics or product features) (Hu and Liu 2004; Popescu and Etzioni, 2005; Carenini et al., 2005; Ku et al., 2006; Kobayashi, Inui and Matsumoto, 2007; Titov and McDonald. 2008). Formal definitions of different aspects of the sentiment analysis problem and discussions of major research directions and algorithms can be found in (Liu, 2006; Liu, 2009). A comprehe</context>
<context position="35455" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="5716" endWordPosition="5719">e several research directions in sentiment analysis (or opinion mining). One of the main directions is sentiment classification, which classifies the whole opinion document (e.g., a product review) as positive or negative (e.g., Pang et al, 2002; Turney, 2002; Dave et al, 2003; Ng et al. 2006; McDonald et al, 2007). It is clearly different from our work as we are interested in conditional sentences. Another important direction is classifying sentences as subjective or objective, and classifying subjective sentences or clauses as positive or negative (Wiebe et al, 1999; Wiebe and Wilson, 2002, Yu and Hatzivassiloglou, 2003; Wilson et al, 2004; Kim and Hovy, 2004; Riloff and Wiebe, 2005; Gamon et al 2005; McDonald et al, 2007). Although these works deal with sentences, they aim to solve the general problem. This paper argues that there is unlikely a onetechnique-fit-all solution, and advocates dealing with specific types of sentences differently by exploiting their unique characteristics. Conditional sentences are the focus of this paper. To the best of our knowledge, there is no focused study on them. Several researchers also studied feature/topicbased sentiment analysis (e.g., Hu and Liu, 2004; Popescu and Etz</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>H. Yu, and Y. Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. EMNLP-2003.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>