<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999609666666667">
The Generative Power of Categorial
Grammars and Head-Driven Phrase
Structure Grammars with Lexical Rules
</title>
<author confidence="0.999562">
Bob Carpenter.
</author>
<affiliation confidence="0.990589">
Carnegie Mellon University
</affiliation>
<bodyText confidence="0.998069166666667">
In this paper, it is shown that the addition of simple and linguistically motivated forms of lexical
rules to grammatical theories based on subcategorization lists, such as categorial grammars
(CG) or head-driven phrase structure grammars (HPSG), results in a system that can generate
all and only the recursively enumerable languages. The proof of this result is carried out by
means of a reduction of generalized rewriting systems. Two restrictions are considered, each of
which constrains the generative power of the resulting system to context-free languages.
</bodyText>
<sectionHeader confidence="0.993959" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999906076923077">
In recent grammatical theories, there has been an increasing trend toward the lexical-
ization of syntactic information. This is particularly evident in the case of categorial
grammars (CG) and head-driven phrase structure grammars (HPSG), where a small
number of highly schematic syntactic rules are assumed to apply universally. With
this assumption of a universal syntax, the task of explaining the variations between
languages must be carried out in the lexicon. Rather than assuming that the lexicon is
simply an unstructured list associating words with syntactic categories, organization
is usually imposed by means of hierarchical inheritance systems, linking theories re-
lating lexical semantics to grammatical categories and finally with lexical rules. It is
the lexical rule component of these grammars that we investigate in this paper.
We present a straightforward formalization of categorial grammars with lexical
rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and
Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG
lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag
(1987). We show that even using such a simple form of lexical rules, any recursively
enumerable language can be recognized. Thus the addition of lexical rules leads to
systems in which it is not possible to effectively decide whether a string is accepted
by a grammar. We first introduce a pared-down formalism that captures the way in
which heads combine with complements in CG and HPSG. We then provide examples
to motivate a very straightforward and natural system of lexical rules.
To show that arbitrary recursively enumerable languages may be generated by
the resulting system, we provide a reduction of generalized rewriting systems (Type 0
grammars). Though the details of our reduction are different, our method is reminis-
cent of that used by Uszkoreit and Peters (1986) to show that context-free grammars
with metarules could generate arbitrary recursively enumerable languages. The anal-
ogy between CG lexical rules and GPSG metarules is strengthened by the fact that
</bodyText>
<note confidence="0.7260375">
* Computational Linguistics Program, Philosophy Department, Carnegie Mellon University, Pittsburgh,
PA 15213 USA; e-mail: carp@lcl.cmu.edu
© 1991 Association for Computational Linguistics
Computational Linguistics Volume 17, Number 3
</note>
<bodyText confidence="0.999465">
GPSG as presented in Gazdar et al. (1985) restricts the application of metarules to
lexical phrase structure rules.
Along the way to proving that categorial grammars with lexical rules can generate
arbitrary recursively enumerable languages, we consider two restrictions that have
the effect of reducing the generative power of the system to context-free languages.
The first of these restrictions limits the recursive application of lexical rules, while
the second puts a bound on the number of complements that can be specified by a
category.
</bodyText>
<sectionHeader confidence="0.649059" genericHeader="categories and subject descriptors">
2. CGs and HPSGs
</sectionHeader>
<bodyText confidence="0.999916272727273">
In Generalized Phrase Structure Grammar (GPSG) as presented in Gazdar et al. (1985),
each lexical head category is assigned a simple integer subcategorization value. Sim-
ilarly, each lexical phrase structure rule specifies the possible value(s) of the subcate-
gorization feature occurring on its head daughter. In both CG and HPSG, the subcate-
gorization value and correspondingly indexed phrase structure rule are replaced with
a lexical encoding of head/complement structure by means of a subcategorization or
complement list. The exact characterization of the notion of head has been the subject
of some debate, but which items are labeled as heads is not important here; we use
the term head to refer to any category that specifies its complements. Thus heads
in our sense may be categories traditionally classified as specifiers or adjuncts. The
subcategorization list of a category determines the number, form, and order of its com-
plements. The only syntactic rule scheme that we consider is one that allows a head to
combine with a complement. The result of such a construction is a category just like
the head, only with the complement removed from its subcategorization list. Many
extended categorial grammar systems and the HPSG system allow more sophisticated
rules than this to deal with adjuncts, coordination, and long-distance dependencies,
but we only need the simple head-complement construction to show that the addition
of lexical rules leads to undecidability.
We now turn to a more formal presentation of a framework that incorporates the
core of both CG and HPSG. We begin with a finite set BasCat of basic categories
out of which complex categories are constructed. The collection of basic categories is
usually assumed to contain &amp;quot;saturated&amp;quot; syntactic categories, including nouns, noun
phrases, sentences, and so forth, but the choice of basic categories is ultimately up to
the grammar writer. We are not concerned with the details of any particular syntactic
analysis here. The full set Cat of categories is defined to be the least collection of objects
of the form b[co, , c,,_i] where b E BasCat is a basic category and c, E Cat for i &lt; n.
The categories between the brackets specify the arguments of the category, with the
assumption being that these arguments must be attached in the order in which they
occur on the subcategorization list. While our notation follows the usage of HPSG and
Unification Categorial Grammar (Calder et al. 1988), it should be clear how it relates
to more traditional categorial grammar notation (see Bar-Hillel et al. 1960).
We assume the following schematic phrase structure rule that allows heads to
combine with a single complement:
</bodyText>
<subsectionHeader confidence="0.605569">
Definition 1
</subsectionHeader>
<bodyText confidence="0.964519">
b[ci,... ,c] b[co,... ,c] co
In most categorial grammars and in HPSG, there are rules in which the complement
category precedes the head, but we do not even need this much power. For instance,
a simple transitive verb might be given the category s[np[] , np[]], a noun phrase the
</bodyText>
<page confidence="0.99589">
302
</page>
<note confidence="0.780094">
Carpenter CG and HPSG with Lexical Rules
</note>
<bodyText confidence="0.978002375">
category np[], a noun n[], and a determiner the category np[n[]]. Thus the rule instance
s [np[]] ---+ s[np[], np[]] np[] allows the combination of a transitive verb with an object
noun phrase, while the rule np[] np[n[]] nn would allow a determiner followed by
a noun to be analyzed as a noun phrase.
Let Rule be the set of all instances of the schematic rule applied to Cat. Note that
this set is totally determined by the choice BasCat of basic categories.
A lexicon for our simple grammar formalism consists of a finite relation between
categories and basic expressions:
</bodyText>
<equation confidence="0.3113495">
Definition 2
Lex C BasExp x Cat.
</equation>
<bodyText confidence="0.95190975">
We write e c if (e, c) E Lex. There is no restriction preventing a single expression from
having more than one lexical entry. What we have with Lex and Rule is a simple phrase
structure grammar, albeit one with an infinite set of rules. We interpret admissibility
(well-formedness or grammaticality) in this phrase structure grammar in the usual
way (see Hoperoft and Ullman 1979:79-87). In particular, we take Lex (c) to be the set
of strings of basic expressions of category c. By mutual recursion over Cat we define
the GLex (c) as the minimal sets such that:
Definition 3
</bodyText>
<listItem confidence="0.9873646">
• e E LLex(C) if (e, c) E Lex
eie2
• , , cn] ) and e2
CLex(cicl, E LLex (c[co, E Lex So )•
• • • , if el
</listItem>
<bodyText confidence="0.997260538461539">
It should be fairly obvious at this point how our simple categorial grammar for-
malism represents the core of both categorial grammars and the subcategorization
component of HPSG. It should also be noted that such a grammar and lexical as-
signment reduces to a context-free grammar. This is because only finitely many sub-
categories of the lexical categories may ever be used in a derivation and thus only
finitely many instances of the application scheme are necessary for a finite categorial
lexicon. Somewhat surprisingly, the converse result also holds (Bar-Hillel et al. 1960);
every context-free language is generated by some categorial grammar in the form we
have presented. This latter result can be deduced from the fact that every context-free
language can be expressed with a Greibach normal form grammar where every pro-
duction is of the form Co aCi • • C, where n &gt; 0, the C, are nonterminal category
symbols, and a is a terminal expression (see Hoperoft and Ullman 1979). Taking a ba-
sic category for every nonterminal of the context-free grammar and a lexical entry of
the form a Co[C1[J,.. . ,Cn[]] for every production of the above form in the context-
free grammar, we produce a categorial grammar that can be shown by induction on
derivation length to generate exactly the same language as the Greibach normal form
context-free grammar.
Not only is recognition decidable for context-free languages, but Earley&apos;s (1970) al-
gorithm is known to decide them in 0(n3) time where n is the length of the input string
(in fact, general CFG parsing algorithms can be constructed from matrix multiplication
algorithms with slightly better worst-case asymptotic performance than Earley&apos;s algo-
rithm [Valiant 19751). Unfortunately, the situation is quite different after the addition
of lexical rules.
Before going on, it should be noted that one of the primary reasons for employing
categorial grammars is its natural relation to a compositional semantics (Montague
1970). While we do not consider the semantic effects of lexical rules here, the interested
</bodyText>
<page confidence="0.997091">
303
</page>
<note confidence="0.308175">
Computational Linguistics Volume 17, Number 3
</note>
<bodyText confidence="0.7140125">
reader is urged to consult Carpenter (1991) for details of how a higher-order typed
semantics can be naturally added to the system of lexical rules presented below.
</bodyText>
<sectionHeader confidence="0.433224" genericHeader="method">
3. Adding Lexical Rules
</sectionHeader>
<bodyText confidence="0.999865761904762">
The form of lexical rules that we propose to add to the basic categorial system are what
Keenan and Faltz (1985) have termed valency affecting operations. These operations
allow the permutation, addition, or subtraction of complements and the modification
of the head or functor category. Our operations do not have any overt morphological
effects, and are thus often referred to as zero morphemes. The same general lexical
rule format has been proposed by virtually everyone considering the lexicon from
a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985;
Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and
Aone and Wittenburg (1990) have presented systems that allow extended categorial
grammars to operate at both the morphological and syntactic levels, but the operations
that can be carried out by their extended sets of rules produce results very similar to the
lexical operations we allow here. Our results are especially relevant in light of recent
work in HPSG, which admits lexical rules that do the same work as the ones employed
here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague,
Dowty (1979) allowed arbitrary well-defined operations to be applied to lexical entries,
but none of the rules he considered fall outside of the scope of the system presented
here. The lexical generalizations studied by Bach (1984) led him to employ lexical
redundancy rules that are expressed by composing basic functions that pick out the
head or tail of a subcategorization list as well as the subcategorization list with either
the head or tail removed. More formally, Bach allowed arbitrary concatenations and
compositions of the following functions to be applied to subcategorization lists:
</bodyText>
<equation confidence="0.9624446">
Definition 4
FIRST(xi • • xn) =
RREST(X1 • • • Xn) = X2 • • • Xn
LAST(X1 &apos; • • xn) = Xn
LREST(X1 • • • XII) = X1 • • &apos; Xn-1
</equation>
<bodyText confidence="0.999995625">
After we present our lexical rule system, it should be obvious that Bach&apos;s system allows
exactly the same operations to be expressed as we do. The only difference is that we
recast Bach&apos;s functional rules in terms of simple pattern-matching. It is conjectured
in Hoeksema and Janda (1988) that the resulting system is a proper subset of the
context-sensitive languages. We show here that this conjecture could not be further
from the truth, as all of the recursively enumerable languages can be generated using
these operations. Keenan and Timberlake (1988) also present a collection of lexical
redundancy rules that would seem to admit the system presented here as a natural
generalization. In particular, they present an analysis of passive almost identical to the
one presented below.
The restriction placed on the form of our rules is similar to the restriction on GPSG
metarules; we only allow one variable over sequences of categories (see Gazdar et al.
1985). This allows the manipulation of arguments a specified distance from either end
of the subcategorization list, but not arbitrary arguments. With obliqueness specified
in terms of subcategorization order (see Dowty 1982 and Pollard and Sag 1987), lex-
ical rules are able to specify operations on arguments based on their obliqueness. In
</bodyText>
<page confidence="0.990545">
304
</page>
<note confidence="0.662585">
Carpenter CG and HPSG with Lexical Rules
</note>
<bodyText confidence="0.881691">
general, a lexical rule is of the form:
</bodyText>
<subsectionHeader confidence="0.513159">
Definition 5
</subsectionHeader>
<bodyText confidence="0.949727">
b [co , . — , cn, $,d0, • • • &apos;dm] bqc/o, • • • , en, $, do,. • • , dn.,&apos; ,I
where $ is taken to be a variable ranging over sequences of categories (as in Ades and
Steedman 1982). More precisely, we assume that the lexical rules are given by a finite
relation:
</bodyText>
<subsectionHeader confidence="0.666629">
Definition 6
</subsectionHeader>
<bodyText confidence="0.7424565">
LexRule C (BasCat x Cat* x Cat*) x (BasCat x Cat* x Cat*).
Thus a rule of the form in (5) would be formally represented as:
</bodyText>
<subsectionHeader confidence="0.616451">
Definition 7
</subsectionHeader>
<bodyText confidence="0.86613">
((b, (co, . . . , ca), (do, . . . , cl,n)), (b&apos;, (c&apos;o, . . . , c&apos;n,), (d&apos;o, . . . , 4,))) E LexRule.
The intended interpretation of an element of LexRu le is that if a basic expression is
assigned to a category that matches its left-hand side, then it is also assigned to a cat-
egory that matches its right-hand side. We generate the final (possibly infinite) lexicon
LexRule(BasLex) by closing the basic lexicon under the lexical rules. More formally, we
define LexRule(BasLex) to be the least relation such that:
Definition 8
</bodyText>
<listItem confidence="0.91751175">
• BasLex C LexRule(BasLex), and
• if a- := b[co,..., cn, eo, . . . , ek, do, . . . , dm] E LexRule(BasLex) and
b[co,...,cn,$, do, . . . , dm] b&apos; [c&apos;o, . . . , c,&apos; ,,$, d&apos;o, . . . , d,i,&apos; ,] E LexRule
then a := b&apos; [c/o, . . . , c,, e0,. . . , ek, d&apos;o, . • • , d,] E LexRule(BasLex).
</listItem>
<bodyText confidence="0.99988125">
Thus, a grammar is determined by the specification of finite sets BasLex and LexRule,
over some given finite sets BasExp and BasCat of basic expressions and categories.
In the undecidability proof that follows, it is only really necessary to consider lexical
rules that modify the subcategorization list; a slightly modified proof goes through if
lexical rules are prohibited from affecting the basic head category.
We now take the time to motivate the full power of this lexical rule system. A
standard example of the application of a lexical rule is passivization, which in our
system can be stated in the form:
</bodyText>
<subsectionHeader confidence="0.901923">
Example 9
</subsectionHeader>
<bodyText confidence="0.9974868">
s[np[ji,$, np[]2] s[$, ppby[]2, nP[[1] (Passive)
The intuitive reading of this rule is that the first argument of any verb can become the
last argument (subject) and the last argument becomes a prepositional by-phrase; the
subscripts, while not an actual part of the rule, indicate this swapping of arguments
and their syntactic markings. For instance, with a ditransitive verb category such as
s[np[]i , np[] 2, np[]3], the result of applying the passive rule would be s[np[]2, ppby[13, np[}1].
While we cannot account for the fact that the subject occurs before the verb rather than
after it in the simplified system presented here, this category reflects the fact that the
number, order, and category of arguments is permuted as a result of passivization.
With the stripped-down system presented here, a second lexical rule is required for
</bodyText>
<page confidence="0.990722">
305
</page>
<note confidence="0.426213">
Computational Linguistics Volume 17, Number 3
</note>
<bodyText confidence="0.8742355">
passives without the prepositional argument. An operation such as detransitivization
can be stated by the rule:
</bodyText>
<equation confidence="0.7495775">
Example 10
s[np[], $] s[$1 (Detransitivization)
</equation>
<bodyText confidence="0.868374">
The effect of detransitivization is simply to remove the most oblique argument from
the subcategorization list. A nominalization rule might be stated in the form:
</bodyText>
<equation confidence="0.6812335">
Example 11 (Nominalization)
s[$1 = n[$.]
</equation>
<bodyText confidence="0.982696">
Applying nominalization to a verbal lexical entry produces a nominal lexical entry
with the same arguments. We can capture causative verbs with the following lexical
rule:
</bodyText>
<equation confidence="0.943824">
Example 12
s[$] = s[$, np[1] (Causative)
</equation>
<bodyText confidence="0.999676333333333">
The causative rule adds another noun phrase argument for the subject in the least
oblique position and increases the obliqueness of the existing arguments. A rule for
dative shift could be expressed as:
</bodyText>
<equation confidence="0.889256">
Example 13
s[np[]1 PPdat[12, np3[]] s[np2[], npi[], np3n] (Dative)
</equation>
<bodyText confidence="0.9979895">
The point of these examples is that very simple lexical regularities such as passives,
causatives, and detransitives motivate a system of lexical rules that switch, add, and
delete elements from the subcategorization lists of lexical entries.
Lexical rules of the form we have here could also be used for what are tradition-
ally considered to be syntactic operations, such as a rule for headless relatives (see
Carpenter 1991):
</bodyText>
<subsectionHeader confidence="0.806714">
Example 14
</subsectionHeader>
<bodyText confidence="0.990424666666667">
s[$, np[]] n[$, n[]] (Headless Relativization)
This rule has the effect of transforming a verbal category into a nominal modifier
category with the same complements. Of course, to achieve the effect we desire, we
must be able to mark verbs for their inflectional form and number. It should be ap-
parent from these examples that the formalization of lexical rules presented here is
particularly simple and motivated by a wide variety of seemingly lexical regularities.
Further applications of lexical rules of the form we use here may be found in Dowty
(1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988),
Flickinger (1987), and Pollard and Sag (1987).
</bodyText>
<sectionHeader confidence="0.935206" genericHeader="method">
4. Finite Closure
</sectionHeader>
<bodyText confidence="0.9999638">
We will now consider a restriction on the application of lexical rules that has the re-
sult of restricting the resulting system to a finite set of lexical entries. In the context
of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could
not apply to rules that they had a hand in generating. This means that starting with a
finite set of rules and metarules, only a finite number of rules would result. A similar
</bodyText>
<page confidence="0.993886">
306
</page>
<note confidence="0.888175">
Carpenter CG and HPSG with Lexical Rules
</note>
<bodyText confidence="0.9994868">
restriction allows Aone and Wittenburg (1990) to pre-compile the results of closing a
categorial lexicon under a set of morphological operations. Let Fin Clos(LexR u le, BasLex)
be the finite closure of the set of basic lexical entries under the metarules with
the restriction that no rule can apply to its own output. More formally, we define
FinClos(LexRule,BasLex) inductively to be the least relation such that:
</bodyText>
<sectionHeader confidence="0.359203" genericHeader="method">
Definition 15
</sectionHeader>
<listItem confidence="0.851806666666667">
• BasLex C FinClos(LexRule, BasLex)
• If e c E FinClos(LexRule — R, BasLex) and R E LexRule maps c to c&apos; then
e c&apos; E FinClos(LexRule, BasLex).
</listItem>
<bodyText confidence="0.885125230769231">
This restriction ensures that a lexical rule never applies to its own output, as a lexical
rule R can only be applied to a lexical entry that is derived without application of R.
We thus have:
Theorem 1 (Finite Closure)
If LexRule and BasLex are finite
then FinClos(LexRule,BasLex) is finite.
Proof
Trivial by induction on the cardinality of LexRule. •
The force of this result is that if we are willing to restrict our lexical rules to
nonrecursive applications, then we have a finite lexicon and hence generate only a
context-free language. But Carpenter (1991) argues for recursive lexical rules and pro-
vides examples from the English verbal system for which recursive rule application
seems necessary.
</bodyText>
<sectionHeader confidence="0.961043" genericHeader="method">
5. Argument Complexity Bounds
</sectionHeader>
<bodyText confidence="0.999965111111111">
Before moving on to the undecidability result, we define a notion of category com-
plexity and show that the result of closing a finite lexicon under a finite number of
lexical rules leads to a lexicon for which there is an upper bound on the complexity
of the complements in lexical categories. Placing an upper bound on the complexity
of entire categories in the lexicon restricts the system to context-free languages and
ensures decidability.
Our complexity metric is based purely on the number of complements for which
a category subcategorizes and not the complexity of the complements themselves. The
complexity of a category bici, , cn] is defined to be n, which we write as:
</bodyText>
<sectionHeader confidence="0.334915" genericHeader="method">
Definition 16
</sectionHeader>
<bodyText confidence="0.890052285714286">
Comp(b[ci, , c„]) =n.
While it is possible to have a lexical rule such as b[$] b[c,$], which allows the deriva-
tion of categories of unbounded complexity, the complements of categories derived
by lexical rules are bounded in their complexity.
Theorem 2
For any finite base lexicon BasLex and finite set LexRule of lexical rules, there is a bound
k such that if e := b[ci, ,c} E LexRule(BasLex) then Comp(c,) &lt;k for 1 &lt; i &lt; n.
</bodyText>
<page confidence="0.988903">
307
</page>
<figure confidence="0.360589">
Computational Linguistics Volume 17, Number 3
Proof
</figure>
<bodyText confidence="0.964061933333333">
Because BasLex is finite, there is an upper bound on argument complexity for any com-
plement category assigned by BasLex. Similarly, since there are only a finite number of
rules in LexRule there is an upper bound on the complexity of complements specified
in the outputs of any rule. Taken together, these facts imply that there is a bounded
complement complexity in the result of closing BasLex under LexRule, since any com-
plement category assigned by LexRule(BasLex) must have been a complement category
either in BasLex or in the complement list of one of the output rules in LexRule. •
This result shows that the lexical rules cannot modify the structure of complements
other than by completely replacing them with one of a finite number of alternatives.
We now note that if we restrict the complexity of lexical categories themselves,
we wind up with a context-free grammar. Let LexRule(BasLex)(n) be the set of lex-
ical entries with categories of complexity less than or equal to n, so that (e, c) E
LexRule(BasLex)(n) if and only if (e,c) E LexRule(BasLex)(n) and Comp(c) &lt; n.
Theorem 3
The language generated by LexRule(BasLex)(n) is context-free.
</bodyText>
<subsectionHeader confidence="0.869487">
Proof
</subsectionHeader>
<bodyText confidence="0.9997826">
Using the previous theorem, we know that there is a bound k on the size of the
complements in any lexical entry in LexRule(BasLex), and thus there must only be a
finite number of lexical entries with complexity of less than or equal to n. Consequently,
LexRu le(BasLex)(n) is finite and thus a standard finitary categorial grammar lexicon
that generates a context-free language. •
</bodyText>
<sectionHeader confidence="0.979881" genericHeader="method">
6. Generative Power
</sectionHeader>
<bodyText confidence="0.999942571428571">
As we said in the introduction, we characterize the generative power of our system
by the reduction of generalized rewriting systems to our head-complement grammars
with lexical rules. Before doing this, we review the basic definition of a generalized
rewriting system. A generalized rewriting system is a quadruple G = (V,s,T,R)
where V is a finite set of nonterminal category symbols, s E V is the start symbol, T
is a set of terminal symbols, and R C (V* x V*) U (V x T) is a finite set of rewriting
rules and lexical insertion rules, which are usually expressed in the forms:
</bodyText>
<subsectionHeader confidence="0.459492">
Definition 17
</subsectionHeader>
<listItem confidence="0.87938">
• z.71 • Vn U1 • • • Urn where vi, u E V
• v t where v E V and t E T.
String rewriting is defined so that:
</listItem>
<subsectionHeader confidence="0.445287">
Definition 18
</subsectionHeader>
<bodyText confidence="0.73885">
pap&apos; PT
if p, p&apos; E (V u T)* and if (a —4 7) E R is a rule. The language L(G) generated by a
general rewriting system G is defined to be
</bodyText>
<equation confidence="0.605689">
Definition 19
L(G) = {a E T* s a}
</equation>
<page confidence="0.994765">
308
</page>
<note confidence="0.876283">
Carpenter CG and HPSG with Lexical Rules
</note>
<bodyText confidence="0.9131582">
where s is the start symbol and &apos;-=+ is the usual transitive closure of the -- relation.
It is well known that:
Theorem 4
A language L is recursively enumerable if and only if there is a generalized rewriting
system G = (V, s, T, R) such that L = L(G).
</bodyText>
<subsectionHeader confidence="0.86497">
Proof
</subsectionHeader>
<bodyText confidence="0.941764125">
See Hoperoft and Ullman (1979:221-223). •
We now present the fundamental result of this paper, which states that the lan-
guages that can be characterized by categorial grammars with lexical rules are exactly
the recursively enumerable languages.
Theorem 5 (R.E.-Completeness)
A language S is recursively enumerable if and only if there is a finite lexicon BasLex
and finite set LexRule of lexical rules such that S is the set of strings assigned to the
category sll by LexRule(BasLex).
</bodyText>
<subsectionHeader confidence="0.870304">
Proof
</subsectionHeader>
<bodyText confidence="0.9998805">
It is trivial to show that the languages generated by our system are recursively enu-
merable; standard breadth-first search mechanisms that interleave lexical and syntactic
derivations in order of complexity can be seen to enumerate all analyses.
Conversely, suppose that we have a recursively enumerable language S and that
the generalized rewriting system G -= (V, s, T, R) is such that S = L(G) is the set of
strings generated by G. We show how to construct a categorial grammar using lexical
rules that assigns the set S of expressions to some distinguished basic category.
We begin by assuming that:
</bodyText>
<equation confidence="0.48159">
Definition 20
BasCat = V U {#, s}.
</equation>
<bodyText confidence="0.999941833333333">
We take a basic category for every nonterminal symbol in the generalized rewriting
system along with two special symbols; the # is used as a delimiter in representing
sequences of nonterminals by means of circular queues, while the s is used as the
distinguished category of the grammar (note that s, not s, is the distinguished start
symbol of G). Our claim is that the lexicon in (21) and lexical rules in (22) generate
exactly the same language as G.
</bodyText>
<subsectionHeader confidence="0.531858">
Definition 21
</subsectionHeader>
<listItem confidence="0.998677">
• t :--,- v[] if (v --+ t) E R
• t := v[#, s] if (v ---+ t) ER
</listItem>
<subsectionHeader confidence="0.386115">
Definition 22
</subsectionHeader>
<listItem confidence="0.980932666666667">
• -&gt; vi [v2, S] if V2 E V U {#}
• vi$, vi,..., vn] ---›- v[S,u1,...,und if (vi • • • vn -- u1 • • • um) ER
• v[#,v,$.] s[$] if v E V
</listItem>
<page confidence="0.996767">
309
</page>
<note confidence="0.59451">
Computational Linguistics Volume 17, Number 3
</note>
<bodyText confidence="0.986280333333333">
We represent an arbitrary string v1v2 • • vn E V* by means of the categorial grammar
category v[#[], v1[],. ..,v{1]. In what follows, we omit empty subcategorization lists,
so that the above category would be abbreviated to v[#, , vn]. Note that with
this encoding, there are as many representations of a string as there are nonterminaIs
V E V.
By repeated application of the first lexical rule in (22), from a lexical entry
</bodyText>
<equation confidence="0.991568666666667">
t :-= v[#,v1,.. • , vm, vm+i, • • ,vnl
we can generate a lexical entry of the form:
t := v[vm+ , ,V„, #, V1,
</equation>
<bodyText confidence="0.99996525">
The application of this rule is the key to allowing an arbitrary string in the middle
of a subcategorization list to move to the end so that it may be modified by a lexical
rule. The # symbol keeps track of the true beginning of the sequence being derived.
Suppose that the generalized rewriting system allows the one-step derivation:
</bodyText>
<equation confidence="0.659778">
Xi • • • xivi • • • vnyi • • • yi xi • • •xiui• • • UMY1 • • • Yi•
</equation>
<bodyText confidence="0.989722333333333">
If this rewriting is possible, then (vi • • • vn ui • • • Um) E R so that by a combination
of the first lexical rule and second lexical rule we can carry out the following lexical
derivation:
</bodyText>
<equation confidence="0.99996625">
t :=
t := -[yl, • • )Yl)#7•Xi, • • • 1X17 VI) • • • V/11
t := v[yi, • • ,yi, #, xi, • • • , x„ • • • , um]
t := v[#,x1,...,xi,ui, • • • , um,yi, • • • ,Yil•
</equation>
<bodyText confidence="0.884747">
A simple induction then gives us the result that if
xi • • • xi ---&gt; yi • &amp;quot;y,
then we can derive a lexical entry of the form
</bodyText>
<equation confidence="0.862712">
t :-= v[ft, yi, ,
</equation>
<bodyText confidence="0.965436">
from a lexical entry of the form
Considering the first lexical entry, and our last observation, if
</bodyText>
<equation confidence="0.457392">
S &amp;quot; • Vn
</equation>
<page confidence="0.988258">
310
</page>
<bodyText confidence="0.6667715">
Carpenter CG and HPSG with Lexical Rules
according to the generalized rewriting system, then we can derive the lexical entry
</bodyText>
<equation confidence="0.89638">
t := v[#, vi, • • • 7 Vni
from the lexical entry
t v[#,s]
</equation>
<bodyText confidence="0.5764665">
if (v E R. Now suppose that (v, t,) E R for 1 &lt; i &lt; n so that ti • • • tn E L(G).
Beginning with the basic lexical entry
</bodyText>
<equation confidence="0.99373">
t1 := [#, S]
</equation>
<bodyText confidence="0.601127333333333">
representing the lexical rewriting (Vi ti) E R, we can derive the lexical entry:
ti := v [#, , • • • , vn]•
From this last entry and our last lexical rule, we may derive a lexical entry:
</bodyText>
<equation confidence="0.975562">
t1 := s[v2, • • • 1Vni•
</equation>
<bodyText confidence="0.999808473684211">
Furthermore, since we have t, :--= v, for 2 &lt; i &lt; n because (v, ----&gt; t,) E R, we can assign
t1t2 tn to the category s[] by repeated application of the categorial grammar rule
scheme. In fact, for 1 &lt; i &lt; n we have ti • • • t, assigned to s[vi+i , • • • , vn]. Thus every
string that belongs to the language generated by G can also be generated using our
categorial grammar with lexical rules.
It simply remains to notice that we have ti s[v2, , vn] if and only if ti :=
vi [#, , ,v], which holds if and only if -&gt;vi • • • vn and v1 t1. The only way to
derive vi[] from t, is by using a lexical entry which is only possible if (v, ti) E R.
Furthermore, the only derivations of category s [] in the categorial grammar must be
derived in this manner, as the only way s can arise is by lexical rule application in the
above situation. Also note that while the # category can be removed by applying some
lexical rule, there are no expressions that are assigned to #[] by our grammar. Thus
the only way that the string t1 tn can be assigned to category s[] is by following a
lexical derivation that directly mirrors a derivation in G. •
The fundamental idea behind our reduction is that the complement specification
on a categorial grammar category can be used to simulate the intermediate stages of
a generalized rewriting system derivation. The only complication arises from the fact
that categorial grammar lexical rules operate on the ends of subcategorization lists,
while generalized rewriting systems are allowed to operate on arbitrary substrings.
</bodyText>
<sectionHeader confidence="0.874705" genericHeader="conclusions">
7. Conclusion
</sectionHeader>
<bodyText confidence="0.99994">
The system presented here for lexical rules in a simplified form of categorial grammar
with only one head-complement rule scheme has proven to generate arbitrary recur-
sively enumerable languages. The inevitable conclusion is that if we want a natural
and effectively decidable lexical rule system for categorial grammars or head-driven
</bodyText>
<page confidence="0.992457">
311
</page>
<note confidence="0.56073">
Computational Linguistics Volume 17, Number 3
</note>
<bodyText confidence="0.999834875">
phrase structure grammars, then we must place restrictions on the system given here
or look to state lexical rules at completely different levels of representation which
themselves provide the restrictiveness desired, such as in terms of some finite set of
thematic roles and grammatical relations, as is done in Lexical Function Grammar
(LFG) (see Bresnan 1982; Levin 1987; Bresnan and Kanerva 1989). The common as-
sumption that lexical rules can perform arbitrary operations on subcategorization lists
based on obliqueness is simply not restrictive enough to yield an effective recognition
algorithm.
</bodyText>
<sectionHeader confidence="0.98284" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9978765">
The primary thanks go to Kevin Kelly, who
suggested using the circular queue idea for
representing the tape of a Turing machine,
an idea that I adapted here. Stuart Shieber
originally conjectured that the
undecidability result would hold. I would
also like to thank two anonymous referees
for comments. Finally, I owe thanks to
Robert Levine, Alex Franz, Mitzi Morris,
and Carl Pollard for providing helpful
comments on a previous incarnation of the
undecidability proof.
</bodyText>
<sectionHeader confidence="0.983185" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996903011904762">
Ades, A. E.; and Steedman, M. J. (1982).
&amp;quot;On the order of words.&amp;quot; Linguistics and
Philosophy 4:517-558.
Aone, C.; and Wittenburg, K. (1990). &amp;quot;Zero
morphemes in unification-based
combinatory categorial grammar.&amp;quot; In
Proceedings, 28th Annual Meeting of the
Association for Computational Linguistics.
Pittsburgh, PA.
Bach, E. (1984). &amp;quot;Some generalizations of
categorial grammars.&amp;quot; In Varieties of
Formal Semantics: Proceedings of the Fourth
Amsterdam Colloquium 1982, edited by
F. Landman and F. Veltman, 1-23.
Dordrecht: Foris.
Bar-Hillel, Y.; Gaif man, C.; and Shamir, E,
(1960). &amp;quot;On categorial and phrase
structure grammars.&amp;quot; Bulletin of the
Research Council of Israel 9F:1-16.
Bresnan, J. (ed.) (1982). The Mental
Representation of Grammatical Relations.
Cambridge, MA: The MIT Press.
Bresnan, J.; and Kanerva, J. M. (1989).
&amp;quot;Locative inversion in Chiche*a: A case
study in factorization in grammar.&amp;quot;
Linguistic Inquiry 20(1):1-50.
Calder, J.; Klein, E.; and Zeevat, H. (1988).
&amp;quot;Unification categorial grammar: A
concise, extendable grammar for natural
language processing.&amp;quot; In Proceedings, :12th
International Conference on Computational
Linguistics. Budapest.
Carpenter, B. (1991). &amp;quot;Categorial grammar,
lexical rules and the English predicative.&amp;quot;
In Formal Grammar: Theory and
Implementation, Vancouver Studies in
Cognitive Science, Volume 2, edited by
R. Levine. Vancouver: University of
British Columbia Press.
Dowty, D. R. (1982). &amp;quot;Grammatical relations
and Montague grammar.&amp;quot; In The Nature of
Syntactic Representation, edited by
P. Jacobson and G. K. Pullum. Dordrecht:
D. Reidel.
Dowty, D. R. (1979). Word Meaning and
Montague Grammar. Synthese Language
Library, Volume 7. Dordrecht: D. Reidel.
Dowty, D. R. (1978). &amp;quot;Lexically governed
transformations as lexical rules in a
Montague grammar.&amp;quot; Linguistic Inquiry
9:393-426.
Earley, J. (1970). &amp;quot;An efficient context-free
parsing algorithm.&amp;quot; Communications of the
ACM 13:94-102.
Flickinger, D. (1987). Lexical Rules in the
Hierarchical Lexicon. Doctoral dissertation,
Stanford University, Stanford, CA.
Flickinger, D., Pollard, C., and Wasow, T.
(1985). &amp;quot;Structure-sharing in lexical
representation.&amp;quot; In Proceedings, 23rd
Annual Meeting of the ACL.
Gazdar, G.; and Klein, E.; Pullum, G.; and
Sag, I. (1985). Generalized Phrase Structure
Grammar. Oxford: Basil Blackwell.
Hoeksema, J.; and Janda, R. D. (1988).
&amp;quot;Implications of process morphology.&amp;quot; In
Categorial Structures and Natural Language
Structures, edited by R. Oehrle, E. Bach,
and D. Wheeler. Dordrecht: D. Reidel.
Hoperoft, J., and Ullman, J. (1979).
Introduction to Automata Theory, Languages
and Computation. Reading, MA:
Addison-Wesley.
Keenan, E. L.; and Faltz, L. M. (1985).
Boolean Semantics, Synthese Language
Library, Volume 23. Dordrecht: D. Reidel.
Keenan, E. L.; and Timberlake, A. (1988).
&amp;quot;Natural language motivations for
extending categorial grammar.&amp;quot; In
Categorial Structures and Natural Language
Structures, edited by R. Oehrle, E. Bach,
and D. Wheeler. Dordrecht: D. Reidel.
Levin, L. (1987). &amp;quot;Toward a linking theory
of relation changing rules in LFG.&amp;quot;
</reference>
<page confidence="0.987352">
312
</page>
<note confidence="0.82666">
Carpenter CG and HPSG with Lexical Rules
</note>
<reference confidence="0.999172586206897">
Technical report CSLI-87-115, Center for
the Study of Language and Information,
Stanford University.
Montague, R. (1970). &amp;quot;Universal grammar.&amp;quot;
Theoria 36:373-398.
Moortgat, M. (1987). &amp;quot;Compositionality and
the syntax of words.&amp;quot; In Foundations of
Pragmatics and Lexical Semantics, edited by
J. Groenendijk, D. de Jongh, and
M. Stokhof. Dordrecht: Foris.
Oehrle, R.; Bach, E.; and Wheeler, D., eds.
(1988). Categorial Grammars and Natural
Language Structures. Dordrecht: D. Reidel.
Pollard, C. J., and Sag, I. A. (1987).
Information-Based Syntax and Semantics:
Volume I — Fundamentals. CSLI Lecture
Notes, Volume 13. Stanford: Center for
the Study of Language and Information.
Thompson, H. (1982). &amp;quot;Handling metarules
in a parser for GPSG.&amp;quot; In The 21st Annual
Meeting of the Association for Computational
Linguistics. 26-37.
Uszkoreit, H., and Peters, P. S. (1986). &amp;quot;On
some formal properties of metarules.&amp;quot;
Linguistics and Philosophy 9(4):477-494.
Valiant, L. (1975). &amp;quot;General context-free
recognition in less than cubic time.&amp;quot;
Journal of Computer and Systems Science
10:308-315.
</reference>
<page confidence="0.99951">
313
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.986998">
<title confidence="0.998613">The Generative Power of Categorial Grammars and Head-Driven Phrase Structure Grammars with Lexical Rules</title>
<author confidence="0.999944">Bob Carpenter</author>
<affiliation confidence="0.999916">Carnegie Mellon University</affiliation>
<abstract confidence="0.998349333333333">In this paper, it is shown that the addition of simple and linguistically motivated forms of lexical rules to grammatical theories based on subcategorization lists, such as categorial grammars (CG) or head-driven phrase structure grammars (HPSG), results in a system that can generate all and only the recursively enumerable languages. The proof of this result is carried out by means of a reduction of generalized rewriting systems. Two restrictions are considered, each of which constrains the generative power of the resulting system to context-free languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A E Ades</author>
<author>M J Steedman</author>
</authors>
<title>On the order of words.&amp;quot;</title>
<date>1982</date>
<journal>Linguistics and Philosophy</journal>
<pages>4--517</pages>
<contexts>
<context position="13774" citStr="Ades and Steedman 1982" startWordPosition="2242" endWordPosition="2245">t al. 1985). This allows the manipulation of arguments a specified distance from either end of the subcategorization list, but not arbitrary arguments. With obliqueness specified in terms of subcategorization order (see Dowty 1982 and Pollard and Sag 1987), lexical rules are able to specify operations on arguments based on their obliqueness. In 304 Carpenter CG and HPSG with Lexical Rules general, a lexical rule is of the form: Definition 5 b [co , . — , cn, $,d0, • • • &apos;dm] bqc/o, • • • , en, $, do,. • • , dn.,&apos; ,I where $ is taken to be a variable ranging over sequences of categories (as in Ades and Steedman 1982). More precisely, we assume that the lexical rules are given by a finite relation: Definition 6 LexRule C (BasCat x Cat* x Cat*) x (BasCat x Cat* x Cat*). Thus a rule of the form in (5) would be formally represented as: Definition 7 ((b, (co, . . . , ca), (do, . . . , cl,n)), (b&apos;, (c&apos;o, . . . , c&apos;n,), (d&apos;o, . . . , 4,))) E LexRule. The intended interpretation of an element of LexRu le is that if a basic expression is assigned to a category that matches its left-hand side, then it is also assigned to a category that matches its right-hand side. We generate the final (possibly infinite) lexicon </context>
</contexts>
<marker>Ades, Steedman, 1982</marker>
<rawString>Ades, A. E.; and Steedman, M. J. (1982). &amp;quot;On the order of words.&amp;quot; Linguistics and Philosophy 4:517-558.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Aone</author>
<author>K Wittenburg</author>
</authors>
<title>Zero morphemes in unification-based combinatory categorial grammar.&amp;quot;</title>
<date>1990</date>
<booktitle>In Proceedings, 28th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="10986" citStr="Aone and Wittenburg (1990)" startWordPosition="1763" endWordPosition="1766">egorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary well-defined operations to be applied to lexical entries, but none of the rules</context>
<context position="18846" citStr="Aone and Wittenburg (1990)" startWordPosition="3106" endWordPosition="3109">), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical Rules restriction allows Aone and Wittenburg (1990) to pre-compile the results of closing a categorial lexicon under a set of morphological operations. Let Fin Clos(LexR u le, BasLex) be the finite closure of the set of basic lexical entries under the metarules with the restriction that no rule can apply to its own output. More formally, we define FinClos(LexRule,BasLex) inductively to be the least relation such that: Definition 15 • BasLex C FinClos(LexRule, BasLex) • If e c E FinClos(LexRule — R, BasLex) and R E LexRule maps c to c&apos; then e c&apos; E FinClos(LexRule, BasLex). This restriction ensures that a lexical rule never applies to its own ou</context>
</contexts>
<marker>Aone, Wittenburg, 1990</marker>
<rawString>Aone, C.; and Wittenburg, K. (1990). &amp;quot;Zero morphemes in unification-based combinatory categorial grammar.&amp;quot; In Proceedings, 28th Annual Meeting of the Association for Computational Linguistics. Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Bach</author>
</authors>
<title>Some generalizations of categorial grammars.&amp;quot;</title>
<date>1984</date>
<booktitle>In Varieties of Formal Semantics: Proceedings of the Fourth Amsterdam Colloquium</booktitle>
<pages>1--23</pages>
<location>Dordrecht: Foris.</location>
<note>edited by</note>
<contexts>
<context position="1720" citStr="Bach (1984)" startWordPosition="252" endWordPosition="253">of explaining the variations between languages must be carried out in the lexicon. Rather than assuming that the lexicon is simply an unstructured list associating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples </context>
<context position="10857" citStr="Bach 1984" startWordPosition="1745" endWordPosition="1746">rules presented below. 3. Adding Lexical Rules The form of lexical rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the trad</context>
<context position="18194" citStr="Bach (1984)" startWordPosition="2998" endWordPosition="2999">s (see Carpenter 1991): Example 14 s[$, np[]] n[$, n[]] (Headless Relativization) This rule has the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical</context>
</contexts>
<marker>Bach, 1984</marker>
<rawString>Bach, E. (1984). &amp;quot;Some generalizations of categorial grammars.&amp;quot; In Varieties of Formal Semantics: Proceedings of the Fourth Amsterdam Colloquium 1982, edited by F. Landman and F. Veltman, 1-23. Dordrecht: Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Bar-Hillel</author>
<author>Gaif man</author>
<author>C</author>
<author>E Shamir</author>
</authors>
<title>On categorial and phrase structure grammars.&amp;quot;</title>
<date>1960</date>
<journal>Bulletin of the Research Council of Israel</journal>
<pages>9--1</pages>
<contexts>
<context position="6260" citStr="Bar-Hillel et al. 1960" startWordPosition="967" endWordPosition="970">any particular syntactic analysis here. The full set Cat of categories is defined to be the least collection of objects of the form b[co, , c,,_i] where b E BasCat is a basic category and c, E Cat for i &lt; n. The categories between the brackets specify the arguments of the category, with the assumption being that these arguments must be attached in the order in which they occur on the subcategorization list. While our notation follows the usage of HPSG and Unification Categorial Grammar (Calder et al. 1988), it should be clear how it relates to more traditional categorial grammar notation (see Bar-Hillel et al. 1960). We assume the following schematic phrase structure rule that allows heads to combine with a single complement: Definition 1 b[ci,... ,c] b[co,... ,c] co In most categorial grammars and in HPSG, there are rules in which the complement category precedes the head, but we do not even need this much power. For instance, a simple transitive verb might be given the category s[np[] , np[]], a noun phrase the 302 Carpenter CG and HPSG with Lexical Rules category np[], a noun n[], and a determiner the category np[n[]]. Thus the rule instance s [np[]] ---+ s[np[], np[]] np[] allows the combination of a</context>
<context position="8578" citStr="Bar-Hillel et al. 1960" startWordPosition="1376" endWordPosition="1379">icl, E LLex (c[co, E Lex So )• • • • , if el It should be fairly obvious at this point how our simple categorial grammar formalism represents the core of both categorial grammars and the subcategorization component of HPSG. It should also be noted that such a grammar and lexical assignment reduces to a context-free grammar. This is because only finitely many subcategories of the lexical categories may ever be used in a derivation and thus only finitely many instances of the application scheme are necessary for a finite categorial lexicon. Somewhat surprisingly, the converse result also holds (Bar-Hillel et al. 1960); every context-free language is generated by some categorial grammar in the form we have presented. This latter result can be deduced from the fact that every context-free language can be expressed with a Greibach normal form grammar where every production is of the form Co aCi • • C, where n &gt; 0, the C, are nonterminal category symbols, and a is a terminal expression (see Hoperoft and Ullman 1979). Taking a basic category for every nonterminal of the context-free grammar and a lexical entry of the form a Co[C1[J,.. . ,Cn[]] for every production of the above form in the contextfree grammar, w</context>
</contexts>
<marker>Bar-Hillel, man, C, Shamir, 1960</marker>
<rawString>Bar-Hillel, Y.; Gaif man, C.; and Shamir, E, (1960). &amp;quot;On categorial and phrase structure grammars.&amp;quot; Bulletin of the Research Council of Israel 9F:1-16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bresnan</author>
</authors>
<title>The Mental Representation of Grammatical Relations.</title>
<date>1982</date>
<publisher>The MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="30275" citStr="Bresnan 1982" startWordPosition="5208" endWordPosition="5209">oven to generate arbitrary recursively enumerable languages. The inevitable conclusion is that if we want a natural and effectively decidable lexical rule system for categorial grammars or head-driven 311 Computational Linguistics Volume 17, Number 3 phrase structure grammars, then we must place restrictions on the system given here or look to state lexical rules at completely different levels of representation which themselves provide the restrictiveness desired, such as in terms of some finite set of thematic roles and grammatical relations, as is done in Lexical Function Grammar (LFG) (see Bresnan 1982; Levin 1987; Bresnan and Kanerva 1989). The common assumption that lexical rules can perform arbitrary operations on subcategorization lists based on obliqueness is simply not restrictive enough to yield an effective recognition algorithm. Acknowledgments The primary thanks go to Kevin Kelly, who suggested using the circular queue idea for representing the tape of a Turing machine, an idea that I adapted here. Stuart Shieber originally conjectured that the undecidability result would hold. I would also like to thank two anonymous referees for comments. Finally, I owe thanks to Robert Levine, </context>
</contexts>
<marker>Bresnan, 1982</marker>
<rawString>Bresnan, J. (ed.) (1982). The Mental Representation of Grammatical Relations. Cambridge, MA: The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bresnan</author>
<author>J M Kanerva</author>
</authors>
<title>Locative inversion in Chiche*a: A case study in factorization in grammar.&amp;quot;</title>
<date>1989</date>
<journal>Linguistic Inquiry</journal>
<pages>20--1</pages>
<contexts>
<context position="30314" citStr="Bresnan and Kanerva 1989" startWordPosition="5212" endWordPosition="5215"> recursively enumerable languages. The inevitable conclusion is that if we want a natural and effectively decidable lexical rule system for categorial grammars or head-driven 311 Computational Linguistics Volume 17, Number 3 phrase structure grammars, then we must place restrictions on the system given here or look to state lexical rules at completely different levels of representation which themselves provide the restrictiveness desired, such as in terms of some finite set of thematic roles and grammatical relations, as is done in Lexical Function Grammar (LFG) (see Bresnan 1982; Levin 1987; Bresnan and Kanerva 1989). The common assumption that lexical rules can perform arbitrary operations on subcategorization lists based on obliqueness is simply not restrictive enough to yield an effective recognition algorithm. Acknowledgments The primary thanks go to Kevin Kelly, who suggested using the circular queue idea for representing the tape of a Turing machine, an idea that I adapted here. Stuart Shieber originally conjectured that the undecidability result would hold. I would also like to thank two anonymous referees for comments. Finally, I owe thanks to Robert Levine, Alex Franz, Mitzi Morris, and Carl Poll</context>
</contexts>
<marker>Bresnan, Kanerva, 1989</marker>
<rawString>Bresnan, J.; and Kanerva, J. M. (1989). &amp;quot;Locative inversion in Chiche*a: A case study in factorization in grammar.&amp;quot; Linguistic Inquiry 20(1):1-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Calder</author>
<author>E Klein</author>
<author>H Zeevat</author>
</authors>
<title>Unification categorial grammar: A concise, extendable grammar for natural language processing.&amp;quot;</title>
<date>1988</date>
<booktitle>In Proceedings, :12th International Conference on Computational Linguistics.</booktitle>
<location>Budapest.</location>
<contexts>
<context position="6148" citStr="Calder et al. 1988" startWordPosition="949" endWordPosition="952">choice of basic categories is ultimately up to the grammar writer. We are not concerned with the details of any particular syntactic analysis here. The full set Cat of categories is defined to be the least collection of objects of the form b[co, , c,,_i] where b E BasCat is a basic category and c, E Cat for i &lt; n. The categories between the brackets specify the arguments of the category, with the assumption being that these arguments must be attached in the order in which they occur on the subcategorization list. While our notation follows the usage of HPSG and Unification Categorial Grammar (Calder et al. 1988), it should be clear how it relates to more traditional categorial grammar notation (see Bar-Hillel et al. 1960). We assume the following schematic phrase structure rule that allows heads to combine with a single complement: Definition 1 b[ci,... ,c] b[co,... ,c] co In most categorial grammars and in HPSG, there are rules in which the complement category precedes the head, but we do not even need this much power. For instance, a simple transitive verb might be given the category s[np[] , np[]], a noun phrase the 302 Carpenter CG and HPSG with Lexical Rules category np[], a noun n[], and a dete</context>
</contexts>
<marker>Calder, Klein, Zeevat, 1988</marker>
<rawString>Calder, J.; Klein, E.; and Zeevat, H. (1988). &amp;quot;Unification categorial grammar: A concise, extendable grammar for natural language processing.&amp;quot; In Proceedings, :12th International Conference on Computational Linguistics. Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>Categorial grammar, lexical rules and the English predicative.&amp;quot;</title>
<date>1991</date>
<booktitle>In Formal Grammar: Theory and Implementation, Vancouver Studies in Cognitive Science,</booktitle>
<volume>2</volume>
<publisher>Press.</publisher>
<institution>Vancouver: University of British Columbia</institution>
<note>edited by</note>
<contexts>
<context position="10149" citStr="Carpenter (1991)" startWordPosition="1633" endWordPosition="1634">neral CFG parsing algorithms can be constructed from matrix multiplication algorithms with slightly better worst-case asymptotic performance than Earley&apos;s algorithm [Valiant 19751). Unfortunately, the situation is quite different after the addition of lexical rules. Before going on, it should be noted that one of the primary reasons for employing categorial grammars is its natural relation to a compositional semantics (Montague 1970). While we do not consider the semantic effects of lexical rules here, the interested 303 Computational Linguistics Volume 17, Number 3 reader is urged to consult Carpenter (1991) for details of how a higher-order typed semantics can be naturally added to the system of lexical rules presented below. 3. Adding Lexical Rules The form of lexical rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed </context>
<context position="17605" citStr="Carpenter 1991" startWordPosition="2901" endWordPosition="2902">t oblique position and increases the obliqueness of the existing arguments. A rule for dative shift could be expressed as: Example 13 s[np[]1 PPdat[12, np3[]] s[np2[], npi[], np3n] (Dative) The point of these examples is that very simple lexical regularities such as passives, causatives, and detransitives motivate a system of lexical rules that switch, add, and delete elements from the subcategorization lists of lexical entries. Lexical rules of the form we have here could also be used for what are traditionally considered to be syntactic operations, such as a rule for headless relatives (see Carpenter 1991): Example 14 s[$, np[]] n[$, n[]] (Headless Relativization) This rule has the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema </context>
<context position="19937" citStr="Carpenter (1991)" startWordPosition="3293" endWordPosition="3294">e maps c to c&apos; then e c&apos; E FinClos(LexRule, BasLex). This restriction ensures that a lexical rule never applies to its own output, as a lexical rule R can only be applied to a lexical entry that is derived without application of R. We thus have: Theorem 1 (Finite Closure) If LexRule and BasLex are finite then FinClos(LexRule,BasLex) is finite. Proof Trivial by induction on the cardinality of LexRule. • The force of this result is that if we are willing to restrict our lexical rules to nonrecursive applications, then we have a finite lexicon and hence generate only a context-free language. But Carpenter (1991) argues for recursive lexical rules and provides examples from the English verbal system for which recursive rule application seems necessary. 5. Argument Complexity Bounds Before moving on to the undecidability result, we define a notion of category complexity and show that the result of closing a finite lexicon under a finite number of lexical rules leads to a lexicon for which there is an upper bound on the complexity of the complements in lexical categories. Placing an upper bound on the complexity of entire categories in the lexicon restricts the system to context-free languages and ensur</context>
</contexts>
<marker>Carpenter, 1991</marker>
<rawString>Carpenter, B. (1991). &amp;quot;Categorial grammar, lexical rules and the English predicative.&amp;quot; In Formal Grammar: Theory and Implementation, Vancouver Studies in Cognitive Science, Volume 2, edited by R. Levine. Vancouver: University of British Columbia Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Dowty</author>
</authors>
<title>Grammatical relations and Montague grammar.&amp;quot;</title>
<date>1982</date>
<booktitle>In The Nature of Syntactic Representation, edited</booktitle>
<contexts>
<context position="13381" citStr="Dowty 1982" startWordPosition="2162" endWordPosition="2163">ollection of lexical redundancy rules that would seem to admit the system presented here as a natural generalization. In particular, they present an analysis of passive almost identical to the one presented below. The restriction placed on the form of our rules is similar to the restriction on GPSG metarules; we only allow one variable over sequences of categories (see Gazdar et al. 1985). This allows the manipulation of arguments a specified distance from either end of the subcategorization list, but not arbitrary arguments. With obliqueness specified in terms of subcategorization order (see Dowty 1982 and Pollard and Sag 1987), lexical rules are able to specify operations on arguments based on their obliqueness. In 304 Carpenter CG and HPSG with Lexical Rules general, a lexical rule is of the form: Definition 5 b [co , . — , cn, $,d0, • • • &apos;dm] bqc/o, • • • , en, $, do,. • • , dn.,&apos; ,I where $ is taken to be a variable ranging over sequences of categories (as in Ades and Steedman 1982). More precisely, we assume that the lexical rules are given by a finite relation: Definition 6 LexRule C (BasCat x Cat* x Cat*) x (BasCat x Cat* x Cat*). Thus a rule of the form in (5) would be formally rep</context>
</contexts>
<marker>Dowty, 1982</marker>
<rawString>Dowty, D. R. (1982). &amp;quot;Grammatical relations and Montague grammar.&amp;quot; In The Nature of Syntactic Representation, edited by P. Jacobson and G. K. Pullum. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Dowty</author>
</authors>
<title>Word Meaning and Montague Grammar.</title>
<date>1979</date>
<booktitle>Synthese Language Library, Volume 7.</booktitle>
<location>Dordrecht: D. Reidel.</location>
<contexts>
<context position="11488" citStr="Dowty (1979)" startWordPosition="1848" endWordPosition="1849">1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary well-defined operations to be applied to lexical entries, but none of the rules he considered fall outside of the scope of the system presented here. The lexical generalizations studied by Bach (1984) led him to employ lexical redundancy rules that are expressed by composing basic functions that pick out the head or tail of a subcategorization list as well as the subcategorization list with either the head or tail removed. More formally, Bach allowed arbitrary concatenations and compositions of the following functions to be applied to subcategorization lists: Definition 4 FI</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>Dowty, D. R. (1979). Word Meaning and Montague Grammar. Synthese Language Library, Volume 7. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Dowty</author>
</authors>
<title>Lexically governed transformations as lexical rules in a Montague grammar.&amp;quot;</title>
<date>1978</date>
<journal>Linguistic Inquiry</journal>
<pages>9--393</pages>
<contexts>
<context position="1700" citStr="Dowty (1978" startWordPosition="249" endWordPosition="250">al syntax, the task of explaining the variations between languages must be carried out in the lexicon. Rather than assuming that the lexicon is simply an unstructured list associating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We th</context>
<context position="10840" citStr="Dowty 1978" startWordPosition="1742" endWordPosition="1743">system of lexical rules presented below. 3. Adding Lexical Rules The form of lexical rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1</context>
<context position="18174" citStr="Dowty (1978" startWordPosition="2995" endWordPosition="2996">or headless relatives (see Carpenter 1991): Example 14 s[$, np[]] n[$, n[]] (Headless Relativization) This rule has the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG a</context>
</contexts>
<marker>Dowty, 1978</marker>
<rawString>Dowty, D. R. (1978). &amp;quot;Lexically governed transformations as lexical rules in a Montague grammar.&amp;quot; Linguistic Inquiry 9:393-426.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.&amp;quot;</title>
<date>1970</date>
<journal>Communications of the ACM</journal>
<pages>13--94</pages>
<marker>Earley, 1970</marker>
<rawString>Earley, J. (1970). &amp;quot;An efficient context-free parsing algorithm.&amp;quot; Communications of the ACM 13:94-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
</authors>
<title>Lexical Rules in the Hierarchical Lexicon. Doctoral dissertation,</title>
<date>1987</date>
<institution>Stanford University,</institution>
<location>Stanford, CA.</location>
<contexts>
<context position="1884" citStr="Flickinger (1987)" startWordPosition="277" endWordPosition="278">ating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straightforward and natural system of lexical rules. To show that arbitrary recursively enumerable languages may be generated by the resulting sy</context>
<context position="11418" citStr="Flickinger 1987" startWordPosition="1836" endWordPosition="1837">ategorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary well-defined operations to be applied to lexical entries, but none of the rules he considered fall outside of the scope of the system presented here. The lexical generalizations studied by Bach (1984) led him to employ lexical redundancy rules that are expressed by composing basic functions that pick out the head or tail of a subcategorization list as well as the subcategorization list with either the head or tail removed. More formally, Bach allowed arbitrary concatenations and compositions of the followi</context>
<context position="18270" citStr="Flickinger (1987)" startWordPosition="3008" endWordPosition="3009">tivization) This rule has the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical Rules restriction allows Aone and Wittenburg (1990) to pre-compile the resu</context>
</contexts>
<marker>Flickinger, 1987</marker>
<rawString>Flickinger, D. (1987). Lexical Rules in the Hierarchical Lexicon. Doctoral dissertation, Stanford University, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Flickinger</author>
<author>C Pollard</author>
<author>T Wasow</author>
</authors>
<title>Structure-sharing in lexical representation.&amp;quot;</title>
<date>1985</date>
<booktitle>In Proceedings, 23rd Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="1865" citStr="Flickinger et al. (1985)" startWordPosition="273" endWordPosition="276">n unstructured list associating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straightforward and natural system of lexical rules. To show that arbitrary recursively enumerable languages may be generated </context>
</contexts>
<marker>Flickinger, Pollard, Wasow, 1985</marker>
<rawString>Flickinger, D., Pollard, C., and Wasow, T. (1985). &amp;quot;Structure-sharing in lexical representation.&amp;quot; In Proceedings, 23rd Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G Pullum</author>
<author>I Sag</author>
</authors>
<date>1985</date>
<booktitle>Generalized Phrase Structure Grammar.</booktitle>
<publisher>Basil Blackwell.</publisher>
<location>Oxford:</location>
<contexts>
<context position="3159" citStr="Gazdar et al. (1985)" startWordPosition="470" endWordPosition="473">ystems (Type 0 grammars). Though the details of our reduction are different, our method is reminiscent of that used by Uszkoreit and Peters (1986) to show that context-free grammars with metarules could generate arbitrary recursively enumerable languages. The analogy between CG lexical rules and GPSG metarules is strengthened by the fact that * Computational Linguistics Program, Philosophy Department, Carnegie Mellon University, Pittsburgh, PA 15213 USA; e-mail: carp@lcl.cmu.edu © 1991 Association for Computational Linguistics Computational Linguistics Volume 17, Number 3 GPSG as presented in Gazdar et al. (1985) restricts the application of metarules to lexical phrase structure rules. Along the way to proving that categorial grammars with lexical rules can generate arbitrary recursively enumerable languages, we consider two restrictions that have the effect of reducing the generative power of the system to context-free languages. The first of these restrictions limits the recursive application of lexical rules, while the second puts a bound on the number of complements that can be specified by a category. 2. CGs and HPSGs In Generalized Phrase Structure Grammar (GPSG) as presented in Gazdar et al. (1</context>
<context position="13162" citStr="Gazdar et al. 1985" startWordPosition="2129" endWordPosition="2132">xt-sensitive languages. We show here that this conjecture could not be further from the truth, as all of the recursively enumerable languages can be generated using these operations. Keenan and Timberlake (1988) also present a collection of lexical redundancy rules that would seem to admit the system presented here as a natural generalization. In particular, they present an analysis of passive almost identical to the one presented below. The restriction placed on the form of our rules is similar to the restriction on GPSG metarules; we only allow one variable over sequences of categories (see Gazdar et al. 1985). This allows the manipulation of arguments a specified distance from either end of the subcategorization list, but not arbitrary arguments. With obliqueness specified in terms of subcategorization order (see Dowty 1982 and Pollard and Sag 1987), lexical rules are able to specify operations on arguments based on their obliqueness. In 304 Carpenter CG and HPSG with Lexical Rules general, a lexical rule is of the form: Definition 5 b [co , . — , cn, $,d0, • • • &apos;dm] bqc/o, • • • , en, $, do,. • • , dn.,&apos; ,I where $ is taken to be a variable ranging over sequences of categories (as in Ades and St</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, G.; and Klein, E.; Pullum, G.; and Sag, I. (1985). Generalized Phrase Structure Grammar. Oxford: Basil Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoeksema</author>
<author>R D Janda</author>
</authors>
<title>Implications of process morphology.&amp;quot;</title>
<date>1988</date>
<booktitle>In Categorial Structures and Natural Language Structures,</booktitle>
<note>edited by</note>
<contexts>
<context position="1802" citStr="Hoeksema and Janda (1988)" startWordPosition="262" endWordPosition="265">n the lexicon. Rather than assuming that the lexicon is simply an unstructured list associating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straightforward and natural system of lexical rules. To show th</context>
<context position="10938" citStr="Hoeksema and Janda 1988" startWordPosition="1756" endWordPosition="1759"> rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary well-defined operations to be a</context>
<context position="12485" citStr="Hoeksema and Janda (1988)" startWordPosition="2020" endWordPosition="2023"> well as the subcategorization list with either the head or tail removed. More formally, Bach allowed arbitrary concatenations and compositions of the following functions to be applied to subcategorization lists: Definition 4 FIRST(xi • • xn) = RREST(X1 • • • Xn) = X2 • • • Xn LAST(X1 &apos; • • xn) = Xn LREST(X1 • • • XII) = X1 • • &apos; Xn-1 After we present our lexical rule system, it should be obvious that Bach&apos;s system allows exactly the same operations to be expressed as we do. The only difference is that we recast Bach&apos;s functional rules in terms of simple pattern-matching. It is conjectured in Hoeksema and Janda (1988) that the resulting system is a proper subset of the context-sensitive languages. We show here that this conjecture could not be further from the truth, as all of the recursively enumerable languages can be generated using these operations. Keenan and Timberlake (1988) also present a collection of lexical redundancy rules that would seem to admit the system presented here as a natural generalization. In particular, they present an analysis of passive almost identical to the one presented below. The restriction placed on the form of our rules is similar to the restriction on GPSG metarules; we </context>
<context position="18221" citStr="Hoeksema and Janda (1988)" startWordPosition="3000" endWordPosition="3003">ter 1991): Example 14 s[$, np[]] n[$, n[]] (Headless Relativization) This rule has the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical Rules restriction allows A</context>
</contexts>
<marker>Hoeksema, Janda, 1988</marker>
<rawString>Hoeksema, J.; and Janda, R. D. (1988). &amp;quot;Implications of process morphology.&amp;quot; In Categorial Structures and Natural Language Structures, edited by R. Oehrle, E. Bach, and D. Wheeler. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoperoft</author>
<author>J Ullman</author>
</authors>
<title>Introduction to Automata Theory, Languages and Computation.</title>
<date>1979</date>
<publisher>Addison-Wesley.</publisher>
<location>Reading, MA:</location>
<contexts>
<context position="7698" citStr="Hoperoft and Ullman 1979" startWordPosition="1216" endWordPosition="1219">plied to Cat. Note that this set is totally determined by the choice BasCat of basic categories. A lexicon for our simple grammar formalism consists of a finite relation between categories and basic expressions: Definition 2 Lex C BasExp x Cat. We write e c if (e, c) E Lex. There is no restriction preventing a single expression from having more than one lexical entry. What we have with Lex and Rule is a simple phrase structure grammar, albeit one with an infinite set of rules. We interpret admissibility (well-formedness or grammaticality) in this phrase structure grammar in the usual way (see Hoperoft and Ullman 1979:79-87). In particular, we take Lex (c) to be the set of strings of basic expressions of category c. By mutual recursion over Cat we define the GLex (c) as the minimal sets such that: Definition 3 • e E LLex(C) if (e, c) E Lex eie2 • , , cn] ) and e2 CLex(cicl, E LLex (c[co, E Lex So )• • • • , if el It should be fairly obvious at this point how our simple categorial grammar formalism represents the core of both categorial grammars and the subcategorization component of HPSG. It should also be noted that such a grammar and lexical assignment reduces to a context-free grammar. This is because o</context>
<context position="8980" citStr="Hoperoft and Ullman 1979" startWordPosition="1447" endWordPosition="1450"> may ever be used in a derivation and thus only finitely many instances of the application scheme are necessary for a finite categorial lexicon. Somewhat surprisingly, the converse result also holds (Bar-Hillel et al. 1960); every context-free language is generated by some categorial grammar in the form we have presented. This latter result can be deduced from the fact that every context-free language can be expressed with a Greibach normal form grammar where every production is of the form Co aCi • • C, where n &gt; 0, the C, are nonterminal category symbols, and a is a terminal expression (see Hoperoft and Ullman 1979). Taking a basic category for every nonterminal of the context-free grammar and a lexical entry of the form a Co[C1[J,.. . ,Cn[]] for every production of the above form in the contextfree grammar, we produce a categorial grammar that can be shown by induction on derivation length to generate exactly the same language as the Greibach normal form context-free grammar. Not only is recognition decidable for context-free languages, but Earley&apos;s (1970) algorithm is known to decide them in 0(n3) time where n is the length of the input string (in fact, general CFG parsing algorithms can be constructed</context>
<context position="24066" citStr="Hoperoft and Ullman (1979" startWordPosition="4024" endWordPosition="4027"> • z.71 • Vn U1 • • • Urn where vi, u E V • v t where v E V and t E T. String rewriting is defined so that: Definition 18 pap&apos; PT if p, p&apos; E (V u T)* and if (a —4 7) E R is a rule. The language L(G) generated by a general rewriting system G is defined to be Definition 19 L(G) = {a E T* s a} 308 Carpenter CG and HPSG with Lexical Rules where s is the start symbol and &apos;-=+ is the usual transitive closure of the -- relation. It is well known that: Theorem 4 A language L is recursively enumerable if and only if there is a generalized rewriting system G = (V, s, T, R) such that L = L(G). Proof See Hoperoft and Ullman (1979:221-223). • We now present the fundamental result of this paper, which states that the languages that can be characterized by categorial grammars with lexical rules are exactly the recursively enumerable languages. Theorem 5 (R.E.-Completeness) A language S is recursively enumerable if and only if there is a finite lexicon BasLex and finite set LexRule of lexical rules such that S is the set of strings assigned to the category sll by LexRule(BasLex). Proof It is trivial to show that the languages generated by our system are recursively enumerable; standard breadth-first search mechanisms that</context>
</contexts>
<marker>Hoperoft, Ullman, 1979</marker>
<rawString>Hoperoft, J., and Ullman, J. (1979). Introduction to Automata Theory, Languages and Computation. Reading, MA: Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E L Keenan</author>
<author>L M Faltz</author>
</authors>
<date>1985</date>
<booktitle>Boolean Semantics, Synthese Language Library, Volume 23.</booktitle>
<location>Dordrecht: D. Reidel.</location>
<contexts>
<context position="1745" citStr="Keenan and Faltz (1985)" startWordPosition="254" endWordPosition="257"> the variations between languages must be carried out in the lexicon. Rather than assuming that the lexicon is simply an unstructured list associating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straig</context>
<context position="10407" citStr="Keenan and Faltz (1985)" startWordPosition="1676" endWordPosition="1679"> lexical rules. Before going on, it should be noted that one of the primary reasons for employing categorial grammars is its natural relation to a compositional semantics (Montague 1970). While we do not consider the semantic effects of lexical rules here, the interested 303 Computational Linguistics Volume 17, Number 3 reader is urged to consult Carpenter (1991) for details of how a higher-order typed semantics can be naturally added to the system of lexical rules presented below. 3. Adding Lexical Rules The form of lexical rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented syste</context>
</contexts>
<marker>Keenan, Faltz, 1985</marker>
<rawString>Keenan, E. L.; and Faltz, L. M. (1985). Boolean Semantics, Synthese Language Library, Volume 23. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E L Keenan</author>
<author>A Timberlake</author>
</authors>
<title>Natural language motivations for extending categorial grammar.&amp;quot;</title>
<date>1988</date>
<booktitle>In Categorial Structures and Natural Language Structures,</booktitle>
<note>edited by</note>
<contexts>
<context position="1775" citStr="Keenan and Timberlake (1988)" startWordPosition="258" endWordPosition="261">anguages must be carried out in the lexicon. Rather than assuming that the lexicon is simply an unstructured list associating words with syntactic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straightforward and natural system o</context>
<context position="10908" citStr="Keenan and Timberlake 1988" startWordPosition="1751" endWordPosition="1754">exical Rules The form of lexical rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary w</context>
<context position="12754" citStr="Keenan and Timberlake (1988)" startWordPosition="2062" endWordPosition="2065">X2 • • • Xn LAST(X1 &apos; • • xn) = Xn LREST(X1 • • • XII) = X1 • • &apos; Xn-1 After we present our lexical rule system, it should be obvious that Bach&apos;s system allows exactly the same operations to be expressed as we do. The only difference is that we recast Bach&apos;s functional rules in terms of simple pattern-matching. It is conjectured in Hoeksema and Janda (1988) that the resulting system is a proper subset of the context-sensitive languages. We show here that this conjecture could not be further from the truth, as all of the recursively enumerable languages can be generated using these operations. Keenan and Timberlake (1988) also present a collection of lexical redundancy rules that would seem to admit the system presented here as a natural generalization. In particular, they present an analysis of passive almost identical to the one presented below. The restriction placed on the form of our rules is similar to the restriction on GPSG metarules; we only allow one variable over sequences of categories (see Gazdar et al. 1985). This allows the manipulation of arguments a specified distance from either end of the subcategorization list, but not arbitrary arguments. With obliqueness specified in terms of subcategoriz</context>
<context position="18251" citStr="Keenan and Timberlake (1988)" startWordPosition="3004" endWordPosition="3007">np[]] n[$, n[]] (Headless Relativization) This rule has the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical Rules restriction allows Aone and Wittenburg (1990) to p</context>
</contexts>
<marker>Keenan, Timberlake, 1988</marker>
<rawString>Keenan, E. L.; and Timberlake, A. (1988). &amp;quot;Natural language motivations for extending categorial grammar.&amp;quot; In Categorial Structures and Natural Language Structures, edited by R. Oehrle, E. Bach, and D. Wheeler. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Levin</author>
</authors>
<title>Toward a linking theory of relation changing rules in LFG.&amp;quot;</title>
<date>1987</date>
<tech>Technical report CSLI-87-115,</tech>
<institution>Center for the Study of Language and Information, Stanford University.</institution>
<contexts>
<context position="30287" citStr="Levin 1987" startWordPosition="5210" endWordPosition="5211">te arbitrary recursively enumerable languages. The inevitable conclusion is that if we want a natural and effectively decidable lexical rule system for categorial grammars or head-driven 311 Computational Linguistics Volume 17, Number 3 phrase structure grammars, then we must place restrictions on the system given here or look to state lexical rules at completely different levels of representation which themselves provide the restrictiveness desired, such as in terms of some finite set of thematic roles and grammatical relations, as is done in Lexical Function Grammar (LFG) (see Bresnan 1982; Levin 1987; Bresnan and Kanerva 1989). The common assumption that lexical rules can perform arbitrary operations on subcategorization lists based on obliqueness is simply not restrictive enough to yield an effective recognition algorithm. Acknowledgments The primary thanks go to Kevin Kelly, who suggested using the circular queue idea for representing the tape of a Turing machine, an idea that I adapted here. Stuart Shieber originally conjectured that the undecidability result would hold. I would also like to thank two anonymous referees for comments. Finally, I owe thanks to Robert Levine, Alex Franz, </context>
</contexts>
<marker>Levin, 1987</marker>
<rawString>Levin, L. (1987). &amp;quot;Toward a linking theory of relation changing rules in LFG.&amp;quot; Technical report CSLI-87-115, Center for the Study of Language and Information, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<title>Universal grammar.&amp;quot;</title>
<date>1970</date>
<journal>Theoria</journal>
<pages>36--373</pages>
<contexts>
<context position="9970" citStr="Montague 1970" startWordPosition="1605" endWordPosition="1606">y is recognition decidable for context-free languages, but Earley&apos;s (1970) algorithm is known to decide them in 0(n3) time where n is the length of the input string (in fact, general CFG parsing algorithms can be constructed from matrix multiplication algorithms with slightly better worst-case asymptotic performance than Earley&apos;s algorithm [Valiant 19751). Unfortunately, the situation is quite different after the addition of lexical rules. Before going on, it should be noted that one of the primary reasons for employing categorial grammars is its natural relation to a compositional semantics (Montague 1970). While we do not consider the semantic effects of lexical rules here, the interested 303 Computational Linguistics Volume 17, Number 3 reader is urged to consult Carpenter (1991) for details of how a higher-order typed semantics can be naturally added to the system of lexical rules presented below. 3. Adding Lexical Rules The form of lexical rules that we propose to add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or func</context>
</contexts>
<marker>Montague, 1970</marker>
<rawString>Montague, R. (1970). &amp;quot;Universal grammar.&amp;quot; Theoria 36:373-398.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
</authors>
<title>Compositionality and the syntax of words.&amp;quot;</title>
<date>1987</date>
<booktitle>In Foundations of Pragmatics and Lexical Semantics,</booktitle>
<location>Dordrecht: Foris.</location>
<note>edited by</note>
<contexts>
<context position="10955" citStr="Moortgat (1987)" startWordPosition="1760" endWordPosition="1761">add to the basic categorial system are what Keenan and Faltz (1985) have termed valency affecting operations. These operations allow the permutation, addition, or subtraction of complements and the modification of the head or functor category. Our operations do not have any overt morphological effects, and are thus often referred to as zero morphemes. The same general lexical rule format has been proposed by virtually everyone considering the lexicon from a categorial perspective (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary well-defined operations to be applied to lexical</context>
</contexts>
<marker>Moortgat, 1987</marker>
<rawString>Moortgat, M. (1987). &amp;quot;Compositionality and the syntax of words.&amp;quot; In Foundations of Pragmatics and Lexical Semantics, edited by J. Groenendijk, D. de Jongh, and M. Stokhof. Dordrecht: Foris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Oehrle</author>
<author>E Bach</author>
<author>D Wheeler</author>
<author>eds</author>
</authors>
<date>1988</date>
<booktitle>Categorial Grammars and Natural Language Structures.</booktitle>
<editor>D. Reidel.</editor>
<location>Dordrecht:</location>
<marker>Oehrle, Bach, Wheeler, eds, 1988</marker>
<rawString>Oehrle, R.; Bach, E.; and Wheeler, D., eds. (1988). Categorial Grammars and Natural Language Structures. Dordrecht: D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Pollard</author>
<author>I A Sag</author>
</authors>
<title>Information-Based Syntax and Semantics: Volume I — Fundamentals. CSLI Lecture Notes, Volume 13. Stanford: Center for the Study of Language and Information.</title>
<date>1987</date>
<contexts>
<context position="1912" citStr="Pollard and Sag (1987)" startWordPosition="280" endWordPosition="283">tic categories, organization is usually imposed by means of hierarchical inheritance systems, linking theories relating lexical semantics to grammatical categories and finally with lexical rules. It is the lexical rule component of these grammars that we investigate in this paper. We present a straightforward formalization of categorial grammars with lexical rules based in part on the systems of Dowty (1978, 1979), Bach (1984), Keenan and Faltz (1985), Keenan and Timberlake (1988), Hoeksema and Janda (1988), and the HPSG lexical rule systems of Flickinger et al. (1985), Flickinger (1987), and Pollard and Sag (1987). We show that even using such a simple form of lexical rules, any recursively enumerable language can be recognized. Thus the addition of lexical rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straightforward and natural system of lexical rules. To show that arbitrary recursively enumerable languages may be generated by the resulting system, we provide a reduction</context>
<context position="11444" citStr="Pollard and Sag 1987" startWordPosition="1839" endWordPosition="1842">e (see Dowty 1978, 1979; Bach 1984; Keenan and Faltz 1985; Keenan and Timberlake 1988; and Hoeksema and Janda 1988). Moortgat (1987) and Aone and Wittenburg (1990) have presented systems that allow extended categorial grammars to operate at both the morphological and syntactic levels, but the operations that can be carried out by their extended sets of rules produce results very similar to the lexical operations we allow here. Our results are especially relevant in light of recent work in HPSG, which admits lexical rules that do the same work as the ones employed here (see Flickinger 1987 and Pollard and Sag 1987). In the tradition of Montague, Dowty (1979) allowed arbitrary well-defined operations to be applied to lexical entries, but none of the rules he considered fall outside of the scope of the system presented here. The lexical generalizations studied by Bach (1984) led him to employ lexical redundancy rules that are expressed by composing basic functions that pick out the head or tail of a subcategorization list as well as the subcategorization list with either the head or tail removed. More formally, Bach allowed arbitrary concatenations and compositions of the following functions to be applied</context>
<context position="13407" citStr="Pollard and Sag 1987" startWordPosition="2165" endWordPosition="2168">xical redundancy rules that would seem to admit the system presented here as a natural generalization. In particular, they present an analysis of passive almost identical to the one presented below. The restriction placed on the form of our rules is similar to the restriction on GPSG metarules; we only allow one variable over sequences of categories (see Gazdar et al. 1985). This allows the manipulation of arguments a specified distance from either end of the subcategorization list, but not arbitrary arguments. With obliqueness specified in terms of subcategorization order (see Dowty 1982 and Pollard and Sag 1987), lexical rules are able to specify operations on arguments based on their obliqueness. In 304 Carpenter CG and HPSG with Lexical Rules general, a lexical rule is of the form: Definition 5 b [co , . — , cn, $,d0, • • • &apos;dm] bqc/o, • • • , en, $, do,. • • , dn.,&apos; ,I where $ is taken to be a variable ranging over sequences of categories (as in Ades and Steedman 1982). More precisely, we assume that the lexical rules are given by a finite relation: Definition 6 LexRule C (BasCat x Cat* x Cat*) x (BasCat x Cat* x Cat*). Thus a rule of the form in (5) would be formally represented as: Definition 7 </context>
<context position="18298" citStr="Pollard and Sag (1987)" startWordPosition="3011" endWordPosition="3014">as the effect of transforming a verbal category into a nominal modifier category with the same complements. Of course, to achieve the effect we desire, we must be able to mark verbs for their inflectional form and number. It should be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical Rules restriction allows Aone and Wittenburg (1990) to pre-compile the results of closing a categorial </context>
</contexts>
<marker>Pollard, Sag, 1987</marker>
<rawString>Pollard, C. J., and Sag, I. A. (1987). Information-Based Syntax and Semantics: Volume I — Fundamentals. CSLI Lecture Notes, Volume 13. Stanford: Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Thompson</author>
</authors>
<title>Handling metarules in a parser for GPSG.&amp;quot;</title>
<date>1982</date>
<booktitle>In The 21st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>26--37</pages>
<contexts>
<context position="18520" citStr="Thompson (1982)" startWordPosition="3052" endWordPosition="3053">ld be apparent from these examples that the formalization of lexical rules presented here is particularly simple and motivated by a wide variety of seemingly lexical regularities. Further applications of lexical rules of the form we use here may be found in Dowty (1978, 1979), Bach (1984), Hoeksema and Janda (1988), Keenan and Timberlake (1988), Flickinger (1987), and Pollard and Sag (1987). 4. Finite Closure We will now consider a restriction on the application of lexical rules that has the result of restricting the resulting system to a finite set of lexical entries. In the context of GPSG, Thompson (1982) restricted metarules to be nonrecursive so that they could not apply to rules that they had a hand in generating. This means that starting with a finite set of rules and metarules, only a finite number of rules would result. A similar 306 Carpenter CG and HPSG with Lexical Rules restriction allows Aone and Wittenburg (1990) to pre-compile the results of closing a categorial lexicon under a set of morphological operations. Let Fin Clos(LexR u le, BasLex) be the finite closure of the set of basic lexical entries under the metarules with the restriction that no rule can apply to its own output. </context>
</contexts>
<marker>Thompson, 1982</marker>
<rawString>Thompson, H. (1982). &amp;quot;Handling metarules in a parser for GPSG.&amp;quot; In The 21st Annual Meeting of the Association for Computational Linguistics. 26-37.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Uszkoreit</author>
<author>P S Peters</author>
</authors>
<title>On some formal properties of metarules.&amp;quot;</title>
<date>1986</date>
<journal>Linguistics and Philosophy</journal>
<pages>9--4</pages>
<contexts>
<context position="2685" citStr="Uszkoreit and Peters (1986)" startWordPosition="406" endWordPosition="409"> rules leads to systems in which it is not possible to effectively decide whether a string is accepted by a grammar. We first introduce a pared-down formalism that captures the way in which heads combine with complements in CG and HPSG. We then provide examples to motivate a very straightforward and natural system of lexical rules. To show that arbitrary recursively enumerable languages may be generated by the resulting system, we provide a reduction of generalized rewriting systems (Type 0 grammars). Though the details of our reduction are different, our method is reminiscent of that used by Uszkoreit and Peters (1986) to show that context-free grammars with metarules could generate arbitrary recursively enumerable languages. The analogy between CG lexical rules and GPSG metarules is strengthened by the fact that * Computational Linguistics Program, Philosophy Department, Carnegie Mellon University, Pittsburgh, PA 15213 USA; e-mail: carp@lcl.cmu.edu © 1991 Association for Computational Linguistics Computational Linguistics Volume 17, Number 3 GPSG as presented in Gazdar et al. (1985) restricts the application of metarules to lexical phrase structure rules. Along the way to proving that categorial grammars w</context>
</contexts>
<marker>Uszkoreit, Peters, 1986</marker>
<rawString>Uszkoreit, H., and Peters, P. S. (1986). &amp;quot;On some formal properties of metarules.&amp;quot; Linguistics and Philosophy 9(4):477-494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Valiant</author>
</authors>
<title>General context-free recognition in less than cubic time.&amp;quot;</title>
<date>1975</date>
<journal>Journal of Computer and Systems Science</journal>
<pages>10--308</pages>
<contexts>
<context position="9711" citStr="Valiant 1975" startWordPosition="1566" endWordPosition="1567">. . ,Cn[]] for every production of the above form in the contextfree grammar, we produce a categorial grammar that can be shown by induction on derivation length to generate exactly the same language as the Greibach normal form context-free grammar. Not only is recognition decidable for context-free languages, but Earley&apos;s (1970) algorithm is known to decide them in 0(n3) time where n is the length of the input string (in fact, general CFG parsing algorithms can be constructed from matrix multiplication algorithms with slightly better worst-case asymptotic performance than Earley&apos;s algorithm [Valiant 19751). Unfortunately, the situation is quite different after the addition of lexical rules. Before going on, it should be noted that one of the primary reasons for employing categorial grammars is its natural relation to a compositional semantics (Montague 1970). While we do not consider the semantic effects of lexical rules here, the interested 303 Computational Linguistics Volume 17, Number 3 reader is urged to consult Carpenter (1991) for details of how a higher-order typed semantics can be naturally added to the system of lexical rules presented below. 3. Adding Lexical Rules The form of lexi</context>
</contexts>
<marker>Valiant, 1975</marker>
<rawString>Valiant, L. (1975). &amp;quot;General context-free recognition in less than cubic time.&amp;quot; Journal of Computer and Systems Science 10:308-315.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>