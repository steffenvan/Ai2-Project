<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000130">
<sectionHeader confidence="0.786381875" genericHeader="method">
THE FINITE STRING NEWSLETTER
SITE REPORT
ANOTHER FROM THE DARPA SERIES
(SEE VOLUME 12, NUMBER 2)
OVERVIEW OF THE TACITUS PROJECT
Jerry R. Hobbs
Artificial Intelligence Center
SRI International
</sectionHeader>
<author confidence="0.5813875">
Researchers: John Bear, William Croft, Todd Davies,
Douglas Edwards, Jerry Hobbs, Kenneth Laws,
Paul Martin, Fernando Pereira, Raymond Perrault,
Stuart Shieber, Mark Stickel, Mabry Tyson
</author>
<sectionHeader confidence="0.97875" genericHeader="method">
AIMS OF THE PROJECT
</sectionHeader>
<bodyText confidence="0.999688842105263">
The specific aim of the TACITUS project is to develop
interpretation processes for handling casualty reports
(casreps), which are messages in free-flowing text about
breakdowns of machinery. These interpretation proc-
esses will be an essential component, and indeed the
principal component, of systems for automatic message
routing and systems for the automatic extraction of infor-
mation from messages for entry into a data base or an
expert system. In the latter application, for example, it is
desirable to be able to recognize conditions in the
message that instantiate conditions in the antecedents of
the expert system&apos;s rules, so that the expert system can
reason on the basis of more up-to-date and more specific
information.
More broadly, our aim is to develop general proce-
dures, together with the underlying theory, for using
commonsense and technical knowledge in the interpreta-
tion of written discourse. This effort divides into five
subareas:
</bodyText>
<listItem confidence="0.9996288">
1. syntax and semantic translation,
2. commonsense knowledge,
3. domain knowledge,
4. deduction,
5. &amp;quot;local&amp;quot; pragmatics.
</listItem>
<bodyText confidence="0.952439">
Our approach in each of these areas is discussed in turn.
</bodyText>
<sectionHeader confidence="0.855976" genericHeader="method">
SYNTAX AND SEMANTIC TRANSLATION
</sectionHeader>
<bodyText confidence="0.999892133333333">
Syntactic analysis and semantic translation in the
TACITUS project are being done by the DIALOGIC
system. DIALOGIC has perhaps as extensive a coverage
of English syntax as any system in existence, it produces
a logical form in first-order predicate calculus, and it was
used as the syntactic component of the TEAM system.
The principal addition we have made to the system
during the TACITUS project has been a menu-based
component for rapid vocabulary acquisition that allows
us to acquire several hundred lexical items in an after-
noon&apos;s work. We are now modifying DIALOGIC to
produce neutral representations instead of multiple read-
ings for the most common types of syntactic ambiguities,
including prepositional phrase attachment ambiguities
and compound noun ambiguities.
</bodyText>
<subsectionHeader confidence="0.694635">
COMMONSENSE KNOWLEDGE
</subsectionHeader>
<bodyText confidence="0.999855933333333">
Our aim in this phase of the project is to encode large
amounts of commonsense knowledge in first-order predi-
cate calculus in a way that can be used for knowledge-
based processing of natural language discourse. Our
approach is to define rich core theories of various
domains, explicating their basic ontologies and structure,
and then to define, or at least to characterize, various
English words in terms of predicates provided by these
core theories. So far, we have alternated between work-
ing from the inside out, from explications of the core
theories to characterizations of the words, and from the
outside in, from the words to the core theories.
Thus, we first proceeded from the outside in by exam-
ining the concept of wear, as in worn bearings, seeking to
define wear, and then to define the concepts we defined
wear in terms of, pushing the process back to basic
concepts in the domains of space, materials, and force,
among others. We then proceeded from the inside out,
trying to flesh out the core theories. of these domains, as
well as the domains of scalar notions, time, measure,
orientation, shape, and functionality. Then to test the
adequacy of these theories, we began working from the
outside in again, spending some time defining, or charac-
terizing, the words related to these domains that occurred
in our target set of casreps. We are now working from
the inside out again, going over the core theories and the
definitions with a fine-tooth comb, checking manually for
consistency and adequacy, and proving simple conse-
quences of the axioms on the KADS theorem-prover.
This work is described in Hobbs et al.
</bodyText>
<sectionHeader confidence="0.57483" genericHeader="method">
DOMAIN KNOWLEDGE
</sectionHeader>
<bodyText confidence="0.999984947368421">
In all of our work we are seeking general solutions that
can be used in a wide variety of applications. This may
seem impossible for domain knowledge. In our particular
case, we must express facts about the starting air
compressor of a ship. It would appear difficult to employ
this knowledge in any other application. However, our
approach makes most of our work, even in this area, rele-
vant to many other domains. We are specifying a
number of &amp;quot;abstract machines&amp;quot; or &amp;quot;abstract systems&amp;quot;, in
levels, of which the particular device we must model is an
instantiation. We define, for example, a closed produc-
er-consumer system. We then define a closed clean fluid
producer-consumer system as a closed producer-consumer
system with certain additional properties, and at one
more level of specificity, we define a pressurized lube-oil
system. The specific lube-oil system of the starting air
compressor, with all its idiosyncratic features, is then an
instantiation of the last of these. In this way, when we
have to model other devices, we can do so by defining
</bodyText>
<page confidence="0.817733">
220 Computational Linguistics, Volume 12, Number 3, July-September 1986
</page>
<bodyText confidence="0.9211282">
The FINITE STRING Newsletter Site Reports
them to be the most specific applicable abstract machine
that has been defined previously, thereby obviating much
of the work of specification. An electrical circuit, for
example, is also a closed producer-consumer system.
</bodyText>
<sectionHeader confidence="0.824836" genericHeader="method">
DEDUCTION
</sectionHeader>
<bodyText confidence="0.999962461538461">
The deduction component of the TACITUS system is the
KLAUS Automated Deduction System (KADS), devel-
oped as part of the KLAUS project for research on the
interactive acquisition and use of knowledge through
natural language. Its principal inference operation is
nonclausal resolution, with possible resolution operations
encoded in a connection graph. The nonclausal repre-
sentation eliminates redundancy introduced by translat-
ing formulas to clause form, and improves readability as
well. Special control connectives can be used to restrict
use of the formulas to either forward chaining or back-
ward chaining. Evaluation functions determine the
sequence of inference operations in KADS. At each step,
KADS resolves on the highest-rated link. The resolvent is
then evaluated for retention and links to the new formula
are evaluated for retention and priority. KADS supports
the incorporation of theories for more efficient
deduction, including deduction by demodulation, associa-
tive and commutative unification, many-sorted unifica-
tion, and theory resolution. The last of these has been
used for efficient deduction using a sort hierarchy. Its
efficient methods for performing some reasoning about
sorts and equality, and the facility for ordering searches
by means of an evaluation function, make it particularly
well suited for the kinds of deductive processing required
in a knowledge-based natural language system.
</bodyText>
<sectionHeader confidence="0.854513" genericHeader="method">
LOCAL PRAGMATICS
</sectionHeader>
<bodyText confidence="0.998521434782609">
We have begun to formulate a general approach to
several problems that lie at the boundary between
semantics and pragmatics. These are problems that arise
in single sentences, even though one may have to look
beyond the single sentence to solve them. The problems
are metonymy, reference, the interpretation of compound
nominals, and lexical and syntactic ambiguity. All of
these may be called problems in &amp;quot;local pragmatics&amp;quot;.
Solving them constitutes at least part of what the inter-
pretation of a text is. We take it that interpretation is a
matter of reasoning about what is possible, and therefore
rests fundamentally on deductive operations. We have
formulated very abstract characterizations of the
solutions to the local pragmatics problems in terms of
what can be deduced from a knowledge base of
commonsense and domain knowledge. In particular, we
have devised a general algorithm for building an
expression from the logical form of a sentence, such that
a constructive proof of the expression from the know-
ledge base will constitute an interpretation of the
sentence. This can be illustrated with the sentence from
the casreps
Disengaged compressor after lube oil alarm.
</bodyText>
<subsectionHeader confidence="0.57776">
Computational Linguistics, Volume 12, Number 3, July-September 1986
</subsectionHeader>
<bodyText confidence="0.9955105">
To resolve the reference of alarm, one must prove
constructively the expression
</bodyText>
<equation confidence="0.689312">
(3 x)alarm(x)
</equation>
<bodyText confidence="0.999977">
To resolve the implicit relation between the two nouns in
the compound nominal lube oil alarm (where lube oil is
taken as a multiword), one must prove constructively
from the knowledge base the existence of some possible
relation, which we may call nn, between the entities
referred to by the nouns:
</bodyText>
<equation confidence="0.861859">
(3 x,y) alarm(x) A lube-oil(y) A nn(y,x)
</equation>
<bodyText confidence="0.989805814814815">
A metonymy occurs in the sentence in that after requires
its object to be an event, whereas the explicit object is a
device. To resolve a metonymy that occurs when a pred-
icate is applied to an explicit argument that fails to satisfy
the constraints imposed by the predicate on its argument,
one must prove constructively the possible existence of
an entity that is related to the explicit argument and satis-
fies the constraints imposed by the predicate. Thus, the
logical form of the sentence is modified to
... A after(d,e) A q(e,x) A alarm(x) A ...
and the expression to be proved constructively is
(3 e) event(e) A q(e,x) A alarm(x) A ...
In the most general approach, nn and q are predicate
variables. In less ambitious approaches, they can be
predicate constants, as illustrated below.
These are very abstract and insufficiently constrained
formulations of solutions to the local pragmatics prob-
lems. Our further research in this area has probed in four
directions.
(1) We have been examining various previous
approaches to these problems in linguistics and computa-
tional linguistics, in order to reinterpret them into our
framework. For example, an approach that says the
implicit relation in a compound nominal must be one of a
specified set of relations, such as &amp;quot;part-of&amp;quot;, can be
captured by treating nn as a predicate constant and by
including in the knowledge base axioms like
</bodyText>
<equation confidence="0.971164">
(V x,y) part-of(y,x) nn(x,y)
</equation>
<bodyText confidence="0.984268">
In this fashion, we have been able to characterize
succinctly the most common methods used for solving
these problems in previous natural language systems,
such as the methods used in the TEAM system.
(2) We have been investigating constraints on the
most general formulations of the problems. There are
general constraints, such as the Minimality Principle,
which states that one should favor the minimal solution
in the sense that the fewest new entities and relations
must be hypothesized. For example, the argument-rela-
tion pattern in compound nominals, as in lube oil
pressure, can be seen as satisfying the Minimality Princi-
ple, since the implicit relation is simply the one already
given by the head noun. In addition, we are looking for
constraints that are specific to given problems. For
example, whereas whole-part compound nominals, like
regulator valve, are quite common, part-whole compound
</bodyText>
<page confidence="0.959714">
221
</page>
<bodyText confidence="0.942802">
The FINITE STRING Newsletter Calls for Papers, Proposals, Pictures, Nominations
nominals seem to be quite rare. This is probably because
of a principle that says noun modifiers should further
restrict the possible reference of the noun phrase, and
parts are common to too many wholes to perform that
function.
</bodyText>
<listItem confidence="0.96952775">
(3) A knowledge base contains two kinds of know-
ledge, &amp;quot;type&amp;quot; knowledge about what kinds of situations
are possible, and &amp;quot;token&amp;quot; knowledge about what the
actual situation is. We are trying to determine which of
these kinds of knowledge are required for each of the
pragmatics problems. For example, reference requires
both type and token knowledge, whereas most if not all
instances of metonymy seem to require only type know-
ledge.
(4) At the most abstract level, interpretation requires
the constructive proof of a single logical expression
consisting of many conjuncts. The deduction component
</listItem>
<bodyText confidence="0.908244111111111">
can attempt to prove these conjuncts in a variety of
orders. We have been investigating some of these possi-
ble orders. For example, one plausible candidate is that
one should work from the inside out, trying first to solve
the reference problems of arguments of predications
before attempting to solve the compound nominal and
metonymy problems presented by those predications. In
our framework, this is an issue of where subgoals for the
deduction component should be placed on an agenda.
</bodyText>
<sectionHeader confidence="0.909945" genericHeader="method">
IMPLEMENTATION
</sectionHeader>
<bodyText confidence="0.999989333333333">
In our implementation of the TACITUS system, we are
beginning with the minimal approach and building up
slowly. As we implement the local pragmatics oper-
ations, we are using a knowledge base containing only
the axioms that are needed for the test examples. Thus,
it grows slowly as we try out more and more texts. As
we gain greater confidence in the pragmatics operations,
we will move more and more of the axioms from our
commonsense and domain knowledge bases into the
system&apos;s knowledge base. Our initial versions of the
pragmatics operations are, for the most part, fairly stand-
ard techniques recast into our abstract framework. When
the knowledge base has reached a significant size, we will
begin experimenting with more general solutions and
with various constraints on those general solutions.
</bodyText>
<sectionHeader confidence="0.855546" genericHeader="method">
FUTURE PLANS
</sectionHeader>
<bodyText confidence="0.999732863636364">
In addition to pursuing our research in each of the areas
described above, we will institute two new efforts next
year. First of all, we will begin to extend our work in
pragmatics to the recognition of discourse structure. This
problem is illustrated by the following text:
Air regulating valve failed.
Gas turbine engine wouldn&apos;t turn over.
Valve parts corroded.
The temporal structure of this text is 3-1-2; first the
valve parts corroded, and this caused the valve to fail,
which caused the engine to not turn over. To recognize
this structure, one must reason about causal relationships
in the model of the device, and in addition one must
recognize patterns of explanation and consequence in the
text.
The second new effort will be to build tools for
domain knowledge acquisition. These will be based on
the abstract machines in terms of which we are presently
encoding our domain knowledge. Thus, the system
should be able to allow the user to choose one of a set of
abstract machines and then to augment it with various
parts, properties and relations.
</bodyText>
<sectionHeader confidence="0.995898" genericHeader="method">
ACKNOWLEDGMENT
</sectionHeader>
<bodyText confidence="0.69857525">
The TACITUS project is funded by the Defense
Advanced Research Projects Agency under Office of
Naval Research contract N00014-85-C-0013, as part of
the Strategic Computing program.
</bodyText>
<sectionHeader confidence="0.875284" genericHeader="method">
REFERENCE
</sectionHeader>
<reference confidence="0.98991825">
Hobbs, Jerry R.; Croft, William; Davies, Todd; Edwards, Douglas; and
Laws, Kenneth 1986 Commonsense Metaphysics and Lexical
Semantics. In Proceedings, 24th Annual Meeting of the Association
for Computational Linguistics. New York (June): 231-240.
</reference>
<sectionHeader confidence="0.936540666666667" genericHeader="method">
CALLS
FOR PAPERS, PROPOSALS, AND PICTURES
FOR AWARD NOMINATIONS
CALL FOR PAPERS
FOURTH SYMPOSIUM ON EMPIRICAL FOUNDATION OF
INFORMATION AND SOFTWARE SCIENCES (EFISS)
</sectionHeader>
<bodyText confidence="0.969462">
22-24 October 1986, Georgia Institute of Technology,
Atlanta, Georgia
The purpose of the meeting is to explore subjects and
methods of scientific inquiry of common interest to infor-
mation and software science, and to identify directions of
research that will benefit from the mutual interaction of
the two fields. The main theme of this symposium is
empirical methods of evaluation of man-machine interfaces.
Specific examples of relevant focal topics are: friendli-
ness, portability, sensitivity, fidelity, integrity, fault-toler-
ance, compatibility, modularity, and evolution of
man-machine interfaces; efficiency of interfaces as
communication channels; evaluation of effects of error
propagation through interfaces; modeling man-machine
interfaces.
Contributed papers will be considered also on other
aspects of empiric foundations of information and soft-
ware sciences such as methods of experimental design;
measurement theory and techniques; empirical laws and
theories of information and software sciences; their vali-
dation and verification; experimental data bases; and
software properties and their evaluation and measure-
ment.
All submitted papers will be refereed. Those selected
will be scheduled for presentation and published in the
proceedings of the symposium.
Abstracts of papers (at least 150 words long) are due
by 15 March 1986. Authors will be notified of their
</bodyText>
<page confidence="0.945096">
222 Computational Linguistics, Volume 12, Number 3, July-September 1986
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.008812">
<title confidence="0.948267">THE FINITE STRING NEWSLETTER SITE REPORT ANOTHER FROM THE DARPA</title>
<affiliation confidence="0.425867">OVERVIEW OF THE TACITUS PROJECT</affiliation>
<author confidence="0.999302">Jerry R Hobbs</author>
<affiliation confidence="0.999177">Artificial Intelligence Center</affiliation>
<address confidence="0.680623">Researchers: John Bear, William Croft, Todd Davies,</address>
<author confidence="0.943928333333333">Douglas Edwards</author>
<author confidence="0.943928333333333">Jerry Hobbs</author>
<author confidence="0.943928333333333">Kenneth Laws</author>
<author confidence="0.943928333333333">Paul Martin</author>
<author confidence="0.943928333333333">Fernando Pereira</author>
<author confidence="0.943928333333333">Raymond Perrault</author>
<author confidence="0.943928333333333">Stuart Shieber</author>
<author confidence="0.943928333333333">Mark Stickel</author>
<author confidence="0.943928333333333">Mabry Tyson</author>
<affiliation confidence="0.864879">AIMS OF THE PROJECT</affiliation>
<abstract confidence="0.9986203800738">The specific aim of the TACITUS project is to develop processes handling casualty reports (casreps), which are messages in free-flowing text about breakdowns of machinery. These interpretation processes will be an essential component, and indeed the principal component, of systems for automatic message routing and systems for the automatic extraction of information from messages for entry into a data base or an expert system. In the latter application, for example, it is desirable to be able to recognize conditions in the message that instantiate conditions in the antecedents of the expert system&apos;s rules, so that the expert system can reason on the basis of more up-to-date and more specific information. More broadly, our aim is to develop general procedures, together with the underlying theory, for using commonsense and technical knowledge in the interpretation of written discourse. This effort divides into five subareas: 1. syntax and semantic translation, 2. commonsense knowledge, 3. domain knowledge, 4. deduction, 5. &amp;quot;local&amp;quot; pragmatics. Our approach in each of these areas is discussed in turn. SYNTAX AND SEMANTIC TRANSLATION Syntactic analysis and semantic translation in the project being done by the DIALOGIC system. DIALOGIC has perhaps as extensive a coverage of English syntax as any system in existence, it produces a logical form in first-order predicate calculus, and it was used as the syntactic component of the TEAM system. The principal addition we have made to the system the project been a menu-based component for rapid vocabulary acquisition that allows us to acquire several hundred lexical items in an afterwork. We are now modifying to produce neutral representations instead of multiple readings for the most common types of syntactic ambiguities, including prepositional phrase attachment ambiguities and compound noun ambiguities. COMMONSENSE KNOWLEDGE Our aim in this phase of the project is to encode large of commonsense knowledge in first-order predicate calculus in a way that can be used for knowledgebased processing of natural language discourse. Our approach is to define rich core theories of various domains, explicating their basic ontologies and structure, and then to define, or at least to characterize, various English words in terms of predicates provided by these core theories. So far, we have alternated between working from the inside out, from explications of the core theories to characterizations of the words, and from the outside in, from the words to the core theories. Thus, we first proceeded from the outside in by examthe concept of in bearings, to then to define the concepts we defined terms of, pushing the process back to basic concepts in the domains of space, materials, and force, among others. We then proceeded from the inside out, trying to flesh out the core theories. of these domains, as well as the domains of scalar notions, time, measure, orientation, shape, and functionality. Then to test the adequacy of these theories, we began working from the outside in again, spending some time defining, or characterizing, the words related to these domains that occurred in our target set of casreps. We are now working from the inside out again, going over the core theories and the definitions with a fine-tooth comb, checking manually for consistency and adequacy, and proving simple consequences of the axioms on the KADS theorem-prover. This work is described in Hobbs et al. DOMAIN KNOWLEDGE In all of our work we are seeking general solutions that can be used in a wide variety of applications. This may seem impossible for domain knowledge. In our particular case, we must express facts about the starting air compressor of a ship. It would appear difficult to employ this knowledge in any other application. However, our approach makes most of our work, even in this area, relevant to many other domains. We are specifying a number of &amp;quot;abstract machines&amp;quot; or &amp;quot;abstract systems&amp;quot;, in levels, of which the particular device we must model is an We define, for example, a producer-consumer system. We then define a closed clean fluid system as closed producer-consumer system with certain additional properties, and at one level of specificity, we define a lube-oil specific lube-oil system of the starting air compressor, with all its idiosyncratic features, is then an instantiation of the last of these. In this way, when we have to model other devices, we can do so by defining Linguistics, Volume 12, Number 3, July-September 1986 The FINITE STRING Newsletter Site Reports them to be the most specific applicable abstract machine that has been defined previously, thereby obviating much of the work of specification. An electrical circuit, for example, is also a closed producer-consumer system. DEDUCTION deduction component of the is the Deduction System (KADS), developed as part of the KLAUS project for research on the interactive acquisition and use of knowledge through natural language. Its principal inference operation is nonclausal resolution, with possible resolution operations encoded in a connection graph. The nonclausal representation eliminates redundancy introduced by translating formulas to clause form, and improves readability as well. Special control connectives can be used to restrict use of the formulas to either forward chaining or backward chaining. Evaluation functions determine the sequence of inference operations in KADS. At each step, KADS resolves on the highest-rated link. The resolvent is then evaluated for retention and links to the new formula are evaluated for retention and priority. KADS supports the incorporation of theories for more efficient deduction, including deduction by demodulation, associative and commutative unification, many-sorted unification, and theory resolution. The last of these has been used for efficient deduction using a sort hierarchy. Its efficient methods for performing some reasoning about sorts and equality, and the facility for ordering searches by means of an evaluation function, make it particularly well suited for the kinds of deductive processing required in a knowledge-based natural language system. LOCAL PRAGMATICS We have begun to formulate a general approach to several problems that lie at the boundary between semantics and pragmatics. These are problems that arise in single sentences, even though one may have to look beyond the single sentence to solve them. The problems are metonymy, reference, the interpretation of compound nominals, and lexical and syntactic ambiguity. All of these may be called problems in &amp;quot;local pragmatics&amp;quot;. Solving them constitutes at least part of what the interpretation of a text is. We take it that interpretation is a matter of reasoning about what is possible, and therefore rests fundamentally on deductive operations. We have formulated very abstract characterizations of the solutions to the local pragmatics problems in terms of what can be deduced from a knowledge base of commonsense and domain knowledge. In particular, we have devised a general algorithm for building an expression from the logical form of a sentence, such that a constructive proof of the expression from the knowledge base will constitute an interpretation of the sentence. This can be illustrated with the sentence from the casreps Disengaged compressor after lube oil alarm. Computational Linguistics, Volume 12, Number 3, July-September 1986 resolve the reference of must prove constructively the expression To resolve the implicit relation between the two nouns in compound nominal oil alarm oil taken as a multiword), one must prove constructively from the knowledge base the existence of some possible which we may call the entities referred to by the nouns: alarm(x) metonymy occurs in the sentence in that its object to be an event, whereas the explicit object is a device. To resolve a metonymy that occurs when a predicate is applied to an explicit argument that fails to satisfy the constraints imposed by the predicate on its argument, one must prove constructively the possible existence of an entity that is related to the explicit argument and satisfies the constraints imposed by the predicate. Thus, the logical form of the sentence is modified to A ... and the expression to be proved constructively is event(e) ... the most general approach, predicate variables. In less ambitious approaches, they can be predicate constants, as illustrated below. These are very abstract and insufficiently constrained formulations of solutions to the local pragmatics problems. Our further research in this area has probed in four directions. (1) We have been examining various previous approaches to these problems in linguistics and computational linguistics, in order to reinterpret them into our framework. For example, an approach that says the implicit relation in a compound nominal must be one of a specified set of relations, such as &amp;quot;part-of&amp;quot;, can be by treating a predicate constant and by including in the knowledge base axioms like part-of(y,x) nn(x,y) In this fashion, we have been able to characterize succinctly the most common methods used for solving these problems in previous natural language systems, as the methods used in the (2) We have been investigating constraints on the most general formulations of the problems. There are general constraints, such as the Minimality Principle, which states that one should favor the minimal solution in the sense that the fewest new entities and relations must be hypothesized. For example, the argument-relapattern in compound nominals, as in oil be seen as satisfying the Minimality Principle, since the implicit relation is simply the one already given by the head noun. In addition, we are looking for constraints that are specific to given problems. For example, whereas whole-part compound nominals, like valve, quite common, part-whole compound 221 The FINITE STRING Newsletter Calls for Papers, Proposals, Pictures, Nominations nominals seem to be quite rare. This is probably because of a principle that says noun modifiers should further restrict the possible reference of the noun phrase, and parts are common to too many wholes to perform that function. (3) A knowledge base contains two kinds of knowledge, &amp;quot;type&amp;quot; knowledge about what kinds of situations are possible, and &amp;quot;token&amp;quot; knowledge about what the actual situation is. We are trying to determine which of these kinds of knowledge are required for each of the pragmatics problems. For example, reference requires both type and token knowledge, whereas most if not all instances of metonymy seem to require only type knowledge. (4) At the most abstract level, interpretation requires the constructive proof of a single logical expression consisting of many conjuncts. The deduction component can attempt to prove these conjuncts in a variety of orders. We have been investigating some of these possible orders. For example, one plausible candidate is that one should work from the inside out, trying first to solve the reference problems of arguments of predications before attempting to solve the compound nominal and metonymy problems presented by those predications. In our framework, this is an issue of where subgoals for the deduction component should be placed on an agenda. IMPLEMENTATION In our implementation of the TACITUS system, we are beginning with the minimal approach and building up slowly. As we implement the local pragmatics operations, we are using a knowledge base containing only the axioms that are needed for the test examples. Thus, it grows slowly as we try out more and more texts. As we gain greater confidence in the pragmatics operations, we will move more and more of the axioms from our commonsense and domain knowledge bases into the system&apos;s knowledge base. Our initial versions of the pragmatics operations are, for the most part, fairly standard techniques recast into our abstract framework. When the knowledge base has reached a significant size, we will begin experimenting with more general solutions and with various constraints on those general solutions. FUTURE PLANS In addition to pursuing our research in each of the areas described above, we will institute two new efforts next year. First of all, we will begin to extend our work in pragmatics to the recognition of discourse structure. This problem is illustrated by the following text: Air regulating valve failed. Gas turbine engine wouldn&apos;t turn over. Valve parts corroded. The temporal structure of this text is 3-1-2; first the valve parts corroded, and this caused the valve to fail, which caused the engine to not turn over. To recognize this structure, one must reason about causal relationships in the model of the device, and in addition one must recognize patterns of explanation and consequence in the text. The second new effort will be to build tools for domain knowledge acquisition. These will be based on the abstract machines in terms of which we are presently encoding our domain knowledge. Thus, the system should be able to allow the user to choose one of a set of abstract machines and then to augment it with various parts, properties and relations.</abstract>
<note confidence="0.9026495">ACKNOWLEDGMENT The TACITUS project is funded by the Defense Advanced Research Projects Agency under Office of Naval Research contract N00014-85-C-0013, as part of the Strategic Computing program. REFERENCE Hobbs, Jerry R.; Croft, William; Davies, Todd; Edwards, Douglas; and Laws, Kenneth 1986 Commonsense Metaphysics and Lexical In 24th Annual Meeting of the Association Computational Linguistics. York (June): 231-240.</note>
<title confidence="0.928794">CALLS FOR PAPERS, PROPOSALS, AND FOR AWARD NOMINATIONS CALL FOR PAPERS</title>
<author confidence="0.512252">FOURTH SYMPOSIUM ON EMPIRICAL FOUNDATION</author>
<affiliation confidence="0.804036">INFORMATION AND SOFTWARE SCIENCES (EFISS) 22-24 October 1986, Georgia Institute of Technology,</affiliation>
<address confidence="0.997577">Atlanta, Georgia</address>
<abstract confidence="0.994273615384615">The purpose of the meeting is to explore subjects and methods of scientific inquiry of common interest to information and software science, and to identify directions of research that will benefit from the mutual interaction of the two fields. The main theme of this symposium is empirical methods of evaluation of man-machine interfaces. Specific examples of relevant focal topics are: friendliness, portability, sensitivity, fidelity, integrity, fault-tolerance, compatibility, modularity, and evolution of man-machine interfaces; efficiency of interfaces as communication channels; evaluation of effects of error propagation through interfaces; modeling man-machine interfaces. Contributed papers will be considered also on other aspects of empiric foundations of information and software sciences such as methods of experimental design; measurement theory and techniques; empirical laws and theories of information and software sciences; their validation and verification; experimental data bases; and software properties and their evaluation and measurement. All submitted papers will be refereed. Those selected will be scheduled for presentation and published in the proceedings of the symposium. papers (at least 150 words long) are due March 1986. Authors will notified of their</abstract>
<intro confidence="0.572195">Linguistics, Volume 12, Number 3, July-September 1986</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>William Croft</author>
<author>Todd Davies</author>
<author>Douglas Edwards</author>
<author>Kenneth Laws</author>
</authors>
<title>Commonsense Metaphysics and Lexical Semantics.</title>
<date>1986</date>
<booktitle>In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<pages>231--240</pages>
<location>New York</location>
<marker>Hobbs, Croft, Davies, Edwards, Laws, 1986</marker>
<rawString>Hobbs, Jerry R.; Croft, William; Davies, Todd; Edwards, Douglas; and Laws, Kenneth 1986 Commonsense Metaphysics and Lexical Semantics. In Proceedings, 24th Annual Meeting of the Association for Computational Linguistics. New York (June): 231-240.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>