<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000467">
<title confidence="0.99761">
A Statistical Model for Lost Language Decipherment
</title>
<author confidence="0.92942">
Benjamin Snyder and Regina Barzilay Kevin Knight
</author>
<affiliation confidence="0.916298">
CSAIL ISI
Massachusetts Institute of Technology University of Southern California
</affiliation>
<email confidence="0.997903">
{bsnyder,regina}@csail.mit.edu knight@isi.edu
</email>
<sectionHeader confidence="0.997397" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999186736842105">
In this paper we propose a method for the
automatic decipherment of lost languages.
Given a non-parallel corpus in a known re-
lated language, our model produces both
alphabetic mappings and translations of
words into their corresponding cognates.
We employ a non-parametric Bayesian
framework to simultaneously capture both
low-level character mappings and high-
level morphemic correspondences. This
formulation enables us to encode some of
the linguistic intuitions that have guided
human decipherers. When applied to
the ancient Semitic language Ugaritic, the
model correctly maps 29 of 30 letters to
their Hebrew counterparts, and deduces
the correct Hebrew cognate for 60% of
the Ugaritic words which have cognates in
Hebrew.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999712461538461">
Dozens of lost languages have been deciphered
by humans in the last two centuries. In each
case, the decipherment has been considered a ma-
jor intellectual breakthrough, often the culmina-
tion of decades of scholarly efforts. Computers
have played no role in the decipherment any of
these languages. In fact, skeptics argue that com-
puters do not possess the “logic and intuition” re-
quired to unravel the mysteries of ancient scripts.1
In this paper, we demonstrate that at least some of
this logic and intuition can be successfully mod-
eled, allowing computational tools to be used in
the decipherment process.
</bodyText>
<footnote confidence="0.935071">
1“Successful archaeological decipherment has turned out
to require a synthesis of logic and intuition ... that comput-
ers do not (and presumably cannot) possess.” A. Robinson,
“Lost Languages: The Enigma of the World’s Undeciphered
Scripts” (2002)
</footnote>
<bodyText confidence="0.999981341463415">
Our definition of the computational decipher-
ment task closely follows the setup typically faced
by human decipherers (Robinson, 2002). Our in-
put consists of texts in a lost language and a corpus
of non-parallel data in a known related language.
The decipherment itself involves two related sub-
tasks: (i) finding the mapping between alphabets
of the known and lost languages, and (ii) translat-
ing words in the lost language into corresponding
cognates of the known language.
While there is no single formula that human de-
cipherers have employed, manual efforts have fo-
cused on several guiding principles. A common
starting point is to compare letter and word fre-
quencies between the lost and known languages.
In the presence of cognates the correct mapping
between the languages will reveal similarities in
frequency, both at the character and lexical level.
In addition, morphological analysis plays a cru-
cial role here, as highly frequent morpheme cor-
respondences can be particularly revealing. In
fact, these three strands of analysis (character fre-
quency, morphology, and lexical frequency) are
intertwined throughout the human decipherment
process. Partial knowledge of each drives discov-
ery in the others.
We capture these intuitions in a generative
Bayesian model. This model assumes that each
word in the lost language is composed of mor-
phemes which were generated with latent coun-
terparts in the known language. We model bilin-
gual morpheme pairs as arising through a series
of Dirichlet processes. This allows us to assign
probabilities based both on character-level corre-
spondences (using a character-edit base distribu-
tion) as well as higher-level morpheme correspon-
dences. In addition, our model carries out an im-
plicit morphological analysis of the lost language,
utilizing the known morphological structure of the
related language. This model structure allows us
to capture the interplay between the character-
</bodyText>
<page confidence="0.942884">
1048
</page>
<note confidence="0.9423215">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1048–1057,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99951224137931">
and morpheme-level correspondences that humans
have used in the manual decipherment process.
In addition, we introduce a novel technique
for imposing structural sparsity constraints on
character-level mappings. We assume that an ac-
curate alphabetic mapping between related lan-
guages will be sparse in the following way: each
letter will map to a very limited subset of letters
in the other language. We capture this intuition
by adapting the so-called “spike and slab” prior to
the Dirichlet-multinomial setting. For each pair
of characters in the two languages, we posit an
indicator variable which controls the prior likeli-
hood of character substitutions. We define a joint
prior over these indicator variables which encour-
ages sparse settings.
We applied our model to a corpus of Ugaritic,
an ancient Semitic language discovered in 1928.
Ugaritic was manually deciphered in 1932, us-
ing knowledge of Hebrew, a related language.
We compare our method against the only existing
decipherment baseline, an HMM-based character
substitution cipher (Knight and Yamada, 1999;
Knight et al., 2006). The baseline correctly maps
the majority of letters — 22 out of 30 — to their
correct Hebrew counterparts, but only correctly
translates 29% of all cognates. In comparison, our
method yields correct mappings for 29 of 30 let-
ters, and correctly translates 60.4% of all cognates.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999956666666667">
Our work on decipherment has connections to
three lines of work in statistical NLP. First, our
work relates to research on cognate identifica-
tion (Lowe and Mazaudon, 1994; Guy, 1994;
Kondrak, 2001; Bouchard et al., 2007; Kondrak,
2009). These methods typically rely on informa-
tion that is unknown in a typical deciphering sce-
nario (while being readily available for living lan-
guages). For instance, some methods employ a
hand-coded similarity function (Kondrak, 2001),
while others assume knowledge of the phonetic
mapping or require parallel cognate pairs to learn
a similarity function (Bouchard et al., 2007).
A second related line of work is lexicon in-
duction from non-parallel corpora. While this
research has similar goals, it typically builds on
information or resources unavailable for ancient
texts, such as comparable corpora, a seed lexi-
con, and cognate information (Fung and McKe-
own, 1997; Rapp, 1999; Koehn and Knight, 2002;
Haghighi et al., 2008). Moreover, distributional
methods that rely on co-occurrence analysis oper-
ate over large corpora, which are typically unavail-
able for a lost language.
Finally, Knight and Yamada (1999) and Knight
et al. (2006) describe a computational HMM-
based method for deciphering an unknown script
that represents a known spoken language. This
method “makes the text speak” by gleaning
character-to-sound mappings from non-parallel
character and sound sequences. It does not relate
words in different languages, thus it cannot encode
deciphering constraints similar to the ones consid-
ered in this paper. More importantly, this method
had not been applied to archaeological data. While
lost languages are gaining increasing interest in
the NLP community (Knight and Sproat, 2009),
there have been no successful attempts of their au-
tomatic decipherment.
</bodyText>
<sectionHeader confidence="0.994454" genericHeader="method">
3 Background on Ugaritic
</sectionHeader>
<subsectionHeader confidence="0.930823">
Manual Decipherment of Ugaritic Ugaritic
</subsectionHeader>
<bodyText confidence="0.999893344827586">
tablets were first found in Syria in 1929 (Smith,
1955; Watson and Wyatt, 1999). At the time, the
cuneiform writing on the tablets was of an un-
known type. Charles Virolleaud, who lead the ini-
tial decipherment effort, recognized that the script
was likely alphabetic, since the inscribed words
consisted of only thirty distinct symbols. The lo-
cation of the tablets discovery further suggested
that Ugaritic was likely to have been a Semitic
language from the Western branch, with proper-
ties similar to Hebrew and Aramaic. This real-
ization was crucial for deciphering the Ugaritic
script. In fact, German cryptographer and Semitic
scholar Hans Bauer decoded the first two Ugaritic
letters—mem and lambda—by mapping them to
Hebrew letters with similar occurrence patterns
in prefixes and suffixes. Bootstrapping from this
finding, Bauer found words in the tablets that were
likely to serve as cognates to Hebrew words—
e.g., the Ugaritic word for king matches its He-
brew equivalent. Through this process a few
more letters were decoded, but the Ugaritic texts
were still unreadable. What made the final deci-
pherment possible was a sheer stroke of luck—
Bauer guessed that a word inscribed on an ax dis-
covered in the Ras Shamra excavations was the
Ugaritic word for ax. Bauer’s guess was cor-
rect, though he selected the wrong phonetic se-
quence. Edouard Dhorme, another cryptographer
</bodyText>
<page confidence="0.993702">
1049
</page>
<bodyText confidence="0.990594666666667">
and Semitic scholar, later corrected the reading,
expanding a set of translated words. Discoveries
of additional tablets allowed Bauer, Dhorme and
Virolleaud to revise their hypothesis, successfully
completing the decipherment.
Linguistic Features of Ugaritic Ugaritic
shares many features with other ancient Semitic
languages, following the same word order, gender,
number, and case structure (Hetzron, 1997). It is a
morphologically rich language, with triliteral roots
and many prefixes and suffixes.
At the same time, it exhibits a number of fea-
tures that distinguish it from Hebrew. Ugaritic has
a bigger phonemic inventory than Hebrew, yield-
ing a bigger alphabet – 30 letters vs. 22 in He-
brew. Another distinguishing feature of Ugaritic
is that vowels are only written with glottal stops
while in Hebrew many long vowels are written us-
ing homorganic consonants. Ugaritic also does not
have articles, while Hebrew nouns and adjectives
take definite articles which are realized as prefixes.
These differences result in significant divergence
between Hebrew and Ugaritic cognates, thereby
complicating the decipherment process.
</bodyText>
<sectionHeader confidence="0.988415" genericHeader="method">
4 Problem Formulation
</sectionHeader>
<bodyText confidence="0.999975685714286">
We are given a corpus in a lost language and a non-
parallel corpus in a related language from the same
language family. Our primary goal is to translate
words in the unknown language by mapping them
to cognates in the known language. As part of this
process, we induce a lower-level mapping between
the letters of the two alphabets, capturing the reg-
ular phonetic correspondences found in cognates.
We make several assumptions about the writ-
ing system of the lost language. First, we assume
that the writing system is alphabetic in nature. In
general, this assumption can be easily validated by
counting the number of symbols found in the writ-
ten record. Next, we assume that the corpus has
been transcribed into electronic format, where the
graphemes present in the physical text have been
unambiguously identified. Finally, we assume that
words are explicitly separated in the text, either by
white space or a special symbol.
We also make a mild assumption about the mor-
phology of the lost language. We posit that each
word consists of a stem, prefix, and suffix, where
the latter two may be omitted. This assumption
captures a wide range of human languages and a
variety of morphological systems. While the cor-
rect morphological analysis of words in the lost
language must be learned, we assume that the in-
ventory and frequencies of prefixes and suffixes in
the known language are given.
In summary, the observed input to the model
consists of two elements: (i) a list of unanalyzed
word types derived from a corpus in the lost lan-
guage, and (ii) a morphologically analyzed lexicon
in a known related language derived from a sepa-
rate corpus, in our case non-parallel.
</bodyText>
<sectionHeader confidence="0.99865" genericHeader="method">
5 Model
</sectionHeader>
<subsectionHeader confidence="0.992112">
5.1 Intuitions
</subsectionHeader>
<bodyText confidence="0.998735166666667">
Our goal is to incorporate the logic and intuition
used by human decipherers in an unsupervised sta-
tistical model. To make these intuitions concrete,
consider the following toy example, consisting of
a lost language much like English, but written us-
ing numerals:
</bodyText>
<listItem confidence="0.999730666666667">
• 15234 (asked)
• 1525 (asks)
• 4352 (desk)
</listItem>
<bodyText confidence="0.999112962962963">
Analyzing the undeciphered corpus, we might first
notice a pair of endings, -34, and -5, which both
occur after the initial sequence 152- (and may like-
wise occur at the end of a variety of words in
the corpus). If we know this lost language to be
closely related to English, we can surmise that
these two endings correspond to the English ver-
bal suffixes -ed and -s. Using this knowledge,
we can hypothesize the following character corre-
spondences: (3 = e), (4 = d), (5 = s). We now know
that (4252 = des2) and we can use our knowl-
edge of the English lexicon to hypothesize that this
word is desk, thereby learning the correspondence
(2 = k). Finally, we can use similar reasoning to
reveal that the initial character sequence 152- cor-
responds to the English verb ask.
As this example illustrates, human deci-
pherment efforts proceed by discovering both
character-level and morpheme-level correspon-
dences. This interplay implicitly relies on a
morphological analysis of words in the lost lan-
guage, while utilizing knowledge of the known
language’s lexicon and morphology.
One final intuition our model should capture is
the sparsity of the alphabetic correspondence be-
tween related languages. We know from compar-
ative linguistics that the correct mapping will pre-
</bodyText>
<page confidence="0.962494">
1050
</page>
<bodyText confidence="0.9999445">
serve regular phonetic relationships between the
two languages (as exemplified by cognates). As a
result, each character in one language will map to
a small number of characters in the other language
(typically one, but sometimes two or three). By
incorporating this structural sparsity intuition, we
can allow the model to focus on on a smaller set of
linguistically valid hypotheses.
Below we give an overview of our model, which
is designed to capture these linguistic intuitions.
</bodyText>
<subsectionHeader confidence="0.999942">
5.2 Model Structure
</subsectionHeader>
<bodyText confidence="0.999967875">
Our model posits that every observed word in the
lost language is composed of a sequence of mor-
phemes (prefix, stem, suffix). Furthermore we
posit that each morpheme was probabilistically
generated jointly with a latent counterpart in the
known language.
Our goal is to find those counterparts that lead to
high frequency correspondences both at the char-
acter and morpheme level. The technical chal-
lenge is that each level of correspondence (char-
acter and morpheme) can completely describe the
observed data. A probabilistic mechanism based
simply on one leaves no room for the other to play
a role. We resolve this tension by employing a
non-parametric Bayesian model: the distributions
over bilingual morpheme pairs assign probabil-
ity based on recurrent patterns at the morpheme
level. These distributions are themselves drawn
from a prior probabilistic process which favors
distributions with consistent character-level corre-
spondences.
We now give a formal description of the model
(see Figure 1 for a graphical overview). There are
four basic layers in the generative process:
</bodyText>
<listItem confidence="0.9936415">
1. Structural sparsity: draw a set of indicator
⃗
variables A corresponding to character-edit
operations.
2. Character-edit distribution: draw a base
distribution G0 parameterized by weights on
character-edit operations.
3. Morpheme-pair distributions: draw a set
of distributions on bilingual morpheme pairs
Gstm, Gpre|stm, Gsuf|stm.
4. Word generation: draw pairs of cognates
in the lost and known language, as well as
words in the lost language with no cognate
counterpart.
</listItem>
<figure confidence="0.987624">
A
Go
</figure>
<figureCaption confidence="0.998347">
Figure 1: Plate diagram of the decipherment
</figureCaption>
<bodyText confidence="0.933057735294118">
model. The structural sparsity indicator variables
A⃗ determine the values of the base distribution hy-
perparameters ⃗v. The base distribution G0 de-
fines probabilities over string-pairs based solely on
character-level edits. The morpheme-pair distri-
butions Gstm, Gpre|stm, Gsuf|stm directly assign
probabilities to highly frequent morpheme pairs.
We now go through each step in more detail.
Structural Sparsity The first step of the genera-
tive process provides a control on the sparsity of
edit-operation probabilities, encoding the linguis-
tic intuition that the correct character-level map-
pings should be sparse. The set of edit opera-
tions includes character substitutions, insertions,
and deletions, as well as a special end sym-
bol: {(u, h), (ϵ, h), (u, ϵ), END} (where u and h
range over characters in the lost and known lan-
guages, respectively). For each edit operation a we
posit a corresponding indicator variable Ae. The
set of character substitutions with indicators set to
one, {(u, h) : A(u,h) = 1}) conveys the set of
phonetically valid correspondences. We define a
joint prior over these variables to encourage sparse
character mappings. This prior can be viewed as a
distribution over binary matrices and is defined to
encourage rows and columns to sum to low integer
values (typically 1). More precisely, for each char-
acter u in the lost language, we count the number
of mappings c(u) = Eh A(u,h). We then define
a set of features which count how many of these
characters map to i other characters beyond some
budget bz: fz = max (0, |{u : c(u) = i} |− bz).
Likewise, we define corresponding features f′ z and
budgets b′ z for the characters h in the known lan-
</bodyText>
<figure confidence="0.922332071428571">
Gstm
ustm
hstm
upre
hpre
usuf
hsuf
word
Gprelstm
stm
Gsuf|stm
stm
1051
⃗
</figure>
<bodyText confidence="0.619944">
guage. The prior over λ is then defined as
</bodyText>
<equation confidence="0.9426005">
P( ⃗λ) = exp(f⃗ · w⃗+ ⃗f′ · ⃗w) (1)
Z
</equation>
<bodyText confidence="0.99989752631579">
where the feature weight vector w⃗ is set to encour-
age sparse mappings, and Z is a corresponding
normalizing constant, which we never need com-
pute. We set w⃗ so that each character must map to
at least one other character, and so that mappings
to more than one other character are discouraged 2
Character-edit Distribution The next step in
the generative process is drawing a base distri-
bution G0 over character edit sequences (each of
which yields a bilingual pair of morphemes). This
distribution is parameterized by a set of weights ϕ
on edit operations, where the weights over substi-
tutions, insertions, and deletions each individually
sum to one. In addition, G0 provides a fixed dis-
tribution q over the number of insertions and dele-
tions occurring in any single edit sequence. Prob-
abilities over edit sequences (and consequently on
bilingual morpheme pairs) are then defined ac-
cording to G0 as:
</bodyText>
<equation confidence="0.99421">
�P (⃗e) = ϕei · q (#ins(⃗e), #del(⃗e))
i
</equation>
<bodyText confidence="0.9999525">
We observe that the average Ugaritic word is over
two letters longer than the average Hebrew word.
Thus, occurrences of Hebrew character insertions
are a priori likely, and Ugaritic character deletions
are very unlikely. In our experiments, we set q
to disallow Ugaritic deletions, and to allow one
Hebrew insertion per morpheme (with probability
0.4).
The prior on the base distribution G0 is a
Dirichlet distribution with hyperparameters ⃗v, i.e.,
ϕ⃗ ∼ Dirichlet(⃗v). Each value ve thus corre-
sponds to a character edit operation e. Crucially,
the value of each ve depends deterministically on
its corresponding indicator variable:
</bodyText>
<equation confidence="0.999075">
ve = � K if λe = 1.
1 if λe = 0,
</equation>
<bodyText confidence="0.961512714285714">
where K is some constant value &gt; 1.3 The overall
effect is that when λe = 0, the marginal prior den-
sity of the corresponding edit weight ϕe spikes at
2We set w0 = −oo, w1 = 0, w2 = −50, w&gt;2 = −oo,
with budgets b′2 = 7, b′3 = 1(otherwise zero), reflecting the
knowledge that there are eight more Ugaritic than Hebrew
letters.
</bodyText>
<footnote confidence="0.660542">
3Set to 50 in our experiments.
</footnote>
<bodyText confidence="0.999644047619048">
0. When λe = 1, the corresponding marginal prior
density remains relatively flat and unconstrained.
See (Ishwaran and Rao, 2005) for a similar appli-
cation of “spike-and-slab” priors in the regression
scenario.
Morpheme-pair Distributions Next we draw a
series of distributions which directly assign prob-
ability to morpheme pairs. The previously drawn
base distribution G0 along with a fixed concentra-
tion parameter α define a Dirichlet process (An-
toniak, 1974): DP(G0, α), which provides prob-
abilities over morpheme-pair distributions. The
resulting distributions are likely to be skewed in
favor of a few frequently occurring morpheme-
pairs, while remaining sensitive to the character-
level probabilities of the base distribution.
Our model distinguishes between three types of
morphemes: prefixes, stems, and suffixes. As a
result, we model each morpheme type as arising
from distinct Dirichlet processes, that share a sin-
gle base distribution:
</bodyText>
<equation confidence="0.998891">
Gstm ∼ DP(G0, αstm)
Gpre|stm ∼ DP(G0, αpre)
Gsuf|stm ∼ DP(G0, αsuf)
</equation>
<bodyText confidence="0.9995842">
We model prefix and suffix distributions as con-
ditionally dependent on the part-of-speech of the
stem morpheme-pair. This choice capture the lin-
guistic fact that different parts-of-speech bear dis-
tinct affix frequencies. Thus, while we draw a sin-
gle distribution Gstm, we maintain separate distri-
butions Gpre|stm and Gsuf|stm for each possible
stem part-of-speech.
Word Generation Once the morpheme-pair
distributions have been drawn, actual word pairs
may now be generated. First the model draws a
boolean variable ci to determine whether word i in
the lost language has a cognate in the known lan-
guage, according to some prior P(ci). If ci = 1,
then a cognate word pair (u, h) is produced:
</bodyText>
<equation confidence="0.8761978">
(ustm, hstm) ∼ Gstm
(upre, hpre) ∼ Gpre|stm
(usuf, hsuf) ∼ Gsuf|stm
u = upreustmusuf
h = hprehstmhsuf
</equation>
<bodyText confidence="0.963248">
Otherwise, a lone word u is generated, according
a uniform character-level language model.
</bodyText>
<page confidence="0.984442">
1052
</page>
<bodyText confidence="0.999927692307692">
In summary, this model structure captures both
character and lexical level correspondences, while
utilizing morphological knowledge of the known
language. An additional feature of this multi-
layered model structure is that each distribution
over morpheme pairs is derived from the single
character-level base distribution Go. As a re-
sult, any character-level mappings learned from
one type of morphological correspondence will be
propagated to all other morpheme distributions.
Finally, the character-level mappings discovered
by the model are encouraged to obey linguistically
motivated structural sparsity constraints.
</bodyText>
<sectionHeader confidence="0.999921" genericHeader="method">
6 Inference
</sectionHeader>
<bodyText confidence="0.999959727272727">
For each word ui in our undeciphered lan-
guage we predict a morphological segmentation
(upreustmusuf)i and corresponding cognate in the
known language (hprehstmhsuf)i. Ideally we
would like to predict the analysis with highest
marginal probability under our model given the
observed undeciphered corpus and related lan-
guage lexicon. In order to do so, we need to
integrate out all the other latent variables in our
model. As these integrals are intractable to com-
pute exactly, we resort to the standard Monte Carlo
approximation. We collect samples of the vari-
ables over which we wish to marginalize but for
which we cannot compute closed-form integrals.
We then approximate the marginal probabilities
for undeciphered word ui by summing over all the
samples, and predicting the analysis with highest
probability.
In our sampling algorithm, we avoid sam-
pling the base distribution Go and the derived
morpheme-pair distributions (Gstm etc.), instead
using analytical closed forms. We explicitly sam-
</bodyText>
<equation confidence="0.534042">
⃗
</equation>
<bodyText confidence="0.997015444444444">
ple the sparsity indicator variables λ, the cognate
indicator variables ci, and latent word analyses
(segmentations and Hebrew counterparts). To do
so tractably, we use Gibbs sampling to draw each
latent variable conditioned on our current sample
of the others. Although the samples are no longer
independent, they form a Markov chain whose sta-
tionary distribution is the true joint distribution de-
fined by the model (Geman and Geman, 1984).
</bodyText>
<subsectionHeader confidence="0.999707">
6.1 Sampling Word Analyses
</subsectionHeader>
<bodyText confidence="0.999249866666667">
For each undeciphered word, we need to sample
a morphological segmentation (upre, ustm, usuf)i
along with latent morphemes in the known lan-
guage (hpre, hstm, hsuf)i. More precisely, we
need to sample three character-edit sequences
⃗esuf which together yield the observed
word ui.
We break this into two sampling steps. First
we sample the morphological segmentation of ui,
along with the part-of-speech pos of the latent
stem cognate. To do so, we enumerate each pos-
sible segmentation and part-of-speech and calcu-
late its joint conditional probability (for notational
clarity, we leave implicit the conditioning on the
other samples in the corpus):
</bodyText>
<equation confidence="0.988233">
P(upre, ustm, usuf, pos) =
∑ ∑P(⃗estm) ∑P(⃗epre|pos) P(⃗esuf|pos)
⃗estm ⃗epre ⃗es.f
(2)
</equation>
<bodyText confidence="0.999617363636364">
where the summations over character-edit se-
quences are restricted to those which yield the seg-
mentation (upre, ustm, usuf) and a latent cognate
with part-of-speech pos.
For a particular stem edit-sequence ⃗estm, we
compute its conditional probability in closed form
according to a Chinese Restaurant Process (An-
toniak, 1974). To do so, we use counts from
the other sampled word analyses: countstm(⃗estm)
gives the number of times that the entire edit-
sequence ⃗estm has been observed:
</bodyText>
<equation confidence="0.999167666666667">
countstm(⃗estm) + α ∏i p(ei)
P(⃗estm) �
n + α
</equation>
<bodyText confidence="0.9967855">
where n is the number of other word analyses sam-
pled, and α is a fixed concentration parameter. The
product ∏i p(ei) gives the probability of ⃗estm ac-
cording to the base distribution Go. Since the
parameters of Go are left unsampled, we use the
marginalized form:
</bodyText>
<equation confidence="0.983851">
p(e)
= ve′ ve′ +(k) (3)
</equation>
<bodyText confidence="0.950506272727273">
where count(e) is the number of times that
character-edit e appears in distinct edit-sequences
(across prefixes, stems, and suffixes), and k is the
sum of these counts across all character-edits. Re-
call that ve is a hyperparameter for the Dirichlet
prior on Go and depends on the value of the corre-
sponding indicator variable λe.
Once the segmentation (upre, ustm, usuf) and
part-of-speech pos have been sampled, we pro-
ceed to sample the actual edit-sequences (and thus
epre, ⃗estm,
</bodyText>
<page confidence="0.89839">
1053
</page>
<bodyText confidence="0.999553333333333">
latent morphemes counterparts). Now, instead of
summing over the values in Equation 2, we instead
sample from them.
</bodyText>
<subsectionHeader confidence="0.999909">
6.2 Sampling Sparsity Indicators
</subsectionHeader>
<bodyText confidence="0.973679">
Recall that each sparsity indicator λe determines
the value of the corresponding hyperparameter ve
of the Dirichlet prior for the character-edit base
distribution G0. In addition, we have an unnormal-
ized joint prior P( ⃗λ) = g(⃗λ)
Z which encourages a
sparse setting of these variables. To sample a par-
</bodyText>
<equation confidence="0.994880375">
⃗
ticular λe, we consider the set λ in which λe = 0
⃗
and λ′ in which λe = 1. We then compute:
P(⃗λ) ∝ g( ⃗λ) · ve
Ee′ v[k]
[count(e)]
e′
</equation>
<bodyText confidence="0.99993225">
where k is the sum of counts for all edit opera-
tions, and the notation a[b] indicates the ascending
factorial. Likewise, we can compute a probability
for ⃗λ′ with corresponding values v′e.
</bodyText>
<subsectionHeader confidence="0.999758">
6.3 Sampling Cognate Indicators
</subsectionHeader>
<bodyText confidence="0.999966222222222">
Finally, for each word ui, we sample a correspond-
ing indicator variable ci. To do so, we calcu-
late Equation 2 for all possible segmentations and
parts-of-speech and sum the resulting values to ob-
tain the conditional likelihood P(ui|ci = 1). We
also calculate P(ui|ci = 0) using a uniform uni-
gram character-level language model (and thus de-
pends only on the number of characters in ui). We
then sample from among the two values:
</bodyText>
<equation confidence="0.9999905">
P(ui|ci = 1) · P(ci = 1)
P(ui|ci = 0) · P(ci = 0)
</equation>
<subsectionHeader confidence="0.997296">
6.4 High-level Resampling
</subsectionHeader>
<bodyText confidence="0.964485388888889">
Besides the individual sampling steps detailed
above, we also consider several larger sampling
moves in order to speed convergence. For exam-
ple, for each type of edit-sequence e⃗ which has
been sampled (and may now occur many times
throughout the data), we consider a single joint
⃗
move to another edit-sequence e′ (both of which
yield the same lost language morpheme u). The
details are much the same as above, and as before
the set of possible edit-sequences is limited by the
string u and the known language lexicon.
We also resample groups of the sparsity indica-
⃗
tor variables λ in tandem, to allow a more rapid ex-
ploration of the probability space. For each char-
acter u, we block sample the entire set {λ(u,h)}h,
and likewise for each character h.
</bodyText>
<subsectionHeader confidence="0.998513">
6.5 Implementation Details
</subsectionHeader>
<bodyText confidence="0.999995580645161">
Many of the steps detailed above involve the con-
sideration of all possible edit-sequences consis-
tent with (i) a particular undeciphered word ui and
(ii) the entire lexicon of words in the known lan-
guage (or some subset of words with a particu-
lar part-of-speech). In particular, we need to both
sample from and sum over this space of possibil-
ities repeatedly. Doing so by simple enumeration
would needlessly repeat many sub-computations.
Instead we use finite-state acceptors to compactly
represent both the entire Hebrew lexicon as well
as potential Hebrew word forms for each Ugaritic
word. By intersecting two such FSAs and mini-
mizing the result we can efficiently represent all
potential Hebrew words for a particular Ugaritic
word. We weight the edges in the FSA according
to the base distribution probabilities (in Equation 3
above). Although these intersected acceptors have
to be constantly reweighted to reflect changing
probabilities, their topologies need only be com-
puted once. One weighted correctly, marginals
and samples can be computed using dynamic pro-
gramming.
Even with a large number of sampling rounds, it
is difficult to fully explore the latent variable space
for complex unsupervised models. Thus a clever
initialization is usually required to start the sam-
pler in a high probability region. We initialize our
model with the results of the HMM-based baseline
(see section 8), and rule out character substitutions
with probability &lt; 0.05 according to the baseline.
</bodyText>
<sectionHeader confidence="0.999785" genericHeader="method">
7 Experiments
</sectionHeader>
<subsectionHeader confidence="0.9999">
7.1 Corpus and Annotations
</subsectionHeader>
<bodyText confidence="0.999973125">
We apply our model to the ancient Ugaritic lan-
guage (see Section 3 for background). Our un-
deciphered corpus consists of an electronic tran-
scription of the Ugaritic tablets (Cunchillos et al.,
2002). This corpus contains 7,386 unique word
types. As our known language corpus, we use the
Hebrew Bible, which is both geographically and
temporally close to Ugaritic. To extract a Hebrew
morphological lexicon we assume the existence
of manual morphological and part-of-speech an-
notations (Groves and Lowery, 2006). We divide
Hebrew stems into four main part-of-speech cat-
egories each with a distinct affix profile: Noun,
Verb, Pronoun, and Particle. For each part-of-
speech category, we determine the set of allowable
affixes using the annotated Bible corpus.
</bodyText>
<page confidence="0.97239">
1054
</page>
<table confidence="0.999471">
Words Morphemes
type token type token
Baseline 28.82% 46.00% N/A N/A
Our Model 60.42% 66.71% 75.07% 81.25%
No Sparsity 46.08% 54.01% 69.48% 76.10%
</table>
<tableCaption confidence="0.99949">
Table 1: Accuracy of cognate translations, mea-
</tableCaption>
<bodyText confidence="0.99609465">
sured with respect to complete word-forms and
morphemes, for the HMM-based substitution ci-
pher baseline, our complete model, and our model
without the structural sparsity priors. Note that the
baseline does not provide per-morpheme results,
as it does not predict morpheme boundaries.
To evaluate the output of our model, we anno-
tated the words in the Ugaritic lexicon with the
corresponding Hebrew cognates found in the stan-
dard reference dictionary (del Olo Lete and San-
mart´ın, 2004). In addition, manual morphological
segmentation was carried out with the guidance of
a standard Ugaritic grammar (Schniedewind and
Hunt, 2007). Although Ugaritic is an inflectional
rather than agglutinative language, in its written
form (which lacks vowels) words can easily be
segmented (e.g. wyplt.n becomes wy-plt.-n).
Overall, we identified Hebrew cognates for
2,155 word forms, covering almost 1/3 of the
Ugaritic vocabulary.4
</bodyText>
<sectionHeader confidence="0.777917" genericHeader="evaluation">
8 Evaluation Tasks and Results
</sectionHeader>
<bodyText confidence="0.999406824324325">
We evaluate our model on four separate decipher-
ment tasks: (i) Learning alphabetic mappings,
(ii) translating cognates, (iii) identifying cognates,
and (iv) morphological segmentation.
As a baseline for the first three of these tasks
(learning alphabetic mappings and translating and
identifying cognates), we adapt the HMM-based
method of Knight et al. (2006) for learning let-
ter substitution ciphers. In its original setting, this
model was used to map written texts to spoken lan-
guage, under the assumption that each character
was emitted from a hidden phonemic state. In our
adaptation, we assume instead that each Ugaritic
character was generated by a hidden Hebrew let-
ter. Hebrew character trigram transition probabili-
ties are estimated using the Hebrew Bible, and He-
brew to Ugaritic character emission probabilities
are learned using EM. Finally, the highest prob-
4We are confident that a large majority of Ugaritic words
with known Hebrew cognates were thus identified. The
remaining Ugaritic words include many personal and geo-
graphic names, words with cognates in other Semitic lan-
guages, and words whose etymology is uncertain.
ability sequence of latent Hebrew letters is pre-
dicted for each Ugaritic word-form, using Viterbi
decoding.
Alphabetic Mapping The first essential step to-
wards successful decipherment is recovering the
mapping between the symbols of the lost language
and the alphabet of a known language. As a gold
standard for this comparison, we use the well-
established relationship between the Ugaritic and
Hebrew alphabets (Hetzron, 1997). This mapping
is not one-to-one but is generally quite sparse. Of
the 30 Ugaritic symbols, 28 map predominantly
to a single Hebrew letter, and the remaining two
map to two different letters. As the Hebrew alpha-
bet contains only 22 letters, six map to two dis-
tinct Ugaritic letters and two map to three distinct
Ugaritic letters.
We recover our model’s predicted alphabetic
mappings by simply examining the sampled val-
ues of the binary indicator variables Au,h for each
Ugaritic-Hebrew letter pair (u, h). Due to our
structural sparsity prior P(⃗A), the predicted map-
pings are sparse: each Ugaritic letter maps to only
a single Hebrew letter, and most Hebrew letters
map to only a single Ugaritic letter. To recover
alphabetic mappings from the HMM substitution
cipher baseline, we predict the Hebrew letter h
which maximizes the model’s probability P(hIu),
for each Ugaritic letter u.
To evaluate these mappings, we simply count
the number of Ugaritic letters that are correctly
mapped to one of their Hebrew reflexes. By this
measure, the baseline recovers correct mappings
for 22 out of 30 Ugaritic characters (73.3%). Our
model recovers correct mappings for all but one
(very low frequency) Ugaritic characters, yielding
96.67% accuracy.
Cognate Decipherment We compare the deci-
pherment accuracy for Ugaritic words that have
corresponding Hebrew cognates. We evaluate
our model’s predictions on each distinct Ugaritic
word-form at both the type and token level. As
Table 1 shows, our method correctly translates
over 60% of all distinct Ugaritic word-forms with
Hebrew cognates and over 71% of the individ-
ual morphemes that compose them, outperform-
ing the baseline by significant margins. Accu-
racy improves when the frequency of the word-
forms is taken into account (token-level evalua-
tion), indicating that the model is able to deci-
pher frequent words more accurately than infre-
</bodyText>
<page confidence="0.973685">
1055
</page>
<figure confidence="0.963962">
0 0.2 0.4 0.6 0.8 1
False positive rate
</figure>
<figureCaption confidence="0.999809">
Figure 2: ROC curve for cognate identification.
</figureCaption>
<bodyText confidence="0.999547628571429">
quent words. We also measure the average Leven-
shtein distance between predicted and actual cog-
nate word-forms. On average, our model’s pre-
dictions lie 0.52 edit operations from the true cog-
nate, whereas the baseline’s predictions average a
distance of 1.26 edit operations.
Finally, we evaluated the performance of our
model when the structural sparsity constraints are
not used. As Table 1 shows, performance degrades
significantly in the absence of these priors, indi-
cating the importance of modeling the sparsity of
character mappings.
Cognate identification We evaluate our
model’s ability to identify cognates using the
sampled indicator variables ci. As before, we
compare our performance against the HMM
substitution cipher baseline. To produce baseline
cognate identification predictions, we calculate
the probability of each latent Hebrew letter se-
quence predicted by the HMM, and compare it to
a uniform character-level Ugaritic language model
(as done by our model, to avoid automatically
assigning higher cognate probability to shorter
Ugaritic words). For both our model and the
baseline, we can vary the threshold for cognate
identification by raising or lowering the cognate
prior P(ci). As the prior is set higher, we detect
more true cognates, but the false positive rate
increases as well.
Figure 2 shows the ROC curve obtained by
varying this prior both for our model and the base-
line. At all operating points, our model outper-
forms the baseline, and both models always pre-
dict better than chance. In practice for our model,
we use a high cognate prior, thus only ruling out
</bodyText>
<table confidence="0.998838333333333">
precision recall f-measure
Morfessor 88.87% 67.48% 76.71%
Our Model 86.62% 90.53% 88.53%
</table>
<tableCaption confidence="0.996467">
Table 2: Morphological segmentation accuracy for
a standard unsupervised baseline and our model.
</tableCaption>
<bodyText confidence="0.977456133333333">
those Ugaritic word-forms which are very unlikely
to have Hebrew cognates.
Morphological segmentation Finally, we eval-
uate the accuracy of our model’s morphological
segmentation for Ugaritic words. As a baseline
for this comparison, we use Morfessor Categories-
MAP (Creutz and Lagus, 2007). As Table 2
shows, our model provides a significant boost in
performance, especially for recall. This result is
consistent with previous work showing that mor-
phological annotations can be projected to new
languages lacking annotation (Yarowsky et al.,
2000; Snyder and Barzilay, 2008), but generalizes
those results to the case where parallel data is un-
available.
</bodyText>
<sectionHeader confidence="0.989581" genericHeader="conclusions">
9 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99961635">
In this paper we proposed a method for the au-
tomatic decipherment of lost languages. The key
strength of our model lies in its ability to incorpo-
rate a range of linguistic intuitions in a statistical
framework.
We hope to address several issues in future
work. Our model fails to take into account
the known frequency of Hebrew words and mor-
phemes. In fact, the most common error is incor-
rectly translating the masculine plural suffix (-m)
as the third person plural possessive suffix (-m)
rather than the correct and much more common
plural suffix (-ym). Also, even with the correct al-
phabetic mapping, many words can only be deci-
phered by examining their literary context. Our
model currently operates purely on the vocabulary
level and thus fails to take this contextual infor-
mation into account. Finally, we intend to explore
our model’s predictive power when the family of
the lost language is unknown.5
</bodyText>
<footnote confidence="0.6916115">
5The authors acknowledge the support of the NSF (CA-
REER grant IIS-0448168, grant IIS-0835445, and grant IIS-
0835652) and the Microsoft Research New Faculty Fellow-
ship. Thanks to Michael Collins, Tommi Jaakkola, and
the MIT NLP group for their suggestions and comments.
Any opinions, findings, conclusions, or recommendations ex-
pressed in this paper are those of the authors, and do not nec-
essarily reflect the views of the funding organizations.
</footnote>
<figure confidence="0.998161666666667">
Our Model
Baseline
Random
True positive rate 1
0.8
0.6
0.4
0.2
0
</figure>
<page confidence="0.985953">
1056
</page>
<sectionHeader confidence="0.997606" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999890472527473">
C. E. Antoniak. 1974. Mixtures of Dirichlet pro-
cesses with applications to bayesian nonparametric
problems. The Annals of Statistics, 2:1152–1174,
November.
Alexandre Bouchard, Percy Liang, Thomas Griffiths,
and Dan Klein. 2007. A probabilistic approach to
diachronic phonology. In Proceedings of EMNLP,
pages 887–896.
Mathias Creutz and Krista Lagus. 2007. Unsuper-
vised models for morpheme segmentation and mor-
phology learning. ACM Transactions on Speech and
Language Processing, 4(1).
Jesus-Luis Cunchillos, Juan-Pablo Vita, and Jose-
´Angel Zamora. 2002. Ugaritic data bank. CD-
ROM.
Gregoria del Olo Lete and Joaquin Sanmart´ın. 2004.
A Dictionary of the Ugaritic Language in the Alpha-
betic Tradition. Number 67 in Handbook of Oriental
Studies. Section 1 The Near and Middle East. Brill.
Pascale Fung and Kathleen McKeown. 1997. Find-
ing terminology translations from non-parallel cor-
pora. In Proceedings of the Annual Workshop on
Very Large Corpora, pages 192–202.
S. Geman and D. Geman. 1984. Stochastic relaxation,
gibbs distributions and the bayesian restoration of
images. IEEE Transactions on Pattern Analysis and
Machine Intelligence, 12:609–628.
Alan Groves and Kirk Lowery, editors. 2006. The
Westminster Hebrew Bible Morphology Database.
Westminster Hebrew Institute, Philadelphia, PA,
USA.
Jacques B. M. Guy. 1994. An algorithm for identifying
cognates in bilingual wordlists and its applicability
to machine translation. Journal of Quantitative Lin-
guistics, 1(1):35–42.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In Proceedings of the
ACL/HLT, pages 771–779.
Robert Hetzron, editor. 1997. The Semitic Languages.
Routledge.
H. Ishwaran and J.S. Rao. 2005. Spike and slab vari-
able selection: frequentist and Bayesian strategies.
The Annals of Statistics, 33(2):730–773.
Kevin Knight and Richard Sproat. 2009. Writing sys-
tems, transliteration and decipherment. NAACL Tu-
torial.
K. Knight and K. Yamada. 1999. A computa-
tional approach to deciphering unknown scripts. In
ACL Workshop on Unsupervised Learning in Natu-
ral Language Processing.
Kevin Knight, Anish Nair, Nishit Rathod, and Kenji
Yamada. 2006. Unsupervised analysis for deci-
pherment problems. In Proceedings of the COL-
ING/ACL, pages 499–506.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In
Proceedings of the ACL-02 workshop on Unsuper-
vised lexical acquisition, pages 9–16.
Grzegorz Kondrak. 2001. Identifying cognates by
phonetic and semantic similarity. In Proceeding of
NAACL, pages 1–8.
Grzegorz Kondrak. 2009. Identification of cognates
and recurrent sound correspondences in word lists.
Traitement Automatique des Langues, 50(2):201–
235.
John B. Lowe and Martine Mazaudon. 1994. The re-
construction engine: a computer implementation of
the comparative method. Computational Linguis-
tics, 20(3):381–417.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In Proceedings of the ACL, pages 519–526.
Andrew Robinson. 2002. Lost Languages: The
Enigma of the World’s Undeciphered Scripts.
McGraw-Hill.
William M. Schniedewind and Joel H. Hunt. 2007. A
Primer on Ugaritic: Language, Culture and Litera-
ture. Cambridge University Press.
Mark S. Smith, editor. 1955. Untold Stories: The Bible
and Ugaritic Studies in the Twentieth Century. Hen-
drickson Publishers.
Benjamin Snyder and Regina Barzilay. 2008. Cross-
lingual propagation for morphological analysis. In
Proceedings of the AAAI, pages 848–854.
Wilfred Watson and Nicolas Wyatt, editors. 1999.
Handbook of Ugaritic Studies. Brill.
David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2000. Inducing multilingual text analysis
tools via robust projection across aligned corpora.
In Proceedings of HLT, pages 161–168.
</reference>
<page confidence="0.993964">
1057
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.470850">
<title confidence="0.999747">A Statistical Model for Lost Language Decipherment</title>
<author confidence="0.999742">Snyder Barzilay Kevin Knight</author>
<affiliation confidence="0.999117">CSAIL ISI Massachusetts Institute of Technology University of Southern California</affiliation>
<email confidence="0.99985">knight@isi.edu</email>
<abstract confidence="0.991630105263158">In this paper we propose a method for the automatic decipherment of lost languages. Given a non-parallel corpus in a known related language, our model produces both alphabetic mappings and translations of words into their corresponding cognates. We employ a non-parametric Bayesian framework to simultaneously capture both low-level character mappings and highlevel morphemic correspondences. This formulation enables us to encode some of the linguistic intuitions that have guided human decipherers. When applied to the ancient Semitic language Ugaritic, the model correctly maps 29 of 30 letters to their Hebrew counterparts, and deduces the correct Hebrew cognate for 60% of the Ugaritic words which have cognates in</abstract>
<intro confidence="0.506334">Hebrew.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C E Antoniak</author>
</authors>
<title>Mixtures of Dirichlet processes with applications to bayesian nonparametric problems. The Annals of Statistics,</title>
<date>1974</date>
<pages>2--1152</pages>
<contexts>
<context position="19369" citStr="Antoniak, 1974" startWordPosition="3100" endWordPosition="3102"> budgets b′2 = 7, b′3 = 1(otherwise zero), reflecting the knowledge that there are eight more Ugaritic than Hebrew letters. 3Set to 50 in our experiments. 0. When λe = 1, the corresponding marginal prior density remains relatively flat and unconstrained. See (Ishwaran and Rao, 2005) for a similar application of “spike-and-slab” priors in the regression scenario. Morpheme-pair Distributions Next we draw a series of distributions which directly assign probability to morpheme pairs. The previously drawn base distribution G0 along with a fixed concentration parameter α define a Dirichlet process (Antoniak, 1974): DP(G0, α), which provides probabilities over morpheme-pair distributions. The resulting distributions are likely to be skewed in favor of a few frequently occurring morphemepairs, while remaining sensitive to the characterlevel probabilities of the base distribution. Our model distinguishes between three types of morphemes: prefixes, stems, and suffixes. As a result, we model each morpheme type as arising from distinct Dirichlet processes, that share a single base distribution: Gstm ∼ DP(G0, αstm) Gpre|stm ∼ DP(G0, αpre) Gsuf|stm ∼ DP(G0, αsuf) We model prefix and suffix distributions as con</context>
<context position="23972" citStr="Antoniak, 1974" startWordPosition="3806" endWordPosition="3808">e enumerate each possible segmentation and part-of-speech and calculate its joint conditional probability (for notational clarity, we leave implicit the conditioning on the other samples in the corpus): P(upre, ustm, usuf, pos) = ∑ ∑P(⃗estm) ∑P(⃗epre|pos) P(⃗esuf|pos) ⃗estm ⃗epre ⃗es.f (2) where the summations over character-edit sequences are restricted to those which yield the segmentation (upre, ustm, usuf) and a latent cognate with part-of-speech pos. For a particular stem edit-sequence ⃗estm, we compute its conditional probability in closed form according to a Chinese Restaurant Process (Antoniak, 1974). To do so, we use counts from the other sampled word analyses: countstm(⃗estm) gives the number of times that the entire editsequence ⃗estm has been observed: countstm(⃗estm) + α ∏i p(ei) P(⃗estm) � n + α where n is the number of other word analyses sampled, and α is a fixed concentration parameter. The product ∏i p(ei) gives the probability of ⃗estm according to the base distribution Go. Since the parameters of Go are left unsampled, we use the marginalized form: p(e) = ve′ ve′ +(k) (3) where count(e) is the number of times that character-edit e appears in distinct edit-sequences (across pre</context>
</contexts>
<marker>Antoniak, 1974</marker>
<rawString>C. E. Antoniak. 1974. Mixtures of Dirichlet processes with applications to bayesian nonparametric problems. The Annals of Statistics, 2:1152–1174, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Bouchard</author>
<author>Percy Liang</author>
<author>Thomas Griffiths</author>
<author>Dan Klein</author>
</authors>
<title>A probabilistic approach to diachronic phonology.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>887--896</pages>
<contexts>
<context position="5555" citStr="Bouchard et al., 2007" startWordPosition="847" endWordPosition="850">herment baseline, an HMM-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information that is unknown in a typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as co</context>
</contexts>
<marker>Bouchard, Liang, Griffiths, Klein, 2007</marker>
<rawString>Alexandre Bouchard, Percy Liang, Thomas Griffiths, and Dan Klein. 2007. A probabilistic approach to diachronic phonology. In Proceedings of EMNLP, pages 887–896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mathias Creutz</author>
<author>Krista Lagus</author>
</authors>
<title>Unsupervised models for morpheme segmentation and morphology learning.</title>
<date>2007</date>
<journal>ACM Transactions on Speech and Language Processing,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="36088" citStr="Creutz and Lagus, 2007" startWordPosition="5756" endWordPosition="5759">rforms the baseline, and both models always predict better than chance. In practice for our model, we use a high cognate prior, thus only ruling out precision recall f-measure Morfessor 88.87% 67.48% 76.71% Our Model 86.62% 90.53% 88.53% Table 2: Morphological segmentation accuracy for a standard unsupervised baseline and our model. those Ugaritic word-forms which are very unlikely to have Hebrew cognates. Morphological segmentation Finally, we evaluate the accuracy of our model’s morphological segmentation for Ugaritic words. As a baseline for this comparison, we use Morfessor CategoriesMAP (Creutz and Lagus, 2007). As Table 2 shows, our model provides a significant boost in performance, especially for recall. This result is consistent with previous work showing that morphological annotations can be projected to new languages lacking annotation (Yarowsky et al., 2000; Snyder and Barzilay, 2008), but generalizes those results to the case where parallel data is unavailable. 9 Conclusion and Future Work In this paper we proposed a method for the automatic decipherment of lost languages. The key strength of our model lies in its ability to incorporate a range of linguistic intuitions in a statistical framew</context>
</contexts>
<marker>Creutz, Lagus, 2007</marker>
<rawString>Mathias Creutz and Krista Lagus. 2007. Unsupervised models for morpheme segmentation and morphology learning. ACM Transactions on Speech and Language Processing, 4(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesus-Luis Cunchillos</author>
<author>Juan-Pablo Vita</author>
<author>Jose´Angel Zamora</author>
</authors>
<title>Ugaritic data bank.</title>
<date>2002</date>
<publisher>CDROM.</publisher>
<contexts>
<context position="28775" citStr="Cunchillos et al., 2002" startWordPosition="4619" endWordPosition="4622">r of sampling rounds, it is difficult to fully explore the latent variable space for complex unsupervised models. Thus a clever initialization is usually required to start the sampler in a high probability region. We initialize our model with the results of the HMM-based baseline (see section 8), and rule out character substitutions with probability &lt; 0.05 according to the baseline. 7 Experiments 7.1 Corpus and Annotations We apply our model to the ancient Ugaritic language (see Section 3 for background). Our undeciphered corpus consists of an electronic transcription of the Ugaritic tablets (Cunchillos et al., 2002). This corpus contains 7,386 unique word types. As our known language corpus, we use the Hebrew Bible, which is both geographically and temporally close to Ugaritic. To extract a Hebrew morphological lexicon we assume the existence of manual morphological and part-of-speech annotations (Groves and Lowery, 2006). We divide Hebrew stems into four main part-of-speech categories each with a distinct affix profile: Noun, Verb, Pronoun, and Particle. For each part-ofspeech category, we determine the set of allowable affixes using the annotated Bible corpus. 1054 Words Morphemes type token type token</context>
</contexts>
<marker>Cunchillos, Vita, Zamora, 2002</marker>
<rawString>Jesus-Luis Cunchillos, Juan-Pablo Vita, and Jose´Angel Zamora. 2002. Ugaritic data bank. CDROM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregoria del Olo Lete</author>
<author>Joaquin Sanmart´ın</author>
</authors>
<title>A Dictionary of the Ugaritic Language in the Alphabetic Tradition.</title>
<date>2004</date>
<journal>Number</journal>
<booktitle>in Handbook of Oriental Studies. Section 1 The Near and Middle East.</booktitle>
<volume>67</volume>
<publisher>Brill.</publisher>
<marker>Lete, Sanmart´ın, 2004</marker>
<rawString>Gregoria del Olo Lete and Joaquin Sanmart´ın. 2004. A Dictionary of the Ugaritic Language in the Alphabetic Tradition. Number 67 in Handbook of Oriental Studies. Section 1 The Near and Middle East. Brill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Kathleen McKeown</author>
</authors>
<title>Finding terminology translations from non-parallel corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the Annual Workshop on Very Large Corpora,</booktitle>
<pages>192--202</pages>
<contexts>
<context position="6236" citStr="Fung and McKeown, 1997" startWordPosition="951" endWordPosition="955">on that is unknown in a typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora, a seed lexicon, and cognate information (Fung and McKeown, 1997; Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). Moreover, distributional methods that rely on co-occurrence analysis operate over large corpora, which are typically unavailable for a lost language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constr</context>
</contexts>
<marker>Fung, McKeown, 1997</marker>
<rawString>Pascale Fung and Kathleen McKeown. 1997. Finding terminology translations from non-parallel corpora. In Proceedings of the Annual Workshop on Very Large Corpora, pages 192–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Geman</author>
<author>D Geman</author>
</authors>
<title>Stochastic relaxation, gibbs distributions and the bayesian restoration of images.</title>
<date>1984</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<pages>12--609</pages>
<contexts>
<context position="22882" citStr="Geman and Geman, 1984" startWordPosition="3638" endWordPosition="3641">our sampling algorithm, we avoid sampling the base distribution Go and the derived morpheme-pair distributions (Gstm etc.), instead using analytical closed forms. We explicitly sam⃗ ple the sparsity indicator variables λ, the cognate indicator variables ci, and latent word analyses (segmentations and Hebrew counterparts). To do so tractably, we use Gibbs sampling to draw each latent variable conditioned on our current sample of the others. Although the samples are no longer independent, they form a Markov chain whose stationary distribution is the true joint distribution defined by the model (Geman and Geman, 1984). 6.1 Sampling Word Analyses For each undeciphered word, we need to sample a morphological segmentation (upre, ustm, usuf)i along with latent morphemes in the known language (hpre, hstm, hsuf)i. More precisely, we need to sample three character-edit sequences ⃗esuf which together yield the observed word ui. We break this into two sampling steps. First we sample the morphological segmentation of ui, along with the part-of-speech pos of the latent stem cognate. To do so, we enumerate each possible segmentation and part-of-speech and calculate its joint conditional probability (for notational cla</context>
</contexts>
<marker>Geman, Geman, 1984</marker>
<rawString>S. Geman and D. Geman. 1984. Stochastic relaxation, gibbs distributions and the bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine Intelligence, 12:609–628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Groves</author>
<author>Kirk Lowery</author>
<author>editors</author>
</authors>
<title>The Westminster Hebrew Bible Morphology Database. Westminster Hebrew Institute,</title>
<date>2006</date>
<location>Philadelphia, PA, USA.</location>
<marker>Groves, Lowery, editors, 2006</marker>
<rawString>Alan Groves and Kirk Lowery, editors. 2006. The Westminster Hebrew Bible Morphology Database. Westminster Hebrew Institute, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques B M Guy</author>
</authors>
<title>An algorithm for identifying cognates in bilingual wordlists and its applicability to machine translation.</title>
<date>1994</date>
<journal>Journal of Quantitative Linguistics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="5517" citStr="Guy, 1994" startWordPosition="843" endWordPosition="844">st the only existing decipherment baseline, an HMM-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information that is unknown in a typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources una</context>
</contexts>
<marker>Guy, 1994</marker>
<rawString>Jacques B. M. Guy. 1994. An algorithm for identifying cognates in bilingual wordlists and its applicability to machine translation. Journal of Quantitative Linguistics, 1(1):35–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL/HLT,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="6296" citStr="Haghighi et al., 2008" startWordPosition="962" endWordPosition="965">being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora, a seed lexicon, and cognate information (Fung and McKeown, 1997; Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). Moreover, distributional methods that rely on co-occurrence analysis operate over large corpora, which are typically unavailable for a lost language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constraints similar to the ones considered in this paper. More imp</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In Proceedings of the ACL/HLT, pages 771–779.</rawString>
</citation>
<citation valid="true">
<title>The Semitic Languages.</title>
<date>1997</date>
<editor>Robert Hetzron, editor.</editor>
<publisher>Routledge.</publisher>
<marker>1997</marker>
<rawString>Robert Hetzron, editor. 1997. The Semitic Languages. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Ishwaran</author>
<author>J S Rao</author>
</authors>
<title>Spike and slab variable selection: frequentist and Bayesian strategies.</title>
<date>2005</date>
<journal>The Annals of Statistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="19037" citStr="Ishwaran and Rao, 2005" startWordPosition="3049" endWordPosition="3052">ion e. Crucially, the value of each ve depends deterministically on its corresponding indicator variable: ve = � K if λe = 1. 1 if λe = 0, where K is some constant value &gt; 1.3 The overall effect is that when λe = 0, the marginal prior density of the corresponding edit weight ϕe spikes at 2We set w0 = −oo, w1 = 0, w2 = −50, w&gt;2 = −oo, with budgets b′2 = 7, b′3 = 1(otherwise zero), reflecting the knowledge that there are eight more Ugaritic than Hebrew letters. 3Set to 50 in our experiments. 0. When λe = 1, the corresponding marginal prior density remains relatively flat and unconstrained. See (Ishwaran and Rao, 2005) for a similar application of “spike-and-slab” priors in the regression scenario. Morpheme-pair Distributions Next we draw a series of distributions which directly assign probability to morpheme pairs. The previously drawn base distribution G0 along with a fixed concentration parameter α define a Dirichlet process (Antoniak, 1974): DP(G0, α), which provides probabilities over morpheme-pair distributions. The resulting distributions are likely to be skewed in favor of a few frequently occurring morphemepairs, while remaining sensitive to the characterlevel probabilities of the base distribution</context>
</contexts>
<marker>Ishwaran, Rao, 2005</marker>
<rawString>H. Ishwaran and J.S. Rao. 2005. Spike and slab variable selection: frequentist and Bayesian strategies. The Annals of Statistics, 33(2):730–773.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Richard Sproat</author>
</authors>
<title>Writing systems, transliteration and decipherment.</title>
<date>2009</date>
<journal>NAACL Tutorial.</journal>
<contexts>
<context position="7062" citStr="Knight and Sproat, 2009" startWordPosition="1076" endWordPosition="1079">language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constraints similar to the ones considered in this paper. More importantly, this method had not been applied to archaeological data. While lost languages are gaining increasing interest in the NLP community (Knight and Sproat, 2009), there have been no successful attempts of their automatic decipherment. 3 Background on Ugaritic Manual Decipherment of Ugaritic Ugaritic tablets were first found in Syria in 1929 (Smith, 1955; Watson and Wyatt, 1999). At the time, the cuneiform writing on the tablets was of an unknown type. Charles Virolleaud, who lead the initial decipherment effort, recognized that the script was likely alphabetic, since the inscribed words consisted of only thirty distinct symbols. The location of the tablets discovery further suggested that Ugaritic was likely to have been a Semitic language from the We</context>
</contexts>
<marker>Knight, Sproat, 2009</marker>
<rawString>Kevin Knight and Richard Sproat. 2009. Writing systems, transliteration and decipherment. NAACL Tutorial.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>K Yamada</author>
</authors>
<title>A computational approach to deciphering unknown scripts.</title>
<date>1999</date>
<booktitle>In ACL Workshop on Unsupervised Learning in Natural Language Processing.</booktitle>
<contexts>
<context position="5019" citStr="Knight and Yamada, 1999" startWordPosition="757" endWordPosition="760">called “spike and slab” prior to the Dirichlet-multinomial setting. For each pair of characters in the two languages, we posit an indicator variable which controls the prior likelihood of character substitutions. We define a joint prior over these indicator variables which encourages sparse settings. We applied our model to a corpus of Ugaritic, an ancient Semitic language discovered in 1928. Ugaritic was manually deciphered in 1932, using knowledge of Hebrew, a related language. We compare our method against the only existing decipherment baseline, an HMM-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information th</context>
<context position="6481" citStr="Knight and Yamada (1999)" startWordPosition="989" endWordPosition="992">g or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora, a seed lexicon, and cognate information (Fung and McKeown, 1997; Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). Moreover, distributional methods that rely on co-occurrence analysis operate over large corpora, which are typically unavailable for a lost language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constraints similar to the ones considered in this paper. More importantly, this method had not been applied to archaeological data. While lost languages are gaining increasing interest in the NLP community (Knight and Sproat, 2009), there have been n</context>
</contexts>
<marker>Knight, Yamada, 1999</marker>
<rawString>K. Knight and K. Yamada. 1999. A computational approach to deciphering unknown scripts. In ACL Workshop on Unsupervised Learning in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Anish Nair</author>
<author>Nishit Rathod</author>
<author>Kenji Yamada</author>
</authors>
<title>Unsupervised analysis for decipherment problems.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL,</booktitle>
<pages>499--506</pages>
<contexts>
<context position="5041" citStr="Knight et al., 2006" startWordPosition="761" endWordPosition="764">rior to the Dirichlet-multinomial setting. For each pair of characters in the two languages, we posit an indicator variable which controls the prior likelihood of character substitutions. We define a joint prior over these indicator variables which encourages sparse settings. We applied our model to a corpus of Ugaritic, an ancient Semitic language discovered in 1928. Ugaritic was manually deciphered in 1932, using knowledge of Hebrew, a related language. We compare our method against the only existing decipherment baseline, an HMM-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information that is unknown in a typ</context>
<context position="6506" citStr="Knight et al. (2006)" startWordPosition="994" endWordPosition="997"> pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora, a seed lexicon, and cognate information (Fung and McKeown, 1997; Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). Moreover, distributional methods that rely on co-occurrence analysis operate over large corpora, which are typically unavailable for a lost language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constraints similar to the ones considered in this paper. More importantly, this method had not been applied to archaeological data. While lost languages are gaining increasing interest in the NLP community (Knight and Sproat, 2009), there have been no successful attempts of </context>
<context position="30841" citStr="Knight et al. (2006)" startWordPosition="4930" endWordPosition="4933">ive language, in its written form (which lacks vowels) words can easily be segmented (e.g. wyplt.n becomes wy-plt.-n). Overall, we identified Hebrew cognates for 2,155 word forms, covering almost 1/3 of the Ugaritic vocabulary.4 8 Evaluation Tasks and Results We evaluate our model on four separate decipherment tasks: (i) Learning alphabetic mappings, (ii) translating cognates, (iii) identifying cognates, and (iv) morphological segmentation. As a baseline for the first three of these tasks (learning alphabetic mappings and translating and identifying cognates), we adapt the HMM-based method of Knight et al. (2006) for learning letter substitution ciphers. In its original setting, this model was used to map written texts to spoken language, under the assumption that each character was emitted from a hidden phonemic state. In our adaptation, we assume instead that each Ugaritic character was generated by a hidden Hebrew letter. Hebrew character trigram transition probabilities are estimated using the Hebrew Bible, and Hebrew to Ugaritic character emission probabilities are learned using EM. Finally, the highest prob4We are confident that a large majority of Ugaritic words with known Hebrew cognates were </context>
</contexts>
<marker>Knight, Nair, Rathod, Yamada, 2006</marker>
<rawString>Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Yamada. 2006. Unsupervised analysis for decipherment problems. In Proceedings of the COLING/ACL, pages 499–506.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="6272" citStr="Koehn and Knight, 2002" startWordPosition="958" endWordPosition="961">phering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora, a seed lexicon, and cognate information (Fung and McKeown, 1997; Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). Moreover, distributional methods that rely on co-occurrence analysis operate over large corpora, which are typically unavailable for a lost language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constraints similar to the ones considered</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL-02 workshop on Unsupervised lexical acquisition, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Identifying cognates by phonetic and semantic similarity.</title>
<date>2001</date>
<booktitle>In Proceeding of NAACL,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="5532" citStr="Kondrak, 2001" startWordPosition="845" endWordPosition="846"> existing decipherment baseline, an HMM-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information that is unknown in a typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for an</context>
</contexts>
<marker>Kondrak, 2001</marker>
<rawString>Grzegorz Kondrak. 2001. Identifying cognates by phonetic and semantic similarity. In Proceeding of NAACL, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Identification of cognates and recurrent sound correspondences in word lists. Traitement Automatique des Langues,</title>
<date>2009</date>
<volume>50</volume>
<issue>2</issue>
<pages>235</pages>
<contexts>
<context position="5571" citStr="Kondrak, 2009" startWordPosition="851" endWordPosition="852">M-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information that is unknown in a typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora</context>
</contexts>
<marker>Kondrak, 2009</marker>
<rawString>Grzegorz Kondrak. 2009. Identification of cognates and recurrent sound correspondences in word lists. Traitement Automatique des Langues, 50(2):201– 235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John B Lowe</author>
<author>Martine Mazaudon</author>
</authors>
<title>The reconstruction engine: a computer implementation of the comparative method.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="5506" citStr="Lowe and Mazaudon, 1994" startWordPosition="839" endWordPosition="842"> compare our method against the only existing decipherment baseline, an HMM-based character substitution cipher (Knight and Yamada, 1999; Knight et al., 2006). The baseline correctly maps the majority of letters — 22 out of 30 — to their correct Hebrew counterparts, but only correctly translates 29% of all cognates. In comparison, our method yields correct mappings for 29 of 30 letters, and correctly translates 60.4% of all cognates. 2 Related Work Our work on decipherment has connections to three lines of work in statistical NLP. First, our work relates to research on cognate identification (Lowe and Mazaudon, 1994; Guy, 1994; Kondrak, 2001; Bouchard et al., 2007; Kondrak, 2009). These methods typically rely on information that is unknown in a typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or re</context>
</contexts>
<marker>Lowe, Mazaudon, 1994</marker>
<rawString>John B. Lowe and Martine Mazaudon. 1994. The reconstruction engine: a computer implementation of the comparative method. Computational Linguistics, 20(3):381–417.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="6248" citStr="Rapp, 1999" startWordPosition="956" endWordPosition="957">typical deciphering scenario (while being readily available for living languages). For instance, some methods employ a hand-coded similarity function (Kondrak, 2001), while others assume knowledge of the phonetic mapping or require parallel cognate pairs to learn a similarity function (Bouchard et al., 2007). A second related line of work is lexicon induction from non-parallel corpora. While this research has similar goals, it typically builds on information or resources unavailable for ancient texts, such as comparable corpora, a seed lexicon, and cognate information (Fung and McKeown, 1997; Rapp, 1999; Koehn and Knight, 2002; Haghighi et al., 2008). Moreover, distributional methods that rely on co-occurrence analysis operate over large corpora, which are typically unavailable for a lost language. Finally, Knight and Yamada (1999) and Knight et al. (2006) describe a computational HMMbased method for deciphering an unknown script that represents a known spoken language. This method “makes the text speak” by gleaning character-to-sound mappings from non-parallel character and sound sequences. It does not relate words in different languages, thus it cannot encode deciphering constraints simila</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the ACL, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Robinson</author>
</authors>
<title>Lost Languages: The Enigma of the World’s Undeciphered Scripts.</title>
<date>2002</date>
<publisher>McGraw-Hill.</publisher>
<contexts>
<context position="1968" citStr="Robinson, 2002" startWordPosition="291" endWordPosition="292">ion” required to unravel the mysteries of ancient scripts.1 In this paper, we demonstrate that at least some of this logic and intuition can be successfully modeled, allowing computational tools to be used in the decipherment process. 1“Successful archaeological decipherment has turned out to require a synthesis of logic and intuition ... that computers do not (and presumably cannot) possess.” A. Robinson, “Lost Languages: The Enigma of the World’s Undeciphered Scripts” (2002) Our definition of the computational decipherment task closely follows the setup typically faced by human decipherers (Robinson, 2002). Our input consists of texts in a lost language and a corpus of non-parallel data in a known related language. The decipherment itself involves two related subtasks: (i) finding the mapping between alphabets of the known and lost languages, and (ii) translating words in the lost language into corresponding cognates of the known language. While there is no single formula that human decipherers have employed, manual efforts have focused on several guiding principles. A common starting point is to compare letter and word frequencies between the lost and known languages. In the presence of cognat</context>
</contexts>
<marker>Robinson, 2002</marker>
<rawString>Andrew Robinson. 2002. Lost Languages: The Enigma of the World’s Undeciphered Scripts. McGraw-Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Schniedewind</author>
<author>Joel H Hunt</author>
</authors>
<title>A Primer on Ugaritic: Language, Culture and Literature.</title>
<date>2007</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="30160" citStr="Schniedewind and Hunt, 2007" startWordPosition="4832" endWordPosition="4835">ured with respect to complete word-forms and morphemes, for the HMM-based substitution cipher baseline, our complete model, and our model without the structural sparsity priors. Note that the baseline does not provide per-morpheme results, as it does not predict morpheme boundaries. To evaluate the output of our model, we annotated the words in the Ugaritic lexicon with the corresponding Hebrew cognates found in the standard reference dictionary (del Olo Lete and Sanmart´ın, 2004). In addition, manual morphological segmentation was carried out with the guidance of a standard Ugaritic grammar (Schniedewind and Hunt, 2007). Although Ugaritic is an inflectional rather than agglutinative language, in its written form (which lacks vowels) words can easily be segmented (e.g. wyplt.n becomes wy-plt.-n). Overall, we identified Hebrew cognates for 2,155 word forms, covering almost 1/3 of the Ugaritic vocabulary.4 8 Evaluation Tasks and Results We evaluate our model on four separate decipherment tasks: (i) Learning alphabetic mappings, (ii) translating cognates, (iii) identifying cognates, and (iv) morphological segmentation. As a baseline for the first three of these tasks (learning alphabetic mappings and translating</context>
</contexts>
<marker>Schniedewind, Hunt, 2007</marker>
<rawString>William M. Schniedewind and Joel H. Hunt. 2007. A Primer on Ugaritic: Language, Culture and Literature. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark S Smith</author>
<author>editor</author>
</authors>
<date>1955</date>
<booktitle>Untold Stories: The Bible and Ugaritic Studies in the Twentieth</booktitle>
<publisher>Century. Hendrickson Publishers.</publisher>
<marker>Smith, editor, 1955</marker>
<rawString>Mark S. Smith, editor. 1955. Untold Stories: The Bible and Ugaritic Studies in the Twentieth Century. Hendrickson Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Crosslingual propagation for morphological analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI,</booktitle>
<pages>848--854</pages>
<contexts>
<context position="36373" citStr="Snyder and Barzilay, 2008" startWordPosition="5799" endWordPosition="5802"> for a standard unsupervised baseline and our model. those Ugaritic word-forms which are very unlikely to have Hebrew cognates. Morphological segmentation Finally, we evaluate the accuracy of our model’s morphological segmentation for Ugaritic words. As a baseline for this comparison, we use Morfessor CategoriesMAP (Creutz and Lagus, 2007). As Table 2 shows, our model provides a significant boost in performance, especially for recall. This result is consistent with previous work showing that morphological annotations can be projected to new languages lacking annotation (Yarowsky et al., 2000; Snyder and Barzilay, 2008), but generalizes those results to the case where parallel data is unavailable. 9 Conclusion and Future Work In this paper we proposed a method for the automatic decipherment of lost languages. The key strength of our model lies in its ability to incorporate a range of linguistic intuitions in a statistical framework. We hope to address several issues in future work. Our model fails to take into account the known frequency of Hebrew words and morphemes. In fact, the most common error is incorrectly translating the masculine plural suffix (-m) as the third person plural possessive suffix (-m) r</context>
</contexts>
<marker>Snyder, Barzilay, 2008</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2008. Crosslingual propagation for morphological analysis. In Proceedings of the AAAI, pages 848–854.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wilfred Watson</author>
<author>Nicolas Wyatt</author>
<author>editors</author>
</authors>
<date>1999</date>
<booktitle>Handbook of Ugaritic Studies.</booktitle>
<publisher>Brill.</publisher>
<marker>Watson, Wyatt, editors, 1999</marker>
<rawString>Wilfred Watson and Nicolas Wyatt, editors. 1999. Handbook of Ugaritic Studies. Brill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2000</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>161--168</pages>
<contexts>
<context position="36345" citStr="Yarowsky et al., 2000" startWordPosition="5795" endWordPosition="5798">l segmentation accuracy for a standard unsupervised baseline and our model. those Ugaritic word-forms which are very unlikely to have Hebrew cognates. Morphological segmentation Finally, we evaluate the accuracy of our model’s morphological segmentation for Ugaritic words. As a baseline for this comparison, we use Morfessor CategoriesMAP (Creutz and Lagus, 2007). As Table 2 shows, our model provides a significant boost in performance, especially for recall. This result is consistent with previous work showing that morphological annotations can be projected to new languages lacking annotation (Yarowsky et al., 2000; Snyder and Barzilay, 2008), but generalizes those results to the case where parallel data is unavailable. 9 Conclusion and Future Work In this paper we proposed a method for the automatic decipherment of lost languages. The key strength of our model lies in its ability to incorporate a range of linguistic intuitions in a statistical framework. We hope to address several issues in future work. Our model fails to take into account the known frequency of Hebrew words and morphemes. In fact, the most common error is incorrectly translating the masculine plural suffix (-m) as the third person plu</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2000</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2000. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of HLT, pages 161–168.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>