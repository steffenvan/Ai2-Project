<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000049">
<title confidence="0.9971825">
Resolving Anaphora in a Portable Natural Language
Front End to Databases
</title>
<author confidence="0.86042">
Flavia A. Barros and Anne DeRoeck
</author>
<affiliation confidence="0.997439">
Department of Computer Science
University of Essex
</affiliation>
<address confidence="0.637691">
Colchester - C04 3SQ - U.K.
</address>
<email confidence="0.474348">
[barrf — deroe]Oessex.ac.uk
</email>
<sectionHeader confidence="0.985658" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999920684210526">
An analysis of the evolution of Natu-
ral Language front ends in the last three
decades shows that the growth in portabil-
ity brought, as a side effect, the narrow-
ing of the provided coverage of contextu-
ally based linguistic phenomena, such as
anaphora and ellipsis.
This paper presents the design and state
of development of a computational mecha-
nism which provides pronominal Anaphora
Resolution within the environment of a
highly portable Natural Language front
end to databases, SQUIRREL.&apos; Simple
cases of Ellipsis are also treated by the pro-
posed model.
An Overview of SQUIRREL is presented,
followed by a description of the Discourse
Module and the results achieved so far. The
prototype is implemented in C-Prolog.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.965205444444444">
The development of Natural Language (NL) systems
for data retrieval has been a central issue in NL Pro-
cessing research for the last three decades, motivated
by the aim of helping non-expert database users.
When we try to draw a line of evolution of such
systems, it can be observed that growth in portabil-
ity, essential for commercial viability, came at a cost
in terms of broader linguistic coverage.&apos;
Earlier systems, mostly research motivated, were
mainly developed for a single application, using
domain-dependent information for treating contex-
tual phenomena (eg, DEACON (Craig et al., 1966),
SHRDLU (Winograd, 1972), LUNAR (Woods,
&apos;The current system forms the base line for a joint
SERC/DTI funded collaborative project between the
University of Essex and Status IQ Ltd. for construct-
ing an integrated platform for the retrieval of structured
and textual data through Natural Language queries.
</bodyText>
<footnote confidence="0.6405725">
2See (Barros and DeRoeck, 1993) for a comprehensive
review on Portable NL front ends.
</footnote>
<bodyText confidence="0.997621095238095">
1973), LADDER (Hendrix et al., 1978)). In con-
trast, the subsequent generation of interfaces car-
ried a higher emphasis on portability in their de-
sign (eg, INTELLECT (Harris, 1984), IRUS (Bates
et al., 1986), TEAM (Grosz et al., 1987)). These
systems, however, offer a reduced coverage of dis-
course phenomena, a central issue when continuity
in the database consultation carries some priority.
Thus, the ideal NL Front End (NLFE) should carry
a broader linguistic coverage, in order to support a
user focused query process, combined with a high
degree of portability.
In this light, we designed a Discourse Module,
which is incorporated into a highly portable NLFE,
SQUIRREL (DeRoeck et al., 1991). The system was
originally conceived with a single-query based mode
of consultation. By providing for anaphora and sim-
ple cases of ellipsis resolution, the Discourse Mod-
ule yields continuous consultations without the use
of world models (to maintain the system&apos;s general
portability).
</bodyText>
<sectionHeader confidence="0.992988" genericHeader="method">
2 Issues in Anaphora Resolution
</sectionHeader>
<bodyText confidence="0.970207210526316">
Our primary goal is the achievement of dialogue-like
querying by extending SQUIRREL to a system ca-
pable of dealing with basic pronominal anaphora and
ellipsis. Information about each query is made avail-
able to the following queries, such that references to
entities already introduced can be resolved.
This solution is common practice among NLFEs
implementations (eg, LDC-1 (Ballard et al., 1984),
Datenbank-DIALOG (Trost et al., 1988)). However,
it is subject to limitations. In particular, sequences
like the following cannot be handled:
Query: who works for which salary in shoes?
DB answer: [Malcolm - $5,000.00]
Query: who is his boss?
because the resulting query
Query: who is the boss of [who works for which
salary in shoes] ?
leads the system into a type error, as a personal
pronoun was substituted by a sentence. This was our
</bodyText>
<page confidence="0.993502">
119
</page>
<figure confidence="0.999791647058824">
English Sentence
Query
Syn/Sem
Represent.
()
Data Mode
Extended
DRC
Represent.
-•••411. SQL query
TRC
•-■111. Represent.
Answer
Database -4--(Database
FOL
Represent.
Context
</figure>
<figureCaption confidence="0.999971">
Figure 1: SQUIRREL with Discourse Module.
</figureCaption>
<bodyText confidence="0.99820675">
main motivation for keeping information conveyed
by the DB answer, so it could be used for future
reference. We consider this essential for achieving a
dialogue-like mode of consultation.
</bodyText>
<sectionHeader confidence="0.937252" genericHeader="method">
3 Overview of SQUIRREL
</sectionHeader>
<bodyText confidence="0.999934978260869">
The system consists of a portable Natural Lan-
guage front end prototype for the interrogation of
logical and relational database systems (DeRoeck et
al., 1991). It is divided into two main sections: the
Front End and the Back End [Fig. 1].
The Front End takes the input sentence, produc-
ing syntactic and semantic representations, which it
maps into First Order Logic. All representations
are independent of the domain of application or
database model. Syntactic and semantic rules work
in tandem. The former are a feature-based CFG,
whereas the latter are expressed in Property Theory
(Turner, 1987). The lexicon is incomplete, treating
unknown words as proper nouns to be fully inter-
preted when reaching the database.
The Back End uses an Extended Data Model to
map the logical representation into expressions in
the Domain Relational Calculus (DRC), which is
translated via Tuple Relational Calculus (TRC) into
SQL (a standard query language) by means of a syn-
tactic transducer. All representations at this level
are domain dependent.
Both the Front End and Back End were designed
to guarantee modularity and portability to the sys-
tem as a whole. Strict separation between domain
dependent and independent components must be
maintained for the sake of portability. The system
has no world model embedded in it, and no infer-
ence engine. Only the lexicon and the table-based
Extended Data Model have to be customised for a
new domain of application.
SQUIRREL maintains three levels of ambiguity,
induced by the syntax, the semantics, and the do-
main. The Back End has a type checker, which uses
the Extended Data Model to resolve ambiguity from
the semantic level. At each level, all possible repre-
sentations are generated by the system, and tried
one at a time. Only the appropriate ones survive
the type checking and the database consultation.
As a consequence, more than one successful an-
swer can be obtained from the same query. All suc-
cessful answers are presented to the user, who is in
charge of choosing one. This feature was added to
the original system in order to give the user control
over which elements are added to the context during
the consultation.
</bodyText>
<sectionHeader confidence="0.995653" genericHeader="method">
4 The Discourse Module - Overview
</sectionHeader>
<bodyText confidence="0.999984730769231">
The core of the Discourse Module is the context, a
dynamic list of candidate antecedents for anaphoric
reference. The context grows as a stack, i.e., can-
didates selected from each query and its DB answer
are stored on top of the candidates from the previous
queries as the consultation evolves. All candidates
are represented in the same format.
Selection of candidates from the query is regulated
by rules embedded in the system&apos;s grammar, where
each syntactic rule has its associated context rule.
Entries are associated with information pertaining
to category, number, gender and semantic represen-
tation. Since the lexicon allows open classes (such as
proper names, for which no specific lexical entry ex-
ists), some of this information may not become avail-
able until the query reaches the database. At this
point, a separate database interrogation will supply
gender information for proper nouns in the context.
Selecting which items in database answers are
added to the context is less straightforward, as no
syntactic or semantic information is available con-
cerning a particular answer. Furthermore, the selec-
tion may depend on a specific application and should
be a factor for customisation. As a consequence, in-
formation on which entities are to be kept as candi-
dates for reference in the context is encoded in the
</bodyText>
<page confidence="0.970577">
120
</page>
<bodyText confidence="0.999312952380952">
Extended Data Model. Entries are formatted and
associated with syntactic and semantic information
(on the basis of the characteristics of the database
domain from which they are retrieved) and, in cases
where the data derives from domains associated with
proper nouns, gender is retrieved immediately.
This context grows dynamically and is passed from
query to query. Nevertheless, this structure does
not grow indefinitely during the consultation (the
context updating mechanism is presented in §5.2).
When an anaphor is encountered in a query, a
candidate is chosen among the available possible an-
tecedents, and its semantics is inserted in the query&apos;s
semantic representation, which is then passed to the
back end in the normal way. The binding mechanism
is presented in §5.3.
Clearly, much hinges on an effective process to de-
termine appropriate antecedents. In the context of
this application, which strongly emphasizes portabil-
ity and, hence, seeks to avoid incorporating general
world knowledge, this issue is subject to constraints.
</bodyText>
<sectionHeader confidence="0.99374" genericHeader="method">
5 The Context
</sectionHeader>
<subsectionHeader confidence="0.925565">
5.1 Rationale
</subsectionHeader>
<bodyText confidence="0.999941210526316">
In resolving anaphoric reference in NLFEs to
databases, due respect must be given to user require-
ments; it must remain clear at all times which query
has been answered. Findings in Anick et al. (1991)
also apply here. The operation of the front end must
be clear to the user, who must retain the ability to
affect the system&apos;s decisions. As a consequence, we
adopt a protocol whereby (i) the user can always
reject the bindings offered by the system, and (ii)
choice between competing candidates is in the hands
of the user.
This scenario has some consequences. First of
all, our strategy aims not to completely resolve an
anaphoric reference at all costs, but to present the
user with alternatives selected on the basis of reliable
system information. Secondly, to make this process
helpful, in a manageable way, the choice of candi-
dates must be focused, intuitively credible, and of
limited size.
</bodyText>
<subsectionHeader confidence="0.999624">
5.2 Context Structuring
</subsectionHeader>
<bodyText confidence="0.999844722222222">
Helpful selection of candidate antecedents presup-
poses a sensitivity to the structure of the current
discourse. More is needed than a simple collection
of items based on compliance with syntactic con-
straints. The literature offers a collection of ap-
proaches to modelling discourse structure.
Some views concentrate on deriving coherence re-
lations between discourse segments, with the help of
world models (Hobbs, 1979; Reichman, 1984). Work
on Discourse Structure Theory (Grosz, 1977; Grosz
and Sidner, 1986) searches for automatic ways of seg-
menting discourse based on intentions and purposes
embedded in discourse segments.
Most of the results available are not readily adapt-
able to the current type of application. No world
model can be introduced without severe conse-
quences for portability. Segmentation information
is not available and cannot be realised in advance
since consultation is on-line.
The lack of clues regarding how to segment the
dialogue between user and interface, and how to
identify the relationships between such segments re-
stricts the possible solutions. Nonetheless, some
domain information is present in the Data Model
and can be exploited. The segmentation process
deployed here relies on two potential sources for
identifying coherence in relational queries. First of
all, &apos;meaningful&apos; queries are always associated with
a complete access path covering relations and at-
tributes in the database: if we represent the data
model as a graph, a meaningful query will always
cover a connected subgraph. This gives us a mea-
sure of cohesion within a single query.
Building on this, we can develop a notion of dis-
course domain covered by successive queries by com-
paring the access paths involved in them. To use the
graphical analogy as above, a collection of queries
covers a discourse domain if their graphs intersect.
Finally, the degree and area of intersection (con-
sulted attributes) may offer information which can
be used in the identification of focus.
Candidates for anaphoric reference are grouped
in segments, each containing all successive queries
which share part of an access path. The first query
starts the first segment of the context. When a
new query is entered, its covered domain is matched
against that of the segment on top of the context.
If the intersection is not empty, candidates from the
query are added to this segment. In case the in-
tersection is empty, the system identifies a change
of focus on the consultation, and a new segment is
started. In order to allow the user to return to the
previous topic after the change of focus occurred, a
number of segments are held in the context. This
number can vary from application to application,
and the current limit is set to three.
Following Grosz and Sidner (1986), segments oc-
cur in sequence, or are embedded, to allow users
to elaborate on a change of focus before returning
to the previous topic. In case the current segment
intersects with the second most recent one on the
context list (if any), this can be seen as a return
to the previous topic (segments 1 and 3 in Fig 2).
The current segment will continue to grow indepen-
dently, but the candidates in the second most recent
segment will become available for reference.
Within a segment, candidates are grouped by
query number. When a candidate re-occurs, it is
placed on the top of the context list, and its previ-
ous occurrence is deleted, regardless what segment
it belongs to. The antecedent of a resolved anaphor
is also added to the top [Fig. 2]. This strategy al-
</bodyText>
<page confidence="0.996222">
121
</page>
<bodyText confidence="0.9930275">
lows for the representation of a notion of &apos;distance&apos;
between candidate antecedents and anaphor.
</bodyText>
<subsectionHeader confidence="0.98774">
5.3 The Binding Mechanism
</subsectionHeader>
<bodyText confidence="0.9999273">
When an anaphoric expression is encountered, all
candidates in the current segment with appropriate
syntactic characteristics are selected and placed in
the foci list (Sidner, 1983). This list is presented to
the user, who must select a candidate or reject all
options (in case there is more than one) [Fig. 3].
Once a candidate is selected, its semantic repre-
sentation is spliced into the First Order Logic rep-
resentation of the current query, and the normal
querying process is resumed.
</bodyText>
<equation confidence="0.813832111111111">
5.4 Examples
Example 1: Context updating mechanism [Fig. 2]
query: who is edna&apos;s boss?
db answer: [malcolm]
query: who supplies shoes?
db answer: [peter&amp;CO]
query: what is sylvia&apos;s salary?
db answer: [2500]
query: who is her boss?
</equation>
<bodyText confidence="0.7549565">
** USER: Please choose one substitute for
the pronoun &apos;her&apos;:
</bodyText>
<equation confidence="0.826004">
1 - sylvia
2 - none above number: I
db answer: [edna]
</equation>
<bodyText confidence="0.6206996">
query: what is kate&apos;s address?
db answer: [spring aye]
query: what is her account?
** USER: Please choose one substitute for
the pronoun &apos;her&apos;:
</bodyText>
<equation confidence="0.802608666666667">
1 - kate
2 - none above number: 1
db answer: [678.654]
</equation>
<bodyText confidence="0.999348666666667">
Candidates are grouped by query number and seg-
ment number. In the fourth query above, only sylvia
is presented as a substitute for the anaphor her, since
this is the only entry with appropriate syntactic fea-
tures in the current segment (segment 3 - Fig. 2).
In case the user rejects it, edna (second most recent
segment) will be presented as a second option. Sim-
ilarly, in the last query, only kate is presented as an
initial choice (current segment).
</bodyText>
<footnote confidence="0.6936244">
Example 2: The binding mechanism [Fig. 3]
query: who is edna&apos;s boss?
db answer: [malcolm]
query: who is sylvia&apos;s boss?
db answer: [edna]
</footnote>
<bodyText confidence="0.785897">
query: who works for her?
** USER: Please choose one substitute for
the pronoun &apos;her&apos;:
</bodyText>
<equation confidence="0.673972">
1 - sylvia
2 - edna
3 - none above number: 2
db answer: [mary, sylvia, ted]
</equation>
<bodyText confidence="0.999935608695652">
The binding mechanism relies solely on informa-
tion provided by the Data Model, since there is no
world model available. The absence of such a knowl-
edge base is justified by the preoccupation with
portability. However, the task of dealing with dis-
course phenomena is made more difficult.
The user is given the burden of establishing pri-
ority when chosing candidates for anaphora. In Ex-
ample 2, for instance, the system has no means of
disambiguating between the two possible candidates
for binding the pronoun ler&apos; (sylvia, edna), since
both have the same properties. Note that humans
would not be able to select one either.
Care must be taken in using information about
candidates to resolve ambiguity (for instance, the
fact that edna is a boss, whereas sylvia is not), since
this could lead into erroneous interpretations. The
person edna can be used in different contexts within
the same dialogue, although it was introduced in the
context via a query where she appears as boss. Imag-
ine that she is a boss in a shop, but also a registered
customer. In such case, references to her name as a
customer would be disregarded.
</bodyText>
<sectionHeader confidence="0.996654" genericHeader="method">
6 Plurals
</sectionHeader>
<bodyText confidence="0.999898">
The importance of a proper context updating mech-
anism is better seen when we focus on the treatment
of plurals. Currently, the system is being extended
to cope with plural nouns and groups, referred to
by pronouns like they, them, their. The incorpora-
tion in the context of these elements appearing in
the query or DB answer is processed as follows:
</bodyText>
<listItem confidence="0.826491444444444">
(a) plural nouns appearing in the query or DB
answer are kept as plural elements, having one entry
in the context;
(b) groups resulting from a DB answer have each
of their elements incorporated in isolation, as a sin-
gular noun, as well as one entry with all elements
combined as a group element;
(c) conjunctions appearing in the query are
treated as in (b).
</listItem>
<bodyText confidence="0.999913444444444">
In the present system, problems mostly concern
the identification of which elements, appearing in
separate queries or in a query/DB answer, should
be gathered together to constitute a group entry.
When a plural anaphor is encountered, the context
is searched. In case there are no plural/group candi-
dates available, or the user rejects them all, elements
in the current discourse segment will be gathered to-
gether and presented to the user as a group.
</bodyText>
<page confidence="0.990622">
122
</page>
<table confidence="0.89506205">
Context Stack Domain Context Stack Domain
4.6 kate
4.6 kate
4.6 account
- _
4.6 kate = customer 4.6 account customer
4.5 address 4.5 address
4.5 spring ave 4.5 spring ave
3.4 sylvia 3.4 sylvia
3.4 boss 3.4 boss
3.4 edna employee 3.4 edna employee
3.3 sylvia _ 3.3 salary
3.3 salary 3.3 2500
3.3 2500
2.2 shoes supplier
2.2 shoes
supplier 2.2 peter&amp;CO
2.2 peter&amp;CO -1&amp;quot;
1.1 edia - _
1.1 iwisg - _ _ employee
</table>
<figure confidence="0.9487295">
1.1 malcolm
(a)
</figure>
<figureCaption confidence="0.731662">
Figure 2: Context Behaviour
</figureCaption>
<figure confidence="0.9939806875">
Foci List
2 sylvia
2 edna
(a)
(b)
Context
3 edna
3 mary
3 sylvia
3 ted
1 malcolm
(b)
Context
2 sylvia
2 edna
1 malcolm
</figure>
<figureCaption confidence="0.99901">
Figure 3: Context - Foci List
</figureCaption>
<page confidence="0.997777">
123
</page>
<sectionHeader confidence="0.998913" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.99998972">
We presented here a module for anaphora resolution
in a highly portable NLFE - SQUIRREL, which al-
lows for continuous consultations whilst maintaining
the system&apos;s portability.
A mechanism to deal with possible alternative suc-
cessful DB answers has also been added. Such fea-
tures did not constitute a problem for the original
system, since no information was passed forward.
With the incorporation of answers into the context,
it became necessary to allow users to choose among
the multiple possibilities presented by the system,
assuring that a unique answer is selected.
We treat some simple cases of there (although it
is not an anaphor, but a deictic adverb), due to the
high rate of usage of such pointing back device in
dialogues. In the domain covered by this implemen-
tation, its use allows reference to addresses and lo-
cations like department and floor.
We maintain that portability is an important
property, as NLFEs to databases only make sense
in a commercial context. We have demonstrated
that it is possible to include reliable, user-oriented
features of discourse phenomena in the coverage of
modular NLFEs without recourse to world models,
safeguarding portability.
</bodyText>
<sectionHeader confidence="0.998419" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999073602564103">
Anick, Peter G.; Brennan, Jeffrey D.; Flynn, Rex A.;
Hanssen, David R.; Alvey, Bryan; and Robbins,
Jeffrey M. (1990). &amp;quot;A Direct Manipulation Inter-
face for Boolean Information Retrieval via Natural
Language Query.&amp;quot; In 13th International Confer-
ence on Research and Development in Information
Retrieval (ACM-SIGIR), 135-150. Brussels.
Ballard, Bruce W.; Lusth, John C.; and Tinkham,
Nancy L. (1984). &amp;quot;LDC-1: A Transportable,
Knowledge-Based Natural Language Processor for
Office Environments.&amp;quot; In ACM Transactions on
Office Information Systems 2(1), 1-25.
Barros, Flavia A., and DeRoeck, Anne (1993).
&amp;quot;Portable Natural Language Front Ends - A Re-
view&amp;quot;. Research Report CSM-194. Dept. of Com-
puter Science. University of Essex, U.K.
Bates, Madeleine; Moser, M.G.; and Stallar, David
(1986). &amp;quot;The IRUS Transportable Natural Lan-
guage Database Interface.&amp;quot; In Expert Database
Systems, edited by Larry Kerschberg, 617-630.
The Benjamin/Cummings Pub. Co. Inc.
DeRoeck, Anne; Fox, Chris; Lowden, Barry!;
Turner, Ray; and Walls, Bryan (1991). &amp;quot;A Nat-
ural Language System Based on Formal Seman-
tics.&amp;quot; Proceedings of the International Conference
on Current Issues in Computational Linguistics,
221-234. Penang, Malaysia.
Grosz, Barbara J. (1977). &amp;quot;The Representation and
Use of Focus in a System for Understanding Di-
alogs.&amp;quot; In Readings in Natural Language Process-
ing, edited by Barbara J. Grosz, Karen S. Jones,
and Bonny L. Webber (1986), 353-362. Morgan
Kaufmann Pub. Inc.
Grosz, Barbara J., and Sidner, Candace L. (1986).
&amp;quot;Attention, Intention, and the Structure of Dis-
course.&amp;quot; In Computational Linguistics 12(3), 175-
204.
Grosz, Barbara J.; Appelt, Douglas E.; Martin, Paul
A.; and Pereira, Fernando C.N. (1987). &amp;quot;TEAM:
An Experiment in the Design of Transportable
Natural-Language Interfaces.&amp;quot; In Artificial Intel-
ligence 32, 173-243.
Harris, Larry R. (1984). &amp;quot;Experience with INTEL-
LECT: Artificial Intelligence Technology Trans-
fer.&amp;quot; In The Al Magazine 2(2), 43-50.
Hendrix, Gary G.; Sacerdoti, Earl D.; Sagalowicz,
Daniel; and Slocum, Jonathan (1978). &amp;quot;Devel-
oping a Natural Language Interface to Complex
Data.&amp;quot; In ACM Transactions on Database Sys-
tems 3(2), 105-147.
Hobbs, Jerry R. (1979). &amp;quot;Coherence and Corefer-
ence.&amp;quot; In Cognitive Science 3(1), 67-90.
Reichman-Adar, Rachel (1984). &amp;quot;Extended Person-
Machine Interface.&amp;quot; In Artificial Intelligence 22,
157-218.
Sidner, Candace L. (1983). &amp;quot;Focusing in the Com-
prehension of Definite Anaphora.&amp;quot; In Computa-
tional Models of Discourse, edited by M. Brady
and R. Berwick, 267-330. MIT Press.
Craig, James A.; Berenzer, Susan C.; Carney, Homer
C.; and Longyear, Christopher R. (1966). &amp;quot;DEA-
CON: Direct English Access and Control.&amp;quot; In Fall
Joint Conference of AFIPS 29, 365-380. San Fran-
cisco, CA.
Trost, Harald; Buchberger, Ernst; Heinz, Wolf-
gang; Hortnagl, Christian; and Matiasek, Jo-
hannes (1988). &amp;quot;Datenbank-DIALOG: A German
language Interface for Relational database.&amp;quot; In
Applied Artificial Intelligence 1, 181-203. Hemi-
sphere Publishing Corporation.
&apos;Turner Ray (1987). &amp;quot;A Theory of Properties.&amp;quot; In
Journal of Symbolic Logic 52(2), 445-472.
Winograd, Terry (1972). Understanding Natural
Language. Academic Press, New York.
Woods, Willian A. (1973). &amp;quot;Progress in Natural Lan-
guage Understanding: An Application to Lunar
Geology.&amp;quot; In Proceedings of AFIPS National Com-
puter Conference, 441-450.
</reference>
<page confidence="0.998305">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.879373">
<title confidence="0.996134">Resolving Anaphora in a Portable Natural Language Front End to Databases</title>
<author confidence="0.999551">A Barros DeRoeck</author>
<affiliation confidence="0.9999725">Department of Computer Science University of Essex</affiliation>
<address confidence="0.934741">Colchester - C04 3SQ - U.K.</address>
<email confidence="0.983319">[barrf—deroe]Oessex.ac.uk</email>
<abstract confidence="0.99747065">An analysis of the evolution of Natural Language front ends in the last three decades shows that the growth in portability brought, as a side effect, the narrowing of the provided coverage of contextually based linguistic phenomena, such as anaphora and ellipsis. This paper presents the design and state of development of a computational mechanism which provides pronominal Anaphora Resolution within the environment of a highly portable Natural Language front end to databases, SQUIRREL.&apos; Simple cases of Ellipsis are also treated by the proposed model. An Overview of SQUIRREL is presented, by a description of the the results achieved so far. The prototype is implemented in C-Prolog.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter G Anick</author>
<author>Jeffrey D Brennan</author>
<author>Rex A Flynn</author>
<author>David R Hanssen</author>
<author>Bryan Alvey</author>
<author>Jeffrey M Robbins</author>
</authors>
<title>A Direct Manipulation Interface for Boolean Information Retrieval via Natural Language Query.&amp;quot;</title>
<date>1990</date>
<booktitle>In 13th International Conference on Research and Development in Information Retrieval (ACM-SIGIR),</booktitle>
<pages>135--150</pages>
<location>Brussels.</location>
<marker>Anick, Brennan, Flynn, Hanssen, Alvey, Robbins, 1990</marker>
<rawString>Anick, Peter G.; Brennan, Jeffrey D.; Flynn, Rex A.; Hanssen, David R.; Alvey, Bryan; and Robbins, Jeffrey M. (1990). &amp;quot;A Direct Manipulation Interface for Boolean Information Retrieval via Natural Language Query.&amp;quot; In 13th International Conference on Research and Development in Information Retrieval (ACM-SIGIR), 135-150. Brussels.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce W Ballard</author>
<author>John C Lusth</author>
<author>Nancy L Tinkham</author>
</authors>
<title>LDC-1: A Transportable, Knowledge-Based Natural Language Processor for Office Environments.&amp;quot; In</title>
<date>1984</date>
<journal>ACM Transactions on Office Information Systems</journal>
<volume>2</volume>
<issue>1</issue>
<pages>1--25</pages>
<contexts>
<context position="3353" citStr="Ballard et al., 1984" startWordPosition="524" endWordPosition="527">iding for anaphora and simple cases of ellipsis resolution, the Discourse Module yields continuous consultations without the use of world models (to maintain the system&apos;s general portability). 2 Issues in Anaphora Resolution Our primary goal is the achievement of dialogue-like querying by extending SQUIRREL to a system capable of dealing with basic pronominal anaphora and ellipsis. Information about each query is made available to the following queries, such that references to entities already introduced can be resolved. This solution is common practice among NLFEs implementations (eg, LDC-1 (Ballard et al., 1984), Datenbank-DIALOG (Trost et al., 1988)). However, it is subject to limitations. In particular, sequences like the following cannot be handled: Query: who works for which salary in shoes? DB answer: [Malcolm - $5,000.00] Query: who is his boss? because the resulting query Query: who is the boss of [who works for which salary in shoes] ? leads the system into a type error, as a personal pronoun was substituted by a sentence. This was our 119 English Sentence Query Syn/Sem Represent. () Data Mode Extended DRC Represent. -•••411. SQL query TRC •-■111. Represent. Answer Database -4--(Database FOL </context>
</contexts>
<marker>Ballard, Lusth, Tinkham, 1984</marker>
<rawString>Ballard, Bruce W.; Lusth, John C.; and Tinkham, Nancy L. (1984). &amp;quot;LDC-1: A Transportable, Knowledge-Based Natural Language Processor for Office Environments.&amp;quot; In ACM Transactions on Office Information Systems 2(1), 1-25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flavia A Barros</author>
<author>Anne DeRoeck</author>
</authors>
<title>Portable Natural Language Front Ends - A Review&amp;quot;.</title>
<date>1993</date>
<tech>Research Report CSM-194.</tech>
<institution>Dept. of Computer Science. University of Essex, U.K.</institution>
<contexts>
<context position="1889" citStr="Barros and DeRoeck, 1993" startWordPosition="295" endWordPosition="298">y, essential for commercial viability, came at a cost in terms of broader linguistic coverage.&apos; Earlier systems, mostly research motivated, were mainly developed for a single application, using domain-dependent information for treating contextual phenomena (eg, DEACON (Craig et al., 1966), SHRDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)). These systems, however, offer a reduced coverage of discourse phenomena, a central issue when continuity in the database consultation carries some priority. Thus, the ideal NL Front End (NLFE) should carry a broader linguistic coverage, in order to support a user focused query process, combined with a high de</context>
</contexts>
<marker>Barros, DeRoeck, 1993</marker>
<rawString>Barros, Flavia A., and DeRoeck, Anne (1993). &amp;quot;Portable Natural Language Front Ends - A Review&amp;quot;. Research Report CSM-194. Dept. of Computer Science. University of Essex, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Madeleine Bates</author>
<author>M G Moser</author>
<author>David Stallar</author>
</authors>
<title>The IRUS Transportable Natural Language Database Interface.&amp;quot; In Expert Database Systems, edited by Larry Kerschberg, 617-630. The Benjamin/Cummings Pub.</title>
<date>1986</date>
<publisher>Co. Inc.</publisher>
<contexts>
<context position="2149" citStr="Bates et al., 1986" startWordPosition="338" endWordPosition="341">ON (Craig et al., 1966), SHRDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)). These systems, however, offer a reduced coverage of discourse phenomena, a central issue when continuity in the database consultation carries some priority. Thus, the ideal NL Front End (NLFE) should carry a broader linguistic coverage, in order to support a user focused query process, combined with a high degree of portability. In this light, we designed a Discourse Module, which is incorporated into a highly portable NLFE, SQUIRREL (DeRoeck et al., 1991). The system was originally conceived with a single-query based mode of consultation. By providing for anaphor</context>
</contexts>
<marker>Bates, Moser, Stallar, 1986</marker>
<rawString>Bates, Madeleine; Moser, M.G.; and Stallar, David (1986). &amp;quot;The IRUS Transportable Natural Language Database Interface.&amp;quot; In Expert Database Systems, edited by Larry Kerschberg, 617-630. The Benjamin/Cummings Pub. Co. Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne DeRoeck</author>
<author>Chris Fox</author>
<author>Barry Lowden</author>
<author>Ray Turner</author>
<author>Bryan Walls</author>
</authors>
<title>A Natural Language System Based on Formal Semantics.&amp;quot;</title>
<date>1991</date>
<booktitle>Proceedings of the International Conference on Current Issues in Computational Linguistics,</booktitle>
<pages>221--234</pages>
<publisher>Penang,</publisher>
<contexts>
<context position="2639" citStr="DeRoeck et al., 1991" startWordPosition="416" endWordPosition="419">ion of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)). These systems, however, offer a reduced coverage of discourse phenomena, a central issue when continuity in the database consultation carries some priority. Thus, the ideal NL Front End (NLFE) should carry a broader linguistic coverage, in order to support a user focused query process, combined with a high degree of portability. In this light, we designed a Discourse Module, which is incorporated into a highly portable NLFE, SQUIRREL (DeRoeck et al., 1991). The system was originally conceived with a single-query based mode of consultation. By providing for anaphora and simple cases of ellipsis resolution, the Discourse Module yields continuous consultations without the use of world models (to maintain the system&apos;s general portability). 2 Issues in Anaphora Resolution Our primary goal is the achievement of dialogue-like querying by extending SQUIRREL to a system capable of dealing with basic pronominal anaphora and ellipsis. Information about each query is made available to the following queries, such that references to entities already introduc</context>
<context position="4383" citStr="DeRoeck et al., 1991" startWordPosition="687" endWordPosition="690">ted by a sentence. This was our 119 English Sentence Query Syn/Sem Represent. () Data Mode Extended DRC Represent. -•••411. SQL query TRC •-■111. Represent. Answer Database -4--(Database FOL Represent. Context Figure 1: SQUIRREL with Discourse Module. main motivation for keeping information conveyed by the DB answer, so it could be used for future reference. We consider this essential for achieving a dialogue-like mode of consultation. 3 Overview of SQUIRREL The system consists of a portable Natural Language front end prototype for the interrogation of logical and relational database systems (DeRoeck et al., 1991). It is divided into two main sections: the Front End and the Back End [Fig. 1]. The Front End takes the input sentence, producing syntactic and semantic representations, which it maps into First Order Logic. All representations are independent of the domain of application or database model. Syntactic and semantic rules work in tandem. The former are a feature-based CFG, whereas the latter are expressed in Property Theory (Turner, 1987). The lexicon is incomplete, treating unknown words as proper nouns to be fully interpreted when reaching the database. The Back End uses an Extended Data Model</context>
</contexts>
<marker>DeRoeck, Fox, Lowden, Turner, Walls, 1991</marker>
<rawString>DeRoeck, Anne; Fox, Chris; Lowden, Barry!; Turner, Ray; and Walls, Bryan (1991). &amp;quot;A Natural Language System Based on Formal Semantics.&amp;quot; Proceedings of the International Conference on Current Issues in Computational Linguistics, 221-234. Penang, Malaysia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The Representation and Use of Focus in a System for Understanding Dialogs.&amp;quot;</title>
<date>1977</date>
<booktitle>In Readings in Natural Language Processing,</booktitle>
<pages>353--362</pages>
<publisher>Morgan Kaufmann Pub. Inc.</publisher>
<note>edited by</note>
<contexts>
<context position="10225" citStr="Grosz, 1977" startWordPosition="1636" endWordPosition="1637"> a manageable way, the choice of candidates must be focused, intuitively credible, and of limited size. 5.2 Context Structuring Helpful selection of candidate antecedents presupposes a sensitivity to the structure of the current discourse. More is needed than a simple collection of items based on compliance with syntactic constraints. The literature offers a collection of approaches to modelling discourse structure. Some views concentrate on deriving coherence relations between discourse segments, with the help of world models (Hobbs, 1979; Reichman, 1984). Work on Discourse Structure Theory (Grosz, 1977; Grosz and Sidner, 1986) searches for automatic ways of segmenting discourse based on intentions and purposes embedded in discourse segments. Most of the results available are not readily adaptable to the current type of application. No world model can be introduced without severe consequences for portability. Segmentation information is not available and cannot be realised in advance since consultation is on-line. The lack of clues regarding how to segment the dialogue between user and interface, and how to identify the relationships between such segments restricts the possible solutions. No</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>Grosz, Barbara J. (1977). &amp;quot;The Representation and Use of Focus in a System for Understanding Dialogs.&amp;quot; In Readings in Natural Language Processing, edited by Barbara J. Grosz, Karen S. Jones, and Bonny L. Webber (1986), 353-362. Morgan Kaufmann Pub. Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, Intention, and the Structure of Discourse.&amp;quot;</title>
<date>1986</date>
<journal>In Computational Linguistics</journal>
<volume>12</volume>
<issue>3</issue>
<pages>175--204</pages>
<contexts>
<context position="10250" citStr="Grosz and Sidner, 1986" startWordPosition="1638" endWordPosition="1641"> way, the choice of candidates must be focused, intuitively credible, and of limited size. 5.2 Context Structuring Helpful selection of candidate antecedents presupposes a sensitivity to the structure of the current discourse. More is needed than a simple collection of items based on compliance with syntactic constraints. The literature offers a collection of approaches to modelling discourse structure. Some views concentrate on deriving coherence relations between discourse segments, with the help of world models (Hobbs, 1979; Reichman, 1984). Work on Discourse Structure Theory (Grosz, 1977; Grosz and Sidner, 1986) searches for automatic ways of segmenting discourse based on intentions and purposes embedded in discourse segments. Most of the results available are not readily adaptable to the current type of application. No world model can be introduced without severe consequences for portability. Segmentation information is not available and cannot be realised in advance since consultation is on-line. The lack of clues regarding how to segment the dialogue between user and interface, and how to identify the relationships between such segments restricts the possible solutions. Nonetheless, some domain in</context>
<context position="12506" citStr="Grosz and Sidner (1986)" startWordPosition="2010" endWordPosition="2013">he first segment of the context. When a new query is entered, its covered domain is matched against that of the segment on top of the context. If the intersection is not empty, candidates from the query are added to this segment. In case the intersection is empty, the system identifies a change of focus on the consultation, and a new segment is started. In order to allow the user to return to the previous topic after the change of focus occurred, a number of segments are held in the context. This number can vary from application to application, and the current limit is set to three. Following Grosz and Sidner (1986), segments occur in sequence, or are embedded, to allow users to elaborate on a change of focus before returning to the previous topic. In case the current segment intersects with the second most recent one on the context list (if any), this can be seen as a return to the previous topic (segments 1 and 3 in Fig 2). The current segment will continue to grow independently, but the candidates in the second most recent segment will become available for reference. Within a segment, candidates are grouped by query number. When a candidate re-occurs, it is placed on the top of the context list, and i</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, Barbara J., and Sidner, Candace L. (1986). &amp;quot;Attention, Intention, and the Structure of Discourse.&amp;quot; In Computational Linguistics 12(3), 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Douglas E Appelt</author>
<author>Paul A Martin</author>
<author>Fernando C N Pereira</author>
</authors>
<title>TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces.&amp;quot;</title>
<date>1987</date>
<journal>In Artificial Intelligence</journal>
<volume>32</volume>
<pages>173--243</pages>
<contexts>
<context position="2176" citStr="Grosz et al., 1987" startWordPosition="343" endWordPosition="346">RDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)). These systems, however, offer a reduced coverage of discourse phenomena, a central issue when continuity in the database consultation carries some priority. Thus, the ideal NL Front End (NLFE) should carry a broader linguistic coverage, in order to support a user focused query process, combined with a high degree of portability. In this light, we designed a Discourse Module, which is incorporated into a highly portable NLFE, SQUIRREL (DeRoeck et al., 1991). The system was originally conceived with a single-query based mode of consultation. By providing for anaphora and simple cases of ellip</context>
</contexts>
<marker>Grosz, Appelt, Martin, Pereira, 1987</marker>
<rawString>Grosz, Barbara J.; Appelt, Douglas E.; Martin, Paul A.; and Pereira, Fernando C.N. (1987). &amp;quot;TEAM: An Experiment in the Design of Transportable Natural-Language Interfaces.&amp;quot; In Artificial Intelligence 32, 173-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry R Harris</author>
</authors>
<title>Experience with INTELLECT: Artificial Intelligence Technology Transfer.&amp;quot;</title>
<date>1984</date>
<journal>In The Al Magazine</journal>
<volume>2</volume>
<issue>2</issue>
<pages>43--50</pages>
<contexts>
<context position="2122" citStr="Harris, 1984" startWordPosition="335" endWordPosition="336">l phenomena (eg, DEACON (Craig et al., 1966), SHRDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)). These systems, however, offer a reduced coverage of discourse phenomena, a central issue when continuity in the database consultation carries some priority. Thus, the ideal NL Front End (NLFE) should carry a broader linguistic coverage, in order to support a user focused query process, combined with a high degree of portability. In this light, we designed a Discourse Module, which is incorporated into a highly portable NLFE, SQUIRREL (DeRoeck et al., 1991). The system was originally conceived with a single-query based mode of consultatio</context>
</contexts>
<marker>Harris, 1984</marker>
<rawString>Harris, Larry R. (1984). &amp;quot;Experience with INTELLECT: Artificial Intelligence Technology Transfer.&amp;quot; In The Al Magazine 2(2), 43-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary G Hendrix</author>
<author>Earl D Sacerdoti</author>
<author>Daniel Sagalowicz</author>
<author>Jonathan Slocum</author>
</authors>
<title>Developing a Natural Language Interface to Complex Data.&amp;quot; In</title>
<date>1978</date>
<journal>ACM Transactions on Database Systems</journal>
<volume>3</volume>
<issue>2</issue>
<pages>105--147</pages>
<contexts>
<context position="1980" citStr="Hendrix et al., 1978" startWordPosition="310" endWordPosition="313"> Earlier systems, mostly research motivated, were mainly developed for a single application, using domain-dependent information for treating contextual phenomena (eg, DEACON (Craig et al., 1966), SHRDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)). These systems, however, offer a reduced coverage of discourse phenomena, a central issue when continuity in the database consultation carries some priority. Thus, the ideal NL Front End (NLFE) should carry a broader linguistic coverage, in order to support a user focused query process, combined with a high degree of portability. In this light, we designed a Discourse Module, which is incorporated i</context>
</contexts>
<marker>Hendrix, Sacerdoti, Sagalowicz, Slocum, 1978</marker>
<rawString>Hendrix, Gary G.; Sacerdoti, Earl D.; Sagalowicz, Daniel; and Slocum, Jonathan (1978). &amp;quot;Developing a Natural Language Interface to Complex Data.&amp;quot; In ACM Transactions on Database Systems 3(2), 105-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Coherence and Coreference.&amp;quot;</title>
<date>1979</date>
<journal>In Cognitive Science</journal>
<volume>3</volume>
<issue>1</issue>
<pages>67--90</pages>
<contexts>
<context position="10159" citStr="Hobbs, 1979" startWordPosition="1627" endWordPosition="1628">ble system information. Secondly, to make this process helpful, in a manageable way, the choice of candidates must be focused, intuitively credible, and of limited size. 5.2 Context Structuring Helpful selection of candidate antecedents presupposes a sensitivity to the structure of the current discourse. More is needed than a simple collection of items based on compliance with syntactic constraints. The literature offers a collection of approaches to modelling discourse structure. Some views concentrate on deriving coherence relations between discourse segments, with the help of world models (Hobbs, 1979; Reichman, 1984). Work on Discourse Structure Theory (Grosz, 1977; Grosz and Sidner, 1986) searches for automatic ways of segmenting discourse based on intentions and purposes embedded in discourse segments. Most of the results available are not readily adaptable to the current type of application. No world model can be introduced without severe consequences for portability. Segmentation information is not available and cannot be realised in advance since consultation is on-line. The lack of clues regarding how to segment the dialogue between user and interface, and how to identify the relati</context>
</contexts>
<marker>Hobbs, 1979</marker>
<rawString>Hobbs, Jerry R. (1979). &amp;quot;Coherence and Coreference.&amp;quot; In Cognitive Science 3(1), 67-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rachel Reichman-Adar</author>
</authors>
<title>Extended PersonMachine Interface.&amp;quot;</title>
<date>1984</date>
<journal>In Artificial Intelligence</journal>
<volume>22</volume>
<pages>157--218</pages>
<marker>Reichman-Adar, 1984</marker>
<rawString>Reichman-Adar, Rachel (1984). &amp;quot;Extended PersonMachine Interface.&amp;quot; In Artificial Intelligence 22, 157-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Focusing in the Comprehension of Definite Anaphora.&amp;quot;</title>
<date>1983</date>
<booktitle>In Computational Models of Discourse,</booktitle>
<publisher>MIT Press.</publisher>
<note>edited by</note>
<contexts>
<context position="13576" citStr="Sidner, 1983" startWordPosition="2193" endWordPosition="2194">rence. Within a segment, candidates are grouped by query number. When a candidate re-occurs, it is placed on the top of the context list, and its previous occurrence is deleted, regardless what segment it belongs to. The antecedent of a resolved anaphor is also added to the top [Fig. 2]. This strategy al121 lows for the representation of a notion of &apos;distance&apos; between candidate antecedents and anaphor. 5.3 The Binding Mechanism When an anaphoric expression is encountered, all candidates in the current segment with appropriate syntactic characteristics are selected and placed in the foci list (Sidner, 1983). This list is presented to the user, who must select a candidate or reject all options (in case there is more than one) [Fig. 3]. Once a candidate is selected, its semantic representation is spliced into the First Order Logic representation of the current query, and the normal querying process is resumed. 5.4 Examples Example 1: Context updating mechanism [Fig. 2] query: who is edna&apos;s boss? db answer: [malcolm] query: who supplies shoes? db answer: [peter&amp;CO] query: what is sylvia&apos;s salary? db answer: [2500] query: who is her boss? ** USER: Please choose one substitute for the pronoun &apos;her&apos;: </context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Sidner, Candace L. (1983). &amp;quot;Focusing in the Comprehension of Definite Anaphora.&amp;quot; In Computational Models of Discourse, edited by M. Brady and R. Berwick, 267-330. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James A Craig</author>
<author>Susan C Berenzer</author>
<author>Homer C Carney</author>
<author>Christopher R Longyear</author>
</authors>
<title>DEACON: Direct English Access and Control.&amp;quot;</title>
<date>1966</date>
<booktitle>In Fall Joint Conference of AFIPS 29,</booktitle>
<pages>365--380</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="1553" citStr="Craig et al., 1966" startWordPosition="244" endWordPosition="247">Prolog. 1 Introduction The development of Natural Language (NL) systems for data retrieval has been a central issue in NL Processing research for the last three decades, motivated by the aim of helping non-expert database users. When we try to draw a line of evolution of such systems, it can be observed that growth in portability, essential for commercial viability, came at a cost in terms of broader linguistic coverage.&apos; Earlier systems, mostly research motivated, were mainly developed for a single application, using domain-dependent information for treating contextual phenomena (eg, DEACON (Craig et al., 1966), SHRDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TE</context>
</contexts>
<marker>Craig, Berenzer, Carney, Longyear, 1966</marker>
<rawString>Craig, James A.; Berenzer, Susan C.; Carney, Homer C.; and Longyear, Christopher R. (1966). &amp;quot;DEACON: Direct English Access and Control.&amp;quot; In Fall Joint Conference of AFIPS 29, 365-380. San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harald Trost</author>
<author>Ernst Buchberger</author>
<author>Wolfgang Heinz</author>
<author>Christian Hortnagl</author>
<author>Johannes Matiasek</author>
</authors>
<title>Datenbank-DIALOG: A German language Interface for Relational database.&amp;quot;</title>
<date>1988</date>
<journal>In Applied Artificial Intelligence</journal>
<volume>1</volume>
<pages>181--203</pages>
<publisher>Hemisphere Publishing Corporation.</publisher>
<contexts>
<context position="3392" citStr="Trost et al., 1988" startWordPosition="529" endWordPosition="532">lipsis resolution, the Discourse Module yields continuous consultations without the use of world models (to maintain the system&apos;s general portability). 2 Issues in Anaphora Resolution Our primary goal is the achievement of dialogue-like querying by extending SQUIRREL to a system capable of dealing with basic pronominal anaphora and ellipsis. Information about each query is made available to the following queries, such that references to entities already introduced can be resolved. This solution is common practice among NLFEs implementations (eg, LDC-1 (Ballard et al., 1984), Datenbank-DIALOG (Trost et al., 1988)). However, it is subject to limitations. In particular, sequences like the following cannot be handled: Query: who works for which salary in shoes? DB answer: [Malcolm - $5,000.00] Query: who is his boss? because the resulting query Query: who is the boss of [who works for which salary in shoes] ? leads the system into a type error, as a personal pronoun was substituted by a sentence. This was our 119 English Sentence Query Syn/Sem Represent. () Data Mode Extended DRC Represent. -•••411. SQL query TRC •-■111. Represent. Answer Database -4--(Database FOL Represent. Context Figure 1: SQUIRREL w</context>
</contexts>
<marker>Trost, Buchberger, Heinz, Hortnagl, Matiasek, 1988</marker>
<rawString>Trost, Harald; Buchberger, Ernst; Heinz, Wolfgang; Hortnagl, Christian; and Matiasek, Johannes (1988). &amp;quot;Datenbank-DIALOG: A German language Interface for Relational database.&amp;quot; In Applied Artificial Intelligence 1, 181-203. Hemisphere Publishing Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>&apos;Turner Ray</author>
</authors>
<title>A Theory of Properties.&amp;quot;</title>
<date>1987</date>
<journal>In Journal of Symbolic Logic</journal>
<volume>52</volume>
<issue>2</issue>
<pages>445--472</pages>
<marker>Ray, 1987</marker>
<rawString>&apos;Turner Ray (1987). &amp;quot;A Theory of Properties.&amp;quot; In Journal of Symbolic Logic 52(2), 445-472.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Winograd</author>
</authors>
<title>Understanding Natural Language.</title>
<date>1972</date>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<contexts>
<context position="1578" citStr="Winograd, 1972" startWordPosition="249" endWordPosition="250">velopment of Natural Language (NL) systems for data retrieval has been a central issue in NL Processing research for the last three decades, motivated by the aim of helping non-expert database users. When we try to draw a line of evolution of such systems, it can be observed that growth in portability, essential for commercial viability, came at a cost in terms of broader linguistic coverage.&apos; Earlier systems, mostly research motivated, were mainly developed for a single application, using domain-dependent information for treating contextual phenomena (eg, DEACON (Craig et al., 1966), SHRDLU (Winograd, 1972), LUNAR (Woods, &apos;The current system forms the base line for a joint SERC/DTI funded collaborative project between the University of Essex and Status IQ Ltd. for constructing an integrated platform for the retrieval of structured and textual data through Natural Language queries. 2See (Barros and DeRoeck, 1993) for a comprehensive review on Portable NL front ends. 1973), LADDER (Hendrix et al., 1978)). In contrast, the subsequent generation of interfaces carried a higher emphasis on portability in their design (eg, INTELLECT (Harris, 1984), IRUS (Bates et al., 1986), TEAM (Grosz et al., 1987)).</context>
</contexts>
<marker>Winograd, 1972</marker>
<rawString>Winograd, Terry (1972). Understanding Natural Language. Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willian A Woods</author>
</authors>
<title>Progress in Natural Language Understanding: An Application to Lunar Geology.&amp;quot;</title>
<date>1973</date>
<booktitle>In Proceedings of AFIPS National Computer Conference,</booktitle>
<pages>441--450</pages>
<marker>Woods, 1973</marker>
<rawString>Woods, Willian A. (1973). &amp;quot;Progress in Natural Language Understanding: An Application to Lunar Geology.&amp;quot; In Proceedings of AFIPS National Computer Conference, 441-450.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>