<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.025413">
<title confidence="0.9979865">
GPLSIUA: Combining Temporal Information and Topic Modeling for
Cross-Document Event Ordering
</title>
<author confidence="0.982527">
Borja Navarro-Colorado and Estela Saquete
</author>
<affiliation confidence="0.821312">
Natural Language Processing Group
University of Alicante
Alicante, Spain
</affiliation>
<email confidence="0.996878">
borja@dlsi.ua.es, stela@dlsi.ua.es
</email>
<sectionHeader confidence="0.995588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9973802">
Building unified timelines from a collection of
written news articles requires cross-document
event coreference resolution and temporal re-
lation extraction. In this paper we present an
approach event coreference resolution accord-
ing to: a) similar temporal information, and
b) similar semantic arguments. Temporal in-
formation is detected using an automatic tem-
poral information system (TIPSem), while se-
mantic information is represented by means
of LDA Topic Modeling. The evaluation of
our approach shows that it obtains the highest
Micro-average F-score results in the SemEval-
2015 Task 4: “TimeLine: Cross-Document
Event Ordering” (25.36% for TrackB, 23.15%
for SubtrackB), with an improvement of up to
6% in comparison to the other systems. How-
ever, our experiment also showed some draw-
backs in the Topic Modeling approach that de-
grades performance of the system.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993131">
Since access to knowledge is crucial in any domain,
connecting and time-ordering the information ex-
tracted from different documents is a very important
task. The goal of this paper is therefore to build or-
dered timelines for a set of events related to a tar-
get entity. In doing so, our approach is dealing with
two problems: a) cross-document event coreference
resolution and b) cross-document temporal relation
extraction.
In order to arrange event mentions in a timeline it
is necessary to know which event mentions co-refer
to the same event or fact and occur at the same mo-
ment. Our approach attempts to formalize the idea
that two or more event mentions co-refer if they have
not only temporal compatibility (the events occur at
the same time) but also semantic compatibility (the
event mentions refers to the same facts, location, en-
tities, etc.).
Of a set of event mentions in one or more texts,
our proposal groups together the event mentions that
</bodyText>
<listItem confidence="0.866708333333333">
(i) have the same or a similar temporal reference,
(ii) have the same or a similar event head word, and
(iii) whose main arguments refer to the same or sim-
ilar topics. In order to evaluate the system, we have
participated in the SemEval-2015 Task 4 “TimeLine:
Cross-Document Event Ordering”.
</listItem>
<bodyText confidence="0.9980838">
In the following sections we will present the the-
oretical background to our approach (section 2) and
the main technical aspects (sections 3 and 4). Then
we will present the results obtained (section 5) and
some conclusions.
</bodyText>
<sectionHeader confidence="0.976096" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999583083333333">
Two or more event mentions co-refer when they re-
fer to the same real fact or event. Two events can
denote the same fact whereas the linguistic mentions
have a different syntax structure, different words, or
even a different meaning. Whatever the case may be,
both event mentions must be semantically related.
An event mention is formed of an event head
(usually a verb or a deverbal noun) that is related
to a semantic structure (linguistically represented
as an argument structure with an agent, patient,
theme, instrument, etc., that is, the semantic roles)
in which there are some event participants (entities)
</bodyText>
<page confidence="0.988767">
820
</page>
<bodyText confidence="0.95276816">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 820–824,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
and which is located in place and time (Levin and
Rappaport-Hovav, 2005; Hovav et al., 2010). The
meaning of an event mention is therefore not only
the meaning of the event head, but also the compo-
sitional meaning of all the components and their re-
lations: head, participants, time, place, etc.
In order to detect this semantic relation between
event mentions, previous papers have isolated the
main components of the event structure. For in-
stance, Cybulska and Vossen (2013) apply an event
model based on four components: location, time,
participant and action. Moreover, with regard to
temporal information, only explicit temporal ex-
pressions that appears in the text are considered,
but no temporal information is inferred by navigat-
ing temporal links. Bejan and Harabagiu (2014)
use a rich set of linguistic features to model the
event structure, including lexical features such as
head word and lemmas, class features such as PoS
or event class, semantic features such as WordNet
sense or semantic roles frames, etc. They use an
unsupervised approach based on a non-parametrical
Bayesian model.
</bodyText>
<sectionHeader confidence="0.976417" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.999963625">
In our approach we represent each event mention as
a head word (the event tag in the TimeML (Saur´ı et
al., 2006) annotation scheme) related to a temporal
expression (implicit or explicit), a set of entities (0
or more), and a set of topics that represents what the
event mention is referring to. This paper is focused
on temporal information processing and topic-based
semantic representation.
</bodyText>
<subsectionHeader confidence="0.997055">
3.1 Temporal Information Processing
</subsectionHeader>
<bodyText confidence="0.999946391304348">
The TimeML (Saur´ı et al., 2006) annotation scheme
has now been adopted as a standard by a large num-
ber of researchers in the field of temporal informa-
tion annotation. It represents not only events and
temporal expressions, but also links (Pustejovsky et
al., 2003)
A manual annotation of event mentions and the
DCT of texts have been considered as an input of
the system, and an automatic system has been used
to perform the annotation with temporal expres-
sions and temporal links in order to be able to es-
tablish a complete timeline of the input texts. If
a plain text is considered, systems such TIPSem
(Temporal Information Processing using Semantics)
(Llorens et al., 2013; Llorens et al., 2012)1 are
able to automatically annotate all the temporal ex-
pressions (TIMEX3), events (EVENT) and links be-
tween them.
Once the temporal links have been established, all
the specific temporal information for each event is
inferred by means of temporal links navigation. This
information allows us to determine temporal com-
patibility between all the events considered.
</bodyText>
<subsectionHeader confidence="0.999855">
3.2 Topic-based Semantic Representation
</subsectionHeader>
<bodyText confidence="0.999991266666667">
The meaning of each event structure has been rep-
resented by using Topic Modeling (Blei, 2012) on
a reference corpus. Topic modeling is a family of
algorithms that automatically discover topics from
a collection of documents. More specifically, we
apply the Latent Dirichlet Allocation (LDA) (Blei
et al., 2003), which follows a bottom up approach.
Each word is assigned to a topic according to the
co-ocurrence words in the context (document) and
the topics assigned to this word in other documents.
In formal terms, a topic is a distribution on a fixed
vocabulary.
We have applied the LDA to the WikiNews cor-
pus.2 Each topic in this corpus is represented using
the twenty most prominent words.
</bodyText>
<sectionHeader confidence="0.615554" genericHeader="method">
4 Architecture of the System
</sectionHeader>
<bodyText confidence="0.997387">
Our approach to build timelines from written news
in English implies event coreference resolution by
applying three cluster processes in sequential order:
a temporal cluster, a lemma cluster, and a topic clus-
ter. It combines various resources:
</bodyText>
<listItem confidence="0.998597625">
• Named entity recognition, using OpeNER web
services.3
• TimeML automatic annotation of texts using
TipSEM system (Llorens et al., 2010).
• The NLTK4 verb lemmatizer based on Word-
Net (Fellbaum, 1998).
• The SENNA (Collobert et al., 2011) Semantic
Roles Labeling.
</listItem>
<footnote confidence="0.9995014">
1http://gplsi.dlsi.ua.es/demos/TIMEE/
2https://dumps.wikimedia.org/enwikinews/
3http://www.opener-project.eu/
webservices/
4http://www.nltk.org/
</footnote>
<page confidence="0.988608">
821
</page>
<listItem confidence="0.9866285">
• The LDA Topic Modeling algorithm, using
MALLET (McCallum, 2002).
</listItem>
<subsectionHeader confidence="0.977249">
4.1 Target Entity Filtering
</subsectionHeader>
<bodyText confidence="0.999983785714286">
If the target entity filtering is to be performed then it
is first necessary to resolve the named entity recog-
nition and coreference resolution. This is done by
integrating the external OpeNER web services into
our proposal. More specifically, the components
applied in our proposal are the NER component,5
which identifies the names of people, cities, and mu-
seums, and classifies them in a semantic class (PER-
SON, LOCATION, etc.) and the coreference resolu-
tion component,6 whose objective is to identify all
those words that refers to the same object or entity.
Only those events that are part of sentences con-
taining the target entity or a coreference entity of the
target will be selected for the final timeline.
</bodyText>
<subsectionHeader confidence="0.967009">
4.2 Temporal Clustering Approach
</subsectionHeader>
<bodyText confidence="0.999891736842105">
A plain text was considered and we use the TIPSem
system to automatically annotate all the temporal
expressions (TIMEX3), events (EVENT) and links
between them. The TLINKS annotated in the text
are used in order to extract the time context of
each event and make it possible to infer both time
at which each event occurs and the temporal or-
dering between the events in the text. Moreover,
if we are able to determine the time of the event,
we will be able to determine temporal compatibil-
ity between events, even when they are contained
in different documents, thus signifying that cross-
document event coreference resolution is also possi-
ble.
In this first step, all the events from the differ-
ent documents that occurring on the same date will
therefore be part of the same cluster. The clusters are
positioned in ascending ordered based on the date
assigned.
</bodyText>
<subsectionHeader confidence="0.999188">
4.3 Semantic Clustering Based on Lemmas
</subsectionHeader>
<bodyText confidence="0.9996288">
Once all the events that share temporal information
and the target entity have been grouped together, we
apply a simple clustering based on head word lem-
mas. This lemma-based clustering groups together
all event mentions with the same head word lemma,
</bodyText>
<footnote confidence="0.9996835">
5http://opener.olery.com/ner
6http://opener.olery.com/coreference
</footnote>
<bodyText confidence="0.99994425">
the same temporal information and the same target
entity. We therefore assume that all these event men-
tions corefer to the same event. This is our Run 1 at
the competition.
</bodyText>
<subsectionHeader confidence="0.997235">
4.4 Semantic Clustering Based on Topics
</subsectionHeader>
<bodyText confidence="0.999570428571429">
The problem of the lemma-based cluster is that it
does not take into account the argument structure of
the event. This last clustering therefore attempts to
solve this problem by extracting the semantic roles
from each event and representing their meaning by
using topics on a reference corpus. This approach
has three steps:
</bodyText>
<listItem confidence="0.999122">
1. Using SENNA (Collobert et al., 2011) as Se-
mantic Roles Labeling, we have detected roles
A0 and A1.7 which are related to the event
mention head word. For each role we extract
only the nouns.
2. We have extracted 500 topics from WikiNews
using Topic Modeling with MALLET. All
these topics are used as a knowledge base. We
will use only the most representative words for
each topic (the twenty words with the greatest
weight) and the weights that they have in each
topic.
3. Finally, we have created an event-topic matrix.
</listItem>
<bodyText confidence="0.9803620625">
Each event (raws) is represented by a vector.
The values of the vector are the addition of
weights of each argument noun in each topic
(columns).
For example, if the nouns in arguments A0 and
A1 are “users, problems, phones”, we represent their
meanings according to the topics tn assigned to them
by applying LDA to WikiNews (user = t0, t3, t5,
problems = t0, t2, phones = t5, t6, etc). Then,
the event e of this sentence is represented by a n-
dimensional vector in which n is the amount of
topics (500) and whoses values are the addition of
weight of each noun in each topic Tn.
In order to group together similar event mentions,
we have applied a k-means clustering algorithm to
these event vectors.8 The distance metric used has
</bodyText>
<footnote confidence="0.999386">
7In order to represent Semantic Roles, SENNA uses the tag
set proposed by Proposition Bank Project (http://verbs.
colorado.edu/˜mpalmer/projects/ace.html) A0
and A1 represent the main roles related to each verb.
8Note that it has been applied only to the events previously
clustered following the lema-based approach (Run 1).
</footnote>
<page confidence="0.995723">
822
</page>
<bodyText confidence="0.999720142857143">
been Euclidean Distance. The number of cluster
has been adjusted to two.9 Therefore, each cluster
with the same head word lemma, the same tempo-
ral information and the same target entity is then re-
clustered according to the similarity of the main top-
ics of its arguments. This cluster corresponds to our
Run 2 at the competition.
</bodyText>
<sectionHeader confidence="0.969097" genericHeader="evaluation">
5 Evaluation Results
</sectionHeader>
<bodyText confidence="0.996955571428572">
SemEval-2015 Task 4 consists on building timelines
from written news in English in which a target entity
is involved. The input data provided by the organiz-
ers is therefore a set of documents and a set of target
entities related to those documents. Two different
tracks are proposed in the task, along with their sub-
tracks:
</bodyText>
<listItem confidence="0.996007642857143">
• Track A: This consists of using raw texts as in-
put and obtaining full timelines. Subtrack A
has the same input data, but the output will be
the timeLines of only ordered events (no as-
signment of time anchors).
• Track B: This consists of using texts with man-
ual annotation of events mentions as input data.
Subtrack B has the same input data but the out-
put will be timeLines of only ordered events.
In the Semeval-2015 Task 4 competition we have
participated in Track B and Subtrack B. The results
for the Micro-average F-score measure obtained by
our approach in the competition are shown in Table
1.
</listItem>
<table confidence="0.9997598">
TRACK Corpus1 Corpus2 Corpus3 Total
TrackB-R1 22.35 19.28 33.59 25.36
TrackB-R2 20.47 16.17 29.90 22.66
SubTrackB-R1 18.35 20.48 32.08 23.15
SubTrackB-R2 15.93 14.44 27.48 19.18
</table>
<tableCaption confidence="0.999476">
Table 1: Results for GPLSIUA Approach.
</tableCaption>
<bodyText confidence="0.998152666666667">
Although the Micro-FScore results are not very
high, the results obtained by our approach are the
highest in all of the corpus evaluated by the organiz-
ers. Our approach obtained an improvement of 7%
compared with the other participant in Track B and
a 6.48% in Subtrack B.
</bodyText>
<footnote confidence="0.951179">
9We have used PyCluster tool: https://pypi.
python.org/pypi/Pycluster
</footnote>
<sectionHeader confidence="0.997146" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.966370894736842">
The results show that our approach is suitable for the
task in hand. On the one hand, temporal information
is automatically extracted with a temporal informa-
tion processing system which makes it possible to
infer and determine the time at which each event has
occurred. On the other hand, the semantic similar-
ity based on the verb is sufficient to group together
coreferent events.
The basic method (Run 1), consisting of search-
ing for similar verb lemma, eventually proved to be
the best. We have therefore carried out an in-depth
analysis of the results obtained for Run 2 and have
observed three main drawbacks in the Topic Model-
ing approach:
• The K-means algorithm forces us to fix the
number of clusters beforehand, and this has
been fixed at 2. However, there is often only
one correct cluster. Another approach without
a fixed number of topics will improve the ap-
proach. Bejan and Harabagiu (2014), for ex-
ample, suggest inferring this value from data.
• The representativity of each event mention de-
pends directly on the amount of topics ex-
tracted from the reference corpus. Many top-
ics will produce excessive granularity, and few
topics will be unrepresentative. We have set
the number of topics at 500, but it is necessary
to study whether another amount of topics will
improve the results.
• This approach depends excessively on the rep-
resentativity of the reference corpus. We be-
lieve using larger corpora should improve the
results.
As Future work, we plan to use other similarity
measures and clustering algorithms in an attempt
to solve the problem of previously fixed number of
clusters. We also plan to evaluate using different
Topic Modeling configurations.
</bodyText>
<sectionHeader confidence="0.998264" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9722918">
We would like to thank the anonymous reviewers for their
helpful suggestions and comments. Paper partially supported
by the following projects: ATTOS (TIN2012-38536-C03-03),
LEGOLANG-UAGE (TIN2012-31224), SAM (FP7-611312),
FIRST (FP7-287607) DIIM2.0 (PROMETEOII/2014/001)
</bodyText>
<page confidence="0.998415">
823
</page>
<sectionHeader confidence="0.990208" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999460884615385">
Cosmin Adrian Bejan and Sanda Harabagiu. 2014. Un-
supervised Event Coreference Resolution. Computa-
tional Linguistics, 40(2):311–347.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
David M Blei. 2012. Probabilistic Topic Models. Com-
munications of the ACM, 55(4):77–84.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlenand Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural Language Processing (Almost) from
Scratch. Journal of Machine Learning Research,
pages 41–71.
Agata Cybulska and Piek Vossen. 2013. Semantic rela-
tions between events and their time, locations and par-
ticipants for event coreference resolution. In RANLP.
Christiane Fellbaum. 1998. WordNet: An Electronic
Lexical Database (Language, Speech, and Communi-
cation). MIT Press.
Malka Rappaport Hovav, Edit Doron, and Ivy Sichel.
2010. Lexical Semantics, Syntax, and Event Structure.
Oxford University Press, Oxford.
Beth Levin and Malka Rappaport-Hovav. 2005. Argu-
ment realization. Cambridge University Press, Cam-
bridge.
Hector Llorens, Estela Saquete, and Borja Navarro-
Colorado. 2010. TIPSem (English and Spanish):
Evaluating CRFs and Semantic Roles in TempEval-2.
In Proceedings of the 5th International Workshop on
Semantic Evaluation.
Hector Llorens, Estela Saquete, and Borja Navarro-
Colorado. 2012. Automatic System for Identifying
and Categorizing Temporal Relations in Natural Lan-
guage. International Journal of Intelligent Systems,
27(7):680–703.
Hector Llorens, Estela Saquete, and Borja Navarro-
Colorado. 2013. Applying Semantic Knowledge to
the Automatic Processing of Temporal Expressions
and Events in Natural Language. Information Pro-
cessing &amp; Management, 49(1):179–197.
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
James Pustejovsky, Jos´e M. Casta˜no, Robert Ingria,
Roser Sauri, Robert Gaizauskas, Andrea Setzer, and
Graham Katz. 2003. TimeML: Robust Specification
of Event and Temporal Expressions in Text. In IWCS-
5.
Roser Sauri, Jessica Littman, Robert Knippen, Robert
Gaizauskas, Andrea Setzer, and James Puste-
jovsky, 2006. TimeML Annotation Guidelines 1.2.1
(http://www.timeml.org/).
</reference>
<page confidence="0.998723">
824
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.430875">
<title confidence="0.990156">GPLSIUA: Combining Temporal Information and Topic Modeling Cross-Document Event Ordering</title>
<author confidence="0.952269">Borja Navarro-Colorado</author>
<author confidence="0.952269">Estela</author>
<affiliation confidence="0.972269">Natural Language Processing University of</affiliation>
<address confidence="0.645899">Alicante,</address>
<email confidence="0.964849">borja@dlsi.ua.es,stela@dlsi.ua.es</email>
<abstract confidence="0.978804761904762">Building unified timelines from a collection of written news articles requires cross-document event coreference resolution and temporal relation extraction. In this paper we present an approach event coreference resolution according to: a) similar temporal information, and b) similar semantic arguments. Temporal information is detected using an automatic temporal information system (TIPSem), while semantic information is represented by means of LDA Topic Modeling. The evaluation of our approach shows that it obtains the highest Micro-average F-score results in the SemEval- 2015 Task 4: “TimeLine: Cross-Document Event Ordering” (25.36% for TrackB, 23.15% for SubtrackB), with an improvement of up to 6% in comparison to the other systems. However, our experiment also showed some drawbacks in the Topic Modeling approach that degrades performance of the system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cosmin Adrian Bejan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Unsupervised Event Coreference Resolution.</title>
<date>2014</date>
<journal>Computational Linguistics,</journal>
<volume>40</volume>
<issue>2</issue>
<contexts>
<context position="4202" citStr="Bejan and Harabagiu (2014)" startWordPosition="658" endWordPosition="661">ing of the event head, but also the compositional meaning of all the components and their relations: head, participants, time, place, etc. In order to detect this semantic relation between event mentions, previous papers have isolated the main components of the event structure. For instance, Cybulska and Vossen (2013) apply an event model based on four components: location, time, participant and action. Moreover, with regard to temporal information, only explicit temporal expressions that appears in the text are considered, but no temporal information is inferred by navigating temporal links. Bejan and Harabagiu (2014) use a rich set of linguistic features to model the event structure, including lexical features such as head word and lemmas, class features such as PoS or event class, semantic features such as WordNet sense or semantic roles frames, etc. They use an unsupervised approach based on a non-parametrical Bayesian model. 3 Our Approach In our approach we represent each event mention as a head word (the event tag in the TimeML (Saur´ı et al., 2006) annotation scheme) related to a temporal expression (implicit or explicit), a set of entities (0 or more), and a set of topics that represents what the e</context>
<context position="14395" citStr="Bejan and Harabagiu (2014)" startWordPosition="2333" endWordPosition="2336">her hand, the semantic similarity based on the verb is sufficient to group together coreferent events. The basic method (Run 1), consisting of searching for similar verb lemma, eventually proved to be the best. We have therefore carried out an in-depth analysis of the results obtained for Run 2 and have observed three main drawbacks in the Topic Modeling approach: • The K-means algorithm forces us to fix the number of clusters beforehand, and this has been fixed at 2. However, there is often only one correct cluster. Another approach without a fixed number of topics will improve the approach. Bejan and Harabagiu (2014), for example, suggest inferring this value from data. • The representativity of each event mention depends directly on the amount of topics extracted from the reference corpus. Many topics will produce excessive granularity, and few topics will be unrepresentative. We have set the number of topics at 500, but it is necessary to study whether another amount of topics will improve the results. • This approach depends excessively on the representativity of the reference corpus. We believe using larger corpora should improve the results. As Future work, we plan to use other similarity measures an</context>
</contexts>
<marker>Bejan, Harabagiu, 2014</marker>
<rawString>Cosmin Adrian Bejan and Sanda Harabagiu. 2014. Unsupervised Event Coreference Resolution. Computational Linguistics, 40(2):311–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="6380" citStr="Blei et al., 2003" startWordPosition="1009" endWordPosition="1012">inks between them. Once the temporal links have been established, all the specific temporal information for each event is inferred by means of temporal links navigation. This information allows us to determine temporal compatibility between all the events considered. 3.2 Topic-based Semantic Representation The meaning of each event structure has been represented by using Topic Modeling (Blei, 2012) on a reference corpus. Topic modeling is a family of algorithms that automatically discover topics from a collection of documents. More specifically, we apply the Latent Dirichlet Allocation (LDA) (Blei et al., 2003), which follows a bottom up approach. Each word is assigned to a topic according to the co-ocurrence words in the context (document) and the topics assigned to this word in other documents. In formal terms, a topic is a distribution on a fixed vocabulary. We have applied the LDA to the WikiNews corpus.2 Each topic in this corpus is represented using the twenty most prominent words. 4 Architecture of the System Our approach to build timelines from written news in English implies event coreference resolution by applying three cluster processes in sequential order: a temporal cluster, a lemma clu</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
</authors>
<title>Probabilistic Topic Models.</title>
<date>2012</date>
<journal>Communications of the ACM,</journal>
<volume>55</volume>
<issue>4</issue>
<contexts>
<context position="6163" citStr="Blei, 2012" startWordPosition="978" endWordPosition="979">systems such TIPSem (Temporal Information Processing using Semantics) (Llorens et al., 2013; Llorens et al., 2012)1 are able to automatically annotate all the temporal expressions (TIMEX3), events (EVENT) and links between them. Once the temporal links have been established, all the specific temporal information for each event is inferred by means of temporal links navigation. This information allows us to determine temporal compatibility between all the events considered. 3.2 Topic-based Semantic Representation The meaning of each event structure has been represented by using Topic Modeling (Blei, 2012) on a reference corpus. Topic modeling is a family of algorithms that automatically discover topics from a collection of documents. More specifically, we apply the Latent Dirichlet Allocation (LDA) (Blei et al., 2003), which follows a bottom up approach. Each word is assigned to a topic according to the co-ocurrence words in the context (document) and the topics assigned to this word in other documents. In formal terms, a topic is a distribution on a fixed vocabulary. We have applied the LDA to the WikiNews corpus.2 Each topic in this corpus is represented using the twenty most prominent words</context>
</contexts>
<marker>Blei, 2012</marker>
<rawString>David M Blei. 2012. Probabilistic Topic Models. Communications of the ACM, 55(4):77–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlenand Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural Language Processing (Almost) from Scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>41--71</pages>
<contexts>
<context position="7276" citStr="Collobert et al., 2011" startWordPosition="1157" endWordPosition="1160">he LDA to the WikiNews corpus.2 Each topic in this corpus is represented using the twenty most prominent words. 4 Architecture of the System Our approach to build timelines from written news in English implies event coreference resolution by applying three cluster processes in sequential order: a temporal cluster, a lemma cluster, and a topic cluster. It combines various resources: • Named entity recognition, using OpeNER web services.3 • TimeML automatic annotation of texts using TipSEM system (Llorens et al., 2010). • The NLTK4 verb lemmatizer based on WordNet (Fellbaum, 1998). • The SENNA (Collobert et al., 2011) Semantic Roles Labeling. 1http://gplsi.dlsi.ua.es/demos/TIMEE/ 2https://dumps.wikimedia.org/enwikinews/ 3http://www.opener-project.eu/ webservices/ 4http://www.nltk.org/ 821 • The LDA Topic Modeling algorithm, using MALLET (McCallum, 2002). 4.1 Target Entity Filtering If the target entity filtering is to be performed then it is first necessary to resolve the named entity recognition and coreference resolution. This is done by integrating the external OpeNER web services into our proposal. More specifically, the components applied in our proposal are the NER component,5 which identifies the na</context>
<context position="10091" citStr="Collobert et al., 2011" startWordPosition="1597" endWordPosition="1600">com/ner 6http://opener.olery.com/coreference the same temporal information and the same target entity. We therefore assume that all these event mentions corefer to the same event. This is our Run 1 at the competition. 4.4 Semantic Clustering Based on Topics The problem of the lemma-based cluster is that it does not take into account the argument structure of the event. This last clustering therefore attempts to solve this problem by extracting the semantic roles from each event and representing their meaning by using topics on a reference corpus. This approach has three steps: 1. Using SENNA (Collobert et al., 2011) as Semantic Roles Labeling, we have detected roles A0 and A1.7 which are related to the event mention head word. For each role we extract only the nouns. 2. We have extracted 500 topics from WikiNews using Topic Modeling with MALLET. All these topics are used as a knowledge base. We will use only the most representative words for each topic (the twenty words with the greatest weight) and the weights that they have in each topic. 3. Finally, we have created an event-topic matrix. Each event (raws) is represented by a vector. The values of the vector are the addition of weights of each argument</context>
</contexts>
<marker>Collobert, Weston, Bottou, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlenand Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural Language Processing (Almost) from Scratch. Journal of Machine Learning Research, pages 41–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Agata Cybulska</author>
<author>Piek Vossen</author>
</authors>
<title>Semantic relations between events and their time, locations and participants for event coreference resolution.</title>
<date>2013</date>
<booktitle>In RANLP.</booktitle>
<contexts>
<context position="3895" citStr="Cybulska and Vossen (2013)" startWordPosition="612" endWordPosition="615">onal Workshop on Semantic Evaluation (SemEval 2015), pages 820–824, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics and which is located in place and time (Levin and Rappaport-Hovav, 2005; Hovav et al., 2010). The meaning of an event mention is therefore not only the meaning of the event head, but also the compositional meaning of all the components and their relations: head, participants, time, place, etc. In order to detect this semantic relation between event mentions, previous papers have isolated the main components of the event structure. For instance, Cybulska and Vossen (2013) apply an event model based on four components: location, time, participant and action. Moreover, with regard to temporal information, only explicit temporal expressions that appears in the text are considered, but no temporal information is inferred by navigating temporal links. Bejan and Harabagiu (2014) use a rich set of linguistic features to model the event structure, including lexical features such as head word and lemmas, class features such as PoS or event class, semantic features such as WordNet sense or semantic roles frames, etc. They use an unsupervised approach based on a non-para</context>
</contexts>
<marker>Cybulska, Vossen, 2013</marker>
<rawString>Agata Cybulska and Piek Vossen. 2013. Semantic relations between events and their time, locations and participants for event coreference resolution. In RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7238" citStr="Fellbaum, 1998" startWordPosition="1152" endWordPosition="1153"> vocabulary. We have applied the LDA to the WikiNews corpus.2 Each topic in this corpus is represented using the twenty most prominent words. 4 Architecture of the System Our approach to build timelines from written news in English implies event coreference resolution by applying three cluster processes in sequential order: a temporal cluster, a lemma cluster, and a topic cluster. It combines various resources: • Named entity recognition, using OpeNER web services.3 • TimeML automatic annotation of texts using TipSEM system (Llorens et al., 2010). • The NLTK4 verb lemmatizer based on WordNet (Fellbaum, 1998). • The SENNA (Collobert et al., 2011) Semantic Roles Labeling. 1http://gplsi.dlsi.ua.es/demos/TIMEE/ 2https://dumps.wikimedia.org/enwikinews/ 3http://www.opener-project.eu/ webservices/ 4http://www.nltk.org/ 821 • The LDA Topic Modeling algorithm, using MALLET (McCallum, 2002). 4.1 Target Entity Filtering If the target entity filtering is to be performed then it is first necessary to resolve the named entity recognition and coreference resolution. This is done by integrating the external OpeNER web services into our proposal. More specifically, the components applied in our proposal are the N</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malka Rappaport Hovav</author>
<author>Edit Doron</author>
<author>Ivy Sichel</author>
</authors>
<title>Lexical Semantics, Syntax, and Event Structure.</title>
<date>2010</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="3512" citStr="Hovav et al., 2010" startWordPosition="549" endWordPosition="552">ions must be semantically related. An event mention is formed of an event head (usually a verb or a deverbal noun) that is related to a semantic structure (linguistically represented as an argument structure with an agent, patient, theme, instrument, etc., that is, the semantic roles) in which there are some event participants (entities) 820 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 820–824, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics and which is located in place and time (Levin and Rappaport-Hovav, 2005; Hovav et al., 2010). The meaning of an event mention is therefore not only the meaning of the event head, but also the compositional meaning of all the components and their relations: head, participants, time, place, etc. In order to detect this semantic relation between event mentions, previous papers have isolated the main components of the event structure. For instance, Cybulska and Vossen (2013) apply an event model based on four components: location, time, participant and action. Moreover, with regard to temporal information, only explicit temporal expressions that appears in the text are considered, but no</context>
</contexts>
<marker>Hovav, Doron, Sichel, 2010</marker>
<rawString>Malka Rappaport Hovav, Edit Doron, and Ivy Sichel. 2010. Lexical Semantics, Syntax, and Event Structure. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
<author>Malka Rappaport-Hovav</author>
</authors>
<title>Argument realization.</title>
<date>2005</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="3491" citStr="Levin and Rappaport-Hovav, 2005" startWordPosition="545" endWordPosition="548"> the case may be, both event mentions must be semantically related. An event mention is formed of an event head (usually a verb or a deverbal noun) that is related to a semantic structure (linguistically represented as an argument structure with an agent, patient, theme, instrument, etc., that is, the semantic roles) in which there are some event participants (entities) 820 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 820–824, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics and which is located in place and time (Levin and Rappaport-Hovav, 2005; Hovav et al., 2010). The meaning of an event mention is therefore not only the meaning of the event head, but also the compositional meaning of all the components and their relations: head, participants, time, place, etc. In order to detect this semantic relation between event mentions, previous papers have isolated the main components of the event structure. For instance, Cybulska and Vossen (2013) apply an event model based on four components: location, time, participant and action. Moreover, with regard to temporal information, only explicit temporal expressions that appears in the text a</context>
</contexts>
<marker>Levin, Rappaport-Hovav, 2005</marker>
<rawString>Beth Levin and Malka Rappaport-Hovav. 2005. Argument realization. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Estela Saquete</author>
<author>Borja NavarroColorado</author>
</authors>
<title>TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation.</booktitle>
<contexts>
<context position="7175" citStr="Llorens et al., 2010" startWordPosition="1139" endWordPosition="1142">ther documents. In formal terms, a topic is a distribution on a fixed vocabulary. We have applied the LDA to the WikiNews corpus.2 Each topic in this corpus is represented using the twenty most prominent words. 4 Architecture of the System Our approach to build timelines from written news in English implies event coreference resolution by applying three cluster processes in sequential order: a temporal cluster, a lemma cluster, and a topic cluster. It combines various resources: • Named entity recognition, using OpeNER web services.3 • TimeML automatic annotation of texts using TipSEM system (Llorens et al., 2010). • The NLTK4 verb lemmatizer based on WordNet (Fellbaum, 1998). • The SENNA (Collobert et al., 2011) Semantic Roles Labeling. 1http://gplsi.dlsi.ua.es/demos/TIMEE/ 2https://dumps.wikimedia.org/enwikinews/ 3http://www.opener-project.eu/ webservices/ 4http://www.nltk.org/ 821 • The LDA Topic Modeling algorithm, using MALLET (McCallum, 2002). 4.1 Target Entity Filtering If the target entity filtering is to be performed then it is first necessary to resolve the named entity recognition and coreference resolution. This is done by integrating the external OpeNER web services into our proposal. More</context>
</contexts>
<marker>Llorens, Saquete, NavarroColorado, 2010</marker>
<rawString>Hector Llorens, Estela Saquete, and Borja NavarroColorado. 2010. TIPSem (English and Spanish): Evaluating CRFs and Semantic Roles in TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Estela Saquete</author>
<author>Borja NavarroColorado</author>
</authors>
<title>Automatic System for Identifying and Categorizing Temporal Relations in Natural Language.</title>
<date>2012</date>
<journal>International Journal of Intelligent Systems,</journal>
<volume>27</volume>
<issue>7</issue>
<contexts>
<context position="5666" citStr="Llorens et al., 2012" startWordPosition="901" endWordPosition="904">andard by a large number of researchers in the field of temporal information annotation. It represents not only events and temporal expressions, but also links (Pustejovsky et al., 2003) A manual annotation of event mentions and the DCT of texts have been considered as an input of the system, and an automatic system has been used to perform the annotation with temporal expressions and temporal links in order to be able to establish a complete timeline of the input texts. If a plain text is considered, systems such TIPSem (Temporal Information Processing using Semantics) (Llorens et al., 2013; Llorens et al., 2012)1 are able to automatically annotate all the temporal expressions (TIMEX3), events (EVENT) and links between them. Once the temporal links have been established, all the specific temporal information for each event is inferred by means of temporal links navigation. This information allows us to determine temporal compatibility between all the events considered. 3.2 Topic-based Semantic Representation The meaning of each event structure has been represented by using Topic Modeling (Blei, 2012) on a reference corpus. Topic modeling is a family of algorithms that automatically discover topics fro</context>
</contexts>
<marker>Llorens, Saquete, NavarroColorado, 2012</marker>
<rawString>Hector Llorens, Estela Saquete, and Borja NavarroColorado. 2012. Automatic System for Identifying and Categorizing Temporal Relations in Natural Language. International Journal of Intelligent Systems, 27(7):680–703.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Estela Saquete</author>
<author>Borja NavarroColorado</author>
</authors>
<date>2013</date>
<booktitle>Applying Semantic Knowledge to the Automatic Processing of Temporal Expressions and Events in Natural Language. Information Processing &amp; Management,</booktitle>
<volume>49</volume>
<issue>1</issue>
<contexts>
<context position="5643" citStr="Llorens et al., 2013" startWordPosition="897" endWordPosition="900">w been adopted as a standard by a large number of researchers in the field of temporal information annotation. It represents not only events and temporal expressions, but also links (Pustejovsky et al., 2003) A manual annotation of event mentions and the DCT of texts have been considered as an input of the system, and an automatic system has been used to perform the annotation with temporal expressions and temporal links in order to be able to establish a complete timeline of the input texts. If a plain text is considered, systems such TIPSem (Temporal Information Processing using Semantics) (Llorens et al., 2013; Llorens et al., 2012)1 are able to automatically annotate all the temporal expressions (TIMEX3), events (EVENT) and links between them. Once the temporal links have been established, all the specific temporal information for each event is inferred by means of temporal links navigation. This information allows us to determine temporal compatibility between all the events considered. 3.2 Topic-based Semantic Representation The meaning of each event structure has been represented by using Topic Modeling (Blei, 2012) on a reference corpus. Topic modeling is a family of algorithms that automatica</context>
</contexts>
<marker>Llorens, Saquete, NavarroColorado, 2013</marker>
<rawString>Hector Llorens, Estela Saquete, and Borja NavarroColorado. 2013. Applying Semantic Knowledge to the Automatic Processing of Temporal Expressions and Events in Natural Language. Information Processing &amp; Management, 49(1):179–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="7516" citStr="McCallum, 2002" startWordPosition="1178" endWordPosition="1179">ng three cluster processes in sequential order: a temporal cluster, a lemma cluster, and a topic cluster. It combines various resources: • Named entity recognition, using OpeNER web services.3 • TimeML automatic annotation of texts using TipSEM system (Llorens et al., 2010). • The NLTK4 verb lemmatizer based on WordNet (Fellbaum, 1998). • The SENNA (Collobert et al., 2011) Semantic Roles Labeling. 1http://gplsi.dlsi.ua.es/demos/TIMEE/ 2https://dumps.wikimedia.org/enwikinews/ 3http://www.opener-project.eu/ webservices/ 4http://www.nltk.org/ 821 • The LDA Topic Modeling algorithm, using MALLET (McCallum, 2002). 4.1 Target Entity Filtering If the target entity filtering is to be performed then it is first necessary to resolve the named entity recognition and coreference resolution. This is done by integrating the external OpeNER web services into our proposal. More specifically, the components applied in our proposal are the NER component,5 which identifies the names of people, cities, and museums, and classifies them in a semantic class (PERSON, LOCATION, etc.) and the coreference resolution component,6 whose objective is to identify all those words that refers to the same object or entity. Only th</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e M Casta˜no</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>TimeML: Robust Specification of Event and Temporal Expressions in Text.</title>
<date>2003</date>
<booktitle>In IWCS5.</booktitle>
<marker>Pustejovsky, Casta˜no, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jos´e M. Casta˜no, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003. TimeML: Robust Specification of Event and Temporal Expressions in Text. In IWCS5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Sauri</author>
<author>Jessica Littman</author>
<author>Robert Knippen</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>James Pustejovsky</author>
</authors>
<date>2006</date>
<journal>TimeML Annotation Guidelines</journal>
<volume>1</volume>
<pages>(http://www.timeml.org/).</pages>
<marker>Sauri, Littman, Knippen, Gaizauskas, Setzer, Pustejovsky, 2006</marker>
<rawString>Roser Sauri, Jessica Littman, Robert Knippen, Robert Gaizauskas, Andrea Setzer, and James Pustejovsky, 2006. TimeML Annotation Guidelines 1.2.1 (http://www.timeml.org/).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>