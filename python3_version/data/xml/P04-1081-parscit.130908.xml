<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000027">
<title confidence="0.991022">
A Kernel PCA Method for Superior Word Sense Disambiguation
</title>
<author confidence="0.7325">
Dekai WU&apos; Weifeng SU Marine CARPUAT
</author>
<email confidence="0.715848">
dekai@cs.ust.hk weifeng@cs.ust.hk marine@cs.ust.hk
</email>
<note confidence="0.336938">
Human Language Technology Center
HKUST
</note>
<affiliation confidence="0.922478666666667">
Department of Computer Science
University of Science and Technology
Clear Water Bay, Hong Kong
</affiliation>
<sectionHeader confidence="0.985677" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999971933333333">
We introduce a new method for disambiguating
word senses that exploits a nonlinear Kernel Prin-
cipal Component Analysis (KPCA) technique to
achieve accuracy superior to the best published indi-
vidual models. We present empirical results demon-
strating significantly better accuracy compared to
the state-of-the-art achieved by either naive Bayes
or maximum entropy models, on Senseval-2 data.
We also contrast against another type of kernel
method, the support vector machine (SVM) model,
and show that our KPCA-based model outperforms
the SVM-based model. It is hoped that these highly
encouraging first results on KPCA for natural lan-
guage processing tasks will inspire further develop-
ment of these directions.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.965283139534884">
Achieving higher precision in supervised word
sense disambiguation (WSD) tasks without resort-
ing to ad hoc voting or similar ensemble techniques
has become somewhat daunting in recent years,
given the challenging benchmarks set by naive
Bayes models (e.g., Mooney (1996), Chodorow et
al. (1999), Pedersen (2001), Yarowsky and Flo-
rian (2002)) as well as maximum entropy models
(e.g., Dang and Palmer (2002), Klein and Man-
ning (2002)). A good foundation for comparative
studies has been established by the Senseval data
and evaluations; of particular relevance here are
the lexical sample tasks from Senseval-1 (Kilgarriff
and Rosenzweig, 1999) and Senseval-2 (Kilgarriff,
2001).
We therefore chose this problem to introduce
an efficient and accurate new word sense disam-
biguation approach that exploits a nonlinear Kernel
PCA technique to make predictions implicitly based
on generalizations over feature combinations. The
&apos;The author would like to thank the Hong Kong Re-
search Grants Council (RGC) for supporting this research
in part through grants RGC6083/99E, RGC6256/00E, and
DAG03/04.EG09.
technique is applicable whenever vector represen-
tations of a disambiguation task can be generated;
thus many properties of our technique can be ex-
pected to be highly attractive from the standpoint of
natural language processing in general.
In the following sections, we first analyze the po-
tential of nonlinear principal components with re-
spect to the task of disambiguating word senses.
Based on this, we describe a full model for WSD
built on KPCA. We then discuss experimental re-
sults confirming that this model outperforms state-
of-the-art published models for Senseval-related
lexical sample tasks as represented by (1) naive
Bayes models, as well as (2) maximum entropy
models. We then consider whether other kernel
methods—in particular, the popular SVM model—
are equally competitive, and discover experimen-
tally that KPCA achieves higher accuracy than the
SVM model.
</bodyText>
<sectionHeader confidence="0.998269" genericHeader="method">
2 Nonlinear principal components and
WSD
</sectionHeader>
<bodyText confidence="0.999753428571429">
The Kernel Principal Component Analysis tech-
nique, or KPCA, is a nonlinear kernel method
for extraction of nonlinear principal components
from vector sets in which, conceptually, the n-
dimensional input vectors are nonlinearly mapped
from their original space Rn to a high-dimensional
feature space F where linear PCA is performed,
yielding a transform by which the input vectors
can be mapped nonlinearly to a new set of vectors
(Sch¨olkopf et al., 1998).
A major advantage of KPCA is that, unlike other
common analysis techniques, as with other kernel
methods it inherently takes combinations of pre-
dictive features into account when optimizing di-
mensionality reduction. For natural language prob-
lems in general, of course, it is widely recognized
that significant accuracy gains can often be achieved
by generalizing over relevant feature combinations
(e.g., Kudo and Matsumoto (2003)). Another ad-
vantage of KPCA for the WSD task is that the
dimensionality of the input data is generally very
</bodyText>
<tableCaption confidence="0.997956">
Table 1: Two of the Senseval-2 sense classes for the target word “art”, from WordNet 1.7 (Fellbaum 1998).
</tableCaption>
<table confidence="0.856694666666667">
Class Sense
1 the creation of beautiful or significant things
2 a superior skill
</table>
<bodyText confidence="0.9633310625">
large, a condition where kernel methods excel.
Nonlinear principal components (Diamantaras
and Kung, 1996) may be defined as follows. Sup-
pose we are given a training set of M pairs (xt, ct)
where the observed vectors xt E Rn in an n-
dimensional input space X represent the context of
the target word being disambiguated, and the cor-
rect class ct represents the sense of the word, for
t = 1,.., M. Suppose  is a nonlinear mapping
from the input space Rn to the feature space F.
Without loss of generality we assume the M vec-
tors are centered vectors in the feature space, i.e.,
Mt=1  (xt) = 0; uncentered vectors can easily
be converted to centered vectors (Sch¨olkopf et al.,
1998). We wish to diagonalize the covariance ma-
trix in F:
</bodyText>
<equation confidence="0.989269">
 (xj) T (xj) (1)
</equation>
<bodyText confidence="0.982138333333333">
To do this requires solving the equation v = Cv
for eigenvalues  &gt; 0 and eigenvectors v E F. Be-
cause
</bodyText>
<equation confidence="0.996095692307692">
((xj) - v) (xj) (2)
we can derive the following two useful results. First,
 ((xt) - v) =  (xt) - Cv (3)
for t = 1, .., M. Second, there exist i for i =
1, ..., M such that
v = M i (xi) (4)
i=1
Combining (1), (3), and (4), we obtain
i ((xt) - (xi ))
 (xj)) ((xj) - (xi ))
for t = 1,.., M. Let Kˆ be the M x M matrix such
that
ˆKij =  (xi) -  (xj) (5)
</equation>
<bodyText confidence="0.999435833333333">
and let ˆ1 &gt; ˆ2 &gt; ... &gt; ˆM denote the eigenval-
ues of Kˆ and ˆ1 ,..., ˆM denote the corresponding
complete set of normalized eigenvectors, such that
ˆt(ˆt - ˆt) = 1 when ˆt &gt; 0. Then the lth nonlinear
principal component of any test vector xt is defined
as
</bodyText>
<equation confidence="0.9995345">
ylt = M ˆli ((xi) - (xt )) (6)
i=1
</equation>
<bodyText confidence="0.999035777777778">
where ˆli is the lth element of ˆl .
To illustrate the potential of nonlinear principal
components for WSD, consider a simplified disam-
biguation example for the ambiguous target word
“art”, with the two senses shown in Table 1. Assume
a training corpus of the eight sentences as shown
in Table 2, adapted from Senseval-2 English lexical
sample corpus. For each sentence, we show the fea-
ture set associated with that occurrence of “art” and
the correct sense class. These eight occurrences of
“art” can be transformed to a binary vector represen-
tation containing one dimension for each feature, as
shown in Table 3.
Extracting nonlinear principal components for
the vectors in this simple corpus results in nonlinear
generalization, reflecting an implicit consideration
of combinations of features. Table 3 shows the first
three dimensions of the principal component vectors
obtained by transforming each of the eight training
vectors xt into (a) principal component vectors zt
using the linear transform obtained via PCA, and
(b) nonlinear principal component vectors yt using
the nonlinear transform obtained via KPCA as de-
scribed below.
Similarly, for the test vector x9, Table 4 shows the
first three dimensions of the principal component
vectors obtained by transforming it into (a) a princi-
pal component vector z9 using the linear PCA trans-
form obtained from training, and (b) a nonlinear
principal component vector y9 using the nonlinear
KPCA transform obtained obtained from training.
The vector similarities in the KPCA-transformed
space can be quite different from those in the PCA-
transformed space. This causes the KPCA-based
model to be able to make the correct class pre-
diction, whereas the PCA-based model makes the
</bodyText>
<equation confidence="0.984200555555556">
1
C = M
M

j=1
1
Cv = M
M

j=1
M
i=1
M
M
i=1
i( (xt) -
M

</equation>
<page confidence="0.746328">
j=1
</page>
<tableCaption confidence="0.807951">
Table 2: A tiny corpus for the target word “art”, adapted from the Senseval-2 English lexical sample corpus
</tableCaption>
<bodyText confidence="0.996602442622951">
(Kilgarriff 2001), together with a tiny example set of features. The training and testing examples can be
represented as a set of binary vectors: each row shows the correct class c for an observed vector x of five
dimensions.
TRAINING design/N media/N the/DT entertainment/N world/N Class
x1 He studies art in London. 1
x2 Punch’s weekly guide to 1 1 1 1
the world of the arts,
entertainment, media and
more.
x3 All such studies have in- 1 1 1
fluenced every form of art,
design, and entertainment
in some way.
x4 Among the techni- 1 2
cal arts cultivated in
some continental schools
that began to affect
England soon after the
Norman Conquest were
those of measurement
and calculation.
x5 The Art of Love. 1 2
x6 Indeed, the art of doc- 1 2
toring does contribute to
better health results and
discourages unwarranted
malpractice litigation.
x7 Countless books and 1 2
classes teach the art of
asserting oneself.
x8 Pop art is an example. 1
TESTING
x9 In the world of de- 1 1 1 1
sign arts particularly, this
led to appointments made
for political rather than
academic reasons.
wrong class prediction.
What permits KPCA to apply stronger general-
ization biases is its implicit consideration of com-
binations of feature information in the data dis-
tribution from the high-dimensional training vec-
tors. In this simplified illustrative example, there
are just five input dimensions; the effect is stronger
in more realistic high dimensional vector spaces.
Since the KPCA transform is computed from unsu-
pervised training vector data, and extracts general-
izations that are subsequently utilized during super-
vised classification, it is quite possible to combine
large amounts of unsupervised data with reasonable
smaller amounts of supervised data.
It can be instructive to attempt to interpret this
example graphically, as follows, even though the
interpretation in three dimensions is severely limit-
ing. Figure 1(a) depicts the eight original observed
training vectors xt in the first three of the five di-
mensions; note that among these eight vectors, there
happen to be only four unique points when restrict-
ing our view to these three dimensions. Ordinary
linear PCA can be straightforwardly seen as pro-
jecting the original points onto the principal axis,
</bodyText>
<tableCaption confidence="0.9898205">
Table 3: The original observed training vectors (showing only the first three dimensions) and their first three
principal components as transformed via PCA and KPCA.
</tableCaption>
<table confidence="0.999513727272727">
Observed vectors PCA-transformed vectors KPCA-transformed vectors Class
t 1 2 3 1 2 3 1 2 3 ct
(xt,xt,xt) (zt ,zt ,zt ) (yt ,yt ,yt )
1 (0, 0, 0) (-1.961, 0.2829, 0.2014) (0.2801, -1.005, -0.06861) 1
2 (0, 1, 1) (1.675, -1.132, 0.1049) (1.149, 0.02934, 0.322) 1
3 (1, 0, 0) (-0.367, 1.697, -0.2391) (0.8209, 0.7722, -0.2015) 1
4 (0, 0, 1) (-1.675, -1.132, -0.1049) (-1.774, -0.1216, 0.03258) 2
5 (0, 0, 1) (-1.675, -1.132, -0.1049) (-1.774, -0.1216, 0.03258) 2
6 (0, 0, 1) (-1.675, -1.132, -0.1049) (-1.774, -0.1216, 0.03258) 2
7 (0, 0, 1) (-1.675, -1.132, -0.1049) (-1.774, -0.1216, 0.03258) 2
8 (0, 0, 0) (-1.961, 0.2829, 0.2014) (0.2801, -1.005, -0.06861) 1
</table>
<tableCaption confidence="0.950946666666667">
Table 4: Testing vector (showing only the first three dimensions) and its first three principal components
as transformed via the trained PCA and KPCA parameters. The PCA-based and KPCA-based sense class
predictions disagree.
</tableCaption>
<table confidence="0.990888333333333">
Observed PCA-transformed vectors KPCA-transformed vec- Predicted Correct
vectors tors Class Class
t 1 2 3 1 2 3 1 2 3 ˆct ct
(xt,xt,xt) (zt ,zt ,zt ) (yt ,yt ,yt )
9 (1, 0, 1) (-0.3671, -0.5658, -0.2392) 2 1
9 (1, 0, 1) (4e-06, 8e-07, 1.111e-18) 1 1
</table>
<bodyText confidence="0.992744428571429">
as can be seen for the case of the first principal axis
in Figure 1(b). Note that in this space, the sense 2
instances are surrounded by sense 1 instances. We
can traverse each of the projections onto the prin-
cipal axis in linear order, simply by visiting each of
the first principal components z1t along the principle
axis in order of their values, i.e., such that
</bodyText>
<equation confidence="0.909711">
z11  z18  z14  z15  z16  z17  z12  z13  z19
</equation>
<bodyText confidence="0.999962666666667">
It is significantly more difficult to visualize
the nonlinear principal components case, however.
Note that in general, there may not exist any prin-
cipal axis in X, since an inverse mapping from F
may not exist. If we attempt to follow the same pro-
cedure to traverse each of the projections onto the
first principal axis as in the case of linear PCA, by
considering each of the first principal components
y1t in order of their value, i.e., such that
</bodyText>
<equation confidence="0.755024">
y14  y15  y16  y17  y19  y11  y18  y13  y12
</equation>
<bodyText confidence="0.99993275">
then we must arbitrarily select a “quasi-projection”
direction for each y1t since there is no actual prin-
cipal axis toward which to project. This results in a
“quasi-axis” roughly as shown in Figure 1(c) which,
though not precisely accurate, provides some idea
as to how the nonlinear generalization capability al-
lows the data points to be grouped by principal com-
ponents reflecting nonlinear patterns in the data dis-
tribution, in ways that linear PCA cannot do. Note
that in this space, the sense 1 instances are already
better separated from sense 2 data points. More-
over, unlike linear PCA, there may be up to M of
the “quasi-axes”, which may number far more than
five. Such effects can become pronounced in the
high dimensional spaces are actually used for real
word sense disambiguation tasks.
</bodyText>
<sectionHeader confidence="0.993873" genericHeader="method">
3 A KPCA-based WSD model
</sectionHeader>
<bodyText confidence="0.999786846153846">
To extract nonlinear principal components effi-
ciently, note that in both Equations (5) and (6) the
explicit form of 4b (xi) is required only in the form
of (4b (xi)·4b (xj)), i.e., the dot product of vectors in
F. This means that we can calculate the nonlinear
principal components by substituting a kernel func-
tion k(xi, xj) for (4b( xi) · 4b(xj )) in Equations (5)
and (6) without knowing the mapping 4b explicitly;
instead, the mapping 4b is implicitly defined by the
kernel function. It is always possible to construct
a mapping into a space where k acts as a dot prod-
uct so long as k is a continuous kernel of a positive
integral operator (Sch¨olkopf et al., 1998).
</bodyText>
<figure confidence="0.93475">
(a)❑
</figure>
<figureCaption confidence="0.9709788">
class 2 (correct sense class=1)❑
: test example with predicted sense❑
class 1 (correct sense class=1)❑
Figure 1: Original vectors, PCA projections, and
KPCA “quasi-projections” (see text).
</figureCaption>
<bodyText confidence="0.534161">
Table 5: Experimental results showing that the
KPCA-based model performs significantly better
than naive Bayes and maximum entropy models.
Significance intervals are computed via bootstrap
resampling.
</bodyText>
<table confidence="0.9912725">
WSD Model Accuracy Sig. Int.
naive Bayes 63.3% +/-0.91%
maximum entropy 63.8% +/-0.79%
KPCA-based model 65.8% +/-0.79%
</table>
<bodyText confidence="0.935853">
Thus we train the KPCA model using the follow-
ing algorithm:
</bodyText>
<listItem confidence="0.961759">
1. Compute an M x M matrix Kˆ such that
</listItem>
<equation confidence="0.760118">
ˆKij = k(xi, xj) (7)
</equation>
<listItem confidence="0.7877768">
2. Compute the eigenvalues and eigenvectors of
matrix Kˆ and normalize the eigenvectors. Let
ˆ�1 &gt; ˆ�2 &gt; ... &gt; ˆ�M denote the eigenvalues
and ˆ�1,..., ˆ�M denote the corresponding com-
plete set of normalized eigenvectors.
</listItem>
<bodyText confidence="0.998841166666667">
To obtain the sense predictions for test instances,
we need only transform the corresponding vectors
using the trained KPCA model and classify the re-
sultant vectors using nearest neighbors. For a given
test instance vector x, its lth nonlinear principal
component is
</bodyText>
<equation confidence="0.975703">
M
ylt = ˆ�lik(xi, xt) (8)
i=1
</equation>
<bodyText confidence="0.997987555555556">
where ˆ�li is the ith element of ˆ�l.
For our disambiguation experiments we employ a
polynomial kernel function of the form k(xi, xj) =
(xi · xj)d, although other kernel functions such as
gaussians could be used as well. Note that the de-
generate case of d = 1 yields the dot product kernel
k(xi,xj) = (xi·xj) which covers linear PCA as a
special case, which may explain why KPCA always
outperforms PCA.
</bodyText>
<sectionHeader confidence="0.999882" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.6429755">
4.1 KPCA versus naive Bayes and maximum
entropy models
</subsectionHeader>
<bodyText confidence="0.999833">
We established two baseline models to represent
the state-of-the-art for individual WSD models: (1)
naive Bayes, and (2) maximum entropy models.
The naive Bayes model was found to be the most
accurate classifier in a comparative study using a
</bodyText>
<figure confidence="0.917278076923077">
the/DT❑
media/N❑
2❑
4, 5, 6, 7❑
9❑
1, 8❑
3❑
design/N❑
(b)❑
the/DT❑
media/N❑
2❑
first principal❑
axis❑
4, 5, 6, 7❑
9❑
1, 8❑ 3❑
design/N❑
(c)❑ the/DT❑
first principal❑
“�I quasi-axis”®
2❑
4, 5, 6, 7❑
9❑
1, 8❑ 3❑
design/N❑
</figure>
<bodyText confidence="0.998518881355932">
: training example with sense class 1❑
: training example with sense class 2❑
: test example with unknown sense class❑
: test example with predicted sense❑
media/N❑
subset of Senseval-2 English lexical sample data
by Yarowsky and Florian (2002). However, the
maximum entropy (Jaynes, 1978) was found to
yield higher accuracy than naive Bayes in a sub-
sequent comparison by Klein and Manning (2002),
who used a different subset of either Senseval-1 or
Senseval-2 English lexical sample data. To control
for data variation, we built and tuned models of both
kinds. Note that our objective in these experiments
is to understand the performance and characteristics
of KPCA relative to other individual methods. It
is not our objective here to compare against voting
or other ensemble methods which, though known to
be useful in practice (e.g., Yarowsky et al. (2001)),
would not add to our understanding.
To compare as evenly as possible, we em-
ployed features approximating those of the “feature-
enhanced naive Bayes model” of Yarowsky and Flo-
rian (2002), which included position-sensitive, syn-
tactic, and local collocational features. The mod-
els in the comparative study by Klein and Man-
ning (2002) did not include such features, and so,
again for consistency of comparison, we experi-
mentally verified that our maximum entropy model
(a) consistently yielded higher scores than when
the features were not used, and (b) consistently
yielded higher scores than naive Bayes using the
same features, in agreement with Klein and Man-
ning (2002). We also verified the maximum en-
tropy results against several different implementa-
tions, using various smoothing criteria, to ensure
that the comparison was even.
Evaluation was done on the Senseval 2 English
lexical sample task. It includes 73 target words,
among which nouns, adjectives, adverbs and verbs.
For each word, training and test instances tagged
with WordNet senses are provided. There are an av-
erage of 7.8 senses per target word type. On average
109 training instances per target word are available.
Note that we used the set of sense classes from Sen-
seval’s ”fine-grained” rather than ”coarse-grained”
classification task.
The KPCA-based model achieves the highest ac-
curacy, as shown in Table 5, followed by the max-
imum entropy model, with naive Bayes doing the
poorest. Bear in mind that all of these models are
significantly more accurate than any of the other re-
ported models on Senseval. “Accuracy” here refers
to both precision and recall since disambiguation of
all target words in the test set is attempted. Results
are statistically significant at the 0.10 level, using
bootstrap resampling (Efron and Tibshirani, 1993);
moreover, we consistently witnessed the same level
of accuracy gains from the KPCA-based model over
</bodyText>
<tableCaption confidence="0.585547">
Table 6: Experimental results comparing the
KPCA-based model versus the SVM model.
</tableCaption>
<table confidence="0.827273333333333">
WSD Model Accuracy Sig. Int.
SVM-based model 65.2% +/-1.00%
KPCA-based model 65.8% +/-0.79%
</table>
<tableCaption confidence="0.316046">
many variations of the experiments.
</tableCaption>
<subsectionHeader confidence="0.952747">
4.2 KPCA versus SVM models
</subsectionHeader>
<bodyText confidence="0.9998754">
Support vector machines (e.g., Vapnik (1995),
Joachims (1998)) are a different kind of ker-
nel method that, unlike KPCA methods, have al-
ready gained high popularity for NLP applications
(e.g., Takamura and Matsumoto (2001), Isozaki and
Kazawa (2002), Mayfield et al. (2003)) including
the word sense disambiguation task (e.g., Cabezas
et al. (2001)). Given that SVM and KPCA are both
kernel methods, we are frequently asked whether
SVM-based WSD could achieve similar results.
To explore this question, we trained and tuned
an SVM model, providing the same rich set of fea-
tures and also varying the feature representations to
optimize for SVM biases. As shown in Table 6,
the highest-achieving SVM model is also able to
obtain higher accuracies than the naive Bayes and
maximum entropy models. However, in all our ex-
periments the KPCA-based model consistently out-
performs the SVM model (though the margin falls
within the statistical significance interval as com-
puted by bootstrap resampling for this single exper-
iment). The difference in KPCA and SVM perfor-
mance is not surprising given that, aside from the
use of kernels, the two models share little structural
resemblance.
</bodyText>
<subsectionHeader confidence="0.999305">
4.3 Running times
</subsectionHeader>
<bodyText confidence="0.9999178125">
Training and testing times for the various model im-
plementations are given in Table 7, as reported by
the Unix time command. Implementations of all
models are in C++, but the level of optimization is
not controlled. For example, no attempt was made
to reduce the training time for naive Bayes, or to re-
duce the testing time for the KPCA-based model.
Nevertheless, we can note that in the operating
range of the Senseval lexical sample task, the run-
ning times of the KPCA-based model are roughly
within the same order of magnitude as for naive
Bayes or maximum entropy. On the other hand,
training is much faster than the alternative kernel
method based on SVMs. However, the KPCA-
based model’s times could be expected to suffer
in situations where significantly larger amounts of
</bodyText>
<tableCaption confidence="0.999162">
Table 7: Comparison of training and testing times for the different WSD model implementations.
</tableCaption>
<table confidence="0.9452925">
WSD Model Training time [CPU sec] Testing time [CPU sec]
naive Bayes 103.41 16.84
maximum entropy 104.62 59.02
SVM-based model 5024.34 16.21
KPCA-based model 216.50 128.51
training data are available.
</table>
<sectionHeader confidence="0.998265" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999982260869565">
This work represents, to the best of our knowl-
edge, the first application of Kernel PCA to a
true natural language processing task. We have
shown that a KPCA-based model can significantly
outperform state-of-the-art results from both naive
Bayes as well as maximum entropy models, for
supervised word sense disambiguation. The fact
that our KPCA-based model outperforms the SVM-
based model indicates that kernel methods other
than SVMs deserve more attention. Given the theo-
retical advantages of KPCA, it is our hope that this
work will encourage broader recognition, and fur-
ther exploration, of the potential of KPCA modeling
within NLP research.
Given the positive results, we plan next to com-
bine large amounts of unsupervised data with rea-
sonable smaller amounts of supervised data such as
the Senseval lexical sample. Earlier we mentioned
that one of the promising advantages of KPCA is
that it computes the transform purely from unsuper-
vised training vector data. We can thus make use of
the vast amounts of cheap unannotated data to aug-
ment the model presented in this paper.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99974506">
Clara Cabezas, Philip Resnik, and Jessica Stevens.
Supervised sense tagging using support vector
machines. In Proceedings of Senseval-2, Sec-
ond International Workshop on Evaluating Word
Sense Disambiguation Systems, pages 59–62,
Toulouse, France, July 2001. SIGLEX, Associ-
ation for Computational Linguistics.
Martin Chodorow, Claudia Leacock, and George A.
Miller. A topical/local classifier for word sense
identification. Computers and the Humanities,
34(1-2):115–120, 1999. Special issue on SEN-
SEVAL.
Hoa Trang Dang and Martha Palmer. Combining
contextual features for word sense disambigua-
tion. In Proceedings of the SIGLEX/SENSEVAL
Workshop on Word Sense Disambiguation: Re-
cent Successes and Future Directions, pages 88–
94, Philadelphia, July 2002. SIGLEX, Associa-
tion for Computational Linguistics.
Konstantinos I. Diamantaras and Sun Yuan Kung.
Principal Component Neural Networks. Wiley,
New York, 1996.
Bradley Efron and Robert J. Tibshirani. An Intro-
duction to the Bootstrap. Chapman and Hall,
1993.
Hideki Isozaki and Hideto Kazawa. Efficient sup-
port vector classifiers for named entity recogni-
tion. In Proceedings of COLING-2002, pages
390–396, Taipei, 2002.
E.T. Jaynes. Where do we Stand on Maximum En-
tropy? MIT Press, Cambridge MA, 1978.
Thorsten Joachims. Text categorization with sup-
port vector machines: Learning with many rel-
evant features. In Proceedings of ECML-98,
10th European Conference on Machine Learning,
pages 137–142, 1998.
Adam Kilgarriff and Joseph Rosenzweig. Frame-
work and results for English Senseval. Comput-
ers and the Humanities, 34(1):15–48, 1999. Spe-
cial issue on SENSEVAL.
Adam Kilgarriff. English lexical sample task de-
scription. In Proceedings of Senseval-2, Sec-
ond International Workshop on Evaluating Word
Sense Disambiguation Systems, pages 17–20,
Toulouse, France, July 2001. SIGLEX, Associ-
ation for Computational Linguistics.
Dan Klein and Christopher D. Manning. Con-
ditional structure versus conditional estimation
in NLP models. In Proceedings of EMNLP-
2002, Conference on Empirical Methods in Nat-
ural Language Processing, pages 9–16, Philadel-
phia, July 2002. SIGDAT, Association for Com-
putational Linguistics.
Taku Kudo and Yuji Matsumoto. Fast methods
for kernel-based text analysis. In Proceedings of
the 41set Annual Meeting of the Asoociation for
Computational Linguistics, pages 24–31, 2003.
James Mayfield, Paul McNamee, and Christine Pi-
atko. Named entity recognition using hundreds of
thousands of features. In Walter Daelemans and
Miles Osborne, editors, Proceedings of CoNLL-
2003, pages 184–187, Edmonton, Canada, 2003.
Raymond J. Mooney. Comparative experiments on
disambiguating word senses: An illustration of
the role of bias in machine learning. In Proceed-
ings of the Conference on Empirical Methods in
Natural Language Processing, Philadelphia, May
1996. SIGDAT, Association for Computational
Linguistics.
Ted Pedersen. Machine learning with lexical fea-
tures: The Duluth approach to SENSEVAL-2.
In Proceedings of Senseval-2, Second Interna-
tional Workshop on Evaluating Word Sense Dis-
ambiguation Systems, pages 139–142, Toulouse,
France, July 2001. SIGLEX, Association for
Computational Linguistics.
Bernhard Sch¨olkopf, Alexander Smola, and Klaus-
Rober M¨uller. Nonlinear component analysis as a
kernel eigenvalue problem. Neural Computation,
10(5), 1998.
Hiroya Takamura and Yuji Matsumoto. Feature
space restructuring for SVMs with application to
text categorization. In Proceedings of EMNLP-
2001, Conference on Empirical Methods in Nat-
ural Language Processing, pages 51–57, 2001.
Vladimir N. Vapnik. The Nature of Statistical
Learning Theory. Springer-Verlag, New York,
1995.
David Yarowsky and Radu Florian. Evaluat-
ing sense disambiguation across diverse param-
eter spaces. Natural Language Engineering,
8(4):293–310, 2002.
David Yarowsky, Silviu Cucerzan, Radu Florian,
Charles Schafer, and Richard Wicentowski. The
Johns Hopkins SENSEVAL2 system descrip-
tions. In Proceedings of Senseval-2, Sec-
ond International Workshop on Evaluating Word
Sense Disambiguation Systems, pages 163–166,
Toulouse, France, July 2001. SIGLEX, Associa-
tion for Computational Linguistics.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.239718">
<title confidence="0.904156">A Kernel PCA Method for Superior Word Sense Disambiguation dekai@cs.ust.hk weifeng@cs.ust.hk marine@cs.ust.hk</title>
<author confidence="0.437671">Human Language Technology Center</author>
<email confidence="0.532278">HKUST</email>
<affiliation confidence="0.999868">Department of Computer Science University of Science and Technology</affiliation>
<address confidence="0.998094">Clear Water Bay, Hong Kong</address>
<abstract confidence="0.9991255625">We introduce a new method for disambiguating senses that exploits a nonlinear Prin- Component Analysis technique to achieve accuracy superior to the best published individual models. We present empirical results demonstrating significantly better accuracy compared to the state-of-the-art achieved by either naive Bayes or maximum entropy models, on Senseval-2 data. We also contrast against another type of kernel method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Clara Cabezas</author>
<author>Philip Resnik</author>
<author>Jessica Stevens</author>
</authors>
<title>Supervised sense tagging using support vector machines.</title>
<date>2001</date>
<booktitle>In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>59--62</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="19064" citStr="Cabezas et al. (2001)" startWordPosition="3183" endWordPosition="3186">ains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al. (2003)) including the word sense disambiguation task (e.g., Cabezas et al. (2001)). Given that SVM and KPCA are both kernel methods, we are frequently asked whether SVM-based WSD could achieve similar results. To explore this question, we trained and tuned an SVM model, providing the same rich set of features and also varying the feature representations to optimize for SVM biases. As shown in Table 6, the highest-achieving SVM model is also able to obtain higher accuracies than the naive Bayes and maximum entropy models. However, in all our experiments the KPCA-based model consistently outperforms the SVM model (though the margin falls within the statistical significance i</context>
</contexts>
<marker>Cabezas, Resnik, Stevens, 2001</marker>
<rawString>Clara Cabezas, Philip Resnik, and Jessica Stevens. Supervised sense tagging using support vector machines. In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems, pages 59–62, Toulouse, France, July 2001. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
<author>George A Miller</author>
</authors>
<title>A topical/local classifier for word sense identification.</title>
<date>1999</date>
<booktitle>Computers and the Humanities,</booktitle>
<pages>34--1</pages>
<note>Special issue on SENSEVAL.</note>
<contexts>
<context position="1308" citStr="Chodorow et al. (1999)" startWordPosition="186" endWordPosition="189"> contrast against another type of kernel method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions. 1 Introduction Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations ove</context>
</contexts>
<marker>Chodorow, Leacock, Miller, 1999</marker>
<rawString>Martin Chodorow, Claudia Leacock, and George A. Miller. A topical/local classifier for word sense identification. Computers and the Humanities, 34(1-2):115–120, 1999. Special issue on SENSEVAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoa Trang Dang</author>
<author>Martha Palmer</author>
</authors>
<title>Combining contextual features for word sense disambiguation.</title>
<date>2002</date>
<booktitle>In Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions,</booktitle>
<pages>88--94</pages>
<location>Philadelphia,</location>
<contexts>
<context position="1419" citStr="Dang and Palmer (2002)" startWordPosition="204" endWordPosition="207">-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions. 1 Introduction Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combinations. The &apos;The author would like to thank the Hong Kong Research Grants Council (RGC) for sup</context>
</contexts>
<marker>Dang, Palmer, 2002</marker>
<rawString>Hoa Trang Dang and Martha Palmer. Combining contextual features for word sense disambiguation. In Proceedings of the SIGLEX/SENSEVAL Workshop on Word Sense Disambiguation: Recent Successes and Future Directions, pages 88– 94, Philadelphia, July 2002. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Konstantinos</author>
</authors>
<title>Diamantaras and Sun Yuan Kung. Principal Component Neural Networks.</title>
<date>1996</date>
<publisher>Wiley,</publisher>
<location>New York,</location>
<marker>Konstantinos, 1996</marker>
<rawString>Konstantinos I. Diamantaras and Sun Yuan Kung. Principal Component Neural Networks. Wiley, New York, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Efron</author>
<author>Robert J Tibshirani</author>
</authors>
<title>An Introduction to the Bootstrap. Chapman and Hall,</title>
<date>1993</date>
<contexts>
<context position="18377" citStr="Efron and Tibshirani, 1993" startWordPosition="3080" endWordPosition="3083">ote that we used the set of sense classes from Senseval’s ”fine-grained” rather than ”coarse-grained” classification task. The KPCA-based model achieves the highest accuracy, as shown in Table 5, followed by the maximum entropy model, with naive Bayes doing the poorest. Bear in mind that all of these models are significantly more accurate than any of the other reported models on Senseval. “Accuracy” here refers to both precision and recall since disambiguation of all target words in the test set is attempted. Results are statistically significant at the 0.10 level, using bootstrap resampling (Efron and Tibshirani, 1993); moreover, we consistently witnessed the same level of accuracy gains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield e</context>
</contexts>
<marker>Efron, Tibshirani, 1993</marker>
<rawString>Bradley Efron and Robert J. Tibshirani. An Introduction to the Bootstrap. Chapman and Hall, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Isozaki</author>
<author>Hideto Kazawa</author>
</authors>
<title>Efficient support vector classifiers for named entity recognition.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING-2002,</booktitle>
<pages>390--396</pages>
<location>Taipei,</location>
<contexts>
<context position="18965" citStr="Isozaki and Kazawa (2002)" startWordPosition="3168" endWordPosition="3171">sampling (Efron and Tibshirani, 1993); moreover, we consistently witnessed the same level of accuracy gains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al. (2003)) including the word sense disambiguation task (e.g., Cabezas et al. (2001)). Given that SVM and KPCA are both kernel methods, we are frequently asked whether SVM-based WSD could achieve similar results. To explore this question, we trained and tuned an SVM model, providing the same rich set of features and also varying the feature representations to optimize for SVM biases. As shown in Table 6, the highest-achieving SVM model is also able to obtain higher accuracies than the naive Bayes and maximum entropy models. However, in all our experiments the KPCA-based model co</context>
</contexts>
<marker>Isozaki, Kazawa, 2002</marker>
<rawString>Hideki Isozaki and Hideto Kazawa. Efficient support vector classifiers for named entity recognition. In Proceedings of COLING-2002, pages 390–396, Taipei, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E T Jaynes</author>
</authors>
<title>Where do we Stand on Maximum Entropy?</title>
<date>1978</date>
<publisher>MIT Press,</publisher>
<location>Cambridge MA,</location>
<contexts>
<context position="15990" citStr="Jaynes, 1978" startWordPosition="2698" endWordPosition="2699">dels. The naive Bayes model was found to be the most accurate classifier in a comparative study using a the/DT❑ media/N❑ 2❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ (b)❑ the/DT❑ media/N❑ 2❑ first principal❑ axis❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ (c)❑ the/DT❑ first principal❑ “�I quasi-axis”® 2❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ : training example with sense class 1❑ : training example with sense class 2❑ : test example with unknown sense class❑ : test example with predicted sense❑ media/N❑ subset of Senseval-2 English lexical sample data by Yarowsky and Florian (2002). However, the maximum entropy (Jaynes, 1978) was found to yield higher accuracy than naive Bayes in a subsequent comparison by Klein and Manning (2002), who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data. To control for data variation, we built and tuned models of both kinds. Note that our objective in these experiments is to understand the performance and characteristics of KPCA relative to other individual methods. It is not our objective here to compare against voting or other ensemble methods which, though known to be useful in practice (e.g., Yarowsky et al. (2001)), would not add to our unde</context>
</contexts>
<marker>Jaynes, 1978</marker>
<rawString>E.T. Jaynes. Where do we Stand on Maximum Entropy? MIT Press, Cambridge MA, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of ECML-98, 10th European Conference on Machine Learning,</booktitle>
<pages>137--142</pages>
<contexts>
<context position="18778" citStr="Joachims (1998)" startWordPosition="3140" endWordPosition="3141">s to both precision and recall since disambiguation of all target words in the test set is attempted. Results are statistically significant at the 0.10 level, using bootstrap resampling (Efron and Tibshirani, 1993); moreover, we consistently witnessed the same level of accuracy gains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al. (2003)) including the word sense disambiguation task (e.g., Cabezas et al. (2001)). Given that SVM and KPCA are both kernel methods, we are frequently asked whether SVM-based WSD could achieve similar results. To explore this question, we trained and tuned an SVM model, providing the same rich set of features and also varying the feature representations to optimize for SVM biases. As shown in</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Thorsten Joachims. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of ECML-98, 10th European Conference on Machine Learning, pages 137–142, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
<author>Joseph Rosenzweig</author>
</authors>
<title>Framework and results for English Senseval.</title>
<date>1999</date>
<journal>Computers and the Humanities,</journal>
<volume>34</volume>
<issue>1</issue>
<note>Special issue on SENSEVAL.</note>
<contexts>
<context position="1656" citStr="Kilgarriff and Rosenzweig, 1999" startWordPosition="239" endWordPosition="242">higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combinations. The &apos;The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through grants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09. technique is applicable whenever vector representations of a disambiguation task can be generated; thus many properties of our technique can be exp</context>
</contexts>
<marker>Kilgarriff, Rosenzweig, 1999</marker>
<rawString>Adam Kilgarriff and Joseph Rosenzweig. Framework and results for English Senseval. Computers and the Humanities, 34(1):15–48, 1999. Special issue on SENSEVAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>English lexical sample task description.</title>
<date>2001</date>
<booktitle>In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>17--20</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="1690" citStr="Kilgarriff, 2001" startWordPosition="245" endWordPosition="246">guation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combinations. The &apos;The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through grants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09. technique is applicable whenever vector representations of a disambiguation task can be generated; thus many properties of our technique can be expected to be highly attractive from</context>
<context position="7662" citStr="Kilgarriff 2001" startWordPosition="1269" endWordPosition="1270"> vector z9 using the linear PCA transform obtained from training, and (b) a nonlinear principal component vector y9 using the nonlinear KPCA transform obtained obtained from training. The vector similarities in the KPCA-transformed space can be quite different from those in the PCAtransformed space. This causes the KPCA-based model to be able to make the correct class prediction, whereas the PCA-based model makes the 1 C = M M  j=1 1 Cv = M M  j=1 M i=1 M M i=1 i( (xt) - M  j=1 Table 2: A tiny corpus for the target word “art”, adapted from the Senseval-2 English lexical sample corpus (Kilgarriff 2001), together with a tiny example set of features. The training and testing examples can be represented as a set of binary vectors: each row shows the correct class c for an observed vector x of five dimensions. TRAINING design/N media/N the/DT entertainment/N world/N Class x1 He studies art in London. 1 x2 Punch’s weekly guide to 1 1 1 1 the world of the arts, entertainment, media and more. x3 All such studies have in- 1 1 1 fluenced every form of art, design, and entertainment in some way. x4 Among the techni- 1 2 cal arts cultivated in some continental schools that began to affect England soon</context>
</contexts>
<marker>Kilgarriff, 2001</marker>
<rawString>Adam Kilgarriff. English lexical sample task description. In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems, pages 17–20, Toulouse, France, July 2001. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Conditional structure versus conditional estimation in NLP models.</title>
<date>2002</date>
<journal>SIGDAT, Association for Computational Linguistics.</journal>
<booktitle>In Proceedings of EMNLP2002, Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>9--16</pages>
<location>Philadelphia,</location>
<contexts>
<context position="1445" citStr="Klein and Manning (2002)" startWordPosition="208" endWordPosition="212"> the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions. 1 Introduction Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combinations. The &apos;The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in p</context>
<context position="16097" citStr="Klein and Manning (2002)" startWordPosition="2715" endWordPosition="2718">using a the/DT❑ media/N❑ 2❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ (b)❑ the/DT❑ media/N❑ 2❑ first principal❑ axis❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ (c)❑ the/DT❑ first principal❑ “�I quasi-axis”® 2❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ : training example with sense class 1❑ : training example with sense class 2❑ : test example with unknown sense class❑ : test example with predicted sense❑ media/N❑ subset of Senseval-2 English lexical sample data by Yarowsky and Florian (2002). However, the maximum entropy (Jaynes, 1978) was found to yield higher accuracy than naive Bayes in a subsequent comparison by Klein and Manning (2002), who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data. To control for data variation, we built and tuned models of both kinds. Note that our objective in these experiments is to understand the performance and characteristics of KPCA relative to other individual methods. It is not our objective here to compare against voting or other ensemble methods which, though known to be useful in practice (e.g., Yarowsky et al. (2001)), would not add to our understanding. To compare as evenly as possible, we employed features approximating those of the “featureenhanc</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. Conditional structure versus conditional estimation in NLP models. In Proceedings of EMNLP2002, Conference on Empirical Methods in Natural Language Processing, pages 9–16, Philadelphia, July 2002. SIGDAT, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast methods for kernel-based text analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41set Annual Meeting of the Asoociation for Computational Linguistics,</booktitle>
<pages>24--31</pages>
<contexts>
<context position="3911" citStr="Kudo and Matsumoto (2003)" startWordPosition="582" endWordPosition="585"> to a high-dimensional feature space F where linear PCA is performed, yielding a transform by which the input vectors can be mapped nonlinearly to a new set of vectors (Sch¨olkopf et al., 1998). A major advantage of KPCA is that, unlike other common analysis techniques, as with other kernel methods it inherently takes combinations of predictive features into account when optimizing dimensionality reduction. For natural language problems in general, of course, it is widely recognized that significant accuracy gains can often be achieved by generalizing over relevant feature combinations (e.g., Kudo and Matsumoto (2003)). Another advantage of KPCA for the WSD task is that the dimensionality of the input data is generally very Table 1: Two of the Senseval-2 sense classes for the target word “art”, from WordNet 1.7 (Fellbaum 1998). Class Sense 1 the creation of beautiful or significant things 2 a superior skill large, a condition where kernel methods excel. Nonlinear principal components (Diamantaras and Kung, 1996) may be defined as follows. Suppose we are given a training set of M pairs (xt, ct) where the observed vectors xt E Rn in an ndimensional input space X represent the context of the target word being</context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumoto. Fast methods for kernel-based text analysis. In Proceedings of the 41set Annual Meeting of the Asoociation for Computational Linguistics, pages 24–31, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Mayfield</author>
<author>Paul McNamee</author>
<author>Christine Piatko</author>
</authors>
<title>Named entity recognition using hundreds of thousands of features.</title>
<date>2003</date>
<booktitle>In Walter Daelemans</booktitle>
<pages>184--187</pages>
<editor>and Miles Osborne, editors,</editor>
<location>Edmonton, Canada,</location>
<contexts>
<context position="18989" citStr="Mayfield et al. (2003)" startWordPosition="3172" endWordPosition="3175">ani, 1993); moreover, we consistently witnessed the same level of accuracy gains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al. (2003)) including the word sense disambiguation task (e.g., Cabezas et al. (2001)). Given that SVM and KPCA are both kernel methods, we are frequently asked whether SVM-based WSD could achieve similar results. To explore this question, we trained and tuned an SVM model, providing the same rich set of features and also varying the feature representations to optimize for SVM biases. As shown in Table 6, the highest-achieving SVM model is also able to obtain higher accuracies than the naive Bayes and maximum entropy models. However, in all our experiments the KPCA-based model consistently outperforms t</context>
</contexts>
<marker>Mayfield, McNamee, Piatko, 2003</marker>
<rawString>James Mayfield, Paul McNamee, and Christine Piatko. Named entity recognition using hundreds of thousands of features. In Walter Daelemans and Miles Osborne, editors, Proceedings of CoNLL2003, pages 184–187, Edmonton, Canada, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond J Mooney</author>
</authors>
<title>Comparative experiments on disambiguating word senses: An illustration of the role of bias in machine learning.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Philadelphia,</location>
<contexts>
<context position="1284" citStr="Mooney (1996)" startWordPosition="184" endWordPosition="185">2 data. We also contrast against another type of kernel method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions. 1 Introduction Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly base</context>
</contexts>
<marker>Mooney, 1996</marker>
<rawString>Raymond J. Mooney. Comparative experiments on disambiguating word senses: An illustration of the role of bias in machine learning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, Philadelphia, May 1996. SIGDAT, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Machine learning with lexical features: The Duluth approach to SENSEVAL-2.</title>
<date>2001</date>
<booktitle>In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>139--142</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="1325" citStr="Pedersen (2001)" startWordPosition="190" endWordPosition="191">r type of kernel method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions. 1 Introduction Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combina</context>
</contexts>
<marker>Pedersen, 2001</marker>
<rawString>Ted Pedersen. Machine learning with lexical features: The Duluth approach to SENSEVAL-2. In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems, pages 139–142, Toulouse, France, July 2001. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Sch¨olkopf</author>
<author>Alexander Smola</author>
<author>KlausRober M¨uller</author>
</authors>
<title>Nonlinear component analysis as a kernel eigenvalue problem.</title>
<date>1998</date>
<journal>Neural Computation,</journal>
<volume>10</volume>
<issue>5</issue>
<marker>Sch¨olkopf, Smola, M¨uller, 1998</marker>
<rawString>Bernhard Sch¨olkopf, Alexander Smola, and KlausRober M¨uller. Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10(5), 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Feature space restructuring for SVMs with application to text categorization.</title>
<date>2001</date>
<booktitle>In Proceedings of EMNLP2001, Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>51--57</pages>
<contexts>
<context position="18938" citStr="Takamura and Matsumoto (2001)" startWordPosition="3164" endWordPosition="3167"> 0.10 level, using bootstrap resampling (Efron and Tibshirani, 1993); moreover, we consistently witnessed the same level of accuracy gains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al. (2003)) including the word sense disambiguation task (e.g., Cabezas et al. (2001)). Given that SVM and KPCA are both kernel methods, we are frequently asked whether SVM-based WSD could achieve similar results. To explore this question, we trained and tuned an SVM model, providing the same rich set of features and also varying the feature representations to optimize for SVM biases. As shown in Table 6, the highest-achieving SVM model is also able to obtain higher accuracies than the naive Bayes and maximum entropy models. However, in all our experime</context>
</contexts>
<marker>Takamura, Matsumoto, 2001</marker>
<rawString>Hiroya Takamura and Yuji Matsumoto. Feature space restructuring for SVMs with application to text categorization. In Proceedings of EMNLP2001, Conference on Empirical Methods in Natural Language Processing, pages 51–57, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag,</publisher>
<location>New York,</location>
<contexts>
<context position="18761" citStr="Vapnik (1995)" startWordPosition="3138" endWordPosition="3139">acy” here refers to both precision and recall since disambiguation of all target words in the test set is attempted. Results are statistically significant at the 0.10 level, using bootstrap resampling (Efron and Tibshirani, 1993); moreover, we consistently witnessed the same level of accuracy gains from the KPCA-based model over Table 6: Experimental results comparing the KPCA-based model versus the SVM model. WSD Model Accuracy Sig. Int. SVM-based model 65.2% +/-1.00% KPCA-based model 65.8% +/-0.79% many variations of the experiments. 4.2 KPCA versus SVM models Support vector machines (e.g., Vapnik (1995), Joachims (1998)) are a different kind of kernel method that, unlike KPCA methods, have already gained high popularity for NLP applications (e.g., Takamura and Matsumoto (2001), Isozaki and Kazawa (2002), Mayfield et al. (2003)) including the word sense disambiguation task (e.g., Cabezas et al. (2001)). Given that SVM and KPCA are both kernel methods, we are frequently asked whether SVM-based WSD could achieve similar results. To explore this question, we trained and tuned an SVM model, providing the same rich set of features and also varying the feature representations to optimize for SVM bi</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>Vladimir N. Vapnik. The Nature of Statistical Learning Theory. Springer-Verlag, New York, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Radu Florian</author>
</authors>
<title>Evaluating sense disambiguation across diverse parameter spaces.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="1354" citStr="Yarowsky and Florian (2002)" startWordPosition="192" endWordPosition="196">method, the support vector machine (SVM) model, and show that our KPCA-based model outperforms the SVM-based model. It is hoped that these highly encouraging first results on KPCA for natural language processing tasks will inspire further development of these directions. 1 Introduction Achieving higher precision in supervised word sense disambiguation (WSD) tasks without resorting to ad hoc voting or similar ensemble techniques has become somewhat daunting in recent years, given the challenging benchmarks set by naive Bayes models (e.g., Mooney (1996), Chodorow et al. (1999), Pedersen (2001), Yarowsky and Florian (2002)) as well as maximum entropy models (e.g., Dang and Palmer (2002), Klein and Manning (2002)). A good foundation for comparative studies has been established by the Senseval data and evaluations; of particular relevance here are the lexical sample tasks from Senseval-1 (Kilgarriff and Rosenzweig, 1999) and Senseval-2 (Kilgarriff, 2001). We therefore chose this problem to introduce an efficient and accurate new word sense disambiguation approach that exploits a nonlinear Kernel PCA technique to make predictions implicitly based on generalizations over feature combinations. The &apos;The author would </context>
<context position="15945" citStr="Yarowsky and Florian (2002)" startWordPosition="2690" endWordPosition="2693">ual WSD models: (1) naive Bayes, and (2) maximum entropy models. The naive Bayes model was found to be the most accurate classifier in a comparative study using a the/DT❑ media/N❑ 2❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ (b)❑ the/DT❑ media/N❑ 2❑ first principal❑ axis❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ (c)❑ the/DT❑ first principal❑ “�I quasi-axis”® 2❑ 4, 5, 6, 7❑ 9❑ 1, 8❑ 3❑ design/N❑ : training example with sense class 1❑ : training example with sense class 2❑ : test example with unknown sense class❑ : test example with predicted sense❑ media/N❑ subset of Senseval-2 English lexical sample data by Yarowsky and Florian (2002). However, the maximum entropy (Jaynes, 1978) was found to yield higher accuracy than naive Bayes in a subsequent comparison by Klein and Manning (2002), who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data. To control for data variation, we built and tuned models of both kinds. Note that our objective in these experiments is to understand the performance and characteristics of KPCA relative to other individual methods. It is not our objective here to compare against voting or other ensemble methods which, though known to be useful in practice (e.g., Yarow</context>
</contexts>
<marker>Yarowsky, Florian, 2002</marker>
<rawString>David Yarowsky and Radu Florian. Evaluating sense disambiguation across diverse parameter spaces. Natural Language Engineering, 8(4):293–310, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Silviu Cucerzan</author>
<author>Radu Florian</author>
<author>Charles Schafer</author>
<author>Richard Wicentowski</author>
</authors>
<title>The Johns Hopkins SENSEVAL2 system descriptions.</title>
<date>2001</date>
<booktitle>In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>163--166</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="16562" citStr="Yarowsky et al. (2001)" startWordPosition="2790" endWordPosition="2793">2002). However, the maximum entropy (Jaynes, 1978) was found to yield higher accuracy than naive Bayes in a subsequent comparison by Klein and Manning (2002), who used a different subset of either Senseval-1 or Senseval-2 English lexical sample data. To control for data variation, we built and tuned models of both kinds. Note that our objective in these experiments is to understand the performance and characteristics of KPCA relative to other individual methods. It is not our objective here to compare against voting or other ensemble methods which, though known to be useful in practice (e.g., Yarowsky et al. (2001)), would not add to our understanding. To compare as evenly as possible, we employed features approximating those of the “featureenhanced naive Bayes model” of Yarowsky and Florian (2002), which included position-sensitive, syntactic, and local collocational features. The models in the comparative study by Klein and Manning (2002) did not include such features, and so, again for consistency of comparison, we experimentally verified that our maximum entropy model (a) consistently yielded higher scores than when the features were not used, and (b) consistently yielded higher scores than naive Ba</context>
</contexts>
<marker>Yarowsky, Cucerzan, Florian, Schafer, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Silviu Cucerzan, Radu Florian, Charles Schafer, and Richard Wicentowski. The Johns Hopkins SENSEVAL2 system descriptions. In Proceedings of Senseval-2, Second International Workshop on Evaluating Word Sense Disambiguation Systems, pages 163–166, Toulouse, France, July 2001. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>