<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005211">
<note confidence="0.539063">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
Association for Computational Linguistics
</note>
<title confidence="0.9942105">
Augmenting Ensemble Classification for Word Sense Disambiguation with a
Kernel PCA Model
</title>
<author confidence="0.389419">
Marine CARPUAT Weifeng SU Dekai WU1
</author>
<email confidence="0.736768">
marine@cs.ust.hk weifeng@cs.ust.hk dekai@cs.ust.hk
</email>
<affiliation confidence="0.973683">
Human Language Technology Center
HKUST
Department of Computer Science
University of Science and Technology, Clear Water Bay, Hong Kong
</affiliation>
<sectionHeader confidence="0.994778" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999895722222222">
The HKUST word sense disambiguation systems
benefit from a new nonlinear Kernel Principal
Component Analysis (KPCA) based disambigua-
tion technique. We discuss and analyze results
from the Senseval-3 English, Chinese, and Multi-
lingual Lexical Sample data sets. Among an en-
semble of four different kinds of voted models, the
KPCA-based model, along with the maximum en-
tropy model, outperforms the boosting model and
naive Bayes model. Interestingly, while the KPCA-
based model typically achieves close or better ac-
curacy than the maximum entropy model, neverthe-
less a comparison of predicted classifications shows
that it has a significantly different bias. This char-
acteristic makes it an excellent voter, as confirmed
by results showing that removing the KPCA-based
model from the ensemble generally degrades per-
formance.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999553222222222">
Classifier combination has become a standard ar-
chitecture for shared task evaluations in word sense
disambiguation (WSD), named entity recognition,
and similar problems that can naturally be cast as
classification problems. Voting is the most com-
mon method of combination, having proven to be
remarkably effective yet simple.
A key problem in improving the accuracy of such
ensemble classification systems is to find new vot-
ing models that (1) exhibit significantly different
prediction biases from the models already voting,
and yet (2) attain stand-alone classification accura-
cies that are as good or better. When either of these
conditions is not met, adding the new voting model
typically degrades the accuracy of the ensemble in-
stead of helping it.
In this work, we investigate the potential of one
promising new disambiguation model with respect
</bodyText>
<footnote confidence="0.63214825">
&apos;The author would like to thank the Hong Kong Research
Grants Council (RGC) for supporting this research in part
through research grants RGC6083/99E, RGC6256/00E, and
DAG03/04.EG09.
</footnote>
<bodyText confidence="0.99994168">
to augmenting our existing ensemble combining a
maximum entropy model, a boosting model, and
a naive Bayes model—a combination representing
some of the best stand-alone WSD models cur-
rently known. The new WSD model, proposed
by Wu et al. (2004), is a method for disambiguat-
ing word senses that exploits a nonlinear Kernel
Principal Component Analysis (KPCA) technique.
That the KPCA-based model could potentially be
a good candidate for a new voting model is sug-
gested by Wu et al.’s empirical results showing that
it yielded higher accuracies on Senseval-2 data sets
than other models that included maximum entropy,
naive Bayes, and SVM based models.
In the following sections, we begin with a de-
scription of the experimental setup, which utilizes
a number of individual classifiers in a voting en-
semble. We then describe the KPCA-based model
to be added to the baseline ensemble. The accuracy
results of the three submitted models are examined,
and also the individual voting models are compared.
Subsequently, we analyze the degree of difference
in voting bias of the KPCA-based model from the
others, and finally show that this does indeed usu-
ally lead to accuracy gains in the voting ensemble.
</bodyText>
<sectionHeader confidence="0.983274" genericHeader="method">
2 Experimental setup
</sectionHeader>
<subsectionHeader confidence="0.997032">
2.1 Tasks evaluated
</subsectionHeader>
<bodyText confidence="0.998150371428571">
We performed experiments on the following lexical
sample tasks from Senseval-3:
English (fine). The English lexical sample task
includes 57 target words (32 verbs, 20 nouns and
5 adjectives). For each word, training and test in-
stances tagged with WordNet senses are provided.
There are an average of 8.5 senses per target word
type, ranging from 3 to 23. On average, 138 training
instances per target word are available.
English (coarse). This modified evaluation of the
preceding task employs a sense map that groups
fine-grained sense distinctions into the same coarse-
grained sense.
Chinese. The Chinese lexical sample task in-
cludes 21 target words. For each word, several
senses are defined using the HowNet knowledge
base. There are an average of 3.95 senses per tar-
get word type, ranging from 2 to 8. Only about 37
training instances per target word are available.
Multilingual (t). The Multilingual (t) task is de-
fined similarly to the English lexical sample task,
except that the word senses are the translations into
Hindi, rather than WordNet senses. The Multilin-
gual (t) task requires finding the Hindi sense for 31
English target word types. There are an average of
7.54 senses per target word type, ranging from 3 to
16. A relatively large training set is provided (more
than 260 training instances per word on average).
Multilingual (ts). The Multilingual (ts) task uses
a different data set of 10 target words and provides
the correct English sense of the target word for both
training and testing. There are an average of 6.2
senses per target word type, ranging from 3 to 11.
The training set for this subtask was smaller, with
about 150 training instances per target word.
</bodyText>
<subsectionHeader confidence="0.997102">
2.2 Ensemble classification
</subsectionHeader>
<bodyText confidence="0.999969432432432">
The WSD models presented here consist of ensem-
bles utilizing various combinations of four voting
models, as follows. Some of these component mod-
els were also evaluated on other Senseval-3 tasks:
the Basque, Catalan, Italian, and Romanian Lexical
Sample tasks (Wicentowski et al., 2004), as well as
Semantic Role Labeling (Ngai et al., 2004).
The first voting model, a naive Bayes model, was
built as Yarowsky and Florian (2002) found this
model to be the most accurate classifier in a compar-
ative study on a subset of Senseval-2 English lexical
sample data.
The second voting model, a maximum entropy
model (Jaynes, 1978), was built as Klein and Man-
ning (2002) found that it yielded higher accuracy
than naive Bayes in a subsequent comparison of
WSD performance. However, note that a different
subset of either Senseval-1 or Senseval-2 English
lexical sample data was used.
The third voting model, a boosting model (Fre-
und and Schapire, 1997), was built as boosting has
consistently turned in very competitive scores on re-
lated tasks such as named entity classification (Car-
reras et al., 2002)(Wu et al., 2002). Specifically, we
employed an AdaBoost.MH model (Schapire and
Singer, 2000), which is a multi-class generalization
of the original boosting algorithm, with boosting on
top of decision stump classifiers (decision trees of
depth one).
The fourth voting model, the KPCA-based
model, is described below.
All classifier models were selected for their abil-
ity to able to handle large numbers of sparse fea-
tures, many of which may be irrelevant. More-
over, the maximum entropy and boosting models are
known to be well suited to handling features that are
highly interdependent.
</bodyText>
<subsectionHeader confidence="0.99913">
2.3 Controlled feature set
</subsectionHeader>
<bodyText confidence="0.999958428571429">
In order to facilitate a controlled comparison across
the individual voting models, the same feature set
was employed for all classifiers. The features are
as described by Yarowsky and Florian (2002) in
their “feature-enhanced naive Bayes model”, with
position-sensitive, syntactic, and local collocational
features.
</bodyText>
<subsectionHeader confidence="0.992965">
2.4 The KPCA-based WSD model
</subsectionHeader>
<bodyText confidence="0.997371435897436">
We briefly summarize the KPCA-based model here;
for full details including illustrative examples and
graphical interpretation, please refer to Wu et al.
(2004).
Kernel PCA Kernel Principal Component Analy-
sis is a nonlinear kernel method for extracting non-
linear principal components from vector sets where,
conceptually, the n-dimensional input vectors are
nonlinearly mapped from their original space Rn
to a high-dimensional feature space F where linear
PCA is performed, yielding a transform by which
the input vectors can be mapped nonlinearly to a
new set of vectors (Sch¨olkopf et al., 1998).
As with other kernel methods, a major advantage
of KPCA over other common analysis techniques is
that it can inherently take combinations of predic-
tive features into account when optimizing dimen-
sionality reduction. For WSD and indeed many nat-
ural language tasks, significant accuracy gains can
often be achieved by generalizing over relevant fea-
ture combinations (see, e.g., Kudo and Matsumoto
(2003)). A further advantage of KPCA in the con-
text of the WSD problem is that the dimensionality
of the input data is generally very large, a condition
where kernel methods excel.
Nonlinear principal components (Diamantaras
and Kung, 1996) are defined as follows. Suppose
we are given a training set of M pairs (xt, ct) where
the observed vectors xt E Rn in an n-dimensional
input space X represent the context of the target
word being disambiguated, and the correct class ct
represents the sense of the word, for t = 1,.., M.
Suppose -b is a nonlinear mapping from the input
space Rn to the feature space F. Without loss of
generality we assume the M vectors are centered
vectors in the feature space, i.e., EMt=1 -b (xt) = 0;
uncentered vectors can easily be converted to cen-
tered vectors (Sch¨olkopf et al., 1998). We wish to
diagonalize the covariance matrix in F:
</bodyText>
<equation confidence="0.963922">
 (xj) T (xj) (1)
</equation>
<bodyText confidence="0.964902666666667">
To do this requires solving the equation v =
Cv for eigenvalues  &gt; 0 and eigenvectors v E
Rn\ {0}. Because
</bodyText>
<equation confidence="0.994019846153846">
((xj) - v) (xj) (2)
we can derive the following two useful results. First,
 ((xt) - v) =  (xt) - Cv (3)
for t = 1, .., M. Second, there exist i for i =
1, ..., M such that
v = M i (xi) (4)
i=1
Combining (1), (3), and (4), we obtain
i ((xt) - (xi ))
 (xj)) ((xj) - (xi ))
for t = 1,.., M. Let Kˆ be the M x M matrix such
that
ˆKij =  (xi) -  (xj) (5)
</equation>
<bodyText confidence="0.999664833333333">
and let ˆ1 &gt; ˆ2 &gt; ... &gt; ˆM denote the eigenval-
ues of Kˆ and ˆ1 ,..., ˆM denote the corresponding
complete set of normalized eigenvectors, such that
ˆt(ˆt - ˆt) = 1 when ˆt &gt; 0. Then the lth nonlinear
principal component of any test vector xt is defined
as
</bodyText>
<equation confidence="0.9871615">
yl t = M ˆl i ((xi) - (xt )) (6)
i=1
</equation>
<bodyText confidence="0.997611105263158">
where ˆli is the lth element of ˆl .
See Wu et al. (2004) for a possible geometric in-
terpretation of the power of the nonlinearity.
WSD using KPCA In order to extract nonlin-
ear principal components efficiently, first note that
in both Equations (5) and (6) the explicit form of
 (xi) is required only in the form of ( (xi) -
 (xj)), i.e., the dot product of vectors in F. This
means that we can calculate the nonlinear princi-
pal components by substituting a kernel function
k(xi, xj) for (( xi) - (xj )) in Equations (5) and
(6) without knowing the mapping  explicitly; in-
stead, the mapping  is implicitly defined by the
kernel function. It is always possible to construct
a mapping into a space where k acts as a dot prod-
uct so long as k is a continuous kernel of a positive
integral operator (Sch¨olkopf et al., 1998).
Thus we train the KPCA model using the follow-
ing algorithm:
</bodyText>
<listItem confidence="0.970569">
1. Compute an M x M matrix Kˆ such that
</listItem>
<equation confidence="0.77238">
ˆKij = k(xi, xj) (7)
</equation>
<listItem confidence="0.730368">
2. Compute the eigenvalues and eigenvectors of
matrix Kˆ and normalize the eigenvectors. Let
ˆ1 &gt; ˆ2 &gt; ... &gt; ˆM denote the eigenvalues
and ˆ1,..., ˆM denote the corresponding com-
plete set of normalized eigenvectors.
</listItem>
<bodyText confidence="0.997422">
To obtain the sense predictions for test instances,
we need only transform the corresponding vectors
using the trained KPCA model and classify the re-
sultant vectors using nearest neighbors. For a given
test instance vector x, its lth nonlinear principal
component is
</bodyText>
<equation confidence="0.988604">
yl t = M ˆlik(xi, xt) (8)
i=1
</equation>
<bodyText confidence="0.999242777777778">
where ˆli is the ith element of ˆl.
For our disambiguation experiments we employ a
polynomial kernel function of the form k(xi, xj) =
(xi - xj)d, although other kernel functions such as
gaussians could be used as well. Note that the de-
generate case of d = 1 yields the dot product kernel
k(xi, xj) = (xi-xj) which covers linear PCA as a
special case, which may explain why KPCA always
outperforms PCA.
</bodyText>
<sectionHeader confidence="0.999712" genericHeader="evaluation">
3 Results and discussion
</sectionHeader>
<subsectionHeader confidence="0.988515">
3.1 Accuracy
</subsectionHeader>
<bodyText confidence="0.999884333333333">
Table 1 summarizes the results of the submitted sys-
tems along with the individual voting models. Since
our models attempted to disambiguate all test in-
stances, we report accuracy (precision and recall be-
ing equal). Earlier experiments on Senseval-2 data
showed that the KPCA-based model significantly
outperformed both naive Bayes and maximum en-
tropy models (Wu et al., 2004). On the Senseval-
3 data, the maximum entropy model fares slightly
better: it remains significantly worse on the Multi-
lingual (ts) task, but achieves statistically the same
accuracy on the English (fine) task and is slightly
</bodyText>
<equation confidence="0.95963755">
1
C = M
M

j=1
1
Cv = M
M

j=1
M
i=1
M
=
i( (xt) -
M
i=1
M

j=1
</equation>
<tableCaption confidence="0.919215">
Table 1: Comparison of accuracy results for various HKUST ensemble and individual models on Senseval-
3 Lexical Sample tasks, confirming the high accuracy of the KPCA-based model. All test instances were
attempted. (Bold model names were the systems entered.)
</tableCaption>
<table confidence="0.999844375">
English English Chinese Multilingual Multilingual
(fine) (coarse) (t) (ts)
HKUST comb2 (me, boost, nb, kpca) 71.4 78.6 66.2 62.0 63.8
HKUST comb (me, boost, kpca) 70.9 78.1 66.5 61.4 63.8
HKUST me 69.3 76.4 64.4 60.6 60.8
HKUST kpca 69.2 - 63.6 60.0 63.3
HKUST boost 67.0 - 64.1 57.3 60.3
HKUST nb 64.3 - 60.4 57.3 56.8
</table>
<tableCaption confidence="0.993235333333333">
Table 2: Confusion matrices showing that the KPCA-based model votes very differently from the other
models on the Senseval-3 Lexical Sample tasks. Percentages representing disagreement between KPCA and
other voting models are shown in bold.
</tableCaption>
<table confidence="0.9977804">
kpca vs: me boost nb
task incorrect correct incorrect correct incorrect correct
English incorrect 24.14% 6.62% 21.60% 9.15% 21.04% 9.71%
(fine) correct 6.59% 62.65% 11.38% 57.86% 14.63% 54.61%
Chinese incorrect 24.01% 12.40% 22.96% 13.46% 26.65% 9.76%
correct 11.61% 51.98% 12.93% 50.66% 12.93% 50.66%
Multilingual incorrect 32.71% 7.33% 32.04% 8.01% 30.54% 9.51%
(t) correct 6.74% 53.22% 10.63% 49.33% 12.20% 47.75%
Multilingual incorrect 33.17% 3.52% 31.66% 5.03% 30.15% 6.53%
(ts) correct 6.03% 57.29% 8.04% 55.28% 13.07% 50.25%
</table>
<bodyText confidence="0.999761125">
more accurate on the Multilingual (t) task. For un-
known reasons—possibly the very small number of
training instances per Chinese target word, as men-
tioned earlier—there is an exception on the Chinese
task, where boosting outperforms the KPCA-based
model. We are investigating the possible causes.
The naive Bayes model remains significantly worse
under all conditions.
</bodyText>
<subsectionHeader confidence="0.999148">
3.2 Differentiated voting bias
</subsectionHeader>
<bodyText confidence="0.999983857142857">
For a new voting model to raise the accuracy of an
existing classifier ensemble, it is not only important
that the new voting model achieve accuracy compa-
rable to the other voters, as shown above, but also
that it provides a significantly differentiated predic-
tion bias than the other voters. Otherwise, the accu-
racy is typically hurt rather than helped by the new
voting model.
To examine whether the KPCA-based model sat-
isfies this requirement, we compared its predictions
against each of the other classifiers (for those tasks
where we have been given the answer key). Table 2
shows nine confusion matrices revealing the per-
centage of instances where the KPCA-based model
votes differently from one of the other voters. The
disagreement between KPCA and the other voting
models ranges from 6.03% to 14.63%, as shown
by the bold entries in the confusion matrices. Note
that where there is disagreement, the KPCA-based
model predicts the correct sense with significantly
higher accuracy, in nearly all cases.
</bodyText>
<subsectionHeader confidence="0.996729">
3.3 Voting effectiveness
</subsectionHeader>
<bodyText confidence="0.999255333333333">
The KPCA-based model exhibits the accuracy and
differentiation characteristics requisite for an effec-
tive additional voter, as shown in the foregoing sec-
</bodyText>
<tableCaption confidence="0.683186333333333">
Table 3: Comparison of the accuracies for the voting ensembles with and without the KPCA voter, confirm-
ing that adding the KPCA-based model to the voting ensemble always helps on Senseval-3 Lexical Sample
tasks.
</tableCaption>
<table confidence="0.9865935">
English English Chinese Multilingual Multilingual
(fine) (coarse) (t) (ts)
HKUST comb3 (me, boost, nb) 71.2 - 67.5 60.6 60.8
HKUST comb2 (me, boost, nb, kpca) 71.4 78.6 66.2 62.0 63.8
</table>
<bodyText confidence="0.998938363636364">
tions. To verify that adding the KPCA-based model
to the voting ensemble indeed improves accuracy,
we compared our voting ensemble’s accuracies to
that obtained with KPCA removed. The results,
shown in Table 3, confirm that the KPCA-based
model generally helps on Senseval-3 Lexical Sam-
ple tasks. The only exception is on Chinese, due
to the aforementioned anomaly of boosting outper-
forming KPCA on that task. In the Multilingual (t)
and (ts) cases, the improvement in accuracy is sig-
nificant.
</bodyText>
<sectionHeader confidence="0.999532" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999991555555556">
We have described our word sense disambiguation
system and its performance on the Senseval-3 En-
glish, Chinese, and Multilingual Lexical Sample
tasks. The system consists of an ensemble clas-
sifier utilizing combinations of maximum entropy,
boosting, naive Bayes, and a new Kernel PCA based
model.
We have demonstrated that our new model based
on Kernel PCA is, along with maximum entropy,
one of the most accurate stand-alone models vot-
ing in the ensemble, as evaluated under carefully
controlled to ensure the same optimized feature set
across all models being compared. Moreover, we
have shown that the KPCA model exhibits a signif-
icantly different classification bias, a characteristic
that makes it a valuable voter in an ensemble. The
results confirm that accuracy is generally improved
by the addition of the KPCA-based model.
</bodyText>
<sectionHeader confidence="0.999645" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999802433962264">
Xavier Carreras, Lluis M`arques, and Lluis Padr´o. Named entity
extraction using AdaBoost. In Dan Roth and Antal van den
Bosch, editors, Proceedings of CoNLL-2002, pages 167–
170, Taipei, Taiwan, 2002.
Konstantinos I. Diamantaras and Sun Yuan Kung. Principal
Component Neural Networks. Wiley, New York, 1996.
Yoram Freund and Robert E. Schapire. A decision-theoretic
generalization of on-line learning and an application to
boosting. In Journal of Computer and System Sciences,
55(1), pages 119–139, 1997.
E.T. Jaynes. Where do we Stand on Maximum Entropy? MIT
Press, Cambridge MA, 1978.
Dan Klein and Christopher D. Manning. Conditional struc-
ture versus conditional estimation in NLP models. In Pro-
ceedings of EMNLP-2002, Conference on Empirical Meth-
ods in Natural Language Processing, pages 9–16, Philadel-
phia, July 2002. SIGDAT, Association for Computational
Linguistics.
Taku Kudo and Yuji Matsumoto. Fast methods for kernel-based
text analysis. In Proceedings of the 41st Annual Meeting of
the Association for Computational Linguistics, pages 24–31,
2003.
Grace Ngai, Dekai Wu, Marine Carpuat, Chi-Shing Wang,
and Chi-Yung Wang. Semantic role labeling with boost-
ing, SVMs, maximum entropy, SNOW, and decision lists.
In Proceedings of Senseval-3, Third International Work-
shop on Evaluating Word Sense Disambiguation Systems,
Barcelona, July 2004. SIGLEX, Association for Computa-
tional Linguistics.
Robert E. Schapire and Yoram Singer. Boostexter: A boosting-
based system for text categorization. In Machine Learning,
39(2/3), pages 135–168, 2000.
Bernhard Sch¨olkopf, Alexander Smola, and Klaus-Rober
M¨uller. Nonlinear component analysis as a kernel eigen-
value problem. Neural Computation, 10(5), 1998.
Richard Wicentowski, Grace Ngai, Dekai Wu, Marine Carpuat,
Emily Thomforde, and Adrian Packel. Joining forces to
resolve lexical ambiguity: East meets West in Barcelona.
In Proceedings of Senseval-3, Third International Work-
shop on Evaluating Word Sense Disambiguation Systems,
Barcelona, July 2004. SIGLEX, Association for Computa-
tional Linguistics.
Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen, and
Yongsheng Yang. Boosting for named entity recognition.
In Dan Roth and Antal van den Bosch, editors, Proceedings
of CoNLL-2002, pages 195–198. Taipei, Taiwan, 2002.
Dekai Wu, Weifeng Su, and Marine Carpuat. A Kernel PCA
method for superior word sense disambiguation. In Pro-
ceedings of the 42nd Annual Meeting of the Association for
Computational Linguistics, Barcelona, July 2004.
David Yarowsky and Radu Florian. Evaluating sense disam-
biguation across diverse parameter spaces. Natural Lan-
guage Engineering, 8(4):293–310, 2002.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.271372">
<note confidence="0.75512">SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004 Association for Computational Linguistics</note>
<title confidence="0.875821">Augmenting Ensemble Classification for Word Sense Disambiguation with a Kernel PCA Model marine@cs.ust.hk weifeng@cs.ust.hk dekai@cs.ust.hk</title>
<author confidence="0.930115">Human Language Technology</author>
<affiliation confidence="0.964788">Department of Computer University of Science and Technology, Clear Water Bay, Hong Kong</affiliation>
<abstract confidence="0.989502">The HKUST word sense disambiguation systems benefit from a new nonlinear Kernel Principal Component Analysis (KPCA) based disambiguation technique. We discuss and analyze results from the Senseval-3 English, Chinese, and Multilingual Lexical Sample data sets. Among an ensemble of four different kinds of voted models, the KPCA-based model, along with the maximum entropy model, outperforms the boosting model and naive Bayes model. Interestingly, while the KPCAbased model typically achieves close or better accuracy than the maximum entropy model, nevertheless a comparison of predicted classifications shows that it has a significantly different bias. This characteristic makes it an excellent voter, as confirmed by results showing that removing the KPCA-based model from the ensemble generally degrades performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
</authors>
<title>Lluis M`arques, and Lluis Padr´o. Named entity extraction using AdaBoost.</title>
<date>2002</date>
<booktitle>In Dan Roth and Antal</booktitle>
<pages>167--170</pages>
<editor>van den Bosch, editors,</editor>
<location>Taipei, Taiwan,</location>
<marker>Carreras, 2002</marker>
<rawString>Xavier Carreras, Lluis M`arques, and Lluis Padr´o. Named entity extraction using AdaBoost. In Dan Roth and Antal van den Bosch, editors, Proceedings of CoNLL-2002, pages 167– 170, Taipei, Taiwan, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Konstantinos</author>
</authors>
<title>Diamantaras and Sun Yuan Kung. Principal Component Neural Networks.</title>
<date>1996</date>
<publisher>Wiley,</publisher>
<location>New York,</location>
<marker>Konstantinos, 1996</marker>
<rawString>Konstantinos I. Diamantaras and Sun Yuan Kung. Principal Component Neural Networks. Wiley, New York, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoram Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>A decision-theoretic generalization of on-line learning and an application to boosting.</title>
<date>1997</date>
<journal>In Journal of Computer and System Sciences,</journal>
<volume>55</volume>
<issue>1</issue>
<pages>119--139</pages>
<contexts>
<context position="6265" citStr="Freund and Schapire, 1997" startWordPosition="987" endWordPosition="991">ling (Ngai et al., 2004). The first voting model, a naive Bayes model, was built as Yarowsky and Florian (2002) found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data. The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third voting model, a boosting model (Freund and Schapire, 1997), was built as boosting has consistently turned in very competitive scores on related tasks such as named entity classification (Carreras et al., 2002)(Wu et al., 2002). Specifically, we employed an AdaBoost.MH model (Schapire and Singer, 2000), which is a multi-class generalization of the original boosting algorithm, with boosting on top of decision stump classifiers (decision trees of depth one). The fourth voting model, the KPCA-based model, is described below. All classifier models were selected for their ability to able to handle large numbers of sparse features, many of which may be irre</context>
</contexts>
<marker>Freund, Schapire, 1997</marker>
<rawString>Yoram Freund and Robert E. Schapire. A decision-theoretic generalization of on-line learning and an application to boosting. In Journal of Computer and System Sciences, 55(1), pages 119–139, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E T Jaynes</author>
</authors>
<title>Where do we Stand on Maximum Entropy?</title>
<date>1978</date>
<publisher>MIT Press,</publisher>
<location>Cambridge MA,</location>
<contexts>
<context position="5944" citStr="Jaynes, 1978" startWordPosition="937" endWordPosition="938">models presented here consist of ensembles utilizing various combinations of four voting models, as follows. Some of these component models were also evaluated on other Senseval-3 tasks: the Basque, Catalan, Italian, and Romanian Lexical Sample tasks (Wicentowski et al., 2004), as well as Semantic Role Labeling (Ngai et al., 2004). The first voting model, a naive Bayes model, was built as Yarowsky and Florian (2002) found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data. The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third voting model, a boosting model (Freund and Schapire, 1997), was built as boosting has consistently turned in very competitive scores on related tasks such as named entity classification (Carreras et al., 2002)(Wu et al., 2002). Specifically, we employed an AdaBoost.MH model (Schapire and Singer, 2000), which is a multi-class generaliza</context>
</contexts>
<marker>Jaynes, 1978</marker>
<rawString>E.T. Jaynes. Where do we Stand on Maximum Entropy? MIT Press, Cambridge MA, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Conditional structure versus conditional estimation in NLP models.</title>
<date>2002</date>
<journal>SIGDAT, Association for Computational Linguistics.</journal>
<booktitle>In Proceedings of EMNLP-2002, Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>9--16</pages>
<location>Philadelphia,</location>
<contexts>
<context position="5983" citStr="Klein and Manning (2002)" startWordPosition="942" endWordPosition="946">t of ensembles utilizing various combinations of four voting models, as follows. Some of these component models were also evaluated on other Senseval-3 tasks: the Basque, Catalan, Italian, and Romanian Lexical Sample tasks (Wicentowski et al., 2004), as well as Semantic Role Labeling (Ngai et al., 2004). The first voting model, a naive Bayes model, was built as Yarowsky and Florian (2002) found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data. The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third voting model, a boosting model (Freund and Schapire, 1997), was built as boosting has consistently turned in very competitive scores on related tasks such as named entity classification (Carreras et al., 2002)(Wu et al., 2002). Specifically, we employed an AdaBoost.MH model (Schapire and Singer, 2000), which is a multi-class generalization of the original boosting algorithm</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. Conditional structure versus conditional estimation in NLP models. In Proceedings of EMNLP-2002, Conference on Empirical Methods in Natural Language Processing, pages 9–16, Philadelphia, July 2002. SIGDAT, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast methods for kernel-based text analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>24--31</pages>
<contexts>
<context position="8377" citStr="Kudo and Matsumoto (2003)" startWordPosition="1311" endWordPosition="1314"> from their original space Rn to a high-dimensional feature space F where linear PCA is performed, yielding a transform by which the input vectors can be mapped nonlinearly to a new set of vectors (Sch¨olkopf et al., 1998). As with other kernel methods, a major advantage of KPCA over other common analysis techniques is that it can inherently take combinations of predictive features into account when optimizing dimensionality reduction. For WSD and indeed many natural language tasks, significant accuracy gains can often be achieved by generalizing over relevant feature combinations (see, e.g., Kudo and Matsumoto (2003)). A further advantage of KPCA in the context of the WSD problem is that the dimensionality of the input data is generally very large, a condition where kernel methods excel. Nonlinear principal components (Diamantaras and Kung, 1996) are defined as follows. Suppose we are given a training set of M pairs (xt, ct) where the observed vectors xt E Rn in an n-dimensional input space X represent the context of the target word being disambiguated, and the correct class ct represents the sense of the word, for t = 1,.., M. Suppose -b is a nonlinear mapping from the input space Rn to the feature space</context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumoto. Fast methods for kernel-based text analysis. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 24–31, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Ngai</author>
<author>Dekai Wu</author>
<author>Marine Carpuat</author>
<author>Chi-Shing Wang</author>
<author>Chi-Yung Wang</author>
</authors>
<title>Semantic role labeling with boosting, SVMs, maximum entropy, SNOW, and decision lists.</title>
<date>2004</date>
<booktitle>In Proceedings of Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="5663" citStr="Ngai et al., 2004" startWordPosition="887" endWordPosition="890"> correct English sense of the target word for both training and testing. There are an average of 6.2 senses per target word type, ranging from 3 to 11. The training set for this subtask was smaller, with about 150 training instances per target word. 2.2 Ensemble classification The WSD models presented here consist of ensembles utilizing various combinations of four voting models, as follows. Some of these component models were also evaluated on other Senseval-3 tasks: the Basque, Catalan, Italian, and Romanian Lexical Sample tasks (Wicentowski et al., 2004), as well as Semantic Role Labeling (Ngai et al., 2004). The first voting model, a naive Bayes model, was built as Yarowsky and Florian (2002) found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data. The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third voting model, a boosting model (Freund and Schapire, 199</context>
</contexts>
<marker>Ngai, Wu, Carpuat, Wang, Wang, 2004</marker>
<rawString>Grace Ngai, Dekai Wu, Marine Carpuat, Chi-Shing Wang, and Chi-Yung Wang. Semantic role labeling with boosting, SVMs, maximum entropy, SNOW, and decision lists. In Proceedings of Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, July 2004. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Boostexter: A boostingbased system for text categorization.</title>
<date>2000</date>
<booktitle>In Machine Learning,</booktitle>
<volume>39</volume>
<issue>2</issue>
<pages>135--168</pages>
<contexts>
<context position="6509" citStr="Schapire and Singer, 2000" startWordPosition="1026" endWordPosition="1029">e second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third voting model, a boosting model (Freund and Schapire, 1997), was built as boosting has consistently turned in very competitive scores on related tasks such as named entity classification (Carreras et al., 2002)(Wu et al., 2002). Specifically, we employed an AdaBoost.MH model (Schapire and Singer, 2000), which is a multi-class generalization of the original boosting algorithm, with boosting on top of decision stump classifiers (decision trees of depth one). The fourth voting model, the KPCA-based model, is described below. All classifier models were selected for their ability to able to handle large numbers of sparse features, many of which may be irrelevant. Moreover, the maximum entropy and boosting models are known to be well suited to handling features that are highly interdependent. 2.3 Controlled feature set In order to facilitate a controlled comparison across the individual voting mo</context>
</contexts>
<marker>Schapire, Singer, 2000</marker>
<rawString>Robert E. Schapire and Yoram Singer. Boostexter: A boostingbased system for text categorization. In Machine Learning, 39(2/3), pages 135–168, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernhard Sch¨olkopf</author>
<author>Alexander Smola</author>
<author>Klaus-Rober M¨uller</author>
</authors>
<title>Nonlinear component analysis as a kernel eigenvalue problem.</title>
<date>1998</date>
<journal>Neural Computation,</journal>
<volume>10</volume>
<issue>5</issue>
<marker>Sch¨olkopf, Smola, M¨uller, 1998</marker>
<rawString>Bernhard Sch¨olkopf, Alexander Smola, and Klaus-Rober M¨uller. Nonlinear component analysis as a kernel eigenvalue problem. Neural Computation, 10(5), 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Wicentowski</author>
<author>Grace Ngai</author>
<author>Dekai Wu</author>
<author>Marine Carpuat</author>
<author>Emily Thomforde</author>
<author>Adrian Packel</author>
</authors>
<title>Joining forces to resolve lexical ambiguity: East meets West in Barcelona.</title>
<date>2004</date>
<booktitle>In Proceedings of Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="5608" citStr="Wicentowski et al., 2004" startWordPosition="877" endWordPosition="880"> uses a different data set of 10 target words and provides the correct English sense of the target word for both training and testing. There are an average of 6.2 senses per target word type, ranging from 3 to 11. The training set for this subtask was smaller, with about 150 training instances per target word. 2.2 Ensemble classification The WSD models presented here consist of ensembles utilizing various combinations of four voting models, as follows. Some of these component models were also evaluated on other Senseval-3 tasks: the Basque, Catalan, Italian, and Romanian Lexical Sample tasks (Wicentowski et al., 2004), as well as Semantic Role Labeling (Ngai et al., 2004). The first voting model, a naive Bayes model, was built as Yarowsky and Florian (2002) found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data. The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third v</context>
</contexts>
<marker>Wicentowski, Ngai, Wu, Carpuat, Thomforde, Packel, 2004</marker>
<rawString>Richard Wicentowski, Grace Ngai, Dekai Wu, Marine Carpuat, Emily Thomforde, and Adrian Packel. Joining forces to resolve lexical ambiguity: East meets West in Barcelona. In Proceedings of Senseval-3, Third International Workshop on Evaluating Word Sense Disambiguation Systems, Barcelona, July 2004. SIGLEX, Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Grace Ngai, Marine Carpuat, Jeppe Larsen, and Yongsheng Yang. Boosting for named entity recognition.</title>
<date>2002</date>
<booktitle>In Dan Roth and Antal</booktitle>
<pages>195--198</pages>
<editor>van den Bosch, editors,</editor>
<location>Taipei, Taiwan,</location>
<marker>Wu, 2002</marker>
<rawString>Dekai Wu, Grace Ngai, Marine Carpuat, Jeppe Larsen, and Yongsheng Yang. Boosting for named entity recognition. In Dan Roth and Antal van den Bosch, editors, Proceedings of CoNLL-2002, pages 195–198. Taipei, Taiwan, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Weifeng Su</author>
<author>Marine Carpuat</author>
</authors>
<title>A Kernel PCA method for superior word sense disambiguation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="2609" citStr="Wu et al. (2004)" startWordPosition="385" endWordPosition="388">the new voting model typically degrades the accuracy of the ensemble instead of helping it. In this work, we investigate the potential of one promising new disambiguation model with respect &apos;The author would like to thank the Hong Kong Research Grants Council (RGC) for supporting this research in part through research grants RGC6083/99E, RGC6256/00E, and DAG03/04.EG09. to augmenting our existing ensemble combining a maximum entropy model, a boosting model, and a naive Bayes model—a combination representing some of the best stand-alone WSD models currently known. The new WSD model, proposed by Wu et al. (2004), is a method for disambiguating word senses that exploits a nonlinear Kernel Principal Component Analysis (KPCA) technique. That the KPCA-based model could potentially be a good candidate for a new voting model is suggested by Wu et al.’s empirical results showing that it yielded higher accuracies on Senseval-2 data sets than other models that included maximum entropy, naive Bayes, and SVM based models. In the following sections, we begin with a description of the experimental setup, which utilizes a number of individual classifiers in a voting ensemble. We then describe the KPCA-based model </context>
<context position="7536" citStr="Wu et al. (2004)" startWordPosition="1181" endWordPosition="1184">ls are known to be well suited to handling features that are highly interdependent. 2.3 Controlled feature set In order to facilitate a controlled comparison across the individual voting models, the same feature set was employed for all classifiers. The features are as described by Yarowsky and Florian (2002) in their “feature-enhanced naive Bayes model”, with position-sensitive, syntactic, and local collocational features. 2.4 The KPCA-based WSD model We briefly summarize the KPCA-based model here; for full details including illustrative examples and graphical interpretation, please refer to Wu et al. (2004). Kernel PCA Kernel Principal Component Analysis is a nonlinear kernel method for extracting nonlinear principal components from vector sets where, conceptually, the n-dimensional input vectors are nonlinearly mapped from their original space Rn to a high-dimensional feature space F where linear PCA is performed, yielding a transform by which the input vectors can be mapped nonlinearly to a new set of vectors (Sch¨olkopf et al., 1998). As with other kernel methods, a major advantage of KPCA over other common analysis techniques is that it can inherently take combinations of predictive features</context>
<context position="10101" citStr="Wu et al. (2004)" startWordPosition="1659" endWordPosition="1662"> 1, .., M. Second, there exist i for i = 1, ..., M such that v = M i (xi) (4) i=1 Combining (1), (3), and (4), we obtain i ((xt) - (xi ))  (xj)) ((xj) - (xi )) for t = 1,.., M. Let Kˆ be the M x M matrix such that ˆKij =  (xi) -  (xj) (5) and let ˆ1 &gt; ˆ2 &gt; ... &gt; ˆM denote the eigenvalues of Kˆ and ˆ1 ,..., ˆM denote the corresponding complete set of normalized eigenvectors, such that ˆt(ˆt - ˆt) = 1 when ˆt &gt; 0. Then the lth nonlinear principal component of any test vector xt is defined as yl t = M ˆl i ((xi) - (xt )) (6) i=1 where ˆli is the lth element of ˆl . See Wu et al. (2004) for a possible geometric interpretation of the power of the nonlinearity. WSD using KPCA In order to extract nonlinear principal components efficiently, first note that in both Equations (5) and (6) the explicit form of  (xi) is required only in the form of ( (xi) -  (xj)), i.e., the dot product of vectors in F. This means that we can calculate the nonlinear principal components by substituting a kernel function k(xi, xj) for (( xi) - (xj )) in Equations (5) and (6) without knowing the mapping  explicitly; instead, the mapping  is implicitly defined by the kernel function. It is always</context>
<context position="12330" citStr="Wu et al., 2004" startWordPosition="2052" endWordPosition="2055">ld be used as well. Note that the degenerate case of d = 1 yields the dot product kernel k(xi, xj) = (xi-xj) which covers linear PCA as a special case, which may explain why KPCA always outperforms PCA. 3 Results and discussion 3.1 Accuracy Table 1 summarizes the results of the submitted systems along with the individual voting models. Since our models attempted to disambiguate all test instances, we report accuracy (precision and recall being equal). Earlier experiments on Senseval-2 data showed that the KPCA-based model significantly outperformed both naive Bayes and maximum entropy models (Wu et al., 2004). On the Senseval3 data, the maximum entropy model fares slightly better: it remains significantly worse on the Multilingual (ts) task, but achieves statistically the same accuracy on the English (fine) task and is slightly 1 C = M M  j=1 1 Cv = M M  j=1 M i=1 M = i( (xt) - M i=1 M  j=1 Table 1: Comparison of accuracy results for various HKUST ensemble and individual models on Senseval3 Lexical Sample tasks, confirming the high accuracy of the KPCA-based model. All test instances were attempted. (Bold model names were the systems entered.) English English Chinese Multilingual Multiling</context>
</contexts>
<marker>Wu, Su, Carpuat, 2004</marker>
<rawString>Dekai Wu, Weifeng Su, and Marine Carpuat. A Kernel PCA method for superior word sense disambiguation. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, Barcelona, July 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Radu Florian</author>
</authors>
<title>Evaluating sense disambiguation across diverse parameter spaces.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="5750" citStr="Yarowsky and Florian (2002)" startWordPosition="902" endWordPosition="905"> are an average of 6.2 senses per target word type, ranging from 3 to 11. The training set for this subtask was smaller, with about 150 training instances per target word. 2.2 Ensemble classification The WSD models presented here consist of ensembles utilizing various combinations of four voting models, as follows. Some of these component models were also evaluated on other Senseval-3 tasks: the Basque, Catalan, Italian, and Romanian Lexical Sample tasks (Wicentowski et al., 2004), as well as Semantic Role Labeling (Ngai et al., 2004). The first voting model, a naive Bayes model, was built as Yarowsky and Florian (2002) found this model to be the most accurate classifier in a comparative study on a subset of Senseval-2 English lexical sample data. The second voting model, a maximum entropy model (Jaynes, 1978), was built as Klein and Manning (2002) found that it yielded higher accuracy than naive Bayes in a subsequent comparison of WSD performance. However, note that a different subset of either Senseval-1 or Senseval-2 English lexical sample data was used. The third voting model, a boosting model (Freund and Schapire, 1997), was built as boosting has consistently turned in very competitive scores on related</context>
<context position="7230" citStr="Yarowsky and Florian (2002)" startWordPosition="1140" endWordPosition="1143">op of decision stump classifiers (decision trees of depth one). The fourth voting model, the KPCA-based model, is described below. All classifier models were selected for their ability to able to handle large numbers of sparse features, many of which may be irrelevant. Moreover, the maximum entropy and boosting models are known to be well suited to handling features that are highly interdependent. 2.3 Controlled feature set In order to facilitate a controlled comparison across the individual voting models, the same feature set was employed for all classifiers. The features are as described by Yarowsky and Florian (2002) in their “feature-enhanced naive Bayes model”, with position-sensitive, syntactic, and local collocational features. 2.4 The KPCA-based WSD model We briefly summarize the KPCA-based model here; for full details including illustrative examples and graphical interpretation, please refer to Wu et al. (2004). Kernel PCA Kernel Principal Component Analysis is a nonlinear kernel method for extracting nonlinear principal components from vector sets where, conceptually, the n-dimensional input vectors are nonlinearly mapped from their original space Rn to a high-dimensional feature space F where line</context>
</contexts>
<marker>Yarowsky, Florian, 2002</marker>
<rawString>David Yarowsky and Radu Florian. Evaluating sense disambiguation across diverse parameter spaces. Natural Language Engineering, 8(4):293–310, 2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>