<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.056185">
<title confidence="0.995364">
Complexity assumptions in ontology verbalisation
</title>
<author confidence="0.996863">
Richard Power
</author>
<affiliation confidence="0.9094745">
Department of Computing
Open University, UK
</affiliation>
<email confidence="0.990495">
r.power@open.ac.uk
</email>
<sectionHeader confidence="0.993715" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999861">
We describe the strategy currently pur-
sued for verbalising OWL ontologies by
sentences in Controlled Natural Language
(i.e., combining generic rules for realising
logical patterns with ontology-specific lex-
icons for realising atomic terms for indi-
viduals, classes, and properties) and argue
that its success depends on assumptions
about the complexity of terms and axioms
in the ontology. We then show, through
analysis of a corpus of ontologies, that al-
though these assumptions could in princi-
ple be violated, they are overwhelmingly
respected in practice by ontology develop-
ers.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999958428571428">
Since OWL (Web Ontology Language) was
adopted as a standard in 2004, researchers have
sought ways of mediating between the (decidedly
cumbersome) raw code and the human users who
aspire to view or edit it. Among the solutions
that have been proposed are more readable coding
formats such as Manchester OWL Syntax (Hor-
ridge et al., 2006), and graphical interfaces such
as Prot´eg´e (Knublauch et al., 2004); more specula-
tively, several research groups have explored ways
of mapping between OWL and controlled English,
with the aim of presenting ontologies (both for
viewing and editing) in natural language (Schwit-
ter and Tilbrook, 2004; Sun and Mellish, 2006;
Kaljurand and Fuchs, 2007; Hart et al., 2008). In
this paper we uncover and test some assumptions
on which this latter approach is based.
Historically, ontology verbalisation evolved
from a more general tradition (predating OWL
and the Semantic Web) that aimed to support
knowledge formation by automatic interpretation
of texts authored in Controlled Natural Languages
(Fuchs and Schwitter, 1995). The idea is to es-
tablish a mapping from a formal language to a
natural subset of English, so that any sentence
conforming to the Controlled Natural Language
(CNL) can be assigned a single interpretation in
the formal language — and conversely, any well-
formed statement in the formal language can be
realised in the CNL. With the advent of OWL,
some of these CNLs were rapidly adapted to the
new opportunity: part of Attempto Controlled En-
glish (ACE) was mapped to OWL (Kaljurand and
Fuchs, 2007), and Processable English (PENG)
evolved to Sydney OWL Syntax (SOS) (Cregan et
al., 2007). In addition, new CNLs were developed
specifically for editing OWL ontologies, such as
Rabbit (Hart et al., 2008) and Controlled Lan-
guage for Ontology Editing (CLOnE) (Funk et al.,
2007).
In detail, these CNLs display some variations:
thus an inclusion relationship between the classes
Admiral and Sailor would be expressed by the
pattern ‘Admirals are a type of sailor’ in CLOnE,
‘Every admiral is a kind of sailor’ in Rabbit, and
‘Every admiral is a sailor’ in ACE and SOS. How-
ever, at the level of general strategy, all the CNLs
rely on the same set of assumptions concerning the
mapping from natural to formal language; for con-
venience we will refer to these assumptions as the
consensus model. In brief, the consensus model
assumes that when an ontology is verbalised in
natural language, axioms are expressed by sen-
tences, and atomic terms are expressed by en-
tries from the lexicon. Such a model may fail in
two ways: (1) an ontology might contain axioms
that cannot be described transparently by a sen-
tence (for instance, because they contain complex
Boolean expressions that lead to structural ambi-
guity); (2) it might contain atomic terms for which
no suitable lexical entry can be found. In the re-
mainder of this paper we first describe the consen-
sus model in more detail, then show that although
</bodyText>
<page confidence="0.972011">
132
</page>
<note confidence="0.7539765">
Proceedings of the ACL 2010 Conference Short Papers, pages 132–136,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.9806405">
Logic OWL
C u D IntersectionOf(C D)
∃P.C SomeValuesFrom(P C)
C v D SubClassOf(C D) a b)
a ∈ C ClassAssertion(C a)
[a, b] ∈ P PropertyAssertion(P
</table>
<tableCaption confidence="0.999858">
Table 1: Common OWL expressions
</tableCaption>
<bodyText confidence="0.996015666666667">
in principle it is vulnerable to both the problems
just mentioned, in practice these problems almost
never arise.
</bodyText>
<sectionHeader confidence="0.980952" genericHeader="method">
2 Consensus model
</sectionHeader>
<bodyText confidence="0.999233555555556">
Atomic terms in OWL (or any other language im-
plementing description logic) are principally of
three kinds, denoting either individuals, classes
or properties1. Individuals denote entities in the
domain, such as Horatio Nelson or the Battle of
Trafalgar; classes denote sets of entities, such as
people or battles; and properties denote relations
between individuals, such as the relation victor of
between a person and a battle.
From these basic terms, a wide range of com-
plex expressions may be constructed for classes,
properties and axioms, of which some common
examples are shown in table 1. The upper part of
the table presents two class constructors (C and
D denote any classes; P denotes any property);
by combining them we could build the following
expression denoting the class of persons that com-
mand fleets2:
</bodyText>
<subsectionHeader confidence="0.406668">
Person u ∃ CommanderOf.Fleet
</subsectionHeader>
<bodyText confidence="0.98008225">
The lower half of the table presents three axiom
patterns for making statements about classes and
individuals (a, b denote individuals); examples of
their usage are as follows:
</bodyText>
<listItem confidence="0.999681">
1. Admiral v ∃ CommanderOf.Fleet
2. Nelson ∈ Admiral
3. [Nelson, Trafalgar] ∈ IictorOf
</listItem>
<bodyText confidence="0.9963829375">
Note that since class expressions contain classes
as constituents, they can become indefinitely com-
plex. For instance, given the intersection A fl B
1If data properties are used, there will also be terms for
data types and literals (e.g., numbers and strings), but for sim-
plicity these are not considered here.
2In description logic notation, the constructor C u D
forms the intersection of two classes and corresponds to
Boolean conjunction, while the existential restriction ∃P.C
forms the class of individuals having the relation P to
one or more members of class C. Thus Person u ∃
CommanderOf.Fleet denotes the set of individuals x such
that x is a person and x commands one or more fleets.
we could replace atomic class A by a constructed
class, thus obtaining perhaps (A1 fl A2) fl B, and
so on ad infinitum. Moreover, since most axiom
patterns contain classes as constituents, they too
can become indefinitely complex.
This sketch of knowledge representation in
OWL illustrates the central distinction be-
tween logical functors (e.g., IntersectionOf,
SubClassOf), which belong to the W3C standard
(Motik et al., 2010), and atomic terms for in-
dividuals, classes and properties (e.g., Nelson,
Admiral, VictorOf). Perhaps the fundamental de-
sign decision of the Semantic Web is that all do-
main terms remain unstandardised, leaving ontol-
ogy developers free to conceptualise the domain
in any way they see fit. In the consensus verbali-
sation model, this distinction is reflected by divid-
ing linguistic resources into a generic grammar for
realising logical patterns, and an ontology-specific
lexicon for realising atomic terms.
Consider for instance C C D, the axiom pat-
tern for class inclusion. This purely logical pattern
can often be mapped (following ACE and SOS) to
the sentence pattern ‘Every [C] is a [D]’, where C
and D will be realised by count nouns from the
lexicon if they are atomic, or further grammatical
rules if they are complex. The more specific pat-
tern C C IP.D can be expressed better by a sen-
tence pattern based on a verb frame (‘Every [C]
[P]s a [D]’). All these mappings depend entirely
on the OWL logical functors, and will work with
any lexicalisation of atomic terms that respects the
syntactic constraints of the grammar, to yield ver-
balisations such as the following (for axioms 1-3
above):
</bodyText>
<listItem confidence="0.999585666666667">
1. Every admiral commands a fleet.
2. Nelson is an admiral.
3. Nelson is the victor of Trafalgar.
</listItem>
<bodyText confidence="0.999474142857143">
The CNLs we have cited are more sophisticated
than this, allowing a wider range of linguistic pat-
terns (e.g., adjectives for classes), but the basic
assumptions are the same. The model provides
satisfactory verbalisations for the simple examples
considered so far, but what happens when the ax-
ioms and atomic terms become more complex?
</bodyText>
<sectionHeader confidence="0.943971" genericHeader="method">
3 Complex terms and axioms
</sectionHeader>
<bodyText confidence="0.999045666666667">
The distribution of content among axioms depends
to some extent on stylistic decisions by ontol-
ogy developers, in particular with regard to ax-
</bodyText>
<page confidence="0.996119">
133
</page>
<bodyText confidence="0.995874210526316">
iom size. This freedom is possible because de-
scription logics (including OWL) allow equiva-
lent formulations using a large number of short
axioms at one extreme, and a small number of
long ones at the other. For many logical patterns,
rules can be stated for amalgamating or splitting
axioms while leaving overall content unchanged
(thus ensuring that exactly the same inferences are
drawn by a reasoning engine); such rules are often
used in reasoning algorithms. For instance, any set
of SubClassOf axioms can be amalgamated into
a single ‘metaconstraint’ (Horrocks, 1997) of the
form T C M, where T is the class containing
all individuals in the domain, and M is a class
to which any individual respecting the axiom set
must belong3. Applying this transformation even
to only two axioms (verbalised by 1 and 2 below)
will yield an outcome (verbalised by 3) that strains
human comprehension:
</bodyText>
<listItem confidence="0.9951336">
1. Every admiral is a sailor.
2. Every admiral commands a fleet.
3. Everything is (a) either a non-admiral or a sailor, and
(b) either a non-admiral or something that commands a
fleet.
</listItem>
<bodyText confidence="0.999941217391304">
An example of axiom-splitting rules is found in
a computational complexity proof for the descrip-
tion logic £G+ (Baader et al., 2005), which re-
quires class inclusion axioms to be rewritten to a
maximally simple ‘normal form’ permitting only
four patterns: A1 C A2, A1 F1 A2 C A3, A1 C
IP.A2, and IP.A1 C A2, where P and all AN
are atomic terms. However, this simplification of
axiom structure can be achieved only by introduc-
ing new atomic terms. For example, to simplify
an axiom of the form A1 C IP.(A2 F1 A3), the
rewriting rules must introduce a new term A23 �
A2 F1 A3, through which the axiom may be rewrit-
ten as A1 C IP.A23 (along with some further ax-
ioms expressing the definition of A23); depending
on the expressions that they replace, the content of
such terms may become indefinitely complex.
A trade-off therefore results. We can often find
rules for refactoring an overcomplex axiom by a
number of simpler ones, but only at the cost of in-
troducing atomic terms for which no satisfactory
lexical realisation may exist. In principle, there-
fore, there is no guarantee that OWL ontologies
</bodyText>
<footnote confidence="0.88597675">
3For an axiom set C1 C_ D1, C2 C_ D2 ..., M will be
(_C1 u D1) n (_C2 u D2) ..., where the class construc-
tors _C (complement of C) and C u D (union of C and D)
correspond to Boolean negation and disjunction.
</footnote>
<figureCaption confidence="0.99996">
Figure 1: Identifier content
</figureCaption>
<bodyText confidence="0.9776595">
can be verbalised transparently within the assump-
tions of the consensus model.
</bodyText>
<sectionHeader confidence="0.990661" genericHeader="method">
4 Empirical studies of usage
</sectionHeader>
<bodyText confidence="0.999984703703704">
We have shown that OWL syntax will permit
atomic terms that cannot be lexicalised, and ax-
ioms that cannot be expressed clearly in a sen-
tence. However, it remains possible that in prac-
tice, ontology developers use OWL in a con-
strained manner that favours verbalisation by the
consensus model. This could happen either be-
cause the relevant constraints are psychologically
intuitive to developers, or because they are some-
how built into the editing tools that they use
(e.g., Prot´eg´e). To investigate this possibility,
we have carried out an exploratory study using a
corpus of 48 ontologies mostly downloaded from
the University of Manchester TONES repository
(TONES, 2010). The corpus covers ontologies of
varying expressivity and subject-matter, including
some well-known tutorial examples (pets, pizzas)
and topics of general interest (photography, travel,
heraldry, wine), as well as some highly technical
scientific material (mosquito anatomy, worm on-
togeny, periodic table). Overall, our sample con-
tains around 45,000 axioms and 25,000 atomic
terms.
Our first analysis concerns identifier length,
which we measure simply by counting the num-
ber of words in the identifying phrase. The pro-
gram recovers the phrase by the following steps:
</bodyText>
<listItem confidence="0.994068333333333">
(1) read an identifier (or label if one is provided4);
(2) strip off the namespace prefix; (3) segment the
resulting string into words. For the third step we
</listItem>
<footnote confidence="0.99821925">
4Some ontology developers use ‘non-semantic’ identifiers
such as #000123, in which case the meaning of the identifier
is indicated in an annotation assertion linking the identifier to
a label.
</footnote>
<page confidence="0.992621">
134
</page>
<table confidence="0.9998615">
Pattern Frequency Percentage
CA v CA 18961 42.3%
CA u CA v ⊥ 8225 18.3%
CA v ∃PA.CA 6211 13.9%
[I, I] ∈ PA 4383 9.8%
[I, L] ∈ DA 1851 4.1%
I ∈ CA 1786 4.0%
CA ≡ CA u ∃PA.CA 500 1.1%
Other 2869 6.4%
Total 44786 100%
</table>
<tableCaption confidence="0.998352">
Table 2: Axiom pattern frequencies
</tableCaption>
<bodyText confidence="0.99641940625">
assume that word boundaries are marked either
by underline characters or by capital letters (e.g.,
battle of trafalgar, BattleOfTrafalgar), a
rule that holds (in our corpus) almost without ex-
ception. The analysis (figure 1) reveals that phrase
lengths are typically between one and four words
(this was true of over 95% of individuals, over
90% of classes, and over 98% of properties), as
in the following random selections:
Individuals: beaujolais region, beringer, blue
mountains, bondi beach
Classes: abi graph plot, amps block format, abat-
toir, abbey church
Properties: has activity, has address, has amino
acid, has aunt in law
Our second analysis concerns axiom patterns,
which we obtain by replacing all atomic terms
with a symbol meaning either individual, class,
property, datatype or literal. Thus for example the
axioms Admiral C Sailor and Dog C Animal
are both reduced to the form CA C CA, where
the symbol CA means ‘any atomic class term’. In
this way we can count the frequencies of all the
logical patterns in the corpus, abstracting from the
domain-specific identifier names. The results (ta-
ble 2) show an overwhelming focus on a small
number of simple logical patterns5. Concern-
ing class constructors, the most common by far
were intersection (C n C) and existential restric-
tion (IP.C); universal restriction (VP.C) was rel-
atively rare, so that for example the pattern CA C
VPA.CA occurred only 54 times (0.1%)6.
</bodyText>
<footnote confidence="0.8674318">
5Most of these patterns have been explained already; the
others are disjoint classes (CA uCA v ⊥), equivalent classes
(CA ≡ CA u ∃PA.CA) and data property assertion ([I, L] ∈
DA). In the latter pattern, DA denotes a data property, which
differs from an object property (PA) in that it ranges over
literals (L) rather than individuals (I).
6If C v ∃P.D means ‘Every admiral commands a fleet’,
C v ∀P.D will mean ‘Every admiral commands only fleets’
(this will remain true if some admirals do not command any-
thing at all).
</footnote>
<bodyText confidence="0.9998957">
The preference for simple patterns was con-
firmed by an analysis of argument struc-
ture for the OWL functors (e.g., SubClassOf,
IntersectionOf) that take classes as arguments.
Overall, 85% of arguments were atomic terms
rather than complex class expressions. Interest-
ingly, there was also a clear effect of argument po-
sition, with the first argument of a functor being
atomic rather than complex in as many as 99.4%
of cases7.
</bodyText>
<sectionHeader confidence="0.997999" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9997205">
Our results indicate that although in principle the
consensus model cannot guarantee transparent re-
alisations, in practice these are almost always at-
tainable, since ontology developers overwhelm-
ingly favour terms and axioms with relatively sim-
ple content. In an analysis of around 50 ontologies
we have found that over 90% of axioms fit a mere
seven patterns (table 2); the following examples
show that each of these patterns can be verbalised
by a clear unambiguous sentence – provided, of
course, that no problems arise in lexicalising the
atomic terms:
</bodyText>
<listItem confidence="0.96613775">
1. Every admiral is a sailor
2. No sailor is a landlubber
3. Every admiral commands a fleet
4. Nelson is the victor of Trafalgar
5. Trafalgar is dated 1805
6. Nelson is an admiral
7. An admiral is defined as a person that com-
mands a fleet
</listItem>
<bodyText confidence="0.992473153846154">
However, since identifiers containing 3-4 words
are fairly common (figure 1), we need to consider
whether these formulations will remain transpar-
ent when combined with more complex lexical en-
tries. For instance, a travel ontology in our cor-
pus contains an axiom (fitting pattern 4) which our
prototype verbalises as follows:
4’. West Yorkshire has as boundary the West
Yorkshire Greater Manchester Boundary Frag-
ment
The lexical entries here are far from ideal: ‘has
as boundary’ is clumsy, and ‘the West Yorkshire
Greater Manchester Boundary Fragment’ has as
</bodyText>
<footnote confidence="0.8757614">
7One explanation for this result could be that develop-
ers (or development tools) treat axioms as having a topic-
comment structure, where the topic is usually the first ar-
gument; we intend to investigate this possibility in a further
study.
</footnote>
<page confidence="0.997586">
135
</page>
<bodyText confidence="0.9999532">
many as six content words (and would benefit
from hyphens). We assess the sentence as ugly but
understandable, but to draw more definite conclu-
sions one would need to perform a different kind
of empirical study using human readers.
</bodyText>
<sectionHeader confidence="0.998616" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999977727272727">
We conclude (a) that existing ontologies can be
mostly verbalised using the consensus model, and
(b) that an editing tool based on relatively simple
linguistic patterns would not inconvenience on-
tology developers, but merely enforce constraints
that they almost always respect anyway. These
conclusions are based on analysis of identifier and
axiom patterns in a corpus of ontologies; they need
to be complemented by studies showing that the
resulting verbalisations are understood by ontol-
ogy developers and other users.
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99988">
The research described in this paper was un-
dertaken as part of the SWAT project (Seman-
tic Web Authoring Tool), which is supported by
the UK Engineering and Physical Sciences Re-
search Council (EPSRC) grants G033579/1 (Open
University) and G032459/1 (University of Manch-
ester). Thanks are due to the anonymous ACL re-
viewers and to colleagues on the SWAT project for
their comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998593" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999530175438597">
F. Baader, I. R. Horrocks, and U. Sattler. 2005. De-
scription logics as ontology languages for the se-
mantic web. Lecture Notes in Artificial Intelligence,
2605:228–248.
Anne Cregan, Rolf Schwitter, and Thomas Meyer.
2007. Sydney OWL Syntax - towards a Controlled
Natural Language Syntax for OWL 1.1. In OWLED.
Norbert Fuchs and Rolf Schwitter. 1995. Specifying
logic programs in controlled natural language. In
CLNLP-95.
Adam Funk, Valentin Tablan, Kalina Bontcheva,
Hamish Cunningham, Brian Davis, and Siegfried
Handschuh. 2007. CLOnE: Controlled Lan-
guage for Ontology Editing. In 6th Interna-
tional and 2nd Asian Semantic Web Conference
(ISWC2007+ASWC2007), pages 141–154, Novem-
ber.
Glen Hart, Martina Johnson, and Catherine Dolbear.
2008. Rabbit: Developing a control natural lan-
guage for authoring ontologies. In ESWC, pages
348–360.
Matthew Horridge, Nicholas Drummond, John Good-
win, Alan Rector, Robert Stevens, and Hai Wang.
2006. The Manchester OWL syntax. In OWL:
Experiences and Directions (OWLED’06), Athens,
Georgia. CEUR.
Ian Horrocks. 1997. Optimising Tableaux Decision
Procedures for Description Logics. Ph.D. thesis,
University of Manchester.
K. Kaljurand and N. Fuchs. 2007. Verbalizing OWL
in Attempto Controlled English. In Proceedings of
OWL: Experiences and Directions, Innsbruck, Aus-
tria.
Holger Knublauch, Ray W. Fergerson, Natalya Frid-
man Noy, and Mark A. Musen. 2004. The Prot´eg´e
OWL Plugin: An Open Development Environment
for Semantic Web Applications. In International Se-
mantic Web Conference, pages 229–243.
Boris Motik, Peter F. Patel-Schneider, and Bijan Par-
sia. 2010. OWL 2 web ontology language:
Structural specification and functional-style syn-
tax. http://www.w3.org/TR/owl2-syntax/. 21st
April 2010.
R. Schwitter and M. Tilbrook. 2004. Controlled nat-
ural language meets the semantic web. In Pro-
ceedings of the Australasian Language Technology
Workshop, pages 55–62, Macquarie University.
X. Sun and C. Mellish. 2006. Domain Independent
Sentence Generation from RDF Representations for
the Semantic Web. In Proceedings of the Combined
Workshop on Language-Enabled Educational Tech-
nology and Development and Evaluation of Robust
Spoken Dialogue Systems (ECAI06), Riva del Garda,
Italy.
TONES. 2010. The TONES ontology repository.
http://owl.cs.manchester.ac.uk/repository/browser.
Last accessed: 21st April 2010.
</reference>
<page confidence="0.998793">
136
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.700789">
<title confidence="0.999497">Complexity assumptions in ontology verbalisation</title>
<author confidence="0.999993">Richard Power</author>
<affiliation confidence="0.9914165">Department of Computing Open University, UK</affiliation>
<email confidence="0.995808">r.power@open.ac.uk</email>
<abstract confidence="0.981814625">We describe the strategy currently pursued for verbalising OWL ontologies by sentences in Controlled Natural Language combining for realising patterns with lexicons for realising atomic terms for individuals, classes, and properties) and argue that its success depends on assumptions about the complexity of terms and axioms in the ontology. We then show, through analysis of a corpus of ontologies, that although these assumptions could in principle be violated, they are overwhelmingly respected in practice by ontology developers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Baader</author>
<author>I R Horrocks</author>
<author>U Sattler</author>
</authors>
<title>Description logics as ontology languages for the semantic web.</title>
<date>2005</date>
<journal>Lecture Notes in Artificial Intelligence,</journal>
<pages>2605--228</pages>
<contexts>
<context position="9397" citStr="Baader et al., 2005" startWordPosition="1533" endWordPosition="1536">M, where T is the class containing all individuals in the domain, and M is a class to which any individual respecting the axiom set must belong3. Applying this transformation even to only two axioms (verbalised by 1 and 2 below) will yield an outcome (verbalised by 3) that strains human comprehension: 1. Every admiral is a sailor. 2. Every admiral commands a fleet. 3. Everything is (a) either a non-admiral or a sailor, and (b) either a non-admiral or something that commands a fleet. An example of axiom-splitting rules is found in a computational complexity proof for the description logic £G+ (Baader et al., 2005), which requires class inclusion axioms to be rewritten to a maximally simple ‘normal form’ permitting only four patterns: A1 C A2, A1 F1 A2 C A3, A1 C IP.A2, and IP.A1 C A2, where P and all AN are atomic terms. However, this simplification of axiom structure can be achieved only by introducing new atomic terms. For example, to simplify an axiom of the form A1 C IP.(A2 F1 A3), the rewriting rules must introduce a new term A23 � A2 F1 A3, through which the axiom may be rewritten as A1 C IP.A23 (along with some further axioms expressing the definition of A23); depending on the expressions that t</context>
</contexts>
<marker>Baader, Horrocks, Sattler, 2005</marker>
<rawString>F. Baader, I. R. Horrocks, and U. Sattler. 2005. Description logics as ontology languages for the semantic web. Lecture Notes in Artificial Intelligence, 2605:228–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Cregan</author>
<author>Rolf Schwitter</author>
<author>Thomas Meyer</author>
</authors>
<title>Sydney OWL Syntax - towards a Controlled Natural Language Syntax for OWL 1.1. In OWLED.</title>
<date>2007</date>
<contexts>
<context position="2374" citStr="Cregan et al., 2007" startWordPosition="367" endWordPosition="370">guages (Fuchs and Schwitter, 1995). The idea is to establish a mapping from a formal language to a natural subset of English, so that any sentence conforming to the Controlled Natural Language (CNL) can be assigned a single interpretation in the formal language — and conversely, any wellformed statement in the formal language can be realised in the CNL. With the advent of OWL, some of these CNLs were rapidly adapted to the new opportunity: part of Attempto Controlled English (ACE) was mapped to OWL (Kaljurand and Fuchs, 2007), and Processable English (PENG) evolved to Sydney OWL Syntax (SOS) (Cregan et al., 2007). In addition, new CNLs were developed specifically for editing OWL ontologies, such as Rabbit (Hart et al., 2008) and Controlled Language for Ontology Editing (CLOnE) (Funk et al., 2007). In detail, these CNLs display some variations: thus an inclusion relationship between the classes Admiral and Sailor would be expressed by the pattern ‘Admirals are a type of sailor’ in CLOnE, ‘Every admiral is a kind of sailor’ in Rabbit, and ‘Every admiral is a sailor’ in ACE and SOS. However, at the level of general strategy, all the CNLs rely on the same set of assumptions concerning the mapping from nat</context>
</contexts>
<marker>Cregan, Schwitter, Meyer, 2007</marker>
<rawString>Anne Cregan, Rolf Schwitter, and Thomas Meyer. 2007. Sydney OWL Syntax - towards a Controlled Natural Language Syntax for OWL 1.1. In OWLED.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norbert Fuchs</author>
<author>Rolf Schwitter</author>
</authors>
<title>Specifying logic programs in controlled natural language.</title>
<date>1995</date>
<booktitle>In CLNLP-95.</booktitle>
<contexts>
<context position="1788" citStr="Fuchs and Schwitter, 1995" startWordPosition="266" endWordPosition="269">ral research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support knowledge formation by automatic interpretation of texts authored in Controlled Natural Languages (Fuchs and Schwitter, 1995). The idea is to establish a mapping from a formal language to a natural subset of English, so that any sentence conforming to the Controlled Natural Language (CNL) can be assigned a single interpretation in the formal language — and conversely, any wellformed statement in the formal language can be realised in the CNL. With the advent of OWL, some of these CNLs were rapidly adapted to the new opportunity: part of Attempto Controlled English (ACE) was mapped to OWL (Kaljurand and Fuchs, 2007), and Processable English (PENG) evolved to Sydney OWL Syntax (SOS) (Cregan et al., 2007). In addition,</context>
</contexts>
<marker>Fuchs, Schwitter, 1995</marker>
<rawString>Norbert Fuchs and Rolf Schwitter. 1995. Specifying logic programs in controlled natural language. In CLNLP-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Funk</author>
<author>Valentin Tablan</author>
<author>Kalina Bontcheva</author>
<author>Hamish Cunningham</author>
<author>Brian Davis</author>
<author>Siegfried Handschuh</author>
</authors>
<title>CLOnE: Controlled Language for Ontology Editing.</title>
<date>2007</date>
<booktitle>In 6th International and 2nd Asian Semantic Web Conference (ISWC2007+ASWC2007),</booktitle>
<pages>141--154</pages>
<contexts>
<context position="2561" citStr="Funk et al., 2007" startWordPosition="397" endWordPosition="400">age (CNL) can be assigned a single interpretation in the formal language — and conversely, any wellformed statement in the formal language can be realised in the CNL. With the advent of OWL, some of these CNLs were rapidly adapted to the new opportunity: part of Attempto Controlled English (ACE) was mapped to OWL (Kaljurand and Fuchs, 2007), and Processable English (PENG) evolved to Sydney OWL Syntax (SOS) (Cregan et al., 2007). In addition, new CNLs were developed specifically for editing OWL ontologies, such as Rabbit (Hart et al., 2008) and Controlled Language for Ontology Editing (CLOnE) (Funk et al., 2007). In detail, these CNLs display some variations: thus an inclusion relationship between the classes Admiral and Sailor would be expressed by the pattern ‘Admirals are a type of sailor’ in CLOnE, ‘Every admiral is a kind of sailor’ in Rabbit, and ‘Every admiral is a sailor’ in ACE and SOS. However, at the level of general strategy, all the CNLs rely on the same set of assumptions concerning the mapping from natural to formal language; for convenience we will refer to these assumptions as the consensus model. In brief, the consensus model assumes that when an ontology is verbalised in natural la</context>
</contexts>
<marker>Funk, Tablan, Bontcheva, Cunningham, Davis, Handschuh, 2007</marker>
<rawString>Adam Funk, Valentin Tablan, Kalina Bontcheva, Hamish Cunningham, Brian Davis, and Siegfried Handschuh. 2007. CLOnE: Controlled Language for Ontology Editing. In 6th International and 2nd Asian Semantic Web Conference (ISWC2007+ASWC2007), pages 141–154, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glen Hart</author>
<author>Martina Johnson</author>
<author>Catherine Dolbear</author>
</authors>
<title>Rabbit: Developing a control natural language for authoring ontologies. In</title>
<date>2008</date>
<booktitle>ESWC,</booktitle>
<pages>348--360</pages>
<contexts>
<context position="1436" citStr="Hart et al., 2008" startWordPosition="215" endWordPosition="218">ought ways of mediating between the (decidedly cumbersome) raw code and the human users who aspire to view or edit it. Among the solutions that have been proposed are more readable coding formats such as Manchester OWL Syntax (Horridge et al., 2006), and graphical interfaces such as Prot´eg´e (Knublauch et al., 2004); more speculatively, several research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support knowledge formation by automatic interpretation of texts authored in Controlled Natural Languages (Fuchs and Schwitter, 1995). The idea is to establish a mapping from a formal language to a natural subset of English, so that any sentence conforming to the Controlled Natural Language (CNL) can be assigned a single interpretation in the formal language — and conversely, an</context>
</contexts>
<marker>Hart, Johnson, Dolbear, 2008</marker>
<rawString>Glen Hart, Martina Johnson, and Catherine Dolbear. 2008. Rabbit: Developing a control natural language for authoring ontologies. In ESWC, pages 348–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Horridge</author>
<author>Nicholas Drummond</author>
<author>John Goodwin</author>
<author>Alan Rector</author>
<author>Robert Stevens</author>
<author>Hai Wang</author>
</authors>
<date>2006</date>
<booktitle>The Manchester OWL syntax. In OWL: Experiences and Directions (OWLED’06),</booktitle>
<location>Athens, Georgia. CEUR.</location>
<contexts>
<context position="1067" citStr="Horridge et al., 2006" startWordPosition="157" endWordPosition="161">pends on assumptions about the complexity of terms and axioms in the ontology. We then show, through analysis of a corpus of ontologies, that although these assumptions could in principle be violated, they are overwhelmingly respected in practice by ontology developers. 1 Introduction Since OWL (Web Ontology Language) was adopted as a standard in 2004, researchers have sought ways of mediating between the (decidedly cumbersome) raw code and the human users who aspire to view or edit it. Among the solutions that have been proposed are more readable coding formats such as Manchester OWL Syntax (Horridge et al., 2006), and graphical interfaces such as Prot´eg´e (Knublauch et al., 2004); more speculatively, several research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support know</context>
</contexts>
<marker>Horridge, Drummond, Goodwin, Rector, Stevens, Wang, 2006</marker>
<rawString>Matthew Horridge, Nicholas Drummond, John Goodwin, Alan Rector, Robert Stevens, and Hai Wang. 2006. The Manchester OWL syntax. In OWL: Experiences and Directions (OWLED’06), Athens, Georgia. CEUR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian Horrocks</author>
</authors>
<title>Optimising Tableaux Decision Procedures for Description Logics.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Manchester.</institution>
<contexts>
<context position="8760" citStr="Horrocks, 1997" startWordPosition="1423" endWordPosition="1424">opers, in particular with regard to ax133 iom size. This freedom is possible because description logics (including OWL) allow equivalent formulations using a large number of short axioms at one extreme, and a small number of long ones at the other. For many logical patterns, rules can be stated for amalgamating or splitting axioms while leaving overall content unchanged (thus ensuring that exactly the same inferences are drawn by a reasoning engine); such rules are often used in reasoning algorithms. For instance, any set of SubClassOf axioms can be amalgamated into a single ‘metaconstraint’ (Horrocks, 1997) of the form T C M, where T is the class containing all individuals in the domain, and M is a class to which any individual respecting the axiom set must belong3. Applying this transformation even to only two axioms (verbalised by 1 and 2 below) will yield an outcome (verbalised by 3) that strains human comprehension: 1. Every admiral is a sailor. 2. Every admiral commands a fleet. 3. Everything is (a) either a non-admiral or a sailor, and (b) either a non-admiral or something that commands a fleet. An example of axiom-splitting rules is found in a computational complexity proof for the descri</context>
</contexts>
<marker>Horrocks, 1997</marker>
<rawString>Ian Horrocks. 1997. Optimising Tableaux Decision Procedures for Description Logics. Ph.D. thesis, University of Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kaljurand</author>
<author>N Fuchs</author>
</authors>
<title>Verbalizing OWL in Attempto Controlled English.</title>
<date>2007</date>
<booktitle>In Proceedings of OWL: Experiences and Directions,</booktitle>
<location>Innsbruck, Austria.</location>
<contexts>
<context position="1416" citStr="Kaljurand and Fuchs, 2007" startWordPosition="211" endWordPosition="214">in 2004, researchers have sought ways of mediating between the (decidedly cumbersome) raw code and the human users who aspire to view or edit it. Among the solutions that have been proposed are more readable coding formats such as Manchester OWL Syntax (Horridge et al., 2006), and graphical interfaces such as Prot´eg´e (Knublauch et al., 2004); more speculatively, several research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support knowledge formation by automatic interpretation of texts authored in Controlled Natural Languages (Fuchs and Schwitter, 1995). The idea is to establish a mapping from a formal language to a natural subset of English, so that any sentence conforming to the Controlled Natural Language (CNL) can be assigned a single interpretation in the formal language </context>
</contexts>
<marker>Kaljurand, Fuchs, 2007</marker>
<rawString>K. Kaljurand and N. Fuchs. 2007. Verbalizing OWL in Attempto Controlled English. In Proceedings of OWL: Experiences and Directions, Innsbruck, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Knublauch</author>
<author>Ray W Fergerson</author>
<author>Natalya Fridman Noy</author>
<author>Mark A Musen</author>
</authors>
<title>The Prot´eg´e OWL Plugin: An Open Development Environment for Semantic Web Applications.</title>
<date>2004</date>
<booktitle>In International Semantic Web Conference,</booktitle>
<pages>229--243</pages>
<contexts>
<context position="1136" citStr="Knublauch et al., 2004" startWordPosition="168" endWordPosition="171"> ontology. We then show, through analysis of a corpus of ontologies, that although these assumptions could in principle be violated, they are overwhelmingly respected in practice by ontology developers. 1 Introduction Since OWL (Web Ontology Language) was adopted as a standard in 2004, researchers have sought ways of mediating between the (decidedly cumbersome) raw code and the human users who aspire to view or edit it. Among the solutions that have been proposed are more readable coding formats such as Manchester OWL Syntax (Horridge et al., 2006), and graphical interfaces such as Prot´eg´e (Knublauch et al., 2004); more speculatively, several research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support knowledge formation by automatic interpretation of texts authored in Cont</context>
</contexts>
<marker>Knublauch, Fergerson, Noy, Musen, 2004</marker>
<rawString>Holger Knublauch, Ray W. Fergerson, Natalya Fridman Noy, and Mark A. Musen. 2004. The Prot´eg´e OWL Plugin: An Open Development Environment for Semantic Web Applications. In International Semantic Web Conference, pages 229–243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Motik</author>
<author>Peter F Patel-Schneider</author>
<author>Bijan Parsia</author>
</authors>
<title>web ontology language: Structural specification and functional-style syntax.</title>
<date>2010</date>
<journal>OWL</journal>
<booktitle>http://www.w3.org/TR/owl2-syntax/. 21st</booktitle>
<volume>2</volume>
<contexts>
<context position="6383" citStr="Motik et al., 2010" startWordPosition="1027" endWordPosition="1030">viduals having the relation P to one or more members of class C. Thus Person u ∃ CommanderOf.Fleet denotes the set of individuals x such that x is a person and x commands one or more fleets. we could replace atomic class A by a constructed class, thus obtaining perhaps (A1 fl A2) fl B, and so on ad infinitum. Moreover, since most axiom patterns contain classes as constituents, they too can become indefinitely complex. This sketch of knowledge representation in OWL illustrates the central distinction between logical functors (e.g., IntersectionOf, SubClassOf), which belong to the W3C standard (Motik et al., 2010), and atomic terms for individuals, classes and properties (e.g., Nelson, Admiral, VictorOf). Perhaps the fundamental design decision of the Semantic Web is that all domain terms remain unstandardised, leaving ontology developers free to conceptualise the domain in any way they see fit. In the consensus verbalisation model, this distinction is reflected by dividing linguistic resources into a generic grammar for realising logical patterns, and an ontology-specific lexicon for realising atomic terms. Consider for instance C C D, the axiom pattern for class inclusion. This purely logical pattern</context>
</contexts>
<marker>Motik, Patel-Schneider, Parsia, 2010</marker>
<rawString>Boris Motik, Peter F. Patel-Schneider, and Bijan Parsia. 2010. OWL 2 web ontology language: Structural specification and functional-style syntax. http://www.w3.org/TR/owl2-syntax/. 21st April 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schwitter</author>
<author>M Tilbrook</author>
</authors>
<title>Controlled natural language meets the semantic web.</title>
<date>2004</date>
<booktitle>In Proceedings of the Australasian Language Technology Workshop,</booktitle>
<pages>55--62</pages>
<institution>Macquarie University.</institution>
<contexts>
<context position="1366" citStr="Schwitter and Tilbrook, 2004" startWordPosition="202" endWordPosition="206">WL (Web Ontology Language) was adopted as a standard in 2004, researchers have sought ways of mediating between the (decidedly cumbersome) raw code and the human users who aspire to view or edit it. Among the solutions that have been proposed are more readable coding formats such as Manchester OWL Syntax (Horridge et al., 2006), and graphical interfaces such as Prot´eg´e (Knublauch et al., 2004); more speculatively, several research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support knowledge formation by automatic interpretation of texts authored in Controlled Natural Languages (Fuchs and Schwitter, 1995). The idea is to establish a mapping from a formal language to a natural subset of English, so that any sentence conforming to the Controlled Natural Language (CNL) can be assign</context>
</contexts>
<marker>Schwitter, Tilbrook, 2004</marker>
<rawString>R. Schwitter and M. Tilbrook. 2004. Controlled natural language meets the semantic web. In Proceedings of the Australasian Language Technology Workshop, pages 55–62, Macquarie University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Sun</author>
<author>C Mellish</author>
</authors>
<title>Domain Independent Sentence Generation from RDF Representations for the Semantic Web.</title>
<date>2006</date>
<booktitle>In Proceedings of the Combined Workshop on Language-Enabled Educational Technology and Development and Evaluation of Robust Spoken Dialogue Systems (ECAI06), Riva del Garda,</booktitle>
<location>Italy.</location>
<contexts>
<context position="1389" citStr="Sun and Mellish, 2006" startWordPosition="207" endWordPosition="210"> adopted as a standard in 2004, researchers have sought ways of mediating between the (decidedly cumbersome) raw code and the human users who aspire to view or edit it. Among the solutions that have been proposed are more readable coding formats such as Manchester OWL Syntax (Horridge et al., 2006), and graphical interfaces such as Prot´eg´e (Knublauch et al., 2004); more speculatively, several research groups have explored ways of mapping between OWL and controlled English, with the aim of presenting ontologies (both for viewing and editing) in natural language (Schwitter and Tilbrook, 2004; Sun and Mellish, 2006; Kaljurand and Fuchs, 2007; Hart et al., 2008). In this paper we uncover and test some assumptions on which this latter approach is based. Historically, ontology verbalisation evolved from a more general tradition (predating OWL and the Semantic Web) that aimed to support knowledge formation by automatic interpretation of texts authored in Controlled Natural Languages (Fuchs and Schwitter, 1995). The idea is to establish a mapping from a formal language to a natural subset of English, so that any sentence conforming to the Controlled Natural Language (CNL) can be assigned a single interpretat</context>
</contexts>
<marker>Sun, Mellish, 2006</marker>
<rawString>X. Sun and C. Mellish. 2006. Domain Independent Sentence Generation from RDF Representations for the Semantic Web. In Proceedings of the Combined Workshop on Language-Enabled Educational Technology and Development and Evaluation of Robust Spoken Dialogue Systems (ECAI06), Riva del Garda, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>TONES</author>
</authors>
<title>The TONES ontology repository. http://owl.cs.manchester.ac.uk/repository/browser. Last accessed: 21st</title>
<date>2010</date>
<contexts>
<context position="11381" citStr="TONES, 2010" startWordPosition="1883" endWordPosition="1884">annot be lexicalised, and axioms that cannot be expressed clearly in a sentence. However, it remains possible that in practice, ontology developers use OWL in a constrained manner that favours verbalisation by the consensus model. This could happen either because the relevant constraints are psychologically intuitive to developers, or because they are somehow built into the editing tools that they use (e.g., Prot´eg´e). To investigate this possibility, we have carried out an exploratory study using a corpus of 48 ontologies mostly downloaded from the University of Manchester TONES repository (TONES, 2010). The corpus covers ontologies of varying expressivity and subject-matter, including some well-known tutorial examples (pets, pizzas) and topics of general interest (photography, travel, heraldry, wine), as well as some highly technical scientific material (mosquito anatomy, worm ontogeny, periodic table). Overall, our sample contains around 45,000 axioms and 25,000 atomic terms. Our first analysis concerns identifier length, which we measure simply by counting the number of words in the identifying phrase. The program recovers the phrase by the following steps: (1) read an identifier (or labe</context>
</contexts>
<marker>TONES, 2010</marker>
<rawString>TONES. 2010. The TONES ontology repository. http://owl.cs.manchester.ac.uk/repository/browser. Last accessed: 21st April 2010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>