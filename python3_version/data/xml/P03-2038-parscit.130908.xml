<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.064384">
<title confidence="0.9796765">
An Intelligent Procedure Assistant
Built Using REGULUS 2 and ALTERF
</title>
<author confidence="0.997313">
Manny Rayner, Beth Ann Hockey, Jim Hieronymus, John Dowding, Greg Aist
</author>
<affiliation confidence="0.990084">
Research Institute for Advanced Computer Science (RIACS)
NASA Ames Research Center
</affiliation>
<address confidence="0.985762">
Moffet Field, CA 94035
</address>
<email confidence="0.999311">
{mrayner,bahockey,jimh,jdowding,aist}@riacs.edu
</email>
<author confidence="0.980677">
Susana Early
</author>
<affiliation confidence="0.943586">
DeAnza College/NASA Ames Research Center
</affiliation>
<email confidence="0.994666">
searly@mail.arc.nasa.gov
</email>
<sectionHeader confidence="0.942732" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999932034482759">
We will demonstrate the latest version of
an ongoing project to create an intelli-
gent procedure assistant for use by as-
tronauts on the International Space Sta-
tion (ISS). The system functionality in-
cludes spoken dialogue control of nav-
igation, coordinated display of the pro-
cedure text, display of related pictures,
alarms, and recording and playback of
voice notes. The demo also exempli-
fies several interesting component tech-
nologies. Speech recognition and lan-
guage understanding have been devel-
oped using the Open Source REGULUS
2 toolkit. This implements an approach
to portable grammar-based language mod-
elling in which all models are derived
from a single linguistically motivated uni-
fication grammar. Domain-specific CFG
language models are produced by first
specialising the grammar using an au-
tomatic corpus-based method, and then
compiling the resulting specialised gram-
mars into CFG form. Translation between
language centered and domain centered
semantic representations is carried out by
ALTERF, another Open Source toolkit,
which combines rule-based and corpus-
based processing in a transparent way.
</bodyText>
<sectionHeader confidence="0.999266" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942481481481">
Astronauts aboard the ISS spend a great deal of their
time performing complex procedures. This often in-
volves having one crew member reading the proce-
dure aloud, while while the other crew member per-
forms the task, an extremely expensive use of as-
tronaut time. The Intelligent Procedure Assistant is
designed to provide a cheaper alternative, whereby a
voice-controlled system navigates through the pro-
cedure under the control of the astronaut perform-
ing the task. This project has several challenging
features including: starting the project with no tran-
scribed data for the actual target input language, and
rapidly changing coverage and functionality. We
are using REGULUS 2 and ALTERF to address these
challenges. Together, they provide an example-
based framework for constructing the portion of the
system from recognizer through intepretation that
allows us to make rapid changes and take advan-
tage of both rule-base and corpus-based information
sources. In this way, we have been able to extract
maximum utility out of the small amounts of data
initial available to the project and also smoothly ad-
just as more data has been accumulated in the course
of the project.
The following sections describe the procedure as-
sistant application and domain, REGULUS 2 and AL-
TERF.
</bodyText>
<sectionHeader confidence="0.858389" genericHeader="introduction">
2 Application and domain
</sectionHeader>
<bodyText confidence="0.999778090909091">
The system, an early version of which was described
in (Aist et al., 2002), is a prototype intelligent voice
enabled personal assistant, intended to support astro-
nauts on the International Space Station in carrying
out complex procedures. The first production ver-
sion is tentatively scheduled for introduction some
time during 2004. The system reads out each pro-
cedure step as it reaches it, using a TTS engine, and
also shows the corresponding text and supplemen-
tary images in a visual display. Core functionality
consists of the following types of commands:
</bodyText>
<listItem confidence="0.972044607142857">
• Navigation: moving to the following step or
substep (“next”, “next step”, “next substep”),
going back to the preceding step or substep
(“previous”, “previous substep”), moving to a
named step or substep (“go to step three”, “go
to step ten point two”).
• Visiting non-current steps, either to preview fu-
ture steps or recall past ones (“read step four”,
“read note before step nine”). When this func-
tionality is invoked, the non-current step is dis-
played in a separate window, which is closed
on returning to the current step.
• Recording, playing and deleting voice notes
(“record voice note”, “play voice note on step
three point one”, “delete voice note on substep
two”).
• Setting and cancelling alarms (“set alarm for
five minutes from now”, “cancel alarm at ten
twenty one”).
• Showing or hiding pictures (“show the small
waste water bag”, “hide the picture”).
• Changing the TTS volume (“increase/decrease
volume”).
• Querying status (“where are we”, “list voice
notes”, “list alarms”).
• Undoing and correcting commands (“go back”,
“no I said increase volume”, “I meant step
four”).
</listItem>
<bodyText confidence="0.999832166666667">
The system consists of a set of modules, written
in several different languages, which communicate
with each other through the SRI Open Agent Ar-
chitecture (Martin et al., 1998). Speech recogni-
tion is carried out using the Nuance Toolkit (Nuance,
2003).
</bodyText>
<sectionHeader confidence="0.32988" genericHeader="method">
3 REGULUS2
</sectionHeader>
<bodyText confidence="0.9988949">
REGULUS 2 (Rayner et al., 2003; Regulus, 2003)
is an Open Source environment that supports effi-
cient compilation of typed unification grammars into
speech recognisers. The basic intent is to provide
a set of tools to support rapid prototyping of spo-
ken dialogue applications in situations where little
or no corpus data exists. The environment has al-
ready been used to build over half a dozen appli-
cations with vocabularies of between 100 and 500
words.
The core functionality provided by the REGU-
LUS 2 environment is compilation of typed unifi-
cation grammars into annotated context-free gram-
mar language models expressed in Nuance Gram-
mar Specification Language (GSL) notation (Nu-
ance, 2003). GSL language models can be con-
verted into runnable speech recognisers by invoking
the Nuance Toolkit compiler utility, so the net result
is the ability to compile a unification grammar into
a speech recogniser.
Experience with grammar-based spoken dialogue
systems shows that there is usually a substantial
overlap between the structures of grammars for dif-
ferent domains. This is hardly surprising, since they
all ultimately have to model general facts about the
linguistic structure of English and other natural lan-
guages. It is consequently natural to consider strate-
gies which attempt to exploit the overlap between
domains by building a single, general grammar valid
for a wide variety of applications. A grammar of this
kind will probably offer more coverage (and hence
lower accuracy) than is desirable for any given spe-
cific application. It is however feasible to address
the problem using corpus-based techniques which
extract a specialised version of the original general
grammar.
REGULUS implements a version of the grammar
specialisation scheme which extends the Explana-
tion Based Learning method described in (Rayner
et al., 2002). There is a general unification gram-
mar, loosely based on the Core Language Engine
grammar for English (Pulman, 1992), which has
been developed over the course of about ten individ-
ual projects. The semantic representations produced
by the grammar are in a simplified version of the
Core Language Engine’s Quasi Logical Form nota-
tion (van Eijck and Moore, 1992).
A grammar built on top of the general grammar is
transformed into a specialised Nuance grammar in
the following processing stages:
</bodyText>
<listItem confidence="0.9986141">
1. The training corpus is converted into a “tree-
bank” of parsed representations. This is done
using a left-corner parser representation of the
grammar.
2. The treebank is used to produce a specialised
grammar in REGULUS format, using the EBL
algorithm (van Harmelen and Bundy, 1988;
Rayner, 1988).
3. The final specialised grammar is compiled into
a Nuance GSL grammar.
</listItem>
<sectionHeader confidence="0.980883" genericHeader="method">
4 ALTERF
</sectionHeader>
<bodyText confidence="0.9980902">
ALTERF (Rayner and Hockey, 2003) is another Open
Source toolkit, whose purpose is to allow a clean
combination of rule-based and corpus-driven pro-
cessing in the semantic interpretation phase. There
is typically no corpus data available at the start
of a project, but considerable amounts at the end:
the intention behind ALTERF is to allow us to shift
smoothly from an initial version of the system which
is entirely rule-based, to a final version which is
largely data-driven.
ALTERF characterises semantic analysis as a task
slightly extending the “decision-list” classification
algorithm (Yarowsky, 1994; Carter, 2000). We start
with a set of semantic atoms, each representing a
primitive domain concept, and define a semantic
representation to be a non-empty set of semantic
atoms. For example, in the procedure assistant do-
main we represent the utterances
please speak up
show me the sample syringe
set an alarm for five minutes from now
no i said go to the next step
respectively as
{increase volume}
{show, sample syringe}
{set alarm, 5, minutes}
{correction, next step}
where increase volume, show,
sample syringe, set alarm, 5, minutes,
correction and next step are semantic
atoms. As well as specifying the permitted semantic
atoms themselves, we also define a target model
which for each atom specifies the other atoms with
which it may legitimately combine. Thus here, for
example, correction may legitimately combine
with any atom, but minutes may only combine
with correction, set alarm or a number.l.
Training data consists of a set of utterances, in
either text or speech form, each tagged with its in-
tended semantic representation. We define a set of
feature extraction rules, each of which associates an
utterance with zero or more features. Feature ex-
traction rules can carry out any type of processing.
In particular, they may involve performing speech
recognition on speech data, parsing on text data, ap-
plication of hand-coded rules to the results of pars-
ing, or some combination of these. Statistics are
then compiled to estimate the probability p(a  |f)
of each semantic atom a given each separate feature
f, using the standard formula
</bodyText>
<equation confidence="0.778303">
p(a  |f) = (NY + 1)/(Nf + 2)
</equation>
<bodyText confidence="0.98030536">
where Nf is the number of occurrences in the train-
ing data of utterances with feature f, and Nf� is the
number of occurrences of utterances with both fea-
ture f and semantic atom a.
The decoding process follows (Yarowsky, 1994)
in assuming complete dependence between the fea-
tures. Note that this is in sharp contrast with the
Naive Bayes classifier (Duda et al., 2000), which as-
sumes complete independence. Of course, neither
assumption can be true in practice; however, as ar-
gued in (Carter, 2000), there are good reasons for
preferring the dependence alternative as the better
option in a situation where there are many features
extracted in ways that are likely to overlap.
We are given an utterance u, to which we wish to
assign a representation R(u) consisting of a set of
semantic atoms, together with a target model com-
prising a set of rules defining which sets of seman-
&apos;The current system post-processes Alterf semantic atom
lists to represent domain dependancies between semantic
atoms more directly before passing on the result. e.g.
(correction, set alarm, 5, minutes) is repack-
aged as (correction(set alarm(time(0,5))))
tic atoms are consistent. The decoding process pro-
ceeds as follows:
</bodyText>
<listItem confidence="0.995176277777778">
1. Initialise R(u) to the empty set.
2. Use the feature extraction rules and the statis-
tics compiled during training to find the set of
all triples (f, a, p) where f is a feature associ-
ated with u, a is a semantic atom, and p is the
probability p(a  |f) estimated by the training
process.
3. Order the set of triples by the value of p, with
the largest probabilities first. Call the ordered
set T.
4. Remove the highest-ranked triple (f, a, p) from
T. Add a to R(u) iff the following conditions
are fulfilled:
• p &gt; pt for some pre-specified threshold
value pt.
• Addition of a to R(u) results in a set
which is consistent with the target model.
5. Repeat step (4) until T is empty.
</listItem>
<bodyText confidence="0.99977675">
Intuitively, the process is very simple. We just
walk down the list of possible semantic atoms, start-
ing with the most probable ones, and add them to
the semantic representation we are building up when
this does not conflict with the consistency rules in
the target model. We stop when the atoms suggested
are too improbable, that is, they have probabilies be-
low a cut-off threshold.
</bodyText>
<sectionHeader confidence="0.985987" genericHeader="conclusions">
5 Summary and structure of demo
</sectionHeader>
<bodyText confidence="0.999934125">
We have described a non-trivial spoken language di-
alogue application built using generic Open Source
tools that combine rule-based and corpus-driven
processing. We intend to demo the system with par-
ticular reference to these tools, displaying intermedi-
ate results of processing and showing how the cover-
age can be rapidly reconfigured in an example-based
fashion.
</bodyText>
<sectionHeader confidence="0.998387" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999567865384616">
G. Aist, J. Dowding, B.A. Hockey, and J. Hieronymus.
2002. An intelligent procedure assistant for astro-
naut training and support. In Proceedings of the 40th
Annual Meeting of the Association for Computational
Linguistics (demo track), Philadelphia, PA.
D. Carter. 2000. Choosing between interpretations. In
M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and
M. Wir´en, editors, The Spoken Language Translator.
Cambridge University Press.
R.O. Duda, P.E. Hart, and H.G. Stork. 2000. Pattern
Classification. Wiley, New York.
D. Martin, A. Cheyer, and D. Moran. 1998. Building
distributed software systems with the open agent ar-
chitecture. In Proceedings of the Third International
Conference on the Practical Application of Intelligent
Agents and Multi-Agent Technology, Blackpool, Lan-
cashire, UK.
Nuance, 2003. http://www.nuance.com. As of 25 Febru-
ary 2003.
S.G. Pulman. 1992. Syntactic and semantic process-
ing. In H. Alshawi, editor, The Core Language En-
gine, pages 129–148. MIT Press, Cambridge, Mas-
sachusetts.
M. Rayner and B.A. Hockey. 2003. Transparent com-
bination of rule-based and data-driven approaches in a
speech understanding architecture. In Proceedings of
the 10th EACL, Budapest, Hungary.
M. Rayner, B.A. Hockey, and J. Dowding. 2002. Gram-
mar specialisation meets language modelling. In Pro-
ceedings of the 7th International Conference on Spo-
ken Language Processing (ICSLP), Denver, CO.
M. Rayner, B.A. Hockey, and J. Dowding. 2003. An
open source environment for compiling typed unifica-
tion grammars into speech recognisers. In Proceed-
ings of the 10th EACL (demo track), Budapest, Hun-
gary.
M. Rayner. 1988. Applying explanation-based general-
ization to natural-language processing. In Proceedings
of the International Conference on Fifth Generation
Computer Systems, pages 1267–1274, Tokyo, Japan.
Regulus, 2003. http://sourceforge.net/projects/regulus/.
As of 24 April 2003.
J. van Eijck and R. Moore. 1992. Semantic rules for
English. In H. Alshawi, editor, The Core Language
Engine, pages 83–116. MIT Press.
T. van Harmelen and A. Bundy. 1988. Explanation-
based generalization = partial evaluation (research
note). Artificial Intelligence, 36:401–412.
D. Yarowsky. 1994. Decision lists for lexical ambiguity
resolution. In Proceedings of the 32nd Annual Meet-
ing of the Association for Computational Linguistics,
pages 88–95, Las Cruces, New Mexico.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.970254">
<title confidence="0.9991275">An Intelligent Procedure Assistant Using</title>
<author confidence="0.999883">Manny Rayner</author>
<author confidence="0.999883">Beth Ann Hockey</author>
<author confidence="0.999883">Jim Hieronymus</author>
<author confidence="0.999883">John Dowding</author>
<author confidence="0.999883">Greg Aist</author>
<affiliation confidence="0.9990485">Research Institute for Advanced Computer Science (RIACS) NASA Ames Research Center</affiliation>
<address confidence="0.999705">Moffet Field, CA 94035</address>
<author confidence="0.995917">Susana Early</author>
<affiliation confidence="0.994149">DeAnza College/NASA Ames Research Center</affiliation>
<email confidence="0.995121">searly@mail.arc.nasa.gov</email>
<abstract confidence="0.9996146">We will demonstrate the latest version of an ongoing project to create an intelligent procedure assistant for use by astronauts on the International Space Station (ISS). The system functionality includes spoken dialogue control of navigation, coordinated display of the procedure text, display of related pictures, alarms, and recording and playback of voice notes. The demo also exemplifies several interesting component technologies. Speech recognition and language understanding have been develusing the Open Source 2 toolkit. This implements an approach to portable grammar-based language modelling in which all models are derived from a single linguistically motivated unification grammar. Domain-specific CFG language models are produced by first specialising the grammar using an automatic corpus-based method, and then compiling the resulting specialised grammars into CFG form. Translation between language centered and domain centered semantic representations is carried out by another Open Source toolkit, which combines rule-based and corpusbased processing in a transparent way.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Aist</author>
<author>J Dowding</author>
<author>B A Hockey</author>
<author>J Hieronymus</author>
</authors>
<title>An intelligent procedure assistant for astronaut training and support.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (demo track),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2883" citStr="Aist et al., 2002" startWordPosition="434" endWordPosition="437"> framework for constructing the portion of the system from recognizer through intepretation that allows us to make rapid changes and take advantage of both rule-base and corpus-based information sources. In this way, we have been able to extract maximum utility out of the small amounts of data initial available to the project and also smoothly adjust as more data has been accumulated in the course of the project. The following sections describe the procedure assistant application and domain, REGULUS 2 and ALTERF. 2 Application and domain The system, an early version of which was described in (Aist et al., 2002), is a prototype intelligent voice enabled personal assistant, intended to support astronauts on the International Space Station in carrying out complex procedures. The first production version is tentatively scheduled for introduction some time during 2004. The system reads out each procedure step as it reaches it, using a TTS engine, and also shows the corresponding text and supplementary images in a visual display. Core functionality consists of the following types of commands: • Navigation: moving to the following step or substep (“next”, “next step”, “next substep”), going back to the pre</context>
</contexts>
<marker>Aist, Dowding, Hockey, Hieronymus, 2002</marker>
<rawString>G. Aist, J. Dowding, B.A. Hockey, and J. Hieronymus. 2002. An intelligent procedure assistant for astronaut training and support. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (demo track), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Carter</author>
</authors>
<title>Choosing between interpretations.</title>
<date>2000</date>
<editor>In M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and M. Wir´en, editors,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="8056" citStr="Carter, 2000" startWordPosition="1260" endWordPosition="1261">Rayner and Hockey, 2003) is another Open Source toolkit, whose purpose is to allow a clean combination of rule-based and corpus-driven processing in the semantic interpretation phase. There is typically no corpus data available at the start of a project, but considerable amounts at the end: the intention behind ALTERF is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to a final version which is largely data-driven. ALTERF characterises semantic analysis as a task slightly extending the “decision-list” classification algorithm (Yarowsky, 1994; Carter, 2000). We start with a set of semantic atoms, each representing a primitive domain concept, and define a semantic representation to be a non-empty set of semantic atoms. For example, in the procedure assistant domain we represent the utterances please speak up show me the sample syringe set an alarm for five minutes from now no i said go to the next step respectively as {increase volume} {show, sample syringe} {set alarm, 5, minutes} {correction, next step} where increase volume, show, sample syringe, set alarm, 5, minutes, correction and next step are semantic atoms. As well as specifying the perm</context>
<context position="10120" citStr="Carter, 2000" startWordPosition="1607" endWordPosition="1608"> |f) of each semantic atom a given each separate feature f, using the standard formula p(a |f) = (NY + 1)/(Nf + 2) where Nf is the number of occurrences in the training data of utterances with feature f, and Nf� is the number of occurrences of utterances with both feature f and semantic atom a. The decoding process follows (Yarowsky, 1994) in assuming complete dependence between the features. Note that this is in sharp contrast with the Naive Bayes classifier (Duda et al., 2000), which assumes complete independence. Of course, neither assumption can be true in practice; however, as argued in (Carter, 2000), there are good reasons for preferring the dependence alternative as the better option in a situation where there are many features extracted in ways that are likely to overlap. We are given an utterance u, to which we wish to assign a representation R(u) consisting of a set of semantic atoms, together with a target model comprising a set of rules defining which sets of seman&apos;The current system post-processes Alterf semantic atom lists to represent domain dependancies between semantic atoms more directly before passing on the result. e.g. (correction, set alarm, 5, minutes) is repackaged as (</context>
</contexts>
<marker>Carter, 2000</marker>
<rawString>D. Carter. 2000. Choosing between interpretations. In M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and M. Wir´en, editors, The Spoken Language Translator. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R O Duda</author>
<author>P E Hart</author>
<author>H G Stork</author>
</authors>
<title>Pattern Classification.</title>
<date>2000</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="9990" citStr="Duda et al., 2000" startWordPosition="1584" endWordPosition="1587"> hand-coded rules to the results of parsing, or some combination of these. Statistics are then compiled to estimate the probability p(a |f) of each semantic atom a given each separate feature f, using the standard formula p(a |f) = (NY + 1)/(Nf + 2) where Nf is the number of occurrences in the training data of utterances with feature f, and Nf� is the number of occurrences of utterances with both feature f and semantic atom a. The decoding process follows (Yarowsky, 1994) in assuming complete dependence between the features. Note that this is in sharp contrast with the Naive Bayes classifier (Duda et al., 2000), which assumes complete independence. Of course, neither assumption can be true in practice; however, as argued in (Carter, 2000), there are good reasons for preferring the dependence alternative as the better option in a situation where there are many features extracted in ways that are likely to overlap. We are given an utterance u, to which we wish to assign a representation R(u) consisting of a set of semantic atoms, together with a target model comprising a set of rules defining which sets of seman&apos;The current system post-processes Alterf semantic atom lists to represent domain dependanc</context>
</contexts>
<marker>Duda, Hart, Stork, 2000</marker>
<rawString>R.O. Duda, P.E. Hart, and H.G. Stork. 2000. Pattern Classification. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Martin</author>
<author>A Cheyer</author>
<author>D Moran</author>
</authors>
<title>Building distributed software systems with the open agent architecture.</title>
<date>1998</date>
<booktitle>In Proceedings of the Third International Conference on the Practical Application of Intelligent Agents and Multi-Agent Technology,</booktitle>
<location>Blackpool, Lancashire, UK.</location>
<contexts>
<context position="4637" citStr="Martin et al., 1998" startWordPosition="718" endWordPosition="721">oice note on substep two”). • Setting and cancelling alarms (“set alarm for five minutes from now”, “cancel alarm at ten twenty one”). • Showing or hiding pictures (“show the small waste water bag”, “hide the picture”). • Changing the TTS volume (“increase/decrease volume”). • Querying status (“where are we”, “list voice notes”, “list alarms”). • Undoing and correcting commands (“go back”, “no I said increase volume”, “I meant step four”). The system consists of a set of modules, written in several different languages, which communicate with each other through the SRI Open Agent Architecture (Martin et al., 1998). Speech recognition is carried out using the Nuance Toolkit (Nuance, 2003). 3 REGULUS2 REGULUS 2 (Rayner et al., 2003; Regulus, 2003) is an Open Source environment that supports efficient compilation of typed unification grammars into speech recognisers. The basic intent is to provide a set of tools to support rapid prototyping of spoken dialogue applications in situations where little or no corpus data exists. The environment has already been used to build over half a dozen applications with vocabularies of between 100 and 500 words. The core functionality provided by the REGULUS 2 environme</context>
</contexts>
<marker>Martin, Cheyer, Moran, 1998</marker>
<rawString>D. Martin, A. Cheyer, and D. Moran. 1998. Building distributed software systems with the open agent architecture. In Proceedings of the Third International Conference on the Practical Application of Intelligent Agents and Multi-Agent Technology, Blackpool, Lancashire, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance</author>
</authors>
<title>http://www.nuance.com.</title>
<date>2003</date>
<journal>As of</journal>
<volume>25</volume>
<contexts>
<context position="4712" citStr="Nuance, 2003" startWordPosition="732" endWordPosition="733">inutes from now”, “cancel alarm at ten twenty one”). • Showing or hiding pictures (“show the small waste water bag”, “hide the picture”). • Changing the TTS volume (“increase/decrease volume”). • Querying status (“where are we”, “list voice notes”, “list alarms”). • Undoing and correcting commands (“go back”, “no I said increase volume”, “I meant step four”). The system consists of a set of modules, written in several different languages, which communicate with each other through the SRI Open Agent Architecture (Martin et al., 1998). Speech recognition is carried out using the Nuance Toolkit (Nuance, 2003). 3 REGULUS2 REGULUS 2 (Rayner et al., 2003; Regulus, 2003) is an Open Source environment that supports efficient compilation of typed unification grammars into speech recognisers. The basic intent is to provide a set of tools to support rapid prototyping of spoken dialogue applications in situations where little or no corpus data exists. The environment has already been used to build over half a dozen applications with vocabularies of between 100 and 500 words. The core functionality provided by the REGULUS 2 environment is compilation of typed unification grammars into annotated context-free</context>
</contexts>
<marker>Nuance, 2003</marker>
<rawString>Nuance, 2003. http://www.nuance.com. As of 25 February 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S G Pulman</author>
</authors>
<title>Syntactic and semantic processing.</title>
<date>1992</date>
<booktitle>The Core Language Engine,</booktitle>
<pages>129--148</pages>
<editor>In H. Alshawi, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="6680" citStr="Pulman, 1992" startWordPosition="1042" endWordPosition="1043">, general grammar valid for a wide variety of applications. A grammar of this kind will probably offer more coverage (and hence lower accuracy) than is desirable for any given specific application. It is however feasible to address the problem using corpus-based techniques which extract a specialised version of the original general grammar. REGULUS implements a version of the grammar specialisation scheme which extends the Explanation Based Learning method described in (Rayner et al., 2002). There is a general unification grammar, loosely based on the Core Language Engine grammar for English (Pulman, 1992), which has been developed over the course of about ten individual projects. The semantic representations produced by the grammar are in a simplified version of the Core Language Engine’s Quasi Logical Form notation (van Eijck and Moore, 1992). A grammar built on top of the general grammar is transformed into a specialised Nuance grammar in the following processing stages: 1. The training corpus is converted into a “treebank” of parsed representations. This is done using a left-corner parser representation of the grammar. 2. The treebank is used to produce a specialised grammar in REGULUS form</context>
</contexts>
<marker>Pulman, 1992</marker>
<rawString>S.G. Pulman. 1992. Syntactic and semantic processing. In H. Alshawi, editor, The Core Language Engine, pages 129–148. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
</authors>
<title>Transparent combination of rule-based and data-driven approaches in a speech understanding architecture.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th EACL,</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="7467" citStr="Rayner and Hockey, 2003" startWordPosition="1168" endWordPosition="1171">e Core Language Engine’s Quasi Logical Form notation (van Eijck and Moore, 1992). A grammar built on top of the general grammar is transformed into a specialised Nuance grammar in the following processing stages: 1. The training corpus is converted into a “treebank” of parsed representations. This is done using a left-corner parser representation of the grammar. 2. The treebank is used to produce a specialised grammar in REGULUS format, using the EBL algorithm (van Harmelen and Bundy, 1988; Rayner, 1988). 3. The final specialised grammar is compiled into a Nuance GSL grammar. 4 ALTERF ALTERF (Rayner and Hockey, 2003) is another Open Source toolkit, whose purpose is to allow a clean combination of rule-based and corpus-driven processing in the semantic interpretation phase. There is typically no corpus data available at the start of a project, but considerable amounts at the end: the intention behind ALTERF is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to a final version which is largely data-driven. ALTERF characterises semantic analysis as a task slightly extending the “decision-list” classification algorithm (Yarowsky, 1994; Carter, 2000). We start </context>
</contexts>
<marker>Rayner, Hockey, 2003</marker>
<rawString>M. Rayner and B.A. Hockey. 2003. Transparent combination of rule-based and data-driven approaches in a speech understanding architecture. In Proceedings of the 10th EACL, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>J Dowding</author>
</authors>
<title>Grammar specialisation meets language modelling.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP),</booktitle>
<location>Denver, CO.</location>
<contexts>
<context position="6562" citStr="Rayner et al., 2002" startWordPosition="1021" endWordPosition="1024">. It is consequently natural to consider strategies which attempt to exploit the overlap between domains by building a single, general grammar valid for a wide variety of applications. A grammar of this kind will probably offer more coverage (and hence lower accuracy) than is desirable for any given specific application. It is however feasible to address the problem using corpus-based techniques which extract a specialised version of the original general grammar. REGULUS implements a version of the grammar specialisation scheme which extends the Explanation Based Learning method described in (Rayner et al., 2002). There is a general unification grammar, loosely based on the Core Language Engine grammar for English (Pulman, 1992), which has been developed over the course of about ten individual projects. The semantic representations produced by the grammar are in a simplified version of the Core Language Engine’s Quasi Logical Form notation (van Eijck and Moore, 1992). A grammar built on top of the general grammar is transformed into a specialised Nuance grammar in the following processing stages: 1. The training corpus is converted into a “treebank” of parsed representations. This is done using a left</context>
</contexts>
<marker>Rayner, Hockey, Dowding, 2002</marker>
<rawString>M. Rayner, B.A. Hockey, and J. Dowding. 2002. Grammar specialisation meets language modelling. In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP), Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>B A Hockey</author>
<author>J Dowding</author>
</authors>
<title>An open source environment for compiling typed unification grammars into speech recognisers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 10th EACL (demo track),</booktitle>
<location>Budapest, Hungary.</location>
<contexts>
<context position="4755" citStr="Rayner et al., 2003" startWordPosition="738" endWordPosition="741">n twenty one”). • Showing or hiding pictures (“show the small waste water bag”, “hide the picture”). • Changing the TTS volume (“increase/decrease volume”). • Querying status (“where are we”, “list voice notes”, “list alarms”). • Undoing and correcting commands (“go back”, “no I said increase volume”, “I meant step four”). The system consists of a set of modules, written in several different languages, which communicate with each other through the SRI Open Agent Architecture (Martin et al., 1998). Speech recognition is carried out using the Nuance Toolkit (Nuance, 2003). 3 REGULUS2 REGULUS 2 (Rayner et al., 2003; Regulus, 2003) is an Open Source environment that supports efficient compilation of typed unification grammars into speech recognisers. The basic intent is to provide a set of tools to support rapid prototyping of spoken dialogue applications in situations where little or no corpus data exists. The environment has already been used to build over half a dozen applications with vocabularies of between 100 and 500 words. The core functionality provided by the REGULUS 2 environment is compilation of typed unification grammars into annotated context-free grammar language models expressed in Nuanc</context>
</contexts>
<marker>Rayner, Hockey, Dowding, 2003</marker>
<rawString>M. Rayner, B.A. Hockey, and J. Dowding. 2003. An open source environment for compiling typed unification grammars into speech recognisers. In Proceedings of the 10th EACL (demo track), Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
</authors>
<title>Applying explanation-based generalization to natural-language processing.</title>
<date>1988</date>
<booktitle>In Proceedings of the International Conference on Fifth Generation Computer Systems,</booktitle>
<pages>1267--1274</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="7352" citStr="Rayner, 1988" startWordPosition="1151" endWordPosition="1152">ividual projects. The semantic representations produced by the grammar are in a simplified version of the Core Language Engine’s Quasi Logical Form notation (van Eijck and Moore, 1992). A grammar built on top of the general grammar is transformed into a specialised Nuance grammar in the following processing stages: 1. The training corpus is converted into a “treebank” of parsed representations. This is done using a left-corner parser representation of the grammar. 2. The treebank is used to produce a specialised grammar in REGULUS format, using the EBL algorithm (van Harmelen and Bundy, 1988; Rayner, 1988). 3. The final specialised grammar is compiled into a Nuance GSL grammar. 4 ALTERF ALTERF (Rayner and Hockey, 2003) is another Open Source toolkit, whose purpose is to allow a clean combination of rule-based and corpus-driven processing in the semantic interpretation phase. There is typically no corpus data available at the start of a project, but considerable amounts at the end: the intention behind ALTERF is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to a final version which is largely data-driven. ALTERF characterises semantic analysis </context>
</contexts>
<marker>Rayner, 1988</marker>
<rawString>M. Rayner. 1988. Applying explanation-based generalization to natural-language processing. In Proceedings of the International Conference on Fifth Generation Computer Systems, pages 1267–1274, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regulus</author>
</authors>
<title>http://sourceforge.net/projects/regulus/.</title>
<date>2003</date>
<journal>As of</journal>
<volume>24</volume>
<contexts>
<context position="4771" citStr="Regulus, 2003" startWordPosition="742" endWordPosition="743">wing or hiding pictures (“show the small waste water bag”, “hide the picture”). • Changing the TTS volume (“increase/decrease volume”). • Querying status (“where are we”, “list voice notes”, “list alarms”). • Undoing and correcting commands (“go back”, “no I said increase volume”, “I meant step four”). The system consists of a set of modules, written in several different languages, which communicate with each other through the SRI Open Agent Architecture (Martin et al., 1998). Speech recognition is carried out using the Nuance Toolkit (Nuance, 2003). 3 REGULUS2 REGULUS 2 (Rayner et al., 2003; Regulus, 2003) is an Open Source environment that supports efficient compilation of typed unification grammars into speech recognisers. The basic intent is to provide a set of tools to support rapid prototyping of spoken dialogue applications in situations where little or no corpus data exists. The environment has already been used to build over half a dozen applications with vocabularies of between 100 and 500 words. The core functionality provided by the REGULUS 2 environment is compilation of typed unification grammars into annotated context-free grammar language models expressed in Nuance Grammar Specif</context>
</contexts>
<marker>Regulus, 2003</marker>
<rawString>Regulus, 2003. http://sourceforge.net/projects/regulus/. As of 24 April 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van Eijck</author>
<author>R Moore</author>
</authors>
<title>Semantic rules for English. In</title>
<date>1992</date>
<booktitle>The Core Language Engine,</booktitle>
<pages>83--116</pages>
<editor>H. Alshawi, editor,</editor>
<publisher>MIT Press.</publisher>
<marker>van Eijck, Moore, 1992</marker>
<rawString>J. van Eijck and R. Moore. 1992. Semantic rules for English. In H. Alshawi, editor, The Core Language Engine, pages 83–116. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T van Harmelen</author>
<author>A Bundy</author>
</authors>
<title>Explanationbased generalization = partial evaluation (research note).</title>
<date>1988</date>
<journal>Artificial Intelligence,</journal>
<pages>36--401</pages>
<marker>van Harmelen, Bundy, 1988</marker>
<rawString>T. van Harmelen and A. Bundy. 1988. Explanationbased generalization = partial evaluation (research note). Artificial Intelligence, 36:401–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Decision lists for lexical ambiguity resolution.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--95</pages>
<location>Las Cruces, New Mexico.</location>
<contexts>
<context position="8041" citStr="Yarowsky, 1994" startWordPosition="1258" endWordPosition="1259"> ALTERF ALTERF (Rayner and Hockey, 2003) is another Open Source toolkit, whose purpose is to allow a clean combination of rule-based and corpus-driven processing in the semantic interpretation phase. There is typically no corpus data available at the start of a project, but considerable amounts at the end: the intention behind ALTERF is to allow us to shift smoothly from an initial version of the system which is entirely rule-based, to a final version which is largely data-driven. ALTERF characterises semantic analysis as a task slightly extending the “decision-list” classification algorithm (Yarowsky, 1994; Carter, 2000). We start with a set of semantic atoms, each representing a primitive domain concept, and define a semantic representation to be a non-empty set of semantic atoms. For example, in the procedure assistant domain we represent the utterances please speak up show me the sample syringe set an alarm for five minutes from now no i said go to the next step respectively as {increase volume} {show, sample syringe} {set alarm, 5, minutes} {correction, next step} where increase volume, show, sample syringe, set alarm, 5, minutes, correction and next step are semantic atoms. As well as spec</context>
<context position="9848" citStr="Yarowsky, 1994" startWordPosition="1562" endWordPosition="1563"> any type of processing. In particular, they may involve performing speech recognition on speech data, parsing on text data, application of hand-coded rules to the results of parsing, or some combination of these. Statistics are then compiled to estimate the probability p(a |f) of each semantic atom a given each separate feature f, using the standard formula p(a |f) = (NY + 1)/(Nf + 2) where Nf is the number of occurrences in the training data of utterances with feature f, and Nf� is the number of occurrences of utterances with both feature f and semantic atom a. The decoding process follows (Yarowsky, 1994) in assuming complete dependence between the features. Note that this is in sharp contrast with the Naive Bayes classifier (Duda et al., 2000), which assumes complete independence. Of course, neither assumption can be true in practice; however, as argued in (Carter, 2000), there are good reasons for preferring the dependence alternative as the better option in a situation where there are many features extracted in ways that are likely to overlap. We are given an utterance u, to which we wish to assign a representation R(u) consisting of a set of semantic atoms, together with a target model com</context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>D. Yarowsky. 1994. Decision lists for lexical ambiguity resolution. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pages 88–95, Las Cruces, New Mexico.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>