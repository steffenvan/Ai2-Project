<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006640">
<title confidence="0.9946495">
The Multimedia Articulation of Answers in a Natural
Language Database Query System
</title>
<author confidence="0.987491">
Susan E. Brennan
</author>
<affiliation confidence="0.805715666666667">
Stanford University
and
Hewlett Packard Labs
</affiliation>
<address confidence="0.844233">
1501 Page Mill Road
Palo Alto, CA 94304
</address>
<sectionHeader confidence="0.987751" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999602111111111">
This paper describes a domain independent strategy
for the multimedia articulation of answers elicited by
a natural language interface to database query ap-
plications. Multimedia answers include videodisc im-
ages and heuristically-produced complete sentences
in text or text-to-speech form. Deictic reference and
feedback about the discourse are enabled. The inter-
face thus presents the application as cooperative and
conversational.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999857952380953">
It is useful to evaluate human-computer communica-
tion in light of Grice&apos;s cooperative principle and max-
ims [Gri75]. Recently there has been much interest
in a &amp;quot;cooperative response&amp;quot; paradigm for interfaces
to database query and expert systems [Ste87]. The
most promising strategies in this area of investigation
involve applying insights gained from psycholinguis-
tics research in order to create better conversational
human/computer interfaces. However, inventing ad-
equate user modeling and inferencing systems for this
purpose is no easy task, and much of the literature
on the subject describes proposals for systems yet
unimplemented or theoretical approaches which may
depend heavily on a particular domain model. Our
multimedia articulator consists of principled solutions
which have been implemented in a domain indepen-
dent manner and which produce answers that are rea-
sonably relevant, informative, and conversational in
style. Such a system makes it possible to begin to
study users interacting with a question-answering ap-
plication.
</bodyText>
<sectionHeader confidence="0.973174" genericHeader="method">
2 System overview
</sectionHeader>
<bodyText confidence="0.999951818181818">
The system described here functions as a conversa-
tional human/computer interface to database query
systems. It consists of a natural language front end
and a module which articulates multimedia answers.
The system accepts well-formed strings as input;
these sentences are interpreted by an HPSG-based
parser [PS871 which produces a parse tree. After fur-
ther processing by a semantics module, a pragmatics
processor [BFP87] and a disambiguator, a logical for-
mula in the language NFLT [CP85] is produced. This
formula is transduced into a database query. Two
database query formats are currently supported: a
frame-based representation language, HPRL, and the
standard relational database query language, SQL.
Answers returned from the database are then pack-
aged appropriately by the articulator for presentation
to the user.
The two database applications currently supported
are a database of people and equipment (a subset
of which we have proposed as a natural language
evaluation test suite [FNSW87]), and a database of
paintings by 19th century Dutch artist Vincent Van
</bodyText>
<page confidence="0.975641">
1
</page>
<bodyText confidence="0.9998146">
Gogh and his contemporaries. The latter database
was based on the index to a commercially available
videodisc [Nim82] and augmented from other sources.
Both applications can be run on workstations config-
ured with or without multimedia output devices.
</bodyText>
<sectionHeader confidence="0.979599" genericHeader="method">
3 Database answer format
</sectionHeader>
<bodyText confidence="0.999969238095238">
The driver of a database query application (i.e. the
domain dependent part of the system) is responsible
for returning answers in a list format which consists of
a keyword specifying the type of the answer, followed
by the answer itself. The answer types expected by
the articulator are boolean, number, item, set, quan-
tity, and table.
In deciding how to package a response, the articu-
lator uses the answer type along with additional in-
formation provided by the parser which identifies the
illocutionary act of a query as imperative, declara-
tive, yes/no question, or wh-question. An answer
is presented textually as a single phrase, as a com-
plete sentence which parallels the user&apos;s query, or
as a table. In addition, depending on answer type
and the system&apos;s hardware configuration, an answer
may include videodisc images, text-to-speech, icons
and maps. While a user can request answers in a
particular medium via menus, a default strategy is
in place which yields a fairly satisfying style of hu-
man/computer interaction.
</bodyText>
<sectionHeader confidence="0.954036" genericHeader="method">
4 Text answers
</sectionHeader>
<subsectionHeader confidence="0.99529">
4.1 Style
</subsectionHeader>
<bodyText confidence="0.999951525423729">
Questions and answers are a common kind of adja-
cency pair in human language use. The preferred
style of an answer is often elliptical and shows paral-
lelism with the surface syntactic structure of the pre-
ceding question [CC77]. In addition, lexical choice
in the answer is constrained by that in the question.
An answer which is articulated using different lexical
entries than its projecting question may lead the user
to infer that the system is making a distinction when
it is in fact only using a synonym.
Although elliptical answers may be the norm in hu-
man/human conversation, the articulator described
here defaults to &amp;quot;verbose mode&amp;quot;; it responds to most
queries with complete sentence answers. The moti-
vation for this approach arose when we noticed that
shorter answers were unsatisfying in certain situa-
tions. When additional textual material intervenes
on the user&apos;s screen after the input query is typed in
and before the answer appears, and in other cases
where the user is distracted or not watching the
screen when the textual answer arrives, a short an-
swer takes on something of the character of a non-
sequitur. This problem manifested itself in an early
version of our system that worked by having users
send queries over the network via electronic mail to
a single natural language server which in due time
mailed its responses back to the user, and also in
the current system, which returns most answers in
a few seconds but can be operated in a mode which
prints modular timing and status information during
processing. Even more unsatisfying was the articula-
tion of answers using text-to-speech hardware. Gen-
erated speech is often hard for users to understand
[TRC84] and in our system, short answers delivered
this way often failed even to attract a user&apos;s atten-
tion as information-bearing. To echo the query au-
dibly seemed confusing; what was needed was the
capability to frame the answer in a complete sen-
tence based on the query. The final impetus for
the verbose articulator was our desire to approxi-
mate some of the effects that real natural language
generation capability might provide in a question-
answering human/computer interface, before com-
mitting resources to a full-scale natural language gen-
eration effort.
In verbose mode, a sentential answer consists sim-
ply of a string derived from the formatted database
answer with constituents of the user&apos;s original query
wrapped around it. Articulation achieves the dual
purposes of satisfying the user&apos;s request for informa-
tion while preserving a conversational style of inter-
action (figure 1). It is interesting to compare these
answers with the kind of paraphrasing capacity that
one finds in some other systems which are commer-
cially available (figure 2).
To paraphrase a user&apos;s query in a form that reflects
the actual database access method (figure 1) can be
extremely helpful in identifying misinterpretations of
the query. However, that approach may interfere with
</bodyText>
<page confidence="0.996264">
2
</page>
<table confidence="0.961959714285714">
User: Who has a terminal? Sentence: How many employees are there?
System: DAN FLICKINGER HAS A TERMINAL. Answer list: (NUMBER 4 (NAMELY {abrams}
Figure 1: Adjacency pair Articulated: {chiang} {devito} {browne}))
THERE ARE 4 EMPLOYEES -
NAMELY, IRA ABRAMS, LYN
CHIANG, KAT DEVITO, AND
DEREK BROWNE.
</table>
<bodyText confidence="0.921202666666667">
User: Who has a terminal?
System: Shall I do the following? Create a
report showing the full name and
the manager and the equipment from
the forms on which the equipment
includes &amp;quot;TERMINAL&amp;quot;?&amp;quot;
</bodyText>
<figureCaption confidence="0.994082">
Figure 2: Dialogue from Q&amp;A [Hen8
</figureCaption>
<bodyText confidence="0.99998305">
natural interaction by insisting that the user confirm
his or her every conversational move. Furthermore,
whether the system&apos;s interpretation of what the user
meant by the query with respect to the database is
a correct mapping or not, the user is forced to re-
formulate his or her question in a program-like or
logical form. Such an interface imposes a significant
cognitive load on the user. Presumably, a central mo-
tivation for providing a natural language interface to
a database is to avoid forcing the user to use a for-
eign language. This strategy pays homage to Grice&apos;s
maxim of manner, &amp;quot;avoid obscurity of expression&amp;quot;.
On the other hand, the argument has been made
that separate, non-equivalent representations provid-
ing different views of the world should be maintained
by the system [5pa83]; each of these views should
be available to the user at appropriate times. Thus
logical paraphrases, desirable in establishing initial
system credibility, should be available upon specific
request by the user.
</bodyText>
<subsectionHeader confidence="0.997663">
4.2 &amp;quot;Namely&amp;quot; answers
</subsectionHeader>
<bodyText confidence="0.999646166666667">
Grice&apos;s maxim of quantity for cooperative communi-
cation is a reminder that it is frequently desirable to
provide more information in an answer than was lit-
erally requested. For example, when a user asks &amp;quot;Are
there any secretaries?&amp;quot; the best answer may be not
&amp;quot;Yes&amp;quot;, but &amp;quot;Yes - namely, X, Y, and Z&amp;quot; (where X,
</bodyText>
<figureCaption confidence="0.992267">
Figure 3: &amp;quot;Namely&amp;quot; answer
</figureCaption>
<bodyText confidence="0.99996385">
Y, and Z are the names of the secretaries). Several
question-answering systems have addressed issues of
this sort [WMJB83] [WJMM82]. While our system
does not explicitly model the user&apos;s goals or know
anything about indirect speech acts, it provides ex-
tended answers to some queries via a list containing
the keyword namely, which appears as the last item
in the answer list passed to the articulator (figure 3).
Extended answer lists are constructed as follows.
When an answer is of type number and its cardinal-
ity is below a certain threshold, or else when it is
both of type boo lean and affirmative, the articulator
makes an additional query to the database which re-
turns information for constructing the &amp;quot;namely&amp;quot; an-
swer. This additional information is combined with
the short answer to the user&apos;s original query, to cre-
ate an extended answer. In this way we attempt to
comply with Grice&apos;s maxims of manner and quan-
tity: to &amp;quot;be brief&apos; and to &amp;quot;make your contribution as
informative as is required&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.999358">
4.3 Verbose mode
</subsectionHeader>
<bodyText confidence="0.999977692307692">
Verbose mode works as follows. Initially, a short an-
swer string is created from the formatted list that the
database returns. First, the type keyword is stripped
off the answer list. Depending on the type, the re-
maining short answer list is transformed into a string
which is a textual phrase consisting of one of the fol-
lowing: a name or names (for type set or item the
database is queried and returns appropriate nouns
or proper names), a string containing an integer (for
type number), a string containing a number followed
by units of measure (for type quantity), or the strings
&amp;quot;yes&amp;quot; or &amp;quot;no&amp;quot; (for type boolean). Set answers are
expanded into coordinated noun phrases with appro-
</bodyText>
<page confidence="0.994934">
3
</page>
<bodyText confidence="0.99966985106383">
priate punctuation. If the type is table, a table is
produced.
In constructing the short answers to wh-questions,
some simple additional heuristics are used. First, if
the short answer string was derived from a null set
or null item, the answer is converted from the empty
string to an appropriate string: &amp;quot;nowhere&amp;quot; if the wh-
question word is &amp;quot;where&amp;quot;, &amp;quot;never&amp;quot; for &amp;quot;when&amp;quot;,
body&apos;s&amp;quot; for &amp;quot;whose&amp;quot;, and either &amp;quot;none&amp;quot; or else &amp;quot;no&amp;quot;
plus the string corresponding to the modified NP
head for &amp;quot;which&amp;quot;, &amp;quot;what&amp;quot; or &amp;quot;how many&amp;quot; phrases.
Otherwise, when the answer is not an empty set and
the wh-question word is &amp;quot;whose&amp;quot;, &amp;quot; &apos;s&amp;quot; is appended
to the answer. When &amp;quot;whose&amp;quot; modifies the head of
a noun phrase, the noun phrase is appended to the
answer.
Then, once the short answer has been produced, if
the query is not an imperative (and the answer is
not a table), the input query&apos;s parse tree represen-
tation is transformed into a template with which to
frame the short answer. Four functions traverse the
parse tree and return strings corresponding to con-
stituents from the input query: these constituents
are subject, auxiliary verb (if there is one), main verb
phrase, and preposition (if the wh-question word is
within a prepositional phrase or fills a trace in one).
An end-of-sentence string is created which contains,
simply, terminating punctuation, or else an expanded
phrase consisting of &amp;quot;namely,&amp;quot; followed by a coor-
dinated noun phrase with appropriate punctuation.
This expanded phrase is constructed whenever a
short to medium-length namely list is available at the
end of an answer list, as shown in figure 3.
Finally, the verbose answer string is constructed us-
ing one of two strategies: if the wh-question word
is in subject position in the query, the constituents
are positioned in the answer as follows, (the items
in parentheses may or may not be present): answer
(aux-verb) (main-verb-phrase) (preposition) end-of-
sentence; if the wh-question word is in non-subject
position, the positioning is: subject (aux-verb) main-
verb-phrase (preposition) answer end-of-sentence.
If the query is a declarative or a yes/no question, a
boolean answer results. When a boolean answer is af-
firmative, the string &amp;quot;yes,&amp;quot; with the modified input
string appended, is articulated. For negative boolean
answers, if the input string contains an auxiliary verb,
</bodyText>
<table confidence="0.6882878">
Sentence: Does Ira program?
Answer list: (BOOLEAN NIL)
Articulated: NO, IRA DOES NOT PROGRAM.
Figure 4: Negation
Sentence: Are there any consultants?
Answer list: (BOOLEAN T (NAMELY {WASOW}
{SAG}))
Articulated: YES, THERE ARE SOME
CONSULTANTS - NAMELY,
TOM WASOW AND IVAN SAG.
Sentence: Will any consultants work
for Kat?
Answer list: (BOOLEAN NIL)
Articulated: NO, NO CONSULTANTS WILL WORK
FOR KAT.
</table>
<figureCaption confidence="0.983197">
Figure 5: Some/any
</figureCaption>
<bodyText confidence="0.982615695652174">
the following sequence is articulated: &amp;quot;No,&amp;quot; sub-
ject aux-verb &amp;quot;not&amp;quot; main-verb-phrase end-of-sentence
(figure 4). If there is no auxiliary verb in the nega-
tive answer, the canned phrase &amp;quot;No, it is not true
that,&amp;quot; with the original input string appended, is ar-
ticulated. In addition, a some/any transformation is
applied to yes/no questions. &amp;quot;Any of&amp;quot; is replaced by
&amp;quot;none of&amp;quot; or &amp;quot;some of&amp;quot;, depending on whether the
answer is affirmative or negative. If the input query
contains an auxiliary verb and the word &amp;quot;any&amp;quot; with-
out &amp;quot;of&amp;quot;, &amp;quot;any&amp;quot; is replaced by &amp;quot;no&amp;quot; or &amp;quot;some&amp;quot; (figure
5). If the constructed answer template contains suc-
cessive double negatives (as might result from a query
containing a negation), these are removed.
Finally, contrast the situation where the answer list
is (BOOLEAN NIL) with the one where the answer
list is simply NIL (which means the database failed to
return an answer). In this case, the system answers &amp;quot;I
don&apos;t know whether&amp;quot; with the modified input query
appended (figure 6).
The style of the articulator&apos;s verbose responses, while
somewhat quaint, appears cooperative because the
answer is delivered using the same lexical and syn-
</bodyText>
<page confidence="0.997582">
4
</page>
<table confidence="0.5972046875">
WHAT SELF-PORTRAITS DID
VAN GOGH PAINT?
(SET &amp;quot;F0296&amp;quot; &amp;quot;F0627&amp;quot; &amp;quot;F0622&amp;quot;)
VAN GOGH DID PAINT
SELF-PORTRAIT, SELF-PORTRAIT,
AND SELF-PORTRAIT
WITH GRAY FELT HAT.
Sentence: Do any vice presidents work? Sentence:
Answer list: NIL
Articulated: I DON&apos;T KNOW WHETHER ANY Answer list:
VICE PRESIDENTS DO WORK. Articulated:
Figure 6: Successful failure
Sentence: SHOW ME STARRY NIGHT.
Sentence: Which manager is Kat Devito? Answer list: (ITEM &amp;quot;F0612&amp;quot;)
Answer list: (ITEM) Articulated: STARRY NIGHT.
Articulated: KAT DEVITO IS NO MANAGER.
</table>
<figureCaption confidence="0.999557">
Figure 8: When words aren&apos;t enough
Figure 7: Pragmatic strangeness
</figureCaption>
<bodyText confidence="0.99997">
tactic forms that the user chooses in the query. Of
course, this technique of wrapping the query around
the answer works only in very simple question-
answering applications, where the system has little of
its own to say. Failure in the form of ungrammatical
answers to wh-questions sometimes occurs due to lack
of agreement; rather than extend the verbose articu-
lator any further, it seems a better strategy to simply
detect those cases and suppress an ungrammatical
verbose answer in favor of a short one. Pragmatic
failures that are still syntactically well-formed may
also occur, particularly in negative boolean answers
and empty set answers; we have not arrived at a con-
sistently successful strategy for detecting and treat-
ing presuppositional failures (figure 7). Our imple-
mentation also does not take into account syntactic
constraints on given/new information in framing the
answer in the query. Despite these limitations, the
appeal of verbose articulation argues for integrating
a real generation capability with a natural language
interface to database query.
</bodyText>
<sectionHeader confidence="0.999122" genericHeader="evaluation">
5 Multimedia
</sectionHeader>
<bodyText confidence="0.999221102564103">
While the articulator always manages to produce
some sort of textual answer, it is often desirable to
respond with an answer in a different medium (fig-
ure 8). Visual images from a videodisc can be dis-
played whenever item or set answers are associated
with videodisc frames in the database, in addition to
whenever an imperative is used to explicitly request
images.
The articulator consults a module called circus which
contains the drivers and methods pertaining to the
videodisc player and the text-to-speech hardware.
This module queries the database application to dis-
cover whether any entities in the answer list can be
displayed as videodisc images. These images are rep-
resented and accessed by videodisc frame numbers
which are stored in the database in SQL tables or in
HPRL slots.
When the system is configured with the text-to-
speech generator and the items in a set answer are
associated with videodisc images, the entire textual
answer is displayed first. Then a synchronizing func-
tion in circus articulates the items in the set by dis-
playing the approprate image on the video monitor
and speaking the corresponding items, one at a time.
Thus the user hears the name of an item spoken im-
mediately after it comes up on the video monitor;
videodisc images are displayed for a few seconds each.
We have not synchronized the textual answers with
the videodisc answers, since these media are displayed
on two separate screens at somewhat different rates
and it would be difficult for a user to attend simul-
taneously to both. Laser videodiscs in CAV format
(constant angular velocity) advertise fast, random ac-
cess to still images, yet with most videodisc players
there is some time cost to searching for frames on a
disc and for changing search direction. We minimize
this cost by reordering the items in the set according
to their videodisc frame numbers, which correspond
to their ordering on the disc.
</bodyText>
<page confidence="0.985995">
5
</page>
<bodyText confidence="0.999994183673469">
It seems appropriate to mention here that videodisc
imagery, like sex and violence, can be either gratu-
itous or meaningful. In the course of our project, we
have demonstrated both. In the context of our peo-
ple and equipment database, the articulator is capa-
ble of displaying a picture of a featureless cubicle or a
slide show of nervously posed employees in conjunc-
tion with a textual answer. On the other hand, the
database of Van Gogh paintings has proven to be a
very appealing application for visual articulation.
With visually articulated answers, we were provided
with an opportunity to begin to experiment with de-
ictic reference. While personal pronouns are inter-
preted by the pragmatics processor using a discourse
model which takes a centering approach [Gro77]
[Sid79] [JW81] [GJW83] [BFP87], demonstrative pro-
nouns are interpreted via a rudimentary environment
model that knows which painting is currently dis-
played on the video screen. Note that the displayed
image may not be the one currently under discussion
in the the discourse, but may be left over from an ear-
lier query if no intervening queries elicited videodisc
answers. Since imagery can be such a salient part
of the user&apos;s environment, it is necessary to support
deictic references to the current image. At present in
our system, &amp;quot;this&amp;quot; and &amp;quot;that&amp;quot; have the same interpre-
tation, but we are exploring alternatives such as inter-
preting &amp;quot;that&amp;quot; as referring to the previously displayed
image when it appears contrastively in the same con-
text as &amp;quot;this&amp;quot;. A more thorough treatment should of
course integrate spatial, temporal and discourse per-
spective [Lin79]. We are attempting to model more
of the visi:al environment, including graphic elements
on the screen, and to integrate deictic information
more fully into the discourse.
By now it should be evident that one should not con-
sider articulation of answers entirely independently
from discourse. A natural language interface to a
database query application can provide textual feed-
back about the discourse apart from the literal an-
swer. Our articulator makes explicit the interpre-
tation of the user&apos;s pronominal reference by sub-
stituting the phrase it cospecifies for the pronoun
in the verbose answer (figure 9). Thus the user
is likely to discover any misunderstanding instantly.
On the other hand, since verbose answers rely on
more or less blindly-applied heuristics to wrap text
around the answer, the articulator is not a full part-
ner in the discourse and is not capable of achieving
</bodyText>
<note confidence="0.989565166666667">
Q: What did Gauguin paint?
A: GAUGUIN PAINTED VINCENT PAINTING.
Q: How many pictures of Van Gogh were not
painted by him?
A: 8 PICTURES OF VAN GOGH WERE NOT PAINTED
BY GAUGUIN.
</note>
<figureCaption confidence="0.999803">
Figure 9: References made explicit
</figureCaption>
<bodyText confidence="0.999732">
subtle but nevertheless critical discourse functions
through syntactic choices. A true generation com-
ponent would presumably exercise lexical and syntax
choices, thus avoiding eccentric as well as ungram-
matical exchanges.
</bodyText>
<sectionHeader confidence="0.997473" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999984461538462">
Obviously there is much ground to be covered in the
areas of natural language communication and con-
versational human/computer interfaces. Yet interim
applications can be built which are incrementally im-
proved over previous ones. This approach is necessary
in order to observe real users of these systems.
The domain independent articulation strategy pre-
sented here enables two very different database query
systems to present answers conversationally. Gen-
erality is achieved through the use of answer type
keywords (provided by the application driver) and
the illocutionary act of the query (provided by the
parser). From this information, multimedia answers
are assembled and templates in which to frame the
textual answer are constructed from the input query.
Although it lacks inferencing ability, the articulator
described here provides several features desirable in a
cooperative interface. These features include answers
presented in a style that parallels the user&apos;s question,
extended answers, the ability to refer deictically to an
image, and explicit feedback regarding co-specifiers of
personal pronouns.
Finally, multimedia articulation provides serendipi-
tous opportunities for dispersing ambiguity, due to
multiple representation of the answer. Take the fol-
lowing query to our Van Gogh database: &amp;quot;Show
</bodyText>
<page confidence="0.996172">
6
</page>
<bodyText confidence="0.9999755">
me the pictures of Van Gogh that he didn&apos;t paint.&amp;quot;
The textual answer came back: &amp;quot;The pictures of
Van Gogh that Van Gogh didn&apos;t paint are Vincent
Painting and Self-Portrait.&amp;quot; As we puzzled over &amp;quot;Self-
Portrait&amp;quot; (how could a self portrait be of Van Gogh,
but not painted by him?) the videodisc answer was
displayed on the adjacent screen: first, a portrait of
Van Gogh that had been painted by his friend Gau-
guin, and — surprisingly — a self portrait of Van Gogh
that was not painted, but drawn.
</bodyText>
<sectionHeader confidence="0.998195" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999660333333333">
The work reported herein was jointly supported
by the National Science Foundation and Hewlett
Packard Labs. It was done in collaboration with
HPLab&apos;s Natural Language group. I would especially
like to thank Lew Creary, Dan Flickinger, Lyn Fried-
man and Herb Clark.
</bodyText>
<sectionHeader confidence="0.99817" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992998879310345">
[BFP87] S.E. Brennan, M.W. Friedman, and C.J.
Pollard. A centering approach to pro-
nouns. In Proc., 25st Annual Meeting
of the ACL, Association of Computa-
tional Linguistics, pages 155-162, Stan-
ford, CA, 1987.
[CC77] H.H. Clark and E.V. Clark. Psychol-
ogy and Language. Harcourt Brace Jo-
vanovich, Publishers, 1977.
[CP85]
[G3W83] B.J. Grosz, A.K. Joshi, and S. Weinstein.
Providing a unified account of definite
noun phrases in discourse. In Proc., 21st
Annual Meeting of the ACL, Association
of Computational Linguistics, pages 44-
50, Cambridge, MA, 1983.
[Gri75] H.P. Grice. Logic and conversation
(from the William James lectures, Har-
vard University, 1967). In P. Cole and J.
Morgan, editors, Syntax and Semantics
3: Speech Acts, pages 41-58, Academic
Press, Inc., 1975.
[Gro77] Barbara.J. Grosz. The representation
and use of focus in dialogue understand-
ing. Technical Report 151, SRI Inter-
national, 333 Ravenswood Ave, Menlo
Park, Ca. 94025, 1977.
[GS851 B.J. Grosz and C.L. Sidner. The struc-
ture of discourse structure. Technical
Report CSLI-85-39, Center for the Study
of Language and Information, Stanford,
CA, 1985.
[Hen851 G. Hendrix. Q&amp;A. Software, Symantec,
1985.
[J W81] A.K. Joshi and S. Weinstein. Control
of inference: role of some aspects of dis-
course structure - centering. In Proc.,
International Joint Conference on Arti-
ficial Intelligence, pages 385-387, Van-
couver, B.C., 1981.
[Kap82] S.J. Kaplan. Cooperative responses from
a portable natural language query sys-
tem. Artificial Intelligence, 2(19), 1982.
[KJM86] J. Kalita, M. Jobes, and G. McCalla.
Summarizing natural language database
responses. Computational Linguistics,
12(2):107-124, 1986.
C. Linde. Focus of attention and the
choice of pronouns in discourse. In T.
Givon, editor, Syntax and Semantics,
pages 337-354, Academic Press, Inc.,
1979.
[LS85] W.G. Lehnert and S.P. Schwartz. Data
base querying by computer. In A.C.
Graesser and J.B. Black, editors, The
Psychology of Questions, pages 359-374,
Lawrence Erlbaum Associates, Publish-
ers, 1985.
</reference>
<bodyText confidence="0.984724909090909">
L. Creary and C.J. Pollard. A computa-
tional semantics for natural language. In
Proc., 23st Annual Meeting of the ACL,
Association of Computational Linguis- [Lin79]
tics, pages 172-179, Chicago, IL, 1985.
[FNSW87] D.P. Flickinger, J. Nerbonne, I. Sag, and
T. Wasow. Toward evaluation of NLP
systems (in conjunction with panel). In
25st Annual Meeting of the ACL, As-
sociation of Computational Linguistics,
Stanford, CA, 1987.
</bodyText>
<page confidence="0.997286">
7
</page>
<reference confidence="0.999266022222222">
[Nim82] L. Nimoy. Vincent Van Gogh: a portrait NL interface to a vision system. In Proc.,
in two parts. Videodisc, Philips Interna- International Joint Conference on Arti-
tional/North American Philips Corpora- ficial Intelligence, pages 643-646, 1983.
tion, 1982.
[Po185] M. Pollack. Information sought and
information provided. In CHI &apos;85,
pages 155-160, San Francisco, CA, 1985.
[PS87] C. Pollard and I.A. Sag. Information-
Based Syntax and Semantics. Vol. I:
Fundamentals. (in press). Lecture notes
series no. 13, Center for the Study of
Language and Information, Stanford,
CA, 1987.
[Rei85] R. Reichman. Getting Computers to
Talk Like You and Me. MIT Press, Cam-
bridge, MA, 1985.
[Sid79] Candace L. Sidner. Toward a computa-
tional theory of definite anaphora com-
prehension in English. Technical Re-
port AI-TR-537, MIT, 1979.
[Sid81] C.L. Sidner. Focusing for interpreta-
tion of pronouns. American Journal
of Computational Linguistics, 7(4):217—
231, 1981.
[Spa83] K. Sparck-Jones. Shifting meaning rep-
resentations. In Proc., International
Joint Conference on Artificial Intelli-
gence, pages 621-623, 1983.
[Ste87] P. Stenton. Designing a co-operative in-
terface to an expert system. Technical
Report HPL-BRC-TM-87-023, HPLabs
Technical Memo, 1987.
[TRC84] J.C. Thomas, M.B. Rosson, and M.
Chodorow. Human factors and syn-
thetic speech. In Proc., INTERACT &apos;84,
pages 37-42, 1984.
[WJMM82] B. Webber, A. Joshi, E. Mays, and K.
McKeown. Extended natural language
data base interactions. International
Journal of Computers and Mathematics:
Special issue on computational linguis-
tics, 1982.
[WMJB83] W. Walster, H. Marburger, A. Jameson,
and S. Busemann. Over-answering yes-
no questions: extended responses in a
</reference>
<page confidence="0.998466">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.715548">
<title confidence="0.9982625">The Multimedia Articulation of Answers in a Natural Language Database Query System</title>
<author confidence="0.999958">Susan E Brennan</author>
<affiliation confidence="0.924703666666667">Stanford University and Hewlett Packard Labs</affiliation>
<address confidence="0.999576">1501 Page Mill Road Palo Alto, CA 94304</address>
<abstract confidence="0.9885945">This paper describes a domain independent strategy for the multimedia articulation of answers elicited by a natural language interface to database query applications. Multimedia answers include videodisc images and heuristically-produced complete sentences in text or text-to-speech form. Deictic reference and feedback about the discourse are enabled. The interface thus presents the application as cooperative and conversational.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S E Brennan</author>
<author>M W Friedman</author>
<author>C J Pollard</author>
</authors>
<title>A centering approach to pronouns.</title>
<date>1987</date>
<booktitle>In Proc., 25st Annual Meeting of the ACL, Association of Computational Linguistics,</booktitle>
<pages>155--162</pages>
<location>Stanford, CA,</location>
<contexts>
<context position="2123" citStr="[BFP87]" startWordPosition="309" endWordPosition="309">sonably relevant, informative, and conversational in style. Such a system makes it possible to begin to study users interacting with a question-answering application. 2 System overview The system described here functions as a conversational human/computer interface to database query systems. It consists of a natural language front end and a module which articulates multimedia answers. The system accepts well-formed strings as input; these sentences are interpreted by an HPSG-based parser [PS871 which produces a parse tree. After further processing by a semantics module, a pragmatics processor [BFP87] and a disambiguator, a logical formula in the language NFLT [CP85] is produced. This formula is transduced into a database query. Two database query formats are currently supported: a frame-based representation language, HPRL, and the standard relational database query language, SQL. Answers returned from the database are then packaged appropriately by the articulator for presentation to the user. The two database applications currently supported are a database of people and equipment (a subset of which we have proposed as a natural language evaluation test suite [FNSW87]), and a database of </context>
<context position="18944" citStr="[BFP87]" startWordPosition="3052" endWordPosition="3052">xt of our people and equipment database, the articulator is capable of displaying a picture of a featureless cubicle or a slide show of nervously posed employees in conjunction with a textual answer. On the other hand, the database of Van Gogh paintings has proven to be a very appealing application for visual articulation. With visually articulated answers, we were provided with an opportunity to begin to experiment with deictic reference. While personal pronouns are interpreted by the pragmatics processor using a discourse model which takes a centering approach [Gro77] [Sid79] [JW81] [GJW83] [BFP87], demonstrative pronouns are interpreted via a rudimentary environment model that knows which painting is currently displayed on the video screen. Note that the displayed image may not be the one currently under discussion in the the discourse, but may be left over from an earlier query if no intervening queries elicited videodisc answers. Since imagery can be such a salient part of the user&apos;s environment, it is necessary to support deictic references to the current image. At present in our system, &amp;quot;this&amp;quot; and &amp;quot;that&amp;quot; have the same interpretation, but we are exploring alternatives such as interp</context>
</contexts>
<marker>[BFP87]</marker>
<rawString>S.E. Brennan, M.W. Friedman, and C.J. Pollard. A centering approach to pronouns. In Proc., 25st Annual Meeting of the ACL, Association of Computational Linguistics, pages 155-162, Stanford, CA, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
<author>E V Clark</author>
</authors>
<title>Psychology and Language.</title>
<date>1977</date>
<publisher>Harcourt Brace Jovanovich, Publishers,</publisher>
<contexts>
<context position="4326" citStr="[CC77]" startWordPosition="663" endWordPosition="663">els the user&apos;s query, or as a table. In addition, depending on answer type and the system&apos;s hardware configuration, an answer may include videodisc images, text-to-speech, icons and maps. While a user can request answers in a particular medium via menus, a default strategy is in place which yields a fairly satisfying style of human/computer interaction. 4 Text answers 4.1 Style Questions and answers are a common kind of adjacency pair in human language use. The preferred style of an answer is often elliptical and shows parallelism with the surface syntactic structure of the preceding question [CC77]. In addition, lexical choice in the answer is constrained by that in the question. An answer which is articulated using different lexical entries than its projecting question may lead the user to infer that the system is making a distinction when it is in fact only using a synonym. Although elliptical answers may be the norm in human/human conversation, the articulator described here defaults to &amp;quot;verbose mode&amp;quot;; it responds to most queries with complete sentence answers. The motivation for this approach arose when we noticed that shorter answers were unsatisfying in certain situations. When ad</context>
</contexts>
<marker>[CC77]</marker>
<rawString>H.H. Clark and E.V. Clark. Psychology and Language. Harcourt Brace Jovanovich, Publishers, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Providing a unified account of definite noun phrases in discourse.</title>
<date>1983</date>
<booktitle>In Proc., 21st Annual Meeting of the ACL, Association of Computational Linguistics,</booktitle>
<pages>44--50</pages>
<location>Cambridge, MA,</location>
<marker>[G3W83]</marker>
<rawString>B.J. Grosz, A.K. Joshi, and S. Weinstein. Providing a unified account of definite noun phrases in discourse. In Proc., 21st Annual Meeting of the ACL, Association of Computational Linguistics, pages 44-50, Cambridge, MA, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<title>Logic and conversation (from the William James lectures,</title>
<date>1967</date>
<booktitle>Syntax and Semantics 3: Speech Acts,</booktitle>
<pages>41--58</pages>
<editor>In P. Cole and J. Morgan, editors,</editor>
<publisher>Academic Press, Inc.,</publisher>
<institution>Harvard University,</institution>
<contexts>
<context position="755" citStr="[Gri75]" startWordPosition="108" endWordPosition="108">1 Page Mill Road Palo Alto, CA 94304 Abstract This paper describes a domain independent strategy for the multimedia articulation of answers elicited by a natural language interface to database query applications. Multimedia answers include videodisc images and heuristically-produced complete sentences in text or text-to-speech form. Deictic reference and feedback about the discourse are enabled. The interface thus presents the application as cooperative and conversational. 1 Introduction It is useful to evaluate human-computer communication in light of Grice&apos;s cooperative principle and maxims [Gri75]. Recently there has been much interest in a &amp;quot;cooperative response&amp;quot; paradigm for interfaces to database query and expert systems [Ste87]. The most promising strategies in this area of investigation involve applying insights gained from psycholinguistics research in order to create better conversational human/computer interfaces. However, inventing adequate user modeling and inferencing systems for this purpose is no easy task, and much of the literature on the subject describes proposals for systems yet unimplemented or theoretical approaches which may depend heavily on a particular domain mod</context>
</contexts>
<marker>[Gri75]</marker>
<rawString>H.P. Grice. Logic and conversation (from the William James lectures, Harvard University, 1967). In P. Cole and J. Morgan, editors, Syntax and Semantics 3: Speech Acts, pages 41-58, Academic Press, Inc., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The representation and use of focus in dialogue understanding.</title>
<date>1977</date>
<tech>Technical Report 151, SRI International, 333 Ravenswood Ave, Menlo Park, Ca. 94025,</tech>
<institution>Center for</institution>
<location>Stanford, CA,</location>
<note>Hen851</note>
<contexts>
<context position="18913" citStr="[Gro77]" startWordPosition="3048" endWordPosition="3048">demonstrated both. In the context of our people and equipment database, the articulator is capable of displaying a picture of a featureless cubicle or a slide show of nervously posed employees in conjunction with a textual answer. On the other hand, the database of Van Gogh paintings has proven to be a very appealing application for visual articulation. With visually articulated answers, we were provided with an opportunity to begin to experiment with deictic reference. While personal pronouns are interpreted by the pragmatics processor using a discourse model which takes a centering approach [Gro77] [Sid79] [JW81] [GJW83] [BFP87], demonstrative pronouns are interpreted via a rudimentary environment model that knows which painting is currently displayed on the video screen. Note that the displayed image may not be the one currently under discussion in the the discourse, but may be left over from an earlier query if no intervening queries elicited videodisc answers. Since imagery can be such a salient part of the user&apos;s environment, it is necessary to support deictic references to the current image. At present in our system, &amp;quot;this&amp;quot; and &amp;quot;that&amp;quot; have the same interpretation, but we are explor</context>
</contexts>
<marker>[Gro77]</marker>
<rawString>Barbara.J. Grosz. The representation and use of focus in dialogue understanding. Technical Report 151, SRI International, 333 Ravenswood Ave, Menlo Park, Ca. 94025, 1977. [GS851 B.J. Grosz and C.L. Sidner. The structure of discourse structure. Technical Report CSLI-85-39, Center for the Study of Language and Information, Stanford, CA, 1985. [Hen851 G. Hendrix. Q&amp;A. Software, Symantec, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Control of inference: role of some aspects of discourse structure - centering.</title>
<date>1981</date>
<booktitle>In Proc., International Joint Conference on Artificial Intelligence,</booktitle>
<pages>385--387</pages>
<location>Vancouver, B.C.,</location>
<marker>[J W81]</marker>
<rawString>A.K. Joshi and S. Weinstein. Control of inference: role of some aspects of discourse structure - centering. In Proc., International Joint Conference on Artificial Intelligence, pages 385-387, Vancouver, B.C., 1981.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S J Kaplan</author>
</authors>
<title>Cooperative responses from a portable natural language query system.</title>
<journal>Artificial Intelligence,</journal>
<volume>2</volume>
<issue>19</issue>
<pages>1982</pages>
<marker>[Kap82]</marker>
<rawString>S.J. Kaplan. Cooperative responses from a portable natural language query system. Artificial Intelligence, 2(19), 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kalita</author>
<author>M Jobes</author>
<author>G McCalla</author>
</authors>
<title>Summarizing natural language database responses.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<booktitle>Syntax and Semantics,</booktitle>
<pages>12--2</pages>
<editor>C. Linde.</editor>
<publisher>Academic Press, Inc.,</publisher>
<marker>[KJM86]</marker>
<rawString>J. Kalita, M. Jobes, and G. McCalla. Summarizing natural language database responses. Computational Linguistics, 12(2):107-124, 1986. C. Linde. Focus of attention and the choice of pronouns in discourse. In T. Givon, editor, Syntax and Semantics, pages 337-354, Academic Press, Inc., 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W G Lehnert</author>
<author>S P Schwartz</author>
</authors>
<title>Data base querying by computer.</title>
<date>1985</date>
<booktitle>The Psychology of Questions,</booktitle>
<pages>359--374</pages>
<editor>In A.C. Graesser and J.B. Black, editors,</editor>
<publisher>Erlbaum Associates, Publishers,</publisher>
<location>Lawrence</location>
<marker>[LS85]</marker>
<rawString>W.G. Lehnert and S.P. Schwartz. Data base querying by computer. In A.C. Graesser and J.B. Black, editors, The Psychology of Questions, pages 359-374, Lawrence Erlbaum Associates, Publishers, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Nimoy</author>
</authors>
<title>Vincent Van Gogh: a portrait NL interface to a vision system. In</title>
<date>1983</date>
<booktitle>Proc., in two parts. Videodisc, Philips Interna- International Joint Conference on Artitional/North American Philips Corpora- ficial Intelligence,</booktitle>
<pages>643--646</pages>
<note>tion,</note>
<contexts>
<context position="2893" citStr="[Nim82]" startWordPosition="428" endWordPosition="428">urrently supported: a frame-based representation language, HPRL, and the standard relational database query language, SQL. Answers returned from the database are then packaged appropriately by the articulator for presentation to the user. The two database applications currently supported are a database of people and equipment (a subset of which we have proposed as a natural language evaluation test suite [FNSW87]), and a database of paintings by 19th century Dutch artist Vincent Van 1 Gogh and his contemporaries. The latter database was based on the index to a commercially available videodisc [Nim82] and augmented from other sources. Both applications can be run on workstations configured with or without multimedia output devices. 3 Database answer format The driver of a database query application (i.e. the domain dependent part of the system) is responsible for returning answers in a list format which consists of a keyword specifying the type of the answer, followed by the answer itself. The answer types expected by the articulator are boolean, number, item, set, quantity, and table. In deciding how to package a response, the articulator uses the answer type along with additional informa</context>
</contexts>
<marker>[Nim82]</marker>
<rawString>L. Nimoy. Vincent Van Gogh: a portrait NL interface to a vision system. In Proc., in two parts. Videodisc, Philips Interna- International Joint Conference on Artitional/North American Philips Corpora- ficial Intelligence, pages 643-646, 1983. tion, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pollack</author>
</authors>
<title>Information sought and information provided.</title>
<date>1985</date>
<booktitle>In CHI &apos;85,</booktitle>
<pages>155--160</pages>
<location>San Francisco, CA,</location>
<marker>[Po185]</marker>
<rawString>M. Pollack. Information sought and information provided. In CHI &apos;85, pages 155-160, San Francisco, CA, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>InformationBased Syntax and Semantics. Vol. I: Fundamentals. (in press).</title>
<date>1987</date>
<booktitle>Lecture notes series no. 13, Center for the Study of Language and Information,</booktitle>
<location>Stanford, CA,</location>
<marker>[PS87]</marker>
<rawString>C. Pollard and I.A. Sag. InformationBased Syntax and Semantics. Vol. I: Fundamentals. (in press). Lecture notes series no. 13, Center for the Study of Language and Information, Stanford, CA, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Reichman</author>
</authors>
<title>Getting Computers to Talk Like You and Me.</title>
<date>1985</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<marker>[Rei85]</marker>
<rawString>R. Reichman. Getting Computers to Talk Like You and Me. MIT Press, Cambridge, MA, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Toward a computational theory of definite anaphora comprehension in English.</title>
<date>1979</date>
<tech>Technical Report AI-TR-537, MIT,</tech>
<contexts>
<context position="18921" citStr="[Sid79]" startWordPosition="3049" endWordPosition="3049">ated both. In the context of our people and equipment database, the articulator is capable of displaying a picture of a featureless cubicle or a slide show of nervously posed employees in conjunction with a textual answer. On the other hand, the database of Van Gogh paintings has proven to be a very appealing application for visual articulation. With visually articulated answers, we were provided with an opportunity to begin to experiment with deictic reference. While personal pronouns are interpreted by the pragmatics processor using a discourse model which takes a centering approach [Gro77] [Sid79] [JW81] [GJW83] [BFP87], demonstrative pronouns are interpreted via a rudimentary environment model that knows which painting is currently displayed on the video screen. Note that the displayed image may not be the one currently under discussion in the the discourse, but may be left over from an earlier query if no intervening queries elicited videodisc answers. Since imagery can be such a salient part of the user&apos;s environment, it is necessary to support deictic references to the current image. At present in our system, &amp;quot;this&amp;quot; and &amp;quot;that&amp;quot; have the same interpretation, but we are exploring alte</context>
</contexts>
<marker>[Sid79]</marker>
<rawString>Candace L. Sidner. Toward a computational theory of definite anaphora comprehension in English. Technical Report AI-TR-537, MIT, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Focusing for interpretation of pronouns.</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>7</volume>
<issue>4</issue>
<pages>231</pages>
<marker>[Sid81]</marker>
<rawString>C.L. Sidner. Focusing for interpretation of pronouns. American Journal of Computational Linguistics, 7(4):217— 231, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sparck-Jones</author>
</authors>
<title>Shifting meaning representations.</title>
<date>1983</date>
<booktitle>In Proc., International Joint Conference on Artificial Intelligence,</booktitle>
<pages>621--623</pages>
<marker>[Spa83]</marker>
<rawString>K. Sparck-Jones. Shifting meaning representations. In Proc., International Joint Conference on Artificial Intelligence, pages 621-623, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Stenton</author>
</authors>
<title>Designing a co-operative interface to an expert system.</title>
<date>1987</date>
<tech>Technical Report HPL-BRC-TM-87-023, HPLabs Technical Memo,</tech>
<contexts>
<context position="891" citStr="[Ste87]" startWordPosition="128" endWordPosition="128">ers elicited by a natural language interface to database query applications. Multimedia answers include videodisc images and heuristically-produced complete sentences in text or text-to-speech form. Deictic reference and feedback about the discourse are enabled. The interface thus presents the application as cooperative and conversational. 1 Introduction It is useful to evaluate human-computer communication in light of Grice&apos;s cooperative principle and maxims [Gri75]. Recently there has been much interest in a &amp;quot;cooperative response&amp;quot; paradigm for interfaces to database query and expert systems [Ste87]. The most promising strategies in this area of investigation involve applying insights gained from psycholinguistics research in order to create better conversational human/computer interfaces. However, inventing adequate user modeling and inferencing systems for this purpose is no easy task, and much of the literature on the subject describes proposals for systems yet unimplemented or theoretical approaches which may depend heavily on a particular domain model. Our multimedia articulator consists of principled solutions which have been implemented in a domain independent manner and which pro</context>
</contexts>
<marker>[Ste87]</marker>
<rawString>P. Stenton. Designing a co-operative interface to an expert system. Technical Report HPL-BRC-TM-87-023, HPLabs Technical Memo, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Thomas</author>
<author>M B Rosson</author>
<author>M Chodorow</author>
</authors>
<title>Human factors and synthetic speech.</title>
<date>1984</date>
<booktitle>In Proc., INTERACT &apos;84,</booktitle>
<pages>37--42</pages>
<contexts>
<context position="5786" citStr="[TRC84]" startWordPosition="907" endWordPosition="907">n something of the character of a nonsequitur. This problem manifested itself in an early version of our system that worked by having users send queries over the network via electronic mail to a single natural language server which in due time mailed its responses back to the user, and also in the current system, which returns most answers in a few seconds but can be operated in a mode which prints modular timing and status information during processing. Even more unsatisfying was the articulation of answers using text-to-speech hardware. Generated speech is often hard for users to understand [TRC84] and in our system, short answers delivered this way often failed even to attract a user&apos;s attention as information-bearing. To echo the query audibly seemed confusing; what was needed was the capability to frame the answer in a complete sentence based on the query. The final impetus for the verbose articulator was our desire to approximate some of the effects that real natural language generation capability might provide in a questionanswering human/computer interface, before committing resources to a full-scale natural language generation effort. In verbose mode, a sentential answer consists</context>
</contexts>
<marker>[TRC84]</marker>
<rawString>J.C. Thomas, M.B. Rosson, and M. Chodorow. Human factors and synthetic speech. In Proc., INTERACT &apos;84, pages 37-42, 1984.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Webber</author>
<author>A Joshi</author>
<author>E Mays</author>
<author>K McKeown</author>
</authors>
<title>Extended natural language data base interactions.</title>
<journal>International Journal of Computers and Mathematics: Special issue on computational linguistics,</journal>
<pages>1982</pages>
<contexts>
<context position="9070" citStr="[WJMM82]" startWordPosition="1439" endWordPosition="1439">paraphrases, desirable in establishing initial system credibility, should be available upon specific request by the user. 4.2 &amp;quot;Namely&amp;quot; answers Grice&apos;s maxim of quantity for cooperative communication is a reminder that it is frequently desirable to provide more information in an answer than was literally requested. For example, when a user asks &amp;quot;Are there any secretaries?&amp;quot; the best answer may be not &amp;quot;Yes&amp;quot;, but &amp;quot;Yes - namely, X, Y, and Z&amp;quot; (where X, Figure 3: &amp;quot;Namely&amp;quot; answer Y, and Z are the names of the secretaries). Several question-answering systems have addressed issues of this sort [WMJB83] [WJMM82]. While our system does not explicitly model the user&apos;s goals or know anything about indirect speech acts, it provides extended answers to some queries via a list containing the keyword namely, which appears as the last item in the answer list passed to the articulator (figure 3). Extended answer lists are constructed as follows. When an answer is of type number and its cardinality is below a certain threshold, or else when it is both of type boo lean and affirmative, the articulator makes an additional query to the database which returns information for constructing the &amp;quot;namely&amp;quot; answer. This </context>
</contexts>
<marker>[WJMM82]</marker>
<rawString>B. Webber, A. Joshi, E. Mays, and K. McKeown. Extended natural language data base interactions. International Journal of Computers and Mathematics: Special issue on computational linguistics, 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W Walster</author>
<author>H Marburger</author>
<author>A Jameson</author>
<author>S Busemann</author>
</authors>
<title>Over-answering yesno questions: extended responses</title>
<note>in a</note>
<contexts>
<context position="9061" citStr="[WMJB83]" startWordPosition="1438" endWordPosition="1438"> logical paraphrases, desirable in establishing initial system credibility, should be available upon specific request by the user. 4.2 &amp;quot;Namely&amp;quot; answers Grice&apos;s maxim of quantity for cooperative communication is a reminder that it is frequently desirable to provide more information in an answer than was literally requested. For example, when a user asks &amp;quot;Are there any secretaries?&amp;quot; the best answer may be not &amp;quot;Yes&amp;quot;, but &amp;quot;Yes - namely, X, Y, and Z&amp;quot; (where X, Figure 3: &amp;quot;Namely&amp;quot; answer Y, and Z are the names of the secretaries). Several question-answering systems have addressed issues of this sort [WMJB83] [WJMM82]. While our system does not explicitly model the user&apos;s goals or know anything about indirect speech acts, it provides extended answers to some queries via a list containing the keyword namely, which appears as the last item in the answer list passed to the articulator (figure 3). Extended answer lists are constructed as follows. When an answer is of type number and its cardinality is below a certain threshold, or else when it is both of type boo lean and affirmative, the articulator makes an additional query to the database which returns information for constructing the &amp;quot;namely&amp;quot; answ</context>
</contexts>
<marker>[WMJB83]</marker>
<rawString>W. Walster, H. Marburger, A. Jameson, and S. Busemann. Over-answering yesno questions: extended responses in a</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>