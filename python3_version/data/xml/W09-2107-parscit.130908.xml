<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000060">
<title confidence="0.994811">
Automated Suggestions for Miscollocations
</title>
<author confidence="0.993516">
Anne Li-E Liu David Wible Nai-Lung Tsao
</author>
<affiliation confidence="0.986465">
Research Centre for English Graduate Institute of Learning and Graduate Institute of Learning and
and Applied Linguistics Instruction Instruction
University of Cambridge National Central University National Central University
</affiliation>
<address confidence="0.9830765">
Cambridge, CB3 9DP, Jhongli City, Taoyuan County Jhongli City, Taoyuan County
United Kingdom 32001, Taiwan 32001, Taiwan
</address>
<email confidence="0.996926">
lel29@cam.ac.uk wible45@yahoo.com beaktsao@gmail.com
</email>
<sectionHeader confidence="0.996629" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997242">
One of the most common and persistent error
types in second language writing is colloca-
tion errors, such as learn knowledge instead of
gain or acquire knowledge, or make damage
rather than cause damage. In this work-in-
progress report, we propose a probabilistic
model for suggesting corrections to lexical
collocation errors. The probabilistic model in-
corporates three features: word association
strength (MI), semantic similarity (via Word-
Net) and the notion of shared collocations (or
intercollocability). The results suggest that
the combination of all three features outper-
forms any single feature or any combination
of two features.
</bodyText>
<sectionHeader confidence="0.8296" genericHeader="method">
1 Collocation in Language Learning
</sectionHeader>
<bodyText confidence="0.999782">
The importance and difficulty of collocations for
second language users has been widely acknowl-
edged and various sources of the difficulty put
forth (Granger 1998, Nesselhauf 2004, Howarth
1998, Liu 2002, inter alia). Liu’s study of a 4-
million-word learner corpus reveals that verb-noun
(VN) miscollocations make up the bulk of the lexi-
cal collocation errors in learners’ essays. Our study
focuses, therefore, on VN miscollocation correc-
tion.
</bodyText>
<sectionHeader confidence="0.974996" genericHeader="method">
2 Error Detection and Correction in NLP
</sectionHeader>
<bodyText confidence="0.999895642857143">
Error detection and correction have been two
major issues in NLP research in the past decade.
Projects involving learner corpora in analyzing and
categorizing learner errors include NICT Japanese
Learners of English (JLE), the Chinese Learners of
English Corpus (Gamon et al., 2008) and English
Taiwan Learner Corpus (or TLC) (Wible et al.,
2003). Studies that focus on providing automatic
correction, however, mainly deal with errors that
derive from closed-class words, such as articles
(Han et al., 2004) and prepositions (Chodorow et
al., 2007). One goal of this work-in-progress is to
address the less studied issue of open class lexical
errors, specifically lexical collocation errors.
</bodyText>
<sectionHeader confidence="0.989598" genericHeader="method">
3 The Present Study
</sectionHeader>
<bodyText confidence="0.999972461538462">
We focus on providing correct collocation sug-
gestions for lexical miscollocations. Three features
are employed to identify the correct collocation
substitute for a miscollocation: word association
measurement, semantic similarity between the cor-
rection candidate and the misused word to be re-
placed, and intercollocability (i.e., the concept of
shared collocates in collocation clusters proposed
by Cowie and Howarth, 1995). NLP research on
learner errors includes work on error detection and
error correction. While we are working on both,
here we report specifically on our work on lexical
miscollocation correction.
</bodyText>
<sectionHeader confidence="0.975545" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.998954888888889">
We incorporate both linguistic and computa-
tional perspectives in our approach. 84 VN miscol-
locations from Liu’s (2002) study were employed
as the training and the testing data in that each
comprised 42 randomly chosen miscollocations.
Two experienced English teachers1 manually went
through the 84 miscollocations and provided a list
of correction suggestions. Only when the system
output matches to any of the suggestions offered
</bodyText>
<footnote confidence="0.797674">
1 One native speaker and one experienced non-native English teacher.
</footnote>
<page confidence="0.988317">
47
</page>
<note confidence="0.8167315">
Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 47–50,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999986333333333">
by the two annotators would the data be included
in the result. The two main knowledge resources
that we incorporated are British National Corpus2
and WordNet (Miller, 1990). BNC was utilized to
measure word association strength and to extract
shared collocates while WordNet was used in de-
termining semantic similarity. Our probabilistic
model that combines the features is described in
sub-section 4.4. Note that all the 84 VN miscollo-
cations are combination of incorrect verbs and fo-
cal nouns, our approach is therefore aimed to find
the correct verb replacements.
</bodyText>
<subsectionHeader confidence="0.989392">
4.1 Word Association Measurement
</subsectionHeader>
<bodyText confidence="0.996871909090909">
The role of word association in miscollocation
suggestions are twofold: 1. all suggested correct
collocations in any case have to be identified as
collocations; thus, we assume candidate replace-
ments for the miscollocate verbs must exceed a
threshold word association strength with the focal
noun; 2. we examine the possibility that the higher
the word association score the more likely it is to
be a correct substitute for the wrong collocate. We
adopt Mutual Information (Church et al. 1991) as
our association measurement.
</bodyText>
<subsectionHeader confidence="0.997918">
4.2 Semantic Similarity
</subsectionHeader>
<bodyText confidence="0.9999764">
Both Gitsaki et al. (2000) and Liu (2002) sug-
gest a semantic relation holds between a miscollo-
cate and its correct counterpart. Following this, we
assume that in the 84 miscollocations, the miscol-
locates should stand in more or less a semantic re-
lation with the corrections. For example, say in an
attested learner miscollocation say story is found to
be a synonym of the correct verb tell in WordNet.
Based on this assumption, words that show some
degree of semantic similarity with the miscollocate
are considered possible candidates for replacing it.
To measure similarity we take the synsets of
WordNet to be nodes in a graph. We quantify the
semantic similarity of the incorrect verb in a mis-
collocation with other possible substitute verbs by
measuring graph-theoretic distance between the
synset containing the miscollocate verb and the
synset containing candidate substitutes. In cases of
polysemy, we take the closest synsets for the dis-
tance measure. If the miscollocate and the candi-
</bodyText>
<footnote confidence="0.7642355">
2 The British National Corpus, version 3 (BNC XML Edition). 2007.
URL: http://www.natcorp.ox.ac.uk/
</footnote>
<bodyText confidence="0.9979295">
date substitute occur in the same synset, then the
distance between them is zero.
The similarity measurement function is as fol-
lows (Tsao et al., 2003):
</bodyText>
<equation confidence="0.9990675">
(w1 , w2) = max (1
si∈synset(w1 ),sj∈synset(w2 )
</equation>
<bodyText confidence="0.956976722222222">
borrow the cluster idea from Cowie
(1995) who propose
to denote
sets of collocations that carry similar meaning and
shared collocates. Figure 1 represents a collocation
cluster that expresses the concept of
something into
The key here is that not
all VN combinations in Figure 1 are acceptable.
While fulfill and achieve collocate with the four
nouns on the right, realize does not collocate with
purpose, as indicated by the dotted line. Cowie and
point is that collocations that can be
clustered via overlapping collocates can be the
source of collocation errors for language learners.
That both fulfill and reach collocate with goal and
the further collocability of fulfill with ambition and
purpose plausibly lead learn
</bodyText>
<equation confidence="0.4489454">
&amp; Howarth
‘overlappingcluster’
‘bringing
actuality.’
Howarth’s
</equation>
<bodyText confidence="0.749656785714286">
ers to assume that
reach shares this collocability as well, leading by
overgeneralization to the miscollocations reach an
ambition or reach a purpose.
,where dis(si, sj) means the node path length be-
tween the synset and in WordNet hy-
si sj
per/hypo tree. means the level number of s in
Ls
hyper/hypo tree and the level of top node is 1.
Multiplying max(Lsi , Lsj) by 2 ensures the simi-
larity is less than 1. If and are synonymous,
si sj
the similarity will be 1.
</bodyText>
<figureCaption confidence="0.959756166666667">
4.3 Shared Collocates in Collocation Clusters
Futagi et al (2008) review several studies which
adopt computational approaches in tackling collo-
cation errors; yet none of them, including Futagi et
al., include the notion of collocation cluster. We
Figure 1. Collocation cluster of
</figureCaption>
<bodyText confidence="0.699731">
‘bringing something
into actuality’
</bodyText>
<equation confidence="0.859604625">
sim
dis(si , s
−
2 x max(Lsi , Lsj
)
)
)
j
</equation>
<page confidence="0.986166">
48
</page>
<bodyText confidence="0.999998">
We employ the ideas of ‘collocation cluster’ and
‘shared collocates’ in identifying correct counter-
parts to the miscollocations. Specifically, taking
the miscollocation reach their purpose as a starting
point, our system generates a collocation cluster by
finding the verbs that collocate with purpose and
nouns that reach collocates with. We consider this
formed cluster the source that contains the possible
correct replacement for reach in reach their pur-
pose. By finding verbs that not only collocate with
purpose but also share the most other collocating
nouns with the wrong verb reach, successfully, we
identified candidate substitutes fulfill and achieve
for the incorrect verb reach.
</bodyText>
<subsectionHeader confidence="0.941097">
4.4 Our Probabilistic Model
</subsectionHeader>
<bodyText confidence="0.999450615384615">
The three features we described above are inte-
grated into a probabilistic model. Each feature is
used to look up the correct collocation suggestion
for a miscollocation. For instance, cause damage,
one of the possible suggestions for the miscolloca-
tion make damage, is found to be ranked the 5th
correction candidate by using word association
measurement merely, the 2nd by semantic similarity
and the 14th by using shared collocates. If we com-
bine the three features, however, cause damage is
ranked first.
The conditional probability of the case where
the candidate is a correct one can be presented as:
</bodyText>
<equation confidence="0.989148">
P (c is a correct verb Fc , m )
</equation>
<bodyText confidence="0.999583333333333">
where c means a candidate for a specific miscollo-
cation and Fc, m means the features values between
m (misused words) and c (candidates). According
to Bayes theorem and Bayes assumption, which
assume that these features are independent, the
probability can be computed by:
</bodyText>
<equation confidence="0.995306666666667">
∏ P f S P S
( ) ( )
c c
( ) ( ) ( )
P F S P S f F
c m c
, c ∈ c m
,
PS F = ≈
c c m
, P(F ) ∏ ( )
P f
c m
,
f∈
</equation>
<bodyText confidence="0.99908">
where means the situation ‘c is a correct verb’,
</bodyText>
<subsubsectionHeader confidence="0.378755">
Sc
</subsubsectionHeader>
<bodyText confidence="0.999943666666667">
as described above and f is one of the three particu-
lar features. We use probability values to choose
and rank the K-best suggestions.
</bodyText>
<sectionHeader confidence="0.996689" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.989037461538462">
Any found VN combination via our probabilistic
approach was compared to the suggestions made
by the two human experts. A match would be
counted as a true positive. A discrete probability
distribution is produced for each feature. We di-
vided feature value into five levels and obtained
prior predicting value for each level of the three
features. For example, we divided MI value to five
levels (&lt;1.5, 1.5~3.0, 3.0~4.5, 4.5~6, &gt;6). The five
ranks for semantic similarity and normalized
shared collocates number are 0.0~0.2, 0.2~0.4,
0.4~0.6, 0.6~0.8 and 0.8 ~1.0. For every feature,
we obtain a predicting value for each level after the
training process. The predicting value is shown
as P f Sc . In line with that, P(MI&gt;6) means the
( )P(f)
probability of all VN collocations retrieved from
BNC in which the MI value is higher than 6
whereas P(MI&gt;6 |Sc) shows the probability of all
correct VN collocations with the MI value higher
than 6.
Different combinations of the three features are
made on the basis of the probabilistic model de-
scribed in Section 4.4. Seven models derive from
such combinations (See Table 1). Table 2 shows
the precision of k-best suggestions for each model.
</bodyText>
<equation confidence="0.98599225">
Models Feature(s) considered
M 1 MI (Mutual Information)
M 2 SS (Semantic Similarity)
M 3 SC (Shared Collocates)
M 4 MI + SS
M 5 MI + SC
M 6 SS + SC
M 7 MI + SS + SC
</equation>
<tableCaption confidence="0.999381">
Table 1. Models of feature combinations.
</tableCaption>
<table confidence="0.999840818181818">
K-Best M1 M2 M3 M4 M5 M6 M7
1 16.67 40.48 22.62 48.81 29.76 55.95 53.57
2 36.90 53.57 38.10 60.71 44.05 63.1 67.86
3 47.62 64.29 50.00 71.43 59.52 77.38 78.57
4 52.38 67.86 63.10 77.38 72.62 80.95 82.14
5 64.29 75.00 72.62 83.33 78.57 83.33 85.71
6 65.48 77.38 75.00 85.71 83.33 84.52 88.10
7 67.86 80.95 77.38 86.90 86.90 86.9 89.29
8 70.24 83.33 82.14 86.90 89.29 88.1 91.67
9 72.62 86.90 85.71 88.10 92.86 90.48 92.86
10 76.19 86.90 88.10 88.10 94.05 90.48 94.05
</table>
<tableCaption confidence="0.999584">
Table 2. The precision rate of Model 1- 7.
</tableCaption>
<table confidence="0.331611666666667">
K-Best M2 M6 M7
1 aim *obtain *acquire
2 generate share share
3 draw *develop *obtain
4 *obtain generate *develop
5 *develop *acquire *gain
</table>
<tableCaption confidence="0.958438">
Table 3. The K-Best suggestions for get
knowledge.
</tableCaption>
<figure confidence="0.4322895">
, m
Fc
</figure>
<page confidence="0.997888">
49
</page>
<bodyText confidence="0.9961845">
Table 2 shows that, considering the results for
each feature run separately (M1-M3), the feature
‘semantic similarity’ (M2) outperforms the other
two. Among combined feature models (M4-M7),
M7 (MI + SS+ SC), provides the highest propor-
tion of true positives at every value of k except k =
1. The full hybrid of all three features (M7) outper-
forms any single feature. The best results are
achieved when taking into account both statistical
and semantic features. This is illustrated with re-
sults for the example get knowledge in Table 3 (the
asterisks (*) indicate the true positives.)
</bodyText>
<sectionHeader confidence="0.999439" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999982846153846">
In this report of work in progress, we present a
probabilistic model that adopts word association
measurement, semantic similarity and shared col-
locates in looking for corrections for learners’ mis-
collocations. Although only VN miscollocations
are examined, the model is designed to be applica-
ble to other types of miscollocations. Applying
such mechanisms to other types of miscollocations
as well as detecting miscollocations will be the
next steps of this research. Further, a larger amount
of miscollocations should be included in order to
verify our approach and to address the issue of the
small drop of the full-hybrid M7 at k=1.
</bodyText>
<sectionHeader confidence="0.997561" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9986605">
The work reported in this paper was partially
supported by the grants from the National Science
Council, Taiwan (Project Nos. 96-2524-S-008-
003- and 98-2511-S-008-002-MY2)
</bodyText>
<sectionHeader confidence="0.997895" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999358757575757">
Anne. Li-E Liu 2002. A Corpus-based Lexical Semantic
Investigation of VN Miscollocations in Taiwan
Learners’ English. Master Thesis, Tamkang Univer-
sity, Taiwan.
Anthony P Cowie and Peter Howarth. 1995. Phrase-
ological Competence and Written Proficiency, Paper
Presented at the British Association of Applied Lin-
guistics Conference (BAAL), Southampton, England,
September.
Christina Gitsaki, Nagoya Shoka Daigaku, and Richard
P. Taylor. 2000. English Collocations and Their
Place in the EFL Classroom, Available at:
http://www.hum.nagoya-cu.ac.jp/
~taylor/publications/collocations.html.
Claudia Leacock and Martin Chodorow. 2003. Auto-
mated Grammatical Error Detection, In MD Shermis
&amp; JC Burstein (Eds.), Automated Essay Scoring: A
Cross-disciplinary, Mahwah, NJ: Lawrence Erlbaum
Associates.
David Wible, Chin-Hwa Kuo, Nai-Lung Tsao, Anne Li-
E Liu, and Hsiu-Lin Lin. 2003. Bootstrapping in a
Language Learning Environment. Journal of Com-
puter Assisted Learning, 19, 90-102.
George Miller. 1990. WordNet: An On-line Lexical
Database, International Journal of Lexicography.
Kenji Kita and Hiroaki Ogata. 1997. Collocations in
Language Learning: Corpus-based Automatic compi-
lation of Collocations and Bilingual Collocation
Concordancer, Computer Assisted Language Learn-
ing. Vol.10, No. 3, 229-238.
Kenneth Church, William Gale, Patrick Hanks and
Donald Hindle. 1991. Using Statistics in Lexical
Analysis, in Zernik (ed), Lexical Acquisition: Using
On-line Resources to Build a Lexicon, Lawrence Erl-
baum, pp. 115-164.
Martin Chodorow, Joel R. Tetreault and Na-Rae Han.
2007. Detection of Grammatical Errors Involving
Prepositions, Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics,
Special Interest Group on Semantics, Workshop on
Prepositions, 25-30.
Michael Gamon, Jianfeng Gao, Chris Brockett, Alexan-
dre Klementiev, William B. Dolan, Dmitriy Belenko,
Lucy Vanderwende. 2008. Using Contextual Speller
Techniques and Language Modeling for ESL Error
Correction, Proceedings of The Third International
Joint Conference on Natural Language Processing,
Hyderabad, India.
Na-Rae Han, Martin Chodorow and Claudia Leacock.
2004. Detecting Errors in English Article Usage with
a Maximum Entropy Classifier Trained on a Large,
Diverse Corpus, Proceedings of the 4th International
Conference on Language Resources and Evaluation,
Lisbon, Portugal.
Nai-Lung Tsao, David Wible and Chin-Hwa Kuo. 2003.
Feature Expansion for Word Sense Disambiguation,
Proceedings of the International Conference on
Natural Language Processing and Knowledge Engi-
neering, 126-131.
Peter Howarth. 1998. Phraseology and Second Lan-
guage Acquisition. Applied Linguistics. 19/1, 24-44.
Yoko Futagi, Paul Deane, Martin Chodorow &amp; Joel
Tetreault. 2008. A computational approach to detecting
collocation errors in the writing of non-native speakers of
English. Computer Assisted Language Learn-
ing,21:4,353 — 367
</reference>
<page confidence="0.997352">
50
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.999698">Automated Suggestions for Miscollocations</title>
<author confidence="0.999362">Anne Li-E Liu David Wible Nai-Lung Tsao</author>
<affiliation confidence="0.993095333333333">Research Centre for English Graduate Institute of Learning and Graduate Institute of Learning and and Applied Linguistics Instruction Instruction University of Cambridge National Central University National Central University</affiliation>
<address confidence="0.784767">Cambridge, CB3 9DP, Jhongli City, Taoyuan County Jhongli City, Taoyuan County United Kingdom 32001, Taiwan 32001, Taiwan</address>
<email confidence="0.898281">lel29@cam.ac.ukwible45@yahoo.combeaktsao@gmail.com</email>
<abstract confidence="0.993781878260869">One of the most common and persistent error types in second language writing is collocaerrors, such as knowledge of or damage than In this work-inprogress report, we propose a probabilistic model for suggesting corrections to lexical collocation errors. The probabilistic model incorporates three features: word association strength (MI), semantic similarity (via Word- Net) and the notion of shared collocations (or intercollocability). The results suggest that the combination of all three features outperforms any single feature or any combination of two features. 1 Collocation in Language Learning The importance and difficulty of collocations for second language users has been widely acknowledged and various sources of the difficulty put forth (Granger 1998, Nesselhauf 2004, Howarth 1998, Liu 2002, inter alia). Liu’s study of a 4million-word learner corpus reveals that verb-noun (VN) miscollocations make up the bulk of the lexical collocation errors in learners’ essays. Our study focuses, therefore, on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learner Corpus (or TLC) (Wible et al., 2003). Studies that focus on providing automatic correction, however, mainly deal with errors that derive from closed-class words, such as articles (Han et al., 2004) and prepositions (Chodorow et al., 2007). One goal of this work-in-progress is to address the less studied issue of open class lexical errors, specifically lexical collocation errors. 3 The Present Study We focus on providing correct collocation suggestions for lexical miscollocations. Three features are employed to identify the correct collocation substitute for a miscollocation: word association measurement, semantic similarity between the correction candidate and the misused word to be replaced, and intercollocability (i.e., the concept of shared collocates in collocation clusters proposed by Cowie and Howarth, 1995). NLP research on learner errors includes work on error detection and error correction. While we are working on both, here we report specifically on our work on lexical miscollocation correction. We incorporate both linguistic and computational perspectives in our approach. 84 VN miscollocations from Liu’s (2002) study were employed as the training and the testing data in that each comprised 42 randomly chosen miscollocations. experienced English manually went through the 84 miscollocations and provided a list of correction suggestions. Only when the system output matches to any of the suggestions offered native speaker and one experienced non-native English teacher. 47 of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational pages 47–50, Colorado, June 2009. Association for Computational Linguistics by the two annotators would the data be included in the result. The two main knowledge resources we incorporated are British National and WordNet (Miller, 1990). BNC was utilized to measure word association strength and to extract shared collocates while WordNet was used in determining semantic similarity. Our probabilistic model that combines the features is described in sub-section 4.4. Note that all the 84 VN miscollocations are combination of incorrect verbs and focal nouns, our approach is therefore aimed to find the correct verb replacements. 4.1 Word Association Measurement The role of word association in miscollocation suggestions are twofold: 1. all suggested correct collocations in any case have to be identified as collocations; thus, we assume candidate replacements for the miscollocate verbs must exceed a threshold word association strength with the focal noun; 2. we examine the possibility that the higher the word association score the more likely it is to be a correct substitute for the wrong collocate. We adopt Mutual Information (Church et al. 1991) as our association measurement. 4.2 Semantic Similarity Both Gitsaki et al. (2000) and Liu (2002) suggest a semantic relation holds between a miscollocate and its correct counterpart. Following this, we assume that in the 84 miscollocations, the miscollocates should stand in more or less a semantic rewith the corrections. For example, an learner miscollocation story found to a synonym of the correct verb WordNet. Based on this assumption, words that show some degree of semantic similarity with the miscollocate are considered possible candidates for replacing it. To measure similarity we take the synsets of WordNet to be nodes in a graph. We quantify the semantic similarity of the incorrect verb in a miscollocation with other possible substitute verbs by measuring graph-theoretic distance between the synset containing the miscollocate verb and the synset containing candidate substitutes. In cases of polysemy, we take the closest synsets for the dismeasure. If the miscollocate and the candi- British National version 3 (BNC XML Edition). 2007.</abstract>
<web confidence="0.757362">URL: http://www.natcorp.ox.ac.uk/</web>
<abstract confidence="0.998989942028985">date substitute occur in the same synset, then the distance between them is zero. The similarity measurement function is as follows (Tsao et al., 2003): , (1 ) borrow the cluster idea from Cowie (1995) who propose to denote sets of collocations that carry similar meaning and shared collocates. Figure 1 represents a collocation cluster that expresses the concept of something into The key here is that not all VN combinations in Figure 1 are acceptable. While fulfill and achieve collocate with the four nouns on the right, realize does not collocate with purpose, as indicated by the dotted line. Cowie and point is that collocations that can be clustered via overlapping collocates can be the source of collocation errors for language learners. That both fulfill and reach collocate with goal and the further collocability of fulfill with ambition and purpose plausibly lead learn &amp; Howarth ‘overlappingcluster’ ‘bringing actuality.’ Howarth’s ers to assume that this collocability as well, leading by to the miscollocations an a ,where dis(si, sj) means the node path length between the synset and in WordNet hysi sj per/hypo tree. means the level number of s in Ls hyper/hypo tree and the level of top node is 1. Multiplying max(Lsi , Lsj) by 2 ensures the similarity is less than 1. If and are synonymous, si sj the similarity will be 1. 4.3 Shared Collocates in Collocation Clusters Futagi et al (2008) review several studies which adopt computational approaches in tackling collocation errors; yet none of them, including Futagi et al., include the notion of collocation cluster. We Figure 1. Collocation cluster of ‘bringing something into actuality’ sim , − , ) ) ) j 48 We employ the ideas of ‘collocation cluster’ and ‘shared collocates’ in identifying correct counterparts to the miscollocations. Specifically, taking miscollocation their purpose a starting point, our system generates a collocation cluster by the verbs that collocate with that with. We consider this formed cluster the source that contains the possible replacement for their pur- By finding verbs that not only collocate with also share the most other collocating with the wrong verb successfully, we candidate substitutes the incorrect verb 4.4 Our Probabilistic Model The three features we described above are integrated into a probabilistic model. Each feature is used to look up the correct collocation suggestion a miscollocation. For instance, one of the possible suggestions for the miscollocais found to be ranked the 5th correction candidate by using word association merely, the by semantic similarity the by using shared collocates. If we comthe three features, however, damage ranked first. The conditional probability of the case where the candidate is a correct one can be presented as: is a correct verb a candidate for a specific miscolloand m the features values between words) and According to Bayes theorem and Bayes assumption, which assume that these features are independent, the probability can be computed by: f S P S ) ) c c ) ( ) ) S P S F c m c m F ≈ c c m ) P f c , where means the situation ‘c is a correct verb’, described above and one of the three particular features. We use probability values to choose and rank the K-best suggestions. 5 Experimental Results Any found VN combination via our probabilistic approach was compared to the suggestions made by the two human experts. A match would be counted as a true positive. A discrete probability distribution is produced for each feature. We divided feature value into five levels and obtained prior predicting value for each level of the three features. For example, we divided MI value to five levels (&lt;1.5, 1.5~3.0, 3.0~4.5, 4.5~6, &gt;6). The five ranks for semantic similarity and normalized shared collocates number are 0.0~0.2, 0.2~0.4, 0.4~0.6, 0.6~0.8 and 0.8 ~1.0. For every feature, we obtain a predicting value for each level after the training process. The predicting value is shown f . In line with that, the probability of all VN collocations retrieved from BNC in which the MI value is higher than 6 the probability of all correct VN collocations with the MI value higher than 6. Different combinations of the three features are made on the basis of the probabilistic model described in Section 4.4. Seven models derive from such combinations (See Table 1). Table 2 shows the precision of k-best suggestions for each model.</abstract>
<note confidence="0.599354545454545">Models Feature(s) considered M 1 MI (Mutual Information) M 2 SS (Semantic Similarity) M 3 SC (Shared Collocates) M 4 MI + SS M 5 MI + SC M 6 SS + SC M 7 MI + SS + SC Table 1. Models of feature combinations. K-Best M1 M2 M3 M4 M5 M6 M7 1 16.67 40.48 22.62 48.81 29.76 55.95 53.57</note>
<phone confidence="0.595783">2 36.90 53.57 38.10 60.71 44.05 63.1 67.86 3 47.62 64.29 50.00 71.43 59.52 77.38 78.57</phone>
<address confidence="0.631013285714286">4 52.38 67.86 63.10 77.38 72.62 80.95 82.14 5 64.29 75.00 72.62 83.33 78.57 83.33 85.71 6 65.48 77.38 75.00 85.71 83.33 84.52 88.10 7 67.86 80.95 77.38 86.90 86.90 86.9 89.29 8 70.24 83.33 82.14 86.90 89.29 88.1 91.67 9 72.62 86.90 85.71 88.10 92.86 90.48 92.86 10 76.19 86.90 88.10 88.10 94.05 90.48 94.05</address>
<abstract confidence="0.977556970588235">Table 2. The precision rate of Model 1- 7. K-Best M2 M6 M7 1 aim *obtain *acquire 2 generate share share 3 draw *develop *obtain 4 *obtain generate *develop 5 *develop *acquire *gain 3. The K-Best suggestions for 49 Table 2 shows that, considering the results for each feature run separately (M1-M3), the feature ‘semantic similarity’ (M2) outperforms the other two. Among combined feature models (M4-M7), M7 (MI + SS+ SC), provides the highest proportion of true positives at every value of k except k = 1. The full hybrid of all three features (M7) outperforms any single feature. The best results are achieved when taking into account both statistical and semantic features. This is illustrated with refor the example knowledge Table 3 (the asterisks (*) indicate the true positives.) 6 Conclusion In this report of work in progress, we present a probabilistic model that adopts word association measurement, semantic similarity and shared collocates in looking for corrections for learners’ miscollocations. Although only VN miscollocations are examined, the model is designed to be applicable to other types of miscollocations. Applying such mechanisms to other types of miscollocations as well as detecting miscollocations will be the next steps of this research. Further, a larger amount of miscollocations should be included in order to verify our approach and to address the issue of the</abstract>
<note confidence="0.737546842105263">small drop of the full-hybrid M7 at k=1. Acknowledgments The work reported in this paper was partially supported by the grants from the National Science Council, Taiwan (Project Nos. 96-2524-S-008- 003and 98-2511-S-008-002-MY2) References Li-E Liu 2002. Corpus-based Lexical Semantic Investigation of VN Miscollocations in Taiwan Master Thesis, Tamkang University, Taiwan. Anthony P Cowie and Peter Howarth. 1995. Phraseological Competence and Written Proficiency, Paper at the Association of Applied Lin- Conference Southampton, England, September. Christina Gitsaki, Nagoya Shoka Daigaku, and Richard P. Taylor. 2000. English Collocations and Their Place in the EFL Classroom, Available at:</note>
<web confidence="0.962391">http://www.hum.nagoya-cu.ac.jp/</web>
<note confidence="0.784311821428571">taylor/publications/collocations.html. Claudia Leacock and Martin Chodorow. 2003. Automated Grammatical Error Detection, In MD Shermis JC Burstein (Eds.), Essay Scoring: A Mahwah, NJ: Lawrence Erlbaum Associates. David Wible, Chin-Hwa Kuo, Nai-Lung Tsao, Anne Li- E Liu, and Hsiu-Lin Lin. 2003. Bootstrapping in a Learning Environment. of Com- Assisted 19, 90-102. George Miller. 1990. WordNet: An On-line Lexical Journal of Lexicography. Kenji Kita and Hiroaki Ogata. 1997. Collocations in Language Learning: Corpus-based Automatic compilation of Collocations and Bilingual Collocation Assisted Language Learn- Vol.10, No. 3, 229-238. Kenneth Church, William Gale, Patrick Hanks and Donald Hindle. 1991. Using Statistics in Lexical in Zernik (ed), Acquisition: Using On-line Resources to Build a Lexicon, Lawrence Erlpp. 115-164. Martin Chodorow, Joel R. Tetreault and Na-Rae Han. 2007. Detection of Grammatical Errors Involving of the 45th Annual Meeting of the Association for Computational Linguistics, Interest Group on Workshop on Prepositions, 25-30.</note>
<author confidence="0.727980333333333">Using Contextual Speller</author>
<affiliation confidence="0.747863">Techniques and Language Modeling for ESL Error of The Third International Joint Conference on Natural Language Processing,</affiliation>
<address confidence="0.772158">Hyderabad, India. Na-Rae Han, Martin Chodorow and Claudia Leacock. 2004. Detecting Errors in English Article Usage with</address>
<affiliation confidence="0.917679333333333">a Maximum Entropy Classifier Trained on a Large, Corpus, of the International on Language Resources and</affiliation>
<address confidence="0.905993">Lisbon, Portugal.</address>
<note confidence="0.842624307692308">Nai-Lung Tsao, David Wible and Chin-Hwa Kuo. 2003. Feature Expansion for Word Sense Disambiguation, Proceedings of the International Conference on Natural Language Processing and Knowledge Engi- 126-131. Peter Howarth. 1998. Phraseology and Second Lan- Acquisition. 19/1, 24-44. Yoko Futagi, Paul Deane, Martin Chodorow &amp; Joel 2008. computational approach to detecting collocation errors in the writing of non-native speakers of Assisted Language Learn- — 367 50</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Li-E Liu</author>
</authors>
<title>A Corpus-based Lexical Semantic Investigation of VN Miscollocations in Taiwan Learners’ English. Master Thesis,</title>
<date>2002</date>
<institution>Tamkang University, Taiwan.</institution>
<contexts>
<context position="1367" citStr="Liu 2002" startWordPosition="190" endWordPosition="191">for suggesting corrections to lexical collocation errors. The probabilistic model incorporates three features: word association strength (MI), semantic similarity (via WordNet) and the notion of shared collocations (or intercollocability). The results suggest that the combination of all three features outperforms any single feature or any combination of two features. 1 Collocation in Language Learning The importance and difficulty of collocations for second language users has been widely acknowledged and various sources of the difficulty put forth (Granger 1998, Nesselhauf 2004, Howarth 1998, Liu 2002, inter alia). Liu’s study of a 4- million-word learner corpus reveals that verb-noun (VN) miscollocations make up the bulk of the lexical collocation errors in learners’ essays. Our study focuses, therefore, on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learner Corpus (</context>
<context position="4878" citStr="Liu (2002)" startWordPosition="724" endWordPosition="725">iation Measurement The role of word association in miscollocation suggestions are twofold: 1. all suggested correct collocations in any case have to be identified as collocations; thus, we assume candidate replacements for the miscollocate verbs must exceed a threshold word association strength with the focal noun; 2. we examine the possibility that the higher the word association score the more likely it is to be a correct substitute for the wrong collocate. We adopt Mutual Information (Church et al. 1991) as our association measurement. 4.2 Semantic Similarity Both Gitsaki et al. (2000) and Liu (2002) suggest a semantic relation holds between a miscollocate and its correct counterpart. Following this, we assume that in the 84 miscollocations, the miscollocates should stand in more or less a semantic relation with the corrections. For example, say in an attested learner miscollocation say story is found to be a synonym of the correct verb tell in WordNet. Based on this assumption, words that show some degree of semantic similarity with the miscollocate are considered possible candidates for replacing it. To measure similarity we take the synsets of WordNet to be nodes in a graph. We quantif</context>
</contexts>
<marker>Liu, 2002</marker>
<rawString>Anne. Li-E Liu 2002. A Corpus-based Lexical Semantic Investigation of VN Miscollocations in Taiwan Learners’ English. Master Thesis, Tamkang University, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony P Cowie</author>
<author>Peter Howarth</author>
</authors>
<date>1995</date>
<booktitle>Phraseological Competence and Written Proficiency, Paper Presented at the British Association of Applied Linguistics Conference (BAAL),</booktitle>
<location>Southampton, England,</location>
<contexts>
<context position="2784" citStr="Cowie and Howarth, 1995" startWordPosition="400" endWordPosition="403"> prepositions (Chodorow et al., 2007). One goal of this work-in-progress is to address the less studied issue of open class lexical errors, specifically lexical collocation errors. 3 The Present Study We focus on providing correct collocation suggestions for lexical miscollocations. Three features are employed to identify the correct collocation substitute for a miscollocation: word association measurement, semantic similarity between the correction candidate and the misused word to be replaced, and intercollocability (i.e., the concept of shared collocates in collocation clusters proposed by Cowie and Howarth, 1995). NLP research on learner errors includes work on error detection and error correction. While we are working on both, here we report specifically on our work on lexical miscollocation correction. 4 Method We incorporate both linguistic and computational perspectives in our approach. 84 VN miscollocations from Liu’s (2002) study were employed as the training and the testing data in that each comprised 42 randomly chosen miscollocations. Two experienced English teachers1 manually went through the 84 miscollocations and provided a list of correction suggestions. Only when the system output matche</context>
</contexts>
<marker>Cowie, Howarth, 1995</marker>
<rawString>Anthony P Cowie and Peter Howarth. 1995. Phraseological Competence and Written Proficiency, Paper Presented at the British Association of Applied Linguistics Conference (BAAL), Southampton, England, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Gitsaki</author>
<author>Nagoya Shoka Daigaku</author>
<author>Richard P Taylor</author>
</authors>
<title>English Collocations and Their Place in the EFL Classroom, Available at: http://www.hum.nagoya-cu.ac.jp/ ~taylor/publications/collocations.html.</title>
<date>2000</date>
<contexts>
<context position="4863" citStr="Gitsaki et al. (2000)" startWordPosition="719" endWordPosition="722">placements. 4.1 Word Association Measurement The role of word association in miscollocation suggestions are twofold: 1. all suggested correct collocations in any case have to be identified as collocations; thus, we assume candidate replacements for the miscollocate verbs must exceed a threshold word association strength with the focal noun; 2. we examine the possibility that the higher the word association score the more likely it is to be a correct substitute for the wrong collocate. We adopt Mutual Information (Church et al. 1991) as our association measurement. 4.2 Semantic Similarity Both Gitsaki et al. (2000) and Liu (2002) suggest a semantic relation holds between a miscollocate and its correct counterpart. Following this, we assume that in the 84 miscollocations, the miscollocates should stand in more or less a semantic relation with the corrections. For example, say in an attested learner miscollocation say story is found to be a synonym of the correct verb tell in WordNet. Based on this assumption, words that show some degree of semantic similarity with the miscollocate are considered possible candidates for replacing it. To measure similarity we take the synsets of WordNet to be nodes in a gr</context>
</contexts>
<marker>Gitsaki, Daigaku, Taylor, 2000</marker>
<rawString>Christina Gitsaki, Nagoya Shoka Daigaku, and Richard P. Taylor. 2000. English Collocations and Their Place in the EFL Classroom, Available at: http://www.hum.nagoya-cu.ac.jp/ ~taylor/publications/collocations.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Automated Grammatical Error Detection,</title>
<date>2003</date>
<journal>In MD Shermis &amp; JC Burstein (Eds.), Automated</journal>
<marker>Leacock, Chodorow, 2003</marker>
<rawString>Claudia Leacock and Martin Chodorow. 2003. Automated Grammatical Error Detection, In MD Shermis &amp; JC Burstein (Eds.), Automated Essay Scoring: A Cross-disciplinary, Mahwah, NJ: Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Wible</author>
<author>Chin-Hwa Kuo</author>
<author>Nai-Lung Tsao</author>
<author>Anne LiE Liu</author>
<author>Hsiu-Lin Lin</author>
</authors>
<title>Bootstrapping in a Language Learning Environment.</title>
<date>2003</date>
<journal>Journal of Computer Assisted Learning,</journal>
<volume>19</volume>
<pages>90--102</pages>
<contexts>
<context position="1995" citStr="Wible et al., 2003" startWordPosition="286" endWordPosition="289">lia). Liu’s study of a 4- million-word learner corpus reveals that verb-noun (VN) miscollocations make up the bulk of the lexical collocation errors in learners’ essays. Our study focuses, therefore, on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learner Corpus (or TLC) (Wible et al., 2003). Studies that focus on providing automatic correction, however, mainly deal with errors that derive from closed-class words, such as articles (Han et al., 2004) and prepositions (Chodorow et al., 2007). One goal of this work-in-progress is to address the less studied issue of open class lexical errors, specifically lexical collocation errors. 3 The Present Study We focus on providing correct collocation suggestions for lexical miscollocations. Three features are employed to identify the correct collocation substitute for a miscollocation: word association measurement, semantic similarity betw</context>
</contexts>
<marker>Wible, Kuo, Tsao, Liu, Lin, 2003</marker>
<rawString>David Wible, Chin-Hwa Kuo, Nai-Lung Tsao, Anne LiE Liu, and Hsiu-Lin Lin. 2003. Bootstrapping in a Language Learning Environment. Journal of Computer Assisted Learning, 19, 90-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Miller</author>
</authors>
<title>WordNet: An On-line Lexical Database,</title>
<date>1990</date>
<journal>International Journal of Lexicography.</journal>
<contexts>
<context position="3859" citStr="Miller, 1990" startWordPosition="564" endWordPosition="565">h teachers1 manually went through the 84 miscollocations and provided a list of correction suggestions. Only when the system output matches to any of the suggestions offered 1 One native speaker and one experienced non-native English teacher. 47 Proceedings of the NAACL HLT Workshop on Innovative Use of NLP for Building Educational Applications, pages 47–50, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics by the two annotators would the data be included in the result. The two main knowledge resources that we incorporated are British National Corpus2 and WordNet (Miller, 1990). BNC was utilized to measure word association strength and to extract shared collocates while WordNet was used in determining semantic similarity. Our probabilistic model that combines the features is described in sub-section 4.4. Note that all the 84 VN miscollocations are combination of incorrect verbs and focal nouns, our approach is therefore aimed to find the correct verb replacements. 4.1 Word Association Measurement The role of word association in miscollocation suggestions are twofold: 1. all suggested correct collocations in any case have to be identified as collocations; thus, we as</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>George Miller. 1990. WordNet: An On-line Lexical Database, International Journal of Lexicography.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Kita</author>
<author>Hiroaki Ogata</author>
</authors>
<title>Collocations in Language Learning: Corpus-based Automatic compilation of</title>
<date>1997</date>
<journal>Collocations and Bilingual Collocation Concordancer, Computer Assisted Language Learning.</journal>
<volume>10</volume>
<pages>229--238</pages>
<marker>Kita, Ogata, 1997</marker>
<rawString>Kenji Kita and Hiroaki Ogata. 1997. Collocations in Language Learning: Corpus-based Automatic compilation of Collocations and Bilingual Collocation Concordancer, Computer Assisted Language Learning. Vol.10, No. 3, 229-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>William Gale</author>
<author>Patrick Hanks</author>
<author>Donald Hindle</author>
</authors>
<title>Using Statistics in Lexical Analysis, in Zernik (ed), Lexical Acquisition: Using On-line Resources to Build a Lexicon, Lawrence Erlbaum,</title>
<date>1991</date>
<pages>115--164</pages>
<contexts>
<context position="4780" citStr="Church et al. 1991" startWordPosition="707" endWordPosition="710">erbs and focal nouns, our approach is therefore aimed to find the correct verb replacements. 4.1 Word Association Measurement The role of word association in miscollocation suggestions are twofold: 1. all suggested correct collocations in any case have to be identified as collocations; thus, we assume candidate replacements for the miscollocate verbs must exceed a threshold word association strength with the focal noun; 2. we examine the possibility that the higher the word association score the more likely it is to be a correct substitute for the wrong collocate. We adopt Mutual Information (Church et al. 1991) as our association measurement. 4.2 Semantic Similarity Both Gitsaki et al. (2000) and Liu (2002) suggest a semantic relation holds between a miscollocate and its correct counterpart. Following this, we assume that in the 84 miscollocations, the miscollocates should stand in more or less a semantic relation with the corrections. For example, say in an attested learner miscollocation say story is found to be a synonym of the correct verb tell in WordNet. Based on this assumption, words that show some degree of semantic similarity with the miscollocate are considered possible candidates for rep</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>Kenneth Church, William Gale, Patrick Hanks and Donald Hindle. 1991. Using Statistics in Lexical Analysis, in Zernik (ed), Lexical Acquisition: Using On-line Resources to Build a Lexicon, Lawrence Erlbaum, pp. 115-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Joel R Tetreault</author>
<author>Na-Rae Han</author>
</authors>
<title>Detection of Grammatical Errors Involving Prepositions,</title>
<date>2007</date>
<booktitle>Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Special Interest Group on Semantics, Workshop on Prepositions,</booktitle>
<pages>25--30</pages>
<contexts>
<context position="2197" citStr="Chodorow et al., 2007" startWordPosition="316" endWordPosition="319"> on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learner Corpus (or TLC) (Wible et al., 2003). Studies that focus on providing automatic correction, however, mainly deal with errors that derive from closed-class words, such as articles (Han et al., 2004) and prepositions (Chodorow et al., 2007). One goal of this work-in-progress is to address the less studied issue of open class lexical errors, specifically lexical collocation errors. 3 The Present Study We focus on providing correct collocation suggestions for lexical miscollocations. Three features are employed to identify the correct collocation substitute for a miscollocation: word association measurement, semantic similarity between the correction candidate and the misused word to be replaced, and intercollocability (i.e., the concept of shared collocates in collocation clusters proposed by Cowie and Howarth, 1995). NLP researc</context>
</contexts>
<marker>Chodorow, Tetreault, Han, 2007</marker>
<rawString>Martin Chodorow, Joel R. Tetreault and Na-Rae Han. 2007. Detection of Grammatical Errors Involving Prepositions, Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, Special Interest Group on Semantics, Workshop on Prepositions, 25-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
<author>Jianfeng Gao</author>
<author>Chris Brockett</author>
<author>Alexandre Klementiev</author>
<author>William B Dolan</author>
<author>Dmitriy Belenko</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Using Contextual Speller Techniques and Language Modeling for ESL Error Correction,</title>
<date>2008</date>
<booktitle>Proceedings of The Third International Joint Conference on Natural Language Processing,</booktitle>
<location>Hyderabad, India.</location>
<contexts>
<context position="1931" citStr="Gamon et al., 2008" startWordPosition="275" endWordPosition="278"> (Granger 1998, Nesselhauf 2004, Howarth 1998, Liu 2002, inter alia). Liu’s study of a 4- million-word learner corpus reveals that verb-noun (VN) miscollocations make up the bulk of the lexical collocation errors in learners’ essays. Our study focuses, therefore, on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learner Corpus (or TLC) (Wible et al., 2003). Studies that focus on providing automatic correction, however, mainly deal with errors that derive from closed-class words, such as articles (Han et al., 2004) and prepositions (Chodorow et al., 2007). One goal of this work-in-progress is to address the less studied issue of open class lexical errors, specifically lexical collocation errors. 3 The Present Study We focus on providing correct collocation suggestions for lexical miscollocations. Three features are employed to identify the correct collocation substitute for a miscol</context>
</contexts>
<marker>Gamon, Gao, Brockett, Klementiev, Dolan, Belenko, Vanderwende, 2008</marker>
<rawString>Michael Gamon, Jianfeng Gao, Chris Brockett, Alexandre Klementiev, William B. Dolan, Dmitriy Belenko, Lucy Vanderwende. 2008. Using Contextual Speller Techniques and Language Modeling for ESL Error Correction, Proceedings of The Third International Joint Conference on Natural Language Processing, Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Na-Rae Han</author>
<author>Martin Chodorow</author>
<author>Claudia Leacock</author>
</authors>
<title>Detecting Errors in English Article Usage with a Maximum Entropy Classifier Trained on a Large, Diverse Corpus,</title>
<date>2004</date>
<booktitle>Proceedings of the 4th International Conference on Language Resources and Evaluation,</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="2156" citStr="Han et al., 2004" startWordPosition="310" endWordPosition="313">ssays. Our study focuses, therefore, on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learner Corpus (or TLC) (Wible et al., 2003). Studies that focus on providing automatic correction, however, mainly deal with errors that derive from closed-class words, such as articles (Han et al., 2004) and prepositions (Chodorow et al., 2007). One goal of this work-in-progress is to address the less studied issue of open class lexical errors, specifically lexical collocation errors. 3 The Present Study We focus on providing correct collocation suggestions for lexical miscollocations. Three features are employed to identify the correct collocation substitute for a miscollocation: word association measurement, semantic similarity between the correction candidate and the misused word to be replaced, and intercollocability (i.e., the concept of shared collocates in collocation clusters proposed</context>
</contexts>
<marker>Han, Chodorow, Leacock, 2004</marker>
<rawString>Na-Rae Han, Martin Chodorow and Claudia Leacock. 2004. Detecting Errors in English Article Usage with a Maximum Entropy Classifier Trained on a Large, Diverse Corpus, Proceedings of the 4th International Conference on Language Resources and Evaluation, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nai-Lung Tsao</author>
<author>David Wible</author>
<author>Chin-Hwa Kuo</author>
</authors>
<title>Feature Expansion for Word Sense Disambiguation,</title>
<date>2003</date>
<booktitle>Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering,</booktitle>
<pages>126--131</pages>
<contexts>
<context position="6082" citStr="Tsao et al., 2003" startWordPosition="915" endWordPosition="918">ph. We quantify the semantic similarity of the incorrect verb in a miscollocation with other possible substitute verbs by measuring graph-theoretic distance between the synset containing the miscollocate verb and the synset containing candidate substitutes. In cases of polysemy, we take the closest synsets for the distance measure. If the miscollocate and the candi2 The British National Corpus, version 3 (BNC XML Edition). 2007. URL: http://www.natcorp.ox.ac.uk/ date substitute occur in the same synset, then the distance between them is zero. The similarity measurement function is as follows (Tsao et al., 2003): (w1 , w2) = max (1 si∈synset(w1 ),sj∈synset(w2 ) borrow the cluster idea from Cowie (1995) who propose to denote sets of collocations that carry similar meaning and shared collocates. Figure 1 represents a collocation cluster that expresses the concept of something into The key here is that not all VN combinations in Figure 1 are acceptable. While fulfill and achieve collocate with the four nouns on the right, realize does not collocate with purpose, as indicated by the dotted line. Cowie and point is that collocations that can be clustered via overlapping collocates can be the source of col</context>
</contexts>
<marker>Tsao, Wible, Kuo, 2003</marker>
<rawString>Nai-Lung Tsao, David Wible and Chin-Hwa Kuo. 2003. Feature Expansion for Word Sense Disambiguation, Proceedings of the International Conference on Natural Language Processing and Knowledge Engineering, 126-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Howarth</author>
</authors>
<title>Phraseology and Second Language Acquisition. Applied Linguistics.</title>
<date>1998</date>
<volume>19</volume>
<pages>24--44</pages>
<contexts>
<context position="1357" citStr="Howarth 1998" startWordPosition="188" endWordPosition="189">ilistic model for suggesting corrections to lexical collocation errors. The probabilistic model incorporates three features: word association strength (MI), semantic similarity (via WordNet) and the notion of shared collocations (or intercollocability). The results suggest that the combination of all three features outperforms any single feature or any combination of two features. 1 Collocation in Language Learning The importance and difficulty of collocations for second language users has been widely acknowledged and various sources of the difficulty put forth (Granger 1998, Nesselhauf 2004, Howarth 1998, Liu 2002, inter alia). Liu’s study of a 4- million-word learner corpus reveals that verb-noun (VN) miscollocations make up the bulk of the lexical collocation errors in learners’ essays. Our study focuses, therefore, on VN miscollocation correction. 2 Error Detection and Correction in NLP Error detection and correction have been two major issues in NLP research in the past decade. Projects involving learner corpora in analyzing and categorizing learner errors include NICT Japanese Learners of English (JLE), the Chinese Learners of English Corpus (Gamon et al., 2008) and English Taiwan Learne</context>
</contexts>
<marker>Howarth, 1998</marker>
<rawString>Peter Howarth. 1998. Phraseology and Second Language Acquisition. Applied Linguistics. 19/1, 24-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoko Futagi</author>
<author>Paul Deane</author>
<author>Martin Chodorow</author>
<author>Joel Tetreault</author>
</authors>
<title>A computational approach to detecting collocation errors in the writing of non-native speakers of English.</title>
<date>2008</date>
<journal>Computer Assisted Language Learning,21:4,353 —</journal>
<volume>367</volume>
<contexts>
<context position="7447" citStr="Futagi et al (2008)" startWordPosition="1142" endWordPosition="1145">purpose plausibly lead learn &amp; Howarth ‘overlappingcluster’ ‘bringing actuality.’ Howarth’s ers to assume that reach shares this collocability as well, leading by overgeneralization to the miscollocations reach an ambition or reach a purpose. ,where dis(si, sj) means the node path length between the synset and in WordNet hysi sj per/hypo tree. means the level number of s in Ls hyper/hypo tree and the level of top node is 1. Multiplying max(Lsi , Lsj) by 2 ensures the similarity is less than 1. If and are synonymous, si sj the similarity will be 1. 4.3 Shared Collocates in Collocation Clusters Futagi et al (2008) review several studies which adopt computational approaches in tackling collocation errors; yet none of them, including Futagi et al., include the notion of collocation cluster. We Figure 1. Collocation cluster of ‘bringing something into actuality’ sim dis(si , s − 2 x max(Lsi , Lsj ) ) ) j 48 We employ the ideas of ‘collocation cluster’ and ‘shared collocates’ in identifying correct counterparts to the miscollocations. Specifically, taking the miscollocation reach their purpose as a starting point, our system generates a collocation cluster by finding the verbs that collocate with purpose a</context>
</contexts>
<marker>Futagi, Deane, Chodorow, Tetreault, 2008</marker>
<rawString>Yoko Futagi, Paul Deane, Martin Chodorow &amp; Joel Tetreault. 2008. A computational approach to detecting collocation errors in the writing of non-native speakers of English. Computer Assisted Language Learning,21:4,353 — 367</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>