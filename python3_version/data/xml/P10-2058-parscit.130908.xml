<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.220332">
<title confidence="0.9988215">
Using Speech to Reply to SMS Messages While Driving:
An In-Car Simulator User Study
</title>
<author confidence="0.999241">
Yun-Cheng Ju, Tim Paek
</author>
<affiliation confidence="0.96679">
Microsoft Research
</affiliation>
<address confidence="0.941575">
Redmond, WA USA
</address>
<email confidence="0.999638">
{yuncj|timpaek}@microsoft.com
</email>
<sectionHeader confidence="0.993921" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999834684210527">
Speech recognition affords automobile
drivers a hands-free, eyes-free method of
replying to Short Message Service (SMS)
text messages. Although a voice search
approach based on template matching has
been shown to be more robust to the chal-
lenging acoustic environment of automo-
biles than using dictation, users may have
difficulties verifying whether SMS re-
sponse templates match their intended
meaning, especially while driving. Using a
high-fidelity driving simulator, we com-
pared dictation for SMS replies versus
voice search in increasingly difficult driv-
ing conditions. Although the two ap-
proaches did not differ in terms of driving
performance measures, users made about
six times more errors on average using
dictation than voice search.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999848444444445">
Users love Short Message Service (SMS) text
messaging; so much so that 3 trillion SMS mes-
sages are expected to have been sent in 2009
alone (Stross, 2008). Because research has
shown that SMS messaging while driving results
in 35% slower reaction time than being intox-
icated (Reed &amp; Robbins, 2008), campaigns have
been launched by states, governments and even
cell phone carriers to discourage and ban SMS
messaging while driving (DOT, 2009). Yet, au-
tomobile manufacturers have started to offer in-
fotainment systems, such as the Ford Sync,
which feature the ability to listen to incoming
SMS messages using text-to-speech (TTS). Au-
tomatic speech recognition (ASR) affords users a
hands-free, eyes-free method of replying to SMS
messages. However, to date, manufacturers have
not established a safe and reliable method of le-
veraging ASR, though some researchers have
begun to explore techniques. In previous re-
search (Ju &amp; Paek, 2009), we examined three
ASR approaches to replying to SMS messages:
dictation using a language model trained on SMS
responses, canned responses using a probabilistic
context-free grammar (PCFG), and a “voice
search” approach based on template matching.
Voice search proceeds in two steps (Natarajan et
al., 2002): an utterance is first converted into
text, which is then used as a search query to
match the most similar items of an index using
IR techniques (Yu et al., 2007). For SMS replies,
we created an index of SMS response templates,
with slots for semantic concepts such as time and
place, from a large SMS corpus. After convolv-
ing recorded SMS replies so that the audio would
exhibit the acoustic characteristics of in-car rec-
ognition, they compared how the three approach-
es handled the convolved audio with respect to
the top n-best reply candidates. The voice search
approach consistently outperformed dictation and
canned responses, achieving as high as 89.7%
task completion with respect to the top 5 reply
candidates.
Even if the voice search approach may be
more robust to in-car noise, this does not guaran-
tee that it will be more usable. Indeed, because
voice search can only match semantic concepts
contained in the templates (which may or may
not utilize the same wording as the reply), users
must verify that a retrieved template matches the
semantics of their intended reply. For example,
suppose a user replies to the SMS message “how
about lunch” with “can’t right now running er-
rands”. Voice search may find “nope, got er-
rands to run” as the closest template match, in
which case, users will have to decide whether
this response has the same meaning as their re-
ply. This of course entails cognitive effort, which
is very limited in the context of driving. On the
other hand, a dictation approach to replying to
SMS messages may be far worse due to misre-
cognitions. For example, dictation may interpret
“can’t right now running errands” as “can right
</bodyText>
<page confidence="0.992797">
313
</page>
<note confidence="0.507241">
Proceedings of the ACL 2010 Conference Short Papers, pages 313–317,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999907727272727">
now fun in errands”. We posited that voice
search has the advantage because it always gene-
rates intelligible SMS replies (since response
templates are manually filtered), as opposed to
dictation, which can sometimes result in unpre-
dictable and nonsensical misrecognitions. How-
ever, this advantage has not been empirically
demonstrated in a user study. This paper presents
a user study investigating how the two approach-
es compare when users are actually driving – that
is, when usability matters most.
</bodyText>
<sectionHeader confidence="0.781214" genericHeader="method">
2 Driving Simulator Study
</sectionHeader>
<bodyText confidence="0.999978277777778">
Although ASR affords users hands-free, eyes-
free interaction, the benefits of leveraging speech
can be forfeit if users are expending cognitive
effort judging whether the speech interface cor-
rectly interpreted their utterances. Indeed, re-
search has shown that the cognitive demands of
dialogue seem to play a more important role in
distracting drivers than physically handling cell
phones (Nunes &amp; Recarte, 2002; Strayer &amp;
Johnston, 2001). Furthermore, Kun et al. (2007)
have found that when in-car speech interfaces
encounter recognition problems, users tend to
drive more dangerously as they attempt to figure
out why their utterances are failing. Hence, any
approach to replying to SMS messages in auto-
mobiles must avoid distracting drivers with er-
rors and be highly usable while users are en-
gaged in their primary task, driving.
</bodyText>
<subsectionHeader confidence="0.99375">
2.1 Method
</subsectionHeader>
<bodyText confidence="0.99993319047619">
To assess the usability and performance of both
the voice search approach and dictation, we con-
ducted a controlled experiment using the STISIM
DriveTM simulator. Our simulation setup con-
sisted of a central console with a steering wheel
and two turn signals, surrounded by three 47”
flat panels placed at a 45° angle to immerse the
driver. Figure 1 displays the setup.
We recruited 16 participants (9 males, 7 fe-
males) through an email sent to employees of our
organization. The mean age was 38.8. All partic-
ipants had a driver’s license and were compen-
sated for their time.
We examined two independent variables: SMS
Reply Approach, consisting of voice search and
dictation, and Driving Condition, consisting of
no driving, easy driving and difficult driving. We
included Driving Condition as a way of increas-
ing cognitive demand (see next section). Overall,
we conducted a 2 (SMS Reply Approach) X 3
(Driving Condition) repeated measures, within-
</bodyText>
<figureCaption confidence="0.997784">
Figure 1. Driving simulator setup.
</figureCaption>
<bodyText confidence="0.989541735294118">
subjects design experiment in which the order of
SMS Reply for each Driving Condition was coun-
ter-balanced. Because our primary variable of
interest was SMS Reply, we had users experience
both voice search and dictation with no driving
first, then easy driving, followed by difficult
driving. This gave users a chance to adjust them-
selves to increasingly difficult road conditions.
Driving Task: As the primary task, users were
asked to drive two courses we developed with
easy driving and difficult driving conditions
while obeying all rules of the road, as they would
in real driving and not in a videogame. With
speed limits ranging from 25 mph to 55 mph,
both courses contained five sequential sections
which took about 15-20 minutes to complete: a
residential area, a country highway, and a small
city with a downtown area as well as a busi-
ness/industrial park. Although both courses were
almost identical in the number of turns, curves,
stops, and traffic lights, the easy course consisted
mostly of simple road segments with relatively
no traffic, whereas the difficult course had four
times as many vehicles, cyclists, and pedestrians.
The difficult course also included a foggy road
section, a few busy construction sites, and many
unexpected events, such as a car in front sudden-
ly breaking, a parked car merging into traffic,
and a pedestrian jaywalking. In short, the diffi-
cult course was designed to fully engage the at-
tention and cognitive resources of drivers.
SMS Reply Task: As the secondary task, we
asked users to listen to an incoming SMS mes-
sage together with a formulated reply, such as:
</bodyText>
<listItem confidence="0.9832265">
(1) Message Received: `Are you lost?” Your
Reply: `No, never with my GPS”
</listItem>
<bodyText confidence="0.999549666666667">
The users were asked to repeat the reply back to
the system. For Example (1) above, users would
have to utter “No, never with my GPS”. Users
</bodyText>
<page confidence="0.995948">
314
</page>
<bodyText confidence="0.99997087962963">
could also say “Repeat” if they had any difficul-
ties understanding the TTS rendering or if they
experienced lapses in attention. For each course,
users engaged in 10 SMS reply tasks. SMS mes-
sages were cued every 3000 feet, roughly every
90 seconds, which provided enough time to
complete each SMS dialogue. Once users uttered
the formulated reply, they received a list of 4
possible reply candidates (each labeled as “One”,
“Two”, etc.), from which they were asked to ei-
ther pick the correct reply (by stating its number
at any time) or reject them all (by stating “All
wrong”). We did not provide any feedback about
whether the replies they picked were correct or
incorrect in order to avoid priming users to pay
more or less attention in subsequent messages.
Users did not have to finish listening to the entire
list before making their selection.
Stimuli: Because we were interested in examin-
ing which was worse, verifying whether SMS
response templates matched the meaning of an
intended reply, or deciphering the sometimes
nonsensical misrecognitions of dictation, we de-
cided to experimentally control both the SMS
reply uttered by the user as well as the 4-best list
generated by the system. However, all SMS rep-
lies and 4-best lists were derived from the logs of
an actual SMS Reply interface which imple-
mented the dictation and the voice search ap-
proaches (see Ju &amp; Paek, 2009). For each course,
5 of the SMS replies were short (with 3 or fewer
words) and 5 were long (with 4 to 7 words). The
mean length of the replies was 3.5 words (17.3
chars). The order of the short and long replies
was randomized.
We selected 4-best lists where the correct an-
swer was in each of four possible positions (1-4)
or All Wrong; that is, there were as many 4-best
lists with the first choice correct as there were
with the second choice correct, and so forth. We
then randomly ordered the presentation of differ-
ent 4-best lists. Although one might argue that
the four positions are not equally likely and that
the top item of a 4-best list is most often the cor-
rect answer, we decided to experimentally con-
trol the position for two reasons: first, our pre-
vious research (Ju &amp; Paek, 2009) had already
demonstrated the superiority of the voice search
approach with respect to the top position (i.e., 1-
best), and second, our experimental design
sought to identify whether the voice search ap-
proach was more usable than the dictation ap-
proach even when the ASR accuracy of the two
approaches was the same.
In the dictation condition, the correct answer
was not always an exact copy of the reply in 0-2
of the 10 SMS messages. For instance, a correct
dictation answer for Example (1) above was “no
I’m never with my GPS”. On the other hand, the
voice search condition had more cases (2-4 mes-
sages) in which the correct answer was not an
exact copy (e.g., “no I have GPS”) due to the
nature of the template approach. To some degree,
this could be seen as handicapping the voice
search condition, though the results did not re-
flect the disadvantage, as we discuss later.
Measures: Performance for both the driving task
and the SMS reply tasks were recorded. For the
driving task, we measured the numbers of colli-
sions, speeding (exceeding 10 mph above the
limit), traffic light and stop sign violations, and
missed or incorrect turns. For the SMS reply
task, we measured duration (i.e., time elapsed
between the beginning of the 4-best list and
when users ultimately provided their answer) and
the number of times users correctly identified
which of the 4 reply candidates contained the
correct answer.
Originally, we had an independent rater verify
the position of the correct answer in all 4-best
lists, however, we considered that some partici-
pants might be choosing replies that are semanti-
cally sufficient, even if they are not exactly cor-
rect. For example, a 4-best list generated by the
dictation approach for Example (1) had: “One:
no I’m never want my GPS. Two: no I’m never
with my GPS. Three: no I’m never when my
GPS. Or Four: no no I’m in my GPS.” Although
the rater identified the second reply as being
“correct”, a participant might view the first or
third replies as sufficient. In order to avoid am-
biguity about correctness, after the study, we
showed the same 16 participants the SMS mes-
sages and replies as well as the 4-best lists they
received during the study and asked them to se-
lect, for each SMS reply, any 4-best list items
they felt sufficiently conveyed the same mean-
ing, even if the items were ungrammatical. Par-
ticipants were explicitly told that they could se-
lect multiple items from the 4-best list. We did
not indicate which item they selected during the
experiment and because this selection task oc-
curred months after the experiment, it was un-
likely that they would remember anyway. Partic-
ipants were compensated with a cafeteria vouch-
er.
In computing the number of “correct” an-
swers, for each SMS reply, we counted an an-
</bodyText>
<page confidence="0.99833">
315
</page>
<bodyText confidence="0.9980594">
swer to be correct if it was included among the
participants’ set of semantically sufficient 4-best
list items. Hence, we calculated the number of
correct items in a personalized fashion for every
participant.
</bodyText>
<subsectionHeader confidence="0.921821">
2.2 Results
</subsectionHeader>
<bodyText confidence="0.999963666666667">
We conducted a series of repeated measures
ANOVAs on all driving task and SMS reply task
measures. For the driving task, we did not find
any statistically significant differences between
the voice search and dictation conditions. In oth-
er words, we could not reject the null hypothesis
that the two approaches were the same in terms
of their influence on driving performance. How-
ever, for the SMS reply task, we did find a main
effect for SMS Reply Approach (F1,47 = 81.28, p &lt;
.001, µDictation = 2.13 (.19), µVoiceSearch = .38 (.10)).
As shown in Figure 2, the average number of
errors per driving course for dictation is roughly
6 times that for voice search. We also found a
main effect for total duration (F1,47 = 11.94, p &lt;
.01, µDictation = 113.75 sec (3.54) or 11.4 sec/reply,
µVoiceSearch = 125.32 sec (3.37) or 12.5 sec/reply).
We discuss our explanation for the shorter dura-
tion below. For both errors and duration, we did
not find any interaction effects with Driving
Conditions.
</bodyText>
<sectionHeader confidence="0.999774" genericHeader="conclusions">
3 Discussion
</sectionHeader>
<bodyText confidence="0.999564291666667">
We conducted a simulator study in order to ex-
amine which was worse while driving: verifying
whether SMS response templates matched the
meaning of an intended reply, or deciphering the
sometimes nonsensical misrecognitions of dicta-
tion. Our results suggest that deciphering dicta-
tion results under the duress of driving leads to
more errors. In conducting a post-hoc error anal-
ysis, we noticed that participants tended to err
when the 4-best lists generated by the dictation
approach contained phonetically similar candi-
date replies. Because it is not atypical for the dic-
tation approach to have n-best list candidates
differing from each other in this way, we rec-
ommend not utilizing this approach in speech-
only user interfaces, unless the n-best list candi-
dates can be made as distinct from each other as
possible, phonetically, syntactically and most
importantly, semantically. The voice search ap-
proach circumvents this problem in two ways: 1)
templates were real responses and manually se-
lected and cleaned up during the development
phase so there were no grammatical mistakes,
and 2) semantically redundant templates can be
</bodyText>
<figureCaption confidence="0.998361666666667">
Figure 2. Mean number of errors for the dictation
and voice search approaches. Error bars represent
standard errors about the mean.
</figureCaption>
<bodyText confidence="0.99923735483871">
further discarded to only present the distinct con-
cepts at the rendering time using the paraphrase
detection algorithms reported in (Wu et al.,
2010).
Given that users committed more errors in the
dictation condition, we initially expected that
dictation would exhibit higher duration than
voice search since users might be spending more
time figuring out the differences between the
similar 4-best list candidates generated by the
dictation approach. However, in our error analy-
sis we observed that most likely users did not
discover the misrecognitions, and prematurely
selected a reply candidate, resulting in shorter
durations. The slightly higher duration for the
voice search approach does not constitute a prob-
lem if users are listening to all of their choices
and correctly selecting their intended SMS reply.
Note that the duration did not bring about any
significant driving performance differences.
Although we did not find any significant driv-
ing performance differences, users experienced
more difficulties confirming whether the dicta-
tion approach correctly interpreted their utter-
ances than they did with the voice search ap-
proach. As such, if a user deems it absolutely
necessary to respond to SMS messages while
driving, our simulator study suggests that the
most reliable (i.e., least error-prone) way to re-
spond may just well be the voice search ap-
proach.
</bodyText>
<sectionHeader confidence="0.999309" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.982952">
Distracted Driving Summit. 2009. Department of
Transportation. Retrieved Dec. 1:
http://www.rita.dot.gov/distracted_driving_summit
</reference>
<page confidence="0.990421">
316
</page>
<reference confidence="0.999865413793104">
Y.C. Ju &amp; T. Paek. 2009. A Voice Search Approach
to Replying to SMS Messages in Automobiles. In
Proc. of Interspeech.
A. Kun, T. Paek &amp; Z. Medenica. 2007. The Effect of
Speech Interface Accuracy on Driving Perfor-
mance, In Proc. of Interspeech.
P. Natarajan, R. Prasad, R. Schwartz, &amp; J. Makhoul.
2002. A Scalable Architecture for Directory Assis-
tance Automation. In Proc. of ICASSP, pp. 21-24.
L. Nunes &amp; M. Recarte. 2002. Cognitive Deamnds of
Hands-Free-Phone Conversation While Driving.
Transportation Research Part F, 5: 133-144.
N. Reed &amp; R. Robbins. 2008. The Effect of Text
Messaging on Driver Behaviour: A Simulator
Study. Transport Research Lab Report, PPR 367.
D. Strayer &amp; W. Johnston. 2001. Driven to Distrac-
tion: Dual-task Studies of Simulated Driving and
Conversing on a Cellular Phone. Psychological
Science, 12: 462-466.
R. Stross. 2008. “What carriers aren’t eager to tell you
about texting”, New York Times, Dec. 26, 2008:
http://www.nytimes.com/2008/12/28/business/28di
gi.html?_r=3
D. Yu, Y.C. Ju, Y.-Y. Wang, G. Zweig, &amp; A. Acero.
2007. Automated Directory Assistance System:
From Theory to Practice. In Proc. of Interspeech.
Wei Wu, Yun-Cheng Ju, Xiao Li, and Ye-Yi Wang,
Paraphrase Detection on SMS Messages in Auto-
mobiles, in ICASSP, IEEE, March 2010
</reference>
<page confidence="0.99862">
317
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.967556">
<title confidence="0.992962">Using Speech to Reply to SMS Messages While Driving: An In-Car Simulator User Study</title>
<author confidence="0.999809">Yun-Cheng Ju</author>
<author confidence="0.999809">Tim Paek</author>
<affiliation confidence="0.999787">Microsoft Research</affiliation>
<address confidence="0.991095">Redmond, WA USA</address>
<email confidence="0.999858">{yuncj|timpaek}@microsoft.com</email>
<abstract confidence="0.9995325">Speech recognition affords automobile drivers a hands-free, eyes-free method of replying to Short Message Service (SMS) text messages. Although a voice search approach based on template matching has been shown to be more robust to the challenging acoustic environment of automobiles than using dictation, users may have difficulties verifying whether SMS response templates match their intended meaning, especially while driving. Using a high-fidelity driving simulator, we compared dictation for SMS replies versus voice search in increasingly difficult driving conditions. Although the two approaches did not differ in terms of driving performance measures, users made about six times more errors on average using dictation than voice search.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Distracted Driving Summit</author>
</authors>
<date>2009</date>
<volume>1</volume>
<pages>http://www.rita.dot.gov/distracted_driving_summit</pages>
<institution>Department of Transportation. Retrieved</institution>
<marker>Summit, 2009</marker>
<rawString>Distracted Driving Summit. 2009. Department of Transportation. Retrieved Dec. 1: http://www.rita.dot.gov/distracted_driving_summit</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y C Ju</author>
<author>T Paek</author>
</authors>
<title>A Voice Search Approach to Replying to SMS Messages in Automobiles.</title>
<date>2009</date>
<booktitle>In Proc. of Interspeech.</booktitle>
<contexts>
<context position="1874" citStr="Ju &amp; Paek, 2009" startWordPosition="285" endWordPosition="288">n launched by states, governments and even cell phone carriers to discourage and ban SMS messaging while driving (DOT, 2009). Yet, automobile manufacturers have started to offer infotainment systems, such as the Ford Sync, which feature the ability to listen to incoming SMS messages using text-to-speech (TTS). Automatic speech recognition (ASR) affords users a hands-free, eyes-free method of replying to SMS messages. However, to date, manufacturers have not established a safe and reliable method of leveraging ASR, though some researchers have begun to explore techniques. In previous research (Ju &amp; Paek, 2009), we examined three ASR approaches to replying to SMS messages: dictation using a language model trained on SMS responses, canned responses using a probabilistic context-free grammar (PCFG), and a “voice search” approach based on template matching. Voice search proceeds in two steps (Natarajan et al., 2002): an utterance is first converted into text, which is then used as a search query to match the most similar items of an index using IR techniques (Yu et al., 2007). For SMS replies, we created an index of SMS response templates, with slots for semantic concepts such as time and place, from a</context>
<context position="9565" citStr="Ju &amp; Paek, 2009" startWordPosition="1555" endWordPosition="1558">d not have to finish listening to the entire list before making their selection. Stimuli: Because we were interested in examining which was worse, verifying whether SMS response templates matched the meaning of an intended reply, or deciphering the sometimes nonsensical misrecognitions of dictation, we decided to experimentally control both the SMS reply uttered by the user as well as the 4-best list generated by the system. However, all SMS replies and 4-best lists were derived from the logs of an actual SMS Reply interface which implemented the dictation and the voice search approaches (see Ju &amp; Paek, 2009). For each course, 5 of the SMS replies were short (with 3 or fewer words) and 5 were long (with 4 to 7 words). The mean length of the replies was 3.5 words (17.3 chars). The order of the short and long replies was randomized. We selected 4-best lists where the correct answer was in each of four possible positions (1-4) or All Wrong; that is, there were as many 4-best lists with the first choice correct as there were with the second choice correct, and so forth. We then randomly ordered the presentation of different 4-best lists. Although one might argue that the four positions are not equally</context>
</contexts>
<marker>Ju, Paek, 2009</marker>
<rawString>Y.C. Ju &amp; T. Paek. 2009. A Voice Search Approach to Replying to SMS Messages in Automobiles. In Proc. of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kun</author>
<author>T Paek</author>
<author>Z Medenica</author>
</authors>
<title>The Effect of Speech Interface Accuracy on Driving Performance,</title>
<date>2007</date>
<booktitle>In Proc. of Interspeech.</booktitle>
<contexts>
<context position="4996" citStr="Kun et al. (2007)" startWordPosition="790" endWordPosition="793">tudy investigating how the two approaches compare when users are actually driving – that is, when usability matters most. 2 Driving Simulator Study Although ASR affords users hands-free, eyesfree interaction, the benefits of leveraging speech can be forfeit if users are expending cognitive effort judging whether the speech interface correctly interpreted their utterances. Indeed, research has shown that the cognitive demands of dialogue seem to play a more important role in distracting drivers than physically handling cell phones (Nunes &amp; Recarte, 2002; Strayer &amp; Johnston, 2001). Furthermore, Kun et al. (2007) have found that when in-car speech interfaces encounter recognition problems, users tend to drive more dangerously as they attempt to figure out why their utterances are failing. Hence, any approach to replying to SMS messages in automobiles must avoid distracting drivers with errors and be highly usable while users are engaged in their primary task, driving. 2.1 Method To assess the usability and performance of both the voice search approach and dictation, we conducted a controlled experiment using the STISIM DriveTM simulator. Our simulation setup consisted of a central console with a steer</context>
</contexts>
<marker>Kun, Paek, Medenica, 2007</marker>
<rawString>A. Kun, T. Paek &amp; Z. Medenica. 2007. The Effect of Speech Interface Accuracy on Driving Performance, In Proc. of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Natarajan</author>
<author>R Prasad</author>
<author>R Schwartz</author>
<author>J Makhoul</author>
</authors>
<title>A Scalable Architecture for Directory Assistance Automation.</title>
<date>2002</date>
<booktitle>In Proc. of ICASSP,</booktitle>
<pages>21--24</pages>
<contexts>
<context position="2182" citStr="Natarajan et al., 2002" startWordPosition="331" endWordPosition="334">ech (TTS). Automatic speech recognition (ASR) affords users a hands-free, eyes-free method of replying to SMS messages. However, to date, manufacturers have not established a safe and reliable method of leveraging ASR, though some researchers have begun to explore techniques. In previous research (Ju &amp; Paek, 2009), we examined three ASR approaches to replying to SMS messages: dictation using a language model trained on SMS responses, canned responses using a probabilistic context-free grammar (PCFG), and a “voice search” approach based on template matching. Voice search proceeds in two steps (Natarajan et al., 2002): an utterance is first converted into text, which is then used as a search query to match the most similar items of an index using IR techniques (Yu et al., 2007). For SMS replies, we created an index of SMS response templates, with slots for semantic concepts such as time and place, from a large SMS corpus. After convolving recorded SMS replies so that the audio would exhibit the acoustic characteristics of in-car recognition, they compared how the three approaches handled the convolved audio with respect to the top n-best reply candidates. The voice search approach consistently outperformed</context>
</contexts>
<marker>Natarajan, Prasad, Schwartz, Makhoul, 2002</marker>
<rawString>P. Natarajan, R. Prasad, R. Schwartz, &amp; J. Makhoul. 2002. A Scalable Architecture for Directory Assistance Automation. In Proc. of ICASSP, pp. 21-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Nunes</author>
<author>M Recarte</author>
</authors>
<title>Cognitive Deamnds of Hands-Free-Phone Conversation While Driving.</title>
<date>2002</date>
<journal>Transportation Research Part F,</journal>
<volume>5</volume>
<pages>133--144</pages>
<contexts>
<context position="4937" citStr="Nunes &amp; Recarte, 2002" startWordPosition="781" endWordPosition="784">ally demonstrated in a user study. This paper presents a user study investigating how the two approaches compare when users are actually driving – that is, when usability matters most. 2 Driving Simulator Study Although ASR affords users hands-free, eyesfree interaction, the benefits of leveraging speech can be forfeit if users are expending cognitive effort judging whether the speech interface correctly interpreted their utterances. Indeed, research has shown that the cognitive demands of dialogue seem to play a more important role in distracting drivers than physically handling cell phones (Nunes &amp; Recarte, 2002; Strayer &amp; Johnston, 2001). Furthermore, Kun et al. (2007) have found that when in-car speech interfaces encounter recognition problems, users tend to drive more dangerously as they attempt to figure out why their utterances are failing. Hence, any approach to replying to SMS messages in automobiles must avoid distracting drivers with errors and be highly usable while users are engaged in their primary task, driving. 2.1 Method To assess the usability and performance of both the voice search approach and dictation, we conducted a controlled experiment using the STISIM DriveTM simulator. Our s</context>
</contexts>
<marker>Nunes, Recarte, 2002</marker>
<rawString>L. Nunes &amp; M. Recarte. 2002. Cognitive Deamnds of Hands-Free-Phone Conversation While Driving. Transportation Research Part F, 5: 133-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Reed</author>
<author>R Robbins</author>
</authors>
<title>The Effect of Text Messaging on Driver Behaviour: A Simulator Study. Transport Research Lab Report,</title>
<date>2008</date>
<tech>PPR 367.</tech>
<contexts>
<context position="1238" citStr="Reed &amp; Robbins, 2008" startWordPosition="186" endWordPosition="189">a high-fidelity driving simulator, we compared dictation for SMS replies versus voice search in increasingly difficult driving conditions. Although the two approaches did not differ in terms of driving performance measures, users made about six times more errors on average using dictation than voice search. 1 Introduction Users love Short Message Service (SMS) text messaging; so much so that 3 trillion SMS messages are expected to have been sent in 2009 alone (Stross, 2008). Because research has shown that SMS messaging while driving results in 35% slower reaction time than being intoxicated (Reed &amp; Robbins, 2008), campaigns have been launched by states, governments and even cell phone carriers to discourage and ban SMS messaging while driving (DOT, 2009). Yet, automobile manufacturers have started to offer infotainment systems, such as the Ford Sync, which feature the ability to listen to incoming SMS messages using text-to-speech (TTS). Automatic speech recognition (ASR) affords users a hands-free, eyes-free method of replying to SMS messages. However, to date, manufacturers have not established a safe and reliable method of leveraging ASR, though some researchers have begun to explore techniques. In</context>
</contexts>
<marker>Reed, Robbins, 2008</marker>
<rawString>N. Reed &amp; R. Robbins. 2008. The Effect of Text Messaging on Driver Behaviour: A Simulator Study. Transport Research Lab Report, PPR 367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Strayer</author>
<author>W Johnston</author>
</authors>
<title>Driven to Distraction: Dual-task Studies of Simulated Driving and Conversing on a Cellular Phone.</title>
<date>2001</date>
<journal>Psychological Science,</journal>
<volume>12</volume>
<pages>462--466</pages>
<contexts>
<context position="4964" citStr="Strayer &amp; Johnston, 2001" startWordPosition="785" endWordPosition="788">user study. This paper presents a user study investigating how the two approaches compare when users are actually driving – that is, when usability matters most. 2 Driving Simulator Study Although ASR affords users hands-free, eyesfree interaction, the benefits of leveraging speech can be forfeit if users are expending cognitive effort judging whether the speech interface correctly interpreted their utterances. Indeed, research has shown that the cognitive demands of dialogue seem to play a more important role in distracting drivers than physically handling cell phones (Nunes &amp; Recarte, 2002; Strayer &amp; Johnston, 2001). Furthermore, Kun et al. (2007) have found that when in-car speech interfaces encounter recognition problems, users tend to drive more dangerously as they attempt to figure out why their utterances are failing. Hence, any approach to replying to SMS messages in automobiles must avoid distracting drivers with errors and be highly usable while users are engaged in their primary task, driving. 2.1 Method To assess the usability and performance of both the voice search approach and dictation, we conducted a controlled experiment using the STISIM DriveTM simulator. Our simulation setup consisted o</context>
</contexts>
<marker>Strayer, Johnston, 2001</marker>
<rawString>D. Strayer &amp; W. Johnston. 2001. Driven to Distraction: Dual-task Studies of Simulated Driving and Conversing on a Cellular Phone. Psychological Science, 12: 462-466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stross</author>
</authors>
<title>What carriers aren’t eager to tell you about texting”,</title>
<date>2008</date>
<location>New York Times,</location>
<note>http://www.nytimes.com/2008/12/28/business/28di gi.html?_r=3</note>
<contexts>
<context position="1095" citStr="Stross, 2008" startWordPosition="165" endWordPosition="166">on, users may have difficulties verifying whether SMS response templates match their intended meaning, especially while driving. Using a high-fidelity driving simulator, we compared dictation for SMS replies versus voice search in increasingly difficult driving conditions. Although the two approaches did not differ in terms of driving performance measures, users made about six times more errors on average using dictation than voice search. 1 Introduction Users love Short Message Service (SMS) text messaging; so much so that 3 trillion SMS messages are expected to have been sent in 2009 alone (Stross, 2008). Because research has shown that SMS messaging while driving results in 35% slower reaction time than being intoxicated (Reed &amp; Robbins, 2008), campaigns have been launched by states, governments and even cell phone carriers to discourage and ban SMS messaging while driving (DOT, 2009). Yet, automobile manufacturers have started to offer infotainment systems, such as the Ford Sync, which feature the ability to listen to incoming SMS messages using text-to-speech (TTS). Automatic speech recognition (ASR) affords users a hands-free, eyes-free method of replying to SMS messages. However, to date</context>
</contexts>
<marker>Stross, 2008</marker>
<rawString>R. Stross. 2008. “What carriers aren’t eager to tell you about texting”, New York Times, Dec. 26, 2008: http://www.nytimes.com/2008/12/28/business/28di gi.html?_r=3</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yu</author>
<author>Y C Ju</author>
<author>Y-Y Wang</author>
<author>G Zweig</author>
<author>A Acero</author>
</authors>
<title>Automated Directory Assistance System: From Theory to Practice.</title>
<date>2007</date>
<booktitle>In Proc. of Interspeech.</booktitle>
<contexts>
<context position="2345" citStr="Yu et al., 2007" startWordPosition="362" endWordPosition="365">ed a safe and reliable method of leveraging ASR, though some researchers have begun to explore techniques. In previous research (Ju &amp; Paek, 2009), we examined three ASR approaches to replying to SMS messages: dictation using a language model trained on SMS responses, canned responses using a probabilistic context-free grammar (PCFG), and a “voice search” approach based on template matching. Voice search proceeds in two steps (Natarajan et al., 2002): an utterance is first converted into text, which is then used as a search query to match the most similar items of an index using IR techniques (Yu et al., 2007). For SMS replies, we created an index of SMS response templates, with slots for semantic concepts such as time and place, from a large SMS corpus. After convolving recorded SMS replies so that the audio would exhibit the acoustic characteristics of in-car recognition, they compared how the three approaches handled the convolved audio with respect to the top n-best reply candidates. The voice search approach consistently outperformed dictation and canned responses, achieving as high as 89.7% task completion with respect to the top 5 reply candidates. Even if the voice search approach may be mo</context>
</contexts>
<marker>Yu, Ju, Wang, Zweig, Acero, 2007</marker>
<rawString>D. Yu, Y.C. Ju, Y.-Y. Wang, G. Zweig, &amp; A. Acero. 2007. Automated Directory Assistance System: From Theory to Practice. In Proc. of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wu</author>
<author>Yun-Cheng Ju</author>
<author>Xiao Li</author>
<author>Ye-Yi Wang</author>
</authors>
<date>2010</date>
<booktitle>Paraphrase Detection on SMS Messages in Automobiles, in ICASSP, IEEE,</booktitle>
<contexts>
<context position="15763" citStr="Wu et al., 2010" startWordPosition="2617" endWordPosition="2620">ch other as possible, phonetically, syntactically and most importantly, semantically. The voice search approach circumvents this problem in two ways: 1) templates were real responses and manually selected and cleaned up during the development phase so there were no grammatical mistakes, and 2) semantically redundant templates can be Figure 2. Mean number of errors for the dictation and voice search approaches. Error bars represent standard errors about the mean. further discarded to only present the distinct concepts at the rendering time using the paraphrase detection algorithms reported in (Wu et al., 2010). Given that users committed more errors in the dictation condition, we initially expected that dictation would exhibit higher duration than voice search since users might be spending more time figuring out the differences between the similar 4-best list candidates generated by the dictation approach. However, in our error analysis we observed that most likely users did not discover the misrecognitions, and prematurely selected a reply candidate, resulting in shorter durations. The slightly higher duration for the voice search approach does not constitute a problem if users are listening to al</context>
</contexts>
<marker>Wu, Ju, Li, Wang, 2010</marker>
<rawString>Wei Wu, Yun-Cheng Ju, Xiao Li, and Ye-Yi Wang, Paraphrase Detection on SMS Messages in Automobiles, in ICASSP, IEEE, March 2010</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>