<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000186">
<title confidence="0.970962">
Dirt Cheap Web-Scale Parallel Text from the Common Crawl
</title>
<author confidence="0.91501">
Jason R. Smith1,2 Herve Saint-Amand3 Magdalena Plamada4
</author>
<email confidence="0.956868">
jsmith@cs.jhu.edu herve@saintamh.org plamada@cl.uzh.ch
</email>
<author confidence="0.921937">
Philipp Koehn3 Chris Callison-Burch1,2,5 Adam Lopez1,2
</author>
<email confidence="0.820598">
pkoehn@inf.ed.ac.uk ccb@cs.jhu.edu ∗ alopez@cs.jhu.edu
</email>
<affiliation confidence="0.9905904">
1Department of Computer Science, Johns Hopkins University
2Human Language Technology Center of Excellence, Johns Hopkins University
3School of Informatics, University of Edinburgh
4Institute of Computational Linguistics, University of Zurich
5Computer and Information Science Department, University of Pennsylvania
</affiliation>
<sectionHeader confidence="0.979087" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999983961538461">
Parallel text is the fuel that drives modern
machine translation systems. The Web is a
comprehensive source of preexisting par-
allel text, but crawling the entire web is
impossible for all but the largest compa-
nies. We bring web-scale parallel text to
the masses by mining the Common Crawl,
a public Web crawl hosted on Amazon’s
Elastic Cloud. Starting from nothing more
than a set of common two-letter language
codes, our open-source extension of the
STRAND algorithm mined 32 terabytes of
the crawl in just under a day, at a cost of
about $500. Our large-scale experiment
uncovers large amounts of parallel text in
dozens of language pairs across a variety
of domains and genres, some previously
unavailable in curated datasets. Even with
minimal cleaning and filtering, the result-
ing data boosts translation performance
across the board for five different language
pairs in the news domain, and on open do-
main test sets we see improvements of up
to 5 BLEU. We make our code and data
available for other researchers seeking to
mine this rich new data resource.1
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999196">
A key bottleneck in porting statistical machine
translation (SMT) technology to new languages
and domains is the lack of readily available paral-
lel corpora beyond curated datasets. For a handful
of language pairs, large amounts of parallel data
</bodyText>
<footnote confidence="0.829646">
∗This research was conducted while Chris Callison-
Burch was at Johns Hopkins University.
1github.com/jrs026/CommonCrawlMiner
</footnote>
<bodyText confidence="0.999686756756757">
are readily available, ordering in the hundreds of
millions of words for Chinese-English and Arabic-
English, and in tens of millions of words for many
European languages (Koehn, 2005). In each case,
much of this data consists of government and news
text. However, for most language pairs and do-
mains there is little to no curated parallel data
available. Hence discovery of parallel data is an
important first step for translation between most
of the world’s languages.
The Web is an important source of parallel
text. Many websites are available in multiple
languages, and unlike other potential sources—
such as multilingual news feeds (Munteanu and
Marcu, 2005) or Wikipedia (Smith et al., 2010)—
it is common to find document pairs that are di-
rect translations of one another. This natural par-
allelism simplifies the mining task, since few re-
sources or existing corpora are needed at the outset
to bootstrap the extraction process.
Parallel text mining from the Web was origi-
nally explored by individuals or small groups of
academic researchers using search engines (Nie
et al., 1999; Chen and Nie, 2000; Resnik, 1999;
Resnik and Smith, 2003). However, anything
more sophisticated generally requires direct access
to web-crawled documents themselves along with
the computing power to process them. For most
researchers, this is prohibitively expensive. As a
consequence, web-mined parallel text has become
the exclusive purview of large companies with the
computational resources to crawl, store, and pro-
cess the entire Web.
To put web-mined parallel text back in the
hands of individual researchers, we mine parallel
text from the Common Crawl, a regularly updated
81-terabyte snapshot of the public internet hosted
</bodyText>
<page confidence="0.953683">
1374
</page>
<note confidence="0.914376">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1374–1383,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.997424636363637">
on Amazon’s Elastic Cloud (EC2) service.2 Us-
ing the Common Crawl completely removes the
bottleneck of web crawling, and makes it possi-
ble to run algorithms on a substantial portion of
the web at very low cost. Starting from nothing
other than a set of language codes, our extension
of the STRAND algorithm (Resnik and Smith,
2003) identifies potentially parallel documents us-
ing cues from URLs and document content (§2).
We conduct an extensive empirical exploration of
the web-mined data, demonstrating coverage in
a wide variety of languages and domains (§3).
Even without extensive pre-processing, the data
improves translation performance on strong base-
line news translation systems in five different lan-
guage pairs (§4). On general domain and speech
translation tasks where test conditions substan-
tially differ from standard government and news
training text, web-mined training data improves
performance substantially, resulting in improve-
ments of up to 1.5 BLEU on standard test sets, and
5 BLEU on test sets outside of the news domain.
</bodyText>
<sectionHeader confidence="0.826842" genericHeader="method">
2 Mining the Common Crawl
</sectionHeader>
<bodyText confidence="0.995548777777778">
The Common Crawl corpus is hosted on Ama-
zon’s Simple Storage Service (S3). It can be
downloaded to a local cluster, but the transfer cost
is prohibitive at roughly 10 cents per gigabyte,
making the total over $8000 for the full dataset.3
However, it is unnecessary to obtain a copy of the
data since it can be accessed freely from Amazon’s
Elastic Compute Cloud (EC2) or Elastic MapRe-
duce (EMR) services. In our pipeline, we per-
form the first step of identifying candidate docu-
ment pairs using Amazon EMR, download the re-
sulting document pairs, and perform the remain-
ing steps on our local cluster. We chose EMR be-
cause our candidate matching strategy fit naturally
into the Map-Reduce framework (Dean and Ghe-
mawat, 2004).
Our system is based on the STRAND algorithm
(Resnik and Smith, 2003):
</bodyText>
<listItem confidence="0.9870694">
1. Candidate pair selection: Retrieve candidate
document pairs from the CommonCrawl cor-
pus.
2. Structural Filtering:
(a) Convert the HTML of each document
</listItem>
<footnote confidence="0.994221">
2commoncrawl.org
3http://aws.amazon.com/s3/pricing/
</footnote>
<bodyText confidence="0.5863015">
into a sequence of start tags, end tags,
and text chunks.
</bodyText>
<listItem confidence="0.990185166666667">
(b) Align the linearized HTML of candidate
document pairs.
(c) Decide whether to accept or reject each
pair based on features of the alignment.
3. Segmentation: For each text chunk, perform
sentence and word segmentation.
4. Sentence Alignment: For each aligned pair of
text chunks, perform the sentence alignment
method of Gale and Church (1993).
5. Sentence Filtering: Remove sentences that
appear to be boilerplate.
Candidate Pair Selection We adopt a strategy
</listItem>
<bodyText confidence="0.934484285714286">
similar to that of Resnik and Smith (2003) for find-
ing candidate parallel documents, adapted to the
parallel architecture of Map-Reduce.
The mapper operates on each website entry in
the CommonCrawl data. It scans the URL string
for some indicator of its language. Specifically,
we check for:
</bodyText>
<listItem confidence="0.999019333333333">
1. Two/three letter language codes (ISO-639).
2. Language names in English and in the lan-
guage of origin.
</listItem>
<bodyText confidence="0.994974777777778">
If either is present in a URL and surrounded by
non-alphanumeric characters, the URL is identi-
fied as a potential match and the mapper outputs
a key value pair in which the key is the original
URL with the matching string replaced by *, and
the value is the original URL, language name, and
full HTML of the page. For example, if we en-
counter the URL www.website.com/fr/, we
output the following.
</bodyText>
<listItem confidence="0.980304666666667">
• Key: www.website.com/*/
• Value: www.website.com/fr/, French,
(full website entry)
</listItem>
<bodyText confidence="0.999661444444444">
The reducer then receives all websites mapped
to the same “language independent” URL. If two
or more websites are associated with the same key,
the reducer will output all associated values, as
long as they are not in the same language, as de-
termined by the language identifier in the URL.
This URL-based matching is a simple and in-
expensive solution to the problem of finding can-
didate document pairs. The mapper will discard
</bodyText>
<page confidence="0.983189">
1375
</page>
<bodyText confidence="0.999921559322034">
most, and neither the mapper nor the reducer do
anything with the HTML of the documents aside
from reading and writing them. This approach is
very simple and likely misses many good potential
candidates, but has the advantage that it requires
no information other than a set of language codes,
and runs in time roughly linear in the size of the
dataset.
Structural Filtering A major component of the
STRAND system is the alignment of HTML docu-
ments. This alignment is used to determine which
document pairs are actually parallel, and if they
are, to align pairs of text blocks within the docu-
ments.
The first step of structural filtering is to lin-
earize the HTML. This means converting its DOM
tree into a sequence of start tags, end tags, and
chunks of text. Some tags (those usually found
within text, such as “font” and “a”) are ignored
during this step. Next, the tag/chunk sequences
are aligned using dynamic programming. The ob-
jective of the alignment is to maximize the number
of matching items.
Given this alignment, Resnik and Smith (2003)
define a small set of features which indicate the
alignment quality. They annotated a set of docu-
ment pairs as parallel or non-parallel, and trained
a classifier on this data. We also annotated 101
Spanish-English document pairs in this way and
trained a maximum entropy classifier. However,
even when using the best performing subset of fea-
tures, the classifier only performed as well as a
naive classifier which labeled every document pair
as parallel, in both accuracy and F1. For this rea-
son, we excluded the classifier from our pipeline.
The strong performance of the naive baseline was
likely due to the unbalanced nature of the anno-
tated data— 80% of the document pairs that we
annotated were parallel.
Segmentation The text chunks from the previ-
ous step may contain several sentences, so before
the sentence alignment step we must perform sen-
tence segmentation. We use the Punkt sentence
splitter from NLTK (Loper and Bird, 2002) to
perform both sentence and word segmentation on
each text chunk.
Sentence Alignment For each aligned text
chunk pair, we perform sentence alignment using
the algorithm of Gale and Church (1993).
Sentence Filtering Since we do not perform any
boilerplate removal in earlier steps, there are many
sentence pairs produced by the pipeline which
contain menu items or other bits of text which are
not useful to an SMT system. We avoid perform-
ing any complex boilerplate removal and only re-
move segment pairs where either the source and
target text are identical, or where the source or
target segments appear more than once in the ex-
tracted corpus.
</bodyText>
<subsectionHeader confidence="0.464872">
3 Analysis of the Common Crawl Data
</subsectionHeader>
<bodyText confidence="0.999986576923077">
We ran our algorithm on the 2009-2010 version
of the crawl, consisting of 32.3 terabytes of data.
Since the full dataset is hosted on EC2, the only
cost to us is CPU time charged by Amazon, which
came to a total of about $400, and data stor-
age/transfer costs for our output, which came to
roughly $100. For practical reasons we split the
run into seven subsets, on which the full algo-
rithm was run independently. This is different
from running a single Map-Reduce job over the
entire dataset, since websites in different subsets
of the data cannot be matched. However, since
the data is stored as it is crawled, it is likely that
matching websites will be found in the same split
of the data. Table 1 shows the amount of raw par-
allel data obtained for a large selection of language
pairs.
As far as we know, ours is the first system built
to mine parallel text from the Common Crawl.
Since the resource is new, we wanted to under-
stand the quantity, quality, and type of data that
we are likely to obtain from it. To this end, we
conducted a number of experiments to measure
these features. Since our mining heuristics are
very simple, these results can be construed as a
lower bound on what is actually possible.
</bodyText>
<subsectionHeader confidence="0.998946">
3.1 Recall Estimates
</subsectionHeader>
<bodyText confidence="0.999968090909091">
Our first question is about recall: of all the pos-
sible parallel text that is actually available on the
Web, how much does our algorithm actually find
in the Common Crawl? Although this question
is difficult to answer precisely, we can estimate
an answer by comparing our mined URLs against
a large collection of previously mined URLs that
were found using targeted techniques: those in the
French-English Gigaword corpus (Callison-Burch
et al., 2011).
We found that 45% of the URL pairs would
</bodyText>
<page confidence="0.968397">
1376
</page>
<table confidence="0.9992975">
French German Spanish Russian Japanese Chinese
Segments 10.2M 7.50M 5.67M 3.58M 1.70M 1.42M
Source Tokens 128M 79.9M 71.5M 34.7M 9.91M 8.14M
Target Tokens 118M 87.5M 67.6M 36.7M 19.1M 14.8M
Arabic Bulgarian Czech Korean Tamil Urdu
Segments 1.21M 909K 848K 756K 116K 52.1K
Source Tokens 13.1M 8.48M 7.42M 6.56M 1.01M 734K
Target Tokens 13.5M 8.61M 8.20M 7.58M 996K 685K
Bengali Farsi Telugu Somali Kannada Pashto
Segments 59.9K 44.2K 50.6K 52.6K 34.5K 28.0K
Source Tokens 573K 477K 336K 318K 305K 208K
Target Tokens 537K 459K 358K 325K 297K 218K
</table>
<tableCaption confidence="0.999531">
Table 1: The amount of parallel data mined from CommonCrawl for each language paired with English.
</tableCaption>
<bodyText confidence="0.914751545454545">
Source tokens are counts of the foreign language tokens, and target tokens are counts of the English
language tokens.
have been discovered by our heuristics, though we
actually only find 3.6% of these URLs in our out-
put.4 If we had included “f” and “e” as identi-
fiers for French and English respectively, coverage
of the URL pairs would increase to 74%. How-
ever, we chose not to include single letter identi-
fiers in our experiments due to the high number of
false positives they generated in preliminary ex-
periments.
</bodyText>
<subsectionHeader confidence="0.999321">
3.2 Precision Estimates
</subsectionHeader>
<bodyText confidence="0.99997875">
Since our algorithms rely on cues that are mostly
external to the contents of the extracted data
and have no knowledge of actual languages, we
wanted to evaluate the precision of our algorithm:
how much of the mined data actually consists of
parallel sentences?
To measure this, we conducted a manual anal-
ysis of 200 randomly selected sentence pairs for
each of three language pairs. The texts are het-
erogeneous, covering several topical domains like
tourism, advertising, technical specifications, fi-
nances, e-commerce and medicine. For German-
English, 78% of the extracted data represent per-
fect translations, 4% are paraphrases of each other
(convey a similar meaning, but cannot be used
for SMT training) and 18% represent misalign-
ments. Furthermore, 22% of the true positives
are potentially machine translations (judging by
the quality), whereas in 13% of the cases one of
the sentences contains additional content not ex-
</bodyText>
<footnote confidence="0.9840315">
4The difference is likely due to the coverage of the Com-
monCrawl corpus.
</footnote>
<bodyText confidence="0.999653416666667">
pressed in the other. As for the false positives,
13.5% of them have either the source or target
sentence in the wrong language, and the remain-
ing ones representing failures in the alignment
process. Across three languages, our inspection
revealed that around 80% of randomly sampled
data appeared to contain good translations (Table
2). Although this analysis suggests that language
identification and SMT output detection (Venu-
gopal et al., 2011) may be useful additions to the
pipeline, we regard this as reasonably high preci-
sion for our simple algorithm.
</bodyText>
<table confidence="0.99708825">
Language Precision
Spanish 82%
French 81%
German 78%
</table>
<tableCaption confidence="0.962818">
Table 2: Manual evaluation of precision (by sen-
</tableCaption>
<bodyText confidence="0.975431142857143">
tence pair) on the extracted parallel data for Span-
ish, French, and German (paired with English).
In addition to the manual evaluation of preci-
sion, we applied language identification to our
extracted parallel data for several additional lan-
guages. We used the “langid.py” tool (Lui and
Baldwin, 2012) at the segment level, and report the
percentage of sentence pairs where both sentences
were recognized as the correct language. Table 3
shows our results. Comparing against our man-
ual evaluation from Table 2, it appears that many
sentence pairs are being incorrectly judged as non-
parallel. This is likely because language identifi-
cation tends to perform poorly on short segments.
</bodyText>
<page confidence="0.9348">
1377
</page>
<table confidence="0.999861625">
French German Spanish Arabic
63% 61% 58% 51%
Chinese Japanese Korean Czech
50% 48% 48% 47%
Russian Urdu Bengali Tamil
44% 31% 14% 12%
Kannada Telugu Kurdish
12% 6.3% 2.9%
</table>
<tableCaption confidence="0.799035333333333">
Table 3: Automatic evaluation of precision
through language identification for several lan-
guages paired with English.
</tableCaption>
<subsectionHeader confidence="0.998995">
3.3 Domain Name and Topic Analysis
</subsectionHeader>
<bodyText confidence="0.999925573770492">
Although the above measures tell us something
about how well our algorithms perform in aggre-
gate for specific language pairs, we also wondered
about the actual contents of the data. A major
difficulty in applying SMT even on languages for
which we have significant quantities of parallel
text is that most of that parallel text is in the news
and government domains. When applied to other
genres, such systems are notoriously brittle. What
kind of genres are represented in the Common
Crawl data?
We first looked at the domain names which con-
tributed the most data. Table 4 gives the top five
domains by the number of tokens. The top two do-
main names are related to travel, and they account
for about 10% of the total data.
We also applied Latent Dirichlet Allocation
(LDA; Blei et al., 2003) to learn a distribution over
latent topics in the extracted data, as this is a pop-
ular exploratory data analysis method. In LDA
a topic is a unigram distribution over words, and
each document is modeled as a distribution over
topics. To create a set of documents from the ex-
tracted CommonCrawl data, we took the English
side of the extracted parallel segments for each
URL in the Spanish-English portion of the data.
This gave us a total of 444,022 documents. In
our first experiment, we used the MALLET toolkit
(McCallum, 2002) to generate 20 topics, which
are shown in Table 5.
Some of the topics that LDA finds cor-
respond closely with specific domains,
such as topics 1 (blingee.com) and 2
(opensubtitles.org). Several of the topics
correspond to the travel domain. Foreign stop
words appear in a few of the topics. Since our sys-
tem does not include any language identification,
this is not surprising.5 However it does suggest an
avenue for possible improvement.
In our second LDA experiment, we compared
our extracted CommonCrawl data with Europarl.
We created a set of documents from both Com-
monCrawl and Europarl, and again used MAL-
LET to generate 100 topics for this data.6 We then
labeled each document by its most likely topic (as
determined by that topic’s mixture weights), and
counted the number of documents from Europarl
and CommonCrawl for which each topic was most
prominent. While this is very rough, it gives some
idea of where each topic is coming from. Table 6
shows a sample of these topics.
In addition to exploring topics in the datasets,
we also performed additional intrinsic evaluation
at the domain level, choosing top domains for
three language pairs. We specifically classified
sentence pairs as useful or boilerplate (Table 7).
Among our observations, we find that commer-
cial websites tend to contain less boilerplate ma-
terial than encyclopedic websites, and that the ra-
tios tend to be similar across languages in the same
domain.
</bodyText>
<table confidence="0.96049775">
FR ES DE
www.booking.com 52% 71% 52%
www.hotel.info 34% 44% -
memory-alpha.org 34% 25% 55%
</table>
<tableCaption confidence="0.78573575">
Table 7: Percentage of useful (non-boilerplate)
sentences found by domain and language pair.
hotel.info was not found in our German-
English data.
</tableCaption>
<sectionHeader confidence="0.995697" genericHeader="method">
4 Machine Translation Experiments
</sectionHeader>
<bodyText confidence="0.999965111111111">
For our SMT experiments, we use the Moses
toolkit (Koehn et al., 2007). In these experiments,
a baseline system is trained on an existing parallel
corpus, and the experimental system is trained on
the baseline corpus plus the mined parallel data.
In all experiments we include the target side of the
mined parallel data in the language model, in order
to distinguish whether results are due to influences
from parallel or monolingual data.
</bodyText>
<footnote confidence="0.9987738">
5We used MALLET’s stop word removal, but that is only
for English.
6Documents were created from Europarl by taking
“SPEAKER” tags as document boundaries, giving us
208,431 documents total.
</footnote>
<page confidence="0.958336">
1378
</page>
<table confidence="0.999732428571429">
Genre Domain Pages Segments Source Tokens Target Tokens
Total 444K 5.67M 71.5M 67.5M
travel www.booking.com 13.4K 424K 5.23M 5.14M
travel www.hotel.info 9.05K 156K 1.93M 2.13M
government www.fao.org 2.47K 60.4K 1.07M 896K
religious scriptures.lds.org 7.04K 47.2K 889K 960K
political www.amnesty.org 4.83K 38.1K 641K 548K
</table>
<tableCaption confidence="0.906358">
Table 4: The top five domains from the Spanish-English portion of the data. The domains are ranked by
the combined number of source and target tokens.
</tableCaption>
<figure confidence="0.739631904761905">
Index Most Likely Tokens
1 glitter graphics profile comments share love size girl friends happy blingee cute anime twilight sexy emo
2 subtitles online web users files rar movies prg akas dwls xvid dvdrip avi results download eng cd movie
3 miles hotels city search hotel home page list overview select tokyo discount destinations china japan
4 english language students details skype american university school languages words england british college
5 translation japanese english chinese dictionary french german spanish korean russian italian dutch
6 products services ni system power high software design technology control national applications industry
7 en de el instructions amd hyper riv saab kfreebsd poland user fr pln org wikimedia pl commons fran norway
8 information service travel services contact number time account card site credit company business terms
9 people time life day good years work make god give lot long world book today great year end things
10 show km map hotels de hotel beach spain san italy resort del mexico rome portugal home santa berlin la
11 rotary international world club korea foundation district business year global hong kong president ri
12 hotel reviews stay guest rooms service facilities room smoking submitted customers desk score united hour
13 free site blog views video download page google web nero internet http search news links category tv
14 casino game games play domaine ago days music online poker free video film sports golf live world tags bet
15 water food attribution health mango japan massage medical body baby natural yen commons traditional
16 file system windows server linux installation user files set debian version support program install type
17 united kingdom states america house london street park road city inn paris york st france home canada
18 km show map hotels hotel featured search station museum amsterdam airport centre home city rue germany
19 hotel room location staff good breakfast rooms friendly nice clean great excellent comfortable helpful
20 de la en le el hotel es het del und die il est der les des das du para
</figure>
<tableCaption confidence="0.9098215">
Table 5: A list of 20 topics generated using the MALLET toolkit (McCallum, 2002) and their most likely
tokens.
</tableCaption>
<subsectionHeader confidence="0.97731">
4.1 News Domain Translation
</subsectionHeader>
<bodyText confidence="0.99997595">
Our first set of experiments are based on systems
built for the 2012 Workshop on Statistical Ma-
chine Translation (WMT) (Callison-Burch et al.,
2012) using all available parallel and monolingual
data for that task, aside from the French-English
Gigaword. In these experiments, we use 5-gram
language models when the target language is En-
glish or German, and 4-gram language models for
French and Spanish. We tune model weights using
minimum error rate training (MERT; Och, 2003)
on the WMT 2008 test data. The results are given
in Table 8. For all language pairs and both test
sets (WMT 2011 and WMT 2012), we show an
improvement of around 0.5 BLEU.
We also included the French-English Gigaword
in separate experiments given in Table 9, and Table
10 compares the sizes of the datasets used. These
results show that even on top of a different, larger
parallel corpus mined from the web, adding Com-
monCrawl data still yields an improvement.
</bodyText>
<subsectionHeader confidence="0.954675">
4.2 Open Domain Translation
</subsectionHeader>
<bodyText confidence="0.999982857142857">
A substantial appeal of web-mined parallel data
is that it might be suitable to translation of do-
mains other than news, and our topic modeling
analysis (§3.3) suggested that this might indeed be
the case. We therefore performed an additional
set of experiments for Spanish-English, but we
include test sets from outside the news domain.
</bodyText>
<page confidence="0.988761">
1379
</page>
<table confidence="0.878890444444444">
Europarl CommonCrawl Most Likely Tokens
9 2975 hair body skin products water massage treatment natural oil weight acid plant
2 4383 river mountain tour park tours de day chile valley ski argentina national peru la
8 10377 ford mercury dealer lincoln amsterdam site call responsible affiliates displayed
7048 675 market services european competition small public companies sector internal
9159 1359 time president people fact make case problem clear good put made years situation
13053 849 commission council european parliament member president states mr agreement
1660 5611 international rights human amnesty government death police court number torture
1617 4577 education training people cultural school students culture young information
</table>
<tableCaption confidence="0.995381333333333">
Table 6: A sample of topics along with the number of Europarl and CommonCrawl documents where
they are the most likely topic in the mixture. We include topics that are mostly found in Europarl or
CommonCrawl, and some that are somewhat prominent in both.
</tableCaption>
<table confidence="0.9998815">
WMT 11 FR-EN EN-FR ES-EN EN-ES EN-DE
Baseline 30.46 29.96 30.79 32.41 16.12
+Web Data 30.92 30.51 31.05 32.89 16.74
WMT 12 FR-EN EN-FR ES-EN EN-ES EN-DE
Baseline 29.25 27.92 32.80 32.83 16.61
+Web Data 29.82 28.22 33.39 33.41 17.30
</table>
<tableCaption confidence="0.9802945">
Table 8: BLEU scores for several language pairs before and after adding the mined parallel data to
systems trained on data from WMT data.
</tableCaption>
<table confidence="0.999895666666667">
WMT 11 FR-EN EN-FR
Baseline 30.96 30.69
+Web Data 31.24 31.17
WMT 12 FR-EN EN-FR
Baseline 29.88 28.50
+Web Data 30.08 28.76
</table>
<tableCaption confidence="0.98234">
Table 9: BLEU scores for French-English and
</tableCaption>
<bodyText confidence="0.990479705882353">
English-French before and after adding the mined
parallel data to systems trained on data from
WMT data including the French-English Giga-
word (Callison-Burch et al., 2011).
For these experiments, we also include training
data mined from Wikipedia using a simplified ver-
sion of the sentence aligner described by Smith
et al. (2010), in order to determine how the ef-
fect of such data compares with the effect of web-
mined data. The baseline system was trained using
only the Europarl corpus (Koehn, 2005) as par-
allel data, and all experiments use the same lan-
guage model trained on the target sides of Eu-
roparl, the English side of all linked Spanish-
English Wikipedia articles, and the English side
of the mined CommonCrawl data. We use a 5-
gram language model and tune using MERT (Och,
</bodyText>
<table confidence="0.998235166666667">
Corpus EN-FR EN-ES EN-DE
News Commentary 2.99M 3.43M 3.39M
Europarl 50.3M 49.2M 47.9M
United Nations 316M 281M -
FR-EN Gigaword 668M - -
CommonCrawl 121M 68.8M 88.4M
</table>
<tableCaption confidence="0.956889333333333">
Table 10: The size (in English tokens) of the train-
ing corpora used in the SMT experiments from Ta-
bles 8 and 9 for each language pair.
</tableCaption>
<bodyText confidence="0.991571266666667">
2003) on the WMT 2009 test set.
Unfortunately, it is difficult to obtain meaning-
ful results on some open domain test sets such as
the Wikipedia dataset used by Smith et al. (2010).
Wikipedia copied across the public internet, and
we did not have a simple way to filter such data
from our mined datasets.
We therefore considered two tests that were
less likely to be problematic. The Tatoeba cor-
pus (Tiedemann, 2009) is a collection of example
sentences translated into many languages by vol-
unteers. The front page of tatoeba.org was
discovered by our URL matching heuristics, but
we excluded any sentence pairs that were found in
the CommonCrawl data from this test set.
</bodyText>
<page confidence="0.979808">
1380
</page>
<bodyText confidence="0.999867736842105">
The second dataset is a set of crowdsourced
translation of Spanish speech transcriptions from
the Spanish Fisher corpus.7 As part of a re-
search effort on cross-lingual speech applications,
we obtained English translations of the data using
Amazon Mechanical Turk, following a protocol
similar to one described by Zaidan and Callison-
Burch (2011): we provided clear instructions,
employed several quality control measures, and
obtained redundant translations of the complete
dataset (Lopez et al., 2013). The advantage of
this data for our open domain translation test is
twofold. First, the Fisher dataset consists of con-
versations in various Spanish dialects on a wide
variety of prompted topics. Second, because we
obtained the translations ourselves, we could be
absolutely assured that they did not appear in some
form anywhere on the Web, making it an ideal
blind test.
</bodyText>
<table confidence="0.997564">
WMT10 Tatoeba Fisher
Europarl 89/72/46/20 94/75/45/18 87/69/39/13
+Wiki 92/78/52/24 96/80/50/21 91/75/44/15
+Web 96/82/56/27 99/88/58/26 96/83/51/19
+Both 96/84/58/29 99/89/60/27 96/83/52/20
</table>
<tableCaption confidence="0.909586">
Table 11: n-gram coverage percentages (up to 4-
grams) of the source side of our test sets given our
different parallel training corpora computed at the
type level.
</tableCaption>
<table confidence="0.9978298">
WMT10 Tatoeba Fisher
Europarl 27.21 36.13 46.32
+Wiki 28.03 37.82 49.34
+Web 28.50 41.07 51.13
+Both 28.74 41.12 52.23
</table>
<tableCaption confidence="0.954506">
Table 12: BLEU scores for Spanish-English be-
</tableCaption>
<bodyText confidence="0.989463833333333">
fore and after adding the mined parallel data to a
baseline Europarl system.
We used 1000 sentences from each of the
Tatoeba and Fisher datasets as test. For com-
parison, we also test on the WMT 2010 test
set (Callison-Burch et al., 2010). Following
Munteanu and Marcu (2005), we show the n-gram
coverage of each corpus (percentage of n-grams
from the test corpus which are also found in the
training corpora) in Table 11. Table 12 gives
end-to-end results, which show a strong improve-
ment on the WMT test set (1.5 BLEU), and larger
</bodyText>
<subsubsectionHeader confidence="0.41915">
7Linguistic Data Consortium LDC2010T04.
</subsubsectionHeader>
<bodyText confidence="0.9874755">
improvements on Tatoeba and Fisher (almost 5
BLEU).
</bodyText>
<sectionHeader confidence="0.996459" genericHeader="discussions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999980872340426">
Web-mined parallel texts have been an exclusive
resource of large companies for several years.
However, when web-mined parallel text is avail-
able to everyone at little or no cost, there will
be much greater potential for groundbreaking re-
search to come from all corners. With the advent
of public services such as Amazon Web Services
and the Common Crawl, this may soon be a re-
ality. As we have shown, it is possible to obtain
parallel text for many language pairs in a variety
of domains very cheaply and quickly, and in suf-
ficient quantity and quality to improve statistical
machine translation systems. However, our effort
has merely scratched the surface of what is pos-
sible with this resource. We will make our code
and data available so that others can build on these
results.
Because our system is so simple, we believe that
our results represent lower bounds on the gains
that should be expected in performance of systems
previously trained only on curated datasets. There
are many possible means through which the sys-
tem could be improved, including more sophisti-
cated techniques for identifying matching URLs,
better alignment, better language identification,
better filtering of data, and better exploitation of
resulting cross-domain datasets. Many of the com-
ponents of our pipeline were basic, leaving consid-
erable room for improvement. For example, the
URL matching strategy could easily be improved
for a given language pair by spending a little time
crafting regular expressions tailored to some ma-
jor websites. Callison-Burch et al. (2011) gathered
almost 1 trillion tokens of French-English parallel
data this way. Another strategy for mining parallel
webpage pairs is to scan the HTML for links to the
same page in another language (Nie et al., 1999).
Other, more sophisticated techniques may also
be possible. Uszkoreit et al. (2010), for ex-
ample, translated all non-English webpages into
English using an existing translation system and
used near-duplicate detection methods to find can-
didate parallel document pairs. Ture and Lin
(2012) had a similar approach for finding paral-
lel Wikipedia documents by using near-duplicate
detection, though they did not need to apply a full
translation system to all non-English documents.
</bodyText>
<page confidence="0.972586">
1381
</page>
<bodyText confidence="0.9999664">
Instead, they represented documents in bag-of-
words vector space, and projected non-English
document vectors into the English vector space us-
ing the translation probabilities of a word align-
ment model. By comparison, one appeal of our
simple approach is that it requires only a table
of language codes. However, with this system
in place, we could obtain enough parallel data to
bootstrap these more sophisticated approaches.
It is also compelling to consider ways in which
web-mined data obtained from scratch could be
used to bootstrap other mining approaches. For
example, Smith et al. (2010) mine parallel sen-
tences from comparable documents in Wikipedia,
demonstrating substantial gains on open domain
translation. However, their approach required seed
parallel data to learn models used in a classifier.
We imagine a two-step process, first obtaining par-
allel data from the web, followed by comparable
data from sources such as Wikipedia using mod-
els bootstrapped from the web-mined data. Such a
process could be used to build translation systems
for new language pairs in a very short period of
time, hence fulfilling one of the original promises
of SMT.
</bodyText>
<sectionHeader confidence="0.994727" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997956">
Thanks to Ann Irvine, Jonathan Weese, and our
anonymous reviewers from NAACL and ACL for
comments on previous drafts. The research lead-
ing to these results has received funding from the
European Union Seventh Framework Programme
(FP7/2007-2013) under grant agreement 288487
(MosesCore). This research was partially funded
by the Johns Hopkins University Human Lan-
guage Technology Center of Excellence, and by
gifts from Google and Microsoft.
</bodyText>
<sectionHeader confidence="0.998609" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999505328358209">
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. J. Mach. Learn.
Res., 3:993–1022, March.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Kay Peterson, Mark Przybocki, and Omar F. Zaidan.
2010. Findings of the 2010 joint workshop on sta-
tistical machine translation and metrics for machine
translation. In Proceedings of the Joint Fifth Work-
shop on Statistical Machine Translation and Met-
ricsMATR, WMT ’10, pages 17–53. Association for
Computational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
and Omar F. Zaidan. 2011. Findings of the 2011
workshop on statistical machine translation. In Pro-
ceedings of the Sixth Workshop on Statistical Ma-
chine Translation, WMT ’11, pages 22–64. Associ-
ation for Computational Linguistics.
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical ma-
chine translation. In Proceedings of the Seventh
Workshop on Statistical Machine Translation, pages
10–51, Montr´eal, Canada, June. Association for
Computational Linguistics.
Jiang Chen and Jian-Yun Nie. 2000. Parallel web text
mining for cross-language ir. In IN IN PROC. OF
RIAO, pages 62–77.
J. Dean and S. Ghemawat. 2004. Mapreduce: simpli-
fied data processing on large clusters. In Proceed-
ings of the 6th conference on Symposium on Opeart-
ing Systems Design &amp; Implementation-Volume 6,
pages 10–10. USENIX Association.
William A. Gale and Kenneth W. Church. 1993. A
program for aligning sentences in bilingual corpora.
Comput. Linguist., 19:75–102, March.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 177–180. Association for Computa-
tional Linguistics.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT summit, volume 5.
Edward Loper and Steven Bird. 2002. Nltk: the natu-
ral language toolkit. In Proceedings of the ACL-02
Workshop on Effective tools and methodologies for
teaching natural language processing and computa-
tional linguistics - Volume 1, ETMTNLP ’02, pages
63–70. Association for Computational Linguistics.
Adam Lopez, Matt Post, and Chris Callison-Burch.
2013. Parallel speech, transcription, and translation:
The Fisher and Callhome Spanish-English speech
translation corpora. Technical Report 11, Johns
Hopkins University Human Language Technology
Center of Excellence.
Marco Lui and Timothy Baldwin. 2012. langid.py:
an off-the-shelf language identification tool. In Pro-
ceedings of the ACL 2012 System Demonstrations,
ACL ’12, pages 25–30. Association for Computa-
tional Linguistics.
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
</reference>
<page confidence="0.911478">
1382
</page>
<reference confidence="0.965207637931035">
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving Machine Translation Performance by Ex-
ploiting Non-Parallel Corpora. Comput. Linguist.,
31:477–504, December.
Omar F. Zaidan and Chris Callison-Burch. 2011.
Crowdsourcing translation: Professional quality
from non-professionals. In Proc. of ACL.
Jian-Yun Nie, Michel Simard, Pierre Isabelle, and
Richard Durand. 1999. Cross-language information
retrieval based on parallel texts and automatic min-
ing of parallel texts from the web. In Proceedings of
the 22nd annual international ACM SIGIR confer-
ence on Research and development in information
retrieval, SIGIR ’99, pages 74–81, New York, NY,
USA. ACM.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In acl, pages 160–
167, Sapporo, Japan.
P. Resnik and N. A Smith. 2003. The web as a parallel
corpus. Computational Linguistics, 29(3):349–380.
Philip Resnik. 1999. Mining the web for bilingual text.
In Proceedings of the 37th annual meeting of the As-
sociation for Computational Linguistics on Compu-
tational Linguistics, ACL ’99, pages 527–534. As-
sociation for Computational Linguistics.
Jason R. Smith, Chris Quirk, and Kristina Toutanova.
2010. Extracting Parallel Sentences from Compara-
ble Corpora using Document Level Alignment. In
NAACL 2010.
J¨org Tiedemann. 2009. News from OPUS - A col-
lection of multilingual parallel corpora with tools
and interfaces. In N. Nicolov, K. Bontcheva,
G. Angelova, and R. Mitkov, editors, Recent
Advances in Natural Language Processing, vol-
ume V, pages 237–248. John Benjamins, Amster-
dam/Philadelphia, Borovets, Bulgaria.
Ferhan Ture and Jimmy Lin. 2012. Why not grab a
free lunch? mining large corpora for parallel sen-
tences to improve translation modeling. In Proceed-
ings of the 2012 Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics: Human Language Technologies, pages
626–630, Montr´eal, Canada, June. Association for
Computational Linguistics.
Jakob Uszkoreit, Jay M. Ponte, Ashok C. Popat, and
Moshe Dubiner. 2010. Large scale parallel docu-
ment mining for machine translation. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, COLING ’10, pages 1101–
1109. Association for Computational Linguistics.
Ashish Venugopal, Jakob Uszkoreit, David Talbot,
Franz J. Och, and Juri Ganitkevitch. 2011. Water-
marking the outputs of structured prediction with an
application in statistical machine translation. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, EMNLP ’11, pages
1363–1372. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.978374">
1383
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.181932">
<title confidence="0.954426">Dirt Cheap Web-Scale Parallel Text from the Common Crawl</title>
<abstract confidence="0.8623652">R. jsmith@cs.jhu.edu herve@saintamh.org plamada@cl.uzh.ch ccb@cs.jhu.edu of Computer Science, Johns Hopkins Language Technology Center of Excellence, Johns Hopkins of Informatics, University of of Computational Linguistics, University of and Information Science Department, University of Pennsylvania Abstract Parallel text is the fuel that drives modern machine translation systems. The Web is a comprehensive source of preexisting parallel text, but crawling the entire web is impossible for all but the largest companies. We bring web-scale parallel text to the masses by mining the Common Crawl, a public Web crawl hosted on Amazon’s Elastic Cloud. Starting from nothing more than a set of common two-letter language codes, our open-source extension of the STRAND algorithm mined 32 terabytes of the crawl in just under a day, at a cost of about $500. Our large-scale experiment uncovers large amounts of parallel text in dozens of language pairs across a variety of domains and genres, some previously unavailable in curated datasets. Even with minimal cleaning and filtering, the resulting data boosts translation performance across the board for five different language pairs in the news domain, and on open domain test sets we see improvements of up to 5 BLEU. We make our code and data available for other researchers seeking to this rich new data</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--993</pages>
<contexts>
<context position="16916" citStr="Blei et al., 2003" startWordPosition="2752" endWordPosition="2755">e data. A major difficulty in applying SMT even on languages for which we have significant quantities of parallel text is that most of that parallel text is in the news and government domains. When applied to other genres, such systems are notoriously brittle. What kind of genres are represented in the Common Crawl data? We first looked at the domain names which contributed the most data. Table 4 gives the top five domains by the number of tokens. The top two domain names are related to travel, and they account for about 10% of the total data. We also applied Latent Dirichlet Allocation (LDA; Blei et al., 2003) to learn a distribution over latent topics in the extracted data, as this is a popular exploratory data analysis method. In LDA a topic is a unigram distribution over words, and each document is modeled as a distribution over topics. To create a set of documents from the extracted CommonCrawl data, we took the English side of the extracted parallel segments for each URL in the Spanish-English portion of the data. This gave us a total of 444,022 documents. In our first experiment, we used the MALLET toolkit (McCallum, 2002) to generate 20 topics, which are shown in Table 5. Some of the topics </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., 3:993–1022, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Kay Peterson</author>
<author>Mark Przybocki</author>
<author>Omar F Zaidan</author>
</authors>
<title>Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, WMT ’10,</booktitle>
<pages>17--53</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28740" citStr="Callison-Burch et al., 2010" startWordPosition="4679" endWordPosition="4682">88/58/26 96/83/51/19 +Both 96/84/58/29 99/89/60/27 96/83/52/20 Table 11: n-gram coverage percentages (up to 4- grams) of the source side of our test sets given our different parallel training corpora computed at the type level. WMT10 Tatoeba Fisher Europarl 27.21 36.13 46.32 +Wiki 28.03 37.82 49.34 +Web 28.50 41.07 51.13 +Both 28.74 41.12 52.23 Table 12: BLEU scores for Spanish-English before and after adding the mined parallel data to a baseline Europarl system. We used 1000 sentences from each of the Tatoeba and Fisher datasets as test. For comparison, we also test on the WMT 2010 test set (Callison-Burch et al., 2010). Following Munteanu and Marcu (2005), we show the n-gram coverage of each corpus (percentage of n-grams from the test corpus which are also found in the training corpora) in Table 11. Table 12 gives end-to-end results, which show a strong improvement on the WMT test set (1.5 BLEU), and larger 7Linguistic Data Consortium LDC2010T04. improvements on Tatoeba and Fisher (almost 5 BLEU). 5 Discussion Web-mined parallel texts have been an exclusive resource of large companies for several years. However, when web-mined parallel text is available to everyone at little or no cost, there will be much g</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Peterson, Przybocki, Zaidan, 2010</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, Kay Peterson, Mark Przybocki, and Omar F. Zaidan. 2010. Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, WMT ’10, pages 17–53. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Omar F Zaidan</author>
</authors>
<title>Findings of the 2011 workshop on statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT ’11,</booktitle>
<pages>22--64</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12221" citStr="Callison-Burch et al., 2011" startWordPosition="1980" endWordPosition="1983">ments to measure these features. Since our mining heuristics are very simple, these results can be construed as a lower bound on what is actually possible. 3.1 Recall Estimates Our first question is about recall: of all the possible parallel text that is actually available on the Web, how much does our algorithm actually find in the Common Crawl? Although this question is difficult to answer precisely, we can estimate an answer by comparing our mined URLs against a large collection of previously mined URLs that were found using targeted techniques: those in the French-English Gigaword corpus (Callison-Burch et al., 2011). We found that 45% of the URL pairs would 1376 French German Spanish Russian Japanese Chinese Segments 10.2M 7.50M 5.67M 3.58M 1.70M 1.42M Source Tokens 128M 79.9M 71.5M 34.7M 9.91M 8.14M Target Tokens 118M 87.5M 67.6M 36.7M 19.1M 14.8M Arabic Bulgarian Czech Korean Tamil Urdu Segments 1.21M 909K 848K 756K 116K 52.1K Source Tokens 13.1M 8.48M 7.42M 6.56M 1.01M 734K Target Tokens 13.5M 8.61M 8.20M 7.58M 996K 685K Bengali Farsi Telugu Somali Kannada Pashto Segments 59.9K 44.2K 50.6K 52.6K 34.5K 28.0K Source Tokens 573K 477K 336K 318K 305K 208K Target Tokens 537K 459K 358K 325K 297K 218K Table 1</context>
<context position="25519" citStr="Callison-Burch et al., 2011" startWordPosition="4148" endWordPosition="4151">Data 30.92 30.51 31.05 32.89 16.74 WMT 12 FR-EN EN-FR ES-EN EN-ES EN-DE Baseline 29.25 27.92 32.80 32.83 16.61 +Web Data 29.82 28.22 33.39 33.41 17.30 Table 8: BLEU scores for several language pairs before and after adding the mined parallel data to systems trained on data from WMT data. WMT 11 FR-EN EN-FR Baseline 30.96 30.69 +Web Data 31.24 31.17 WMT 12 FR-EN EN-FR Baseline 29.88 28.50 +Web Data 30.08 28.76 Table 9: BLEU scores for French-English and English-French before and after adding the mined parallel data to systems trained on data from WMT data including the French-English Gigaword (Callison-Burch et al., 2011). For these experiments, we also include training data mined from Wikipedia using a simplified version of the sentence aligner described by Smith et al. (2010), in order to determine how the effect of such data compares with the effect of webmined data. The baseline system was trained using only the Europarl corpus (Koehn, 2005) as parallel data, and all experiments use the same language model trained on the target sides of Europarl, the English side of all linked SpanishEnglish Wikipedia articles, and the English side of the mined CommonCrawl data. We use a 5- gram language model and tune usi</context>
<context position="30696" citStr="Callison-Burch et al. (2011)" startWordPosition="4997" endWordPosition="5000">s previously trained only on curated datasets. There are many possible means through which the system could be improved, including more sophisticated techniques for identifying matching URLs, better alignment, better language identification, better filtering of data, and better exploitation of resulting cross-domain datasets. Many of the components of our pipeline were basic, leaving considerable room for improvement. For example, the URL matching strategy could easily be improved for a given language pair by spending a little time crafting regular expressions tailored to some major websites. Callison-Burch et al. (2011) gathered almost 1 trillion tokens of French-English parallel data this way. Another strategy for mining parallel webpage pairs is to scan the HTML for links to the same page in another language (Nie et al., 1999). Other, more sophisticated techniques may also be possible. Uszkoreit et al. (2010), for example, translated all non-English webpages into English using an existing translation system and used near-duplicate detection methods to find candidate parallel document pairs. Ture and Lin (2012) had a similar approach for finding parallel Wikipedia documents by using near-duplicate detection</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Zaidan, 2011</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, and Omar F. Zaidan. 2011. Findings of the 2011 workshop on statistical machine translation. In Proceedings of the Sixth Workshop on Statistical Machine Translation, WMT ’11, pages 22–64. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Matt Post</author>
<author>Radu Soricut</author>
<author>Lucia Specia</author>
</authors>
<title>Findings of the 2012 workshop on statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>10--51</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="22653" citStr="Callison-Burch et al., 2012" startWordPosition="3684" endWordPosition="3687">et park road city inn paris york st france home canada 18 km show map hotels hotel featured search station museum amsterdam airport centre home city rue germany 19 hotel room location staff good breakfast rooms friendly nice clean great excellent comfortable helpful 20 de la en le el hotel es het del und die il est der les des das du para Table 5: A list of 20 topics generated using the MALLET toolkit (McCallum, 2002) and their most likely tokens. 4.1 News Domain Translation Our first set of experiments are based on systems built for the 2012 Workshop on Statistical Machine Translation (WMT) (Callison-Burch et al., 2012) using all available parallel and monolingual data for that task, aside from the French-English Gigaword. In these experiments, we use 5-gram language models when the target language is English or German, and 4-gram language models for French and Spanish. We tune model weights using minimum error rate training (MERT; Och, 2003) on the WMT 2008 test data. The results are given in Table 8. For all language pairs and both test sets (WMT 2011 and WMT 2012), we show an improvement of around 0.5 BLEU. We also included the French-English Gigaword in separate experiments given in Table 9, and Table 10</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Post, Soricut, Specia, 2012</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2012. Findings of the 2012 workshop on statistical machine translation. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 10–51, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Chen</author>
<author>Jian-Yun Nie</author>
</authors>
<title>Parallel web text mining for cross-language ir. In</title>
<date>2000</date>
<booktitle>IN IN PROC. OF RIAO,</booktitle>
<pages>62--77</pages>
<contexts>
<context position="3155" citStr="Chen and Nie, 2000" startWordPosition="478" endWordPosition="481">tant source of parallel text. Many websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process. Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (Nie et al., 1999; Chen and Nie, 2000; Resnik, 1999; Resnik and Smith, 2003). However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with the computing power to process them. For most researchers, this is prohibitively expensive. As a consequence, web-mined parallel text has become the exclusive purview of large companies with the computational resources to crawl, store, and process the entire Web. To put web-mined parallel text back in the hands of individual researchers, we mine parallel text from the Common Crawl, a regularly updated 81-terabyte snapshot of the public in</context>
</contexts>
<marker>Chen, Nie, 2000</marker>
<rawString>Jiang Chen and Jian-Yun Nie. 2000. Parallel web text mining for cross-language ir. In IN IN PROC. OF RIAO, pages 62–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dean</author>
<author>S Ghemawat</author>
</authors>
<title>Mapreduce: simplified data processing on large clusters.</title>
<date>2004</date>
<booktitle>In Proceedings of the 6th conference on Symposium on Opearting Systems Design &amp; Implementation-Volume 6,</booktitle>
<pages>10--10</pages>
<publisher>USENIX Association.</publisher>
<contexts>
<context position="5754" citStr="Dean and Ghemawat, 2004" startWordPosition="886" endWordPosition="890">o a local cluster, but the transfer cost is prohibitive at roughly 10 cents per gigabyte, making the total over $8000 for the full dataset.3 However, it is unnecessary to obtain a copy of the data since it can be accessed freely from Amazon’s Elastic Compute Cloud (EC2) or Elastic MapReduce (EMR) services. In our pipeline, we perform the first step of identifying candidate document pairs using Amazon EMR, download the resulting document pairs, and perform the remaining steps on our local cluster. We chose EMR because our candidate matching strategy fit naturally into the Map-Reduce framework (Dean and Ghemawat, 2004). Our system is based on the STRAND algorithm (Resnik and Smith, 2003): 1. Candidate pair selection: Retrieve candidate document pairs from the CommonCrawl corpus. 2. Structural Filtering: (a) Convert the HTML of each document 2commoncrawl.org 3http://aws.amazon.com/s3/pricing/ into a sequence of start tags, end tags, and text chunks. (b) Align the linearized HTML of candidate document pairs. (c) Decide whether to accept or reject each pair based on features of the alignment. 3. Segmentation: For each text chunk, perform sentence and word segmentation. 4. Sentence Alignment: For each aligned p</context>
</contexts>
<marker>Dean, Ghemawat, 2004</marker>
<rawString>J. Dean and S. Ghemawat. 2004. Mapreduce: simplified data processing on large clusters. In Proceedings of the 6th conference on Symposium on Opearting Systems Design &amp; Implementation-Volume 6, pages 10–10. USENIX Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<contexts>
<context position="6437" citStr="Gale and Church (1993)" startWordPosition="990" endWordPosition="993">th, 2003): 1. Candidate pair selection: Retrieve candidate document pairs from the CommonCrawl corpus. 2. Structural Filtering: (a) Convert the HTML of each document 2commoncrawl.org 3http://aws.amazon.com/s3/pricing/ into a sequence of start tags, end tags, and text chunks. (b) Align the linearized HTML of candidate document pairs. (c) Decide whether to accept or reject each pair based on features of the alignment. 3. Segmentation: For each text chunk, perform sentence and word segmentation. 4. Sentence Alignment: For each aligned pair of text chunks, perform the sentence alignment method of Gale and Church (1993). 5. Sentence Filtering: Remove sentences that appear to be boilerplate. Candidate Pair Selection We adopt a strategy similar to that of Resnik and Smith (2003) for finding candidate parallel documents, adapted to the parallel architecture of Map-Reduce. The mapper operates on each website entry in the CommonCrawl data. It scans the URL string for some indicator of its language. Specifically, we check for: 1. Two/three letter language codes (ISO-639). 2. Language names in English and in the language of origin. If either is present in a URL and surrounded by non-alphanumeric characters, the URL</context>
<context position="10049" citStr="Gale and Church (1993)" startWordPosition="1597" endWordPosition="1600">e classifier from our pipeline. The strong performance of the naive baseline was likely due to the unbalanced nature of the annotated data— 80% of the document pairs that we annotated were parallel. Segmentation The text chunks from the previous step may contain several sentences, so before the sentence alignment step we must perform sentence segmentation. We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk. Sentence Alignment For each aligned text chunk pair, we perform sentence alignment using the algorithm of Gale and Church (1993). Sentence Filtering Since we do not perform any boilerplate removal in earlier steps, there are many sentence pairs produced by the pipeline which contain menu items or other bits of text which are not useful to an SMT system. We avoid performing any complex boilerplate removal and only remove segment pairs where either the source and target text are identical, or where the source or target segments appear more than once in the extracted corpus. 3 Analysis of the Common Crawl Data We ran our algorithm on the 2009-2010 version of the crawl, consisting of 32.3 terabytes of data. Since the full </context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>William A. Gale and Kenneth W. Church. 1993. A program for aligning sentences in bilingual corpora. Comput. Linguist., 19:75–102, March.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19219" citStr="Koehn et al., 2007" startWordPosition="3136" endWordPosition="3139"> specifically classified sentence pairs as useful or boilerplate (Table 7). Among our observations, we find that commercial websites tend to contain less boilerplate material than encyclopedic websites, and that the ratios tend to be similar across languages in the same domain. FR ES DE www.booking.com 52% 71% 52% www.hotel.info 34% 44% - memory-alpha.org 34% 25% 55% Table 7: Percentage of useful (non-boilerplate) sentences found by domain and language pair. hotel.info was not found in our GermanEnglish data. 4 Machine Translation Experiments For our SMT experiments, we use the Moses toolkit (Koehn et al., 2007). In these experiments, a baseline system is trained on an existing parallel corpus, and the experimental system is trained on the baseline corpus plus the mined parallel data. In all experiments we include the target side of the mined parallel data in the language model, in order to distinguish whether results are due to influences from parallel or monolingual data. 5We used MALLET’s stop word removal, but that is only for English. 6Documents were created from Europarl by taking “SPEAKER” tags as document boundaries, giving us 208,431 documents total. 1378 Genre Domain Pages Segments Source T</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT summit,</booktitle>
<volume>5</volume>
<contexts>
<context position="2231" citStr="Koehn, 2005" startWordPosition="327" endWordPosition="328">seeking to mine this rich new data resource.1 1 Introduction A key bottleneck in porting statistical machine translation (SMT) technology to new languages and domains is the lack of readily available parallel corpora beyond curated datasets. For a handful of language pairs, large amounts of parallel data ∗This research was conducted while Chris CallisonBurch was at Johns Hopkins University. 1github.com/jrs026/CommonCrawlMiner are readily available, ordering in the hundreds of millions of words for Chinese-English and ArabicEnglish, and in tens of millions of words for many European languages (Koehn, 2005). In each case, much of this data consists of government and news text. However, for most language pairs and domains there is little to no curated parallel data available. Hence discovery of parallel data is an important first step for translation between most of the world’s languages. The Web is an important source of parallel text. Many websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. Th</context>
<context position="25849" citStr="Koehn, 2005" startWordPosition="4207" endWordPosition="4208">1.17 WMT 12 FR-EN EN-FR Baseline 29.88 28.50 +Web Data 30.08 28.76 Table 9: BLEU scores for French-English and English-French before and after adding the mined parallel data to systems trained on data from WMT data including the French-English Gigaword (Callison-Burch et al., 2011). For these experiments, we also include training data mined from Wikipedia using a simplified version of the sentence aligner described by Smith et al. (2010), in order to determine how the effect of such data compares with the effect of webmined data. The baseline system was trained using only the Europarl corpus (Koehn, 2005) as parallel data, and all experiments use the same language model trained on the target sides of Europarl, the English side of all linked SpanishEnglish Wikipedia articles, and the English side of the mined CommonCrawl data. We use a 5- gram language model and tune using MERT (Och, Corpus EN-FR EN-ES EN-DE News Commentary 2.99M 3.43M 3.39M Europarl 50.3M 49.2M 47.9M United Nations 316M 281M - FR-EN Gigaword 668M - - CommonCrawl 121M 68.8M 88.4M Table 10: The size (in English tokens) of the training corpora used in the SMT experiments from Tables 8 and 9 for each language pair. 2003) on the WM</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT summit, volume 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Loper</author>
<author>Steven Bird</author>
</authors>
<title>Nltk: the natural language toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics - Volume 1, ETMTNLP ’02,</booktitle>
<pages>63--70</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9853" citStr="Loper and Bird, 2002" startWordPosition="1566" endWordPosition="1569"> performing subset of features, the classifier only performed as well as a naive classifier which labeled every document pair as parallel, in both accuracy and F1. For this reason, we excluded the classifier from our pipeline. The strong performance of the naive baseline was likely due to the unbalanced nature of the annotated data— 80% of the document pairs that we annotated were parallel. Segmentation The text chunks from the previous step may contain several sentences, so before the sentence alignment step we must perform sentence segmentation. We use the Punkt sentence splitter from NLTK (Loper and Bird, 2002) to perform both sentence and word segmentation on each text chunk. Sentence Alignment For each aligned text chunk pair, we perform sentence alignment using the algorithm of Gale and Church (1993). Sentence Filtering Since we do not perform any boilerplate removal in earlier steps, there are many sentence pairs produced by the pipeline which contain menu items or other bits of text which are not useful to an SMT system. We avoid performing any complex boilerplate removal and only remove segment pairs where either the source and target text are identical, or where the source or target segments </context>
</contexts>
<marker>Loper, Bird, 2002</marker>
<rawString>Edward Loper and Steven Bird. 2002. Nltk: the natural language toolkit. In Proceedings of the ACL-02 Workshop on Effective tools and methodologies for teaching natural language processing and computational linguistics - Volume 1, ETMTNLP ’02, pages 63–70. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
<author>Matt Post</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Parallel speech, transcription, and translation: The Fisher and Callhome Spanish-English speech translation corpora.</title>
<date>2013</date>
<tech>Technical Report 11,</tech>
<institution>Johns Hopkins University Human Language Technology Center of Excellence.</institution>
<contexts>
<context position="27611" citStr="Lopez et al., 2013" startWordPosition="4501" endWordPosition="4504">ching heuristics, but we excluded any sentence pairs that were found in the CommonCrawl data from this test set. 1380 The second dataset is a set of crowdsourced translation of Spanish speech transcriptions from the Spanish Fisher corpus.7 As part of a research effort on cross-lingual speech applications, we obtained English translations of the data using Amazon Mechanical Turk, following a protocol similar to one described by Zaidan and CallisonBurch (2011): we provided clear instructions, employed several quality control measures, and obtained redundant translations of the complete dataset (Lopez et al., 2013). The advantage of this data for our open domain translation test is twofold. First, the Fisher dataset consists of conversations in various Spanish dialects on a wide variety of prompted topics. Second, because we obtained the translations ourselves, we could be absolutely assured that they did not appear in some form anywhere on the Web, making it an ideal blind test. WMT10 Tatoeba Fisher Europarl 89/72/46/20 94/75/45/18 87/69/39/13 +Wiki 92/78/52/24 96/80/50/21 91/75/44/15 +Web 96/82/56/27 99/88/58/26 96/83/51/19 +Both 96/84/58/29 99/89/60/27 96/83/52/20 Table 11: n-gram coverage percentage</context>
</contexts>
<marker>Lopez, Post, Callison-Burch, 2013</marker>
<rawString>Adam Lopez, Matt Post, and Chris Callison-Burch. 2013. Parallel speech, transcription, and translation: The Fisher and Callhome Spanish-English speech translation corpora. Technical Report 11, Johns Hopkins University Human Language Technology Center of Excellence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>langid.py: an off-the-shelf language identification tool.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations, ACL ’12,</booktitle>
<pages>25--30</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15414" citStr="Lui and Baldwin, 2012" startWordPosition="2499" endWordPosition="2502">lthough this analysis suggests that language identification and SMT output detection (Venugopal et al., 2011) may be useful additions to the pipeline, we regard this as reasonably high precision for our simple algorithm. Language Precision Spanish 82% French 81% German 78% Table 2: Manual evaluation of precision (by sentence pair) on the extracted parallel data for Spanish, French, and German (paired with English). In addition to the manual evaluation of precision, we applied language identification to our extracted parallel data for several additional languages. We used the “langid.py” tool (Lui and Baldwin, 2012) at the segment level, and report the percentage of sentence pairs where both sentences were recognized as the correct language. Table 3 shows our results. Comparing against our manual evaluation from Table 2, it appears that many sentence pairs are being incorrectly judged as nonparallel. This is likely because language identification tends to perform poorly on short segments. 1377 French German Spanish Arabic 63% 61% 58% 51% Chinese Japanese Korean Czech 50% 48% 48% 47% Russian Urdu Bengali Tamil 44% 31% 14% 12% Kannada Telugu Kurdish 12% 6.3% 2.9% Table 3: Automatic evaluation of precision </context>
</contexts>
<marker>Lui, Baldwin, 2012</marker>
<rawString>Marco Lui and Timothy Baldwin. 2012. langid.py: an off-the-shelf language identification tool. In Proceedings of the ACL 2012 System Demonstrations, ACL ’12, pages 25–30. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="17445" citStr="McCallum, 2002" startWordPosition="2846" endWordPosition="2847">f the total data. We also applied Latent Dirichlet Allocation (LDA; Blei et al., 2003) to learn a distribution over latent topics in the extracted data, as this is a popular exploratory data analysis method. In LDA a topic is a unigram distribution over words, and each document is modeled as a distribution over topics. To create a set of documents from the extracted CommonCrawl data, we took the English side of the extracted parallel segments for each URL in the Spanish-English portion of the data. This gave us a total of 444,022 documents. In our first experiment, we used the MALLET toolkit (McCallum, 2002) to generate 20 topics, which are shown in Table 5. Some of the topics that LDA finds correspond closely with specific domains, such as topics 1 (blingee.com) and 2 (opensubtitles.org). Several of the topics correspond to the travel domain. Foreign stop words appear in a few of the topics. Since our system does not include any language identification, this is not surprising.5 However it does suggest an avenue for possible improvement. In our second LDA experiment, we compared our extracted CommonCrawl data with Europarl. We created a set of documents from both CommonCrawl and Europarl, and aga</context>
<context position="22446" citStr="McCallum, 2002" startWordPosition="3653" endWordPosition="3654">aby natural yen commons traditional 16 file system windows server linux installation user files set debian version support program install type 17 united kingdom states america house london street park road city inn paris york st france home canada 18 km show map hotels hotel featured search station museum amsterdam airport centre home city rue germany 19 hotel room location staff good breakfast rooms friendly nice clean great excellent comfortable helpful 20 de la en le el hotel es het del und die il est der les des das du para Table 5: A list of 20 topics generated using the MALLET toolkit (McCallum, 2002) and their most likely tokens. 4.1 News Domain Translation Our first set of experiments are based on systems built for the 2012 Workshop on Statistical Machine Translation (WMT) (Callison-Burch et al., 2012) using all available parallel and monolingual data for that task, aside from the French-English Gigaword. In these experiments, we use 5-gram language models when the target language is English or German, and 4-gram language models for French and Spanish. We tune model weights using minimum error rate training (MERT; Och, 2003) on the WMT 2008 test data. The results are given in Table 8. Fo</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving Machine Translation Performance by Exploiting Non-Parallel Corpora.</title>
<date>2005</date>
<journal>Comput. Linguist.,</journal>
<pages>31--477</pages>
<contexts>
<context position="2712" citStr="Munteanu and Marcu, 2005" startWordPosition="403" endWordPosition="406"> hundreds of millions of words for Chinese-English and ArabicEnglish, and in tens of millions of words for many European languages (Koehn, 2005). In each case, much of this data consists of government and news text. However, for most language pairs and domains there is little to no curated parallel data available. Hence discovery of parallel data is an important first step for translation between most of the world’s languages. The Web is an important source of parallel text. Many websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process. Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (Nie et al., 1999; Chen and Nie, 2000; Resnik, 1999; Resnik and Smith, 2003). However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with</context>
<context position="28777" citStr="Munteanu and Marcu (2005)" startWordPosition="4684" endWordPosition="4687">9/89/60/27 96/83/52/20 Table 11: n-gram coverage percentages (up to 4- grams) of the source side of our test sets given our different parallel training corpora computed at the type level. WMT10 Tatoeba Fisher Europarl 27.21 36.13 46.32 +Wiki 28.03 37.82 49.34 +Web 28.50 41.07 51.13 +Both 28.74 41.12 52.23 Table 12: BLEU scores for Spanish-English before and after adding the mined parallel data to a baseline Europarl system. We used 1000 sentences from each of the Tatoeba and Fisher datasets as test. For comparison, we also test on the WMT 2010 test set (Callison-Burch et al., 2010). Following Munteanu and Marcu (2005), we show the n-gram coverage of each corpus (percentage of n-grams from the test corpus which are also found in the training corpora) in Table 11. Table 12 gives end-to-end results, which show a strong improvement on the WMT test set (1.5 BLEU), and larger 7Linguistic Data Consortium LDC2010T04. improvements on Tatoeba and Fisher (almost 5 BLEU). 5 Discussion Web-mined parallel texts have been an exclusive resource of large companies for several years. However, when web-mined parallel text is available to everyone at little or no cost, there will be much greater potential for groundbreaking r</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving Machine Translation Performance by Exploiting Non-Parallel Corpora. Comput. Linguist., 31:477–504, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Crowdsourcing translation: Professional quality from non-professionals.</title>
<date>2011</date>
<booktitle>In Proc. of ACL.</booktitle>
<marker>Zaidan, Callison-Burch, 2011</marker>
<rawString>Omar F. Zaidan and Chris Callison-Burch. 2011. Crowdsourcing translation: Professional quality from non-professionals. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yun Nie</author>
<author>Michel Simard</author>
<author>Pierre Isabelle</author>
<author>Richard Durand</author>
</authors>
<title>Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’99,</booktitle>
<pages>74--81</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3135" citStr="Nie et al., 1999" startWordPosition="474" endWordPosition="477">he Web is an important source of parallel text. Many websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process. Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (Nie et al., 1999; Chen and Nie, 2000; Resnik, 1999; Resnik and Smith, 2003). However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with the computing power to process them. For most researchers, this is prohibitively expensive. As a consequence, web-mined parallel text has become the exclusive purview of large companies with the computational resources to crawl, store, and process the entire Web. To put web-mined parallel text back in the hands of individual researchers, we mine parallel text from the Common Crawl, a regularly updated 81-terabyte snaps</context>
<context position="30909" citStr="Nie et al., 1999" startWordPosition="5033" endWordPosition="5036">e identification, better filtering of data, and better exploitation of resulting cross-domain datasets. Many of the components of our pipeline were basic, leaving considerable room for improvement. For example, the URL matching strategy could easily be improved for a given language pair by spending a little time crafting regular expressions tailored to some major websites. Callison-Burch et al. (2011) gathered almost 1 trillion tokens of French-English parallel data this way. Another strategy for mining parallel webpage pairs is to scan the HTML for links to the same page in another language (Nie et al., 1999). Other, more sophisticated techniques may also be possible. Uszkoreit et al. (2010), for example, translated all non-English webpages into English using an existing translation system and used near-duplicate detection methods to find candidate parallel document pairs. Ture and Lin (2012) had a similar approach for finding parallel Wikipedia documents by using near-duplicate detection, though they did not need to apply a full translation system to all non-English documents. 1381 Instead, they represented documents in bag-ofwords vector space, and projected non-English document vectors into the</context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>Jian-Yun Nie, Michel Simard, Pierre Isabelle, and Richard Durand. 1999. Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’99, pages 74–81, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In acl,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="22982" citStr="Och, 2003" startWordPosition="3738" endWordPosition="3739">5: A list of 20 topics generated using the MALLET toolkit (McCallum, 2002) and their most likely tokens. 4.1 News Domain Translation Our first set of experiments are based on systems built for the 2012 Workshop on Statistical Machine Translation (WMT) (Callison-Burch et al., 2012) using all available parallel and monolingual data for that task, aside from the French-English Gigaword. In these experiments, we use 5-gram language models when the target language is English or German, and 4-gram language models for French and Spanish. We tune model weights using minimum error rate training (MERT; Och, 2003) on the WMT 2008 test data. The results are given in Table 8. For all language pairs and both test sets (WMT 2011 and WMT 2012), we show an improvement of around 0.5 BLEU. We also included the French-English Gigaword in separate experiments given in Table 9, and Table 10 compares the sizes of the datasets used. These results show that even on top of a different, larger parallel corpus mined from the web, adding CommonCrawl data still yields an improvement. 4.2 Open Domain Translation A substantial appeal of web-mined parallel data is that it might be suitable to translation of domains other th</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In acl, pages 160– 167, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>N A Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="3194" citStr="Resnik and Smith, 2003" startWordPosition="484" endWordPosition="487"> websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process. Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (Nie et al., 1999; Chen and Nie, 2000; Resnik, 1999; Resnik and Smith, 2003). However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with the computing power to process them. For most researchers, this is prohibitively expensive. As a consequence, web-mined parallel text has become the exclusive purview of large companies with the computational resources to crawl, store, and process the entire Web. To put web-mined parallel text back in the hands of individual researchers, we mine parallel text from the Common Crawl, a regularly updated 81-terabyte snapshot of the public internet hosted 1374 Proceedings of the 5</context>
<context position="5824" citStr="Resnik and Smith, 2003" startWordPosition="899" endWordPosition="902">ents per gigabyte, making the total over $8000 for the full dataset.3 However, it is unnecessary to obtain a copy of the data since it can be accessed freely from Amazon’s Elastic Compute Cloud (EC2) or Elastic MapReduce (EMR) services. In our pipeline, we perform the first step of identifying candidate document pairs using Amazon EMR, download the resulting document pairs, and perform the remaining steps on our local cluster. We chose EMR because our candidate matching strategy fit naturally into the Map-Reduce framework (Dean and Ghemawat, 2004). Our system is based on the STRAND algorithm (Resnik and Smith, 2003): 1. Candidate pair selection: Retrieve candidate document pairs from the CommonCrawl corpus. 2. Structural Filtering: (a) Convert the HTML of each document 2commoncrawl.org 3http://aws.amazon.com/s3/pricing/ into a sequence of start tags, end tags, and text chunks. (b) Align the linearized HTML of candidate document pairs. (c) Decide whether to accept or reject each pair based on features of the alignment. 3. Segmentation: For each text chunk, perform sentence and word segmentation. 4. Sentence Alignment: For each aligned pair of text chunks, perform the sentence alignment method of Gale and </context>
<context position="8915" citStr="Resnik and Smith (2003)" startWordPosition="1410" endWordPosition="1413">nment of HTML documents. This alignment is used to determine which document pairs are actually parallel, and if they are, to align pairs of text blocks within the documents. The first step of structural filtering is to linearize the HTML. This means converting its DOM tree into a sequence of start tags, end tags, and chunks of text. Some tags (those usually found within text, such as “font” and “a”) are ignored during this step. Next, the tag/chunk sequences are aligned using dynamic programming. The objective of the alignment is to maximize the number of matching items. Given this alignment, Resnik and Smith (2003) define a small set of features which indicate the alignment quality. They annotated a set of document pairs as parallel or non-parallel, and trained a classifier on this data. We also annotated 101 Spanish-English document pairs in this way and trained a maximum entropy classifier. However, even when using the best performing subset of features, the classifier only performed as well as a naive classifier which labeled every document pair as parallel, in both accuracy and F1. For this reason, we excluded the classifier from our pipeline. The strong performance of the naive baseline was likely </context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>P. Resnik and N. A Smith. 2003. The web as a parallel corpus. Computational Linguistics, 29(3):349–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Mining the web for bilingual text.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99,</booktitle>
<pages>527--534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3169" citStr="Resnik, 1999" startWordPosition="482" endWordPosition="483">lel text. Many websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process. Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (Nie et al., 1999; Chen and Nie, 2000; Resnik, 1999; Resnik and Smith, 2003). However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with the computing power to process them. For most researchers, this is prohibitively expensive. As a consequence, web-mined parallel text has become the exclusive purview of large companies with the computational resources to crawl, store, and process the entire Web. To put web-mined parallel text back in the hands of individual researchers, we mine parallel text from the Common Crawl, a regularly updated 81-terabyte snapshot of the public internet hosted </context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Mining the web for bilingual text. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99, pages 527–534. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason R Smith</author>
<author>Chris Quirk</author>
<author>Kristina Toutanova</author>
</authors>
<title>Extracting Parallel Sentences from Comparable Corpora using Document Level Alignment.</title>
<date>2010</date>
<booktitle>In NAACL</booktitle>
<contexts>
<context position="2746" citStr="Smith et al., 2010" startWordPosition="409" endWordPosition="412">se-English and ArabicEnglish, and in tens of millions of words for many European languages (Koehn, 2005). In each case, much of this data consists of government and news text. However, for most language pairs and domains there is little to no curated parallel data available. Hence discovery of parallel data is an important first step for translation between most of the world’s languages. The Web is an important source of parallel text. Many websites are available in multiple languages, and unlike other potential sources— such as multilingual news feeds (Munteanu and Marcu, 2005) or Wikipedia (Smith et al., 2010)— it is common to find document pairs that are direct translations of one another. This natural parallelism simplifies the mining task, since few resources or existing corpora are needed at the outset to bootstrap the extraction process. Parallel text mining from the Web was originally explored by individuals or small groups of academic researchers using search engines (Nie et al., 1999; Chen and Nie, 2000; Resnik, 1999; Resnik and Smith, 2003). However, anything more sophisticated generally requires direct access to web-crawled documents themselves along with the computing power to process th</context>
<context position="25678" citStr="Smith et al. (2010)" startWordPosition="4174" endWordPosition="4177">res for several language pairs before and after adding the mined parallel data to systems trained on data from WMT data. WMT 11 FR-EN EN-FR Baseline 30.96 30.69 +Web Data 31.24 31.17 WMT 12 FR-EN EN-FR Baseline 29.88 28.50 +Web Data 30.08 28.76 Table 9: BLEU scores for French-English and English-French before and after adding the mined parallel data to systems trained on data from WMT data including the French-English Gigaword (Callison-Burch et al., 2011). For these experiments, we also include training data mined from Wikipedia using a simplified version of the sentence aligner described by Smith et al. (2010), in order to determine how the effect of such data compares with the effect of webmined data. The baseline system was trained using only the Europarl corpus (Koehn, 2005) as parallel data, and all experiments use the same language model trained on the target sides of Europarl, the English side of all linked SpanishEnglish Wikipedia articles, and the English side of the mined CommonCrawl data. We use a 5- gram language model and tune using MERT (Och, Corpus EN-FR EN-ES EN-DE News Commentary 2.99M 3.43M 3.39M Europarl 50.3M 49.2M 47.9M United Nations 316M 281M - FR-EN Gigaword 668M - - CommonCr</context>
<context position="31987" citStr="Smith et al. (2010)" startWordPosition="5199" endWordPosition="5202">-English documents. 1381 Instead, they represented documents in bag-ofwords vector space, and projected non-English document vectors into the English vector space using the translation probabilities of a word alignment model. By comparison, one appeal of our simple approach is that it requires only a table of language codes. However, with this system in place, we could obtain enough parallel data to bootstrap these more sophisticated approaches. It is also compelling to consider ways in which web-mined data obtained from scratch could be used to bootstrap other mining approaches. For example, Smith et al. (2010) mine parallel sentences from comparable documents in Wikipedia, demonstrating substantial gains on open domain translation. However, their approach required seed parallel data to learn models used in a classifier. We imagine a two-step process, first obtaining parallel data from the web, followed by comparable data from sources such as Wikipedia using models bootstrapped from the web-mined data. Such a process could be used to build translation systems for new language pairs in a very short period of time, hence fulfilling one of the original promises of SMT. Acknowledgements Thanks to Ann Ir</context>
</contexts>
<marker>Smith, Quirk, Toutanova, 2010</marker>
<rawString>Jason R. Smith, Chris Quirk, and Kristina Toutanova. 2010. Extracting Parallel Sentences from Comparable Corpora using Document Level Alignment. In NAACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>News from OPUS - A collection of multilingual parallel corpora with tools and interfaces.</title>
<date>2009</date>
<booktitle>Recent Advances in Natural Language Processing,</booktitle>
<volume>volume V,</volume>
<pages>237--248</pages>
<editor>In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors,</editor>
<location>Amsterdam/Philadelphia, Borovets, Bulgaria.</location>
<contexts>
<context position="26849" citStr="Tiedemann, 2009" startWordPosition="4386" endWordPosition="4387"> 316M 281M - FR-EN Gigaword 668M - - CommonCrawl 121M 68.8M 88.4M Table 10: The size (in English tokens) of the training corpora used in the SMT experiments from Tables 8 and 9 for each language pair. 2003) on the WMT 2009 test set. Unfortunately, it is difficult to obtain meaningful results on some open domain test sets such as the Wikipedia dataset used by Smith et al. (2010). Wikipedia copied across the public internet, and we did not have a simple way to filter such data from our mined datasets. We therefore considered two tests that were less likely to be problematic. The Tatoeba corpus (Tiedemann, 2009) is a collection of example sentences translated into many languages by volunteers. The front page of tatoeba.org was discovered by our URL matching heuristics, but we excluded any sentence pairs that were found in the CommonCrawl data from this test set. 1380 The second dataset is a set of crowdsourced translation of Spanish speech transcriptions from the Spanish Fisher corpus.7 As part of a research effort on cross-lingual speech applications, we obtained English translations of the data using Amazon Mechanical Turk, following a protocol similar to one described by Zaidan and CallisonBurch (</context>
</contexts>
<marker>Tiedemann, 2009</marker>
<rawString>J¨org Tiedemann. 2009. News from OPUS - A collection of multilingual parallel corpora with tools and interfaces. In N. Nicolov, K. Bontcheva, G. Angelova, and R. Mitkov, editors, Recent Advances in Natural Language Processing, volume V, pages 237–248. John Benjamins, Amsterdam/Philadelphia, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferhan Ture</author>
<author>Jimmy Lin</author>
</authors>
<title>Why not grab a free lunch? mining large corpora for parallel sentences to improve translation modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>626--630</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="31198" citStr="Ture and Lin (2012)" startWordPosition="5075" endWordPosition="5078"> by spending a little time crafting regular expressions tailored to some major websites. Callison-Burch et al. (2011) gathered almost 1 trillion tokens of French-English parallel data this way. Another strategy for mining parallel webpage pairs is to scan the HTML for links to the same page in another language (Nie et al., 1999). Other, more sophisticated techniques may also be possible. Uszkoreit et al. (2010), for example, translated all non-English webpages into English using an existing translation system and used near-duplicate detection methods to find candidate parallel document pairs. Ture and Lin (2012) had a similar approach for finding parallel Wikipedia documents by using near-duplicate detection, though they did not need to apply a full translation system to all non-English documents. 1381 Instead, they represented documents in bag-ofwords vector space, and projected non-English document vectors into the English vector space using the translation probabilities of a word alignment model. By comparison, one appeal of our simple approach is that it requires only a table of language codes. However, with this system in place, we could obtain enough parallel data to bootstrap these more sophis</context>
</contexts>
<marker>Ture, Lin, 2012</marker>
<rawString>Ferhan Ture and Jimmy Lin. 2012. Why not grab a free lunch? mining large corpora for parallel sentences to improve translation modeling. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 626–630, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Uszkoreit</author>
<author>Jay M Ponte</author>
<author>Ashok C Popat</author>
<author>Moshe Dubiner</author>
</authors>
<title>Large scale parallel document mining for machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>1101--1109</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="30993" citStr="Uszkoreit et al. (2010)" startWordPosition="5045" endWordPosition="5048">ng cross-domain datasets. Many of the components of our pipeline were basic, leaving considerable room for improvement. For example, the URL matching strategy could easily be improved for a given language pair by spending a little time crafting regular expressions tailored to some major websites. Callison-Burch et al. (2011) gathered almost 1 trillion tokens of French-English parallel data this way. Another strategy for mining parallel webpage pairs is to scan the HTML for links to the same page in another language (Nie et al., 1999). Other, more sophisticated techniques may also be possible. Uszkoreit et al. (2010), for example, translated all non-English webpages into English using an existing translation system and used near-duplicate detection methods to find candidate parallel document pairs. Ture and Lin (2012) had a similar approach for finding parallel Wikipedia documents by using near-duplicate detection, though they did not need to apply a full translation system to all non-English documents. 1381 Instead, they represented documents in bag-ofwords vector space, and projected non-English document vectors into the English vector space using the translation probabilities of a word alignment model.</context>
</contexts>
<marker>Uszkoreit, Ponte, Popat, Dubiner, 2010</marker>
<rawString>Jakob Uszkoreit, Jay M. Ponte, Ashok C. Popat, and Moshe Dubiner. 2010. Large scale parallel document mining for machine translation. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 1101– 1109. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Venugopal</author>
<author>Jakob Uszkoreit</author>
<author>David Talbot</author>
<author>Franz J Och</author>
<author>Juri Ganitkevitch</author>
</authors>
<title>Watermarking the outputs of structured prediction with an application in statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1363--1372</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14901" citStr="Venugopal et al., 2011" startWordPosition="2415" endWordPosition="2419">g by the quality), whereas in 13% of the cases one of the sentences contains additional content not ex4The difference is likely due to the coverage of the CommonCrawl corpus. pressed in the other. As for the false positives, 13.5% of them have either the source or target sentence in the wrong language, and the remaining ones representing failures in the alignment process. Across three languages, our inspection revealed that around 80% of randomly sampled data appeared to contain good translations (Table 2). Although this analysis suggests that language identification and SMT output detection (Venugopal et al., 2011) may be useful additions to the pipeline, we regard this as reasonably high precision for our simple algorithm. Language Precision Spanish 82% French 81% German 78% Table 2: Manual evaluation of precision (by sentence pair) on the extracted parallel data for Spanish, French, and German (paired with English). In addition to the manual evaluation of precision, we applied language identification to our extracted parallel data for several additional languages. We used the “langid.py” tool (Lui and Baldwin, 2012) at the segment level, and report the percentage of sentence pairs where both sentences</context>
</contexts>
<marker>Venugopal, Uszkoreit, Talbot, Och, Ganitkevitch, 2011</marker>
<rawString>Ashish Venugopal, Jakob Uszkoreit, David Talbot, Franz J. Och, and Juri Ganitkevitch. 2011. Watermarking the outputs of structured prediction with an application in statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1363–1372. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>