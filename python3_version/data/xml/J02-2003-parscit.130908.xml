<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9993445">
Class-Based Probability Estimation Using
a Semantic Hierarchy
</title>
<author confidence="0.999909">
Stephen Clark∗ David Weir†
</author>
<affiliation confidence="0.999291">
University of Edinburgh University of Sussex
</affiliation>
<bodyText confidence="0.998893923076923">
This article concerns the estimation of a particular kind of probability, namely, the probability
of a noun sense appearing as a particular argument of a predicate. In order to overcome the
accompanying sparse-data problem, the proposal here is to define the probabilities in terms of
senses from a semantic hierarchy and exploit the fact that the senses can be grouped into classes
consisting of semantically similar senses. There is a particular focus on the problem of how
to determine a suitable class for a given sense, or, alternatively, how to determine a suitable
level of generalization in the hierarchy. A procedure is developed that uses a chi-square test to
determine a suitable level of generalization. In order to test the performance of the estimation
method, a pseudo-disambiguation task is used, together with two alternative estimation methods.
Each method uses a different generalization procedure; the first alternative uses the minimum
description length principle, and the second uses Resnik’s measure of selectional preference. In
addition, the performance of our method is investigated using both the standard Pearson chi-
square statistic and the log-likelihood chi-square statistic.
</bodyText>
<sectionHeader confidence="0.997658" genericHeader="abstract">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999949666666667">
This article concerns the problem of how to estimate the probabilities of noun senses
appearing as particular arguments of predicates. Such probabilities can be useful for a
variety of natural language processing (NLP) tasks, such as structural disambiguation
and statistical parsing, word sense disambiguation, anaphora resolution, and language
modeling. To see how such knowledge can be used to resolve structural ambiguities,
consider the following prepositional phrase attachment ambiguity:
</bodyText>
<subsectionHeader confidence="0.535071">
Example 1
</subsectionHeader>
<bodyText confidence="0.999182666666667">
Fred ate strawberries with a spoon.
The ambiguity arises because the prepositional phrase with a spoon can attach to either
strawberries or ate. The ambiguity can be resolved by noting that the correct sense of
spoon is more likely to be an argument of “ate-with” than “strawberries-with” (Li and
Abe 1998; Clark and Weir 2000).
The problem with estimating a probability model defined over a large vocabulary
of predicates and noun senses is that this involves a huge number of parameters,
which results in a sparse-data problem. In order to reduce the number of parameters,
we propose to define a probability model over senses in a semantic hierarchy and
</bodyText>
<note confidence="0.668114333333333">
∗ Division of Informatics, University of Edinburgh, 2 Buccleuch Place, Edinburgh, EH8 9LW, UK. E-mail:
stephenc@cogsci.ed.ac.uk.
† School of Cognitive and Computing Sciences, University of Sussex, Brighton, BN1 9QH, UK. E-mail:
david.weir@cogs.susx.ac.uk.
© 2002 Association for Computational Linguistics
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.999929875">
to exploit the fact that senses can be grouped into classes consisting of semantically
similar senses. The assumption underlying this approach is that the probability of a
particular noun sense can be approximated by a probability based on a suitably chosen
class. For example, it seems reasonable to suppose that the probability of (the food
sense of) chicken appearing as an object of the verb eat can be approximated in some
way by a probability based on a class such as FOOD.
There are two elements involved in the problem of using a class to estimate the
probability of a noun sense. First, given a suitably chosen class, how can that class
be used to estimate the probability of the sense? And second, given a particular noun
sense, how can a suitable class be determined? This article offers novel solutions to
both problems, and there is a particular focus on the second question, which can be
thought of as how to find a suitable level of generalization in the hierarchy.1
The semantic hierarchy used here is the noun hierarchy of WordNet (Fellbaum
1998), version 1.6. Previous work has considered how to estimate probabilities us-
ing classes from WordNet in the context of acquiring selectional preferences (Resnik
1998; Ribas 1995; Li and Abe 1998; McCarthy 2000), and this previous work has also
addressed the question of how to determine a suitable level of generalization in the
hierarchy. Li and Abe use the minimum description length principle to obtain a level
of generalization, and Resnik uses a simple technique based on a statistical measure
of selectional preference. (The work by Ribas builds on that by Resnik, and the work
by McCarthy builds on that by Li and Abe.) We compare our estimation method with
those of Resnik and Li and Abe, using a pseudo-disambiguation task. Our method
outperforms these alternatives on the pseudo-disambiguation task, and an analysis of
the results shows that the generalization methods of Resnik and Li and Abe appear
to be overgeneralizing, at least for this task.
Note that the problem being addressed here is the engineering problem of es-
timating predicate argument probabilities, with the aim of producing estimates that
will be useful for NLP applications. In particular, we are not addressing the problem
of acquiring selectional restrictions in the way this is usually construed (Resnik 1993;
Ribas 1995; McCarthy 1997; Li and Abe 1998; Wagner 2000). The purpose of using a
semantic hierarchy for generalization is to overcome the sparse data problem, rather
than find a level of abstraction that best represents the selectional restrictions of some
predicate. This point is considered further in Section 5.
The next section describes the noun hierarchy from WordNet and gives a more
precise description of the probabilities to be estimated. Section 3 shows how a class
from WordNet can be used to estimate the probability of a noun sense. Section 4 shows
how a chi-square test is used as part of the generalization procedure, and Section 5
describes the generalization procedure. Section 6 describes the alternative class-based
estimation methods used in the pseudo-disambiguation experiments, and Section 7
presents those experiments.
</bodyText>
<sectionHeader confidence="0.98922" genericHeader="method">
2. The Semantic Hierarchy
</sectionHeader>
<bodyText confidence="0.99886625">
The noun hierarchy of WordNet consists of senses, or what Miller (1998) calls lexicalized
concepts, organized according to the “is-a-kind-of” relation. Note that we are using
concept to refer to a lexicalized concept or sense and not to a set of senses; we use class to
refer to a set of senses. There are around 66,000 different concepts in the noun hierarchy
</bodyText>
<footnote confidence="0.6738675">
1 A third element of the problem, namely, how to obtain arguments of predicates as training data, is not
considered here. We assume the existence of such data, obtained from a treebank or shallow parser.
</footnote>
<page confidence="0.991562">
188
</page>
<note confidence="0.929476">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.999288914285714">
of WordNet version 1.6. A concept in WordNet is represented by a “synset,” which is
the set of synonymous words that can be used to denote that concept. For example,
the synset for the concept (cocaine)2 is { cocaine, cocain, coke, snow, C }. Let syn(c) be the
synset for concept c, and let cn(n) = { c  |n E syn(c) } be the set of concepts that can be
denoted by noun n.
The hierarchy has the structure of a directed acyclic graph (although only around
1% of the nodes have more than one parent), where the edges of the graph constitute
what we call the “direct–isa” relation. Let isa be the transitive, reflexive closure of
direct–isa; then c&apos; isa c implies c&apos; is a kind of c. If c&apos; isa c, then c is a hypernym of c&apos; and
c&apos; is a hyponym of c. In fact, the hierarchy is not a single hierarchy but instead consists of
nine separate subhierarchies, each headed by the most general kind of concept, such as
(entity), (abstraction), (event), and (psychological feature). For the purposes of this work
we add a common root dominating the nine subhierarchies, which we denote (root).
There are some important points that need to be clarified regarding the hierarchy.
First, every concept in the hierarchy has a nonempty synset (except the notional con-
cept (root)). Even the most general concepts, such as (entity), can be denoted by some
noun; the synset for (entity) is { entity, something }. Second, there is an important distinc-
tion between an individual concept and a set of concepts. For example, the individual
concept (entity) should not be confused with the set or class consisting of concepts
denoting kinds of entities. To make this distinction clear, we use c = { c&apos;  |c&apos; isa c }
to denote the set of concepts dominated by concept c, including c itself. For exam-
ple, (animal) is the set consisting of those concepts corresponding to kinds of animals
(including (animal) itself).
The probability of a concept appearing as an argument of a predicate is written p(c |
v, r), where c is a concept in WordNet, v is a predicate, and r is an argument position.3
The focus in this article is on the arguments of verbs, but the techniques discussed
can be applied to any predicate that takes nominal arguments, such as adjectives. The
probability p(c  |v, r) is to be interpreted as follows: This is the probability that some
noun n in syn(c), when denoting concept c, appears in position r of verb v (given
v and r). The example used throughout the article is p((dog)  |run,subj), which is
the conditional probability that some noun in the synset of (dog), when denoting the
concept (dog), appears in the subject position of the verb run. Note that, in practice,
no distinction is made between the different senses of a verb (although the techniques
do allow such a distinction) and that each use of a noun is assumed to correspond to
exactly one concept.4
</bodyText>
<sectionHeader confidence="0.971045" genericHeader="method">
3. Class-Based Probability Estimation
</sectionHeader>
<bodyText confidence="0.999892">
This section explains how a set of concepts, or class, from WordNet can be used to
estimate the probability of an individual concept. More specifically, we explain how
a set of concepts c&apos;, where c&apos; is some hypernym of concept c, can be used to estimate
p(c  |v, r). (Recall that c&apos; denotes the set of concepts dominated by c&apos;, including c&apos; itself.)
One possible approach would be simply to substitute c&apos; for the individual concept c.
This is a poor solution, however, since p(c&apos;  |v, r) is the conditional probability that
</bodyText>
<footnote confidence="0.99517">
2 Angled brackets are used to denote concepts in the hierarchy.
3 The term predicate is used loosely here, in that the predicate does not have to be a semantic object but
can simply be a word form.
4 A recent paper that extends the acquisition of selectional preferences to sense-sense relationships is
Agirre and Martinez (2001).
</footnote>
<page confidence="0.988416">
189
</page>
<note confidence="0.441662">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.99849025">
some noun denoting a concept in c&apos; appears in position r of verb v. For example,
p((animal)  |run,subj) is the probability that some noun denoting a kind of animal
appears in the subject position of the verb run. Probabilities of sets of concepts are
obtained by summing over the concepts in the set:
</bodyText>
<equation confidence="0.99728">
�p(c&apos;  |v, r) = p(c&apos;&apos;  |v, r) (1)
c/IEcI
</equation>
<bodyText confidence="0.9972095">
This means that p((animal)  |run,subj) is likely to be much greater than p((dog) |
run,subj) and thus is not a good approximation of p((dog)  |run,subj).
What can be done, though, is to condition on sets of concepts. If it can be shown
that p(v  |c&apos;, r), for some hypernym c&apos; of c, is a reasonable approximation of p(v  |c, r),
then we have a way of estimating p(c  |v, r). The probability p(v  |c, r) can be obtained
from p(c  |v, r) using Bayes’ theorem:
</bodyText>
<equation confidence="0.999343">
p(c  |v, r) = p(v  |c, r) p(c  |r) (2)
p(v  |r)
</equation>
<bodyText confidence="0.992799428571429">
Since p(c  |r) and p(v  |r) are conditioned on the argument slot only, we assume
these can be estimated satisfactorily using relative frequency estimates. Alternatively,
a standard smoothing technique such as Good-Turing could be used.5 This leaves p(v |
c, r). Continuing with the (dog) example, the proposal is to estimate p(run  |(dog),subj)
using a relative-frequency estimate of p(run  |(animal),subj) or an estimate based on a
similar, suitably chosen class. Thus, assuming this choice of class, p((dog)  |run,subj)
would be approximated as follows:
</bodyText>
<equation confidence="0.9908365">
p((dog)  |run,subj) ,: p(run  |(animal),subj)p((dog) |subj) (3)
p(run  |subj)
</equation>
<bodyText confidence="0.6630485">
The following derivation shows that if p(v  |c&apos;i, r) = k for each child c&apos;i of c&apos;, and
p(v  |c&apos;, r) = k, then p(v  |c&apos;, r) is also equal to k:
</bodyText>
<equation confidence="0.966940866666667">
p(v  |c&apos;, r) = p(c&apos;  |v, r) p(v  |r) (4)
p(c&apos;  |r)
P(c&apos; ||) C�p(c&apos;i  |v, r) + p(c&apos;  |v, r)) (5) i
r)
p(c&apos;  |r) E
p(v|
p(v  |r) + p(v  |c&apos;, r)p(c&apos;  |r)
= p(v  |c&apos; i, r)p(c&apos; i  |r)
p(v  |r)
1
p(c&apos;  |r) k p(c&apos;i  |r) + k p(c&apos;  |r) (7) i
~~ kp (c&apos;  |r)p(ci&apos;  |r) + p(c&apos;  |r)) (8) i
= k (9)
5 Unsmoothed estimates were used in this work.
(6)
</equation>
<page confidence="0.918788">
190
</page>
<note confidence="0.553877">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.983675388888889">
Note that the proof applies only to a tree, since the proof assumes that c&apos; is partitioned
by c&apos; and the sets of concepts dominated by each of the daughters of c&apos;, which is not
necessarily true for a directed acyclic graph (DAG). WordNet is a DAG but is a close
approximation to a tree, and so we assume this will not be a problem in practice.6
The derivation in (4)–(9) shows how probabilities conditioned on sets of concepts
can remain constant when moving up the hierarchy, and this suggests a way of finding
a suitable set, c&apos;, as a generalization for concept c: Initially set c&apos; equal to c and move
up the hierarchy, changing the value of c&apos;, until there is a significant change in p(v |
c&apos;, r). Estimates of p(v  |ci, r), for each child ci of c&apos;, can be compared to see whether
p(v  |c&apos;, r) has significantly changed. (We ignore the probability p(v  |c&apos;, r) and consider
the probabilities p(v  |ci, r) only.) Note that this procedure rests on the assumption that
p(v  |c, r) is close to p(v  |c, r). (In fact, p(v  |c, r) is equal to p(v  |c, r) when c is a leaf
node.) So when finding a suitable level for the estimation of p((sandwich)  |eat, obj),
for example, we first assume that p(eat  |(sandwich), obj) is a good approximation of
p(eat  |(sandwich), obj) and then apply the procedure to p(eat  |(sandwich), obj).
A feature of the proposed generalization procedure is that comparing probabilities
of the form p(v  |C, r), where C is a class, is closely related to comparing ratios of
probabilities of the form p(C  |v,r)/p(C  |r) (for a given verb and argument position):
</bodyText>
<equation confidence="0.9997655">
p(v  |C,r) = p(C  |v,r)
p(C  |r) p(v  |r) (10)
</equation>
<bodyText confidence="0.999340909090909">
Note that, for a given verb and argument position, p(v  |r) is constant across classes.
Equation (10) is of interest because the ratio p(C  |v,r)/p(C  |r) can be interpreted as a
measure of association between the verb v and class C. This ratio is similar to point-
wise mutual information (Church and Hanks 1990) and also forms part of Resnik’s
association score, which will be introduced in Section 6. Thus the generalization pro-
cedure can be thought of as one that finds “homogeneous” areas of the hierarchy,
that is, areas consisting of classes that are associated to a similar degree with the verb
(Clark and Weir 1999).
Finally, we note that the proposed estimation method does not guarantee that the
estimates form a probability distribution over the concepts in the hierarchy, and so a
normalization factor is required:
</bodyText>
<equation confidence="0.99946025">
psc(c  |v, r) = ˆp(v  |[c,v, r],r)ˆp(c|r)
ˆp(v|r) (11)
Ee∈Cˆp(v  |[c�,v,r],r)ˆp(c�|r)
ˆp(v|r)
</equation>
<bodyText confidence="0.999543">
We use psc to denote an estimate obtained using our method (since the technique
finds sets of semantically similar senses, or “similarity classes”) and [c, v, r] to denote
the class chosen for concept c in position r of verb v; pˆ denotes a relative frequency
estimate, and C denotes the set of concepts in the hierarchy.
Before providing the details of the generalization procedure, we give the relative-
frequency estimates of the relevant probabilities and deal with the problem of am-
</bodyText>
<footnote confidence="0.99504925">
6 Li and Abe (1998) also develop a theoretical framework that applies only to a tree and turn WordNet
into a tree by copying each subgraph with multiple parents. One way to extend the experiments in
Section 7 would be to investigate whether this transformation has an impact on the results of those
experiments.
</footnote>
<page confidence="0.985137">
191
</page>
<note confidence="0.369972">
Computational Linguistics Volume 28, Number 2
</note>
<bodyText confidence="0.662555">
biguous data. The relative-frequency estimates are as follows:
</bodyText>
<equation confidence="0.984548833333333">
� v�∈V f (c, v~, r)
ˆp(c  |r) = f(c,r)
f(r) = � � (12)
c�∈C f (c~, v~, r)
v�∈V
� c�∈C f (c~, v, r)
ˆp(v  |r) = f(v,r)
f(r) = � � (13)
c�∈C f (c~, v�,r)
v�∈V
c��∈c� f (c~~, v~, r)
v�∈V
</equation>
<bodyText confidence="0.9995549">
where f (c, v, r) is the number of (n, v, r) triples in the data in which n is being used to
denote c, and V is the set of verbs in the data. The problem is that the estimates are
defined in terms of frequencies of senses, whereas the data are assumed to be in the
form of (n, v, r) triples: a noun, verb, and argument position. All the data used in this
work have been obtained from the British National Corpus (BNC), using the system
of Briscoe and Carroll (1997), which consists of a shallow-parsing component that is
able to identify verbal arguments.
We take a simple approach to the problem of estimating the frequencies of senses,
by distributing the count for each noun in the data evenly among all senses of the
noun:
</bodyText>
<equation confidence="0.998648222222222">
�c��∈c� f(c��,v,r)
ˆp(v  |c~, r) = f(c�,v,r) �
f(c�
,r) = � (14)
�fˆ (c, v, r) =
n∈syn(c)
(15)
|cn(n)|
f(n,v,r)
</equation>
<bodyText confidence="0.998486333333333">
where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position
r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by
Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how
this apparently crude technique works surprisingly well. Alternative approaches are
described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999),
and Ciaramita and Johnson (2000).
</bodyText>
<subsectionHeader confidence="0.513906">
4. Using a Chi-Square Test to Compare Probabilities
</subsectionHeader>
<bodyText confidence="0.9997638">
In this section we show how to test whether p(v  |c&apos;, r) changes significantly when
considering a node higher in the hierarchy. Consider the problem of deciding whether
p(run  |(canine),subj) is a good approximation of p(run  |(dog),subj). ((canine) is the
parent of (dog) in WordNet.) To do this, the probabilities p(run  |ci,subj) are compared
using a chi-square test, where the ci are the children of (canine). In this case, the null
hypothesis of the test is that the probabilities p(run  |ci,subj) are the same for each
child ci. By judging the strength of the evidence against the null hypothesis, how
similar the true probabilities are likely to be can be determined. If the test indicates
that the probabilities are sufficiently unlikely to be the same, then the null hypothesis
is rejected, and the conclusion is that p(run  |(canine), subj) is not a good approximation
of p(run  |(dog),subj).
An example contingency table, based on counts obtained from a subset of the BNC
using the system of Briscoe and Carroll, is given in Table 1. (Recall that the frequencies
are estimated by distributing the count for a noun equally among the noun’s senses;
this explains the fractional counts.) One column contains estimates of counts arising
</bodyText>
<listItem confidence="0.2924895">
7 Resnik takes a similar approach but divides the count evenly among the noun’s senses and all the
hypernyms of those senses.
</listItem>
<page confidence="0.994294">
192
</page>
<note confidence="0.817154">
Clark and Weir Class-Based Probability Estimation
</note>
<tableCaption confidence="0.996912">
Table 1
</tableCaption>
<table confidence="0.929892">
Contingency table for the children of (canine) in the subject position of run.
ci ˆf(ci, run, subj) ˆf(ci, subj) −ˆf(ci, run, subj) ˆf(ci, subj) = � v∈V ˆf(ci, v, subj)
0.3 (0.5) 26.7 (26.6) 27.0
(bitch)
(dog) 12.8 (10.5) 620.4 (622.7) 633.2
(wolf) 0.3 (0.6) 38.7 (38.4) 39.0
(jackal) 0.0 (0.3) 20.0 (19.7) 20.0
(wild dog) 0.0 (0.0) 3.0 (3.0) 3.0
(hyena) 0.0 (0.2) 10.0 (9.8) 10.0
(fox) 0.0 (1.2) 72.3 (71.1) 72.3
13.4 791.1 804.5
</table>
<bodyText confidence="0.992643857142857">
from concepts in ci appearing in the subject position of the verb run: fˆ (ci, run, subj). A
second column presents estimates of counts arising from concepts in ci appearing in
the subject position of a verb other than run. The figures in brackets are the expected
values if the null hypothesis is true.
There is a choice of which statistic to use in conjunction with the chi-square test.
The usual statistic encountered in textbooks is the Pearson chi-square statistic, de-
noted X2:
</bodyText>
<equation confidence="0.9786155">
�X2 = (oij − eij)2 (16)
i,j eij
</equation>
<bodyText confidence="0.97274245">
where oij is the observed value for the cell in row i and column j, and eij is the
corresponding expected value. An alternative statistic is the log-likelihood chi-square
statistic, denoted G2:8
�G2 = 2 oij
i,j oij loge (17)
eij
The two statistics have similar values when the counts in the contingency table are
large (Agresti 1996). The statistics behave differently, however, when the table contains
low counts, and, since corpus data are likely to lead to some low counts, the question
of which statistic to use is an important one. Dunning (1993) argues for the use of G2
rather than X2, based on an analysis of the sampling distributions of G2 and X2, and
results obtained when using the statistics to acquire highly associated bigrams. We
consider Dunning’s analysis at the end of this section, and the question of whether to
use G2 or X2 will be discussed further there. For now, we continue with the discussion
of how the chi-square test is used in the generalization procedure.
For Table 1, the value of G2 is 3.8, and the value of X2 is 2.5. Assuming a level of
significance of α = 0.05, the critical value is 12.6 (for six degrees of freedom). Thus,
for this α value, the null hypothesis would not be rejected for either statistic, and the
conclusion would be that there is no reason to suppose that p(run  |(canine), subj) is
not a reasonable approximation of p(run  |(dog), subj).
</bodyText>
<footnote confidence="0.595046">
8 An alternative formula for G2 is given in Dunning (1993), but the two are equivalent.
</footnote>
<page confidence="0.993477">
193
</page>
<note confidence="0.402824">
Computational Linguistics Volume 28, Number 2
</note>
<tableCaption confidence="0.967531">
Table 2
</tableCaption>
<table confidence="0.915249384615385">
Contingency table for the children of (liquid) in the object position of drink.
ci ˆf(ci, drink, obj) ˆf(ci, obj) − ˆf(ci, drink, obj) ˆf(ci, obj) = Ev∈Vˆf(ci, v, obj)
261.0 (238.7) 2,367.7 (2,390.0) 2,628.7
(beverage)
(supernatant) 0.0 (0.1) 1.0 (0.9) 1.0
(alcohol) 11.5 (9.4) 92.0 (94.1) 103.5
(ammonia) 0.0 (0.8) 8.5 (7.7) 8.5
(antifreeze) 0.0 (0.1) 1.0 (0.9) 1.0
(distillate) 0.0 (0.5) 6.0 (5.5) 6.0
(water) 12.0 (31.6) 335.7 (316.1) 347.7
(ink) 0.0 (2.9) 32.0 (29.1) 32.0
(liquor) 0.7 (1.1) 11.6 (11.2) 12.3
285.2 2,855.5 3,140.7
</table>
<bodyText confidence="0.99995728125">
As a further example, Table 2 gives counts for the children of (liquid) in the object
position of drink. Again, the counts have been obtained from a subset of the BNC
using the system of Briscoe and Carroll. Not all the sets dominated by the children of
(liquid) are shown, as some, such as (sheep dip), never appear in the object position
of a verb in the data. This example is designed to show a case in which the null
hypothesis is rejected. The value of G2 for this table is 29.0, and the value of X2 is
21.2. So for G2, even if an α value as low as 0.0005 were being used (for which the
critical value is 27.9 for eight degrees of freedom), the null hypothesis would still be
rejected. For X2, the null hypothesis is rejected for α values greater than 0.005. This
seems reasonable, since the probabilities associated with the children of (liquid) and
the object position of drink would be expected to show a lot of variation across the
children.
A key question is how to select the appropriate value for α. One solution is to
treat α as a parameter and set it empirically by taking a held-out test set and choosing
the value of α that maximizes performance on the relevant task. For example, Clark
and Weir (2000) describes a prepositional phrase attachment algorithm that employs
probability estimates obtained using the WordNet method described here. To set the
value of α, the performance of the algorithm on a development set could be com-
pared across different values of α, and the value that leads to the best performance
could be chosen. Note that this approach sets no constraints on the value of α: The
value could be as high as 0.995 or as low as 0.0005, depending on the particular
application.
There may be cases in which the conditions for the appropriate application of a chi-
square test are not met. One condition that is likely to be violated is the requirement
that expected values in the contingency table not be too small. (A rule of thumb
often found in textbooks is that the expected values should be greater than five.) One
response to this problem is to apply some kind of thresholding and either ignore
counts below the threshold, or apply the test only to tables that do not contain low
counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use
some kind of thresholding when dealing with counts in the hierarchy (although not in
the context of a chi-square test). Another approach would be to use Fisher’s exact test
(Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of
</bodyText>
<page confidence="0.983302">
194
</page>
<note confidence="0.580616">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.999892363636363">
the counts they contain. The main problem with this test is that it is computationally
expensive, especially for large contingency tables.
What we have found in practice is that applying the chi-square test to tables dom-
inated by low counts tends to produce an insignificant result, and the null hypothesis
is not rejected. The consequences of this for the generalization procedure are that
low-count tables tend to result in the procedure moving up to the next node in the
hierarchy. But given that the purpose of the generalization is to overcome the sparse-
data problem, moving up a node is desirable, and therefore we do not modify the test
for tables with low counts.
The final issue to consider is which chi-square statistic to use. Dunning (1993)
argues for the use of G2 rather than X2, based on the claim that the sampling distri-
bution of G2 approaches the true chi-square distribution quicker than the sampling
distribution of X2. However, Agresti (1996, page 34) makes the opposite claim: “The
sampling distributions of X2 and G2 get closer to chi-squared as the sample size n
increases.... The convergence is quicker for X2 than G2.”
In addition, Pedersen (2001) questions whether one statistic should be preferred
over the other for the bigram acquisition task and cites Cressie and Read (1984), who
argue that there are some cases where the Pearson statistic is more reliable than the
log-likelihood statistic. Finally, the results of the pseudo-disambiguation experiments
presented in Section 7 are at least as good, if not better, when using X2 rather than G2,
and so we conclude that the question of which statistic to use should be answered on
a per application basis.
</bodyText>
<sectionHeader confidence="0.976946" genericHeader="method">
5. The Generalization Procedure
</sectionHeader>
<bodyText confidence="0.99985932">
The procedure for finding a suitable class, c&apos;, to generalize concept c in position r
of verb v works as follows. (We refer to c&apos; as the “similarity class” of c with respect
to v and r and the hypernym c&apos; as top(c,v,r), since the chosen hypernym sits at the
“top” of the similarity class.) Initially, concept c is assigned to a variable top. Then,
by working up the hierarchy, successive hypernyms of c are assigned to top, and this
process continues until the probabilities associated with the sets of concepts dominated
by top and the siblings of top are significantly different. Once a node is reached that
results in a significant result for the chi-square test, the procedure stops, and top is
returned as top(c,v,r). In cases where a concept has more than one parent, the parent
is chosen that results in the lowest value of the chi-square statistic, as this indicates
the probabilities are the most similar. The set top(c, v, r) is the similarity class of c for
verb v and position r. Figure 1 gives an algorithm for determining top(c,v,r).
Figure 2 gives an example of the procedure at work. Here, top((soup), stir, obj) is
being determined. The example is based on data from a subset of the BNC, with 303
cases of an argument in the object position of stir. The G2 statistic is used, together with
an α value of 0.05. Initially, top is set to (soup), and the probabilities corresponding
to the children of (dish) are compared: p(stir  |(soup),obj), p(stir  |(lasagne),obj), p(stir |
(haggis),obj), and so on for the rest of the children. The chi-square test results in a G2
value of 14.5, compared to a critical value of 55.8. Since G2 is less than the critical value,
the procedure moves up to the next node. This process continues until a significant
result is obtained, which first occurs at (substance) when comparing the children of
(object). Thus (substance) is the chosen level of generalization.
Now we show how the chosen level of generalization varies with α and how it
varies with the size of the data set. A note of clarification is required before presenting
the results. In related work on acquiring selectional preferences (Ribas 1995; McCarthy
</bodyText>
<page confidence="0.979884">
195
</page>
<figure confidence="0.985086944444445">
Computational Linguistics Volume 28, Number 2
Algorithm top(c,v,r):
top +— c
sig result +— false
comment parentmin gives lowest G2 value, G2min
while not sig result &amp; top =� (root) do
G2min +— 00
for all parents of top do
calculate G2 for sets dominated by children of parent
if G2 &lt; G2min
then G2min +— G2
parentmin +— parent
end
if chi-square test for parentmin is significant
then sig result +— true
else move up to next node: top +— parentmin
end
return top
</figure>
<figureCaption confidence="0.79946">
Figure 1
</figureCaption>
<bodyText confidence="0.356504">
An algorithm for determining top(c, v, r).
</bodyText>
<figureCaption confidence="0.906745">
Figure 2
</figureCaption>
<bodyText confidence="0.452583">
An example generalization: Determining top((soup), stir, obj).
</bodyText>
<figure confidence="0.981023052631579">
artifact
ground
food
fluid poison
G2: 29.9, crit val: 58.1
substance
entity
object
G2: 141.1, crit val: 37.7
nourishment
fare beverage
dish
meal
course
G2: 5.5, crit val: 16.9
G2: 5.4, crit val: 16.9
lasagne haggis
G2: 14.5, critical value: 55.8
soup
</figure>
<page confidence="0.943467">
196
</page>
<note confidence="0.434537">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.9981153">
1997; Li and Abe 1998; Wagner 2000), the level of generalization is often determined for
a small number of hand-picked verbs and the result compared with the researcher’s
intuition about the most appropriate level for representing a selectional preference.
According to this approach, if (sandwich) were chosen to represent (hotdog) in the
object position of eat, this might be considered an undergeneralization, since (food)
might be considered more appropriate. For this work we argue that such an evaluation
is not appropriate; since the purpose of this work is probability estimation, the most
appropriate level is the one that leads to the most accurate estimate, and this may or
may not agree with intuition. Furthermore, we show in Section 7 that to generalize
unnecessarily can be harmful for some tasks: If we already have lots of data regarding
(sandwich), why generalize any higher? Thus the purpose of this section is not to show
that the acquired levels are “correct,” but simply to show how the levels vary with α
and the sample size.
To show how the level of generalization varies with changes in α, top(c,v,obj)
was determined for a number of hand-picked (c, v, obj) triples over a range of values
for α. The triples were chosen to give a range of strongly and weakly selecting verbs
and a range of verb frequencies. The data were again extracted from a subset of the
BNC using the system of Briscoe and Carroll (1997), and the G2 statistic was used in
the chi-square test. The results are shown in Table 3. The number of times the verb
occurred with some object is also given in the table.
The results suggest that the generalization level becomes more specific as α in-
creases. This is to be expected, since, given a contingency table chosen at random, a
higher value of α is more likely to lead to a significant result than a lower value of α.
We also see that, for some cases, the value of α has little effect on the level. We would
expect there to be less change in the level of generalization for strongly selecting verbs,
such as drink and eat, and a greater range of levels for weakly selecting verbs such
as see. This is because any significant difference in probabilities is likely to be more
marked for a strongly selecting verb, and likely to be significant over a wider range
of α values. The table only provides anecdotal evidence, but provides some support
to this argument.
To investigate more generally how the level of generalization varies with changes
in α, and also with changes in sample size, we took 6, 000 (c, v, obj) triples and calcu-
lated the difference in depth between c and top(c, v, r) for each triple. The 6, 000 triples
were taken from the first experimental test set described in Section 7, and the train-
ing data from this experiment were used to provide the counts. (The test set contains
nouns, rather than noun senses, and so the sense of the noun that is most probable
given the verb and object slot was used.) An average difference in depth was then
calculated. To give an example of how the difference in depth was calculated, sup-
pose (dog) generalized to (placental mammal) via (canine) and (carnivore); in this case
the difference would be three.
The results for various levels of α and different sample sizes are shown in Table 4.
The figures in each column arise from using the contingency tables based on the
complete training data, but with each count in the table multiplied by the percentage
at the head of the column. Thus the 50% column is based on contingency tables in
which each original count is multiplied by 50%, which is equivalent to using a sample
one-half the size of the original training set. Reading across a row shows how the
generalization varies with sample size, and reading down a column shows how it
varies with α. The results show clearly that the extent of generalization decreases
with an increase in the value of α, supporting the trend observed in Table 3. The
results also show that the extent of generalization increases with a decrease in sample
</bodyText>
<page confidence="0.984619">
197
</page>
<table confidence="0.458918">
Computational Linguistics Volume 28, Number 2
</table>
<tableCaption confidence="0.7574115">
Table 3
Example levels of generalization for different values of α.
</tableCaption>
<equation confidence="0.986633827586207">
(c, v, r), f(v, r) α
((coffee), drink, obj) 0.0005 (coffee)(BEVERAGE)(food) ... (object)(entity)
0.05 (coffee)(BEVERAGE)(food) ... (object)(entity)
f(drink,obj) = 849 0.5 (coffee)(BEVERAGE)(food) ... (object)(entity)
0.995 (coffee)(BEVERAGE)(food) ... (object)(entity)
((hotdog), eat, obj) 0.0005 (hotdog)(sandwich)(snack food)(DISH) ... (food) ... (entity)
0.05 (hotdog)(sandwich)(snack food)(DISH) ... (food) ... (entity)
f (eat, obj) = 1,703 0.5 (hotdog)(sandwich)(snack food)(DISH) ... (food) ... (entity)
0.995 (hotdog)(SANDWICH)(snack food)(dish) ... (food) ... (entity)
((Socrates), kiss, obj) 0.0005 (Socrates) ... (person)(life form)(CAUSAL AGENT)(entity)
0.05 (Socrates) ... (person)(life form)(CAUSAL AGENT)(entity)
f (kiss, obj) = 345 0.5 (Socrates) ... (person)(life form)(CAUSAL AGENT)(entity)
0.995 (Socrates) ... (PERSON)(life form)(causal agent)(entity)
((dream), remember, obj) 0.0005 (dream) ... (preoccupation)(cognitive state)(STATE)
0.05 (dream) ... (preoccupation)(cognitive state)(STATE)
f (remember, obj) = 1,982 0.5 (dream) ... (preoccupation)(COGNITIVE STATE)(state)
0.995 (dream) ... (PREOCCUPATION)(cognitive state)(state)
((man), see, obj) 0.0005 (man) ... (mammal) ... (ANIMAL)(life form)(entity)
0.05 (man) ... (MAMMAL) ... (animal)(life form)(entity)
f (see, obj) = 16,757 0.5 (man) ... (MAMMAL) ... (animal)(life form)(entity)
0.995 (MAN) ... (mammal) ... (animal)(life form)(entity)
((belief), abandon, obj) 0.0005 (belief)(mental object)(cognition)(PSYCHOLOGICAL FEATURE)
0.05 (belief)(MENTAL OBJECT)(cognition)(psychological feature)
f (abandon, obj) = 673 0.5 (BELIEF)(mental object)(cognition)(psychological feature)
0.995 (BELIEF)(mental object)(cognition)(psychological feature)
((nightmare), have, obj) 0.0005 (nightmare)(dreaming)(IMAGINATION) ... (psychological feature)
0.05 (nightmare)(dreaming)(IMAGINATION) ... (psychological feature)
f (have, obj) = 93,683 0.5 (nightmare)(DREAMING)(imagination) ... (psychological feature)
0.995 (nightmare)(DREAMING)(imagination) ... (psychological feature)
</equation>
<tableCaption confidence="0.787913">
Note: The selected level is shown in upper case.
Table 4
</tableCaption>
<table confidence="0.996091">
Extent of generalization for different values of α and sample sizes.
α 100% 50% 10% 1%
0.0005 3.3 3.9 5.0 5.6
0.05 2.8 3.5 4.6 5.6
0.5 2.1 2.9 4.1 5.4
0.995 1.2 1.5 2.6 3.9
</table>
<bodyText confidence="0.897034">
size. Again, this is to be expected, since any difference in probability estimates is less
likely to be significant for tables with low counts.
</bodyText>
<sectionHeader confidence="0.981854" genericHeader="method">
6. Alternative Class-Based Estimation Methods
</sectionHeader>
<bodyText confidence="0.9998275">
The approaches used for comparison are that of Resnik (1993, 1998), subsequently
developed by Ribas (1995), and that of Li and Abe (1998), which has been adopted by
McCarthy (2000). These have been chosen because they directly address the question
of how to find a suitable level of generalization in WordNet.
</bodyText>
<page confidence="0.995891">
198
</page>
<note confidence="0.794188">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.936528333333333">
The first alternative uses the “association score,” which is a measure of how well
a set of concepts, C, satisfies the selectional preferences of a verb, v, for an argument
position, r:9
</bodyText>
<equation confidence="0.999884666666667">
p(C  |v,r)
A(C,v,r) = p(C  |v,r) log2 (18)
p(C  |r)
</equation>
<bodyText confidence="0.999959815789474">
An estimate of the association score, ˆA(C, v, r), can be obtained using relative frequency
estimates of the probabilities. The key question is how to determine a suitable level of
generalization for concept c, or, alternatively, how to find a suitable class to represent
concept c (assuming the choice is from those classes that contain all concepts dom-
inated by some hypernym of c). Resnik’s solution to this problem (which he neatly
refers to as the “vertical-ambiguity” problem) is to choose the class that maximizes
the association score.
It is not clear that the class with the highest association score is always the most
appropriate level of generalization. For example, this approach does not always gen-
eralize appropriately for arguments that are negatively associated with some verb. To
see why, consider the problem of deciding how well the concept (location) satisfies the
preferences of the verb eat for its object. Since locations are not the kinds of things that
are typically eaten, a suitable level of generalization would correspond to a class that
has a low association score with respect to eat. However, (location) is a kind of (entity)
in WordNet,10 and choosing the class with the highest association score is likely to
produce (entity) as the chosen class. This is a problem, because the association score
of (entity) with respect to eat may be too high to reflect the fact that (location) is a very
unlikely object of the verb.
Note that the solution to the vertical-ambiguity problem presented in the previous
sections is able to generalize appropriately in such cases. Continuing with the eat
(location) example, our generalization procedure is unlikely to get as high as (entity)
(assuming a reasonable number of examples of eat in the training data), since the
probabilities corresponding to the daughters of (entity) are likely to be very different
with respect to the object position of eat.
The second alternative uses the minimum description length (MDL) principle.
Li and Abe use MDL to select a set of classes from a hierarchy, together with their
associated probabilities, to represent the selectional preferences of a particular verb.
The preferences and class-based probabilities are then used to estimate probabilities
of the form p(n  |v, r), where n is a noun, v is a verb, and r is an argument slot.
Li and Abe’s application of MDL requires the hierarchy to be in the form of a
thesaurus, in which each leaf node represents a noun and internal nodes represent the
class of nouns that the node dominates. The hierarchy is also assumed to be in the
form of a tree. The class-based models consist of a partition of the set of nouns (leaf
nodes) and a probability associated with each class in the partition. The probabilities
are the conditional probabilities of each class, given the relevant verb and argument
position. Li and Abe refer to such a partition as a “cut” and the cut together with the
probabilities as a “tree cut model.” The probabilities of the classes in a cut, P, satisfy
the following constraint:
</bodyText>
<equation confidence="0.953612">
E p(C  |v,r) = 1 (19)
C∈Γ
</equation>
<page confidence="0.775351">
9 The definition used here is that given by Ribas (1995).
10 For example, the hypernyms of the concept (Dallas) are as follows: (city), (municipality),
</page>
<bodyText confidence="0.568632">
(urban area), (geographical area), (region), (location), (object), (entity).
</bodyText>
<page confidence="0.983331">
199
</page>
<figure confidence="0.989058">
Computational Linguistics Volume 28, Number 2
&lt;root&gt;
</figure>
<figureCaption confidence="0.75623">
Figure 3
</figureCaption>
<bodyText confidence="0.841590666666667">
Possible cut returned by MDL.
In order to determine the probability of a noun, the probability of a class is assumed
to be distributed uniformly among the members of that class:
</bodyText>
<equation confidence="0.989411">
1
p(n  |v, r) = |C |p(C  |v, r) for all n E C (20)
</equation>
<bodyText confidence="0.99937868">
Since WordNet is a hierarchy with noun senses, rather than nouns, at the nodes,
Li and Abe deal with the issue of word sense ambiguity using the method described
in Section 3, by dividing the count for a noun equally among the concepts whose
synsets contain the noun. Also, since WordNet is a DAG, Li and Abe turn WordNet
into a tree by copying each subgraph with multiple parents. And so that each noun
in the data appears (in a synset) at a leaf node, Li and Abe remove those parts of the
hierarchy dominated by a noun in the data (but only for that instance of WordNet
corresponding to the relevant verb).
An example cut showing part of the WordNet hierarchy is shown in Figure 3 (based
on an example from Li and Abe [1998]; the dashed lines indicate parts of the hierarchy
that are not shown in the diagram). This is a possible cut for the object position of the
verb eat, and the cut consists of the following classes: (life form), (solid), (fluid), (food),
(artifact), (space), (time), (set). (The particular choice of classes for the cut in this example
is not too important; the example is designed to show how probabilities of senses are
estimated from class probabilities.) Since the class in the cut containing (pizza) is (food),
the probability p((pizza)  |eat,obj) would be estimated as p((food)  |eat, obj)/|(food)|.
Similarly, since the class in the cut containing (mushroom) is (life form), the probability
p((mushroom)  |eat, obj) would be estimated as p((life form)  |eat, obj)/|(life form)|.
The uniform-distribution assumption (20) means that cuts close to the root of the
hierarchy result in a greater smoothing of the probability estimates than cuts near the
leaves. Thus there is a trade-off between choosing a model that has a cut near the
leaves, which is likely to overfit the data, and a more general (simple) model near the
root, which is likely to underfit the data. MDL looks ideally suited to the task of model
selection, since it is designed to deal with precisely this trade-off. The simplicity of a
model is measured using the model description length, which is an information-theoretic
</bodyText>
<figure confidence="0.999496111111111">
&lt;entity&gt;
&lt;abstraction&gt;
&lt;plant&gt;
&lt;mushroom&gt;
&lt;animal&gt;
&lt;lobster&gt;
&lt;substance&gt;
&lt;solid&gt; &lt;fluid&gt;
&lt;lobster&gt;
&lt;life_form&gt;
&lt;time&gt;
&lt;space&gt;
&lt;set&gt;
&lt;artifact&gt;
&lt;food&gt;
&lt;object&gt;
&lt;rope&gt;
&lt;pizza&gt;
</figure>
<page confidence="0.939213">
200
</page>
<note confidence="0.799857">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.999942058823529">
term and denotes the number of bits required to encode the model. The fit to the data
is measured using the data description length, which is the number of bits required to
encode the data (relative to the model). The overall description length is the sum of
the model description length and the data description length, and the MDL principle
is to select the model with the shortest description length.
We used McCarthy’s (2000) implementation of MDL. So that every noun is repre-
sented at a leaf node, McCarthy does not remove parts of the hierarchy, as Li and Abe
do, but instead creates new leaf nodes for each synset at an internal node. McCarthy
also does not transform WordNet into a tree, which is strictly required for Li and
Abe’s application of MDL. This did create a problem with overgeneralization: Many
of the cuts returned by MDL were overgeneralizing at the (entity) node. The reason
is that (person), which is close to (entity) and dominated by (entity), has two parents:
(life form) and (causal agent). This DAG-like property was responsible for the over-
generalization, and so we removed the link between (person) and (causal agent). This
appeared to solve the problem, and the results presented later for the average degree
of generalization do not show an overgeneralization compared with those given in Li
and Abe (1998).
</bodyText>
<sectionHeader confidence="0.862418" genericHeader="method">
7. Pseudo-Disambiguation Experiments
</sectionHeader>
<bodyText confidence="0.992387344827586">
The task we used to compare the class-based estimation techniques is a decision task
previously used by Pereira, Tishby, and Lee (1993) and Rooth et al. (1999). The task is
to decide which of two verbs, v and v&apos;, is more likely to take a given noun, n, as an
object. The test and training data were obtained as follows. A number of verb–direct
object pairs were extracted from a subset of the BNC, using the system of Briscoe and
Carroll. All those pairs containing a noun not in WordNet were removed, and each
verb and argument was lemmatized. This resulted in a data set of around 1.3 million
(v, n) pairs.
To form a test set, 3,000 of these pairs were randomly selected such that each
selected pair contained a fairly frequent verb. (Following Pereira, Tishby, and Lee, only
those verbs that occurred between 500 and 5,000 times in the data were considered.)
Each instance of a selected pair was then deleted from the data to ensure that the test
data were unseen. The remaining pairs formed the training data. To complete the test
set, a further fairly frequent verb, v&apos;, was randomly chosen for each (v, n) pair. The
random choice was made according to the verb’s frequency in the original data set,
subject to the condition that the pair (v&apos;, n) did not occur in the training data. Given
the set of (v, n, v&apos;) triples, the task is to decide whether (v, n) or (v&apos;, n) is the correct
pair.11
We acknowledge that the task is somewhat artificial, but pseudo-disambiguation
tasks of this kind are becoming popular in statistical NLP because of the ease with
which training and test data can be created. We also feel that the pseudo-disambig-
uation task is useful for evaluating the different estimation methods, since it directly
addresses the question of how likely a particular predicate is to take a given noun as
an argument. An evaluation using a PP attachment task was attempted in Clark and
Weir (2000), but the evaluation was limited by the relatively small size of the Penn
Treebank.
11 We note that this procedure does not guarantee that the correct pair is more likely than the incorrect
pair, because of noise in the data from the parser and also because a highly plausible incorrect pair
could be generated by chance.
</bodyText>
<page confidence="0.994968">
201
</page>
<note confidence="0.531369">
Computational Linguistics Volume 28, Number 2
</note>
<tableCaption confidence="0.870977">
Table 5
</tableCaption>
<figure confidence="0.8545779">
Results for the pseudo-disambiguation task.
Generalization technique
Similarity class
α = 0.0005
α = 0.05
α = 0.3
α = 0.75
α = 0.995
Low class
MDL
Assoc
% correct av.gen. sd.gen.
73.8 3.3 2.0
73.4 2.8 1.9
73.0 2.4 1.8
73.9 1.9 1.6
73.8 1.2 1.2
73.6 0.9 1.0
68.3 4.1 1.9
63.9 4.2 2.1
</figure>
<figureCaption confidence="0.831514">
Note: av.gen. is the average number of generalized levels;
sd.gen. is the standard deviation.
</figureCaption>
<bodyText confidence="0.894942">
Using our approach, the disambiguation decision for each (v, n, v&apos;) triple was made
according to the following procedure:
if max psc(c I v, obj) &gt; max psc(c I v&apos;, obj)
</bodyText>
<equation confidence="0.882333">
cEcn(n) cEcn(n)
then choose (v, n)
else if max
</equation>
<bodyText confidence="0.999264714285714">
If n has more than one sense, the sense is chosen that maximizes the relevant prob-
ability estimate; this explains the maximization over cn(n). The probability estimates
were obtained using our class-based method, and the G2 statistic was used for the
chi-square test. This procedure was also used for the MDL alternative, but using the
MDL method to estimate the probabilities.
Using the association score for each test triple, the decision was made according
to the following procedure:
</bodyText>
<figure confidence="0.990105">
psc(c I v&apos;, obj) &gt; max psc(c I v, obj)
cEcn(n) cEcn(n)
then choose (v&apos;, n)
else choose at random
if max max ˆA(c&apos;,v,obj) &gt; max max ˆA(c&apos;, v&apos;, obj)
cEcn(n) c&apos;Eh(c) cEcn(n) c&apos;Eh(c)
then choose (v, n)
else if max max ˆA(c&apos;,v&apos;,obj) &gt; max max ˆA(c&apos;, v, obj)
cEcn(n) c&apos;Eh(c) cEcn(n) c&apos;Eh(c)
</figure>
<bodyText confidence="0.859452666666667">
then choose (v&apos;, n)
else choose at random
We use h(c) to denote the set consisting of the hypernyms of c. The inner maximization
is over h(c), assuming c is the chosen sense of n, which corresponds to Resnik’s method
of choosing a set to represent c. The outer maximization is over the senses of n, cn(n),
which determines the sense of n by choosing the sense that maximizes the association
score.
The first set of results is given in Table 5. Our technique is referred to as the
“similarity class” technique, and the approach using the association score is referred
</bodyText>
<page confidence="0.995332">
202
</page>
<note confidence="0.886159">
Clark and Weir Class-Based Probability Estimation
</note>
<tableCaption confidence="0.94764">
Table 6
</tableCaption>
<figure confidence="0.80044655">
Results for the pseudo-disambiguation task with one-fifth training data.
Generalization technique
Similarity class
α = 0.0005
α = 0.05
α = 0.3
α = 0.75
α = 0.995
Low class
MDL
Assoc
% correct av.gen. sd.gen.
66.7 4.5 1.9
68.4 4.1 1.9
70.2 3.7 1.9
72.3 3.0 1.9
72.4 1.9 1.6
71.9 1.1 1.1
62.9 4.7 1.9
62.6 4.1 2.0
</figure>
<figureCaption confidence="0.831608">
Note: av.gen. is the average number of generalized levels;
sd.gen. is the standard deviation.
</figureCaption>
<bodyText confidence="0.999809766666667">
to as “Assoc.” The results are given for a range of α values and demonstrate clearly that
the performance of similarity class varies little with changes in α and that similarity
class outperforms both MDL and Assoc.12
We also give a score for our approach using a simple generalization procedure,
which we call “low class.” The procedure is to select the first class that has a count
greater than zero (relative to the verb and argument position), which is likely to return
a low level of generalization, on the whole. The results show that our generalization
technique only narrowly outperforms the simple alternative. Note that, although low
class is based on a very simple generalization method, the estimation method is still
using our class-based technique, by applying Bayes’ theorem and conditioning on a
class, as described in Section 3; the difference is in how the class is chosen.
To investigate the results, we calculated the average number of generalized levels
for each approach. The number of generalized levels for a concept c (relative to a
verb v and argument position r) is the difference in depth between c and top(c, v, r),
as explained in Section 5. For each test case, the number of generalized levels for
both verbs, v and v&apos;, was calculated, but only for the chosen sense of n. The results
are given in the third column of Table 5 and demonstrate clearly that both MDL and
Assoc are generalizing to a greater extent than similarity class. (The fourth column
gives a standard deviation figure.) These results suggest that MDL and Assoc are
overgeneralizing, at least for the purposes of this task.
To investigate why the value for α had no impact on the results, we repeated the
experiment, but with one fifth of the data. A new data set was created by taking every
fifth pair of the original 1.3 million pairs. A test set of 3,000 triples was created from
this new data set, as before, but this time only verbs that occurred between 100 and
1,000 times were considered. The results using these test and training data are given
in Table 6.
These results show a variation in performance across values for α, with an opti-
mal performance when α is around 0.75. (Of course, in practice, the value for α would
need to be optimized on a held-out set.) But even with this variation, similarity class is
still outperforming MDL and Assoc across the whole range of α values. Note that the
</bodyText>
<footnote confidence="0.9093935">
12 The results given for similarity class are different from those given in Clark and Weir (2001) because
the probability estimates used in Clark and Weir (2001) were not normalized.
</footnote>
<page confidence="0.995234">
203
</page>
<note confidence="0.60116">
Computational Linguistics Volume 28, Number 2
</note>
<tableCaption confidence="0.994588">
Table 7
</tableCaption>
<table confidence="0.983935">
Disambiguation results for G2 and X2.
α value % correct (G2) % correct (X2)
0.0005 73.8 (3.3) 74.1 (3.0)
0.05 73.4 (2.8) 73.8 (2.5)
0.3 73.0 (2.4) 74.1 (2.2)
0.75 73.9 (1.9) 74.3 (1.8)
0.995 73.8 (1.2) 73.3 (1.2)
</table>
<bodyText confidence="0.999778411764706">
α values corresponding to the lowest scores lead to a significant amount of general-
ization, which provides additional evidence that MDL and Assoc are overgeneralizing
for this task. The low-class method scores highly for this data set also, but given that
the task is one that apparently favors a low level of generalization, the high score is
not too surprising.
As a final experiment, we compared the task performance using the X2, rather than
G2, statistic in the chi-square test. The results are given in Table 7 for the complete
data set.13 The figures in brackets give the average number of generalized levels.
The X2 statistic is performing at least as well as G2, and the results show that the
average level of generalization is slightly higher for G2 than X2. This suggests a possible
explanation for the results presented here and those in Dunning (1993): that the X2
statistic provides a less conservative test when counts in the contingency table are
low. (By a conservative test we mean one in which the null hypothesis is not easily
rejected.) A less conservative test is better suited to the pseudo-disambiguation task,
since it results in a lower level of generalization, on the whole, which is good for this
task. In contrast, the task that Dunning considers, the discovery of bigrams, is better
served by a more conservative test.
</bodyText>
<sectionHeader confidence="0.935343" genericHeader="conclusions">
8. Conclusion
</sectionHeader>
<bodyText confidence="0.999468235294118">
We have presented a class-based estimation method that incorporates a procedure for
finding a suitable level of generalization in WordNet. This method has been shown to
provide superior performance on a pseudo-disambiguation task, compared with two
alternative approaches. An analysis of the results has shown that the other approaches
appear to be overgeneralizing, at least for this task. One of the features of the gener-
alization procedure is the way that α, the level of significance in the chi-square test,
is treated as a parameter. This allows some control over the extent of generalization,
which can be tailored to particular tasks. We have also shown that the task perfor-
mance is at least as good when using the Pearson chi-square statistic as when using
the log-likelihood chi-square statistic.
There are a number of ways in which this work could be extended. One possibility
would be to use all the classes dominated by the hypernyms of a concept, rather than
just one, to estimate the probability of the concept. An estimate would be obtained for
each hypernym, and the estimates combined in a linear interpolation. An approach
similar to this is taken by Bikel (2000), in the context of statistical parsing.
There is still room for investigation of the hidden-data problem when data are used
that have not been sense disambiguated. In this article, a very simple approach is taken,
</bodyText>
<page confidence="0.8440615">
13 χ2 performed slightly better than G2 using the smaller data set also.
204
</page>
<note confidence="0.834425">
Clark and Weir Class-Based Probability Estimation
</note>
<bodyText confidence="0.999914866666667">
which is to split the count for a noun evenly among the noun’s senses. Abney and Light
(1999) have tried a more motivated approach, using the expectation maximization
algorithm, but with little success. The approach described in Clark and Weir (1999) is
shown in Clark (2001) to have some impact on the pseudo-disambiguation task, but
only with certain values of the α parameter, and ultimately does not improve on the
best performance.
Finally, an issue that has not been much addressed in the literature (except by
Li and Abe [1996]) is how the accuracy of class-based estimation techniques compare
when automatically acquired classes, as opposed to the manually created classes from
WordNet, are used. The pseudo-disambiguation task described here has also been used
to evaluate clustering algorithms (Pereira, Tishby, and Lee, 1993; Rooth et al., 1999),
but with different data, and so it is difficult to compare the results. A related issue
is how the structure of WordNet affects the accuracy of the probability estimates. We
have taken the structure of the hierarchy for granted, without any analysis, but it may
be that an alternative design could be more conducive to probability estimation.
</bodyText>
<sectionHeader confidence="0.9922" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999495882352941">
This article is an extended and updated
version of a paper that appeared in the
proceedings of NAACL 2001. The work on
which it is based was carried out while the
first author was a D.Phil. student at the
University of Sussex and was supported by
an EPSRC studentship. We would like to
thank Diana McCarthy for suggesting the
pseudo-disambiguation task and providing
the MDL software, John Carroll for
supplying the data, and Ted Briscoe, Geoff
Sampson, Gerald Gazdar, Bill Keller, Ted
Pedersen, and the anonymous reviewers for
their helpful comments. We would also like
to thank Ted Briscoe for presenting an
earlier version of this article on our behalf
at NAACL 2001.
</bodyText>
<sectionHeader confidence="0.98899" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999196147540984">
Abney, Steven P. and Marc Light. 1999.
Hiding a semantic hierarchy in a Markov
model. In Proceedings of the ACL Workshop
on Unsupervised Learning in Natural
Language Processing, University of
Maryland, College Park, pages 1–8.
Agirre, Eneko and David Martinez. 2001.
Learning class-to-class selectional
preferences. In Proceedings of the Fifth ACL
Workshop on Computational Language
Learning, Toulouse, France, pages 15–22.
Agresti, Alan. 1996. An Introduction to
Categorical Data Analysis. Wiley.
Bikel, Daniel M. 2000. A statistical model
for parsing and word-sense
disambiguation. In Proceedings of the Joint
SIGDAT Conference on Empirical Methods in
Natural Language Processing and Very Large
Corpora, pages 155–163, Hong Kong.
Briscoe, Ted and John Carroll. 1997.
Automatic extraction of subcategorization
from corpora. In Proceedings of the Fifth
ACL Conference on Applied Natural Language
Processing, pages 356–363, Washington,
DC.
Church, Kenneth W. and Patrick Hanks.
1990. Word association norms, mutual
information, and lexicography.
Computational Linguistics, 16(1):22–29.
Ciaramita, Massimiliano and Mark Johnson.
2000. Explaining away ambiguity:
Learning verb selectional preference with
Bayesian networks. In Proceedings of the
18th International Conference on
Computational Linguistics, pages 187–193,
Saarbrucken, Germany.
Clark, Stephen. 2001. Class-Based Statistical
Models for Lexical Knowledge Acquisition.
Ph.D. dissertation, University of Sussex.
Clark, Stephen and David Weir. 1999. An
iterative approach to estimating
frequencies over a semantic hierarchy. In
Proceedings of the Joint SIGDAT Conference
on Empirical Methods in Natural Language
Processing and Very Large Corpora, pages
258–265, University of Maryland, College
Park.
Clark, Stephen and David Weir. 2000. A
class-based probabilistic approach to
structural disambiguation. In Proceedings
of the 18th International Conference on
Computational Linguistics, pages 194–200,
Saarbrucken, Germany.
Clark, Stephen and David Weir. 2001.
Class-based probability estimation using a
semantic hierarchy. In Proceedings of the
Second Meeting of the North American
Chapter of the Association for Computational
Linguistics, pages 95–102, Pittsburgh.
Cressie, Noel A. C. and Timothy R. C. Read.
1984. Multinomial goodness of fit tests.
</reference>
<page confidence="0.959113">
205
</page>
<note confidence="0.35568">
Computational Linguistics Volume 28, Number 2
</note>
<reference confidence="0.999304986666667">
Journal of the Royal Statistics Society Series B,
46:440–464.
Dunning, Ted. 1993. Accurate methods for
the statistics of surprise and coincidence.
Computational Linguistics, 19(1):61–74.
Fellbaum, Christiane, editor. 1998. WordNet:
An Electronic Lexical Database. MIT Press.
Li, Hang and Naoki Abe. 1996. Clustering
words with the MDL principle. In
Proceedings of the 16th International
Conference on Computational Linguistics,
pages 4–9, Copenhagen, Denmark.
Li, Hang and Naoki Abe. 1998. Generalizing
case frames using a thesaurus and the
MDL principle. Computational Linguistics,
24(2):217–244.
McCarthy, Diana. 1997. Word sense
disambiguation for acquisition of
selectional preferences. In Proceedings of
the ACL/EACL Workshop on Automatic
Information Extraction and Building of Lexical
Semantic Resources for NLP Applications,
pages 52–61, Madrid.
McCarthy, Diana. 2000. Using semantic
preferences to identify verbal
participation in role switching. In
Proceedings of the First Conference of the
North American Chapter of the Association for
Computational Linguistics, pages 256–263,
Seattle.
Miller, George A. 1998. Nouns in WordNet.
In Christiane Fellbaum, editor, WordNet:
An Electronic Lexical Database. MIT Press,
pages 23–46.
Pedersen, Ted. 1996. Fishing for exactness.
In Proceedings of the South-Central SAS Users
Group Conference, Austin, pages 188–200.
Pedersen, Ted. 2001. A decision tree of
bigrams is an accurate predictor of word
sense. In Proceedings of the Second Meeting
of the North American Chapter of the
Association for Computational Linguistics,
pages 79–86, Pittsburgh.
Pereira, Fernando, Naftali Tishby, and
Lillian Lee. 1993. Distributional clustering
of English words. In Proceedings of the 31st
Annual Meeting of the Association for
Computational Linguistics, pages 183–190,
Columbus, OH.
Resnik, Philip. 1993. Selection and
Information: A Class-Based Approach to
Lexical Relationships. Ph.D. dissertation,
University of Pennsylvania.
Resnik, Philip. 1998. WordNet and
class-based probabilities. In Christiane
Fellbaum, editor, WordNet: An Electronic
Lexical Database. MIT Press, pages 239–263.
Ribas, Francesc. 1995. On learning more
appropriate selectional restrictions. In
Proceedings of the Seventh Conference of the
European Chapter of the Association for
Computational Linguistics, pages 112–118,
Dublin.
Rooth, Mats, Stefan Riezler, Detlef Prescher,
Glenn Carroll, and Franz Beil. 1999.
Inducing a semantically annotated lexicon
via EM-based clustering. In Proceedings of
the 37th Annual Meeting of the Association for
Computational Linguistics, pages 104–111,
University of Maryland, College Park.
Wagner, Andreas. 2000. Enriching a lexical
semantic net with selectional preferences
by means of statistical corpus analysis. In
Proceedings of the ECAI-2000 Workshop on
Ontology Learning, Berlin, pages 37–42.
</reference>
<page confidence="0.998882">
206
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.848713">
<title confidence="0.978914">Class-Based Probability Estimation Using a Semantic Hierarchy</title>
<author confidence="0.969751">David</author>
<affiliation confidence="0.976397">University of Edinburgh University of Sussex</affiliation>
<abstract confidence="0.993750615384615">This article concerns the estimation of a particular kind of probability, namely, the probability of a noun sense appearing as a particular argument of a predicate. In order to overcome the accompanying sparse-data problem, the proposal here is to define the probabilities in terms of senses from a semantic hierarchy and exploit the fact that the senses can be grouped into classes consisting of semantically similar senses. There is a particular focus on the problem of how to determine a suitable class for a given sense, or, alternatively, how to determine a suitable level of generalization in the hierarchy. A procedure is developed that uses a chi-square test to determine a suitable level of generalization. In order to test the performance of the estimation method, a pseudo-disambiguation task is used, together with two alternative estimation methods. Each method uses a different generalization procedure; the first alternative uses the minimum description length principle, and the second uses Resnik’s measure of selectional preference. In addition, the performance of our method is investigated using both the standard Pearson chisquare statistic and the log-likelihood chi-square statistic.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven P Abney</author>
<author>Marc Light</author>
</authors>
<title>Hiding a semantic hierarchy in a Markov model.</title>
<date>1999</date>
<booktitle>In Proceedings of the ACL Workshop on Unsupervised Learning in Natural Language Processing,</booktitle>
<pages>1--8</pages>
<institution>University of Maryland, College Park,</institution>
<contexts>
<context position="17356" citStr="Abney and Light (1999)" startWordPosition="2963" endWordPosition="2966"> distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.) To do this, the probabilities p(run |ci,subj) are compared using a chi-square test, where the ci are the children of (canine). In this case, the null hypothesis of the test is that the probabilities p(run |ci,subj) are the same f</context>
<context position="54354" citStr="Abney and Light (1999)" startWordPosition="9166" endWordPosition="9169">the probability of the concept. An estimate would be obtained for each hypernym, and the estimates combined in a linear interpolation. An approach similar to this is taken by Bikel (2000), in the context of statistical parsing. There is still room for investigation of the hidden-data problem when data are used that have not been sense disambiguated. In this article, a very simple approach is taken, 13 χ2 performed slightly better than G2 using the smaller data set also. 204 Clark and Weir Class-Based Probability Estimation which is to split the count for a noun evenly among the noun’s senses. Abney and Light (1999) have tried a more motivated approach, using the expectation maximization algorithm, but with little success. The approach described in Clark and Weir (1999) is shown in Clark (2001) to have some impact on the pseudo-disambiguation task, but only with certain values of the α parameter, and ultimately does not improve on the best performance. Finally, an issue that has not been much addressed in the literature (except by Li and Abe [1996]) is how the accuracy of class-based estimation techniques compare when automatically acquired classes, as opposed to the manually created classes from WordNet</context>
</contexts>
<marker>Abney, Light, 1999</marker>
<rawString>Abney, Steven P. and Marc Light. 1999. Hiding a semantic hierarchy in a Markov model. In Proceedings of the ACL Workshop on Unsupervised Learning in Natural Language Processing, University of Maryland, College Park, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>David Martinez</author>
</authors>
<title>Learning class-to-class selectional preferences.</title>
<date>2001</date>
<booktitle>In Proceedings of the Fifth ACL Workshop on Computational Language Learning,</booktitle>
<pages>15--22</pages>
<location>Toulouse, France,</location>
<contexts>
<context position="10454" citStr="Agirre and Martinez (2001)" startWordPosition="1711" endWordPosition="1714">t c, can be used to estimate p(c |v, r). (Recall that c&apos; denotes the set of concepts dominated by c&apos;, including c&apos; itself.) One possible approach would be simply to substitute c&apos; for the individual concept c. This is a poor solution, however, since p(c&apos; |v, r) is the conditional probability that 2 Angled brackets are used to denote concepts in the hierarchy. 3 The term predicate is used loosely here, in that the predicate does not have to be a semantic object but can simply be a word form. 4 A recent paper that extends the acquisition of selectional preferences to sense-sense relationships is Agirre and Martinez (2001). 189 Computational Linguistics Volume 28, Number 2 some noun denoting a concept in c&apos; appears in position r of verb v. For example, p((animal) |run,subj) is the probability that some noun denoting a kind of animal appears in the subject position of the verb run. Probabilities of sets of concepts are obtained by summing over the concepts in the set: �p(c&apos; |v, r) = p(c&apos;&apos; |v, r) (1) c/IEcI This means that p((animal) |run,subj) is likely to be much greater than p((dog) | run,subj) and thus is not a good approximation of p((dog) |run,subj). What can be done, though, is to condition on sets of conc</context>
</contexts>
<marker>Agirre, Martinez, 2001</marker>
<rawString>Agirre, Eneko and David Martinez. 2001. Learning class-to-class selectional preferences. In Proceedings of the Fifth ACL Workshop on Computational Language Learning, Toulouse, France, pages 15–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Agresti</author>
</authors>
<title>An Introduction to Categorical Data Analysis.</title>
<date>1996</date>
<publisher>Wiley.</publisher>
<contexts>
<context position="20148" citStr="Agresti 1996" startWordPosition="3437" endWordPosition="3438"> in brackets are the expected values if the null hypothesis is true. There is a choice of which statistic to use in conjunction with the chi-square test. The usual statistic encountered in textbooks is the Pearson chi-square statistic, denoted X2: �X2 = (oij − eij)2 (16) i,j eij where oij is the observed value for the cell in row i and column j, and eij is the corresponding expected value. An alternative statistic is the log-likelihood chi-square statistic, denoted G2:8 �G2 = 2 oij i,j oij loge (17) eij The two statistics have similar values when the counts in the contingency table are large (Agresti 1996). The statistics behave differently, however, when the table contains low counts, and, since corpus data are likely to lead to some low counts, the question of which statistic to use is an important one. Dunning (1993) argues for the use of G2 rather than X2, based on an analysis of the sampling distributions of G2 and X2, and results obtained when using the statistics to acquire highly associated bigrams. We consider Dunning’s analysis at the end of this section, and the question of whether to use G2 or X2 will be discussed further there. For now, we continue with the discussion of how the ch</context>
<context position="24374" citStr="Agresti 1996" startWordPosition="4180" endWordPosition="4181">irement that expected values in the contingency table not be too small. (A rule of thumb often found in textbooks is that the expected values should be greater than five.) One response to this problem is to apply some kind of thresholding and either ignore counts below the threshold, or apply the test only to tables that do not contain low counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use some kind of thresholding when dealing with counts in the hierarchy (although not in the context of a chi-square test). Another approach would be to use Fisher’s exact test (Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of 194 Clark and Weir Class-Based Probability Estimation the counts they contain. The main problem with this test is that it is computationally expensive, especially for large contingency tables. What we have found in practice is that applying the chi-square test to tables dominated by low counts tends to produce an insignificant result, and the null hypothesis is not rejected. The consequences of this for the generalization procedure are that low-count tables tend to result in the procedure moving up to the next node in t</context>
</contexts>
<marker>Agresti, 1996</marker>
<rawString>Agresti, Alan. 1996. An Introduction to Categorical Data Analysis. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>A statistical model for parsing and word-sense disambiguation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>155--163</pages>
<location>Hong Kong.</location>
<contexts>
<context position="53919" citStr="Bikel (2000)" startWordPosition="9095" endWordPosition="9096">the extent of generalization, which can be tailored to particular tasks. We have also shown that the task performance is at least as good when using the Pearson chi-square statistic as when using the log-likelihood chi-square statistic. There are a number of ways in which this work could be extended. One possibility would be to use all the classes dominated by the hypernyms of a concept, rather than just one, to estimate the probability of the concept. An estimate would be obtained for each hypernym, and the estimates combined in a linear interpolation. An approach similar to this is taken by Bikel (2000), in the context of statistical parsing. There is still room for investigation of the hidden-data problem when data are used that have not been sense disambiguated. In this article, a very simple approach is taken, 13 χ2 performed slightly better than G2 using the smaller data set also. 204 Clark and Weir Class-Based Probability Estimation which is to split the count for a noun evenly among the noun’s senses. Abney and Light (1999) have tried a more motivated approach, using the expectation maximization algorithm, but with little success. The approach described in Clark and Weir (1999) is show</context>
</contexts>
<marker>Bikel, 2000</marker>
<rawString>Bikel, Daniel M. 2000. A statistical model for parsing and word-sense disambiguation. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 155–163, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Automatic extraction of subcategorization from corpora.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth ACL Conference on Applied Natural Language Processing,</booktitle>
<pages>356--363</pages>
<location>Washington, DC.</location>
<contexts>
<context position="16559" citStr="Briscoe and Carroll (1997)" startWordPosition="2824" endWordPosition="2827">p(c |r) = f(c,r) f(r) = � � (12) c�∈C f (c~, v~, r) v�∈V � c�∈C f (c~, v, r) ˆp(v |r) = f(v,r) f(r) = � � (13) c�∈C f (c~, v�,r) v�∈V c��∈c� f (c~~, v~, r) v�∈V where f (c, v, r) is the number of (n, v, r) triples in the data in which n is being used to denote c, and V is the set of verbs in the data. The problem is that the estimates are defined in terms of frequencies of senses, whereas the data are assumed to be in the form of (n, v, r) triples: a noun, verb, and argument position. All the data used in this work have been obtained from the British National Corpus (BNC), using the system of Briscoe and Carroll (1997), which consists of a shallow-parsing component that is able to identify verbal arguments. We take a simple approach to the problem of estimating the frequencies of senses, by distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000</context>
<context position="30717" citStr="Briscoe and Carroll (1997)" startWordPosition="5252" endWordPosition="5255">sks: If we already have lots of data regarding (sandwich), why generalize any higher? Thus the purpose of this section is not to show that the acquired levels are “correct,” but simply to show how the levels vary with α and the sample size. To show how the level of generalization varies with changes in α, top(c,v,obj) was determined for a number of hand-picked (c, v, obj) triples over a range of values for α. The triples were chosen to give a range of strongly and weakly selecting verbs and a range of verb frequencies. The data were again extracted from a subset of the BNC using the system of Briscoe and Carroll (1997), and the G2 statistic was used in the chi-square test. The results are shown in Table 3. The number of times the verb occurred with some object is also given in the table. The results suggest that the generalization level becomes more specific as α increases. This is to be expected, since, given a contingency table chosen at random, a higher value of α is more likely to lead to a significant result than a lower value of α. We also see that, for some cases, the value of α has little effect on the level. We would expect there to be less change in the level of generalization for strongly selecti</context>
</contexts>
<marker>Briscoe, Carroll, 1997</marker>
<rawString>Briscoe, Ted and John Carroll. 1997. Automatic extraction of subcategorization from corpora. In Proceedings of the Fifth ACL Conference on Applied Natural Language Processing, pages 356–363, Washington, DC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="14396" citStr="Church and Hanks 1990" startWordPosition="2436" endWordPosition="2439">andwich), obj). A feature of the proposed generalization procedure is that comparing probabilities of the form p(v |C, r), where C is a class, is closely related to comparing ratios of probabilities of the form p(C |v,r)/p(C |r) (for a given verb and argument position): p(v |C,r) = p(C |v,r) p(C |r) p(v |r) (10) Note that, for a given verb and argument position, p(v |r) is constant across classes. Equation (10) is of interest because the ratio p(C |v,r)/p(C |r) can be interpreted as a measure of association between the verb v and class C. This ratio is similar to pointwise mutual information (Church and Hanks 1990) and also forms part of Resnik’s association score, which will be introduced in Section 6. Thus the generalization procedure can be thought of as one that finds “homogeneous” areas of the hierarchy, that is, areas consisting of classes that are associated to a similar degree with the verb (Clark and Weir 1999). Finally, we note that the proposed estimation method does not guarantee that the estimates form a probability distribution over the concepts in the hierarchy, and so a normalization factor is required: psc(c |v, r) = ˆp(v |[c,v, r],r)ˆp(c|r) ˆp(v|r) (11) Ee∈Cˆp(v |[c�,v,r],r)ˆp(c�|r) ˆp</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Church, Kenneth W. and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimiliano Ciaramita</author>
<author>Mark Johnson</author>
</authors>
<title>Explaining away ambiguity: Learning verb selectional preference with Bayesian networks.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics,</booktitle>
<pages>187--193</pages>
<location>Saarbrucken, Germany.</location>
<contexts>
<context position="17390" citStr="Ciaramita and Johnson (2000)" startWordPosition="2968" endWordPosition="2971">each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.) To do this, the probabilities p(run |ci,subj) are compared using a chi-square test, where the ci are the children of (canine). In this case, the null hypothesis of the test is that the probabilities p(run |ci,subj) are the same for each child ci. By judging the s</context>
</contexts>
<marker>Ciaramita, Johnson, 2000</marker>
<rawString>Ciaramita, Massimiliano and Mark Johnson. 2000. Explaining away ambiguity: Learning verb selectional preference with Bayesian networks. In Proceedings of the 18th International Conference on Computational Linguistics, pages 187–193, Saarbrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
</authors>
<title>Class-Based Statistical Models for Lexical Knowledge Acquisition.</title>
<date>2001</date>
<institution>University of Sussex.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="54536" citStr="Clark (2001)" startWordPosition="9196" endWordPosition="9197">the context of statistical parsing. There is still room for investigation of the hidden-data problem when data are used that have not been sense disambiguated. In this article, a very simple approach is taken, 13 χ2 performed slightly better than G2 using the smaller data set also. 204 Clark and Weir Class-Based Probability Estimation which is to split the count for a noun evenly among the noun’s senses. Abney and Light (1999) have tried a more motivated approach, using the expectation maximization algorithm, but with little success. The approach described in Clark and Weir (1999) is shown in Clark (2001) to have some impact on the pseudo-disambiguation task, but only with certain values of the α parameter, and ultimately does not improve on the best performance. Finally, an issue that has not been much addressed in the literature (except by Li and Abe [1996]) is how the accuracy of class-based estimation techniques compare when automatically acquired classes, as opposed to the manually created classes from WordNet, are used. The pseudo-disambiguation task described here has also been used to evaluate clustering algorithms (Pereira, Tishby, and Lee, 1993; Rooth et al., 1999), but with differen</context>
</contexts>
<marker>Clark, 2001</marker>
<rawString>Clark, Stephen. 2001. Class-Based Statistical Models for Lexical Knowledge Acquisition. Ph.D. dissertation, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David Weir</author>
</authors>
<title>An iterative approach to estimating frequencies over a semantic hierarchy.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>258--265</pages>
<institution>University of Maryland, College Park.</institution>
<contexts>
<context position="14707" citStr="Clark and Weir 1999" startWordPosition="2489" endWordPosition="2492"> Note that, for a given verb and argument position, p(v |r) is constant across classes. Equation (10) is of interest because the ratio p(C |v,r)/p(C |r) can be interpreted as a measure of association between the verb v and class C. This ratio is similar to pointwise mutual information (Church and Hanks 1990) and also forms part of Resnik’s association score, which will be introduced in Section 6. Thus the generalization procedure can be thought of as one that finds “homogeneous” areas of the hierarchy, that is, areas consisting of classes that are associated to a similar degree with the verb (Clark and Weir 1999). Finally, we note that the proposed estimation method does not guarantee that the estimates form a probability distribution over the concepts in the hierarchy, and so a normalization factor is required: psc(c |v, r) = ˆp(v |[c,v, r],r)ˆp(c|r) ˆp(v|r) (11) Ee∈Cˆp(v |[c�,v,r],r)ˆp(c�|r) ˆp(v|r) We use psc to denote an estimate obtained using our method (since the technique finds sets of semantically similar senses, or “similarity classes”) and [c, v, r] to denote the class chosen for concept c in position r of verb v; pˆ denotes a relative frequency estimate, and C denotes the set of concepts i</context>
<context position="17308" citStr="Clark and Weir (1999)" startWordPosition="2955" endWordPosition="2958">lem of estimating the frequencies of senses, by distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.) To do this, the probabilities p(run |ci,subj) are compared using a chi-square test, where the ci are the children of (canine). In this case, the null hypothesis of the test is that </context>
<context position="54511" citStr="Clark and Weir (1999)" startWordPosition="9189" endWordPosition="9192">this is taken by Bikel (2000), in the context of statistical parsing. There is still room for investigation of the hidden-data problem when data are used that have not been sense disambiguated. In this article, a very simple approach is taken, 13 χ2 performed slightly better than G2 using the smaller data set also. 204 Clark and Weir Class-Based Probability Estimation which is to split the count for a noun evenly among the noun’s senses. Abney and Light (1999) have tried a more motivated approach, using the expectation maximization algorithm, but with little success. The approach described in Clark and Weir (1999) is shown in Clark (2001) to have some impact on the pseudo-disambiguation task, but only with certain values of the α parameter, and ultimately does not improve on the best performance. Finally, an issue that has not been much addressed in the literature (except by Li and Abe [1996]) is how the accuracy of class-based estimation techniques compare when automatically acquired classes, as opposed to the manually created classes from WordNet, are used. The pseudo-disambiguation task described here has also been used to evaluate clustering algorithms (Pereira, Tishby, and Lee, 1993; Rooth et al.,</context>
</contexts>
<marker>Clark, Weir, 1999</marker>
<rawString>Clark, Stephen and David Weir. 1999. An iterative approach to estimating frequencies over a semantic hierarchy. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 258–265, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David Weir</author>
</authors>
<title>A class-based probabilistic approach to structural disambiguation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics,</booktitle>
<pages>194--200</pages>
<location>Saarbrucken, Germany.</location>
<contexts>
<context position="2189" citStr="Clark and Weir 2000" startWordPosition="323" endWordPosition="326"> (NLP) tasks, such as structural disambiguation and statistical parsing, word sense disambiguation, anaphora resolution, and language modeling. To see how such knowledge can be used to resolve structural ambiguities, consider the following prepositional phrase attachment ambiguity: Example 1 Fred ate strawberries with a spoon. The ambiguity arises because the prepositional phrase with a spoon can attach to either strawberries or ate. The ambiguity can be resolved by noting that the correct sense of spoon is more likely to be an argument of “ate-with” than “strawberries-with” (Li and Abe 1998; Clark and Weir 2000). The problem with estimating a probability model defined over a large vocabulary of predicates and noun senses is that this involves a huge number of parameters, which results in a sparse-data problem. In order to reduce the number of parameters, we propose to define a probability model over senses in a semantic hierarchy and ∗ Division of Informatics, University of Edinburgh, 2 Buccleuch Place, Edinburgh, EH8 9LW, UK. E-mail: stephenc@cogsci.ed.ac.uk. † School of Cognitive and Computing Sciences, University of Sussex, Brighton, BN1 9QH, UK. E-mail: david.weir@cogs.susx.ac.uk. © 2002 Associat</context>
<context position="23107" citStr="Clark and Weir (2000)" startWordPosition="3959" endWordPosition="3962">cal value is 27.9 for eight degrees of freedom), the null hypothesis would still be rejected. For X2, the null hypothesis is rejected for α values greater than 0.005. This seems reasonable, since the probabilities associated with the children of (liquid) and the object position of drink would be expected to show a lot of variation across the children. A key question is how to select the appropriate value for α. One solution is to treat α as a parameter and set it empirically by taking a held-out test set and choosing the value of α that maximizes performance on the relevant task. For example, Clark and Weir (2000) describes a prepositional phrase attachment algorithm that employs probability estimates obtained using the WordNet method described here. To set the value of α, the performance of the algorithm on a development set could be compared across different values of α, and the value that leads to the best performance could be chosen. Note that this approach sets no constraints on the value of α: The value could be as high as 0.995 or as low as 0.0005, depending on the particular application. There may be cases in which the conditions for the appropriate application of a chisquare test are not met. </context>
<context position="45737" citStr="Clark and Weir (2000)" startWordPosition="7683" endWordPosition="7686">Given the set of (v, n, v&apos;) triples, the task is to decide whether (v, n) or (v&apos;, n) is the correct pair.11 We acknowledge that the task is somewhat artificial, but pseudo-disambiguation tasks of this kind are becoming popular in statistical NLP because of the ease with which training and test data can be created. We also feel that the pseudo-disambiguation task is useful for evaluating the different estimation methods, since it directly addresses the question of how likely a particular predicate is to take a given noun as an argument. An evaluation using a PP attachment task was attempted in Clark and Weir (2000), but the evaluation was limited by the relatively small size of the Penn Treebank. 11 We note that this procedure does not guarantee that the correct pair is more likely than the incorrect pair, because of noise in the data from the parser and also because a highly plausible incorrect pair could be generated by chance. 201 Computational Linguistics Volume 28, Number 2 Table 5 Results for the pseudo-disambiguation task. Generalization technique Similarity class α = 0.0005 α = 0.05 α = 0.3 α = 0.75 α = 0.995 Low class MDL Assoc % correct av.gen. sd.gen. 73.8 3.3 2.0 73.4 2.8 1.9 73.0 2.4 1.8 73</context>
</contexts>
<marker>Clark, Weir, 2000</marker>
<rawString>Clark, Stephen and David Weir. 2000. A class-based probabilistic approach to structural disambiguation. In Proceedings of the 18th International Conference on Computational Linguistics, pages 194–200, Saarbrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David Weir</author>
</authors>
<title>Class-based probability estimation using a semantic hierarchy.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>95--102</pages>
<location>Pittsburgh.</location>
<contexts>
<context position="51018" citStr="Clark and Weir (2001)" startWordPosition="8609" endWordPosition="8612"> this new data set, as before, but this time only verbs that occurred between 100 and 1,000 times were considered. The results using these test and training data are given in Table 6. These results show a variation in performance across values for α, with an optimal performance when α is around 0.75. (Of course, in practice, the value for α would need to be optimized on a held-out set.) But even with this variation, similarity class is still outperforming MDL and Assoc across the whole range of α values. Note that the 12 The results given for similarity class are different from those given in Clark and Weir (2001) because the probability estimates used in Clark and Weir (2001) were not normalized. 203 Computational Linguistics Volume 28, Number 2 Table 7 Disambiguation results for G2 and X2. α value % correct (G2) % correct (X2) 0.0005 73.8 (3.3) 74.1 (3.0) 0.05 73.4 (2.8) 73.8 (2.5) 0.3 73.0 (2.4) 74.1 (2.2) 0.75 73.9 (1.9) 74.3 (1.8) 0.995 73.8 (1.2) 73.3 (1.2) α values corresponding to the lowest scores lead to a significant amount of generalization, which provides additional evidence that MDL and Assoc are overgeneralizing for this task. The low-class method scores highly for this data set also, bu</context>
</contexts>
<marker>Clark, Weir, 2001</marker>
<rawString>Clark, Stephen and David Weir. 2001. Class-based probability estimation using a semantic hierarchy. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics, pages 95–102, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noel A C Cressie</author>
<author>Timothy R C Read</author>
</authors>
<title>Multinomial goodness of fit tests.</title>
<date>1984</date>
<journal>Journal of the Royal Statistics Society Series B,</journal>
<pages>46--440</pages>
<contexts>
<context position="25809" citStr="Cressie and Read (1984)" startWordPosition="4416" endWordPosition="4419">ssue to consider is which chi-square statistic to use. Dunning (1993) argues for the use of G2 rather than X2, based on the claim that the sampling distribution of G2 approaches the true chi-square distribution quicker than the sampling distribution of X2. However, Agresti (1996, page 34) makes the opposite claim: “The sampling distributions of X2 and G2 get closer to chi-squared as the sample size n increases.... The convergence is quicker for X2 than G2.” In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic. Finally, the results of the pseudo-disambiguation experiments presented in Section 7 are at least as good, if not better, when using X2 rather than G2, and so we conclude that the question of which statistic to use should be answered on a per application basis. 5. The Generalization Procedure The procedure for finding a suitable class, c&apos;, to generalize concept c in position r of verb v works as follows. (We refer to c&apos; as the “similarity class” of c with respect to v and r and</context>
</contexts>
<marker>Cressie, Read, 1984</marker>
<rawString>Cressie, Noel A. C. and Timothy R. C. Read. 1984. Multinomial goodness of fit tests. Journal of the Royal Statistics Society Series B, 46:440–464.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="20366" citStr="Dunning (1993)" startWordPosition="3473" endWordPosition="3474">-square statistic, denoted X2: �X2 = (oij − eij)2 (16) i,j eij where oij is the observed value for the cell in row i and column j, and eij is the corresponding expected value. An alternative statistic is the log-likelihood chi-square statistic, denoted G2:8 �G2 = 2 oij i,j oij loge (17) eij The two statistics have similar values when the counts in the contingency table are large (Agresti 1996). The statistics behave differently, however, when the table contains low counts, and, since corpus data are likely to lead to some low counts, the question of which statistic to use is an important one. Dunning (1993) argues for the use of G2 rather than X2, based on an analysis of the sampling distributions of G2 and X2, and results obtained when using the statistics to acquire highly associated bigrams. We consider Dunning’s analysis at the end of this section, and the question of whether to use G2 or X2 will be discussed further there. For now, we continue with the discussion of how the chi-square test is used in the generalization procedure. For Table 1, the value of G2 is 3.8, and the value of X2 is 2.5. Assuming a level of significance of α = 0.05, the critical value is 12.6 (for six degrees of freed</context>
<context position="25255" citStr="Dunning (1993)" startWordPosition="4327" endWordPosition="4328"> What we have found in practice is that applying the chi-square test to tables dominated by low counts tends to produce an insignificant result, and the null hypothesis is not rejected. The consequences of this for the generalization procedure are that low-count tables tend to result in the procedure moving up to the next node in the hierarchy. But given that the purpose of the generalization is to overcome the sparsedata problem, moving up a node is desirable, and therefore we do not modify the test for tables with low counts. The final issue to consider is which chi-square statistic to use. Dunning (1993) argues for the use of G2 rather than X2, based on the claim that the sampling distribution of G2 approaches the true chi-square distribution quicker than the sampling distribution of X2. However, Agresti (1996, page 34) makes the opposite claim: “The sampling distributions of X2 and G2 get closer to chi-squared as the sample size n increases.... The convergence is quicker for X2 than G2.” In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where th</context>
<context position="52239" citStr="Dunning (1993)" startWordPosition="8818" endWordPosition="8819"> that the task is one that apparently favors a low level of generalization, the high score is not too surprising. As a final experiment, we compared the task performance using the X2, rather than G2, statistic in the chi-square test. The results are given in Table 7 for the complete data set.13 The figures in brackets give the average number of generalized levels. The X2 statistic is performing at least as well as G2, and the results show that the average level of generalization is slightly higher for G2 than X2. This suggests a possible explanation for the results presented here and those in Dunning (1993): that the X2 statistic provides a less conservative test when counts in the contingency table are low. (By a conservative test we mean one in which the null hypothesis is not easily rejected.) A less conservative test is better suited to the pseudo-disambiguation task, since it results in a lower level of generalization, on the whole, which is good for this task. In contrast, the task that Dunning considers, the discovery of bigrams, is better served by a more conservative test. 8. Conclusion We have presented a class-based estimation method that incorporates a procedure for finding a suitabl</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, Ted. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Fellbaum, Christiane, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="40830" citStr="[1998]" startWordPosition="6867" endWordPosition="6867">ense ambiguity using the method described in Section 3, by dividing the count for a noun equally among the concepts whose synsets contain the noun. Also, since WordNet is a DAG, Li and Abe turn WordNet into a tree by copying each subgraph with multiple parents. And so that each noun in the data appears (in a synset) at a leaf node, Li and Abe remove those parts of the hierarchy dominated by a noun in the data (but only for that instance of WordNet corresponding to the relevant verb). An example cut showing part of the WordNet hierarchy is shown in Figure 3 (based on an example from Li and Abe [1998]; the dashed lines indicate parts of the hierarchy that are not shown in the diagram). This is a possible cut for the object position of the verb eat, and the cut consists of the following classes: (life form), (solid), (fluid), (food), (artifact), (space), (time), (set). (The particular choice of classes for the cut in this example is not too important; the example is designed to show how probabilities of senses are estimated from class probabilities.) Since the class in the cut containing (pizza) is (food), the probability p((pizza) |eat,obj) would be estimated as p((food) |eat, obj)/|(food)</context>
</contexts>
<marker>1998</marker>
<rawString>Fellbaum, Christiane, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Clustering words with the MDL principle.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics,</booktitle>
<pages>4--9</pages>
<location>Copenhagen, Denmark.</location>
<marker>Li, Abe, 1996</marker>
<rawString>Li, Hang and Naoki Abe. 1996. Clustering words with the MDL principle. In Proceedings of the 16th International Conference on Computational Linguistics, pages 4–9, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Generalizing case frames using a thesaurus and the MDL principle.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="2167" citStr="Li and Abe 1998" startWordPosition="319" endWordPosition="322">nguage processing (NLP) tasks, such as structural disambiguation and statistical parsing, word sense disambiguation, anaphora resolution, and language modeling. To see how such knowledge can be used to resolve structural ambiguities, consider the following prepositional phrase attachment ambiguity: Example 1 Fred ate strawberries with a spoon. The ambiguity arises because the prepositional phrase with a spoon can attach to either strawberries or ate. The ambiguity can be resolved by noting that the correct sense of spoon is more likely to be an argument of “ate-with” than “strawberries-with” (Li and Abe 1998; Clark and Weir 2000). The problem with estimating a probability model defined over a large vocabulary of predicates and noun senses is that this involves a huge number of parameters, which results in a sparse-data problem. In order to reduce the number of parameters, we propose to define a probability model over senses in a semantic hierarchy and ∗ Division of Informatics, University of Edinburgh, 2 Buccleuch Place, Edinburgh, EH8 9LW, UK. E-mail: stephenc@cogsci.ed.ac.uk. † School of Cognitive and Computing Sciences, University of Sussex, Brighton, BN1 9QH, UK. E-mail: david.weir@cogs.susx.</context>
<context position="4126" citStr="Li and Abe 1998" startWordPosition="634" endWordPosition="637">ass be used to estimate the probability of the sense? And second, given a particular noun sense, how can a suitable class be determined? This article offers novel solutions to both problems, and there is a particular focus on the second question, which can be thought of as how to find a suitable level of generalization in the hierarchy.1 The semantic hierarchy used here is the noun hierarchy of WordNet (Fellbaum 1998), version 1.6. Previous work has considered how to estimate probabilities using classes from WordNet in the context of acquiring selectional preferences (Resnik 1998; Ribas 1995; Li and Abe 1998; McCarthy 2000), and this previous work has also addressed the question of how to determine a suitable level of generalization in the hierarchy. Li and Abe use the minimum description length principle to obtain a level of generalization, and Resnik uses a simple technique based on a statistical measure of selectional preference. (The work by Ribas builds on that by Resnik, and the work by McCarthy builds on that by Li and Abe.) We compare our estimation method with those of Resnik and Li and Abe, using a pseudo-disambiguation task. Our method outperforms these alternatives on the pseudo-disam</context>
<context position="15506" citStr="Li and Abe (1998)" startWordPosition="2619" endWordPosition="2622">n factor is required: psc(c |v, r) = ˆp(v |[c,v, r],r)ˆp(c|r) ˆp(v|r) (11) Ee∈Cˆp(v |[c�,v,r],r)ˆp(c�|r) ˆp(v|r) We use psc to denote an estimate obtained using our method (since the technique finds sets of semantically similar senses, or “similarity classes”) and [c, v, r] to denote the class chosen for concept c in position r of verb v; pˆ denotes a relative frequency estimate, and C denotes the set of concepts in the hierarchy. Before providing the details of the generalization procedure, we give the relativefrequency estimates of the relevant probabilities and deal with the problem of am6 Li and Abe (1998) also develop a theoretical framework that applies only to a tree and turn WordNet into a tree by copying each subgraph with multiple parents. One way to extend the experiments in Section 7 would be to investigate whether this transformation has an impact on the results of those experiments. 191 Computational Linguistics Volume 28, Number 2 biguous data. The relative-frequency estimates are as follows: � v�∈V f (c, v~, r) ˆp(c |r) = f(c,r) f(r) = � � (12) c�∈C f (c~, v~, r) v�∈V � c�∈C f (c~, v, r) ˆp(v |r) = f(v,r) f(r) = � � (13) c�∈C f (c~, v�,r) v�∈V c��∈c� f (c~~, v~, r) v�∈V where f (c, </context>
<context position="17125" citStr="Li and Abe (1998)" startWordPosition="2930" endWordPosition="2933">NC), using the system of Briscoe and Carroll (1997), which consists of a shallow-parsing component that is able to identify verbal arguments. We take a simple approach to the problem of estimating the frequencies of senses, by distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.</context>
<context position="24143" citStr="Li and Abe (1998)" startWordPosition="4140" endWordPosition="4143">h as 0.995 or as low as 0.0005, depending on the particular application. There may be cases in which the conditions for the appropriate application of a chisquare test are not met. One condition that is likely to be violated is the requirement that expected values in the contingency table not be too small. (A rule of thumb often found in textbooks is that the expected values should be greater than five.) One response to this problem is to apply some kind of thresholding and either ignore counts below the threshold, or apply the test only to tables that do not contain low counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use some kind of thresholding when dealing with counts in the hierarchy (although not in the context of a chi-square test). Another approach would be to use Fisher’s exact test (Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of 194 Clark and Weir Class-Based Probability Estimation the counts they contain. The main problem with this test is that it is computationally expensive, especially for large contingency tables. What we have found in practice is that applying the chi-square test to tables dominated by low counts</context>
<context position="29304" citStr="Li and Abe 1998" startWordPosition="5015" endWordPosition="5018">min +— G2 parentmin +— parent end if chi-square test for parentmin is significant then sig result +— true else move up to next node: top +— parentmin end return top Figure 1 An algorithm for determining top(c, v, r). Figure 2 An example generalization: Determining top((soup), stir, obj). artifact ground food fluid poison G2: 29.9, crit val: 58.1 substance entity object G2: 141.1, crit val: 37.7 nourishment fare beverage dish meal course G2: 5.5, crit val: 16.9 G2: 5.4, crit val: 16.9 lasagne haggis G2: 14.5, critical value: 55.8 soup 196 Clark and Weir Class-Based Probability Estimation 1997; Li and Abe 1998; Wagner 2000), the level of generalization is often determined for a small number of hand-picked verbs and the result compared with the researcher’s intuition about the most appropriate level for representing a selectional preference. According to this approach, if (sandwich) were chosen to represent (hotdog) in the object position of eat, this might be considered an undergeneralization, since (food) might be considered more appropriate. For this work we argue that such an evaluation is not appropriate; since the purpose of this work is probability estimation, the most appropriate level is th</context>
<context position="36038" citStr="Li and Abe (1998)" startWordPosition="6045" endWordPosition="6048">ghtmare)(DREAMING)(imagination) ... (psychological feature) Note: The selected level is shown in upper case. Table 4 Extent of generalization for different values of α and sample sizes. α 100% 50% 10% 1% 0.0005 3.3 3.9 5.0 5.6 0.05 2.8 3.5 4.6 5.6 0.5 2.1 2.9 4.1 5.4 0.995 1.2 1.5 2.6 3.9 size. Again, this is to be expected, since any difference in probability estimates is less likely to be significant for tables with low counts. 6. Alternative Class-Based Estimation Methods The approaches used for comparison are that of Resnik (1993, 1998), subsequently developed by Ribas (1995), and that of Li and Abe (1998), which has been adopted by McCarthy (2000). These have been chosen because they directly address the question of how to find a suitable level of generalization in WordNet. 198 Clark and Weir Class-Based Probability Estimation The first alternative uses the “association score,” which is a measure of how well a set of concepts, C, satisfies the selectional preferences of a verb, v, for an argument position, r:9 p(C |v,r) A(C,v,r) = p(C |v,r) log2 (18) p(C |r) An estimate of the association score, ˆA(C, v, r), can be obtained using relative frequency estimates of the probabilities. The key quest</context>
<context position="43789" citStr="Li and Abe (1998)" startWordPosition="7342" endWordPosition="7345">for Li and Abe’s application of MDL. This did create a problem with overgeneralization: Many of the cuts returned by MDL were overgeneralizing at the (entity) node. The reason is that (person), which is close to (entity) and dominated by (entity), has two parents: (life form) and (causal agent). This DAG-like property was responsible for the overgeneralization, and so we removed the link between (person) and (causal agent). This appeared to solve the problem, and the results presented later for the average degree of generalization do not show an overgeneralization compared with those given in Li and Abe (1998). 7. Pseudo-Disambiguation Experiments The task we used to compare the class-based estimation techniques is a decision task previously used by Pereira, Tishby, and Lee (1993) and Rooth et al. (1999). The task is to decide which of two verbs, v and v&apos;, is more likely to take a given noun, n, as an object. The test and training data were obtained as follows. A number of verb–direct object pairs were extracted from a subset of the BNC, using the system of Briscoe and Carroll. All those pairs containing a noun not in WordNet were removed, and each verb and argument was lemmatized. This resulted in</context>
</contexts>
<marker>Li, Abe, 1998</marker>
<rawString>Li, Hang and Naoki Abe. 1998. Generalizing case frames using a thesaurus and the MDL principle. Computational Linguistics, 24(2):217–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Word sense disambiguation for acquisition of selectional preferences.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL/EACL Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications,</booktitle>
<pages>52--61</pages>
<location>Madrid.</location>
<contexts>
<context position="5250" citStr="McCarthy 1997" startWordPosition="816" endWordPosition="817">pseudo-disambiguation task. Our method outperforms these alternatives on the pseudo-disambiguation task, and an analysis of the results shows that the generalization methods of Resnik and Li and Abe appear to be overgeneralizing, at least for this task. Note that the problem being addressed here is the engineering problem of estimating predicate argument probabilities, with the aim of producing estimates that will be useful for NLP applications. In particular, we are not addressing the problem of acquiring selectional restrictions in the way this is usually construed (Resnik 1993; Ribas 1995; McCarthy 1997; Li and Abe 1998; Wagner 2000). The purpose of using a semantic hierarchy for generalization is to overcome the sparse data problem, rather than find a level of abstraction that best represents the selectional restrictions of some predicate. This point is considered further in Section 5. The next section describes the noun hierarchy from WordNet and gives a more precise description of the probabilities to be estimated. Section 3 shows how a class from WordNet can be used to estimate the probability of a noun sense. Section 4 shows how a chi-square test is used as part of the generalization pr</context>
</contexts>
<marker>McCarthy, 1997</marker>
<rawString>McCarthy, Diana. 1997. Word sense disambiguation for acquisition of selectional preferences. In Proceedings of the ACL/EACL Workshop on Automatic Information Extraction and Building of Lexical Semantic Resources for NLP Applications, pages 52–61, Madrid.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Using semantic preferences to identify verbal participation in role switching.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>256--263</pages>
<location>Seattle.</location>
<contexts>
<context position="4142" citStr="McCarthy 2000" startWordPosition="638" endWordPosition="639">timate the probability of the sense? And second, given a particular noun sense, how can a suitable class be determined? This article offers novel solutions to both problems, and there is a particular focus on the second question, which can be thought of as how to find a suitable level of generalization in the hierarchy.1 The semantic hierarchy used here is the noun hierarchy of WordNet (Fellbaum 1998), version 1.6. Previous work has considered how to estimate probabilities using classes from WordNet in the context of acquiring selectional preferences (Resnik 1998; Ribas 1995; Li and Abe 1998; McCarthy 2000), and this previous work has also addressed the question of how to determine a suitable level of generalization in the hierarchy. Li and Abe use the minimum description length principle to obtain a level of generalization, and Resnik uses a simple technique based on a statistical measure of selectional preference. (The work by Ribas builds on that by Resnik, and the work by McCarthy builds on that by Li and Abe.) We compare our estimation method with those of Resnik and Li and Abe, using a pseudo-disambiguation task. Our method outperforms these alternatives on the pseudo-disambiguation task, </context>
<context position="17160" citStr="McCarthy (2000)" startWordPosition="2937" endWordPosition="2938">Carroll (1997), which consists of a shallow-parsing component that is able to identify verbal arguments. We take a simple approach to the problem of estimating the frequencies of senses, by distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.) To do this, the probabilities p(r</context>
<context position="24160" citStr="McCarthy (2000)" startWordPosition="4144" endWordPosition="4145">w as 0.0005, depending on the particular application. There may be cases in which the conditions for the appropriate application of a chisquare test are not met. One condition that is likely to be violated is the requirement that expected values in the contingency table not be too small. (A rule of thumb often found in textbooks is that the expected values should be greater than five.) One response to this problem is to apply some kind of thresholding and either ignore counts below the threshold, or apply the test only to tables that do not contain low counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use some kind of thresholding when dealing with counts in the hierarchy (although not in the context of a chi-square test). Another approach would be to use Fisher’s exact test (Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of 194 Clark and Weir Class-Based Probability Estimation the counts they contain. The main problem with this test is that it is computationally expensive, especially for large contingency tables. What we have found in practice is that applying the chi-square test to tables dominated by low counts tends to produce</context>
<context position="36081" citStr="McCarthy (2000)" startWordPosition="6054" endWordPosition="6055">gical feature) Note: The selected level is shown in upper case. Table 4 Extent of generalization for different values of α and sample sizes. α 100% 50% 10% 1% 0.0005 3.3 3.9 5.0 5.6 0.05 2.8 3.5 4.6 5.6 0.5 2.1 2.9 4.1 5.4 0.995 1.2 1.5 2.6 3.9 size. Again, this is to be expected, since any difference in probability estimates is less likely to be significant for tables with low counts. 6. Alternative Class-Based Estimation Methods The approaches used for comparison are that of Resnik (1993, 1998), subsequently developed by Ribas (1995), and that of Li and Abe (1998), which has been adopted by McCarthy (2000). These have been chosen because they directly address the question of how to find a suitable level of generalization in WordNet. 198 Clark and Weir Class-Based Probability Estimation The first alternative uses the “association score,” which is a measure of how well a set of concepts, C, satisfies the selectional preferences of a verb, v, for an argument position, r:9 p(C |v,r) A(C,v,r) = p(C |v,r) log2 (18) p(C |r) An estimate of the association score, ˆA(C, v, r), can be obtained using relative frequency estimates of the probabilities. The key question is how to determine a suitable level of</context>
</contexts>
<marker>McCarthy, 2000</marker>
<rawString>McCarthy, Diana. 2000. Using semantic preferences to identify verbal participation in role switching. In Proceedings of the First Conference of the North American Chapter of the Association for Computational Linguistics, pages 256–263, Seattle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Nouns in WordNet.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database.</booktitle>
<pages>23--46</pages>
<publisher>MIT Press,</publisher>
<contexts>
<context position="6166" citStr="Miller (1998)" startWordPosition="959" endWordPosition="960">ion describes the noun hierarchy from WordNet and gives a more precise description of the probabilities to be estimated. Section 3 shows how a class from WordNet can be used to estimate the probability of a noun sense. Section 4 shows how a chi-square test is used as part of the generalization procedure, and Section 5 describes the generalization procedure. Section 6 describes the alternative class-based estimation methods used in the pseudo-disambiguation experiments, and Section 7 presents those experiments. 2. The Semantic Hierarchy The noun hierarchy of WordNet consists of senses, or what Miller (1998) calls lexicalized concepts, organized according to the “is-a-kind-of” relation. Note that we are using concept to refer to a lexicalized concept or sense and not to a set of senses; we use class to refer to a set of senses. There are around 66,000 different concepts in the noun hierarchy 1 A third element of the problem, namely, how to obtain arguments of predicates as training data, is not considered here. We assume the existence of such data, obtained from a treebank or shallow parser. 188 Clark and Weir Class-Based Probability Estimation of WordNet version 1.6. A concept in WordNet is repr</context>
</contexts>
<marker>Miller, 1998</marker>
<rawString>Miller, George A. 1998. Nouns in WordNet. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database. MIT Press, pages 23–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>Fishing for exactness.</title>
<date>1996</date>
<booktitle>In Proceedings of the South-Central SAS Users Group Conference,</booktitle>
<pages>188--200</pages>
<location>Austin,</location>
<contexts>
<context position="24390" citStr="Pedersen 1996" startWordPosition="4182" endWordPosition="4183">xpected values in the contingency table not be too small. (A rule of thumb often found in textbooks is that the expected values should be greater than five.) One response to this problem is to apply some kind of thresholding and either ignore counts below the threshold, or apply the test only to tables that do not contain low counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use some kind of thresholding when dealing with counts in the hierarchy (although not in the context of a chi-square test). Another approach would be to use Fisher’s exact test (Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of 194 Clark and Weir Class-Based Probability Estimation the counts they contain. The main problem with this test is that it is computationally expensive, especially for large contingency tables. What we have found in practice is that applying the chi-square test to tables dominated by low counts tends to produce an insignificant result, and the null hypothesis is not rejected. The consequences of this for the generalization procedure are that low-count tables tend to result in the procedure moving up to the next node in the hierarchy. Bu</context>
</contexts>
<marker>Pedersen, 1996</marker>
<rawString>Pedersen, Ted. 1996. Fishing for exactness. In Proceedings of the South-Central SAS Users Group Conference, Austin, pages 188–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>A decision tree of bigrams is an accurate predictor of word sense.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>79--86</pages>
<location>Pittsburgh.</location>
<contexts>
<context position="25676" citStr="Pedersen (2001)" startWordPosition="4397" endWordPosition="4398">edata problem, moving up a node is desirable, and therefore we do not modify the test for tables with low counts. The final issue to consider is which chi-square statistic to use. Dunning (1993) argues for the use of G2 rather than X2, based on the claim that the sampling distribution of G2 approaches the true chi-square distribution quicker than the sampling distribution of X2. However, Agresti (1996, page 34) makes the opposite claim: “The sampling distributions of X2 and G2 get closer to chi-squared as the sample size n increases.... The convergence is quicker for X2 than G2.” In addition, Pedersen (2001) questions whether one statistic should be preferred over the other for the bigram acquisition task and cites Cressie and Read (1984), who argue that there are some cases where the Pearson statistic is more reliable than the log-likelihood statistic. Finally, the results of the pseudo-disambiguation experiments presented in Section 7 are at least as good, if not better, when using X2 rather than G2, and so we conclude that the question of which statistic to use should be answered on a per application basis. 5. The Generalization Procedure The procedure for finding a suitable class, c&apos;, to gene</context>
</contexts>
<marker>Pedersen, 2001</marker>
<rawString>Pedersen, Ted. 2001. A decision tree of bigrams is an accurate predictor of word sense. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics, pages 79–86, Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="55096" citStr="Pereira, Tishby, and Lee, 1993" startWordPosition="9279" endWordPosition="9283">e approach described in Clark and Weir (1999) is shown in Clark (2001) to have some impact on the pseudo-disambiguation task, but only with certain values of the α parameter, and ultimately does not improve on the best performance. Finally, an issue that has not been much addressed in the literature (except by Li and Abe [1996]) is how the accuracy of class-based estimation techniques compare when automatically acquired classes, as opposed to the manually created classes from WordNet, are used. The pseudo-disambiguation task described here has also been used to evaluate clustering algorithms (Pereira, Tishby, and Lee, 1993; Rooth et al., 1999), but with different data, and so it is difficult to compare the results. A related issue is how the structure of WordNet affects the accuracy of the probability estimates. We have taken the structure of the hierarchy for granted, without any analysis, but it may be that an alternative design could be more conducive to probability estimation. Acknowledgments This article is an extended and updated version of a paper that appeared in the proceedings of NAACL 2001. The work on which it is based was carried out while the first author was a D.Phil. student at the University of</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Pereira, Fernando, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of English words. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, pages 183–190, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.</title>
<date>1993</date>
<institution>University of Pennsylvania.</institution>
<note>Ph.D. dissertation,</note>
<contexts>
<context position="5223" citStr="Resnik 1993" startWordPosition="812" endWordPosition="813"> and Li and Abe, using a pseudo-disambiguation task. Our method outperforms these alternatives on the pseudo-disambiguation task, and an analysis of the results shows that the generalization methods of Resnik and Li and Abe appear to be overgeneralizing, at least for this task. Note that the problem being addressed here is the engineering problem of estimating predicate argument probabilities, with the aim of producing estimates that will be useful for NLP applications. In particular, we are not addressing the problem of acquiring selectional restrictions in the way this is usually construed (Resnik 1993; Ribas 1995; McCarthy 1997; Li and Abe 1998; Wagner 2000). The purpose of using a semantic hierarchy for generalization is to overcome the sparse data problem, rather than find a level of abstraction that best represents the selectional restrictions of some predicate. This point is considered further in Section 5. The next section describes the noun hierarchy from WordNet and gives a more precise description of the probabilities to be estimated. Section 3 shows how a class from WordNet can be used to estimate the probability of a noun sense. Section 4 shows how a chi-square test is used as pa</context>
<context position="35960" citStr="Resnik (1993" startWordPosition="6034" endWordPosition="6035"> (nightmare)(DREAMING)(imagination) ... (psychological feature) 0.995 (nightmare)(DREAMING)(imagination) ... (psychological feature) Note: The selected level is shown in upper case. Table 4 Extent of generalization for different values of α and sample sizes. α 100% 50% 10% 1% 0.0005 3.3 3.9 5.0 5.6 0.05 2.8 3.5 4.6 5.6 0.5 2.1 2.9 4.1 5.4 0.995 1.2 1.5 2.6 3.9 size. Again, this is to be expected, since any difference in probability estimates is less likely to be significant for tables with low counts. 6. Alternative Class-Based Estimation Methods The approaches used for comparison are that of Resnik (1993, 1998), subsequently developed by Ribas (1995), and that of Li and Abe (1998), which has been adopted by McCarthy (2000). These have been chosen because they directly address the question of how to find a suitable level of generalization in WordNet. 198 Clark and Weir Class-Based Probability Estimation The first alternative uses the “association score,” which is a measure of how well a set of concepts, C, satisfies the selectional preferences of a verb, v, for an argument position, r:9 p(C |v,r) A(C,v,r) = p(C |v,r) log2 (18) p(C |r) An estimate of the association score, ˆA(C, v, r), can be o</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Resnik, Philip. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. Ph.D. dissertation, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>WordNet and class-based probabilities.</title>
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database.</booktitle>
<pages>239--263</pages>
<editor>In Christiane Fellbaum, editor,</editor>
<publisher>MIT Press,</publisher>
<contexts>
<context position="4097" citStr="Resnik 1998" startWordPosition="630" endWordPosition="631">en class, how can that class be used to estimate the probability of the sense? And second, given a particular noun sense, how can a suitable class be determined? This article offers novel solutions to both problems, and there is a particular focus on the second question, which can be thought of as how to find a suitable level of generalization in the hierarchy.1 The semantic hierarchy used here is the noun hierarchy of WordNet (Fellbaum 1998), version 1.6. Previous work has considered how to estimate probabilities using classes from WordNet in the context of acquiring selectional preferences (Resnik 1998; Ribas 1995; Li and Abe 1998; McCarthy 2000), and this previous work has also addressed the question of how to determine a suitable level of generalization in the hierarchy. Li and Abe use the minimum description length principle to obtain a level of generalization, and Resnik uses a simple technique based on a statistical measure of selectional preference. (The work by Ribas builds on that by Resnik, and the work by McCarthy builds on that by Li and Abe.) We compare our estimation method with those of Resnik and Li and Abe, using a pseudo-disambiguation task. Our method outperforms these alt</context>
<context position="17176" citStr="Resnik (1998)" startWordPosition="2939" endWordPosition="2940">ich consists of a shallow-parsing component that is able to identify verbal arguments. We take a simple approach to the problem of estimating the frequencies of senses, by distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.) To do this, the probabilities p(run |ci,subj) are</context>
</contexts>
<marker>Resnik, 1998</marker>
<rawString>Resnik, Philip. 1998. WordNet and class-based probabilities. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database. MIT Press, pages 239–263.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesc Ribas</author>
</authors>
<title>On learning more appropriate selectional restrictions.</title>
<date>1995</date>
<booktitle>In Proceedings of the Seventh Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>112--118</pages>
<location>Dublin.</location>
<contexts>
<context position="4109" citStr="Ribas 1995" startWordPosition="632" endWordPosition="633"> can that class be used to estimate the probability of the sense? And second, given a particular noun sense, how can a suitable class be determined? This article offers novel solutions to both problems, and there is a particular focus on the second question, which can be thought of as how to find a suitable level of generalization in the hierarchy.1 The semantic hierarchy used here is the noun hierarchy of WordNet (Fellbaum 1998), version 1.6. Previous work has considered how to estimate probabilities using classes from WordNet in the context of acquiring selectional preferences (Resnik 1998; Ribas 1995; Li and Abe 1998; McCarthy 2000), and this previous work has also addressed the question of how to determine a suitable level of generalization in the hierarchy. Li and Abe use the minimum description length principle to obtain a level of generalization, and Resnik uses a simple technique based on a statistical measure of selectional preference. (The work by Ribas builds on that by Resnik, and the work by McCarthy builds on that by Li and Abe.) We compare our estimation method with those of Resnik and Li and Abe, using a pseudo-disambiguation task. Our method outperforms these alternatives on</context>
<context position="17139" citStr="Ribas (1995)" startWordPosition="2934" endWordPosition="2935">em of Briscoe and Carroll (1997), which consists of a shallow-parsing component that is able to identify verbal arguments. We take a simple approach to the problem of estimating the frequencies of senses, by distributing the count for each noun in the data evenly among all senses of the noun: �c��∈c� f(c��,v,r) ˆp(v |c~, r) = f(c�,v,r) � f(c� ,r) = � (14) �fˆ (c, v, r) = n∈syn(c) (15) |cn(n)| f(n,v,r) where fˆ (c, v, r) is an estimate of the number of times that concept c appears in position r of verb v, and |cn(n) |is the cardinality of cn(n). This is the approach taken by Li and Abe (1998), Ribas (1995), and McCarthy (2000).7 Resnik (1998) explains how this apparently crude technique works surprisingly well. Alternative approaches are described in Clark and Weir (1999) (see also Clark [2001]), Abney and Light (1999), and Ciaramita and Johnson (2000). 4. Using a Chi-Square Test to Compare Probabilities In this section we show how to test whether p(v |c&apos;, r) changes significantly when considering a node higher in the hierarchy. Consider the problem of deciding whether p(run |(canine),subj) is a good approximation of p(run |(dog),subj). ((canine) is the parent of (dog) in WordNet.) To do this, </context>
<context position="24124" citStr="Ribas (1995)" startWordPosition="4138" endWordPosition="4139">ould be as high as 0.995 or as low as 0.0005, depending on the particular application. There may be cases in which the conditions for the appropriate application of a chisquare test are not met. One condition that is likely to be violated is the requirement that expected values in the contingency table not be too small. (A rule of thumb often found in textbooks is that the expected values should be greater than five.) One response to this problem is to apply some kind of thresholding and either ignore counts below the threshold, or apply the test only to tables that do not contain low counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use some kind of thresholding when dealing with counts in the hierarchy (although not in the context of a chi-square test). Another approach would be to use Fisher’s exact test (Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of 194 Clark and Weir Class-Based Probability Estimation the counts they contain. The main problem with this test is that it is computationally expensive, especially for large contingency tables. What we have found in practice is that applying the chi-square test to tables domi</context>
<context position="28377" citStr="Ribas 1995" startWordPosition="4858" endWordPosition="4859">he chi-square test results in a G2 value of 14.5, compared to a critical value of 55.8. Since G2 is less than the critical value, the procedure moves up to the next node. This process continues until a significant result is obtained, which first occurs at (substance) when comparing the children of (object). Thus (substance) is the chosen level of generalization. Now we show how the chosen level of generalization varies with α and how it varies with the size of the data set. A note of clarification is required before presenting the results. In related work on acquiring selectional preferences (Ribas 1995; McCarthy 195 Computational Linguistics Volume 28, Number 2 Algorithm top(c,v,r): top +— c sig result +— false comment parentmin gives lowest G2 value, G2min while not sig result &amp; top =� (root) do G2min +— 00 for all parents of top do calculate G2 for sets dominated by children of parent if G2 &lt; G2min then G2min +— G2 parentmin +— parent end if chi-square test for parentmin is significant then sig result +— true else move up to next node: top +— parentmin end return top Figure 1 An algorithm for determining top(c, v, r). Figure 2 An example generalization: Determining top((soup), stir, obj).</context>
<context position="36007" citStr="Ribas (1995)" startWordPosition="6040" endWordPosition="6041">logical feature) 0.995 (nightmare)(DREAMING)(imagination) ... (psychological feature) Note: The selected level is shown in upper case. Table 4 Extent of generalization for different values of α and sample sizes. α 100% 50% 10% 1% 0.0005 3.3 3.9 5.0 5.6 0.05 2.8 3.5 4.6 5.6 0.5 2.1 2.9 4.1 5.4 0.995 1.2 1.5 2.6 3.9 size. Again, this is to be expected, since any difference in probability estimates is less likely to be significant for tables with low counts. 6. Alternative Class-Based Estimation Methods The approaches used for comparison are that of Resnik (1993, 1998), subsequently developed by Ribas (1995), and that of Li and Abe (1998), which has been adopted by McCarthy (2000). These have been chosen because they directly address the question of how to find a suitable level of generalization in WordNet. 198 Clark and Weir Class-Based Probability Estimation The first alternative uses the “association score,” which is a measure of how well a set of concepts, C, satisfies the selectional preferences of a verb, v, for an argument position, r:9 p(C |v,r) A(C,v,r) = p(C |v,r) log2 (18) p(C |r) An estimate of the association score, ˆA(C, v, r), can be obtained using relative frequency estimates of t</context>
<context position="39638" citStr="Ribas (1995)" startWordPosition="6652" endWordPosition="6653"> the node dominates. The hierarchy is also assumed to be in the form of a tree. The class-based models consist of a partition of the set of nouns (leaf nodes) and a probability associated with each class in the partition. The probabilities are the conditional probabilities of each class, given the relevant verb and argument position. Li and Abe refer to such a partition as a “cut” and the cut together with the probabilities as a “tree cut model.” The probabilities of the classes in a cut, P, satisfy the following constraint: E p(C |v,r) = 1 (19) C∈Γ 9 The definition used here is that given by Ribas (1995). 10 For example, the hypernyms of the concept (Dallas) are as follows: (city), (municipality), (urban area), (geographical area), (region), (location), (object), (entity). 199 Computational Linguistics Volume 28, Number 2 &lt;root&gt; Figure 3 Possible cut returned by MDL. In order to determine the probability of a noun, the probability of a class is assumed to be distributed uniformly among the members of that class: 1 p(n |v, r) = |C |p(C |v, r) for all n E C (20) Since WordNet is a hierarchy with noun senses, rather than nouns, at the nodes, Li and Abe deal with the issue of word sense ambiguity</context>
</contexts>
<marker>Ribas, 1995</marker>
<rawString>Ribas, Francesc. 1995. On learning more appropriate selectional restrictions. In Proceedings of the Seventh Conference of the European Chapter of the Association for Computational Linguistics, pages 112–118, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
<author>Stefan Riezler</author>
<author>Detlef Prescher</author>
<author>Glenn Carroll</author>
<author>Franz Beil</author>
</authors>
<title>Inducing a semantically annotated lexicon via EM-based clustering.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<institution>University of Maryland, College Park.</institution>
<contexts>
<context position="43987" citStr="Rooth et al. (1999)" startWordPosition="7372" endWordPosition="7375">ich is close to (entity) and dominated by (entity), has two parents: (life form) and (causal agent). This DAG-like property was responsible for the overgeneralization, and so we removed the link between (person) and (causal agent). This appeared to solve the problem, and the results presented later for the average degree of generalization do not show an overgeneralization compared with those given in Li and Abe (1998). 7. Pseudo-Disambiguation Experiments The task we used to compare the class-based estimation techniques is a decision task previously used by Pereira, Tishby, and Lee (1993) and Rooth et al. (1999). The task is to decide which of two verbs, v and v&apos;, is more likely to take a given noun, n, as an object. The test and training data were obtained as follows. A number of verb–direct object pairs were extracted from a subset of the BNC, using the system of Briscoe and Carroll. All those pairs containing a noun not in WordNet were removed, and each verb and argument was lemmatized. This resulted in a data set of around 1.3 million (v, n) pairs. To form a test set, 3,000 of these pairs were randomly selected such that each selected pair contained a fairly frequent verb. (Following Pereira, Tis</context>
<context position="55117" citStr="Rooth et al., 1999" startWordPosition="9284" endWordPosition="9287">d Weir (1999) is shown in Clark (2001) to have some impact on the pseudo-disambiguation task, but only with certain values of the α parameter, and ultimately does not improve on the best performance. Finally, an issue that has not been much addressed in the literature (except by Li and Abe [1996]) is how the accuracy of class-based estimation techniques compare when automatically acquired classes, as opposed to the manually created classes from WordNet, are used. The pseudo-disambiguation task described here has also been used to evaluate clustering algorithms (Pereira, Tishby, and Lee, 1993; Rooth et al., 1999), but with different data, and so it is difficult to compare the results. A related issue is how the structure of WordNet affects the accuracy of the probability estimates. We have taken the structure of the hierarchy for granted, without any analysis, but it may be that an alternative design could be more conducive to probability estimation. Acknowledgments This article is an extended and updated version of a paper that appeared in the proceedings of NAACL 2001. The work on which it is based was carried out while the first author was a D.Phil. student at the University of Sussex and was suppo</context>
</contexts>
<marker>Rooth, Riezler, Prescher, Carroll, Beil, 1999</marker>
<rawString>Rooth, Mats, Stefan Riezler, Detlef Prescher, Glenn Carroll, and Franz Beil. 1999. Inducing a semantically annotated lexicon via EM-based clustering. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 104–111, University of Maryland, College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Wagner</author>
</authors>
<title>Enriching a lexical semantic net with selectional preferences by means of statistical corpus analysis.</title>
<date>2000</date>
<booktitle>In Proceedings of the ECAI-2000 Workshop on Ontology Learning,</booktitle>
<pages>37--42</pages>
<location>Berlin,</location>
<contexts>
<context position="5281" citStr="Wagner 2000" startWordPosition="822" endWordPosition="823">method outperforms these alternatives on the pseudo-disambiguation task, and an analysis of the results shows that the generalization methods of Resnik and Li and Abe appear to be overgeneralizing, at least for this task. Note that the problem being addressed here is the engineering problem of estimating predicate argument probabilities, with the aim of producing estimates that will be useful for NLP applications. In particular, we are not addressing the problem of acquiring selectional restrictions in the way this is usually construed (Resnik 1993; Ribas 1995; McCarthy 1997; Li and Abe 1998; Wagner 2000). The purpose of using a semantic hierarchy for generalization is to overcome the sparse data problem, rather than find a level of abstraction that best represents the selectional restrictions of some predicate. This point is considered further in Section 5. The next section describes the noun hierarchy from WordNet and gives a more precise description of the probabilities to be estimated. Section 3 shows how a class from WordNet can be used to estimate the probability of a noun sense. Section 4 shows how a chi-square test is used as part of the generalization procedure, and Section 5 describe</context>
<context position="24179" citStr="Wagner (2000)" startWordPosition="4147" endWordPosition="4148">g on the particular application. There may be cases in which the conditions for the appropriate application of a chisquare test are not met. One condition that is likely to be violated is the requirement that expected values in the contingency table not be too small. (A rule of thumb often found in textbooks is that the expected values should be greater than five.) One response to this problem is to apply some kind of thresholding and either ignore counts below the threshold, or apply the test only to tables that do not contain low counts. Ribas (1995), Li and Abe (1998), McCarthy (2000), and Wagner (2000) all use some kind of thresholding when dealing with counts in the hierarchy (although not in the context of a chi-square test). Another approach would be to use Fisher’s exact test (Agresti 1996; Pedersen 1996), which can be applied to tables regardless of the size of 194 Clark and Weir Class-Based Probability Estimation the counts they contain. The main problem with this test is that it is computationally expensive, especially for large contingency tables. What we have found in practice is that applying the chi-square test to tables dominated by low counts tends to produce an insignificant r</context>
<context position="29318" citStr="Wagner 2000" startWordPosition="5019" endWordPosition="5020">in +— parent end if chi-square test for parentmin is significant then sig result +— true else move up to next node: top +— parentmin end return top Figure 1 An algorithm for determining top(c, v, r). Figure 2 An example generalization: Determining top((soup), stir, obj). artifact ground food fluid poison G2: 29.9, crit val: 58.1 substance entity object G2: 141.1, crit val: 37.7 nourishment fare beverage dish meal course G2: 5.5, crit val: 16.9 G2: 5.4, crit val: 16.9 lasagne haggis G2: 14.5, critical value: 55.8 soup 196 Clark and Weir Class-Based Probability Estimation 1997; Li and Abe 1998; Wagner 2000), the level of generalization is often determined for a small number of hand-picked verbs and the result compared with the researcher’s intuition about the most appropriate level for representing a selectional preference. According to this approach, if (sandwich) were chosen to represent (hotdog) in the object position of eat, this might be considered an undergeneralization, since (food) might be considered more appropriate. For this work we argue that such an evaluation is not appropriate; since the purpose of this work is probability estimation, the most appropriate level is the one that lea</context>
</contexts>
<marker>Wagner, 2000</marker>
<rawString>Wagner, Andreas. 2000. Enriching a lexical semantic net with selectional preferences by means of statistical corpus analysis. In Proceedings of the ECAI-2000 Workshop on Ontology Learning, Berlin, pages 37–42.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>