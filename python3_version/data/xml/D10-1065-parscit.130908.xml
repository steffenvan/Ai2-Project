<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.039378">
<title confidence="0.9964765">
Combining Unsupervised and Supervised Alignments for MT:
An Empirical Study
</title>
<author confidence="0.819385">
Jinxi Xu and Antti-Veikko I. Rosti
</author>
<affiliation confidence="0.667949">
Raytheon BBN Technologies, 10 Moulton Street, Cambridge, MA 02138, USA
</affiliation>
<email confidence="0.997812">
{jxu,arosti}@bbn.com
</email>
<sectionHeader confidence="0.99859" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999122206896552">
Word alignment plays a central role in statisti-
cal MT (SMT) since almost all SMT systems
extract translation rules from word aligned
parallel training data. While most SMT
systems use unsupervised algorithms (e.g.
GIZA++) for training word alignment, super-
vised methods, which exploit a small amount
of human-aligned data, have become increas-
ingly popular recently. This work empirically
studies the performance of these two classes
of alignment algorithms and explores strate-
gies to combine them to improve overall sys-
tem performance. We used two unsupervised
aligners, GIZA++ and HMM, and one super-
vised aligner, ITG, in this study. To avoid lan-
guage and genre specific conclusions, we ran
experiments on test sets consisting of two lan-
guage pairs (Chinese-to-English and Arabic-
to-English) and two genres (newswire and we-
blog). Results show that the two classes of al-
gorithms achieve the same level of MT perfor-
mance. Modest improvements were achieved
by taking the union of the translation gram-
mars extracted from different alignments. Sig-
nificant improvements (around 1.0 in BLEU)
were achieved by combining outputs of differ-
ent systems trained with different alignments.
The improvements are consistent across lan-
guages and genres.
</bodyText>
<sectionHeader confidence="0.999616" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999616210526316">
Word alignment plays a central role in training sta-
tistical machine translation (SMT) systems since al-
most all SMT systems extract translation rules from
word aligned parallel training data. Until recently,
most SMT systems used GIZA++ (Och and Ney,
2003), an unsupervised algorithm, for aligning par-
allel training data. In recent years, with the availabil-
ity of human aligned training data, supervised meth-
ods (e.g. the ITG aligner (Haghighi et al., 2009))
have become increasingly popular.
The main objective of this work is to show the
two classes (unsupervised and supervised) of al-
gorithms are complementary and combining them
will improve overall system performance. The use
of human aligned training data allows supervised
methods such as ITG to more accurately align fre-
quent words, such as the alignments of Chinese par-
ticles (e.g. “bei”, “de”, etc) to their English equiv-
alents (e.g. “is/are/was/..”, “of”, etc). On the other
hand, supervised methods can be affected by sub-
optimal alignments in hand-aligned data. For exam-
ple, the hand-aligned data used in our experiments
contain some coarse-grained alignments (e.g. “lian-
he guo” to “United Nations”) although fine-grained
alignments (“lian-he” to “United” and “guo” to “Na-
tions”) are usually more appropriate for SMT. Un-
supervised methods are less likely to be affected
by this problem. We used two well studied unsu-
pervised aligners, GIZA++ (Och and Ney, 2003)
and HMM (Liang et al., 2006) and one supervised
aligner, ITG (Haghighi et al., 2009) as representa-
tives in this work.
We explored two techniques to combine different
alignment algorithms. One is to take the union of
the translation rules extracted from alignments pro-
duced by different aligners. This is motivated by
studies that showed that the coverage of translation
rules is critical to SMT (DeNeefe et al., 2007). The
</bodyText>
<page confidence="0.964436">
667
</page>
<bodyText confidence="0.9671368">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 667–673,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
other method is to combine the outputs of different
MT systems trained using different aligners. As-
suming different systems make independent errors,
system combination can generate a better transla-
tion than those of individual systems through voting
(Rosti et al., 2007).
Our work differs from previous work in two ways.
Past studies of combining alternative alignments fo-
cused on minimizing alignment errors, usually by
merging alternative alignments for a sentence pair
into a single alignment with the fewest number of
incorrect alignment links (Ayan and Dorr, 2006). In
contrast, our work is based on the assumption that
perfect word alignment is impossible due to the in-
trinsic difficulty of the problem, and it is more effec-
tive to resolve translation ambiguities at later stages
of the MT pipeline. A main focus of much previous
work on word alignments is on theoretical aspects
of the proposed algorithms. In contrast, the nature
of this work is purely empirical. Our system was
trained on a large amount of training data and evalu-
ated on multiple languages (Chinese-to-English and
Arabic-to-English) and multiple genres (newswire
and weblog). Furthermore, we used a state of the art
string-to-tree decoder (Shen et al., 2008) to estab-
lish the strongest possible baseline. In comparison,
experiments in previous studies typically used one
language pair and one genre (usually newswire), a
reduced amount of training data and a phrase based
decoder.
This paper is organized as follows. Section 2 de-
scribes the three alignment algorithms. Section 3
describes the two methods used to combine these
aligners to improve MT. The experimental setup
used to compare these methods is presented in Sec-
tion 4. Section 5 shows the results including a dis-
cussion. Section 6 discusses related work. Section 7
concludes the paper.
</bodyText>
<sectionHeader confidence="0.96962" genericHeader="introduction">
2 Alignment Algorithms
</sectionHeader>
<bodyText confidence="0.999954346153846">
We used three aligners in this work: GIZA++ (Och
and Ney, 2003), jointly trained HMM (Liang et al.,
2006), and ITG (Haghighi et al., 2009). GIZA++
is an unsupervised method based on models 1-5 of
Brown et al. (1993). Given a sentence pair e − f,
it seeks the alignment a that maximizes the proba-
bility P(f, a|e). As in most previous studies using
GIZA++, we ran GIZA++ in both directions, from e
to f and from f to e, and symmetrized the bidirec-
tional alignments into one, using a method similar
to the grow-diagonal-final method described in Och
and Ney (2003). We ran GIZA++ up to model 4.
The jointly trained HMM aligner, or HMM for
short, is also unsupervised but it uses a small amount
of hand-aligned data to tweak a few high level pa-
rameters. Low level parameters are estimated in an
unsupervised manner like GIZA++.
The ITG aligner is a supervised method whose pa-
rameters are tuned to optimize alignment accuracy
on hand-aligned data. It uses the inversion transduc-
tion grammar (ITG) (Wu, 1997) to narrow the space
of possible alignments. Since the ITG aligner uses
features extracted from HMM alignments, HMM
was run as a prepossessing step in our experiments.
Both the HMM and ITG aligners are publicly avail-
able1.
</bodyText>
<sectionHeader confidence="0.992139" genericHeader="method">
3 Methods of Combining Alternative
Alignments for MT
</sectionHeader>
<bodyText confidence="0.999954833333333">
We explored two methods of combining alternative
alignments for MT. One is to extract translation rules
from the three alternative alignments and take the
union of the three sets of rules as the single transla-
tion grammar. Procedurally, this is done by concate-
nating the alignment files before extracting transla-
tion rules. We call this method unioned grammar.
This method greatly increases the coverage of the
rules, as the unioned translation grammar has about
80% more rules than the ones extracted from the in-
dividual alignment in our experiments. As such, de-
coding is also slower.
The other is to use system combination to com-
bine outputs of systems trained using different align-
ers. Due to differences in the alignment algorithms,
these systems would produce different hypotheses
with independent errors. Combining a diverse set
of hypotheses could improve overall system perfor-
mance. While system combination is a well-known
technique, to our knowledge this work is the first to
apply it to explicitly exploit complementary align-
ment algorithms on a large scale.
Since system combination is an established tech-
nique, here we only briefly discuss our system com-
</bodyText>
<footnote confidence="0.988346">
1http://code.google.com/p/berkeleyaligner/
</footnote>
<page confidence="0.994017">
668
</page>
<bodyText confidence="0.999960130434783">
bination setup. The basic algorithm was described in
Rosti et al. (2007). In this work, we use incremental
hypothesis alignment with flexible matching (Rosti
et al., 2009) to produce the confusion networks. 10-
best lists from all systems are collected first. All
1-best hypotheses for each segment are used as con-
fusion network skeletons, the remaining hypotheses
are aligned to the confusion networks, and the result-
ing networks are connected in parallel into a joint
lattice with skeleton specific prior probabilities es-
timated from the alignment statistics on the initial
arcs. This lattice is expanded with an unpruned bi-
gram language model and the system combination
weights are tuned directly to maximize the BLEU
score of the 1-best decoding outputs. Given the
tuned system combination weights, a 300-best list
is extracted from the lattice, the hypotheses are re-
scored using an unpruned 5-gram language model,
and a second set of system combination weights is
tuned to maximize the BLEU score of the 1-best hy-
pothesis of the re-scored 300-best list. The same re-
scoring step is also applied to the outputs of individ-
ual systems.
</bodyText>
<sectionHeader confidence="0.994698" genericHeader="method">
4 Experiment Setup
</sectionHeader>
<bodyText confidence="0.997761305555555">
To establish strong baselines, we used a string-to-
tree SMT system (Shen et al., 2008), one of the top
performing systems in the NIST 2009 MT evalua-
tion, and trained it with very large amounts of par-
allel and language model data. The system used
large sets of discriminatively tuned features (up to
55,000 on Arabic) inspired by the work of Chiang et
al. (2009). To avoid drawing language, genre, and
metric specific conclusions, we experimented with
two language pairs, Arabic-English and Chinese-
English, and two genres, newswire and weblog, and
report both BLEU (Papineni et al., 2002) and TER
(Snover et al., 2006) scores. Systems were tuned to
maximize BLEU on the tuning set using a procedure
described in Devlin (2009).
The sizes of the parallel training corpora are
238M words (target side) for Arabic-English MT
and 265M words for Chinese-English. While the
majority of the data is publicly available from the
Linguistic Data Consortium (LDC), some of the data
is available under the DARPA GALE program. Due
to the size of the parallel corpora, we divided them
into five chunks and aligned them in parallel to save
time. Due to its running complexity, we ran ITG
only on sentences with 60 or fewer words. For
longer sentences, we used HMM alignments instead,
which were conveniently generated in the prepro-
cessing step of ITG aligner. For language model
training, we used about 9 billion words of English
text, most of which are from English Gigaword cor-
pus and GoogleNews. Each system used a 3-gram
LM for decoding and a 5-gram LM for re-scoring.
The same 5-gram LM was also used for re-scoring
system combination results.
For each combination of language pair and genre,
we used three development sets:
</bodyText>
<listItem confidence="0.9966039">
• Tune, which was used to tune parameters of
individual MT systems. Each system was tuned
ten iterations based on BLEU.
• SysCombTune, which was used to tune pa-
rameters of system combination. A subset of it
was also used as validation for determining the
best iteration in tuning individual systems.
• Test, which was the blind test corpus for mea-
suring performances of both individual systems
and system combination.
</listItem>
<bodyText confidence="0.999628727272727">
Test materials were drawn from two sources:
NIST MT evaluations 2004 to 2008, and develop-
ment and evaluation data for the DARPA GALE pro-
gram. Due to the mixing of different data sources,
some test sentences have four reference translations
while the rest have only one. The average num-
ber of references per test sentence varies across test
sets. For this reason, MT scores are not comparable
across test sets. Table 1 shows the size and the av-
erage number of references per sentence of the test
sets.
Two hand-aligned corpora were used to train the
ITG aligner: LDC2009E82 (Arabic-English) and
LDC2009E83 (Chinese-English). We re-tokenized
the corpora using our tokenizers and projected the
LDC alignments to our tokenization heuristically.
The projection was not perfect and sometimes cre-
ated very coarse-grained alignments. We used a set
of filters to remove such problematic data. We ended
up with 3,667 Arabic-English and 879 Chinese-
English hand-aligned sentence pairs with sufficient
quality for training automatic aligners.
</bodyText>
<page confidence="0.989972">
669
</page>
<table confidence="0.9967656">
language and genre Tune SysCombTune Test
Arabic newswire 2963 (2.9) 3223 (2.7) 2242 (2.7)
Arabic web 4597 (1.5) 4526 (1.4) 2703 (2.7)
Chinese newswire 3085 (2.6) 3001 (2.7) 2055 (1.4)
Chinese web 4221 (1.3) 4285 (1.3) 3092 (1.2)
</table>
<tableCaption confidence="0.999612">
Table 1: Numbers of sentences and average number of references (in parentheses) of test sets
</tableCaption>
<sectionHeader confidence="0.999844" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.984652373333333">
Three baseline systems were trained using the three
different aligners. Case insensitive BLEU and TER
scores for Arabic newswire, Arabic weblog, Chi-
nese newswire, and Chinese weblog are shown in
Tables 2, 3, 4, and 5, respectively2. The BLEU
scores on the Test set are fairly similar but the
ordering between different alignment algorithms is
mixed between different languages and genres. To
compare the two alignment combination strategies,
we trained a system using the union of the rules ex-
tracted from the alternative alignments (union in
the tables) and a combination of the three baseline
system outputs (3 syscomb in the tables). The
system with the unioned grammar was also added
as an additional system in the combination marked
by 4 syscomb.
As seen in the tables, unioned grammar and sys-
tem combination improve MT on both languages
(Arabic and Chinese) and both genres (newswire
and weblog). While there are improvements on
both SysCombTune and Test, the results on
SysCombTune are not totally fair since it was used
for tuning system combination weights and as val-
idation for optimizing weights of the MT systems.
Therefore our discussion will focus on results on
Test. (We did not show scores on Tune because
systems were directly tuned on it.) Statistical sig-
nificance is determined at 95% confidence level us-
ing the bootstrap method described in Koehn (2004),
and is only applied on results obtained on the blind
Test set.
For unioned grammar, the overall improvement
in BLEU is modest, ranging from 0.1 to 0.6 point
2Dagger () indicates statistically better results than the best
individual alignment system. Double dagger ($) indicates sta-
tistically better results than both best individual alignment and
unioned grammar. Bold indicates best Test set performance
among individual alignment systems.
compared with the best baseline system, with little
change in TER score. The improvements in BLEU
score are statistically significant for Arabic (both
genres), but not for Chinese. The improvements in
TER are not significant for either language.
System combination produces bigger improve-
ments in performance. Compared with the best base-
line system, the improvement in BLEU ranges from
0.8 to 1.6 point. There are also noticeable improve-
ments in TER, around 1.0 point. The TER improve-
ments are mostly explained by the hypothesis align-
ment algorithm which is closely related to TER scor-
ing (Rosti et al., 2009). The results are interesting
because all three baseline systems (GIZA++, HMM
and ITG) are identical except for the word align-
ments used in rule extraction. The results confirm
that the aligners are indeed complementary, as we
conjectured earlier. Also, the four-system combi-
nation yields consistent gains over the three-system
combination, suggesting that the system using the
unioned grammar is somewhat complementary to
the three baseline systems. The statistical test in-
dicates that both the three and four system combi-
nations are significantly better than the single best
alignment system for all languages and genres in
BLEU and TER. In most cases, they are also sig-
nificantly better than unioned grammar.
Somewhat surprisingly, the GIZA++ trained sys-
tem is slightly better than the ITG trained system on
all genres but Chinese weblog. However, we should
point out that such a comparison is not entirely fair.
First, we only ran ITG on short sentences. (For long
sentences, we had to settle for HMM alignments for
computing reasons.) Second, the hand-aligned data
used for ITG training are not very clean, as we said
before. The ITG results could be improved if these
problems were not present.
</bodyText>
<page confidence="0.995952">
670
</page>
<table confidence="0.999721875">
System SysCombTune Test
BLEU TER BLEU TER
GIZA++ 51.31 38.01 50.96 38.38
HMM 50.87 38.49 50.84 38.87
ITG 51.04 38.44 50.69 38.94
union 51.55 37.93 51.531 38.32
3 syscomb 52.66 37.20 52.43$ 37.69$
4 syscomb 52.80 37.05 52.55$ 37.46$
</table>
<tableCaption confidence="0.905762">
Table 2: MT results on Arabic newswire (see footnote 2).
</tableCaption>
<table confidence="0.999884">
System SysCombTune Test
BLEU TER BLEU TER
GIZA++ 27.49 55.00 38.00 49.55
HMM 27.42 55.53 37.81 50.12
ITG 27.19 55.32 37.77 49.94
union 27.66 54.82 38.431 49.43
3 syscomb 27.65 53.89 38.701 48.72$
4 syscomb 27.83 53.68 38.82$ 48.53$
</table>
<tableCaption confidence="0.967226">
Table 3: MT results on Arabic weblog (see footnote 2).
</tableCaption>
<table confidence="0.9998795">
System SysCombTune Test
BLEU TER BLEU TER
GIZA++ 36.42 54.21 26.77 57.67
HMM 36.12 54.50 26.17 58.22
ITG 36.23 54.11 26.53 57.40
union 36.57 54.07 26.83 57.37
3 syscomb 37.60 53.19 27.46$ 56.88$
4 syscomb 37.77 53.11 27.57$ 56.57$
</table>
<tableCaption confidence="0.9419665">
Table 4: MT results on Chinese newswire (see footnote
2).
</tableCaption>
<table confidence="0.99981875">
System SysCombTune Test
BLEU TER BLEU TER
GIZA++ 18.71 64.10 16.94 63.46
HMM 18.35 64.66 16.66 64.02
ITG 18.76 63.67 16.97 63.29
union 18.97 63.86 17.22 63.20
3 syscomb 19.66 63.40 17.98$ 62.47$
4 syscomb 19.80 63.32 18.05$ 62.36$
</table>
<tableCaption confidence="0.999086">
Table 5: MT results on Chinese weblog (see footnote 2).
</tableCaption>
<subsectionHeader confidence="0.957065">
5.1 Discussion
</subsectionHeader>
<bodyText confidence="0.999976814814815">
Inter-aligner agreements provide additional evi-
dence about the differences between the aligners.
Suppose on a common data set, the sets of align-
ment links produced by two aligners are A and
B, we compute their agreement as (|A n B|/|A |+
|A n B|/|B|)/2. (This is the average of recall and
precision of one set by treating the other set as refer-
ence.) The agreement between GIZA++ and ITG
is around 78% on a subset of the Arabic-English
parallel data. The agreements between GIZA++
and HMM, and between HMM and ITG are slightly
higher, around 83%. Since ITG could not align long
sentences, we only used short sentences (at most 60
words in length) in our calculation.
Due to the large differences between the align-
ers, significantly more rules were extracted with
the unioned grammar method in our experiments.
On average, the size of the grammar (number of
rules) was increased by about 80% compared with
the baseline systems. The larger grammar results
in more combinations of partial theories in decod-
ing. However, for computing reasons, we kept the
beam size of the decoder constant despite the in-
crease in grammar size, potentially pruning out good
theories. Performance could be improved further if
larger beam sizes were used. We will leave this to
future work.
</bodyText>
<sectionHeader confidence="0.99994" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999957588235294">
Ayan and Dorr (2006) described a method to min-
imize alignment errors by combining alternative
alignments into a single alignment for each sentence
pair. Deng and Zhou (2009) used the number of ex-
tractable translation pairs as the objective function
for alignment combination. Och and Ney (2003) and
Koehn et al. (2003) used heuristics to merge the bidi-
rectional GIZA++ alignments into a single align-
ment. Despite differences in algorithms and objec-
tive functions in these studies, they all attempted to
produce a single final alignment for each sentence
pair. In comparison, all alternative alignments are
directly used by the translation system in this work.
The unioned grammar method in this work is
very similar to Gim´enez and M`arquez (2005), which
combined phrase pairs extracted from different
alignments into a single phrase table. The difference
</bodyText>
<page confidence="0.996643">
671
</page>
<bodyText confidence="0.999989863636364">
from that work is that our focus is to leverage com-
plementary alignment algorithms, while theirs was
to leverage alignments of different lexical units pro-
duced by the same aligner.
Some studies leveraged other types of differences
between systems to improve MT. For example, de
Gispert et al. (2009) combined systems trained with
different tokenizations.
The theory behind the GIZA++ aligner was due to
Brown et al. (1993). The theory of Inversion Trans-
duction Grammars (ITG) was due to Wu (1997).
The ITG aligner (Haghighi et al., 2009) used in this
work extended the original ITG to handle blocks of
words in addition to single words. The use of HMM
for word alignment can be traced as far back as to
Vogel et al. (1996). The HMM aligner used in this
work was due to Liang et al. (2006). It refined the
original HMM alignment algorithm by jointly train-
ing two HMMs, one in each direction. Furthermore,
it used a small amount of supervised data to tweak
some high level parameters, although it did not di-
rectly use the supervised data in training.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999911857142857">
We explored two methods to exploit complementary
alignment algorithms. One is to extract translation
rules from all alternative alignments. The other is to
combine outputs of different MT systems trained us-
ing different aligners. Experiments on two language
pairs and two genres show consistent improvements
over the baseline systems.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999466166666667">
This work was supported by DARPA/IPTO Contract
No. HR0011-06-C-0022 under the GALE program3
(Approved for Public Release, Distribution Unlim-
ited). The authors are grateful to John DeNero and
John Blitzer for their help with the Berkeley HMM
and ITG aligners.
</bodyText>
<footnote confidence="0.9850878">
3The views, opinions, and/or findings contained in this ar-
ticle/presentation are those of the author/presenter and should
not be interpreted as representing the official views or policies,
either expressed or implied, of the Defense Advanced Research
Projects Agency or the Department of Defense.
</footnote>
<sectionHeader confidence="0.847225" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.968594038461538">
Necip Fazil Ayan and Bonnie J. Dorr. 2006. A maximum
entropy approach to combining word alignments. In
Proceedings of the Human Language Technology Con-
ference of the North American Chapter of the ACL,
pages 96–103.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: Parameter estima-
tion. Computational Linguistics, 19(2):263–311.
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 new features for statistical machine transla-
tion. In Proceedings of Human Language Technolo-
gies: The 2009 Annual Conference of the North Amer-
ican Chapter of the ACL, pages 218–226.
Adri`a de Gispert, Sami Virpioja, Mikko Kurimo, and
William Byrne. 2009. Minimum Bayes risk combi-
nation of translation hypotheses from alternative mor-
phological decompositions. In Proceedings ofHuman
Language Technologies: The 2009 Annual Conference
of the North American Chapter of the ACL, pages 73–
76.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What can syntax-based MT learn from
phrase-based MT? In Proceedings of the 2007 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, pages 755–763.
Yonggang Deng and Bowen Zhou. 2009. Optimizing
word alignment combination for phrase table training.
In Proceedings of the Joint Conference of the 47th An-
nual Meeting of the ACL and the 4th IJCNLP of the
AFNLP, pages 229–232.
Jacob Devlin. 2009. Lexical features for statistical ma-
chine translation. Master’s thesis, University of Mary-
land.
Jes´us Gim´enez and Lluis M`arquez. 2005. Combining
linguistic data views for phrase-based SMT. In Pro-
ceedings of the ACL Workshop on Building and Using
Parallel Texts, pages 145–148.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with supervised
ITG models. In Proceedings of the Joint Conference
of the 47th Annual Meeting of the ACL and the 4th
IJCNLP of the AFNLP, pages 923–931.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical phrase-based translation. In Proceedings of
the 2003 Human Language Technology Conference of
the North American Chapter of the ACL, pages 48–54.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of the
2004 Conference on Empirical Methods in Natural
Language Processing, pages 388–395.
</reference>
<page confidence="0.980428">
672
</page>
<reference confidence="0.9997735">
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the Human
Language Technology Conference of the North Ameri-
can Chapter of the ACL, pages 104–111.
Franz J. Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1):19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318.
Antti-Veikko I. Rosti, Bing Xiang, Spyros Matsoukas,
Richard Schwartz, Necip Fazil Ayan, and Bonnie J.
Dorr. 2007. Combining outputs from multiple ma-
chine translation systems. In Proceedings of Human
Language Technologies 2007: The Conference of the
North American Chapter of the ACL, pages 228–235.
Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2009. Incremental hypothe-
sis alignment with flexible matching for building con-
fusion networks: BBN system description for WMT09
system combination task. In Proceedings ofthe Fourth
Workshop on Statistical Machine Translation, pages
61–65.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
new string-to-dependency machine translation algo-
rithm with a target dependency language model. In
Proceedings ofACL-08: HLT, pages 577–585.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciula, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of the 7th Conference of the Associa-
tion for Machine Translation in the Americas, pages
223–231.
Stephan Vogel, Hermann Ney, and Christoph Tillman.
1996. HMM-based word alignment in statistical trans-
lation. In The 16th International Conference on Com-
putational Linguistics, pages 836–841.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3).
</reference>
<page confidence="0.999275">
673
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.587492">
<title confidence="0.9823555">Combining Unsupervised and Supervised Alignments for An Empirical Study</title>
<author confidence="0.8199865">Xu I Rosti Raytheon BBN Technologies</author>
<author confidence="0.8199865">Moulton Street</author>
<author confidence="0.8199865">MA Cambridge</author>
<abstract confidence="0.9981349">Word alignment plays a central role in statistical MT (SMT) since almost all SMT systems extract translation rules from word aligned parallel training data. While most SMT systems use unsupervised algorithms (e.g. GIZA++) for training word alignment, supervised methods, which exploit a small amount of human-aligned data, have become increasingly popular recently. This work empirically studies the performance of these two classes of alignment algorithms and explores strategies to combine them to improve overall system performance. We used two unsupervised aligners, GIZA++ and HMM, and one supervised aligner, ITG, in this study. To avoid language and genre specific conclusions, we ran experiments on test sets consisting of two language pairs (Chinese-to-English and Arabicto-English) and two genres (newswire and weblog). Results show that the two classes of algorithms achieve the same level of MT performance. Modest improvements were achieved by taking the union of the translation grammars extracted from different alignments. Significant improvements (around 1.0 in BLEU) were achieved by combining outputs of different systems trained with different alignments. The improvements are consistent across languages and genres.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>A maximum entropy approach to combining word alignments.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL,</booktitle>
<pages>96--103</pages>
<contexts>
<context position="4080" citStr="Ayan and Dorr, 2006" startWordPosition="625" endWordPosition="628">. c�2010 Association for Computational Linguistics other method is to combine the outputs of different MT systems trained using different aligners. Assuming different systems make independent errors, system combination can generate a better translation than those of individual systems through voting (Rosti et al., 2007). Our work differs from previous work in two ways. Past studies of combining alternative alignments focused on minimizing alignment errors, usually by merging alternative alignments for a sentence pair into a single alignment with the fewest number of incorrect alignment links (Ayan and Dorr, 2006). In contrast, our work is based on the assumption that perfect word alignment is impossible due to the intrinsic difficulty of the problem, and it is more effective to resolve translation ambiguities at later stages of the MT pipeline. A main focus of much previous work on word alignments is on theoretical aspects of the proposed algorithms. In contrast, the nature of this work is purely empirical. Our system was trained on a large amount of training data and evaluated on multiple languages (Chinese-to-English and Arabic-to-English) and multiple genres (newswire and weblog). Furthermore, we u</context>
<context position="18602" citStr="Ayan and Dorr (2006)" startWordPosition="3013" endWordPosition="3016"> differences between the aligners, significantly more rules were extracted with the unioned grammar method in our experiments. On average, the size of the grammar (number of rules) was increased by about 80% compared with the baseline systems. The larger grammar results in more combinations of partial theories in decoding. However, for computing reasons, we kept the beam size of the decoder constant despite the increase in grammar size, potentially pruning out good theories. Performance could be improved further if larger beam sizes were used. We will leave this to future work. 6 Related Work Ayan and Dorr (2006) described a method to minimize alignment errors by combining alternative alignments into a single alignment for each sentence pair. Deng and Zhou (2009) used the number of extractable translation pairs as the objective function for alignment combination. Och and Ney (2003) and Koehn et al. (2003) used heuristics to merge the bidirectional GIZA++ alignments into a single alignment. Despite differences in algorithms and objective functions in these studies, they all attempted to produce a single final alignment for each sentence pair. In comparison, all alternative alignments are directly used </context>
</contexts>
<marker>Ayan, Dorr, 2006</marker>
<rawString>Necip Fazil Ayan and Bonnie J. Dorr. 2006. A maximum entropy approach to combining word alignments. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="5573" citStr="Brown et al. (1993)" startWordPosition="871" endWordPosition="874">ased decoder. This paper is organized as follows. Section 2 describes the three alignment algorithms. Section 3 describes the two methods used to combine these aligners to improve MT. The experimental setup used to compare these methods is presented in Section 4. Section 5 shows the results including a discussion. Section 6 discusses related work. Section 7 concludes the paper. 2 Alignment Algorithms We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al., 2006), and ITG (Haghighi et al., 2009). GIZA++ is an unsupervised method based on models 1-5 of Brown et al. (1993). Given a sentence pair e − f, it seeks the alignment a that maximizes the probability P(f, a|e). As in most previous studies using GIZA++, we ran GIZA++ in both directions, from e to f and from f to e, and symmetrized the bidirectional alignments into one, using a method similar to the grow-diagonal-final method described in Och and Ney (2003). We ran GIZA++ up to model 4. The jointly trained HMM aligner, or HMM for short, is also unsupervised but it uses a small amount of hand-aligned data to tweak a few high level parameters. Low level parameters are estimated in an unsupervised manner like</context>
<context position="19864" citStr="Brown et al. (1993)" startWordPosition="3213" endWordPosition="3216"> unioned grammar method in this work is very similar to Gim´enez and M`arquez (2005), which combined phrase pairs extracted from different alignments into a single phrase table. The difference 671 from that work is that our focus is to leverage complementary alignment algorithms, while theirs was to leverage alignments of different lexical units produced by the same aligner. Some studies leveraged other types of differences between systems to improve MT. For example, de Gispert et al. (2009) combined systems trained with different tokenizations. The theory behind the GIZA++ aligner was due to Brown et al. (1993). The theory of Inversion Transduction Grammars (ITG) was due to Wu (1997). The ITG aligner (Haghighi et al., 2009) used in this work extended the original ITG to handle blocks of words in addition to single words. The use of HMM for word alignment can be traced as far back as to Vogel et al. (1996). The HMM aligner used in this work was due to Liang et al. (2006). It refined the original HMM alignment algorithm by jointly training two HMMs, one in each direction. Furthermore, it used a small amount of supervised data to tweak some high level parameters, although it did not directly use the su</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Kevin Knight</author>
<author>Wei Wang</author>
</authors>
<title>11,001 new features for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL,</booktitle>
<pages>218--226</pages>
<contexts>
<context position="9366" citStr="Chiang et al. (2009)" startWordPosition="1497" endWordPosition="1500">5-gram language model, and a second set of system combination weights is tuned to maximize the BLEU score of the 1-best hypothesis of the re-scored 300-best list. The same rescoring step is also applied to the outputs of individual systems. 4 Experiment Setup To establish strong baselines, we used a string-totree SMT system (Shen et al., 2008), one of the top performing systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data. The system used large sets of discriminatively tuned features (up to 55,000 on Arabic) inspired by the work of Chiang et al. (2009). To avoid drawing language, genre, and metric specific conclusions, we experimented with two language pairs, Arabic-English and ChineseEnglish, and two genres, newswire and weblog, and report both BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. Systems were tuned to maximize BLEU on the tuning set using a procedure described in Devlin (2009). The sizes of the parallel training corpora are 238M words (target side) for Arabic-English MT and 265M words for Chinese-English. While the majority of the data is publicly available from the Linguistic Data Consortium (LDC), some of t</context>
</contexts>
<marker>Chiang, Knight, Wang, 2009</marker>
<rawString>David Chiang, Kevin Knight, and Wei Wang. 2009. 11,001 new features for statistical machine translation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 218–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adri`a de Gispert</author>
<author>Sami Virpioja</author>
<author>Mikko Kurimo</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes risk combination of translation hypotheses from alternative morphological decompositions.</title>
<date>2009</date>
<booktitle>In Proceedings ofHuman Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL,</booktitle>
<pages>73--76</pages>
<marker>de Gispert, Virpioja, Kurimo, Byrne, 2009</marker>
<rawString>Adri`a de Gispert, Sami Virpioja, Mikko Kurimo, and William Byrne. 2009. Minimum Bayes risk combination of translation hypotheses from alternative morphological decompositions. In Proceedings ofHuman Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 73– 76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve DeNeefe</author>
<author>Kevin Knight</author>
<author>Wei Wang</author>
<author>Daniel Marcu</author>
</authors>
<title>What can syntax-based MT learn from phrase-based MT?</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>755--763</pages>
<contexts>
<context position="3305" citStr="DeNeefe et al., 2007" startWordPosition="511" endWordPosition="514">d “guo” to “Nations”) are usually more appropriate for SMT. Unsupervised methods are less likely to be affected by this problem. We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al., 2006) and one supervised aligner, ITG (Haghighi et al., 2009) as representatives in this work. We explored two techniques to combine different alignment algorithms. One is to take the union of the translation rules extracted from alignments produced by different aligners. This is motivated by studies that showed that the coverage of translation rules is critical to SMT (DeNeefe et al., 2007). The 667 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 667–673, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics other method is to combine the outputs of different MT systems trained using different aligners. Assuming different systems make independent errors, system combination can generate a better translation than those of individual systems through voting (Rosti et al., 2007). Our work differs from previous work in two ways. Past studies of combining alternative alignments focused on minimizing al</context>
</contexts>
<marker>DeNeefe, Knight, Wang, Marcu, 2007</marker>
<rawString>Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel Marcu. 2007. What can syntax-based MT learn from phrase-based MT? In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 755–763.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonggang Deng</author>
<author>Bowen Zhou</author>
</authors>
<title>Optimizing word alignment combination for phrase table training.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP,</booktitle>
<pages>229--232</pages>
<contexts>
<context position="18755" citStr="Deng and Zhou (2009)" startWordPosition="3037" endWordPosition="3040">e grammar (number of rules) was increased by about 80% compared with the baseline systems. The larger grammar results in more combinations of partial theories in decoding. However, for computing reasons, we kept the beam size of the decoder constant despite the increase in grammar size, potentially pruning out good theories. Performance could be improved further if larger beam sizes were used. We will leave this to future work. 6 Related Work Ayan and Dorr (2006) described a method to minimize alignment errors by combining alternative alignments into a single alignment for each sentence pair. Deng and Zhou (2009) used the number of extractable translation pairs as the objective function for alignment combination. Och and Ney (2003) and Koehn et al. (2003) used heuristics to merge the bidirectional GIZA++ alignments into a single alignment. Despite differences in algorithms and objective functions in these studies, they all attempted to produce a single final alignment for each sentence pair. In comparison, all alternative alignments are directly used by the translation system in this work. The unioned grammar method in this work is very similar to Gim´enez and M`arquez (2005), which combined phrase pa</context>
</contexts>
<marker>Deng, Zhou, 2009</marker>
<rawString>Yonggang Deng and Bowen Zhou. 2009. Optimizing word alignment combination for phrase table training. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 229–232.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Devlin</author>
</authors>
<title>Lexical features for statistical machine translation. Master’s thesis,</title>
<date>2009</date>
<institution>University of Maryland.</institution>
<contexts>
<context position="9729" citStr="Devlin (2009)" startWordPosition="1556" endWordPosition="1557">ng systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data. The system used large sets of discriminatively tuned features (up to 55,000 on Arabic) inspired by the work of Chiang et al. (2009). To avoid drawing language, genre, and metric specific conclusions, we experimented with two language pairs, Arabic-English and ChineseEnglish, and two genres, newswire and weblog, and report both BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. Systems were tuned to maximize BLEU on the tuning set using a procedure described in Devlin (2009). The sizes of the parallel training corpora are 238M words (target side) for Arabic-English MT and 265M words for Chinese-English. While the majority of the data is publicly available from the Linguistic Data Consortium (LDC), some of the data is available under the DARPA GALE program. Due to the size of the parallel corpora, we divided them into five chunks and aligned them in parallel to save time. Due to its running complexity, we ran ITG only on sentences with 60 or fewer words. For longer sentences, we used HMM alignments instead, which were conveniently generated in the preprocessing st</context>
</contexts>
<marker>Devlin, 2009</marker>
<rawString>Jacob Devlin. 2009. Lexical features for statistical machine translation. Master’s thesis, University of Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jes´us Gim´enez</author>
<author>Lluis M`arquez</author>
</authors>
<title>Combining linguistic data views for phrase-based SMT.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>145--148</pages>
<marker>Gim´enez, M`arquez, 2005</marker>
<rawString>Jes´us Gim´enez and Lluis M`arquez. 2005. Combining linguistic data views for phrase-based SMT. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 145–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>John Blitzer</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Better word alignments with supervised ITG models.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP,</booktitle>
<pages>923--931</pages>
<contexts>
<context position="1920" citStr="Haghighi et al., 2009" startWordPosition="290" endWordPosition="293">ere achieved by combining outputs of different systems trained with different alignments. The improvements are consistent across languages and genres. 1 Introduction Word alignment plays a central role in training statistical machine translation (SMT) systems since almost all SMT systems extract translation rules from word aligned parallel training data. Until recently, most SMT systems used GIZA++ (Och and Ney, 2003), an unsupervised algorithm, for aligning parallel training data. In recent years, with the availability of human aligned training data, supervised methods (e.g. the ITG aligner (Haghighi et al., 2009)) have become increasingly popular. The main objective of this work is to show the two classes (unsupervised and supervised) of algorithms are complementary and combining them will improve overall system performance. The use of human aligned training data allows supervised methods such as ITG to more accurately align frequent words, such as the alignments of Chinese particles (e.g. “bei”, “de”, etc) to their English equivalents (e.g. “is/are/was/..”, “of”, etc). On the other hand, supervised methods can be affected by suboptimal alignments in hand-aligned data. For example, the hand-aligned da</context>
<context position="5496" citStr="Haghighi et al., 2009" startWordPosition="857" endWordPosition="860">d one genre (usually newswire), a reduced amount of training data and a phrase based decoder. This paper is organized as follows. Section 2 describes the three alignment algorithms. Section 3 describes the two methods used to combine these aligners to improve MT. The experimental setup used to compare these methods is presented in Section 4. Section 5 shows the results including a discussion. Section 6 discusses related work. Section 7 concludes the paper. 2 Alignment Algorithms We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al., 2006), and ITG (Haghighi et al., 2009). GIZA++ is an unsupervised method based on models 1-5 of Brown et al. (1993). Given a sentence pair e − f, it seeks the alignment a that maximizes the probability P(f, a|e). As in most previous studies using GIZA++, we ran GIZA++ in both directions, from e to f and from f to e, and symmetrized the bidirectional alignments into one, using a method similar to the grow-diagonal-final method described in Och and Ney (2003). We ran GIZA++ up to model 4. The jointly trained HMM aligner, or HMM for short, is also unsupervised but it uses a small amount of hand-aligned data to tweak a few high level </context>
<context position="19979" citStr="Haghighi et al., 2009" startWordPosition="3233" endWordPosition="3236">s extracted from different alignments into a single phrase table. The difference 671 from that work is that our focus is to leverage complementary alignment algorithms, while theirs was to leverage alignments of different lexical units produced by the same aligner. Some studies leveraged other types of differences between systems to improve MT. For example, de Gispert et al. (2009) combined systems trained with different tokenizations. The theory behind the GIZA++ aligner was due to Brown et al. (1993). The theory of Inversion Transduction Grammars (ITG) was due to Wu (1997). The ITG aligner (Haghighi et al., 2009) used in this work extended the original ITG to handle blocks of words in addition to single words. The use of HMM for word alignment can be traced as far back as to Vogel et al. (1996). The HMM aligner used in this work was due to Liang et al. (2006). It refined the original HMM alignment algorithm by jointly training two HMMs, one in each direction. Furthermore, it used a small amount of supervised data to tweak some high level parameters, although it did not directly use the supervised data in training. 7 Conclusions We explored two methods to exploit complementary alignment algorithms. One</context>
</contexts>
<marker>Haghighi, Blitzer, DeNero, Klein, 2009</marker>
<rawString>Aria Haghighi, John Blitzer, John DeNero, and Dan Klein. 2009. Better word alignments with supervised ITG models. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 923–931.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the ACL,</booktitle>
<pages>48--54</pages>
<contexts>
<context position="18900" citStr="Koehn et al. (2003)" startWordPosition="3061" endWordPosition="3064">ial theories in decoding. However, for computing reasons, we kept the beam size of the decoder constant despite the increase in grammar size, potentially pruning out good theories. Performance could be improved further if larger beam sizes were used. We will leave this to future work. 6 Related Work Ayan and Dorr (2006) described a method to minimize alignment errors by combining alternative alignments into a single alignment for each sentence pair. Deng and Zhou (2009) used the number of extractable translation pairs as the objective function for alignment combination. Och and Ney (2003) and Koehn et al. (2003) used heuristics to merge the bidirectional GIZA++ alignments into a single alignment. Despite differences in algorithms and objective functions in these studies, they all attempted to produce a single final alignment for each sentence pair. In comparison, all alternative alignments are directly used by the translation system in this work. The unioned grammar method in this work is very similar to Gim´enez and M`arquez (2005), which combined phrase pairs extracted from different alignments into a single phrase table. The difference 671 from that work is that our focus is to leverage complement</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the ACL, pages 48–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>388--395</pages>
<contexts>
<context position="13875" citStr="Koehn (2004)" startWordPosition="2236" endWordPosition="2237">n the tables, unioned grammar and system combination improve MT on both languages (Arabic and Chinese) and both genres (newswire and weblog). While there are improvements on both SysCombTune and Test, the results on SysCombTune are not totally fair since it was used for tuning system combination weights and as validation for optimizing weights of the MT systems. Therefore our discussion will focus on results on Test. (We did not show scores on Tune because systems were directly tuned on it.) Statistical significance is determined at 95% confidence level using the bootstrap method described in Koehn (2004), and is only applied on results obtained on the blind Test set. For unioned grammar, the overall improvement in BLEU is modest, ranging from 0.1 to 0.6 point 2Dagger () indicates statistically better results than the best individual alignment system. Double dagger ($) indicates statistically better results than both best individual alignment and unioned grammar. Bold indicates best Test set performance among individual alignment systems. compared with the best baseline system, with little change in TER score. The improvements in BLEU score are statistically significant for Arabic (both genres</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL,</booktitle>
<pages>104--111</pages>
<contexts>
<context position="2916" citStr="Liang et al., 2006" startWordPosition="448" endWordPosition="451">s (e.g. “bei”, “de”, etc) to their English equivalents (e.g. “is/are/was/..”, “of”, etc). On the other hand, supervised methods can be affected by suboptimal alignments in hand-aligned data. For example, the hand-aligned data used in our experiments contain some coarse-grained alignments (e.g. “lianhe guo” to “United Nations”) although fine-grained alignments (“lian-he” to “United” and “guo” to “Nations”) are usually more appropriate for SMT. Unsupervised methods are less likely to be affected by this problem. We used two well studied unsupervised aligners, GIZA++ (Och and Ney, 2003) and HMM (Liang et al., 2006) and one supervised aligner, ITG (Haghighi et al., 2009) as representatives in this work. We explored two techniques to combine different alignment algorithms. One is to take the union of the translation rules extracted from alignments produced by different aligners. This is motivated by studies that showed that the coverage of translation rules is critical to SMT (DeNeefe et al., 2007). The 667 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 667–673, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics other</context>
<context position="5463" citStr="Liang et al., 2006" startWordPosition="851" endWordPosition="854">ally used one language pair and one genre (usually newswire), a reduced amount of training data and a phrase based decoder. This paper is organized as follows. Section 2 describes the three alignment algorithms. Section 3 describes the two methods used to combine these aligners to improve MT. The experimental setup used to compare these methods is presented in Section 4. Section 5 shows the results including a discussion. Section 6 discusses related work. Section 7 concludes the paper. 2 Alignment Algorithms We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al., 2006), and ITG (Haghighi et al., 2009). GIZA++ is an unsupervised method based on models 1-5 of Brown et al. (1993). Given a sentence pair e − f, it seeks the alignment a that maximizes the probability P(f, a|e). As in most previous studies using GIZA++, we ran GIZA++ in both directions, from e to f and from f to e, and symmetrized the bidirectional alignments into one, using a method similar to the grow-diagonal-final method described in Och and Ney (2003). We ran GIZA++ up to model 4. The jointly trained HMM aligner, or HMM for short, is also unsupervised but it uses a small amount of hand-aligne</context>
<context position="20230" citStr="Liang et al. (2006)" startWordPosition="3284" endWordPosition="3287">me aligner. Some studies leveraged other types of differences between systems to improve MT. For example, de Gispert et al. (2009) combined systems trained with different tokenizations. The theory behind the GIZA++ aligner was due to Brown et al. (1993). The theory of Inversion Transduction Grammars (ITG) was due to Wu (1997). The ITG aligner (Haghighi et al., 2009) used in this work extended the original ITG to handle blocks of words in addition to single words. The use of HMM for word alignment can be traced as far back as to Vogel et al. (1996). The HMM aligner used in this work was due to Liang et al. (2006). It refined the original HMM alignment algorithm by jointly training two HMMs, one in each direction. Furthermore, it used a small amount of supervised data to tweak some high level parameters, although it did not directly use the supervised data in training. 7 Conclusions We explored two methods to exploit complementary alignment algorithms. One is to extract translation rules from all alternative alignments. The other is to combine outputs of different MT systems trained using different aligners. Experiments on two language pairs and two genres show consistent improvements over the baseline</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="1719" citStr="Och and Ney, 2003" startWordPosition="258" endWordPosition="261"> same level of MT performance. Modest improvements were achieved by taking the union of the translation grammars extracted from different alignments. Significant improvements (around 1.0 in BLEU) were achieved by combining outputs of different systems trained with different alignments. The improvements are consistent across languages and genres. 1 Introduction Word alignment plays a central role in training statistical machine translation (SMT) systems since almost all SMT systems extract translation rules from word aligned parallel training data. Until recently, most SMT systems used GIZA++ (Och and Ney, 2003), an unsupervised algorithm, for aligning parallel training data. In recent years, with the availability of human aligned training data, supervised methods (e.g. the ITG aligner (Haghighi et al., 2009)) have become increasingly popular. The main objective of this work is to show the two classes (unsupervised and supervised) of algorithms are complementary and combining them will improve overall system performance. The use of human aligned training data allows supervised methods such as ITG to more accurately align frequent words, such as the alignments of Chinese particles (e.g. “bei”, “de”, e</context>
<context position="5421" citStr="Och and Ney, 2003" startWordPosition="844" endWordPosition="847">on, experiments in previous studies typically used one language pair and one genre (usually newswire), a reduced amount of training data and a phrase based decoder. This paper is organized as follows. Section 2 describes the three alignment algorithms. Section 3 describes the two methods used to combine these aligners to improve MT. The experimental setup used to compare these methods is presented in Section 4. Section 5 shows the results including a discussion. Section 6 discusses related work. Section 7 concludes the paper. 2 Alignment Algorithms We used three aligners in this work: GIZA++ (Och and Ney, 2003), jointly trained HMM (Liang et al., 2006), and ITG (Haghighi et al., 2009). GIZA++ is an unsupervised method based on models 1-5 of Brown et al. (1993). Given a sentence pair e − f, it seeks the alignment a that maximizes the probability P(f, a|e). As in most previous studies using GIZA++, we ran GIZA++ in both directions, from e to f and from f to e, and symmetrized the bidirectional alignments into one, using a method similar to the grow-diagonal-final method described in Och and Ney (2003). We ran GIZA++ up to model 4. The jointly trained HMM aligner, or HMM for short, is also unsupervised</context>
<context position="18876" citStr="Och and Ney (2003)" startWordPosition="3056" endWordPosition="3059">re combinations of partial theories in decoding. However, for computing reasons, we kept the beam size of the decoder constant despite the increase in grammar size, potentially pruning out good theories. Performance could be improved further if larger beam sizes were used. We will leave this to future work. 6 Related Work Ayan and Dorr (2006) described a method to minimize alignment errors by combining alternative alignments into a single alignment for each sentence pair. Deng and Zhou (2009) used the number of extractable translation pairs as the objective function for alignment combination. Och and Ney (2003) and Koehn et al. (2003) used heuristics to merge the bidirectional GIZA++ alignments into a single alignment. Despite differences in algorithms and objective functions in these studies, they all attempted to produce a single final alignment for each sentence pair. In comparison, all alternative alignments are directly used by the translation system in this work. The unioned grammar method in this work is very similar to Gim´enez and M`arquez (2005), which combined phrase pairs extracted from different alignments into a single phrase table. The difference 671 from that work is that our focus i</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="9592" citStr="Papineni et al., 2002" startWordPosition="1530" endWordPosition="1533">ividual systems. 4 Experiment Setup To establish strong baselines, we used a string-totree SMT system (Shen et al., 2008), one of the top performing systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data. The system used large sets of discriminatively tuned features (up to 55,000 on Arabic) inspired by the work of Chiang et al. (2009). To avoid drawing language, genre, and metric specific conclusions, we experimented with two language pairs, Arabic-English and ChineseEnglish, and two genres, newswire and weblog, and report both BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. Systems were tuned to maximize BLEU on the tuning set using a procedure described in Devlin (2009). The sizes of the parallel training corpora are 238M words (target side) for Arabic-English MT and 265M words for Chinese-English. While the majority of the data is publicly available from the Linguistic Data Consortium (LDC), some of the data is available under the DARPA GALE program. Due to the size of the parallel corpora, we divided them into five chunks and aligned them in parallel to save time. Due to its running complexity, we ran ITG only on sentence</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Bing Xiang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Combining outputs from multiple machine translation systems.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the ACL,</booktitle>
<pages>228--235</pages>
<contexts>
<context position="3781" citStr="Rosti et al., 2007" startWordPosition="579" endWordPosition="582">y different aligners. This is motivated by studies that showed that the coverage of translation rules is critical to SMT (DeNeefe et al., 2007). The 667 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 667–673, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics other method is to combine the outputs of different MT systems trained using different aligners. Assuming different systems make independent errors, system combination can generate a better translation than those of individual systems through voting (Rosti et al., 2007). Our work differs from previous work in two ways. Past studies of combining alternative alignments focused on minimizing alignment errors, usually by merging alternative alignments for a sentence pair into a single alignment with the fewest number of incorrect alignment links (Ayan and Dorr, 2006). In contrast, our work is based on the assumption that perfect word alignment is impossible due to the intrinsic difficulty of the problem, and it is more effective to resolve translation ambiguities at later stages of the MT pipeline. A main focus of much previous work on word alignments is on theo</context>
<context position="7922" citStr="Rosti et al. (2007)" startWordPosition="1256" endWordPosition="1259">g different aligners. Due to differences in the alignment algorithms, these systems would produce different hypotheses with independent errors. Combining a diverse set of hypotheses could improve overall system performance. While system combination is a well-known technique, to our knowledge this work is the first to apply it to explicitly exploit complementary alignment algorithms on a large scale. Since system combination is an established technique, here we only briefly discuss our system com1http://code.google.com/p/berkeleyaligner/ 668 bination setup. The basic algorithm was described in Rosti et al. (2007). In this work, we use incremental hypothesis alignment with flexible matching (Rosti et al., 2009) to produce the confusion networks. 10- best lists from all systems are collected first. All 1-best hypotheses for each segment are used as confusion network skeletons, the remaining hypotheses are aligned to the confusion networks, and the resulting networks are connected in parallel into a joint lattice with skeleton specific prior probabilities estimated from the alignment statistics on the initial arcs. This lattice is expanded with an unpruned bigram language model and the system combination</context>
</contexts>
<marker>Rosti, Xiang, Matsoukas, Schwartz, Ayan, Dorr, 2007</marker>
<rawString>Antti-Veikko I. Rosti, Bing Xiang, Spyros Matsoukas, Richard Schwartz, Necip Fazil Ayan, and Bonnie J. Dorr. 2007. Combining outputs from multiple machine translation systems. In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the ACL, pages 228–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Incremental hypothesis alignment with flexible matching for building confusion networks: BBN system description for WMT09 system combination task.</title>
<date>2009</date>
<booktitle>In Proceedings ofthe Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>61--65</pages>
<contexts>
<context position="8021" citStr="Rosti et al., 2009" startWordPosition="1271" endWordPosition="1274">ifferent hypotheses with independent errors. Combining a diverse set of hypotheses could improve overall system performance. While system combination is a well-known technique, to our knowledge this work is the first to apply it to explicitly exploit complementary alignment algorithms on a large scale. Since system combination is an established technique, here we only briefly discuss our system com1http://code.google.com/p/berkeleyaligner/ 668 bination setup. The basic algorithm was described in Rosti et al. (2007). In this work, we use incremental hypothesis alignment with flexible matching (Rosti et al., 2009) to produce the confusion networks. 10- best lists from all systems are collected first. All 1-best hypotheses for each segment are used as confusion network skeletons, the remaining hypotheses are aligned to the confusion networks, and the resulting networks are connected in parallel into a joint lattice with skeleton specific prior probabilities estimated from the alignment statistics on the initial arcs. This lattice is expanded with an unpruned bigram language model and the system combination weights are tuned directly to maximize the BLEU score of the 1-best decoding outputs. Given the tu</context>
<context position="14927" citStr="Rosti et al., 2009" startWordPosition="2399" endWordPosition="2402"> systems. compared with the best baseline system, with little change in TER score. The improvements in BLEU score are statistically significant for Arabic (both genres), but not for Chinese. The improvements in TER are not significant for either language. System combination produces bigger improvements in performance. Compared with the best baseline system, the improvement in BLEU ranges from 0.8 to 1.6 point. There are also noticeable improvements in TER, around 1.0 point. The TER improvements are mostly explained by the hypothesis alignment algorithm which is closely related to TER scoring (Rosti et al., 2009). The results are interesting because all three baseline systems (GIZA++, HMM and ITG) are identical except for the word alignments used in rule extraction. The results confirm that the aligners are indeed complementary, as we conjectured earlier. Also, the four-system combination yields consistent gains over the three-system combination, suggesting that the system using the unioned grammar is somewhat complementary to the three baseline systems. The statistical test indicates that both the three and four system combinations are significantly better than the single best alignment system for al</context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2009</marker>
<rawString>Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2009. Incremental hypothesis alignment with flexible matching for building confusion networks: BBN system description for WMT09 system combination task. In Proceedings ofthe Fourth Workshop on Statistical Machine Translation, pages 61–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08: HLT,</booktitle>
<pages>577--585</pages>
<contexts>
<context position="4745" citStr="Shen et al., 2008" startWordPosition="734" endWordPosition="737">ion that perfect word alignment is impossible due to the intrinsic difficulty of the problem, and it is more effective to resolve translation ambiguities at later stages of the MT pipeline. A main focus of much previous work on word alignments is on theoretical aspects of the proposed algorithms. In contrast, the nature of this work is purely empirical. Our system was trained on a large amount of training data and evaluated on multiple languages (Chinese-to-English and Arabic-to-English) and multiple genres (newswire and weblog). Furthermore, we used a state of the art string-to-tree decoder (Shen et al., 2008) to establish the strongest possible baseline. In comparison, experiments in previous studies typically used one language pair and one genre (usually newswire), a reduced amount of training data and a phrase based decoder. This paper is organized as follows. Section 2 describes the three alignment algorithms. Section 3 describes the two methods used to combine these aligners to improve MT. The experimental setup used to compare these methods is presented in Section 4. Section 5 shows the results including a discussion. Section 6 discusses related work. Section 7 concludes the paper. 2 Alignmen</context>
<context position="9091" citStr="Shen et al., 2008" startWordPosition="1447" endWordPosition="1450"> bigram language model and the system combination weights are tuned directly to maximize the BLEU score of the 1-best decoding outputs. Given the tuned system combination weights, a 300-best list is extracted from the lattice, the hypotheses are rescored using an unpruned 5-gram language model, and a second set of system combination weights is tuned to maximize the BLEU score of the 1-best hypothesis of the re-scored 300-best list. The same rescoring step is also applied to the outputs of individual systems. 4 Experiment Setup To establish strong baselines, we used a string-totree SMT system (Shen et al., 2008), one of the top performing systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data. The system used large sets of discriminatively tuned features (up to 55,000 on Arabic) inspired by the work of Chiang et al. (2009). To avoid drawing language, genre, and metric specific conclusions, we experimented with two language pairs, Arabic-English and ChineseEnglish, and two genres, newswire and weblog, and report both BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. Systems were tuned to maximize BLEU on the tuning set using </context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In Proceedings ofACL-08: HLT, pages 577–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciula</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="9622" citStr="Snover et al., 2006" startWordPosition="1536" endWordPosition="1539">tup To establish strong baselines, we used a string-totree SMT system (Shen et al., 2008), one of the top performing systems in the NIST 2009 MT evaluation, and trained it with very large amounts of parallel and language model data. The system used large sets of discriminatively tuned features (up to 55,000 on Arabic) inspired by the work of Chiang et al. (2009). To avoid drawing language, genre, and metric specific conclusions, we experimented with two language pairs, Arabic-English and ChineseEnglish, and two genres, newswire and weblog, and report both BLEU (Papineni et al., 2002) and TER (Snover et al., 2006) scores. Systems were tuned to maximize BLEU on the tuning set using a procedure described in Devlin (2009). The sizes of the parallel training corpora are 238M words (target side) for Arabic-English MT and 265M words for Chinese-English. While the majority of the data is publicly available from the Linguistic Data Consortium (LDC), some of the data is available under the DARPA GALE program. Due to the size of the parallel corpora, we divided them into five chunks and aligned them in parallel to save time. Due to its running complexity, we ran ITG only on sentences with 60 or fewer words. For </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciula, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciula, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, pages 223–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillman</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In The 16th International Conference on Computational Linguistics,</booktitle>
<pages>836--841</pages>
<contexts>
<context position="20164" citStr="Vogel et al. (1996)" startWordPosition="3270" endWordPosition="3273"> leverage alignments of different lexical units produced by the same aligner. Some studies leveraged other types of differences between systems to improve MT. For example, de Gispert et al. (2009) combined systems trained with different tokenizations. The theory behind the GIZA++ aligner was due to Brown et al. (1993). The theory of Inversion Transduction Grammars (ITG) was due to Wu (1997). The ITG aligner (Haghighi et al., 2009) used in this work extended the original ITG to handle blocks of words in addition to single words. The use of HMM for word alignment can be traced as far back as to Vogel et al. (1996). The HMM aligner used in this work was due to Liang et al. (2006). It refined the original HMM alignment algorithm by jointly training two HMMs, one in each direction. Furthermore, it used a small amount of supervised data to tweak some high level parameters, although it did not directly use the supervised data in training. 7 Conclusions We explored two methods to exploit complementary alignment algorithms. One is to extract translation rules from all alternative alignments. The other is to combine outputs of different MT systems trained using different aligners. Experiments on two language p</context>
</contexts>
<marker>Vogel, Ney, Tillman, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillman. 1996. HMM-based word alignment in statistical translation. In The 16th International Conference on Computational Linguistics, pages 836–841.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="6360" citStr="Wu, 1997" startWordPosition="1012" endWordPosition="1013"> e to f and from f to e, and symmetrized the bidirectional alignments into one, using a method similar to the grow-diagonal-final method described in Och and Ney (2003). We ran GIZA++ up to model 4. The jointly trained HMM aligner, or HMM for short, is also unsupervised but it uses a small amount of hand-aligned data to tweak a few high level parameters. Low level parameters are estimated in an unsupervised manner like GIZA++. The ITG aligner is a supervised method whose parameters are tuned to optimize alignment accuracy on hand-aligned data. It uses the inversion transduction grammar (ITG) (Wu, 1997) to narrow the space of possible alignments. Since the ITG aligner uses features extracted from HMM alignments, HMM was run as a prepossessing step in our experiments. Both the HMM and ITG aligners are publicly available1. 3 Methods of Combining Alternative Alignments for MT We explored two methods of combining alternative alignments for MT. One is to extract translation rules from the three alternative alignments and take the union of the three sets of rules as the single translation grammar. Procedurally, this is done by concatenating the alignment files before extracting translation rules. </context>
<context position="19938" citStr="Wu (1997)" startWordPosition="3228" endWordPosition="3229">, which combined phrase pairs extracted from different alignments into a single phrase table. The difference 671 from that work is that our focus is to leverage complementary alignment algorithms, while theirs was to leverage alignments of different lexical units produced by the same aligner. Some studies leveraged other types of differences between systems to improve MT. For example, de Gispert et al. (2009) combined systems trained with different tokenizations. The theory behind the GIZA++ aligner was due to Brown et al. (1993). The theory of Inversion Transduction Grammars (ITG) was due to Wu (1997). The ITG aligner (Haghighi et al., 2009) used in this work extended the original ITG to handle blocks of words in addition to single words. The use of HMM for word alignment can be traced as far back as to Vogel et al. (1996). The HMM aligner used in this work was due to Liang et al. (2006). It refined the original HMM alignment algorithm by jointly training two HMMs, one in each direction. Furthermore, it used a small amount of supervised data to tweak some high level parameters, although it did not directly use the supervised data in training. 7 Conclusions We explored two methods to exploi</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>