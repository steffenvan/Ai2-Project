<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003251">
<title confidence="0.999086">
A Simplex Armijo Downhill Algorithm for
Optimizing Statistical Machine Translation Decoding Parameters
</title>
<author confidence="0.948844">
Bing Zhao
</author>
<affiliation confidence="0.49194">
IBM T.J. Watson Research
</affiliation>
<email confidence="0.95892">
zhaob@us.ibm.com
</email>
<sectionHeader confidence="0.98123" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995893428571428">
We propose a variation of simplex-downhill algo-
rithm specifically customized for optimizing param-
eters in statistical machine translation (SMT) de-
coder for better end-user automatic evaluation met-
ric scores for translations, such as versions of BLEU,
TER and mixtures of them. Traditional simplex-
downhill has the advantage of derivative-free com-
putations of objective functions, yet still gives satis-
factory searching directions in most scenarios. This
is suitable for optimizing translation metrics as they
are not differentiable in nature. On the other hand,
Armijo algorithm usually performs line search ef-
ficiently given a searching direction. It is a deep
hidden fact that an efficient line search method
will change the iterations of simplex, and hence
the searching trajectories. We propose to embed
the Armijo inexact line search within the simplex-
downhill algorithm. We show, in our experiments,
the proposed algorithm improves over the widely-
applied Minimum Error Rate training algorithm for
optimizing machine translation parameters.
</bodyText>
<sectionHeader confidence="0.998974" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999868913043478">
A simple log-linear form is used in SMT systems to
combine feature functions designed for identifying good
translations, with proper weights. However, we often ob-
serve that tuning the weight associated with each feature
function is indeed not easy. Starting from a N-Best list
generated from a translation decoder, an optimizer, such
as Minimum Error Rate (MER) (Och, 2003) training, pro-
poses directions to search for a better weight-vector A to
combine feature functions. With a given A, the N-Best
list is re-ranked, and newly selected top-1 hypothesis will
be used to compute the final MT evaluation metric score.
Due to limited variations in the N-Best list, the nature of
ranking, and more importantly, the non-differentiable ob-
jective functions used for MT (such as BLEU (Papineni et
al., 2002)), one often found only local optimal solutions
to A, with no clue to walk out of the riddles.
Automatic evaluation metrics of translations known so
far are designed to simulate human judgments of trans-
lation qualities especially in the aspects of fluency and
adequacy; they are not differentiable in nature. Simplex-
downhill algorithm (Nelder and Mead, 1965) does not
require the objective function to be differentiable, and
this is well-suited for optimizing such automatic met-
</bodyText>
<page confidence="0.986069">
21
</page>
<subsectionHeader confidence="0.828224">
Shengyuan Chen
</subsectionHeader>
<bodyText confidence="0.982749666666667">
IBM T.J. Watson Research
sychen@us.ibm.com
rics. MER searches each dimension independently in a
greedy fashion, while simplex algorithms consider the
movement of all the dimensions at the same time via
three basic operations: reflection, expansion and contrac-
tion, to shrink the simplex iteratively to some local op-
timal. Practically, as also shown in our experiments, we
observe simplex-downhill usually gives better solutions
over MER with random restarts for both, and reaches
the solutions much faster in most of the cases. How-
ever, simplex-downhill algorithm is an unconstrained al-
gorithm, which does not leverage any domain knowledge
in machine translation. Indeed, the objective function
used in SMT is shown to be a piece-wise linear prob-
lem in (Papineni et al., 1998), and this motivated us to
embed an inexact line search with Armijo rules (Armijo,
1966) within a simplex to guide the directions for itera-
tive expansion, reflection and contraction operations. Our
proposed modification to the simplex algorithm is an em-
bedded backtracking line search, and the algorithm’s con-
vergence (McKinnon, 1999) still holds, though it is con-
figured specially here for optimizing automatic machine
translation evaluation metrics.
The remainder of the paper is structured as follow: we
briefly introduce the optimization problem in section 2;
in section 3, our proposed simplex Armijo downhill al-
gorithm is explained in details; experiments comparing
relevant algorithms are in section 4; the conclusions and
discussions are given in section 5.
</bodyText>
<sectionHeader confidence="0.982383" genericHeader="introduction">
2 Notations
</sectionHeader>
<bodyText confidence="0.997819">
Let {(ei,k, �ci,k, Si,k), k E [1, K]} be the K-Best list
for a given input source sentence fi in a development
dataset containing N sentences. ei,k is a English hy-
pothesis at the rank of k; ci,k is a cost vector — a
vector of feature function values, with M dimensions:
ci,k = (ci,k,1, ci,k,2 ... ci,k,M); Si,k is a sentence-level
translation metric general counter (e.g. ngram hits for
BLEU, or specific types of errors counted in TER, etc.)
for the hypothesis. Let A� be the weight-vector, so that the
cost of ei,k is an inner product: C(ei,k) = A · ci,k. The
optimization process is then defined as below:
</bodyText>
<equation confidence="0.925120777777778">
k*(wrt i) = arg min
k
A* = arg min
A
A · �ci,k (1)
N
Eval( Si,k*), (2)
i=1
Proceedings of NAACL HLT 2009: Short Papers, pages 21–24,
</equation>
<bodyText confidence="0.98219">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
where Eval is an evaluation Error metric for MT, presum-
ing the smaller the better internal to an optimizer; in our
case, we decompose BLEU, TER (Snover et al., 2006)
and (TER-BLEU)/2.0 into corresponding specific coun-
ters for each sentence, cache the intermediate counts in
Si,k, and compute final corpus-level scores using the sum
of all counters; Eqn. 1 is simply a ranking process, with
regard to the source sentence i, to select the top-1 hypoth-
esis, indexed by k* with the lowest cost C(ei,k.) given
current A; Eqn. 2 is a scoring process of computing the fi-
nal corpus-level MT metrics via the intermediate counters
collected from each top1 hypothesis selected in Eqn. 1.
Iteratively, the optimizer picks up an initial guess of A�
using current K-Best list, and reaches a solution k, and
then updates the event space with new K-Best list gener-
ated using a decoder with A*; it iterates until there is little
change to final scores (a local optimal k is reached).
</bodyText>
<sectionHeader confidence="0.99554" genericHeader="method">
3 Simplex Armijo Downhill
</sectionHeader>
<bodyText confidence="0.999965125">
We integrate the Armijo line search into the simplex-
downhill algorithm in Algorithm 1. We take the reflec-
tion, expansion and contractions steps1 from the simplex-
downhill algorithm to find a A&apos; to form a direction A&apos; −
AM+1 as the input to the Armijo algorithm, which in
turn updates A&apos; to A+ as the input for the next iteration
of simplex-downhill algorithm. The combined algorithm
iterates until the simplex shrink sufficiently within a pre-
defined threshold. Via Armijo algorithm, we avoid the
expensive shrink step, and slightly speed up the search-
ing process of simplex-downhill algorithm. Also, the
simplex-downhill algorithm usually provides a descend
direction to start the Armijo algorithm efficiently. Both
algorithms are well known to converge. Moreover, the
new algorithm changes the searching path of the tradi-
tional simplex-downhill algorithm, and usually leads to
better local minimal solutions.
To be more specific, Algorithm 1 clearly conducts an
iterative search in the while loop from line 3 to line 28
until the stopping criteria on line 3 is satisfied. Within
the loop, the algorithm can be logically divided into two
major parts: from line 4 to line 24, it does the simplex-
downhill algorithm; the rest does the Armijo search. The
simplex-downhill algorithm looks for a lower point by
trying the reflection (line 6), expansion (line 10) and con-
traction (line 17) points in the order showed in the al-
gorithm, which turned out to be very efficient. In rare
cases, especially for many dimensions (for instance, 10
to 30 dimensions, as in typical statistical machine trans-
lation decoders) none of these three points are not lower
enough (line 21), we adapt other means to select lower
points. We avoid the traditional expensive shrink pro-
</bodyText>
<footnote confidence="0.9115405">
1These three basic operations are generally based on heuristics in
the traditional simplex-downhill algorithm.
</footnote>
<construct confidence="0.264731">
Algorithm 1 Simplex Armijo Downhill Algorithm
</construct>
<listItem confidence="0.937892193548387">
1: a �-- 1,y �-- 2,p �-- 0.5,0 = 77 �-- 0.9,e 1.0 x
10−6
2: initilize (A1, · · · , AM+1)
3: while �M+1
i,j=1 11Ai − Aj112 &lt; e do
4: sort Ai ascend
5: Ao N Em, Ai,
6: Ar Ao + a(Ao − AM+1)
7: if S(A1) &lt; S(Ar) &lt; S(AM) then
8: A&apos; �--Ar —
9: else if S(Ar) &lt; S(A1) then
10: Ae �-- Ao + y(Ao − AM+1)
11: if S(Ae) &lt; S(Ar) then
12: A&apos; Ae
13: else
14: A&apos; Ar
15: end if
16: else if S(Ar) &gt; S(AM) then
17: Ac AM+1 + p(Ao − AM+1)
18: if S(Ac) &lt; S(Ar) then
19: A&apos; �-- Ac
20: else
21: try points on two additional lines for A&apos;
22: end if
23: end if
24: d n A&apos; − AM+1
25: 0* �-- maxk=0,1,···//,,�40{0k |S(AM+1 + 0kd) −
S(AM+1) &lt; −7711 d112Nk}
26: A+ = AM+1 + 0* * d
27: replace AM+1 with A+
28: end while
</listItem>
<bodyText confidence="0.999942555555556">
cedure, which is not favorable for our machine transla-
tion problem neither. Instead we try points on different
search lines. Specifically, we test two additional points
on the line through the highest point and the lowest point,
and on the line through the reflection point and the low-
est point. It worth pointing out that there are many vari-
ants of simplex-downhill algorithm 2, and the implemen-
tation described above showed that the algorithm can suc-
cessfully select a lower A&apos; in many of our translation test
cases to enable the simplex move to a better region of lo-
cal optimals in the high-dimension space. Our proposed
embedded Armijo algorithm, in the second part of the
loop (line 25), continues to refine the search processes.
By backtracking on the segment from A&apos; to AM+1, the
Armijo algorithm does bring even lower points in our
many test cases. With the new lower A&apos; found by the
Armijo algorithm, the simplex-downhill algorithm starts
over again. The parameters in line 1 we used are com-
</bodyText>
<footnote confidence="0.981665">
2One of such effective tricks for the baseline simplex algorithms
can be found here: http://paula.univ.gda.pl/∼dokgrk/simplex.html (link
tested to be valid as of 04/03/2009)
</footnote>
<page confidence="0.997097">
22
</page>
<figure confidence="0.999813454545455">
0.43
0.428
0.426
0.424
0.422
0.42
0.418
0.416
0.414
0.412
0.41
Optimizing (1-TER)
MER
Simplex
Simplex-Arm
0.375
MER
SIMPLEX
SIMPLEX-ARM
Optimizing IBM BLEU
0.393
0.391
0.389
0.387
0.385
0.383
0.381
0.379
0.377
1 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163
Random Seeds
1 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163
Random Seeds
(a) Optimizing Toward Metric (1-TER) (b) Optimizing Toward Metric IBM BLEU
0.413
0.408
0.403
0.398
0.393
0.388
Optimizing NIST-BLEU
MER
Simplex-Arm
Simplex
0.418
0.416
0.414
0.412
0.408
0.406
0.404
0.402
0.41
0.4
Optimizing (1-(TER-BLEU))/2.0
MER
Simplex-Armijo
Simplex
ER
Random Seeds
1 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163
(c) Optimizing Toward Metric NIST BLEU
81 ER
1 10 19 28 37 46 55 64 73 82 91 100 109 118 127 136 145 154 163
Random Seeds
(d) Optimizing Toward Metric (1-(TER-NISTBLEU))/2
</figure>
<figureCaption confidence="0.9945764">
Figure 1: On devset, comparing MER, Simplex Downhill, and Simplex Armijo Downhill Algorithms on different Translation
Metrics including TER, IBM BLEU, NIST BLEU, and the combination of TER &amp; NISTBLEU. Empirically, we found optimizing
toward (TER-NISTBLEU)/2 gave more reliable solutions on unseen test data. All optimizations are with internal random restarts,
and were run from the same 164 random seeds with multiple iterations until convergence. Simplex Armijo downhill algorithm is
often better than Simplex-downhill algorithm, and is also much better than MER algorithm.
</figureCaption>
<bodyText confidence="0.999962833333333">
mon ones from literatures and can be tuned further. We
find that the combination not only accelerates the search-
ing process to reach similar solutions to the baseline sim-
plex algorithm, but also changes the searching trajectory
significantly, leading to even better solutions for machine
translation test cases as shown in our experiments.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999705888888889">
Our experiments were carried out on Chinese-English
using our syntax-based decoder (Zhao and Al-Onaizan,
2008), a chart-based decoder with tree-to-string 3 gram-
mar, in GALE P3/P3.5 evaluations. There were 10 fea-
ture functions computed for each hypothesis, and N-best
list size is up to 2,000 per sentence.
Given a weight-vector ao, our decoder outputs N-Best
unique hypotheses for each input source sentence; the
event space is then built, and the optimizer is called with
</bodyText>
<footnote confidence="0.574444">
3Source shallow constituency tree to target-string rules with vari-
ables, forming a probabilistic synchronous context free grammar.
</footnote>
<bodyText confidence="0.999401444444445">
a number of random restarts. We used 164 seeds4 with
a small perturbation of three random dimensions in A0.
The best al is selected under a given optimizing metric,
and is fed back to the decoder to re-generate a new N-Best
list. Event space is enriched by merging the newly gen-
erated N-Best list, and the optimization runs again. This
process is iteratively carried out until there are no more
improvements observed on a development data set.
We select three different metrics: NIST BLEU, IBM
BLEU, TER, and a combination of (TER-NISTBLEU)/2
as our optimization goal. On the devset with four refer-
ences using MT06-NIST text part data, we carried out the
optimizations as shown in Figure 1. Over these 164 ran-
dom restarts in each of the optimizers over the four con-
figurations shown in Figure 1, we found most of the time
simplex algorithms perform better than MER in these
configurations. Simplex algorithm considers to move all
the dimensions at the same time, instead of fixing other
</bodyText>
<footnote confidence="0.981218">
4There are 41 servers used in our experiments, four CPUs each.
</footnote>
<page confidence="0.998575">
23
</page>
<tableCaption confidence="0.975347">
Table 1: Comparing different optimization algorithms on the held-out speech data, measured on document-average TER, IBMBLEU
and (TER-IBMBLEU)/2.0, which were used in GALE P3/3.5 Chinese-English evaluations in Rosetta consortium.
</tableCaption>
<table confidence="0.9990298">
Setup Broadcast News &amp; Conversation Data
BLEUr4n4 TER (TER-BLEUr4n4)/2
MER 37.36 51.12 6.88
Simplex-Downhill 37.71 50.10 6.19
Simplex Armijo Downhill 38.15 49.92 5.89
</table>
<bodyText confidence="0.999725717948718">
dimensions and carrying out a greedy search for one di-
mension as in MER. With Armijo line search embedded
in the simplex-downhill algorithm, the algorithm has a
better chance to walk out of the local optimal, via chang-
ing the shrinking trajectory of the simplex using a line
search to identify the best steps to move. Shown in Fig-
ure 1, the solutions from simplex Armijo downhill out-
performed the other two under four different optimiza-
tion metrics for most of the time. Empirically, we found
optimizing toward (TER-NISTBLEU)/2 gives marginally
better results on final TER and IBM BLEU.
On our devset, we also observed that whenever opti-
mizing toward TER (or mixture of TER &amp; BLEU), MER
does not seem to move much, as shown in Figure 1-(a)
and Figure 1-(d). However, on BLEU (NIST or IBM ver-
sion), MER does move reasonably with random restarts.
Comparing TER with BLEU, we think the “shift” counter
in TER is a confusing factor to the optimizer, and cannot
be computed accurately in the current TER implementa-
tions. Also, our random perturbations to the seeds used
in restarts might be relatively weaker for MER compar-
ing to our simplex algorithms, though they use exactly the
same random seeds. Another fact we found is optimizing
toward corpus-level (TER-NISTBLEU)/2 seems to give
better performances on most of our unseen datasets, and
we choose this as optimization goal to illustrate the algo-
rithms’ performances on our unseen testset.
Our test set is the held-out speech part data5. We
optimize toward corpus-level (TER-NISTBLEU)/2 using
devset, and apply the weight-vector on testset to evalu-
ate TER, IBMBLEUr4n4, and a simple combination of
(TER-IBMBLEU)/2.0 to compare different algorithms’
strengths6. Shown in Table 1, simplex Armijo downhill
performs the best (though not statistically significant),
and the improvements are consistent in multiple runs in
our observations. Also, given limited resources, such as
number of machines and fixed time schedule, both sim-
plex algorithms can run with more random restarts than
MER, and can potentially reach better solutions.
</bodyText>
<footnote confidence="0.966009">
5Transcriptions of broadcast news and broadcast conversion in
MT06; there are 565 sentences, or 11,691 words after segmentation.
6We choose document-average metrics to show here simply because
they were chosen/required in our GALE P3/P3.5 evaluations for both
Arabic-English and Chinese-English individual systems and syscombs.
</footnote>
<sectionHeader confidence="0.996777" genericHeader="conclusions">
5 Conclusions and Discussions
</sectionHeader>
<bodyText confidence="0.999990692307692">
We proposed a simplex Armijo downhill algorithm
for improved optimization solutions over the standard
simplex-downhill and the widely-applied MER. The
Armijo algorithm changes the trajectories for the simplex
to shrink to a local optimal, and empowers the algorithm a
better chance to walk out of the riddled error surface com-
puted by automatic MT evaluation metrics. We showed,
empirically, such utilities under several evaluation met-
rics including BLEU, TER, and a mixture of them. In the
future, we plan to integrate domain specific heuristics via
approximated derivatives of evaluation metrics or mix-
ture of them to guide the optimizers move toward better
solutions for simplex-downhill algorithms.
</bodyText>
<sectionHeader confidence="0.999109" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999311862068966">
L. Armijo. 1966. Minimization of functions having lipschitz
continuous first partial derivatives. Pacific Journal of mathe-
matics, 6:1–3.
K.I.M. McKinnon. 1999. Convergence of the nelder-mead sim-
plex method to a non-stationary point. SIAM J Optimization,
9:148–158.
J.A. Nelder and R. Mead. 1965. A simplex method for function
minimization. The Computer Journal, 7:308–313.
Franz J. Och. 2003. Minimum error rate training for statistical
machine translation. In Proc. of the 41st Annual Meeting of
the Association for Computational Linguistics, Japan, Sap-
poro, July.
Kishore Papineni, Salim Roukos, and Todd Ward. 1998. Maxi-
mum likelihood and discriminative training of direct transla-
tion models. In Proceedings of the 1998 IEEE International
Conference on Acoustics, Speech &amp; Signal Processing, vol-
ume 1, pages 189–192, Seattle, May.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing
Zhu. 2002. Bleu: a method for automatic evaluation of ma-
chine translation. In Proc. of the 40th Annual Conf. of the
Association for Computational Linguistics (ACL 02), pages
311–318, Philadelphia, PA, July.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Mic-
ciulla, and John Makhoul. 2006. A study of translation edit
rate with targeted human annotation. In AMTA.
Bing Zhao and Yaser Al-Onaizan. 2008. Generalizing local
and non-local word-reordering patterns for syntax-based ma-
chine translation. In Conference on Empirical Methods in
Natural Language Processing (EMNLP).
</reference>
<page confidence="0.999169">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981395">
<title confidence="0.9998065">A Simplex Armijo Downhill Algorithm Optimizing Statistical Machine Translation Decoding Parameters</title>
<author confidence="0.999871">Bing Zhao</author>
<affiliation confidence="0.988019">IBM T.J. Watson Research</affiliation>
<email confidence="0.998829">zhaob@us.ibm.com</email>
<abstract confidence="0.999755136363637">We propose a variation of simplex-downhill algorithm specifically customized for optimizing parameters in statistical machine translation (SMT) decoder for better end-user automatic evaluation metric scores for translations, such as versions of BLEU, TER and mixtures of them. Traditional simplexdownhill has the advantage of derivative-free computations of objective functions, yet still gives satisfactory searching directions in most scenarios. This is suitable for optimizing translation metrics as they are not differentiable in nature. On the other hand, Armijo algorithm usually performs line search efficiently given a searching direction. It is a deep hidden fact that an efficient line search method will change the iterations of simplex, and hence the searching trajectories. We propose to embed the Armijo inexact line search within the simplexdownhill algorithm. We show, in our experiments, the proposed algorithm improves over the widelyapplied Minimum Error Rate training algorithm for optimizing machine translation parameters.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Armijo</author>
</authors>
<title>Minimization of functions having lipschitz continuous first partial derivatives.</title>
<date>1966</date>
<journal>Pacific Journal of mathematics,</journal>
<pages>6--1</pages>
<contexts>
<context position="3384" citStr="Armijo, 1966" startWordPosition="516" endWordPosition="517"> contraction, to shrink the simplex iteratively to some local optimal. Practically, as also shown in our experiments, we observe simplex-downhill usually gives better solutions over MER with random restarts for both, and reaches the solutions much faster in most of the cases. However, simplex-downhill algorithm is an unconstrained algorithm, which does not leverage any domain knowledge in machine translation. Indeed, the objective function used in SMT is shown to be a piece-wise linear problem in (Papineni et al., 1998), and this motivated us to embed an inexact line search with Armijo rules (Armijo, 1966) within a simplex to guide the directions for iterative expansion, reflection and contraction operations. Our proposed modification to the simplex algorithm is an embedded backtracking line search, and the algorithm’s convergence (McKinnon, 1999) still holds, though it is configured specially here for optimizing automatic machine translation evaluation metrics. The remainder of the paper is structured as follow: we briefly introduce the optimization problem in section 2; in section 3, our proposed simplex Armijo downhill algorithm is explained in details; experiments comparing relevant algorit</context>
</contexts>
<marker>Armijo, 1966</marker>
<rawString>L. Armijo. 1966. Minimization of functions having lipschitz continuous first partial derivatives. Pacific Journal of mathematics, 6:1–3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K I M McKinnon</author>
</authors>
<title>Convergence of the nelder-mead simplex method to a non-stationary point.</title>
<date>1999</date>
<journal>SIAM J Optimization,</journal>
<pages>9--148</pages>
<contexts>
<context position="3630" citStr="McKinnon, 1999" startWordPosition="552" endWordPosition="553">uch faster in most of the cases. However, simplex-downhill algorithm is an unconstrained algorithm, which does not leverage any domain knowledge in machine translation. Indeed, the objective function used in SMT is shown to be a piece-wise linear problem in (Papineni et al., 1998), and this motivated us to embed an inexact line search with Armijo rules (Armijo, 1966) within a simplex to guide the directions for iterative expansion, reflection and contraction operations. Our proposed modification to the simplex algorithm is an embedded backtracking line search, and the algorithm’s convergence (McKinnon, 1999) still holds, though it is configured specially here for optimizing automatic machine translation evaluation metrics. The remainder of the paper is structured as follow: we briefly introduce the optimization problem in section 2; in section 3, our proposed simplex Armijo downhill algorithm is explained in details; experiments comparing relevant algorithms are in section 4; the conclusions and discussions are given in section 5. 2 Notations Let {(ei,k, �ci,k, Si,k), k E [1, K]} be the K-Best list for a given input source sentence fi in a development dataset containing N sentences. ei,k is a Eng</context>
</contexts>
<marker>McKinnon, 1999</marker>
<rawString>K.I.M. McKinnon. 1999. Convergence of the nelder-mead simplex method to a non-stationary point. SIAM J Optimization, 9:148–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Nelder</author>
<author>R Mead</author>
</authors>
<title>A simplex method for function minimization.</title>
<date>1965</date>
<journal>The Computer Journal,</journal>
<pages>7--308</pages>
<contexts>
<context position="2382" citStr="Nelder and Mead, 1965" startWordPosition="358" endWordPosition="361">d top-1 hypothesis will be used to compute the final MT evaluation metric score. Due to limited variations in the N-Best list, the nature of ranking, and more importantly, the non-differentiable objective functions used for MT (such as BLEU (Papineni et al., 2002)), one often found only local optimal solutions to A, with no clue to walk out of the riddles. Automatic evaluation metrics of translations known so far are designed to simulate human judgments of translation qualities especially in the aspects of fluency and adequacy; they are not differentiable in nature. Simplexdownhill algorithm (Nelder and Mead, 1965) does not require the objective function to be differentiable, and this is well-suited for optimizing such automatic met21 Shengyuan Chen IBM T.J. Watson Research sychen@us.ibm.com rics. MER searches each dimension independently in a greedy fashion, while simplex algorithms consider the movement of all the dimensions at the same time via three basic operations: reflection, expansion and contraction, to shrink the simplex iteratively to some local optimal. Practically, as also shown in our experiments, we observe simplex-downhill usually gives better solutions over MER with random restarts for </context>
</contexts>
<marker>Nelder, Mead, 1965</marker>
<rawString>J.A. Nelder and R. Mead. 1965. A simplex method for function minimization. The Computer Journal, 7:308–313.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
</authors>
<title>Minimum error rate training for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Japan, Sapporo,</location>
<contexts>
<context position="1597" citStr="Och, 2003" startWordPosition="233" endWordPosition="234">ct line search within the simplexdownhill algorithm. We show, in our experiments, the proposed algorithm improves over the widelyapplied Minimum Error Rate training algorithm for optimizing machine translation parameters. 1 Introduction A simple log-linear form is used in SMT systems to combine feature functions designed for identifying good translations, with proper weights. However, we often observe that tuning the weight associated with each feature function is indeed not easy. Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate (MER) (Och, 2003) training, proposes directions to search for a better weight-vector A to combine feature functions. With a given A, the N-Best list is re-ranked, and newly selected top-1 hypothesis will be used to compute the final MT evaluation metric score. Due to limited variations in the N-Best list, the nature of ranking, and more importantly, the non-differentiable objective functions used for MT (such as BLEU (Papineni et al., 2002)), one often found only local optimal solutions to A, with no clue to walk out of the riddles. Automatic evaluation metrics of translations known so far are designed to simu</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz J. Och. 2003. Minimum error rate training for statistical machine translation. In Proc. of the 41st Annual Meeting of the Association for Computational Linguistics, Japan, Sapporo, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
</authors>
<title>Maximum likelihood and discriminative training of direct translation models.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1998 IEEE International Conference on Acoustics, Speech &amp; Signal Processing,</booktitle>
<volume>1</volume>
<pages>189--192</pages>
<location>Seattle,</location>
<contexts>
<context position="3296" citStr="Papineni et al., 1998" startWordPosition="499" endWordPosition="502">ment of all the dimensions at the same time via three basic operations: reflection, expansion and contraction, to shrink the simplex iteratively to some local optimal. Practically, as also shown in our experiments, we observe simplex-downhill usually gives better solutions over MER with random restarts for both, and reaches the solutions much faster in most of the cases. However, simplex-downhill algorithm is an unconstrained algorithm, which does not leverage any domain knowledge in machine translation. Indeed, the objective function used in SMT is shown to be a piece-wise linear problem in (Papineni et al., 1998), and this motivated us to embed an inexact line search with Armijo rules (Armijo, 1966) within a simplex to guide the directions for iterative expansion, reflection and contraction operations. Our proposed modification to the simplex algorithm is an embedded backtracking line search, and the algorithm’s convergence (McKinnon, 1999) still holds, though it is configured specially here for optimizing automatic machine translation evaluation metrics. The remainder of the paper is structured as follow: we briefly introduce the optimization problem in section 2; in section 3, our proposed simplex A</context>
</contexts>
<marker>Papineni, Roukos, Ward, 1998</marker>
<rawString>Kishore Papineni, Salim Roukos, and Todd Ward. 1998. Maximum likelihood and discriminative training of direct translation models. In Proceedings of the 1998 IEEE International Conference on Acoustics, Speech &amp; Signal Processing, volume 1, pages 189–192, Seattle, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of the 40th Annual Conf. of the Association for Computational Linguistics (ACL 02),</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="2024" citStr="Papineni et al., 2002" startWordPosition="301" endWordPosition="304">g the weight associated with each feature function is indeed not easy. Starting from a N-Best list generated from a translation decoder, an optimizer, such as Minimum Error Rate (MER) (Och, 2003) training, proposes directions to search for a better weight-vector A to combine feature functions. With a given A, the N-Best list is re-ranked, and newly selected top-1 hypothesis will be used to compute the final MT evaluation metric score. Due to limited variations in the N-Best list, the nature of ranking, and more importantly, the non-differentiable objective functions used for MT (such as BLEU (Papineni et al., 2002)), one often found only local optimal solutions to A, with no clue to walk out of the riddles. Automatic evaluation metrics of translations known so far are designed to simulate human judgments of translation qualities especially in the aspects of fluency and adequacy; they are not differentiable in nature. Simplexdownhill algorithm (Nelder and Mead, 1965) does not require the objective function to be differentiable, and this is well-suited for optimizing such automatic met21 Shengyuan Chen IBM T.J. Watson Research sychen@us.ibm.com rics. MER searches each dimension independently in a greedy f</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proc. of the 40th Annual Conf. of the Association for Computational Linguistics (ACL 02), pages 311–318, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In AMTA.</booktitle>
<contexts>
<context position="5060" citStr="Snover et al., 2006" startWordPosition="796" endWordPosition="799">(e.g. ngram hits for BLEU, or specific types of errors counted in TER, etc.) for the hypothesis. Let A� be the weight-vector, so that the cost of ei,k is an inner product: C(ei,k) = A · ci,k. The optimization process is then defined as below: k*(wrt i) = arg min k A* = arg min A A · �ci,k (1) N Eval( Si,k*), (2) i=1 Proceedings of NAACL HLT 2009: Short Papers, pages 21–24, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics where Eval is an evaluation Error metric for MT, presuming the smaller the better internal to an optimizer; in our case, we decompose BLEU, TER (Snover et al., 2006) and (TER-BLEU)/2.0 into corresponding specific counters for each sentence, cache the intermediate counts in Si,k, and compute final corpus-level scores using the sum of all counters; Eqn. 1 is simply a ranking process, with regard to the source sentence i, to select the top-1 hypothesis, indexed by k* with the lowest cost C(ei,k.) given current A; Eqn. 2 is a scoring process of computing the final corpus-level MT metrics via the intermediate counters collected from each top1 hypothesis selected in Eqn. 1. Iteratively, the optimizer picks up an initial guess of A� using current K-Best list, an</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Yaser Al-Onaizan</author>
</authors>
<title>Generalizing local and non-local word-reordering patterns for syntax-based machine translation.</title>
<date>2008</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="11590" citStr="Zhao and Al-Onaizan, 2008" startWordPosition="1928" endWordPosition="1931">iple iterations until convergence. Simplex Armijo downhill algorithm is often better than Simplex-downhill algorithm, and is also much better than MER algorithm. mon ones from literatures and can be tuned further. We find that the combination not only accelerates the searching process to reach similar solutions to the baseline simplex algorithm, but also changes the searching trajectory significantly, leading to even better solutions for machine translation test cases as shown in our experiments. 4 Experiments Our experiments were carried out on Chinese-English using our syntax-based decoder (Zhao and Al-Onaizan, 2008), a chart-based decoder with tree-to-string 3 grammar, in GALE P3/P3.5 evaluations. There were 10 feature functions computed for each hypothesis, and N-best list size is up to 2,000 per sentence. Given a weight-vector ao, our decoder outputs N-Best unique hypotheses for each input source sentence; the event space is then built, and the optimizer is called with 3Source shallow constituency tree to target-string rules with variables, forming a probabilistic synchronous context free grammar. a number of random restarts. We used 164 seeds4 with a small perturbation of three random dimensions in A0</context>
</contexts>
<marker>Zhao, Al-Onaizan, 2008</marker>
<rawString>Bing Zhao and Yaser Al-Onaizan. 2008. Generalizing local and non-local word-reordering patterns for syntax-based machine translation. In Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>