<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.068655">
<title confidence="0.993994">
From Structured Prediction to Inverse Reinforcement Learning
</title>
<author confidence="0.996416">
Hal Daum´e III
</author>
<affiliation confidence="0.9811375">
School of Computing, University of Utah
and UMIACS, University of Maryland
</affiliation>
<email confidence="0.958068">
me@hal3.name
</email>
<sectionHeader confidence="0.999763" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999834923076923">
Machine learning is all about making predictions;
language is full of complex rich structure. Struc-
tured prediction marries these two. However,
structured prediction isn’t always enough: some-
times the world throws even more complex data
at us, and we need reinforcement learning tech-
niques. This tutorial is all about the how and the
why of structured prediction and inverse reinforce-
ment learning (aka inverse optimal control): par-
ticipants should walk away comfortable that they
could implement many structured prediction and
IRL algorithms, and have a sense of which ones
might work for which problems.
</bodyText>
<sectionHeader confidence="0.924259" genericHeader="categories and subject descriptors">
2 Content Overview
</sectionHeader>
<bodyText confidence="0.99955725">
The first half of the tutorial will cover the “ba-
sics” of structured prediction: the structured per-
ceptron and Magerman’s incremental parsing al-
gorithm. It will then build up to more advanced al-
gorithms that are shockingly reminiscent of these
simple approaches: maximum margin techniques
and search-based structured prediction.
The second half of the tutorial will ask the ques-
tion: what happens when our standard assump-
tions about our data are violated? This is what
leads us into the world of reinforcement learning
(the basics of which we’ll cover) and then to in-
verse reinforcement learning and inverse optimal
control.
Throughout the tutorial, we will see exam-
ples ranging from simple (part of speech tagging,
named entity recognition, etc.) through complex
(parsing, machine translation).
The tutorial does not assume attendees know
anything about structured prediction or reinforce-
ment learning (though it will hopefully be inter-
esting even to those who know some!), but does
assume some knowledge of simple machine learn-
ing (eg., binary classification).
</bodyText>
<sectionHeader confidence="0.990863" genericHeader="general terms">
3 Tutorial Outline
</sectionHeader>
<subsectionHeader confidence="0.213522">
Part I: Structured prediction
</subsectionHeader>
<listItem confidence="0.985718090909091">
• What is structured prediction?
• Refresher on binary classification
– What does it mean to learn?
– Linear models for classification
– Batch versus stochastic optimization
• From perceptron to structured perceptron
– Linear models for structured prediction
– The “argmax” problem
– From perceptron to margins
• Search-based structured prediction
– Training classifiers to make parsing de-
cisions
– Searn and generalizations
Part II: Inverse reinforcement learning
• Refersher on reinforcement learning
– Markov decision processes
– Q learning
• Inverse optimal control and A* search
– Maximum margin planning
– Learning to search
• Apprenticeship learning
• Open problems
</listItem>
<sectionHeader confidence="0.995131" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.478238333333333">
See http://www.cs.utah.edu/
˜suresh/mediawiki/index.php/MLRG/
spring10.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.616907">
<title confidence="0.999435">From Structured Prediction to Inverse Reinforcement Learning</title>
<author confidence="0.963874">Hal Daum´e</author>
<affiliation confidence="0.999944">School of Computing, University of Utah University of Maryland</affiliation>
<intro confidence="0.640224">me@hal3.name</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<note>See http://www.cs.utah.edu/ ˜suresh/mediawiki/index.php/MLRG/ spring10.</note>
<marker></marker>
<rawString>See http://www.cs.utah.edu/ ˜suresh/mediawiki/index.php/MLRG/ spring10.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>