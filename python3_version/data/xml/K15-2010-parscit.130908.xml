<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001307">
<title confidence="0.996804">
JAIST: A two-phase machine learning approach for identifying dis-
course relations in newswire texts
</title>
<author confidence="0.99776">
Nguyen Truong Son
</author>
<affiliation confidence="0.997163">
University of Science, VNU
</affiliation>
<address confidence="0.5720105">
Ho Chi Minh City
Viet Nam
</address>
<email confidence="0.981024">
ntson@fit.hcmus.edu.vn
</email>
<author confidence="0.975711">
Ho Bao Quoc
</author>
<affiliation confidence="0.98734">
University of Science, VNU
</affiliation>
<address confidence="0.5674795">
Ho Chi Minh City
Viet Nam
</address>
<email confidence="0.980711">
hbquoc@fit.hcmus.edu.vn
</email>
<author confidence="0.97838">
Nguyen Le Minh
</author>
<affiliation confidence="0.762594">
Japan Advanced Institute of
Science and Technology
</affiliation>
<address confidence="0.868078">
Ishikawa, 923-1292
Japan
</address>
<email confidence="0.99703">
nguyenml@jaist.ac.jp
</email>
<sectionHeader confidence="0.993845" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997953727272727">
In this paper, we present a machine learn-
ing approach for identifying shallow dis-
course relations in news wire text. Our
approach has 2 phases. The arguments
detection phase will identify arguments
and explicit connectives by using the
Conditional Random Fields
(CRFs) learning algorithm with a set of
features such as words, parts of speech
(POS) and features extracted from the
parsing tree of sentences. The second
phase, the sense classification phase, will
classify arguments and explicit connec-
tives into one of fifteen types of senses
by using the SMO classifier with a sim-
ple feature set. The performance of sys-
tem was evaluated three different data
sets given by the CoNLL 2015 Shared
Task. The parser of our system was
ranked 4 of 16 participating systems on
F-measure when evaluating on the blind
data set (strict matching).
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999943065217391">
The shallow discourse parsing task given by
the CoNLL 2015 Shared Task proposed by Xue
et al. (2015) aims to extract discourse relations in
newswire texts. Each discourse relation is a set
of four: two arguments, connective words and
senses. However, the connective words may not
be available in case of implicit discourses. Identi-
fying discourse relations is clearly an important
part of natural language understanding that bene-
fits a wide range of natural language applica-
tions. A number of applications of discourse
information have been proposed for recent years.
For example, in the task of identifying para-
phrase texts, Bach et al. (2014) has used dis-
course information to compute the similarity
score between two sentences or Somasundaran et
al. (2009) has used discourse relations to im-
prove the performance of the opinion polarity
classification task.
In the past, this task is solved at different lev-
els. Lin et al. (2009) have used supervised learn-
ing method to build a maximum entropy classifi-
er to identify implicit relations. Ghosh et al.
(2011, 2012) have used CRFs with a set of local
and global features to recognize arguments of
discourses from texts. However, in contrast to
the CoNLL 2015 SDP Shared Task, Ghosh et al.
(2011, 2012) just considered explicit relations
with explicit connectives have been provided.
Our team approach for this shared task com-
poses two phases. In the first phase, we use
CRFs and a set of features such as words, POS
and pattern features based on parsing tree
of sentences to build models for recognizing ar-
guments and connective words. In the second
phase, we use the SMO algorithm, an optimiza-
tion of SVM, to build a classifier to predict the
senses of discourse relations.
The remainder of this paper is structured as
follows: Section 2 describes the details of the
proposed system for solving the task of identify-
ing shallow discourse relations given by CoNLL
2015 Shared Task. We also describe the experi-
mental results and some analysis in Section 3.
Finally, Section 4 presents our conclusions and
future works.
</bodyText>
<sectionHeader confidence="0.927321" genericHeader="method">
2 System description
</sectionHeader>
<bodyText confidence="0.999879">
Our parser system is divided into 2 phases. First-
ly, documents without discourse information will
be passed through the argument detection phase
to recognize components of discourse relations
such as both of arguments and explicit connec-
tives if it is possible. Secondly, the sense classi-
fication phase will identify the sense of discourse
relation by using a SVM classifier then format
</bodyText>
<page confidence="0.978252">
66
</page>
<note confidence="0.830302">
Proceedings of the Nineteenth Conference on Computational Natural Language Learning: Shared Task, pages 66–70,
Beijing, China, July 26-31, 2015. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.987494">
the results according to the expected output of
evaluate system.
</bodyText>
<subsectionHeader confidence="0.86791">
2.1 Phase 1: detection of arguments
</subsectionHeader>
<figureCaption confidence="0.98072">
Figure 1. Workflow of the arguments detection phase
</figureCaption>
<bodyText confidence="0.999940484848485">
The workflow of the first phase consists of
two stages. In the training stage, we use ma-
chine-learning algorithms to build models, which
will be used to identify boundaries of compo-
nents in the parsing stage. In order to learn mod-
els by using machine learning (ML) algorithms,
we use some popular features in such as words,
parts of speech. Besides, we extract a set of pat-
tern features based on the parsing tree of sen-
tences.
According to our analysis of discourse rela-
tions, two arguments of each discourse relation
may be appeared at different positions: in the
same sentence, in two consecutive sentences or
in far apart sentences. Based on the statistic of
discourse relations in the training dataset, we see
that the number of discourse relations which two
arguments located in the same sentence or two
consecutive sentences is in a large quantity
(92.5%). Therefore, our system focus on identi-
fying these kinds of discourse relations by build-
ing two models: one for recognizing discourse
relations in the same sentence (SS) and another
model for recognizing discourse relations in two
consecutive sentences (2CS).
To build learning models using ML algo-
rithms, we need to extract the features from the
data set for the input of the ML algorithm. Each
type of discourse relation (SS-type or 2CS-type)
has some common features and some reserved
features. Table 1 describes all features that are
used for machine learning approaches in our ex-
periments.
</bodyText>
<tableCaption confidence="0.990421">
Table 1. List of all features using for identifying argu-
ments and connectives
</tableCaption>
<table confidence="0.998532772727273">
# Feature description
Common features for both SS-type and 2CS-type
A Word
B POS
C Stem
D Belongs to connective list
E Brown cluster
F Noun phrase / verb phrase
G CLAUSES from S
Pattern features of SS discourse relations
H S_CC_S
I SBAR_CC_SBAR
K SBAR IN S
Pattern features of 2CS discourse relations
L 1st sentence: RIGHTMOST_S
M 2nd sentence: S_begin_with_CC
N 1st sentence: RIGHTMOST_S
O 2nd sentence: NP_ADVP_VP
1st sentence: RIGHTMOST_S
2nd sentence: S_begin_with_ADVP
1st sentence: RIGHTMOST_S
2nd sentence: S_ begin_with_PP
</table>
<bodyText confidence="0.999674533333333">
After all required features are extracted, the
training data and these extracted features will be
formatted as the input format of the machine
learning algorithm tool in which words of dis-
course relations are marked labels using IOB
notations. We use CRF++ (Taku Kudo, 2005), an
implementation of the Conditional Random
Fields (John Lafferty et al, 2001) to train models
from the training data sets.
After models are built, they were used to pre-
dict the discourse labels of new documents (in
the parsing stage) then the result will be convert-
ed into expected format.
Section 2.1.1 and 2.1.2 will describe the de-
tails of all features we used in our experiments.
</bodyText>
<listItem confidence="0.8845108">
2.1.1 Common features:
• Popular language features (A-C): includ-
ing words, their parts of speeches and their
stems.
• Connective features (D): The features
</listItem>
<bodyText confidence="0.743314777777778">
show whether or not the words belong to a
predefined connective list. Predefined
connective lists are constructed from con-
nective words in the training data set.
Then we use these lists to extract this fea-
ture for building the model.
• Brown clusters features (E): Brown clus-
ters, introduced and prepared by Turian
(2010), were successfully applied in some
</bodyText>
<page confidence="0.997514">
67
</page>
<bodyText confidence="0.999855833333333">
named entity recognition tasks. In Brown
clusters, the semantic similarities of words
in the same cluster are higher than of
words in different clusters. We use the
Brown cluster index of words as a feature
for the ML process.
</bodyText>
<listItem confidence="0.920044666666667">
• Noun phrases, verb phrases and clauses
features (F, G): all words of a noun
phrase, verb phrase or clauses are often
located entirely in arguments. Moreover,
the beginning of arguments is often the
same with the beginning of noun phrases,
verb phrases or clauses. We extract noun
phrases, verb phrases and clause based on
the syntactic parse tree of sentences.
</listItem>
<subsubsectionHeader confidence="0.503783">
2.1.2 Pattern based features based on syn-
</subsubsectionHeader>
<bodyText confidence="0.996654833333333">
tactic parse trees
Our analysis on the training corpus shows that
the syntactic information based on the syntactic
parse trees is very important for identify dis-
course relations. According to our analysis, sen-
tences that express discourse relations are usually
follow some special syntax. Therefore, if we can
extract features based on these special syntaxes,
the system will recognize arguments of discourse
relations more exactly.
Due to the linguist characteristic of discourses
in sentences, each kind of discourse relations
(SS-type or 2CS-type) has different pattern fea-
ture sets. Below are patterns based on syntactic
parse trees we have used to extract features for
each of type:
Pattern features for SS-type discourses
recognition (H, I, K): We have three patterns
that help to recognize boundaries of arguments
of SS-type discourse relations. These patterns are
based on the syntactic characteristic of discourse
expressions using prepositions or conjunctions
such as and, but, if, although, É For example,
the pattern S_CC_S (feature H) and
SBAR_CC_SBAR (feature I) indicate S nodes
of which child nodes matched with the pattern
S(.*)CC(.*)S(.*) or SBAR(.*)CC(.*)SBAR(.*). In
this case, related S-nodes or SBAR-nodes may
be the arguments of a discourse relation. Figure 2
shows an example of sentences which matches
with pattern S_CC_S. In this example, the
matched left S node and the right S node are ar-
guments of a discourse relation in the training
data set. Another pattern is SBAR_IN_S (Feature
K). This pattern matched with sentences of
which SBAR node has an IN node (“if”, “alt-
hough”, “before”, “after”, “though”) follow by
an S node. If a sentence match with this pattern,
the S node is often the first arguments and the
rest is often the second argument of a discourse
relation. Figure 3 shows an example of sentences
matched with the pattern SBAR_IN_S.
</bodyText>
<figureCaption confidence="0.98928975">
Figure 2. The matching of a discourse relation with the
pattern S_CC_S
Figure 3. The matching of a discourse relation with the
IN_SBAR pattern
</figureCaption>
<bodyText confidence="0.999796352941177">
Pattern features for 2CS-type discourses
recognition (L, M, N, O): When arguments of
discourse relations are not located in the same
sentence the task is more difficult. To build the
model for identifying 2CS discourses, we will
extract pattern-based features of each pair of sen-
tences in the training data set based on parsing
tree of sentences. Our analysis on the training
corpus shows that if a pair of sentence in which
the second sentence begins with a conjunction,
an adverb, and a preposition (e.g. “for exam-
ple”, “by comparison” and so on) or a noun
phrase followed by an adverb (e.g., “also”), the
right most clauses of first sentence and the left
most sentence in the second sentence may be
arguments of a discourse relation. We use pat-
terns from L-O to extract these features.
</bodyText>
<page confidence="0.998374">
68
</page>
<subsectionHeader confidence="0.975681">
2.2 Phase 2: Sense classification
</subsectionHeader>
<bodyText confidence="0.999793533333333">
After arguments and explicit connectives of
discourses are identified, we need to identify the
sense of these discourses. These discourses with-
out sense information are passed through a clas-
sifier with a model trained in the training stage to
identify the correct senses of discourse relations.
This model used in the above step are built by
using the Sequential Minimal Optimization algo-
rithm (SMO), a fast algorithm for training sup-
port vector machines (John Platt, 1998), with
some simple features such as: connective words;
type of discourses (SS or 2CS); does the first
character of connective words capital or not? The
workflow of sense classification phase is shown
in Figure 4.
</bodyText>
<figureCaption confidence="0.976458">
Figure 4. Workflow of the sense classification phase
</figureCaption>
<bodyText confidence="0.999902833333334">
We use LIBSVM (Chang and Lin. 2011) – a
library that implemented SMO algorithm to build
the model and classify discourses into the senses
category. The trained model for sense classifica-
tion task achieves an F-score of 79.8% (Preci-
sion=80.9%, R=81.6%) when evaluate using
cross validation 10-fold method.
One limitation of our sense classification step
is that it just takes into account discourses with
explicit connectives, so the sense recognition of
non-implicit discourses still has not been solved
yet.
</bodyText>
<sectionHeader confidence="0.996864" genericHeader="method">
3 Experimental results
</sectionHeader>
<bodyText confidence="0.999666083333333">
Table 2 shows the evaluation result of our system
on the three data sets provided by the CONLL
Shared task 2015, the rank column is the rank of
our system when compare with other participat-
ing systems. In general, this task is a difficult
task, so the result is not as high as our expecta-
tion. Moreover, due to the usage of special syn-
tactic patterns extracted from parse trees, the
precision scores of our system is higher than oth-
er teams. However, these patterns just cover sev-
eral special cases, so the recall score of our sys-
tem is low.
</bodyText>
<tableCaption confidence="0.989463">
Table 2. The evaluation result of our system on the
blind, test and dev data sets
</tableCaption>
<table confidence="0.999422461538462">
BLIND data set TEST data set DEV data set
score rank score rank score rank
Arg 1 Arg2 extraction (%)
F1 32.11 7 35.43 7 40.07 8
P 42.72 3 52.98 1 58.92 1
R 25.72 11 26.61 12 30.36 12
Arg1 extraction (%)
F1 40.99 6 42.43 7 46.60 8
P 54.53 3 63.45 1 68.51 1
R 32.84 12 31.87 12 35.31 12
Arg2 extraction (%)
F1 48.53 9 47.99 7 48.99 11
P 64.56 6 71.77 2 72.03 4
R 38.88 12 36.05 13 37.12 13
Explicit connective (%)
F1 61.66 12 63.89 15 65.53 14
P 88.55 10 91.87 8 91.56 10
R 47.30 13 48.97 16 51.03 16
Overall parser performance (%)
F1 18.28 4 20.25 8 26.10 5
P 24.31 2 30.29 2 38.38 1
R 14.64 6 15.21 10 19.78 8
Sense (%)
F1 15.61 6 13.61 8 19.93 5
P 40.55 1 49.34 1 63.15 1
R 12.44 8 10.73 12 15.01 9
</table>
<bodyText confidence="0.999831375">
The comparison of the evaluation result be-
tween explicit discourses and non-explicit dis-
courses are shown in Table 3. With the help of
special patterns based on explicit connectives
and parse trees, the result of explicit discourses
recognition is higher than the result of non-
explicit discourses recognition for both of preci-
sion and recall scores.
</bodyText>
<tableCaption confidence="0.98521">
Table 3. Comparison result between explicit discourses
and non-explicit discourses
</tableCaption>
<table confidence="0.987645928571429">
BLIND set TEST data set
ALL Ex- Non- ALL Ex- Non-
plicit Exp. plicit Exp.
Arg 1 Arg2 extraction (%)
F1 32.11 34.23 30.44 35.43 38.16 32.44
P 42.72 49.16 38.28 52.98 54.88 50.41
R 25.72 26.26 25.27 26.61 29.25 23.92
Arg1 extraction (%)
F1 40.99 44.08 36.9 42.43 43.82 38.85
P 54.53 63.3 46.4 63.45 63.01 60.37
R 32.84 33.81 30.63 31.87 33.59 28.64
Arg2 extraction (%)
F1 48.53 51.35 46.13 47.99 56.25 38.85
P 64.56 73.74 58 71.77 80.89 60.37
R 38.88 39.39 38.28 36.05 43.12 28.64
Explicit connective (%)
F1 61.66 61.66 0 63.89 63.89 0
P 88.55 88.55 0 91.87 91.87 0
R 47.3 47.3 0 48.97 48.97 0
69
Overall parser performance
F1 18.28 27.2 11.25 20.25 33.22 8.01
P 24.31 39.06 14.15 30.29 47.76 12.45
R 14.64 20.86 9.34 15.21 25.46 5.91
Sense (%)
F1 15.61 22.89 1.61 13.61 19.14 1.23
P 40.55 42.58 84.51 49.34 48.43 86.6
R 12.44 17.88 2.54 10.73 14.66 1.97
</table>
<bodyText confidence="0.999490571428571">
The feature set based on the syntactic parse
tree is very important for our system. Table 4
shows the comparison between two different fea-
ture set on the development data set. The FULL
feature set consists of all feature including lexi-
cal, part of speeches, and pattern features based
on syntactic parse trees and so on. However, in
the SHORT feature set, we remove all pattern fea-
tures based on syntactic parse trees to evaluate
the importance of these features. The result,
which just considered discourse relations in the
same sentences, showed that there is a significant
improvement when we use the FULL feature set
instead of the SHORT feature set.
</bodyText>
<tableCaption confidence="0.93505">
Table 4. The comparison between FULL and SHORT
feature set
</tableCaption>
<table confidence="0.999774846153846">
FULL SHORT
Arg 1 Arg2 extraction
F1 0.505 0.315
P 0.684 0.559
R 0.401 0.219
Arg1 extraction
F1 0.567 0.382
P 0.766 0.677
R 0.449 0.266
Arg2 extraction
F1 0.612 0.433
P 0.827 0.769
R 0.485 0.302
</table>
<sectionHeader confidence="0.998498" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999719">
Our approach to the Shallow Discourse Pars-
ing at CONLL 2015 Shared task was to create a
2-phase system that identifies discourse relations
in newswire text. Results show that our approach
achieves the high precision of all systems and
was ranked 4th in terms of F1-measure when
strict matching is used.
In the future we would like to improve the re-
call of our approach by exploring the use of a
wider range of features.
</bodyText>
<sectionHeader confidence="0.99009" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999245">
N. Xue, H.T. Ng, S. Pradhan, R. Prasad, C. Bryant, A.
Rutherford. 2015. The CoNLL-2015 Shared Task
on Shallow Discourse Parsing. In Proceedings of
the Nineteenth Conference on Computational
Natural Language Learning: Shared Task. Bei-
jing, China.
N.X. Bach, N.L. Minh, and A. Shimazu. 2014. Ex-
ploiting discourse information to identify para-
phrases. Expert Systems with Applications,
41(6):2832–2841, May.
J. Lafferty, A. McCallum, and F.C.N Pereira. 2001.
Conditional random fields: Probabilistic models
for segmenting and labeling sequence data.
S. Ghosh, R. Johansson, and S. Tonelli. 2011. Shal-
low discourse parsing with conditional random
fields. In In Proceedings of the 5th International
Joint Conference on Natural Language Pro-
cessing (IJCNLP 2011. Citeseer.
S. Ghosh, G. Riccardi, and R. Johansson. 2012. Glob-
al features for shallow discourse parsing. In Pro-
ceedings of the 13th Annual Meeting of the Spe-
cial Interest Group on Discourse and Dialogue,
pages 150–159. Association for Computational
Linguistics.
T. Kudo. 2005. CRF++: Yet another CRF toolkit.
Software available at http://crfpp. sourceforge.
net.
J. Platt. 1998. Sequential minimal optimization: A fast
algorithm for training support vector machines.
C.C. Chang and C.J. Lin. 2011. LIBSVM: a library
for support vector machines. ACM Transactions
on Intelligent Systems and Technology (TIST),
2(3):27.
S. Somasundaran, G. Namata, J. Wiebe, and L.
Getoor. 2009. Supervised and unsupervised
methods in employing discourse relations for im-
proving opinion polarity classification. In Pro-
ceedings of the 2009 Conference on Empirical
Methods in Natural Language Processing, pages
170–179.
Z. Lin, M.Y. Kan, and H.T. Ng. 2009. Recognizing
implicit discourse relations in the Penn Discourse
Treebank. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Pro-
cessing: Volume 1-Volume 1, pages 343–351.
J. Turian, L. Ratinov, and Y. Bengio. 2010. Word
representations: a simple and general method for
semi-supervised learning. In Proceedings of the
48th annual meeting of the association for com-
putational linguistics, pages 384–394.
</reference>
<figure confidence="0.999125076923077">
FULL SHORT
Explicit connective
0.670 0.512
0.886 0.885
0.539 0.360
Overall parser
0.452 0.270
0.612 0.479
0.359 0.188
Sense
0.232 0.159
0.665 0.612
0.184 0.109
</figure>
<page confidence="0.904901">
70
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.041865">
<title confidence="0.995804">A two-phase machine learning approach for identifying course relations in newswire texts</title>
<author confidence="0.999487">Nguyen Truong</author>
<affiliation confidence="0.999979">University of Science,</affiliation>
<author confidence="0.5551745">Ho Chi Minh Viet Nam</author>
<email confidence="0.667452">ntson@fit.hcmus.edu.vn</email>
<affiliation confidence="0.879234">Ho Bao University of Science,</affiliation>
<author confidence="0.4937425">Ho Chi Minh Viet Nam</author>
<email confidence="0.815828">hbquoc@fit.hcmus.edu.vn</email>
<author confidence="0.991894">Nguyen Le</author>
<affiliation confidence="0.931809333333333">Japan Advanced Institute Science and Ishikawa,</affiliation>
<address confidence="0.780634">Japan</address>
<email confidence="0.96949">nguyenml@jaist.ac.jp</email>
<abstract confidence="0.998546217391304">In this paper, we present a machine learning approach for identifying shallow discourse relations in news wire text. Our approach has 2 phases. The arguments detection phase will identify arguments and explicit connectives by using the Conditional Random (CRFs) learning algorithm with a set of features such as words, parts of speech (POS) and features extracted from the parsing tree of sentences. The second phase, the sense classification phase, will classify arguments and explicit connectives into one of fifteen types of senses by using the SMO classifier with a simple feature set. The performance of system was evaluated three different data sets given by the CoNLL 2015 Shared Task. The parser of our system was ranked 4 of 16 participating systems on F-measure when evaluating on the blind data set (strict matching).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Xue</author>
<author>H T Ng</author>
<author>S Pradhan</author>
<author>R Prasad</author>
<author>C Bryant</author>
<author>A Rutherford</author>
</authors>
<date>2015</date>
<booktitle>The CoNLL-2015 Shared Task on Shallow Discourse Parsing. In Proceedings of the Nineteenth Conference on Computational Natural Language Learning: Shared Task.</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="1354" citStr="Xue et al. (2015)" startWordPosition="211" endWordPosition="214"> speech (POS) and features extracted from the parsing tree of sentences. The second phase, the sense classification phase, will classify arguments and explicit connectives into one of fifteen types of senses by using the SMO classifier with a simple feature set. The performance of system was evaluated three different data sets given by the CoNLL 2015 Shared Task. The parser of our system was ranked 4 of 16 participating systems on F-measure when evaluating on the blind data set (strict matching). 1 Introduction The shallow discourse parsing task given by the CoNLL 2015 Shared Task proposed by Xue et al. (2015) aims to extract discourse relations in newswire texts. Each discourse relation is a set of four: two arguments, connective words and senses. However, the connective words may not be available in case of implicit discourses. Identifying discourse relations is clearly an important part of natural language understanding that benefits a wide range of natural language applications. A number of applications of discourse information have been proposed for recent years. For example, in the task of identifying paraphrase texts, Bach et al. (2014) has used discourse information to compute the similarit</context>
</contexts>
<marker>Xue, Ng, Pradhan, Prasad, Bryant, Rutherford, 2015</marker>
<rawString>N. Xue, H.T. Ng, S. Pradhan, R. Prasad, C. Bryant, A. Rutherford. 2015. The CoNLL-2015 Shared Task on Shallow Discourse Parsing. In Proceedings of the Nineteenth Conference on Computational Natural Language Learning: Shared Task. Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N X Bach</author>
<author>N L Minh</author>
<author>A Shimazu</author>
</authors>
<title>Exploiting discourse information to identify paraphrases.</title>
<date>2014</date>
<journal>Expert Systems with Applications,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="1898" citStr="Bach et al. (2014)" startWordPosition="297" endWordPosition="300">ing task given by the CoNLL 2015 Shared Task proposed by Xue et al. (2015) aims to extract discourse relations in newswire texts. Each discourse relation is a set of four: two arguments, connective words and senses. However, the connective words may not be available in case of implicit discourses. Identifying discourse relations is clearly an important part of natural language understanding that benefits a wide range of natural language applications. A number of applications of discourse information have been proposed for recent years. For example, in the task of identifying paraphrase texts, Bach et al. (2014) has used discourse information to compute the similarity score between two sentences or Somasundaran et al. (2009) has used discourse relations to improve the performance of the opinion polarity classification task. In the past, this task is solved at different levels. Lin et al. (2009) have used supervised learning method to build a maximum entropy classifier to identify implicit relations. Ghosh et al. (2011, 2012) have used CRFs with a set of local and global features to recognize arguments of discourses from texts. However, in contrast to the CoNLL 2015 SDP Shared Task, Ghosh et al. (2011</context>
</contexts>
<marker>Bach, Minh, Shimazu, 2014</marker>
<rawString>N.X. Bach, N.L. Minh, and A. Shimazu. 2014. Exploiting discourse information to identify paraphrases. Expert Systems with Applications, 41(6):2832–2841, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<contexts>
<context position="6498" citStr="Lafferty et al, 2001" startWordPosition="1046" endWordPosition="1049"> features of 2CS discourse relations L 1st sentence: RIGHTMOST_S M 2nd sentence: S_begin_with_CC N 1st sentence: RIGHTMOST_S O 2nd sentence: NP_ADVP_VP 1st sentence: RIGHTMOST_S 2nd sentence: S_begin_with_ADVP 1st sentence: RIGHTMOST_S 2nd sentence: S_ begin_with_PP After all required features are extracted, the training data and these extracted features will be formatted as the input format of the machine learning algorithm tool in which words of discourse relations are marked labels using IOB notations. We use CRF++ (Taku Kudo, 2005), an implementation of the Conditional Random Fields (John Lafferty et al, 2001) to train models from the training data sets. After models are built, they were used to predict the discourse labels of new documents (in the parsing stage) then the result will be converted into expected format. Section 2.1.1 and 2.1.2 will describe the details of all features we used in our experiments. 2.1.1 Common features: • Popular language features (A-C): including words, their parts of speeches and their stems. • Connective features (D): The features show whether or not the words belong to a predefined connective list. Predefined connective lists are constructed from connective words i</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F.C.N Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ghosh</author>
<author>R Johansson</author>
<author>S Tonelli</author>
</authors>
<title>Shallow discourse parsing with conditional random fields. In</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011. Citeseer.</booktitle>
<contexts>
<context position="2312" citStr="Ghosh et al. (2011" startWordPosition="366" endWordPosition="369"> range of natural language applications. A number of applications of discourse information have been proposed for recent years. For example, in the task of identifying paraphrase texts, Bach et al. (2014) has used discourse information to compute the similarity score between two sentences or Somasundaran et al. (2009) has used discourse relations to improve the performance of the opinion polarity classification task. In the past, this task is solved at different levels. Lin et al. (2009) have used supervised learning method to build a maximum entropy classifier to identify implicit relations. Ghosh et al. (2011, 2012) have used CRFs with a set of local and global features to recognize arguments of discourses from texts. However, in contrast to the CoNLL 2015 SDP Shared Task, Ghosh et al. (2011, 2012) just considered explicit relations with explicit connectives have been provided. Our team approach for this shared task composes two phases. In the first phase, we use CRFs and a set of features such as words, POS and pattern features based on parsing tree of sentences to build models for recognizing arguments and connective words. In the second phase, we use the SMO algorithm, an optimization of SVM, t</context>
</contexts>
<marker>Ghosh, Johansson, Tonelli, 2011</marker>
<rawString>S. Ghosh, R. Johansson, and S. Tonelli. 2011. Shallow discourse parsing with conditional random fields. In In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ghosh</author>
<author>G Riccardi</author>
<author>R Johansson</author>
</authors>
<title>Global features for shallow discourse parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue,</booktitle>
<pages>150--159</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Ghosh, Riccardi, Johansson, 2012</marker>
<rawString>S. Ghosh, G. Riccardi, and R. Johansson. 2012. Global features for shallow discourse parsing. In Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 150–159. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
</authors>
<title>CRF++: Yet another CRF toolkit. Software available at http://crfpp.</title>
<date>2005</date>
<note>sourceforge. net.</note>
<contexts>
<context position="6418" citStr="Kudo, 2005" startWordPosition="1036" endWordPosition="1037"> of SS discourse relations H S_CC_S I SBAR_CC_SBAR K SBAR IN S Pattern features of 2CS discourse relations L 1st sentence: RIGHTMOST_S M 2nd sentence: S_begin_with_CC N 1st sentence: RIGHTMOST_S O 2nd sentence: NP_ADVP_VP 1st sentence: RIGHTMOST_S 2nd sentence: S_begin_with_ADVP 1st sentence: RIGHTMOST_S 2nd sentence: S_ begin_with_PP After all required features are extracted, the training data and these extracted features will be formatted as the input format of the machine learning algorithm tool in which words of discourse relations are marked labels using IOB notations. We use CRF++ (Taku Kudo, 2005), an implementation of the Conditional Random Fields (John Lafferty et al, 2001) to train models from the training data sets. After models are built, they were used to predict the discourse labels of new documents (in the parsing stage) then the result will be converted into expected format. Section 2.1.1 and 2.1.2 will describe the details of all features we used in our experiments. 2.1.1 Common features: • Popular language features (A-C): including words, their parts of speeches and their stems. • Connective features (D): The features show whether or not the words belong to a predefined conn</context>
</contexts>
<marker>Kudo, 2005</marker>
<rawString>T. Kudo. 2005. CRF++: Yet another CRF toolkit. Software available at http://crfpp. sourceforge. net.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Platt</author>
</authors>
<title>Sequential minimal optimization: A fast algorithm for training support vector machines.</title>
<date>1998</date>
<contexts>
<context position="11270" citStr="Platt, 1998" startWordPosition="1834" endWordPosition="1835">entence may be arguments of a discourse relation. We use patterns from L-O to extract these features. 68 2.2 Phase 2: Sense classification After arguments and explicit connectives of discourses are identified, we need to identify the sense of these discourses. These discourses without sense information are passed through a classifier with a model trained in the training stage to identify the correct senses of discourse relations. This model used in the above step are built by using the Sequential Minimal Optimization algorithm (SMO), a fast algorithm for training support vector machines (John Platt, 1998), with some simple features such as: connective words; type of discourses (SS or 2CS); does the first character of connective words capital or not? The workflow of sense classification phase is shown in Figure 4. Figure 4. Workflow of the sense classification phase We use LIBSVM (Chang and Lin. 2011) – a library that implemented SMO algorithm to build the model and classify discourses into the senses category. The trained model for sense classification task achieves an F-score of 79.8% (Precision=80.9%, R=81.6%) when evaluate using cross validation 10-fold method. One limitation of our sense c</context>
</contexts>
<marker>Platt, 1998</marker>
<rawString>J. Platt. 1998. Sequential minimal optimization: A fast algorithm for training support vector machines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C C Chang</author>
<author>C J Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines.</title>
<date>2011</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>2--3</pages>
<marker>Chang, Lin, 2011</marker>
<rawString>C.C. Chang and C.J. Lin. 2011. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent Systems and Technology (TIST), 2(3):27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>G Namata</author>
<author>J Wiebe</author>
<author>L Getoor</author>
</authors>
<title>Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>170--179</pages>
<contexts>
<context position="2013" citStr="Somasundaran et al. (2009)" startWordPosition="315" endWordPosition="318">ons in newswire texts. Each discourse relation is a set of four: two arguments, connective words and senses. However, the connective words may not be available in case of implicit discourses. Identifying discourse relations is clearly an important part of natural language understanding that benefits a wide range of natural language applications. A number of applications of discourse information have been proposed for recent years. For example, in the task of identifying paraphrase texts, Bach et al. (2014) has used discourse information to compute the similarity score between two sentences or Somasundaran et al. (2009) has used discourse relations to improve the performance of the opinion polarity classification task. In the past, this task is solved at different levels. Lin et al. (2009) have used supervised learning method to build a maximum entropy classifier to identify implicit relations. Ghosh et al. (2011, 2012) have used CRFs with a set of local and global features to recognize arguments of discourses from texts. However, in contrast to the CoNLL 2015 SDP Shared Task, Ghosh et al. (2011, 2012) just considered explicit relations with explicit connectives have been provided. Our team approach for this</context>
</contexts>
<marker>Somasundaran, Namata, Wiebe, Getoor, 2009</marker>
<rawString>S. Somasundaran, G. Namata, J. Wiebe, and L. Getoor. 2009. Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 170–179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Lin</author>
<author>M Y Kan</author>
<author>H T Ng</author>
</authors>
<title>Recognizing implicit discourse relations in the Penn Discourse Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>343--351</pages>
<contexts>
<context position="2186" citStr="Lin et al. (2009)" startWordPosition="345" endWordPosition="348">scourses. Identifying discourse relations is clearly an important part of natural language understanding that benefits a wide range of natural language applications. A number of applications of discourse information have been proposed for recent years. For example, in the task of identifying paraphrase texts, Bach et al. (2014) has used discourse information to compute the similarity score between two sentences or Somasundaran et al. (2009) has used discourse relations to improve the performance of the opinion polarity classification task. In the past, this task is solved at different levels. Lin et al. (2009) have used supervised learning method to build a maximum entropy classifier to identify implicit relations. Ghosh et al. (2011, 2012) have used CRFs with a set of local and global features to recognize arguments of discourses from texts. However, in contrast to the CoNLL 2015 SDP Shared Task, Ghosh et al. (2011, 2012) just considered explicit relations with explicit connectives have been provided. Our team approach for this shared task composes two phases. In the first phase, we use CRFs and a set of features such as words, POS and pattern features based on parsing tree of sentences to build m</context>
</contexts>
<marker>Lin, Kan, Ng, 2009</marker>
<rawString>Z. Lin, M.Y. Kan, and H.T. Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 343–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Turian</author>
<author>L Ratinov</author>
<author>Y Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th annual</booktitle>
<pages>384--394</pages>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>J. Turian, L. Ratinov, and Y. Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th annual meeting of the association for computational linguistics, pages 384–394.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>