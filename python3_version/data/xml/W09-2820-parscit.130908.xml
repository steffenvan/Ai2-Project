<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.050833">
<title confidence="0.997801">
JUNLG-MSR: A Machine Learning Approach of Main Subject
Reference Selection with Rule Based Improvement
</title>
<author confidence="0.990581">
Samir Gupta
</author>
<affiliation confidence="0.7594795">
Department of Computer Science and
Engineering, Jadavpur University.
</affiliation>
<address confidence="0.496284">
Kolkata-700032, India.
</address>
<email confidence="0.991961">
samir.ju@gmail.com
</email>
<author confidence="0.933282">
Sivaji Bandopadhyay
</author>
<affiliation confidence="0.732527">
Department of Computer Science and
Engineering, Jadavpur University.
</affiliation>
<address confidence="0.483247">
Kolkata-700032, India.
</address>
<email confidence="0.992955">
sivaji_cse_ju@yahoo.com
</email>
<sectionHeader confidence="0.998563" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999886615384616">
The GREC-MSR task is to generate appropri-
ate references to an entity in the context of a
piece of discourse longer than a sentence. In
MSR ’09 run of this task, the main aim is to
select the actual main subject reference
(MSR) from a list of given referential expres-
sions that is appropriate in context. We used a
machine learning approach augmented with
some rules to select the most appropriate ref-
erential expression. Our approach uses the
training set for learning and then combines
some of the rules found by observation to im-
prove the system.
</bodyText>
<sectionHeader confidence="0.998764" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9909144">
In this paper we provide a description of our sys-
tem for the GREC MSR task of Generation Chal-
lenges 2009. GREC-2.0 Corpus of 2,000
Wikipedia introduction sections in which refer-
ences to the main subject of the Wikipedia article
have been annotated was provided to us by the or-
ganizers. The corpus was divided into five differ-
ent domains like cities, countries, mountains,
people and rivers.
The basic approach we used was to develop a
baseline system first by training the system on the
training set. This system then selects the most fre-
quent referential expression based on a number of
parameters of the corresponding reference. After
evaluation on the development set we used the de-
velopment set to deduce certain rules based on ob-
servation and iteratively added these rules to the
system and evaluated resulting performance. Thus
the system development can be divided into two
phases which are discussed in sections 2 and 3.
</bodyText>
<sectionHeader confidence="0.9911965" genericHeader="method">
2 Baseline System: Training and Classifi-
cation
</sectionHeader>
<bodyText confidence="0.999977392857143">
The machine learning approach we used for the
baseline system was domain independent and
hence was build by populating a single database
with the training set data. First we parsed the con-
tents of the XML files of the training sets using a
Java DOM XML Parser. Then we inserted the
training set data into the database named grec
which had two tables: parsed_ref and possi-
ble_refex. There is a one to many mapping from
possible_refex to parsed_ref. The possible_refex
contains all possible REFEX elements i.e. referen-
tial expressions possible while parsed_ref contains
all the parsed references of the training set with
attributes such as syncat, semcat, paragraph num-
ber, reference number (with respect to a para-
graph), sentence number and a foreign key refex id
referring to the possible_refex table.
The prediction of the referential expression was
done based on features such as the semantic cate-
gory, syntactic category, paragraph number, refer-
ence number with respect to a paragraph and
sentence number of the referent. One example
from the database is, if the semcat of the reference
is cities, syncat is np-subj, paragraph number is 2,
ref number is 1 and sentence number equals 1 then
in 74% of the cases of the training set the referen-
tial expression was with refex id=1 (i.e.
type=common, emphatic=no, head=nominal and
</bodyText>
<page confidence="0.982508">
103
</page>
<note confidence="0.9955795">
Proceedings of the 2009 Workshop on Language Generation and Summarisation, ACL-IJCNLP 2009, pages 103–104,
Suntec, Singapore, 6 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.99918875">
case= plain) and refex id = 4 (i.e. type=name, em-
phatic=no, head=nominal and case= plain) had the
second highest count (19.6%). Thus we selected
the most frequent refex from the possible referen-
tial expressions corresponding to the feature set of
the reference, based on their count in the training
set populated database. These decision rules with
their associated probabilities are stored in a table
which served as our model for classification. When
a number of referential expressions from the
alt_refex match from the list of the given refexes
then we select the refex with the longest surface
form. In certain case when the refex was not in the
alt_refex element we select the second best case
from our decision model. Results of this intermedi-
ate baseline system are given in Table 1.
</bodyText>
<table confidence="0.9984015">
Domain String Reg Mean Norm.
Acc. 08 Edit mean
type Dis- edit dis-
Acc. tance tance
Cities 0.404 0.495 1.657 0.575
Countr. 0.468 0.576 1.467 0.471
Mount. 0.567 0.646 1.192 0.380
People 0.576 0.673 0.902 0.379
Rivers 0.6 0.6 1.06 0.36
Overall 0.532 0.62 1.205 0.421
</table>
<tableCaption confidence="0.999047">
Table 1: Baseline Results
</tableCaption>
<sectionHeader confidence="0.98856" genericHeader="method">
3 Rule based Improvement
</sectionHeader>
<bodyText confidence="0.9695768125">
After the baseline system was evaluated on the
development set we iteratively added some rules to
optimize the system output. These rules are ap-
plied only when a reference matches the below
stated condition, otherwise the result from the
baseline system was used.
The different rules that we deduced are as follows:
• The referential expression is empty if its
immediate preceding word is a conjunction
and the referent’s syncat is np-subj. Thus
the surface form of the refex is null.
• In the people domain if the best case out-
put from the baseline results in Reg-type =
”name” and if earlier in the paragraph the
person’s full name has been referred to,
then subsequent references will have a
shorter version of the referential expres-
sion i.e. shorter surface form (example:
Zinn’s instead of Howard Zinn&apos;s)
• If the same sentence spans two or more
references then generally a pronoun form
is used if a noun has been used earlier.
• Generally common form of the noun is
used instead of the baseline pronoun out-
put if words like in, for, to, of, in precedes
the reference (maximum distance 3
words). This rule is applied to all domains
except people.
The first and the last rules had some effect to
the system but the improvement from the other
rules was very negligible. Final results are tabu-
lated in Table 2.
</bodyText>
<sectionHeader confidence="0.999982" genericHeader="conclusions">
4 Results
</sectionHeader>
<bodyText confidence="0.999242777777778">
We provide final results of our system in Table 2
Script geval.pl was provided by the organizers for
this purpose. We see that inclusion of the above
rules in the system increased it’s accuracy by al-
most 4-5%. More rules can be added to system by
studying cases of the training set which do not get
classified correctly by the best case baseline sys-
tem. Overall reg08 accuracy, precision and recall
were 66.4 %.
</bodyText>
<table confidence="0.9754506">
Domain String Reg Mean Norm.
Acc. 08 Edit mean
type Dist. edit
Acc. Dist.
Cities 0.434 0.525 1.596 0.544
Countr. 0.5 0.619 1.381 0.431
Mount. 0.583 0.663 1.158 0.363
People 0.659 0.756 0.746 0.296
Rivers 0.65 0.65 0.95 0.31
Overall 0.575 0.664 1.12 0.377
</table>
<tableCaption confidence="0.990251">
Table 2: Final Results
</tableCaption>
<sectionHeader confidence="0.997887" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997970111111111">
Anja Belz and Albert Gatt. 2008. Grec Main Subject
Reference Generation Challenge 2009: Participants’
Pack.
http://www.nltg.brighton.ac.uk/research/genchal09
Anja Belz, Eric Kow, Jette Viethen, Albert Gatt. 2008.
The GREC Challenge 2008: Overview and Evalua-
tion Results. In Proceedings of the Fifth Interna-
tional Natural Language Generation Conference
(INLG-2008) pages 183-192.
</reference>
<page confidence="0.99878">
104
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.352302">
<title confidence="0.9946095">JUNLG-MSR: A Machine Learning Approach of Main Reference Selection with Rule Based Improvement</title>
<author confidence="0.911583">Samir</author>
<affiliation confidence="0.832996">Department of Computer Science Engineering, Jadavpur</affiliation>
<address confidence="0.99281">Kolkata-700032, India.</address>
<email confidence="0.999902">samir.ju@gmail.com</email>
<author confidence="0.898186">Sivaji</author>
<affiliation confidence="0.833333">Department of Computer Science Engineering, Jadavpur</affiliation>
<address confidence="0.992255">Kolkata-700032, India.</address>
<email confidence="0.999947">sivaji_cse_ju@yahoo.com</email>
<abstract confidence="0.999301714285714">The GREC-MSR task is to generate appropriate references to an entity in the context of a piece of discourse longer than a sentence. In MSR ’09 run of this task, the main aim is to select the actual main subject reference (MSR) from a list of given referential expressions that is appropriate in context. We used a machine learning approach augmented with some rules to select the most appropriate referential expression. Our approach uses the training set for learning and then combines some of the rules found by observation to improve the system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Anja Belz</author>
<author>Albert Gatt</author>
</authors>
<title>Grec Main Subject Reference Generation Challenge</title>
<date>2008</date>
<note>Participants’ Pack.</note>
<marker>Belz, Gatt, 2008</marker>
<rawString>Anja Belz and Albert Gatt. 2008. Grec Main Subject Reference Generation Challenge 2009: Participants’ Pack.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<title>Eric Kow, Jette Viethen, Albert Gatt.</title>
<date>2008</date>
<booktitle>In Proceedings of the Fifth International Natural Language Generation Conference (INLG-2008)</booktitle>
<pages>183--192</pages>
<marker>Belz, 2008</marker>
<rawString>Anja Belz, Eric Kow, Jette Viethen, Albert Gatt. 2008. The GREC Challenge 2008: Overview and Evaluation Results. In Proceedings of the Fifth International Natural Language Generation Conference (INLG-2008) pages 183-192.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>