<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000673">
<note confidence="0.390255">
Book Reviews The Linguistic Basis of Text Generation
</note>
<bodyText confidence="0.999971421052631">
representation of linguistic knowledge, although his
main concern is extensibility. His English generator,
KING, uses a simple control scheme that exploits the
rich linguistic representations in a separate, frame-
based, hierarchical system. The section on grammars
and grammatical formalisms present detailed papers on
everything from the relevance of Tree Adjoining Gram-
mars to generation (by Aravind Joshi) to a formal model
of systemic grammar (by Terry Patten and Graeme
Ritchie). There is also a detailed description of a gen-
erator, by Harry Bunt, that uses pragmatic information.
The final sections primarily contain the contributions
of the psychologists. Koenraad De Smedt and Gerard
Kempen propose what is surely the first true computa-
tional model of sentence production that mimics the
incremental nature of human production. Their model,
which includes a monitoring component, captures var-
ious phenomena, such as hesitations, syntactic dead-
lock, and self-corrections, including modifications to
conceptual structures.
Another contribution by Willem Levelt and Herbert
Schriefers, explores stages of activation of lexical prop-
erties such as sound form and conceptual conditions.
One of the more interesting aspects that they address is
how a lexical item checks if its conceptual conditions
are satisfied. They extend the earlier idea of matching a
core sense to include checks on specificity of meaning.
One final paper is worth mention. Karen Kukich&apos;s
paper presents a connectionist implementation of part
of her stock market report generator. This is important,
but preliminary, work on architectures that could liber-
ate generators from serial processing schemes. How-
ever, we should not throw out our previous serial
schemes just yet.
On the whole, this book provides an important
source for research on many aspects of natural language
generation. Although the contributions are not of uni-
form quality and level of detail, most are very good.
</bodyText>
<sectionHeader confidence="0.985931" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.776315333333333">
Cullingford, R.E. 1986 Natural Language Processing: A Knowledge-
Engineering Approach, Rowman and Littlefield, Inc., Totowa, NJ.
McKeown, K. 1985 Text Generation, Cambridge University Press,
Cambridge, England.
Grishman, R. 1986 Computational Linguistics Cambridge University
Press, Cambridge, England.
</reference>
<footnote confidence="0.9057944">
NOTE
1. The views expressed in this review are the author&apos;s and do not
necessarily reflect the opinions of SRI International.
Marie Bienkowski is a member of the Applied Al Technology
Program at SRI International. Her Ph.D. research dealt with
explanation production and language generation for problem-
solving systems; her current research is on methods for
explanation production in training systems. Bienkowski&apos;s
address is: SRI International, 333 Ravenswood Ave., Menlo
Park, CA 94025. E-Mail: bienk@istc.sri.com.
</footnote>
<note confidence="0.522737">
THE LINGUISTIC BASIS OF TEXT GENERATION
</note>
<subsectionHeader confidence="0.943629">
Laurence Danlos
</subsectionHeader>
<bodyText confidence="0.9533074">
(Centre National de la Recherche Scientifique, Paris,
France)
(Studies in Natural Language Processing)
Cambridge University Press: Cambridge, England,
1987, x+222 pp.
</bodyText>
<figure confidence="0.702619">
ISBN 0-521-32398-8, $39.50 (hb) (20% discount to
ACL members)
Reviewed by
Kathleen McCoy
</figure>
<subsubsectionHeader confidence="0.430506">
University of Delaware
</subsubsectionHeader>
<bodyText confidence="0.981585545454545">
In this book Laurence Danlos has been able to achieve
a nice balance between straight linguistics and straight
computer science (artificial intelligence). She uses a
detailed linguistic analysis as the basis for a text gener-
ation system. In doing so, she has managed to come up
with ideas of interest to both fields.
The book describes the methodology behind a gen-
eration system whose aim is to produce &amp;quot;good&amp;quot; texts
from semantic representations of what is to be con-
veyed. Danlos says that there are two kinds of decisions
that must be made to do this:
</bodyText>
<listItem confidence="0.990972166666667">
• Conceptual decisions (e.g., what order should the
information be presented in, what should be made
explicit and what implicit?); and
• Linguistic decisions (e.g., where should sentence
boundaries be made, what words should be used,
what syntactic constructions?).
</listItem>
<bodyText confidence="0.996119882352941">
Danlos rather convincingly defends a claim that all of
these decisions are dependent on each other. For in-
stance, a decision to order the information in one way
will limit the choice of syntactic constructions available
(which in turn will limit lexical choice) and vice versa.
In addition, there is no a priori reason why priority
should be given to one of these decisions over the
others. The priority decision concerning a particular
semantic relation can only be made within a particular
domain after detailed linguistic analysis. In order for the
generation system to work, it must capture the available
conceptual and linguistic choices. Danlos advocates
encoding the choices in two structures, and illustrates
how the choices are determined and resulting structures
used for texts concerning direct causal relationships
(between an ACT and RESULTing state) within the
terrorist domain. The two structures she advocates are:
</bodyText>
<listItem confidence="0.993698666666667">
1. A lexicon grammar that is specific to a particular
domain and semantic relationship and encodes the
possible simple sentences (lexical items) that can
be used to express concepts in the domain (e.g.,
the act and result in a direct causal relationship
such as a murder attempt); and
2. A discourse grammar that is specific to a particu-
lar semantic relation and encodes the remaining
choices.
</listItem>
<bodyText confidence="0.959349795918367">
Computational Linguistics, Volume 14, Number 3, September 1988 115
Book Reviews Cognitive Science: An Introduction
For instance, for a direct causal relationship, once the
simple sentences that express the ACT and RESULT
have been chosen, the choice of syntactic structure, the
ordering of information, and the number of sentences
still remain. Moreover, not all combinations of these
choices yield acceptable texts. The discourse grammar
encodes the acceptable choice combinations for the
semantic relationship.
Thus, in order to build a generation system which is
able to handle some particular semantic relation, one
must first do a detailed linguistic analysis to find the
simple sentences that could be used to convey the
information (and encode this in the lexicon grammar),
and next do another linguistic analysis to see how these
simple sentences can be combined, ordered, and syn-
tactically presented so as to convey the semantic rela-
tionship (and encode this in the discourse grammar).
Once the analysis has been done, the generation system
can use these two grammars to do generation. It is the
case, however, that the two grammars encode choices
that are mutually dependent. Thus a choice in one will
limit the available choices in the other. The priority of
these decisions can only be determined within a partic-
ular domain. In applying this generation model to several
domains, Danlos is extremely thorough and insightful.
While one would hope that the domain dependence
that Danlos advocates is not necessary, her analysis is
quite convincing. Throughout the book she points out
areas where &amp;quot;general principles&amp;quot; used by others must
actually be operationalized in a very domain-dependent
fashion. Thus the usefulness of such principles is called
into question.
In all I found the book to be most interesting. As a
computer scientist I found the book&apos;s linguistic analysis
very helpful. It forced me to look at generation from a
new point of view. I would expect that linguists will
have a similar reaction because of the book&apos;s strong
commitment to processing. I believe that Danlos has
been able to successfully straddle the fence that lies
between these two fields. In doing so, she has made a
real contribution to both.
Kathleen McCoy is an assistant professor at the University of
Delaware working in the areas of natural language generation,
discourse, and correcting misconceptions. McCoy&apos;s address
is: Department of Computer and Information Sciences, Uni-
versity of Delaware, Newark, DE 19716. E-mail:
mccoy@udel.edu
</bodyText>
<note confidence="0.549283">
COGNITIVE SCIENCE: AN INTRODUCTION
</note>
<reference confidence="0.720428090909091">
Neil A. StiRings; Mark H. Feinstein; Jay L. Garfield;
Edwina L. Rissland; David A. Rosenbaum; Steven E.
Weisler; and Lynne Baker-Ward
(Hampshire College and University of Massachusetts,
Amherst, MA)
The MIT Press/Bradford Books, Cambridge, MA
1987, xvii+533 pp.
ISBN 0-262-19257-8, $25.00 (hb)
Reviewed by
Helen M. Gigley
National Science Foundation
</reference>
<bodyText confidence="0.999939279069768">
The study of cognitive science in modern terms is an
emerging field and the term itself evokes many discus-
sions regarding its nature. For instance, what are criti-
cal aspects of its study, and to what degree can certain
traditional disciplines contribute? Given these facts,
this book makes a significant contribution to providing
a basic overview of current cognitive science. But I am
not reviewing it strictly for its contribution to the study
of cognitive science. Instead, I am reviewing it here as
it might be used for an introduction to natural language
processing (NLP) or to issues which are relevant to
computational linguistics. The attempt will be to focus
only on issues that are related to language and its
processing. However, since there are areas where the
separation of language and cognition in general are
impossible, there will be some related description of the
cognitive discussions.
The overall presentation of the material is at a level
that is easily accessible to students unfamiliar with the
problems raised. Specifically, for persons beginning the
study of language as a part of cognition, including its
acquisition, its processing, and aspects of its knowledge
base, I find the discussions very adequate in most
respects. Because the chapters are individually
authored, there is some disparity in style and type of
information contained, but for most chapters this can be
overlooked.
First, I will raise some problems that I found with the
text that might influence its selection. Of critical import
to a book such as this is a chapter that attempts to
integrate what has been presented separately. This is
lacking here and I feel is a serious omission. Having one
final chapter that pulls together the threads of common-
ality that have been described throughout is very im-
portant for new students in afield. Even having suitable
pointers between chapters as cross-reference to where
another viewpoint of the same problem is presented
would be helpful. This also is not done; the reader is left
to infer such relationships. Without significant guidance
from someone who is knowledgeable across several of
the disciplines, seeing the parallel and interrelated re-
search efforts is not a trivial task, but is necessary to
fully grasp the problems faced in cognitive science
</bodyText>
<page confidence="0.976855">
116 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.012281">
<title confidence="0.984971">Book Reviews The Linguistic Basis of Text Generation</title>
<abstract confidence="0.997247921052632">representation of linguistic knowledge, although his main concern is extensibility. His English generator, KING, uses a simple control scheme that exploits the rich linguistic representations in a separate, framebased, hierarchical system. The section on grammars and grammatical formalisms present detailed papers on everything from the relevance of Tree Adjoining Grammars to generation (by Aravind Joshi) to a formal model of systemic grammar (by Terry Patten and Graeme Ritchie). There is also a detailed description of a generator, by Harry Bunt, that uses pragmatic information. The final sections primarily contain the contributions of the psychologists. Koenraad De Smedt and Gerard Kempen propose what is surely the first true computational model of sentence production that mimics the incremental nature of human production. Their model, which includes a monitoring component, captures various phenomena, such as hesitations, syntactic deadlock, and self-corrections, including modifications to conceptual structures. Another contribution by Willem Levelt and Herbert Schriefers, explores stages of activation of lexical properties such as sound form and conceptual conditions. One of the more interesting aspects that they address is how a lexical item checks if its conceptual conditions are satisfied. They extend the earlier idea of matching a core sense to include checks on specificity of meaning. One final paper is worth mention. Karen Kukich&apos;s paper presents a connectionist implementation of part of her stock market report generator. This is important, but preliminary, work on architectures that could liberate generators from serial processing schemes. However, we should not throw out our previous serial schemes just yet. On the whole, this book provides an important source for research on many aspects of natural language generation. Although the contributions are not of uniform quality and level of detail, most are very good.</abstract>
<note confidence="0.8107825">REFERENCES R.E. 1986 Language Processing: A Knowledge- Approach, and Littlefield, Inc., Totowa, NJ. K. 1985 Generation, University Press,</note>
<address confidence="0.888983">Cambridge, England. R. 1986 Linguistics University Press, Cambridge, England.</address>
<email confidence="0.84047">NOTE</email>
<abstract confidence="0.928219428571429">The views expressed in this review are the and do not necessarily reflect the opinions of SRI International. Bienkowski is member of the Applied Al Technology Program at SRI International. Her Ph.D. research dealt with explanation production and language generation for problemsolving systems; her current research is on methods for explanation production in training systems. Bienkowski&apos;s</abstract>
<note confidence="0.815604">address is: SRI International, 333 Ravenswood Ave., Menlo Park, CA 94025. E-Mail: bienk@istc.sri.com.</note>
<title confidence="0.67352">OF TEXT</title>
<author confidence="0.895445">Laurence Danlos</author>
<affiliation confidence="0.981328">Centre National de la Recherche Scientifique, Paris,</affiliation>
<address confidence="0.85298">France</address>
<affiliation confidence="0.515967">(Studies in Natural Language Processing) Cambridge University Press: Cambridge, England,</affiliation>
<address confidence="0.785895">1987, x+222 pp.</address>
<note confidence="0.988178666666667">ISBN 0-521-32398-8, $39.50 (hb) (20% discount to ACL members) Reviewed by</note>
<author confidence="0.999728">Kathleen McCoy</author>
<affiliation confidence="0.995203">University of Delaware</affiliation>
<abstract confidence="0.999731534883721">In this book Laurence Danlos has been able to achieve a nice balance between straight linguistics and straight computer science (artificial intelligence). She uses a detailed linguistic analysis as the basis for a text generation system. In doing so, she has managed to come up with ideas of interest to both fields. The book describes the methodology behind a generation system whose aim is to produce &amp;quot;good&amp;quot; texts from semantic representations of what is to be conveyed. Danlos says that there are two kinds of decisions that must be made to do this: • Conceptual decisions (e.g., what order should the information be presented in, what should be made explicit and what implicit?); and • Linguistic decisions (e.g., where should sentence boundaries be made, what words should be used, what syntactic constructions?). Danlos rather convincingly defends a claim that all of these decisions are dependent on each other. For instance, a decision to order the information in one way will limit the choice of syntactic constructions available (which in turn will limit lexical choice) and vice versa. In addition, there is no a priori reason why priority should be given to one of these decisions over the others. The priority decision concerning a particular semantic relation can only be made within a particular domain after detailed linguistic analysis. In order for the generation system to work, it must capture the available conceptual and linguistic choices. Danlos advocates encoding the choices in two structures, and illustrates how the choices are determined and resulting structures used for texts concerning direct causal relationships (between an ACT and RESULTing state) within the terrorist domain. The two structures she advocates are: 1. A lexicon grammar that is specific to a particular domain and semantic relationship and encodes the possible simple sentences (lexical items) that can be used to express concepts in the domain (e.g., the act and result in a direct causal relationship such as a murder attempt); and 2. A discourse grammar that is specific to a particular semantic relation and encodes the remaining choices.</abstract>
<intro confidence="0.706942">Computational Linguistics, Volume 14, Number 3, September 1988 115</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R E Cullingford</author>
</authors>
<title>Natural Language Processing: A KnowledgeEngineering Approach,</title>
<date>1986</date>
<location>Rowman and Littlefield, Inc., Totowa, NJ.</location>
<marker>Cullingford, 1986</marker>
<rawString>Cullingford, R.E. 1986 Natural Language Processing: A KnowledgeEngineering Approach, Rowman and Littlefield, Inc., Totowa, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K McKeown</author>
</authors>
<title>Text Generation,</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England.</location>
<marker>McKeown, 1985</marker>
<rawString>McKeown, K. 1985 Text Generation, Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
</authors>
<title>Computational Linguistics Cambridge</title>
<date>1986</date>
<publisher>University Press,</publisher>
<location>Cambridge, England.</location>
<marker>Grishman, 1986</marker>
<rawString>Grishman, R. 1986 Computational Linguistics Cambridge University Press, Cambridge, England.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Neil A StiRings</author>
<author>Mark H Feinstein</author>
<author>Jay L Garfield</author>
<author>Edwina L Rissland</author>
<author>David A Rosenbaum</author>
<author>Steven E Weisler</author>
</authors>
<institution>and Lynne Baker-Ward (Hampshire College and University of Massachusetts,</institution>
<location>Amherst, MA</location>
<marker>StiRings, Feinstein, Garfield, Rissland, Rosenbaum, Weisler, </marker>
<rawString>Neil A. StiRings; Mark H. Feinstein; Jay L. Garfield; Edwina L. Rissland; David A. Rosenbaum; Steven E. Weisler; and Lynne Baker-Ward (Hampshire College and University of Massachusetts, Amherst, MA)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Helen</author>
</authors>
<date>1987</date>
<pages>0--262</pages>
<institution>The MIT Press/Bradford Books,</institution>
<location>Cambridge, MA</location>
<note>(hb) Reviewed by</note>
<marker>Helen, 1987</marker>
<rawString>The MIT Press/Bradford Books, Cambridge, MA 1987, xvii+533 pp. ISBN 0-262-19257-8, $25.00 (hb) Reviewed by Helen M. Gigley National Science Foundation</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>