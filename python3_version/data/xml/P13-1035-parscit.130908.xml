<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000032">
<title confidence="0.994948">
Learning Latent Personas of Film Characters
</title>
<author confidence="0.99551">
David Bamman Brendan O’Connor Noah A. Smith
</author>
<affiliation confidence="0.900049">
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998798">
{dbamman,brenocon,nasmith}@cs.cmu.edu
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99998">
We present two latent variable models for
learning character types, or personas, in
film, in which a persona is defined as a
set of mixtures over latent lexical classes.
These lexical classes capture the stereo-
typical actions of which a character is the
agent and patient, as well as attributes by
which they are described. As the first
attempt to solve this problem explicitly,
we also present a new dataset for the
text-driven analysis of film, along with
a benchmark testbed to help drive future
work in this area.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999849823529412">
Philosophers and dramatists have long argued
whether the most important element of narrative
is plot or character. Under a classical Aristotelian
perspective, plot is supreme;1 modern theoretical
dramatists and screenwriters disagree.2
Without addressing this debate directly, much
computational work on narrative has focused on
learning the sequence of events by which a story
is defined; in this tradition we might situate sem-
inal work on learning procedural scripts (Schank
and Abelson, 1977; Regneri et al., 2010), narrative
chains (Chambers and Jurafsky, 2008), and plot
structure (Finlayson, 2011; Elsner, 2012; McIn-
tyre and Lapata, 2010; Goyal et al., 2010).
We present a complementary perspective that
addresses the importance of character in defining
1“Dramatic action ... is not with a view to the representa-
tion of character: character comes in as subsidiary to the ac-
tions ... The Plot, then, is the first principle, and, as it were,
the soul of a tragedy: Character holds the second place.” Po-
etics I.VI (Aristotle, 335 BCE).
2“Aristotle was mistaken in his time, and our scholars are
mistaken today when they accept his rulings concerning char-
acter. Character was a great factor in Aristotle’s time, and no
fine play ever was or ever will be written without it” (Egri,
1946, p. 94); “What the reader wants is fascinating, complex
characters” (McKee, 1997, 100).
a story. Our testbed is film. Under this perspec-
tive, a character’s latent internal nature drives the
action we observe. Articulating narrative in this
way leads to a natural generative story: we first de-
cide that we’re going to make a particular kind of
movie (e.g., a romantic comedy), then decide on a
set of character types, or personas, we want to see
involved (the PROTAGONIST, the LOVE INTER-
EST, the BEST FRIEND). After picking this set, we
fill out each of these roles with specific attributes
(female, 28 years old, klutzy); with this cast of
characters, we then sketch out the set of events by
which they interact with the world and with each
other (runs but just misses the train, spills coffee
on her boss) – through which they reveal to the
viewer those inherent qualities about themselves.
This work is inspired by past approaches that in-
fer typed semantic arguments along with narra-
tive schemas (Chambers and Jurafsky, 2009; Reg-
neri et al., 2011), but seeks a more holistic view
of character, one that learns from stereotypical at-
tributes in addition to plot events. This work also
naturally draws on earlier work on the unsuper-
vised learning of verbal arguments and semantic
roles (Pereira et al., 1993; Grenager and Manning,
2006; Titov and Klementiev, 2012) and unsuper-
vised relation discovery (Yao et al., 2011).
This character-centric perspective leads to two
natural questions. First, can we learn what those
standard personas are by how individual charac-
ters (who instantiate those types) are portrayed?
Second, can we learn the set of attributes and ac-
tions by which we recognize those common types?
How do we, as viewers, recognize a VILLIAN?
At its most extreme, this perspective reduces
to learning the grand archetypes of Joseph Camp-
bell (1949) or Carl Jung (1981), such as the HERO
or TRICKSTER. We seek, however, a more fine-
grained set that includes not only archetypes, but
stereotypes as well – characters defined by a fixed
set of actions widely known to be representative of
</bodyText>
<page confidence="0.963456">
352
</page>
<note confidence="0.9147285">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 352–361,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.998800444444444">
a class. This work offers a data-driven method for
answering these questions, presenting two proba-
blistic generative models for inferring latent char-
acter types.
This is the first work that attempts to learn ex-
plicit character personas in detail; as such, we
present a new dataset for character type induction
in film and a benchmark testbed for evaluating fu-
ture work.3
</bodyText>
<sectionHeader confidence="0.996859" genericHeader="introduction">
2 Data
</sectionHeader>
<subsectionHeader confidence="0.863101">
2.1 Text
</subsectionHeader>
<bodyText confidence="0.99898635">
Our primary source of data comes from 42,306
movie plot summaries extracted from the
November 2, 2012 dump of English-language
Wikipedia.4 These summaries, which have a
median length of approximately 176 words,5
contain a concise synopsis of the movie’s events,
along with implicit descriptions of the characters
(e.g., “rebel leader Princess Leia,” “evil lord Darth
Vader”). To extract structure from this data, we
use the Stanford CoreNLP library6 to tag and
syntactically parse the text, extract entities, and
resolve coreference within the document. With
this structured representation, we extract linguistic
features for each character, looking at immediate
verb governors and attribute syntactic dependen-
cies to all of the entity’s mention headwords,
extracted from the typed dependency tuples pro-
duced by the parser; we refer to “CCprocessed”
syntactic relations described in de Marneffe and
Manning (2008):
</bodyText>
<listItem confidence="0.997708666666666">
• Agent verbs. Verbs for which the entity is an
agent argument (nsubj or agent).
• Patient verbs. Verbs for which the entity is
the patient, theme or other argument (dobj,
nsubjpass, iobj, or any prepositional argu-
ment prep *).
• Attributes. Adjectives and common noun
words that relate to the mention as adjecti-
val modifiers, noun-noun compounds, appos-
itives, or copulas (nsubj or appos governors,
or nsubj, appos, amod, nn dependents of an
entity mention).
</listItem>
<footnote confidence="0.979675375">
3All datasets and software for replication can be found at
http://www.ark.cs.cmu.edu/personas.
4http://dumps.wikimedia.org/enwiki/
5More popular movies naturally attract more attention on
Wikipedia and hence more detail: the top 1,000 movies by
box office revenue have a median length of 715 words.
6http://nlp.stanford.edu/software/
corenlp.shtml
</footnote>
<bodyText confidence="0.999627375">
These three roles capture three different ways in
which character personas are revealed: the actions
they take on others, the actions done to them, and
the attributes by which they are described. For ev-
ery character we thus extract a bag of (r, w) tu-
ples, where w is the word lemma and r is one
of {agent verb, patient verb, attribute} as iden-
tified by the above rules.
</bodyText>
<subsectionHeader confidence="0.998995">
2.2 Metadata
</subsectionHeader>
<bodyText confidence="0.99998684375">
Our second source of information consists of char-
acter and movie metadata drawn from the Novem-
ber 4, 2012 dump of Freebase.7 At the movie
level, this includes data on the language, country,
release date and detailed genre (365 non-mutually
exclusive categories, including “Epic Western,”
“Revenge,” and “Hip Hop Movies”). Many of the
characters in movies are also associated with the
actors who play them; since many actors also have
detailed biographical information, we can ground
the characters in what we know of those real peo-
ple – including their gender and estimated age at
the time of the movie’s release (the difference be-
tween the release date of the movie and the actor’s
date of birth).
Across all 42,306 movies, entities average 3.4
agent events, 2.0 patient events, and 2.1 attributes.
For all experiments described below, we restrict
our dataset to only those events that are among the
1,000 most frequent overall, and only characters
with at least 3 events. 120,345 characters meet this
criterion; of these, 33,559 can be matched to Free-
base actors with a specified gender, and 29,802 can
be matched to actors with a given date of birth. Of
all actors in the Freebase data whose age is given,
the average age at the time of movie is 37.9 (stan-
dard deviation 14.1); of all actors whose gender
is known, 66.7% are male.8 The age distribution
is strongly bimodal when conditioning on gender:
the average age of a female actress at the time of a
movie’s release is 33.0 (s.d. 13.4), while that of a
male actor is 40.5 (s.d. 13.7).
</bodyText>
<sectionHeader confidence="0.997799" genericHeader="method">
3 Personas
</sectionHeader>
<bodyText confidence="0.956652">
One way we recognize a character’s latent type
is by observing the stereotypical actions they
</bodyText>
<footnote confidence="0.993269833333333">
7http://download.freebase.com/
datadumps/
8Whether this extreme 2:1 male/female ratio reflects an
inherent bias in film or a bias in attention on Freebase (or
Wikipedia, on which it draws) is an interesting research ques-
tion in itself.
</footnote>
<page confidence="0.998754">
353
</page>
<figure confidence="0.998737111111111">
w
v
0
Y
W
a
P
e
Z
r
W
E
D
w
v
µ β σ2
φ
Y
W
P Me
Z
Md
r
W
E
D
Number of personas (hyperparameter)
Number of word topics (hyperparameter)
Number of movie plot summaries
Number of characters in movie d
Number of (role, word) tuples used by character e
Topic k’s distribution over V words.
Tuple role: agent verb, patient verb, attribute
Distribution over topics for persona p in role r
Movie d’s distribution over personas
Character e’s persona (integer, p ∈ {1..P})
A specific (r, w) tuple in the data
Word topic for tuple j
Word for tuple j
Concentration parameter for Dirichlet model
Feature weights for regression model
Gaussian mean and variance (for regularizing 0)
Movie features (from movie metadata)
Entity features (from movie actor metadata)
Dirichlet concentration parameters
</figure>
<figureCaption confidence="0.930840666666667">
Figure 2: Above: Dirichlet persona model (left)
and persona regression model (right). Bottom:
Definition of variables.
</figureCaption>
<bodyText confidence="0.814910666666667">
for simplicity. Throughout, V is the word vocab-
ulary size, P is the number of personas, and K is
the number of topics.
</bodyText>
<subsectionHeader confidence="0.97111">
4.1 Dirichlet Persona Model
</subsectionHeader>
<bodyText confidence="0.999873181818182">
In the most basic model, we only use informa-
tion from the structured text, which comes as a
bag of (r, w) tuples for each character in a movie,
where w is the word lemma and r is the rela-
tion of the word with respect to the character (one
of agent verb, patient verb or attribute, as out-
lined in §2.1 above). The generative story runs as
follows. First, let there be K latent word topics;
as in LDA (Blei et al., 2003), these are words that
will be soft-clustered together by virtue of appear-
ing in similar contexts. Each latent word cluster
</bodyText>
<figure confidence="0.824375421052632">
P
K
D
E
W
Ok
r
pp,r
Bd
pe
j
zj
wj
α
0
µ, σ2
Md
Me
yr, γ
</figure>
<bodyText confidence="0.99934975">
perform (e.g., VILLAINS strangle), the actions
done to them (e.g., VILLAINS are foiled and ar-
rested) and the words by which they are described
(VILLAINS are evil). To capture this intuition, we
define a persona as a set of three typed distribu-
tions: one for the words for which the character is
the agent, one for which it is the patient, and one
for words by which the character is attributively
modified. Each distribution ranges over a fixed set
of latent word classes, or topics. Figure 1 illus-
trates this definition for a toy example: a ZOMBIE
persona may be characterized as being the agent
of primarily eating and killing actions, the patient
of killing actions, and the object of dead attributes.
The topic labeled eat may include words like eat,
drink, and devour.
</bodyText>
<subsectionHeader confidence="0.540998">
agent patient attribute
</subsectionHeader>
<figureCaption confidence="0.910344">
Figure 1: A persona is a set of three distributions
</figureCaption>
<bodyText confidence="0.9585492">
over latent topics. In this toy example, the ZOM-
BIE persona is primarily characterized by being
the agent of words from the eat and kill topics, the
patient of kill words, and the object of words from
the dead topic.
</bodyText>
<sectionHeader confidence="0.995571" genericHeader="method">
4 Models
</sectionHeader>
<bodyText confidence="0.999929470588235">
Both models that we present here simultaneously
learn three things: 1.) a soft clustering over words
to topics (e.g., the verb “strangle” is mostly a type
of Assault word); 2.) a soft clustering over top-
ics to personas (e.g., VILLIANS perform a lot of
Assault actions); and 3.) a hard clustering over
characters to personas (e.g., Darth Vader is a VIL-
LAIN.) They each use different evidence: since
our data includes not only textual features (in the
form of actions and attributes of the characters) but
also non-textual information (such as movie genre,
age and gender), we design a model that exploits
this additional source of information in discrimi-
nating between character types; since this extra-
linguistic information may not always be avail-
able, we also design a model that learns only from
the text itself. We present the text-only model first
</bodyText>
<figure confidence="0.997551944444445">
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
eat
kill
love
dead
happy
eat
kill
love
dead
happy
eat
kill
love
dead
happy
</figure>
<page confidence="0.995837">
354
</page>
<bodyText confidence="0.9974495">
φk — Dir(γ) is a multinomial over the V words in
the vocabulary, drawn from a Dirichlet parameter-
ized by γ. Next, let a persona p be defined as a set
of three multinomials ψp over these K topics, one
for each typed role r, each drawn from a Dirichlet
with a role-specific hyperparameter (νr).
Every document (a movie plot summary) con-
tains a set of characters, each of which is associ-
ated with a single latent persona p; for every ob-
served (r, w) tuple associated with the character,
we sample a latent topic k from the role-specific
ψp,r. Conditioned on this topic assignment, the
observed word is drawn from φk. The distribu-
tion of these personas for a given document is de-
termined by a document-specific multinomial θ,
drawn from a Dirichlet parameterized by α.
Figure 2 (above left) illustrates the form of the
model. To simplify inference, we collapse out the
persona-topic distributions ψ, the topic-word dis-
tributions φ and the persona distribution θ for each
document. Inference on the remaining latent vari-
ables – the persona p for each character type and
the topic z for each word associated with that char-
acter – is conducted via collapsed Gibbs sampling
(Griffiths and Steyvers, 2004); at each iteration,
for each character e, we sample their persona pe:
</bodyText>
<equation confidence="0.8986698">
P(pe = k  |p−e, z, α, ν) a
−e 1
(q,e
k + αk) X k,zj+−e rj,k,?+Kνrj)
Here, c−e
</equation>
<bodyText confidence="0.938682529411765">
d,k is the count of all characters in docu-
ment d whose current persona sample is also k
(not counting the current character e under con-
sideration);9 j ranges over all (rj, wj) tuples asso-
ciated with character e. Each c−e is the count
rj ,k,zj
of all tuples with role rj and current topic zj used
with persona k. c−e
rj,k,? is the same count, summing
over all topics z. In other words, the probabil-
ity that character e embodies persona k is propor-
tional to the number of other characters in the plot
summary who also embody that persona (plus the
Dirichlet hyperparameter αk) times the contribu-
tion of each observed word wj for that character,
given its current topic assignment zj.
Once all personas have been sampled, we sam-
</bodyText>
<footnote confidence="0.955653">
9The −e superscript denotes counts taken without consid-
ering the current sample for character e.
</footnote>
<equation confidence="0.890844">
ple the latent topics for each tuple as the following.
P(zj = k  |p, z−j, w, r, ν, γ) a
(c−j
rj ,p,k+νrj )
− X
(crjjp,?+Kνrj )
</equation>
<bodyText confidence="0.998338272727273">
Here, conditioned on the current sample p for
the character’s persona, the probability that tuple
j originates in topic k is proportional to the num-
ber of other tuples with that same role rj drawn
from the same topic for that persona (c−j
rj,p,k), nor-
malized by the number of other rj tuples associ-
ated with that persona overall (c−j
rj,p,?), multiplied
by the number of times word wj is associated with
that topic (c−j
k,wj) normalized by the total number
of other words associated with that topic overall
(c−j
k,?).
We optimize the values of the Dirichlet hyper-
parameters α, ν and γ using slice sampling with a
uniform prior every 20 iterations for the first 500
iterations, and every 100 iterations thereafter. Af-
ter a burn-in phase of 10,000 iterations, we collect
samples every 10 iterations (to lessen autocorrela-
tion) until a total of 100 have been collected.
</bodyText>
<subsectionHeader confidence="0.972843">
4.2 Persona Regression
</subsectionHeader>
<bodyText confidence="0.999987904761905">
To incorporate observed metadata in the form of
movie genre, character age and character gen-
der, we adopt an “upstream” modeling approach
(Mimno and McCallum, 2008), letting those ob-
served features influence the conditional probabil-
ity with which a given character is expected to as-
sume a particular persona, prior to observing any
of their actions. This captures the increased likeli-
hood, for example, that a 25-year-old male actor in
an action movie will play an ACTION HERO than
he will play a VALLEY GIRL.
To capture these effects, each character’s la-
tent persona is no longer drawn from a document-
specific Dirichlet; instead, the P-dimensional sim-
plex is the output of a multiclass logistic regres-
sion, where the document genre metadata md and
the character age and gender metadata me together
form a feature vector that combines with persona-
specific feature weights to form the following log-
linear distribution over personas, with the proba-
bility for persona k being:
</bodyText>
<equation confidence="0.947634">
emd βk)
P(p = k  |md, me, β) 1+PPP1[exp([mdTme]&gt; βj)
(3)
</equation>
<bodyText confidence="0.8138145">
The persona-specific β coefficients are learned
through Monte Carlo Expectation Maximization
</bodyText>
<figure confidence="0.7356868">
(c−j
k,wj+γ)
(c−j
k,?+V γ)
(2)
</figure>
<page confidence="0.988257">
355
</page>
<bodyText confidence="0.969505">
(Wei and Tanner, 1990), in which we alternate be-
tween the following:
</bodyText>
<listItem confidence="0.736521125">
1. Given current values for β, for all characters
e in all plot summaries, sample values of pe
and zj for all associated tuples.
2. Given input metadata features m and the as-
sociated sampled values of p, find the values
of β that maximize the standard multiclass lo-
gistic regression log likelihood, subject to `2
regularization.
</listItem>
<bodyText confidence="0.990982142857143">
Figure 2 (above right) illustrates this model. As
with the Dirichlet persona model, inference on p
for step 1 is conducted with collapsed Gibbs sam-
pling; the only difference in the sampling prob-
ability from equation 1 is the effect of the prior,
which here is deterministically fixed as the output
of the regression.
</bodyText>
<equation confidence="0.9986585">
P(pe = k  |p−e, z, ν, md, me, β) a
(cr e% z +νrj) (4)
exp([md; me]T βk) x �j (c−e ,
rj,k,.+Kν rj)
</equation>
<bodyText confidence="0.999949833333333">
The sampling equation for the topic assign-
ments z is identical to that in equation 2. In
practice we optimize β every 1,000 iterations, un-
til a burn-in phase of 10,000 iterations has been
reached; at this point we following the same sam-
pling regime as for the Dirichlet persona model.
</bodyText>
<sectionHeader confidence="0.999063" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999965">
We evaluate our methods in two quantitative ways
by measuring the degree to which we recover two
different sets of gold-standard clusterings. This
evaluation also helps offer guidance for model se-
lection (in choosing the number of latent topics
and personas) by measuring performance on an
objective task.
</bodyText>
<subsectionHeader confidence="0.991454">
5.1 Character Names
</subsectionHeader>
<bodyText confidence="0.999990909090909">
First, we consider all character names that occur in
at least two separate movies, generally as a conse-
quence of remakes or sequels; this includes proper
names such as “Rocky Balboa,” “Oliver Twist,”
and “Indiana Jones,” as well as generic type names
such as “Gang Member” and “The Thief”; to mini-
mize ambiguity, we only consider character names
consisting of at least two tokens. Each of these
names is used by at least two different characters;
for example, a character named “Jason Bourne”
is portrayed in The Bourne Identity, The Bourne
Supremacy, and The Bourne Ultimatum. While
these characters are certainly free to assume dif-
ferent roles in different movies, we believe that,
in the aggregate, they should tend to embody the
same character type and thus prove to be a natu-
ral clustering to recover. 970 character names oc-
cur at least twice in our data, and 2,666 individual
characters use one of those names. Let those 970
character names define 970 unique gold clusters
whose members include the individual characters
who use that name.
</bodyText>
<subsectionHeader confidence="0.991769">
5.2 TV Tropes
</subsectionHeader>
<bodyText confidence="0.99985865">
As a second external measure of validation, we
consider a manually created clustering presented
at the website TV Tropes,10 a wiki that col-
lects user-submitted examples of common tropes
(narrative, character and plot devices) found in
television, film, and fiction, among other me-
dia. While TV Tropes contains a wide range of
such conventions, we manually identified a set of
72 tropes that could reasonably be labeled char-
acter types, including THE CORRUPT CORPO-
RATE EXECUTIVE, THE HARDBOILED DETEC-
TIVE, THE JERK JOCK, THE KLUTZ and THE
SURFER DUDE.
We manually aligned user-submitted examples
of characters embodying these 72 character types
with the canonical references in Freebase to cre-
ate a test set of 501 individual characters. While
the 72 character tropes represented here are a more
subjective measure, we expect to be able to at least
partially recover this clustering.
</bodyText>
<subsectionHeader confidence="0.999897">
5.3 Variation of Information
</subsectionHeader>
<bodyText confidence="0.999958">
To measure the similarity between the two clus-
terings of movie characters, gold clusters 9 and
induced latent persona clusters C, we calculate the
variation of information (Meil˘a, 2007):
</bodyText>
<equation confidence="0.999976">
V I(9, C) = H(9) + H(C) − 2I(9, C) (5)
= H(9|C) + H(C|9) (6)
</equation>
<bodyText confidence="0.999390875">
VI measures the information-theoretic distance
between the two clusterings: a lower value means
greater similarity, and VI = 0 if they are iden-
tical. Low VI indicates that (induced) clusters
and (gold) clusters tend to overlap; i.e., knowing a
character’s (induced) cluster usually tells us their
(gold) cluster, and vice versa. Variation of infor-
mation is a metric (symmetric and obeys triangle
</bodyText>
<footnote confidence="0.951537">
10http://tvtropes.org
</footnote>
<page confidence="0.994282">
356
</page>
<table confidence="0.9998795">
Character Names §5.1 TV Tropes §5.2
K Model P = 25 P = 50 P = 100 P = 25 P = 50 P = 100
25 Persona regression 7.73 7.32 6.79 6.26 6.13 5.74
Dirichlet persona 7.83 7.11 6.44 6.29 6.01 5.57
50 Persona regression 7.59 7.08 6.46 6.30 5.99 5.65
Dirichlet persona 7.57 7.04 6.35 6.23 5.88 5.60
100 Persona regression 7.58 6.95 6.32 6.11 6.05 5.49
Dirichlet persona 7.64 6.95 6.25 6.24 5.91 5.42
</table>
<tableCaption confidence="0.9931045">
Table 1: Variation of information between learned personas and gold clusters for different numbers of
topics K and personas P. Lower values are better. All values are reported in bits.
</tableCaption>
<table confidence="0.999915375">
Character Names §5.1 TV Tropes §5.2
K Model P = 25 P = 50 P = 100 P = 25 P = 50 P = 100
25 Persona regression 62.8 (r41 %) 59.5 (r40 %) 53.7 (r33 %) 42.3 (r31 %) 38.5 (r24 %) 33.1 (r25 %)
Dirichlet persona 54.7 (r27 %) 50.5 (r26 %) 45.4 (r17 %) 39.5 (r20 %) 31.7 (r28 %) 25.1 (r21 %)
50 Persona regression 63.1 (r42 %) 59.8 (r42 %) 53.6 (r34 %) 42.9 (r30 %) 39.1 (r33 %) 31.3 (r20 %)
Dirichlet persona 57.2 (r34 %) 49.0 (r23 %) 44.7 (r16 %) 39.7 (r30 %) 31.5 (r32 %) 24.6 (r22 %)
100 Persona regression 63.1 (r42 %) 57.7 (r39 %) 53.0 (r34 %) 43.5 (r33 %) 32.1 (r28 %) 26.5 (r22 %)
Dirichlet persona 55.3 (r30 %) 49.5 (r24 %) 45.2 (r18 %) 39.7 (r34 %) 29.9 (r24 %) 23.6 (r19 %)
</table>
<tableCaption confidence="0.992972">
Table 2: Purity scores of recovering gold clusters. Higher values are better. Each absolute purity score
</tableCaption>
<bodyText confidence="0.959525829787234">
is paired with its improvement over a controlled baseline of permuting the learned labels while keeping
the cluster proportions the same.
inequality), and has a number of other desirable
properties.
Table 1 presents the VI between the learned per-
sona clusters and gold clusters, for varying num-
bers of personas (P = {25, 50,100}) and top-
ics (K = {25, 50, 100}). To determine signifi-
cance with respect to a random baseline, we con-
duct a permutation test (Fisher, 1935; Pitman,
1937) in which we randomly shuffle the labels of
the learned persona clusters and count the num-
ber of times in 1,000 such trials that the VI of
the observed persona labels is lower than the VI
of the permuted labels; this defines a nonparamet-
ric p-value. All results presented are significant at
p &lt; 0.001 (i.e. observed VI is never lower than
the simulation VI).
Over all tests in comparison to both gold clus-
terings, we see VI improve as both P and, to
a lesser extent, K increase. While this may be
expected as the number of personas increase to
match the number of distinct types in the gold
clusters (970 and 72, respectively), the fact that VI
improves as the number of latent topics increases
suggests that more fine-grained topics are helpful
for capturing nuanced character types.11
The difference between the persona regression
model and the Dirichlet persona model here is not
11This trend is robust to the choice of cluster metric: here
VI and F-score have a correlation of −0.87; as more latent
topics and personas are added, clustering improves (causing
the F-score to go up and the VI distance to go down).
significant; while VI allows us to compare mod-
els with different numbers of latent clusters, its re-
quirement that clusterings be mutually informative
places a high overhead on models that are funda-
mentally unidirectional (in Table 1, for example,
the room for improvement between two models
of the same P and K is naturally smaller than
the bigger difference between different P or K).
While we would naturally prefer a text-only model
to be as expressive as a model that requires po-
tentially hard to acquire metadata, we tease apart
whether a distinction actually does exist by evalu-
ating the purity of the gold clusters with respect to
the labels assigned them.
</bodyText>
<subsectionHeader confidence="0.994877">
5.4 Purity
</subsectionHeader>
<bodyText confidence="0.767256333333333">
For gold clusters G = {9i ...9k} and inferred
clusters C = {ci ... cj} we calculate purity as:
Purity = N
</bodyText>
<equation confidence="0.988221666666667">
1 �
k max |9k n cj |(7)
j
</equation>
<bodyText confidence="0.9999371">
While purity cannot be used to compare models of
different persona size P, it can help us distinguish
between models of the same size. A model can
attain perfect purity, however, by placing all char-
acters into a single cluster; to control for this, we
present a controlled baseline in which each char-
acter is assigned a latent character type label pro-
portional to the size of the latent clusters we have
learned (so that, for example, if one latent per-
sona cluster contains 3.2% of the total characters,
</bodyText>
<page confidence="0.979574">
357
</page>
<figure confidence="0.99629375">
The Bourne
Identity
Iron Man
Titanic
</figure>
<figureCaption confidence="0.916188">
dark, major, henchman
shoot, aim, overpower
sentence, arrest, assign
</figureCaption>
<figure confidence="0.92841748">
Jack
Dawson
Jason
Bourne
Tony
Stark
approve, die, suffer
relent, refuse, agree
inherit live imagine
Batman
Jim
Gordon
The Dark
Knight
Rachel
shoot, aim, overpower
testify, rebuff, confess
hatch, vow, undergo
Dracula
Colin
Sullivan
The
Joker
The Departed
Van Helsing
</figure>
<figureCaption confidence="0.998233">
Figure 3: Dramatis personae of The Dark Knight (2008), illustrating 3 of the 100 character types learned
</figureCaption>
<bodyText confidence="0.9508272">
by the persona regression model, along with links from other characters in those latent classes to other
movies. Each character type is listed with the top three latent topics with which it is associated.
the probability of selecting that persona at random
is 3.2%). Table 2 presents each model’s absolute
purity score paired with its improvement over its
controlled permutation (e.g., ↑41%).
Within each fixed-size partition, the use of
metadata yields a substantial improvement over
the Dirichlet model, both in terms of absolute pu-
rity and in its relative improvement over its sized-
controlled baseline. In practice, we find that while
the Dirichlet model distinguishes between charac-
ter personas in different movies, the persona re-
gression model helps distinguish between differ-
ent personas within the same movie.
</bodyText>
<sectionHeader confidence="0.993447" genericHeader="method">
6 Exploratory Data Analysis
</sectionHeader>
<bodyText confidence="0.9999316">
As with other generative approaches, latent per-
sona models enable exploratory data analysis. To
illustrate this, we present results from the persona
regression model learned above, with 50 latent
lexical classes and 100 latent personas. Figure 3
visualizes this data by focusing on a single movie,
The Dark Knight (2008); the movie’s protagonist,
Batman, belongs to the same latent persona as De-
tective Jim Gordon, as well as other action movie
protagonists Jason Bourne and Tony Stark (Iron
Man). The movie’s antagonist, The Joker, belongs
to the same latent persona as Dracula from Van
Helsing and Colin Sullivan from The Departed, il-
lustrating the ability of personas to be informed
by, but still cut across, different genres.
Table 3 presents an exhaustive list of all 50 top-
ics, along with an assigned label that consists of
the single word with the highest PMI for that class.
Of note are topics relating to romance (unite,
marry, woo, elope, court), commercial transac-
tions (purchase, sign, sell, owe, buy), and the clas-
sic criminal schema from Chambers (2011) (sen-
tence, arrest, assign, convict, promote).
Table 4 presents the most frequent 14 personas
in our dataset, illustrated with characters from
the 500 highest grossing movies. The personas
learned are each three separate mixtures of the
50 latent topics (one for agent relations, one for
patient relations, and one for attributes), as illus-
trated in figure 1 above. Rather than presenting
a 3 × 50 histogram for each persona, we illus-
trate them by listing the most characteristic top-
ics, movie characters, and metadata features asso-
ciated with it. Characteristic actions and features
are defined as those having the highest smoothed
pointwise mutual information with that class; ex-
emplary characters are those with the highest pos-
terior probability of being drawn from that class.
Among the personas learned are canonical male
action heroes (exemplified by the protagonists of
The Bourne Supremacy, Speed, and Taken), super-
heroes (Hulk, Batman and Robin, Hector of Troy)
and several romantic comedy types, largely char-
acterized by words drawn from the FLIRT topic,
including flirt, reconcile, date, dance and forgive.
</bodyText>
<page confidence="0.993138">
358
</page>
<table confidence="0.999921846153846">
Label Most characteristic words Label Most characteristic words
UNITE unite marry woo elope court SWITCH switch confirm escort report instruct
PURCHASE purchase sign sell owe buy INFATUATE infatuate obsess acquaint revolve concern
SHOOT shoot aim overpower interrogate kill ALIEN alien child governor bandit priest
EXPLORE explore investigate uncover deduce CAPTURE capture corner transport imprison trap
WOMAN woman friend wife sister husband MAYA maya monster monk goon dragon
WITCH witch villager kid boy mom INHERIT inherit live imagine experience share
INVADE invade sail travel land explore TESTIFY testify rebuff confess admit deny
DEFEAT defeat destroy transform battle inject APPLY apply struggle earn graduate develop
CHASE chase scare hit punch eat EXPEL expel inspire humiliate bully grant
TALK talk tell reassure assure calm DIG dig take welcome sink revolve
POP pop lift crawl laugh shake COMMAND command abduct invade seize surrender
SING sing perform cast produce dance RELENT relent refuse agree insist hope
APPROVE approve die suffer forbid collapse EMBARK embark befriend enlist recall meet
WEREWOLF werewolf mother parent killer father MANIPULATE manipulate conclude investigate conduct
DINER diner grandfather brother terrorist ELOPE elope forget succumb pretend like
DECAPITATE decapitate bite impale strangle stalk FLEE flee escape swim hide manage
REPLY reply say mention answer shout BABY baby sheriff vampire knight spirit
DEMON demon narrator mayor duck crime BIND bind select belong refer represent
CONGRATULATE congratulate cheer thank recommend REJOIN rejoin fly recruit include disguise
INTRODUCE introduce bring mock read hatch DARK dark major henchman warrior sergeant
HATCH hatch don exist vow undergo SENTENCE sentence arrest assign convict promote
FLIRT flirt reconcile date dance forgive DISTURB disturb frighten confuse tease scare
ADOPT adopt raise bear punish feed RIP rip vanish crawl drive smash
FAIRY fairy kidnapper soul slave president INFILTRATE infiltrate deduce leap evade obtain
BUG bug zombie warden king princess SCREAM scream faint wake clean hear
</table>
<tableCaption confidence="0.9527025">
Table 3: Latent topics learned for K = 50 and P = 100. The words shown for each class are those with
the highest smoothed PMI, with the label being the single word with the highest PMI.
</tableCaption>
<table confidence="0.999934696969697">
Freq Actions Characters Features
0.109 DARK,,,,, SHOOTa, Jason Bourne (The Bourne Supremacy), Jack Traven Action, Male, War
SHOOTp (Speed), Jean-Claude (Taken) film
0.079 CAPTUREp, Aang (The Last Airbender), Carly (Transformers: Dark of Female, Action,
INFILTRATEa, FLEEa the Moon), Susan Murphy/Ginormica (Monsters vs. Aliens) Adventure
0.067 DEFEATa, DEFEATp, Glenn Talbot (Hulk), Batman (Batman and Robin), Hector Action, Animation,
INFILTRATEa (Troy) Adventure
0.060 COMMANDa, DEFEATp, Zoe Neville (I Am Legend), Ursula (The Little Mermaid), Action, Adventure,
CAPTUREp Joker (Batman) Male
0.046 INFILTRATEa, Peter Parker (Spider-Man 3), Ethan Hunt (Mission: Male, Action, Age
EXPLOREa, EMBARKa Impossible), Jason Bourne (The Bourne Ultimatum) 34-36
0.036 FLIRTa, FLIRTp, Mark Darcy (Bridget Jones: The Edge of Reason), Jerry Female, Romance
TESTIFYa Maguire (Jerry Maguire), Donna (Mamma Mia!) Film, Comedy
0.033 EMBARKa, INFILTRATEa, Perseus (Wrath of the Titans), Maximus Decimus Meridius Male, Chinese
INVADEa (Gladiator), Julius (Twins) Movies, Spy
0.027 CONGRATULATEa, Professor Albus Dumbledore (Harry Potter and the Age 58+, Family
CONGRATULATEp, Philosopher’s Stone), Magic Mirror (Shrek), Josephine Film, Age 51-57
SWITCHa Anwhistle (Lemony Snicket’s A Series of Unfortunate
Events)
0.025 SWITCHa, SWITCHp, Clarice Starling (The Silence of the Lambs), Hannibal Age 58+, Male,
MANIPULATEa Lecter (The Silence of the Lambs), Colonel Bagley (The Age 45-50
Last Samurai)
0.022 REPLYa, TALKp, FLIRTp Graham (The Holiday), Abby Richter (The Ugly Truth), Female, Comedy,
Anna Scott (Notting Hill) Romance Film
0.020 EXPLOREa, EMBARKa, Harry Potter (Harry Potter and the Philosopher’s Stone), Adventure, Family
CAPTUREp Harry Potter (Harry Potter and the Chamber of Secrets), Film, Horror
Captain Leo Davidson (Planet of the Apes)
0.018 FAIRY,,,,, COMMANDa, Captain Jack Sparrow (Pirates of the Caribbean: At Action, Family
CAPTUREp World’s End), Shrek (Shrek), Shrek (Shrek Forever After) Film, Animation
0.018 DECAPITATEa, Jericho Cane (End of Days), Martin Riggs (Lethal Weapon Horror, Slasher,
DECAPITATEp, RIPa 2), Gabriel Van Helsing (Van Helsing) Teen
0.017 APPLYa, EXPELp, Oscar (Shark Tale), Elizabeth Halsey (Bad Teacher), Dre Female, Teen,
PURCHASEp Parker (The Karate Kid) Under Age 22
</table>
<tableCaption confidence="0.953632666666667">
Table 4: Of 100 latent personas learned, we present the top 14 by frequency. Actions index the latent
topic classes presented in table 3; subscripts denote whether the character is predominantly the agent (a),
patient (p) or is modified by an attribute (m).
</tableCaption>
<page confidence="0.998294">
359
</page>
<sectionHeader confidence="0.999105" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.99999712">
We present a method for automatically inferring
latent character personas from text (and metadata,
when available). While our testbed has been tex-
tual synopses of film, this approach is easily ex-
tended to other genres (such as novelistic fiction)
and to non-fictional domains as well, where the
choice of portraying a real-life person as embody-
ing a particular kind of persona may, for instance,
give insight into questions of media framing and
bias in newswire; self-presentation of individual
personas likewise has a long history in communi-
cation theory (Goffman, 1959) and may be use-
ful for inferring user types for personalization sys-
tems (El-Arini et al., 2012). While the goal of this
work has been to induce a set of latent character
classes and partition all characters among them,
one interesting question that remains is how a spe-
cific character’s actions may informatively be at
odds with their inferred persona, given the choice
of that persona as the single best fit to explain the
actions we observe. By examining how any indi-
vidual character deviates from the behavior indica-
tive of their type, we might be able to paint a more
nuanced picture of how a character can embody a
specific persona while resisting it at the same time.
</bodyText>
<sectionHeader confidence="0.999075" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999866444444444">
We thank Megan Morrison at the CMU School of
Drama for early conversations guiding our work,
as well as the anonymous reviewers for helpful
comments. The research reported in this article
was supported by U.S. National Science Founda-
tion grant IIS-0915187 and by an ARCS scholar-
ship to D.B. This work was made possible through
the use of computing resources made available by
the Pittsburgh Supercomputing Center.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999768704918033">
Aristotle. 335 BCE. Poetics, translated by Samuel H.
Butcher (1902). Macmillan, London.
David M. Blei, Andrew Ng, and Michael Jordan. 2003.
Latent dirichlet allocation. JMLR, 3:993–1022.
Joseph Campbell. 1949. The Hero with a Thousand
Faces. Pantheon Books.
Nathanael Chambers and Dan Jurafsky. 2008. Unsu-
pervised learning of narrative event chains. In Pro-
ceedings of ACL-08: HLT.
Nathanael Chambers and Dan Jurafsky. 2009. Unsu-
pervised learning of narrative schemas and their par-
ticipants. In Proceedings of the 47th Annual Meet-
ing of the ACL.
Nathanael Chambers. 2011. Inducing Event Schemas
and their Participants from Unlabeled Text. Ph.D.
thesis, Stanford University.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. Stanford typed dependencies manual.
Technical report, Stanford University.
Lajos Egri. 1946. The Art of Dramatic Writing. Simon
and Schuster, New York.
Khalid El-Arini, Ulrich Paquet, Ralf Herbrich, Jurgen
Van Gael, and Blaise Ag¨uera y Arcas. 2012. Trans-
parent user models for personalization. In Proceed-
ings of the 18th ACM SIGKDD.
Micha Elsner. 2012. Character-based kernels for nov-
elistic plot structure. In Proceedings of the 13th
Conference of the EACL.
Mark Alan Finlayson. 2011. Learning Narrative
Structure from Annotated Folktales. Ph.D. thesis,
MIT.
R. A. Fisher. 1935. The Design of Experiments. Oliver
and Boyde, Edinburgh and London.
Erving Goffman. 1959. The Presentation of the Self in
Everyday Life. Anchor.
Amit Goyal, Ellen Riloff, and Hal Daum´e, III. 2010.
Automatically producing plot unit representations
for narrative text. In Proceedings of the 2010 Con-
ference on EMNLP.
Trond Grenager and Christopher D. Manning. 2006.
Unsupervised discovery of a statistical verb lexicon.
In Proceedings of the 2006 Conference on EMNLP.
Thomas L. Griffiths and Mark Steyvers. 2004. Finding
scientific topics. PNAS, 101(suppl. 1):5228–5235.
Carl Jung. 1981. The Archetypes and The Collective
Unconscious, volume 9 of Collected Works. Bollin-
gen, Princeton, NJ, 2nd edition.
Neil McIntyre and Mirella Lapata. 2010. Plot induc-
tion and evolutionary search for story generation. In
Proceedings of the 48th Annual Meeting of the ACL.
Association for Computational Linguistics.
Robert McKee. 1997. Story: Substance, Structure,
Style and the Principles of Screenwriting. Harper-
Colllins.
Marina Meil˘a. 2007. Comparing clusterings—an in-
formation based distance. Journal of Multivariate
Analysis, 98(5):873–895.
David Mimno and Andrew McCallum. 2008. Topic
models conditioned on arbitrary features with
dirichlet-multinomial regression. In Proceedings of
UAI.
</reference>
<page confidence="0.974266">
360
</page>
<reference confidence="0.99975984375">
Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993. Distributional clustering of english words. In
Proceedings of the 31st Annual Meeting of the ACL.
E. J. G. Pitman. 1937. Significance tests which may
be applied to samples from any population. Supple-
ment to the Journal of the Royal Statistical Society,
4(1):119–130.
Michaela Regneri, Alexander Koller, and Manfred
Pinkal. 2010. Learning script knowledge with web
experiments. In Proceedings of the 48th Annual
Meeting of the ACL.
Michaela Regneri, Alexander Koller, Josef Ruppen-
hofer, and Manfred Pinkal. 2011. Learning script
participants from unlabeled data. In Proceedings of
the Conference on Recent Advances in Natural Lan-
guage Processing.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
plans, goals, and understanding: An inquiry into
human knowledge structures. Lawrence Erlbaum,
Hillsdale, NJ.
Ivan Titov and Alexandre Klementiev. 2012. A
bayesian approach to unsupervised semantic role in-
duction. In Proceedings of the 13th Conference of
EACL.
Greg C. G. Wei and Martin A. Tanner. 1990. A Monte
Carlo implementation of the EM algorithm and the
poor man’s data augmentation algorithms. Journal
of the American Statistical Association, 85:699–704.
Limin Yao, Aria Haghighi, Sebastian Riedel, and An-
drew McCallum. 2011. Structured relation discov-
ery using generative models. In Proceedings of the
Conference on EMNLP.
</reference>
<page confidence="0.998719">
361
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968423">
<title confidence="0.999998">Learning Latent Personas of Film Characters</title>
<author confidence="0.999994">David Bamman Brendan O’Connor Noah A Smith</author>
<affiliation confidence="0.9999575">School of Computer Science Carnegie Mellon University</affiliation>
<address confidence="0.999497">Pittsburgh, PA 15213, USA</address>
<abstract confidence="0.997754071428571">We present two latent variable models for character types, or in film, in which a persona is defined as a set of mixtures over latent lexical classes. These lexical classes capture the stereotypical actions of which a character is the agent and patient, as well as attributes by which they are described. As the first attempt to solve this problem explicitly, we also present a new dataset for the text-driven analysis of film, along with a benchmark testbed to help drive future work in this area.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>BCE Poetics</author>
<author>translated by Samuel H Butcher</author>
</authors>
<date>1902</date>
<publisher>Macmillan,</publisher>
<location>London.</location>
<marker>Poetics, Butcher, 1902</marker>
<rawString>Aristotle. 335 BCE. Poetics, translated by Samuel H. Butcher (1902). Macmillan, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<date>2003</date>
<booktitle>Latent dirichlet allocation. JMLR,</booktitle>
<pages>3--993</pages>
<contexts>
<context position="10172" citStr="Blei et al., 2003" startWordPosition="1671" endWordPosition="1674">sion model (right). Bottom: Definition of variables. for simplicity. Throughout, V is the word vocabulary size, P is the number of personas, and K is the number of topics. 4.1 Dirichlet Persona Model In the most basic model, we only use information from the structured text, which comes as a bag of (r, w) tuples for each character in a movie, where w is the word lemma and r is the relation of the word with respect to the character (one of agent verb, patient verb or attribute, as outlined in §2.1 above). The generative story runs as follows. First, let there be K latent word topics; as in LDA (Blei et al., 2003), these are words that will be soft-clustered together by virtue of appearing in similar contexts. Each latent word cluster P K D E W Ok r pp,r Bd pe j zj wj α 0 µ, σ2 Md Me yr, γ perform (e.g., VILLAINS strangle), the actions done to them (e.g., VILLAINS are foiled and arrested) and the words by which they are described (VILLAINS are evil). To capture this intuition, we define a persona as a set of three typed distributions: one for the words for which the character is the agent, one for which it is the patient, and one for words by which the character is attributively modified. Each distribu</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Ng, and Michael Jordan. 2003. Latent dirichlet allocation. JMLR, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Campbell</author>
</authors>
<title>The Hero with a Thousand Faces.</title>
<date>1949</date>
<publisher>Pantheon Books.</publisher>
<contexts>
<context position="3895" citStr="Campbell (1949)" startWordPosition="630" endWordPosition="632">g of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of attributes and actions by which we recognize those common types? How do we, as viewers, recognize a VILLIAN? At its most extreme, this perspective reduces to learning the grand archetypes of Joseph Campbell (1949) or Carl Jung (1981), such as the HERO or TRICKSTER. We seek, however, a more finegrained set that includes not only archetypes, but stereotypes as well – characters defined by a fixed set of actions widely known to be representative of 352 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 352–361, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics a class. This work offers a data-driven method for answering these questions, presenting two probablistic generative models for inferring latent character types. This is th</context>
</contexts>
<marker>Campbell, 1949</marker>
<rawString>Joseph Campbell. 1949. The Hero with a Thousand Faces. Pantheon Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative event chains.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT.</booktitle>
<contexts>
<context position="1313" citStr="Chambers and Jurafsky, 2008" startWordPosition="195" endWordPosition="198">testbed to help drive future work in this area. 1 Introduction Philosophers and dramatists have long argued whether the most important element of narrative is plot or character. Under a classical Aristotelian perspective, plot is supreme;1 modern theoretical dramatists and screenwriters disagree.2 Without addressing this debate directly, much computational work on narrative has focused on learning the sequence of events by which a story is defined; in this tradition we might situate seminal work on learning procedural scripts (Schank and Abelson, 1977; Regneri et al., 2010), narrative chains (Chambers and Jurafsky, 2008), and plot structure (Finlayson, 2011; Elsner, 2012; McIntyre and Lapata, 2010; Goyal et al., 2010). We present a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when they accept his rulings concerning character. C</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Unsupervised learning of narrative event chains. In Proceedings of ACL-08: HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative schemas and their participants.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="3062" citStr="Chambers and Jurafsky, 2009" startWordPosition="493" endWordPosition="496"> character types, or personas, we want to see involved (the PROTAGONIST, the LOVE INTEREST, the BEST FRIEND). After picking this set, we fill out each of these roles with specific attributes (female, 28 years old, klutzy); with this cast of characters, we then sketch out the set of events by which they interact with the world and with each other (runs but just misses the train, spills coffee on her boss) – through which they reveal to the viewer those inherent qualities about themselves. This work is inspired by past approaches that infer typed semantic arguments along with narrative schemas (Chambers and Jurafsky, 2009; Regneri et al., 2011), but seeks a more holistic view of character, one that learns from stereotypical attributes in addition to plot events. This work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can </context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2009. Unsupervised learning of narrative schemas and their participants. In Proceedings of the 47th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
</authors>
<title>Inducing Event Schemas and their Participants from Unlabeled Text.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="27508" citStr="Chambers (2011)" startWordPosition="4682" endWordPosition="4683">nists Jason Bourne and Tony Stark (Iron Man). The movie’s antagonist, The Joker, belongs to the same latent persona as Dracula from Van Helsing and Colin Sullivan from The Departed, illustrating the ability of personas to be informed by, but still cut across, different genres. Table 3 presents an exhaustive list of all 50 topics, along with an assigned label that consists of the single word with the highest PMI for that class. Of note are topics relating to romance (unite, marry, woo, elope, court), commercial transactions (purchase, sign, sell, owe, buy), and the classic criminal schema from Chambers (2011) (sentence, arrest, assign, convict, promote). Table 4 presents the most frequent 14 personas in our dataset, illustrated with characters from the 500 highest grossing movies. The personas learned are each three separate mixtures of the 50 latent topics (one for agent relations, one for patient relations, and one for attributes), as illustrated in figure 1 above. Rather than presenting a 3 × 50 histogram for each persona, we illustrate them by listing the most characteristic topics, movie characters, and metadata features associated with it. Characteristic actions and features are defined as t</context>
</contexts>
<marker>Chambers, 2011</marker>
<rawString>Nathanael Chambers. 2011. Inducing Event Schemas and their Participants from Unlabeled Text. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>Stanford typed dependencies manual.</title>
<date>2008</date>
<tech>Technical report,</tech>
<institution>Stanford University.</institution>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. Stanford typed dependencies manual. Technical report, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lajos Egri</author>
</authors>
<title>The Art of Dramatic Writing.</title>
<date>1946</date>
<publisher>Simon and Schuster,</publisher>
<location>New York.</location>
<contexts>
<context position="2035" citStr="Egri, 1946" startWordPosition="320" endWordPosition="321">a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when they accept his rulings concerning character. Character was a great factor in Aristotle’s time, and no fine play ever was or ever will be written without it” (Egri, 1946, p. 94); “What the reader wants is fascinating, complex characters” (McKee, 1997, 100). a story. Our testbed is film. Under this perspective, a character’s latent internal nature drives the action we observe. Articulating narrative in this way leads to a natural generative story: we first decide that we’re going to make a particular kind of movie (e.g., a romantic comedy), then decide on a set of character types, or personas, we want to see involved (the PROTAGONIST, the LOVE INTEREST, the BEST FRIEND). After picking this set, we fill out each of these roles with specific attributes (female, </context>
</contexts>
<marker>Egri, 1946</marker>
<rawString>Lajos Egri. 1946. The Art of Dramatic Writing. Simon and Schuster, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalid El-Arini</author>
<author>Ulrich Paquet</author>
<author>Ralf Herbrich</author>
<author>Jurgen Van Gael</author>
</authors>
<title>and Blaise Ag¨uera y Arcas.</title>
<date>2012</date>
<booktitle>In Proceedings of the 18th ACM SIGKDD.</booktitle>
<marker>El-Arini, Paquet, Herbrich, Van Gael, 2012</marker>
<rawString>Khalid El-Arini, Ulrich Paquet, Ralf Herbrich, Jurgen Van Gael, and Blaise Ag¨uera y Arcas. 2012. Transparent user models for personalization. In Proceedings of the 18th ACM SIGKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
</authors>
<title>Character-based kernels for novelistic plot structure.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the EACL.</booktitle>
<contexts>
<context position="1364" citStr="Elsner, 2012" startWordPosition="204" endWordPosition="205">osophers and dramatists have long argued whether the most important element of narrative is plot or character. Under a classical Aristotelian perspective, plot is supreme;1 modern theoretical dramatists and screenwriters disagree.2 Without addressing this debate directly, much computational work on narrative has focused on learning the sequence of events by which a story is defined; in this tradition we might situate seminal work on learning procedural scripts (Schank and Abelson, 1977; Regneri et al., 2010), narrative chains (Chambers and Jurafsky, 2008), and plot structure (Finlayson, 2011; Elsner, 2012; McIntyre and Lapata, 2010; Goyal et al., 2010). We present a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when they accept his rulings concerning character. Character was a great factor in Aristotle’s time, an</context>
</contexts>
<marker>Elsner, 2012</marker>
<rawString>Micha Elsner. 2012. Character-based kernels for novelistic plot structure. In Proceedings of the 13th Conference of the EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Alan Finlayson</author>
</authors>
<title>Learning Narrative Structure from Annotated Folktales.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>MIT.</institution>
<contexts>
<context position="1350" citStr="Finlayson, 2011" startWordPosition="202" endWordPosition="203">Introduction Philosophers and dramatists have long argued whether the most important element of narrative is plot or character. Under a classical Aristotelian perspective, plot is supreme;1 modern theoretical dramatists and screenwriters disagree.2 Without addressing this debate directly, much computational work on narrative has focused on learning the sequence of events by which a story is defined; in this tradition we might situate seminal work on learning procedural scripts (Schank and Abelson, 1977; Regneri et al., 2010), narrative chains (Chambers and Jurafsky, 2008), and plot structure (Finlayson, 2011; Elsner, 2012; McIntyre and Lapata, 2010; Goyal et al., 2010). We present a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when they accept his rulings concerning character. Character was a great factor in Aristo</context>
</contexts>
<marker>Finlayson, 2011</marker>
<rawString>Mark Alan Finlayson. 2011. Learning Narrative Structure from Annotated Folktales. Ph.D. thesis, MIT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Fisher</author>
</authors>
<title>The Design of Experiments. Oliver and Boyde,</title>
<date>1935</date>
<location>Edinburgh and London.</location>
<contexts>
<context position="22672" citStr="Fisher, 1935" startWordPosition="3871" endWordPosition="3872">) 39.7 (r34 %) 29.9 (r24 %) 23.6 (r19 %) Table 2: Purity scores of recovering gold clusters. Higher values are better. Each absolute purity score is paired with its improvement over a controlled baseline of permuting the learned labels while keeping the cluster proportions the same. inequality), and has a number of other desirable properties. Table 1 presents the VI between the learned persona clusters and gold clusters, for varying numbers of personas (P = {25, 50,100}) and topics (K = {25, 50, 100}). To determine significance with respect to a random baseline, we conduct a permutation test (Fisher, 1935; Pitman, 1937) in which we randomly shuffle the labels of the learned persona clusters and count the number of times in 1,000 such trials that the VI of the observed persona labels is lower than the VI of the permuted labels; this defines a nonparametric p-value. All results presented are significant at p &lt; 0.001 (i.e. observed VI is never lower than the simulation VI). Over all tests in comparison to both gold clusterings, we see VI improve as both P and, to a lesser extent, K increase. While this may be expected as the number of personas increase to match the number of distinct types in the</context>
</contexts>
<marker>Fisher, 1935</marker>
<rawString>R. A. Fisher. 1935. The Design of Experiments. Oliver and Boyde, Edinburgh and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erving Goffman</author>
</authors>
<title>The Presentation of the Self in Everyday Life.</title>
<date>1959</date>
<publisher>Anchor.</publisher>
<contexts>
<context position="34066" citStr="Goffman, 1959" startWordPosition="5654" endWordPosition="5655">fied by an attribute (m). 359 7 Conclusion We present a method for automatically inferring latent character personas from text (and metadata, when available). While our testbed has been textual synopses of film, this approach is easily extended to other genres (such as novelistic fiction) and to non-fictional domains as well, where the choice of portraying a real-life person as embodying a particular kind of persona may, for instance, give insight into questions of media framing and bias in newswire; self-presentation of individual personas likewise has a long history in communication theory (Goffman, 1959) and may be useful for inferring user types for personalization systems (El-Arini et al., 2012). While the goal of this work has been to induce a set of latent character classes and partition all characters among them, one interesting question that remains is how a specific character’s actions may informatively be at odds with their inferred persona, given the choice of that persona as the single best fit to explain the actions we observe. By examining how any individual character deviates from the behavior indicative of their type, we might be able to paint a more nuanced picture of how a cha</context>
</contexts>
<marker>Goffman, 1959</marker>
<rawString>Erving Goffman. 1959. The Presentation of the Self in Everyday Life. Anchor.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Goyal</author>
<author>Ellen Riloff</author>
<author>Hal Daum´e</author>
</authors>
<title>Automatically producing plot unit representations for narrative text.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on EMNLP.</booktitle>
<marker>Goyal, Riloff, Daum´e, 2010</marker>
<rawString>Amit Goyal, Ellen Riloff, and Hal Daum´e, III. 2010. Automatically producing plot unit representations for narrative text. In Proceedings of the 2010 Conference on EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trond Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>Unsupervised discovery of a statistical verb lexicon.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on EMNLP.</booktitle>
<contexts>
<context position="3370" citStr="Grenager and Manning, 2006" startWordPosition="545" endWordPosition="548">act with the world and with each other (runs but just misses the train, spills coffee on her boss) – through which they reveal to the viewer those inherent qualities about themselves. This work is inspired by past approaches that infer typed semantic arguments along with narrative schemas (Chambers and Jurafsky, 2009; Regneri et al., 2011), but seeks a more holistic view of character, one that learns from stereotypical attributes in addition to plot events. This work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of attributes and actions by which we recognize those common types? How do we, as viewers, recognize a VILLIAN? At its most extreme, this perspective reduces to learning the grand archetypes of Joseph Campbell (1949) or Carl Jung (1981), such as the HERO or TRICKSTER. We seek, however, a mo</context>
</contexts>
<marker>Grenager, Manning, 2006</marker>
<rawString>Trond Grenager and Christopher D. Manning. 2006. Unsupervised discovery of a statistical verb lexicon. In Proceedings of the 2006 Conference on EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<journal>PNAS,</journal>
<volume>101</volume>
<pages>1--5228</pages>
<contexts>
<context position="13627" citStr="Griffiths and Steyvers, 2004" startWordPosition="2285" endWordPosition="2288">ssignment, the observed word is drawn from φk. The distribution of these personas for a given document is determined by a document-specific multinomial θ, drawn from a Dirichlet parameterized by α. Figure 2 (above left) illustrates the form of the model. To simplify inference, we collapse out the persona-topic distributions ψ, the topic-word distributions φ and the persona distribution θ for each document. Inference on the remaining latent variables – the persona p for each character type and the topic z for each word associated with that character – is conducted via collapsed Gibbs sampling (Griffiths and Steyvers, 2004); at each iteration, for each character e, we sample their persona pe: P(pe = k |p−e, z, α, ν) a −e 1 (q,e k + αk) X k,zj+−e rj,k,?+Kνrj) Here, c−e d,k is the count of all characters in document d whose current persona sample is also k (not counting the current character e under consideration);9 j ranges over all (rj, wj) tuples associated with character e. Each c−e is the count rj ,k,zj of all tuples with role rj and current topic zj used with persona k. c−e rj,k,? is the same count, summing over all topics z. In other words, the probability that character e embodies persona k is proportional</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. PNAS, 101(suppl. 1):5228–5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Jung</author>
</authors>
<title>The Archetypes and The Collective Unconscious,</title>
<date>1981</date>
<volume>9</volume>
<location>Bollingen, Princeton, NJ,</location>
<note>2nd edition.</note>
<contexts>
<context position="3915" citStr="Jung (1981)" startWordPosition="635" endWordPosition="636">d semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of attributes and actions by which we recognize those common types? How do we, as viewers, recognize a VILLIAN? At its most extreme, this perspective reduces to learning the grand archetypes of Joseph Campbell (1949) or Carl Jung (1981), such as the HERO or TRICKSTER. We seek, however, a more finegrained set that includes not only archetypes, but stereotypes as well – characters defined by a fixed set of actions widely known to be representative of 352 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 352–361, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics a class. This work offers a data-driven method for answering these questions, presenting two probablistic generative models for inferring latent character types. This is the first work that at</context>
</contexts>
<marker>Jung, 1981</marker>
<rawString>Carl Jung. 1981. The Archetypes and The Collective Unconscious, volume 9 of Collected Works. Bollingen, Princeton, NJ, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil McIntyre</author>
<author>Mirella Lapata</author>
</authors>
<title>Plot induction and evolutionary search for story generation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the ACL. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1391" citStr="McIntyre and Lapata, 2010" startWordPosition="206" endWordPosition="210">ramatists have long argued whether the most important element of narrative is plot or character. Under a classical Aristotelian perspective, plot is supreme;1 modern theoretical dramatists and screenwriters disagree.2 Without addressing this debate directly, much computational work on narrative has focused on learning the sequence of events by which a story is defined; in this tradition we might situate seminal work on learning procedural scripts (Schank and Abelson, 1977; Regneri et al., 2010), narrative chains (Chambers and Jurafsky, 2008), and plot structure (Finlayson, 2011; Elsner, 2012; McIntyre and Lapata, 2010; Goyal et al., 2010). We present a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when they accept his rulings concerning character. Character was a great factor in Aristotle’s time, and no fine play ever was or </context>
</contexts>
<marker>McIntyre, Lapata, 2010</marker>
<rawString>Neil McIntyre and Mirella Lapata. 2010. Plot induction and evolutionary search for story generation. In Proceedings of the 48th Annual Meeting of the ACL. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert McKee</author>
</authors>
<date>1997</date>
<booktitle>Story: Substance, Structure, Style and the Principles of Screenwriting.</booktitle>
<publisher>HarperColllins.</publisher>
<contexts>
<context position="2116" citStr="McKee, 1997" startWordPosition="332" endWordPosition="333">ng 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when they accept his rulings concerning character. Character was a great factor in Aristotle’s time, and no fine play ever was or ever will be written without it” (Egri, 1946, p. 94); “What the reader wants is fascinating, complex characters” (McKee, 1997, 100). a story. Our testbed is film. Under this perspective, a character’s latent internal nature drives the action we observe. Articulating narrative in this way leads to a natural generative story: we first decide that we’re going to make a particular kind of movie (e.g., a romantic comedy), then decide on a set of character types, or personas, we want to see involved (the PROTAGONIST, the LOVE INTEREST, the BEST FRIEND). After picking this set, we fill out each of these roles with specific attributes (female, 28 years old, klutzy); with this cast of characters, we then sketch out the set o</context>
</contexts>
<marker>McKee, 1997</marker>
<rawString>Robert McKee. 1997. Story: Substance, Structure, Style and the Principles of Screenwriting. HarperColllins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Meil˘a</author>
</authors>
<title>Comparing clusterings—an information based distance.</title>
<date>2007</date>
<journal>Journal of Multivariate Analysis,</journal>
<volume>98</volume>
<issue>5</issue>
<marker>Meil˘a, 2007</marker>
<rawString>Marina Meil˘a. 2007. Comparing clusterings—an information based distance. Journal of Multivariate Analysis, 98(5):873–895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Andrew McCallum</author>
</authors>
<title>Topic models conditioned on arbitrary features with dirichlet-multinomial regression.</title>
<date>2008</date>
<booktitle>In Proceedings of UAI.</booktitle>
<contexts>
<context position="15777" citStr="Mimno and McCallum, 2008" startWordPosition="2670" endWordPosition="2673">malized by the total number of other words associated with that topic overall (c−j k,?). We optimize the values of the Dirichlet hyperparameters α, ν and γ using slice sampling with a uniform prior every 20 iterations for the first 500 iterations, and every 100 iterations thereafter. After a burn-in phase of 10,000 iterations, we collect samples every 10 iterations (to lessen autocorrelation) until a total of 100 have been collected. 4.2 Persona Regression To incorporate observed metadata in the form of movie genre, character age and character gender, we adopt an “upstream” modeling approach (Mimno and McCallum, 2008), letting those observed features influence the conditional probability with which a given character is expected to assume a particular persona, prior to observing any of their actions. This captures the increased likelihood, for example, that a 25-year-old male actor in an action movie will play an ACTION HERO than he will play a VALLEY GIRL. To capture these effects, each character’s latent persona is no longer drawn from a documentspecific Dirichlet; instead, the P-dimensional simplex is the output of a multiclass logistic regression, where the document genre metadata md and the character a</context>
</contexts>
<marker>Mimno, McCallum, 2008</marker>
<rawString>David Mimno and Andrew McCallum. 2008. Topic models conditioned on arbitrary features with dirichlet-multinomial regression. In Proceedings of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of english words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="3342" citStr="Pereira et al., 1993" startWordPosition="541" endWordPosition="544">ts by which they interact with the world and with each other (runs but just misses the train, spills coffee on her boss) – through which they reveal to the viewer those inherent qualities about themselves. This work is inspired by past approaches that infer typed semantic arguments along with narrative schemas (Chambers and Jurafsky, 2009; Regneri et al., 2011), but seeks a more holistic view of character, one that learns from stereotypical attributes in addition to plot events. This work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of attributes and actions by which we recognize those common types? How do we, as viewers, recognize a VILLIAN? At its most extreme, this perspective reduces to learning the grand archetypes of Joseph Campbell (1949) or Carl Jung (1981), such as the HERO or TRICK</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of english words. In Proceedings of the 31st Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E J G Pitman</author>
</authors>
<title>Significance tests which may be applied to samples from any population. Supplement to the</title>
<date>1937</date>
<journal>Journal of the Royal Statistical Society,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="22687" citStr="Pitman, 1937" startWordPosition="3873" endWordPosition="3874"> 29.9 (r24 %) 23.6 (r19 %) Table 2: Purity scores of recovering gold clusters. Higher values are better. Each absolute purity score is paired with its improvement over a controlled baseline of permuting the learned labels while keeping the cluster proportions the same. inequality), and has a number of other desirable properties. Table 1 presents the VI between the learned persona clusters and gold clusters, for varying numbers of personas (P = {25, 50,100}) and topics (K = {25, 50, 100}). To determine significance with respect to a random baseline, we conduct a permutation test (Fisher, 1935; Pitman, 1937) in which we randomly shuffle the labels of the learned persona clusters and count the number of times in 1,000 such trials that the VI of the observed persona labels is lower than the VI of the permuted labels; this defines a nonparametric p-value. All results presented are significant at p &lt; 0.001 (i.e. observed VI is never lower than the simulation VI). Over all tests in comparison to both gold clusterings, we see VI improve as both P and, to a lesser extent, K increase. While this may be expected as the number of personas increase to match the number of distinct types in the gold clusters </context>
</contexts>
<marker>Pitman, 1937</marker>
<rawString>E. J. G. Pitman. 1937. Significance tests which may be applied to samples from any population. Supplement to the Journal of the Royal Statistical Society, 4(1):119–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michaela Regneri</author>
<author>Alexander Koller</author>
<author>Manfred Pinkal</author>
</authors>
<title>Learning script knowledge with web experiments.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the ACL.</booktitle>
<contexts>
<context position="1265" citStr="Regneri et al., 2010" startWordPosition="189" endWordPosition="192">analysis of film, along with a benchmark testbed to help drive future work in this area. 1 Introduction Philosophers and dramatists have long argued whether the most important element of narrative is plot or character. Under a classical Aristotelian perspective, plot is supreme;1 modern theoretical dramatists and screenwriters disagree.2 Without addressing this debate directly, much computational work on narrative has focused on learning the sequence of events by which a story is defined; in this tradition we might situate seminal work on learning procedural scripts (Schank and Abelson, 1977; Regneri et al., 2010), narrative chains (Chambers and Jurafsky, 2008), and plot structure (Finlayson, 2011; Elsner, 2012; McIntyre and Lapata, 2010; Goyal et al., 2010). We present a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars are mistaken today when</context>
</contexts>
<marker>Regneri, Koller, Pinkal, 2010</marker>
<rawString>Michaela Regneri, Alexander Koller, and Manfred Pinkal. 2010. Learning script knowledge with web experiments. In Proceedings of the 48th Annual Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michaela Regneri</author>
<author>Alexander Koller</author>
<author>Josef Ruppenhofer</author>
<author>Manfred Pinkal</author>
</authors>
<title>Learning script participants from unlabeled data.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Recent Advances in Natural Language Processing.</booktitle>
<contexts>
<context position="3085" citStr="Regneri et al., 2011" startWordPosition="497" endWordPosition="501">, we want to see involved (the PROTAGONIST, the LOVE INTEREST, the BEST FRIEND). After picking this set, we fill out each of these roles with specific attributes (female, 28 years old, klutzy); with this cast of characters, we then sketch out the set of events by which they interact with the world and with each other (runs but just misses the train, spills coffee on her boss) – through which they reveal to the viewer those inherent qualities about themselves. This work is inspired by past approaches that infer typed semantic arguments along with narrative schemas (Chambers and Jurafsky, 2009; Regneri et al., 2011), but seeks a more holistic view of character, one that learns from stereotypical attributes in addition to plot events. This work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of att</context>
</contexts>
<marker>Regneri, Koller, Ruppenhofer, Pinkal, 2011</marker>
<rawString>Michaela Regneri, Alexander Koller, Josef Ruppenhofer, and Manfred Pinkal. 2011. Learning script participants from unlabeled data. In Proceedings of the Conference on Recent Advances in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
<author>Robert P Abelson</author>
</authors>
<title>Scripts, plans, goals, and understanding: An inquiry into human knowledge structures. Lawrence Erlbaum,</title>
<date>1977</date>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="1242" citStr="Schank and Abelson, 1977" startWordPosition="185" endWordPosition="188">taset for the text-driven analysis of film, along with a benchmark testbed to help drive future work in this area. 1 Introduction Philosophers and dramatists have long argued whether the most important element of narrative is plot or character. Under a classical Aristotelian perspective, plot is supreme;1 modern theoretical dramatists and screenwriters disagree.2 Without addressing this debate directly, much computational work on narrative has focused on learning the sequence of events by which a story is defined; in this tradition we might situate seminal work on learning procedural scripts (Schank and Abelson, 1977; Regneri et al., 2010), narrative chains (Chambers and Jurafsky, 2008), and plot structure (Finlayson, 2011; Elsner, 2012; McIntyre and Lapata, 2010; Goyal et al., 2010). We present a complementary perspective that addresses the importance of character in defining 1“Dramatic action ... is not with a view to the representation of character: character comes in as subsidiary to the actions ... The Plot, then, is the first principle, and, as it were, the soul of a tragedy: Character holds the second place.” Poetics I.VI (Aristotle, 335 BCE). 2“Aristotle was mistaken in his time, and our scholars </context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Roger C. Schank and Robert P. Abelson. 1977. Scripts, plans, goals, and understanding: An inquiry into human knowledge structures. Lawrence Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A bayesian approach to unsupervised semantic role induction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of EACL.</booktitle>
<contexts>
<context position="3399" citStr="Titov and Klementiev, 2012" startWordPosition="549" endWordPosition="552">each other (runs but just misses the train, spills coffee on her boss) – through which they reveal to the viewer those inherent qualities about themselves. This work is inspired by past approaches that infer typed semantic arguments along with narrative schemas (Chambers and Jurafsky, 2009; Regneri et al., 2011), but seeks a more holistic view of character, one that learns from stereotypical attributes in addition to plot events. This work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of attributes and actions by which we recognize those common types? How do we, as viewers, recognize a VILLIAN? At its most extreme, this perspective reduces to learning the grand archetypes of Joseph Campbell (1949) or Carl Jung (1981), such as the HERO or TRICKSTER. We seek, however, a more finegrained set that inclu</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012. A bayesian approach to unsupervised semantic role induction. In Proceedings of the 13th Conference of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg C G Wei</author>
<author>Martin A Tanner</author>
</authors>
<title>A Monte Carlo implementation of the EM algorithm and the poor man’s data augmentation algorithms.</title>
<date>1990</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>85--699</pages>
<contexts>
<context position="16793" citStr="Wei and Tanner, 1990" startWordPosition="2837" endWordPosition="2840"> persona is no longer drawn from a documentspecific Dirichlet; instead, the P-dimensional simplex is the output of a multiclass logistic regression, where the document genre metadata md and the character age and gender metadata me together form a feature vector that combines with personaspecific feature weights to form the following loglinear distribution over personas, with the probability for persona k being: emd βk) P(p = k |md, me, β) 1+PPP1[exp([mdTme]&gt; βj) (3) The persona-specific β coefficients are learned through Monte Carlo Expectation Maximization (c−j k,wj+γ) (c−j k,?+V γ) (2) 355 (Wei and Tanner, 1990), in which we alternate between the following: 1. Given current values for β, for all characters e in all plot summaries, sample values of pe and zj for all associated tuples. 2. Given input metadata features m and the associated sampled values of p, find the values of β that maximize the standard multiclass logistic regression log likelihood, subject to `2 regularization. Figure 2 (above right) illustrates this model. As with the Dirichlet persona model, inference on p for step 1 is conducted with collapsed Gibbs sampling; the only difference in the sampling probability from equation 1 is the</context>
</contexts>
<marker>Wei, Tanner, 1990</marker>
<rawString>Greg C. G. Wei and Martin A. Tanner. 1990. A Monte Carlo implementation of the EM algorithm and the poor man’s data augmentation algorithms. Journal of the American Statistical Association, 85:699–704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Aria Haghighi</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Structured relation discovery using generative models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on EMNLP.</booktitle>
<contexts>
<context position="3454" citStr="Yao et al., 2011" startWordPosition="558" endWordPosition="561">boss) – through which they reveal to the viewer those inherent qualities about themselves. This work is inspired by past approaches that infer typed semantic arguments along with narrative schemas (Chambers and Jurafsky, 2009; Regneri et al., 2011), but seeks a more holistic view of character, one that learns from stereotypical attributes in addition to plot events. This work also naturally draws on earlier work on the unsupervised learning of verbal arguments and semantic roles (Pereira et al., 1993; Grenager and Manning, 2006; Titov and Klementiev, 2012) and unsupervised relation discovery (Yao et al., 2011). This character-centric perspective leads to two natural questions. First, can we learn what those standard personas are by how individual characters (who instantiate those types) are portrayed? Second, can we learn the set of attributes and actions by which we recognize those common types? How do we, as viewers, recognize a VILLIAN? At its most extreme, this perspective reduces to learning the grand archetypes of Joseph Campbell (1949) or Carl Jung (1981), such as the HERO or TRICKSTER. We seek, however, a more finegrained set that includes not only archetypes, but stereotypes as well – char</context>
</contexts>
<marker>Yao, Haghighi, Riedel, McCallum, 2011</marker>
<rawString>Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew McCallum. 2011. Structured relation discovery using generative models. In Proceedings of the Conference on EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>