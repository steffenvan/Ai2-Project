<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.9982225">
Learning Multi Character Alignment Rules and Classification of training
data for Transliteration
</title>
<author confidence="0.988764">
Dipankar Bose
</author>
<affiliation confidence="0.936989">
Dept. of Computer Science and Engg.
Indian Institute of Technology
Kharagpur, West Bengal
</affiliation>
<address confidence="0.627389">
India - 721302
</address>
<email confidence="0.990488">
dipankarcsiit@gmail.com
</email>
<author confidence="0.976151">
Sudeshna Sarkar
</author>
<affiliation confidence="0.936616333333333">
Dept. of Computer Science and Engg.
Indian Institute of Technology
Kharagpur, West Bengal
</affiliation>
<address confidence="0.62961">
India - 721302
</address>
<email confidence="0.99507">
shudeshna@gmail.com
</email>
<sectionHeader confidence="0.9947" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999923304347826">
We address the issues of transliteration be-
tween Indian languages and English, es-
pecially for named entities. We use an
EM algorithm to learn the alignment be-
tween the languages. We find that there
are lot of ambiguities in the rules map-
ping the characters in the source language
to the corresponding characters in the tar-
get language. Some of these ambiguities
can be handled by capturing context by
learning multi-character based alignments
and use of character n-gram models. We
observed that a word in the source script
may have actually originated from differ-
ent languages. Instead of learning one
model for the language pair, we propose
that one may use multiple models and a
classifier to decide which model to use. A
contribution of this work is that the models
and classifiers are learned in a completely
unsupervised manner. Using our system
we were able to get quite accurate translit-
eration models.
</bodyText>
<sectionHeader confidence="0.998883" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995485222222222">
Transliteration is the practice of transcribing a
word or text written in one writing system into an-
other writing system which may have a different
script (wikipedia 1). The rules are often quite am-
biguous, and they are often related with the pro-
nunciation of the word.
Many applications like Machine Transla-
tion (MT), Cross Language Information Re-
trieval (CLIR), Question Answering (QA) require
</bodyText>
<footnote confidence="0.977308">
1http://www.wikipedia.org
</footnote>
<bodyText confidence="0.999679461538461">
transliteration of named entities, which are the ma-
jor component of out-of-vocabulary (OOV) words,
and they are most often transliterated and not
translated, in any cross language system. For ex-
ample ,‘Europe’ is transliterated as ‘iuropa’ and
‘Michael’ transliterates to ‘maaikela’ in Bengali.2
In this paper we develop a scheme of translit-
eration, which captures context by creating a dic-
tionary of multi-character transliteration rules. We
have tested our system for English and several In-
dian languages. For Indian Languages, we have an
additional preprocessor which enhances the per-
formance.
</bodyText>
<sectionHeader confidence="0.999718" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999774">
Brown et al. (1993) have come up with their revo-
lutionary IBM alignment models, and the Giza++
(Och and Ney, 2000) is a well appreciated imple-
mentation which work with parallel data in two
languages. Though originally designed for ma-
chine translation, the package can as well be used
for transliteration, where the alignment is between
the characters in the languages. Moses further en-
hances the accuracy by using phrase based decod-
ing, which can capture context. We have Moses3
as our baseline system.
Li et al. (2004) have pointed out the prob-
lems of using language information. Apart from
the difficulty of collecting the language informa-
tion, they pointed out that, although written in
the same script, the origin of the source names
may vary widely. For example French and Eng-
lish names may vary a lot. But it is difficult
to collect information for each and every lan-
guage. They came up with a joint source chan-
</bodyText>
<footnote confidence="0.992084333333333">
2above Bengali words are scripted using ITrans, instead
of traditional Bengali script.
3http://www.statmt.org/moses/
</footnote>
<page confidence="0.978272">
61
</page>
<note confidence="0.983853">
Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 61–64,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999817733333333">
nel model, to transliterate foreign names to Chi-
nese, Korean, and Japanese, which uses, direct or-
thographic mapping (DOM), between two differ-
ent languages, to find out how the source and tar-
get words can be generated simultaneously. Ekbal
et al. (2006) also used this model for English-
Bengali Transliteration. Ganesh et al. (2008)
used Hidden Markov Model (HMM) alignment
and Conditional Random Field (CRF), a discrim-
inative model together. Surana et al. (2008) used
fuzzy string matching algorithms to identify the
origin of the source word, and then apply rules of
transliteration accordingly. However the classifier
makes use of labeled training data, which is often
not available.
</bodyText>
<sectionHeader confidence="0.999117" genericHeader="method">
3 Issues
</sectionHeader>
<bodyText confidence="0.999983928571429">
Transliteration is ambiguous. Firstly, the translit-
eration rules depend on the context. For exam-
ple, ‘a’ in English may transliterate to ‘a’ or ‘A’
in Hindi, but ‘aa’ almost definitely maps to ‘A’.
Secondly, there can be multiple transliterations
of the same source word. For example ‘abhi-
jIta’ may transliterate to ‘abhijit’ and ‘abhijeet’ as
well. Thirdly, the transliteration rules also vary,
depending on the origin of the word. For exam-
ple, when considering Hindi to English translitera-
tion the English characters used vary depending on
whether the word originated from Arabic or from
Sanskrit. We elaborate more on this in the section
on classification of corpus.
</bodyText>
<sectionHeader confidence="0.994734" genericHeader="method">
4 Approach
</sectionHeader>
<bodyText confidence="0.999980029411765">
Our method is primarily based on IBM models
used in machine translation based on the EM al-
gorithm. But before we move on to the IBM mod-
els, we first preprocess the training data. Other
than marking the ‘Start’ and ‘End’, for each of the
parallel words, we can do further preprocessing if
any of the scripts is Indian. All Indian language
scripts consist of a set of consonants and vowels.
Independent vowels and their corresponding dia-
critic markers (Matra) are considered as the same
character in the standard analysis of words into
their constituent characters (varna vishleshhana).
Unlike ITrans, Unicode assigns different codes to
them. We found in our experiment that treating
them as one, improves the accuracy of the system.
Our preprocessor thus transforms Unicode data to
ITrans format. We have seen that preprocessor im-
proves the accuracy by around 10-15%.
After preprocessing, we align the letters us-
ing the expectation maximization (EM) algorithm
of IBM model 1, using the parallel corpus of
named entities as input. We use only the IBM
model 1; the subsequent models are omitted since
in transliteration we need not consider the re-
ordering of letters. Both Unicode and transliter-
ated text are in phonetic order, and re-ordering of
letters are rarely observed. As an output of the EM
learner we get a table of translation probabilities
TP, of source letters to target letters. If, si and
tj are source and target letters, bsi, tj, TPs,,t; E
[0, 1], denotes the corresponding translation prob-
ability. For example after EM learning, the values
of TPbha,v and TPbha,b will be much more than
TPbha,k, since ‘bha’ rarely transliterates to ‘k’.
</bodyText>
<subsectionHeader confidence="0.997218">
4.1 Learning Phrase Mappings
</subsectionHeader>
<bodyText confidence="0.999824633333333">
We now move on to capture context. For each
word in the parallel data, we compute an align-
ment array, Ae, where e E [0, E], and I and E
are the corresponding lengths of the words in In-
dian and English script respectively. So, we have,
be E [0, E], Ae E [0, I]. Following is an example:
Let, source word be: Start s1 s2 s3 End, target
word be: Start t1 t2 t3 t4 End, and Alignment ar-
ray be: 0 1 1 2 3 4. This means that s1 maps to
t1 and t2; s2 maps to t3 and so on. We further
enforce Ae, &lt; Ae, iff e1 &lt; e2, since we neglect
re-ordering of letters. The aim is to figure out null
mappings, filter out noises in the TP-table, and fi-
nally create a phrase to phrase mapped dictionary.
Using the TP-table values, we propose an iterative
algorithm to find the alignment array A. WL[i] de-
notes the ith letter of a word in language ‘L’. Ini-
tially Ai = 0 if i = 0, Ai = I −1 if i &lt; E, otherwise
Ai = I. The first and last characters are always the
‘Start’ and ‘End’ tags, in all the words.
Initially letters are allowed a larger window to
fit to. After each iteration, the window size de-
creases and thus the margins are made more strin-
gent. Using iterations we are being less greedy in
deciding the alignment, so that noises in the TP-
table are filtered out. Finally after 5 iterations,
we freeze the alignment array. It may happen that
]i E [0, I], such that bj E [0, E], Aj 74 i. It
means that the letter, WInd[i] maps to ‘null’ in this
case, and thus it is a ‘Schwa’ character.
</bodyText>
<subsectionHeader confidence="0.971581">
4.2 Scoring the alignment
</subsectionHeader>
<bodyText confidence="0.9970425">
In spite of all our attempts, it may happen that the
words are not well aligned; the reason may be a
</bodyText>
<page confidence="0.996311">
62
</page>
<bodyText confidence="0.976416">
Algorithm 1 Method to compute Alignment
for window = 5 to 1 do
fore= 1 to E − 1 do
</bodyText>
<equation confidence="0.6755632">
left = Max(1, Ae−1 − window + 1)
right = Min(I, Ae+1 + window)
Ae = s : s E [left, right] such that
TPWInd[s],WEng[e] X (1 − |s/I − e/E|)
is maximum
end for
fore= 1 to E − 1 do
if -,(Ae−1 &lt; Ae &lt; Ae+1) then
{try to smooth out anomalies}
Ae = (Ae−1 + Ae+1)/2
</equation>
<tableCaption confidence="0.400763333333333">
end if
end for
end for
</tableCaption>
<bodyText confidence="0.999590833333333">
deficiency in the Algorithm 1, or a badly transliter-
ated parallel word as input. For example the train-
ing data may contain ‘mississippi river’ translit-
erated to Bengali as ‘misisipi nadI’. In this case
we see that the second word is translated and not
transliterated. Retaining this in the training set
will introduce noise in the model. There may also
be typographical errors also. We have developed
a filtering mechanism, so that we can eliminate
these words, otherwise we will end up learning
spurious mappings. We find the score of an align-
ment,
</bodyText>
<equation confidence="0.999364">
SA = �N−1
e�1 (TPWInd[Ae],WEng[e] X (1 − |Ae/I −
</equation>
<bodyText confidence="0.9993476">
We were trying to maximize SA under certain
constraints in algorithm 1. The value of SA is
an estimate of how good our alignment is. Next
we set thresholds to distinguish between different
“Classes” of alignments.
</bodyText>
<subsectionHeader confidence="0.999269">
4.3 Classifying the training corpus
</subsectionHeader>
<bodyText confidence="0.9548885">
The training corpus may consist of words from
varied origins. Though they are written in
the same script, pronunciation varies widely.
For example Urdu origin names like Farooque
(pharUka), Razzaq (rajjAka) tend to replace ‘q’ in
place of ‘ka’, but Hindi names like Latika (latika),
Nakul (nakula), tend to replace ‘k’ for ‘ka’. Unlike
Surana et al. (2008) who extracted 5-gram models
from labeled data in different languages, we pro-
pose Algorithm 2, to classify the parallel corpus
into groups, which does not need any labeled data.
We define, Classes C1, C2, ..., CN, where Ci con-
sists of a set of parallel words &lt; Ij, Ej &gt;, (Ij,
Ej being the jth word in Indian and English lan-
guage, in the training corpus), such that the align-
ment score of the word pairs, lie between the pre-
defined thresholds, thi+1 and thi. Let us assume
that C1 is initialized with the parallel training cor-
pus from input.
Algorithm 2 Classify the Corpus
for i = 1 to N do
Set threshold, thi for Class Ci: thi &lt; thi−1
while size of Class Ci does not decrease do
Compute TP-table using IBM model 1. on
</bodyText>
<figure confidence="0.546745090909091">
Ci
for each parallel word pair &lt; Ij, Ej &gt; in
Ci do
Compute Alignment using Algorithm 1.
Compute Score of Alignment, SA.
if Score &lt; thi then
{Move the word pair to the next
class}
Ci+1 = Ci+1U &lt; Ij, Ej &gt;
Ci = Ci� &lt; Ij, Ej &gt;
end if
</figure>
<subsectionHeader confidence="0.182126">
end for
</subsectionHeader>
<bodyText confidence="0.479551">
end while{move on to next Class}
</bodyText>
<subsectionHeader confidence="0.518456">
end for
</subsectionHeader>
<bodyText confidence="0.997734038461539">
We continuously discard word pairs from a
class until there is no word pair to be discarded.
We use IBM Model 1 to re-learn the TP-table, on
the latest content of the class. Since the poor word
pairs have been removed, learning the TP-table
afresh, helps in improving the TPsi,tj values. It
helps in removing the bad word pairs yet left, in
the subsequent iterations. It is to be noted that CN
consists of word pairs, which are of no use, and we
discard them completely. We had 5 useful classes,
and the thresholds of C1 to C5 were 0.4, 0.35, 0.3,
0.25, 0.2 respectively. In each class, for each word
pair, we extract all possible ngrams on Indian lan-
guage side and collect their corresponding English
characters, using the alignment array. We keep fre-
quency counts of these ngram mappings, and use
this score in decoding. We use a language model,
which uses Good Turing smoothing technique. We
have used greedy beam search based decoder.
All that remains is to guess the class of an un-
known word. Given a test word, in source script
we calculate probability Pi of it being in class,
Ci, based on ngram similarities. The decoders of
each of the classes returns a list of feasible translit-
eration candidates along with their ‘local scores’
e/E|).
</bodyText>
<page confidence="0.998156">
63
</page>
<table confidence="0.99974275">
Language Accuracy in Top1 Mean F-Score MRR MAP,.,f MAPIO MAPs&apos;Ys
En2Ta 0.404 0.883 0.539 0.398 0.182 0.182
En2Hi 0.366 0.854 0.493 0.360 0.164 0.164
En2Ka 0.335 0.856 0.457 0.328 0.154 0.154
</table>
<tableCaption confidence="0.977335">
Table 1: Transliteration Accuracies. En2Ta: English to Tamil, En2Hi: English to Hindi, En2Ka: English
to Kannada
</tableCaption>
<bodyText confidence="0.973615857142857">
(score according to that class), We denote the lo-
cal score of a candidate from Class Ci as LS[Ci].
We calculate the global score, GS for each candi-
date, using GS= �N��
i=� (LS[Ci]�Pi). The candi-
dates are sorted in decreasing order of their global
scores and top ‘K’ of them produced as output.
</bodyText>
<sectionHeader confidence="0.999968" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999985111111111">
We have evaluated our system, against datasets
with Hindi, Tamil, Kannada and English parallel
named entities (Kumaran and Kellner, 2007). The
results are in Table 1. The data consists of named
entities from varied origins: almost all Indian lan-
guages and English. We combined the training and
development sets to create the new training set.
There are about 9000 parallel words in the train-
ing sets and 1000 words for testing.
Algorithm 2 classifies the training corpus, into
5 sets of corpus. Following are some details af-
ter classifying the Tamil-English dataset. Corpus
1, consists of Sanskrit derived words mostly; they
get perfectly aligned and Schwa deletions rarely
occur; Ex: Keena, Asiya, Nehra, Hemaraaj, Vi-
jendra. This corpus contains 2167 words. Cor-
pus 2 also is mostly comprised of Sanskrit de-
rived words and also English words which eas-
ily align; like Wilton, Natesh, Raghu, Gerry,
Achintya, Amaanat. Schwa deletions does occur,
and hence the alignment scores are a little low.
Size of this corpus is 2168.
Corpus 3 consists more of Urdu origin and
English words, which are not fit for the normal
transliteration rules. The corpus consists of words
like Tarzan, Anoife, Sevier, Zahid Fazal, Floriane,
where letters like ‘q’, ’zz’, ‘y’ are more likely than
‘k’, ‘j’, ‘i’ respectively. The size of Corpus 3 is
1835. Corpus 4 &amp; 5 consists largely of English
origin words, like Lucky number, Ian Healy, Clea-
vant, Fort Vancouver, Virginia Reel, Bundesver-
dienstkreuz. These words need completely differ-
ent set of rules, and moreover if these words were
in any other class, it would corrupt their learning
rules. Size of these corpora are 1234 and 1455 re-
spectively.
</bodyText>
<sectionHeader confidence="0.999363" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999935166666667">
Our system is robust in the sense that it can filter
out noise in the training corpus, can handle words
of different origins by classifying them into dif-
ferent classes. Our classifying algorithm improves
the accuracy, but we believe that there is scope of
further improvement and we are working on it.
</bodyText>
<sectionHeader confidence="0.999207" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999803055555556">
Asif Ekbal, Sudip Kumar Naskar, Sivaji Bandyopad-
hyay. 2006. A modified joint source-channel
model for transliteration. Proceedings of the
COLING/ACL on Main conference poster ses-
sions.Sydney, Australia.
Harshit Surana and A. K. Singh 2008. A More Dis-
cerning and Adaptable Multilingual Transliteration
Mechanism for Indian Languages. The Third In-
ternational Joint Conference on Natural Language
Processing (IJCNLP). Hyderabad, India.
Kumaran A. and Kellner Tobias. 2007. A generic
framework for machine transliteration SIGIR ’07:
Proceedings of the 30th annual international ACM
SIGIR conference on Research and development in
information retrieval, pages 721–722.
Li Haizhou, Zhang Min, Su Jian. 2004. A joint
source-channel model for machine transliteration.
Proceedings of the 42nd Annual Meeting on As-
sociation for Computational Linguistics. Barcelona,
Spain.
Och Franz Josef and Hermann Ney. 2000. Improved
Statistical Alignment Models. Proc. of the 38th An-
nual Meeting of the Association for Computational
Linguistics, pp. 440-447, Hong Kong, China.
Peter F. Brown, Vincent J. Delta Pietra, Stephen A.
Delta Pietra and Robert L. Mercer. 1993. The math-
ematics of statistical machine translation: parame-
ter estimation. MIT Press Cambridge, MA, USA.
Surya Ganesh, Sree Harsha, Prasad Pingali, Vasudeva
Verma. 2008. Statistical Transliteration for Cross
Language Information Retrieval using HMM align-
ment model and CRF. CLIA-2008, 2nd International
workshop on Cross Language Information Access,
3rd International Joint Conference on Natural Lan-
guage Processing (IJCNLP 2008), January 7-12,
2008, Hyderabad, India.
</reference>
<page confidence="0.999418">
64
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.101942">
<title confidence="0.9992055">Learning Multi Character Alignment Rules and Classification of training data for Transliteration</title>
<author confidence="0.755861">Dipankar</author>
<affiliation confidence="0.9984985">Dept. of Computer Science and Indian Institute of</affiliation>
<address confidence="0.786847">Kharagpur, West</address>
<affiliation confidence="0.616933">India -</affiliation>
<email confidence="0.998362">dipankarcsiit@gmail.com</email>
<author confidence="0.665837">Sudeshna</author>
<affiliation confidence="0.9984455">Dept. of Computer Science and Indian Institute of</affiliation>
<address confidence="0.755242">Kharagpur, West</address>
<affiliation confidence="0.738889">India -</affiliation>
<email confidence="0.999407">shudeshna@gmail.com</email>
<abstract confidence="0.997986333333334">We address the issues of transliteration between Indian languages and English, especially for named entities. We use an EM algorithm to learn the alignment between the languages. We find that there are lot of ambiguities in the rules mapping the characters in the source language to the corresponding characters in the target language. Some of these ambiguities can be handled by capturing context by learning multi-character based alignments and use of character n-gram models. We observed that a word in the source script may have actually originated from different languages. Instead of learning one model for the language pair, we propose that one may use multiple models and a classifier to decide which model to use. A contribution of this work is that the models and classifiers are learned in a completely unsupervised manner. Using our system we were able to get quite accurate transliteration models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Asif Ekbal</author>
</authors>
<title>Sudip Kumar Naskar, Sivaji Bandyopadhyay.</title>
<date>2006</date>
<booktitle>Proceedings of the COLING/ACL on Main conference poster sessions.Sydney,</booktitle>
<location>Australia.</location>
<marker>Ekbal, 2006</marker>
<rawString>Asif Ekbal, Sudip Kumar Naskar, Sivaji Bandyopadhyay. 2006. A modified joint source-channel model for transliteration. Proceedings of the COLING/ACL on Main conference poster sessions.Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harshit Surana</author>
<author>A K Singh</author>
</authors>
<title>A More Discerning and Adaptable Multilingual Transliteration Mechanism for Indian Languages.</title>
<date>2008</date>
<booktitle>The Third International Joint Conference on Natural Language Processing (IJCNLP).</booktitle>
<location>Hyderabad, India.</location>
<marker>Surana, Singh, 2008</marker>
<rawString>Harshit Surana and A. K. Singh 2008. A More Discerning and Adaptable Multilingual Transliteration Mechanism for Indian Languages. The Third International Joint Conference on Natural Language Processing (IJCNLP). Hyderabad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kumaran</author>
<author>Kellner Tobias</author>
</authors>
<title>A generic framework for machine transliteration SIGIR ’07:</title>
<date>2007</date>
<booktitle>Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>721--722</pages>
<marker>Kumaran, Tobias, 2007</marker>
<rawString>Kumaran A. and Kellner Tobias. 2007. A generic framework for machine transliteration SIGIR ’07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, pages 721–722.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Haizhou</author>
<author>Zhang Min</author>
<author>Su Jian</author>
</authors>
<title>A joint source-channel model for machine transliteration.</title>
<date>2004</date>
<booktitle>Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics.</booktitle>
<location>Barcelona,</location>
<marker>Haizhou, Min, Jian, 2004</marker>
<rawString>Li Haizhou, Zhang Min, Su Jian. 2004. A joint source-channel model for machine transliteration. Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Och Franz Josef</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>Proc. of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hong Kong, China.</location>
<marker>Josef, Ney, 2000</marker>
<rawString>Och Franz Josef and Hermann Ney. 2000. Improved Statistical Alignment Models. Proc. of the 38th Annual Meeting of the Association for Computational Linguistics, pp. 440-447, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Delta Pietra</author>
<author>Stephen A Delta Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<publisher>MIT Press</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="2369" citStr="Brown et al. (1993)" startWordPosition="364" endWordPosition="367">ion of named entities, which are the major component of out-of-vocabulary (OOV) words, and they are most often transliterated and not translated, in any cross language system. For example ,‘Europe’ is transliterated as ‘iuropa’ and ‘Michael’ transliterates to ‘maaikela’ in Bengali.2 In this paper we develop a scheme of transliteration, which captures context by creating a dictionary of multi-character transliteration rules. We have tested our system for English and several Indian languages. For Indian Languages, we have an additional preprocessor which enhances the performance. 2 Related Work Brown et al. (1993) have come up with their revolutionary IBM alignment models, and the Giza++ (Och and Ney, 2000) is a well appreciated implementation which work with parallel data in two languages. Though originally designed for machine translation, the package can as well be used for transliteration, where the alignment is between the characters in the languages. Moses further enhances the accuracy by using phrase based decoding, which can capture context. We have Moses3 as our baseline system. Li et al. (2004) have pointed out the problems of using language information. Apart from the difficulty of collectin</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Delta Pietra, Stephen A. Delta Pietra and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. MIT Press Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Surya Ganesh</author>
<author>Sree Harsha</author>
<author>Prasad Pingali</author>
<author>Vasudeva Verma</author>
</authors>
<title>Statistical Transliteration for Cross Language Information Retrieval using HMM alignment model and CRF.</title>
<date>2008</date>
<booktitle>CLIA-2008, 2nd International workshop on Cross Language Information Access, 3rd International Joint Conference on Natural Language Processing (IJCNLP</booktitle>
<location>Hyderabad, India.</location>
<contexts>
<context position="3851" citStr="Ganesh et al. (2008)" startWordPosition="607" endWordPosition="610">hey came up with a joint source chan2above Bengali words are scripted using ITrans, instead of traditional Bengali script. 3http://www.statmt.org/moses/ 61 Proceedings of the 2009 Named Entities Workshop, ACL-IJCNLP 2009, pages 61–64, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP nel model, to transliterate foreign names to Chinese, Korean, and Japanese, which uses, direct orthographic mapping (DOM), between two different languages, to find out how the source and target words can be generated simultaneously. Ekbal et al. (2006) also used this model for EnglishBengali Transliteration. Ganesh et al. (2008) used Hidden Markov Model (HMM) alignment and Conditional Random Field (CRF), a discriminative model together. Surana et al. (2008) used fuzzy string matching algorithms to identify the origin of the source word, and then apply rules of transliteration accordingly. However the classifier makes use of labeled training data, which is often not available. 3 Issues Transliteration is ambiguous. Firstly, the transliteration rules depend on the context. For example, ‘a’ in English may transliterate to ‘a’ or ‘A’ in Hindi, but ‘aa’ almost definitely maps to ‘A’. Secondly, there can be multiple transl</context>
</contexts>
<marker>Ganesh, Harsha, Pingali, Verma, 2008</marker>
<rawString>Surya Ganesh, Sree Harsha, Prasad Pingali, Vasudeva Verma. 2008. Statistical Transliteration for Cross Language Information Retrieval using HMM alignment model and CRF. CLIA-2008, 2nd International workshop on Cross Language Information Access, 3rd International Joint Conference on Natural Language Processing (IJCNLP 2008), January 7-12, 2008, Hyderabad, India.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>