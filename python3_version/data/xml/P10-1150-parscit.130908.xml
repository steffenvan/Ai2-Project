<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000400">
<title confidence="0.9963905">
Learning Arguments and Supertypes of Semantic Relations using
Recursive Patterns
</title>
<author confidence="0.867792">
Zornitsa Kozareva and Eduard Hovy
</author>
<affiliation confidence="0.830995">
USC Information Sciences Institute
</affiliation>
<address confidence="0.850797">
4676 Admiralty Way
Marina del Rey, CA 90292-6695
</address>
<email confidence="0.999221">
{kozareva,hovy}@isi.edu
</email>
<sectionHeader confidence="0.993907" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999987">
A challenging problem in open informa-
tion extraction and text mining is the learn-
ing of the selectional restrictions of se-
mantic relations. We propose a mini-
mally supervised bootstrapping algorithm
that uses a single seed and a recursive
lexico-syntactic pattern to learn the ar-
guments and the supertypes of a diverse
set of semantic relations from the Web.
We evaluate the performance of our algo-
rithm on multiple semantic relations ex-
pressed using “verb”, “noun”, and “verb
prep” lexico-syntactic patterns. Human-
based evaluation shows that the accuracy
of the harvested information is about 90%.
We also compare our results with existing
knowledge base to outline the similarities
and differences of the granularity and di-
versity of the harvested knowledge.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999224966666667">
Building and maintaining knowledge-rich re-
sources is of great importance to information ex-
traction, question answering, and textual entail-
ment. Given the endless amount of data we have at
our disposal, many efforts have focused on mining
knowledge from structured or unstructured text,
including ground facts (Etzioni et al., 2005), se-
mantic lexicons (Thelen and Riloff, 2002), ency-
clopedic knowledge (Suchanek et al., 2007), and
concept lists (Katz et al., 2003). Researchers have
also successfully harvested relations between en-
tities, such as is-a (Hearst, 1992; Pasca, 2004) and
part-of (Girju et al., 2003). The kinds of knowl-
edge learned are generally of two kinds: ground
instance facts (New York is-a city, Rome is the cap-
ital of Italy) and general relational types (city is-a
location, engines are part-of cars).
A variety of NLP tasks involving inference or
entailment (Zanzotto et al., 2006), including QA
(Katz and Lin, 2003) and MT (Mt et al., 1988),
require a slightly different form of knowledge, de-
rived from many more relations. This knowledge
is usually used to support inference and is ex-
pressed as selectional restrictions (Wilks, 1975)
(namely, the types of arguments that may fill a
given relation, such as person live-in city and air-
line fly-to location). Selectional restrictions con-
strain the possible fillers of a relation, and hence
the possible contexts in which the patterns ex-
pressing that relation can participate in, thereby
enabling sense disambiguation of both the fillers
and the expression itself.
To acquire this knowledge two common ap-
proaches are employed: clustering and patterns.
While clustering has the advantage of being fully
unsupervised, it may or may not produce the types
and granularity desired by a user. In contrast
pattern-based approaches are more precise, but
they typically require a handful to dozens of seeds
and lexico-syntactic patterns to initiate the learn-
ing process. In a closed domain these approaches
are both very promising, but when tackling an un-
bounded number of relations they are unrealistic.
The quality of clustering decreases as the domain
becomes more continuously varied and diverse,
and it has proven difficult to create collections of
effective patterns and high-yield seeds manually.
In addition, the output of most harvesting sys-
tems is a flat list of lexical semantic expressions
such as “New York is-a city” and “virus causes
flu”. However, using this knowledge in inference
requires it to be formulated appropriately and or-
ganized in a semantic repository. (Pennacchiotti
and Pantel, 2006) proposed an algorithm for au-
tomatically ontologizing semantic relations into
WordNet. However, despite its high precision en-
tries, WordNet’s limited coverage makes it impos-
sible for relations whose arguments are not present
in WordNet to be incorporated. One would like a
procedure that dynamically organizes and extends
</bodyText>
<page confidence="0.951569">
1482
</page>
<note confidence="0.9427625">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1482–1491,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.998119222222222">
its semantic repository in order to be able to ac-
commodate all newly-harvested information, and
thereby become a global semantic repository.
Given these considerations, we address in this
paper the following question: How can the selec-
tional restrictions of semantic relations be learned
automatically from the Web with minimal effort us-
ing lexico-syntactic recursive patterns?
The contributions of the paper are as follows:
</bodyText>
<listItem confidence="0.997414333333333">
• A novel representation of semantic relations
using recursive lexico-syntactic patterns.
• An automatic procedure to learn the se-
lectional restrictions (arguments and super-
types) of semantic relations from Web data.
• An exhaustive human-based evaluation of the
harvested knowledge.
• A comparison of the results with some large
existing knowledge bases.
</listItem>
<bodyText confidence="0.99957875">
The rest of the paper is organized as follows. In
the next section, we review related work. Section
3 addresses the representation of semantic rela-
tions using recursive patterns. Section 4 describes
the bootstrapping mechanism that learns the selec-
tional restrictions of the relations. Section 5 de-
scribes data collection. Section 6 discusses the ob-
tained results. Finally, we conclude in Section 7.
</bodyText>
<sectionHeader confidence="0.999744" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999963575342466">
A substantial body of work has been done in at-
tempts to harvest bits of semantic information, in-
cluding: semantic lexicons (Riloff and Shepherd,
1997), concept lists (Lin and Pantel, 2002), is-
a relations (Hearst, 1992; Etzioni et al., 2005;
Pasca, 2004; Kozareva et al., 2008), part-of re-
lations (Girju et al., 2003), and others. Knowl-
edge has been harvested with varying success both
from structured text such as Wikipedia’s infoboxes
(Suchanek et al., 2007) or unstructured text such
as the Web (Pennacchiotti and Pantel, 2006; Yates
et al., 2007). A variety of techniques have been
employed, including clustering (Lin and Pantel,
2002), co-occurrence statistics (Roark and Char-
niak, 1998), syntactic dependencies (Pantel and
Ravichandran, 2004), and lexico-syntactic pat-
terns (Riloff and Jones, 1999; Fleischman and
Hovy, 2002; Thelen and Riloff, 2002).
When research focuses on a particular relation,
careful attention is paid to the pattern(s) that ex-
press it in various ways (as in most of the work
above, notably (Riloff and Jones, 1999)). But it
has proven a difficult task to manually find ef-
fectively different variations and alternative pat-
terns for each relation. In contrast, when re-
search focuses on any relation, as in TextRun-
ner (Yates et al., 2007), there is no standardized
manner for re-using the pattern learned. TextRun-
ner scans sentences to obtain relation-independent
lexico-syntactic patterns to extract triples of the
form (John, fly to, Prague). The middle string de-
notes some (unspecified) semantic relation while
the first and third denote the learned arguments of
this relation. But TextRunner does not seek spe-
cific semantic relations, and does not re-use the
patterns it harvests with different arguments in or-
der to extend their yields.
Clearly, it is important to be able to specify both
the actual semantic relation sought and use its tex-
tual expression(s) in a controlled manner for max-
imal benefit.
The objective of our research is to combine the
strengths of the two approaches, and, in addition,
to provide even richer information by automati-
cally mapping each harvested argument to its su-
pertype(s) (i.e., its semantic concepts). For in-
stance, given the relation destination and the pat-
tern X flies to Y, automatically determining that
John, Prague) and (John, conference) are two
valid filler instance pairs, that (RyanAir, Prague)
is another, as well as that person and airline are
supertypes of the first argument and city and event
of the second. This information provides the se-
lectional restrictions of the given semantic rela-
tion, indicating that living things like people can
fly to cities and events, while non-living things like
airlines fly mainly to cities. This is a significant
improvement over systems that output a flat list
of lexical semantic knowledge (Thelen and Riloff,
2002; Yates et al., 2007; Suchanek et al., 2007).
Knowing the sectional restrictions of a semantic
relation supports inference in many applications,
for example enabling more accurate information
extraction. (Igo and Riloff, 2009) report that pat-
terns like “attack on (NP)” can learn undesirable
words due to idiomatic expressions and parsing er-
rors. Over time this becomes problematic for the
bootstrapping process and leads to significant de-
terioration in performance. (Thelen and Riloff,
2002) address this problem by learning multiple
semantic categories simultaneously, relying on the
often unrealistic assumption that a word cannot
belong to more than one semantic category. How-
</bodyText>
<page confidence="0.976468">
1483
</page>
<bodyText confidence="0.999869">
ever, if we have at our disposal a repository of se-
mantic relations with their selectional restrictions,
the problem addressed in (Igo and Riloff, 2009)
can be alleviated.
In order to obtain selectional restriction classes,
(Pennacchiotti and Pantel, 2006) made an attempt
to ontologize the harvested arguments of is-a,
part-of, and cause relations. They mapped each
argument of the relation into WordNet and identi-
fied the senses for which the relation holds. Un-
fortunately, despite its very high precision en-
tries, WordNet is known to have limited cover-
age, which makes it impossible for algorithms to
map the content of a relation whose arguments
are not present in WordNet. To surmount this
limitation, we do not use WordNet, but employ
a different method of obtaining superclasses of a
filler term: the inverse doubly-anchored patterns
DAP−1 (Hovy et al., 2009), which, given two ar-
guments, harvests its supertypes from the source
corpus. (Hovy et al., 2009) show that DAP−1 is
reliable and it enriches WordNet with additional
hyponyms and hypernyms.
</bodyText>
<sectionHeader confidence="0.994678" genericHeader="method">
3 Recursive Patterns
</sectionHeader>
<bodyText confidence="0.999909342105263">
A singly-anchored pattern contains one example
of the seed term (the anchor) and one open posi-
tion for the term to be learned. Most researchers
use singly-anchored patterns to harvest semantic
relations. Unfortunately, these patterns run out of
steam very quickly. To surmount this obstacle, a
handful of seeds is generally used, and helps to
guarantee diversity in the extraction of new lexico-
syntactic patterns (Riloff and Jones, 1999; Snow et
al., 2005; Etzioni et al., 2005).
Some algorithms require ten seeds (Riloff and
Jones, 1999; Igo and Riloff, 2009), while others
use a variation of 5, 10, to even 25 seeds (Taluk-
dar et al., 2008). Seeds may be chosen at ran-
dom (Davidov et al., 2007; Kozareva et al., 2008),
by picking the most frequent terms of the desired
class (Igo and Riloff, 2009), or by asking humans
(Pantel et al., 2009). As (Pantel et al., 2009) show,
picking seeds that yield high numbers of differ-
ent terms is difficult. Thus, when dealing with
unbounded sets of relations (Banko and Etzioni,
2008), providing many seeds becomes unrealistic.
Interestingly, recent work reports a class of pat-
terns that use only one seed to learn as much infor-
mation with only one seed. (Kozareva et al., 2008;
Hovy et al., 2009) introduce the so-called doubly-
anchored pattern (DAP) that has two anchor seed
positions “(type) such as (seed) and *”, plus one
open position for the terms to be learned. Learned
terms can then be replaced into the seed position
automatically, creating a recursive procedure that
is reportedly much more accurate and has much
higher final yield. (Kozareva et al., 2008; Hovy et
al., 2009) have successfully applied DAP for the
learning of hyponyms and hypernyms of is-a rela-
tions and report improvements over (Etzioni et al.,
2005) and (Pasca, 2004).
Surprisingly, this work was limited to the se-
mantic relation is-a. No other study has described
the use or effect of recursive patterns for differ-
ent semantic relations. Therefore, going beyond
(Kozareva et al., 2008; Hovy et al., 2009), we here
introduce recursive patterns other than DAP that
use only one seed to harvest the arguments and su-
pertypes of a wide variety of relations.
(Banko and Etzioni, 2008) show that seman-
tic relations can be expressed using a handful
of relation-independent lexico-syntactic patterns.
Practically, we can turn any of these patterns into
recursive form by giving as input only one of the
arguments and leaving the other one as an open
slot, allowing the learned arguments to replace the
initial seed argument directly. For example, for
the relation “fly to”, the following recursive pat-
terns can be built: “* and (seed) fly to *”, “(seed)
and *fly to *”, “* fly to (seed) and *”, “* fly to *
and (seed)”, “(seed) fly to *” or “* fly to (seed)”,
where (seed) is an example like John or Ryanair,
and (*) indicates the position on which the ar-
guments are learned. Conjunctions like and, or
are useful because they express list constructions
and extract arguments similar to the seed. Poten-
tially, one can explore all recursive pattern varia-
tions when learning a relation and compare their
yield, however this study is beyond the scope of
this paper.
We are particularly interested in the usage of re-
cursive patterns for the learning of semantic re-
lations not only because it is a novel method,
but also because recursive patterns of the DAP
fashion are known to: (1) learn concepts with
high precision compared to singly-anchored pat-
terns (Kozareva et al., 2008), (2) use only one
seed instance for the discovery of new previously
unknown terms, and (3) harvest knowledge with
minimal supervision.
</bodyText>
<page confidence="0.990283">
1484
</page>
<sectionHeader confidence="0.980612" genericHeader="method">
4 Bootstrapping Recursive Patterns
</sectionHeader>
<subsectionHeader confidence="0.996753">
4.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.992770166666667">
The main goal of our research is:
Task Definition: Given a seed and a semantic relation ex-
pressed using a recursive lexico-syntactic pattern, learn in
bootstrapping fashion the selectional restrictions (i.e., the
arguments and supertypes) of the semantic relation from
an unstructured corpus such as the Web.
</bodyText>
<figureCaption confidence="0.771476666666667">
Figure 1 shows an example of the task and the
types of information learned by our algorithm.
Figure 1: Bootstrapping Recursive Patterns.
</figureCaption>
<bodyText confidence="0.999915769230769">
Given a seed John and a semantic relation fly to
expressed using the recursive pattern “* and John
fly to *”, our algorithm learns the left side argu-
ments {Brian, Kate, bees, Delta, Alaska} and the
right side arguments {flowers, trees, party, New
York, Italy, France}. For each argument, the algo-
rithm harvests supertypes such as {people, artists,
politicians, airlines, city, countries, plants, event}
among others. The colored links between the right
and left side concepts denote the selectional re-
strictions of the relation. For instance, people fly
to events and countries, but never to trees or flow-
ers.
</bodyText>
<subsectionHeader confidence="0.998187">
4.2 System Architecture
</subsectionHeader>
<bodyText confidence="0.999928428571429">
We propose a minimally supervised bootstrap-
ping algorithm based on the framework adopted in
(Kozareva et al., 2008; Hovy et al., 2009). The al-
gorithm has two phases: argument harvesting and
supertype harvesting. The final output is a ranked
list of interlinked concepts which captures the se-
lectional restrictions of the relation.
</bodyText>
<subsectionHeader confidence="0.711984">
4.2.1 Argument Harvesting
</subsectionHeader>
<bodyText confidence="0.999857758620689">
In the argument extraction phase, the first boot-
strapping iteration is initiated with a seed Y and a
recursive pattern “X∗ and Y verb+prep|verb|noun
Z∗”, where X∗ and Z∗ are the placeholders for the
arguments to be learned. The pattern is submit-
ted to Yahoo! as a web query and all unique snip-
pets matching the query are retrieved. The newly
learned and previously unexplored arguments on
the X∗ position are used as seeds in the subse-
quent iteration. The arguments on the Z∗ posi-
tion are stored at each iteration, but never used
as seeds since the recursivity is created using the
terms on X and Y . The bootstrapping process is
implemented as an exhaustive breadth-first algo-
rithm which terminates when all arguments are ex-
plored.
We noticed that despite the specific lexico-
syntactic structure of the patterns, erroneous in-
formation can be acquired due to part-of-speech
tagging errors or flawed facts on the Web. The
challenge is to identify and separate the erroneous
from the true arguments. We incorporate the har-
vested arguments on X and Y positions in a di-
rected graph G = (V, E), where each vertex
v E V is a candidate argument and each edge
(u, v) E E indicates that the argument v is gener-
ated by the argument u. An edge has weight w cor-
responding to the number of times the pair (u, v)
is extracted from different snippets. A node u
</bodyText>
<equation confidence="0.634349333333333">
� ∀(u,v)∈E w(u,v)+� ∀(v,u)∈E w(v,u)
is ranked by u=
|V |−1
</equation>
<bodyText confidence="0.999517684210526">
which represents the weighted sum of the outgo-
ing and incoming edges normalized by the total
number of nodes in the graph. Intuitively, our con-
fidence in a correct argument u increases when the
argument (1) discovers and (2) is discovered by
many different arguments.
Similarly, to rank the arguments standing on
the Z position, we build a bipartite graph G0 =
(V 0, E0) that has two types of vertices. One set
of vertices represents the arguments found on the
Y position in the recursive pattern. We will call
these Vy. The second set of vertices represents the
arguments learned on the Z position. We will call
these Vz. We create an edge e0(u0, v0) E E0 be-
tween u0 E Vy and v0 E Vz when the argument on
the Z position represented by v0 was harvested by
the argument on the Y position represented by u0.
The weight w0 of the edge indicates the number
of times an argument on the Y position found Z.
</bodyText>
<equation confidence="0.990460333333333">
�∀(u0,v0)∈E0 w(u0,v0)
Vertex v0 is ranked as v0= . In
|V 0|−1
</equation>
<bodyText confidence="0.901013">
a very large corpus, like the Web, we assume that
a correct argument Z is the one that is frequently
discovered by various arguments Y .
</bodyText>
<figure confidence="0.996851833333333">
animals
BrianKate
Delta
Alaska
airlines
carriers
bees
artists
politicians
people
* and John fly to *
flowers
trees
city
New York
party event
seed = John
relation = fly to
</figure>
<page confidence="0.856562">
1485
</page>
<subsubsectionHeader confidence="0.622364">
4.2.2 Supertype Harvesting
</subsubsectionHeader>
<bodyText confidence="0.999796307692308">
In the supertype extraction phase, we take all
&lt;X,Y&gt; argument pairs collected during the argu-
ment harvesting stage and instantiate them in the
inverse DAP−1 pattern “* such as X and Y”. The
query is sent to Yahoo! as a web query and all 1000
snippets matching the pattern are retrieved. For
each &lt;X,Y&gt; pair, the terms on the (*) position are
extracted and considered as candidate supertypes.
To avoid the inclusion of erroneous supertypes,
again we build a bipartite graph G00 = (V 00, E00).
The set of vertices Vsup represents the supertypes,
while the set of vertices Vp corresponds to the
(X,Y) pair that produced the supertype. An edge
e00(u00, v00) E E00, where u00 E Vp and v00 E Vsup
shows that the pair (X,Y) denoted as u00 harvested
the supertype represented by v00.
For example, imagine that the argument X∗=
Ryanair was harvested in the previous phase by
the recursive pattern “X∗ and EasyJet fly to Z∗”.
Then the pair (Ryanair,EasyJet) forms a new Web
query “* such as Ryanair and EasyJet” which
learns the supertypes “airlines” and “carriers”.
The bipartite graph has two vertices v001 and v002 for
the supertypes “airlines” and “carriers”, one ver-
tex u003 for the argument pair (Ryanair, EasyJet),
and two edges e00 1(u003, v001) and e002(u003, v001). A vertex
</bodyText>
<equation confidence="0.922108">
�00 00)
v &amp;quot; E V up is ranked by v00= ∀ u00,v|V 0 1
</equation>
<footnote confidence="0.794561">
1Except for the “dress” and “person” relations, where
the targeted arguments are adjectives, and the supertypes are
nouns.
</footnote>
<sectionHeader confidence="0.978716" genericHeader="method">
5 Semantic Relations
</sectionHeader>
<bodyText confidence="0.999936533333333">
So far, we have described the mechanism that
learns from one seed and a recursive pattern the
selectional restrictions of any semantic relation.
Now, we are interested in evaluating the per-
formance of our algorithm. A natural question
that arises is: “How many patterns are there?”.
(Banko and Etzioni, 2008) found that 95% of the
semantic relations can be expressed using eight
lexico-syntactic patterns. Space prevents us from
describing all of them, therefore we focus on the
three most frequent patterns which capture a large
diversity of semantic relations. The relative fre-
quency of these patterns is 37.80% for “verbs”,
22.80% for “noun prep”, and 16.00% for “verb
prep”.
</bodyText>
<subsectionHeader confidence="0.964942">
5.1 Data Collection
</subsectionHeader>
<bodyText confidence="0.9997017">
Table 1 shows the lexico-syntactic pattern and the
initial seed we used to express each semantic rela-
tion. To collect data, we ran our knowledge har-
vesting algorithm until complete exhaustion. For
each query submitted to Yahoo!, we retrieved the
top 1000 web snippets and kept only the unique
ones. In total, we collected 30GB raw data which
was part-of-speech tagged and used for the argu-
ment and supertype extraction. Table 1 shows the
obtained results.
</bodyText>
<table confidence="0.998041533333333">
recursive pattern seed X arg Z arg #iter
X and Y work for Z Charlie 2949 3396 20
X and Y fly to Z EasyJet 772 1176 19
X and Y go to Z Rita 18406 27721 13
X and Y work in Z John 4142 4918 13
X and Y work on Z Mary 4126 5186 7
X and Y work at Z Scott 1084 1186 14
X and Y live in Z Harry 8886 19698 15
X and Y live at Z Donald 1102 1175 15
X and Y live with Z Peter 1344 834 11
X and Y cause Z virus 12790 52744 19
X and Y celebrate Jim 6033 – 12
X and Y drink Sam 1810 – 13
X and Y dress nice 1838 – 8
X and Y person scared 2984 – 17
</table>
<tableCaption confidence="0.999476">
Table 1: Total Number of Harvested Arguments.
</tableCaption>
<bodyText confidence="0.999934133333333">
An interesting characteristic of the recursive
patterns is the speed of leaning which can be mea-
sured in terms of the number of unique argu-
ments acquired during each bootstrapping itera-
tion. Figure 2 shows the bootstrapping process for
the “cause” and “dress” relations. Although both
relations differ in terms of the total number of it-
erations and harvested items, the overall behavior
of the learning curves is similar. Learning starts
of very slowly and as bootstrapping progresses a
.
Intuitively, a supertype which is discovered mul-
tiple times by various argument pairs is ranked
highly.
However, it might happen that a highly ranked
supertype actually does not satisfy the selectional
restrictions of the semantic relation. To avoid such
situations, we further instantiate each supertype
concept in the original pattern1. For example,
“aircompanies fly to *” and “carriers fly to *”. If
the candidate supertype produces many web hits
for the query, then this suggests that the term is a
relevant supertype.
Unfortunately, to learn the supertypes of the Z
arguments, currently we have to form all possi-
ble combinations among the top 150 highly ranked
concepts, because these arguments have not been
learned through pairing. For each pair of Z argu-
ments, we repeat the same procedure as described
above.
</bodyText>
<page confidence="0.962903">
1486
</page>
<bodyText confidence="0.997616555555556">
rapid growth is observed until a saturation point is
reached.
The speed of leaning is related to the connectiv-
ity behavior of the arguments of the relation. In-
tuitively, a densely connected graph takes shorter
time (i.e., fewer iterations) to be learned, as in the
“work on” relation, while a weakly connected net-
work takes longer time to harvest the same amount
of information, as in the “work for” relation.
</bodyText>
<sectionHeader confidence="0.999959" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999989310344828">
In this section, we evaluate the results of our
knowledge harvesting algorithm. Initially, we de-
cided to conduct an automatic evaluation compar-
ing our results to knowledge bases that have been
extracted in a similar way (i.e., through pattern ap-
plication over unstructured text). However, it is
not always possible to perform a complete com-
parison, because either researchers have not fully
explored the same relations we have studied, or for
those relations that overlap, the gold standard data
was not available.
The online demo of TextRunner2 (Yates et al.,
2007) actually allowed us to collect the arguments
for all our semantic relations. However, due to
Web based query limitations, TextRunner returns
only the first 1000 snippets. Since we do not have
the complete and ranked output of TextRunner,
comparing results in terms of recall and precision
is impossible.
Turning instead to results obtained from struc-
tured sources (which one expects to have high
correctness), we found that two of our relations
overlap with those of the freely available ontology
Yago (Suchanek et al., 2007), which was harvested
from the Infoboxes tables in Wikipedia. In addi-
tion, we also had two human annotators judge as
many results as we could afford, to obtain Preci-
sion. We conducted two evaluations, one for the
arguments and one for the supertypes.
</bodyText>
<footnote confidence="0.923326">
2http://www.cs.washington.edu/research/textrunner/
</footnote>
<subsectionHeader confidence="0.992995">
6.1 Human-Based Argument Evaluation
</subsectionHeader>
<bodyText confidence="0.999523">
In this section, we discuss the results of the har-
vested arguments. For each relation, we selected
the top 200 highly ranked arguments. We hired
two annotators to judge their correctness. We cre-
ated detailed annotation guidelines that define the
labels for the arguments of the relations, as shown
in Table 2. (Previously, for the same task, re-
searchers have not conducted such an exhaustive
and detailed human-based evaluation.) The anno-
tation was conducted using the CAT system3.
</bodyText>
<table confidence="0.8716159375">
TYPE LABEL EXAMPLES
Correct Person John, Mary
Role mother, president
Group team, Japanese
Physical yellow, shabby
NonPhysical ugly, thought
NonLiving airplane
Organization IBM, parliament
Location village, New York, in the house
Time at 5 o’clock
Event party, prom, earthquake
State sick, anrgy
Manner live in happiness
Medium work on Linux, Word
Fixed phrase go to war
Incorrect Error wrong part-of-speech tag
</table>
<tableCaption confidence="0.708871">
Other none of the above
Table 2: Annotation Labels.
</tableCaption>
<bodyText confidence="0.999935956521739">
We allow multiple labels to be assigned to the
same concept, because sometimes the concept can
appear in different contexts that carry various con-
ceptual representations. Although the labels can
be easily collapsed to judge correct and incorrect
terms, the fine-grained annotation shown here pro-
vides a better overview of the information learned
by our algorithm.
We measured the inter-annotator agreement for
all labels and relations considering that a single
entry can be tagged with multiple labels. The
Kappa score is around 0.80. This judgement is
good enough to warrant using these human judge-
ments to estimate the accuracy of the algorithm.
We compute Accuracy as the number of examples
tagged as Correct divided by the total number of
examples.
Table 4 shows the obtained results. The over-
all accuracy of the argument harvesting phase is
91%. The majority of the occurred errors are due
to part-of-speech tagging. Table 3 shows a sam-
ple of 10 randomly selected examples from the top
200 ranked and manually annotated arguments.
</bodyText>
<footnote confidence="0.651052">
3http://cat.ucsur.pitt.edu/default.aspx
</footnote>
<note confidence="0.256627">
X and Y Cause Z X and Y Dress
</note>
<figureCaption confidence="0.61453">
Figure 2: Items extracted in 10 iterations.
</figureCaption>
<figure confidence="0.997119571428571">
60000
50000
MI���� Learned
40000
30000
20000
10000
0
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
Iterations
X
0
1 2 3 4 5 6 7 8
Iterations
X
Z
#Items Learned
2000
1500
1000
500
</figure>
<page confidence="0.976971">
1487
</page>
<table confidence="0.991017538461538">
Relation Arguments
(X) Dress: stylish, comfortable, expensive, shabby, gorgeous
silver, clean, casual, Indian, black
(X) Person: honest, caring, happy, intelligent, gifted
friendly, responsible, mature, wise, outgoing
(X) Cause: pressure, stress, fire, bacteria, cholesterol
flood, ice, cocaine, injuries, wars
GoTo (Z): school, bed, New York, the movies, the park, a bar
the hospital, the church, the mall, the beach
LiveIn (Z): peace, close proximity, harmony, Chicago, town
New York, London, California, a house, Australia
WorkFor (Z): a company, the local prison, a gangster, the show
a boss, children, UNICEF, a living, Hispanics
</table>
<tableCaption confidence="0.999734">
Table 3: Examples of Harvested Arguments.
</tableCaption>
<subsectionHeader confidence="0.99881">
6.2 Comparison against Existing Resources
</subsectionHeader>
<bodyText confidence="0.98303">
In this section, we compare the performance of our
approach with the semantic knowledge base Yago4
that contains 2 million entities5, 95% of which
were manually confirmed to be correct. In this
study, we compare only the unique arguments of
the “live in” and “work at” relations. We provide
Precision scores using the following measures:
PrY ago =#terms found in Y ago
#terms harvested by system
PrHuman = #terms judged correct by human
#terms harvested by system
</bodyText>
<equation confidence="0.445306">
NotInY ago = #terms judged correct by human but not in Y ago
</equation>
<bodyText confidence="0.999703333333333">
Table 5 shows the obtained results.
We carefully analyzed those arguments that
were found by one of the systems but were miss-
ing in the other. The recursive patterns learn infor-
mation about non-famous entities like Peter and
famous entities like Michael Jordan. In contrast,
Yago contains entries mostly about famous enti-
ties, because this is the predominant knowledge in
Wikipedia. For the “live in” relation, both repos-
itories contain the same city and country names.
However, the recursive pattern learned arguments
like pain, effort which express a manner of living,
and locations like slums, box. This information is
missing from Yago. Similarly for the “work at”
relation, both systems learned that people work
at universities. In addition, the recursive pattern
learned a diversity of company names absent from
Yago.
While it is expected that our algorithm finds
many terms not contained in Yago—specifically,
the information not deemed worthy of inclusion
in Wikipedia—we are interested in the relatively
large number of terms contained in Yago but not
found by our algorithm. To our knowledge, no
</bodyText>
<footnote confidence="0.990477">
4http://www.mpi-inf.mpg.de/yago-naga/yago/
5Names of cities, people, organizations among others.
</footnote>
<table confidence="0.999989891566266">
X WorkFor A1 A2 WorkFor Z A1 A2
Person 148 152 Organization 111 110
Role 5 7 Person 60 60
Group 12 14 Event 4 2
Organization 8 7 Time 4 5
NonPhysical 22 23 NonPhysical 18 19
Other 5 5 Other 3 4
Acc. .98 .98 Acc. .99 .98
X Cause A1 A2 Cause Z A1 A2
PhysicalObj 82 75 PhysicalObj 15 20
NonPhysicalObj 69 66 NonPhysicalObj 89 91
Event 21 24 Event 72 72
State 29 31 State 50 50
Other 3 4 Other 5 4
Acc. .99 .98 Acc. .98 .98
X GoTo A1 A2 GoTo Z A1 A2
Person 190 188 Location 163 155
Role 4 4 Event 21 30
Group 3 3 Person 11 13
NonPhysical 1 3 NonPhysical 2 1
Other 2 2 Other 3 1
Acc. .99 .99 Acc. .99 .99
X FlyTo A1 A2 FlyTo Z A1 A2
Person 140 139 Location 199 198
Organization 54 57 Event 1 2
NonPhysical 2 2 Person 0 0
Other 4 2 Other 0 0
Acc. .98 .99 Acc. 1 1
X WorkOn A1 A2 WorkOn Z A1 A2
Person 173 172 Location 110 108
Role 2 3 Organization 27 25
Group 4 5 Manner 38 40
Organization 6 6 Time 4 4
NonPhysical 15 14 NonPhysical 18 21
Error 1 1 Medium 8 8
Other 1 1 Other 13 15
Acc. .99 .99 Acc. .94 .93
X WorkIn A1 A2 WorkInZ A1 A2
Person 117 118 Location 104 111
Group 10 9 Organization 10 25
Organization 3 3 Manner 39 40
Fixed 3 1 Time 4 4
NonPhysical 55 59 NonPhysical 22 21
Error 12 10 Medium 8 8
Other 0 0 Error 13 15
Acc. .94 .95 Acc. .94 .93
X WorkAt A1 A2 WorkAt Z A1 A2
Person 193 192 Organization 189 190
Role 1 1 Manner 5 4
Group 1 1 Time 3 3
Organization 0 0 Error 3 2
Other 5 6 Other 0 1
Acc. .98 .97 Acc. .99 .99
X LiveIn A1 A2 LiveIn Z A1 A2
Person 185 185 Location 182 186
Role 3 4 Manner 6 8
Group 9 8 Time 1 2
NonPhysical 1 2 Fixed 5 2
Other 2 1 Other 6 2
Acc. .99 .99 Acc. .97 .99
XLiveAt A1 A2 LiveAtZ A1 A2
Person 196 195 Location 158 157
Role 1 1 Person 5 7
NonPhysical 0 1 Manner 1 2
Other 3 3 Error 36 34
Acc. .99 .99 Acc. .82 .83
X LiveWith A1 A2 LiveWith Z A1 A2
Person 188 187 Person 165 163
Role 6 6 Animal 2 4
Group 2 2 Manner 15 15
NonPhysical 2 3 NonPhysical 15 15
Other 2 2 Other 3 3
Acc. .99 .99 Acc. .99 .99
X Dress A1 A2 X Person A1 A2
Physical 72 59 Physical 8 2
NonPhysical 120 136 NonPhysical 188 194
Other 8 5 Other 4 4
Acc .96 .98 Acc. .98 .98
X Drink A1 A2 X Celebrate A1 A2
Living 165 174 Living 157 164
NonLiving 8 2 NonLiving 42 35
Error 27 24 Error 1 1
Acc .87 .88 Acc. .99 .99
</table>
<tableCaption confidence="0.998852">
Table 4: Harvested Arguments.
</tableCaption>
<page confidence="0.879929">
1488
</page>
<table confidence="0.9997714">
PrYago PrHuman NotInYago
X LiveIn .19 (2863/14705) .58 (5165)/8886 2302
LiveIn Z .10 (495/4754) .72 (14248)/19698 13753
X WorkAt .12(167/1399) .88 (959)/1084 792
WorkAt Z .3(15/525) .95 (1128)/1186 1113
</table>
<tableCaption confidence="0.999898">
Table 5: Comparison against Yago.
</tableCaption>
<bodyText confidence="0.999166">
other automated harvesting algorithm has ever
been compared to Yago, and our results here form
a baseline that we aim to improve upon. And in
the future, one can build an extensive knowledge
harvesting system combining the wisdom of the
crowd and Wikipedia.
</bodyText>
<subsectionHeader confidence="0.998047">
6.3 Human-Based Supertype Evaluation
</subsectionHeader>
<bodyText confidence="0.999843571428571">
In this section, we discuss the results of harvest-
ing the supertypes of the learned arguments. Fig-
ure 3 shows the top 100 ranked supertypes for the
“cause” and “work on” relations. The x-axis in-
dicates a supertype, the y-axis denotes the number
of different argument pairs that lead to the discov-
ery of the supertype.
</bodyText>
<figure confidence="0.9729175">
10 20 30 40 50 60 70 80 90 100
Supertype
</figure>
<figureCaption confidence="0.999986">
Figure 3: Ranked Supertypes.
</figureCaption>
<bodyText confidence="0.999827588235294">
The decline of the curve indicates that certain
supertypes are preferred and shared among differ-
ent argument pairs. It is interesting to note that the
text on the Web prefers a small set of supertypes,
and to see what they are. These most-popular har-
vested types tend to be the more descriptive terms.
The results indicate that one does not need an elab-
orate supertype hierarchy to handle the selectional
restrictions of semantic relations.
Since our problem definition differs from avail-
able related work, and WordNet does not contain
all harvested arguments as shown in (Hovy et al.,
2009), it is not possible to make a direct compar-
ison. Instead, we conduct a manual evaluation of
the most highly ranked supertypes which normally
are the top 20. The overall accuracy of the super-
types for all relations is 92%. Table 6 shows the
</bodyText>
<table confidence="0.999547933333333">
Relation Arguments
(Sups) Celebrate: men, people, nations, angels, workers, children
countries, teams, parents, teachers
(Sups) Dress: colors, effects, color tones, activities, patterns
styles, materials, size, languages, aspects
(Sups) FlyTo: airlines, carriers, companies, giants, people
competitors, political figures, stars, celebs
Cause (Sup,): diseases, abnormalities, disasters, processes, isses
disorders, discomforts, emotions, defects, symptoms
WorkFor (Sup,) organizations, industries, people, markets, men
automakers, countries, departments, artists, media
GoTo (Sup,) : countries, locations, cities, people, events
men, activities, games, organizations,
FlyTo (Sup,) places, countries, regions, airports, destinations
locations, cities, area, events
</table>
<tableCaption confidence="0.999268">
Table 6: Examples of Harvested Supertypes.
</tableCaption>
<bodyText confidence="0.981618">
top 10 highly ranked supertypes for six of our re-
lations.
</bodyText>
<sectionHeader confidence="0.999002" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999981617647059">
We propose a minimally supervised algorithm that
uses only one seed example and a recursive lexico-
syntactic pattern to learn in bootstrapping fash-
ion the selectional restrictions of a large class of
semantic relations. The principal contribution of
the paper is to demonstrate that this kind of pat-
tern can be applied to almost any kind of se-
mantic relation, as long as it is expressible in
a concise surface pattern, and that the recursive
mechanism that allows each newly acquired term
to restart harvesting automatically is a signifi-
cant advance over patterns that require a handful
of seeds to initiate the learning process. It also
shows how one can combine free-form but undi-
rected pattern-learning approaches like TextRun-
ner with more-controlled but effort-intensive ap-
proaches like commonly used.
In our evaluation, we show that our algorithm is
capable of extracting high quality non-trivial in-
formation from unstructured text given very re-
stricted input (one seed). To measure the perfor-
mance of our approach, we use various semantic
relations expressed with three lexico-syntactic pat-
terns. For two of the relations, we compare results
with the freely available ontology Yago, and con-
duct a manual evaluation of the harvested terms.
We will release the annotated and the harvested
data to the public to be used for comparison by
other knowledge harvesting algorithms.
The success of the proposed framework opens
many challenging directions. We plan to use the
algorithm described in this paper to learn the se-
lectional restrictions of numerous other relations,
in order to build a rich knowledge repository
</bodyText>
<figure confidence="0.996313142857143">
#Pairs Discovering the Supertype
1000
900
800
700
600
500
400
300
200
100
0
WorkOn
Cause
</figure>
<page confidence="0.990327">
1489
</page>
<bodyText confidence="0.991706">
that can support a variety of applications, includ-
ing textual entailment, information extraction, and
question answering.
</bodyText>
<sectionHeader confidence="0.995461" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9899635">
This research was supported by DARPA contract
number FA8750-09-C-3705.
</bodyText>
<sectionHeader confidence="0.998505" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99986391919192">
Michele Banko and Oren Etzioni. 2008. The tradeoffs
between open and traditional relation extraction. In
Proceedings of ACL-08: HLT, pages 28–36, June.
Dmitry Davidov, Ari Rappoport, and Moshel Koppel.
2007. Fully unsupervised discovery of concept-
specific relationships by web mining. In Proc. of
the 45th Annual Meeting of the Association of Com-
putational Linguistics, pages 232–239, June.
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S. Weld, and Alexander Yates. 2005. Un-
supervised named-entity extraction from the web:
an experimental study. Artificial Intelligence,
165(1):91–134, June.
Michael Fleischman and Eduard Hovy. 2002. Fine
grained classification of named entities. In Proceed-
ings of the 19th international conference on Compu-
tational linguistics, pages 1–7.
Roxana Girju, Adriana Badulescu, and Dan Moldovan.
2003. Learning semantic constraints for the auto-
matic discovery of part-whole relations. In Proc. of
the 2003 Conference of the North American Chapter
of the Association for Computational Linguistics on
Human Language Technology, pages 1–8.
Marti Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. of the
14th conference on Computational linguistics, pages
539–545.
Eduard Hovy, Zornitsa Kozareva, and Ellen Riloff.
2009. Toward completeness in concept extraction
and classification. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing, pages 948–957.
Sean Igo and Ellen Riloff. 2009. Corpus-based se-
mantic lexicon induction with web-based corrobora-
tion. In Proceedings of the Workshop on Unsuper-
vised and Minimally Supervised Learning of Lexical
Semantics.
Boris Katz and Jimmy Lin. 2003. Selectively using re-
lations to improve precision in question answering.
In In Proceedings of the EACL-2003 Workshop on
Natural Language Processing for Question Answer-
ing, pages 43–50.
Boris Katz, Jimmy Lin, Daniel Loreto, Wesley Hilde-
brandt, Matthew Bilotti, Sue Felshin, Aaron Fernan-
des, Gregory Marton, and Federico Mora. 2003.
Integrating web-based and corpus-based techniques
for question answering. In Proceedings of the
twelfth text retrieval conference (TREC), pages 426–
435.
Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy.
2008. Semantic class learning from the web with
hyponym pattern linkage graphs. In Proceedings of
ACL-08: HLT, pages 1048–1056.
Dekang Lin and Patrick Pantel. 2002. Concept dis-
covery from text. In Proc. of the 19th international
conference on Computational linguistics, pages 1–7.
Characteristics Of Mt, John Lehrberger, Laurent
Bourbeau, Philadelphia John Benjamins, and Rita
Mccardell. 1988. Machine Translation: Linguistic
Characteristics of Mt Systems and General Method-
ology of Evaluation. John Benjamins Publishing
Co(1988-03).
Patrick Pantel and Deepak Ravichandran. 2004. Auto-
matically labeling semantic classes. In Proc. of Hu-
man Language Technology Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 321–328.
Patrick Pantel, Eric Crestan, Arkady Borkovsky, Ana-
Maria Popescu, and Vishnu Vyas. 2009. Web-
scale distributional similarity and entity set expan-
sion. In Proceedings of the 2009 Conference on
Empirical Methods in Natural Language Process-
ing, pages 938–947, August.
Marius Pasca. 2004. Acquisition of categorized named
entities for web search. In Proc. of the thirteenth
ACM international conference on Information and
knowledge management, pages 137–145.
Marco Pennacchiotti and Patrick Pantel. 2006. On-
tologizing semantic relations. In ACL-44: Proceed-
ings of the 21st International Conference on Com-
putational Linguistics and the 44th annual meeting
of the Association for Computational Linguistics,
pages 793–800.
Ellen Riloff and Rosie Jones. 1999. Learning dic-
tionaries for information extraction by multi-level
bootstrapping. In AAAI ’99/IAAI ’99: Proceedings
of the Sixteenth National Conference on Artificial in-
telligence.
Ellen Riloff and Jessica Shepherd. 1997. A Corpus-
Based Approach for Building Semantic Lexicons.
In Proc. of the Second Conference on Empirical
Methods in Natural Language Processing, pages
117–124.
Brian Roark and Eugene Charniak. 1998. Noun-
phrase co-occurrence statistics for semiautomatic
semantic lexicon construction. In Proceedings of the
17th international conference on Computational lin-
guistics, pages 1110–1116.
</reference>
<page confidence="0.768835">
1490
</page>
<reference confidence="0.9990134">
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2005.
Learning syntactic patterns for automatic hypernym
discovery. In Advances in Neural Information Pro-
cessing Systems 17, pages 1297–1304. MIT Press.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In WWW ’07: Proceedings of the 16th inter-
national conference on World Wide Web, pages 697–
706.
Partha Pratim Talukdar, Joseph Reisinger, Marius
Pasca, Deepak Ravichandran, Rahul Bhagat, and
Fernando Pereira. 2008. Weakly-supervised acqui-
sition of labeled class instances using graph random
walks. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP 2008, pages 582–590.
Michael Thelen and Ellen Riloff. 2002. A Bootstrap-
ping Method for Learning Semantic Lexicons Using
Extraction Pattern Contexts. In Proc. of the 2002
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 214–221.
Yorick Wilks. 1975. A preferential pattern-seeking,
semantics for natural language inference. Artificial
Intelligence, 6(1):53–74.
Alexander Yates, Michael Cafarella, Michele Banko,
Oren Etzioni, Matthew Broadhead, and Stephen
Soderland. 2007. Textrunner: open information ex-
traction on the web. In NAACL ’07: Proceedings of
Human Language Technologies: The Annual Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Demonstra-
tions on XX, pages 25–26.
Fabio Massimo Zanzotto, Marco Pennacchiotti, and
Maria Teresa Pazienza. 2006. Discovering asym-
metric entailment relations between verbs using se-
lectional preferences. In ACL-44: Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics, pages 849–
856.
</reference>
<page confidence="0.993066">
1491
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.957007">
<title confidence="0.9997195">Learning Arguments and Supertypes of Semantic Relations using Recursive Patterns</title>
<author confidence="0.99926">Zornitsa Kozareva</author>
<author confidence="0.99926">Eduard Hovy</author>
<affiliation confidence="0.999962">USC Information Sciences Institute</affiliation>
<address confidence="0.9979435">4676 Admiralty Way Marina del Rey, CA 90292-6695</address>
<abstract confidence="0.9980997">A challenging problem in open information extraction and text mining is the learning of the selectional restrictions of semantic relations. We propose a minimally supervised bootstrapping algorithm that uses a single seed and a recursive lexico-syntactic pattern to learn the arguments and the supertypes of a diverse set of semantic relations from the Web. We evaluate the performance of our algorithm on multiple semantic relations expressed using “verb”, “noun”, and “verb prep” lexico-syntactic patterns. Humanbased evaluation shows that the accuracy of the harvested information is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
</authors>
<title>The tradeoffs between open and traditional relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>28--36</pages>
<contexts>
<context position="10910" citStr="Banko and Etzioni, 2008" startWordPosition="1707" endWordPosition="1710">actic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingly, recent work reports a class of patterns that use only one seed to learn as much information with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) introduce the so-called doublyanchored pattern (DAP) that has two anchor seed positions “(type) such as (seed) and *”, plus one open position for the terms to be learned. Learned terms can then be replaced into the seed position automatically, creating a recursive procedure that is reportedly much more accurate and has much higher final yield. (Kozareva et al., 2008; Hovy et al., 200</context>
<context position="19494" citStr="Banko and Etzioni, 2008" startWordPosition="3179" endWordPosition="3182">one vertex u003 for the argument pair (Ryanair, EasyJet), and two edges e00 1(u003, v001) and e002(u003, v001). A vertex �00 00) v &amp;quot; E V up is ranked by v00= ∀ u00,v|V 0 1 1Except for the “dress” and “person” relations, where the targeted arguments are adjectives, and the supertypes are nouns. 5 Semantic Relations So far, we have described the mechanism that learns from one seed and a recursive pattern the selectional restrictions of any semantic relation. Now, we are interested in evaluating the performance of our algorithm. A natural question that arises is: “How many patterns are there?”. (Banko and Etzioni, 2008) found that 95% of the semantic relations can be expressed using eight lexico-syntactic patterns. Space prevents us from describing all of them, therefore we focus on the three most frequent patterns which capture a large diversity of semantic relations. The relative frequency of these patterns is 37.80% for “verbs”, 22.80% for “noun prep”, and 16.00% for “verb prep”. 5.1 Data Collection Table 1 shows the lexico-syntactic pattern and the initial seed we used to express each semantic relation. To collect data, we ran our knowledge harvesting algorithm until complete exhaustion. For each query s</context>
</contexts>
<marker>Banko, Etzioni, 2008</marker>
<rawString>Michele Banko and Oren Etzioni. 2008. The tradeoffs between open and traditional relation extraction. In Proceedings of ACL-08: HLT, pages 28–36, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
<author>Moshel Koppel</author>
</authors>
<title>Fully unsupervised discovery of conceptspecific relationships by web mining.</title>
<date>2007</date>
<booktitle>In Proc. of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>232--239</pages>
<contexts>
<context position="10582" citStr="Davidov et al., 2007" startWordPosition="1651" endWordPosition="1654">r) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingly, recent work reports a class of patterns that use only one seed to learn as much information with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) introduce the so-called doublyanchored pattern (DAP) that </context>
</contexts>
<marker>Davidov, Rappoport, Koppel, 2007</marker>
<rawString>Dmitry Davidov, Ari Rappoport, and Moshel Koppel. 2007. Fully unsupervised discovery of conceptspecific relationships by web mining. In Proc. of the 45th Annual Meeting of the Association of Computational Linguistics, pages 232–239, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>AnaMaria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: an experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="1338" citStr="Etzioni et al., 2005" startWordPosition="197" endWordPosition="200">ico-syntactic patterns. Humanbased evaluation shows that the accuracy of the harvested information is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge. 1 Introduction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin,</context>
<context position="5531" citStr="Etzioni et al., 2005" startWordPosition="846" endWordPosition="849"> as follows. In the next section, we review related work. Section 3 addresses the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen a</context>
<context position="10366" citStr="Etzioni et al., 2005" startWordPosition="1610" endWordPosition="1613">e corpus. (Hovy et al., 2009) show that DAP−1 is reliable and it enriches WordNet with additional hyponyms and hypernyms. 3 Recursive Patterns A singly-anchored pattern contains one example of the seed term (the anchor) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingl</context>
<context position="11655" citStr="Etzioni et al., 2005" startWordPosition="1831" endWordPosition="1834"> learn as much information with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) introduce the so-called doublyanchored pattern (DAP) that has two anchor seed positions “(type) such as (seed) and *”, plus one open position for the terms to be learned. Learned terms can then be replaced into the seed position automatically, creating a recursive procedure that is reportedly much more accurate and has much higher final yield. (Kozareva et al., 2008; Hovy et al., 2009) have successfully applied DAP for the learning of hyponyms and hypernyms of is-a relations and report improvements over (Etzioni et al., 2005) and (Pasca, 2004). Surprisingly, this work was limited to the semantic relation is-a. No other study has described the use or effect of recursive patterns for different semantic relations. Therefore, going beyond (Kozareva et al., 2008; Hovy et al., 2009), we here introduce recursive patterns other than DAP that use only one seed to harvest the arguments and supertypes of a wide variety of relations. (Banko and Etzioni, 2008) show that semantic relations can be expressed using a handful of relation-independent lexico-syntactic patterns. Practically, we can turn any of these patterns into recu</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, AnaMaria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: an experimental study. Artificial Intelligence, 165(1):91–134, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Fleischman</author>
<author>Eduard Hovy</author>
</authors>
<title>Fine grained classification of named entities.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th international conference on Computational linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="6121" citStr="Fleischman and Hovy, 2002" startWordPosition="934" endWordPosition="937">(Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variations and alternative patterns for each relation. In contrast, when research focuses on any relation, as in TextRunner (Yates et al., 2007), there is no standardized manner for re-using the pattern learned. TextRunner scans sentences to obtain relation-independent lexico-syntactic patterns to extract t</context>
</contexts>
<marker>Fleischman, Hovy, 2002</marker>
<rawString>Michael Fleischman and Eduard Hovy. 2002. Fine grained classification of named entities. In Proceedings of the 19th international conference on Computational linguistics, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Adriana Badulescu</author>
<author>Dan Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proc. of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="1618" citStr="Girju et al., 2003" startWordPosition="240" endWordPosition="243">duction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely, the types of arguments that may fill a given </context>
<context position="5608" citStr="Girju et al., 2003" startWordPosition="859" endWordPosition="862">the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful att</context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proc. of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of the 14th conference on Computational linguistics,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="1571" citStr="Hearst, 1992" startWordPosition="234" endWordPosition="235">sity of the harvested knowledge. 1 Introduction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely</context>
<context position="5509" citStr="Hearst, 1992" startWordPosition="844" endWordPosition="845">r is organized as follows. In the next section, we review related work. Section 3 addresses the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman an</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of the 14th conference on Computational linguistics, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
</authors>
<title>Toward completeness in concept extraction and classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>948--957</pages>
<contexts>
<context position="9677" citStr="Hovy et al., 2009" startWordPosition="1500" endWordPosition="1503">l, 2006) made an attempt to ontologize the harvested arguments of is-a, part-of, and cause relations. They mapped each argument of the relation into WordNet and identified the senses for which the relation holds. Unfortunately, despite its very high precision entries, WordNet is known to have limited coverage, which makes it impossible for algorithms to map the content of a relation whose arguments are not present in WordNet. To surmount this limitation, we do not use WordNet, but employ a different method of obtaining superclasses of a filler term: the inverse doubly-anchored patterns DAP−1 (Hovy et al., 2009), which, given two arguments, harvests its supertypes from the source corpus. (Hovy et al., 2009) show that DAP−1 is reliable and it enriches WordNet with additional hyponyms and hypernyms. 3 Recursive Patterns A singly-anchored pattern contains one example of the seed term (the anchor) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new l</context>
<context position="11123" citStr="Hovy et al., 2009" startWordPosition="1744" endWordPosition="1747"> (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingly, recent work reports a class of patterns that use only one seed to learn as much information with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) introduce the so-called doublyanchored pattern (DAP) that has two anchor seed positions “(type) such as (seed) and *”, plus one open position for the terms to be learned. Learned terms can then be replaced into the seed position automatically, creating a recursive procedure that is reportedly much more accurate and has much higher final yield. (Kozareva et al., 2008; Hovy et al., 2009) have successfully applied DAP for the learning of hyponyms and hypernyms of is-a relations and report improvements over (Etzioni et al., 2005) and (Pasca, 2004). Surprisingly, this work was limited to the seman</context>
<context position="14786" citStr="Hovy et al., 2009" startWordPosition="2347" endWordPosition="2350">ents {Brian, Kate, bees, Delta, Alaska} and the right side arguments {flowers, trees, party, New York, Italy, France}. For each argument, the algorithm harvests supertypes such as {people, artists, politicians, airlines, city, countries, plants, event} among others. The colored links between the right and left side concepts denote the selectional restrictions of the relation. For instance, people fly to events and countries, but never to trees or flowers. 4.2 System Architecture We propose a minimally supervised bootstrapping algorithm based on the framework adopted in (Kozareva et al., 2008; Hovy et al., 2009). The algorithm has two phases: argument harvesting and supertype harvesting. The final output is a ranked list of interlinked concepts which captures the selectional restrictions of the relation. 4.2.1 Argument Harvesting In the argument extraction phase, the first bootstrapping iteration is initiated with a seed Y and a recursive pattern “X∗ and Y verb+prep|verb|noun Z∗”, where X∗ and Z∗ are the placeholders for the arguments to be learned. The pattern is submitted to Yahoo! as a web query and all unique snippets matching the query are retrieved. The newly learned and previously unexplored a</context>
<context position="32580" citStr="Hovy et al., 2009" startWordPosition="5502" endWordPosition="5505">gure 3: Ranked Supertypes. The decline of the curve indicates that certain supertypes are preferred and shared among different argument pairs. It is interesting to note that the text on the Web prefers a small set of supertypes, and to see what they are. These most-popular harvested types tend to be the more descriptive terms. The results indicate that one does not need an elaborate supertype hierarchy to handle the selectional restrictions of semantic relations. Since our problem definition differs from available related work, and WordNet does not contain all harvested arguments as shown in (Hovy et al., 2009), it is not possible to make a direct comparison. Instead, we conduct a manual evaluation of the most highly ranked supertypes which normally are the top 20. The overall accuracy of the supertypes for all relations is 92%. Table 6 shows the Relation Arguments (Sups) Celebrate: men, people, nations, angels, workers, children countries, teams, parents, teachers (Sups) Dress: colors, effects, color tones, activities, patterns styles, materials, size, languages, aspects (Sups) FlyTo: airlines, carriers, companies, giants, people competitors, political figures, stars, celebs Cause (Sup,): diseases,</context>
</contexts>
<marker>Hovy, Kozareva, Riloff, 2009</marker>
<rawString>Eduard Hovy, Zornitsa Kozareva, and Ellen Riloff. 2009. Toward completeness in concept extraction and classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 948–957.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Igo</author>
<author>Ellen Riloff</author>
</authors>
<title>Corpus-based semantic lexicon induction with web-based corroboration.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics.</booktitle>
<contexts>
<context position="8352" citStr="Igo and Riloff, 2009" startWordPosition="1292" endWordPosition="1295">e first argument and city and event of the second. This information provides the selectional restrictions of the given semantic relation, indicating that living things like people can fly to cities and events, while non-living things like airlines fly mainly to cities. This is a significant improvement over systems that output a flat list of lexical semantic knowledge (Thelen and Riloff, 2002; Yates et al., 2007; Suchanek et al., 2007). Knowing the sectional restrictions of a semantic relation supports inference in many applications, for example enabling more accurate information extraction. (Igo and Riloff, 2009) report that patterns like “attack on (NP)” can learn undesirable words due to idiomatic expressions and parsing errors. Over time this becomes problematic for the bootstrapping process and leads to significant deterioration in performance. (Thelen and Riloff, 2002) address this problem by learning multiple semantic categories simultaneously, relying on the often unrealistic assumption that a word cannot belong to more than one semantic category. How1483 ever, if we have at our disposal a repository of semantic relations with their selectional restrictions, the problem addressed in (Igo and Ri</context>
<context position="10448" citStr="Igo and Riloff, 2009" startWordPosition="1623" endWordPosition="1626">with additional hyponyms and hypernyms. 3 Recursive Patterns A singly-anchored pattern contains one example of the seed term (the anchor) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingly, recent work reports a class of patterns that use only one seed to learn as much</context>
</contexts>
<marker>Igo, Riloff, 2009</marker>
<rawString>Sean Igo and Ellen Riloff. 2009. Corpus-based semantic lexicon induction with web-based corroboration. In Proceedings of the Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
</authors>
<title>Selectively using relations to improve precision in question answering. In</title>
<date>2003</date>
<booktitle>In Proceedings of the EACL-2003 Workshop on Natural Language Processing for Question Answering,</booktitle>
<pages>43--50</pages>
<contexts>
<context position="1944" citStr="Katz and Lin, 2003" startWordPosition="295" endWordPosition="298">et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely, the types of arguments that may fill a given relation, such as person live-in city and airline fly-to location). Selectional restrictions constrain the possible fillers of a relation, and hence the possible contexts in which the patterns expressing that relation can participate in, thereby enabling sense disambiguation of both the fillers and the expression itself. To </context>
</contexts>
<marker>Katz, Lin, 2003</marker>
<rawString>Boris Katz and Jimmy Lin. 2003. Selectively using relations to improve precision in question answering. In In Proceedings of the EACL-2003 Workshop on Natural Language Processing for Question Answering, pages 43–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boris Katz</author>
<author>Jimmy Lin</author>
<author>Daniel Loreto</author>
<author>Wesley Hildebrandt</author>
<author>Matthew Bilotti</author>
<author>Sue Felshin</author>
<author>Aaron Fernandes</author>
<author>Gregory Marton</author>
<author>Federico Mora</author>
</authors>
<title>Integrating web-based and corpus-based techniques for question answering.</title>
<date>2003</date>
<booktitle>In Proceedings of the twelfth text retrieval conference (TREC),</booktitle>
<pages>426--435</pages>
<contexts>
<context position="1470" citStr="Katz et al., 2003" startWordPosition="218" endWordPosition="221">sults with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge. 1 Introduction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is</context>
</contexts>
<marker>Katz, Lin, Loreto, Hildebrandt, Bilotti, Felshin, Fernandes, Marton, Mora, 2003</marker>
<rawString>Boris Katz, Jimmy Lin, Daniel Loreto, Wesley Hildebrandt, Matthew Bilotti, Sue Felshin, Aaron Fernandes, Gregory Marton, and Federico Mora. 2003. Integrating web-based and corpus-based techniques for question answering. In Proceedings of the twelfth text retrieval conference (TREC), pages 426– 435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic class learning from the web with hyponym pattern linkage graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>1048--1056</pages>
<contexts>
<context position="5568" citStr="Kozareva et al., 2008" startWordPosition="852" endWordPosition="855">e review related work. Section 3 addresses the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focus</context>
<context position="10606" citStr="Kozareva et al., 2008" startWordPosition="1655" endWordPosition="1658">on for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingly, recent work reports a class of patterns that use only one seed to learn as much information with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) introduce the so-called doublyanchored pattern (DAP) that has two anchor seed posi</context>
<context position="11891" citStr="Kozareva et al., 2008" startWordPosition="1869" endWordPosition="1872">the terms to be learned. Learned terms can then be replaced into the seed position automatically, creating a recursive procedure that is reportedly much more accurate and has much higher final yield. (Kozareva et al., 2008; Hovy et al., 2009) have successfully applied DAP for the learning of hyponyms and hypernyms of is-a relations and report improvements over (Etzioni et al., 2005) and (Pasca, 2004). Surprisingly, this work was limited to the semantic relation is-a. No other study has described the use or effect of recursive patterns for different semantic relations. Therefore, going beyond (Kozareva et al., 2008; Hovy et al., 2009), we here introduce recursive patterns other than DAP that use only one seed to harvest the arguments and supertypes of a wide variety of relations. (Banko and Etzioni, 2008) show that semantic relations can be expressed using a handful of relation-independent lexico-syntactic patterns. Practically, we can turn any of these patterns into recursive form by giving as input only one of the arguments and leaving the other one as an open slot, allowing the learned arguments to replace the initial seed argument directly. For example, for the relation “fly to”, the following recur</context>
<context position="13372" citStr="Kozareva et al., 2008" startWordPosition="2125" endWordPosition="2128"> arguments are learned. Conjunctions like and, or are useful because they express list constructions and extract arguments similar to the seed. Potentially, one can explore all recursive pattern variations when learning a relation and compare their yield, however this study is beyond the scope of this paper. We are particularly interested in the usage of recursive patterns for the learning of semantic relations not only because it is a novel method, but also because recursive patterns of the DAP fashion are known to: (1) learn concepts with high precision compared to singly-anchored patterns (Kozareva et al., 2008), (2) use only one seed instance for the discovery of new previously unknown terms, and (3) harvest knowledge with minimal supervision. 1484 4 Bootstrapping Recursive Patterns 4.1 Problem Formulation The main goal of our research is: Task Definition: Given a seed and a semantic relation expressed using a recursive lexico-syntactic pattern, learn in bootstrapping fashion the selectional restrictions (i.e., the arguments and supertypes) of the semantic relation from an unstructured corpus such as the Web. Figure 1 shows an example of the task and the types of information learned by our algorithm</context>
<context position="14766" citStr="Kozareva et al., 2008" startWordPosition="2343" endWordPosition="2346">rns the left side arguments {Brian, Kate, bees, Delta, Alaska} and the right side arguments {flowers, trees, party, New York, Italy, France}. For each argument, the algorithm harvests supertypes such as {people, artists, politicians, airlines, city, countries, plants, event} among others. The colored links between the right and left side concepts denote the selectional restrictions of the relation. For instance, people fly to events and countries, but never to trees or flowers. 4.2 System Architecture We propose a minimally supervised bootstrapping algorithm based on the framework adopted in (Kozareva et al., 2008; Hovy et al., 2009). The algorithm has two phases: argument harvesting and supertype harvesting. The final output is a ranked list of interlinked concepts which captures the selectional restrictions of the relation. 4.2.1 Argument Harvesting In the argument extraction phase, the first bootstrapping iteration is initiated with a seed Y and a recursive pattern “X∗ and Y verb+prep|verb|noun Z∗”, where X∗ and Z∗ are the placeholders for the arguments to be learned. The pattern is submitted to Yahoo! as a web query and all unique snippets matching the query are retrieved. The newly learned and pre</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic class learning from the web with hyponym pattern linkage graphs. In Proceedings of ACL-08: HLT, pages 1048–1056.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th international conference on Computational linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="5480" citStr="Lin and Pantel, 2002" startWordPosition="837" endWordPosition="840"> knowledge bases. The rest of the paper is organized as follows. In the next section, we review related work. Section 3 addresses the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff a</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>Dekang Lin and Patrick Pantel. 2002. Concept discovery from text. In Proc. of the 19th international conference on Computational linguistics, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Characteristics Of Mt</author>
<author>John Lehrberger</author>
<author>Laurent Bourbeau</author>
<author>Philadelphia John Benjamins</author>
<author>Rita Mccardell</author>
</authors>
<title>Machine Translation: Linguistic Characteristics of Mt Systems and General Methodology of Evaluation.</title>
<date>1988</date>
<publisher>John Benjamins Publishing Co(1988-03).</publisher>
<contexts>
<context position="1969" citStr="Mt et al., 1988" startWordPosition="301" endWordPosition="304">cons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely, the types of arguments that may fill a given relation, such as person live-in city and airline fly-to location). Selectional restrictions constrain the possible fillers of a relation, and hence the possible contexts in which the patterns expressing that relation can participate in, thereby enabling sense disambiguation of both the fillers and the expression itself. To acquire this knowledge tw</context>
</contexts>
<marker>Mt, Lehrberger, Bourbeau, Benjamins, Mccardell, 1988</marker>
<rawString>Characteristics Of Mt, John Lehrberger, Laurent Bourbeau, Philadelphia John Benjamins, and Rita Mccardell. 1988. Machine Translation: Linguistic Characteristics of Mt Systems and General Methodology of Evaluation. John Benjamins Publishing Co(1988-03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Automatically labeling semantic classes.</title>
<date>2004</date>
<booktitle>In Proc. of Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>321--328</pages>
<contexts>
<context position="6039" citStr="Pantel and Ravichandran, 2004" startWordPosition="922" endWordPosition="925">icons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variations and alternative patterns for each relation. In contrast, when research focuses on any relation, as in TextRunner (Yates et al., 2007), there is no standardized manner for re-using the pattern learned. TextRunner sca</context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>Patrick Pantel and Deepak Ravichandran. 2004. Automatically labeling semantic classes. In Proc. of Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics, pages 321–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Eric Crestan, Arkady Borkovsky, AnaMaria Popescu, and Vishnu Vyas.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>938--947</pages>
<marker>Pantel, 2009</marker>
<rawString>Patrick Pantel, Eric Crestan, Arkady Borkovsky, AnaMaria Popescu, and Vishnu Vyas. 2009. Webscale distributional similarity and entity set expansion. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 938–947, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
</authors>
<title>Acquisition of categorized named entities for web search.</title>
<date>2004</date>
<booktitle>In Proc. of the thirteenth ACM international conference on Information and knowledge management,</booktitle>
<pages>137--145</pages>
<contexts>
<context position="1585" citStr="Pasca, 2004" startWordPosition="236" endWordPosition="237">rvested knowledge. 1 Introduction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely, the types of</context>
<context position="5544" citStr="Pasca, 2004" startWordPosition="850" endWordPosition="851">xt section, we review related work. Section 3 addresses the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 20</context>
<context position="11673" citStr="Pasca, 2004" startWordPosition="1836" endWordPosition="1837">with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) introduce the so-called doublyanchored pattern (DAP) that has two anchor seed positions “(type) such as (seed) and *”, plus one open position for the terms to be learned. Learned terms can then be replaced into the seed position automatically, creating a recursive procedure that is reportedly much more accurate and has much higher final yield. (Kozareva et al., 2008; Hovy et al., 2009) have successfully applied DAP for the learning of hyponyms and hypernyms of is-a relations and report improvements over (Etzioni et al., 2005) and (Pasca, 2004). Surprisingly, this work was limited to the semantic relation is-a. No other study has described the use or effect of recursive patterns for different semantic relations. Therefore, going beyond (Kozareva et al., 2008; Hovy et al., 2009), we here introduce recursive patterns other than DAP that use only one seed to harvest the arguments and supertypes of a wide variety of relations. (Banko and Etzioni, 2008) show that semantic relations can be expressed using a handful of relation-independent lexico-syntactic patterns. Practically, we can turn any of these patterns into recursive form by givi</context>
</contexts>
<marker>Pasca, 2004</marker>
<rawString>Marius Pasca. 2004. Acquisition of categorized named entities for web search. In Proc. of the thirteenth ACM international conference on Information and knowledge management, pages 137–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Patrick Pantel</author>
</authors>
<title>Ontologizing semantic relations.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>793--800</pages>
<contexts>
<context position="3580" citStr="Pennacchiotti and Pantel, 2006" startWordPosition="553" endWordPosition="556"> domain these approaches are both very promising, but when tackling an unbounded number of relations they are unrealistic. The quality of clustering decreases as the domain becomes more continuously varied and diverse, and it has proven difficult to create collections of effective patterns and high-yield seeds manually. In addition, the output of most harvesting systems is a flat list of lexical semantic expressions such as “New York is-a city” and “virus causes flu”. However, using this knowledge in inference requires it to be formulated appropriately and organized in a semantic repository. (Pennacchiotti and Pantel, 2006) proposed an algorithm for automatically ontologizing semantic relations into WordNet. However, despite its high precision entries, WordNet’s limited coverage makes it impossible for relations whose arguments are not present in WordNet to be incorporated. One would like a procedure that dynamically organizes and extends 1482 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1482–1491, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics its semantic repository in order to be able to accommodate all newly-harvested infor</context>
<context position="5820" citStr="Pennacchiotti and Pantel, 2006" startWordPosition="892" endWordPosition="895">llection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variati</context>
<context position="9067" citStr="Pennacchiotti and Pantel, 2006" startWordPosition="1400" endWordPosition="1403">atic expressions and parsing errors. Over time this becomes problematic for the bootstrapping process and leads to significant deterioration in performance. (Thelen and Riloff, 2002) address this problem by learning multiple semantic categories simultaneously, relying on the often unrealistic assumption that a word cannot belong to more than one semantic category. How1483 ever, if we have at our disposal a repository of semantic relations with their selectional restrictions, the problem addressed in (Igo and Riloff, 2009) can be alleviated. In order to obtain selectional restriction classes, (Pennacchiotti and Pantel, 2006) made an attempt to ontologize the harvested arguments of is-a, part-of, and cause relations. They mapped each argument of the relation into WordNet and identified the senses for which the relation holds. Unfortunately, despite its very high precision entries, WordNet is known to have limited coverage, which makes it impossible for algorithms to map the content of a relation whose arguments are not present in WordNet. To surmount this limitation, we do not use WordNet, but employ a different method of obtaining superclasses of a filler term: the inverse doubly-anchored patterns DAP−1 (Hovy et </context>
</contexts>
<marker>Pennacchiotti, Pantel, 2006</marker>
<rawString>Marco Pennacchiotti and Patrick Pantel. 2006. Ontologizing semantic relations. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 793–800.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Rosie Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In AAAI ’99/IAAI ’99: Proceedings of the Sixteenth National Conference on Artificial intelligence.</booktitle>
<contexts>
<context position="6094" citStr="Riloff and Jones, 1999" startWordPosition="930" endWordPosition="933">l, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variations and alternative patterns for each relation. In contrast, when research focuses on any relation, as in TextRunner (Yates et al., 2007), there is no standardized manner for re-using the pattern learned. TextRunner scans sentences to obtain relation-independent lexico-synt</context>
<context position="10324" citStr="Riloff and Jones, 1999" startWordPosition="1602" endWordPosition="1605">nts, harvests its supertypes from the source corpus. (Hovy et al., 2009) show that DAP−1 is reliable and it enriches WordNet with additional hyponyms and hypernyms. 3 Recursive Patterns A singly-anchored pattern contains one example of the seed term (the anchor) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing ma</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>Ellen Riloff and Rosie Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In AAAI ’99/IAAI ’99: Proceedings of the Sixteenth National Conference on Artificial intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Jessica Shepherd</author>
</authors>
<title>A CorpusBased Approach for Building Semantic Lexicons.</title>
<date>1997</date>
<booktitle>In Proc. of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>117--124</pages>
<contexts>
<context position="5442" citStr="Riloff and Shepherd, 1997" startWordPosition="831" endWordPosition="834">son of the results with some large existing knowledge bases. The rest of the paper is organized as follows. In the next section, we review related work. Section 3 addresses the representation of semantic relations using recursive patterns. Section 4 describes the bootstrapping mechanism that learns the selectional restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), a</context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>Ellen Riloff and Jessica Shepherd. 1997. A CorpusBased Approach for Building Semantic Lexicons. In Proc. of the Second Conference on Empirical Methods in Natural Language Processing, pages 117–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Eugene Charniak</author>
</authors>
<title>Nounphrase co-occurrence statistics for semiautomatic semantic lexicon construction.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational linguistics,</booktitle>
<pages>1110--1116</pages>
<contexts>
<context position="5983" citStr="Roark and Charniak, 1998" startWordPosition="915" endWordPosition="919">ts of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variations and alternative patterns for each relation. In contrast, when research focuses on any relation, as in TextRunner (Yates et al., 2007), there is no standardized</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>Brian Roark and Eugene Charniak. 1998. Nounphrase co-occurrence statistics for semiautomatic semantic lexicon construction. In Proceedings of the 17th international conference on Computational linguistics, pages 1110–1116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Learning syntactic patterns for automatic hypernym discovery.</title>
<date>2005</date>
<booktitle>In Advances in Neural Information Processing Systems 17,</booktitle>
<pages>1297--1304</pages>
<publisher>MIT Press.</publisher>
<contexts>
<context position="10343" citStr="Snow et al., 2005" startWordPosition="1606" endWordPosition="1609">ypes from the source corpus. (Hovy et al., 2009) show that DAP−1 is reliable and it enriches WordNet with additional hyponyms and hypernyms. 3 Recursive Patterns A singly-anchored pattern contains one example of the seed term (the anchor) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes un</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2005</marker>
<rawString>Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2005. Learning syntactic patterns for automatic hypernym discovery. In Advances in Neural Information Processing Systems 17, pages 1297–1304. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In WWW ’07: Proceedings of the 16th international conference on World Wide Web,</booktitle>
<pages>697--706</pages>
<contexts>
<context position="1431" citStr="Suchanek et al., 2007" startWordPosition="211" endWordPosition="214">mation is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge. 1 Introduction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from</context>
<context position="5751" citStr="Suchanek et al., 2007" startWordPosition="881" endWordPosition="884">al restrictions of the relations. Section 5 describes data collection. Section 6 discusses the obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has p</context>
<context position="8170" citStr="Suchanek et al., 2007" startWordPosition="1268" endWordPosition="1271">y determining that John, Prague) and (John, conference) are two valid filler instance pairs, that (RyanAir, Prague) is another, as well as that person and airline are supertypes of the first argument and city and event of the second. This information provides the selectional restrictions of the given semantic relation, indicating that living things like people can fly to cities and events, while non-living things like airlines fly mainly to cities. This is a significant improvement over systems that output a flat list of lexical semantic knowledge (Thelen and Riloff, 2002; Yates et al., 2007; Suchanek et al., 2007). Knowing the sectional restrictions of a semantic relation supports inference in many applications, for example enabling more accurate information extraction. (Igo and Riloff, 2009) report that patterns like “attack on (NP)” can learn undesirable words due to idiomatic expressions and parsing errors. Over time this becomes problematic for the bootstrapping process and leads to significant deterioration in performance. (Thelen and Riloff, 2002) address this problem by learning multiple semantic categories simultaneously, relying on the often unrealistic assumption that a word cannot belong to </context>
<context position="23745" citStr="Suchanek et al., 2007" startWordPosition="3922" endWordPosition="3925">p, the gold standard data was not available. The online demo of TextRunner2 (Yates et al., 2007) actually allowed us to collect the arguments for all our semantic relations. However, due to Web based query limitations, TextRunner returns only the first 1000 snippets. Since we do not have the complete and ranked output of TextRunner, comparing results in terms of recall and precision is impossible. Turning instead to results obtained from structured sources (which one expects to have high correctness), we found that two of our relations overlap with those of the freely available ontology Yago (Suchanek et al., 2007), which was harvested from the Infoboxes tables in Wikipedia. In addition, we also had two human annotators judge as many results as we could afford, to obtain Precision. We conducted two evaluations, one for the arguments and one for the supertypes. 2http://www.cs.washington.edu/research/textrunner/ 6.1 Human-Based Argument Evaluation In this section, we discuss the results of the harvested arguments. For each relation, we selected the top 200 highly ranked arguments. We hired two annotators to judge their correctness. We created detailed annotation guidelines that define the labels for the a</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In WWW ’07: Proceedings of the 16th international conference on World Wide Web, pages 697– 706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>Joseph Reisinger</author>
<author>Marius Pasca</author>
<author>Deepak Ravichandran</author>
<author>Rahul Bhagat</author>
<author>Fernando Pereira</author>
</authors>
<title>Weakly-supervised acquisition of labeled class instances using graph random walks.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP</booktitle>
<pages>582--590</pages>
<contexts>
<context position="10529" citStr="Talukdar et al., 2008" startWordPosition="1639" endWordPosition="1643">attern contains one example of the seed term (the anchor) and one open position for the term to be learned. Most researchers use singly-anchored patterns to harvest semantic relations. Unfortunately, these patterns run out of steam very quickly. To surmount this obstacle, a handful of seeds is generally used, and helps to guarantee diversity in the extraction of new lexicosyntactic patterns (Riloff and Jones, 1999; Snow et al., 2005; Etzioni et al., 2005). Some algorithms require ten seeds (Riloff and Jones, 1999; Igo and Riloff, 2009), while others use a variation of 5, 10, to even 25 seeds (Talukdar et al., 2008). Seeds may be chosen at random (Davidov et al., 2007; Kozareva et al., 2008), by picking the most frequent terms of the desired class (Igo and Riloff, 2009), or by asking humans (Pantel et al., 2009). As (Pantel et al., 2009) show, picking seeds that yield high numbers of different terms is difficult. Thus, when dealing with unbounded sets of relations (Banko and Etzioni, 2008), providing many seeds becomes unrealistic. Interestingly, recent work reports a class of patterns that use only one seed to learn as much information with only one seed. (Kozareva et al., 2008; Hovy et al., 2009) intro</context>
</contexts>
<marker>Talukdar, Reisinger, Pasca, Ravichandran, Bhagat, Pereira, 2008</marker>
<rawString>Partha Pratim Talukdar, Joseph Reisinger, Marius Pasca, Deepak Ravichandran, Rahul Bhagat, and Fernando Pereira. 2008. Weakly-supervised acquisition of labeled class instances using graph random walks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP 2008, pages 582–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Thelen</author>
<author>Ellen Riloff</author>
</authors>
<title>A Bootstrapping Method for Learning Semantic Lexicons Using Extraction Pattern Contexts.</title>
<date>2002</date>
<booktitle>In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>214--221</pages>
<contexts>
<context position="1383" citStr="Thelen and Riloff, 2002" startWordPosition="204" endWordPosition="207">ion shows that the accuracy of the harvested information is about 90%. We also compare our results with existing knowledge base to outline the similarities and differences of the granularity and diversity of the harvested knowledge. 1 Introduction Building and maintaining knowledge-rich resources is of great importance to information extraction, question answering, and textual entailment. Given the endless amount of data we have at our disposal, many efforts have focused on mining knowledge from structured or unstructured text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a sl</context>
<context position="6147" citStr="Thelen and Riloff, 2002" startWordPosition="938" endWordPosition="941">l., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variations and alternative patterns for each relation. In contrast, when research focuses on any relation, as in TextRunner (Yates et al., 2007), there is no standardized manner for re-using the pattern learned. TextRunner scans sentences to obtain relation-independent lexico-syntactic patterns to extract triples of the form (John, </context>
<context position="8126" citStr="Thelen and Riloff, 2002" startWordPosition="1260" endWordPosition="1263">on and the pattern X flies to Y, automatically determining that John, Prague) and (John, conference) are two valid filler instance pairs, that (RyanAir, Prague) is another, as well as that person and airline are supertypes of the first argument and city and event of the second. This information provides the selectional restrictions of the given semantic relation, indicating that living things like people can fly to cities and events, while non-living things like airlines fly mainly to cities. This is a significant improvement over systems that output a flat list of lexical semantic knowledge (Thelen and Riloff, 2002; Yates et al., 2007; Suchanek et al., 2007). Knowing the sectional restrictions of a semantic relation supports inference in many applications, for example enabling more accurate information extraction. (Igo and Riloff, 2009) report that patterns like “attack on (NP)” can learn undesirable words due to idiomatic expressions and parsing errors. Over time this becomes problematic for the bootstrapping process and leads to significant deterioration in performance. (Thelen and Riloff, 2002) address this problem by learning multiple semantic categories simultaneously, relying on the often unrealis</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>Michael Thelen and Ellen Riloff. 2002. A Bootstrapping Method for Learning Semantic Lexicons Using Extraction Pattern Contexts. In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 214–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>A preferential pattern-seeking, semantics for natural language inference.</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="2163" citStr="Wilks, 1975" startWordPosition="333" endWordPosition="334">s is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely, the types of arguments that may fill a given relation, such as person live-in city and airline fly-to location). Selectional restrictions constrain the possible fillers of a relation, and hence the possible contexts in which the patterns expressing that relation can participate in, thereby enabling sense disambiguation of both the fillers and the expression itself. To acquire this knowledge two common approaches are employed: clustering and patterns. While clustering has the advantage of being fully unsupervised, it may or may not produce the types and granularity desired by a user. </context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Yorick Wilks. 1975. A preferential pattern-seeking, semantics for natural language inference. Artificial Intelligence, 6(1):53–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Michael Cafarella</author>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
<author>Matthew Broadhead</author>
<author>Stephen Soderland</author>
</authors>
<title>Textrunner: open information extraction on the web. In</title>
<date>2007</date>
<booktitle>NAACL ’07: Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations on XX,</booktitle>
<pages>25--26</pages>
<contexts>
<context position="5841" citStr="Yates et al., 2007" startWordPosition="896" endWordPosition="899">e obtained results. Finally, we conclude in Section 7. 2 Related Work A substantial body of work has been done in attempts to harvest bits of semantic information, including: semantic lexicons (Riloff and Shepherd, 1997), concept lists (Lin and Pantel, 2002), isa relations (Hearst, 1992; Etzioni et al., 2005; Pasca, 2004; Kozareva et al., 2008), part-of relations (Girju et al., 2003), and others. Knowledge has been harvested with varying success both from structured text such as Wikipedia’s infoboxes (Suchanek et al., 2007) or unstructured text such as the Web (Pennacchiotti and Pantel, 2006; Yates et al., 2007). A variety of techniques have been employed, including clustering (Lin and Pantel, 2002), co-occurrence statistics (Roark and Charniak, 1998), syntactic dependencies (Pantel and Ravichandran, 2004), and lexico-syntactic patterns (Riloff and Jones, 1999; Fleischman and Hovy, 2002; Thelen and Riloff, 2002). When research focuses on a particular relation, careful attention is paid to the pattern(s) that express it in various ways (as in most of the work above, notably (Riloff and Jones, 1999)). But it has proven a difficult task to manually find effectively different variations and alternative p</context>
<context position="8146" citStr="Yates et al., 2007" startWordPosition="1264" endWordPosition="1267">s to Y, automatically determining that John, Prague) and (John, conference) are two valid filler instance pairs, that (RyanAir, Prague) is another, as well as that person and airline are supertypes of the first argument and city and event of the second. This information provides the selectional restrictions of the given semantic relation, indicating that living things like people can fly to cities and events, while non-living things like airlines fly mainly to cities. This is a significant improvement over systems that output a flat list of lexical semantic knowledge (Thelen and Riloff, 2002; Yates et al., 2007; Suchanek et al., 2007). Knowing the sectional restrictions of a semantic relation supports inference in many applications, for example enabling more accurate information extraction. (Igo and Riloff, 2009) report that patterns like “attack on (NP)” can learn undesirable words due to idiomatic expressions and parsing errors. Over time this becomes problematic for the bootstrapping process and leads to significant deterioration in performance. (Thelen and Riloff, 2002) address this problem by learning multiple semantic categories simultaneously, relying on the often unrealistic assumption that </context>
<context position="23219" citStr="Yates et al., 2007" startWordPosition="3838" endWordPosition="3841">nformation, as in the “work for” relation. 6 Results In this section, we evaluate the results of our knowledge harvesting algorithm. Initially, we decided to conduct an automatic evaluation comparing our results to knowledge bases that have been extracted in a similar way (i.e., through pattern application over unstructured text). However, it is not always possible to perform a complete comparison, because either researchers have not fully explored the same relations we have studied, or for those relations that overlap, the gold standard data was not available. The online demo of TextRunner2 (Yates et al., 2007) actually allowed us to collect the arguments for all our semantic relations. However, due to Web based query limitations, TextRunner returns only the first 1000 snippets. Since we do not have the complete and ranked output of TextRunner, comparing results in terms of recall and precision is impossible. Turning instead to results obtained from structured sources (which one expects to have high correctness), we found that two of our relations overlap with those of the freely available ontology Yago (Suchanek et al., 2007), which was harvested from the Infoboxes tables in Wikipedia. In addition,</context>
</contexts>
<marker>Yates, Cafarella, Banko, Etzioni, Broadhead, Soderland, 2007</marker>
<rawString>Alexander Yates, Michael Cafarella, Michele Banko, Oren Etzioni, Matthew Broadhead, and Stephen Soderland. 2007. Textrunner: open information extraction on the web. In NAACL ’07: Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations on XX, pages 25–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Maria Teresa Pazienza</author>
</authors>
<title>Discovering asymmetric entailment relations between verbs using selectional preferences.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>849--856</pages>
<contexts>
<context position="1909" citStr="Zanzotto et al., 2006" startWordPosition="289" endWordPosition="292">text, including ground facts (Etzioni et al., 2005), semantic lexicons (Thelen and Riloff, 2002), encyclopedic knowledge (Suchanek et al., 2007), and concept lists (Katz et al., 2003). Researchers have also successfully harvested relations between entities, such as is-a (Hearst, 1992; Pasca, 2004) and part-of (Girju et al., 2003). The kinds of knowledge learned are generally of two kinds: ground instance facts (New York is-a city, Rome is the capital of Italy) and general relational types (city is-a location, engines are part-of cars). A variety of NLP tasks involving inference or entailment (Zanzotto et al., 2006), including QA (Katz and Lin, 2003) and MT (Mt et al., 1988), require a slightly different form of knowledge, derived from many more relations. This knowledge is usually used to support inference and is expressed as selectional restrictions (Wilks, 1975) (namely, the types of arguments that may fill a given relation, such as person live-in city and airline fly-to location). Selectional restrictions constrain the possible fillers of a relation, and hence the possible contexts in which the patterns expressing that relation can participate in, thereby enabling sense disambiguation of both the fil</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Pazienza, 2006</marker>
<rawString>Fabio Massimo Zanzotto, Marco Pennacchiotti, and Maria Teresa Pazienza. 2006. Discovering asymmetric entailment relations between verbs using selectional preferences. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 849– 856.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>