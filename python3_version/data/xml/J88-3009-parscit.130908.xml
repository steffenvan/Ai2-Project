<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.180681">
<title confidence="0.723247">
USER MODELS AND DISCOURSE MODELS
</title>
<author confidence="0.969468">
David N. Chin
</author>
<affiliation confidence="0.9869225">
Department of Information and Computer Services
University of Hawaii at Manoa
</affiliation>
<sectionHeader confidence="0.932524" genericHeader="abstract">
2565 The Mall
Honolulu, HI 96822
</sectionHeader>
<bodyText confidence="0.999977884615385">
A user model (UM) contains information about users,
such as users&apos; goals, beliefs, knowledge, preferences,
and capabilities. A discourse model (DM) contains
information about the conversation, such as the linguis-
tic structure, the attentional state, and the intentional
structure [Grosz and Sidner 1986). Given these defini-
tions, I will argue that the UM intersects the DM. That
is, the UM contains items that are missing from the UM;
the DM contains items that are missing from the DM;
and the two share some items.
First, Schuster (1987) argues convincingly that the
UM contains items that are missing from the DM. This
is especially evident in cases where the speaker and
listener have a long association, and hence the speaker
has a large amount of prior knowledge about the listener
which is stored in the speaker&apos;s UM of the listener.
However, this information is not present in the DM,
which starts off empty.
Next, the DM contains items that are missing from
the UM. To support this argument, I will cite an
example given by Wahlster. Suppose the speaker men-
tions a long list of names that is not familiar to the
listener. Then the speaker knows that the listener
cannot know nameX, which is a particular name in the
middle of the list. This is represented in the speaker&apos;s
UM of the listener. However, nameX is in the linguistic
structure of the speaker&apos;s DM since nameX was part of
the discourse. Thus part of the linguistic structure of the
DM is not represented in the UM.
Actually, Wahlster interprets his example as an ar-
gument that the DM and the UM must be different. He
argues that since nameX is in the DM, then the UM
must be different, or else the speaker could not repre-
sent the fact that the user does not know nameX. This
argument misses a crucial point. Although it is true that
the names are listed in the linguistic structure of the
DM, these names are not present in the attentional
structure of the DM. Since the attentional structure of
the DM is that part of the DM which represents objects,
properties, and relations with which the user is familiar,
this is the proper part of the DM to compare with the
UM. To show that these names are not in the attentional
structure of the DM, consider whether it is possible to
use a pronoun to refer to nameX. If all of the other
names were male, and nameX were female, then the
speaker should be able to use the pronoun &amp;quot;she&amp;quot; in
place of nameX. However, human speakers generally
would not use such a pronoun. So there is no disagree-
ment between the attentional structure of the speaker&apos;s
DM and the speaker&apos;s UM of the listener.
Not only is there no disagreement between the atten-
tional structure of the DM and the UM, but I would like
to argue that the items in the attentional structure of the
DM are part of the UM. Take the related example of
when the speaker introduces a person&apos;s name, nameX,
unknown to the listener. In this case, the DM model
represents the fact that nameX is the name of a person
and that nameX refers to some person. Later, the
speaker can use either nameX to refer to this person, or
a pronoun. Likewise in the UM, the speaker represents
the fact that the listener knows nameX refers to some
unknown person, and represents the fact that the lis-
tener does not know the person referred to by nameX.
In this example, the contents of the attentional structure
of the DM is a subset of the UM.
Another part of the DM that intersects with the UM
is the intentional structure of the DM. The intentional
structure is made up of the immediate goals of the user
as expressed in the user&apos;s utterances plus some higher
level goals. These are also present by definition in the
UM.
Another compelling argument for the view that the
DM intersects the UM is the phenomenon of multi-
speaker discourses. In multispeaker discourses, each
speaker needs to keep not only a separate UM for each
listener, but also a separate DM for each participant.
For example, consider the following dialog among three
people debugging a circuit board.
</bodyText>
<footnote confidence="0.80688875">
Copyright 1988 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided
that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To
copy otherwise, or to republish, requires a fee and/or specific permission.
0362-613X/ 88 /01000-0403.00
</footnote>
<page confidence="0.875049">
86 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
<note confidence="0.626773">
David N. Chin User Models and Discourse Models
</note>
<bodyText confidence="0.997227193548387">
Tom: The 777 timer is really heating up.
Dick: Let&apos;s check it.
Tom (whose hands are full): OK. Dick, could you
check the frequency at the output pin. Harry,
could you check the voltage at the power pin here.
(Tom points to the power pin.)
Tom and Dick are experts, while Harry knows little
about hardware. Tom knows this, so Tom has a sepa-
rate DM for Dick and Harry. In Tom&apos;s DM for Dick,
Dick&apos;s attentional state includes the 777 timer in his
focus space. However, since Tom knows that Harry
cannot identify a 777 timer, the timer is not in Tom&apos;s
DM for Harry. So, when Tom tells Dick to check the
frequency at the output pin, Tom knows that Dick will
understand this referent. On the other hand, Harry
would not know the referent of the power pin, so Tom
points this out to Harry.
If there were only a single DM for the entire conver-
sation, then Tom would not be able to represent the
different attentional states of Dick and Harry. This
argues for the view that DMs are user dependent and
hence are subparts of UMs.
In some sense, the above scenario is somewhat
aberrant in that usually speakers assume that their
listeners share the same attentional state. So it may be
more efficient to only represent the separate attentional
states of different listeners as differences from the
norm. Thus in most cases, the list of differences would
be very small and the efficiency would be effectively the
same as having only one DM.
Although the DM and UM share some data, they are
used for fairly different purposes. DMs are used in the
generation and understanding of references such as
noun phrases and pronouns. DMs are also used in the
generation and understanding of connectives such as
cue words and phrases. On the other hand, UMs mainly
used in deciding how to respond to the user. For
example, UMs are useful for detecting user misconcep-
tions (McCoy 1983, 1985) and deciding which concepts
need to be explained to the user (Chin 1986). Sometimes
these differences lead to the confusion that the data
stored in UMs and DMs must be different, since their
applications are so different.
Another difference between UMs and DMs is in how
they are built up. Although both DMs and UMs are built
up from propositions expressed in the conversation, the
DM expires at the end of the discourse, while parts of
the UM are kept for future use. Grosz and Sidner (1986)
discuss how DMs are built up, and Chin (1986), Litman
and Allen (1984), Carberry (1983), and Allen and Per-
rault (1980), among others, discuss this process for
different aspects of UMs.
In summary, the DM and UM are not separate, but
rather share common parts. Shared parts include the
intentional structure of the discourse and the attentional
structure of the discourse. In addition, the DM contains
the linguistic structure of the discourse, which is not
present in the UM. Likewise, the UM contains many
items that are not present in the DM. These include
facts about the user which were learned in previous
dialogs and uncertain facts that were inferred from
stereotypes to which the user belongs.
</bodyText>
<sectionHeader confidence="0.99875" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.9887775">
Allen, J.F. and Perrault C.R. 1980 Analyzing Intention in Utterances.
In Artificial Intelligence 15:143-178.
Carberry, S. 1983 Tracking User Goals in an Information-Seeking
Environment. In Proceedings of the 3rd National Conference on
Artificial Intelligence, Washington, DC: 59-63.
Chin, D.N. 1986 User Modeling in UC, the UNIX Consultant. In
Proceedings of the Conference on Human Factors in Computing
Systems, Boston, MA:24-28.
Grosz, B. and Sidner C. 1986 Attention, Intentions, and the Structure
of Discourse. In Computational Linguistics 12: 175-204.
Litman, D.J. and Allen J.F. 1984 A Plan Recognition Model for
Clarification Sub-dialogues. In Proceedings of the 10th Interna-
tional Conference on Computational Linguistics and 22nd Annual
Meeting of the Association for Computational Linguistics, Stan-
ford University, Stanford, CA: 302-311.
McCoy, K.F. 1983 Correcting Misconceptions: What to Say When the
User is Mistaken. In Proceedings of the Conference on Human
Factors in Computing Systems, Boston, MA:197-201.
McCoy, K.F. 1985 Correcting Object-Related Misconceptions. Ph.D.
thesis, MS-CIS-85-57, Department of Computer and Information
Science, University of Pennsylvania, Philadelphia, PA.
McKeown, K.R.; Wish, M.; and Matthews, K. 1985 Tailoring Expla-
nations for the User. In Proceedings of the 9th International Joint
Conference on Artificial Intelligence, Los Angeles, CA:794-798.
Wahlster, W. and Kobsa A. 1988 User Models in Dialog Systems. In
Kobsa A. and Wahlster W. (eds.), User Models in Dialog Systems,
Springer-Verlag, Berlin—New York.
Computational Linguistics, Volume 14, Number 3, September 1988 87
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.087021">
<title confidence="0.567482">USER MODELS AND DISCOURSE MODELS</title>
<affiliation confidence="0.9928635">Department of Information and Computer University of Hawaii at</affiliation>
<address confidence="0.947366">2565 The Honolulu, HI 96822</address>
<abstract confidence="0.981697657534247">A user model (UM) contains information about users, such as users&apos; goals, beliefs, knowledge, preferences, and capabilities. A discourse model (DM) contains information about the conversation, such as the linguistic structure, the attentional state, and the intentional structure [Grosz and Sidner 1986). Given these definitions, I will argue that the UM intersects the DM. That is, the UM contains items that are missing from the UM; the DM contains items that are missing from the DM; and the two share some items. First, Schuster (1987) argues convincingly that the UM contains items that are missing from the DM. This is especially evident in cases where the speaker and listener have a long association, and hence the speaker has a large amount of prior knowledge about the listener which is stored in the speaker&apos;s UM of the listener. However, this information is not present in the DM, which starts off empty. Next, the DM contains items that are missing from the UM. To support this argument, I will cite an example given by Wahlster. Suppose the speaker mentions a long list of names that is not familiar to the listener. Then the speaker knows that the listener cannot know nameX, which is a particular name in the middle of the list. This is represented in the speaker&apos;s UM of the listener. However, nameX is in the linguistic structure of the speaker&apos;s DM since nameX was part of the discourse. Thus part of the linguistic structure of the DM is not represented in the UM. Actually, Wahlster interprets his example as an argument that the DM and the UM must be different. He argues that since nameX is in the DM, then the UM must be different, or else the speaker could not represent the fact that the user does not know nameX. This argument misses a crucial point. Although it is true that the names are listed in the linguistic structure of the DM, these names are not present in the attentional structure of the DM. Since the attentional structure of the DM is that part of the DM which represents objects, properties, and relations with which the user is familiar, this is the proper part of the DM to compare with the UM. To show that these names are not in the attentional structure of the DM, consider whether it is possible to use a pronoun to refer to nameX. If all of the other names were male, and nameX were female, then the speaker should be able to use the pronoun &amp;quot;she&amp;quot; in place of nameX. However, human speakers generally would not use such a pronoun. So there is no disagreement between the attentional structure of the speaker&apos;s DM and the speaker&apos;s UM of the listener. Not only is there no disagreement between the attentional structure of the DM and the UM, but I would like to argue that the items in the attentional structure of the DM are part of the UM. Take the related example of when the speaker introduces a person&apos;s name, nameX, unknown to the listener. In this case, the DM model represents the fact that nameX is the name of a person and that nameX refers to some person. Later, the speaker can use either nameX to refer to this person, or a pronoun. Likewise in the UM, the speaker represents the fact that the listener knows nameX refers to some unknown person, and represents the fact that the listener does not know the person referred to by nameX. In this example, the contents of the attentional structure of the DM is a subset of the UM. Another part of the DM that intersects with the UM is the intentional structure of the DM. The intentional structure is made up of the immediate goals of the user as expressed in the user&apos;s utterances plus some higher level goals. These are also present by definition in the UM. Another compelling argument for the view that the DM intersects the UM is the phenomenon of multispeaker discourses. In multispeaker discourses, each speaker needs to keep not only a separate UM for each listener, but also a separate DM for each participant. For example, consider the following dialog among three people debugging a circuit board. by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided the copies are not made for direct commercial advantage and the and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. /01000-0403.00 Linguistics, Volume 14, Number 3, September 1988 David N. Chin User Models and Discourse Models Tom: The 777 timer is really heating up. Dick: Let&apos;s check it. Tom (whose hands are full): OK. Dick, could you check the frequency at the output pin. Harry, could you check the voltage at the power pin here. (Tom points to the power pin.) Tom and Dick are experts, while Harry knows little about hardware. Tom knows this, so Tom has a separate DM for Dick and Harry. In Tom&apos;s DM for Dick, Dick&apos;s attentional state includes the 777 timer in his focus space. However, since Tom knows that Harry cannot identify a 777 timer, the timer is not in Tom&apos;s DM for Harry. So, when Tom tells Dick to check the frequency at the output pin, Tom knows that Dick will understand this referent. On the other hand, Harry would not know the referent of the power pin, so Tom points this out to Harry. If there were only a single DM for the entire conversation, then Tom would not be able to represent the different attentional states of Dick and Harry. This argues for the view that DMs are user dependent and hence are subparts of UMs. In some sense, the above scenario is somewhat aberrant in that usually speakers assume that their listeners share the same attentional state. So it may be more efficient to only represent the separate attentional states of different listeners as differences from the norm. Thus in most cases, the list of differences would be very small and the efficiency would be effectively the same as having only one DM. Although the DM and UM share some data, they are used for fairly different purposes. DMs are used in the generation and understanding of references such as noun phrases and pronouns. DMs are also used in the generation and understanding of connectives such as cue words and phrases. On the other hand, UMs mainly used in deciding how to respond to the user. For example, UMs are useful for detecting user misconceptions (McCoy 1983, 1985) and deciding which concepts need to be explained to the user (Chin 1986). Sometimes these differences lead to the confusion that the data stored in UMs and DMs must be different, since their applications are so different. Another difference between UMs and DMs is in how they are built up. Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use. Grosz and Sidner (1986) discuss how DMs are built up, and Chin (1986), Litman and Allen (1984), Carberry (1983), and Allen and Perrault (1980), among others, discuss this process for different aspects of UMs. In summary, the DM and UM are not separate, but rather share common parts. Shared parts include the intentional structure of the discourse and the attentional structure of the discourse. In addition, the DM contains the linguistic structure of the discourse, which is not present in the UM. Likewise, the UM contains many items that are not present in the DM. These include facts about the user which were learned in previous dialogs and uncertain facts that were inferred from stereotypes to which the user belongs.</abstract>
<note confidence="0.963789931034483">REFERENCES Allen, J.F. and Perrault C.R. 1980 Analyzing Intention in Utterances. Intelligence Carberry, S. 1983 Tracking User Goals in an Information-Seeking In of the 3rd National Conference on Intelligence, DC: 59-63. Chin, D.N. 1986 User Modeling in UC, the UNIX Consultant. In Proceedings of the Conference on Human Factors in Computing MA:24-28. Grosz, B. and Sidner C. 1986 Attention, Intentions, and the Structure Discourse. In Linguistics 175-204. Litman, D.J. and Allen J.F. 1984 A Plan Recognition Model for Sub-dialogues. In of the 10th Interna- Conference on Computational Linguistics Annual of the Association for Computational Linguistics, Stanford University, Stanford, CA: 302-311. McCoy, K.F. 1983 Correcting Misconceptions: What to Say When the is Mistaken. In of the Conference on Human in Computing Systems, MA:197-201. McCoy, K.F. 1985 Correcting Object-Related Misconceptions. Ph.D. thesis, MS-CIS-85-57, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA. McKeown, K.R.; Wish, M.; and Matthews, K. 1985 Tailoring Explafor the User. In of the 9th International Joint on Artificial Intelligence, Angeles, CA:794-798. Wahlster, W. and Kobsa A. 1988 User Models in Dialog Systems. In A. and Wahlster W. (eds.), Models in Dialog Systems, Springer-Verlag, Berlin—New York. Computational Linguistics, Volume 14, Number 3, September 1988 87</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J F Allen</author>
<author>C R Perrault</author>
</authors>
<title>Analyzing Intention in Utterances.</title>
<date>1980</date>
<journal>In Artificial Intelligence</journal>
<pages>15--143</pages>
<marker>Allen, Perrault, 1980</marker>
<rawString>Allen, J.F. and Perrault C.R. 1980 Analyzing Intention in Utterances. In Artificial Intelligence 15:143-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
</authors>
<title>Tracking User Goals in an Information-Seeking Environment.</title>
<date>1983</date>
<booktitle>In Proceedings of the 3rd National Conference on Artificial Intelligence,</booktitle>
<pages>59--63</pages>
<location>Washington, DC:</location>
<contexts>
<context position="7126" citStr="Carberry (1983)" startWordPosition="1256" endWordPosition="1257"> misconceptions (McCoy 1983, 1985) and deciding which concepts need to be explained to the user (Chin 1986). Sometimes these differences lead to the confusion that the data stored in UMs and DMs must be different, since their applications are so different. Another difference between UMs and DMs is in how they are built up. Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use. Grosz and Sidner (1986) discuss how DMs are built up, and Chin (1986), Litman and Allen (1984), Carberry (1983), and Allen and Perrault (1980), among others, discuss this process for different aspects of UMs. In summary, the DM and UM are not separate, but rather share common parts. Shared parts include the intentional structure of the discourse and the attentional structure of the discourse. In addition, the DM contains the linguistic structure of the discourse, which is not present in the UM. Likewise, the UM contains many items that are not present in the DM. These include facts about the user which were learned in previous dialogs and uncertain facts that were inferred from stereotypes to which the</context>
</contexts>
<marker>Carberry, 1983</marker>
<rawString>Carberry, S. 1983 Tracking User Goals in an Information-Seeking Environment. In Proceedings of the 3rd National Conference on Artificial Intelligence, Washington, DC: 59-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D N Chin</author>
</authors>
<title>User Modeling in UC, the UNIX Consultant.</title>
<date>1986</date>
<booktitle>In Proceedings of the Conference on Human Factors in Computing Systems,</booktitle>
<pages>24--28</pages>
<location>Boston,</location>
<contexts>
<context position="6618" citStr="Chin 1986" startWordPosition="1167" endWordPosition="1168">rences would be very small and the efficiency would be effectively the same as having only one DM. Although the DM and UM share some data, they are used for fairly different purposes. DMs are used in the generation and understanding of references such as noun phrases and pronouns. DMs are also used in the generation and understanding of connectives such as cue words and phrases. On the other hand, UMs mainly used in deciding how to respond to the user. For example, UMs are useful for detecting user misconceptions (McCoy 1983, 1985) and deciding which concepts need to be explained to the user (Chin 1986). Sometimes these differences lead to the confusion that the data stored in UMs and DMs must be different, since their applications are so different. Another difference between UMs and DMs is in how they are built up. Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use. Grosz and Sidner (1986) discuss how DMs are built up, and Chin (1986), Litman and Allen (1984), Carberry (1983), and Allen and Perrault (1980), among others, discuss this process for different aspects of</context>
</contexts>
<marker>Chin, 1986</marker>
<rawString>Chin, D.N. 1986 User Modeling in UC, the UNIX Consultant. In Proceedings of the Conference on Human Factors in Computing Systems, Boston, MA:24-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention, Intentions, and the Structure of Discourse.</title>
<date>1986</date>
<journal>In Computational Linguistics</journal>
<volume>12</volume>
<pages>175--204</pages>
<contexts>
<context position="7038" citStr="Grosz and Sidner (1986)" startWordPosition="1239" endWordPosition="1242">inly used in deciding how to respond to the user. For example, UMs are useful for detecting user misconceptions (McCoy 1983, 1985) and deciding which concepts need to be explained to the user (Chin 1986). Sometimes these differences lead to the confusion that the data stored in UMs and DMs must be different, since their applications are so different. Another difference between UMs and DMs is in how they are built up. Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use. Grosz and Sidner (1986) discuss how DMs are built up, and Chin (1986), Litman and Allen (1984), Carberry (1983), and Allen and Perrault (1980), among others, discuss this process for different aspects of UMs. In summary, the DM and UM are not separate, but rather share common parts. Shared parts include the intentional structure of the discourse and the attentional structure of the discourse. In addition, the DM contains the linguistic structure of the discourse, which is not present in the UM. Likewise, the UM contains many items that are not present in the DM. These include facts about the user which were learned </context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, B. and Sidner C. 1986 Attention, Intentions, and the Structure of Discourse. In Computational Linguistics 12: 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Litman</author>
<author>J F Allen</author>
</authors>
<title>A Plan Recognition Model for Clarification Sub-dialogues.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>302--311</pages>
<location>Stanford University, Stanford, CA:</location>
<contexts>
<context position="7109" citStr="Litman and Allen (1984)" startWordPosition="1252" endWordPosition="1255">useful for detecting user misconceptions (McCoy 1983, 1985) and deciding which concepts need to be explained to the user (Chin 1986). Sometimes these differences lead to the confusion that the data stored in UMs and DMs must be different, since their applications are so different. Another difference between UMs and DMs is in how they are built up. Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use. Grosz and Sidner (1986) discuss how DMs are built up, and Chin (1986), Litman and Allen (1984), Carberry (1983), and Allen and Perrault (1980), among others, discuss this process for different aspects of UMs. In summary, the DM and UM are not separate, but rather share common parts. Shared parts include the intentional structure of the discourse and the attentional structure of the discourse. In addition, the DM contains the linguistic structure of the discourse, which is not present in the UM. Likewise, the UM contains many items that are not present in the DM. These include facts about the user which were learned in previous dialogs and uncertain facts that were inferred from stereot</context>
</contexts>
<marker>Litman, Allen, 1984</marker>
<rawString>Litman, D.J. and Allen J.F. 1984 A Plan Recognition Model for Clarification Sub-dialogues. In Proceedings of the 10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics, Stanford University, Stanford, CA: 302-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K F McCoy</author>
</authors>
<title>Correcting Misconceptions: What to Say When the User is Mistaken.</title>
<date>1983</date>
<booktitle>In Proceedings of the Conference on Human Factors in Computing Systems,</booktitle>
<pages>197--201</pages>
<location>Boston,</location>
<contexts>
<context position="6538" citStr="McCoy 1983" startWordPosition="1153" endWordPosition="1154">nt listeners as differences from the norm. Thus in most cases, the list of differences would be very small and the efficiency would be effectively the same as having only one DM. Although the DM and UM share some data, they are used for fairly different purposes. DMs are used in the generation and understanding of references such as noun phrases and pronouns. DMs are also used in the generation and understanding of connectives such as cue words and phrases. On the other hand, UMs mainly used in deciding how to respond to the user. For example, UMs are useful for detecting user misconceptions (McCoy 1983, 1985) and deciding which concepts need to be explained to the user (Chin 1986). Sometimes these differences lead to the confusion that the data stored in UMs and DMs must be different, since their applications are so different. Another difference between UMs and DMs is in how they are built up. Although both DMs and UMs are built up from propositions expressed in the conversation, the DM expires at the end of the discourse, while parts of the UM are kept for future use. Grosz and Sidner (1986) discuss how DMs are built up, and Chin (1986), Litman and Allen (1984), Carberry (1983), and Allen </context>
</contexts>
<marker>McCoy, 1983</marker>
<rawString>McCoy, K.F. 1983 Correcting Misconceptions: What to Say When the User is Mistaken. In Proceedings of the Conference on Human Factors in Computing Systems, Boston, MA:197-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K F McCoy</author>
</authors>
<title>Correcting Object-Related Misconceptions.</title>
<date>1985</date>
<tech>Ph.D. thesis, MS-CIS-85-57,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<marker>McCoy, 1985</marker>
<rawString>McCoy, K.F. 1985 Correcting Object-Related Misconceptions. Ph.D. thesis, MS-CIS-85-57, Department of Computer and Information Science, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K R McKeown</author>
<author>M Wish</author>
<author>K Matthews</author>
</authors>
<title>Tailoring Explanations for the User.</title>
<date>1985</date>
<booktitle>In Proceedings of the 9th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>794--798</pages>
<location>Los Angeles,</location>
<marker>McKeown, Wish, Matthews, 1985</marker>
<rawString>McKeown, K.R.; Wish, M.; and Matthews, K. 1985 Tailoring Explanations for the User. In Proceedings of the 9th International Joint Conference on Artificial Intelligence, Los Angeles, CA:794-798.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>A Kobsa</author>
</authors>
<title>User Models in Dialog Systems.</title>
<date>1988</date>
<booktitle>In Kobsa A. and Wahlster W. (eds.), User Models in Dialog Systems,</booktitle>
<publisher>Springer-Verlag,</publisher>
<location>Berlin—New York.</location>
<marker>Wahlster, Kobsa, 1988</marker>
<rawString>Wahlster, W. and Kobsa A. 1988 User Models in Dialog Systems. In Kobsa A. and Wahlster W. (eds.), User Models in Dialog Systems, Springer-Verlag, Berlin—New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Computational Linguistics</author>
</authors>
<date>1988</date>
<volume>14</volume>
<pages>87</pages>
<marker>Linguistics, 1988</marker>
<rawString>Computational Linguistics, Volume 14, Number 3, September 1988 87</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>