<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.046611">
<title confidence="0.975058">
Translationese and Its Dialects
</title>
<author confidence="0.998349">
Moshe Koppel Noam Ordan
</author>
<affiliation confidence="0.998223">
Department of Computer Science Department of Computer Science
Bar Ilan University University of Haifa
</affiliation>
<address confidence="0.896287">
Ramat-Gan, Israel 52900 Haifa, Israel 31905
</address>
<email confidence="0.999385">
moishk@gmail.com noam.ordan@gmail.com
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999969173913044">
While it is has often been observed that the
product of translation is somehow different
than non-translated text, scholars have empha-
sized two distinct bases for such differences.
Some have noted interference from the source
language spilling over into translation in a
source-language-specific way, while others
have noted general effects of the process of
translation that are independent of source lan-
guage. Using a series of text categorization
experiments, we show that both these effects
exist and that, moreover, there is a continuum
between them. There are many effects of
translation that are consistent among texts
translated from a given source language, some
of which are consistent even among texts
translated from families of source languages.
Significantly, we find that even for widely
unrelated source languages and multiple ge-
nres, differences between translated texts and
non-translated texts are sufficient for a learned
classifier to accurately determine if a given
text is translated or original.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999528333333333">
The products of translation (written or oral) are
generally assumed to be ontologically different
from non-translated texts. Researchers have em-
phasized two aspects of this difference. Some
(Baker 1993) have emphasized general effects of
the process of translation that are independent of
source language and regard the collective product
of this process in a given target language as an `in-
terlanguage&apos; (Selinker, 1972), `third code&apos; (Fraw-
ley, 1984) or `translationese&apos; (Gellerstam, 1986).
Others (Toury, 1995) have emphasized the effects
of interference, the process by which a specific
source language leaves distinct marks or finger-
prints in the target language, so that translations
from different source languages into the same tar-
get language may be regarded as distinct dialects
of translationese.
We wish to use text categorization methods to
set both of these claims on a firm empirical foun-
dation. We will begin by bringing evidence for two
claims:
</bodyText>
<listItem confidence="0.9907518">
(1) Translations from different source languages
into the same target language are sufficiently dif-
ferent from each other for a learned classifier to
accurately identify the source language of a given
translated text;
(2) Translations from a mix of source languages
are sufficiently distinct from texts originally writ-
ten in the target language for a learned classifier to
accurately determine if a given text is translated or
original.
</listItem>
<bodyText confidence="0.9996006">
Each of these claims has been made before, but
our results will strengthen them in a number of
ways. Furthermore, we will show that the degree of
difference between translations from two source
languages reflects the degree of difference between
the source languages themselves. Translations
from cognate languages differ from non-translated
texts in similar ways, while translations from unre-
lated languages differ from non-translated texts in
distinct ways. The same result holds for families of
languages.
The outline of the paper is as follows. In the fol-
lowing section, we show that translations from dif-
ferent source languages can be distinguished from
each other and that closely related source languag-
es manifest similar forms of interference. In sec-
tion 3, we show that, in a corpus involving five
European languages, we can distinguish translatio-
nese from non-translated text and we consider
some salient markers of translationese. In section
</bodyText>
<page confidence="0.940803">
1318
</page>
<note confidence="0.9790815">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1318–1326,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9998532">
4, we consider the extent to which markers of
translationese cross over into non-European lan-
guages as well as into different genres. Finally, we
consider possible applications and implications for
future studies.
</bodyText>
<sectionHeader confidence="0.978674" genericHeader="method">
2 Interference Effects in Translationese
</sectionHeader>
<bodyText confidence="0.999925">
In this section, we perform several text categoriza-
tion experiments designed to show the extent to
which interference affects (both positively and ne-
gatively) our ability to classify documents.
</bodyText>
<subsectionHeader confidence="0.945831">
2.1 The Europarl Corpus
</subsectionHeader>
<bodyText confidence="0.999879170731708">
The main corpus we will use throughout this paper
is Europarl (Koehn, 2005), which consists of tran-
scripts of addresses given in the European Parlia-
ment. The full corpus consists of texts translated
into English from 11 different languages (and vice
versa), as well as texts originally produced in Eng-
lish. For our purposes, it will be sufficient to use
translations from five languages (Finnish, French,
German, Italian and Spanish), as well as original
English. We note that this corpus constitutes a
comparable corpus (Laviosa, 1997), since it con-
tains (1) texts written originally in a certain lan-
guage (English), as well as (2) texts translated into
that same language, matched for genre, domain,
publication timeframe, etc. Each of the five trans-
lated components is a text file containing just un-
der 500,000 words; the original English component
is a file of the same size as the aggregate of the
other five.
The five source languages we use were selected
by first eliminating several source languages for
which the available text was limited and then
choosing from among the remaining languages,
those of varying degrees of pairwise similarity.
Thus, we select three cognate (Romance) languag-
es (French, Italian and Spanish), a fourth less re-
lated language (German), and a fifth even further
removed (Finnish). As will become clear, the mo-
tivation is to see whether the distance between the
languages impacts the distinctiveness of the trans-
lation product.
We divide each of the translated corpora into
250 equal chunks, paying no attention to natural
units within the corpus. Similarly, we divide the
original English corpus into 1250 equal chunks.
We set aside 50 chunks from each of the translated
corpora and 250 chunks from the original English
corpus for development purposes (as will be ex-
plained below). The experiments described below
use the remaining 1000 translated chunks and 1000
original English chunks.
</bodyText>
<subsectionHeader confidence="0.998354">
2.2 Identifying source language
</subsectionHeader>
<bodyText confidence="0.993756">
Our objective in this section is to measure the ex-
tent to which translations are affected by source
language. Our first experiment will be to use text
categorization methods to learn a classifier that
categorizes translations according to source lan-
guage. We will check the accuracy of such clas-
sifiers on out-of-sample texts. High accuracy
would reflect that there are exploitable differences
among translations of otherwise comparable texts
that differ only in terms of source language.
The details of the experiment are as follows. We
use the 200 chunks from each translated corpus, as
described above. We use as our feature set a list of
300 function words taken from LIWC (Pennebak-
er, 2001) and represent each chunk as a vector of
size 300 in which each entry represents the fre-
quency of the corresponding feature in the chunk.
The restriction to function words is crucial; we
wish to rely only on stylistic differences rather than
content differences that might be artifacts of the
corpus.
We use Bayesian logistic regression (Madigan,
2005) as our learning method in order to learn a
classifier that classifies a given text into one of five
classes representing the different source languages.
We use 10-fold cross-validation as our testing me-
thod.
We find that 92.7% of documents are correctly
classified.
In Table 1 we show the confusion matrix for the
five languages. As can be seen, there are more mis-
takes across the three cognate languages than be-
tween those three languages and German and still
fewer mistakes involving the more distant Finnish
language.
It Fr Es De Fi
It 169 19 8 4 0
Fr 18 161 12 8 1
Es 3 11 172 11 3
De 4 12 3 178 3
Fi 0 1 2 5 192
</bodyText>
<tableCaption confidence="0.972941">
Table 1: Confusion matrix for 10-fold cross validation
experiment to determine source language of texts trans-
lated into English
</tableCaption>
<page confidence="0.997254">
1319
</page>
<bodyText confidence="0.999896555555555">
This result strengthens that of van Halteren
(2008) in a similar experiment. Van Halteren, also
using Europarl (but with Dutch as the fifth source
language, rather than Finnish), obtained accuracy
of 87.2%-96.7% for a two-way decision on source
language, and 81.5%-87.4% for a six-way decision
(including the original which has no source lan-
guage). Significantly, though, van Halteren&apos;s fea-
ture set included content words and he notes that
many of the most salient differences reflected dif-
ferences in thematic emphasis. By restricting our
feature set to function words, we neutralize such
effects.
In Table 2, we show the two words most over-
represented and the two words most under-
represented in translations from each source lan-
guage (ranked according to an unpaired T-test).
For each of these, the difference between frequen-
cy of use in the indicated language and frequency
of use in the other languages in aggregate is signif-
icant at p&lt;0.01.
over-represented under-represented
Fr of, finally here, also
It upon, moreover also, here
Es with, therefore too, then
De here, then of, moreover
Fi be, example me, which
</bodyText>
<tableCaption confidence="0.8761125">
Table 2: Most salient markers of translations from each
source language.
</tableCaption>
<bodyText confidence="0.999985916666667">
The two most underrepresented words for
French and Italian, respectively, are in fact identic-
al. Furthermore, the word too which is underrepre-
sented for Spanish is a near synonym of also which
appears in both French and Spanish. This suggests
the possibility that interference effects in cognate
languages such as French, Italian and Spanish
might be similar. We will see presently that this is
in fact the case.
When a less related language is involved we see
the opposite picture. For German, both underrepre-
sented items appear as overrepresented in the
Romance languages, and, conversely, underrepre-
sented items in the Romance languages appear as
overrepresented items for German. This may cast
doubt on the idea that all translations share univer-
sal properties and that at best we may claim that
particular properties are shared by closely related
languages but not others. In the experiments pre-
sented in the next subsection, we&apos;ll find that trans-
lationese is gradable: closely related languages
share more features, yet even further removed lan-
guages share enough properties to hold the general
translationese hypothesis as valid.
</bodyText>
<subsectionHeader confidence="0.8198835">
2.3 Identifying translationese per source lan-
guage
</subsectionHeader>
<bodyText confidence="0.999986048780488">
We now wish to measure in a subtler manner the
extent to which interference affects translation. In
this experiment, the challenge is to learn a classifi-
er that classifies a text as belonging to one of only
two classes: original English (O) or translated-into-
English (T). The catch is that all our training texts
for the class T will be translations from some fixed
source language, while all our test documents in T
will be translations from a different source lan-
guage. What accuracy can be achieved in such an
experiment? The answer to this question will tell
us a great deal about how much of translationese is
general and how much of it is language dependent.
If accuracy is close to 100%, translationese is pure-
ly general (Baker, 1993). (We already know from
the previous experiment that that&apos;s not the case.). If
accuracy is near 50%, there are no general effects,
just language-dependent ones. Note that, whereas
in our first experiment above pair-specific interfe-
rence facilitated good classification, in this expe-
riment pair-specific interference is an impediment
to good classification.
The details of the experiment are as follows. We
create, for example, a “French” corpus consisting
of the 200 chunks of text translated from French
and 200 original English texts. We similarly create
a corpus for each of the other source languages,
taking care that each of the 1000 original English
texts appears in exactly one of the corpora. As
above, we represent each chunk in terms of fre-
quencies of function words. Now, using Bayesian
logistic regression, we learn a classifier that distin-
guishes T from O in the French corpus. We then
apply this learned classifier to the texts in, for ex-
ample, the equivalent “Italian” corpus to see if we
can classify them as translated or original. We re-
peat this for each of the 25 train_corpus,
test_corpus pairs.
In Table 3, we show the accuracy obtained for
each such pair. (For the case where the training
corpus and testing corpus are identical – the di-
</bodyText>
<page confidence="0.941433">
1320
</page>
<bodyText confidence="0.999983155555556">
agonal of the matrix – we show results for ten-fold
cross-validation.)
We note several interesting facts. First, results of
cross-validation within each corpus are very
strong. For any given source language, it is quite
easy to distinguish translations from original Eng-
lish. This corroborates results obtained by Baroni
and Bernardini (2006), Ilisei et al. (2010), Kuro-
kawa et al. (2009) and van Halteren (2008), which
we will discuss below.
We note further, that for the cases where we
train on one source language and test on another,
results are far worse. This clearly indicates that
interference effects from one source language
might be misleading when used to identify transla-
tions from a different language. Thus, for example,
in the Finnish corpus, the word me is a strong indi-
cator of original English (constituting 0.0003 of
tokens in texts translated from Finnish as opposed
to 0.0015 of tokens in original English texts), but
in the German corpus, me is an indicator of trans-
lated text (constituting 0.0020 of tokens in text
translated from German).
The most interesting result that can be seen in
this table is that the accuracy obtained when train-
ing using language x and testing using language y
depends precisely on the degree of similarity be-
tween x and y. Thus, for training and testing within
the three cognate languages, results are fairly
strong, ranging between 84.5% and 91.5%. For
training/testing on German and testing/training on
one of the other European languages, results are
worse, ranging from 68.5% to 83.3%. Finally, for
training/testing on Finnish and testing/training on
any of the European languages, results are still
worse, hovering near 60% (with the single unex-
plained outlier for training on German and testing
on Finnish).
Finally, we note that even in the case of training
or testing on Finnish, results are considerably bet-
ter than random, suggesting that despite the con-
founding effects of interference, some general
properties of translationese are being picked up in
each case. We explore these in the following sec-
tion.
</bodyText>
<sectionHeader confidence="0.998776" genericHeader="method">
3 General Properties of Translationese
</sectionHeader>
<bodyText confidence="0.9766015">
Having established that there are source-language-
dependent effects on translations, let‟s now con-
</bodyText>
<table confidence="0.976338142857143">
Train
It Fr Es De Fi
It 98.3 91.5 86.5 71.3 61.5
Fr 91 97 86.5 68.5 60.8
Es 84.5 88.3 95.8 76.3 59.5
De 82 83.3 78.5 95 80.8
Fi 56 60.3 56 62.3 97.3
</table>
<tableCaption confidence="0.98453">
Table 3: Results of learning a T vs. O classifier us-
ing one source language and testing it using another
source language
</tableCaption>
<bodyText confidence="0.9207545">
sider source-language-independent effects on
translation.
</bodyText>
<subsectionHeader confidence="0.99904">
3.1 Identifying translationese
</subsectionHeader>
<bodyText confidence="0.999970717948718">
In order to identify general effects on translation,
we now consider the same two-class classification
problem as above, distinguishing T from O, except
that now the translated texts in both our train and
test data will be drawn from multiple source lan-
guages. If we succeed at this task, it must be be-
cause of features of translationese that cross
source-languages.
The details of our experiment are as follows. We
use as our translated corpus, the 1000 translated
chunks (200 from each of five source languages)
and as our original English corpus all 1000 original
English chunks. As above, we represent each
chunk in terms of function words frequencies. We
use Bayesian logistic regression to learn a two-
class classifier and test its accuracy using ten-fold
cross-validation.
Remarkably, we obtain accuracy of 96.7%.
This result extends and strengthens results re-
ported in some earlier studies. Ilisei et al. (2010),
Kurokawa (2009) and van Halteren (2008) each
obtained above 90% accuracy in distinguishing
translation from original. However, in each case
the translations were from a single source lan-
guage. (Van Halteren considered multiple source
languages, but each learned classifier used only
one of them.) Thus, those results do not prove that
translationese has distinctive source-language-
independent features. To our knowledge, the only
earlier work that used a learned classifier to identi-
fy translations in which both test and train sets in-
volved multiple source languages is Baroni and
Bernardini (2006), in which the target language
was Italian and the source languages were known
to be varied. The actual distribution of source lan-
guages was, however, not known to the research-
ers. They obtained accuracy of 86.7%. Their result
was obtained using combinations of lexical and
syntactic features.
</bodyText>
<page confidence="0.960519">
1321
</page>
<subsectionHeader confidence="0.998248">
3.2 Some distinguishing features
</subsectionHeader>
<bodyText confidence="0.99940925">
Let us now consider some of the most salient func-
tion words for which frequency of usage in T dif-
fers significantly from that in O. While there are
many such features, we focus on two categories of
words that are most prominent among those with
the most significant differences.
First, we consider animate pronouns. In Table 4,
we show the frequencies of animate pronouns in O
and T, respectively (the possessive pronouns, mine,
yours and hers, not shown, are extremely rare in
the corpus). As can be seen, all pronouns are un-
der-represented in T; for most (bolded), the differ-
ence is significant at p&lt;0.01.
By contrast, the word the is significantly overre-
presented in T (15.32% in T vs. 13.73% in O; sig-
nificant at p&lt;0.01).
</bodyText>
<table confidence="0.756945928571429">
word freq O freq T
I 2.552% 2.148%
we 2.713% 2.344%
you 0.479% 0.470%
he 0.286% 0.115%
she 0.081% 0.039%
me 0.148% 0.141%
us 0.415% 0.320%
him 0.066% 0.033%
her 0.091% 0.056%
my 0.462% 0.345%
our 0.696% 0.632%
your 0.119% 0.109%
his 0.218% 0.123%
</table>
<tableCaption confidence="0.988675">
Table 4: Frequency of pronouns in O and T in the Eu-
roparl corpus. Bold indicates significance at p&lt;0.01.
</tableCaption>
<bodyText confidence="0.99966725">
In Table 5, we consider cohesive markers,
tagged as adverbs (Schmid, 2004). (These are ad-
verbs that can appear at the beginning of a sen-
tence followed immediately by a comma.)
</bodyText>
<table confidence="0.977064153846154">
word freq O freq T
therefore 0.153% 0.287%
thus 0.015% 0.041%
consequently 0.006% 0.014%
hence 0.007% 0.013%
accordingly 0.006% 0.011%
however 0.216% 0.241%
nevertheless 0.019% 0.045%
also 0.460% 0.657%
furthermore 0.012% 0.048%
moreover 0.008% 0.036%
indeed 0.098% 0.053%
actually 0.065% 0.042%
</table>
<tableCaption confidence="0.987817">
Table 5: Frequency of cohesive adverbs in O and T in
the Europarl corpus. Bold indicates significance at
p&lt;0.01.
</tableCaption>
<bodyText confidence="0.999965615384616">
We note that the preponderance of such cohesive
markers are significantly more frequent in transla-
tions. In fact, we also find that a variety of phrases
that serve the same purpose as cohesive adverbs,
such as in fact and as a result are significantly
more frequent in translationese.
The general principle underlying these pheno-
mena is subject to speculation. Previous research-
ers have noted the phenomenon of explicitation,
according to which translators tend to render im-
plicit utterances in the source text into explicit ut-
terances in the target text (Blum-Kulka, 1986,
Laviosa-Braithwaite, 1998), for example by filling
out elliptical expressions or adding connectives to
increase cohesion of the text (Laviosa-Braithwaite,
1998). It is plausible that the use of cohesive ad-
verbs is an instantiation of this phenomenon.
With regard to the under-representation of pro-
nouns and the over-representation of the, there are
a number of possible interpretations. It may be that
this too is the result of explicitation, in which ana-
phora is resolved by replacing pronouns with noun
phrases (e.g., the man instead of he). But it also
might be that this is an example of simplification
(Laviosa- Braithwaite 1998, Laviosa 2002), ac-
cording to which the translator simplifies the mes-
sage, the language, or both. Related results
confirming the simplification hypothesis were
found by Ilisei et al. (2010) on Spanish texts. In
particular, they found that type-to-token ratio (lexi-
cal variety/richness), mean sentence length and
proportion of grammatical words (lexical densi-
ty/readability) are all smaller in translated texts.
We note that Van Halteren (2008) and Kurokawa
et al. (2009), who considered lexical features,
found cultural differences, like over-representation
of ladies and gentlemen in translated speeches.
Such differences, while of general interest, are or-
thogonal to our purposes in this paper.
</bodyText>
<page confidence="0.987494">
1322
</page>
<subsectionHeader confidence="0.999107">
3.3 Overriding language-specific effects
</subsectionHeader>
<bodyText confidence="0.999765033333333">
We found in Section 2.3 that when we trained in
one language and tested in another, classification
succeeded to the extent that the source languages
used in training and testing, respectively, are re-
lated to each other. In effect, general differences
between translationese and original English were
partially overwhelmed by language-specific differ-
ences that held for the training language but not the
test language. We thus now revisit that earlier ex-
periment, but restrict ourselves to features that dis-
tinguish translationese from original English
generally.
To do this, we use the small development corpus
described in Section 2.1. We use Bayesian logistic
regression to learn a classifier to distinguish be-
tween translationese and original English. We se-
lect the 10 highest-weighted function-word
markers for T and the 10 highest-weighted func-
tion-word markers for O in the development cor-
pus. We then rerun our train-on-source-language-x,
test-on-source-language-y experiment using this
restricted set as our feature set. We now find that
even in the difficult case where we train on Finnish
and test on another language (or vice versa), we
succeed at distinguishing translationese from orig-
inal English with accuracy above 80%. This consi-
derably improves the earlier results shown in Table
3. Thus, a bit of feature engineering facilitates
learning a good classifier for T vs. O even across
source languages.
</bodyText>
<sectionHeader confidence="0.76936" genericHeader="method">
4 Other Genres and Language Families
</sectionHeader>
<bodyText confidence="0.999903571428571">
We have found both general and language-specific
differences between translationese and original
English in one large corpus. It might be wondered
whether the phenomena we have found hold in
other genres and for a completely different set of
source languages. To test this, we consider a
second corpus.
</bodyText>
<subsectionHeader confidence="0.995928">
4.1 The IHT corpus
</subsectionHeader>
<bodyText confidence="0.999973775">
Our second corpus includes three translated corpo-
ra, each of which is an on-line local supplement to
the International Herald Tribune (IHT): Kathime-
rini (translated from Greek), Ha’aretz (translated
from Hebrew), and the JoongAng Daily (translated
from Korean). In addition, the corpus includes
original English articles from the IHT. Each of the
four components contains four different domains
balanced roughly equally: news (80,000 words),
arts and leisure (50,000), business and finance
(50,000), and opinion (50,000) and each covers the
period from April-September 2004. Each compo-
nent consists of about 230,000 tokens. (Unlike for
our Europarl corpus, the amount of English text
available is not equal to the aggregate of the trans-
lated corpora, but rather equal to each of the indi-
vidual corpora.)
It should be noted that the IHT corpus belongs
to the writing modality while the Europarl corpus
belongs to the speaking modality (although possi-
bly post-edited). Furthermore, the source languag-
es (Hebrew, Greek and Korean) in the IHT corpus
are more disparate than those in the Europarl cor-
pus.
Our first objective is to confirm that the results
we obtained earlier on the Europarl corpus hold for
the IHT corpus as well.
Perhaps more interestingly, our second objective
is to see if the gradability phenomenon observed
earlier (Table 3) generalizes to families of lan-
guages. Our first hypothesis is that a classifier for
identifying translationese that is trained on Euro-
parl will succeed only weakly to identify transla-
tionese in IHT. But our second hypothesis is that
there are sufficient general properties of translatio-
nese that cross language families and genres that a
learned classifier can accurately identify transla-
tionese even on a test corpus that includes both
corpora, spanning eight disparate languages across
two distinct genres.
</bodyText>
<subsectionHeader confidence="0.970688">
4.2 Results on IHT corpus
</subsectionHeader>
<bodyText confidence="0.9999402">
Running essentially the same experiments as de-
scribed for the Europarl corpus, we obtain the fol-
lowing results.
First of all, we can determine source language
with accuracy of 86.5%. This is a somewhat weak-
er result than the 92.7% result obtained on Euro-
parl, especially considering that there are only
three classes instead of five. The difference is most
likely due to the fact that the IHT corpus is about
half the size of the Europarl corpus. Nevertheless,
it is clear that source language strongly affects
translationese in this corpus.
Second, as can be seen in Table 6, we find that
the gradability phenomenon occurs in this corpus
as well. Results are strongest when the train and
</bodyText>
<page confidence="0.956275">
1323
</page>
<bodyText confidence="0.99825275">
test corpora involve the same source language and
trials involving Korean, the most distant language,
are somewhat weaker than those across Greek and
Hebrew.
</bodyText>
<table confidence="0.924061">
Train
Gr He Ko
Gr 89.8 73.4 64.8
He 82.0 86.3 65.5
Ko 73.0 72.5 85.0
</table>
<tableCaption confidence="0.928263666666667">
Table 6: Results of learning a T vs. O classifier using
one source language and testing it using another source
language
</tableCaption>
<bodyText confidence="0.99984">
Third, we find in ten-fold cross-validation expe-
riments that we can distinguish translationese from
original English in the IHT corpus with accuracy
of 86.3%. Thus, despite the great distance between
the three source languages in this corpus, general
differences between translationese and original
English are sufficient to facilitate reasonably accu-
rate identification of translationese.
</bodyText>
<subsectionHeader confidence="0.999872">
4.3 Combining the corpora
</subsectionHeader>
<bodyText confidence="0.990997131147541">
First, we consider whether a classifier learned on
the Europarl corpus can be used to identify trans-
lationese in the IHT corpus, and vice versa. It
would be consistent with our findings in Section
2.3, that we would achieve better than random
results but not high accuracy, since there are no
doubt features common to translations from the
five European languages of Europarl that are dis-
tinct from those of translations from the very dif-
ferent languages in IHT.
In fact, we find that training on Europarl and
testing on IHT yields accuracy of 64.8%, while
training on IHT and testing on Europarl yields
accuracy of 58.8%. The weak results reflect both
differences between the families of source lan-
guages involved in the respective corpora, as well
as genre differences. Thus, for example, we find
that of the pronouns shown in Table 4 above, only
he and his are significantly under-represented in
translationese in the IHT corpus. Thus, that effect
is specific either to the genre of Europarl or to the
European languages considered there.
Now, we combine the two corpora and check if
we can identify translationese across two genres
and eight languages. We run the same experiments
as described above, using 200 texts from each of
the eight source languages and 1600 non-translated
English texts, 1000 from Europarl and 600 from
IHT.
In 10-fold cross-validation, we find that we can
distinguish translationese from non-translated Eng-
lish with accuracy of 90.5%.
This shows that there are features of translatio-
nese that cross genres and widely disparate lan-
guages. Thus, for one prominent example, we find
that, as in Europarl, the word the is over-
represented in translationese in IHT (15.36% in T
vs. 13.31% in O; significant at p&lt;0.01). In fact, the
frequencies across corpora are astonishingly con-
sistent.
To further appreciate this point, let‟s look at the
frequencies of cohesive adverbs in the IHT corpus.
We find essentially, the same pattern in IHT as
we did in Europarl. The preponderance of cohesive
adverbs are over-represented in translationese,
most of them with differences significant at
p&lt;0.01. Curiously, the word actually is a counter-
example in both corpora.
word freq O freq T
therefore 0.011% 0.031%
thus 0.011% 0.027%
consequently 0.000% 0.004%
hence 0.003% 0.007%
accordingly 0.003% 0.003%
however 0.078% 0.129%
nevertheless 0.008% 0.018%
also 0.305% 0.453%
furthermore 0.003% 0.011%
moreover 0.009% 0.008%
indeed 0.018% 0.024%
actually 0.032% 0.018%
</bodyText>
<tableCaption confidence="0.944819666666667">
Table 7: Frequency of cohesive adverbs in O and T
in the IHT corpus. Bold indicates significance at
p&lt;0.01.
</tableCaption>
<sectionHeader confidence="0.999192" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999745">
We have found that we can learn classifiers that
determine source language given a translated text,
as well as classifiers that distinguish translated text
from non-translated text in the source language.
These text categorization experiments suggest that
both source language and the mere fact of being
</bodyText>
<page confidence="0.983894">
1324
</page>
<bodyText confidence="0.999928115384616">
translated play a crucial role in the makeup of a
translated text.
It is important to note that our learned classifiers
are based solely on function words, so that, unlike
earlier studies, the differences we find are unlikely
to include cultural or thematic differences that
might be artifacts of corpus construction.
In addition, we find that the exploitability of dif-
ferences between translated texts and non-
translated texts are related to the difference be-
tween source languages: translations from similar
source languages are different from non-translated
texts in similar ways.
Linguists use a variety of methods to quantify
the extent of differences and similarities between
languages. For example, Fusco (1990) studies
translations between Spanish and Italian and con-
siders the impact of structural differences between
the two languages on translation quality. Studying
the differences and distance between languages by
comparing translations into the same language may
serve as another way to deepen our typological
knowledge. As we have seen, training on source
language x and testing on source language y pro-
vides us with a good estimation of the distance be-
tween languages, in accordance with what we find
in standard works on typology (cf. Katzner, 2002).
In addition to its intrinsic interest, the finding
that the distance between languages is directly cor-
related with our ability to distinguish translations
from a given source language from non-translated
text is of great importance for several computa-
tional tasks. First, translations can be studied in
order to shed new light on the differences between
languages and can bear on attested techniques for
using cognates to improve machine translation
(Kondrak &amp; Sherif, 2006). Additionally, given the
results of our experiments, it stands to reason that
using translated texts, especially from related
source languages, will prove beneficial for con-
structing language models and will outperform
results obtained from non-translated texts. This,
too, bears on the quality of machine translation.
Finally, we find that there are general properties
of translationese sufficiently strong that we can
identify translationese even in a combined corpus
that is comprised of eight very disparate languages
across two distinct genres, one spoken and the oth-
er written. Prominent among these properties is the
word the, as well as a number of cohesive adverbs,
each of which is significantly over-represented in
translated texts.
</bodyText>
<sectionHeader confidence="0.999191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999907717391304">
Mona Baker. 1993. Corpus linguistics and translation
studies: Implications and applications. In Gill Francis
Mona Baker and Elena Tognini Bonelli, editors, Text
and technology: in honour of John Sinclair, pages
233-252. John Benjamins, Amsterdam.
Marco Baroni and Silvia Bernardini. 2006. A new ap-
proach to the study of Translationese: Machine-
learning the difference between original and trans-
lated text. Literary and Linguistic Computing,
21(3):259-274.
Shoshan Blum-Kulka. Shifts of cohesion and coherence
in translation. 1986. In Juliane House and Shoshana
Blum-Kulka (Eds), Interlingual and Intercultural
Communication (17-35). Tübingen: Günter Narr Ver-
lag.
William Frawley. 1984. Prolegomenon to a theory of
translation. In William Frawley (ed), Translation. Li-
terary, Linguistic and Philosophical Perspectives
(179-175). Newark: University of Delaware Press.
Maria Antonietta Fusco. 1990. Quality in conference
interpreting between cognate languages: A prelimi-
nary approach to the Spanish-Italian case. The Inter-
preters’ Newsletter, 3, 93-97.
Martin Gellerstam. 1986. Translationese in Swedish
novels translated from English, in Lars Wollin &amp;
Hans Lindquist (eds.), Translation Studies in Scandi-
navia (88-95). Lund: CWK Gleerup.
Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor, and
Ruslan Mitkov. Identification of translationese: A
machine learning approach. In Alexander F. Gel-
bukh, editor, Proceedings of CICLing-2010: Compu-
tational Linguistics and Intelligent Text Processing,
11th International, volume 6008 of Lecture Notes in
Computer Science, pages 503-511. Springer, 2010.
Kenneth Katzner. 2002. The Languages of the World.
Routledge.
Grzegorz Kondrak and Tarek Sherif. 2006. Evaluation
of several phonetic similarity algorithms on the task
of cognate identification. In Proceedings of the
Workshop on Linguistic Distances (LD &apos;06). 43-50.
David Kurokawa, Cyril Goutte, and Pierre Isabelle.
2009. Automatic detection of translated text and its
impact on machine translation. In Proceedings of
MT-Summit XII.
Sara Laviosa: 1997. How Comparable can &apos;Comparable
Corpora&apos; Be?. Target, 9 (2), pp. 289-319.
</reference>
<page confidence="0.813529">
1325
</page>
<reference confidence="0.999302703703704">
Sara Laviosa-Braithwaite. 1998. In Mona Baker (ed.)
Routledge Encyclopedia of Translation Studies. Lon-
don/New York: Routledge, pp.288-291.
Sara Laviosa. 2002. Corpus-based Translation Studies.
Theory, Findings, Applications. Amsterdam/New
York: Rodopi.
David Madigan, Alexander Genkin, David D. Lewis and
Dmitriy Fradkin 2005. Bayesian Multinomial Logis-
tic Regression for Author Identification, In Maxent
Conference, 509-516.
James W. Pennebaker, Martha E. Francis, and Roger J.
Booth. 2001. Linguistic Inquiry and Word Count
(LIWC): LIWC2001 Manual. Erlbaum Publishers,
Mahwah, NJ, USA.
Helmut Schmid. Probabilistic Part-of-Speech Tagging
Using Decision Trees. 2004. In Proceedings of In-
ternational Conference on New Methods in Lan-
guage Processing.
Larry Selinker.1972. Interlanguage. International Re-
view of Applied Linguistics. 10, 209-241.
Gideon Toury. 1995. Descriptive Translation Studies
and beyond. John Benjamins, Amsterdam / Philadel-
phia.
Hans van Halteren. 2008. Source language markers in
EUROPARL translations. In COLING &apos;08: Proceed-
ings of the 22nd International Conference on Compu-
tational Linguistics, pages 937-944.
</reference>
<page confidence="0.992932">
1326
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.871775">
<title confidence="0.999887">Translationese and Its Dialects</title>
<author confidence="0.999831">Moshe Koppel Noam Ordan</author>
<affiliation confidence="0.9639595">Department of Computer Science Department of Computer Science Bar Ilan University University of Haifa</affiliation>
<address confidence="0.990502">Ramat-Gan, Israel 52900 Haifa, Israel 31905</address>
<email confidence="0.998041">moishk@gmail.comnoam.ordan@gmail.com</email>
<abstract confidence="0.997086083333333">While it is has often been observed that the product of translation is somehow different than non-translated text, scholars have emphasized two distinct bases for such differences. Some have noted interference from the source language spilling over into translation in a source-language-specific way, while others have noted general effects of the process of translation that are independent of source language. Using a series of text categorization experiments, we show that both these effects exist and that, moreover, there is a continuum between them. There are many effects of translation that are consistent among texts translated from a given source language, some of which are consistent even among texts translated from families of source languages. Significantly, we find that even for widely unrelated source languages and multiple genres, differences between translated texts and non-translated texts are sufficient for a learned classifier to accurately determine if a given text is translated or original.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mona Baker</author>
</authors>
<title>Corpus linguistics and translation studies: Implications and applications.</title>
<date>1993</date>
<booktitle>Text and technology: in honour of John Sinclair,</booktitle>
<pages>233--252</pages>
<editor>In Gill Francis Mona Baker and Elena Tognini Bonelli, editors,</editor>
<publisher>John Benjamins,</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="1486" citStr="Baker 1993" startWordPosition="214" endWordPosition="215">translated from a given source language, some of which are consistent even among texts translated from families of source languages. Significantly, we find that even for widely unrelated source languages and multiple genres, differences between translated texts and non-translated texts are sufficient for a learned classifier to accurately determine if a given text is translated or original. 1 Introduction The products of translation (written or oral) are generally assumed to be ontologically different from non-translated texts. Researchers have emphasized two aspects of this difference. Some (Baker 1993) have emphasized general effects of the process of translation that are independent of source language and regard the collective product of this process in a given target language as an `interlanguage&apos; (Selinker, 1972), `third code&apos; (Frawley, 1984) or `translationese&apos; (Gellerstam, 1986). Others (Toury, 1995) have emphasized the effects of interference, the process by which a specific source language leaves distinct marks or fingerprints in the target language, so that translations from different source languages into the same target language may be regarded as distinct dialects of translatione</context>
<context position="11178" citStr="Baker, 1993" startWordPosition="1782" endWordPosition="1783">e is to learn a classifier that classifies a text as belonging to one of only two classes: original English (O) or translated-intoEnglish (T). The catch is that all our training texts for the class T will be translations from some fixed source language, while all our test documents in T will be translations from a different source language. What accuracy can be achieved in such an experiment? The answer to this question will tell us a great deal about how much of translationese is general and how much of it is language dependent. If accuracy is close to 100%, translationese is purely general (Baker, 1993). (We already know from the previous experiment that that&apos;s not the case.). If accuracy is near 50%, there are no general effects, just language-dependent ones. Note that, whereas in our first experiment above pair-specific interference facilitated good classification, in this experiment pair-specific interference is an impediment to good classification. The details of the experiment are as follows. We create, for example, a “French” corpus consisting of the 200 chunks of text translated from French and 200 original English texts. We similarly create a corpus for each of the other source langu</context>
</contexts>
<marker>Baker, 1993</marker>
<rawString>Mona Baker. 1993. Corpus linguistics and translation studies: Implications and applications. In Gill Francis Mona Baker and Elena Tognini Bonelli, editors, Text and technology: in honour of John Sinclair, pages 233-252. John Benjamins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Silvia Bernardini</author>
</authors>
<title>A new approach to the study of Translationese: Machinelearning the difference between original and translated text.</title>
<date>2006</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>21--3</pages>
<contexts>
<context position="12787" citStr="Baroni and Bernardini (2006)" startWordPosition="2042" endWordPosition="2045">an” corpus to see if we can classify them as translated or original. We repeat this for each of the 25 train_corpus, test_corpus pairs. In Table 3, we show the accuracy obtained for each such pair. (For the case where the training corpus and testing corpus are identical – the di1320 agonal of the matrix – we show results for ten-fold cross-validation.) We note several interesting facts. First, results of cross-validation within each corpus are very strong. For any given source language, it is quite easy to distinguish translations from original English. This corroborates results obtained by Baroni and Bernardini (2006), Ilisei et al. (2010), Kurokawa et al. (2009) and van Halteren (2008), which we will discuss below. We note further, that for the cases where we train on one source language and test on another, results are far worse. This clearly indicates that interference effects from one source language might be misleading when used to identify translations from a different language. Thus, for example, in the Finnish corpus, the word me is a strong indicator of original English (constituting 0.0003 of tokens in texts translated from Finnish as opposed to 0.0015 of tokens in original English texts), but in</context>
<context position="16529" citStr="Baroni and Bernardini (2006)" startWordPosition="2650" endWordPosition="2653">udies. Ilisei et al. (2010), Kurokawa (2009) and van Halteren (2008) each obtained above 90% accuracy in distinguishing translation from original. However, in each case the translations were from a single source language. (Van Halteren considered multiple source languages, but each learned classifier used only one of them.) Thus, those results do not prove that translationese has distinctive source-languageindependent features. To our knowledge, the only earlier work that used a learned classifier to identify translations in which both test and train sets involved multiple source languages is Baroni and Bernardini (2006), in which the target language was Italian and the source languages were known to be varied. The actual distribution of source languages was, however, not known to the researchers. They obtained accuracy of 86.7%. Their result was obtained using combinations of lexical and syntactic features. 1321 3.2 Some distinguishing features Let us now consider some of the most salient function words for which frequency of usage in T differs significantly from that in O. While there are many such features, we focus on two categories of words that are most prominent among those with the most significant di</context>
</contexts>
<marker>Baroni, Bernardini, 2006</marker>
<rawString>Marco Baroni and Silvia Bernardini. 2006. A new approach to the study of Translationese: Machinelearning the difference between original and translated text. Literary and Linguistic Computing, 21(3):259-274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shoshan Blum-Kulka</author>
</authors>
<title>Shifts of cohesion and coherence in translation.</title>
<date>1986</date>
<booktitle>In Juliane House and Shoshana Blum-Kulka (Eds), Interlingual and Intercultural Communication (17-35).</booktitle>
<publisher>Günter Narr Verlag.</publisher>
<location>Tübingen:</location>
<contexts>
<context position="19096" citStr="Blum-Kulka, 1986" startWordPosition="3078" endWordPosition="3079">pus. Bold indicates significance at p&lt;0.01. We note that the preponderance of such cohesive markers are significantly more frequent in translations. In fact, we also find that a variety of phrases that serve the same purpose as cohesive adverbs, such as in fact and as a result are significantly more frequent in translationese. The general principle underlying these phenomena is subject to speculation. Previous researchers have noted the phenomenon of explicitation, according to which translators tend to render implicit utterances in the source text into explicit utterances in the target text (Blum-Kulka, 1986, Laviosa-Braithwaite, 1998), for example by filling out elliptical expressions or adding connectives to increase cohesion of the text (Laviosa-Braithwaite, 1998). It is plausible that the use of cohesive adverbs is an instantiation of this phenomenon. With regard to the under-representation of pronouns and the over-representation of the, there are a number of possible interpretations. It may be that this too is the result of explicitation, in which anaphora is resolved by replacing pronouns with noun phrases (e.g., the man instead of he). But it also might be that this is an example of simpli</context>
</contexts>
<marker>Blum-Kulka, 1986</marker>
<rawString>Shoshan Blum-Kulka. Shifts of cohesion and coherence in translation. 1986. In Juliane House and Shoshana Blum-Kulka (Eds), Interlingual and Intercultural Communication (17-35). Tübingen: Günter Narr Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Frawley</author>
</authors>
<title>Prolegomenon to a theory of translation.</title>
<date>1984</date>
<booktitle>In William Frawley (ed), Translation. Literary, Linguistic and Philosophical Perspectives (179-175).</booktitle>
<publisher>University of Delaware Press.</publisher>
<location>Newark:</location>
<contexts>
<context position="1734" citStr="Frawley, 1984" startWordPosition="252" endWordPosition="254">translated texts and non-translated texts are sufficient for a learned classifier to accurately determine if a given text is translated or original. 1 Introduction The products of translation (written or oral) are generally assumed to be ontologically different from non-translated texts. Researchers have emphasized two aspects of this difference. Some (Baker 1993) have emphasized general effects of the process of translation that are independent of source language and regard the collective product of this process in a given target language as an `interlanguage&apos; (Selinker, 1972), `third code&apos; (Frawley, 1984) or `translationese&apos; (Gellerstam, 1986). Others (Toury, 1995) have emphasized the effects of interference, the process by which a specific source language leaves distinct marks or fingerprints in the target language, so that translations from different source languages into the same target language may be regarded as distinct dialects of translationese. We wish to use text categorization methods to set both of these claims on a firm empirical foundation. We will begin by bringing evidence for two claims: (1) Translations from different source languages into the same target language are suffici</context>
</contexts>
<marker>Frawley, 1984</marker>
<rawString>William Frawley. 1984. Prolegomenon to a theory of translation. In William Frawley (ed), Translation. Literary, Linguistic and Philosophical Perspectives (179-175). Newark: University of Delaware Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Antonietta Fusco</author>
</authors>
<title>Quality in conference interpreting between cognate languages: A preliminary approach to the Spanish-Italian case.</title>
<date>1990</date>
<journal>The Interpreters’ Newsletter,</journal>
<volume>3</volume>
<pages>93--97</pages>
<contexts>
<context position="29210" citStr="Fusco (1990)" startWordPosition="4671" endWordPosition="4672">ed classifiers are based solely on function words, so that, unlike earlier studies, the differences we find are unlikely to include cultural or thematic differences that might be artifacts of corpus construction. In addition, we find that the exploitability of differences between translated texts and nontranslated texts are related to the difference between source languages: translations from similar source languages are different from non-translated texts in similar ways. Linguists use a variety of methods to quantify the extent of differences and similarities between languages. For example, Fusco (1990) studies translations between Spanish and Italian and considers the impact of structural differences between the two languages on translation quality. Studying the differences and distance between languages by comparing translations into the same language may serve as another way to deepen our typological knowledge. As we have seen, training on source language x and testing on source language y provides us with a good estimation of the distance between languages, in accordance with what we find in standard works on typology (cf. Katzner, 2002). In addition to its intrinsic interest, the findin</context>
</contexts>
<marker>Fusco, 1990</marker>
<rawString>Maria Antonietta Fusco. 1990. Quality in conference interpreting between cognate languages: A preliminary approach to the Spanish-Italian case. The Interpreters’ Newsletter, 3, 93-97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Gellerstam</author>
</authors>
<title>Translationese in Swedish novels translated from English,</title>
<date>1986</date>
<booktitle>Translation Studies in Scandinavia (88-95).</booktitle>
<editor>in Lars Wollin &amp; Hans Lindquist (eds.),</editor>
<publisher>CWK Gleerup.</publisher>
<location>Lund:</location>
<contexts>
<context position="1773" citStr="Gellerstam, 1986" startWordPosition="257" endWordPosition="258">texts are sufficient for a learned classifier to accurately determine if a given text is translated or original. 1 Introduction The products of translation (written or oral) are generally assumed to be ontologically different from non-translated texts. Researchers have emphasized two aspects of this difference. Some (Baker 1993) have emphasized general effects of the process of translation that are independent of source language and regard the collective product of this process in a given target language as an `interlanguage&apos; (Selinker, 1972), `third code&apos; (Frawley, 1984) or `translationese&apos; (Gellerstam, 1986). Others (Toury, 1995) have emphasized the effects of interference, the process by which a specific source language leaves distinct marks or fingerprints in the target language, so that translations from different source languages into the same target language may be regarded as distinct dialects of translationese. We wish to use text categorization methods to set both of these claims on a firm empirical foundation. We will begin by bringing evidence for two claims: (1) Translations from different source languages into the same target language are sufficiently different from each other for a l</context>
</contexts>
<marker>Gellerstam, 1986</marker>
<rawString>Martin Gellerstam. 1986. Translationese in Swedish novels translated from English, in Lars Wollin &amp; Hans Lindquist (eds.), Translation Studies in Scandinavia (88-95). Lund: CWK Gleerup.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iustina Ilisei</author>
</authors>
<title>Diana Inkpen, Gloria Corpas Pastor, and Ruslan Mitkov. Identification of translationese: A machine learning approach.</title>
<date>2010</date>
<booktitle>Proceedings of CICLing-2010: Computational Linguistics and Intelligent Text Processing, 11th International,</booktitle>
<volume>6008</volume>
<pages>503--511</pages>
<editor>In Alexander F. Gelbukh, editor,</editor>
<publisher>Springer,</publisher>
<marker>Ilisei, 2010</marker>
<rawString>Iustina Ilisei, Diana Inkpen, Gloria Corpas Pastor, and Ruslan Mitkov. Identification of translationese: A machine learning approach. In Alexander F. Gelbukh, editor, Proceedings of CICLing-2010: Computational Linguistics and Intelligent Text Processing, 11th International, volume 6008 of Lecture Notes in Computer Science, pages 503-511. Springer, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Katzner</author>
</authors>
<date>2002</date>
<booktitle>The Languages of</booktitle>
<publisher>the World. Routledge.</publisher>
<contexts>
<context position="29759" citStr="Katzner, 2002" startWordPosition="4758" endWordPosition="4759">ces and similarities between languages. For example, Fusco (1990) studies translations between Spanish and Italian and considers the impact of structural differences between the two languages on translation quality. Studying the differences and distance between languages by comparing translations into the same language may serve as another way to deepen our typological knowledge. As we have seen, training on source language x and testing on source language y provides us with a good estimation of the distance between languages, in accordance with what we find in standard works on typology (cf. Katzner, 2002). In addition to its intrinsic interest, the finding that the distance between languages is directly correlated with our ability to distinguish translations from a given source language from non-translated text is of great importance for several computational tasks. First, translations can be studied in order to shed new light on the differences between languages and can bear on attested techniques for using cognates to improve machine translation (Kondrak &amp; Sherif, 2006). Additionally, given the results of our experiments, it stands to reason that using translated texts, especially from relat</context>
</contexts>
<marker>Katzner, 2002</marker>
<rawString>Kenneth Katzner. 2002. The Languages of the World. Routledge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
<author>Tarek Sherif</author>
</authors>
<title>Evaluation of several phonetic similarity algorithms on the task of cognate identification.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Linguistic Distances (LD &apos;06).</booktitle>
<pages>43--50</pages>
<contexts>
<context position="30235" citStr="Kondrak &amp; Sherif, 2006" startWordPosition="4829" endWordPosition="4832">ides us with a good estimation of the distance between languages, in accordance with what we find in standard works on typology (cf. Katzner, 2002). In addition to its intrinsic interest, the finding that the distance between languages is directly correlated with our ability to distinguish translations from a given source language from non-translated text is of great importance for several computational tasks. First, translations can be studied in order to shed new light on the differences between languages and can bear on attested techniques for using cognates to improve machine translation (Kondrak &amp; Sherif, 2006). Additionally, given the results of our experiments, it stands to reason that using translated texts, especially from related source languages, will prove beneficial for constructing language models and will outperform results obtained from non-translated texts. This, too, bears on the quality of machine translation. Finally, we find that there are general properties of translationese sufficiently strong that we can identify translationese even in a combined corpus that is comprised of eight very disparate languages across two distinct genres, one spoken and the other written. Prominent among</context>
</contexts>
<marker>Kondrak, Sherif, 2006</marker>
<rawString>Grzegorz Kondrak and Tarek Sherif. 2006. Evaluation of several phonetic similarity algorithms on the task of cognate identification. In Proceedings of the Workshop on Linguistic Distances (LD &apos;06). 43-50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kurokawa</author>
<author>Cyril Goutte</author>
<author>Pierre Isabelle</author>
</authors>
<title>Automatic detection of translated text and its impact on machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of MT-Summit XII.</booktitle>
<contexts>
<context position="12833" citStr="Kurokawa et al. (2009)" startWordPosition="2050" endWordPosition="2054">ted or original. We repeat this for each of the 25 train_corpus, test_corpus pairs. In Table 3, we show the accuracy obtained for each such pair. (For the case where the training corpus and testing corpus are identical – the di1320 agonal of the matrix – we show results for ten-fold cross-validation.) We note several interesting facts. First, results of cross-validation within each corpus are very strong. For any given source language, it is quite easy to distinguish translations from original English. This corroborates results obtained by Baroni and Bernardini (2006), Ilisei et al. (2010), Kurokawa et al. (2009) and van Halteren (2008), which we will discuss below. We note further, that for the cases where we train on one source language and test on another, results are far worse. This clearly indicates that interference effects from one source language might be misleading when used to identify translations from a different language. Thus, for example, in the Finnish corpus, the word me is a strong indicator of original English (constituting 0.0003 of tokens in texts translated from Finnish as opposed to 0.0015 of tokens in original English texts), but in the German corpus, me is an indicator of tran</context>
<context position="20201" citStr="Kurokawa et al. (2009)" startWordPosition="3246" endWordPosition="3249">cing pronouns with noun phrases (e.g., the man instead of he). But it also might be that this is an example of simplification (Laviosa- Braithwaite 1998, Laviosa 2002), according to which the translator simplifies the message, the language, or both. Related results confirming the simplification hypothesis were found by Ilisei et al. (2010) on Spanish texts. In particular, they found that type-to-token ratio (lexical variety/richness), mean sentence length and proportion of grammatical words (lexical density/readability) are all smaller in translated texts. We note that Van Halteren (2008) and Kurokawa et al. (2009), who considered lexical features, found cultural differences, like over-representation of ladies and gentlemen in translated speeches. Such differences, while of general interest, are orthogonal to our purposes in this paper. 1322 3.3 Overriding language-specific effects We found in Section 2.3 that when we trained in one language and tested in another, classification succeeded to the extent that the source languages used in training and testing, respectively, are related to each other. In effect, general differences between translationese and original English were partially overwhelmed by la</context>
</contexts>
<marker>Kurokawa, Goutte, Isabelle, 2009</marker>
<rawString>David Kurokawa, Cyril Goutte, and Pierre Isabelle. 2009. Automatic detection of translated text and its impact on machine translation. In Proceedings of MT-Summit XII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Laviosa</author>
</authors>
<title>How Comparable can &apos;Comparable Corpora&apos;</title>
<date>1997</date>
<journal>Be?. Target,</journal>
<volume>9</volume>
<issue>2</issue>
<pages>289--319</pages>
<contexts>
<context position="4839" citStr="Laviosa, 1997" startWordPosition="730" endWordPosition="731">ly and negatively) our ability to classify documents. 2.1 The Europarl Corpus The main corpus we will use throughout this paper is Europarl (Koehn, 2005), which consists of transcripts of addresses given in the European Parliament. The full corpus consists of texts translated into English from 11 different languages (and vice versa), as well as texts originally produced in English. For our purposes, it will be sufficient to use translations from five languages (Finnish, French, German, Italian and Spanish), as well as original English. We note that this corpus constitutes a comparable corpus (Laviosa, 1997), since it contains (1) texts written originally in a certain language (English), as well as (2) texts translated into that same language, matched for genre, domain, publication timeframe, etc. Each of the five translated components is a text file containing just under 500,000 words; the original English component is a file of the same size as the aggregate of the other five. The five source languages we use were selected by first eliminating several source languages for which the available text was limited and then choosing from among the remaining languages, those of varying degrees of pairw</context>
</contexts>
<marker>Laviosa, 1997</marker>
<rawString>Sara Laviosa: 1997. How Comparable can &apos;Comparable Corpora&apos; Be?. Target, 9 (2), pp. 289-319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Laviosa-Braithwaite</author>
</authors>
<date>1998</date>
<booktitle>Routledge Encyclopedia of Translation Studies.</booktitle>
<pages>288--291</pages>
<editor>In Mona Baker (ed.)</editor>
<publisher>Routledge,</publisher>
<location>London/New York:</location>
<contexts>
<context position="19124" citStr="Laviosa-Braithwaite, 1998" startWordPosition="3080" endWordPosition="3081">s significance at p&lt;0.01. We note that the preponderance of such cohesive markers are significantly more frequent in translations. In fact, we also find that a variety of phrases that serve the same purpose as cohesive adverbs, such as in fact and as a result are significantly more frequent in translationese. The general principle underlying these phenomena is subject to speculation. Previous researchers have noted the phenomenon of explicitation, according to which translators tend to render implicit utterances in the source text into explicit utterances in the target text (Blum-Kulka, 1986, Laviosa-Braithwaite, 1998), for example by filling out elliptical expressions or adding connectives to increase cohesion of the text (Laviosa-Braithwaite, 1998). It is plausible that the use of cohesive adverbs is an instantiation of this phenomenon. With regard to the under-representation of pronouns and the over-representation of the, there are a number of possible interpretations. It may be that this too is the result of explicitation, in which anaphora is resolved by replacing pronouns with noun phrases (e.g., the man instead of he). But it also might be that this is an example of simplification (Laviosa- Braithwai</context>
</contexts>
<marker>Laviosa-Braithwaite, 1998</marker>
<rawString>Sara Laviosa-Braithwaite. 1998. In Mona Baker (ed.) Routledge Encyclopedia of Translation Studies. London/New York: Routledge, pp.288-291.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Laviosa</author>
</authors>
<title>Corpus-based Translation Studies. Theory,</title>
<date>2002</date>
<location>Findings, Applications. Amsterdam/New York: Rodopi.</location>
<contexts>
<context position="19746" citStr="Laviosa 2002" startWordPosition="3180" endWordPosition="3181">mple by filling out elliptical expressions or adding connectives to increase cohesion of the text (Laviosa-Braithwaite, 1998). It is plausible that the use of cohesive adverbs is an instantiation of this phenomenon. With regard to the under-representation of pronouns and the over-representation of the, there are a number of possible interpretations. It may be that this too is the result of explicitation, in which anaphora is resolved by replacing pronouns with noun phrases (e.g., the man instead of he). But it also might be that this is an example of simplification (Laviosa- Braithwaite 1998, Laviosa 2002), according to which the translator simplifies the message, the language, or both. Related results confirming the simplification hypothesis were found by Ilisei et al. (2010) on Spanish texts. In particular, they found that type-to-token ratio (lexical variety/richness), mean sentence length and proportion of grammatical words (lexical density/readability) are all smaller in translated texts. We note that Van Halteren (2008) and Kurokawa et al. (2009), who considered lexical features, found cultural differences, like over-representation of ladies and gentlemen in translated speeches. Such diff</context>
</contexts>
<marker>Laviosa, 2002</marker>
<rawString>Sara Laviosa. 2002. Corpus-based Translation Studies. Theory, Findings, Applications. Amsterdam/New York: Rodopi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Madigan</author>
<author>Alexander Genkin</author>
<author>David D Lewis</author>
<author>Dmitriy Fradkin</author>
</authors>
<title>Bayesian Multinomial Logistic Regression for Author Identification,</title>
<date>2005</date>
<booktitle>In Maxent Conference,</booktitle>
<pages>509--516</pages>
<marker>Madigan, Genkin, Lewis, Fradkin, 2005</marker>
<rawString>David Madigan, Alexander Genkin, David D. Lewis and Dmitriy Fradkin 2005. Bayesian Multinomial Logistic Regression for Author Identification, In Maxent Conference, 509-516.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Martha E Francis</author>
<author>Roger J Booth</author>
</authors>
<date>2001</date>
<booktitle>Linguistic Inquiry and Word Count (LIWC): LIWC2001 Manual. Erlbaum Publishers,</booktitle>
<location>Mahwah, NJ, USA.</location>
<marker>Pennebaker, Francis, Booth, 2001</marker>
<rawString>James W. Pennebaker, Martha E. Francis, and Roger J. Booth. 2001. Linguistic Inquiry and Word Count (LIWC): LIWC2001 Manual. Erlbaum Publishers, Mahwah, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>2004</date>
<booktitle>In Proceedings of International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="18013" citStr="Schmid, 2004" startWordPosition="2907" endWordPosition="2908">ed in T; for most (bolded), the difference is significant at p&lt;0.01. By contrast, the word the is significantly overrepresented in T (15.32% in T vs. 13.73% in O; significant at p&lt;0.01). word freq O freq T I 2.552% 2.148% we 2.713% 2.344% you 0.479% 0.470% he 0.286% 0.115% she 0.081% 0.039% me 0.148% 0.141% us 0.415% 0.320% him 0.066% 0.033% her 0.091% 0.056% my 0.462% 0.345% our 0.696% 0.632% your 0.119% 0.109% his 0.218% 0.123% Table 4: Frequency of pronouns in O and T in the Europarl corpus. Bold indicates significance at p&lt;0.01. In Table 5, we consider cohesive markers, tagged as adverbs (Schmid, 2004). (These are adverbs that can appear at the beginning of a sentence followed immediately by a comma.) word freq O freq T therefore 0.153% 0.287% thus 0.015% 0.041% consequently 0.006% 0.014% hence 0.007% 0.013% accordingly 0.006% 0.011% however 0.216% 0.241% nevertheless 0.019% 0.045% also 0.460% 0.657% furthermore 0.012% 0.048% moreover 0.008% 0.036% indeed 0.098% 0.053% actually 0.065% 0.042% Table 5: Frequency of cohesive adverbs in O and T in the Europarl corpus. Bold indicates significance at p&lt;0.01. We note that the preponderance of such cohesive markers are significantly more frequent i</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Helmut Schmid. Probabilistic Part-of-Speech Tagging Using Decision Trees. 2004. In Proceedings of International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Larry Selinker 1972 Interlanguage</author>
</authors>
<journal>International Review of Applied Linguistics.</journal>
<volume>10</volume>
<pages>209--241</pages>
<marker>Interlanguage, </marker>
<rawString>Larry Selinker.1972. Interlanguage. International Review of Applied Linguistics. 10, 209-241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Toury</author>
</authors>
<title>Descriptive Translation Studies and beyond. John Benjamins,</title>
<date>1995</date>
<location>Amsterdam / Philadelphia.</location>
<contexts>
<context position="1795" citStr="Toury, 1995" startWordPosition="260" endWordPosition="261">learned classifier to accurately determine if a given text is translated or original. 1 Introduction The products of translation (written or oral) are generally assumed to be ontologically different from non-translated texts. Researchers have emphasized two aspects of this difference. Some (Baker 1993) have emphasized general effects of the process of translation that are independent of source language and regard the collective product of this process in a given target language as an `interlanguage&apos; (Selinker, 1972), `third code&apos; (Frawley, 1984) or `translationese&apos; (Gellerstam, 1986). Others (Toury, 1995) have emphasized the effects of interference, the process by which a specific source language leaves distinct marks or fingerprints in the target language, so that translations from different source languages into the same target language may be regarded as distinct dialects of translationese. We wish to use text categorization methods to set both of these claims on a firm empirical foundation. We will begin by bringing evidence for two claims: (1) Translations from different source languages into the same target language are sufficiently different from each other for a learned classifier to a</context>
</contexts>
<marker>Toury, 1995</marker>
<rawString>Gideon Toury. 1995. Descriptive Translation Studies and beyond. John Benjamins, Amsterdam / Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans van Halteren</author>
</authors>
<title>Source language markers in EUROPARL translations.</title>
<date>2008</date>
<booktitle>In COLING &apos;08: Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>937--944</pages>
<marker>van Halteren, 2008</marker>
<rawString>Hans van Halteren. 2008. Source language markers in EUROPARL translations. In COLING &apos;08: Proceedings of the 22nd International Conference on Computational Linguistics, pages 937-944.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>