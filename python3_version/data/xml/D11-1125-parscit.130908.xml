<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.973725">
Tuning as Ranking
</title>
<author confidence="0.934764">
Mark Hopkins and Jonathan May
</author>
<affiliation confidence="0.832151">
SDL Language Weaver
</affiliation>
<address confidence="0.969696">
Los Angeles, CA 90045
</address>
<email confidence="0.999608">
{mhopkins,jmay}@sdl.com
</email>
<sectionHeader confidence="0.998605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99924995">
We offer a simple, effective, and scalable
method for statistical machine translation pa-
rameter tuning based on the pairwise approach
to ranking (Herbrich et al., 1999). Unlike
the popular MERT algorithm (Och, 2003), our
pairwise ranking optimization (PRO) method
is not limited to a handful of parameters and
can easily handle systems with thousands of
features. Moreover, unlike recent approaches
built upon the MIRA algorithm of Crammer
and Singer (2003) (Watanabe et al., 2007; Chi-
ang et al., 2008b), PRO is easy to imple-
ment. It uses off-the-shelf linear binary classi-
fier software and can be built on top of an ex-
isting MERT framework in a matter of hours.
We establish PRO’s scalability and effective-
ness by comparing it to MERT and MIRA and
demonstrate parity on both phrase-based and
syntax-based systems in a variety of language
pairs, using large scale data scenarios.
</bodyText>
<sectionHeader confidence="0.999476" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999873309523809">
The MERT algorithm (Och, 2003) is currently the
most popular way to tune the parameters of a sta-
tistical machine translation (MT) system. MERT
is well-understood, easy to implement, and runs
quickly, but can behave erratically and does not scale
beyond a handful of features. This lack of scalability
is a significant weakness, as it inhibits systems from
using more than a couple dozen features to discrimi-
nate between candidate translations and stymies fea-
ture development innovation.
Several researchers have attempted to address
this weakness. Recently, Watanabe et al. (2007)
and Chiang et al. (2008b) have developed tuning
methods using the MIRA algorithm (Crammer and
Singer, 2003) as a nucleus. The MIRA technique of
Chiang et al. has been shown to perform well on
large-scale tasks with hundreds or thousands of fea-
tures (2009). However, the technique is complex and
architecturally quite different from MERT. Tellingly,
in the entire proceedings of ACL 2010 (Hajiˇc et al.,
2010), only one paper describing a statistical MT
system cited the use of MIRA for tuning (Chiang,
2010), while 15 used MERT.1
Here we propose a simpler approach to tuning that
scales similarly to high-dimensional feature spaces.
We cast tuning as a ranking problem (Chen et al.,
2009), where the explicit goal is to learn to correctly
rank candidate translations. Specifically, we follow
the pairwise approach to ranking (Herbrich et al.,
1999; Freund et al., 2003; Burges et al., 2005; Cao et
al., 2007), in which the ranking problem is reduced
to the binary classification task of deciding between
candidate translation pairs.
Of primary concern to us is the ease of adoption of
our proposed technique. Because of this, we adhere
as closely as possible to the established MERT ar-
chitecture and use freely available machine learning
software. The end result is a technique that scales
and performs just as well as MIRA-based tuning,
but which can be implemented in a couple of hours
by anyone with an existing MERT implementation.
Mindful that many would-be enhancements to the
</bodyText>
<footnote confidence="0.9614235">
1The remainder either did not specify their tuning method
(though a number of these used the Moses toolkit (Koehn et al.,
2007), which uses MERT for tuning) or, in one case, set weights
by hand.
</footnote>
<page confidence="0.858686">
1352
</page>
<note confidence="0.958259">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352–1362,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999849">
state-of-the-art are false positives that only show im-
provement in a narrowly defined setting or with lim-
ited data, we validate our claims on both syntax and
phrase-based systems, using multiple language pairs
and large data sets.
We describe tuning in abstract and somewhat for-
mal terms in Section 2, describe the MERT algo-
rithm in the context of those terms and illustrate its
scalability issues via a synthetic experiment in Sec-
tion 3, introduce our pairwise ranking optimization
method in Section 4, present numerous large-scale
MT experiments to validate our claims in Section 5,
discuss some related work in Section 6, and con-
clude in Section 7.
</bodyText>
<sectionHeader confidence="0.995577" genericHeader="introduction">
2 Tuning
</sectionHeader>
<bodyText confidence="0.99712">
In Figure 1, we show an example candidate space,
defined as a tuple (A, I, J, f, e, x) where:
</bodyText>
<listItem confidence="0.999052533333333">
• A is a positive integer referred to as the dimen-
sionality of the space
• I is a (possibly infinite) set of positive integers,
referred to as sentence indices
• J maps each sentence index to a (possibly infi-
nite) set of positive integers, referred to as can-
didate indices
• f maps each sentence index to a sentence from
the source language
• e maps each pair (i, j) E I x J(i) to the jth
target-language candidate translation of source
sentence f(i)
• x maps each pair (i, j) E I x J(i) to a
A-dimension feature vector representation of
e(i, j)
</listItem>
<bodyText confidence="0.999842909090909">
The example candidate space has two source sen-
tences, three candidate translations for each source
sentence, and feature vectors of dimension 2. It is
an example of a finite candidate space, defined as
a candidate space for which I is finite and J maps
each index of I to a finite set.
A policy of candidate space (A, I, J, f, e, x) is a
function that maps each member i E I to a member
of J(i). A policy corresponds to a choice of one
candidate translation for each source sentence. For
the example in Figure 1, policy p1 = 11 �-+ 2, 2 �-+
31 corresponds to the choice of “he does not go” for
the first source sentence and “I do not go” for the
second source sentence. Obviously some policies
are better than others. Policy p2 = 11 �-+ 3, 2 �-+ 11
corresponds to the inferior translations “she not go”
and “I go not.”
We assume the MT system distinguishes between
policies using a scoring function for candidate trans-
lations of the form hw(i, j) = w · x(i, j), where w
is a weight vector of the same dimension as feature
vector x(i, j). This scoring function extends to a
policy p by summing the cost of each of the policy’s
candidate translations: Hw(p) = Ei∈I hw(i, p(i)).
As can be seen in Figure 1, using w = [−2, 1],
Hw(p1) = 9 and Hw(p2) = −8.
The goal of tuning is to learn a weight vector w
such that Hw(p) assigns a high score to good poli-
cies, and a low score to bad policies.2 To do so,
we need information about which policies are good
and which are bad. This information is provided by
a “gold” scoring function G that maps each policy
to a real-valued score. Typically this gold function
is BLEU (Papineni et al., 2002), though there are
several common alternatives (Lavie and Denkowski,
2009; Melamed et al., 2003; Snover et al., 2006;
Chiang et al., 2008a).
We want to find a weight vector w such that Hw
behaves “similarly” to G on a candidate space s.
We assume a loss function ls(Hw, G) which returns
the real-valued loss of using scoring function Hw
when the gold scoring function is G and the candi-
date space is s. Thus, we may say the goal of tuning
is to find the weight vector w that minimizes loss.
</bodyText>
<sectionHeader confidence="0.999289" genericHeader="method">
3 MERT
</sectionHeader>
<bodyText confidence="0.99995475">
In general, the candidate space may have infinitely
many source sentences, as well as infinitely many
candidate translations per source sentence. In prac-
tice, tuning optimizes over a finite subset of source
sentences3 and a finite subset of candidate transla-
tions as well. The classic tuning architecture used
in the dominant MERT approach (Och, 2003) forms
the translation subset and learns weight vector w via
</bodyText>
<footnote confidence="0.99209075">
2Without loss of generality, we assume that a higher score
indicates a better translation.
3See Section 5.2 for the tune sets used in this paper’s exper-
iments.
</footnote>
<page confidence="0.922356">
1353
</page>
<table confidence="0.99158625">
Source Sentence Candidate Translations
i f(i) j e(i,j) x(i,j) hw(i,j) g(i,j)
1 “il ne va pas” 1 “he goes not” [2 4] 0 0.28
2 “he does not go” [3 8] 2 0.42
3 “she not go” [6 1] -11 0.12
2 “je ne vais pas” 1 “I go not” [-3 -3] 3 0.15
2 “we do not go” [1 -5] -7 0.18
3 “I do not go” [-5 -3] 7 0.34
</table>
<figureCaption confidence="0.995696">
Figure 1: Example candidate space of dimensionality 2. Note: I = {1, 2}, J(1) = J(2) = {1, 2, 3}. We also show a
local scoring function h,(i, j) (where w = [−2, 1]) and a local gold scoring function g(i, j).
</figureCaption>
<bodyText confidence="0.252322">
Algorithm TUNE(s, G):
</bodyText>
<listItem confidence="0.97043725">
1: initialize pool: let s0 = hA, I0, J0, f, e, xi,
where I0 ⊆ I and J0 = ∅
2: for the desired number of iterations do
3: candidate generation: choose index pairs
(i, j); for each, add j to J0(i)
4: optimization: find vector w that minimizes
ls,(Hw, G)
5: return w
</listItem>
<figureCaption confidence="0.944662">
Figure 2: Schema for iterative tuning of base candidate
</figureCaption>
<bodyText confidence="0.975589466666667">
space s = hA, I, J, f, e, xi w.r.t. gold function G.
a feedback loop consisting of two phases. Figure 2
shows the pseudocode. During candidate genera-
tion, candidate translations are selected from a base
candidate space s and added to a finite candidate
space s0 called the candidate pool. During optimiza-
tion, the weight vector w is optimized to minimize
loss ls,(Hw, G).
For its candidate generation phase, MERT gener-
ates the k-best candidate translations for each source
sentence according to hw, where w is the weight
vector from the previous optimization phase (or an
arbitrary weight vector for the first iteration).
For its optimization phase, MERT defines the loss
function as follows:
</bodyText>
<equation confidence="0.972169">
ls(Hw, G) = max G(p) − G(arg max Hw(p))
p p
</equation>
<bodyText confidence="0.999805181818182">
In other words, it prefers weight vectors w such
that the gold function G scores Hw’s best policy as
highly as possible (if Hw’s best policy is the same
as G’s best policy, then there is zero loss). Typically
the optimization phase is implemented using Och’s
line optimization algorithm (2003).
MERT has proven itself effective at tuning candi-
date spaces with low dimensionality. However, it is
often claimed that MERT does not scale well with
dimensionality. To test this claim, we devised the
following synthetic data experiment:
</bodyText>
<listItem confidence="0.98692175">
1. We created a gold scoring function G that is
also a linear function of the same form as Hw,
i.e., G(p) = Hw∗(p) for some gold weight vec-
tor w∗. Under this assumption, the role of the
optimization phase reduces to learning back the
gold weight vector w∗.
2. We generated a A-dimensionality candidate
pool with 500 source “sentences” and 100 can-
didate “translations” per sentence. We created
the corresponding feature vectors by drawing
A random real numbers uniformly from the in-
terval [0, 500].
3. We ran MERT’s line optimization on this syn-
thetic candidate pool and compared the learned
weight vector w to the gold weight vector w∗
using cosine similarity.
</listItem>
<bodyText confidence="0.999844769230769">
We used line optimization in the standard way,
by generating 20 random starting weight vectors and
hill-climbing on each independently until no further
progress is made, then choosing the final weight vec-
tor that minimizes loss. We tried various dimen-
sionalities from 10 to 1000. We repeated each set-
ting three times, generating different random data
each time. The results in Figure 3 indicate that as
the dimensionality of the problem increases MERT
rapidly loses the ability to learn w∗. Note that this
synthetic problem is considerably easier than a real
MT scenario, where the data is noisy and interdepen-
dent, and the gold scoring function is nonlinear. If
</bodyText>
<page confidence="0.991249">
1354
</page>
<bodyText confidence="0.996541">
MERT cannot scale in this simple scenario, it has lit-
tle hope of succeeding in a high-dimensionality de-
ployment scenario.
</bodyText>
<sectionHeader confidence="0.963591" genericHeader="method">
4 Optimization via Pairwise Ranking
</sectionHeader>
<bodyText confidence="0.99999325">
We would like to modify MERT so that it scales well
to high-dimensionality candidate spaces. The most
prominent example of a tuning method that per-
forms well on high-dimensionality candidate spaces
is the MIRA-based approach used by Watanabe et
al. (2007) and Chiang et al. (2008b; 2009). Unfortu-
nately, this approach requires a complex architecture
that diverges significantly from the MERT approach,
and consequently has not been widely adopted. Our
goal is to achieve the same performance with mini-
mal modification to MERT.
With MERT as a starting point, we have a choice:
modify candidate generation, optimization, or both.
Although alternative candidate generation methods
have been proposed (Macherey et al., 2008; Chiang
et al., 2008b; Chatterjee and Cancedda, 2010), we
will restrict ourselves to MERT-style candidate gen-
eration, in order to minimize divergence from the
established MERT tuning architecture. Instead, we
focus on the optimization phase.
</bodyText>
<subsectionHeader confidence="0.999129">
4.1 Basic Approach
</subsectionHeader>
<bodyText confidence="0.999993111111111">
While intuitive, the MERT optimization module fo-
cuses attention on Hw’s best policy, and not on its
overall prowess at ranking policies. We will cre-
ate an optimization module that directly addresses
Hw’s ability to rank policies in the hope that this
more holistic approach will generalize better to un-
seen data.
Assume that the gold scoring function G decom-
poses in the following way:
</bodyText>
<equation confidence="0.9802195">
G(p) =1: g(i,p(i)) (1)
iEI
</equation>
<bodyText confidence="0.995180625">
where g(i, j) is a local scoring function that scores
the single candidate translation e(i, j). We show an
example g in Figure 1. For an arbitrary pair of can-
didate translations e(i, j) and e(i, j&apos;), the local gold
function g tells us which is the better translation.
Note that this induces a ranking on the candidate
translations for each source sentence.
We follow the pairwise approach to ranking (Her-
brich et al., 1999; Freund et al., 2003; Burges et al.,
2005; Cao et al., 2007). In the pairwise approach,
the learning task is framed as the classification of
candidate pairs into two categories: correctly or-
dered and incorrectly ordered. Specifically, for can-
didate translation pair e(i, j) and e(i, j&apos;), we want:
g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;). We can
re-express this condition:
</bodyText>
<equation confidence="0.823808">
g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;)
⇔ hw(i, j) − hw(i, j&apos;) &gt; 0
⇔ w · x(i,j) − w · x(i,j&apos;) &gt; 0
⇔ w · (x(i, j) − x(i, j&apos;)) &gt; 0
</equation>
<bodyText confidence="0.99998346875">
Thus optimization reduces to a classic binary clas-
sification problem. We create a labeled training in-
stance for this problem by computing difference vec-
tor x(i, j) − x(i, j&apos;), and labeling it as a positive
or negative instance based on whether, respectively,
the first or second vector is superior according to
gold function g. To ensure balance, we consider
both possible difference vectors from a pair. For ex-
ample, given the candidate space of Figure 1, since
g(1,1) &gt; g(1, 3), we would add ([−4, 3], +) and
([4, −3], −) to our training set. We can then feed this
training data directly to any off-the-shelf classifica-
tion tool that returns a linear classifier, in order to ob-
tain a weight vector w that optimizes the above con-
dition. This weight vector can then be used directly
by the MT system in the subsequent candidate gen-
eration phase. The exact loss function ls,(Hw, G)
optimized depends on the choice of classifier.4
Typical approaches to pairwise ranking enumer-
ate all difference vectors as training data. For tuning
however, this means O(|I |∗ J2max) vectors, where
Jmax is the cardinality of the largest J(i). Since
I and Jmax commonly range in the thousands, a
full enumeration would produce billions of feature
vectors. Out of tractability considerations, we sam-
ple from the space of difference vectors, using the
sampler template in Figure 4. For each source sen-
tence i, the sampler generates F candidate transla-
tion pairs hj, j&apos;i, and accepts each pair with proba-
bility αi(|g(i,j) − g(i, j&apos;)|). Among the accepted
pairs, it keeps the Ξ with greatest g differential, and
adds their difference vectors to the training data.5
</bodyText>
<footnote confidence="0.996608">
4See (Chen et al., 2009) for a brief survey.
5The intuition for biasing toward high score differential is
</footnote>
<page confidence="0.989725">
1355
</page>
<figureCaption confidence="0.78685925">
Figure 3: Result of synthetic data learning experiment
for MERT and PRO, with and without added noise. As
the dimensionality increases MERT is unable to learn the
original weights but PRO still performs adequately.
</figureCaption>
<subsectionHeader confidence="0.989288">
4.2 Scalability
</subsectionHeader>
<bodyText confidence="0.935704444444445">
We repeated the scalability study from Section 3,
now using our pairwise ranking optimization (here-
after, PRO) approach. Throughout all experiments
with PRO we choose Γ = 5000, Ξ = 50, and the
following step function α for each αz: 6
We used MegaM
III, 2004) as a binary
classifier in our contrasting synthetic experiment and
of the
i.e., with all default settings
for binary
Figure 3 shows that PRO
is able to learn
nearly perfectly at all dimension-
alities from 10 to 1000.
As noted previously, though, this is a rather sim-
ple task. To encourage a disconnect between g and
h, and make the synthetic scenario look more like
</bodyText>
<figure confidence="0.86260228">
MT reali
(Daum´e
“out
box,”
classification.7
w∗
ty, we repeated the synthetic experiments
Algorithm
1:
3: Choose (j,
E
uniformly at ran-
dom.
4: With probability
add
to V .
5: Sort V decreasingly by
6: return (x(i, j)
x(i,
and (x(i,
j),
j))) for
each of the first
members
I, J, f, e, x) is a finite candidate space; g is a scoring
function;
i are nonnegative integers;
is a func-
tion from the
(Δ,
Γ,Ξ,
αi
nonnegative real numbers to the real interval
[0, 1].
i,
):
also in Figure 3 (the lines labeled
show
that the pairwise ranking approach is less successful
than before at learning
at high dimensionality,
“Noisy”),
w∗
greatly outperforms MERT.
2: for
samplings do
4.3 Discussion
�0 if n &lt; 0.05
α(n) =
1 otherwise
</figure>
<bodyText confidence="0.987391615384616">
obtained these parameters by trial-and-error experi-
mentation on a single MT system (Urdu-English SBMT), then
held them fixed throughout our experiments. We obtained sim-
ilar results using P =
= 100, and for each
a logistic sig-
moid function centered at the mean g differential of candidate
translation pairs for the ith source sentence. This alternative ap-
proach has the advantage of being agnostic about which gold
scoring function is used.
the sampling settings previously described and
MegaM as our classifier we were able to optimize two to three
times faster than with
</bodyText>
<figure confidence="0.484585708333333">
6We
Ξ
αi,
7With
MERT’s line optimization.
ran it
that our primary goal is to ensure good translations are preferred
to bad translations, and not to tease apart small differences.
1356
SAMPLERs,g(Γ,Ξ,
αz
V = ()
Γ
j0)
J(i)xJ(i)
αz(|g(i,j)-g(i,j0)|),
(x(i,j),x(i,j0),|g(i,j)-g(i,j0)|)
|g(i,j)-g(i,j0)|.
−
j0),sign(g(i,j)-g(i,j0))
j0)-x(i,
sign(g(i,j0)-g(i,
Ξ
of V .
</figure>
<figureCaption confidence="0.97376">
Figure 4: Pseudocode for our sampler. Arguments: s =
</figureCaption>
<bodyText confidence="0.998251538461538">
but added noise to each feature vector, drawn from
a zero-mean Gaussian with a standard deviation of
500. The results of the noisy synthetic experiments,
but still
The idea of learning from difference vectors also lies
at the heart of the MIRA-based approaches (Watan-
abe et al., 2007; Chiang et al., 2008b) and the ap-
proach of Roth et al. (2010), which, similar to our
method, uses sampling to select vectors. Here, we
isolate these aspects of those approaches to create
a simpler tuning technique that closely mirrors the
ubiquitous MERT architecture. Among other sim-
plifications, we abstract away the choice of MIRA
as the classification method (our approach can use
any classification technique that learns a separating
hyperplane), and we eliminate the need for oracle
translations.
An important observation is that BLEU does not
satisfy the decomposability assumption of Equa-
tion (1). An advantage of MERT is that it can di-
rectly optimize for non-decomposable scoring func-
tions like BLEU. In our experiments, we use
the BLEU+1 approximation to BLEU (Liang et al.,
2006) to determine class labels. We will nevert
he-
less use BLEU to evaluate the trained systems.
</bodyText>
<table confidence="0.9997656">
PBMT SBMT
Language Experiment BLEU tune test Experiment BLEU
feats method Language feats method tune test
Urdu-English MERT 20.5 17.7 Urdu-English MERT 23.4 21.4
base MIRA 20.5 17.9 base MIRA 23.6 22.3
PRO 20.4 18.2 PRO 23.4 22.2
MIRA 21.8 17.8 MIRA 25.2 22.8
ext PRO 21.6 18.1 ext PRO 24.2 22.8
Arabic-English MERT 46.8 41.2 Arabic-English MERT 44.7 39.0
base MIRA 47.0 41.1 base MIRA 44.6 39.0
PRO 46.9 41.1 PRO 44.5 39.0
MIRA 47.5 41.7 48.5 41.9 MIRA 45.8 39.8
ext ext 45.9 40.3
PRO PRO
Chinese-English MERT 23.8 22.2 Chinese-English MERT 25.5 22.7
base MIRA 24.1 22.5 base MIRA 25.4 22.9
PRO 23.8 22.5 PRO 25.5 22.9
MIRA 24.8 22.6 24.9 22.7 MIRA 26.0 23.3
ext ext 25.6 23.5
PRO PRO
</table>
<tableCaption confidence="0.9926565">
Table 1: Machine translation performance for the experiments listed in this paper. Scores are case-sensitive IBM
BLEU. For every choice of system, language pair, and feature set, PRO performs comparably with the other methods.
</tableCaption>
<sectionHeader confidence="0.998953" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999984928571429">
We now turn to real machine translation condi-
tions to validate our thesis: We can cleanly replace
MERT’s line optimization with pairwise ranking op-
timization and immediately realize the benefits of
high-dimension tuning. We now detail the three
language pairs, two feature scenarios, and two MT
models used for our experiments. For each language
pair and each MT model we used MERT, MIRA, and
PRO to tune with a standard set of baseline features,
and used the latter two methods to tune with an ex-
tended set of features.8 At the end of every experi-
ment we used the final feature weights to decode a
held-out test set and evaluated it with case-sensitive
BLEU. The results are in Table 1.
</bodyText>
<subsectionHeader confidence="0.977576">
5.1 Systems
</subsectionHeader>
<bodyText confidence="0.9964172">
We used two systems, each based on a different MT
model. Our syntax-based system (hereafter, SBMT)
follows the model of Galley et al. (2004). Our
8MERT could not run to a satisfactory completion in any
extended feature scenario; as implied in the synthetic data ex-
periment of Section 3, the algorithm makes poor choices for
its weights and this leads to low-quality k-best lists and dismal
performance, near 0 BLEU in every iteration.
phrase-based system (hereafter, PBMT) follows the
model of Och and Ney (2004). In both systems
we learn alignments with GIZA++ (Och and Ney,
2000) using IBM Model 4; for Urdu-English and
Chinese-English we merged alignments with the re-
fined method, and for Arabic-English we merged
with the union method.
</bodyText>
<subsectionHeader confidence="0.995166">
5.2 Data
</subsectionHeader>
<bodyText confidence="0.988853666666667">
Table 2 notes the sizes of the datasets used in our ex-
periments. All tune and test data have four English
reference sets for the purposes of scoring.
</bodyText>
<table confidence="0.9993917">
Data U-E A-E C-E
lines 515K 6.5M 7.9M
Train 2.2M 175M 173M
words
lines 923 1994 1615
Tune 16K 65K 42K
words
lines 938 1357 1357
Test 18K 47K 37K
words
</table>
<tableCaption confidence="0.9604175">
Table 2: Data sizes for the experiments reported in this
paper (English words shown).
</tableCaption>
<page confidence="0.810798">
1357
</page>
<table confidence="0.999801090909091">
Class Urdu-English Arabic-English Chinese-English
PBMT SBMT PBMT SBMT PBMT SBMT
base ext base ext base ext base ext base ext base ext
baseline 15 15 19 19 15 15 19 19 15 15 19 19
target word – 51 – 50 – 51 – 50 – 51 – 299
discount – 11 – 11 – 11 – 10 – 11 – 10
node count – – – 99 – – – 138 – – – 96
rule overlap – – – 98 – – – 136 – – – 93
word pair – 2110 – – – 6193 – – – 1688 – –
phrase length – 63 – – – 63 – – – 63 – –
total 15 2250 19 277 15 6333 18 352 15 1828 19 517
</table>
<tableCaption confidence="0.999844">
Table 3: Summary of features used in experiments in this paper.
</tableCaption>
<subsectionHeader confidence="0.768228">
5.2.1 Urdu-English
</subsectionHeader>
<bodyText confidence="0.9999551">
The training data for Urdu-English is that made
available in the constrained track in the NIST 2009
MT evaluation. This includes many lexicon entries
and other single-word data, which accounts for the
large number of lines relative to word count. The
NIST 2008 evaluation set, which contains newswire
and web data, is split into two parts; we used roughly
half each for tune and test. We trained a 5-gram
English language model on the English side of the
training data.
</bodyText>
<subsectionHeader confidence="0.938231">
5.2.2 Arabic-English
</subsectionHeader>
<bodyText confidence="0.9999303">
The training data for Arabic English is that made
available in the constrained track in the NIST 2008
MT evaluation. The tune set, which contains only
newswire data, is a mix from NIST MT evaluation
sets from 2003–2006 and from GALE development
data. The test set, which contains both web and
newswire data, is the evaluation set from the NIST
2008 MT evaluation. We trained a 4-gram English
language model on the English side of the training
data.
</bodyText>
<subsectionHeader confidence="0.941612">
5.2.3 Chinese-English
</subsectionHeader>
<bodyText confidence="0.999774272727273">
For Chinese-English we used 173M words of
training data from GALE 2008. For SBMT we used
a 32M word subset for extracting rules and building
a language model, but used the entire training data
for alignments, and for all PBMT training. The tune
and test sets both contain web and newswire data.
The tune set is selected from NIST MT evaluation
sets from 2003–2006. The test set is the evaluation
set from the NIST 2008 MT evaluation. We trained a
3-gram English language model on the English side
of the training data.
</bodyText>
<subsectionHeader confidence="0.898934">
5.3 Features
</subsectionHeader>
<bodyText confidence="0.999383272727273">
For each of our systems we identify two feature sets:
baseline, which correspond to the typical small fea-
ture set reported in current MT literature, and ex-
tended, a superset of baseline, which adds hundreds
or thousands of features. Specifically, we use 15
baseline features for PBMT, similar to the baseline
features described by Watanabe et al. (2007). We
use 19 baseline features for SBMT, similar to the
baseline features described by Chiang et al. (2008b).
We used the following feature classes in SBMT
and PBMT extended scenarios:
</bodyText>
<listItem confidence="0.988727333333333">
• Discount features for rule frequency bins (cf.
Chiang et al. (2009), Section 4.1)
• Target word insertion features9
</listItem>
<bodyText confidence="0.996917">
We used the following feature classes in SBMT ex-
tended scenarios only (cf. Chiang et al. (2009), Sec-
tion 4.1):10
</bodyText>
<listItem confidence="0.998294">
• Rule overlap features
• Node count features
</listItem>
<footnote confidence="0.988994857142857">
9For Chinese-English and Urdu-English SBMT these fea-
tures only fired when the inserted target word was unaligned to
any source word.
10The parser used for Arabic-English had a different nonter-
minal set than that used for the other two SBMT systems, ac-
counting for the wide disparity in feature count for these feature
classes.
</footnote>
<page confidence="0.991049">
1358
</page>
<figureCaption confidence="0.9991455">
Figure 5: Comparison of MERT, PRO, and MIRA on tuning Urdu-English SBMT systems, and test results at every
iteration. PRO performs comparably to MERT and MIRA.
</figureCaption>
<bodyText confidence="0.9969925">
We used the following feature classes in PBMT
extended scenarios only:
</bodyText>
<listItem confidence="0.952836">
• Unigram word pair features for the 80 most fre-
quent words in both languages plus tokens for
unaligned and all other words (cf. Watanabe et
al. (2007), Section 3.2.1)11
• Source, target, and joint phrase length fea-
tures from 1 to 7, e.g. “tgt=4”, “src=2”, and
“src/tgt=2,4”
</listItem>
<bodyText confidence="0.999832">
The feature classes and number of features used
within those classes for each language pair are sum-
marized in Table 3.
</bodyText>
<subsectionHeader confidence="0.999601">
5.4 Tuning settings
</subsectionHeader>
<bodyText confidence="0.999913142857143">
Each of the three approaches we compare in this
study has various details associated with it that may
prove useful to those wishing to reproduce our re-
sults. We list choices made for the various tuning
methods here, and note that all our decisions were
made in keeping with best practices for each algo-
rithm.
</bodyText>
<subsectionHeader confidence="0.639085">
5.4.1 MERT
</subsectionHeader>
<bodyText confidence="0.993851875">
We used David Chiang’s CMERT implementation
of MERT that is available with the Moses system
(Koehn et al., 2007). We ran MERT for up to 30 it-
erations, using k = 1500, and stopping early when
11This constitutes 6,723 features in principle (822 − 1 since
“unaligned-unaligned” is not considered) but in practice far
fewer co-occurrences were seen. Table 3 shows the number of
actual unigram word pair features observed in data.
the accumulated k-best list does not change in an it-
eration. In every tuning iteration we ran MERT once
with weights initialized to the last iteration’s chosen
weight set and 19 times with random weights, and
chose the the best of the 20 ending points according
to G on the development set. The G we optimize
is tokenized, lower-cased 4-gram BLEU (Papineni et
al., 2002).
</bodyText>
<subsectionHeader confidence="0.834107">
5.4.2 MIRA
</subsectionHeader>
<bodyText confidence="0.99998425">
We for the most part follow the MIRA algorithm
for machine translation as described by Chiang et al.
(2009)12 but instead of using the 10-best of each of
the best hw, hw +g, and hw-g, we use the 30-best
according to hw.13 We use the same sentence-level
BLEU calculated in the context of previous 1-best
translations as Chiang et al. (2008b; 2009). We ran
MIRA for 30 iterations.
</bodyText>
<subsectionHeader confidence="0.784071">
5.4.3 PRO
</subsectionHeader>
<bodyText confidence="0.999671">
We used the MegaM classifier and sampled as de-
scribed in Section 4.2. As previously noted, we used
BLEU+1 (Liang et al., 2006) for g. MegaM was easy
to set up and ran fairly quickly, however any linear
binary classifier that operates on real-valued features
can be used, and in fact we obtained similar results
</bodyText>
<footnote confidence="0.939112428571429">
12and acknowledge the use of David Chiang’s code
13This is a more realistic scenario for would-be implementers
of MIRA, as obtaining the so-called “hope” and “fear” transla-
tions from the lattice or forest is significantly more complicated
than simply obtaining a k-best list. Other tests comparing these
methods have shown between 0.1 to 0.3 BLEU drop using 30-
best hw on Chinese-English (Wang, 2011).
</footnote>
<page confidence="0.996228">
1359
</page>
<bodyText confidence="0.999356">
using the support vector machine module of WEKA
(Hall et al., 2009) as well as the Stanford classifier
(Manning and Klein, 2003). We ran for up to 30 iter-
ations and used the same k and stopping criterion as
was used for MERT, though variability of sampling
precluded list convergence.
While MERT and MIRA use each iteration’s final
weights as a starting point for hill-climbing the next
iteration, the pairwise ranking approach has no ex-
plicit tie to previous iterations. To incorporate such
stability into our process we interpolated the weights
w&apos; learned by the classifier in iteration t with those
from iteration t − 1 by a factor of Ψ, such that
wt = Ψ · w&apos; + (1 − Ψ) · wt−1. We found Ψ = 0.1
gave good performance across the board.
</bodyText>
<subsectionHeader confidence="0.921053">
5.5 Discussion
</subsectionHeader>
<bodyText confidence="0.99999125">
We implore the reader to avoid the natural tendency
to compare results using baseline vs. extended fea-
tures or between PBMT and SBMT on the same lan-
guage pair. Such discussions are indeed interesting,
and could lead to improvements in feature engineer-
ing or sartorial choices due to the outcome of wagers
(Goodale, 2008), but they distract from our thesis.
As can be seen in Table 1, for each of the 12 choices
of system, language pair, and feature set, the PRO
method performed nearly the same as or better than
MIRA and MERT on test data.
In Figure 5 we show the tune and test BLEU us-
ing the weights learned at every iteration for each
Urdu-English SBMT experiment. Typical of the rest
of the experiments, we can clearly see that PRO ap-
pears to proceed more monotonically than the other
methods. We quantified PRO’s stability as compared
to MERT by repeating the Urdu-English baseline
PBMT experiment five times with each configura-
tion. The tune and test BLEU at each iteration is
depicted in Figure 6. The standard deviation of the
final test BLEU of MERT was 0.13 across the five
experiment instances, while PRO had a standard de-
viation of just 0.05.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9995845">
Several works (Shen et al., 2004; Cowan et al.,
2006; Watanabe et al., 2006) have used discrimina-
tive techniques to re-rank k-best lists for MT. Till-
mann and Zhang (2005) used a customized form of
</bodyText>
<figureCaption confidence="0.997295666666667">
Figure 6: Tune and test curves of five repetitions of the
same Urdu-English PBMT baseline feature experiment.
PRO is more stable than MERT.
</figureCaption>
<bodyText confidence="0.999951769230769">
multi-class stochastic gradient descent to learn fea-
ture weights for an MT model. Och and Ney (2002)
used maximum entropy to tune feature weights but
did not compare pairs of derivations. Ittycheriah and
Roukos (2005) used a maximum entropy classifier to
train an alignment model using hand-labeled data.
Xiong et al. (2006) also used a maximum entropy
classifier, in this case to train the reordering com-
ponent of their MT model. Lattice- and hypergraph-
based variants of MERT (Macherey et al., 2008; Ku-
mar et al., 2009) are more stable than traditional
MERT, but also require significant engineering ef-
forts.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999267">
We have described a simple technique for tuning
an MT system that is on par with the leading tech-
niques, exhibits reliable behavior, scales gracefully
to high-dimension feature spaces, and is remark-
ably easy to implement. We have demonstrated, via
a litany of experiments, that our claims are valid
and that this technique is widely applicable. It is
our hope that the adoption of PRO tuning leads to
fewer headaches during tuning and motivates ad-
vanced MT feature engineering research.
</bodyText>
<sectionHeader confidence="0.998814" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999524166666667">
Thanks to Markus Dreyer, Kevin Knight, Saiyam
Kohli, Greg Langmead, Daniel Marcu, Dragos
Munteanu, and Wei Wang for their assistance.
Thanks also to the anonymous reviewers, especially
the reviewer who implemented PRO during the re-
view period and replicated our results.
</bodyText>
<page confidence="0.988559">
1360
</page>
<sectionHeader confidence="0.996324" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998609009523809">
Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier,
Matt Deeds, Nicole Hamilton, and Greg Hullender.
2005. Learning to rank using gradient descent. In Pro-
ceedings of the 22nd International Conference on Ma-
chine Learning, ICML ’05, pages 89–96, Bonn, Ger-
many. ACM.
Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and
Hang Li. 2007. Learning to rank: From pairwise
approach to listwise approach. In Proceedings of the
24th International Conference on Machine Learning,
pages 129–136, Corvalis, OR.
Samidh Chatterjee and Nicola Cancedda. 2010. Mini-
mum error rate training by sampling the translation lat-
tice. In Proceedings of the 2010 Conference on Empir-
ical Methods in Natural Language Processing, pages
606–615, Cambridge, MA, October. Association for
Computational Linguistics.
Wei Chen, Tie-Yan Liu, Yanyan Lan, Zhi-Ming Ma, and
Hang Li. 2009. Ranking measures and loss functions
in learning to rank. In Y. Bengio, D. Schuurmans,
J. Lafferty, C. K. I. Williams, and A. Culotta, editors,
Advances in Neural Information Processing Systems
22, pages 315–323.
David Chiang, Steve DeNeefe, Yee Seng Chan, and
Hwee Tou Ng. 2008a. Decomposability of transla-
tion metrics for improved evaluation and efficient al-
gorithms. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing,
pages 610–619, Honolulu, HI, October. Association
for Computational Linguistics.
David Chiang, Yuval Marton, and Philip Resnik. 2008b.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the 2008
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 224–233, Honolulu, HI, Oc-
tober. Association for Computational Linguistics.
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 new features for statistical machine transla-
tion. In Proceedings of Human Language Technolo-
gies: The 2009Annual Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics, pages 218–226, Boulder, CO, June. Associa-
tion for Computational Linguistics.
David Chiang. 2010. Learning to translate with source
and target syntax. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 1443–1452, Uppsala, Sweden, July. Asso-
ciation for Computational Linguistics.
Brooke Cowan, Ivona Ku˘cerov´a, and Michael Collins.
2006. A discriminative model for tree-to-tree trans-
lation. In Proceedings of the 2006 Conference on
Empirical Methods in Natural Language Processing,
pages 232–241, Sydney, Australia, July. Association
for Computational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultraconserva-
tive online algorithms for multiclass problems. Jour-
nal of Machine Learning Research, 3:951–991.
Hal Daum´e III. 2004. Notes on CG and LM-BFGS
optimization of logistic regression. Paper available at
http://pub.hal3.name#daume04cg-bfgs,
implementation available at http://hal3.name/
megam/, August.
Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram
Singer. 2003. An efficient boosting algorithm for
combining preferences. Journal of Machine Learning
Research, 4:933–969.
Michel Galley, Mark Hopkins, Kevin Knight, and Daniel
Marcu. 2004. What’s in a translation rule? In HLT-
NAACL 2004: Main Proceedings, pages 273–280,
Boston, MA, May. Association for Computational Lin-
guistics.
Gloria Goodale. 2008. Language Weaver: fast
in translation. The Christian Science Monitor,
October 1. http://www.csmonitor.com/
Innovation/Tech-Culture/2008/1001/
language-weaver-fast-in-translation.
Jan Hajiˇc, Sandra Carberry, Stephen Clark, and Joakim
Nivre, editors. 2010. Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics. Association for Computational Linguistics, Upp-
sala, Sweden, July.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The WEKA data mining software: An update.
SIGKDD Explorations, 11(1).
Ralf Herbrich, Thore Graepel, and Klaus Obermayer.
1999. Support vector learning for ordinal regression.
In Proceedings of the 1999 International Conference
on Artificial Neural Networks, pages 97–102.
Abraham Ittycheriah and Salim Roukos. 2005. A max-
imum entropy word aligner for Arabic-English ma-
chine translation. In Proceedings of Human Language
Technology Conference and Conference on Empiri-
cal Methods in Natural Language Processing, pages
89–96, Vancouver, Canada, October. Association for
Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the Association for
Computational Linguistics Companion Volume Pro-
ceedings of the Demo and Poster Sessions, pages 177–
</reference>
<page confidence="0.817049">
1361
</page>
<reference confidence="0.999903160377358">
180, Prague, Czech Republic, June. Association for
Computational Linguistics.
Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate train-
ing and minimum bayes-risk decoding for translation
hypergraphs and lattices. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL and
the 4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP, pages 163–171, Sun-
tec, Singapore, August. Association for Computational
Linguistics.
Alon Lavie and Michael J. Denkowski. 2009. The
METEOR metric for automatic evaluation of machine
translation. Machine Translation, 23(2–3):105–115,
September.
Percy Liang, Alexandre Bouchard-Cˆot´e, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative ap-
proach to machine translation. In Proceedings of the
21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Association
for Computational Linguistics, pages 761–768, Syd-
ney, Australia, July. Association for Computational
Linguistics.
Wolfgang Macherey, Franz Josef Och, Ignacio Thayer,
and Jakob Uszkoreit. 2008. Lattice-based minimum
error rate training for statistical machine translation.
In Proceedings of the 2008 Conference on Empirical
Methods in Natural Language Processing, pages 725–
734, Honolulu, HI, October. Association for Compu-
tational Linguistics.
Christopher Manning and Dan Klein. 2003. Optimiza-
tion, maxent models, and conditional estimation with-
out magic. Tutorial at HLT-NAACL 2003 and ACL
2003.
I. Dan Melamed, Ryan Green, and Joseph P. Turian.
2003. Precision and recall of machine translation. In
Companion Volume of the Proceedings of HLT-NAACL
2003 - Short Papers, pages 61–63, Edmonton, Canada,
May–June. Association for Computational Linguis-
tics.
Franz Och and Hermann Ney. 2000. Improved statistical
alignment models. In Proceedings of the 38th Annual
Meeting of the Association for Computational Linguis-
tics, pages 440–447, Hong Kong, October.
Franz Josef Och and Hermann Ney. 2002. Discrimi-
native training and maximum entropy models for sta-
tistical machine translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 295–302, Philadelphia, PA, July.
Association for Computational Linguistics.
Franz Och and Hermann Ney. 2004. The alignment tem-
plate approach to statistical machine translation. Com-
putational Linguistics, 30(4):417–449.
Franz Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proceedings of the 41st
Annual Meeting of the Association for Computational
Linguistics, pages 160–167, Sapporo, Japan, July. As-
sociation for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318, Philadelphia, PA,
July. Association for Computational Linguistics.
Benjamin Roth, Andrew McCallum, Marc Dymetman,
and Nicola Cancedda. 2010. Machine translation us-
ing overlapping alignments and samplerank. In Pro-
ceedings ofAssociation for Machine Translation in the
Americas, Denver, CO.
Libin Shen, Anoop Sarkar, and Franz Josef Och. 2004.
Discriminative reranking for machine translation. In
Daniel Marcu Susan Dumais and Salim Roukos, ed-
itors, HLT-NAACL 2004: Main Proceedings, pages
177–184, Boston, MA, May 2 - May 7. Association
for Computational Linguistics.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings ofAssociation forMachine Translation
in the Americas, pages 223–231.
Christoph Tillmann and Tong Zhang. 2005. A localized
prediction model for statistical machine translation. In
Proceedings of the 43rd Annual Meeting of the ACL,
pages 557–564, Ann Arbor, MI, June. Association for
Computational Linguistics.
Wei Wang. 2011. Personal communication.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2006. NTT statistical machine translation for
IWSLT 2006. In Proceedings of IWSLT 2006, pages
95–102.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2007. Online large-margin training for sta-
tistical machine translation. In Proceedings of the
2007 Joint Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL), pages 764–
773, Prague, Czech Republic, June. Association for
Computational Linguistics.
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for sta-
tistical machine translation. In Proceedings of the 21st
International Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics, pages 521–528, Sydney,
Australia, July. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.994477">
1362
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.961556">
<title confidence="0.999331">Tuning as Ranking</title>
<author confidence="0.999433">Mark Hopkins</author>
<author confidence="0.999433">Jonathan</author>
<affiliation confidence="0.995717">SDL Language</affiliation>
<address confidence="0.974055">Los Angeles, CA</address>
<abstract confidence="0.999512619047619">We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999). Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features. Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement. It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours. We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chris Burges</author>
<author>Tal Shaked</author>
<author>Erin Renshaw</author>
<author>Ari Lazier</author>
<author>Matt Deeds</author>
<author>Nicole Hamilton</author>
<author>Greg Hullender</author>
</authors>
<title>Learning to rank using gradient descent.</title>
<date>2005</date>
<booktitle>In Proceedings of the 22nd International Conference on Machine Learning, ICML ’05,</booktitle>
<pages>89--96</pages>
<publisher>ACM.</publisher>
<location>Bonn, Germany.</location>
<contexts>
<context position="2488" citStr="Burges et al., 2005" startWordPosition="395" endWordPosition="398">technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation. Mindful that many would-be enhancements to the 1The r</context>
<context position="12948" citStr="Burges et al., 2005" startWordPosition="2234" endWordPosition="2237">listic approach will generalize better to unseen data. Assume that the gold scoring function G decomposes in the following way: G(p) =1: g(i,p(i)) (1) iEI where g(i, j) is a local scoring function that scores the single candidate translation e(i, j). We show an example g in Figure 1. For an arbitrary pair of candidate translations e(i, j) and e(i, j&apos;), the local gold function g tells us which is the better translation. Note that this induces a ranking on the candidate translations for each source sentence. We follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007). In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered. Specifically, for candidate translation pair e(i, j) and e(i, j&apos;), we want: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;). We can re-express this condition: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;) ⇔ hw(i, j) − hw(i, j&apos;) &gt; 0 ⇔ w · x(i,j) − w · x(i,j&apos;) &gt; 0 ⇔ w · (x(i, j) − x(i, j&apos;)) &gt; 0 Thus optimization reduces to a classic binary classification problem. We create a labeled training instance for this problem by computing differ</context>
</contexts>
<marker>Burges, Shaked, Renshaw, Lazier, Deeds, Hamilton, Hullender, 2005</marker>
<rawString>Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole Hamilton, and Greg Hullender. 2005. Learning to rank using gradient descent. In Proceedings of the 22nd International Conference on Machine Learning, ICML ’05, pages 89–96, Bonn, Germany. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhe Cao</author>
<author>Tao Qin</author>
<author>Tie-Yan Liu</author>
<author>Ming-Feng Tsai</author>
<author>Hang Li</author>
</authors>
<title>Learning to rank: From pairwise approach to listwise approach.</title>
<date>2007</date>
<booktitle>In Proceedings of the 24th International Conference on Machine Learning,</booktitle>
<pages>129--136</pages>
<location>Corvalis, OR.</location>
<contexts>
<context position="2507" citStr="Cao et al., 2007" startWordPosition="399" endWordPosition="402">and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation. Mindful that many would-be enhancements to the 1The remainder either did</context>
<context position="12967" citStr="Cao et al., 2007" startWordPosition="2238" endWordPosition="2241">generalize better to unseen data. Assume that the gold scoring function G decomposes in the following way: G(p) =1: g(i,p(i)) (1) iEI where g(i, j) is a local scoring function that scores the single candidate translation e(i, j). We show an example g in Figure 1. For an arbitrary pair of candidate translations e(i, j) and e(i, j&apos;), the local gold function g tells us which is the better translation. Note that this induces a ranking on the candidate translations for each source sentence. We follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007). In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered. Specifically, for candidate translation pair e(i, j) and e(i, j&apos;), we want: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;). We can re-express this condition: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;) ⇔ hw(i, j) − hw(i, j&apos;) &gt; 0 ⇔ w · x(i,j) − w · x(i,j&apos;) &gt; 0 ⇔ w · (x(i, j) − x(i, j&apos;)) &gt; 0 Thus optimization reduces to a classic binary classification problem. We create a labeled training instance for this problem by computing difference vector x(i, j)</context>
</contexts>
<marker>Cao, Qin, Liu, Tsai, Li, 2007</marker>
<rawString>Zhe Cao, Tao Qin, Tie-Yan Liu, Ming-Feng Tsai, and Hang Li. 2007. Learning to rank: From pairwise approach to listwise approach. In Proceedings of the 24th International Conference on Machine Learning, pages 129–136, Corvalis, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samidh Chatterjee</author>
<author>Nicola Cancedda</author>
</authors>
<title>Minimum error rate training by sampling the translation lattice.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>606--615</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="11863" citStr="Chatterjee and Cancedda, 2010" startWordPosition="2051" endWordPosition="2054"> performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009). Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted. Our goal is to achieve the same performance with minimal modification to MERT. With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both. Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minimize divergence from the established MERT tuning architecture. Instead, we focus on the optimization phase. 4.1 Basic Approach While intuitive, the MERT optimization module focuses attention on Hw’s best policy, and not on its overall prowess at ranking policies. We will create an optimization module that directly addresses Hw’s ability to rank policies in the hope that this more holistic approach will generalize better to unseen data. Assume that the gold scoring function G decomposes in the following way: G(p) =</context>
</contexts>
<marker>Chatterjee, Cancedda, 2010</marker>
<rawString>Samidh Chatterjee and Nicola Cancedda. 2010. Minimum error rate training by sampling the translation lattice. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 606–615, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Chen</author>
<author>Tie-Yan Liu</author>
<author>Yanyan Lan</author>
<author>Zhi-Ming Ma</author>
<author>Hang Li</author>
</authors>
<title>Ranking measures and loss functions in learning to rank. In</title>
<date>2009</date>
<booktitle>Advances in Neural Information Processing Systems 22,</booktitle>
<pages>315--323</pages>
<editor>Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors,</editor>
<contexts>
<context position="2287" citStr="Chen et al., 2009" startWordPosition="363" endWordPosition="366"> algorithm (Crammer and Singer, 2003) as a nucleus. The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scale</context>
<context position="15070" citStr="Chen et al., 2009" startWordPosition="2606" endWordPosition="2609">s O(|I |∗ J2max) vectors, where Jmax is the cardinality of the largest J(i). Since I and Jmax commonly range in the thousands, a full enumeration would produce billions of feature vectors. Out of tractability considerations, we sample from the space of difference vectors, using the sampler template in Figure 4. For each source sentence i, the sampler generates F candidate translation pairs hj, j&apos;i, and accepts each pair with probability αi(|g(i,j) − g(i, j&apos;)|). Among the accepted pairs, it keeps the Ξ with greatest g differential, and adds their difference vectors to the training data.5 4See (Chen et al., 2009) for a brief survey. 5The intuition for biasing toward high score differential is 1355 Figure 3: Result of synthetic data learning experiment for MERT and PRO, with and without added noise. As the dimensionality increases MERT is unable to learn the original weights but PRO still performs adequately. 4.2 Scalability We repeated the scalability study from Section 3, now using our pairwise ranking optimization (hereafter, PRO) approach. Throughout all experiments with PRO we choose Γ = 5000, Ξ = 50, and the following step function α for each αz: 6 We used MegaM III, 2004) as a binary classifier </context>
</contexts>
<marker>Chen, Liu, Lan, Ma, Li, 2009</marker>
<rawString>Wei Chen, Tie-Yan Liu, Yanyan Lan, Zhi-Ming Ma, and Hang Li. 2009. Ranking measures and loss functions in learning to rank. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I. Williams, and A. Culotta, editors, Advances in Neural Information Processing Systems 22, pages 315–323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Steve DeNeefe</author>
<author>Yee Seng Chan</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Decomposability of translation metrics for improved evaluation and efficient algorithms.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>610--619</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, HI,</location>
<contexts>
<context position="624" citStr="Chiang et al., 2008" startWordPosition="91" endWordPosition="95">g as Ranking Mark Hopkins and Jonathan May SDL Language Weaver Los Angeles, CA 90045 {mhopkins,jmay}@sdl.com Abstract We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999). Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features. Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement. It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours. We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios. 1 Introduction The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system. MERT is well-understood, easy to implement, and runs quickly, but ca</context>
<context position="6551" citStr="Chiang et al., 2008" startWordPosition="1126" endWordPosition="1129">(p) = Ei∈I hw(i, p(i)). As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8. The goal of tuning is to learn a weight vector w such that Hw(p) assigns a high score to good policies, and a low score to bad policies.2 To do so, we need information about which policies are good and which are bad. This information is provided by a “gold” scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a). We want to find a weight vector w such that Hw behaves “similarly” to G on a candidate space s. We assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes over a finite subset of source sentences3 and a finite subset o</context>
<context position="11369" citStr="Chiang et al. (2008" startWordPosition="1978" endWordPosition="1981"> w∗. Note that this synthetic problem is considerably easier than a real MT scenario, where the data is noisy and interdependent, and the gold scoring function is nonlinear. If 1354 MERT cannot scale in this simple scenario, it has little hope of succeeding in a high-dimensionality deployment scenario. 4 Optimization via Pairwise Ranking We would like to modify MERT so that it scales well to high-dimensionality candidate spaces. The most prominent example of a tuning method that performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009). Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted. Our goal is to achieve the same performance with minimal modification to MERT. With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both. Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minimize divergence from the </context>
<context position="18017" citStr="Chiang et al., 2008" startWordPosition="3103" endWordPosition="3106"> are preferred to bad translations, and not to tease apart small differences. 1356 SAMPLERs,g(Γ,Ξ, αz V = () Γ j0) J(i)xJ(i) αz(|g(i,j)-g(i,j0)|), (x(i,j),x(i,j0),|g(i,j)-g(i,j0)|) |g(i,j)-g(i,j0)|. − j0),sign(g(i,j)-g(i,j0)) j0)-x(i, sign(g(i,j0)-g(i, Ξ of V . Figure 4: Pseudocode for our sampler. Arguments: s = but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500. The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors. Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture. Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations. An important observation is that BLEU does not satisfy the decomposability assumption of Equation (1). An advantage o</context>
<context position="24158" citStr="Chiang et al. (2008" startWordPosition="4198" endWordPosition="4201">st set is the evaluation set from the NIST 2008 MT evaluation. We trained a 3-gram English language model on the English side of the training data. 5.3 Features For each of our systems we identify two feature sets: baseline, which correspond to the typical small feature set reported in current MT literature, and extended, a superset of baseline, which adds hundreds or thousands of features. Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007). We use 19 baseline features for SBMT, similar to the baseline features described by Chiang et al. (2008b). We used the following feature classes in SBMT and PBMT extended scenarios: • Discount features for rule frequency bins (cf. Chiang et al. (2009), Section 4.1) • Target word insertion features9 We used the following feature classes in SBMT extended scenarios only (cf. Chiang et al. (2009), Section 4.1):10 • Rule overlap features • Node count features 9For Chinese-English and Urdu-English SBMT these features only fired when the inserted target word was unaligned to any source word. 10The parser used for Arabic-English had a different nonterminal set than that used for the other two SBMT syst</context>
<context position="26958" citStr="Chiang et al. (2008" startWordPosition="4678" endWordPosition="4681">e with weights initialized to the last iteration’s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development set. The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002). 5.4.2 MIRA We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009)12 but instead of using the 10-best of each of the best hw, hw +g, and hw-g, we use the 30-best according to hw.13 We use the same sentence-level BLEU calculated in the context of previous 1-best translations as Chiang et al. (2008b; 2009). We ran MIRA for 30 iterations. 5.4.3 PRO We used the MegaM classifier and sampled as described in Section 4.2. As previously noted, we used BLEU+1 (Liang et al., 2006) for g. MegaM was easy to set up and ran fairly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results 12and acknowledge the use of David Chiang’s code 13This is a more realistic scenario for would-be implementers of MIRA, as obtaining the so-called “hope” and “fear” translations from the lattice or forest is significantly more complicated</context>
</contexts>
<marker>Chiang, DeNeefe, Chan, Ng, 2008</marker>
<rawString>David Chiang, Steve DeNeefe, Yee Seng Chan, and Hwee Tou Ng. 2008a. Decomposability of translation metrics for improved evaluation and efficient algorithms. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 610–619, Honolulu, HI, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>224--233</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, HI,</location>
<contexts>
<context position="624" citStr="Chiang et al., 2008" startWordPosition="91" endWordPosition="95">g as Ranking Mark Hopkins and Jonathan May SDL Language Weaver Los Angeles, CA 90045 {mhopkins,jmay}@sdl.com Abstract We offer a simple, effective, and scalable method for statistical machine translation parameter tuning based on the pairwise approach to ranking (Herbrich et al., 1999). Unlike the popular MERT algorithm (Och, 2003), our pairwise ranking optimization (PRO) method is not limited to a handful of parameters and can easily handle systems with thousands of features. Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement. It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours. We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios. 1 Introduction The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system. MERT is well-understood, easy to implement, and runs quickly, but ca</context>
<context position="6551" citStr="Chiang et al., 2008" startWordPosition="1126" endWordPosition="1129">(p) = Ei∈I hw(i, p(i)). As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8. The goal of tuning is to learn a weight vector w such that Hw(p) assigns a high score to good policies, and a low score to bad policies.2 To do so, we need information about which policies are good and which are bad. This information is provided by a “gold” scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a). We want to find a weight vector w such that Hw behaves “similarly” to G on a candidate space s. We assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes over a finite subset of source sentences3 and a finite subset o</context>
<context position="11369" citStr="Chiang et al. (2008" startWordPosition="1978" endWordPosition="1981"> w∗. Note that this synthetic problem is considerably easier than a real MT scenario, where the data is noisy and interdependent, and the gold scoring function is nonlinear. If 1354 MERT cannot scale in this simple scenario, it has little hope of succeeding in a high-dimensionality deployment scenario. 4 Optimization via Pairwise Ranking We would like to modify MERT so that it scales well to high-dimensionality candidate spaces. The most prominent example of a tuning method that performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009). Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted. Our goal is to achieve the same performance with minimal modification to MERT. With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both. Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minimize divergence from the </context>
<context position="18017" citStr="Chiang et al., 2008" startWordPosition="3103" endWordPosition="3106"> are preferred to bad translations, and not to tease apart small differences. 1356 SAMPLERs,g(Γ,Ξ, αz V = () Γ j0) J(i)xJ(i) αz(|g(i,j)-g(i,j0)|), (x(i,j),x(i,j0),|g(i,j)-g(i,j0)|) |g(i,j)-g(i,j0)|. − j0),sign(g(i,j)-g(i,j0)) j0)-x(i, sign(g(i,j0)-g(i, Ξ of V . Figure 4: Pseudocode for our sampler. Arguments: s = but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500. The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors. Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture. Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations. An important observation is that BLEU does not satisfy the decomposability assumption of Equation (1). An advantage o</context>
<context position="24158" citStr="Chiang et al. (2008" startWordPosition="4198" endWordPosition="4201">st set is the evaluation set from the NIST 2008 MT evaluation. We trained a 3-gram English language model on the English side of the training data. 5.3 Features For each of our systems we identify two feature sets: baseline, which correspond to the typical small feature set reported in current MT literature, and extended, a superset of baseline, which adds hundreds or thousands of features. Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007). We use 19 baseline features for SBMT, similar to the baseline features described by Chiang et al. (2008b). We used the following feature classes in SBMT and PBMT extended scenarios: • Discount features for rule frequency bins (cf. Chiang et al. (2009), Section 4.1) • Target word insertion features9 We used the following feature classes in SBMT extended scenarios only (cf. Chiang et al. (2009), Section 4.1):10 • Rule overlap features • Node count features 9For Chinese-English and Urdu-English SBMT these features only fired when the inserted target word was unaligned to any source word. 10The parser used for Arabic-English had a different nonterminal set than that used for the other two SBMT syst</context>
<context position="26958" citStr="Chiang et al. (2008" startWordPosition="4678" endWordPosition="4681">e with weights initialized to the last iteration’s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development set. The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002). 5.4.2 MIRA We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009)12 but instead of using the 10-best of each of the best hw, hw +g, and hw-g, we use the 30-best according to hw.13 We use the same sentence-level BLEU calculated in the context of previous 1-best translations as Chiang et al. (2008b; 2009). We ran MIRA for 30 iterations. 5.4.3 PRO We used the MegaM classifier and sampled as described in Section 4.2. As previously noted, we used BLEU+1 (Liang et al., 2006) for g. MegaM was easy to set up and ran fairly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results 12and acknowledge the use of David Chiang’s code 13This is a more realistic scenario for would-be implementers of MIRA, as obtaining the so-called “hope” and “fear” translations from the lattice or forest is significantly more complicated</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008b. Online large-margin training of syntactic and structural translation features. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 224–233, Honolulu, HI, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Kevin Knight</author>
<author>Wei Wang</author>
</authors>
<title>11,001 new features for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>218--226</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, CO,</location>
<contexts>
<context position="24306" citStr="Chiang et al. (2009)" startWordPosition="4222" endWordPosition="4225"> 5.3 Features For each of our systems we identify two feature sets: baseline, which correspond to the typical small feature set reported in current MT literature, and extended, a superset of baseline, which adds hundreds or thousands of features. Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007). We use 19 baseline features for SBMT, similar to the baseline features described by Chiang et al. (2008b). We used the following feature classes in SBMT and PBMT extended scenarios: • Discount features for rule frequency bins (cf. Chiang et al. (2009), Section 4.1) • Target word insertion features9 We used the following feature classes in SBMT extended scenarios only (cf. Chiang et al. (2009), Section 4.1):10 • Rule overlap features • Node count features 9For Chinese-English and Urdu-English SBMT these features only fired when the inserted target word was unaligned to any source word. 10The parser used for Arabic-English had a different nonterminal set than that used for the other two SBMT systems, accounting for the wide disparity in feature count for these feature classes. 1358 Figure 5: Comparison of MERT, PRO, and MIRA on tuning Urdu-E</context>
<context position="26727" citStr="Chiang et al. (2009)" startWordPosition="4636" endWordPosition="4639">t in practice far fewer co-occurrences were seen. Table 3 shows the number of actual unigram word pair features observed in data. the accumulated k-best list does not change in an iteration. In every tuning iteration we ran MERT once with weights initialized to the last iteration’s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development set. The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002). 5.4.2 MIRA We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009)12 but instead of using the 10-best of each of the best hw, hw +g, and hw-g, we use the 30-best according to hw.13 We use the same sentence-level BLEU calculated in the context of previous 1-best translations as Chiang et al. (2008b; 2009). We ran MIRA for 30 iterations. 5.4.3 PRO We used the MegaM classifier and sampled as described in Section 4.2. As previously noted, we used BLEU+1 (Liang et al., 2006) for g. MegaM was easy to set up and ran fairly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results 12and a</context>
</contexts>
<marker>Chiang, Knight, Wang, 2009</marker>
<rawString>David Chiang, Kevin Knight, and Wei Wang. 2009. 11,001 new features for statistical machine translation. In Proceedings of Human Language Technologies: The 2009Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 218–226, Boulder, CO, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Learning to translate with source and target syntax.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1443--1452</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="2106" citStr="Chiang, 2010" startWordPosition="335" endWordPosition="336">innovation. Several researchers have attempted to address this weakness. Recently, Watanabe et al. (2007) and Chiang et al. (2008b) have developed tuning methods using the MIRA algorithm (Crammer and Singer, 2003) as a nucleus. The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique</context>
</contexts>
<marker>Chiang, 2010</marker>
<rawString>David Chiang. 2010. Learning to translate with source and target syntax. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1443–1452, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brooke Cowan</author>
<author>Ivona Ku˘cerov´a</author>
<author>Michael Collins</author>
</authors>
<title>A discriminative model for tree-to-tree translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>232--241</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<marker>Cowan, Ku˘cerov´a, Collins, 2006</marker>
<rawString>Brooke Cowan, Ivona Ku˘cerov´a, and Michael Collins. 2006. A discriminative model for tree-to-tree translation. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 232–241, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="1706" citStr="Crammer and Singer, 2003" startWordPosition="266" endWordPosition="269">y to tune the parameters of a statistical machine translation (MT) system. MERT is well-understood, easy to implement, and runs quickly, but can behave erratically and does not scale beyond a handful of features. This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation. Several researchers have attempted to address this weakness. Recently, Watanabe et al. (2007) and Chiang et al. (2008b) have developed tuning methods using the MIRA algorithm (Crammer and Singer, 2003) as a nucleus. The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explici</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
</authors>
<title>Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://pub.hal3.name#daume04cg-bfgs, implementation available at http://hal3.name/ megam/,</title>
<date>2004</date>
<marker>Daum´e, 2004</marker>
<rawString>Hal Daum´e III. 2004. Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://pub.hal3.name#daume04cg-bfgs, implementation available at http://hal3.name/ megam/, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Raj Iyer</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>An efficient boosting algorithm for combining preferences.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>4--933</pages>
<contexts>
<context position="2467" citStr="Freund et al., 2003" startWordPosition="391" endWordPosition="394">(2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation. Mindful that many would-be enhan</context>
<context position="12927" citStr="Freund et al., 2003" startWordPosition="2230" endWordPosition="2233">ope that this more holistic approach will generalize better to unseen data. Assume that the gold scoring function G decomposes in the following way: G(p) =1: g(i,p(i)) (1) iEI where g(i, j) is a local scoring function that scores the single candidate translation e(i, j). We show an example g in Figure 1. For an arbitrary pair of candidate translations e(i, j) and e(i, j&apos;), the local gold function g tells us which is the better translation. Note that this induces a ranking on the candidate translations for each source sentence. We follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007). In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered. Specifically, for candidate translation pair e(i, j) and e(i, j&apos;), we want: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;). We can re-express this condition: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;) ⇔ hw(i, j) − hw(i, j&apos;) &gt; 0 ⇔ w · x(i,j) − w · x(i,j&apos;) &gt; 0 ⇔ w · (x(i, j) − x(i, j&apos;)) &gt; 0 Thus optimization reduces to a classic binary classification problem. We create a labeled training instance for this proble</context>
</contexts>
<marker>Freund, Iyer, Schapire, Singer, 2003</marker>
<rawString>Yoav Freund, Raj Iyer, Robert E. Schapire, and Yoram Singer. 2003. An efficient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In HLTNAACL 2004: Main Proceedings,</booktitle>
<pages>273--280</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boston, MA,</location>
<contexts>
<context position="20646" citStr="Galley et al. (2004)" startWordPosition="3548" endWordPosition="3551"> We now detail the three language pairs, two feature scenarios, and two MT models used for our experiments. For each language pair and each MT model we used MERT, MIRA, and PRO to tune with a standard set of baseline features, and used the latter two methods to tune with an extended set of features.8 At the end of every experiment we used the final feature weights to decode a held-out test set and evaluated it with case-sensitive BLEU. The results are in Table 1. 5.1 Systems We used two systems, each based on a different MT model. Our syntax-based system (hereafter, SBMT) follows the model of Galley et al. (2004). Our 8MERT could not run to a satisfactory completion in any extended feature scenario; as implied in the synthetic data experiment of Section 3, the algorithm makes poor choices for its weights and this leads to low-quality k-best lists and dismal performance, near 0 BLEU in every iteration. phrase-based system (hereafter, PBMT) follows the model of Och and Ney (2004). In both systems we learn alignments with GIZA++ (Och and Ney, 2000) using IBM Model 4; for Urdu-English and Chinese-English we merged alignments with the refined method, and for Arabic-English we merged with the union method. </context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In HLTNAACL 2004: Main Proceedings, pages 273–280, Boston, MA, May. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gloria Goodale</author>
</authors>
<title>Language Weaver: fast in translation.</title>
<date>2008</date>
<booktitle>The Christian Science Monitor, October 1. http://www.csmonitor.com/ Innovation/Tech-Culture/2008/1001/</booktitle>
<pages>language-weaver-fast-in-translation.</pages>
<contexts>
<context position="28801" citStr="Goodale, 2008" startWordPosition="5000" endWordPosition="5001"> iterations. To incorporate such stability into our process we interpolated the weights w&apos; learned by the classifier in iteration t with those from iteration t − 1 by a factor of Ψ, such that wt = Ψ · w&apos; + (1 − Ψ) · wt−1. We found Ψ = 0.1 gave good performance across the board. 5.5 Discussion We implore the reader to avoid the natural tendency to compare results using baseline vs. extended features or between PBMT and SBMT on the same language pair. Such discussions are indeed interesting, and could lead to improvements in feature engineering or sartorial choices due to the outcome of wagers (Goodale, 2008), but they distract from our thesis. As can be seen in Table 1, for each of the 12 choices of system, language pair, and feature set, the PRO method performed nearly the same as or better than MIRA and MERT on test data. In Figure 5 we show the tune and test BLEU using the weights learned at every iteration for each Urdu-English SBMT experiment. Typical of the rest of the experiments, we can clearly see that PRO appears to proceed more monotonically than the other methods. We quantified PRO’s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with e</context>
</contexts>
<marker>Goodale, 2008</marker>
<rawString>Gloria Goodale. 2008. Language Weaver: fast in translation. The Christian Science Monitor, October 1. http://www.csmonitor.com/ Innovation/Tech-Culture/2008/1001/ language-weaver-fast-in-translation.</rawString>
</citation>
<citation valid="true">
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics,</booktitle>
<editor>Jan Hajiˇc, Sandra Carberry, Stephen Clark, and Joakim Nivre, editors.</editor>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="18058" citStr="(2010)" startWordPosition="3115" endWordPosition="3115">part small differences. 1356 SAMPLERs,g(Γ,Ξ, αz V = () Γ j0) J(i)xJ(i) αz(|g(i,j)-g(i,j0)|), (x(i,j),x(i,j0),|g(i,j)-g(i,j0)|) |g(i,j)-g(i,j0)|. − j0),sign(g(i,j)-g(i,j0)) j0)-x(i, sign(g(i,j0)-g(i, Ξ of V . Figure 4: Pseudocode for our sampler. Arguments: s = but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500. The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors. Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture. Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations. An important observation is that BLEU does not satisfy the decomposability assumption of Equation (1). An advantage of MERT is that it can directly optimize f</context>
</contexts>
<marker>2010</marker>
<rawString>Jan Hajiˇc, Sandra Carberry, Stephen Clark, and Joakim Nivre, editors. 2010. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: An update.</title>
<date>2009</date>
<journal>SIGKDD Explorations,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="27795" citStr="Hall et al., 2009" startWordPosition="4819" endWordPosition="4822">airly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results 12and acknowledge the use of David Chiang’s code 13This is a more realistic scenario for would-be implementers of MIRA, as obtaining the so-called “hope” and “fear” translations from the lattice or forest is significantly more complicated than simply obtaining a k-best list. Other tests comparing these methods have shown between 0.1 to 0.3 BLEU drop using 30- best hw on Chinese-English (Wang, 2011). 1359 using the support vector machine module of WEKA (Hall et al., 2009) as well as the Stanford classifier (Manning and Klein, 2003). We ran for up to 30 iterations and used the same k and stopping criterion as was used for MERT, though variability of sampling precluded list convergence. While MERT and MIRA use each iteration’s final weights as a starting point for hill-climbing the next iteration, the pairwise ranking approach has no explicit tie to previous iterations. To incorporate such stability into our process we interpolated the weights w&apos; learned by the classifier in iteration t with those from iteration t − 1 by a factor of Ψ, such that wt = Ψ · w&apos; + (1</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The WEKA data mining software: An update. SIGKDD Explorations, 11(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Herbrich</author>
<author>Thore Graepel</author>
<author>Klaus Obermayer</author>
</authors>
<title>Support vector learning for ordinal regression.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 International Conference on Artificial Neural Networks,</booktitle>
<pages>97--102</pages>
<contexts>
<context position="2446" citStr="Herbrich et al., 1999" startWordPosition="387" endWordPosition="390"> thousands of features (2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to high-dimensional feature spaces. We cast tuning as a ranking problem (Chen et al., 2009), where the explicit goal is to learn to correctly rank candidate translations. Specifically, we follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007), in which the ranking problem is reduced to the binary classification task of deciding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation. Mindful tha</context>
<context position="12906" citStr="Herbrich et al., 1999" startWordPosition="2225" endWordPosition="2229"> rank policies in the hope that this more holistic approach will generalize better to unseen data. Assume that the gold scoring function G decomposes in the following way: G(p) =1: g(i,p(i)) (1) iEI where g(i, j) is a local scoring function that scores the single candidate translation e(i, j). We show an example g in Figure 1. For an arbitrary pair of candidate translations e(i, j) and e(i, j&apos;), the local gold function g tells us which is the better translation. Note that this induces a ranking on the candidate translations for each source sentence. We follow the pairwise approach to ranking (Herbrich et al., 1999; Freund et al., 2003; Burges et al., 2005; Cao et al., 2007). In the pairwise approach, the learning task is framed as the classification of candidate pairs into two categories: correctly ordered and incorrectly ordered. Specifically, for candidate translation pair e(i, j) and e(i, j&apos;), we want: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;). We can re-express this condition: g(i,j) &gt; g(i,j&apos;) ⇔ hw(i,j) &gt; hw(i,j&apos;) ⇔ hw(i, j) − hw(i, j&apos;) &gt; 0 ⇔ w · x(i,j) − w · x(i,j&apos;) &gt; 0 ⇔ w · (x(i, j) − x(i, j&apos;)) &gt; 0 Thus optimization reduces to a classic binary classification problem. We create a labeled training ins</context>
</contexts>
<marker>Herbrich, Graepel, Obermayer, 1999</marker>
<rawString>Ralf Herbrich, Thore Graepel, and Klaus Obermayer. 1999. Support vector learning for ordinal regression. In Proceedings of the 1999 International Conference on Artificial Neural Networks, pages 97–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abraham Ittycheriah</author>
<author>Salim Roukos</author>
</authors>
<title>A maximum entropy word aligner for Arabic-English machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>89--96</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, Canada,</location>
<contexts>
<context position="30205" citStr="Ittycheriah and Roukos (2005)" startWordPosition="5244" endWordPosition="5247">instances, while PRO had a standard deviation of just 0.05. 6 Related Work Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of Figure 6: Tune and test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts. 7 Conclusion We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is re</context>
</contexts>
<marker>Ittycheriah, Roukos, 2005</marker>
<rawString>Abraham Ittycheriah and Salim Roukos. 2005. A maximum entropy word aligner for Arabic-English machine translation. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 89–96, Vancouver, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="3209" citStr="Koehn et al., 2007" startWordPosition="515" endWordPosition="518">ding between candidate translation pairs. Of primary concern to us is the ease of adoption of our proposed technique. Because of this, we adhere as closely as possible to the established MERT architecture and use freely available machine learning software. The end result is a technique that scales and performs just as well as MIRA-based tuning, but which can be implemented in a couple of hours by anyone with an existing MERT implementation. Mindful that many would-be enhancements to the 1The remainder either did not specify their tuning method (though a number of these used the Moses toolkit (Koehn et al., 2007), which uses MERT for tuning) or, in one case, set weights by hand. 1352 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352–1362, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics state-of-the-art are false positives that only show improvement in a narrowly defined setting or with limited data, we validate our claims on both syntax and phrase-based systems, using multiple language pairs and large data sets. We describe tuning in abstract and somewhat formal terms in Section 2, describe the MERT algorithm </context>
<context position="25923" citStr="Koehn et al., 2007" startWordPosition="4497" endWordPosition="4500"> to 7, e.g. “tgt=4”, “src=2”, and “src/tgt=2,4” The feature classes and number of features used within those classes for each language pair are summarized in Table 3. 5.4 Tuning settings Each of the three approaches we compare in this study has various details associated with it that may prove useful to those wishing to reproduce our results. We list choices made for the various tuning methods here, and note that all our decisions were made in keeping with best practices for each algorithm. 5.4.1 MERT We used David Chiang’s CMERT implementation of MERT that is available with the Moses system (Koehn et al., 2007). We ran MERT for up to 30 iterations, using k = 1500, and stopping early when 11This constitutes 6,723 features in principle (822 − 1 since “unaligned-unaligned” is not considered) but in practice far fewer co-occurrences were seen. Table 3 shows the number of actual unigram word pair features observed in data. the accumulated k-best list does not change in an iteration. In every tuning iteration we ran MERT once with weights initialized to the last iteration’s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177– 180, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Shankar Kumar</author>
<author>Wolfgang Macherey</author>
<author>Chris Dyer</author>
<author>Franz Och</author>
</authors>
<title>Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>163--171</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="30508" citStr="Kumar et al., 2009" startWordPosition="5295" endWordPosition="5299">petitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts. 7 Conclusion We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement. We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable. It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering research. Acknowledg</context>
</contexts>
<marker>Kumar, Macherey, Dyer, Och, 2009</marker>
<rawString>Shankar Kumar, Wolfgang Macherey, Chris Dyer, and Franz Och. 2009. Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 163–171, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Michael J Denkowski</author>
</authors>
<title>The METEOR metric for automatic evaluation of machine translation.</title>
<date>2009</date>
<journal>Machine Translation,</journal>
<pages>23--2</pages>
<contexts>
<context position="6487" citStr="Lavie and Denkowski, 2009" startWordPosition="1114" endWordPosition="1117">by summing the cost of each of the policy’s candidate translations: Hw(p) = Ei∈I hw(i, p(i)). As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8. The goal of tuning is to learn a weight vector w such that Hw(p) assigns a high score to good policies, and a low score to bad policies.2 To do so, we need information about which policies are good and which are bad. This information is provided by a “gold” scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a). We want to find a weight vector w such that Hw behaves “similarly” to G on a candidate space s. We assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes</context>
</contexts>
<marker>Lavie, Denkowski, 2009</marker>
<rawString>Alon Lavie and Michael J. Denkowski. 2009. The METEOR metric for automatic evaluation of machine translation. Machine Translation, 23(2–3):105–115, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>761--768</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<marker>Liang, Bouchard-Cˆot´e, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Bouchard-Cˆot´e, Dan Klein, and Ben Taskar. 2006. An end-to-end discriminative approach to machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 761–768, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Macherey</author>
<author>Franz Josef Och</author>
<author>Ignacio Thayer</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Lattice-based minimum error rate training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>725--734</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, HI,</location>
<contexts>
<context position="11809" citStr="Macherey et al., 2008" startWordPosition="2043" endWordPosition="2046">ost prominent example of a tuning method that performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009). Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted. Our goal is to achieve the same performance with minimal modification to MERT. With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both. Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minimize divergence from the established MERT tuning architecture. Instead, we focus on the optimization phase. 4.1 Basic Approach While intuitive, the MERT optimization module focuses attention on Hw’s best policy, and not on its overall prowess at ranking policies. We will create an optimization module that directly addresses Hw’s ability to rank policies in the hope that this more holistic approach will generalize better to unseen data. Assume that the gold scor</context>
<context position="30487" citStr="Macherey et al., 2008" startWordPosition="5291" endWordPosition="5294"> test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts. 7 Conclusion We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement. We have demonstrated, via a litany of experiments, that our claims are valid and that this technique is widely applicable. It is our hope that the adoption of PRO tuning leads to fewer headaches during tuning and motivates advanced MT feature engineering</context>
</contexts>
<marker>Macherey, Och, Thayer, Uszkoreit, 2008</marker>
<rawString>Wolfgang Macherey, Franz Josef Och, Ignacio Thayer, and Jakob Uszkoreit. 2008. Lattice-based minimum error rate training for statistical machine translation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 725– 734, Honolulu, HI, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Dan Klein</author>
</authors>
<title>Optimization, maxent models, and conditional estimation without magic.</title>
<date>2003</date>
<booktitle>Tutorial at HLT-NAACL 2003 and ACL</booktitle>
<contexts>
<context position="27856" citStr="Manning and Klein, 2003" startWordPosition="4829" endWordPosition="4832">t operates on real-valued features can be used, and in fact we obtained similar results 12and acknowledge the use of David Chiang’s code 13This is a more realistic scenario for would-be implementers of MIRA, as obtaining the so-called “hope” and “fear” translations from the lattice or forest is significantly more complicated than simply obtaining a k-best list. Other tests comparing these methods have shown between 0.1 to 0.3 BLEU drop using 30- best hw on Chinese-English (Wang, 2011). 1359 using the support vector machine module of WEKA (Hall et al., 2009) as well as the Stanford classifier (Manning and Klein, 2003). We ran for up to 30 iterations and used the same k and stopping criterion as was used for MERT, though variability of sampling precluded list convergence. While MERT and MIRA use each iteration’s final weights as a starting point for hill-climbing the next iteration, the pairwise ranking approach has no explicit tie to previous iterations. To incorporate such stability into our process we interpolated the weights w&apos; learned by the classifier in iteration t with those from iteration t − 1 by a factor of Ψ, such that wt = Ψ · w&apos; + (1 − Ψ) · wt−1. We found Ψ = 0.1 gave good performance across t</context>
</contexts>
<marker>Manning, Klein, 2003</marker>
<rawString>Christopher Manning and Dan Klein. 2003. Optimization, maxent models, and conditional estimation without magic. Tutorial at HLT-NAACL 2003 and ACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
<author>Ryan Green</author>
<author>Joseph P Turian</author>
</authors>
<title>Precision and recall of machine translation.</title>
<date>2003</date>
<booktitle>In Companion Volume of the Proceedings of HLT-NAACL</booktitle>
<pages>61--63</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edmonton, Canada, May–June.</location>
<contexts>
<context position="6509" citStr="Melamed et al., 2003" startWordPosition="1118" endWordPosition="1121"> of the policy’s candidate translations: Hw(p) = Ei∈I hw(i, p(i)). As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8. The goal of tuning is to learn a weight vector w such that Hw(p) assigns a high score to good policies, and a low score to bad policies.2 To do so, we need information about which policies are good and which are bad. This information is provided by a “gold” scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a). We want to find a weight vector w such that Hw behaves “similarly” to G on a candidate space s. We assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes over a finite subset </context>
</contexts>
<marker>Melamed, Green, Turian, 2003</marker>
<rawString>I. Dan Melamed, Ryan Green, and Joseph P. Turian. 2003. Precision and recall of machine translation. In Companion Volume of the Proceedings of HLT-NAACL 2003 - Short Papers, pages 61–63, Edmonton, Canada, May–June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hong Kong,</location>
<contexts>
<context position="21087" citStr="Och and Ney, 2000" startWordPosition="3621" endWordPosition="3624"> results are in Table 1. 5.1 Systems We used two systems, each based on a different MT model. Our syntax-based system (hereafter, SBMT) follows the model of Galley et al. (2004). Our 8MERT could not run to a satisfactory completion in any extended feature scenario; as implied in the synthetic data experiment of Section 3, the algorithm makes poor choices for its weights and this leads to low-quality k-best lists and dismal performance, near 0 BLEU in every iteration. phrase-based system (hereafter, PBMT) follows the model of Och and Ney (2004). In both systems we learn alignments with GIZA++ (Och and Ney, 2000) using IBM Model 4; for Urdu-English and Chinese-English we merged alignments with the refined method, and for Arabic-English we merged with the union method. 5.2 Data Table 2 notes the sizes of the datasets used in our experiments. All tune and test data have four English reference sets for the purposes of scoring. Data U-E A-E C-E lines 515K 6.5M 7.9M Train 2.2M 175M 173M words lines 923 1994 1615 Tune 16K 65K 42K words lines 938 1357 1357 Test 18K 47K 37K words Table 2: Data sizes for the experiments reported in this paper (English words shown). 1357 Class Urdu-English Arabic-English Chines</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics, pages 440–447, Hong Kong, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>295--302</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, PA,</location>
<contexts>
<context position="30088" citStr="Och and Ney (2002)" startWordPosition="5226" endWordPosition="5229">ed in Figure 6. The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05. 6 Related Work Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of Figure 6: Tune and test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts. 7 Conclusion We have described a simple technique for tuning an MT system that is on par w</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 295–302, Philadelphia, PA, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="21018" citStr="Och and Ney (2004)" startWordPosition="3609" endWordPosition="3612">de a held-out test set and evaluated it with case-sensitive BLEU. The results are in Table 1. 5.1 Systems We used two systems, each based on a different MT model. Our syntax-based system (hereafter, SBMT) follows the model of Galley et al. (2004). Our 8MERT could not run to a satisfactory completion in any extended feature scenario; as implied in the synthetic data experiment of Section 3, the algorithm makes poor choices for its weights and this leads to low-quality k-best lists and dismal performance, near 0 BLEU in every iteration. phrase-based system (hereafter, PBMT) follows the model of Och and Ney (2004). In both systems we learn alignments with GIZA++ (Och and Ney, 2000) using IBM Model 4; for Urdu-English and Chinese-English we merged alignments with the refined method, and for Arabic-English we merged with the union method. 5.2 Data Table 2 notes the sizes of the datasets used in our experiments. All tune and test data have four English reference sets for the purposes of scoring. Data U-E A-E C-E lines 515K 6.5M 7.9M Train 2.2M 175M 173M words lines 923 1994 1615 Tune 16K 65K 42K words lines 938 1357 1357 Test 18K 47K 37K words Table 2: Data sizes for the experiments reported in this paper</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Och and Hermann Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4):417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan,</location>
<contexts>
<context position="1048" citStr="Och, 2003" startWordPosition="166" endWordPosition="167">asily handle systems with thousands of features. Moreover, unlike recent approaches built upon the MIRA algorithm of Crammer and Singer (2003) (Watanabe et al., 2007; Chiang et al., 2008b), PRO is easy to implement. It uses off-the-shelf linear binary classifier software and can be built on top of an existing MERT framework in a matter of hours. We establish PRO’s scalability and effectiveness by comparing it to MERT and MIRA and demonstrate parity on both phrase-based and syntax-based systems in a variety of language pairs, using large scale data scenarios. 1 Introduction The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system. MERT is well-understood, easy to implement, and runs quickly, but can behave erratically and does not scale beyond a handful of features. This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation. Several researchers have attempted to address this weakness. Recently, Watanabe et al. (2007) and Chiang et al. (2008b) have developed tuning m</context>
<context position="7263" citStr="Och, 2003" startWordPosition="1254" endWordPosition="1255"> assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes over a finite subset of source sentences3 and a finite subset of candidate translations as well. The classic tuning architecture used in the dominant MERT approach (Och, 2003) forms the translation subset and learns weight vector w via 2Without loss of generality, we assume that a higher score indicates a better translation. 3See Section 5.2 for the tune sets used in this paper’s experiments. 1353 Source Sentence Candidate Translations i f(i) j e(i,j) x(i,j) hw(i,j) g(i,j) 1 “il ne va pas” 1 “he goes not” [2 4] 0 0.28 2 “he does not go” [3 8] 2 0.42 3 “she not go” [6 1] -11 0.12 2 “je ne vais pas” 1 “I go not” [-3 -3] 3 0.15 2 “we do not go” [1 -5] -7 0.18 3 “I do not go” [-5 -3] 7 0.34 Figure 1: Example candidate space of dimensionality 2. Note: I = {1, 2}, J(1) =</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, PA,</location>
<contexts>
<context position="6414" citStr="Papineni et al., 2002" startWordPosition="1104" endWordPosition="1107">s feature vector x(i, j). This scoring function extends to a policy p by summing the cost of each of the policy’s candidate translations: Hw(p) = Ei∈I hw(i, p(i)). As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8. The goal of tuning is to learn a weight vector w such that Hw(p) assigns a high score to good policies, and a low score to bad policies.2 To do so, we need information about which policies are good and which are bad. This information is provided by a “gold” scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a). We want to find a weight vector w such that Hw behaves “similarly” to G on a candidate space s. We assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many </context>
<context position="26607" citStr="Papineni et al., 2002" startWordPosition="4615" endWordPosition="4618">pping early when 11This constitutes 6,723 features in principle (822 − 1 since “unaligned-unaligned” is not considered) but in practice far fewer co-occurrences were seen. Table 3 shows the number of actual unigram word pair features observed in data. the accumulated k-best list does not change in an iteration. In every tuning iteration we ran MERT once with weights initialized to the last iteration’s chosen weight set and 19 times with random weights, and chose the the best of the 20 ending points according to G on the development set. The G we optimize is tokenized, lower-cased 4-gram BLEU (Papineni et al., 2002). 5.4.2 MIRA We for the most part follow the MIRA algorithm for machine translation as described by Chiang et al. (2009)12 but instead of using the 10-best of each of the best hw, hw +g, and hw-g, we use the 30-best according to hw.13 We use the same sentence-level BLEU calculated in the context of previous 1-best translations as Chiang et al. (2008b; 2009). We ran MIRA for 30 iterations. 5.4.3 PRO We used the MegaM classifier and sampled as described in Section 4.2. As previously noted, we used BLEU+1 (Liang et al., 2006) for g. MegaM was easy to set up and ran fairly quickly, however any lin</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, PA, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Roth</author>
<author>Andrew McCallum</author>
<author>Marc Dymetman</author>
<author>Nicola Cancedda</author>
</authors>
<title>Machine translation using overlapping alignments and samplerank.</title>
<date>2010</date>
<booktitle>In Proceedings ofAssociation for Machine Translation in the Americas,</booktitle>
<location>Denver, CO.</location>
<contexts>
<context position="18058" citStr="Roth et al. (2010)" startWordPosition="3112" endWordPosition="3115">t to tease apart small differences. 1356 SAMPLERs,g(Γ,Ξ, αz V = () Γ j0) J(i)xJ(i) αz(|g(i,j)-g(i,j0)|), (x(i,j),x(i,j0),|g(i,j)-g(i,j0)|) |g(i,j)-g(i,j0)|. − j0),sign(g(i,j)-g(i,j0)) j0)-x(i, sign(g(i,j0)-g(i, Ξ of V . Figure 4: Pseudocode for our sampler. Arguments: s = but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500. The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors. Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture. Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations. An important observation is that BLEU does not satisfy the decomposability assumption of Equation (1). An advantage of MERT is that it can directly optimize f</context>
</contexts>
<marker>Roth, McCallum, Dymetman, Cancedda, 2010</marker>
<rawString>Benjamin Roth, Andrew McCallum, Marc Dymetman, and Nicola Cancedda. 2010. Machine translation using overlapping alignments and samplerank. In Proceedings ofAssociation for Machine Translation in the Americas, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Anoop Sarkar</author>
<author>Franz Josef Och</author>
</authors>
<title>Discriminative reranking for machine translation.</title>
<date>2004</date>
<booktitle>In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings,</booktitle>
<volume>2</volume>
<pages>177--184</pages>
<location>Boston, MA,</location>
<contexts>
<context position="29683" citStr="Shen et al., 2004" startWordPosition="5157" endWordPosition="5160">sing the weights learned at every iteration for each Urdu-English SBMT experiment. Typical of the rest of the experiments, we can clearly see that PRO appears to proceed more monotonically than the other methods. We quantified PRO’s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with each configuration. The tune and test BLEU at each iteration is depicted in Figure 6. The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05. 6 Related Work Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of Figure 6: Tune and test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labe</context>
</contexts>
<marker>Shen, Sarkar, Och, 2004</marker>
<rawString>Libin Shen, Anoop Sarkar, and Franz Josef Och. 2004. Discriminative reranking for machine translation. In Daniel Marcu Susan Dumais and Salim Roukos, editors, HLT-NAACL 2004: Main Proceedings, pages 177–184, Boston, MA, May 2 - May 7. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings ofAssociation forMachine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="6530" citStr="Snover et al., 2006" startWordPosition="1122" endWordPosition="1125">date translations: Hw(p) = Ei∈I hw(i, p(i)). As can be seen in Figure 1, using w = [−2, 1], Hw(p1) = 9 and Hw(p2) = −8. The goal of tuning is to learn a weight vector w such that Hw(p) assigns a high score to good policies, and a low score to bad policies.2 To do so, we need information about which policies are good and which are bad. This information is provided by a “gold” scoring function G that maps each policy to a real-valued score. Typically this gold function is BLEU (Papineni et al., 2002), though there are several common alternatives (Lavie and Denkowski, 2009; Melamed et al., 2003; Snover et al., 2006; Chiang et al., 2008a). We want to find a weight vector w such that Hw behaves “similarly” to G on a candidate space s. We assume a loss function ls(Hw, G) which returns the real-valued loss of using scoring function Hw when the gold scoring function is G and the candidate space is s. Thus, we may say the goal of tuning is to find the weight vector w that minimizes loss. 3 MERT In general, the candidate space may have infinitely many source sentences, as well as infinitely many candidate translations per source sentence. In practice, tuning optimizes over a finite subset of source sentences3 </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings ofAssociation forMachine Translation in the Americas, pages 223–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
<author>Tong Zhang</author>
</authors>
<title>A localized prediction model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the ACL,</booktitle>
<pages>557--564</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, MI,</location>
<contexts>
<context position="29821" citStr="Tillmann and Zhang (2005)" startWordPosition="5180" endWordPosition="5184">clearly see that PRO appears to proceed more monotonically than the other methods. We quantified PRO’s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with each configuration. The tune and test BLEU at each iteration is depicted in Figure 6. The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05. 6 Related Work Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of Figure 6: Tune and test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. La</context>
</contexts>
<marker>Tillmann, Zhang, 2005</marker>
<rawString>Christoph Tillmann and Tong Zhang. 2005. A localized prediction model for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the ACL, pages 557–564, Ann Arbor, MI, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
</authors>
<date>2011</date>
<tech>Personal communication.</tech>
<contexts>
<context position="27721" citStr="Wang, 2011" startWordPosition="4808" endWordPosition="4809">EU+1 (Liang et al., 2006) for g. MegaM was easy to set up and ran fairly quickly, however any linear binary classifier that operates on real-valued features can be used, and in fact we obtained similar results 12and acknowledge the use of David Chiang’s code 13This is a more realistic scenario for would-be implementers of MIRA, as obtaining the so-called “hope” and “fear” translations from the lattice or forest is significantly more complicated than simply obtaining a k-best list. Other tests comparing these methods have shown between 0.1 to 0.3 BLEU drop using 30- best hw on Chinese-English (Wang, 2011). 1359 using the support vector machine module of WEKA (Hall et al., 2009) as well as the Stanford classifier (Manning and Klein, 2003). We ran for up to 30 iterations and used the same k and stopping criterion as was used for MERT, though variability of sampling precluded list convergence. While MERT and MIRA use each iteration’s final weights as a starting point for hill-climbing the next iteration, the pairwise ranking approach has no explicit tie to previous iterations. To incorporate such stability into our process we interpolated the weights w&apos; learned by the classifier in iteration t wi</context>
</contexts>
<marker>Wang, 2011</marker>
<rawString>Wei Wang. 2011. Personal communication.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>NTT statistical machine translation for IWSLT</title>
<date>2006</date>
<booktitle>In Proceedings of IWSLT</booktitle>
<pages>95--102</pages>
<contexts>
<context position="29727" citStr="Watanabe et al., 2006" startWordPosition="5165" endWordPosition="5168">tion for each Urdu-English SBMT experiment. Typical of the rest of the experiments, we can clearly see that PRO appears to proceed more monotonically than the other methods. We quantified PRO’s stability as compared to MERT by repeating the Urdu-English baseline PBMT experiment five times with each configuration. The tune and test BLEU at each iteration is depicted in Figure 6. The standard deviation of the final test BLEU of MERT was 0.13 across the five experiment instances, while PRO had a standard deviation of just 0.05. 6 Related Work Several works (Shen et al., 2004; Cowan et al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of Figure 6: Tune and test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a ma</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2006</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2006. NTT statistical machine translation for IWSLT 2006. In Proceedings of IWSLT 2006, pages 95–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>764--773</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1598" citStr="Watanabe et al. (2007)" startWordPosition="249" endWordPosition="252">arge scale data scenarios. 1 Introduction The MERT algorithm (Och, 2003) is currently the most popular way to tune the parameters of a statistical machine translation (MT) system. MERT is well-understood, easy to implement, and runs quickly, but can behave erratically and does not scale beyond a handful of features. This lack of scalability is a significant weakness, as it inhibits systems from using more than a couple dozen features to discriminate between candidate translations and stymies feature development innovation. Several researchers have attempted to address this weakness. Recently, Watanabe et al. (2007) and Chiang et al. (2008b) have developed tuning methods using the MIRA algorithm (Crammer and Singer, 2003) as a nucleus. The MIRA technique of Chiang et al. has been shown to perform well on large-scale tasks with hundreds or thousands of features (2009). However, the technique is complex and architecturally quite different from MERT. Tellingly, in the entire proceedings of ACL 2010 (Hajiˇc et al., 2010), only one paper describing a statistical MT system cited the use of MIRA for tuning (Chiang, 2010), while 15 used MERT.1 Here we propose a simpler approach to tuning that scales similarly to</context>
<context position="11345" citStr="Watanabe et al. (2007)" startWordPosition="1973" endWordPosition="1976"> loses the ability to learn w∗. Note that this synthetic problem is considerably easier than a real MT scenario, where the data is noisy and interdependent, and the gold scoring function is nonlinear. If 1354 MERT cannot scale in this simple scenario, it has little hope of succeeding in a high-dimensionality deployment scenario. 4 Optimization via Pairwise Ranking We would like to modify MERT so that it scales well to high-dimensionality candidate spaces. The most prominent example of a tuning method that performs well on high-dimensionality candidate spaces is the MIRA-based approach used by Watanabe et al. (2007) and Chiang et al. (2008b; 2009). Unfortunately, this approach requires a complex architecture that diverges significantly from the MERT approach, and consequently has not been widely adopted. Our goal is to achieve the same performance with minimal modification to MERT. With MERT as a starting point, we have a choice: modify candidate generation, optimization, or both. Although alternative candidate generation methods have been proposed (Macherey et al., 2008; Chiang et al., 2008b; Chatterjee and Cancedda, 2010), we will restrict ourselves to MERT-style candidate generation, in order to minim</context>
<context position="17996" citStr="Watanabe et al., 2007" startWordPosition="3098" endWordPosition="3102">nsure good translations are preferred to bad translations, and not to tease apart small differences. 1356 SAMPLERs,g(Γ,Ξ, αz V = () Γ j0) J(i)xJ(i) αz(|g(i,j)-g(i,j0)|), (x(i,j),x(i,j0),|g(i,j)-g(i,j0)|) |g(i,j)-g(i,j0)|. − j0),sign(g(i,j)-g(i,j0)) j0)-x(i, sign(g(i,j0)-g(i, Ξ of V . Figure 4: Pseudocode for our sampler. Arguments: s = but added noise to each feature vector, drawn from a zero-mean Gaussian with a standard deviation of 500. The results of the noisy synthetic experiments, but still The idea of learning from difference vectors also lies at the heart of the MIRA-based approaches (Watanabe et al., 2007; Chiang et al., 2008b) and the approach of Roth et al. (2010), which, similar to our method, uses sampling to select vectors. Here, we isolate these aspects of those approaches to create a simpler tuning technique that closely mirrors the ubiquitous MERT architecture. Among other simplifications, we abstract away the choice of MIRA as the classification method (our approach can use any classification technique that learns a separating hyperplane), and we eliminate the need for oracle translations. An important observation is that BLEU does not satisfy the decomposability assumption of Equatio</context>
<context position="24053" citStr="Watanabe et al. (2007)" startWordPosition="4180" endWordPosition="4183"> contain web and newswire data. The tune set is selected from NIST MT evaluation sets from 2003–2006. The test set is the evaluation set from the NIST 2008 MT evaluation. We trained a 3-gram English language model on the English side of the training data. 5.3 Features For each of our systems we identify two feature sets: baseline, which correspond to the typical small feature set reported in current MT literature, and extended, a superset of baseline, which adds hundreds or thousands of features. Specifically, we use 15 baseline features for PBMT, similar to the baseline features described by Watanabe et al. (2007). We use 19 baseline features for SBMT, similar to the baseline features described by Chiang et al. (2008b). We used the following feature classes in SBMT and PBMT extended scenarios: • Discount features for rule frequency bins (cf. Chiang et al. (2009), Section 4.1) • Target word insertion features9 We used the following feature classes in SBMT extended scenarios only (cf. Chiang et al. (2009), Section 4.1):10 • Rule overlap features • Node count features 9For Chinese-English and Urdu-English SBMT these features only fired when the inserted target word was unaligned to any source word. 10The </context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2007</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2007. Online large-margin training for statistical machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 764– 773, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum entropy based phrase reordering model for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>521--528</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="30312" citStr="Xiong et al. (2006)" startWordPosition="5261" endWordPosition="5264"> al., 2006; Watanabe et al., 2006) have used discriminative techniques to re-rank k-best lists for MT. Tillmann and Zhang (2005) used a customized form of Figure 6: Tune and test curves of five repetitions of the same Urdu-English PBMT baseline feature experiment. PRO is more stable than MERT. multi-class stochastic gradient descent to learn feature weights for an MT model. Och and Ney (2002) used maximum entropy to tune feature weights but did not compare pairs of derivations. Ittycheriah and Roukos (2005) used a maximum entropy classifier to train an alignment model using hand-labeled data. Xiong et al. (2006) also used a maximum entropy classifier, in this case to train the reordering component of their MT model. Lattice- and hypergraphbased variants of MERT (Macherey et al., 2008; Kumar et al., 2009) are more stable than traditional MERT, but also require significant engineering efforts. 7 Conclusion We have described a simple technique for tuning an MT system that is on par with the leading techniques, exhibits reliable behavior, scales gracefully to high-dimension feature spaces, and is remarkably easy to implement. We have demonstrated, via a litany of experiments, that our claims are valid an</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maximum entropy based phrase reordering model for statistical machine translation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 521–528, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>