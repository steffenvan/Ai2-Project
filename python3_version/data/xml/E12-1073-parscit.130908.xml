<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.996863">
Validation of sub-sentential paraphrases acquired
from parallel monolingual corpora
</title>
<author confidence="0.630047">
Houda Bouamor Aur´elien Max Anne Vilnat
</author>
<affiliation confidence="0.5013855">
LIMSI-CNRS &amp; Univ. Paris Sud
Orsay, France
</affiliation>
<email confidence="0.997218">
firstname.lastname@limsi.fr
</email>
<sectionHeader confidence="0.993845" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999896521739131">
The task of paraphrase acquisition from re-
lated sentences can be tackled by a variety
of techniques making use of various types
of knowledge. In this work, we make the
hypothesis that their performance can be
increased if candidate paraphrases can be
validated using information that character-
izes paraphrases independently of the set of
techniques that proposed them. We imple-
ment this as a bi-class classification prob-
lem (i.e. paraphrase vs. not paraphrase),
allowing any paraphrase acquisition tech-
nique to be easily integrated into the com-
bination system. We report experiments on
two languages, English and French, with
5 individual techniques on parallel mono-
lingual parallel corpora obtained via multi-
ple translation, and a large set of classifi-
cation features including surface to contex-
tual similarity measures. Relative improve-
ments in F-measure close to 18% are ob-
tained on both languages over the best per-
forming techniques.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999908510204082">
The fact that natural language allows messages
to be conveyed in a great variety of ways consti-
tutes an important difficulty for NLP, with appli-
cations in both text analysis and generation. The
term paraphrase is now commonly used in the
NLP litterature to refer to textual units of equiva-
lent meaning at the phrasal level (including single
words). For instance, the phrases six months and
half a year form a paraphrase pair applicable in
many different contexts, as they would appropri-
ately denote the same concept. Although one can
envisage to manually build high-coverage lists of
synonyms, enumerating meaning equivalences at
the level of phrases is too daunting a task for hu-
mans. Because this type of knowledge can how-
ever greatly benefit many NLP applications, au-
tomatic acquisition of such paraphrases has at-
tracted a lot of attention (Androutsopoulos and
Malakasiotis, 2010; Madnani and Dorr, 2010),
and significant research efforts have been devoted
to this objective (Callison-Burch, 2007; Bhagat,
2009; Madnani, 2010).
Central to acquiring paraphrases is the need of
assessing the quality of the candidate paraphrases
produced by a given technique. Most works to
date have resorted to human evaluation of para-
phrases on the levels of grammaticality and mean-
ing equivalence. Human evaluation is however
often criticized as being both costly and non re-
producible, and the situation is even more compli-
cated by the inherent complexity of the task that
can produce low inter-judge agreement. Task-
based evaluation involving the use of paraphras-
ing into some application thus seem an acceptable
solution, provided the evaluation methodologies
for the given task are deemed acceptable. This,
in turn, puts the emphasis on observing the im-
pact of paraphrasing on the targeted application
and is rarely accompanied by a study of the intrin-
sic limitations of the paraphrase acquisition tech-
nique used.
The present work is concerned with the task of
sub-sentential paraphrase acquisition from pairs
of related sentences. A large variety of tech-
niques have been proposed that can be applied
to this task. They typically make use of differ-
ent kinds of automatically or manually acquired
knowledge. We make the hypothesis that their
performance can be increased if candidate para-
</bodyText>
<page confidence="0.972297">
716
</page>
<note confidence="0.978011">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 716–725,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.9975788">
phrases can be validated using information that
characterize paraphrases in complement to the set
of techniques that proposed them. We propose to
implement this as a bi-class classification problem
(i.e. paraphrase vs. not paraphrase), allowing
any paraphrase acquisition technique to be easily
integrated into the combination system. In this
article, we report experiments on two languages,
English and French, with 5 individual techniques
based on a) statistical word alignment models,
b) translational equivalence, c) handcoded rules of
term variation, d) syntactic similarity, and e) edit
distance on word sequences. We used parallel
monolingual parallel corpora obtained via mul-
tiple translation from a single language as our
sources of related sentences, and a large set of
features including surface to contextual similarity
measures. Relative improvements in F-measure
close to 18% are obtained on both languages over
the best performing techniques.
The remainder of this article is organized as
follows. We first briefly review previous work
on sub-sentential paraphrase acquisition in sec-
tion 2. We then describe our experimental setting
in section 3 and the individual techniques that we
have studied in section 4. Section 5 is devoted to
our approach for validating paraphrases proposed
by individual techniques. Finally, section 6 con-
cludes the article and presents some of our future
work in the area of paraphrase acquisition.
</bodyText>
<sectionHeader confidence="0.999493" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999461">
The hypothesis that if two words or, by exten-
sion, two phrases, occur in similar contexts then
they may be interchangeable has been extensively
tested. The distributional hypothesis, attributed to
Zellig Harris, was for example applied to syntac-
tic dependency paths in the work of Lin and Pan-
tel (2001). Their results take the form of equiva-
lence patterns with two arguments such as {X asks
for Y, X requests Y, X’s request for Y, X wants Y,
Y is requested by X, ...}.
Using comparable corpora, where the same in-
formation probably exists under various linguis-
tic forms, increases the likelihood of finding very
close contexts for sub-sentential units. Barzilay
and Lee (2003) proposed a multi-sequence align-
ment algorithm that takes structurally similar sen-
tences and builds a compact lattice representation
that encodes local variations. The work by Bhagat
and Ravichandran (2008) describes an application
of a similar technique on a very large scale.
The hypothesis that two words or phrases are
interchangeable if they share a common trans-
lation into one or more other languages has
also been extensively studied in works on sub-
sentential paraphrase acquisition. Bannard and
Callison-Burch (2005) described a pivoting ap-
proach that can exploit bilingual parallel corpora
in several languages. The same technique has
been applied to the acquisition of local paraphras-
ing patterns in Zhao et al. (2008). The work of
Callison-Burch (2008) has shown how the mono-
lingual context of a sentence to paraphrase can be
used to improve the quality of the acquired para-
phrases.
Another approach consists in modelling local
paraphrasing identification rules. The work of
Jacquemin (1999) on the identification of term
variants, which exploits rewriting morphosyntac-
tic rules and descriptions of morphological and
semantic lexical families, can be extended to ex-
tract the various forms corresponding to input pat-
terns from large monolingual corpora.
When parallel monolingual corpora aligned at
the sentence level are available (e.g. multiple
translations into the same language), the task of
sub-sentential paraphrase acquisition can be cast
as one of word alignment between two aligned
sentences (Cohn et al., 2008). Barzilay and
McKeown (2001) applied the distributionality hy-
pothesis on such parallel sentences, and Pang et
al. (2003) proposed an algorithm to align sen-
tences by recursive fusion of their common syn-
tactic constituants.
Finally, they has been a recent interest in auto-
matic evaluation of paraphrases (Callison-Burch
et al., 2008; Liu et al., 2010; Chen and Dolan,
2011; Metzler et al., 2011).
</bodyText>
<sectionHeader confidence="0.992273" genericHeader="method">
3 Experimental setting
</sectionHeader>
<bodyText confidence="0.999826875">
We used the main aspects of the methodology
described by Cohn et al. (2008) for constructing
evaluation corpora and assessing the performance
of techniques on the task of sub-sentential para-
phrase acquisition. Pairs of related sentences are
hand-aligned to define a set of reference atomic
paraphrase pairs at the level of words or phrases,
denoted as Ratom1.
</bodyText>
<footnote confidence="0.710499">
1Note that in this study we do not distinguish between
“Sure” and “Possible” alignments, and when reusing anno-
</footnote>
<page confidence="0.99154">
717
</page>
<table confidence="0.999114222222222">
single language multiple language video descriptions multiply-translated news headlines
translation translation subtitles
# tokens 4,476 4,630 1,452 2,721 1,908
# unique tokens 656 795 357 830 716
% aligned tokens (excluding identities) 60.58 48.80 23.82 29.76 14.46
lexical overlap (tokens) 77.21 61.03 59.50 32.51 39.63
lexical overlap (lemmas content words) 83.77 71.04 64.83 39.54 45.31
translation edit rate (TER) 0.32 0.55 0.76 0.68 0.62
penalized n-gram prec. (BLEU) 0.33 0.15 0.13 0.14 0.39
</table>
<tableCaption confidence="0.994972">
Table 1: Various indicators of sentence pair comparability for different corpus types. Statistics are reported for
French on sets of 100 sentence pairs.
</tableCaption>
<bodyText confidence="0.9948925">
We conducted a small-scale study to assess dif-
ferent types of corpora of related sentences:
</bodyText>
<listItem confidence="0.997444470588235">
1. single language translation Corpora ob-
tained by several independent human trans-
lation of the same sentences (e.g. (Barzilay
and McKeown, 2001)).
2. multiple language translation Same as
above, but where a sentence is translated
from 4 different languages into the same lan-
guage (Bouamor et al., 2010).
3. video descriptions Descriptions of short
YouTube videos obtained via Mechanical
Turk (Chen and Dolan, 2011).
4. multiply-translated subtitles Aligned mul-
tiple translations of contributed movie subti-
tles (Tiedemann, 2007).
5. comparable news headlines News head-
lines collected from Google News clusters
(e.g. (Dolan et al., 2004)).
</listItem>
<bodyText confidence="0.994597153846154">
We collected 100 sentence pairs of each type
in French, for which various comparability mea-
sures are reported on Table 1. In particular, the
“% aligned tokens” row indicates the propor-
tion of tokens from the sentence pairs that could
be manually aligned by a native-speaker annota-
tor.2 Obviously, the more common tokens two
sentences from a pair contain, the fewer sub-
sentential paraphrases may be extracted from that
pair. However, high lexical overlap increases the
probability that two sentences be indeed para-
phrases, and in turn the probability that some of
their phrases be paraphrases. Furthermore, the
</bodyText>
<footnote confidence="0.889942">
tated corpora using them we considered all alignments as be-
ing correct.
2The same annotator hand-aligned the 5*100=500 para-
phrase pairs using the YAWAT (Germann, 2008) manual
alignment tool.
</footnote>
<bodyText confidence="0.999273564102564">
presence of common token may serve as useful
clues to guide paraphrase extraction.
For our experiments, we chose to use parallel
monolingual corpora obtained by single language
translation, the most direct resource type for ac-
quiring sub-sentential paraphrase pairs. This al-
lows us to define acceptable references for the
task and resort to the most consensual evaluation
technique for paraphrase acquisition to date. Us-
ing such corpora, we expect to be able to extract
precise paraphrases (see Table 1), which will be
natural candidates for further validation, which
will be addressed in section 5.3.
Figure 1 illustrates a reference alignment ob-
tained on a pair of English sentential paraphrases
and the list of atomic paraphrase pairs that can be
extracted from it, against which acquisition tech-
niques will be evaluated. Note that we do not con-
sider pairs of identical units during evaluation, so
we filter them out from the list of reference para-
phrase pairs.
The example in Figure 1 shows different cases
that point to the inherent complexity of this task,
even for human annotators: it could be argued,
for instance, that a correct atomic paraphrase
pair should be reached H amounted to rather
than reached H amounted. Also, aligning in-
dependently 260 H 0.26 and million H billion
is assuredly an error, while the pair 260 mil-
lion H 0.26 billion would have been appropriate.
A case of alignment that seems non trivial can be
observed in the provided example (during the en-
tire year H annual). The abovementioned rea-
sons will explain in part the difficulties in reach-
ing high performance values using such gold stan-
dards.
Reference composite paraphrase pairs (denoted
as R), obtained by joining adjacent atomic para-
phrase pairs from Ratom up to 6 tokens3, will
</bodyText>
<footnote confidence="0.902527">
3We used standard biphrase extraction heuristics (Koehn
</footnote>
<page confidence="0.970277">
718
</page>
<bodyText confidence="0.660297666666667">
the corpus described in (Cohn et al., 2008), consist-
annual ing of multiply-translated Chinese sentences into
foreign English, and used as our gold standard both the
investment alignments marked as “Sure” and “Possible”. For
actually French, we used the CESTA corpus of news ar-
used ticles4 obtained by translating into French from
amounted English.
to We used the YAWAT (Germann, 2008) manual
us$ alignment tool. Inter-annotator agreement val-
0.26 ues (averaging with each annotation set as the
billion gold standard) are 66.1 for English and 64.6 for
French, which we interpret as acceptable val-
ues. Manual inspection of the two corpora reveals
that the French corpus tends to contain more lit-
eral translations, possibly due to the original lan-
guages of the sentences, which are closer to the
target language than Chinese is to English.
the
amount
of
foreign
capital
actually
utilized
during
the
entire
year
reached
260
million
us
dollars
</bodyText>
<figure confidence="0.995024285714286">
capital ↔ investment
utilized ↔ used
during the entire year ↔ annual
reached ↔ amounted
260 ↔ 0.26
million ↔ billion
us dollars ↔ us$
</figure>
<figureCaption confidence="0.980039">
Figure 1: Reference alignments for a pair of English
sentential paraphrases from the annotation corpus of
Cohn et al. (2008) (note that possible and sure align-
ments are not distinguished here) and the list of atomic
paraphrase pairs extracted from these alignments.
</figureCaption>
<bodyText confidence="0.999639875">
also be considered when measuring performance.
Evaluated techniques have to output atomic can-
didate paraphrase pairs (denoted as Hatom) from
which composite paraphrase pairs (denoted as
H) are computed. The usual measures of pre-
cision (P), recall (R) and F-measure (Fl) can
then be defined in the following way (Cohn et al.,
2008):
</bodyText>
<equation confidence="0.996726">
_ |Hatom ∩ R |_ |H ∩ Ratom |_ 2pr
P  |Hatom  |R  |Ratom  |F1 p + r
</equation>
<bodyText confidence="0.9999715">
We conducted experiments using two different
corpora in English and French. In each case,
a held-out development corpus of 150 sentential
paraphrase pairs was used for development and
tuning, and all techniques were evaluated on the
same test set consisting of 375 sentential para-
phrase pairs. For English, we used the MTC
et al., 2007) : all words from a phrase must be aligned to at
least one word from the other and not to words outside, but
unaligned words at phrase boundaries are not used.
</bodyText>
<sectionHeader confidence="0.978526" genericHeader="method">
4 Individual techniques for paraphrase
acquisition
</sectionHeader>
<bodyText confidence="0.999985214285714">
As discussed in section 2, the acquisition of sub-
sentential paraphrases is a challenging task that
has previously attracted a lot of work. In this
work, we consider the scenario where sentential
paraphrases are available and words and phrases
from one sentence can be aligned to words and
phrases from the other sentence to form atomic
paraphrase pairs. We now describe several tech-
niques that perform the task of sub-sentential unit
alignment. We have selected and implemented
five techniques which we believe are representa-
tive of the type of knowledge that these techniques
use, and have reused existing tools, initially devel-
oped for other tasks, when possible.
</bodyText>
<subsectionHeader confidence="0.925752">
4.1 Statistical learning of word alignments
</subsectionHeader>
<bodyText confidence="0.963848076923077">
(Giza)
The GIZA++ tool (Och and Ney, 2004) computes
statistical word alignment models of increasing
complexity from parallel corpora. While origi-
nally developed in the bilingual context of Statis-
tical Machine Translation, nothing prevents build-
ing such models on monolingual corpora. How-
ever, in order to build reliable models, it is nec-
essary to use enough training material includ-
ing minimal redundancy of words. To this end,
we provided GIZA++ with all possible sentence
pairs from our mutiply-translated corpus to im-
prove the quality of its word alignments (note that
</bodyText>
<footnote confidence="0.972037">
4http://www.elda.org/article125.html
</footnote>
<page confidence="0.996096">
719
</page>
<bodyText confidence="0.9995904">
we used symmetrized alignments from the align-
ments in both directions). This constitutes a sig-
nificant advantage for this technique that tech-
niques working on each sentence pair indepen-
dently do not have.
</bodyText>
<subsectionHeader confidence="0.950476">
4.2 Translational equivalence (Pivot)
</subsectionHeader>
<bodyText confidence="0.999926">
Translational equivalence can be exploited to de-
termine that two phrases may be paraphrases.
Bannard and Callison-Burch (2005) defined a
paraphrasing probability between two phrases
based on their translation probability through all
possible pivot phrases as:
</bodyText>
<equation confidence="0.9804505">
�Ppara(P1,P2) � Pt(PZvjP1)Pt(P2jPZv)
piv
</equation>
<bodyText confidence="0.999987722222222">
where Pt denotes translation probabilies. We used
the Europarl corpus5 of parliamentary debates in
English and French, consisting of approximately
1.7 million parallel sentences : this allowed us
to use the same resource to build paraphrases for
English, using French as the pivot language, and
for French, using English as the pivot language.
The GIZA++ tool was used for word alignment
and the MOSES Statistical Machine Translation
toolkit (Koehn et al., 2007) was used to com-
pute phrase translation probabilities from these
word alignments. For each sentential paraphrase
pair, we applied the following algorithm: for each
phrase, we build the entire set of paraphrases us-
ing the previous definition. We then extract its
best paraphrase as the one exactly appearing in the
other sentence with maximum paraphrase proba-
bility, using a minimal threshold value of 10−4.
</bodyText>
<subsectionHeader confidence="0.547898">
4.3 Linguistic knowledge on term variation
(Fastr)
</subsectionHeader>
<bodyText confidence="0.999959">
The FASTR tool (Jacquemin, 1999) was designed
to spot term/phrase variants in large corpora.
Variants are described through metarules express-
ing how the morphosyntactic structure of a term
variant can be derived from a given term by means
of regular expressions on word morphosyntactic
categories. Paradigmatic variation can also be ex-
pressed by expressing constraints between words,
imposing that they be of the same morphologi-
cal or semantic family. Both constraints rely on
preexisting repertoires available for English and
French. To compute candidate paraphrase pairs
using FASTR, we first consider all phrases from
</bodyText>
<footnote confidence="0.751008">
5http://statmt.org/europarl
</footnote>
<bodyText confidence="0.999352333333333">
the first sentence and search for variants in the
other sentence, then do the reverse process and
finally take the intersection of the two sets.
</bodyText>
<subsectionHeader confidence="0.988613">
4.4 Syntactic similarity (Synt)
</subsectionHeader>
<bodyText confidence="0.99994">
The algorithm introduced by Pang et al. (2003)
takes two sentences as input and merges them by
top-down syntactic fusion guided by compatible
syntactic substructure. A lexical blocking mecha-
nism prevents constituents from fusionning when
there is evidence of the presence of a word in an-
other constituent of one of the sentence. We use
the Berkeley Probabilistic parser (Klein and Man-
ning, 2003) to obtain syntactic trees for English
and its adapted version for French (Candito et al.,
2010). Because this process is highly sensitive to
syntactic parse errors, we use in our implemen-
tation k-best parses and retain the most compact
fusion from any pair of candidate parses.
</bodyText>
<subsectionHeader confidence="0.909018">
4.5 Edit rate on word sequences (TERp)
</subsectionHeader>
<bodyText confidence="0.999457875">
TERp (Translation Edit Rate Plus) (Snover et al.,
2010) is a score designed for the evaluation of
Machine Translation output. Its typical use takes
a system hypothesis to compute an optimal set of
word edits that can transform it into some exist-
ing reference translation. Edit types include ex-
act word matching, word insertion and deletion,
block movement of contiguous words (computed
as an approximation), as well as optionally vari-
ants substitution through stemming, synonym or
paraphrase matching.6 Each edit type is parame-
terized by at least one weight which can be opti-
mized using e.g. hill climbing. TERp being a tun-
able metric, our experiments will include tuning
TERp systems towards either precision (! P),
recall (! R), or F-measure (! F1).7
</bodyText>
<subsectionHeader confidence="0.998062">
4.6 Evaluation of individual techniques
</subsectionHeader>
<bodyText confidence="0.747215307692308">
Results for the 5 individual techniques are given
on the left part of Table 2. It is first apparent
that all techniques but TERp fared better on the
French corpus than on the English corpus. This
can certainly be explained by the fact that the for-
mer results from more literal translations (from
6Note that for these experiments we did not use the stem-
ming module, the interface to WordNet for synonym match-
ing and the provided paraphrase table for English, due to the
fact that these resources were available for English only.
7Hill climbing was used for all tunings as done by Snover
et al. (2010), and we used one iteration starting with uniform
weights and 100 random restarts.
</bodyText>
<page confidence="0.933827">
720
</page>
<table confidence="0.9996265">
Individual techniques Combinations
GIZA PIVOT FASTR SYNT P -ER -, F1 union validation
English
P 31.01 31.78 37.38 52.17 50.00 29.15 33.37 21.44 50.51
R 38.30 18.50 6.71 2.53 5.83 45.19 45.37 60.87 41.19
Fl 34.27 23.39 11.38 4.83 10.44 35.44 38.46 31.71 45.37
French
P 28.99 29.53 52.48 62.50 31.35 30.26 31.43 17.58 40.77
R 45.98 26.66 8.59 8.65 44.22 44.60 44.10 63.36 45.85
Fl 35.56 28.02 14.77 15.20 36.69 36.05 36.70 27.53 43.16
</table>
<tableCaption confidence="0.993283">
Table 2: Results on the test set on English and French for the 5 individual paraphrase acquisition techniques (left
part) and for the 2 combination techniques (right part).
</tableCaption>
<bodyText confidence="0.999909352941176">
English to French, compared with from Chinese
to English), which should be consequently eas-
ier to word-align. This is for example clearly
shown by the results of the statistical aligner
GIZA, which obtains a 7.68 advantage on recall
for French over English.
The two linguistically-aware techniques,
FASTR and SYNT, have a very strong precision
on the more parallel French corpus, but fail to
achieve an acceptable recall on their own. This
is not surprising : FASTR metarules are focussed
on term variant extraction, and SYNT requires
two syntactic trees to be highly comparable
to extract sub-sentential paraphrases. When
these constrained conditions are met, these two
techniques appear to perform quite well in terms
of precision.
GIZA and TERp perform roughly in the same
range on French, with acceptable precision and
recall, TERp performing overall better, with e.g.
a 1.14 advantage on F-measure on French and
4.19 on English. The fact that TERp performs
comparatively better on English than on French8,
with a 1.76 advantage on F-measure, is not con-
tradictory: the implemented edit distance makes
it possible to align reasonably distant words and
phrases independently from syntax, and to find
alignments for close remaining words, so the dif-
ferences of performance between the two lan-
guages are not necessarily expected to be com-
parable with the results of a statistical alignment
technique. English being a poorly-inflected lan-
guage, alignment clues between two sentential
paraphrases are expected to be more numerous
</bodyText>
<tableCaption confidence="0.561947">
8Recall that all specific linguistic modules for English
only from TER, had been disabled, so the better perfor-
mance on English cannot be explained by a difference in
terms of resources used.
</tableCaption>
<bodyText confidence="0.997161052631579">
than for highly-inflected French.
PIVOT is on par with GIZA as regards preci-
sion, but obtains a comparatively much lower re-
call (differences of 19.32 and 19.80 on recall on
French and English respectively). This may first
be due in part to the paraphrasing score threshold
used for PIVOT, but most certainly to the use of
a bilingual corpus from the domain of parliamen-
tary debates to extract paraphrases when our test
sets are from the news domain: we may be ob-
serving differences inherent to the domain, and
possibly facing the issue of numerous “out-of-
vocabulary” phrases, in particular for named en-
tities which frequently occur in the news domain.
Importantly, we can note that we obtain at best
a recall of 45.98 on French (GIZA) and of 45.37
on English (TERp). This may come as a disap-
pointment but, given the broad set of techniques
evaluated, this should rather underline the inher-
ent complexity of the task. Also, recall that the
metrics used do not consider identity paraphrases
(e.g. at the same time H at the same time), as
well as the fact that gold standard alignment is
a very difficult process as shown by interjudge
agreement values and our example from section 3.
This, again, confirms that the task that is ad-
dressed is indeed a difficult one, and provides fur-
ther justification for initially focussing on parallel
monolingual corpora, albeit scarce, for conduct-
ing fine-grained studies on sub-sentential para-
phrasing.
Lastly, we can also note that precision is not
very high, with (at best, using TERp,P) average
values for all techniques of 40.97 and 40.46 on
French and English, respectively. Several facts
may provide explanations for this observation.
First, it should be noted that none of those tech-
niques, except SYNT, was originally developed
</bodyText>
<page confidence="0.994643">
721
</page>
<bodyText confidence="0.999988379310345">
for the task of sub-sentential paraphrase acqui-
sition from monolingual parallel corpora. This
results in definitions that are at best closely re-
lated to this task.9 Designing new techniques
was not one of the objectives of our study, so we
have reused existing techniques, originally devel-
oped with different aims (bilingual parallel cor-
pora word alignment (GIZA), term variant recog-
nition (FASTR), Machine Translation evaluation
(TERM,)). Also, techniques such as GIZA and
TERM, attempt to align as many words as possi-
ble in a sentence pair, when gold standard align-
ments sometimes contain gaps.10 Finally, the met-
rics used will count as false small variations of
gold standard paraphrases (e.g. missing function
word): the acceptability or not of such candi-
dates could be either evaluated in a scenario where
such “acceptable” variants would be taken into
account, and could be considered in the context
of some actual use of the acquired paraphrases
in some application. Nonetheless, on average the
techniques in our study produce more candidates
that are not in the gold standard: this will be an
important fact to keep in mind when tackling the
task of combining their outputs. In particular, we
will investigate the use of features indicating the
combination of techniques that predicted a given
paraphrase pair, aiming to capture consensus in-
formation.
</bodyText>
<sectionHeader confidence="0.997653" genericHeader="method">
5 Paraphrase validation
</sectionHeader>
<subsectionHeader confidence="0.998967">
5.1 Technique complementarity
</subsectionHeader>
<bodyText confidence="0.999628444444444">
Before considering combining and validating the
outputs of individual techniques, it is informative
to look at some notion of “complementarity” be-
tween techniques, in terms of how many correct
paraphrases a technique would add to a combined
set. The following formula was used to account
for the complementarity between the set of can-
didates from some technique i, ti, and the set for
some technique j, tj:
</bodyText>
<equation confidence="0.982322">
C(ti,tj) = recall(tiUtj)−max(recall(ti),recall(tj))
</equation>
<bodyText confidence="0.889565285714286">
9Recall, however, that our best performing technique on
F-measure, TER,, was optimized to our task using a held
out development set.
10It is arguable whether such cases should happen in sen-
tence pairs obtained by translating the same original sentence
into the same language, but this clearly depends on the inter-
pretation of the expected level of annotation by the annota-
tors.
Results on the test set for the two languages
are given in Table 3. A number of pairs of tech-
niques have strong complementarity values, the
strongest one being for GIZA and TERM, for both
languages. According to these figures, PIVOT
identify paraphrases which are slightly more sim-
ilar to those of TERM, than those of GIZA. Inter-
estingly, FASTR and SYNT exhibit a strong com-
plementarity, where in French, for instance, they
only have a very small proportion of paraphrases
in common. Considering the set of all other tech-
niques, GIZA provides the more new paraphrases
on French and TERM, on English.
</bodyText>
<table confidence="0.999636076923077">
GIZA PIVOT FASTR SYNT TERM,�R all others
English
GIZA - 4.65 2.83 0.59 10.31 8.31
PIVOT 4.65 - 2.30 1.88 3.12 3.72
FASTR 2.83 2.30 - 2.42 1.71 0.53
SYNT 0.59 1.88 2.42 - 0.59 0.00
TERM,�R 10.31 3.12 1.71 0.59 - 12.20
French
GIZA - 9.79 3.64 2.20 10.73 8.91
PIVOT 9.79 - 2.26 5.22 7.84 3.39
FASTR 3.64 2.26 - 7.28 3.01 0.19
SYNT 2.20 5.22 7.28 - 1.76 0.44
TERM,-R 10.73 7.84 3.01 1.76 - 5.65
</table>
<tableCaption confidence="0.997952">
Table 3: Values of complementarity on the test set for
</tableCaption>
<bodyText confidence="0.960806">
both languages, where the following formula was used
for the set of technique outputs T = {t1, t2, ..., tom,} :
C(ti,tj) = recall(tiUtj)−max(recall(ti), recall(tj)).
Complementarity values are computed between all
pairs of individual techniques, and each individual
technique and the set of all other techniques. Values in
bold indicate highest values for the technique of each
row.
</bodyText>
<subsectionHeader confidence="0.993873">
5.2 Naive combination by union
</subsectionHeader>
<bodyText confidence="0.9999754375">
We first implemented a naive combination ob-
tained by taking the union of all techniques. Re-
sults are given in the first column of the right part
of Table 2. The first result is quite encouraging:
in both languages, more than 6 paraphrases from
the gold standard out of 10 are found by at least
one of the techniques, which, given our previous
discussion, constitutes a good result and provide
a clear justification for combining different tech-
niques for improving performance on this task.
Precision is mechanically lowered to account for
roughly 1 correct paraphrase over 5 candidates
for both languages. F-measure values are much
lower than those of TERM, and GIZA, showing
that the union of all techniques is only interest-
ing for recall-oriented paraphrase acquisition. In
</bodyText>
<page confidence="0.992236">
722
</page>
<bodyText confidence="0.998841666666667">
the next section, we will show how the results of
the union can be validated using machine learning
to improve these figures.
</bodyText>
<subsectionHeader confidence="0.8089305">
5.3 Paraphrase validation via automatic
classification
</subsectionHeader>
<bodyText confidence="0.999671078947369">
A natural improvement to the naive combination
of paraphrase candidates from all techniques can
consist in validating candidate paraphrases by us-
ing several models that may be good indicators of
their paraphrasing status. We can therefore cast
our problem as one of biclass classification (i.e.
“paraphrase” vs. “not paraphrase”).
We have used a maximum entropy classifier11
with the following features, aiming at capturing
information on the paraphrase status of a candi-
date pair:
Morphosyntactic equivalence (POS) It may
be the case that some sequences of part-of-speech
can be rewritten as different sequences, e.g. as
a result of verb nominalization. We therefore
use features to indicate the sequences of part-of-
speech for a pair of candidate paraphrases. We
used the preterminal symbols of the syntactic
trees of the parser used for SYNT.
Character-based distance (CAR) Morpholog-
ical variants often have close word forms, and
more generally close word forms in sentential
paraphase pairs may indicate related words. We
used features for discretized values of the edit
distance between the two phrases of a candidate
paraphrase pair as measured by the Levenshtein
distance.
Stem similarity (STEM) Inflectional morphol-
ogy, which is quite productive in languages such
as French, can increase vocabulary size signifi-
cantly, while in sentential paraphrases common
stems may indicate related words. We used a
binary feature indicating whether the stemmed
phrases of a candidate paraphrase pair match.12
Token set identity (BOW) Syntactic rearrange-
ments may involve the same sets of words in var-
ious orders. We used discretized features indicat-
ing the proportion of common tokens in the set
</bodyText>
<footnote confidence="0.962695333333333">
11We used the implementation available at:
http://homepages.inf.ed.ac.uk/lzhang10/
maxent_toolkit.html
12We use the implementations of the Snowball stem-
mer from English and French available from: http://
snowball.tartarus.org
</footnote>
<bodyText confidence="0.999840891304348">
of tokens for the two phrases of a candidate para-
phrase pair.
Context similarity (CTXT) It can be derived
from the distributionality hypothesis that the more
two phrases will be seen in similar contexts, the
more they are likely to be paraphrases. We used
discretized features indicating how similar the
contexts of occurrences of two paraphrases are.
For this, we used the full set of bilingual English-
French data available for the translation task of
the Workshop on Statistical Machine Transla-
tion13, totalling roughly 30 million parallel sen-
tences: this again ensures that the same resources
are used for experiments in the two languages. We
collect all occurrences for the phrases in a pair,
and build a vector of content words cooccurring
within a distance of 10 words from each phrase.
We finally compute the cosine between the vec-
tors of the two phrases of a candidate paraphrase
pair.
Relative position in a sentence (REL) De-
pending on the language in which parallel sen-
tences are analyzed, it may be the case that sub-
sentential paraphrases occur at close locations in
their respective sentence. We used a discretized
feature indicating the relative position of the two
phrases in their original sentence.
Identity check (COOC) We used a binary fea-
ture indicating whether one of the two phrases
from a candidate pair, or the two, occurred at
some other location in the other sentence.
Phrase length ratio (LEN) We used a dis-
cretized feature indicating phrase length ratio.
Source techniques (SRC) Finally, as our set-
ting validates paraphrase candidates produced by
a set of techniques, we used features indicat-
ing which combination of techniques predicted a
paraphrase candidate. This can allow learning that
paraphrases in the intersection of the predicted
sets for some techniques may produce good re-
sults.
We used a held out training set consisting of
150 sentential paraphrase pairs from the same cor-
pora as our previous developement and test sets
for both languages. Positive examples were taken
from the candidate paraphrase pairs from any of
</bodyText>
<footnote confidence="0.917381">
13http://www.statmt.org/wmt11/
translation-task.html
</footnote>
<page confidence="0.997518">
723
</page>
<bodyText confidence="0.999995324324324">
the 5 techniques in our study which belong to
the gold standard, and we used a corresponding
number of negative examples (randomly selected)
from candidate pairs not in the gold standard. The
right part of Table 2 provides the results for our
validation experiments of the union set for all pre-
vioustechniques.
We obtain our best results for this study using
the output of our validation classifier over the set
of all candidate paraphrase pairs. On French, it
yields an improvement in F-measure (43.16) of
+6.46 over the best individual technique (TERM,)
and of +15.63 over the naive union from all indi-
vidual techniques. On English, the improvement
in F-measure (45.37) is for the same conditions of
respectively +6.91 (over TERM,) and +13.66. We
unfortunately observe an important decrease in re-
call over the naive union, of respectively -17.54
and -19.68 for French and English. Increasing our
amount of training data to better represent the full
range of paraphrase types may certainly overcome
this in part. This would indeed be sensible, as bet-
ter covering the variety of paraphrase types as a
one-time effort would help all subsequent valida-
tions. Figure 2 shows how performance varies on
French with number of training examples for var-
ious feature configurations. However, some para-
phrase types will require integration of more com-
plex knowledge, as is the case, for instance, for
paraphrase pairs involving some anaphora and its
antecedent (e.g. China H it).
While these results, which are very comparable
for the two languages studied, are already satisfy-
ing given the complexity of our task, further in-
spection of false positives and negatives may help
us to develop additional models that will help us
obtain a better classification performance.
</bodyText>
<sectionHeader confidence="0.996358" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999957166666667">
In this article, we have addressed the task of com-
bining the results of sub-sentential paraphrase ac-
quition from parallel monolingual corpora using a
large variety of techniques. We have provided jus-
tifications for using highly parallel corpora con-
sisting of multiply translated sentences from a
single language. All our experiments were con-
ducted on both English and French using com-
parable resources, so although the results cannot
be directly compared they give some acceptable
comparison points. The best recall of any indi-
vidual technique is around 45 for both language,
</bodyText>
<figure confidence="0.946764">
10 20 30 40 50 60 70 80 90 100
% of examples from training corpus
</figure>
<figureCaption confidence="0.996941">
Figure 2: Learning curves obtained on French by re-
moving features individually.
</figureCaption>
<bodyText confidence="0.999921285714286">
and F-measure in the range 36-38, indicating that
the task under study is a very challenging one.
Our validation strategy based on bi-class classi-
fication using a broad set of features applicable to
all candidate paraphrase pairs allowed us to obtain
a 18% relative improvement in F-measure over
the best individual technique for both languages.
Our future work include performing a deeper
error analysis of our current results, to better com-
prehend what characteristics of paraphrase still
defy current validation. Also, we want to inves-
tigate adding new individual techniques to pro-
vide so far unseen candidates. Another possible
approach would be to submit all pairs of sub-
sentential paraphrase pairs from a sentence pair
to our validation process, which would obviously
require some optimization and devising sensible
heuristics to limit time complexity. We also in-
tend to collect larger corpora for all other corpus
types appearing in Table 1 and conducting anew
our acquisition and validation tasks.
</bodyText>
<sectionHeader confidence="0.99495" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999959">
The authors would like to thank the reviewers for
their comments and suggestions, as well as Guil-
laume Wisniewski for helpful discussions. This
work was partly funded by ANR project Edylex
(ANR-09-CORD-008).
</bodyText>
<sectionHeader confidence="0.994632" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.806475">
Ion Androutsopoulos and Prodromos Malakasiotis.
2010. A Survey of Paraphrasing and Textual En-
</reference>
<page confidence="0.964308">
43
</page>
<figure confidence="0.926962642857143">
41
39
37
35
33
31
All
\POS
\SRC
\CTXT
\STEM
\LEN
\COOC
F-measure
</figure>
<page confidence="0.983863">
724
</page>
<reference confidence="0.999840881188119">
tailment Methods. Journal of Artificial Intelligence
Research, 38:135–187.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with Bilingual Parallel Corpora. In Pro-
ceedings of ACL, Ann Arbor, USA.
Regina Barzilay and Lillian Lee. 2003. Learn-
ing to paraphrase: an unsupervised approach us-
ing multiple-sequence alignment. In Proceedings
of NAACL-HLT, Edmonton, Canada.
Regina Barzilay and Kathleen R. McKeown. 2001.
Extracting paraphrases from a parallel corpus. In
Proceedings of ACL, Toulouse, France.
Rahul Bhagat and Deepak Ravichandran. 2008. Large
scale acquisition of paraphrases for learning surface
patterns. In Proceedings of ACL-HLT, Columbus,
USA.
Rahul Bhagat. 2009. Learning Paraphrases from Text.
Ph.D. thesis, University of Southern California.
Houda Bouamor, Aur´elien Max, and Anne Vilnat.
2010. Comparison of Paraphrase Acquisition Tech-
niques on Sentential Paraphrases. In Proceedings of
IceTAL, Rejkavik, Iceland.
Chris Callison-Burch, Trevor Cohn, and Mirella La-
pata. 2008. Parametric: An automatic evaluation
metric for paraphrasing. In Proceedings of COL-
ING, Manchester, UK.
Chris Callison-Burch. 2007. Paraphrasing and Trans-
lation. Ph.D. thesis, University of Edinburgh.
Chris Callison-Burch. 2008. Syntactic Constraints
on Paraphrases Extracted from Parallel Corpora. In
Proceedings of EMNLP, Hawai, USA.
Marie Candito, Benoit Crabb´e, and Pascal Denis.
2010. Statistical French dependency parsing: tree-
bank conversion and first results. In Proceedings of
LREC, Valletta, Malta.
David Chen and William Dolan. 2011. Collecting
highly parallel data for paraphrase evaluation. In
Proceedings of ACL, Portland, USA.
Trevor Cohn, Chris Callison-Burch, and Mirella Lap-
ata. 2008. Constructing corpora for the develop-
ment and evaluation of paraphrase systems. Com-
putational Linguistics, 34(4).
Bill Dolan, Chris Quirk, and Chris Brockett. 2004.
Unsupervised construction of large paraphrase cor-
pora: Exploiting massively parallel news sources.
In Proceedings of COLING, Geneva, Switzerland.
Ulrich Germann. 2008. Yawat : Yet Another Word
Alignment Tool. In Proceedings of the ACL-HLT,
demo session, Columbus, USA.
Christian Jacquemin. 1999. Syntagmatic and paradig-
matic representations of term variation. In Proceed-
ings of ACL, College Park, USA.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of ACL,
Sapporo, Japan.
Philipp Koehn, Hieu Hoang, Alexandra Birch,
Chris Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open Source Toolkit for Statistical Machine
Translation. In Proceedings of ACL, demo session,
Prague, Czech Republic.
Dekang Lin and Patrick Pantel. 2001. Discovery of in-
ference rules for question answering. Natural Lan-
guage Engineering, 7(4):343–360.
Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng.
2010. PEM: A paraphrase evaluation metric ex-
ploiting parallel texts. In Proceedings of EMNLP,
Cambridge, USA.
Nitin Madnani and Bonnie J. Dorr. 2010. Generat-
ing Phrasal and Sentential Paraphrases: A Survey
of Data-Driven Methods . Computational Linguis-
tics, 36(3).
Nitin Madnani. 2010. The Circle of Meaning: From
Translation to Paraphrasing and Back. Ph.D. the-
sis, University of Maryland College Park.
Donald Metzler, Eduard Hovy, and Chunliang Zhang.
2011. An empirical evaluation of data-driven para-
phrase generation techniques. In Proceedings of
ACL-HLT, Portland, USA.
Franz Josef Och and Herman Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. Computational Linguistics, 30(4).
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignement of multiple translations:
Extracting paraphrases and generating new sen-
tences. In Proceedings of NAACL-HLT, Edmonton,
Canada.
Matthew Snover, Nitin Madnani, Bonnie J. Dorr, and
Richard Schwartz. 2010. TER-Plus: paraphrase,
semantic, and alignment enhancements to Transla-
tion Edit Rate. Machine Translation, 23(2-3).
J¨org Tiedemann. 2007. Building a Multilingual Paral-
lel Subtitle Corpus. In Proceedings of the Confer-
ence on Computational Linguistics in the Nether-
lands, Leuven, Belgium.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2008. Pivot Approach for Extracting Paraphrase
Patterns from Bilingual Corpora. In Proceedings
of ACL-HLT, Columbus, USA.
</reference>
<page confidence="0.998437">
725
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.729364">
<title confidence="0.885317">Validation of sub-sentential paraphrases from parallel monolingual corpora</title>
<author confidence="0.979675">Houda Bouamor Aur´elien Max Anne Vilnat</author>
<affiliation confidence="0.998253">LIMSI-CNRS &amp; Univ. Paris</affiliation>
<address confidence="0.981421">Orsay, France</address>
<email confidence="0.999038">firstname.lastname@limsi.fr</email>
<abstract confidence="0.998687458333333">The task of paraphrase acquisition from related sentences can be tackled by a variety of techniques making use of various types of knowledge. In this work, we make the hypothesis that their performance can be increased if candidate paraphrases can be validated using information that characterizes paraphrases independently of the set of techniques that proposed them. We implement this as a bi-class classification prob- (i.e. allowing any paraphrase acquisition technique to be easily integrated into the combination system. We report experiments on two languages, English and French, with 5 individual techniques on parallel monoparallel corpora obtained multiple translation, and a large set of classification features including surface to contextual similarity measures. Relative improvements in F-measure close to 18% are obtained on both languages over the best performing techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ion Androutsopoulos</author>
<author>Prodromos Malakasiotis</author>
</authors>
<title>A Survey of Paraphrasing and Textual Entailment Methods.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>38--135</pages>
<contexts>
<context position="2039" citStr="Androutsopoulos and Malakasiotis, 2010" startWordPosition="313" endWordPosition="316">tterature to refer to textual units of equivalent meaning at the phrasal level (including single words). For instance, the phrases six months and half a year form a paraphrase pair applicable in many different contexts, as they would appropriately denote the same concept. Although one can envisage to manually build high-coverage lists of synonyms, enumerating meaning equivalences at the level of phrases is too daunting a task for humans. Because this type of knowledge can however greatly benefit many NLP applications, automatic acquisition of such paraphrases has attracted a lot of attention (Androutsopoulos and Malakasiotis, 2010; Madnani and Dorr, 2010), and significant research efforts have been devoted to this objective (Callison-Burch, 2007; Bhagat, 2009; Madnani, 2010). Central to acquiring paraphrases is the need of assessing the quality of the candidate paraphrases produced by a given technique. Most works to date have resorted to human evaluation of paraphrases on the levels of grammaticality and meaning equivalence. Human evaluation is however often criticized as being both costly and non reproducible, and the situation is even more complicated by the inherent complexity of the task that can produce low inter</context>
</contexts>
<marker>Androutsopoulos, Malakasiotis, 2010</marker>
<rawString>Ion Androutsopoulos and Prodromos Malakasiotis. 2010. A Survey of Paraphrasing and Textual Entailment Methods. Journal of Artificial Intelligence Research, 38:135–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with Bilingual Parallel Corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="6304" citStr="Bannard and Callison-Burch (2005)" startWordPosition="975" endWordPosition="978">ms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological </context>
<context position="16187" citStr="Bannard and Callison-Burch (2005)" startWordPosition="2546" endWordPosition="2549">e enough training material including minimal redundancy of words. To this end, we provided GIZA++ with all possible sentence pairs from our mutiply-translated corpus to improve the quality of its word alignments (note that 4http://www.elda.org/article125.html 719 we used symmetrized alignments from the alignments in both directions). This constitutes a significant advantage for this technique that techniques working on each sentence pair independently do not have. 4.2 Translational equivalence (Pivot) Translational equivalence can be exploited to determine that two phrases may be paraphrases. Bannard and Callison-Burch (2005) defined a paraphrasing probability between two phrases based on their translation probability through all possible pivot phrases as: �Ppara(P1,P2) � Pt(PZvjP1)Pt(P2jPZv) piv where Pt denotes translation probabilies. We used the Europarl corpus5 of parliamentary debates in English and French, consisting of approximately 1.7 million parallel sentences : this allowed us to use the same resource to build paraphrases for English, using French as the pivot language, and for French, using English as the pivot language. The GIZA++ tool was used for word alignment and the MOSES Statistical Machine Tra</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with Bilingual Parallel Corpora. In Proceedings of ACL, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: an unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="5780" citStr="Barzilay and Lee (2003)" startWordPosition="896" endWordPosition="899">wo phrases, occur in similar contexts then they may be interchangeable has been extensively tested. The distributional hypothesis, attributed to Zellig Harris, was for example applied to syntactic dependency paths in the work of Lin and Pantel (2001). Their results take the form of equivalence patterns with two arguments such as {X asks for Y, X requests Y, X’s request for Y, X wants Y, Y is requested by X, ...}. Using comparable corpora, where the same information probably exists under various linguistic forms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora i</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: an unsupervised approach using multiple-sequence alignment. In Proceedings of NAACL-HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="7340" citStr="Barzilay and McKeown (2001)" startWordPosition="1133" endWordPosition="1136">local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. </context>
<context position="9093" citStr="Barzilay and McKeown, 2001" startWordPosition="1404" endWordPosition="1407">4.46 lexical overlap (tokens) 77.21 61.03 59.50 32.51 39.63 lexical overlap (lemmas content words) 83.77 71.04 64.83 39.54 45.31 translation edit rate (TER) 0.32 0.55 0.76 0.68 0.62 penalized n-gram prec. (BLEU) 0.33 0.15 0.13 0.14 0.39 Table 1: Various indicators of sentence pair comparability for different corpus types. Statistics are reported for French on sets of 100 sentence pairs. We conducted a small-scale study to assess different types of corpora of related sentences: 1. single language translation Corpora obtained by several independent human translation of the same sentences (e.g. (Barzilay and McKeown, 2001)). 2. multiple language translation Same as above, but where a sentence is translated from 4 different languages into the same language (Bouamor et al., 2010). 3. video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011). 4. multiply-translated subtitles Aligned multiple translations of contributed movie subtitles (Tiedemann, 2007). 5. comparable news headlines News headlines collected from Google News clusters (e.g. (Dolan et al., 2004)). We collected 100 sentence pairs of each type in French, for which various comparability measures are repor</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of ACL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Large scale acquisition of paraphrases for learning surface patterns.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="5986" citStr="Bhagat and Ravichandran (2008)" startWordPosition="925" endWordPosition="928">pendency paths in the work of Lin and Pantel (2001). Their results take the form of equivalence patterns with two arguments such as {X asks for Y, X requests Y, X’s request for Y, X wants Y, Y is requested by X, ...}. Using comparable corpora, where the same information probably exists under various linguistic forms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a</context>
</contexts>
<marker>Bhagat, Ravichandran, 2008</marker>
<rawString>Rahul Bhagat and Deepak Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. In Proceedings of ACL-HLT, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
</authors>
<title>Learning Paraphrases from Text.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Southern California.</institution>
<contexts>
<context position="2170" citStr="Bhagat, 2009" startWordPosition="333" endWordPosition="334"> form a paraphrase pair applicable in many different contexts, as they would appropriately denote the same concept. Although one can envisage to manually build high-coverage lists of synonyms, enumerating meaning equivalences at the level of phrases is too daunting a task for humans. Because this type of knowledge can however greatly benefit many NLP applications, automatic acquisition of such paraphrases has attracted a lot of attention (Androutsopoulos and Malakasiotis, 2010; Madnani and Dorr, 2010), and significant research efforts have been devoted to this objective (Callison-Burch, 2007; Bhagat, 2009; Madnani, 2010). Central to acquiring paraphrases is the need of assessing the quality of the candidate paraphrases produced by a given technique. Most works to date have resorted to human evaluation of paraphrases on the levels of grammaticality and meaning equivalence. Human evaluation is however often criticized as being both costly and non reproducible, and the situation is even more complicated by the inherent complexity of the task that can produce low inter-judge agreement. Taskbased evaluation involving the use of paraphrasing into some application thus seem an acceptable solution, pr</context>
</contexts>
<marker>Bhagat, 2009</marker>
<rawString>Rahul Bhagat. 2009. Learning Paraphrases from Text. Ph.D. thesis, University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Houda Bouamor</author>
<author>Aur´elien Max</author>
<author>Anne Vilnat</author>
</authors>
<title>Comparison of Paraphrase Acquisition Techniques on Sentential Paraphrases.</title>
<date>2010</date>
<booktitle>In Proceedings of IceTAL,</booktitle>
<location>Rejkavik, Iceland.</location>
<contexts>
<context position="9251" citStr="Bouamor et al., 2010" startWordPosition="1430" endWordPosition="1433">55 0.76 0.68 0.62 penalized n-gram prec. (BLEU) 0.33 0.15 0.13 0.14 0.39 Table 1: Various indicators of sentence pair comparability for different corpus types. Statistics are reported for French on sets of 100 sentence pairs. We conducted a small-scale study to assess different types of corpora of related sentences: 1. single language translation Corpora obtained by several independent human translation of the same sentences (e.g. (Barzilay and McKeown, 2001)). 2. multiple language translation Same as above, but where a sentence is translated from 4 different languages into the same language (Bouamor et al., 2010). 3. video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011). 4. multiply-translated subtitles Aligned multiple translations of contributed movie subtitles (Tiedemann, 2007). 5. comparable news headlines News headlines collected from Google News clusters (e.g. (Dolan et al., 2004)). We collected 100 sentence pairs of each type in French, for which various comparability measures are reported on Table 1. In particular, the “% aligned tokens” row indicates the proportion of tokens from the sentence pairs that could be manually aligned by a nativ</context>
</contexts>
<marker>Bouamor, Max, Vilnat, 2010</marker>
<rawString>Houda Bouamor, Aur´elien Max, and Anne Vilnat. 2010. Comparison of Paraphrase Acquisition Techniques on Sentential Paraphrases. In Proceedings of IceTAL, Rejkavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Parametric: An automatic evaluation metric for paraphrasing.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="7642" citStr="Callison-Burch et al., 2008" startWordPosition="1180" endWordPosition="1183">m large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. Pairs of related sentences are hand-aligned to define a set of reference atomic paraphrase pairs at the level of words or phrases, denoted as Ratom1. 1Note that in this study we do not distinguish between “Sure” and “Possible” alignments, and when reusing anno717 single language multiple language vide</context>
</contexts>
<marker>Callison-Burch, Cohn, Lapata, 2008</marker>
<rawString>Chris Callison-Burch, Trevor Cohn, and Mirella Lapata. 2008. Parametric: An automatic evaluation metric for paraphrasing. In Proceedings of COLING, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing and Translation.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="2156" citStr="Callison-Burch, 2007" startWordPosition="331" endWordPosition="332">months and half a year form a paraphrase pair applicable in many different contexts, as they would appropriately denote the same concept. Although one can envisage to manually build high-coverage lists of synonyms, enumerating meaning equivalences at the level of phrases is too daunting a task for humans. Because this type of knowledge can however greatly benefit many NLP applications, automatic acquisition of such paraphrases has attracted a lot of attention (Androutsopoulos and Malakasiotis, 2010; Madnani and Dorr, 2010), and significant research efforts have been devoted to this objective (Callison-Burch, 2007; Bhagat, 2009; Madnani, 2010). Central to acquiring paraphrases is the need of assessing the quality of the candidate paraphrases produced by a given technique. Most works to date have resorted to human evaluation of paraphrases on the levels of grammaticality and meaning equivalence. Human evaluation is however often criticized as being both costly and non reproducible, and the situation is even more complicated by the inherent complexity of the task that can produce low inter-judge agreement. Taskbased evaluation involving the use of paraphrasing into some application thus seem an acceptabl</context>
</contexts>
<marker>Callison-Burch, 2007</marker>
<rawString>Chris Callison-Burch. 2007. Paraphrasing and Translation. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic Constraints on Paraphrases Extracted from Parallel Corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Hawai, USA.</location>
<contexts>
<context position="6543" citStr="Callison-Burch (2008)" startWordPosition="1015" endWordPosition="1016">des local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple transl</context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic Constraints on Paraphrases Extracted from Parallel Corpora. In Proceedings of EMNLP, Hawai, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
<author>Pascal Denis</author>
</authors>
<title>Statistical French dependency parsing: treebank conversion and first results.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Valletta,</location>
<marker>Candito, Crabb´e, Denis, 2010</marker>
<rawString>Marie Candito, Benoit Crabb´e, and Pascal Denis. 2010. Statistical French dependency parsing: treebank conversion and first results. In Proceedings of LREC, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chen</author>
<author>William Dolan</author>
</authors>
<title>Collecting highly parallel data for paraphrase evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Portland, USA.</location>
<contexts>
<context position="7682" citStr="Chen and Dolan, 2011" startWordPosition="1188" endWordPosition="1191">lingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. Pairs of related sentences are hand-aligned to define a set of reference atomic paraphrase pairs at the level of words or phrases, denoted as Ratom1. 1Note that in this study we do not distinguish between “Sure” and “Possible” alignments, and when reusing anno717 single language multiple language video descriptions multiply-translated news </context>
<context position="9363" citStr="Chen and Dolan, 2011" startWordPosition="1446" endWordPosition="1449"> pair comparability for different corpus types. Statistics are reported for French on sets of 100 sentence pairs. We conducted a small-scale study to assess different types of corpora of related sentences: 1. single language translation Corpora obtained by several independent human translation of the same sentences (e.g. (Barzilay and McKeown, 2001)). 2. multiple language translation Same as above, but where a sentence is translated from 4 different languages into the same language (Bouamor et al., 2010). 3. video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011). 4. multiply-translated subtitles Aligned multiple translations of contributed movie subtitles (Tiedemann, 2007). 5. comparable news headlines News headlines collected from Google News clusters (e.g. (Dolan et al., 2004)). We collected 100 sentence pairs of each type in French, for which various comparability measures are reported on Table 1. In particular, the “% aligned tokens” row indicates the proportion of tokens from the sentence pairs that could be manually aligned by a native-speaker annotator.2 Obviously, the more common tokens two sentences from a pair contain, the fewer subsententi</context>
</contexts>
<marker>Chen, Dolan, 2011</marker>
<rawString>David Chen and William Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Proceedings of ACL, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Chris Callison-Burch</author>
<author>Mirella Lapata</author>
</authors>
<title>Constructing corpora for the development and evaluation of paraphrase systems.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="7311" citStr="Cohn et al., 2008" startWordPosition="1129" endWordPosition="1132">nsists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-senten</context>
<context position="12258" citStr="Cohn et al., 2008" startWordPosition="1913" endWordPosition="1916">ly 260 H 0.26 and million H billion is assuredly an error, while the pair 260 million H 0.26 billion would have been appropriate. A case of alignment that seems non trivial can be observed in the provided example (during the entire year H annual). The abovementioned reasons will explain in part the difficulties in reaching high performance values using such gold standards. Reference composite paraphrase pairs (denoted as R), obtained by joining adjacent atomic paraphrase pairs from Ratom up to 6 tokens3, will 3We used standard biphrase extraction heuristics (Koehn 718 the corpus described in (Cohn et al., 2008), consistannual ing of multiply-translated Chinese sentences into foreign English, and used as our gold standard both the investment alignments marked as “Sure” and “Possible”. For actually French, we used the CESTA corpus of news arused ticles4 obtained by translating into French from amounted English. to We used the YAWAT (Germann, 2008) manual us$ alignment tool. Inter-annotator agreement val0.26 ues (averaging with each annotation set as the billion gold standard) are 66.1 for English and 64.6 for French, which we interpret as acceptable values. Manual inspection of the two corpora reveals</context>
<context position="13883" citStr="Cohn et al., 2008" startWordPosition="2176" endWordPosition="2179">lion us dollars ↔ us$ Figure 1: Reference alignments for a pair of English sentential paraphrases from the annotation corpus of Cohn et al. (2008) (note that possible and sure alignments are not distinguished here) and the list of atomic paraphrase pairs extracted from these alignments. also be considered when measuring performance. Evaluated techniques have to output atomic candidate paraphrase pairs (denoted as Hatom) from which composite paraphrase pairs (denoted as H) are computed. The usual measures of precision (P), recall (R) and F-measure (Fl) can then be defined in the following way (Cohn et al., 2008): _ |Hatom ∩ R |_ |H ∩ Ratom |_ 2pr P |Hatom |R |Ratom |F1 p + r We conducted experiments using two different corpora in English and French. In each case, a held-out development corpus of 150 sentential paraphrase pairs was used for development and tuning, and all techniques were evaluated on the same test set consisting of 375 sentential paraphrase pairs. For English, we used the MTC et al., 2007) : all words from a phrase must be aligned to at least one word from the other and not to words outside, but unaligned words at phrase boundaries are not used. 4 Individual techniques for paraphrase </context>
</contexts>
<marker>Cohn, Callison-Burch, Lapata, 2008</marker>
<rawString>Trevor Cohn, Chris Callison-Burch, and Mirella Lapata. 2008. Constructing corpora for the development and evaluation of paraphrase systems. Computational Linguistics, 34(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="9584" citStr="Dolan et al., 2004" startWordPosition="1477" endWordPosition="1480">e translation Corpora obtained by several independent human translation of the same sentences (e.g. (Barzilay and McKeown, 2001)). 2. multiple language translation Same as above, but where a sentence is translated from 4 different languages into the same language (Bouamor et al., 2010). 3. video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011). 4. multiply-translated subtitles Aligned multiple translations of contributed movie subtitles (Tiedemann, 2007). 5. comparable news headlines News headlines collected from Google News clusters (e.g. (Dolan et al., 2004)). We collected 100 sentence pairs of each type in French, for which various comparability measures are reported on Table 1. In particular, the “% aligned tokens” row indicates the proportion of tokens from the sentence pairs that could be manually aligned by a native-speaker annotator.2 Obviously, the more common tokens two sentences from a pair contain, the fewer subsentential paraphrases may be extracted from that pair. However, high lexical overlap increases the probability that two sentences be indeed paraphrases, and in turn the probability that some of their phrases be paraphrases. Furt</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of COLING, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Germann</author>
</authors>
<title>Yawat : Yet Another Word Alignment Tool.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-HLT, demo session,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="10364" citStr="Germann, 2008" startWordPosition="1603" endWordPosition="1604"> indicates the proportion of tokens from the sentence pairs that could be manually aligned by a native-speaker annotator.2 Obviously, the more common tokens two sentences from a pair contain, the fewer subsentential paraphrases may be extracted from that pair. However, high lexical overlap increases the probability that two sentences be indeed paraphrases, and in turn the probability that some of their phrases be paraphrases. Furthermore, the tated corpora using them we considered all alignments as being correct. 2The same annotator hand-aligned the 5*100=500 paraphrase pairs using the YAWAT (Germann, 2008) manual alignment tool. presence of common token may serve as useful clues to guide paraphrase extraction. For our experiments, we chose to use parallel monolingual corpora obtained by single language translation, the most direct resource type for acquiring sub-sentential paraphrase pairs. This allows us to define acceptable references for the task and resort to the most consensual evaluation technique for paraphrase acquisition to date. Using such corpora, we expect to be able to extract precise paraphrases (see Table 1), which will be natural candidates for further validation, which will be </context>
<context position="12599" citStr="Germann, 2008" startWordPosition="1968" endWordPosition="1969">ues using such gold standards. Reference composite paraphrase pairs (denoted as R), obtained by joining adjacent atomic paraphrase pairs from Ratom up to 6 tokens3, will 3We used standard biphrase extraction heuristics (Koehn 718 the corpus described in (Cohn et al., 2008), consistannual ing of multiply-translated Chinese sentences into foreign English, and used as our gold standard both the investment alignments marked as “Sure” and “Possible”. For actually French, we used the CESTA corpus of news arused ticles4 obtained by translating into French from amounted English. to We used the YAWAT (Germann, 2008) manual us$ alignment tool. Inter-annotator agreement val0.26 ues (averaging with each annotation set as the billion gold standard) are 66.1 for English and 64.6 for French, which we interpret as acceptable values. Manual inspection of the two corpora reveals that the French corpus tends to contain more literal translations, possibly due to the original languages of the sentences, which are closer to the target language than Chinese is to English. the amount of foreign capital actually utilized during the entire year reached 260 million us dollars capital ↔ investment utilized ↔ used during th</context>
</contexts>
<marker>Germann, 2008</marker>
<rawString>Ulrich Germann. 2008. Yawat : Yet Another Word Alignment Tool. In Proceedings of the ACL-HLT, demo session, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Syntagmatic and paradigmatic representations of term variation.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>College Park, USA.</location>
<contexts>
<context position="6782" citStr="Jacquemin (1999)" startWordPosition="1053" endWordPosition="1054">more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis </context>
<context position="17314" citStr="Jacquemin, 1999" startWordPosition="2718" endWordPosition="2719">nguage. The GIZA++ tool was used for word alignment and the MOSES Statistical Machine Translation toolkit (Koehn et al., 2007) was used to compute phrase translation probabilities from these word alignments. For each sentential paraphrase pair, we applied the following algorithm: for each phrase, we build the entire set of paraphrases using the previous definition. We then extract its best paraphrase as the one exactly appearing in the other sentence with maximum paraphrase probability, using a minimal threshold value of 10−4. 4.3 Linguistic knowledge on term variation (Fastr) The FASTR tool (Jacquemin, 1999) was designed to spot term/phrase variants in large corpora. Variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on word morphosyntactic categories. Paradigmatic variation can also be expressed by expressing constraints between words, imposing that they be of the same morphological or semantic family. Both constraints rely on preexisting repertoires available for English and French. To compute candidate paraphrase pairs using FASTR, we first consider all phrases from 5http://sta</context>
</contexts>
<marker>Jacquemin, 1999</marker>
<rawString>Christian Jacquemin. 1999. Syntagmatic and paradigmatic representations of term variation. In Proceedings of ACL, College Park, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="18503" citStr="Klein and Manning, 2003" startWordPosition="2897" endWordPosition="2901">nsider all phrases from 5http://statmt.org/europarl the first sentence and search for variants in the other sentence, then do the reverse process and finally take the intersection of the two sets. 4.4 Syntactic similarity (Synt) The algorithm introduced by Pang et al. (2003) takes two sentences as input and merges them by top-down syntactic fusion guided by compatible syntactic substructure. A lexical blocking mechanism prevents constituents from fusionning when there is evidence of the presence of a word in another constituent of one of the sentence. We use the Berkeley Probabilistic parser (Klein and Manning, 2003) to obtain syntactic trees for English and its adapted version for French (Candito et al., 2010). Because this process is highly sensitive to syntactic parse errors, we use in our implementation k-best parses and retain the most compact fusion from any pair of candidate parses. 4.5 Edit rate on word sequences (TERp) TERp (Translation Edit Rate Plus) (Snover et al., 2010) is a score designed for the evaluation of Machine Translation output. Its typical use takes a system hypothesis to compute an optimal set of word edits that can transform it into some existing reference translation. Edit types</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of ACL, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL, demo session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="16824" citStr="Koehn et al., 2007" startWordPosition="2640" endWordPosition="2643">asing probability between two phrases based on their translation probability through all possible pivot phrases as: �Ppara(P1,P2) � Pt(PZvjP1)Pt(P2jPZv) piv where Pt denotes translation probabilies. We used the Europarl corpus5 of parliamentary debates in English and French, consisting of approximately 1.7 million parallel sentences : this allowed us to use the same resource to build paraphrases for English, using French as the pivot language, and for French, using English as the pivot language. The GIZA++ tool was used for word alignment and the MOSES Statistical Machine Translation toolkit (Koehn et al., 2007) was used to compute phrase translation probabilities from these word alignments. For each sentential paraphrase pair, we applied the following algorithm: for each phrase, we build the entire set of paraphrases using the previous definition. We then extract its best paraphrase as the one exactly appearing in the other sentence with maximum paraphrase probability, using a minimal threshold value of 10−4. 4.3 Linguistic knowledge on term variation (Fastr) The FASTR tool (Jacquemin, 1999) was designed to spot term/phrase variants in large corpora. Variants are described through metarules expressi</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings of ACL, demo session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="5407" citStr="Lin and Pantel (2001)" startWordPosition="831" endWordPosition="835">l setting in section 3 and the individual techniques that we have studied in section 4. Section 5 is devoted to our approach for validating paraphrases proposed by individual techniques. Finally, section 6 concludes the article and presents some of our future work in the area of paraphrase acquisition. 2 Related work The hypothesis that if two words or, by extension, two phrases, occur in similar contexts then they may be interchangeable has been extensively tested. The distributional hypothesis, attributed to Zellig Harris, was for example applied to syntactic dependency paths in the work of Lin and Pantel (2001). Their results take the form of equivalence patterns with two arguments such as {X asks for Y, X requests Y, X’s request for Y, X wants Y, Y is requested by X, ...}. Using comparable corpora, where the same information probably exists under various linguistic forms, increases the likelihood of finding very close contexts for sub-sentential units. Barzilay and Lee (2003) proposed a multi-sequence alignment algorithm that takes structurally similar sentences and builds a compact lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an applica</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chang Liu</author>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>PEM: A paraphrase evaluation metric exploiting parallel texts.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="7660" citStr="Liu et al., 2010" startWordPosition="1184" endWordPosition="1187">When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. Pairs of related sentences are hand-aligned to define a set of reference atomic paraphrase pairs at the level of words or phrases, denoted as Ratom1. 1Note that in this study we do not distinguish between “Sure” and “Possible” alignments, and when reusing anno717 single language multiple language video descriptions mul</context>
</contexts>
<marker>Liu, Dahlmeier, Ng, 2010</marker>
<rawString>Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng. 2010. PEM: A paraphrase evaluation metric exploiting parallel texts. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Generating Phrasal and Sentential Paraphrases: A Survey of Data-Driven Methods .</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="2064" citStr="Madnani and Dorr, 2010" startWordPosition="317" endWordPosition="320">quivalent meaning at the phrasal level (including single words). For instance, the phrases six months and half a year form a paraphrase pair applicable in many different contexts, as they would appropriately denote the same concept. Although one can envisage to manually build high-coverage lists of synonyms, enumerating meaning equivalences at the level of phrases is too daunting a task for humans. Because this type of knowledge can however greatly benefit many NLP applications, automatic acquisition of such paraphrases has attracted a lot of attention (Androutsopoulos and Malakasiotis, 2010; Madnani and Dorr, 2010), and significant research efforts have been devoted to this objective (Callison-Burch, 2007; Bhagat, 2009; Madnani, 2010). Central to acquiring paraphrases is the need of assessing the quality of the candidate paraphrases produced by a given technique. Most works to date have resorted to human evaluation of paraphrases on the levels of grammaticality and meaning equivalence. Human evaluation is however often criticized as being both costly and non reproducible, and the situation is even more complicated by the inherent complexity of the task that can produce low inter-judge agreement. Taskbas</context>
</contexts>
<marker>Madnani, Dorr, 2010</marker>
<rawString>Nitin Madnani and Bonnie J. Dorr. 2010. Generating Phrasal and Sentential Paraphrases: A Survey of Data-Driven Methods . Computational Linguistics, 36(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
</authors>
<title>The Circle of Meaning: From Translation to Paraphrasing and Back.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Maryland College Park.</institution>
<contexts>
<context position="2186" citStr="Madnani, 2010" startWordPosition="335" endWordPosition="336">rase pair applicable in many different contexts, as they would appropriately denote the same concept. Although one can envisage to manually build high-coverage lists of synonyms, enumerating meaning equivalences at the level of phrases is too daunting a task for humans. Because this type of knowledge can however greatly benefit many NLP applications, automatic acquisition of such paraphrases has attracted a lot of attention (Androutsopoulos and Malakasiotis, 2010; Madnani and Dorr, 2010), and significant research efforts have been devoted to this objective (Callison-Burch, 2007; Bhagat, 2009; Madnani, 2010). Central to acquiring paraphrases is the need of assessing the quality of the candidate paraphrases produced by a given technique. Most works to date have resorted to human evaluation of paraphrases on the levels of grammaticality and meaning equivalence. Human evaluation is however often criticized as being both costly and non reproducible, and the situation is even more complicated by the inherent complexity of the task that can produce low inter-judge agreement. Taskbased evaluation involving the use of paraphrasing into some application thus seem an acceptable solution, provided the evalu</context>
</contexts>
<marker>Madnani, 2010</marker>
<rawString>Nitin Madnani. 2010. The Circle of Meaning: From Translation to Paraphrasing and Back. Ph.D. thesis, University of Maryland College Park.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>Eduard Hovy</author>
<author>Chunliang Zhang</author>
</authors>
<title>An empirical evaluation of data-driven paraphrase generation techniques.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Portland, USA.</location>
<contexts>
<context position="7705" citStr="Metzler et al., 2011" startWordPosition="1192" endWordPosition="1195">d at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. Pairs of related sentences are hand-aligned to define a set of reference atomic paraphrase pairs at the level of words or phrases, denoted as Ratom1. 1Note that in this study we do not distinguish between “Sure” and “Possible” alignments, and when reusing anno717 single language multiple language video descriptions multiply-translated news headlines translation t</context>
</contexts>
<marker>Metzler, Hovy, Zhang, 2011</marker>
<rawString>Donald Metzler, Eduard Hovy, and Chunliang Zhang. 2011. An empirical evaluation of data-driven paraphrase generation techniques. In Proceedings of ACL-HLT, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Herman Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="15247" citStr="Och and Ney, 2004" startWordPosition="2407" endWordPosition="2410">ork. In this work, we consider the scenario where sentential paraphrases are available and words and phrases from one sentence can be aligned to words and phrases from the other sentence to form atomic paraphrase pairs. We now describe several techniques that perform the task of sub-sentential unit alignment. We have selected and implemented five techniques which we believe are representative of the type of knowledge that these techniques use, and have reused existing tools, initially developed for other tasks, when possible. 4.1 Statistical learning of word alignments (Giza) The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. While originally developed in the bilingual context of Statistical Machine Translation, nothing prevents building such models on monolingual corpora. However, in order to build reliable models, it is necessary to use enough training material including minimal redundancy of words. To this end, we provided GIZA++ with all possible sentence pairs from our mutiply-translated corpus to improve the quality of its word alignments (note that 4http://www.elda.org/article125.html 719 we used symmetrized alignment</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Herman Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignement of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="7432" citStr="Pang et al. (2003)" startWordPosition="1147" endWordPosition="1150">ariants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level are available (e.g. multiple translations into the same language), the task of sub-sentential paraphrase acquisition can be cast as one of word alignment between two aligned sentences (Cohn et al., 2008). Barzilay and McKeown (2001) applied the distributionality hypothesis on such parallel sentences, and Pang et al. (2003) proposed an algorithm to align sentences by recursive fusion of their common syntactic constituants. Finally, they has been a recent interest in automatic evaluation of paraphrases (Callison-Burch et al., 2008; Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011). 3 Experimental setting We used the main aspects of the methodology described by Cohn et al. (2008) for constructing evaluation corpora and assessing the performance of techniques on the task of sub-sentential paraphrase acquisition. Pairs of related sentences are hand-aligned to define a set of reference atomic paraphrase p</context>
<context position="18154" citStr="Pang et al. (2003)" startWordPosition="2842" endWordPosition="2845">essions on word morphosyntactic categories. Paradigmatic variation can also be expressed by expressing constraints between words, imposing that they be of the same morphological or semantic family. Both constraints rely on preexisting repertoires available for English and French. To compute candidate paraphrase pairs using FASTR, we first consider all phrases from 5http://statmt.org/europarl the first sentence and search for variants in the other sentence, then do the reverse process and finally take the intersection of the two sets. 4.4 Syntactic similarity (Synt) The algorithm introduced by Pang et al. (2003) takes two sentences as input and merges them by top-down syntactic fusion guided by compatible syntactic substructure. A lexical blocking mechanism prevents constituents from fusionning when there is evidence of the presence of a word in another constituent of one of the sentence. We use the Berkeley Probabilistic parser (Klein and Manning, 2003) to obtain syntactic trees for English and its adapted version for French (Candito et al., 2010). Because this process is highly sensitive to syntactic parse errors, we use in our implementation k-best parses and retain the most compact fusion from an</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignement of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of NAACL-HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>TER-Plus: paraphrase, semantic, and alignment enhancements to Translation Edit Rate.</title>
<date>2010</date>
<journal>Machine Translation,</journal>
<pages>23--2</pages>
<contexts>
<context position="18876" citStr="Snover et al., 2010" startWordPosition="2960" endWordPosition="2963">tic substructure. A lexical blocking mechanism prevents constituents from fusionning when there is evidence of the presence of a word in another constituent of one of the sentence. We use the Berkeley Probabilistic parser (Klein and Manning, 2003) to obtain syntactic trees for English and its adapted version for French (Candito et al., 2010). Because this process is highly sensitive to syntactic parse errors, we use in our implementation k-best parses and retain the most compact fusion from any pair of candidate parses. 4.5 Edit rate on word sequences (TERp) TERp (Translation Edit Rate Plus) (Snover et al., 2010) is a score designed for the evaluation of Machine Translation output. Its typical use takes a system hypothesis to compute an optimal set of word edits that can transform it into some existing reference translation. Edit types include exact word matching, word insertion and deletion, block movement of contiguous words (computed as an approximation), as well as optionally variants substitution through stemming, synonym or paraphrase matching.6 Each edit type is parameterized by at least one weight which can be optimized using e.g. hill climbing. TERp being a tunable metric, our experiments wil</context>
<context position="20213" citStr="Snover et al. (2010)" startWordPosition="3186" endWordPosition="3189">ndividual techniques Results for the 5 individual techniques are given on the left part of Table 2. It is first apparent that all techniques but TERp fared better on the French corpus than on the English corpus. This can certainly be explained by the fact that the former results from more literal translations (from 6Note that for these experiments we did not use the stemming module, the interface to WordNet for synonym matching and the provided paraphrase table for English, due to the fact that these resources were available for English only. 7Hill climbing was used for all tunings as done by Snover et al. (2010), and we used one iteration starting with uniform weights and 100 random restarts. 720 Individual techniques Combinations GIZA PIVOT FASTR SYNT P -ER -, F1 union validation English P 31.01 31.78 37.38 52.17 50.00 29.15 33.37 21.44 50.51 R 38.30 18.50 6.71 2.53 5.83 45.19 45.37 60.87 41.19 Fl 34.27 23.39 11.38 4.83 10.44 35.44 38.46 31.71 45.37 French P 28.99 29.53 52.48 62.50 31.35 30.26 31.43 17.58 40.77 R 45.98 26.66 8.59 8.65 44.22 44.60 44.10 63.36 45.85 Fl 35.56 28.02 14.77 15.20 36.69 36.05 36.70 27.53 43.16 Table 2: Results on the test set on English and French for the 5 individual para</context>
</contexts>
<marker>Snover, Madnani, Dorr, Schwartz, 2010</marker>
<rawString>Matthew Snover, Nitin Madnani, Bonnie J. Dorr, and Richard Schwartz. 2010. TER-Plus: paraphrase, semantic, and alignment enhancements to Translation Edit Rate. Machine Translation, 23(2-3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Building a Multilingual Parallel Subtitle Corpus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics in the Netherlands,</booktitle>
<location>Leuven, Belgium.</location>
<contexts>
<context position="9476" citStr="Tiedemann, 2007" startWordPosition="1462" endWordPosition="1463">onducted a small-scale study to assess different types of corpora of related sentences: 1. single language translation Corpora obtained by several independent human translation of the same sentences (e.g. (Barzilay and McKeown, 2001)). 2. multiple language translation Same as above, but where a sentence is translated from 4 different languages into the same language (Bouamor et al., 2010). 3. video descriptions Descriptions of short YouTube videos obtained via Mechanical Turk (Chen and Dolan, 2011). 4. multiply-translated subtitles Aligned multiple translations of contributed movie subtitles (Tiedemann, 2007). 5. comparable news headlines News headlines collected from Google News clusters (e.g. (Dolan et al., 2004)). We collected 100 sentence pairs of each type in French, for which various comparability measures are reported on Table 1. In particular, the “% aligned tokens” row indicates the proportion of tokens from the sentence pairs that could be manually aligned by a native-speaker annotator.2 Obviously, the more common tokens two sentences from a pair contain, the fewer subsentential paraphrases may be extracted from that pair. However, high lexical overlap increases the probability that two </context>
</contexts>
<marker>Tiedemann, 2007</marker>
<rawString>J¨org Tiedemann. 2007. Building a Multilingual Parallel Subtitle Corpus. In Proceedings of the Conference on Computational Linguistics in the Netherlands, Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="6508" citStr="Zhao et al. (2008)" startWordPosition="1008" endWordPosition="1011">lattice representation that encodes local variations. The work by Bhagat and Ravichandran (2008) describes an application of a similar technique on a very large scale. The hypothesis that two words or phrases are interchangeable if they share a common translation into one or more other languages has also been extensively studied in works on subsentential paraphrase acquisition. Bannard and Callison-Burch (2005) described a pivoting approach that can exploit bilingual parallel corpora in several languages. The same technique has been applied to the acquisition of local paraphrasing patterns in Zhao et al. (2008). The work of Callison-Burch (2008) has shown how the monolingual context of a sentence to paraphrase can be used to improve the quality of the acquired paraphrases. Another approach consists in modelling local paraphrasing identification rules. The work of Jacquemin (1999) on the identification of term variants, which exploits rewriting morphosyntactic rules and descriptions of morphological and semantic lexical families, can be extended to extract the various forms corresponding to input patterns from large monolingual corpora. When parallel monolingual corpora aligned at the sentence level </context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2008</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2008. Pivot Approach for Extracting Paraphrase Patterns from Bilingual Corpora. In Proceedings of ACL-HLT, Columbus, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>