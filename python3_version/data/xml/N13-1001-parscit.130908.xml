<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007431">
<title confidence="0.97442">
Model With Minimal Translation Units, But Decode With Phrases
</title>
<author confidence="0.99666">
Nadir Durrani* Alexander Fraser Helmut Schmid
</author>
<affiliation confidence="0.999891">
University of Edinburgh University of Stuttgart
</affiliation>
<email confidence="0.995775">
dnadir@inf.ed.ac.uk fraser,schmid@ims.uni-stuttgart.de
</email>
<sectionHeader confidence="0.99561" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999623818181818">
N-gram-based models co-exist with their
phrase-based counterparts as an alternative
SMT framework. Both techniques have pros
and cons. While the N-gram-based frame-
work provides a better model that captures
both source and target contexts and avoids
spurious phrasal segmentation, the ability to
memorize and produce larger translation units
gives an edge to the phrase-based systems dur-
ing decoding, in terms of better search per-
formance and superior selection of transla-
tion units. In this paper we combine N-gram-
based modeling with phrase-based decoding,
and obtain the benefits of both approaches.
Our experiments show that using this combi-
nation not only improves the search accuracy
of the N-gram model but that it also improves
the BLEU scores. Our system outperforms
state-of-the-art phrase-based systems (Moses
and Phrasal) and N-gram-based systems by
a significant margin on German, French and
Spanish to English translation tasks.
</bodyText>
<sectionHeader confidence="0.999129" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9875471">
Statistical Machine Translation advanced from
word-based models (Brown et al., 1993) towards
more sophisticated models that take contextual in-
formation into account. Phrase-based (Och and
Ney, 2004; Koehn et al., 2003) and N-gram-based
(Mari˜no et al., 2006) models are two instances of
such frameworks. While the two models have some
common properties, they are substantially different.
Much of the work presented here was carried out while the
first author was at the University of Stuttgart.
</bodyText>
<page confidence="0.849066">
1
</page>
<bodyText confidence="0.999719551724138">
Phrase-based systems employ a simple and effec-
tive machinery by learning larger chunks of trans-
lation called phrases1. Memorizing larger units en-
ables the phrase-based model to learn local depen-
dencies such as short reorderings, idioms, insertions
and deletions, etc. The model however, has the fol-
lowing drawbacks: i) it makes independence as-
sumptions over phrases ignoring the contextual in-
formation outside of phrases ii) it has issues han-
dling long-distance reordering iii) it has the spurious
phrasal segmentation problem which allows multi-
ple derivations of a bilingual sentence pair having
different model scores for each segmentation.
Modeling with minimal translation units helps ad-
dress some of these issues. The N-gram-based SMT
framework is based on tuples. Tuples are mini-
mal translation units composed of source and target
cepts2. N-gram-based models are Markov models
over sequences of tuples (Mari˜no et al., 2006; Crego
and Mari˜no, 2006) or operations encapsulating tu-
ples (Durrani et al., 2011). This mechanism has sev-
eral useful properties. Firstly, no phrasal indepen-
dence assumption is made. The model has access
to both source and target context outside of phrases.
Secondly the model learns a unique derivation of a
bilingual sentence given its alignment, thus avoiding
the spurious segmentation problem.
Using minimal translation units, however, results
in a higher number of search errors because of i)
</bodyText>
<footnote confidence="0.997879333333333">
1A phrase-pair in PBSMT is a sequence of source and target
words that is translation of each other, and is not necessarily a
linguistic constituent. Phrases are built by combining minimal
translation units and ordering information.
2A cept is a group of words in one language that is translated
as a minimal unit in one specific context (Brown et al., 1993).
</footnote>
<note confidence="0.5780685">
Proceedings of NAACL-HLT 2013, pages 1–11,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.993627479166667">
poor translation selection, ii) inaccurate future-cost
estimates and iii) incorrect early pruning of hypothe-
ses that would produce better model scores if al-
lowed to continue. In order to deal with these
problems, search is carried out only on a graph
of pre-calculated orderings, and ad-hoc reordering
limits are imposed to constrain the search space
(Crego et al., 2005; Crego and Mari˜no, 2006), or
a higher beam size is used in decoding (Durrani
et al., 2011). The ability to memorize and pro-
duce larger translation chunks during decoding, on
the other hand, gives a distinct advantage to the
phrase-based system during search. Phrase-based
systems i) have access to uncommon translations,
ii) do not require higher beam sizes, iii) have more
accurate future-cost estimates because of the avail-
ability of phrase-internal language model context
before search is started. To illustrate this consider
the German-English phrase-pair “schoß ein Tor –
scored a goal”, composed from the tuples (cept-
pairs) “schoß – scored”, “ein – a” and “Tor – goal”.
It is likely that the N-gram system does not have
the tuple “schoß – scored” in its n-best translation
options because “scored” is an uncommon transla-
tion for “schoß” outside the sports domain. Even if
“schoß – scored” is hypothesized, it will be ranked
quite low in the stack until “ein” and “Tor” are gen-
erated in the next steps. A higher beam is required
to prevent it from getting pruned. Phrase-based sys-
tems, on the other hand, are likely to have access to
the phrasal unit “schoß ein Tor – scored a goal” and
can generate it in a single step. Moreover, a more ac-
curate future-cost estimate can be computed because
of the available context internal to the phrase.
In this work, we extend the N-gram model, based
on operation sequences (Durrani et al., 2011), to
use phrases during decoding. The main idea is to
study whether a combination of modeling with min-
imal translation units and using phrasal information
during decoding helps to solve the above-mentioned
problems.
The remainder of this paper is organized as fol-
lows. The next two sections review phrase-based
and N-gram-based SMT. Section 2 provides a com-
parison of phrase-based and N-gram-based SMT.
Section 3 summarizes the operation sequence model
(OSM), the main baseline for this work. Section
4 analyzes the search problem when decoding with
</bodyText>
<figureCaption confidence="0.992634">
Figure 1: Different Segmentations of a Bilingual Sen-
tence Pair
</figureCaption>
<bodyText confidence="0.999747272727273">
minimal units. Section 5 discusses how information
available in phrases can be used to improve search
performance. Section 6 presents the results of this
work. We conducted experiments on the German-to-
English and French-to-English translation tasks and
found that using phrases in decoding improves both
search accuracy and BLEU scores. Finally we com-
pare our system with two state-of-the-art phrase-
based systems (Moses and Phrasal) and two state-
of-the-art N-gram-based systems (Ncode and OSM)
on standard translation tasks.
</bodyText>
<sectionHeader confidence="0.993558" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.99948272">
Phrase-based and N-gram-based SMT are alter-
native frameworks for string-to-string translation.
Phrase-based SMT segments a bilingual sentence
pair into phrases that are continuous sequences of
words (Och and Ney, 2004; Koehn et al., 2003)
or discontinuous sequences of words (Galley and
Manning, 2010). These phrases are then reordered
through a lexicalized reordering model that takes
into account the orientation of a phrase with respect
to its previous phrase (Tillmann and Zhang, 2005)
or block of phrases (Galley and Manning, 2008).
There are several drawbacks of the phrase-based
model. Firstly it makes an independence assump-
tion over phrases, according to which phrases are
translated independently of each other, thus ignor-
ing the contextual information outside of the phrasal
boundary. This problem is corrected by the monolin-
gual language model that takes context into account.
But often the language model cannot compensate for
the dispreference of the translation model for non-
local dependencies. The second problem is that the
model is unaware of the actual phrasal segmentation
of a sentence during training. It therefore learns all
possible ways of segmenting a bilingual sentence.
Different segmentations of a bilingual sentence re-
</bodyText>
<page confidence="0.988277">
2
</page>
<bodyText confidence="0.996474864583334">
sult in different probability scores for the translation
and reordering models, causing spurious ambiguity
in the model. See Figure 1. In the first segmentation,
the model learns the lexical and reordering proba-
bilities of the phrases “sie w¨urden – they would”
and “gegen ihre kampagne abstimmen – vote against
your campaign”. In the second segmentation, the
model learns the lexical and reordering probabilities
of the phrases “sie – they” “w¨urden – would”, “ab-
stimmen – vote”, “gegen ihre kampagne – against
your campaign”. Both segmentations result in dif-
ferent translation and reordering scores. This kind
of ambiguity in the model subsequently results in
the presence of many different equivalent segmen-
tations in the search space. Also note that the two
segmentations contain different information. From
the first segmentation the model learns the depen-
dency between the verb “abstimmen – vote” and the
phrase “gegen ihre kampagne – against your cam-
paign”. The second segmentation allows the model
to capture the reordering of the complex verb pred-
icate “w¨urden – would” and “abstimmen – vote” by
learning that the verb “abstimmen – vote” is discon-
tinuous with respect to the auxiliary. This informa-
tion cannot be captured in the first segmentation be-
cause of the phrasal independence assumption and
stiff phrasal boundaries. The model loses one of the
dependencies depending upon which segmentation
it chooses during decoding.
N-gram-based SMT is an instance of a joint
model that generates source and target strings to-
gether in bilingual translation units called tuples.
Tuples are essentially phrases but they are atomic
units that cannot be decomposed any further. This
condition of atomicity results in a unique segmen-
tation of the bilingual sentence pair given its align-
ments. The model does not make any phrasal inde-
pendence assumption and generates a tuple by look-
ing at a context of n − 1 previous tuples (or opera-
tions). This allows the N-gram model to model all
the dependencies through a single derivation.
The main drawback of N-gram-based SMT is its
poor search mechanism which is inherent from us-
ing minimal translation units during search. Decod-
ing with tuples has problems with a high number
of search errors caused by lower translation cover-
age, inaccurate future-cost estimation and pruning
of correct hypotheses (see Section 4.2 for details).
Crego and Mari˜no (2006) proposed a way to couple
reordering and search through POS-based rewrite
rules. These rules are learned during training when
units with crossing alignments are unfolded through
source linearization to form minimal tuples. For ex-
ample, in Figure 1, the N-gram-based MT will lin-
earize the word sequence “gegen ihre kampagne ab-
stimmen” to “abstimmen gegen ihre kampagne”, so
that it is in the same order as the English words.
It also learns a POS-rule “IN PRP NN VB —* VB
IN PRP NN”. The POS-based rewrite rules serve
to precompute the orderings that are hypothesized
during decoding. Coupling reordering and search
allows the N-gram model to arrange hypotheses in
2&apos; stacks (for an m word source sentence), each
containing hypotheses that cover exactly the same
foreign words. This removes the need for future-
cost estimation3. Secondly, memorizing POS-based
rules enables phrase-based like reordering, however
without lexical selection. There are three drawbacks
of this approach. Firstly, lexical generation and re-
ordering are decoupled. Search is only performed on
a small number of reorderings, pre-calculated using
the source side and completely ignoring the target-
side. And lastly, the POS-based rules face data spar-
sity problems especially in the case of long distance
reorderings.
Durrani et al. (2011) recently addressed these
problems by proposing an operation sequence N-
gram model which strongly couples translation and
reordering, hypothesizes all possible reorderings
and does not require POS-based rules. Represent-
ing bilingual sentences as a sequence of operations
enables them to memorize phrases and lexical re-
ordering triggers like PBSMT. However, using min-
imal units during decoding and searching over all
possible reorderings means that hypotheses can no
longer be arranged in 2&apos; stacks. The problem of
inaccurate future-cost estimates resurfaces resulting
in more search errors. A higher beam size of 500 is
therefore used to produce translation units in com-
parison to phrase-based systems. This, however,
still does not eliminate all search errors. This pa-
per shows that using phrases instead of cepts in de-
3Using m stacks with future-cost estimation is a more effi-
cient solution but is not used “due to the complexity of accu-
rately computing these estimations in the N-gram architecture”
(Crego et al., 2011).
</bodyText>
<page confidence="0.995213">
3
</page>
<bodyText confidence="0.99958925">
coding improves the search accuracy and translation
quality. It also shows that using some phrasal in-
formation in cept-based decoding captures some of
these improvements.
</bodyText>
<sectionHeader confidence="0.991144" genericHeader="method">
3 Operation Sequence Model
</sectionHeader>
<bodyText confidence="0.991907583333333">
The N-gram model with integrated reordering mod-
els a sequence of operations obtained through the
transformation of a bilingual sentence pair. An op-
eration can either be to i) generate a sequence of
source and target words, ii) to insert a gap as a place-
holder for skipped words, iii) or to jump forward and
backward in a sentence to translate words discon-
tinuously. The translate operation Generate(X,Y)
encapsulates the translation tuple (X,Y). It gener-
ates source and target translations simultaneously4.
This is similar to N-gram-based SMT except that
the tuples in the N-gram-based model are generated
monotonically, whereas in this case lexical genera-
tion and reordering information is strongly coupled
in an operation sequence.
Consider the phrase pair:
The model memorizes it
through the sequence:
Generate(Wie, What is) —* Gap —* Generate (Sie,
your) —* Jump Back (1) —* Generate (heissen, name)
Let O = o1, ... , oj−1 be a sequence of opera-
tions as hypothesized by the translator to generate
the bilingual sentence pair (F, E) with an alignment
function A. The translation model is defined as:
</bodyText>
<equation confidence="0.978719666666667">
J
p(F, E, A) = p(oJ1) = p(oj|oj−n+1, ..., oj−1)
j=1
</equation>
<bodyText confidence="0.9999145">
where n indicates the amount of context used. The
translation model is implemented as an N-gram
model of operations using SRILM-Toolkit (Stol-
cke, 2002) with Kneser-Ney smoothing. A 9-gram
model is used. Several count-based features such as
gap and open gap penalties and distance-based fea-
tures such as gap-width and reordering distance are
added to the model, along with the lexical weighting
and length penalty features in a standard log-linear
framework (Durrani et al., 2011).
</bodyText>
<footnote confidence="0.9604685">
4The generation is carried out in the order of the target lan-
guage E.
</footnote>
<sectionHeader confidence="0.969621" genericHeader="method">
4 Search
</sectionHeader>
<subsectionHeader confidence="0.99978">
4.1 Overview of Decoding Framework
</subsectionHeader>
<bodyText confidence="0.999983636363637">
The decoding framework used in the operation se-
quence model is based on Pharaoh (Koehn, 2004a).
The decoder uses beam search to build up the trans-
lation from left to right. The hypotheses are ar-
ranged in m stacks such that stack i maintains hy-
potheses that have already translated i many foreign
words. The ultimate goal is to find the best scor-
ing hypothesis, that has translated all the words in
the foreign sentence. The overall process can be
roughly divided into the following steps: i) extrac-
tion of translation units ii) future-cost estimation, iii)
hypothesis extension iv) recombination and pruning.
During the hypothesis extension each extracted
phrase is translated into a sequence of operations.
The reordering operations (gaps and jumps) are gen-
erated by looking at the position of the translator,
the last foreign word generated etc. (Refer to Algo-
rithm 1 in Durrani et al. (2011)). The probability of
an operation depends on the n — 1 previous opera-
tions. The model backs-off to the smaller n-grams
of operations if the full history is unknown. We use
Kneser-Ney smoothing to handle back-off5.
</bodyText>
<subsectionHeader confidence="0.999071">
4.2 Drawbacks of Cept-based Decoding
</subsectionHeader>
<bodyText confidence="0.999845105263158">
One of the main drawbacks of the operation se-
quence model is that it has a more difficult search
problem than the phrase-based model. The opera-
tion model, although based on minimal translation
units, can learn larger translation chunks by mem-
orizing a sequence of operations. However, using
cepts during decoding has the following drawbacks:
i) the cept-based decoder does not have access to
all the translation units that a phrase-based decoder
uses as part of a larger phrase. ii) it requires a higher
beam size to prevent early pruning of better hypothe-
ses that lead toward higher model scores when al-
lowed to continue and iii) it uses worse future-cost
estimates than the phrase-based decoder.
Recall the example from the last section. For
the cept-based decoder to generate the same phrasal
translation, it requires three separate tuple transla-
tions “Wie – what is”, “Sie – your” and “heißen –
name”. Here we are faced with three challenges.
</bodyText>
<footnote confidence="0.788472333333333">
5We also tried Witten-Bell and Good Turing methods of dis-
counting and found Kneser-Ney smoothing to produce the best
results.
</footnote>
<page confidence="0.994574">
4
</page>
<bodyText confidence="0.988456525">
Translation Coverage: The first problem is that
the N-gram model does not have the same cov-
erage of translation options. The English cepts
“what is”, “your” and “name” are not good candi-
date translations for the German cepts “Wie”, “Sie”
and “hei6en”, respectively. When extracting tuple
translations for these cepts from the Europarl data
for our system, the tuple “Wie – what is” is ranked
124th, “hei6en – name” is ranked 56th, and “Sie –
your” is ranked 9th in the list of n-best translation
candidates. Typically only the 20 best translation
options are used, to reduce the decoding time, and
such phrasal units with less frequent cept transla-
tions are never hypothesized in the N-gram-based
systems. The phrase-based system on the other hand
can extract the phrase “Wie hei6en Sie – what is
your name” even if it is observed only once dur-
ing training. A similar problem is also reported in
Costa-juss`a et al. (2007). When trying to repro-
duce the sentences in the n-best translation output
of the phrase-based system, the N-gram-based sys-
tem was only able to produce 37.5% of the sen-
tences in the Spanish-to-English and 37.2% in the
English-to-Spanish translation tasks. In compar-
ison the phrase-based system was able to repro-
duce 57.5% and 48.6% of the sentences in the n-
best translation output of the Spanish-to-English and
English-to-Spanish N-gram-based systems.
Larger Beam Size: A related problem is that a
higher beam size is required in cept-based decod-
ing to prevent uncommon translations from getting
pruned. The phrase-based system can generate the
phrase-pair “Wie hei6en Sie – what is your name”
in a single step placing it directly into the stack three
words to the right. The cept-based decoder generates
this phrase in three stacks with the tuple translations
“Wie – What is”, “Sie – your” and “hei6en – name”.
A very large stack size is required during decoding
to prevent the pruning of “Wie – What is” which is
ranked quite low in the stack until the tuple “Sie –
your” is hypothesized in the next stack. Costa-juss`a
et al. (2007) reports a significant drop in the perfor-
mance of N-gram-based SMT when a beam size of
10 is used instead of 50 in their experiments. For the
(cept-based) operation sequence model, Durrani et
al. (2011) required a stack size of 500. In compari-
son, the translation quality achieved by phrase-based
SMT remains the same when varying the beam size
between 5 and 50.
Future-Cost Estimation: A third problem is
caused by inaccurate future-cost estimation. Using
phrases helps phrase-based SMT to better estimate
the future language model cost because of the larger
context available, and allows the decoder to capture
local (phrase-internal) reorderings in the future cost.
In comparison the future cost for tuples is mostly un-
igram probabilities. The future-cost estimate for the
phrase pair “Wie hei6en Sie – What is your name”
is estimated by calculating the cost of each feature.
The language model cost, for example, is estimated
in the phrase-based system as follows:
plm = p(What) × p(is|What) × p(your|What is)
× p(name|What is your)
The cost of the direct phrase translation probabil-
ity, one of the features used in the phrase translation
model, is estimated as:
ptm = p(What is your name|Wie hei6en Sie)
Phrase-based SMT is aware during the prepro-
cessing step that the words “Wie hei6en Sie” may
be translated as a phrase. This is helpful for estimat-
ing a more accurate future cost because the phrase-
internal context is already available. The same is not
true for the operation sequence model, to which only
minimal units are available. The operation model
does not have the information that “Wie hei6en Sie”
may be translated as a phrase during decoding. The
future-cost estimate available to the operation model
for the span covering “Wie hei6en Sie” will have un-
igram probabilities for both the translation and lan-
guage model:
</bodyText>
<equation confidence="0.997373666666667">
plm = p(What) × p(is|What) × p(your) × p(name)
ptm = p(Generate(Wie, What is)) × p(Generate
(hei6en,name)) × p(Generate(Sie, your))
</equation>
<bodyText confidence="0.999881666666667">
Thus the future-cost estimate in the operation
model is much worse than that of the phrase-based
model. The poor future-cost estimation leads to
search errors, causing a drop in the translation qual-
ity. A more accurate future-cost estimate for the
translation model cost would be:
</bodyText>
<page confidence="0.664384">
5
</page>
<equation confidence="0.939241">
ptm = p(Generate(Wie,What is)) × p(Insert Gap|C)
× p(Generate(Sie,your)|C) × p(Jump Back(1)|C)
p(Generate(heißen,name)|C)
</equation>
<bodyText confidence="0.9999004">
where C is the context, i.e., the n−1 previously gen-
erated operations. The future-cost estimates com-
puted in this manner are much more accurate be-
cause they not only consider context, but also take
the reordering operations into account.
</bodyText>
<sectionHeader confidence="0.9682195" genericHeader="method">
5 N-gram Model with Phrase-based
Decoding
</sectionHeader>
<bodyText confidence="0.99984">
In the last section we discussed the disadvantages of
using cepts during search in a left-to-right decoding
framework. We now define a method to empirically
study the mentioned drawbacks and whether using
information available in phrase-pairs during decod-
ing can help improve search accuracy and translation
quality.
</bodyText>
<subsectionHeader confidence="0.965568">
5.1 Training
</subsectionHeader>
<bodyText confidence="0.999879842105263">
We extended the training steps in Durrani et al.
(2011) to extract a phrase lexicon from the paral-
lel data. We extract all phrase pairs of length 6 and
below, that are consistent (Och et al., 1999) with
the word alignments. Only continuous phrases as
used in a traditional phrase-based system are ex-
tracted thus allowing only inside-out (Wu, 1997)
type of alignments. The future cost of each fea-
ture component used in the log-linear model is cal-
culated. The operation sequence required to hypoth-
esize each phrase is generated and its future cost is
calculated. The future costs of other features such
as language models, lexicalized probability features,
etc. are also estimated. The estimates of the count-
based reordering penalties (gap penalty and open
gap penalty) and the distance-based features (gap-
width and reordering distance) could not be esti-
mated previously with cepts but are available when
using phrases.
</bodyText>
<subsectionHeader confidence="0.995631">
5.2 Decoding
</subsectionHeader>
<bodyText confidence="0.999993075">
We extended the decoder developed by Durrani et al.
(2011) and tried three ideas. In our primary experi-
ments we enabled the decoder to use phrases instead
of cepts. This allows the decoder to i) use phrase-
internal context when computing the future-cost es-
timates, ii) hypothesize translation options not avail-
able to the cept-based decoder iii) cover multiple
source words in a single step subsequently improv-
ing translation coverage and search. Note that us-
ing phrases instead of cepts during decoding, does
not reintroduce the spurious phrasal segmentation
problem as is present in the phrase-based system,
because the model is built on minimal units which
avoids segmentation ambiguity. Different compo-
sitions of the same phrasal unit lead to exactly the
same model score. We therefore do not create any
alternative compositions of the same phrasal unit
during decoding. This option is not available in
phrase-based decoding, because an alternative com-
position may lead towards a better model score.
In our secondary set of experiments, we used
cept-based decoding but modified the decoder to
use information available from the phrases extracted
for the test sentences. Firstly, we used future-cost
estimates from the extracted phrases (see system
cept.500.fc in Table1). This however, leads to in-
consistency in the cases where the future cost is es-
timated from some phrasal unit that cannot be gen-
erated through the available cept translations. For
example, say the best cost to cover the sequence
“Wie heißen Sie” is given by the phrase “What is
your name”. The 20-best translation options in cept-
based system, however, do not have tuples “Wie –
What” and “heißen – name”. To remove this dis-
crepancy, we add all such tuples that are used in
the extracted phrases, to the list of extracted cepts
(system cept.500.fc.t). We also studied how much
gain we obtain by only adding tuples from phrases
and using cept-based future-cost estimates (system
cept.500.t).
</bodyText>
<subsectionHeader confidence="0.992615">
5.3 Evaluation Method
</subsectionHeader>
<bodyText confidence="0.999988818181818">
To evaluate our modifications we apply a simple
strategy. We hold the model constant and change
the search to use the baseline decoder, which uses
minimal translation units, or the modified decoders
that use phrasal information during decoding. The
model parameters are optimized by running MERT
(minimum error rate training) for the baseline de-
coder on the dev set. After we have the optimized
weights, we run the baseline decoder and our mod-
ifications on the test. Note that because all the de-
coding runs use the same feature vector, the model
</bodyText>
<page confidence="0.998297">
6
</page>
<bodyText confidence="0.999694217391304">
stays constant, only search changes. This allows us
to compare different decoding runs, obtained using
the same parameters, but different search strategies,
in terms of model scores. We compute a search ac-
curacy and translation quality for each run.
Search accuracy is computed by comparing trans-
lation hypotheses from the different decoding runs.
We form a collection of the best scoring hypotheses
by traversing through all the runs and selecting the
sentences with highest model score. For each input
sentence we select a single best scoring hypothesis.
The best scoring hypothesis can be contributed from
several runs. In this case all these runs will be given
a credit for that particular sentence when computing
the search accuracy. The search accuracy of a decod-
ing run is defined as the percentage of hypotheses
that were contributed from this run, when forming a
list of best scoring hypotheses. For example, for a
test set of 1000 sentences, the accuracy of a decod-
ing run would be 30% if it was able to produce the
best scoring hypothesis for 300 sentences in the test
set. Translation quality is measured through BLEU
(Papineni et al., 2002).
</bodyText>
<sectionHeader confidence="0.998563" genericHeader="method">
6 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999967947368421">
We initially experimented with two language pairs:
German-to-English (G-E) and French-to-English (F-
E). We trained our system and the baseline sys-
tems on most of the data6 made available for the
translation task of the Fourth Workshop on Statis-
tical Machine Translation.7 We used 1M bilin-
gual sentences, for the estimation of the transla-
tion model and 2M sentences from the monolingual
corpus (news commentary) which also contains the
English part of the bilingual corpus. Word align-
ments are obtained by running GIZA++ (Och and
Ney, 2003) with the grow-diag-final-and (Koehn et
al., 2005) symmetrization heuristic. We follow the
training steps described in Durrani et al. (2011), con-
sisting of i) post-processing the alignments to re-
move discontinuous and unaligned target cepts, ii)
conversion of bilingual alignments into operation
sequences, iii) estimation of the n-gram language
models.
</bodyText>
<footnote confidence="0.99953275">
6We did not use all the available data due to scalability is-
sues. The scores reported are therefore well below those ob-
tained by the systems submitted to the WMT evaluation series.
7http://www.statmt.org/wmt09/translation-task.html
</footnote>
<subsectionHeader confidence="0.995828">
6.1 Search Accuracy Results
</subsectionHeader>
<bodyText confidence="0.999957638888889">
We divided our evaluation into two halves. In
the first half we carried out experiments to mea-
sure search accuracy and translation quality of
our decoders against the baseline cept-based OSM
(cept.500) that uses minimal translation units with a
stack size of 500. We used the version of the cept-
based OSM system that does not allow discontinu-
ous8 source cepts. To increase the speed of the sys-
tem we used a hard reordering limit of 159, in the
baseline decoder and our modifications, disallowing
jumps that are beyond 15 words from the first open
gap. For each extracted cept or phrase 10-best trans-
lation options are extracted.
Using phrases in search reduces the decoding
speed. In order to make a fair comparison, both the
phrase-based and the baseline cept-based decoders
should be allowed to run for the same amount of
time. We therefore reduced the stack size in the
phrase-based decoder so that it runs in the same
amount of time as the cept-based decoder. We found
that using a stack size of 20010 for the phrase-based
decoder was comparable in speed to using a stack-
size of 500 in the cept-based decoding.
We first tuned the baseline on dev11 to obtain an
optimized weight vector. We then ran the baseline
and our decoders as discussed in Section 5.2 on the
dev-test. Then we repeated this experiment by tun-
ing the weights with our phrase-based decoder (us-
ing a stack size of 100) and ran all the decoders again
using the new weights.
Table 1 shows the average search accuracies and
BLEU scores of the two experiments. Using phrases
during decoding in the G-E experiments resulted
in a statistically significant12 0.69 BLEU points
gain comparing our best system phrase.200 with the
baseline system cept.500. We mark a result as sig-
</bodyText>
<footnote confidence="0.992604083333333">
8Discontinuous source-side units did not lead to any im-
provements in (Durrani et al., 2011) and increased the decoding
times by multiple folds. We also found these to be less useful.
9Imposing a hard reordering limit significantly reduced the
decoding time and also slightly increased the BLEU scores.
10Higher stack sizes leads to improvement in model scores
for both German-English and French-English and slight im-
provement of BLEU in the case of the former.
11We used news-dev2009a as dev and news-dev2009b as dev-
test and tuned the weights with Z-MERT (Zaidan, 2009).
12We use bootstrap resampling (Koehn, 2004b) to test our
results against the baseline result.
</footnote>
<page confidence="0.999041">
7
</page>
<table confidence="0.999761933333333">
System German French
Acc. BLEU Acc. BLEU
Baseline System cept.stack-size
cept.50 25.95% 19.50 42.10% 21.44
cept.100 30.04% 19.79 47.32% 21.70
cept.200 35.17% 19.98 51.47% 21.82
cept.500 41.56% 20.14 54.93% 21.87
Our Cept-based Decoders
cept.500.fc 48.44% 20.52* 54.73% 21.86
cept.500.t 52.24% 20.34 67.95% 22.00
cept.500.fc.t 61.81% 20.53* 67.76% 21.96
Our Phrase-based Decoders
phrase.50 58.88% 20.58* 80.83% 22.04
phrase.100 69.85% 20.73* 88.34% 22.13
phrase.200 79.71% 20.83* 92.93% 22.17*
</table>
<tableCaption confidence="0.96134675">
Table 1: Search Accuracies (Acc.) and BLEU scores of
the Baseline and Our Decoders with different Stack Sizes
(fc = Future Cost Estimated from Phrases, t = Cept Trans-
lation Options enriched from Phrases)
</tableCaption>
<bodyText confidence="0.999987">
nificant if the improvement shown by our decoder
over the baseline decoder (cept.500) is significant at
the p &lt; 0.05 level, in both the runs. All the out-
puts that show statistically significant improvements
over the baseline decoder (cept.500) in Table 1 are
marked with an asterisk.
The search accuracy of our best system
(phrase.200), in G-E experiments is roughly
80%, which means that 80% of the times the
phrase-based decoder (using stack size 200) was
able to produce the same model score or a better
model score than the cept-based decoders (using
a stack size of 500). Our F-E experiments also
showed improvements in BLEU and model scores.
The search accuracy of our best system phrase.200
is roughly 93% as compared with 55% in the
baseline decoder (cept.500) giving a BLEU point
gain of +0.30 over the baseline.
Our modifications to the cept-based decoder also
showed improvements. We found that extending
the cept translation table (cept.500.t) using phrases
helps both in G-E and F-E experiments by extend-
ing the list of n-best translation options by 18% and
18.30% respectively. Using future costs estimated
from phrases (cept.500.fc) improved both search ac-
curacy and BLEU scores in G-E experiments, but
does not lead to any improvements in the F-E ex-
periments, as both BLEU and model scores drop
slightly. We looked at a few examples where the
model score dropped and found that in these cases,
the best scoring hypotheses are ranked very low ear-
lier in the decoding and make their way to the top
gradually in subsequent steps. A slight difference in
the future-cost estimate prunes these hypotheses in
one or the other decoder. We found future cost to
be more critical in G-E than F-E experiments. This
can be explained by the fact that more reordering is
required in G-E and it is necessary to account for the
reordering operations and jump-based features (gap-
based penalties, reordering distance and gap-width)
in the future-cost estimation. F-E on the other hand
is largely monotonic except for a few short distance
reorderings such as flipping noun and adjective.
</bodyText>
<subsectionHeader confidence="0.999932">
6.2 Comparison with other Baseline Systems
</subsectionHeader>
<bodyText confidence="0.96720506060606">
In the second half of our evaluation we compared
our best system phrase.200 with the baseline sys-
tem cept.500, and other state-of-the-art phrase-based
and N-gram-based systems on German-to-English,
French-to-English, and Spanish-to-English tasks13.
We used the official evaluation data (news-test sets)
from the Statistical Machine Translation Workshops
2009-2011 for all three language pairs (German,
Spanish and French). The feature weights for all the
systems are tuned using the dev set news-dev2009a.
We separately tune the baseline system (cept.500)
and the phrase-based system (phrase.200) and do not
hold the lambda vector constant like before.
Baseline Systems: We also compared our system
with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer
et al., 2010), and iii) Ncode (Crego et al., 2011).
We used the default stack sizes of 100 for
Moses15, 200 for Phrasal, 25 for Ncode (with 2&apos;
stacks). A 5-gram English language model is used.
Both phrase-based systems use 20-best phrases for
translation, Ncode uses 25-best tuple translations.
The training and test data for Ncode was tagged us-
ing TreeTagger (Schmid, 1994). All the baseline
systems used lexicalized reordering model. A hard
reordering limit16 of 6 words is used as a default in
13We did not include the results of Spanish in the previous
section due to space limitations but these are similar to those of
the French-to-English translation task.
14Phrasal provides two extensions to Moses: i) hierarchical
reordering model (Galley and Manning, 2008) and ii) discon-
tinuous phrases (Galley and Manning, 2010).
15Using stacks sizes from 200−1000 did not improve results.
16We tried to increase the distortion limit in the baseline sys-
</bodyText>
<page confidence="0.993327">
8
</page>
<bodyText confidence="0.998473222222222">
both the baseline phrase-based systems. Amongst
the other defaults we retained the hard source gap
penalty of 15 and a target gap penalty of 7 in Phrasal.
We provide Moses and Ncode with the same post-
edited alignments17 from which we removed target-
side discontinuities. We feed the original alignments
to Phrasal because of its ability to learn discontinu-
ous source and target phrases. All the systems use
MERT for the optimization of the weight vector.
</bodyText>
<table confidence="0.999532307692308">
M. Pd Ne C500 P200
German-to-English
MT09 18.73* 19.00* 18.37* 19.06* 19.66
MT10 18.58* 18.96* 18.64* 19.12* 19.70
MT11 17.38* 17.58* 17.49* 17.87* 18.19
French-to-English
MT09 24.61* 24.73* 24.28* 24.94* 25.27
MT10 23.69* 23.09* 23.96 23.90* 24.25
MT11 25.17* 25.55* 24.92* 25.40* 25.92
Spanish-to-English
MT09 24.38* 24.63 24.72 24.48* 24.72
MT10 25.55* 25.66* 25.87 25.68* 26.10
MT11 25.72* 26.17* 26.36* 26.48 26.67
</table>
<tableCaption confidence="0.928423">
Table 2: Comparison on 3-Test Sets – M. = Moses, Pd
= Phrasal (Discontinuous Phrases), N. = Ncode, C500 =
Cept.500, P200 = Phrase.200
</tableCaption>
<bodyText confidence="0.99567525">
Table 2 compares the performance of our phrase-
based decoder against the baselines. Our system
shows an improvement over all the baseline systems
for the G-E pair, in 11 out of 12 cases in the F-E
pair and in 8 out of 12 cases in the S-E language
pair. We mark a baseline with “*” to indicate that
our decoder shows an improvement over this base-
line result which is significant at the p &lt; 0.05 level.
</bodyText>
<sectionHeader confidence="0.991261" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.998527608695652">
We proposed a combination of using a model based
on minimal units and decoding with phrases. Mod-
eling with minimal units enables us to learn local
and non-local dependencies in a unified manner and
avoid spurious segmentation ambiguities. However,
using minimal units also in the search presents a
significant challenge because of the poor transla-
tion coverage, inaccurate future-cost estimates and
tems to 15 (in G-E experiments) as used in our systems but the
results dropped significantly in case of Moses and slightly for
Phrasal so we used the default limits for both decoders.
17Using post-processed alignments gave slightly better re-
sults than the original alignments for these baseline systems.
Details are omitted due to space limitation.
the pruning of the correct hypotheses. Phrase-based
SMT on the other hand overcomes these drawbacks
by using larger translation chunks during search.
However, the drawback of the phrase-based model is
the phrasal independence assumption, spurious am-
biguity in segmentation and a weak mechanism to
handle non-local reorderings. We showed that com-
bining a model based on minimal units with phrase-
based decoding can improve both search accuracy
and translation quality. We also showed that the
phrasal information can be indirectly used in cept-
based decoding with improved results. We tested
our system against the state-of-the-art phrase-based
and N-gram-based systems, for German-to-English,
French-to-English, and Spanish-to-English for three
standard test sets. Our system showed statistically
significant improvements over all the baseline sys-
tems in most of the cases. We have shown the bene-
fits of using phrase-based search with a model based
on minimal units. In future work, we would like to
study whether a phrase-based system like Moses or
Phrasal can profit from an OSM-style or N-gram-
style feature. Feng et al. (2010) previously showed
that adding a linearized source-side language model
in a phrase-based system helped. It would also
be interesting to study whether the insight of us-
ing minimal units for modeling and phrase-based
search would hold for hierarchical SMT. Vaswani et
al. (2011) recently showed that a Markov model over
the derivation history of minimal rules can obtain the
same translation quality as using grammars formed
with composed rules.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999944142857143">
We would like to thank the anonymous reviewers
for their helpful feedback and suggestions. Nadir
Durrani and Alexander Fraser were funded by
Deutsche Forschungsgemeinschaft grant Models of
Morphosyntax for Statistical Machine Translation.
Nadir Durrani was partially funded by the European
Union Seventh Framework Programme (FP7/2007-
2013) under grant agreement n&apos; 287658. Helmut
Schmid was supported by Deutsche Forschungsge-
meinschaft grant SFB 732. This work was sup-
ported in part by the IST Programme of the Eu-
ropean Community, under the PASCAL2 Network
of Excellence, IST-2007-216886. This publication
only reflects the authors’ views.
</bodyText>
<page confidence="0.997104">
9
</page>
<sectionHeader confidence="0.990114" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999945625">
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and R. L. Mercer. 1993. The Mathematics
of Statistical Machine Translation: Parameter Estima-
tion. Computational Linguistics, 19(2):263–311.
Daniel Cer, Michel Galley, Daniel Jurafsky, and Christo-
pher D. Manning. 2010. Phrasal: A Statistical Ma-
chine Translation Toolkit for Exploring New model
Features. In Proceedings of the NAACL HLT 2010
Demonstration Session, pages 9–12, Los Angeles,
California, June.
Marta R. Costa-juss`a, Josep M. Crego, David Vilar,
Jos´e A.R. Fonollosa, Jos´e B. Mari˜no, and Hermann
Ney. 2007. Analysis and System Combination of
Phrase- and N-Gram-Based Statistical Machine Trans-
lation Systems. In Human Language Technologies
2007: The Conference of the North American Chap-
ter of the Association for Computational Linguistics;
Companion Volume, Short Papers, pages 137–140,
Rochester, New York, April.
Josep M. Crego and Jos´e B. Mari˜no. 2006. Improving
Statistical MT by Coupling Reordering and Decoding.
Machine Translation, 20(3):199–215.
Josep M. Crego, Jos´e B. Mari˜no, and Adri`a de Gispert.
2005. Reordered Search and Unfolding Tuples for N-
Gram-Based SMT. In Proceedings of the 10th Ma-
chine Translation Summit (MT Summit X), pages 283–
289, Phuket, Thailand.
Josep M. Crego, Franc¸ois Yvon, and Jos´e B. Mari˜no.
2011. Ncode: an Open Source Bilingual N-gram SMT
Toolkit. The Prague Bulletin of Mathematical Lin-
guistics, (96):49–58.
Nadir Durrani, Helmut Schmid, and Alexander Fraser.
2011. A Joint Sequence Translation Model with Inte-
grated Reordering. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies, pages 1045–
1054, Portland, Oregon, USA, June.
Minwei Feng, Arne Mauser, and Hermann Ney. 2010.
A Source-side Decoding Sequence Model for Statisti-
cal Machine Translation. In Conference of the Associ-
ation for Machine Translation in the Americas 2010,
Denver, Colorado, USA, October.
Michel Galley and Christopher D. Manning. 2008. A
Simple and Effective Hierarchical Phrase Reordering
Model. In Proceedings of the 2008 Conference on
Empirical Methods in Natural Language Processing,
pages 848–856, Honolulu, Hawaii, October.
Michel Galley and Christopher D. Manning. 2010. Ac-
curate Non-Hierarchical Phrase-Based Translation. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 966–
974, Los Angeles, California, June. Association for
Computational Linguistics.
Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003.
Statistical Phrase-Based Translation. In Proceedings
of HLT-NAACL, pages 127–133, Edmonton, Canada.
Philipp Koehn, Amittai Axelrod, Alexandra Birch
Mayne, Chris Callison-Burch, Miles Osborne, and
David Talbot. 2005. Edinburgh System Description
for the 2005 IWSLT Speech Translation Evaluation. In
International Workshop on Spoken Language Transla-
tion 2005.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open source
toolkit for statistical machine translation. In ACL 2007
Demonstrations, Prague, Czech Republic.
Philipp Koehn. 2004a. Pharaoh: A Beam Search De-
coder for Phrase-Based Statistical Machine Transla-
tion Models. In AMTA, pages 115–124.
Philipp Koehn. 2004b. Statistical Significance Tests
for Machine Translation Evaluation. In Dekang Lin
and Dekai Wu, editors, Proceedings of EMNLP 2004,
pages 388–395, Barcelona, Spain, July.
Jos´e B. Mari˜no, Rafael E. Banchs, Josep M. Crego, Adri`a
de Gispert, Patrik Lambert, Jos´e A. R. Fonollosa, and
Marta R. Costa-juss`a. 2006. N-gram-Based Machine
Translation. Computational Linguistics, 32(4):527–
549.
Franz J. Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational Linguistics, 29(1):19–51.
Franz J. Och and Hermann Ney. 2004. The Alignment
Template Approach to Statistical Machine Translation.
Computational Linguistics, 30(1):417–449.
Franz J. Och, Christoph Tillmann, and Hermann Ney.
1999. Improved alignment models for statistical ma-
chine translation. In Joint SIGDAT Conf. on Empiri-
cal Methods in Natural Language Processing and Very
Large Corpora, pages 20–28, University of Maryland,
College Park, MD.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the 40th Annual Meeting on Association for Computa-
tional Linguistics, ACL ’02, pages 311–318, Morris-
town, NJ, USA.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In International Conference
on New Methods in Language Processing, pages 44–
49, Manchester, UK.
</reference>
<page confidence="0.949144">
10
</page>
<reference confidence="0.999901047619048">
Andreas Stolcke. 2002. SRILM - An Extensible Lan-
guage Modeling Toolkit. In Intl. Conf. Spoken Lan-
guage Processing, Denver, Colorado.
Christoph Tillmann and Tong Zhang. 2005. A Local-
ized Prediction Model for Statistical Machine Transla-
tion. In Proceedings of the 43rd Annual Meeting of the
Association for Computational Linguistics (ACL’05),
pages 557–564, Ann Arbor, Michigan, June.
Ashish Vaswani, Haitao Mi, Liang Huang, and David
Chiang. 2011. Rule Markov Models for Fast Tree-to-
String Translation. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies, pages 856–864,
Portland, Oregon, USA, June.
Dekai Wu. 1997. Stochastic Inversion Transduction
Grammars and Bilingual Parsing of Parallel Corpora.
Computational Linguistics, 23(3):377–403.
Omar F. Zaidan. 2009. Z-MERT: A Fully Configurable
Open Source Tool for Minimum Error Rate Training
of Machine Translation Systems. The Prague Bulletin
of Mathematical Linguistics, 91:79–88.
</reference>
<page confidence="0.999487">
11
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.567518">
<title confidence="0.999911">Model With Minimal Translation Units, But Decode With Phrases</title>
<author confidence="0.997636">Fraser Helmut Schmid</author>
<affiliation confidence="0.997795">University of Edinburgh University of</affiliation>
<email confidence="0.657223">dnadir@inf.ed.ac.ukfraser,schmid@ims.uni-stuttgart.de</email>
<abstract confidence="0.992122826086956">N-gram-based models co-exist with their phrase-based counterparts as an alternative SMT framework. Both techniques have pros and cons. While the N-gram-based framework provides a better model that captures both source and target contexts and avoids spurious phrasal segmentation, the ability to memorize and produce larger translation units gives an edge to the phrase-based systems during decoding, in terms of better search performance and superior selection of translation units. In this paper we combine N-grambased modeling with phrase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1260" citStr="Brown et al., 1993" startWordPosition="174" endWordPosition="177">arch performance and superior selection of translation units. In this paper we combine N-grambased modeling with phrase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. Much of the work presented here was carried out while the first author was at the University of Stuttgart. 1 Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1. Memorizing larger units enables the phrase-based model to learn loca</context>
<context position="3459" citStr="Brown et al., 1993" startWordPosition="519" endWordPosition="522">t outside of phrases. Secondly the model learns a unique derivation of a bilingual sentence given its alignment, thus avoiding the spurious segmentation problem. Using minimal translation units, however, results in a higher number of search errors because of i) 1A phrase-pair in PBSMT is a sequence of source and target words that is translation of each other, and is not necessarily a linguistic constituent. Phrases are built by combining minimal translation units and ordering information. 2A cept is a group of words in one language that is translated as a minimal unit in one specific context (Brown et al., 1993). Proceedings of NAACL-HLT 2013, pages 1–11, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics poor translation selection, ii) inaccurate future-cost estimates and iii) incorrect early pruning of hypotheses that would produce better model scores if allowed to continue. In order to deal with these problems, search is carried out only on a graph of pre-calculated orderings, and ad-hoc reordering limits are imposed to constrain the search space (Crego et al., 2005; Crego and Mari˜no, 2006), or a higher beam size is used in decoding (Durrani et al., 2011). The abil</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and R. L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Cer</author>
<author>Michel Galley</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Phrasal: A Statistical Machine Translation Toolkit for Exploring New model Features.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Demonstration Session,</booktitle>
<pages>9--12</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="33528" citStr="Cer et al., 2010" startWordPosition="5370" endWordPosition="5373"> and N-gram-based systems on German-to-English, French-to-English, and Spanish-to-English tasks13. We used the official evaluation data (news-test sets) from the Statistical Machine Translation Workshops 2009-2011 for all three language pairs (German, Spanish and French). The feature weights for all the systems are tuned using the dev set news-dev2009a. We separately tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15, 200 for Phrasal, 25 for Ncode (with 2&apos; stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13We did not include the results of Spanish in the previous section due to space limitations but these are similar t</context>
</contexts>
<marker>Cer, Galley, Jurafsky, Manning, 2010</marker>
<rawString>Daniel Cer, Michel Galley, Daniel Jurafsky, and Christopher D. Manning. 2010. Phrasal: A Statistical Machine Translation Toolkit for Exploring New model Features. In Proceedings of the NAACL HLT 2010 Demonstration Session, pages 9–12, Los Angeles, California, June.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marta R Costa-juss`a</author>
<author>Josep M Crego</author>
<author>David Vilar</author>
<author>Jos´e A R Fonollosa</author>
<author>Jos´e B Mari˜no</author>
<author>Hermann Ney</author>
</authors>
<title>Analysis and System Combination of Phrase- and N-Gram-Based Statistical Machine Translation Systems.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers,</booktitle>
<pages>137--140</pages>
<location>Rochester, New York,</location>
<marker>Costa-juss`a, Crego, Vilar, Fonollosa, Mari˜no, Ney, 2007</marker>
<rawString>Marta R. Costa-juss`a, Josep M. Crego, David Vilar, Jos´e A.R. Fonollosa, Jos´e B. Mari˜no, and Hermann Ney. 2007. Analysis and System Combination of Phrase- and N-Gram-Based Statistical Machine Translation Systems. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers, pages 137–140, Rochester, New York, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josep M Crego</author>
<author>Jos´e B Mari˜no</author>
</authors>
<title>Improving Statistical MT by Coupling Reordering and Decoding.</title>
<date>2006</date>
<journal>Machine Translation,</journal>
<volume>20</volume>
<issue>3</issue>
<marker>Crego, Mari˜no, 2006</marker>
<rawString>Josep M. Crego and Jos´e B. Mari˜no. 2006. Improving Statistical MT by Coupling Reordering and Decoding. Machine Translation, 20(3):199–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josep M Crego</author>
<author>Jos´e B Mari˜no</author>
<author>Adri`a de Gispert</author>
</authors>
<title>Reordered Search and Unfolding Tuples for NGram-Based SMT.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th Machine Translation Summit (MT Summit X),</booktitle>
<pages>283--289</pages>
<location>Phuket, Thailand.</location>
<marker>Crego, Mari˜no, de Gispert, 2005</marker>
<rawString>Josep M. Crego, Jos´e B. Mari˜no, and Adri`a de Gispert. 2005. Reordered Search and Unfolding Tuples for NGram-Based SMT. In Proceedings of the 10th Machine Translation Summit (MT Summit X), pages 283– 289, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josep M Crego</author>
<author>Franc¸ois Yvon</author>
<author>Jos´e B Mari˜no</author>
</authors>
<date>2011</date>
<booktitle>Ncode: an Open Source Bilingual N-gram SMT Toolkit. The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>96--49</pages>
<marker>Crego, Yvon, Mari˜no, 2011</marker>
<rawString>Josep M. Crego, Franc¸ois Yvon, and Jos´e B. Mari˜no. 2011. Ncode: an Open Source Bilingual N-gram SMT Toolkit. The Prague Bulletin of Mathematical Linguistics, (96):49–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nadir Durrani</author>
<author>Helmut Schmid</author>
<author>Alexander Fraser</author>
</authors>
<title>A Joint Sequence Translation Model with Integrated Reordering.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1045--1054</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="2686" citStr="Durrani et al., 2011" startWordPosition="394" endWordPosition="397">formation outside of phrases ii) it has issues handling long-distance reordering iii) it has the spurious phrasal segmentation problem which allows multiple derivations of a bilingual sentence pair having different model scores for each segmentation. Modeling with minimal translation units helps address some of these issues. The N-gram-based SMT framework is based on tuples. Tuples are minimal translation units composed of source and target cepts2. N-gram-based models are Markov models over sequences of tuples (Mari˜no et al., 2006; Crego and Mari˜no, 2006) or operations encapsulating tuples (Durrani et al., 2011). This mechanism has several useful properties. Firstly, no phrasal independence assumption is made. The model has access to both source and target context outside of phrases. Secondly the model learns a unique derivation of a bilingual sentence given its alignment, thus avoiding the spurious segmentation problem. Using minimal translation units, however, results in a higher number of search errors because of i) 1A phrase-pair in PBSMT is a sequence of source and target words that is translation of each other, and is not necessarily a linguistic constituent. Phrases are built by combining mini</context>
<context position="4049" citStr="Durrani et al., 2011" startWordPosition="611" endWordPosition="614">ic context (Brown et al., 1993). Proceedings of NAACL-HLT 2013, pages 1–11, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics poor translation selection, ii) inaccurate future-cost estimates and iii) incorrect early pruning of hypotheses that would produce better model scores if allowed to continue. In order to deal with these problems, search is carried out only on a graph of pre-calculated orderings, and ad-hoc reordering limits are imposed to constrain the search space (Crego et al., 2005; Crego and Mari˜no, 2006), or a higher beam size is used in decoding (Durrani et al., 2011). The ability to memorize and produce larger translation chunks during decoding, on the other hand, gives a distinct advantage to the phrase-based system during search. Phrase-based systems i) have access to uncommon translations, ii) do not require higher beam sizes, iii) have more accurate future-cost estimates because of the availability of phrase-internal language model context before search is started. To illustrate this consider the German-English phrase-pair “schoß ein Tor – scored a goal”, composed from the tuples (ceptpairs) “schoß – scored”, “ein – a” and “Tor – goal”. It is likely t</context>
<context position="5398" citStr="Durrani et al., 2011" startWordPosition="839" endWordPosition="842"> translation for “schoß” outside the sports domain. Even if “schoß – scored” is hypothesized, it will be ranked quite low in the stack until “ein” and “Tor” are generated in the next steps. A higher beam is required to prevent it from getting pruned. Phrase-based systems, on the other hand, are likely to have access to the phrasal unit “schoß ein Tor – scored a goal” and can generate it in a single step. Moreover, a more accurate future-cost estimate can be computed because of the available context internal to the phrase. In this work, we extend the N-gram model, based on operation sequences (Durrani et al., 2011), to use phrases during decoding. The main idea is to study whether a combination of modeling with minimal translation units and using phrasal information during decoding helps to solve the above-mentioned problems. The remainder of this paper is organized as follows. The next two sections review phrase-based and N-gram-based SMT. Section 2 provides a comparison of phrase-based and N-gram-based SMT. Section 3 summarizes the operation sequence model (OSM), the main baseline for this work. Section 4 analyzes the search problem when decoding with Figure 1: Different Segmentations of a Bilingual S</context>
<context position="11506" citStr="Durrani et al. (2011)" startWordPosition="1794" endWordPosition="1797"> source sentence), each containing hypotheses that cover exactly the same foreign words. This removes the need for futurecost estimation3. Secondly, memorizing POS-based rules enables phrase-based like reordering, however without lexical selection. There are three drawbacks of this approach. Firstly, lexical generation and reordering are decoupled. Search is only performed on a small number of reorderings, pre-calculated using the source side and completely ignoring the targetside. And lastly, the POS-based rules face data sparsity problems especially in the case of long distance reorderings. Durrani et al. (2011) recently addressed these problems by proposing an operation sequence Ngram model which strongly couples translation and reordering, hypothesizes all possible reorderings and does not require POS-based rules. Representing bilingual sentences as a sequence of operations enables them to memorize phrases and lexical reordering triggers like PBSMT. However, using minimal units during decoding and searching over all possible reorderings means that hypotheses can no longer be arranged in 2&apos; stacks. The problem of inaccurate future-cost estimates resurfaces resulting in more search errors. A higher b</context>
<context position="14363" citStr="Durrani et al., 2011" startWordPosition="2249" endWordPosition="2252">l sentence pair (F, E) with an alignment function A. The translation model is defined as: J p(F, E, A) = p(oJ1) = p(oj|oj−n+1, ..., oj−1) j=1 where n indicates the amount of context used. The translation model is implemented as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4The generation is carried out in the order of the target language E. 4 Search 4.1 Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following st</context>
<context position="18958" citStr="Durrani et al. (2011)" startWordPosition="3022" endWordPosition="3025">ng it directly into the stack three words to the right. The cept-based decoder generates this phrase in three stacks with the tuple translations “Wie – What is”, “Sie – your” and “hei6en – name”. A very large stack size is required during decoding to prevent the pruning of “Wie – What is” which is ranked quite low in the stack until the tuple “Sie – your” is hypothesized in the next stack. Costa-juss`a et al. (2007) reports a significant drop in the performance of N-gram-based SMT when a beam size of 10 is used instead of 50 in their experiments. For the (cept-based) operation sequence model, Durrani et al. (2011) required a stack size of 500. In comparison, the translation quality achieved by phrase-based SMT remains the same when varying the beam size between 5 and 50. Future-Cost Estimation: A third problem is caused by inaccurate future-cost estimation. Using phrases helps phrase-based SMT to better estimate the future language model cost because of the larger context available, and allows the decoder to capture local (phrase-internal) reorderings in the future cost. In comparison the future cost for tuples is mostly unigram probabilities. The future-cost estimate for the phrase pair “Wie hei6en Si</context>
<context position="21793" citStr="Durrani et al. (2011)" startWordPosition="3473" endWordPosition="3476">usly generated operations. The future-cost estimates computed in this manner are much more accurate because they not only consider context, but also take the reordering operations into account. 5 N-gram Model with Phrase-based Decoding In the last section we discussed the disadvantages of using cepts during search in a left-to-right decoding framework. We now define a method to empirically study the mentioned drawbacks and whether using information available in phrase-pairs during decoding can help improve search accuracy and translation quality. 5.1 Training We extended the training steps in Durrani et al. (2011) to extract a phrase lexicon from the parallel data. We extract all phrase pairs of length 6 and below, that are consistent (Och et al., 1999) with the word alignments. Only continuous phrases as used in a traditional phrase-based system are extracted thus allowing only inside-out (Wu, 1997) type of alignments. The future cost of each feature component used in the log-linear model is calculated. The operation sequence required to hypothesize each phrase is generated and its future cost is calculated. The future costs of other features such as language models, lexicalized probability features, </context>
<context position="27056" citStr="Durrani et al. (2011)" startWordPosition="4330" endWordPosition="4333">-to-English (G-E) and French-to-English (FE). We trained our system and the baseline systems on most of the data6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.7 We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus. Word alignments are obtained by running GIZA++ (Och and Ney, 2003) with the grow-diag-final-and (Koehn et al., 2005) symmetrization heuristic. We follow the training steps described in Durrani et al. (2011), consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models. 6We did not use all the available data due to scalability issues. The scores reported are therefore well below those obtained by the systems submitted to the WMT evaluation series. 7http://www.statmt.org/wmt09/translation-task.html 6.1 Search Accuracy Results We divided our evaluation into two halves. In the first half we carried out experiments to measure search accuracy and transla</context>
<context position="29361" citStr="Durrani et al., 2011" startWordPosition="4713" endWordPosition="4716">line and our decoders as discussed in Section 5.2 on the dev-test. Then we repeated this experiment by tuning the weights with our phrase-based decoder (using a stack size of 100) and ran all the decoders again using the new weights. Table 1 shows the average search accuracies and BLEU scores of the two experiments. Using phrases during decoding in the G-E experiments resulted in a statistically significant12 0.69 BLEU points gain comparing our best system phrase.200 with the baseline system cept.500. We mark a result as sig8Discontinuous source-side units did not lead to any improvements in (Durrani et al., 2011) and increased the decoding times by multiple folds. We also found these to be less useful. 9Imposing a hard reordering limit significantly reduced the decoding time and also slightly increased the BLEU scores. 10Higher stack sizes leads to improvement in model scores for both German-English and French-English and slight improvement of BLEU in the case of the former. 11We used news-dev2009a as dev and news-dev2009b as devtest and tuned the weights with Z-MERT (Zaidan, 2009). 12We use bootstrap resampling (Koehn, 2004b) to test our results against the baseline result. 7 System German French Acc</context>
</contexts>
<marker>Durrani, Schmid, Fraser, 2011</marker>
<rawString>Nadir Durrani, Helmut Schmid, and Alexander Fraser. 2011. A Joint Sequence Translation Model with Integrated Reordering. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1045– 1054, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minwei Feng</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>A Source-side Decoding Sequence Model for Statistical Machine Translation.</title>
<date>2010</date>
<booktitle>In Conference of the Association for Machine Translation in the Americas 2010,</booktitle>
<location>Denver, Colorado, USA,</location>
<contexts>
<context position="37778" citStr="Feng et al. (2010)" startWordPosition="6055" endWordPosition="6058">n can be indirectly used in ceptbased decoding with improved results. We tested our system against the state-of-the-art phrase-based and N-gram-based systems, for German-to-English, French-to-English, and Spanish-to-English for three standard test sets. Our system showed statistically significant improvements over all the baseline systems in most of the cases. We have shown the benefits of using phrase-based search with a model based on minimal units. In future work, we would like to study whether a phrase-based system like Moses or Phrasal can profit from an OSM-style or N-gramstyle feature. Feng et al. (2010) previously showed that adding a linearized source-side language model in a phrase-based system helped. It would also be interesting to study whether the insight of using minimal units for modeling and phrase-based search would hold for hierarchical SMT. Vaswani et al. (2011) recently showed that a Markov model over the derivation history of minimal rules can obtain the same translation quality as using grammars formed with composed rules. Acknowledgments We would like to thank the anonymous reviewers for their helpful feedback and suggestions. Nadir Durrani and Alexander Fraser were funded by</context>
</contexts>
<marker>Feng, Mauser, Ney, 2010</marker>
<rawString>Minwei Feng, Arne Mauser, and Hermann Ney. 2010. A Source-side Decoding Sequence Model for Statistical Machine Translation. In Conference of the Association for Machine Translation in the Americas 2010, Denver, Colorado, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>A Simple and Effective Hierarchical Phrase Reordering Model.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>848--856</pages>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="7088" citStr="Galley and Manning, 2008" startWordPosition="1096" endWordPosition="1099">-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often the language model cannot compensate for the dispreference of the translation model for nonlocal dependencies. The second problem is that the model is unaware of the actual phrasal segmentation of a sentence during training. It therefore</context>
<context position="34282" citStr="Galley and Manning, 2008" startWordPosition="5492" endWordPosition="5495"> stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13We did not include the results of Spanish in the previous section due to space limitations but these are similar to those of the French-to-English translation task. 14Phrasal provides two extensions to Moses: i) hierarchical reordering model (Galley and Manning, 2008) and ii) discontinuous phrases (Galley and Manning, 2010). 15Using stacks sizes from 200−1000 did not improve results. 16We tried to increase the distortion limit in the baseline sys8 both the baseline phrase-based systems. Amongst the other defaults we retained the hard source gap penalty of 15 and a target gap penalty of 7 in Phrasal. We provide Moses and Ncode with the same postedited alignments17 from which we removed targetside discontinuities. We feed the original alignments to Phrasal because of its ability to learn discontinuous source and target phrases. All the systems use MERT for t</context>
</contexts>
<marker>Galley, Manning, 2008</marker>
<rawString>Michel Galley and Christopher D. Manning. 2008. A Simple and Effective Hierarchical Phrase Reordering Model. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 848–856, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate Non-Hierarchical Phrase-Based Translation. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>966--974</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="6853" citStr="Galley and Manning, 2010" startWordPosition="1059" endWordPosition="1062">ch-to-English translation tasks and found that using phrases in decoding improves both search accuracy and BLEU scores. Finally we compare our system with two state-of-the-art phrasebased systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often th</context>
<context position="34339" citStr="Galley and Manning, 2010" startWordPosition="5501" endWordPosition="5504">hrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13We did not include the results of Spanish in the previous section due to space limitations but these are similar to those of the French-to-English translation task. 14Phrasal provides two extensions to Moses: i) hierarchical reordering model (Galley and Manning, 2008) and ii) discontinuous phrases (Galley and Manning, 2010). 15Using stacks sizes from 200−1000 did not improve results. 16We tried to increase the distortion limit in the baseline sys8 both the baseline phrase-based systems. Amongst the other defaults we retained the hard source gap penalty of 15 and a target gap penalty of 7 in Phrasal. We provide Moses and Ncode with the same postedited alignments17 from which we removed targetside discontinuities. We feed the original alignments to Phrasal because of its ability to learn discontinuous source and target phrases. All the systems use MERT for the optimization of the weight vector. M. Pd Ne C500 P200 </context>
</contexts>
<marker>Galley, Manning, 2010</marker>
<rawString>Michel Galley and Christopher D. Manning. 2010. Accurate Non-Hierarchical Phrase-Based Translation. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 966– 974, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz J Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>127--133</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1394" citStr="Koehn et al., 2003" startWordPosition="194" endWordPosition="197">, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. Much of the work presented here was carried out while the first author was at the University of Stuttgart. 1 Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1. Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc. The model however, has the following drawbacks: i) it</context>
<context position="6790" citStr="Koehn et al., 2003" startWordPosition="1050" endWordPosition="1053">We conducted experiments on the German-toEnglish and French-to-English translation tasks and found that using phrases in decoding improves both search accuracy and BLEU scores. Finally we compare our system with two state-of-the-art phrasebased systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingu</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz J. Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of HLT-NAACL, pages 127–133, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Amittai Axelrod</author>
<author>Alexandra Birch Mayne</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
<author>David Talbot</author>
</authors>
<title>IWSLT Speech Translation Evaluation.</title>
<date>2005</date>
<booktitle>Edinburgh System Description for the</booktitle>
<contexts>
<context position="26966" citStr="Koehn et al., 2005" startWordPosition="4317" endWordPosition="4320">., 2002). 6 Experimental Setup We initially experimented with two language pairs: German-to-English (G-E) and French-to-English (FE). We trained our system and the baseline systems on most of the data6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.7 We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus. Word alignments are obtained by running GIZA++ (Och and Ney, 2003) with the grow-diag-final-and (Koehn et al., 2005) symmetrization heuristic. We follow the training steps described in Durrani et al. (2011), consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models. 6We did not use all the available data due to scalability issues. The scores reported are therefore well below those obtained by the systems submitted to the WMT evaluation series. 7http://www.statmt.org/wmt09/translation-task.html 6.1 Search Accuracy Results We divided our evaluation into two h</context>
</contexts>
<marker>Koehn, Axelrod, Mayne, Callison-Burch, Osborne, Talbot, 2005</marker>
<rawString>Philipp Koehn, Amittai Axelrod, Alexandra Birch Mayne, Chris Callison-Burch, Miles Osborne, and David Talbot. 2005. Edinburgh System Description for the 2005 IWSLT Speech Translation Evaluation. In International Workshop on Spoken Language Translation 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL 2007 Demonstrations,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="33494" citStr="Koehn et al., 2007" startWordPosition="5364" endWordPosition="5367"> other state-of-the-art phrase-based and N-gram-based systems on German-to-English, French-to-English, and Spanish-to-English tasks13. We used the official evaluation data (news-test sets) from the Statistical Machine Translation Workshops 2009-2011 for all three language pairs (German, Spanish and French). The feature weights for all the systems are tuned using the dev set news-dev2009a. We separately tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15, 200 for Phrasal, 25 for Ncode (with 2&apos; stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13We did not include the results of Spanish in the previous section due to space l</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL 2007 Demonstrations, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: A Beam Search Decoder for Phrase-Based Statistical Machine Translation Models. In</title>
<date>2004</date>
<booktitle>AMTA,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="14571" citStr="Koehn, 2004" startWordPosition="2288" endWordPosition="2289">mented as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4The generation is carried out in the order of the target language E. 4 Search 4.1 Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following steps: i) extraction of translation units ii) future-cost estimation, iii) hypothesis extension iv) recombination and pruning. During the hypothesis extension each extracted phrase is translated into a sequence</context>
<context position="29883" citStr="Koehn, 2004" startWordPosition="4798" endWordPosition="4799">iscontinuous source-side units did not lead to any improvements in (Durrani et al., 2011) and increased the decoding times by multiple folds. We also found these to be less useful. 9Imposing a hard reordering limit significantly reduced the decoding time and also slightly increased the BLEU scores. 10Higher stack sizes leads to improvement in model scores for both German-English and French-English and slight improvement of BLEU in the case of the former. 11We used news-dev2009a as dev and news-dev2009b as devtest and tuned the weights with Z-MERT (Zaidan, 2009). 12We use bootstrap resampling (Koehn, 2004b) to test our results against the baseline result. 7 System German French Acc. BLEU Acc. BLEU Baseline System cept.stack-size cept.50 25.95% 19.50 42.10% 21.44 cept.100 30.04% 19.79 47.32% 21.70 cept.200 35.17% 19.98 51.47% 21.82 cept.500 41.56% 20.14 54.93% 21.87 Our Cept-based Decoders cept.500.fc 48.44% 20.52* 54.73% 21.86 cept.500.t 52.24% 20.34 67.95% 22.00 cept.500.fc.t 61.81% 20.53* 67.76% 21.96 Our Phrase-based Decoders phrase.50 58.88% 20.58* 80.83% 22.04 phrase.100 69.85% 20.73* 88.34% 22.13 phrase.200 79.71% 20.83* 92.93% 22.17* Table 1: Search Accuracies (Acc.) and BLEU scores of </context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004a. Pharaoh: A Beam Search Decoder for Phrase-Based Statistical Machine Translation Models. In AMTA, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Significance Tests for Machine Translation Evaluation.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<pages>388--395</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="14571" citStr="Koehn, 2004" startWordPosition="2288" endWordPosition="2289">mented as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4The generation is carried out in the order of the target language E. 4 Search 4.1 Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation from left to right. The hypotheses are arranged in m stacks such that stack i maintains hypotheses that have already translated i many foreign words. The ultimate goal is to find the best scoring hypothesis, that has translated all the words in the foreign sentence. The overall process can be roughly divided into the following steps: i) extraction of translation units ii) future-cost estimation, iii) hypothesis extension iv) recombination and pruning. During the hypothesis extension each extracted phrase is translated into a sequence</context>
<context position="29883" citStr="Koehn, 2004" startWordPosition="4798" endWordPosition="4799">iscontinuous source-side units did not lead to any improvements in (Durrani et al., 2011) and increased the decoding times by multiple folds. We also found these to be less useful. 9Imposing a hard reordering limit significantly reduced the decoding time and also slightly increased the BLEU scores. 10Higher stack sizes leads to improvement in model scores for both German-English and French-English and slight improvement of BLEU in the case of the former. 11We used news-dev2009a as dev and news-dev2009b as devtest and tuned the weights with Z-MERT (Zaidan, 2009). 12We use bootstrap resampling (Koehn, 2004b) to test our results against the baseline result. 7 System German French Acc. BLEU Acc. BLEU Baseline System cept.stack-size cept.50 25.95% 19.50 42.10% 21.44 cept.100 30.04% 19.79 47.32% 21.70 cept.200 35.17% 19.98 51.47% 21.82 cept.500 41.56% 20.14 54.93% 21.87 Our Cept-based Decoders cept.500.fc 48.44% 20.52* 54.73% 21.86 cept.500.t 52.24% 20.34 67.95% 22.00 cept.500.fc.t 61.81% 20.53* 67.76% 21.96 Our Phrase-based Decoders phrase.50 58.88% 20.58* 80.83% 22.04 phrase.100 69.85% 20.73* 88.34% 22.13 phrase.200 79.71% 20.83* 92.93% 22.17* Table 1: Search Accuracies (Acc.) and BLEU scores of </context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004b. Statistical Significance Tests for Machine Translation Evaluation. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 388–395, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e B Mari˜no</author>
<author>Rafael E Banchs</author>
<author>Josep M Crego</author>
<author>Adri`a de Gispert</author>
<author>Patrik Lambert</author>
<author>Jos´e A R Fonollosa</author>
<author>Marta R Costa-juss`a</author>
</authors>
<title>N-gram-Based Machine Translation.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<pages>549</pages>
<marker>Mari˜no, Banchs, Crego, de Gispert, Lambert, Fonollosa, Costa-juss`a, 2006</marker>
<rawString>Jos´e B. Mari˜no, Rafael E. Banchs, Josep M. Crego, Adri`a de Gispert, Patrik Lambert, Jos´e A. R. Fonollosa, and Marta R. Costa-juss`a. 2006. N-gram-Based Machine Translation. Computational Linguistics, 32(4):527– 549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="26916" citStr="Och and Ney, 2003" startWordPosition="4310" endWordPosition="4313"> quality is measured through BLEU (Papineni et al., 2002). 6 Experimental Setup We initially experimented with two language pairs: German-to-English (G-E) and French-to-English (FE). We trained our system and the baseline systems on most of the data6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.7 We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus. Word alignments are obtained by running GIZA++ (Och and Ney, 2003) with the grow-diag-final-and (Koehn et al., 2005) symmetrization heuristic. We follow the training steps described in Durrani et al. (2011), consisting of i) post-processing the alignments to remove discontinuous and unaligned target cepts, ii) conversion of bilingual alignments into operation sequences, iii) estimation of the n-gram language models. 6We did not use all the available data due to scalability issues. The scores reported are therefore well below those obtained by the systems submitted to the WMT evaluation series. 7http://www.statmt.org/wmt09/translation-task.html 6.1 Search Acc</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz J. Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>The Alignment Template Approach to Statistical Machine Translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="1373" citStr="Och and Ney, 2004" startWordPosition="190" endWordPosition="193">rase-based decoding, and obtain the benefits of both approaches. Our experiments show that using this combination not only improves the search accuracy of the N-gram model but that it also improves the BLEU scores. Our system outperforms state-of-the-art phrase-based systems (Moses and Phrasal) and N-gram-based systems by a significant margin on German, French and Spanish to English translation tasks. 1 Introduction Statistical Machine Translation advanced from word-based models (Brown et al., 1993) towards more sophisticated models that take contextual information into account. Phrase-based (Och and Ney, 2004; Koehn et al., 2003) and N-gram-based (Mari˜no et al., 2006) models are two instances of such frameworks. While the two models have some common properties, they are substantially different. Much of the work presented here was carried out while the first author was at the University of Stuttgart. 1 Phrase-based systems employ a simple and effective machinery by learning larger chunks of translation called phrases1. Memorizing larger units enables the phrase-based model to learn local dependencies such as short reorderings, idioms, insertions and deletions, etc. The model however, has the follo</context>
<context position="6769" citStr="Och and Ney, 2004" startWordPosition="1046" endWordPosition="1049">ults of this work. We conducted experiments on the German-toEnglish and French-to-English translation tasks and found that using phrases in decoding improves both search accuracy and BLEU scores. Finally we compare our system with two state-of-the-art phrasebased systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corre</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz J. Och and Hermann Ney. 2004. The Alignment Template Approach to Statistical Machine Translation. Computational Linguistics, 30(1):417–449.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Christoph Tillmann</author>
<author>Hermann Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Joint SIGDAT Conf. on Empirical Methods in Natural Language Processing and Very Large Corpora,</booktitle>
<pages>20--28</pages>
<institution>University of Maryland, College Park, MD.</institution>
<contexts>
<context position="21935" citStr="Och et al., 1999" startWordPosition="3500" endWordPosition="3503">so take the reordering operations into account. 5 N-gram Model with Phrase-based Decoding In the last section we discussed the disadvantages of using cepts during search in a left-to-right decoding framework. We now define a method to empirically study the mentioned drawbacks and whether using information available in phrase-pairs during decoding can help improve search accuracy and translation quality. 5.1 Training We extended the training steps in Durrani et al. (2011) to extract a phrase lexicon from the parallel data. We extract all phrase pairs of length 6 and below, that are consistent (Och et al., 1999) with the word alignments. Only continuous phrases as used in a traditional phrase-based system are extracted thus allowing only inside-out (Wu, 1997) type of alignments. The future cost of each feature component used in the log-linear model is calculated. The operation sequence required to hypothesize each phrase is generated and its future cost is calculated. The future costs of other features such as language models, lexicalized probability features, etc. are also estimated. The estimates of the countbased reordering penalties (gap penalty and open gap penalty) and the distance-based featur</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>Franz J. Och, Christoph Tillmann, and Hermann Ney. 1999. Improved alignment models for statistical machine translation. In Joint SIGDAT Conf. on Empirical Methods in Natural Language Processing and Very Large Corpora, pages 20–28, University of Maryland, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>311--318</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="26355" citStr="Papineni et al., 2002" startWordPosition="4220" endWordPosition="4223"> best scoring hypothesis. The best scoring hypothesis can be contributed from several runs. In this case all these runs will be given a credit for that particular sentence when computing the search accuracy. The search accuracy of a decoding run is defined as the percentage of hypotheses that were contributed from this run, when forming a list of best scoring hypotheses. For example, for a test set of 1000 sentences, the accuracy of a decoding run would be 30% if it was able to produce the best scoring hypothesis for 300 sentences in the test set. Translation quality is measured through BLEU (Papineni et al., 2002). 6 Experimental Setup We initially experimented with two language pairs: German-to-English (G-E) and French-to-English (FE). We trained our system and the baseline systems on most of the data6 made available for the translation task of the Fourth Workshop on Statistical Machine Translation.7 We used 1M bilingual sentences, for the estimation of the translation model and 2M sentences from the monolingual corpus (news commentary) which also contains the English part of the bilingual corpus. Word alignments are obtained by running GIZA++ (Och and Ney, 2003) with the grow-diag-final-and (Koehn et</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 311–318, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="33889" citStr="Schmid, 1994" startWordPosition="5432" endWordPosition="5433">tely tune the baseline system (cept.500) and the phrase-based system (phrase.200) and do not hold the lambda vector constant like before. Baseline Systems: We also compared our system with i) Moses (Koehn et al., 2007), ii) Phrasal14 (Cer et al., 2010), and iii) Ncode (Crego et al., 2011). We used the default stack sizes of 100 for Moses15, 200 for Phrasal, 25 for Ncode (with 2&apos; stacks). A 5-gram English language model is used. Both phrase-based systems use 20-best phrases for translation, Ncode uses 25-best tuple translations. The training and test data for Ncode was tagged using TreeTagger (Schmid, 1994). All the baseline systems used lexicalized reordering model. A hard reordering limit16 of 6 words is used as a default in 13We did not include the results of Spanish in the previous section due to space limitations but these are similar to those of the French-to-English translation task. 14Phrasal provides two extensions to Moses: i) hierarchical reordering model (Galley and Manning, 2008) and ii) discontinuous phrases (Galley and Manning, 2010). 15Using stacks sizes from 200−1000 did not improve results. 16We tried to increase the distortion limit in the baseline sys8 both the baseline phras</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing, pages 44– 49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - An Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Intl. Conf. Spoken Language Processing,</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="14035" citStr="Stolcke, 2002" startWordPosition="2199" endWordPosition="2201">trongly coupled in an operation sequence. Consider the phrase pair: The model memorizes it through the sequence: Generate(Wie, What is) —* Gap —* Generate (Sie, your) —* Jump Back (1) —* Generate (heissen, name) Let O = o1, ... , oj−1 be a sequence of operations as hypothesized by the translator to generate the bilingual sentence pair (F, E) with an alignment function A. The translation model is defined as: J p(F, E, A) = p(oJ1) = p(oj|oj−n+1, ..., oj−1) j=1 where n indicates the amount of context used. The translation model is implemented as an N-gram model of operations using SRILM-Toolkit (Stolcke, 2002) with Kneser-Ney smoothing. A 9-gram model is used. Several count-based features such as gap and open gap penalties and distance-based features such as gap-width and reordering distance are added to the model, along with the lexical weighting and length penalty features in a standard log-linear framework (Durrani et al., 2011). 4The generation is carried out in the order of the target language E. 4 Search 4.1 Overview of Decoding Framework The decoding framework used in the operation sequence model is based on Pharaoh (Koehn, 2004a). The decoder uses beam search to build up the translation fro</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - An Extensible Language Modeling Toolkit. In Intl. Conf. Spoken Language Processing, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Tillmann</author>
<author>Tong Zhang</author>
</authors>
<title>A Localized Prediction Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>557--564</pages>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="7041" citStr="Tillmann and Zhang, 2005" startWordPosition="1088" endWordPosition="1091">systems (Moses and Phrasal) and two stateof-the-art N-gram-based systems (Ncode and OSM) on standard translation tasks. 2 Previous Work Phrase-based and N-gram-based SMT are alternative frameworks for string-to-string translation. Phrase-based SMT segments a bilingual sentence pair into phrases that are continuous sequences of words (Och and Ney, 2004; Koehn et al., 2003) or discontinuous sequences of words (Galley and Manning, 2010). These phrases are then reordered through a lexicalized reordering model that takes into account the orientation of a phrase with respect to its previous phrase (Tillmann and Zhang, 2005) or block of phrases (Galley and Manning, 2008). There are several drawbacks of the phrase-based model. Firstly it makes an independence assumption over phrases, according to which phrases are translated independently of each other, thus ignoring the contextual information outside of the phrasal boundary. This problem is corrected by the monolingual language model that takes context into account. But often the language model cannot compensate for the dispreference of the translation model for nonlocal dependencies. The second problem is that the model is unaware of the actual phrasal segmentat</context>
</contexts>
<marker>Tillmann, Zhang, 2005</marker>
<rawString>Christoph Tillmann and Tong Zhang. 2005. A Localized Prediction Model for Statistical Machine Translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 557–564, Ann Arbor, Michigan, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Haitao Mi</author>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Rule Markov Models for Fast Tree-toString Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>856--864</pages>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="38054" citStr="Vaswani et al. (2011)" startWordPosition="6098" endWordPosition="6101">tatistically significant improvements over all the baseline systems in most of the cases. We have shown the benefits of using phrase-based search with a model based on minimal units. In future work, we would like to study whether a phrase-based system like Moses or Phrasal can profit from an OSM-style or N-gramstyle feature. Feng et al. (2010) previously showed that adding a linearized source-side language model in a phrase-based system helped. It would also be interesting to study whether the insight of using minimal units for modeling and phrase-based search would hold for hierarchical SMT. Vaswani et al. (2011) recently showed that a Markov model over the derivation history of minimal rules can obtain the same translation quality as using grammars formed with composed rules. Acknowledgments We would like to thank the anonymous reviewers for their helpful feedback and suggestions. Nadir Durrani and Alexander Fraser were funded by Deutsche Forschungsgemeinschaft grant Models of Morphosyntax for Statistical Machine Translation. Nadir Durrani was partially funded by the European Union Seventh Framework Programme (FP7/2007- 2013) under grant agreement n&apos; 287658. Helmut Schmid was supported by Deutsche Fo</context>
</contexts>
<marker>Vaswani, Mi, Huang, Chiang, 2011</marker>
<rawString>Ashish Vaswani, Haitao Mi, Liang Huang, and David Chiang. 2011. Rule Markov Models for Fast Tree-toString Translation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 856–864, Portland, Oregon, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="22085" citStr="Wu, 1997" startWordPosition="3525" endWordPosition="3526">ring search in a left-to-right decoding framework. We now define a method to empirically study the mentioned drawbacks and whether using information available in phrase-pairs during decoding can help improve search accuracy and translation quality. 5.1 Training We extended the training steps in Durrani et al. (2011) to extract a phrase lexicon from the parallel data. We extract all phrase pairs of length 6 and below, that are consistent (Och et al., 1999) with the word alignments. Only continuous phrases as used in a traditional phrase-based system are extracted thus allowing only inside-out (Wu, 1997) type of alignments. The future cost of each feature component used in the log-linear model is calculated. The operation sequence required to hypothesize each phrase is generated and its future cost is calculated. The future costs of other features such as language models, lexicalized probability features, etc. are also estimated. The estimates of the countbased reordering penalties (gap penalty and open gap penalty) and the distance-based features (gapwidth and reordering distance) could not be estimated previously with cepts but are available when using phrases. 5.2 Decoding We extended the </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic Inversion Transduction Grammars and Bilingual Parsing of Parallel Corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
</authors>
<title>Z-MERT: A Fully Configurable Open Source Tool for Minimum Error Rate Training of Machine Translation Systems.</title>
<date>2009</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>91--79</pages>
<contexts>
<context position="29839" citStr="Zaidan, 2009" startWordPosition="4792" endWordPosition="4793">ine system cept.500. We mark a result as sig8Discontinuous source-side units did not lead to any improvements in (Durrani et al., 2011) and increased the decoding times by multiple folds. We also found these to be less useful. 9Imposing a hard reordering limit significantly reduced the decoding time and also slightly increased the BLEU scores. 10Higher stack sizes leads to improvement in model scores for both German-English and French-English and slight improvement of BLEU in the case of the former. 11We used news-dev2009a as dev and news-dev2009b as devtest and tuned the weights with Z-MERT (Zaidan, 2009). 12We use bootstrap resampling (Koehn, 2004b) to test our results against the baseline result. 7 System German French Acc. BLEU Acc. BLEU Baseline System cept.stack-size cept.50 25.95% 19.50 42.10% 21.44 cept.100 30.04% 19.79 47.32% 21.70 cept.200 35.17% 19.98 51.47% 21.82 cept.500 41.56% 20.14 54.93% 21.87 Our Cept-based Decoders cept.500.fc 48.44% 20.52* 54.73% 21.86 cept.500.t 52.24% 20.34 67.95% 22.00 cept.500.fc.t 61.81% 20.53* 67.76% 21.96 Our Phrase-based Decoders phrase.50 58.88% 20.58* 80.83% 22.04 phrase.100 69.85% 20.73* 88.34% 22.13 phrase.200 79.71% 20.83* 92.93% 22.17* Table 1: </context>
</contexts>
<marker>Zaidan, 2009</marker>
<rawString>Omar F. Zaidan. 2009. Z-MERT: A Fully Configurable Open Source Tool for Minimum Error Rate Training of Machine Translation Systems. The Prague Bulletin of Mathematical Linguistics, 91:79–88.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>