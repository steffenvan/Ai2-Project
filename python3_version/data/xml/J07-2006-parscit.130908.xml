<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.043881">
<title confidence="0.948328">
From Molecule to Metaphor: A Neural Theory of Language
</title>
<author confidence="0.940029">
Jerome A. Feldman
</author>
<affiliation confidence="0.98651">
(University of California, Berkeley)
</affiliation>
<address confidence="0.489626">
Cambridge, MA: The MIT Press (A Bradford book), 2006, xx+357 pp; hardbound,
</address>
<figure confidence="0.6437105">
ISBN 0-262-06253-4, $36.00
Reviewed by
Stefan Frank
Radboud University Nijmegen
</figure>
<bodyText confidence="0.996108147727273">
Over the last decade or so, it has become increasingly clear to many cognitive scientists
that research into human language (and cognition in general, for that matter) has largely
neglected how language and thought are embedded in the body and the world. As
argued by, for instance, Clark (1997), cognition is fundamentally embodied, that is, it
can only be studied in relation to human action, perception, thought, and experience. As
Feldman puts it: “Human language and thought are crucially shaped by the properties
of our bodies and the structure of our physical and social environment. Language
and thought are not best studied as formal mathematics and logic, but as adaptations
that enable creatures like us to thrive in a wide range of situations” (p. 7). Although
it may seem paradoxical to try formalizing this view in a computational theory of
language comprehension, this is exactly what From Molecule to Metaphor does. Starting
from the assumption that human thought is neural computation, Feldman develops
a computational theory that takes the embodied nature of language into account: the
neural theory of language.
The book comprises 27 short chapters, distributed over nine parts. Part I presents
the basic ideas behind embodied language and cognition and explains how the embod-
iment of language is apparent in the brain: The neural circuits involved in a particular
experience or action are, for a large part, the same circuits involved in processing
language about this experience or action.
Part II discusses neural computation, starting from the molecules that take part in
information processing by neurons. This detailed exposition is followed by a description
of neuronal networks in the human body, in particular in the brain.
The description of the neural theory of language begins in Part III, where it is
explained how localist neural networks, often used as psycholinguistic models, can
represent the meaning of concepts. This is done by introducing triangle nodes into the
network. Each triangle node connects the nodes representing a concept, a role, and a
filler—for example, “pea,” “has-color,” and “green.” Such networks are trained by a
process called recruitment learning, which is described only very informally. This is
certainly an interesting idea for combining propositional and connectionist models, but
it does leave the reader with a number of questions. For instance, how is the concept
distinguished from the filler when they can be interchanged, as in “cats, feed-on, mice”
versus “mice, feed-on, cats.” And on a more philosophical note: Where does this leave
embodiment? The idea that there exists a node representing the concept “pea,” neurally
distinct from its properties and from experiences with peas, seems to introduce abstract
and arbitrary symbols. These are quite alien to embodied theories of cognition, which
generally assume modal and analogical perceptual symbols (Barsalou 1999) or even no
symbols at all (Brooks 1991).
Computational Linguistics Volume 33, Number 2
In Part IV, Feldman explains how systems can be described at different levels of ab-
straction. A description at the computational level involves role-filler (or feature-value)
structures and rules for manipulating these. The reader is regularly reminded that this
is just a higher-level description of a connectionist, neural structure. Nevertheless, it
remains unclear how exactly such a computational system can be implemented in a
neural network, especially as the models’ complexity increases in the later chapters of
the book.
Part IV also introduces the notion of conceptual schemas. These are cognitive
structures that emerge from the organization of our bodies and of the world, and are
therefore universal across cultures. Examples are basic concepts such as “grasp” and
“support.” Although the conceptual schemas themselves are universal, the mapping
between words and schemas differs across languages. For instance, there is no one-to-
one translation between the spatial prepositions of different languages. The acquisition
of words denoting spatial relations in different languages is simulated by Regier’s (1996)
connectionist model, which is the first specific model discussed in the book.
Part V discusses the acquisition of words for actions. Knowledge of particular
actions is encoded as execution schemas for controlling motor behavior. People are
not aware of complete actions, but only of particular parameters that can be set in the
execution schema—for instance, the action’s speed, direction, and duration. Learning
the meaning of a verb comes down to associating the word with the corresponding
parameters of the execution schema. These ideas are implemented in Bailey’s (1997)
model of verb learning, presented at the end of this part of the book.
Part VI explains how abstract expressions are understood through metaphor. When
a metaphor is used, words in the abstract domain are understood by using words and
knowledge from more-concrete domains. Primary metaphors are grounded directly in
perception and action. For instance, the expression a warm greeting makes use of primary
metaphor by talking about affection in terms of temperature. Complex metaphors are
conceptual combinations of primary metaphors. One of the most important complex
metaphors is used for describing the structure of events, and combines mappings such
as “causes are physical forces,” “states are locations,” and “changes are movements.”
Understanding a sentence, so it is claimed in Part VI, is not akin to logical inference,
but comes down to mentally simulating the event or situation described by the sentence
(after metaphorically mapping to a more-concrete domain, if necessary). In support of
this view, the book gives evidence from brain-imaging experiments but, oddly, ignores
compelling behavioral findings by, for instance, Glenberg and Kaschak (2003), Stanfield
and Zwaan (2001), and Zwaan, Stanfield, and Yaxley (2002).
In Part VII, this idea of mental simulation is put into computational form by pre-
senting Narayanan’s (1997) model of story comprehension. In this model, background
knowledge is implemented in temporal belief (Bayes) networks. These perform proba-
bilistic inference by means of a process of parallel multiple constraint satisfaction, which
is quite plausible from a neural perspective. Again, metaphorical or abstract language
is understood by mapping to a more-concrete domain. As an example, it is shown how
the model would process an excerpt from a newspaper article about economics.
It isn’t until Part VIII that grammar begins to play a role, reflecting that the neural
theory of language relies less on the syntactic structure of sentences than do more
traditional theories of language comprehension. According to the proposed theory of
grammar (based on Bergen and Chang’s [2005] Embodied Construction Grammar),
the basic element of linguistic knowledge is the construction: a pairing of linguistic
form and meaning. By applying linguistic and conceptual knowledge, an utterance (in
the context of a situation) is transformed into a network of conceptual schemas that
</bodyText>
<page confidence="0.984594">
260
</page>
<subsectionHeader confidence="0.851066">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999316117647059">
specifies the meaning of the sentence. “The job of grammar is to specify which semantic
schemas are being evoked, how they are parameterized, and how they are linked
together in the semantic specification. The complete embodied meaning comes from
enacting or imagining the content ... and always depends on the context in addition to
the utterance” (p. 288). This is clarified by a complete and detailed analysis of the simple
sentence Harry strolled into Berkeley.
The book’s final part presents a model (Chang 2006) that simulates how construc-
tions are learned by associating an utterance (a linguistic form) to its meaning as
inferred from the situational context.
To conclude, From Molecule to Metaphor is a good introduction to embodied theories
of language and computational modeling in cognitive linguistics. It discusses a wide
range of issues, many of which were not included in this review. The view that language
should not be described as a mathematical or logical system but is foremost a part of
human behavior and a function of the brain could well be new and thought-provoking
to readers of this journal. However, the same readers are also likely to desire a high
level of computational detail which the book does not provide, as it does not present
any formal specification of the discussed models.
</bodyText>
<sectionHeader confidence="0.991638" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.998178020833333">
Bailey, D. 1997. When Push Comes to Shove: A
Computational Model of the Role of Motor
Control in the Acquisition of Action Verbs.
Ph.D. thesis, University of California,
Berkeley.
Barsalou, L. W. 1999. Perceptual symbol
systems. Behavorial and Brain Sciences,
22:577–660.
Bergen, B. and N. Chang. 2005. Embodied
construction grammar in simulation-based
language understanding. In J.-O. ¨Ostman
and M. Fried, editors, Construction
Grammar(s): Cognitive and Cross-Language
Dimensions. John Benjamins.
Brooks, R. A. 1991. Intelligence without
representation. Artificial Intelligence,
47:139–159.
Chang, N. 2006. Construction Grammar: A
Computational Model of the Acquisition of
Early Constructions. Ph.D. thesis,
University of California, Berkeley.
Clark, A. 1997. Being There. The MIT Press,
Cambridge, MA.
Glenberg, A. M. and M. P. Kaschak. 2003. The
body’s contribution to language. In B. H.
Ross, editor, The Psychology of Learning and
Motivation, volume 43. Elsevier Science,
pages 93–126.
Narayanan, S. 1997. KARMA:
Knowledge-Based Action Representation for
Metaphor and Aspect. Ph.D. thesis,
University of California, Berkeley.
Regier, T. 1996. The Human Semantic Potential.
MIT Press, Cambridge, MA.
Stanfield, R. A. and R. A. Zwaan. 2001.
The effect of implied orientation
derived from verbal context on picture
recognition. Psychological Science,
12(2):153–156.
Zwaan, R. A., R. A. Stanfield, and R. H.
Yaxley. 2002. Language comprehenders
mentally represent the shapes of objects.
Psychological Science, 13(2):168–171.
Stefan Frank is a postdoctoral researcher at the Radboud University, Nijmegen. He develops
psycholinguistic models of sentence and text comprehension, using recurrent neural networks
and other dynamical systems. His address is: Nijmegen Institute for Cognition and Infor-
mation, P.O. Box 9104, 6500 HE Nijmegen, The Netherlands; e-mail: S.Frank@nici.ru.nl; URL:
www.nici.ru.nl/∼stefanf.
</reference>
<page confidence="0.997762">
261
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.422781">
<title confidence="0.995829">From Molecule to Metaphor: A Neural Theory of Language</title>
<author confidence="0.999989">Jerome A Feldman</author>
<affiliation confidence="0.989855">(University of California, Berkeley)</affiliation>
<address confidence="0.968118">Cambridge, MA: The MIT Press (A Bradford book), 2006, xx+357 pp; hardbound,</address>
<note confidence="0.790176">ISBN 0-262-06253-4, $36.00 Reviewed by</note>
<author confidence="0.99992">Stefan Frank</author>
<affiliation confidence="0.996696">Radboud University Nijmegen</affiliation>
<abstract confidence="0.994201747474748">Over the last decade or so, it has become increasingly clear to many cognitive scientists that research into human language (and cognition in general, for that matter) has largely neglected how language and thought are embedded in the body and the world. As by, for instance, Clark (1997), cognition is fundamentally that is, it can only be studied in relation to human action, perception, thought, and experience. As Feldman puts it: “Human language and thought are crucially shaped by the properties of our bodies and the structure of our physical and social environment. Language and thought are not best studied as formal mathematics and logic, but as adaptations that enable creatures like us to thrive in a wide range of situations” (p. 7). Although it may seem paradoxical to try formalizing this view in a computational theory of comprehension, this is exactly what Molecule to Metaphor Starting from the assumption that human thought is neural computation, Feldman develops a computational theory that takes the embodied nature of language into account: the theory of The book comprises 27 short chapters, distributed over nine parts. Part I presents the basic ideas behind embodied language and cognition and explains how the embodiment of language is apparent in the brain: The neural circuits involved in a particular experience or action are, for a large part, the same circuits involved in processing this experience or action. Part II discusses neural computation, starting from the molecules that take part in information processing by neurons. This detailed exposition is followed by a description of neuronal networks in the human body, in particular in the brain. The description of the neural theory of language begins in Part III, where it is explained how localist neural networks, often used as psycholinguistic models, can the meaning of concepts. This is done by introducing nodes the network. Each triangle node connects the nodes representing a concept, a role, and a filler—for example, “pea,” “has-color,” and “green.” Such networks are trained by a called which is described only very informally. This is certainly an interesting idea for combining propositional and connectionist models, but it does leave the reader with a number of questions. For instance, how is the concept distinguished from the filler when they can be interchanged, as in “cats, feed-on, mice” versus “mice, feed-on, cats.” And on a more philosophical note: Where does this leave embodiment? The idea that there exists a node representing the concept “pea,” neurally distinct from its properties and from experiences with peas, seems to introduce abstract and arbitrary symbols. These are quite alien to embodied theories of cognition, which assume modal and analogical symbols 1999) or even no symbols at all (Brooks 1991). Computational Linguistics Volume 33, Number 2 In Part IV, Feldman explains how systems can be described at different levels of abstraction. A description at the computational level involves role-filler (or feature-value) structures and rules for manipulating these. The reader is regularly reminded that this is just a higher-level description of a connectionist, neural structure. Nevertheless, it remains unclear how exactly such a computational system can be implemented in a neural network, especially as the models’ complexity increases in the later chapters of the book. IV also introduces the notion of These are cognitive structures that emerge from the organization of our bodies and of the world, and are therefore universal across cultures. Examples are basic concepts such as “grasp” and “support.” Although the conceptual schemas themselves are universal, the mapping between words and schemas differs across languages. For instance, there is no one-toone translation between the spatial prepositions of different languages. The acquisition of words denoting spatial relations in different languages is simulated by Regier’s (1996) connectionist model, which is the first specific model discussed in the book. Part V discusses the acquisition of words for actions. Knowledge of particular is encoded as schemas controlling motor behavior. People are not aware of complete actions, but only of particular parameters that can be set in the execution schema—for instance, the action’s speed, direction, and duration. Learning the meaning of a verb comes down to associating the word with the corresponding parameters of the execution schema. These ideas are implemented in Bailey’s (1997) model of verb learning, presented at the end of this part of the book. Part VI explains how abstract expressions are understood through metaphor. When a metaphor is used, words in the abstract domain are understood by using words and from more-concrete domains. metaphors grounded directly in and action. For instance, the expression warm greeting use of primary by talking about affection in terms of temperature. metaphors conceptual combinations of primary metaphors. One of the most important complex metaphors is used for describing the structure of events, and combines mappings such as “causes are physical forces,” “states are locations,” and “changes are movements.” Understanding a sentence, so it is claimed in Part VI, is not akin to logical inference, but comes down to mentally simulating the event or situation described by the sentence (after metaphorically mapping to a more-concrete domain, if necessary). In support of this view, the book gives evidence from brain-imaging experiments but, oddly, ignores compelling behavioral findings by, for instance, Glenberg and Kaschak (2003), Stanfield and Zwaan (2001), and Zwaan, Stanfield, and Yaxley (2002). In Part VII, this idea of mental simulation is put into computational form by presenting Narayanan’s (1997) model of story comprehension. In this model, background knowledge is implemented in temporal belief (Bayes) networks. These perform probabilistic inference by means of a process of parallel multiple constraint satisfaction, which is quite plausible from a neural perspective. Again, metaphorical or abstract language is understood by mapping to a more-concrete domain. As an example, it is shown how the model would process an excerpt from a newspaper article about economics. It isn’t until Part VIII that grammar begins to play a role, reflecting that the neural theory of language relies less on the syntactic structure of sentences than do more traditional theories of language comprehension. According to the proposed theory of grammar (based on Bergen and Chang’s [2005] Embodied Construction Grammar), basic element of linguistic knowledge is the pairing of linguistic form and meaning. By applying linguistic and conceptual knowledge, an utterance (in the context of a situation) is transformed into a network of conceptual schemas that 260 Book Reviews specifies the meaning of the sentence. “The job of grammar is to specify which semantic schemas are being evoked, how they are parameterized, and how they are linked together in the semantic specification. The complete embodied meaning comes from enacting or imagining the content ... and always depends on the context in addition to the utterance” (p. 288). This is clarified by a complete and detailed analysis of the simple strolled into The book’s final part presents a model (Chang 2006) that simulates how constructions are learned by associating an utterance (a linguistic form) to its meaning as inferred from the situational context.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bailey</author>
</authors>
<title>When Push Comes to Shove: A Computational Model of the Role of Motor Control in the Acquisition of Action Verbs.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Berkeley.</institution>
<marker>Bailey, 1997</marker>
<rawString>Bailey, D. 1997. When Push Comes to Shove: A Computational Model of the Role of Motor Control in the Acquisition of Action Verbs. Ph.D. thesis, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L W Barsalou</author>
</authors>
<title>Perceptual symbol systems.</title>
<date>1999</date>
<journal>Behavorial and Brain Sciences,</journal>
<pages>22--577</pages>
<contexts>
<context position="3207" citStr="Barsalou 1999" startWordPosition="495" endWordPosition="496">ionist models, but it does leave the reader with a number of questions. For instance, how is the concept distinguished from the filler when they can be interchanged, as in “cats, feed-on, mice” versus “mice, feed-on, cats.” And on a more philosophical note: Where does this leave embodiment? The idea that there exists a node representing the concept “pea,” neurally distinct from its properties and from experiences with peas, seems to introduce abstract and arbitrary symbols. These are quite alien to embodied theories of cognition, which generally assume modal and analogical perceptual symbols (Barsalou 1999) or even no symbols at all (Brooks 1991). Computational Linguistics Volume 33, Number 2 In Part IV, Feldman explains how systems can be described at different levels of abstraction. A description at the computational level involves role-filler (or feature-value) structures and rules for manipulating these. The reader is regularly reminded that this is just a higher-level description of a connectionist, neural structure. Nevertheless, it remains unclear how exactly such a computational system can be implemented in a neural network, especially as the models’ complexity increases in the later cha</context>
</contexts>
<marker>Barsalou, 1999</marker>
<rawString>Barsalou, L. W. 1999. Perceptual symbol systems. Behavorial and Brain Sciences, 22:577–660.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Bergen</author>
<author>N Chang</author>
</authors>
<title>Embodied construction grammar in simulation-based language understanding.</title>
<date>2005</date>
<editor>In J.-O. ¨Ostman and M. Fried, editors,</editor>
<publisher>John Benjamins.</publisher>
<marker>Bergen, Chang, 2005</marker>
<rawString>Bergen, B. and N. Chang. 2005. Embodied construction grammar in simulation-based language understanding. In J.-O. ¨Ostman and M. Fried, editors, Construction Grammar(s): Cognitive and Cross-Language Dimensions. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Brooks</author>
</authors>
<title>Intelligence without representation.</title>
<date>1991</date>
<journal>Artificial Intelligence,</journal>
<pages>47--139</pages>
<contexts>
<context position="3247" citStr="Brooks 1991" startWordPosition="503" endWordPosition="504">r with a number of questions. For instance, how is the concept distinguished from the filler when they can be interchanged, as in “cats, feed-on, mice” versus “mice, feed-on, cats.” And on a more philosophical note: Where does this leave embodiment? The idea that there exists a node representing the concept “pea,” neurally distinct from its properties and from experiences with peas, seems to introduce abstract and arbitrary symbols. These are quite alien to embodied theories of cognition, which generally assume modal and analogical perceptual symbols (Barsalou 1999) or even no symbols at all (Brooks 1991). Computational Linguistics Volume 33, Number 2 In Part IV, Feldman explains how systems can be described at different levels of abstraction. A description at the computational level involves role-filler (or feature-value) structures and rules for manipulating these. The reader is regularly reminded that this is just a higher-level description of a connectionist, neural structure. Nevertheless, it remains unclear how exactly such a computational system can be implemented in a neural network, especially as the models’ complexity increases in the later chapters of the book. Part IV also introduc</context>
</contexts>
<marker>Brooks, 1991</marker>
<rawString>Brooks, R. A. 1991. Intelligence without representation. Artificial Intelligence, 47:139–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Chang</author>
</authors>
<title>Construction Grammar: A Computational Model of the Acquisition of Early Constructions.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Berkeley.</institution>
<contexts>
<context position="7935" citStr="Chang 2006" startWordPosition="1214" endWordPosition="1215">ext of a situation) is transformed into a network of conceptual schemas that 260 Book Reviews specifies the meaning of the sentence. “The job of grammar is to specify which semantic schemas are being evoked, how they are parameterized, and how they are linked together in the semantic specification. The complete embodied meaning comes from enacting or imagining the content ... and always depends on the context in addition to the utterance” (p. 288). This is clarified by a complete and detailed analysis of the simple sentence Harry strolled into Berkeley. The book’s final part presents a model (Chang 2006) that simulates how constructions are learned by associating an utterance (a linguistic form) to its meaning as inferred from the situational context. To conclude, From Molecule to Metaphor is a good introduction to embodied theories of language and computational modeling in cognitive linguistics. It discusses a wide range of issues, many of which were not included in this review. The view that language should not be described as a mathematical or logical system but is foremost a part of human behavior and a function of the brain could well be new and thought-provoking to readers of this journ</context>
</contexts>
<marker>Chang, 2006</marker>
<rawString>Chang, N. 2006. Construction Grammar: A Computational Model of the Acquisition of Early Constructions. Ph.D. thesis, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Clark</author>
</authors>
<title>Being There.</title>
<date>1997</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Clark, 1997</marker>
<rawString>Clark, A. 1997. Being There. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Glenberg</author>
<author>M P Kaschak</author>
</authors>
<title>The body’s contribution to language. In</title>
<date>2003</date>
<booktitle>The Psychology of Learning and Motivation,</booktitle>
<volume>43</volume>
<pages>93--126</pages>
<editor>B. H. Ross, editor,</editor>
<publisher>Elsevier Science,</publisher>
<contexts>
<context position="6157" citStr="Glenberg and Kaschak (2003)" startWordPosition="936" endWordPosition="939">e of the most important complex metaphors is used for describing the structure of events, and combines mappings such as “causes are physical forces,” “states are locations,” and “changes are movements.” Understanding a sentence, so it is claimed in Part VI, is not akin to logical inference, but comes down to mentally simulating the event or situation described by the sentence (after metaphorically mapping to a more-concrete domain, if necessary). In support of this view, the book gives evidence from brain-imaging experiments but, oddly, ignores compelling behavioral findings by, for instance, Glenberg and Kaschak (2003), Stanfield and Zwaan (2001), and Zwaan, Stanfield, and Yaxley (2002). In Part VII, this idea of mental simulation is put into computational form by presenting Narayanan’s (1997) model of story comprehension. In this model, background knowledge is implemented in temporal belief (Bayes) networks. These perform probabilistic inference by means of a process of parallel multiple constraint satisfaction, which is quite plausible from a neural perspective. Again, metaphorical or abstract language is understood by mapping to a more-concrete domain. As an example, it is shown how the model would proce</context>
</contexts>
<marker>Glenberg, Kaschak, 2003</marker>
<rawString>Glenberg, A. M. and M. P. Kaschak. 2003. The body’s contribution to language. In B. H. Ross, editor, The Psychology of Learning and Motivation, volume 43. Elsevier Science, pages 93–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Narayanan</author>
</authors>
<title>KARMA: Knowledge-Based Action Representation for Metaphor and Aspect.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Berkeley.</institution>
<marker>Narayanan, 1997</marker>
<rawString>Narayanan, S. 1997. KARMA: Knowledge-Based Action Representation for Metaphor and Aspect. Ph.D. thesis, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Regier</author>
</authors>
<title>The Human Semantic Potential.</title>
<date>1996</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Regier, 1996</marker>
<rawString>Regier, T. 1996. The Human Semantic Potential. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Stanfield</author>
<author>R A Zwaan</author>
</authors>
<title>The effect of implied orientation derived from verbal context on picture recognition.</title>
<date>2001</date>
<journal>Psychological Science,</journal>
<volume>12</volume>
<issue>2</issue>
<contexts>
<context position="6185" citStr="Stanfield and Zwaan (2001)" startWordPosition="940" endWordPosition="943">ex metaphors is used for describing the structure of events, and combines mappings such as “causes are physical forces,” “states are locations,” and “changes are movements.” Understanding a sentence, so it is claimed in Part VI, is not akin to logical inference, but comes down to mentally simulating the event or situation described by the sentence (after metaphorically mapping to a more-concrete domain, if necessary). In support of this view, the book gives evidence from brain-imaging experiments but, oddly, ignores compelling behavioral findings by, for instance, Glenberg and Kaschak (2003), Stanfield and Zwaan (2001), and Zwaan, Stanfield, and Yaxley (2002). In Part VII, this idea of mental simulation is put into computational form by presenting Narayanan’s (1997) model of story comprehension. In this model, background knowledge is implemented in temporal belief (Bayes) networks. These perform probabilistic inference by means of a process of parallel multiple constraint satisfaction, which is quite plausible from a neural perspective. Again, metaphorical or abstract language is understood by mapping to a more-concrete domain. As an example, it is shown how the model would process an excerpt from a newspap</context>
</contexts>
<marker>Stanfield, Zwaan, 2001</marker>
<rawString>Stanfield, R. A. and R. A. Zwaan. 2001. The effect of implied orientation derived from verbal context on picture recognition. Psychological Science, 12(2):153–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Zwaan</author>
<author>R A Stanfield</author>
<author>R H Yaxley</author>
</authors>
<title>Language comprehenders mentally represent the shapes of objects.</title>
<date>2002</date>
<journal>Psychological Science,</journal>
<volume>13</volume>
<issue>2</issue>
<marker>Zwaan, Stanfield, Yaxley, 2002</marker>
<rawString>Zwaan, R. A., R. A. Stanfield, and R. H. Yaxley. 2002. Language comprehenders mentally represent the shapes of objects. Psychological Science, 13(2):168–171.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stefan</author>
</authors>
<title>Frank is a postdoctoral researcher at the Radboud University, Nijmegen. He develops psycholinguistic models of sentence and text comprehension, using recurrent neural networks and other dynamical systems. His address is:</title>
<booktitle>Nijmegen Institute for Cognition and Information, P.O. Box 9104, 6500 HE Nijmegen, The Netherlands; e-mail: S.Frank@nici.ru.nl; URL: www.nici.ru.nl/∼stefanf.</booktitle>
<marker>Stefan, </marker>
<rawString>Stefan Frank is a postdoctoral researcher at the Radboud University, Nijmegen. He develops psycholinguistic models of sentence and text comprehension, using recurrent neural networks and other dynamical systems. His address is: Nijmegen Institute for Cognition and Information, P.O. Box 9104, 6500 HE Nijmegen, The Netherlands; e-mail: S.Frank@nici.ru.nl; URL: www.nici.ru.nl/∼stefanf.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>