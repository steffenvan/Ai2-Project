<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017788">
<title confidence="0.9984975">
The Prevalence of Descriptive Referring Expressions
in News and Narrative
</title>
<author confidence="0.907315">
Raquel Herv´as
</author>
<affiliation confidence="0.646003333333333">
Departamento de Ingenieria
del Software e Inteligencia Artificial
Universidad Complutense de Madrid
</affiliation>
<address confidence="0.921865">
Madrid, 28040 Spain
</address>
<email confidence="0.996778">
raquelhb@fdi.ucm.es
</email>
<author confidence="0.987017">
Mark Alan Finlayson
</author>
<affiliation confidence="0.994892">
Computer Science and
Artificial Intelligence Laboratory
Massachusetts Institute of Technology
</affiliation>
<address confidence="0.888574">
Cambridge, MA, 02139 USA
</address>
<email confidence="0.999429">
markaf@mit.edu
</email>
<sectionHeader confidence="0.993909" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999862">
Generating referring expressions is a key
step in Natural Language Generation. Re-
searchers have focused almost exclusively
on generating distinctive referring expres-
sions, that is, referring expressions that
uniquely identify their intended referent.
While undoubtedly one of their most im-
portant functions, referring expressions
can be more than distinctive. In particular,
descriptive referring expressions – those
that provide additional information not re-
quired for distinction – are critical to flu-
ent, efficient, well-written text. We present
a corpus analysis in which approximately
one-fifth of 7,207 referring expressions in
24,422 words of news and narrative are de-
scriptive. These data show that if we are
ever to fully master natural language gen-
eration, especially for the genres of news
and narrative, researchers will need to de-
vote more attention to understanding how
to generate descriptive, and not just dis-
tinctive, referring expressions.
</bodyText>
<sectionHeader confidence="0.984621" genericHeader="method">
1 A Distinctive Focus
</sectionHeader>
<bodyText confidence="0.999282557692308">
Generating referring expressions is a key step in
Natural Language Generation (NLG). From early
treatments in seminal papers by Appelt (1985)
and Reiter and Dale (1992) to the recent set
of Referring Expression Generation (REG) Chal-
lenges (Gatt et al., 2009) through different corpora
available for the community (Eugenio et al., 1998;
van Deemter et al., 2006; Viethen and Dale, 2008),
generating referring expressions has become one
of the most studied areas of NLG.
Researchers studying this area have, almost
without exception, focused exclusively on how
to generate distinctive referring expressions, that
is, referring expressions that unambiguously iden-
tify their intended referent. Referring expres-
sions, however, may be more than distinctive. It
is widely acknowledged that they can be used to
achieve multiple goals, above and beyond distinc-
tion. Here we focus on descriptive referring ex-
pressions, that is, referring expressions that are not
only distinctive, but provide additional informa-
tion not required for identifying their intended ref-
erent. Consider the following text, in which some
of the referring expressions have been underlined:
Once upon a time there was a man, who had
three daughters. They lived in a house and
their dresses were made offabric.
While a bit strange, the text is perfectly well-
formed. All the referring expressions are distinc-
tive, in that we can properly identify the referents
of each expression. But the real text, the opening
lines to the folktale The Beauty and the Beast, is
actually much more lyrical:
Once upon a time there was a rich merchant,
who had three daughters. They lived in a
very fine house and their gowns were made
of the richest fabric sewn with jewels.
All the boldfaced portions – namely, the choice
of head nouns, the addition of adjectives, the use
of appositive phrases – serve to perform a descrip-
tive function, and, importantly, are all unneces-
sary for distinction! In all of these cases, the au-
thor is using the referring expressions as a vehi-
cle for communicating information about the ref-
erents. This descriptive information is sometimes
new, sometimes necessary for understanding the
text, and sometimes just for added flavor. But
when the expression is descriptive, as opposed to
distinctive, this additional information is not re-
quired for identifying the referent of the expres-
sion, and it is these sorts of referring expressions
that we will be concerned with here.
</bodyText>
<page confidence="0.993722">
49
</page>
<note confidence="0.5068105">
Proceedings of the ACL 2010 Conference Short Papers, pages 49–54,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999960066666667">
Although these sorts of referring expression
have been mostly ignored by researchers in this
area1, we show in this corpus study that descrip-
tive expressions are in fact quite prevalent: nearly
one-fifth of referring expressions in news and nar-
rative are descriptive. In particular, our data,
the trained judgments of native English speakers,
show that 18% of all distinctive referring expres-
sions in news and 17% of those in narrative folk-
tales are descriptive. With this as motivation, we
argue that descriptive referring expressions must
be studied more carefully, especially as the field
progresses from referring in a physical, immedi-
ate context (like that in the REG Challenges) to
generating more literary forms of text.
</bodyText>
<sectionHeader confidence="0.967958" genericHeader="method">
2 Corpus Annotation
</sectionHeader>
<bodyText confidence="0.9998965">
This is a corpus study; our procedure was there-
fore to define our annotation guidelines (Sec-
tion 2.1), select texts to annotate (2.2), create an
annotation tool for our annotators (2.3), and, fi-
nally, train annotators, have them annotate refer-
ring expressions’ constituents and function, and
then adjudicate the double-annotated texts into a
gold standard (2.4).
</bodyText>
<subsectionHeader confidence="0.962326">
2.1 Definitions
</subsectionHeader>
<bodyText confidence="0.993470681818182">
We wrote an annotation guide explaining the dif-
ference between distinctive and descriptive refer-
ring expressions. We used the guide when train-
ing annotators, and it was available to them while
annotating. With limited space here we can only
give an outline of what is contained in the guide;
for full details see (Finlayson and Herv´as, 2010a).
Referring Expressions We defined referring
expressions as referential noun phrases and their
coreferential expressions, e.g., “John kissed Mary.
She blushed.”. This included referring expressions
to generics (e.g., “Lions are fierce”), dates, times,
and numbers, as well as events if they were re-
ferred to using a noun phrase. We included in each
referring expression all the determiners, quan-
tifiers, adjectives, appositives, and prepositional
phrases that syntactically attached to that expres-
sion. When referring expressions were nested, all
the nested referring expressions were also marked
separately.
Nuclei vs. Modifiers In the only previous cor-
pus study of descriptive referring expressions, on
</bodyText>
<footnote confidence="0.814764">
1With the exception of a small amount of work, discussed
in Section 4.
</footnote>
<bodyText confidence="0.999596052631579">
museum labels, Cheng et al. (2001) noted that de-
scriptive information is often integrated into refer-
ring expressions using modifiers to the head noun.
To study this, and to allow our results to be more
closely compared with Cheng’s, we had our an-
notators split referring expressions into their con-
stituents, portions called either nuclei or modifiers.
The nuclei were the portions of the referring ex-
pression that performed the ‘core’ referring func-
tion; the modifiers were those portions that could
be varied, syntactically speaking, independently of
the nuclei. Annotators then assigned a distinctive
or descriptive function to each constituent, rather
than the referring expression as a whole.
Normally, the nuclei corresponded to the head
of the noun phrase. In (1), the nucleus is the token
king, which we have here surrounded with square
brackets. The modifiers, surrounded by parenthe-
ses, are The and old.
</bodyText>
<equation confidence="0.548997">
(1) (The) (old) [king] was wise.
</equation>
<bodyText confidence="0.9974795">
Phrasal modifiers were marked as single modi-
fiers, for example, in (2).
</bodyText>
<listItem confidence="0.83341">
(2) (The) [roof] (of the house) collapsed.
</listItem>
<bodyText confidence="0.999713888888889">
It is significant that we had our annotators mark
and tag the nuclei of referring expressions. Cheng
and colleagues only mentioned the possibility that
additional information could be introduced in the
modifiers. However, O’Donnell et al. (1998) ob-
served that often the choice of head noun can also
influence the function of a referring expression.
Consider (3), in which the word villain is used to
refer to the King.
</bodyText>
<listItem confidence="0.895682">
(3) The King assumed the throne today.
I don’t trust (that) [villain] one bit.
</listItem>
<bodyText confidence="0.999924923076923">
The speaker could have merely used him to re-
fer to the King–the choice of that particular head
noun villain gives us additional information about
the disposition of the speaker. Thus villain is de-
scriptive.
Function: Distinctive vs. Descriptive As al-
ready noted, instead of tagging the whole re-
ferring expression, annotators tagged each con-
stituent (nuclei and modifiers) as distinctive or de-
scriptive.
The two main tests for determining descriptive-
ness were (a) if presence of the constituent was
unnecessary for identifying the referent, or (b) if
</bodyText>
<page confidence="0.974763">
50
</page>
<bodyText confidence="0.999944">
the constituent was expressed using unusual or os-
tentatious word choice. If either was true, the con-
stituent was considered descriptive; otherwise, it
was tagged as distinctive. In cases where the con-
stituent was completely irrelevant to identifying
the referent, it was tagged as descriptive. For ex-
ample, in the folktale The Princess and the Pea,
from which (1) was extracted, there is only one
king in the entire story. Thus, in that story, the
king is sufficient for identification, and therefore
the modifier old is descriptive. This points out the
importance of context in determining distinctive-
ness or descriptiveness; if there had been a room-
ful of kings, the tags on those modifiers would
have been reversed.
There is some question as to whether copular
predicates, such as the plumber in (4), are actually
referring expressions.
</bodyText>
<listItem confidence="0.597542">
(4) John is the plumber
</listItem>
<bodyText confidence="0.9999314">
Our annotators marked and tagged these construc-
tions as normal referring expressions, but they
added an additional flag to identify them as cop-
ular predicates. We then excluded these construc-
tions from our final analysis. Note that copular
predicates were treated differently from apposi-
tives: in appositives the predicate was included in
the referring expression, and in most cases (again,
depending on context) was marked descriptive
(e.g., John, the plumber, slept.).
</bodyText>
<subsectionHeader confidence="0.995971">
2.2 Text Selection
</subsectionHeader>
<bodyText confidence="0.999996285714286">
Our corpus comprised 62 texts, all originally writ-
ten in English, from two different genres, news
and folktales. We began with 30 folktales of dif-
ferent sizes, totaling 12,050 words. These texts
were used in a previous work on the influence of
dialogues on anaphora resolution algorithms (Ag-
garwal et al., 2009); they were assembled with an
eye toward including different styles, different au-
thors, and different time periods. Following this,
we matched, approximately, the number of words
in the folktales by selecting 32 texts from Wall
Street Journal section of the Penn Treebank (Mar-
cus et al., 1993). These texts were selected at ran-
dom from the first 200 texts in the corpus.
</bodyText>
<subsectionHeader confidence="0.997271">
2.3 The Story Workbench
</subsectionHeader>
<bodyText confidence="0.9997942">
We used the Story Workbench application (Fin-
layson, 2008) to actually perform the annotation.
The Story Workbench is a semantic annotation
program that, among other things, includes the
ability to annotate referring expressions and coref-
erential relationships. We added the ability to an-
notate nuclei, modifiers, and their functions by
writing a workbench “plugin” in Java that could
be installed in the application.
The Story Workbench is not yet available to the
public at large, being in a limited distribution beta
testing phase. The developers plan to release it as
free software within the next year. At that time,
we also plan to release our plugin as free, down-
loadable software.
</bodyText>
<subsectionHeader confidence="0.998797">
2.4 Annotation &amp; Adjudication
</subsectionHeader>
<bodyText confidence="0.99998654054054">
The main task of the study was the annotation of
the constituents of each referring expression, as
well as the function (distinctive or descriptive) of
each constituent. The system generated a first pass
of constituent analysis, but did not mark functions.
We hired two native English annotators, neither of
whom had any linguistics background, who cor-
rected these automatically-generated constituent
analyses, and tagged each constituent as descrip-
tive or distinctive. Every text was annotated by
both annotators. Adjudication of the differences
was conducted by discussion between the two an-
notators; the second author moderated these dis-
cussions and settled irreconcilable disagreements.
We followed a “train-as-you-go” paradigm, where
there was no distinct training period, but rather
adjudication proceeded in step with annotation,
and annotators received feedback during those ses-
sions.
We calculated two measures of inter-annotator
agreement: a kappa statistic and an f-measure,
shown in Table 1. All of our f-measures indicated
that annotators agreed almost perfectly on the lo-
cation of referring expressions and their break-
down into constituents. These agreement calcu-
lations were performed on the annotators’ original
corrected texts.
All the kappa statistics were calculated for two
tags (nuclei vs. modifier for the constituents, and
distinctive vs. descriptive for the functions) over
both each token assigned to a nucleus or modifier
and each referring expression pair. Our kappas in-
dicate moderate to good agreement, especially for
the folktales. These results are expected because
of the inherent subjectivity of language. During
the adjudication sessions it became clear that dif-
ferent people do not consider the same information
</bodyText>
<page confidence="0.99317">
51
</page>
<bodyText confidence="0.9990985">
as obvious or descriptive for the same concepts,
and even the contexts deduced by each annotators
from the texts were sometimes substantially dif-
ferent.
</bodyText>
<table confidence="0.995291666666667">
Tales Articles Total
Ref. Exp. (Fl) 1.00 0.99 0.99
Constituents (Fl) 0.99 0.98 0.98
Nuc./Mod. (r.) 0.97 0.95 0.96
Const. Func. (r.) 0.61 0.48 0.54
Ref. Exp. Func. (r.) 0.65 0.54 0.59
</table>
<tableCaption confidence="0.995632">
Table 1: Inter-annotator agreement measures
</tableCaption>
<table confidence="0.9995765">
Tales Articles Total
Nuclei 3,666 3,502 7,168
Max. Nuc/Ref 1 1 1
Dist. Nuc. 95% 97% 96%
Desc. Nuc. 5% 3% 4%
Modifiers 2,277 3,627 5,904
Avg. Mod/Ref 0.6 1.0 0.8
Max. Mod/Ref 4 6 6
Dist. Mod. 78% 81% 80%
Desc. Mod. 22% 19% 20%
</table>
<tableCaption confidence="0.999721">
Table 3: Breakdown of Constituent Tags
</tableCaption>
<sectionHeader confidence="0.999736" genericHeader="method">
3 Results
</sectionHeader>
<bodyText confidence="0.999502428571429">
Table 2 lists the primary results of the study. We
considered a referring expression descriptive if
any of its constituents were descriptive. Thus,
18% of the referring expressions in the corpus
added additional information beyond what was re-
quired to unambiguously identify their referent.
The results were similar in both genres.
</bodyText>
<table confidence="0.996498222222222">
Tales Articles Total
Texts 30 32 62
Words 12,050 12,372 24,422
Sentences 904 571 1,475
Ref. Exp. 3,681 3,526 7,207
Dist. Ref. Exp. 3,057 2,830 5,887
Desc. Ref. Exp. 609 672 1,281
% Dist. Ref. 83% 81% 82%
% Desc. Ref. 17% 19% 18%
</table>
<tableCaption confidence="0.999422">
Table 2: Primary results.
</tableCaption>
<bodyText confidence="0.996633375">
Table 3 contains the percentages of descriptive
and distinctive tags broken down by constituent.
Like Cheng’s results, our analysis shows that de-
scriptive referring expressions make up a signif-
icant fraction of all referring expressions. Al-
though Cheng did not examine nuclei, our results
show that the use of descriptive nuclei is small but
not negligible.
</bodyText>
<sectionHeader confidence="0.97134" genericHeader="method">
4 Relation to the Field
</sectionHeader>
<bodyText confidence="0.999827772727273">
Researchers working on generating referring ex-
pressions typically acknowledge that referring ex-
pressions can perform functions other than distinc-
tion. Despite this widespread acknowledgment,
researchers have, for the most part, explicitly ig-
nored these functions. Exceptions to this trend
are three. First is the general study of aggregation
in the process of referring expression generation.
Second and third are corpus studies by Cheng et al.
(2001) and Jordan (2000a) that bear on the preva-
lence of descriptive referring expressions.
The NLG subtask of aggregation can be used
to imbue referring expressions with a descriptive
function (Reiter and Dale, 2000, §5.3). There is a
specific kind of aggregation called embedding that
moves information from one clause to another in-
side the structure of a separate noun phrase. This
type of aggregation can be used to transform two
sentences such as “The princess lived in a castle.
She was pretty” into “The pretty princess lived in
a castle”. The adjective pretty, previously a cop-
ular predicate, becomes a descriptive modifier of
the reference to the princess, making the second
text more natural and fluent. This kind of ag-
gregation is widely used by humans for making
the discourse more compact and efficient. In or-
der to create NLG systems with this ability, we
must take into account the caveat, noted by Cheng
(1998), that any non-distinctive information in a
referring expression must not lead to confusion
about the distinctive function of the referring ex-
pression. This is by no means a trivial problem
– this sort of aggregation interferes with refer-
ring and coherence planning at both a local and
global level (Cheng and Mellish, 2000; Cheng et
al., 2001). It is clear, from the current state of the
art of NLG, that we have not yet obtained a deep
enough understanding of aggregation to enable us
to handle these interactions. More research on the
topic is needed.
Two previous corpus studies have looked at
the use of descriptive referring expressions. The
first showed explicitly that people craft descrip-
tive referring expressions to accomplish different
</bodyText>
<page confidence="0.996297">
52
</page>
<bodyText confidence="0.999971744680851">
goals. Jordan and colleagues (Jordan, 2000b; Jor-
dan, 2000a) examined the use of referring expres-
sions using the COCONUT corpus (Eugenio et
al., 1998). They tested how domain and discourse
goals can influence the content of non-pronominal
referring expressions in a dialogue context, check-
ing whether or not a subject’s goals led them to in-
clude non-referring information in a referring ex-
pression. Their results are intriguing because they
point toward heretofore unexamined constraints,
utilities and expectations (possibly genre- or style-
dependent) that may underlie the use of descriptive
information to perform different functions, and are
not yet captured by aggregation modules in partic-
ular or NLG systems in general.
In the other corpus study, which partially in-
spired this work, Cheng and colleagues analyzed
a set of museum descriptions, the GNOME cor-
pus (Poesio, 2004), for the pragmatic functions of
referring expressions. They had three functions
in their study, in contrast to our two. Their first
function (marked by their uniq tag) was equiv-
alent to our distinctive function. The other two
were specializations of our descriptive tag, where
they differentiated between additional information
that helped to understand the text (int), or ad-
ditional information not necessary for understand-
ing (attr). Despite their annotators seeming to
have trouble distinguishing between the latter two
tags, they did achieve good overall inter-annotator
agreement. They identified 1,863 modifiers to
referring expressions in their corpus, of which
47.3% fulfilled a descriptive (attr or int) func-
tion. This is supportive of our main assertion,
namely, that descriptive referring expressions, not
only crucial for efficient and fluent text, are ac-
tually a significant phenomenon. It is interest-
ing, though, that Cheng’s fraction of descriptive
referring expression was so much higher than ours
(47.3% versus our 18%). We attribute this sub-
stantial difference to genre, in that Cheng stud-
ied museum labels, in which the writer is space-
constrained, having to pack a lot of information
into a small label. The issue bears further study,
and perhaps will lead to insights into differences
in writing style that may be attributed to author or
genre.
</bodyText>
<sectionHeader confidence="0.991227" genericHeader="conclusions">
5 Contributions
</sectionHeader>
<bodyText confidence="0.999973852941177">
We make two contributions in this paper.
First, we assembled, double-annotated, and ad-
judicated into a gold-standard a corpus of 24,422
words. We marked all referring expressions,
coreferential relations, and referring expression
constituents, and tagged each constituent as hav-
ing a descriptive or distinctive function. We wrote
an annotation guide and created software that al-
lows the annotation of this information in free text.
The corpus and the guide are available on-line in a
permanent digital archive (Finlayson and Hervas,
2010a; Finlayson and Hervas, 2010b). The soft-
ware will also be released in the same archive
when the Story Workbench annotation application
is released to the public. This corpus will be useful
for the automatic generation and analysis of both
descriptive and distinctive referring expressions.
Any kind of system intended to generate text as
humans do must take into account that identifica-
tion is not the only function of referring expres-
sions. Many analysis applications would benefit
from the automatic recognition of descriptive re-
ferring expressions.
Second, we demonstrated that descriptive refer-
ring expressions comprise a substantial fraction
(18%) of the referring expressions in news and
narrative. Along with museum descriptions, stud-
ied by Cheng, it seems that news and narrative are
genres where authors naturally use a large num-
ber of descriptive referring expressions. Given that
so little work has been done on descriptive refer-
ring expressions, this indicates that the field would
be well served by focusing more attention on this
phenomenon.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999404411764706">
This work was supported in part by the Air
Force Office of Scientific Research under grant
number A9550-05-1-0321, as well as by the
Office of Naval Research under award number
N00014091059. Any opinions, findings, and con-
clusions or recommendations expressed in this pa-
per are those of the authors and do not necessarily
reflect the views of the Office of Naval Research.
This research is also partially funded the Span-
ish Ministry of Education and Science (TIN2009-
14659-C03-01) and Universidad Complutense de
Madrid (GR58/08). We also thank Whitman
Richards, Ozlem Uzuner, Peter Szolovits, Patrick
Winston, Pablo Gervas, and Mark Seifter for their
helpful comments and discussion, and thank our
annotators Saam Batmanghelidj and Geneva Trot-
ter.
</bodyText>
<page confidence="0.998343">
53
</page>
<sectionHeader confidence="0.99004" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998977444444444">
Alaukik Aggarwal, Pablo Gerv´as, and Raquel Herv´as.
2009. Measuring the influence of errors induced by
the presence of dialogues in reference clustering of
narrative text. In Proceedings of ICON-2009: 7th
International Conference on Natural Language Pro-
cessing, India. Macmillan Publishers.
Douglas E. Appelt. 1985. Planning English referring
expressions. Artificial Intelligence, 26:1–33.
Hua Cheng and Chris Mellish. 2000. Capturing the in-
teraction between aggregation and text planning in
two generation systems. In INLG ’00: First interna-
tional conference on Natural Language Generation
2000, pages 186–193, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Hua Cheng, Massimo Poesio, Renate Henschel, and
Chris Mellish. 2001. Corpus-based np modifier
generation. In NAACL ’01: Second meeting of
the North American Chapter of the Association for
Computational Linguistics on Language technolo-
gies 2001, pages 1–8, Morristown, NJ, USA. Asso-
ciation for Computational Linguistics.
Hua Cheng. 1998. Embedding new information into
referring expressions. In ACL-36: Proceedings of
the 36th Annual Meeting of the Association for Com-
putational Linguistics and 17th International Con-
ference on Computational Linguistics, pages 1478–
1480, Morristown, NJ, USA. Association for Com-
putational Linguistics.
Barbara Di Eugenio, Johanna D. Moore, Pamela W.
Jordan, and Richmond H. Thomason. 1998. An
empirical investigation of proposals in collabora-
tive dialogues. In Proceedings of the 17th inter-
national conference on Computational linguistics,
pages 325–329, Morristown, NJ, USA. Association
for Computational Linguistics.
Mark A. Finlayson and Raquel Herv´as. 2010a. Anno-
tation guide for the UCM/MIT indications, referring
expressions, and coreference corpus (UMIREC cor-
pus). Technical Report MIT-CSAIL-TR-2010-025,
MIT Computer Science and Artificial Intelligence
Laboratory. http://hdl.handle.net/1721.1/54765.
Mark A. Finlayson and Raquel Herv´as. 2010b.
UCM/MIT indications, referring expres-
sions, and coreference corpus (UMIREC
corpus). Work product, MIT Computer Sci-
ence and Artificial Intelligence Laboratory.
http://hdl.handle.net/1721.1/54766.
Mark A. Finlayson. 2008. Collecting semantics in
the wild: The Story Workbench. In Proceedings of
the AAAI Fall Symposium on Naturally-Inspired Ar-
tificial Intelligence, pages 46–53, Menlo Park, CA,
USA. AAAI Press.
Albert Gatt, Anja Belz, and Eric Kow. 2009. The
TUNA-REG challenge 2009: overview and evalu-
ation results. In ENLG ’09: Proceedings of the 12th
European Workshop on Natural Language Genera-
tion, pages 174–182, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
Pamela W. Jordan. 2000a. Can nominal expressions
achieve multiple goals?: an empirical study. In ACL
’00: Proceedings of the 38th Annual Meeting on As-
sociation for Computational Linguistics, pages 142–
149, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Pamela W. Jordan. 2000b. Influences on attribute se-
lection in redescriptions: A corpus study. In Pro-
ceedings of CogSci2000, pages 250–255.
Mitchell P. Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: the penn treebank. Compu-
tational Linguistics, 19(2):313–330.
Michael O’Donnell, Hua Cheng, and Janet Hitze-
man. 1998. Integrating referring and informing in
NP planning. In Proceedings of COLING-ACL’98
Workshop on the Computational Treatment of Nom-
inals, pages 46–56.
Massimo Poesio. 2004. Discourse annotation and
semantic annotation in the GNOME corpus. In
DiscAnnotation ’04: Proceedings of the 2004 ACL
Workshop on Discourse Annotation, pages 72–79,
Morristown, NJ, USA. Association for Computa-
tional Linguistics.
Ehud Reiter and Robert Dale. 1992. A fast algorithm
for the generation of referring expressions. In Pro-
ceedings of the 14th conference on Computational
linguistics, Nantes, France.
Ehud Reiter and Robert Dale. 2000. Building Natural
Language Generation Systems. Cambridge Univer-
sity Press.
Kees van Deemter, Ielka van der Sluis, and Albert Gatt.
2006. Building a semantically transparent corpus
for the generation of referring expressions. In Pro-
ceedings of the 4th International Conference on Nat-
ural Language Generation (Special Session on Data
Sharing and Evaluation), INLG-06.
Jette Viethen and Robert Dale. 2008. The use of spa-
tial relations in referring expressions. In Proceed-
ings of the 5th International Conference on Natural
Language Generation.
</reference>
<page confidence="0.998956">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993456">The Prevalence of Descriptive Referring Expressions in News and Narrative</title>
<author confidence="0.997203">Raquel Herv´as</author>
<affiliation confidence="0.984184666666667">Departamento de Ingenieria del Software e Inteligencia Artificial Universidad Complutense de Madrid</affiliation>
<address confidence="0.998115">Madrid, 28040 Spain</address>
<email confidence="0.955266">raquelhb@fdi.ucm.es</email>
<author confidence="0.99998">Mark Alan Finlayson</author>
<affiliation confidence="0.999935333333333">Computer Science and Artificial Intelligence Laboratory Massachusetts Institute of Technology</affiliation>
<address confidence="0.999412">Cambridge, MA, 02139 USA</address>
<email confidence="0.999525">markaf@mit.edu</email>
<abstract confidence="0.9966024">Generating referring expressions is a key step in Natural Language Generation. Researchers have focused almost exclusively generating expressions, that is, referring expressions that uniquely identify their intended referent. While undoubtedly one of their most important functions, referring expressions can be more than distinctive. In particular, expressions – those that provide additional information not required for distinction – are critical to fluent, efficient, well-written text. We present a corpus analysis in which approximately one-fifth of 7,207 referring expressions in 24,422 words of news and narrative are descriptive. These data show that if we are ever to fully master natural language generation, especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions. 1 A Distinctive Focus Generating referring expressions is a key step in Natural Language Generation (NLG). From early treatments in seminal papers by Appelt (1985) and Reiter and Dale (1992) to the recent set of Referring Expression Generation (REG) Challenges (Gatt et al., 2009) through different corpora available for the community (Eugenio et al., 1998; van Deemter et al., 2006; Viethen and Dale, 2008), generating referring expressions has become one of the most studied areas of NLG. Researchers studying this area have, almost without exception, focused exclusively on how generate expressions, that is, referring expressions that unambiguously identify their intended referent. Referring expressions, however, may be more than distinctive. It is widely acknowledged that they can be used to achieve multiple goals, above and beyond distinc- Here we focus on expressions, that is, referring expressions that are not only distinctive, but provide additional information not required for identifying their intended referent. Consider the following text, in which some of the referring expressions have been underlined: Once upon a time there was a man, who had daughters. They lived in houseand dresseswere made offabric. While a bit strange, the text is perfectly wellformed. All the referring expressions are distinctive, in that we can properly identify the referents of each expression. But the real text, the opening to the folktale Beauty and the is actually much more lyrical: upon a time there was who had three daughters. They lived in a fine houseand their gownswere made the richest with All the boldfaced portions – namely, the choice of head nouns, the addition of adjectives, the use of appositive phrases – serve to perform a descriptive function, and, importantly, are all unnecessary for distinction! In all of these cases, the author is using the referring expressions as a vehicle for communicating information about the referents. This descriptive information is sometimes new, sometimes necessary for understanding the text, and sometimes just for added flavor. But the expression is as opposed to this additional information is not required for identifying the referent of the expression, and it is these sorts of referring expressions that we will be concerned with here. 49 of the ACL 2010 Conference Short pages 49–54, Sweden, 11-16 July 2010. Association for Computational Linguistics Although these sorts of referring expression have been mostly ignored by researchers in this we show in this corpus study that descriptive expressions are in fact quite prevalent: nearly one-fifth of referring expressions in news and narrative are descriptive. In particular, our data, the trained judgments of native English speakers, show that 18% of all distinctive referring expressions in news and 17% of those in narrative folktales are descriptive. With this as motivation, we argue that descriptive referring expressions must be studied more carefully, especially as the field progresses from referring in a physical, immediate context (like that in the REG Challenges) to generating more literary forms of text. 2 Corpus Annotation This is a corpus study; our procedure was therefore to define our annotation guidelines (Section 2.1), select texts to annotate (2.2), create an annotation tool for our annotators (2.3), and, finally, train annotators, have them annotate referring expressions’ constituents and function, and then adjudicate the double-annotated texts into a gold standard (2.4). 2.1 Definitions We wrote an annotation guide explaining the difference between distinctive and descriptive referring expressions. We used the guide when training annotators, and it was available to them while annotating. With limited space here we can only give an outline of what is contained in the guide; for full details see (Finlayson and Herv´as, 2010a). Expressions defined referring expressions as referential noun phrases and their expressions, e.g., “Johnkissed Sheblushed.”. This included referring expressions to generics (e.g., “Lions are fierce”), dates, times, and numbers, as well as events if they were referred to using a noun phrase. We included in each referring expression all the determiners, quantifiers, adjectives, appositives, and prepositional phrases that syntactically attached to that expression. When referring expressions were nested, all the nested referring expressions were also marked separately. vs. Modifiers the only previous corpus study of descriptive referring expressions, on the exception of a small amount of work, discussed in Section 4. museum labels, Cheng et al. (2001) noted that descriptive information is often integrated into referring expressions using modifiers to the head noun. To study this, and to allow our results to be more closely compared with Cheng’s, we had our annotators split referring expressions into their conportions called either The nuclei were the portions of the referring expression that performed the ‘core’ referring function; the modifiers were those portions that could be varied, syntactically speaking, independently of the nuclei. Annotators then assigned a distinctive or descriptive function to each constituent, rather than the referring expression as a whole. Normally, the nuclei corresponded to the head of the noun phrase. In (1), the nucleus is the token which we have here surrounded with square brackets. The modifiers, surrounded by parentheare (The) (old) [king]was wise. Phrasal modifiers were marked as single modifiers, for example, in (2). (The) [roof] (of the house)collapsed. It is significant that we had our annotators mark and tag the nuclei of referring expressions. Cheng and colleagues only mentioned the possibility that additional information could be introduced in the modifiers. However, O’Donnell et al. (1998) observed that often the choice of head noun can also influence the function of a referring expression. (3), in which the word used to refer to the King. (3) The King assumed the throne today. don’t trust [villain]one bit. speaker could have merely used refer to the King–the choice of that particular head us additional information about disposition of the speaker. Thus descriptive. Distinctive vs. Descriptive already noted, instead of tagging the whole referring expression, annotators tagged each constituent (nuclei and modifiers) as distinctive or descriptive. The two main tests for determining descriptiveness were (a) if presence of the constituent was unnecessary for identifying the referent, or (b) if 50 the constituent was expressed using unusual or ostentatious word choice. If either was true, the constituent was considered descriptive; otherwise, it was tagged as distinctive. In cases where the constituent was completely irrelevant to identifying the referent, it was tagged as descriptive. For exin the folktale Princess and the from which (1) was extracted, there is only one in the entire story. Thus, in that story, sufficient for identification, and therefore modifier descriptive. This points out the importance of context in determining distinctiveness or descriptiveness; if there had been a roomful of kings, the tags on those modifiers would have been reversed. There is some question as to whether copular such as plumber (4), are actually referring expressions. Johnis plumber Our annotators marked and tagged these constructions as normal referring expressions, but they added an additional flag to identify them as copular predicates. We then excluded these constructions from our final analysis. Note that copular predicates were treated differently from appositives: in appositives the predicate was included in the referring expression, and in most cases (again, depending on context) was marked descriptive the plumber,slept.). 2.2 Text Selection Our corpus comprised 62 texts, all originally written in English, from two different genres, news and folktales. We began with 30 folktales of different sizes, totaling 12,050 words. These texts were used in a previous work on the influence of dialogues on anaphora resolution algorithms (Aggarwal et al., 2009); they were assembled with an eye toward including different styles, different authors, and different time periods. Following this, we matched, approximately, the number of words in the folktales by selecting 32 texts from Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). These texts were selected at random from the first 200 texts in the corpus. 2.3 The Story Workbench We used the Story Workbench application (Finlayson, 2008) to actually perform the annotation. The Story Workbench is a semantic annotation program that, among other things, includes the ability to annotate referring expressions and coreferential relationships. We added the ability to annotate nuclei, modifiers, and their functions by writing a workbench “plugin” in Java that could be installed in the application. The Story Workbench is not yet available to the public at large, being in a limited distribution beta testing phase. The developers plan to release it as free software within the next year. At that time, we also plan to release our plugin as free, downloadable software. 2.4 Annotation &amp; Adjudication The main task of the study was the annotation of the constituents of each referring expression, as well as the function (distinctive or descriptive) of each constituent. The system generated a first pass of constituent analysis, but did not mark functions. We hired two native English annotators, neither of whom had any linguistics background, who corrected these automatically-generated constituent analyses, and tagged each constituent as descriptive or distinctive. Every text was annotated by both annotators. Adjudication of the differences was conducted by discussion between the two annotators; the second author moderated these discussions and settled irreconcilable disagreements. We followed a “train-as-you-go” paradigm, where there was no distinct training period, but rather adjudication proceeded in step with annotation, and annotators received feedback during those sessions. We calculated two measures of inter-annotator agreement: a kappa statistic and an f-measure, shown in Table 1. All of our f-measures indicated that annotators agreed almost perfectly on the location of referring expressions and their breakdown into constituents. These agreement calculations were performed on the annotators’ original corrected texts. All the kappa statistics were calculated for two tags (nuclei vs. modifier for the constituents, and distinctive vs. descriptive for the functions) over both each token assigned to a nucleus or modifier and each referring expression pair. Our kappas indicate moderate to good agreement, especially for the folktales. These results are expected because of the inherent subjectivity of language. During the adjudication sessions it became clear that different people do not consider the same information 51 as obvious or descriptive for the same concepts, and even the contexts deduced by each annotators from the texts were sometimes substantially different.</abstract>
<note confidence="0.757572578947368">Tales Articles Total Exp. 1.00 0.99 0.99 0.99 0.98 0.98 0.97 0.95 0.96 Func. 0.61 0.48 0.54 Exp. Func. 0.65 0.54 0.59 Table 1: Inter-annotator agreement measures Tales Articles Total Nuclei 3,666 3,502 7,168 Max. Nuc/Ref 1 1 1 Dist. Nuc. 95% 97% 96% Desc. Nuc. 5% 3% 4% Modifiers 2,277 3,627 5,904 Avg. Mod/Ref 0.6 1.0 0.8 Max. Mod/Ref 4 6 6 Dist. Mod. 78% 81% 80% Desc. Mod. 22% 19% 20% Table 3: Breakdown of Constituent Tags 3 Results</note>
<abstract confidence="0.974915">Table 2 lists the primary results of the study. We considered a referring expression descriptive if any of its constituents were descriptive. Thus, 18% of the referring expressions in the corpus added additional information beyond what was required to unambiguously identify their referent. The results were similar in both genres.</abstract>
<note confidence="0.394954">Tales Articles Total Texts 30 32 62 Words 12,050 12,372 24,422 Sentences 904 571 1,475 Ref. Exp. 3,681 3,526 7,207 Dist. Ref. Exp. 3,057 2,830 5,887 Desc. Ref. Exp. 609 672 1,281</note>
<abstract confidence="0.982870662162162">Dist. Ref. 83% 81% 82% % Desc. Ref. 17% 19% 18% Table 2: Primary results. Table 3 contains the percentages of descriptive and distinctive tags broken down by constituent. Like Cheng’s results, our analysis shows that descriptive referring expressions make up a significant fraction of all referring expressions. Although Cheng did not examine nuclei, our results show that the use of descriptive nuclei is small but not negligible. 4 Relation to the Field Researchers working on generating referring expressions typically acknowledge that referring expressions can perform functions other than distinction. Despite this widespread acknowledgment, researchers have, for the most part, explicitly ignored these functions. Exceptions to this trend three. First is the general study of in the process of referring expression generation. Second and third are corpus studies by Cheng et al. (2001) and Jordan (2000a) that bear on the prevalence of descriptive referring expressions. The NLG subtask of aggregation can be used to imbue referring expressions with a descriptive (Reiter and Dale, 2000, There is a kind of aggregation called moves information from one clause to another inside the structure of a separate noun phrase. This type of aggregation can be used to transform two such as princess lived in a castle. was pretty” pretty princess lived in The adjective previously a copular predicate, becomes a descriptive modifier of the reference to the princess, making the second text more natural and fluent. This kind of aggregation is widely used by humans for making the discourse more compact and efficient. In order to create NLG systems with this ability, we must take into account the caveat, noted by Cheng (1998), that any non-distinctive information in a referring expression must not lead to confusion about the distinctive function of the referring expression. This is by no means a trivial problem – this sort of aggregation interferes with referring and coherence planning at both a local and global level (Cheng and Mellish, 2000; Cheng et al., 2001). It is clear, from the current state of the art of NLG, that we have not yet obtained a deep enough understanding of aggregation to enable us to handle these interactions. More research on the topic is needed. Two previous corpus studies have looked at the use of descriptive referring expressions. The first showed explicitly that people craft descriptive referring expressions to accomplish different 52 goals. Jordan and colleagues (Jordan, 2000b; Jordan, 2000a) examined the use of referring expressions using the COCONUT corpus (Eugenio et al., 1998). They tested how domain and discourse goals can influence the content of non-pronominal referring expressions in a dialogue context, checking whether or not a subject’s goals led them to include non-referring information in a referring expression. Their results are intriguing because they point toward heretofore unexamined constraints, utilities and expectations (possibly genreor styledependent) that may underlie the use of descriptive information to perform different functions, and are not yet captured by aggregation modules in particular or NLG systems in general. In the other corpus study, which partially inspired this work, Cheng and colleagues analyzed a set of museum descriptions, the GNOME corpus (Poesio, 2004), for the pragmatic functions of referring expressions. They had three functions in their study, in contrast to our two. Their first (marked by their was equivalent to our distinctive function. The other two were specializations of our descriptive tag, where they differentiated between additional information helped to understand the text or additional information not necessary for understand- Despite their annotators seeming to have trouble distinguishing between the latter two tags, they did achieve good overall inter-annotator agreement. They identified 1,863 modifiers to referring expressions in their corpus, of which fulfilled a descriptive function. This is supportive of our main assertion, namely, that descriptive referring expressions, not only crucial for efficient and fluent text, are actually a significant phenomenon. It is interesting, though, that Cheng’s fraction of descriptive referring expression was so much higher than ours (47.3% versus our 18%). We attribute this substantial difference to genre, in that Cheng studied museum labels, in which the writer is spaceconstrained, having to pack a lot of information into a small label. The issue bears further study, and perhaps will lead to insights into differences in writing style that may be attributed to author or genre. 5 Contributions We make two contributions in this paper. First, we assembled, double-annotated, and adjudicated into a gold-standard a corpus of 24,422 words. We marked all referring expressions, coreferential relations, and referring expression constituents, and tagged each constituent as having a descriptive or distinctive function. We wrote an annotation guide and created software that allows the annotation of this information in free text. The corpus and the guide are available on-line in a permanent digital archive (Finlayson and Hervas, 2010a; Finlayson and Hervas, 2010b). The software will also be released in the same archive when the Story Workbench annotation application is released to the public. This corpus will be useful for the automatic generation and analysis of both descriptive and distinctive referring expressions. Any kind of system intended to generate text as humans do must take into account that identification is not the only function of referring expressions. Many analysis applications would benefit from the automatic recognition of descriptive referring expressions. Second, we demonstrated that descriptive referring expressions comprise a substantial fraction (18%) of the referring expressions in news and narrative. Along with museum descriptions, studied by Cheng, it seems that news and narrative are genres where authors naturally use a large number of descriptive referring expressions. Given that so little work has been done on descriptive referring expressions, this indicates that the field would be well served by focusing more attention on this phenomenon. Acknowledgments This work was supported in part by the Air Force Office of Scientific Research under grant number A9550-05-1-0321, as well as by the Office of Naval Research under award number N00014091059. Any opinions, findings, and conclusions or recommendations expressed in this paper are those of the authors and do not necessarily reflect the views of the Office of Naval Research.</abstract>
<note confidence="0.78293575">This research is also partially funded the Spanish Ministry of Education and Science (TIN2009- 14659-C03-01) and Universidad Complutense de Madrid (GR58/08). We also thank Whitman</note>
<degree confidence="0.6088645">Richards, Ozlem Uzuner, Peter Szolovits, Patrick Winston, Pablo Gervas, and Mark Seifter for their</degree>
<abstract confidence="0.886642">helpful comments and discussion, and thank our annotators Saam Batmanghelidj and Geneva Trotter.</abstract>
<note confidence="0.880068857142857">53 References Alaukik Aggarwal, Pablo Gerv´as, and Raquel Herv´as. 2009. Measuring the influence of errors induced by the presence of dialogues in reference clustering of text. In of ICON-2009: 7th International Conference on Natural Language Pro-</note>
<affiliation confidence="0.802361">India. Macmillan Publishers.</affiliation>
<address confidence="0.806347">Douglas E. Appelt. 1985. Planning English referring</address>
<abstract confidence="0.839969857142857">26:1–33. Hua Cheng and Chris Mellish. 2000. Capturing the interaction between aggregation and text planning in generation systems. In ’00: First international conference on Natural Language Generation pages 186–193, Morristown, NJ, USA. Association for Computational Linguistics.</abstract>
<note confidence="0.889268">Hua Cheng, Massimo Poesio, Renate Henschel, and Chris Mellish. 2001. Corpus-based np modifier In ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technolopages 1–8, Morristown, NJ, USA. Association for Computational Linguistics. Hua Cheng. 1998. Embedding new information into expressions. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conon Computational pages 1478– 1480, Morristown, NJ, USA. Association for Computational Linguistics. Barbara Di Eugenio, Johanna D. Moore, Pamela W. Jordan, and Richmond H. Thomason. 1998. An</note>
<abstract confidence="0.488794375">empirical investigation of proposals in collaboradialogues. In of the 17th interconference on Computational pages 325–329, Morristown, NJ, USA. Association for Computational Linguistics. Mark A. Finlayson and Raquel Herv´as. 2010a. Annotation guide for the UCM/MIT indications, referring expressions, and coreference corpus (UMIREC cor-</abstract>
<pubnum confidence="0.484925">pus). Technical Report MIT-CSAIL-TR-2010-025,</pubnum>
<affiliation confidence="0.530795">MIT Computer Science and Artificial Intelligence</affiliation>
<note confidence="0.847973474576271">Laboratory. http://hdl.handle.net/1721.1/54765. Mark A. Finlayson and Raquel Herv´as. 2010b. UCM/MIT indications, referring expressions, and coreference corpus (UMIREC Work product, MIT Computer ence and Artificial Intelligence Laboratory. http://hdl.handle.net/1721.1/54766. Mark A. Finlayson. 2008. Collecting semantics in wild: The Story Workbench. In of the AAAI Fall Symposium on Naturally-Inspired Arpages 46–53, Menlo Park, CA, USA. AAAI Press. Albert Gatt, Anja Belz, and Eric Kow. 2009. The TUNA-REG challenge 2009: overview and evaluresults. In ’09: Proceedings of the 12th European Workshop on Natural Language Generapages 174–182, Morristown, NJ, USA. Association for Computational Linguistics. Pamela W. Jordan. 2000a. Can nominal expressions multiple goals?: an empirical study. In ’00: Proceedings of the 38th Annual Meeting on Asfor Computational pages 142– 149, Morristown, NJ, USA. Association for Computational Linguistics. Pamela W. Jordan. 2000b. Influences on attribute sein redescriptions: A corpus study. In Proof pages 250–255. Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annocorpus of english: the penn treebank. Compu- 19(2):313–330. Michael O’Donnell, Hua Cheng, and Janet Hitzeman. 1998. Integrating referring and informing in planning. In of COLING-ACL’98 Workshop on the Computational Treatment of Nompages 46–56. Massimo Poesio. 2004. Discourse annotation and semantic annotation in the GNOME corpus. In DiscAnnotation ’04: Proceedings of the 2004 ACL on Discourse pages 72–79, Morristown, NJ, USA. Association for Computational Linguistics. Ehud Reiter and Robert Dale. 1992. A fast algorithm the generation of referring expressions. In Proceedings of the 14th conference on Computational Nantes, France. Reiter and Robert Dale. 2000. Natural Generation Cambridge University Press. Kees van Deemter, Ielka van der Sluis, and Albert Gatt. 2006. Building a semantically transparent corpus the generation of referring expressions. In Proceedings of the 4th International Conference on Natural Language Generation (Special Session on Data and Evaluation), Jette Viethen and Robert Dale. 2008. The use of sparelations in referring expressions. In Proceedings of the 5th International Conference on Natural 54</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alaukik Aggarwal</author>
<author>Pablo Gerv´as</author>
<author>Raquel Herv´as</author>
</authors>
<title>Measuring the influence of errors induced by the presence of dialogues in reference clustering of narrative text.</title>
<date>2009</date>
<booktitle>In Proceedings of ICON-2009: 7th International Conference on Natural Language Processing,</booktitle>
<publisher>India. Macmillan Publishers.</publisher>
<marker>Aggarwal, Gerv´as, Herv´as, 2009</marker>
<rawString>Alaukik Aggarwal, Pablo Gerv´as, and Raquel Herv´as. 2009. Measuring the influence of errors induced by the presence of dialogues in reference clustering of narrative text. In Proceedings of ICON-2009: 7th International Conference on Natural Language Processing, India. Macmillan Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning English referring expressions.</title>
<date>1985</date>
<journal>Artificial Intelligence,</journal>
<pages>26--1</pages>
<contexts>
<context position="1513" citStr="Appelt (1985)" startWordPosition="211" endWordPosition="212">efficient, well-written text. We present a corpus analysis in which approximately one-fifth of 7,207 referring expressions in 24,422 words of news and narrative are descriptive. These data show that if we are ever to fully master natural language generation, especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions. 1 A Distinctive Focus Generating referring expressions is a key step in Natural Language Generation (NLG). From early treatments in seminal papers by Appelt (1985) and Reiter and Dale (1992) to the recent set of Referring Expression Generation (REG) Challenges (Gatt et al., 2009) through different corpora available for the community (Eugenio et al., 1998; van Deemter et al., 2006; Viethen and Dale, 2008), generating referring expressions has become one of the most studied areas of NLG. Researchers studying this area have, almost without exception, focused exclusively on how to generate distinctive referring expressions, that is, referring expressions that unambiguously identify their intended referent. Referring expressions, however, may be more than di</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Douglas E. Appelt. 1985. Planning English referring expressions. Artificial Intelligence, 26:1–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Cheng</author>
<author>Chris Mellish</author>
</authors>
<title>Capturing the interaction between aggregation and text planning in two generation systems.</title>
<date>2000</date>
<booktitle>In INLG ’00: First international conference on Natural Language Generation</booktitle>
<pages>186--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16174" citStr="Cheng and Mellish, 2000" startWordPosition="2548" endWordPosition="2551">ifier of the reference to the princess, making the second text more natural and fluent. This kind of aggregation is widely used by humans for making the discourse more compact and efficient. In order to create NLG systems with this ability, we must take into account the caveat, noted by Cheng (1998), that any non-distinctive information in a referring expression must not lead to confusion about the distinctive function of the referring expression. This is by no means a trivial problem – this sort of aggregation interferes with referring and coherence planning at both a local and global level (Cheng and Mellish, 2000; Cheng et al., 2001). It is clear, from the current state of the art of NLG, that we have not yet obtained a deep enough understanding of aggregation to enable us to handle these interactions. More research on the topic is needed. Two previous corpus studies have looked at the use of descriptive referring expressions. The first showed explicitly that people craft descriptive referring expressions to accomplish different 52 goals. Jordan and colleagues (Jordan, 2000b; Jordan, 2000a) examined the use of referring expressions using the COCONUT corpus (Eugenio et al., 1998). They tested how domai</context>
</contexts>
<marker>Cheng, Mellish, 2000</marker>
<rawString>Hua Cheng and Chris Mellish. 2000. Capturing the interaction between aggregation and text planning in two generation systems. In INLG ’00: First international conference on Natural Language Generation 2000, pages 186–193, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Cheng</author>
<author>Massimo Poesio</author>
<author>Renate Henschel</author>
<author>Chris Mellish</author>
</authors>
<title>Corpus-based np modifier generation.</title>
<date>2001</date>
<booktitle>In NAACL ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6250" citStr="Cheng et al. (2001)" startWordPosition="955" endWordPosition="958">ssions to generics (e.g., “Lions are fierce”), dates, times, and numbers, as well as events if they were referred to using a noun phrase. We included in each referring expression all the determiners, quantifiers, adjectives, appositives, and prepositional phrases that syntactically attached to that expression. When referring expressions were nested, all the nested referring expressions were also marked separately. Nuclei vs. Modifiers In the only previous corpus study of descriptive referring expressions, on 1With the exception of a small amount of work, discussed in Section 4. museum labels, Cheng et al. (2001) noted that descriptive information is often integrated into referring expressions using modifiers to the head noun. To study this, and to allow our results to be more closely compared with Cheng’s, we had our annotators split referring expressions into their constituents, portions called either nuclei or modifiers. The nuclei were the portions of the referring expression that performed the ‘core’ referring function; the modifiers were those portions that could be varied, syntactically speaking, independently of the nuclei. Annotators then assigned a distinctive or descriptive function to each</context>
<context position="14931" citStr="Cheng et al. (2001)" startWordPosition="2340" endWordPosition="2343"> referring expressions. Although Cheng did not examine nuclei, our results show that the use of descriptive nuclei is small but not negligible. 4 Relation to the Field Researchers working on generating referring expressions typically acknowledge that referring expressions can perform functions other than distinction. Despite this widespread acknowledgment, researchers have, for the most part, explicitly ignored these functions. Exceptions to this trend are three. First is the general study of aggregation in the process of referring expression generation. Second and third are corpus studies by Cheng et al. (2001) and Jordan (2000a) that bear on the prevalence of descriptive referring expressions. The NLG subtask of aggregation can be used to imbue referring expressions with a descriptive function (Reiter and Dale, 2000, §5.3). There is a specific kind of aggregation called embedding that moves information from one clause to another inside the structure of a separate noun phrase. This type of aggregation can be used to transform two sentences such as “The princess lived in a castle. She was pretty” into “The pretty princess lived in a castle”. The adjective pretty, previously a copular predicate, becom</context>
<context position="16195" citStr="Cheng et al., 2001" startWordPosition="2552" endWordPosition="2555"> the princess, making the second text more natural and fluent. This kind of aggregation is widely used by humans for making the discourse more compact and efficient. In order to create NLG systems with this ability, we must take into account the caveat, noted by Cheng (1998), that any non-distinctive information in a referring expression must not lead to confusion about the distinctive function of the referring expression. This is by no means a trivial problem – this sort of aggregation interferes with referring and coherence planning at both a local and global level (Cheng and Mellish, 2000; Cheng et al., 2001). It is clear, from the current state of the art of NLG, that we have not yet obtained a deep enough understanding of aggregation to enable us to handle these interactions. More research on the topic is needed. Two previous corpus studies have looked at the use of descriptive referring expressions. The first showed explicitly that people craft descriptive referring expressions to accomplish different 52 goals. Jordan and colleagues (Jordan, 2000b; Jordan, 2000a) examined the use of referring expressions using the COCONUT corpus (Eugenio et al., 1998). They tested how domain and discourse goals</context>
</contexts>
<marker>Cheng, Poesio, Henschel, Mellish, 2001</marker>
<rawString>Hua Cheng, Massimo Poesio, Renate Henschel, and Chris Mellish. 2001. Corpus-based np modifier generation. In NAACL ’01: Second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies 2001, pages 1–8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Cheng</author>
</authors>
<title>Embedding new information into referring expressions. In</title>
<date>1998</date>
<booktitle>ACL-36: Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>1478--1480</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="15851" citStr="Cheng (1998)" startWordPosition="2497" endWordPosition="2498">clause to another inside the structure of a separate noun phrase. This type of aggregation can be used to transform two sentences such as “The princess lived in a castle. She was pretty” into “The pretty princess lived in a castle”. The adjective pretty, previously a copular predicate, becomes a descriptive modifier of the reference to the princess, making the second text more natural and fluent. This kind of aggregation is widely used by humans for making the discourse more compact and efficient. In order to create NLG systems with this ability, we must take into account the caveat, noted by Cheng (1998), that any non-distinctive information in a referring expression must not lead to confusion about the distinctive function of the referring expression. This is by no means a trivial problem – this sort of aggregation interferes with referring and coherence planning at both a local and global level (Cheng and Mellish, 2000; Cheng et al., 2001). It is clear, from the current state of the art of NLG, that we have not yet obtained a deep enough understanding of aggregation to enable us to handle these interactions. More research on the topic is needed. Two previous corpus studies have looked at th</context>
</contexts>
<marker>Cheng, 1998</marker>
<rawString>Hua Cheng. 1998. Embedding new information into referring expressions. In ACL-36: Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 1478– 1480, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Johanna D Moore</author>
<author>Pamela W Jordan</author>
<author>Richmond H Thomason</author>
</authors>
<title>An empirical investigation of proposals in collaborative dialogues.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational linguistics,</booktitle>
<pages>325--329</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker>Di Eugenio, Moore, Jordan, Thomason, 1998</marker>
<rawString>Barbara Di Eugenio, Johanna D. Moore, Pamela W. Jordan, and Richmond H. Thomason. 1998. An empirical investigation of proposals in collaborative dialogues. In Proceedings of the 17th international conference on Computational linguistics, pages 325–329, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Finlayson</author>
<author>Raquel Herv´as</author>
</authors>
<title>Annotation guide for the UCM/MIT indications, referring expressions, and coreference corpus (UMIREC corpus).</title>
<date>2010</date>
<tech>Technical Report MIT-CSAIL-TR-2010-025,</tech>
<institution>MIT Computer Science and Artificial Intelligence Laboratory.</institution>
<note>http://hdl.handle.net/1721.1/54765.</note>
<marker>Finlayson, Herv´as, 2010</marker>
<rawString>Mark A. Finlayson and Raquel Herv´as. 2010a. Annotation guide for the UCM/MIT indications, referring expressions, and coreference corpus (UMIREC corpus). Technical Report MIT-CSAIL-TR-2010-025, MIT Computer Science and Artificial Intelligence Laboratory. http://hdl.handle.net/1721.1/54765.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Finlayson</author>
<author>Raquel Herv´as</author>
</authors>
<title>UCM/MIT indications, referring expressions, and coreference corpus</title>
<date>2010</date>
<booktitle>(UMIREC corpus). Work product, MIT Computer Science and Artificial Intelligence Laboratory. http://hdl.handle.net/1721.1/54766.</booktitle>
<marker>Finlayson, Herv´as, 2010</marker>
<rawString>Mark A. Finlayson and Raquel Herv´as. 2010b. UCM/MIT indications, referring expressions, and coreference corpus (UMIREC corpus). Work product, MIT Computer Science and Artificial Intelligence Laboratory. http://hdl.handle.net/1721.1/54766.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Finlayson</author>
</authors>
<title>Collecting semantics in the wild: The Story Workbench.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI Fall Symposium on Naturally-Inspired Artificial Intelligence,</booktitle>
<pages>46--53</pages>
<publisher>AAAI Press.</publisher>
<location>Menlo Park, CA, USA.</location>
<contexts>
<context position="10445" citStr="Finlayson, 2008" startWordPosition="1635" endWordPosition="1637">erent sizes, totaling 12,050 words. These texts were used in a previous work on the influence of dialogues on anaphora resolution algorithms (Aggarwal et al., 2009); they were assembled with an eye toward including different styles, different authors, and different time periods. Following this, we matched, approximately, the number of words in the folktales by selecting 32 texts from Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). These texts were selected at random from the first 200 texts in the corpus. 2.3 The Story Workbench We used the Story Workbench application (Finlayson, 2008) to actually perform the annotation. The Story Workbench is a semantic annotation program that, among other things, includes the ability to annotate referring expressions and coreferential relationships. We added the ability to annotate nuclei, modifiers, and their functions by writing a workbench “plugin” in Java that could be installed in the application. The Story Workbench is not yet available to the public at large, being in a limited distribution beta testing phase. The developers plan to release it as free software within the next year. At that time, we also plan to release our plugin a</context>
</contexts>
<marker>Finlayson, 2008</marker>
<rawString>Mark A. Finlayson. 2008. Collecting semantics in the wild: The Story Workbench. In Proceedings of the AAAI Fall Symposium on Naturally-Inspired Artificial Intelligence, pages 46–53, Menlo Park, CA, USA. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert Gatt</author>
<author>Anja Belz</author>
<author>Eric Kow</author>
</authors>
<title>The TUNA-REG challenge 2009: overview and evaluation results.</title>
<date>2009</date>
<booktitle>In ENLG ’09: Proceedings of the 12th</booktitle>
<contexts>
<context position="1630" citStr="Gatt et al., 2009" startWordPosition="229" endWordPosition="232">xpressions in 24,422 words of news and narrative are descriptive. These data show that if we are ever to fully master natural language generation, especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions. 1 A Distinctive Focus Generating referring expressions is a key step in Natural Language Generation (NLG). From early treatments in seminal papers by Appelt (1985) and Reiter and Dale (1992) to the recent set of Referring Expression Generation (REG) Challenges (Gatt et al., 2009) through different corpora available for the community (Eugenio et al., 1998; van Deemter et al., 2006; Viethen and Dale, 2008), generating referring expressions has become one of the most studied areas of NLG. Researchers studying this area have, almost without exception, focused exclusively on how to generate distinctive referring expressions, that is, referring expressions that unambiguously identify their intended referent. Referring expressions, however, may be more than distinctive. It is widely acknowledged that they can be used to achieve multiple goals, above and beyond distinction. H</context>
</contexts>
<marker>Gatt, Belz, Kow, 2009</marker>
<rawString>Albert Gatt, Anja Belz, and Eric Kow. 2009. The TUNA-REG challenge 2009: overview and evaluation results. In ENLG ’09: Proceedings of the 12th</rawString>
</citation>
<citation valid="false">
<booktitle>European Workshop on Natural Language Generation,</booktitle>
<pages>174--182</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<marker></marker>
<rawString>European Workshop on Natural Language Generation, pages 174–182, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
</authors>
<title>Can nominal expressions achieve multiple goals?: an empirical study.</title>
<date>2000</date>
<booktitle>In ACL ’00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>142--149</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="14948" citStr="Jordan (2000" startWordPosition="2345" endWordPosition="2346">Although Cheng did not examine nuclei, our results show that the use of descriptive nuclei is small but not negligible. 4 Relation to the Field Researchers working on generating referring expressions typically acknowledge that referring expressions can perform functions other than distinction. Despite this widespread acknowledgment, researchers have, for the most part, explicitly ignored these functions. Exceptions to this trend are three. First is the general study of aggregation in the process of referring expression generation. Second and third are corpus studies by Cheng et al. (2001) and Jordan (2000a) that bear on the prevalence of descriptive referring expressions. The NLG subtask of aggregation can be used to imbue referring expressions with a descriptive function (Reiter and Dale, 2000, §5.3). There is a specific kind of aggregation called embedding that moves information from one clause to another inside the structure of a separate noun phrase. This type of aggregation can be used to transform two sentences such as “The princess lived in a castle. She was pretty” into “The pretty princess lived in a castle”. The adjective pretty, previously a copular predicate, becomes a descriptive </context>
<context position="16644" citStr="Jordan, 2000" startWordPosition="2626" endWordPosition="2627"> problem – this sort of aggregation interferes with referring and coherence planning at both a local and global level (Cheng and Mellish, 2000; Cheng et al., 2001). It is clear, from the current state of the art of NLG, that we have not yet obtained a deep enough understanding of aggregation to enable us to handle these interactions. More research on the topic is needed. Two previous corpus studies have looked at the use of descriptive referring expressions. The first showed explicitly that people craft descriptive referring expressions to accomplish different 52 goals. Jordan and colleagues (Jordan, 2000b; Jordan, 2000a) examined the use of referring expressions using the COCONUT corpus (Eugenio et al., 1998). They tested how domain and discourse goals can influence the content of non-pronominal referring expressions in a dialogue context, checking whether or not a subject’s goals led them to include non-referring information in a referring expression. Their results are intriguing because they point toward heretofore unexamined constraints, utilities and expectations (possibly genre- or styledependent) that may underlie the use of descriptive information to perform different functions, and ar</context>
</contexts>
<marker>Jordan, 2000</marker>
<rawString>Pamela W. Jordan. 2000a. Can nominal expressions achieve multiple goals?: an empirical study. In ACL ’00: Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages 142– 149, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pamela W Jordan</author>
</authors>
<title>Influences on attribute selection in redescriptions: A corpus study.</title>
<date>2000</date>
<booktitle>In Proceedings of CogSci2000,</booktitle>
<pages>250--255</pages>
<contexts>
<context position="14948" citStr="Jordan (2000" startWordPosition="2345" endWordPosition="2346">Although Cheng did not examine nuclei, our results show that the use of descriptive nuclei is small but not negligible. 4 Relation to the Field Researchers working on generating referring expressions typically acknowledge that referring expressions can perform functions other than distinction. Despite this widespread acknowledgment, researchers have, for the most part, explicitly ignored these functions. Exceptions to this trend are three. First is the general study of aggregation in the process of referring expression generation. Second and third are corpus studies by Cheng et al. (2001) and Jordan (2000a) that bear on the prevalence of descriptive referring expressions. The NLG subtask of aggregation can be used to imbue referring expressions with a descriptive function (Reiter and Dale, 2000, §5.3). There is a specific kind of aggregation called embedding that moves information from one clause to another inside the structure of a separate noun phrase. This type of aggregation can be used to transform two sentences such as “The princess lived in a castle. She was pretty” into “The pretty princess lived in a castle”. The adjective pretty, previously a copular predicate, becomes a descriptive </context>
<context position="16644" citStr="Jordan, 2000" startWordPosition="2626" endWordPosition="2627"> problem – this sort of aggregation interferes with referring and coherence planning at both a local and global level (Cheng and Mellish, 2000; Cheng et al., 2001). It is clear, from the current state of the art of NLG, that we have not yet obtained a deep enough understanding of aggregation to enable us to handle these interactions. More research on the topic is needed. Two previous corpus studies have looked at the use of descriptive referring expressions. The first showed explicitly that people craft descriptive referring expressions to accomplish different 52 goals. Jordan and colleagues (Jordan, 2000b; Jordan, 2000a) examined the use of referring expressions using the COCONUT corpus (Eugenio et al., 1998). They tested how domain and discourse goals can influence the content of non-pronominal referring expressions in a dialogue context, checking whether or not a subject’s goals led them to include non-referring information in a referring expression. Their results are intriguing because they point toward heretofore unexamined constraints, utilities and expectations (possibly genre- or styledependent) that may underlie the use of descriptive information to perform different functions, and ar</context>
</contexts>
<marker>Jordan, 2000</marker>
<rawString>Pamela W. Jordan. 2000b. Influences on attribute selection in redescriptions: A corpus study. In Proceedings of CogSci2000, pages 250–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of english: the penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="10286" citStr="Marcus et al., 1993" startWordPosition="1605" endWordPosition="1609"> Text Selection Our corpus comprised 62 texts, all originally written in English, from two different genres, news and folktales. We began with 30 folktales of different sizes, totaling 12,050 words. These texts were used in a previous work on the influence of dialogues on anaphora resolution algorithms (Aggarwal et al., 2009); they were assembled with an eye toward including different styles, different authors, and different time periods. Following this, we matched, approximately, the number of words in the folktales by selecting 32 texts from Wall Street Journal section of the Penn Treebank (Marcus et al., 1993). These texts were selected at random from the first 200 texts in the corpus. 2.3 The Story Workbench We used the Story Workbench application (Finlayson, 2008) to actually perform the annotation. The Story Workbench is a semantic annotation program that, among other things, includes the ability to annotate referring expressions and coreferential relationships. We added the ability to annotate nuclei, modifiers, and their functions by writing a workbench “plugin” in Java that could be installed in the application. The Story Workbench is not yet available to the public at large, being in a limit</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P. Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of english: the penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael O’Donnell</author>
<author>Hua Cheng</author>
<author>Janet Hitzeman</author>
</authors>
<title>Integrating referring and informing in NP planning.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL’98 Workshop on the Computational Treatment of Nominals,</booktitle>
<pages>46--56</pages>
<marker>O’Donnell, Cheng, Hitzeman, 1998</marker>
<rawString>Michael O’Donnell, Hua Cheng, and Janet Hitzeman. 1998. Integrating referring and informing in NP planning. In Proceedings of COLING-ACL’98 Workshop on the Computational Treatment of Nominals, pages 46–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
</authors>
<title>Discourse annotation and semantic annotation in the GNOME corpus.</title>
<date>2004</date>
<booktitle>In DiscAnnotation ’04: Proceedings of the 2004 ACL Workshop on Discourse Annotation,</booktitle>
<pages>72--79</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="17481" citStr="Poesio, 2004" startWordPosition="2756" endWordPosition="2757">ialogue context, checking whether or not a subject’s goals led them to include non-referring information in a referring expression. Their results are intriguing because they point toward heretofore unexamined constraints, utilities and expectations (possibly genre- or styledependent) that may underlie the use of descriptive information to perform different functions, and are not yet captured by aggregation modules in particular or NLG systems in general. In the other corpus study, which partially inspired this work, Cheng and colleagues analyzed a set of museum descriptions, the GNOME corpus (Poesio, 2004), for the pragmatic functions of referring expressions. They had three functions in their study, in contrast to our two. Their first function (marked by their uniq tag) was equivalent to our distinctive function. The other two were specializations of our descriptive tag, where they differentiated between additional information that helped to understand the text (int), or additional information not necessary for understanding (attr). Despite their annotators seeming to have trouble distinguishing between the latter two tags, they did achieve good overall inter-annotator agreement. They identifi</context>
</contexts>
<marker>Poesio, 2004</marker>
<rawString>Massimo Poesio. 2004. Discourse annotation and semantic annotation in the GNOME corpus. In DiscAnnotation ’04: Proceedings of the 2004 ACL Workshop on Discourse Annotation, pages 72–79, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>A fast algorithm for the generation of referring expressions.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational linguistics,</booktitle>
<location>Nantes, France.</location>
<contexts>
<context position="1540" citStr="Reiter and Dale (1992)" startWordPosition="214" endWordPosition="217">itten text. We present a corpus analysis in which approximately one-fifth of 7,207 referring expressions in 24,422 words of news and narrative are descriptive. These data show that if we are ever to fully master natural language generation, especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions. 1 A Distinctive Focus Generating referring expressions is a key step in Natural Language Generation (NLG). From early treatments in seminal papers by Appelt (1985) and Reiter and Dale (1992) to the recent set of Referring Expression Generation (REG) Challenges (Gatt et al., 2009) through different corpora available for the community (Eugenio et al., 1998; van Deemter et al., 2006; Viethen and Dale, 2008), generating referring expressions has become one of the most studied areas of NLG. Researchers studying this area have, almost without exception, focused exclusively on how to generate distinctive referring expressions, that is, referring expressions that unambiguously identify their intended referent. Referring expressions, however, may be more than distinctive. It is widely ack</context>
</contexts>
<marker>Reiter, Dale, 1992</marker>
<rawString>Ehud Reiter and Robert Dale. 1992. A fast algorithm for the generation of referring expressions. In Proceedings of the 14th conference on Computational linguistics, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="15141" citStr="Reiter and Dale, 2000" startWordPosition="2373" endWordPosition="2376">ing expressions typically acknowledge that referring expressions can perform functions other than distinction. Despite this widespread acknowledgment, researchers have, for the most part, explicitly ignored these functions. Exceptions to this trend are three. First is the general study of aggregation in the process of referring expression generation. Second and third are corpus studies by Cheng et al. (2001) and Jordan (2000a) that bear on the prevalence of descriptive referring expressions. The NLG subtask of aggregation can be used to imbue referring expressions with a descriptive function (Reiter and Dale, 2000, §5.3). There is a specific kind of aggregation called embedding that moves information from one clause to another inside the structure of a separate noun phrase. This type of aggregation can be used to transform two sentences such as “The princess lived in a castle. She was pretty” into “The pretty princess lived in a castle”. The adjective pretty, previously a copular predicate, becomes a descriptive modifier of the reference to the princess, making the second text more natural and fluent. This kind of aggregation is widely used by humans for making the discourse more compact and efficient.</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>Ehud Reiter and Robert Dale. 2000. Building Natural Language Generation Systems. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kees van Deemter</author>
<author>Ielka van der Sluis</author>
<author>Albert Gatt</author>
</authors>
<title>Building a semantically transparent corpus for the generation of referring expressions.</title>
<date>2006</date>
<booktitle>In Proceedings of the 4th International Conference on Natural Language Generation (Special Session on Data Sharing and Evaluation), INLG-06.</booktitle>
<marker>van Deemter, van der Sluis, Gatt, 2006</marker>
<rawString>Kees van Deemter, Ielka van der Sluis, and Albert Gatt. 2006. Building a semantically transparent corpus for the generation of referring expressions. In Proceedings of the 4th International Conference on Natural Language Generation (Special Session on Data Sharing and Evaluation), INLG-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jette Viethen</author>
<author>Robert Dale</author>
</authors>
<title>The use of spatial relations in referring expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the 5th International Conference on Natural Language Generation.</booktitle>
<contexts>
<context position="1757" citStr="Viethen and Dale, 2008" startWordPosition="249" endWordPosition="252">ral language generation, especially for the genres of news and narrative, researchers will need to devote more attention to understanding how to generate descriptive, and not just distinctive, referring expressions. 1 A Distinctive Focus Generating referring expressions is a key step in Natural Language Generation (NLG). From early treatments in seminal papers by Appelt (1985) and Reiter and Dale (1992) to the recent set of Referring Expression Generation (REG) Challenges (Gatt et al., 2009) through different corpora available for the community (Eugenio et al., 1998; van Deemter et al., 2006; Viethen and Dale, 2008), generating referring expressions has become one of the most studied areas of NLG. Researchers studying this area have, almost without exception, focused exclusively on how to generate distinctive referring expressions, that is, referring expressions that unambiguously identify their intended referent. Referring expressions, however, may be more than distinctive. It is widely acknowledged that they can be used to achieve multiple goals, above and beyond distinction. Here we focus on descriptive referring expressions, that is, referring expressions that are not only distinctive, but provide ad</context>
</contexts>
<marker>Viethen, Dale, 2008</marker>
<rawString>Jette Viethen and Robert Dale. 2008. The use of spatial relations in referring expressions. In Proceedings of the 5th International Conference on Natural Language Generation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>