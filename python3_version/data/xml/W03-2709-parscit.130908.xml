<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001315">
<title confidence="0.996753">
Multi-Level Architectures for Natural Activity-Oriented Dialogue
</title>
<author confidence="0.997956">
Oliver Lemon
</author>
<affiliation confidence="0.998682">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.8452925">
2 Buccleugh Place
Edinburgh, EH8 9LW, UK
</address>
<email confidence="0.997897">
olemon@inf.ed.ac.uk
</email>
<author confidence="0.819325">
Lawrence Cavedon
</author>
<affiliation confidence="0.8242055">
Center for the Study of Language and Information
Stanford University
</affiliation>
<address confidence="0.8734675">
210 Panama Street
Stanford, CA 94306, USA
</address>
<email confidence="0.998985">
lcavedon@csli.stanford.edu
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999900222222222">
We argue for the development of dis-
tinct high and low levels of process-
ing in dialogue management. An archi-
tecture is described, which cleanly sep-
arates high-level communicative pro-
cesses (e.g. semantic and pragmatic in-
terpretation, content planning), from
low-level interaction processes which
maintain the communication channel
with the user (e.g. feedback, ground-
ing, turn-management). These lev-
els operate asychronously and semi-
independently. We present four exam-
ples of processes at the interaction-level
in an implemented dialogue system:
&amp;quot;Helper&amp;quot; feedback, turn-management,
incremental aggregation, and generation
of NPs.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998354">
Real dialogues between humans involve utter-
ances and gestures whose main purpose is to ma-
nipulate and maintain the communication chan-
nel, e.g. grounding, turn-taking, signalling mis-
understading, requesting repetition, requesting
pause, direction, space-filling, feedback. Seeing
dialogue as a joint activity (Clark, 1996), partic-
ularly when participants are engaged in collab-
orative tasks, highlights the importance of these
adaptive &amp;quot;low-level&amp;quot; processes of channel man-
agement. Dialogue participants often also &amp;quot;align&amp;quot;
with each others&apos; vocabulary, syntax, and commu-
nication styles. On the other hand, dialogue also
involves simultaneous high-level processes such
as utterance planning and interpretation, which in-
teract with the low-level processes, and vice versa.
For such reasons, we argue that it is appro-
priate to view dialogue management similarly to
the multi-level architectures for goal-oriented au-
tonomous agents, e.g. (Firby, 1994; Muller, 1996):
</bodyText>
<listItem confidence="0.921123555555555">
• a planning and activity-focused layer man-
ages the bulk of the communication aris-
ing from the negotiation and performance of
tasks or activities (e.g. interpreting new com-
mands, requesting clarification, reporting on
task status, dialogue structure, utterance con-
tent planning);
• an &amp;quot;interaction&amp;quot; management layer uses typi-
cally &amp;quot;shallow&amp;quot; NL processing techniques to
</listItem>
<bodyText confidence="0.918331466666667">
maintain the communication channel and re-
spond to any issues that may arise (e.g. man-
aging turn-taking, acknowledging communi-
cations quickly, using alternative processing
for handling unrecognized utterances, surface
realization of utterance content).
As with the agent-architectures, the two lev-
els of processing cannot be entirely independent:
data-structures described below mediate commu-
nication between the components. In particu-
lar, the interaction level may need to notify the
activity-planning level if it notices the user behav-
ing in a manner that indicates a problem (e.g. a
previously undetected misunderstanding or lack of
a required grounding response).
</bodyText>
<page confidence="0.998589">
61
</page>
<bodyText confidence="0.999932392857143">
We argue that for a dialogue system to be ef-
ficient, to feel &amp;quot;natural&amp;quot; to a human user, and to
be satisfactorily robust, it must address the issue
of maintaining and mangaging the communication
channel with the user. Recently, several systems
have been built to manage activity-oriented dia-
logue between a human and intelligent devices,
e.g. (Allen et al., 1996; Lemon et al., 2002b) with
some degree of success. These systems have paid
limited attention to the need to maintain the com-
munication channel.
While a dialogue system clearly should not
overload the user with feedback, it must nonethe-
less keep the user engaged, and monitor their at-
tention, which will also help to focus on the ac-
tivity being discussed. Unfortunately, very lit-
tle work has been done in dialogue systems re-
search regarding low-level interactions in conver-
sation, and still less has been achieved with regard
to dialogue management architectures which re-
spect this distinction. Our aim is to argue that di-
alogue management architectures should embody
asychronous and encapsulated levels of processing
respecting these high and low levels of conversa-
tional interaction, and we present such an archi-
tecture.
The following low-level processing techniques
are currently implemented in our system:
</bodyText>
<listItem confidence="0.941293363636364">
• A back-up recognition pass, using statistical
processing to extend grammar-based cover-
age and provide immediate user &amp;quot;help&amp;quot; feed-
back for unrecognized utterances (Hockey et
al., 2003);
• Turn management — timing of system output
is governed by monitoring the speech channel
and prior dialogue move. If the system wants
to take the turn, it grabs it using only low-
level processing;
• Handling user barge-in — user speech inter-
rupts system output and automatically grabs
the turn;
• Immediate Grounding of recognized com-
mands (e.g. system says &amp;quot;OK&amp;quot; immediately
after recognizing the user: &amp;quot;fly to the tower&amp;quot;);
• NP selection — choosing anaphoric or salient
noun-phrases at the point of generation;
• Incremental aggregation of system-generated
utterances — appropriately condensing and
forming elliptical system output at the point
of generation.
</listItem>
<bodyText confidence="0.989598891891891">
The resulting system is able to participate in con-
versations such as the one illustrated in Figure 1.
Thus we have gone some way towards a multi-
level architecture for activity-oriented dialogue
systems, analogous to the multi-level architectures
for goal-oriented autonomous agents, e.g. (Firby,
1994; Muller, 1996). Such agent architectures
generally involve a higher, more abstract level at
which goals are represented and plans are defined
or constructed. A lower-level manages more direct
interaction with the environment, or monitors the
performance of long-running tasks. For example,
the goal-level may plan the route to move a robot
to a destination while the lower-level handles ob-
stacle avoidance and corrects for wheel slippage.
Below, we describe a number of techniques we
have used at such a &amp;quot;low&amp;quot; interaction level to en-
hance the user&apos;s dialogue experience, and the ways
that they interact with high-level dialogue process-
ing. We also suggest ways in which this strategy
could be enhanced to address further issues, for
instance using reactive planning and learning tech-
niques, e.g. (Shapiro et al., 2001).
2 Motivation for an Interaction Layer
Studies in linguistics and psychology provide ev-
idence for the claim that dialogue consists of two
parallel &amp;quot;channels&amp;quot; of interaction, and that partici-
pants attempt to co-ordinate and align these chan-
nel through conversation. For example:
&amp;quot;There is co-ordination of both content,
what the participants intend to do, and
process, the physical and mental sys-
tems they recruit in carrying out those
intentions.&amp;quot; (Clark, 1996), p. 59.
Human-human dialogue involves immediate
acknowledgement and grounding of utterances
(&amp;quot;yep&amp;quot; or &amp;quot;okay&amp;quot;), often in the middle of a
</bodyText>
<page confidence="0.999112">
62
</page>
<figureCaption confidence="0.999632">
Figure 1: Demonstration system, november 2002
</figureCaption>
<figure confidence="0.842795152173913">
Utterance
Operator (0): Fly around the school
Helper (H): I heard you say &amp;quot;Fly around the school&amp;quot; but the
system does not know the word &amp;quot;around&amp;quot;. You could say &amp;quot;fly
to the school&amp;quot;
0: Fly to the school
Robot (R): OK.
0: Then pick up the medical supplies at the hospital
R: OK. Wait a minute
R: lam supposed to always fly high
R: Shall I fly to the hospital at low altitude anyway?
0: Yes. Do it anyway
R: OK. Wait a minute
R: There is afire at the tower
R: lam flying to the hospital
0: Why?
R: Because I am picking up the medical sup
0: Stop that.
R: OK. I have cancelled flying there
0: Fight the .fire at the tower
R: OK. I am flying to the lake
0: Why are you doing that?
R: Because I am picking up water there.
Dialogue Move
Command
Helper feedback
Command
Confirmation
Take turn, Command
Confirmation, System grab turn
Report Global Constraint
Negotiate constraint relaxation, Re-
lease Turn
Yn-Answer
Confirmation, System grab turn
Report observation
Report Current Activity
Why-question, Release Turn
Why-Answer, User barge-in
Command (Barge-in)
Confirmation, Report Activity State,
Anaphoric NP
Command
Confirmation, Report Activity State
Why-question, Release Turn
Why-Answer, Anaphoric NP
</figure>
<bodyText confidence="0.999664529411765">
speaker&apos;s sentence (if that sentence contains mul-
tiple information items). Moreover, human di-
alogue participants often expect such behaviour
from their partner—the absence of such acknowl-
edgement often makes us pause to wait for it.1 A
dialogue system should exploit such natural pat-
terns of behaviour both when speaking – to assure
the human speaker that their utterances are being
understood, and when listening – to use such feed-
back, or lack of it, as early evidence of problems
requiring repair.
Other dialogue phenomena that must be ac-
counted for include managing turn-taking, as well
as handling participants speaking out of turn. The
dialogue system must react quickly to users inter-
rupting it and then decide whether to continue (e.g.
if the user seems to be simply acknowledging a
</bodyText>
<footnote confidence="0.543219666666667">
1For example, think of giving someone a phone number
and waiting for them to echo the first half of it before contin-
uing.
</footnote>
<bodyText confidence="0.99991845">
portion of the utterance), or whether to stop what
it is saying and revise its planned output.
In engineering terms, such a division of labour
is also attractive in that the clarity and modularity
of dialogue managment is enhanced. Rather than
conflating, for example, turn-management with ut-
terance planning in a single generation component
of a dialogue system, the separation into multiple
levels of processing allows different turn-taking
and utterance planning strategies to be developed
independently, and various combinations to be ex-
perimented with.
Allen et al. have also noted the importance of
accounting for such phenomena and have used it
as one of the motivations for the revised architec-
ture of their TRIPS system (Allen et al., 2001).
They separate dialogue management into a num-
ber of different asynchronous modules, and use
incremental interpretation and generation to en-
sure high reactivity to user activity. We believe
</bodyText>
<page confidence="0.997031">
63
</page>
<bodyText confidence="0.999956833333333">
that identifying the two streams of dialogue (i.e.
activity-oriented versus channel-maintenance) is
an important one, and that clean separation into the
separate layers allows use of shallow techniques
for fast response without need to access the con-
tent planning layer.
</bodyText>
<sectionHeader confidence="0.926666" genericHeader="introduction">
3 A Two-Level Architecture
</sectionHeader>
<bodyText confidence="0.982447285714286">
Figure 2 illustrates various aspects of the partic-
ular two-level architecture which we are develop-
ing. The lower level interfaces directly with the
user and, importantly, is driven by this interaction.
For example the low level includes a Turn Man-
ager which manipulates the speech channel to en-
sure that:
</bodyText>
<listItem confidence="0.993295625">
• user inputs are respected without interruption
(except when necessary),
• the turn passes to the appropriate partici-
pant, based on the preceding dialogue move
(passed in from the top level),
• generated outputs are natural and timely,
• recognized user inputs are acknowledged
quickly using simple feedback utterances.
</listItem>
<bodyText confidence="0.999989678571429">
The upper level is responsible for modeling
other aspects of the conversational context, as well
as communicative goals and intentions. The con-
tent (i.e. logical forms) of user utterances are pro-
cessed using the dialogue model (e.g. updates and
adding nodes to the Dialogue Move Tree (Lemon
et al., 2002b)), and system utterances are con-
structed which are in line with the system&apos;s com-
municative goals and intentions, whether they be
imparting information to the user or requesting
clarification or further information. This level also
interacts with the rest of the agent architecture,
mediated by an &amp;quot;Activity Model&amp;quot; (i.e. a represen-
tation of the agent activities about which dialogue
may occur (Gruenstein, 2002)). The agent may
wish to communicate about its goals, the progress
of its activities, or report on any observations it
makes regarding its environment.
As with multi-layered agent architectures, the
two levels operate semi-autonomously and asyn-
chronously: the lower level is driven by tight inter-
action with the user, while the upper level is driven
by longer-range communicative goals from its ac-
tivities and responses to user utterances. However,
various types of information exchange connect the
two levels. For instance, user utterances recog-
nized at the lower level must clearly be passed
to the content-management level to be parsed and
then incorporated into the dialogue context, while
high-level communication goals must be passed to
the lower level&apos;s &amp;quot;Output Agenda&amp;quot; for generation
and speech-synthesis.
Perhaps of more interest, the interaction level
can be used to monitor user engagement and at-
tention in other ways — e.g. time between utter-
ances, speaking rate, use of speech fillers — to
detect potential problems as soon as possible, and
to provide early warning to the content level that
the user may have, for example, misunderstood
some instruction. This can be used to generate a
clarification or grounding sub-dialogue, in order
to establish mutual understanding before proceed-
ing (thus improving robustness of the system as a
whole).
Conversely, expectations at the upper-layer can
influence processing at the interaction layer: for
example, open points of attachment on the Dia-
logue Move Tree represent types of utterances the
system expects from the user, and these are used
to bias the recognition of incoming utterances for
faster processing, as well as influencing the turn.
In the rest of the paper, we discuss our dia-
logue management architecture and, in particular,
the techniques employed at each of the two lev-
els described here to enhance user experience and
improve overall system performance.
</bodyText>
<sectionHeader confidence="0.99593" genericHeader="method">
4 Top-level context management
</sectionHeader>
<bodyText confidence="0.999719083333333">
The approach to dialogue modelling we have
implemented is based on the theory of &amp;quot;dia-
logue games&amp;quot; (Carlson, 1983; Power, 1979), and,
for task-oriented dialogues, &amp;quot;discourse segments&amp;quot;
(Grosz and Sidner, 1986). These accounts rely
on the observation that answers generally follow
questions, commands are usually acknowledged,
and so on, so that dialogues can be partially de-
scribed as consisting of &amp;quot;adjacency pairs&amp;quot; of such
dialogue moves. The notion of &amp;quot;attachment&amp;quot; of
dialogue moves on a Dialogue Move Tree (DMT)
(Lemon et al., 2002b) embodies this idea.
</bodyText>
<page confidence="0.99773">
64
</page>
<figureCaption confidence="0.994635">
Figure 2: System Architecture
</figureCaption>
<figure confidence="0.957890727272728">
Content layer:
- utterance planning
- communicative intentions
- grounding
- content management
- interaction with agent arch
Activity
Model
Conversation
Planner
Interaction layer
- timing
- form
- engagement
- acknowledgement
Backup
Shallow
Processor
(Helper)
Attention
Monitor
Speech
recogition
and
Parsing
Speech channel
Generation
Module
Generation:
- anaphora
- pronouns
- aggregation
- echoing
Agent
- intentions
- goals
- plans
- observations
K._
Context
Mgr
alogue
Move
Tree
</figure>
<bodyText confidence="0.9975815">
An &amp;quot;Activity Tree&amp;quot; represents hierarchical and
temporal information about the task-state of the
dialogue. Activities are the joint tasks managed
by the dialogue: e.g. booking a flight or moving
a robot—again, see (Lemon et al., 2002b) for de-
tails. Nodes on the Activity Tree can be in vari-
ous states (active, complete, failed, ...), and any
change in the state of a node (typically because
of an action by the agent) is placed onto the sys-
tem&apos;s Output Agenda for possible verbal report to
the user, via the low-level message selection and
generation module.
This level of the architecture is also where
conversation planning and generation of system-
initiated topics occurs. Any planned communi-
cation (whether it be in response to a user ut-
terance or system-initiated) is put on to the Out-
put Agenda, where it is scheduled for generation.2
Conversely, true grounding — i.e. acknowledging
that an utterance is understood within the context
of the rest of the dialogue — only occurs after the
utterance has been interpreted with respect to the
DMT. Since a simple acknowledgement may al-
ready have been generated after recognition, out-
put after interpretation is only needed if a response
is required (e.g. the user asked a question), or if a
problem is detected (e.g. an ambiguity must be re-
solved).
2The order in which outputs are generated, or even
whether they end up generated at all, depends on the priority
of the corresponding information as well other interactions
with the user.
Since system communication is planned here,
this layer is also the one that interacts with the rest
of the agent architecture: any goals, state-changes,
or observations that the agent may wish to commu-
nicate are added as communicative goals, typically
via the Activity Model.
</bodyText>
<sectionHeader confidence="0.764349666666667" genericHeader="method">
5 Low-level conversation management:
Maintaining the Communication
Channel
</sectionHeader>
<bodyText confidence="0.999972692307692">
We currently employ a range of shallow process-
ing techniques to maintain a smooth interaction
with the human dialogue participant. By &amp;quot;shal-
low processing&amp;quot; we mean processing that does not
necessarily result in or concern itself with the se-
mantic representation or pragmatic interpretation
of the utterance in the context of the dialogue.
In particular, information at this level is not pro-
cessed in the context of the Dialogue Move Tree
or the Activity Tree.
In the following, we describe a number of the
low-level processing techniques currently imple-
mented in our system.
</bodyText>
<subsectionHeader confidence="0.982782">
5.1 Case study 1: &amp;quot;Helper Feedback&amp;quot;
</subsectionHeader>
<bodyText confidence="0.999969333333333">
In cases where the user utterance is not recog-
nized, the input is passed to a statistical recog-
nizer of wider coverage. This recognizer is of-
ten able to detect lexical items and grammatical
structures in the input that are not covered by the
first (grammar-based) recognizer. In these cases,
</bodyText>
<page confidence="0.999126">
65
</page>
<bodyText confidence="0.999982714285714">
the results of the second recognition pass are used
to inform the user of the system&apos;s shortcomings,
for example: &amp;quot;The system heard you say &apos;Look
around for a red car&apos;, but the system does not know
the word &apos;around&apos;. You could say &apos;Look for a red
car&apos; &amp;quot;.
None of these utterances is planned or repre-
sented at the top level of dialogue management.
They are produced simply to inform the user of a
communication breakdown and to try to keep the
communication flowing. If the user were to in-
dulge in meta-dialogue about the help message,
then that message would need to be represented
in the high-level context. However, we present
the help message as being generated by a different
&amp;quot;helper&amp;quot; agent, which disappears (from the GUI)
as soon as the help message is produced, thus dis-
couraging the user from engaging it in dialogue.
User tests have shown that the use of this low
level module (which can be installed indepen-
dently of the high-level dialogue manager) signif-
icantly improves task completion (both percent-
age of tasks completed and time taken). By the
fifth task, 100% of users with the helper completed
the task as compared with 80% of those without,
and those without the helper took on average 53%
longer to complete the tasks. For full details of the
evaluation see (Hockey et al., 2003).
</bodyText>
<subsectionHeader confidence="0.966887">
5.2 Case study 2: &amp;quot;Turn Taking&amp;quot;
</subsectionHeader>
<bodyText confidence="0.998553684210526">
Here we use a turn-marker at the low-level of dia-
logue processing. The turn can be marked as user,
system or none, and is set in a variety of ways.
If the user begins to speak (start-of-speech signal
is received from the recognizer) the turn becomes
user and any system audio output is stopped. If
the system needs to take the turn, but it is set to
user, and the user is not speaking, the system will
output &amp;quot;Just a moment&amp;quot; and so take the turn be-
fore generating its required utterance. Again, note
that this turn-grabbing utterance is not planned or
represented at the top-level of dialogue moves. It
does not need to enter into such high-level plans or
representations because it is required only in order
to manipulate and maintain the channel, and does
not carry any content of its own.
The demonstration system displays a turn
marker on the GUI, allowing observers to watch
the changing possession of the turn.
</bodyText>
<subsectionHeader confidence="0.454775">
5.3 Case study 3: &amp;quot;Incremental aggregation&amp;quot;
</subsectionHeader>
<bodyText confidence="0.999630333333333">
Aggregation (Appelt, 1985) combines and com-
presses utterances to make them more concise,
avoid repetitious language structure, and make the
system&apos;s speech more natural and understandable
overall. In our system, this process is carried out
not at the level of content planning, but at the
lower-level of processing, where content logical
forms are manipulated (possibly combined) and
converted into strings for speech synthesis. In-
deed, it is important that aggregation functions at
this lower level, because the process needs access
to:
</bodyText>
<listItem confidence="0.999388">
• the message to be uttered (A),
• what has just been said (B),
• what is to be said next (C),
</listItem>
<bodyText confidence="0.999446035714286">
and the precise surface form of B is only repre-
sented at the low-level. High-level processing only
plans the content of the utterance to be generated,
and passes it down, and so cannot determine the
details of the eventual surface form of the gener-
ated utterance.
Aggregation techniques on a prewritten body of
text combine and compress sentences that have al-
ready been determined and ordered. In a complex
dialogue system however, aggregation should pro-
duce similarly natural output, but must function
incrementally because utterances are generated on
the fly. In fact, when constructing an utterance
we often have no information about the utterances
that will follow it, and thus the best we can do is
to compress it or &amp;quot;retro-aggregate&amp;quot; it with utter-
ances that preceded it (see the example below).
Only occasionally does the Output Agenda con-
tain enough unsaid utterances to perform reason-
able &amp;quot;pre-aggregation&amp;quot;.
At the low-level of processing, the generator re-
ceives an item (on the Output Agenda) to be con-
verted into synthesized speech. This item consists
of a dialogue move type along with some content
(e.g. wh—answer, location (tower ) ).
Each dialogue move type (e.g. report, wh-
question, wh-answer) has its own aggregation
rules, stored in the class for that logical form (LF)
</bodyText>
<page confidence="0.967375">
66
</page>
<bodyText confidence="0.999675541666667">
type. In each type, rules specify which other di-
alogue move types can aggregate with it, and ex-
actly how aggregation works. The rules note iden-
tical portions of LFs and unify them, and then
combine the non-identical portions appropriately.
For example, the LF that represents the phrase
&amp;quot;I will fly to the tower and I will land at the park-
ing lot&amp;quot;, will be converted to one representing &amp;quot;I
will fly to the tower and land at the parking lot&amp;quot;
according to the compression rules. Similarly, &amp;quot;I
will fly to the tower and fly to the hospital&amp;quot; gets
converted to &amp;quot;I will fly to the tower and the hospi-
tal&amp;quot;.
In contrast, the &amp;quot;retro-aggregation&amp;quot; rules result
in sequences of system utterances such as,
System: I have cancelled flying
to the base
System: and the tower
System: and landing at the
school
Again, this process happens only at the low-
level processing stage of content realization, and
needs no access to the high-level representations
of dialogue structure, history, and plans.
</bodyText>
<subsectionHeader confidence="0.95534">
5.4 Case study 4: &amp;quot;Choosing NPs&amp;quot;
</subsectionHeader>
<bodyText confidence="0.99996816">
Another low-level process in utterance realization
is choosing appropriate NPs — anaphoric expres-
sions such as &amp;quot;it&amp;quot; or &amp;quot;there&amp;quot;, or NPs which &amp;quot;echo&amp;quot;
those already used by the human operator. Again,
this routine does not need access to the high-level
dialogue management representations, but only to
the list of NPs employed in the dialogue thus far
(the &amp;quot;Salience List&amp;quot;).
Echoing is achieved by accessing the Salience
List whenever generating referential terms, and
using whatever noun-phrase (if any) the user has
previously employed to refer to the object in ques-
tion. Anaphoric phrases are generated whenever
the reference object is the same as the one at the
top of the Salience List.
As in the case of aggregation, the top level con-
tent generation algorithm does not manage the de-
tails of utterance realization — this is better handled
at the instant that the content logical form is to be
translated into a string for the speech synthesizer.
Otherwise the top level would have to replan utter-
ances after every intervening dialogue move. This
example shows how respecting the multi-level ar-
chitecture is desirable from an engineering point
of view.
</bodyText>
<sectionHeader confidence="0.995682" genericHeader="method">
6 Further Possibilities
</sectionHeader>
<bodyText confidence="0.999990758620689">
There are many other dialogue phenomena that
could be treated along these lines. For instance,
processes at the lower level could detect mis-
communication and channel breakdown, and send
a request to the top level to replan the long-
range dialogue strategy. This is particularly im-
portant in the genre of tutorial dialogue (Zinn et
al., 2002), where low-level processes could de-
tect problems with user attention and responsive-
ness, and prompt a switch to a different high-
level strategy. Particularly important for safety-
critical applications, but of general use, would be
low-level monitoring of channel noise and other
environmental factors such as user gestures and
gaze. Again, certain combinations of these inputs
would have high-level consequences for interpre-
tation and dialogue planning.
We are currently investigating using Icarus
(Shapiro et al., 2001), a reactive planning system
that learns and adapts to user behavior, for imple-
menting and integrating different low-level mod-
ules. We hope that this will allow, for instance,
turn-taking facilities to be more easily adapted as
personalities or situations require: for example, af-
ter noticing a particular event the system may be
more likely to interrupt a speaker, or may adapt to
become less prone to interruption when interact-
ing with a speaker who responds poorly to system
barge-in.
</bodyText>
<sectionHeader confidence="0.999091" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999995333333333">
We argue for the development of distinct high and
low levels of processing in dialogue management.
There are many aspects of dialogue management
which have to do with manipulating and main-
taining the communication channel, but do not
have any content that is relevant to the tasks be-
ing co-ordinated by the conversation. We advo-
cate separating these processes into modules in a
&amp;quot;low-level&amp;quot; of dialogue management, independent
of &amp;quot;high-level&amp;quot; semantic and pragmatic interpreta-
tion and utterance content planning, analogously
to the multi-level architectures used in robotics.
</bodyText>
<page confidence="0.997881">
67
</page>
<bodyText confidence="0.9996916">
We gave four examples of such asynchronous
and semi-autonomous low-level processes, cur-
rently implemented in a full working dialogue sys-
tem: Helper feedback; Turn-taking; Aggregation;
NP selection.
</bodyText>
<sectionHeader confidence="0.994709" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998942">
This research was partially supported by the Wal-
lenberg Foundation&apos;s WITAS project, Linkoping
University, Sweden, and by grant number
N00014-02-1-0417 from the Department of the
US Navy.
</bodyText>
<sectionHeader confidence="0.999239" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998709464285714">
James F. Allen, Bradford W. Miller, Eric K. Ringger,
and Teresa Sikorski. 1996. A robust system for nat-
ural spoken dialogue. In Proceedings of ACL.
James Allen, George Ferguson, and Amanda Stent.
2001. An architecture for more realistic conversa-
tional systems. In Proceedings of Intelligent User
Interfaces 2001, Santa Fe, NM.
Douglas E. Appelt. 1985. Planning english referring
expressions. Artificial Intelligence, 26(1):1 –33.
Lauri Carlson. 1983. Dialogue Games: An Approach
to Discourse Analysis. D. Reidel.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
James Firby. 1994. Task networks for controlling con-
tinuous processes. In Proceedings 2nd Int&apos;l Conf. on
Al Planning Systems, pages 49-54.
Barbara Grosz and Candace Sidner. 1986. Attentions,
intentions, and the structure of discourse. Computa-
tional Linguistics, 12(3):175-204.
Alexander H. Gruenstein. 2002. Conversational inter-
faces: A domain-independent architecture for task-
oriented dialogues. Master&apos;s thesis, Stanford.
Beth-Ann Hockey, Oliver Lemon, Ellen Campana,
Laura Hiatt, Gregory Aist, Jim Hieronymus,
Alexander Gruenstein, and John Dowding. 2003.
Targeted help for spoken dialogue systems: intelli-
gent feed back improves naive users&apos; performance.
In Proceedings of European Association for Com-
putational Linguistics (EACL 03), page (in press).
Oliver Lemon, Alexander Gruenstein, Alexis Battle,
and Stanley Peters. 2002a. Multi-tasking and col-
laborative activities in dialogue systems. In Pro-
ceedings of 3rd SIGdial Workshop on Discourse and
Dialogue, pages 113 – 124, Philadelphia.
Oliver Lemon, Alexander Gruenstein, and Stanley Pe-
ters. 2002b. Collaborative activities and multi-
tasking in dialogue systems. Traitement Automa-
tique des Langues (TAL), 43(2):131 – 154. Special
Issue on Dialogue.
J. P. Muller. 1996. The Design of Intelligent Agents—
A Layered Approach. Springer Verlag, Heidelberg,
Germany.
Richard Power. 1979. The organization of purposeful
dialogues. Linguistics, 17:107-152.
Dan Shapiro, Pat Langley, and Ross Shachter. 2001.
Using background knowledge to speed reinforce-
ment learning. In Fifth International Conference on
Autonomous Agents, pages 254 – 261. ACM Press.
Jan van Kuppevelt, Ulrich Heid, and Hans Kamp.
2000. Best practice in spoken language dialogue
system engineering. Natural Language Engineer-
ing, 6.
Claus Zinn, Johanna D. Moore, and Mark G. Core.
2002. A 3-tier planning architecture for managing
tutorial dialogue,. In Intelligent Tutoring Systems,
Sixth International Conference (ITS 2002).
</reference>
<page confidence="0.999412">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.452658">
<title confidence="0.998698">Multi-Level Architectures for Natural Activity-Oriented Dialogue</title>
<author confidence="0.97538">Oliver</author>
<affiliation confidence="0.982803666666667">School of University of 2 Buccleugh</affiliation>
<address confidence="0.911317">Edinburgh, EH8 9LW,</address>
<email confidence="0.997889">olemon@inf.ed.ac.uk</email>
<affiliation confidence="0.830328666666667">Lawrence Center for the Study of Language and Stanford</affiliation>
<address confidence="0.9986925">210 Panama Stanford, CA 94306,</address>
<email confidence="0.999815">lcavedon@csli.stanford.edu</email>
<abstract confidence="0.99749">We argue for the development of distinct high and low levels of processing in dialogue management. An architecture is described, which cleanly separates high-level communicative processes (e.g. semantic and pragmatic interpretation, content planning), from low-level interaction processes which maintain the communication channel the user (e.g. feedback, groundturn-management). These els operate asychronously and semiindependently. We present four examples of processes at the interaction-level in an implemented dialogue system: &amp;quot;Helper&amp;quot; feedback, turn-management, incremental aggregation, and generation of NPs.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Bradford W Miller</author>
<author>Eric K Ringger</author>
<author>Teresa Sikorski</author>
</authors>
<title>A robust system for natural spoken dialogue.</title>
<date>1996</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="3353" citStr="Allen et al., 1996" startWordPosition="473" endWordPosition="476">omponents. In particular, the interaction level may need to notify the activity-planning level if it notices the user behaving in a manner that indicates a problem (e.g. a previously undetected misunderstanding or lack of a required grounding response). 61 We argue that for a dialogue system to be efficient, to feel &amp;quot;natural&amp;quot; to a human user, and to be satisfactorily robust, it must address the issue of maintaining and mangaging the communication channel with the user. Recently, several systems have been built to manage activity-oriented dialogue between a human and intelligent devices, e.g. (Allen et al., 1996; Lemon et al., 2002b) with some degree of success. These systems have paid limited attention to the need to maintain the communication channel. While a dialogue system clearly should not overload the user with feedback, it must nonetheless keep the user engaged, and monitor their attention, which will also help to focus on the activity being discussed. Unfortunately, very little work has been done in dialogue systems research regarding low-level interactions in conversation, and still less has been achieved with regard to dialogue management architectures which respect this distinction. Our a</context>
</contexts>
<marker>Allen, Miller, Ringger, Sikorski, 1996</marker>
<rawString>James F. Allen, Bradford W. Miller, Eric K. Ringger, and Teresa Sikorski. 1996. A robust system for natural spoken dialogue. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>George Ferguson</author>
<author>Amanda Stent</author>
</authors>
<title>An architecture for more realistic conversational systems.</title>
<date>2001</date>
<booktitle>In Proceedings of Intelligent User Interfaces</booktitle>
<location>Santa Fe, NM.</location>
<contexts>
<context position="9735" citStr="Allen et al., 2001" startWordPosition="1495" endWordPosition="1498">on of labour is also attractive in that the clarity and modularity of dialogue managment is enhanced. Rather than conflating, for example, turn-management with utterance planning in a single generation component of a dialogue system, the separation into multiple levels of processing allows different turn-taking and utterance planning strategies to be developed independently, and various combinations to be experimented with. Allen et al. have also noted the importance of accounting for such phenomena and have used it as one of the motivations for the revised architecture of their TRIPS system (Allen et al., 2001). They separate dialogue management into a number of different asynchronous modules, and use incremental interpretation and generation to ensure high reactivity to user activity. We believe 63 that identifying the two streams of dialogue (i.e. activity-oriented versus channel-maintenance) is an important one, and that clean separation into the separate layers allows use of shallow techniques for fast response without need to access the content planning layer. 3 A Two-Level Architecture Figure 2 illustrates various aspects of the particular two-level architecture which we are developing. The lo</context>
</contexts>
<marker>Allen, Ferguson, Stent, 2001</marker>
<rawString>James Allen, George Ferguson, and Amanda Stent. 2001. An architecture for more realistic conversational systems. In Proceedings of Intelligent User Interfaces 2001, Santa Fe, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas E Appelt</author>
</authors>
<title>Planning english referring expressions.</title>
<date>1985</date>
<journal>Artificial Intelligence,</journal>
<volume>26</volume>
<issue>1</issue>
<pages>33</pages>
<contexts>
<context position="19658" citStr="Appelt, 1985" startWordPosition="3107" endWordPosition="3108">t speaking, the system will output &amp;quot;Just a moment&amp;quot; and so take the turn before generating its required utterance. Again, note that this turn-grabbing utterance is not planned or represented at the top-level of dialogue moves. It does not need to enter into such high-level plans or representations because it is required only in order to manipulate and maintain the channel, and does not carry any content of its own. The demonstration system displays a turn marker on the GUI, allowing observers to watch the changing possession of the turn. 5.3 Case study 3: &amp;quot;Incremental aggregation&amp;quot; Aggregation (Appelt, 1985) combines and compresses utterances to make them more concise, avoid repetitious language structure, and make the system&apos;s speech more natural and understandable overall. In our system, this process is carried out not at the level of content planning, but at the lower-level of processing, where content logical forms are manipulated (possibly combined) and converted into strings for speech synthesis. Indeed, it is important that aggregation functions at this lower level, because the process needs access to: • the message to be uttered (A), • what has just been said (B), • what is to be said nex</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>Douglas E. Appelt. 1985. Planning english referring expressions. Artificial Intelligence, 26(1):1 –33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Carlson</author>
</authors>
<title>Dialogue Games: An Approach to Discourse Analysis.</title>
<date>1983</date>
<journal>D. Reidel.</journal>
<contexts>
<context position="13638" citStr="Carlson, 1983" startWordPosition="2108" endWordPosition="2109">mple, open points of attachment on the Dialogue Move Tree represent types of utterances the system expects from the user, and these are used to bias the recognition of incoming utterances for faster processing, as well as influencing the turn. In the rest of the paper, we discuss our dialogue management architecture and, in particular, the techniques employed at each of the two levels described here to enhance user experience and improve overall system performance. 4 Top-level context management The approach to dialogue modelling we have implemented is based on the theory of &amp;quot;dialogue games&amp;quot; (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, &amp;quot;discourse segments&amp;quot; (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of &amp;quot;adjacency pairs&amp;quot; of such dialogue moves. The notion of &amp;quot;attachment&amp;quot; of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. 64 Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent ar</context>
</contexts>
<marker>Carlson, 1983</marker>
<rawString>Lauri Carlson. 1983. Dialogue Games: An Approach to Discourse Analysis. D. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1314" citStr="Clark, 1996" startWordPosition="174" endWordPosition="175">dback, grounding, turn-management). These levels operate asychronously and semiindependently. We present four examples of processes at the interaction-level in an implemented dialogue system: &amp;quot;Helper&amp;quot; feedback, turn-management, incremental aggregation, and generation of NPs. 1 Introduction Real dialogues between humans involve utterances and gestures whose main purpose is to manipulate and maintain the communication channel, e.g. grounding, turn-taking, signalling misunderstading, requesting repetition, requesting pause, direction, space-filling, feedback. Seeing dialogue as a joint activity (Clark, 1996), particularly when participants are engaged in collaborative tasks, highlights the importance of these adaptive &amp;quot;low-level&amp;quot; processes of channel management. Dialogue participants often also &amp;quot;align&amp;quot; with each others&apos; vocabulary, syntax, and communication styles. On the other hand, dialogue also involves simultaneous high-level processes such as utterance planning and interpretation, which interact with the low-level processes, and vice versa. For such reasons, we argue that it is appropriate to view dialogue management similarly to the multi-level architectures for goal-oriented autonomous age</context>
<context position="6690" citStr="Clark, 1996" startWordPosition="994" endWordPosition="995">h this strategy could be enhanced to address further issues, for instance using reactive planning and learning techniques, e.g. (Shapiro et al., 2001). 2 Motivation for an Interaction Layer Studies in linguistics and psychology provide evidence for the claim that dialogue consists of two parallel &amp;quot;channels&amp;quot; of interaction, and that participants attempt to co-ordinate and align these channel through conversation. For example: &amp;quot;There is co-ordination of both content, what the participants intend to do, and process, the physical and mental systems they recruit in carrying out those intentions.&amp;quot; (Clark, 1996), p. 59. Human-human dialogue involves immediate acknowledgement and grounding of utterances (&amp;quot;yep&amp;quot; or &amp;quot;okay&amp;quot;), often in the middle of a 62 Figure 1: Demonstration system, november 2002 Utterance Operator (0): Fly around the school Helper (H): I heard you say &amp;quot;Fly around the school&amp;quot; but the system does not know the word &amp;quot;around&amp;quot;. You could say &amp;quot;fly to the school&amp;quot; 0: Fly to the school Robot (R): OK. 0: Then pick up the medical supplies at the hospital R: OK. Wait a minute R: lam supposed to always fly high R: Shall I fly to the hospital at low altitude anyway? 0: Yes. Do it anyway R: OK. Wait a</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Herbert H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Firby</author>
</authors>
<title>Task networks for controlling continuous processes.</title>
<date>1994</date>
<booktitle>In Proceedings 2nd Int&apos;l Conf. on Al Planning Systems,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="1936" citStr="Firby, 1994" startWordPosition="263" endWordPosition="264">rly when participants are engaged in collaborative tasks, highlights the importance of these adaptive &amp;quot;low-level&amp;quot; processes of channel management. Dialogue participants often also &amp;quot;align&amp;quot; with each others&apos; vocabulary, syntax, and communication styles. On the other hand, dialogue also involves simultaneous high-level processes such as utterance planning and interpretation, which interact with the low-level processes, and vice versa. For such reasons, we argue that it is appropriate to view dialogue management similarly to the multi-level architectures for goal-oriented autonomous agents, e.g. (Firby, 1994; Muller, 1996): • a planning and activity-focused layer manages the bulk of the communication arising from the negotiation and performance of tasks or activities (e.g. interpreting new commands, requesting clarification, reporting on task status, dialogue structure, utterance content planning); • an &amp;quot;interaction&amp;quot; management layer uses typically &amp;quot;shallow&amp;quot; NL processing techniques to maintain the communication channel and respond to any issues that may arise (e.g. managing turn-taking, acknowledging communications quickly, using alternative processing for handling unrecognized utterances, surfa</context>
<context position="5409" citStr="Firby, 1994" startWordPosition="794" endWordPosition="795">em says &amp;quot;OK&amp;quot; immediately after recognizing the user: &amp;quot;fly to the tower&amp;quot;); • NP selection — choosing anaphoric or salient noun-phrases at the point of generation; • Incremental aggregation of system-generated utterances — appropriately condensing and forming elliptical system output at the point of generation. The resulting system is able to participate in conversations such as the one illustrated in Figure 1. Thus we have gone some way towards a multilevel architecture for activity-oriented dialogue systems, analogous to the multi-level architectures for goal-oriented autonomous agents, e.g. (Firby, 1994; Muller, 1996). Such agent architectures generally involve a higher, more abstract level at which goals are represented and plans are defined or constructed. A lower-level manages more direct interaction with the environment, or monitors the performance of long-running tasks. For example, the goal-level may plan the route to move a robot to a destination while the lower-level handles obstacle avoidance and corrects for wheel slippage. Below, we describe a number of techniques we have used at such a &amp;quot;low&amp;quot; interaction level to enhance the user&apos;s dialogue experience, and the ways that they inter</context>
</contexts>
<marker>Firby, 1994</marker>
<rawString>James Firby. 1994. Task networks for controlling continuous processes. In Proceedings 2nd Int&apos;l Conf. on Al Planning Systems, pages 49-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candace Sidner</author>
</authors>
<title>Attentions, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--3</pages>
<contexts>
<context position="13733" citStr="Grosz and Sidner, 1986" startWordPosition="2118" endWordPosition="2121">es the system expects from the user, and these are used to bias the recognition of incoming utterances for faster processing, as well as influencing the turn. In the rest of the paper, we discuss our dialogue management architecture and, in particular, the techniques employed at each of the two levels described here to enhance user experience and improve overall system performance. 4 Top-level context management The approach to dialogue modelling we have implemented is based on the theory of &amp;quot;dialogue games&amp;quot; (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, &amp;quot;discourse segments&amp;quot; (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of &amp;quot;adjacency pairs&amp;quot; of such dialogue moves. The notion of &amp;quot;attachment&amp;quot; of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. 64 Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent arch Activity Model Conversation Planner Interaction layer - timing - form - engagement - acknowl</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara Grosz and Candace Sidner. 1986. Attentions, intentions, and the structure of discourse. Computational Linguistics, 12(3):175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander H Gruenstein</author>
</authors>
<title>Conversational interfaces: A domain-independent architecture for taskoriented dialogues. Master&apos;s thesis,</title>
<date>2002</date>
<location>Stanford.</location>
<contexts>
<context position="11567" citStr="Gruenstein, 2002" startWordPosition="1782" endWordPosition="1783">s communicative goals and intentions. The content (i.e. logical forms) of user utterances are processed using the dialogue model (e.g. updates and adding nodes to the Dialogue Move Tree (Lemon et al., 2002b)), and system utterances are constructed which are in line with the system&apos;s communicative goals and intentions, whether they be imparting information to the user or requesting clarification or further information. This level also interacts with the rest of the agent architecture, mediated by an &amp;quot;Activity Model&amp;quot; (i.e. a representation of the agent activities about which dialogue may occur (Gruenstein, 2002)). The agent may wish to communicate about its goals, the progress of its activities, or report on any observations it makes regarding its environment. As with multi-layered agent architectures, the two levels operate semi-autonomously and asynchronously: the lower level is driven by tight interaction with the user, while the upper level is driven by longer-range communicative goals from its activities and responses to user utterances. However, various types of information exchange connect the two levels. For instance, user utterances recognized at the lower level must clearly be passed to the</context>
</contexts>
<marker>Gruenstein, 2002</marker>
<rawString>Alexander H. Gruenstein. 2002. Conversational interfaces: A domain-independent architecture for taskoriented dialogues. Master&apos;s thesis, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth-Ann Hockey</author>
<author>Oliver Lemon</author>
<author>Ellen Campana</author>
<author>Laura Hiatt</author>
<author>Gregory Aist</author>
<author>Jim Hieronymus</author>
<author>Alexander Gruenstein</author>
<author>John Dowding</author>
</authors>
<title>Targeted help for spoken dialogue systems: intelligent feed back improves naive users&apos; performance.</title>
<date>2003</date>
<booktitle>In Proceedings of European Association for Computational Linguistics (EACL 03),</booktitle>
<pages>page</pages>
<note>(in press).</note>
<contexts>
<context position="4447" citStr="Hockey et al., 2003" startWordPosition="643" endWordPosition="646">ation, and still less has been achieved with regard to dialogue management architectures which respect this distinction. Our aim is to argue that dialogue management architectures should embody asychronous and encapsulated levels of processing respecting these high and low levels of conversational interaction, and we present such an architecture. The following low-level processing techniques are currently implemented in our system: • A back-up recognition pass, using statistical processing to extend grammar-based coverage and provide immediate user &amp;quot;help&amp;quot; feedback for unrecognized utterances (Hockey et al., 2003); • Turn management — timing of system output is governed by monitoring the speech channel and prior dialogue move. If the system wants to take the turn, it grabs it using only lowlevel processing; • Handling user barge-in — user speech interrupts system output and automatically grabs the turn; • Immediate Grounding of recognized commands (e.g. system says &amp;quot;OK&amp;quot; immediately after recognizing the user: &amp;quot;fly to the tower&amp;quot;); • NP selection — choosing anaphoric or salient noun-phrases at the point of generation; • Incremental aggregation of system-generated utterances — appropriately condensing and</context>
<context position="18637" citStr="Hockey et al., 2003" startWordPosition="2927" endWordPosition="2930">t &amp;quot;helper&amp;quot; agent, which disappears (from the GUI) as soon as the help message is produced, thus discouraging the user from engaging it in dialogue. User tests have shown that the use of this low level module (which can be installed independently of the high-level dialogue manager) significantly improves task completion (both percentage of tasks completed and time taken). By the fifth task, 100% of users with the helper completed the task as compared with 80% of those without, and those without the helper took on average 53% longer to complete the tasks. For full details of the evaluation see (Hockey et al., 2003). 5.2 Case study 2: &amp;quot;Turn Taking&amp;quot; Here we use a turn-marker at the low-level of dialogue processing. The turn can be marked as user, system or none, and is set in a variety of ways. If the user begins to speak (start-of-speech signal is received from the recognizer) the turn becomes user and any system audio output is stopped. If the system needs to take the turn, but it is set to user, and the user is not speaking, the system will output &amp;quot;Just a moment&amp;quot; and so take the turn before generating its required utterance. Again, note that this turn-grabbing utterance is not planned or represented at</context>
</contexts>
<marker>Hockey, Lemon, Campana, Hiatt, Aist, Hieronymus, Gruenstein, Dowding, 2003</marker>
<rawString>Beth-Ann Hockey, Oliver Lemon, Ellen Campana, Laura Hiatt, Gregory Aist, Jim Hieronymus, Alexander Gruenstein, and John Dowding. 2003. Targeted help for spoken dialogue systems: intelligent feed back improves naive users&apos; performance. In Proceedings of European Association for Computational Linguistics (EACL 03), page (in press).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alexander Gruenstein</author>
<author>Alexis Battle</author>
<author>Stanley Peters</author>
</authors>
<title>Multi-tasking and collaborative activities in dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings of 3rd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>113--124</pages>
<location>Philadelphia.</location>
<contexts>
<context position="3373" citStr="Lemon et al., 2002" startWordPosition="477" endWordPosition="480">ular, the interaction level may need to notify the activity-planning level if it notices the user behaving in a manner that indicates a problem (e.g. a previously undetected misunderstanding or lack of a required grounding response). 61 We argue that for a dialogue system to be efficient, to feel &amp;quot;natural&amp;quot; to a human user, and to be satisfactorily robust, it must address the issue of maintaining and mangaging the communication channel with the user. Recently, several systems have been built to manage activity-oriented dialogue between a human and intelligent devices, e.g. (Allen et al., 1996; Lemon et al., 2002b) with some degree of success. These systems have paid limited attention to the need to maintain the communication channel. While a dialogue system clearly should not overload the user with feedback, it must nonetheless keep the user engaged, and monitor their attention, which will also help to focus on the activity being discussed. Unfortunately, very little work has been done in dialogue systems research regarding low-level interactions in conversation, and still less has been achieved with regard to dialogue management architectures which respect this distinction. Our aim is to argue that </context>
<context position="11155" citStr="Lemon et al., 2002" startWordPosition="1717" endWordPosition="1720"> inputs are respected without interruption (except when necessary), • the turn passes to the appropriate participant, based on the preceding dialogue move (passed in from the top level), • generated outputs are natural and timely, • recognized user inputs are acknowledged quickly using simple feedback utterances. The upper level is responsible for modeling other aspects of the conversational context, as well as communicative goals and intentions. The content (i.e. logical forms) of user utterances are processed using the dialogue model (e.g. updates and adding nodes to the Dialogue Move Tree (Lemon et al., 2002b)), and system utterances are constructed which are in line with the system&apos;s communicative goals and intentions, whether they be imparting information to the user or requesting clarification or further information. This level also interacts with the rest of the agent architecture, mediated by an &amp;quot;Activity Model&amp;quot; (i.e. a representation of the agent activities about which dialogue may occur (Gruenstein, 2002)). The agent may wish to communicate about its goals, the progress of its activities, or report on any observations it makes regarding its environment. As with multi-layered agent architec</context>
<context position="14059" citStr="Lemon et al., 2002" startWordPosition="2170" endWordPosition="2173">er experience and improve overall system performance. 4 Top-level context management The approach to dialogue modelling we have implemented is based on the theory of &amp;quot;dialogue games&amp;quot; (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, &amp;quot;discourse segments&amp;quot; (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of &amp;quot;adjacency pairs&amp;quot; of such dialogue moves. The notion of &amp;quot;attachment&amp;quot; of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. 64 Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent arch Activity Model Conversation Planner Interaction layer - timing - form - engagement - acknowledgement Backup Shallow Processor (Helper) Attention Monitor Speech recogition and Parsing Speech channel Generation Module Generation: - anaphora - pronouns - aggregation - echoing Agent - intentions - goals - plans - observations K._ Context Mgr alogue Move Tree An &amp;quot;Activity Tree&amp;quot; represents hierarchical and temporal infor</context>
</contexts>
<marker>Lemon, Gruenstein, Battle, Peters, 2002</marker>
<rawString>Oliver Lemon, Alexander Gruenstein, Alexis Battle, and Stanley Peters. 2002a. Multi-tasking and collaborative activities in dialogue systems. In Proceedings of 3rd SIGdial Workshop on Discourse and Dialogue, pages 113 – 124, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alexander Gruenstein</author>
<author>Stanley Peters</author>
</authors>
<title>Collaborative activities and multitasking in dialogue systems.</title>
<date>2002</date>
<booktitle>Traitement Automatique des Langues (TAL), 43(2):131 – 154. Special Issue on Dialogue.</booktitle>
<contexts>
<context position="3373" citStr="Lemon et al., 2002" startWordPosition="477" endWordPosition="480">ular, the interaction level may need to notify the activity-planning level if it notices the user behaving in a manner that indicates a problem (e.g. a previously undetected misunderstanding or lack of a required grounding response). 61 We argue that for a dialogue system to be efficient, to feel &amp;quot;natural&amp;quot; to a human user, and to be satisfactorily robust, it must address the issue of maintaining and mangaging the communication channel with the user. Recently, several systems have been built to manage activity-oriented dialogue between a human and intelligent devices, e.g. (Allen et al., 1996; Lemon et al., 2002b) with some degree of success. These systems have paid limited attention to the need to maintain the communication channel. While a dialogue system clearly should not overload the user with feedback, it must nonetheless keep the user engaged, and monitor their attention, which will also help to focus on the activity being discussed. Unfortunately, very little work has been done in dialogue systems research regarding low-level interactions in conversation, and still less has been achieved with regard to dialogue management architectures which respect this distinction. Our aim is to argue that </context>
<context position="11155" citStr="Lemon et al., 2002" startWordPosition="1717" endWordPosition="1720"> inputs are respected without interruption (except when necessary), • the turn passes to the appropriate participant, based on the preceding dialogue move (passed in from the top level), • generated outputs are natural and timely, • recognized user inputs are acknowledged quickly using simple feedback utterances. The upper level is responsible for modeling other aspects of the conversational context, as well as communicative goals and intentions. The content (i.e. logical forms) of user utterances are processed using the dialogue model (e.g. updates and adding nodes to the Dialogue Move Tree (Lemon et al., 2002b)), and system utterances are constructed which are in line with the system&apos;s communicative goals and intentions, whether they be imparting information to the user or requesting clarification or further information. This level also interacts with the rest of the agent architecture, mediated by an &amp;quot;Activity Model&amp;quot; (i.e. a representation of the agent activities about which dialogue may occur (Gruenstein, 2002)). The agent may wish to communicate about its goals, the progress of its activities, or report on any observations it makes regarding its environment. As with multi-layered agent architec</context>
<context position="14059" citStr="Lemon et al., 2002" startWordPosition="2170" endWordPosition="2173">er experience and improve overall system performance. 4 Top-level context management The approach to dialogue modelling we have implemented is based on the theory of &amp;quot;dialogue games&amp;quot; (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, &amp;quot;discourse segments&amp;quot; (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of &amp;quot;adjacency pairs&amp;quot; of such dialogue moves. The notion of &amp;quot;attachment&amp;quot; of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. 64 Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent arch Activity Model Conversation Planner Interaction layer - timing - form - engagement - acknowledgement Backup Shallow Processor (Helper) Attention Monitor Speech recogition and Parsing Speech channel Generation Module Generation: - anaphora - pronouns - aggregation - echoing Agent - intentions - goals - plans - observations K._ Context Mgr alogue Move Tree An &amp;quot;Activity Tree&amp;quot; represents hierarchical and temporal infor</context>
</contexts>
<marker>Lemon, Gruenstein, Peters, 2002</marker>
<rawString>Oliver Lemon, Alexander Gruenstein, and Stanley Peters. 2002b. Collaborative activities and multitasking in dialogue systems. Traitement Automatique des Langues (TAL), 43(2):131 – 154. Special Issue on Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J P Muller</author>
</authors>
<title>The Design of Intelligent Agents— A Layered Approach.</title>
<date>1996</date>
<publisher>Springer Verlag,</publisher>
<location>Heidelberg, Germany.</location>
<contexts>
<context position="1951" citStr="Muller, 1996" startWordPosition="265" endWordPosition="266">icipants are engaged in collaborative tasks, highlights the importance of these adaptive &amp;quot;low-level&amp;quot; processes of channel management. Dialogue participants often also &amp;quot;align&amp;quot; with each others&apos; vocabulary, syntax, and communication styles. On the other hand, dialogue also involves simultaneous high-level processes such as utterance planning and interpretation, which interact with the low-level processes, and vice versa. For such reasons, we argue that it is appropriate to view dialogue management similarly to the multi-level architectures for goal-oriented autonomous agents, e.g. (Firby, 1994; Muller, 1996): • a planning and activity-focused layer manages the bulk of the communication arising from the negotiation and performance of tasks or activities (e.g. interpreting new commands, requesting clarification, reporting on task status, dialogue structure, utterance content planning); • an &amp;quot;interaction&amp;quot; management layer uses typically &amp;quot;shallow&amp;quot; NL processing techniques to maintain the communication channel and respond to any issues that may arise (e.g. managing turn-taking, acknowledging communications quickly, using alternative processing for handling unrecognized utterances, surface realization </context>
<context position="5424" citStr="Muller, 1996" startWordPosition="796" endWordPosition="797">immediately after recognizing the user: &amp;quot;fly to the tower&amp;quot;); • NP selection — choosing anaphoric or salient noun-phrases at the point of generation; • Incremental aggregation of system-generated utterances — appropriately condensing and forming elliptical system output at the point of generation. The resulting system is able to participate in conversations such as the one illustrated in Figure 1. Thus we have gone some way towards a multilevel architecture for activity-oriented dialogue systems, analogous to the multi-level architectures for goal-oriented autonomous agents, e.g. (Firby, 1994; Muller, 1996). Such agent architectures generally involve a higher, more abstract level at which goals are represented and plans are defined or constructed. A lower-level manages more direct interaction with the environment, or monitors the performance of long-running tasks. For example, the goal-level may plan the route to move a robot to a destination while the lower-level handles obstacle avoidance and corrects for wheel slippage. Below, we describe a number of techniques we have used at such a &amp;quot;low&amp;quot; interaction level to enhance the user&apos;s dialogue experience, and the ways that they interact with high-l</context>
</contexts>
<marker>Muller, 1996</marker>
<rawString>J. P. Muller. 1996. The Design of Intelligent Agents— A Layered Approach. Springer Verlag, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Power</author>
</authors>
<title>The organization of purposeful dialogues.</title>
<date>1979</date>
<journal>Linguistics,</journal>
<pages>17--107</pages>
<contexts>
<context position="13652" citStr="Power, 1979" startWordPosition="2110" endWordPosition="2111">ts of attachment on the Dialogue Move Tree represent types of utterances the system expects from the user, and these are used to bias the recognition of incoming utterances for faster processing, as well as influencing the turn. In the rest of the paper, we discuss our dialogue management architecture and, in particular, the techniques employed at each of the two levels described here to enhance user experience and improve overall system performance. 4 Top-level context management The approach to dialogue modelling we have implemented is based on the theory of &amp;quot;dialogue games&amp;quot; (Carlson, 1983; Power, 1979), and, for task-oriented dialogues, &amp;quot;discourse segments&amp;quot; (Grosz and Sidner, 1986). These accounts rely on the observation that answers generally follow questions, commands are usually acknowledged, and so on, so that dialogues can be partially described as consisting of &amp;quot;adjacency pairs&amp;quot; of such dialogue moves. The notion of &amp;quot;attachment&amp;quot; of dialogue moves on a Dialogue Move Tree (DMT) (Lemon et al., 2002b) embodies this idea. 64 Figure 2: System Architecture Content layer: - utterance planning - communicative intentions - grounding - content management - interaction with agent arch Activity Mo</context>
</contexts>
<marker>Power, 1979</marker>
<rawString>Richard Power. 1979. The organization of purposeful dialogues. Linguistics, 17:107-152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shapiro</author>
<author>Pat Langley</author>
<author>Ross Shachter</author>
</authors>
<title>Using background knowledge to speed reinforcement learning.</title>
<date>2001</date>
<booktitle>In Fifth International Conference on Autonomous Agents,</booktitle>
<pages>254--261</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="6228" citStr="Shapiro et al., 2001" startWordPosition="921" endWordPosition="924">action with the environment, or monitors the performance of long-running tasks. For example, the goal-level may plan the route to move a robot to a destination while the lower-level handles obstacle avoidance and corrects for wheel slippage. Below, we describe a number of techniques we have used at such a &amp;quot;low&amp;quot; interaction level to enhance the user&apos;s dialogue experience, and the ways that they interact with high-level dialogue processing. We also suggest ways in which this strategy could be enhanced to address further issues, for instance using reactive planning and learning techniques, e.g. (Shapiro et al., 2001). 2 Motivation for an Interaction Layer Studies in linguistics and psychology provide evidence for the claim that dialogue consists of two parallel &amp;quot;channels&amp;quot; of interaction, and that participants attempt to co-ordinate and align these channel through conversation. For example: &amp;quot;There is co-ordination of both content, what the participants intend to do, and process, the physical and mental systems they recruit in carrying out those intentions.&amp;quot; (Clark, 1996), p. 59. Human-human dialogue involves immediate acknowledgement and grounding of utterances (&amp;quot;yep&amp;quot; or &amp;quot;okay&amp;quot;), often in the middle of a 6</context>
<context position="24604" citStr="Shapiro et al., 2001" startWordPosition="3918" endWordPosition="3921">ialogue strategy. This is particularly important in the genre of tutorial dialogue (Zinn et al., 2002), where low-level processes could detect problems with user attention and responsiveness, and prompt a switch to a different highlevel strategy. Particularly important for safetycritical applications, but of general use, would be low-level monitoring of channel noise and other environmental factors such as user gestures and gaze. Again, certain combinations of these inputs would have high-level consequences for interpretation and dialogue planning. We are currently investigating using Icarus (Shapiro et al., 2001), a reactive planning system that learns and adapts to user behavior, for implementing and integrating different low-level modules. We hope that this will allow, for instance, turn-taking facilities to be more easily adapted as personalities or situations require: for example, after noticing a particular event the system may be more likely to interrupt a speaker, or may adapt to become less prone to interruption when interacting with a speaker who responds poorly to system barge-in. 7 Conclusion We argue for the development of distinct high and low levels of processing in dialogue management. </context>
</contexts>
<marker>Shapiro, Langley, Shachter, 2001</marker>
<rawString>Dan Shapiro, Pat Langley, and Ross Shachter. 2001. Using background knowledge to speed reinforcement learning. In Fifth International Conference on Autonomous Agents, pages 254 – 261. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan van Kuppevelt</author>
<author>Ulrich Heid</author>
<author>Hans Kamp</author>
</authors>
<title>Best practice in spoken language dialogue system engineering.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<marker>van Kuppevelt, Heid, Kamp, 2000</marker>
<rawString>Jan van Kuppevelt, Ulrich Heid, and Hans Kamp. 2000. Best practice in spoken language dialogue system engineering. Natural Language Engineering, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claus Zinn</author>
<author>Johanna D Moore</author>
<author>Mark G Core</author>
</authors>
<title>A 3-tier planning architecture for managing tutorial dialogue,.</title>
<date>2002</date>
<booktitle>In Intelligent Tutoring Systems, Sixth International Conference (ITS</booktitle>
<contexts>
<context position="24085" citStr="Zinn et al., 2002" startWordPosition="3842" endWordPosition="3845">lated into a string for the speech synthesizer. Otherwise the top level would have to replan utterances after every intervening dialogue move. This example shows how respecting the multi-level architecture is desirable from an engineering point of view. 6 Further Possibilities There are many other dialogue phenomena that could be treated along these lines. For instance, processes at the lower level could detect miscommunication and channel breakdown, and send a request to the top level to replan the longrange dialogue strategy. This is particularly important in the genre of tutorial dialogue (Zinn et al., 2002), where low-level processes could detect problems with user attention and responsiveness, and prompt a switch to a different highlevel strategy. Particularly important for safetycritical applications, but of general use, would be low-level monitoring of channel noise and other environmental factors such as user gestures and gaze. Again, certain combinations of these inputs would have high-level consequences for interpretation and dialogue planning. We are currently investigating using Icarus (Shapiro et al., 2001), a reactive planning system that learns and adapts to user behavior, for impleme</context>
</contexts>
<marker>Zinn, Moore, Core, 2002</marker>
<rawString>Claus Zinn, Johanna D. Moore, and Mark G. Core. 2002. A 3-tier planning architecture for managing tutorial dialogue,. In Intelligent Tutoring Systems, Sixth International Conference (ITS 2002).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>