<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000062">
<title confidence="0.998656">
A Corpus-Based Statistical Approach to Automatic Book Indexing
</title>
<author confidence="0.997476666666667">
Jyun-Sheng Chang*, Tsung-Yih Tseng,
Ying Cheng, Huey-Chyun Chen,
Shun-Der Cheng
</author>
<affiliation confidence="0.990805">
Department of Computer Science
National Tsing Hua University
</affiliation>
<address confidence="0.721335">
Hsinchu, Taiwan 30043, ROC
</address>
<email confidence="0.996041">
jschang@cs.nthu.edu.tw
</email>
<sectionHeader confidence="0.996621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999740142857143">
The paper reports on a new approach to automatic
generation of back-of-book indexes for Chinese
books. Parsing on the level of complete sentential
analysis is avoided because of the inefficiency and
unavailability of a Chinese Grammar with enough
coverage. Instead, fundamental analysis particular
to Chinese text called word segmentation is
performed to break up characters into a sequence
of lexical units equivalent to words in English.
The sequence of words then goes through part-of-
speech tagging and noun phrase analysis. All these
analyses are done using a corpus-based statistical
algorithm. Experimental results have shown
satisfactory results.
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="introduction">
1. Introduction
</sectionHeader>
<bodyText confidence="0.999726588235294">
Preparing back-of-book indexes is of vital importance to
the publishing industry but is a very labor intensive task.
Attempts have been made over the years to automate this
procedure for the apparent benefits of cost saving, shorter
preparation time, and possibility of producing more
complete and consistent indexes. Early work involves
using occurrence characteristics of contents words [Borko,
1970]. Later people came to realize that indexes are often
multi-word terms and their generation might involve more
elaborated syntactic analysis on phrasal or sentential level
[Salton, 1988; Dillon and McDonald, 1983]. However, a
full syntactical approach [Salton, 1988] to this task has real
problem with efficiency and coverage for unrestricted text.
No viable automatic solution is currently in use.
Indexing Chinese books involves another severe
obstacle, namely the word segmentation problem. Chinese
text consists of a sequence of characters which roughly
</bodyText>
<footnote confidence="0.558733">
* This research was supported by ROC National Science
Council under Contract NSC 81-0408-E-007-529.
</footnote>
<author confidence="0.788107">
Sur-Jin Ker
</author>
<affiliation confidence="0.9746805">
Department of Computer Science
SooChow University
</affiliation>
<author confidence="0.906805">
John S. Liu
</author>
<affiliation confidence="0.8136095">
Software Research Office
Sampo Research Institute
</affiliation>
<bodyText confidence="0.998314625">
correspond to letters in English. However, there are no
spaces to mark the beginning and end of a word as in
English. Until recently, this problem has been considered
difficult to solve without elaborated syntactical and
semantic analyses [Chen, 1988].
Recent research advances may lead to the development
of viable book indexing methods for Chinese books. These
include the availability of efficient and high precision word
segmentation methods for Chinese text [Chang et al., 1991;
Sproat and Shih, 1990; Wang et al., 1990], the availability
of statistical analysis of a Chinese corpus [Liu et al., 1975]
and large-scale electronic Chinese dictionaries with part-
of-speech inforznation [Chang et al., 1988; BDC, 1992],
the corpus-based statistical part-of-speech tagger [Church,
1988; DeRose, 1988; Beale, 1988], as well as phrasal and
clausal analyzers [Church 1988; Ejerhed 1990]
</bodyText>
<sectionHeader confidence="0.906141" genericHeader="method">
2. Problem description
</sectionHeader>
<bodyText confidence="0.99989695">
As being pointed out in [Salton, 1988], back-of-book
indexes may consist of more than one word that are
derived from a noun phrase. Given the text of a book, an
indexing system, must perform some kind of phrasal and
statistical analysis in order to produce a list of candidate
indexes and their occurrence statistics in order to generate
indexes as shown in Figure 1 which is an excerpt from the
reconstruction of indexes of a book on transformational
grammar for Mandarin Chinese [Tang, 1977].
Before phrasal analysis can be performed, the text must
go through the more fundamental morphological and part-
of-speech analysis. The morphological analysis for
Chinese text is mainly a so-called word segmentation
process, which segments a sequence of Chinese character
into a sequence of words. See Figure 2 for illustration.
The noun phrase generation process described in this
paper is based on a corpus-based statistical analysis and
does not use an explicit syntactical representation.
Examples of noun phrases found are underlined as shown
in Figure 2.
</bodyText>
<page confidence="0.987999">
147
</page>
<figure confidence="0.9992373">
MNI[liangci] measure word
[lienci] conjunction
IiI)i[LiNa] Li, C.N.
#11E1 [LinShuangFu] Lin, S.F.
N[LiXi] Li, H.
Ni[leici] classifier
Ifitfiff [leitueizuoyondanalogy
tefeit[lunyun] argument
a ORM (luojihuanwei] logical scope
a fa [luojishuci] logical predicate
</figure>
<figureCaption confidence="0.916973">
Figure 1. Indexes
</figureCaption>
<figure confidence="0.9876424375">
1--/n/Pita/MtP/
[dan/lian/ge/yishang/de/luogi/shuci]
P/Q/CL/LOC/CTM/NC/NC/
When two or more logical predicates
trili—iflt1/1-31-7-10/144/1k/DR/tItl/WIR/
[zai/tong/yi/ge/juzi/limian/qian/hou/cuxian/de/shihou]
P/D/Q/CL/NC/LOC/LOC/LOCN/CTM/NC/
apear at the same sentence,
tfil/gt/i9,/1t/trg/VrtV/
[wuomen/jiou/shuo/houmian/de/shuci]
NP/ADV/V/NC/CTM/NC/
we then say that the predicate
AITElliglig/321k-gAgrl/Wita/g41/
[zai/qiantnian/de/shuci/de/luoji/fangweif]
P/NC/CTM/NC/CTM/NC/NC/
is within the logical scope of predicates before it.
</figure>
<figureCaption confidence="0.999642">
Figure 2. Segmentation, tagging, and noun phrase finding
</figureCaption>
<sectionHeader confidence="0.929229" genericHeader="method">
3. Generating Indexes
</sectionHeader>
<subsectionHeader confidence="0.995069">
3.1. Word Segmentation
</subsectionHeader>
<subsubsectionHeader confidence="0.746415">
Segmentation through Constraint Satisfaction
</subsubsectionHeader>
<bodyText confidence="0.999925">
The word segmentation problem for Chinese can be
simply stated as follows: Given a Chinese sentence,
segment the sentence into words. For example, given
</bodyText>
<equation confidence="0.924683333333333">
tE 111 AO fr. fh ff 7 5)- C.
we are supposed to segment it into
tE/111 frP/M/fik fh/f/7/ft IR
</equation>
<bodyText confidence="0.974909875">
[ba /liuxianzhong/de/queshi/xiendong/cuo/le/fenxi]
Xian-Zhong Liu &apos;s exact action was given an analysis.
where Ill (Liu) is a surname and Milli (Xian-Zhong) is a
last name. In the following, we will describe a method that
extends our previous work on segmentation [Chang et al.,
1991a] to handle surname-names [Chang et al., 1991b].
Segmentation is solved as a constraint satisfaction
problem.
</bodyText>
<figureCaption confidence="0.994633">
Figure 3. List of part-of-speeches
</figureCaption>
<bodyText confidence="0.938835333333333">
The constraint satisfaction problem
The constraint satisfaction problem involves the
assignment of values to variables subject to a set of
constraining relations. Examples of CSPs include map
coloring, understanding line drawing, and scheduling
[Detcher and Pear, 1988]. The CSP with binary constraints
can be defined as follows: Given a set of n variables X1,
Xn and a set of binary constraints Kii, find all
possible n-tuples (xi, x2, ..., x5,) such that each n-tuple is
an instantiation of the n variables satisfying
(xi, xi) in Kg, for all
Segmentation as a Constraint Satisfaction Problem
The word segmentation problem can be cast as a CSP as
follows: Suppose that we are given a sequence of Chinese
character (Ci, C2....., Cn) and are to segment the sequence
into subsequences of characters that are either words in the
dictionary or surname-names. We can think of a solution to
this segmentation problem as an assignment of
break/continue (denoted by the symbols I&gt;1 and &apos;=&apos;
respectively) to each place Xi between two adjacent
characters Ci and Ci+i:
</bodyText>
<equation confidence="0.9878815">
C2 I c3 I cn I
X0 Xi X2 ... Xn_i Xn
</equation>
<bodyText confidence="0.9790215">
subject to the constraint that the characters between two
closest breaks correspond to either a Chinese word in the
dictionary or surname-names. (For convenience, we add
two more places; one at the beginning, the other at the
end.) So the set of constraints can be constructed as
follows:
</bodyText>
<figure confidence="0.999032166666667">
15, 24, 38
291, 306
286
292
212, 232, 296
15, 24
293
160, 279
61
60, 301
1. V Verbe (Predicative)
2. NC Nouns
3. NP Proper Names or Pronouns
4. A Adjectives (Non-Predicative)
5. P Prepositions
6. ADV Adverbs
7. CI Conjunctions
8. D Determiners
9.Q Quantifiers
10. CL Classifers
11. LOC Locatives
12. ASP Aspect Markers
13. CTS Sentential Clitics
14. CTN Noun Clitics
15. CTM Modifiers Clitics
16. INT Interrogatives
17. S Sentences
18. PP Prepositional Phrases
19. PREF Prefixes
20. SUF Suffixes
</figure>
<page confidence="0.915639">
148
</page>
<bodyText confidence="0.8026854">
For each sequence of characters Ci, i) which
are a Chinese word in the dictionary or a surname-name,
if] = i, then put (&gt;,&gt;) in
if j&gt; i, then put (›,=) in Ki-1,i, (=,&apos;) in Ki, i+ 1, , and
(=,&apos;) in Kj-1,j.
</bodyText>
<equation confidence="0.955756315789474">
For example, consider again the following:
.111 Mfi 1k fi 7 5)- The corresponding corresponding CSP is
KO, 1 =
1(1,2 =
K2,3 =
1(3,4 =
1(4,5 =
K6,6 = {(&gt;,&gt;)),
1(6,7 =
K7,8 =
K8,9 =
K9,10 = {(&gt;,&gt;),(=,&gt;),(&gt;,=)},
1&lt;10,11 = {(&gt;,&gt;),(=,&gt;),(&gt;,=)},
1(11,12 = {(&gt;,&gt;)},
1(12,13 = {(&gt;,›),(&gt;,=)},
1&lt;13,14 = {(=,&gt;)},
since
tE/111M/100fLP/frg/frgia/Mgt/14fil
filIVIM/ff/ 7 MO-1W/
</equation>
<bodyText confidence="0.999377833333333">
are either words in the dictionary or probable surname-
names (hypothesized words).
Typically, there will be more than one solution to this
CSP. So the most probable one with highest product of
probability of hypothesized words is chosen to be the
solution. Ordinary words are listed in the dictionary along
with this kind of probability estimated from a general
corpus [Liu et al., 1975]. As for proper names such as
Chinese surname-names not listed in the dictionary, their
probability are approximated by using another corpus
containing more than 18,000 names as described in the
following subsection.
</bodyText>
<subsectionHeader confidence="0.451349">
The Problem with Proper Names in Chinese Text
</subsectionHeader>
<bodyText confidence="0.952354414634146">
Proper nouns account for only about 2% of average
Chinese text. However, according to a recent study on
word segmentation [Chang et al., 1991a], they account for
at least 50% of errors made by a typical segmentation
system. Moreover, proper names are oftentimes indexes.
Therefore their correct segmentation is crucial to automatic
generation of back-of-book indexes.
The difficulties involved in handling proper names are
due to the following: (1) No apparent punctuation marking
is given like capitalization in English. (2). Most of
characters in proper names have different usage. So this
problem has been held impossible to solve in the
segmentation process. And it was suggested that proper
names are best left untouched in the segmentation process
and rely on syntactical and semantic analysis to solve the
problem when nothing can be made out of the characters
representing them [Chen, 1988]. Using the corpus-based
statistical approach, we have shown that it is possible to
identify most Chinese surname-names (A without using
explicit syntactical or semantic representation.
Most surnames are single character and some rare ones
are of two characters (single-surnames and double-
surnames). Names can be either one or two characters
(single-names and double-names). Some characters are
more often used for names than others. Currently, there
are more double-names than single-name in Taiwan.
The formation of hypothesized surname-names is
triggered by the recognition of a surname. In the example
above, 111 (Liu) is one of some 300 surnames.
Subsequently, we will take one character and two
characters after the surname as probable last names, in this
case (Xian) and MI* (Xian-Zhong). A general corpus,
G and a surname-name corpus N are used to evaluate the
probability of a surname-name. For instance, the
probability of a most common kind of 3-character name
(single-surname/double-name) such as MON] is:
P( MOP) = P( single-surname/double-names in G) x
P(111 being a surname in Al) x
P(Nfi being 1st character in names in N) x
P(111 being 2nd character in names in N)
Names of other combinations can be handled similarly.
</bodyText>
<subsectionHeader confidence="0.440612">
The Algorithm
</subsectionHeader>
<bodyText confidence="0.890408">
To sum up, the whole process of word segmentation with
surname-name identification is as follows:
</bodyText>
<listItem confidence="0.902922642857143">
1. Scan from left to right across the sentence
2. Check to see if the prefix of what is being scanned
is a hypothesize word, by
2.1. dictionary lookup of an ordinary word and its
probability
2.2. checking for the existence of a surname
2.2.1. forming possible combinations of the
surname-name
2.2.2. evaluating the probability of each combination
3. Post the constraints of the CSP and probability for
each hypothesized word
4. Solve the CSP
5. Find the most probable solution to CSP through
dynamic programming
</listItem>
<subsectionHeader confidence="0.991411">
3.2. Part-of-speech Tagging
</subsectionHeader>
<bodyText confidence="0.99855375">
As far as we know, there has been only scarce research
done on part-of-speech tagging for Chinese [Chang et al.,
1988; Chen, 1991; Bai and Xia, 1991; BDC, 1992]. As for
English, there are at least three independently developed
</bodyText>
<page confidence="0.997931">
149
</page>
<bodyText confidence="0.995941444444445">
taggers [Church 1988; DeRose 1988; Beale 1988]. We
started out using an electronic dictionary [Chen; 1991;
Chang et al., 1988] with a very elaborated part-of-speech
system based on Chao&apos;s work [Chao, 1968]. Because it is
difficult to get sufficient manualy tagged data for a large
tag set, we have since switched to another electronic
dictionary with some 90,000 entries and a much smaller
tag set. The dictionary is actually a bilingual one (Chinese-
English) developed by Behavior Design Corporation
</bodyText>
<figureCaption confidence="0.775657285714286">
[BDC, 1992]. The list of part-of-speeches is shown in
Figure 3. The algorithm is essentially the same as
[DeRose, 1988]. The BDC Chinese-English Dictionary is
used to obtain the list of possible part-of-speeches for each
segmented word. Currently, the collocation probabilities
of part-of-speech are estimated from a manually tagged
text of about 4,000 words.
</figureCaption>
<subsectionHeader confidence="0.997912">
3.3. Finding Noun Phrases
</subsectionHeader>
<bodyText confidence="0.9999326">
Instead of using a full-blown parser to find noun phrases,
we first mark the noun phrases in the same text of about
4,000 words and compute the statistical characteristics of
categoric patterns of noun phrase and then use the statistics
in a stochastic algorithm for finding noun phrases in a
manner similar to [Church 1988; Ejerhed 1990].
Extracting keywords from a noun phrase is somewhat
heuristic unlike the rigorous approach of using the
syntactical structure within the noun phrase in [Salton,
1988].
</bodyText>
<sectionHeader confidence="0.912068" genericHeader="method">
4. The Experimental Results
</sectionHeader>
<bodyText confidence="0.950982458333333">
The algorithm described in Section 3 is currently under
development and the programs are written in C and
ProFox, and run on an IBM PC compatible machine. The
segmentation, tagging, and NP identification parts are
completed, while the statistical analysis of the occurrence
of NPs is being implemented now. The statistics used in
the system consists of four parts:
(SI) Appearance counts of 40,032 distinct words
from a corpus of 1,000,000 words of Chinese text
[Liu el al., 1975].
(S2) The BDC Chinese-English Dictionary [BDC,
1992].
(S3) A general corpus of 300,000 words. Some
4,000 words of text from this corpus is tagged and
marked with NP.
(S4) A name corpus of some 18,000 surname-
names.
The performance of the completed parts of the system is
as follows: The hit rate of word segmentation is about 97%
on the average. For the surname-names alone, we get 90%
average hit rate which eliminate about 40% of errors
produced by our previous segmentation system. About 98%
of part-of-speeches are tagged correctly. And about 95% of
the noun phrases are found successfully.
</bodyText>
<sectionHeader confidence="0.956928" genericHeader="conclusions">
5. Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999971727272727">
The preliminary results that we have obtained seem very
promising. The approach presented here does not rely on a
fully developed Chinese grammar for syntactical analysis
on the sentential level. Thus the efficiency in system
development and generation of indexes is reasonable and
cost of building and maintaining such a system is
acceptable. Currently, we are working on (I) handling
translated names, (2) improving the hit rate of tagging and
NP identification by using a larger and more correctly
tagged and marked training corpus, and (3) completion of
the statistical analysis of occurrence of noun phrases.
</bodyText>
<sectionHeader confidence="0.996946" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999484428571429">
Thanks are due to for Dr. Keh-Yih Su for making the BDC
dictionary available to us. Preliminary work in
segmentation has been done using the electronic dictionary
developed by the Chinese Dictionary Group, Academia
Sinica and acquired from Computer and Communication
Research Laboratories through thd Technology Diffusion
Program of ITRI.
</bodyText>
<sectionHeader confidence="0.996667" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994599478260869">
Shuanhu Bai and Ying Xia. A Scheme for Tagging Chinese
Running Text. In Proceedings of Natural Language
Processing Pacific Rim Symposium, pages 345-350,
Singapore, 1991.
Andrew David Beale. Lexicon and Grammar in
Probabilistic Tagging of written English, In Proceedings of
the Annual Meeting of the Association for Computational
Linguistics, pages 211-216, Buffalo, 1988.
Behavior Design Corporation. BDC Electronic Chinese-
English Dictionary, Hsinchu, Taiwan, 1992.
H. Borko. Experiments in Book Indexing by Computer,
Information Storage and Retrieval, 6(1):5-16, 1970.
Jywi-Sheng Chang, Chi-Dah Chen, and Shun-Der Chen.
Chinese Word Segmentation through Constraint
Satisfaction and Statistical Optimization, In Proceedings of
ROC Computational Linguistics Conference, pages 147-
165, Kenting, Taiwan, 1991, (in Chinese).
Jyan-Sheng Chang, Shun-Der Chen, Ying Chen, John S.
Liu, and Sue-Jin Ker. A Multiple-corpus Approach to
Identification of Chinese Surname-Names, In Proceedings
of Natural Language Processing Pacific Rim Symposium,
pages 87-91, Singapore, 1991.
Li-Li Chang et al. Part-of-Speech Analysis for Mandarin
</reference>
<page confidence="0.995949">
150
</page>
<bodyText confidence="0.735759888888889">
Chinese, Technical Rep. T0002, Computation Center,
Academia Sinica, Taiwan, 1975, (in Chinese).
Lian-Jyh Wang, Tzusheng Pei, Wei-Chuan Li, and Lih-
Ching R. Huang. A Parsing Method for Identifying Words
in Mandarin Chinese Sentences, Identification of Chinese
Name, In Proceedings of International Joint Conference on
Artificial Intelligence, pages 1018-1023, Sidney, 1991.
Yuen Ren Chao, A Grammar for Spoken Chinese,
University of California Press, California, 1968.
</bodyText>
<reference confidence="0.994137461538462">
Chih-Dah Chen. Segmentation and Part-of-speech Tagging
for Chinese, master thesis, National Tsing-Hua University,
Hsinchu, Taiwan, 1991.
Keh-Jiann Chen and Chu-Ren Huang, Word Classifications
and Grammatical Representation in Chinese, manuscript,
1991.
Keh-Jiann Chen. Problems and Strategies in Parsing
Chinese Sentences - A Tutorial, In Proceedings of ROC
Computational Linguistics Workshop, Sitou, Taiwan,
September, 1988, pp. 19-24, (in Chinese).
Kenneth Ward Church. A Stochastic Parts Program and
Noun Phrase Parser for Unrestricted Text. In Proceedings
of Second Conference on Applied Natural Language
Processing, pages 136-143, Austin, 1988.
Steven J. DeRose. Grammatical Category Disambiguation
by Statistical Optimization, Computational Linguistics,
14(1):31-39, Winter 1988.
Rina Dechter and Judea Pearl, 1988, Network-Based
Heuristics for Constraint-Satisfaction Problems, J. of
Artificial Intelligence 34(1):1-38, 1988.
M. Dillon and L.K. McDonald. Fully Automatic Book
Indexing, Journal of Documentation, 39(3):135-154, 1983.
Eva I. Ejerhed. Finding Clauses in Unrestricted Text by
Finitary and Stochastic Methods, In Proceedings of the
Annual Meeting of the Association for Computational
Linguistics, pages 219-227, Austin, 1988.
In-mao Liu et al. Frequency Counts of Chinese Words,
Lucky Book Co., Taipei, Taiwan, 1975.
Gerard Salton. Syntactical Approaches to Automatic Book
Indexing, In Proceedings of the Annual Meeting of the
Association for Computational Linguistics, pages 204-210,
1988.
Richard Sproat and Chilin Shih, A Statistical Method for
Finding Word Boundaries in Chinese Text, Journal of
Computer Processing of Chinese and Oriental Languages,
4(4):336-351, March, 1990.
Ting-chi Tang. Studies in Transformational Grammar of
Chinese, Volume I. Movement Transformations, Taipei,
Student Book Co., 1977, (in Chinese).
</reference>
<page confidence="0.998344">
151
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.741362">
<title confidence="0.999868">A Corpus-Based Statistical Approach to Automatic Book Indexing</title>
<author confidence="0.905140666666667">Tsung-Yih Tseng</author>
<author confidence="0.905140666666667">Ying Cheng</author>
<author confidence="0.905140666666667">Huey-Chyun Chen</author>
<author confidence="0.905140666666667">Shun-Der_Cheng</author>
<affiliation confidence="0.9997885">Department of Computer Science National Tsing Hua University</affiliation>
<address confidence="0.999431">Hsinchu, Taiwan 30043, ROC</address>
<email confidence="0.969766">jschang@cs.nthu.edu.tw</email>
<abstract confidence="0.9995066">The paper reports on a new approach to automatic generation of back-of-book indexes for Chinese books. Parsing on the level of complete sentential analysis is avoided because of the inefficiency and unavailability of a Chinese Grammar with enough coverage. Instead, fundamental analysis particular to Chinese text called word segmentation is performed to break up characters into a sequence of lexical units equivalent to words in English. The sequence of words then goes through part-ofspeech tagging and noun phrase analysis. All these analyses are done using a corpus-based statistical algorithm. Experimental results have shown satisfactory results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shuanhu Bai</author>
<author>Ying Xia</author>
</authors>
<title>A Scheme for Tagging Chinese Running Text.</title>
<date>1991</date>
<booktitle>In Proceedings of Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>345--350</pages>
<contexts>
<context position="11752" citStr="Bai and Xia, 1991" startWordPosition="1793" endWordPosition="1796">refix of what is being scanned is a hypothesize word, by 2.1. dictionary lookup of an ordinary word and its probability 2.2. checking for the existence of a surname 2.2.1. forming possible combinations of the surname-name 2.2.2. evaluating the probability of each combination 3. Post the constraints of the CSP and probability for each hypothesized word 4. Solve the CSP 5. Find the most probable solution to CSP through dynamic programming 3.2. Part-of-speech Tagging As far as we know, there has been only scarce research done on part-of-speech tagging for Chinese [Chang et al., 1988; Chen, 1991; Bai and Xia, 1991; BDC, 1992]. As for English, there are at least three independently developed 149 taggers [Church 1988; DeRose 1988; Beale 1988]. We started out using an electronic dictionary [Chen; 1991; Chang et al., 1988] with a very elaborated part-of-speech system based on Chao&apos;s work [Chao, 1968]. Because it is difficult to get sufficient manualy tagged data for a large tag set, we have since switched to another electronic dictionary with some 90,000 entries and a much smaller tag set. The dictionary is actually a bilingual one (ChineseEnglish) developed by Behavior Design Corporation [BDC, 1992]. The </context>
</contexts>
<marker>Bai, Xia, 1991</marker>
<rawString>Shuanhu Bai and Ying Xia. A Scheme for Tagging Chinese Running Text. In Proceedings of Natural Language Processing Pacific Rim Symposium, pages 345-350, Singapore, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew David Beale</author>
</authors>
<title>Lexicon and Grammar in Probabilistic Tagging of written English,</title>
<date>1988</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>211--216</pages>
<location>Buffalo,</location>
<contexts>
<context position="2928" citStr="Beale, 1988" startWordPosition="421" endWordPosition="422">ated syntactical and semantic analyses [Chen, 1988]. Recent research advances may lead to the development of viable book indexing methods for Chinese books. These include the availability of efficient and high precision word segmentation methods for Chinese text [Chang et al., 1991; Sproat and Shih, 1990; Wang et al., 1990], the availability of statistical analysis of a Chinese corpus [Liu et al., 1975] and large-scale electronic Chinese dictionaries with partof-speech inforznation [Chang et al., 1988; BDC, 1992], the corpus-based statistical part-of-speech tagger [Church, 1988; DeRose, 1988; Beale, 1988], as well as phrasal and clausal analyzers [Church 1988; Ejerhed 1990] 2. Problem description As being pointed out in [Salton, 1988], back-of-book indexes may consist of more than one word that are derived from a noun phrase. Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese [Tang, 1977]. Before phr</context>
<context position="11880" citStr="Beale 1988" startWordPosition="1815" endWordPosition="1816">or the existence of a surname 2.2.1. forming possible combinations of the surname-name 2.2.2. evaluating the probability of each combination 3. Post the constraints of the CSP and probability for each hypothesized word 4. Solve the CSP 5. Find the most probable solution to CSP through dynamic programming 3.2. Part-of-speech Tagging As far as we know, there has been only scarce research done on part-of-speech tagging for Chinese [Chang et al., 1988; Chen, 1991; Bai and Xia, 1991; BDC, 1992]. As for English, there are at least three independently developed 149 taggers [Church 1988; DeRose 1988; Beale 1988]. We started out using an electronic dictionary [Chen; 1991; Chang et al., 1988] with a very elaborated part-of-speech system based on Chao&apos;s work [Chao, 1968]. Because it is difficult to get sufficient manualy tagged data for a large tag set, we have since switched to another electronic dictionary with some 90,000 entries and a much smaller tag set. The dictionary is actually a bilingual one (ChineseEnglish) developed by Behavior Design Corporation [BDC, 1992]. The list of part-of-speeches is shown in Figure 3. The algorithm is essentially the same as [DeRose, 1988]. The BDC Chinese-English </context>
</contexts>
<marker>Beale, 1988</marker>
<rawString>Andrew David Beale. Lexicon and Grammar in Probabilistic Tagging of written English, In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 211-216, Buffalo, 1988.</rawString>
</citation>
<citation valid="false">
<date>1992</date>
<institution>Behavior Design Corporation. BDC Electronic ChineseEnglish Dictionary,</institution>
<location>Hsinchu, Taiwan,</location>
<marker>1992</marker>
<rawString>Behavior Design Corporation. BDC Electronic ChineseEnglish Dictionary, Hsinchu, Taiwan, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Borko</author>
</authors>
<title>Experiments in Book Indexing by Computer,</title>
<date>1970</date>
<journal>Information Storage and Retrieval,</journal>
<pages>6--1</pages>
<contexts>
<context position="1334" citStr="Borko, 1970" startWordPosition="187" endWordPosition="188">s then goes through part-ofspeech tagging and noun phrase analysis. All these analyses are done using a corpus-based statistical algorithm. Experimental results have shown satisfactory results. 1. Introduction Preparing back-of-book indexes is of vital importance to the publishing industry but is a very labor intensive task. Attempts have been made over the years to automate this procedure for the apparent benefits of cost saving, shorter preparation time, and possibility of producing more complete and consistent indexes. Early work involves using occurrence characteristics of contents words [Borko, 1970]. Later people came to realize that indexes are often multi-word terms and their generation might involve more elaborated syntactic analysis on phrasal or sentential level [Salton, 1988; Dillon and McDonald, 1983]. However, a full syntactical approach [Salton, 1988] to this task has real problem with efficiency and coverage for unrestricted text. No viable automatic solution is currently in use. Indexing Chinese books involves another severe obstacle, namely the word segmentation problem. Chinese text consists of a sequence of characters which roughly * This research was supported by ROC Nati</context>
</contexts>
<marker>Borko, 1970</marker>
<rawString>H. Borko. Experiments in Book Indexing by Computer, Information Storage and Retrieval, 6(1):5-16, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jywi-Sheng Chang</author>
<author>Chi-Dah Chen</author>
<author>Shun-Der Chen</author>
</authors>
<title>Chinese Word Segmentation through Constraint Satisfaction and Statistical Optimization,</title>
<date>1991</date>
<booktitle>In Proceedings of ROC Computational Linguistics Conference,</booktitle>
<pages>147--165</pages>
<location>Kenting, Taiwan,</location>
<note>(in Chinese).</note>
<marker>Chang, Chen, Shun-Der Chen, 1991</marker>
<rawString>Jywi-Sheng Chang, Chi-Dah Chen, and Shun-Der Chen. Chinese Word Segmentation through Constraint Satisfaction and Statistical Optimization, In Proceedings of ROC Computational Linguistics Conference, pages 147-165, Kenting, Taiwan, 1991, (in Chinese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jyan-Sheng Chang</author>
<author>Ying Chen Shun-Der Chen</author>
<author>John S Liu</author>
<author>Sue-Jin Ker</author>
</authors>
<title>A Multiple-corpus Approach to Identification of Chinese Surname-Names,</title>
<date>1991</date>
<booktitle>In Proceedings of Natural Language Processing Pacific Rim Symposium,</booktitle>
<pages>87--91</pages>
<marker>Chang, Shun-Der Chen, Liu, Ker, 1991</marker>
<rawString>Jyan-Sheng Chang, Shun-Der Chen, Ying Chen, John S. Liu, and Sue-Jin Ker. A Multiple-corpus Approach to Identification of Chinese Surname-Names, In Proceedings of Natural Language Processing Pacific Rim Symposium, pages 87-91, Singapore, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li-Li Chang</author>
</authors>
<title>Part-of-Speech Analysis for Mandarin Chih-Dah Chen. Segmentation and Part-of-speech Tagging for Chinese, master thesis,</title>
<date>1991</date>
<institution>National Tsing-Hua University,</institution>
<location>Hsinchu, Taiwan,</location>
<marker>Chang, 1991</marker>
<rawString>Li-Li Chang et al. Part-of-Speech Analysis for Mandarin Chih-Dah Chen. Segmentation and Part-of-speech Tagging for Chinese, master thesis, National Tsing-Hua University, Hsinchu, Taiwan, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Jiann Chen</author>
<author>Chu-Ren Huang</author>
</authors>
<title>Word Classifications and Grammatical Representation in Chinese,</title>
<date>1991</date>
<note>manuscript,</note>
<marker>Chen, Huang, 1991</marker>
<rawString>Keh-Jiann Chen and Chu-Ren Huang, Word Classifications and Grammatical Representation in Chinese, manuscript, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keh-Jiann Chen</author>
</authors>
<title>Problems and Strategies in Parsing Chinese Sentences - A Tutorial,</title>
<date>1988</date>
<booktitle>In Proceedings of ROC Computational Linguistics Workshop,</booktitle>
<location>Sitou, Taiwan,</location>
<contexts>
<context position="2367" citStr="Chen, 1988" startWordPosition="339" endWordPosition="340">involves another severe obstacle, namely the word segmentation problem. Chinese text consists of a sequence of characters which roughly * This research was supported by ROC National Science Council under Contract NSC 81-0408-E-007-529. Sur-Jin Ker Department of Computer Science SooChow University John S. Liu Software Research Office Sampo Research Institute correspond to letters in English. However, there are no spaces to mark the beginning and end of a word as in English. Until recently, this problem has been considered difficult to solve without elaborated syntactical and semantic analyses [Chen, 1988]. Recent research advances may lead to the development of viable book indexing methods for Chinese books. These include the availability of efficient and high precision word segmentation methods for Chinese text [Chang et al., 1991; Sproat and Shih, 1990; Wang et al., 1990], the availability of statistical analysis of a Chinese corpus [Liu et al., 1975] and large-scale electronic Chinese dictionaries with partof-speech inforznation [Chang et al., 1988; BDC, 1992], the corpus-based statistical part-of-speech tagger [Church, 1988; DeRose, 1988; Beale, 1988], as well as phrasal and clausal analy</context>
<context position="9715" citStr="Chen, 1988" startWordPosition="1467" endWordPosition="1468">correct segmentation is crucial to automatic generation of back-of-book indexes. The difficulties involved in handling proper names are due to the following: (1) No apparent punctuation marking is given like capitalization in English. (2). Most of characters in proper names have different usage. So this problem has been held impossible to solve in the segmentation process. And it was suggested that proper names are best left untouched in the segmentation process and rely on syntactical and semantic analysis to solve the problem when nothing can be made out of the characters representing them [Chen, 1988]. Using the corpus-based statistical approach, we have shown that it is possible to identify most Chinese surname-names (A without using explicit syntactical or semantic representation. Most surnames are single character and some rare ones are of two characters (single-surnames and doublesurnames). Names can be either one or two characters (single-names and double-names). Some characters are more often used for names than others. Currently, there are more double-names than single-name in Taiwan. The formation of hypothesized surname-names is triggered by the recognition of a surname. In the e</context>
</contexts>
<marker>Chen, 1988</marker>
<rawString>Keh-Jiann Chen. Problems and Strategies in Parsing Chinese Sentences - A Tutorial, In Proceedings of ROC Computational Linguistics Workshop, Sitou, Taiwan, September, 1988, pp. 19-24, (in Chinese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
</authors>
<title>A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text.</title>
<date>1988</date>
<booktitle>In Proceedings of Second Conference on Applied Natural Language Processing,</booktitle>
<pages>136--143</pages>
<location>Austin,</location>
<contexts>
<context position="2901" citStr="Church, 1988" startWordPosition="417" endWordPosition="418">cult to solve without elaborated syntactical and semantic analyses [Chen, 1988]. Recent research advances may lead to the development of viable book indexing methods for Chinese books. These include the availability of efficient and high precision word segmentation methods for Chinese text [Chang et al., 1991; Sproat and Shih, 1990; Wang et al., 1990], the availability of statistical analysis of a Chinese corpus [Liu et al., 1975] and large-scale electronic Chinese dictionaries with partof-speech inforznation [Chang et al., 1988; BDC, 1992], the corpus-based statistical part-of-speech tagger [Church, 1988; DeRose, 1988; Beale, 1988], as well as phrasal and clausal analyzers [Church 1988; Ejerhed 1990] 2. Problem description As being pointed out in [Salton, 1988], back-of-book indexes may consist of more than one word that are derived from a noun phrase. Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chine</context>
<context position="11855" citStr="Church 1988" startWordPosition="1811" endWordPosition="1812">robability 2.2. checking for the existence of a surname 2.2.1. forming possible combinations of the surname-name 2.2.2. evaluating the probability of each combination 3. Post the constraints of the CSP and probability for each hypothesized word 4. Solve the CSP 5. Find the most probable solution to CSP through dynamic programming 3.2. Part-of-speech Tagging As far as we know, there has been only scarce research done on part-of-speech tagging for Chinese [Chang et al., 1988; Chen, 1991; Bai and Xia, 1991; BDC, 1992]. As for English, there are at least three independently developed 149 taggers [Church 1988; DeRose 1988; Beale 1988]. We started out using an electronic dictionary [Chen; 1991; Chang et al., 1988] with a very elaborated part-of-speech system based on Chao&apos;s work [Chao, 1968]. Because it is difficult to get sufficient manualy tagged data for a large tag set, we have since switched to another electronic dictionary with some 90,000 entries and a much smaller tag set. The dictionary is actually a bilingual one (ChineseEnglish) developed by Behavior Design Corporation [BDC, 1992]. The list of part-of-speeches is shown in Figure 3. The algorithm is essentially the same as [DeRose, 1988].</context>
</contexts>
<marker>Church, 1988</marker>
<rawString>Kenneth Ward Church. A Stochastic Parts Program and Noun Phrase Parser for Unrestricted Text. In Proceedings of Second Conference on Applied Natural Language Processing, pages 136-143, Austin, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven J DeRose</author>
</authors>
<title>Grammatical Category Disambiguation by Statistical Optimization,</title>
<date>1988</date>
<journal>Computational Linguistics,</journal>
<pages>14--1</pages>
<location>Winter</location>
<contexts>
<context position="2915" citStr="DeRose, 1988" startWordPosition="419" endWordPosition="420">without elaborated syntactical and semantic analyses [Chen, 1988]. Recent research advances may lead to the development of viable book indexing methods for Chinese books. These include the availability of efficient and high precision word segmentation methods for Chinese text [Chang et al., 1991; Sproat and Shih, 1990; Wang et al., 1990], the availability of statistical analysis of a Chinese corpus [Liu et al., 1975] and large-scale electronic Chinese dictionaries with partof-speech inforznation [Chang et al., 1988; BDC, 1992], the corpus-based statistical part-of-speech tagger [Church, 1988; DeRose, 1988; Beale, 1988], as well as phrasal and clausal analyzers [Church 1988; Ejerhed 1990] 2. Problem description As being pointed out in [Salton, 1988], back-of-book indexes may consist of more than one word that are derived from a noun phrase. Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese [Tang, 1977</context>
<context position="11868" citStr="DeRose 1988" startWordPosition="1813" endWordPosition="1814">2. checking for the existence of a surname 2.2.1. forming possible combinations of the surname-name 2.2.2. evaluating the probability of each combination 3. Post the constraints of the CSP and probability for each hypothesized word 4. Solve the CSP 5. Find the most probable solution to CSP through dynamic programming 3.2. Part-of-speech Tagging As far as we know, there has been only scarce research done on part-of-speech tagging for Chinese [Chang et al., 1988; Chen, 1991; Bai and Xia, 1991; BDC, 1992]. As for English, there are at least three independently developed 149 taggers [Church 1988; DeRose 1988; Beale 1988]. We started out using an electronic dictionary [Chen; 1991; Chang et al., 1988] with a very elaborated part-of-speech system based on Chao&apos;s work [Chao, 1968]. Because it is difficult to get sufficient manualy tagged data for a large tag set, we have since switched to another electronic dictionary with some 90,000 entries and a much smaller tag set. The dictionary is actually a bilingual one (ChineseEnglish) developed by Behavior Design Corporation [BDC, 1992]. The list of part-of-speeches is shown in Figure 3. The algorithm is essentially the same as [DeRose, 1988]. The BDC Chin</context>
</contexts>
<marker>DeRose, 1988</marker>
<rawString>Steven J. DeRose. Grammatical Category Disambiguation by Statistical Optimization, Computational Linguistics, 14(1):31-39, Winter 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rina Dechter</author>
<author>Judea Pearl</author>
</authors>
<title>Network-Based Heuristics for Constraint-Satisfaction Problems,</title>
<date>1988</date>
<journal>J. of Artificial Intelligence</journal>
<pages>34--1</pages>
<marker>Dechter, Pearl, 1988</marker>
<rawString>Rina Dechter and Judea Pearl, 1988, Network-Based Heuristics for Constraint-Satisfaction Problems, J. of Artificial Intelligence 34(1):1-38, 1988. M. Dillon and L.K. McDonald. Fully Automatic Book Indexing, Journal of Documentation, 39(3):135-154, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva I Ejerhed</author>
</authors>
<title>Finding Clauses in Unrestricted Text by Finitary and Stochastic Methods,</title>
<date>1988</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>219--227</pages>
<location>Austin,</location>
<marker>Ejerhed, 1988</marker>
<rawString>Eva I. Ejerhed. Finding Clauses in Unrestricted Text by Finitary and Stochastic Methods, In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 219-227, Austin, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In-mao Liu</author>
</authors>
<title>Frequency Counts of Chinese Words,</title>
<date>1975</date>
<publisher>Lucky Book Co.,</publisher>
<location>Taipei, Taiwan,</location>
<marker>Liu, 1975</marker>
<rawString>In-mao Liu et al. Frequency Counts of Chinese Words, Lucky Book Co., Taipei, Taiwan, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
</authors>
<title>Syntactical Approaches to Automatic Book Indexing,</title>
<date>1988</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>204--210</pages>
<contexts>
<context position="1520" citStr="Salton, 1988" startWordPosition="214" endWordPosition="215">results. 1. Introduction Preparing back-of-book indexes is of vital importance to the publishing industry but is a very labor intensive task. Attempts have been made over the years to automate this procedure for the apparent benefits of cost saving, shorter preparation time, and possibility of producing more complete and consistent indexes. Early work involves using occurrence characteristics of contents words [Borko, 1970]. Later people came to realize that indexes are often multi-word terms and their generation might involve more elaborated syntactic analysis on phrasal or sentential level [Salton, 1988; Dillon and McDonald, 1983]. However, a full syntactical approach [Salton, 1988] to this task has real problem with efficiency and coverage for unrestricted text. No viable automatic solution is currently in use. Indexing Chinese books involves another severe obstacle, namely the word segmentation problem. Chinese text consists of a sequence of characters which roughly * This research was supported by ROC National Science Council under Contract NSC 81-0408-E-007-529. Sur-Jin Ker Department of Computer Science SooChow University John S. Liu Software Research Office Sampo Research Institute cor</context>
<context position="3060" citStr="Salton, 1988" startWordPosition="442" endWordPosition="443">ethods for Chinese books. These include the availability of efficient and high precision word segmentation methods for Chinese text [Chang et al., 1991; Sproat and Shih, 1990; Wang et al., 1990], the availability of statistical analysis of a Chinese corpus [Liu et al., 1975] and large-scale electronic Chinese dictionaries with partof-speech inforznation [Chang et al., 1988; BDC, 1992], the corpus-based statistical part-of-speech tagger [Church, 1988; DeRose, 1988; Beale, 1988], as well as phrasal and clausal analyzers [Church 1988; Ejerhed 1990] 2. Problem description As being pointed out in [Salton, 1988], back-of-book indexes may consist of more than one word that are derived from a noun phrase. Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese [Tang, 1977]. Before phrasal analysis can be performed, the text must go through the more fundamental morphological and partof-speech analysis. The morpholo</context>
<context position="13225" citStr="Salton, 1988" startWordPosition="2027" endWordPosition="2028">of part-of-speech are estimated from a manually tagged text of about 4,000 words. 3.3. Finding Noun Phrases Instead of using a full-blown parser to find noun phrases, we first mark the noun phrases in the same text of about 4,000 words and compute the statistical characteristics of categoric patterns of noun phrase and then use the statistics in a stochastic algorithm for finding noun phrases in a manner similar to [Church 1988; Ejerhed 1990]. Extracting keywords from a noun phrase is somewhat heuristic unlike the rigorous approach of using the syntactical structure within the noun phrase in [Salton, 1988]. 4. The Experimental Results The algorithm described in Section 3 is currently under development and the programs are written in C and ProFox, and run on an IBM PC compatible machine. The segmentation, tagging, and NP identification parts are completed, while the statistical analysis of the occurrence of NPs is being implemented now. The statistics used in the system consists of four parts: (SI) Appearance counts of 40,032 distinct words from a corpus of 1,000,000 words of Chinese text [Liu el al., 1975]. (S2) The BDC Chinese-English Dictionary [BDC, 1992]. (S3) A general corpus of 300,000 w</context>
</contexts>
<marker>Salton, 1988</marker>
<rawString>Gerard Salton. Syntactical Approaches to Automatic Book Indexing, In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 204-210, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Chilin Shih</author>
</authors>
<title>A Statistical Method for Finding Word Boundaries in Chinese Text,</title>
<date>1990</date>
<booktitle>Journal of Computer Processing of Chinese and Oriental Languages,</booktitle>
<pages>4--4</pages>
<contexts>
<context position="2622" citStr="Sproat and Shih, 1990" startWordPosition="376" endWordPosition="379">Ker Department of Computer Science SooChow University John S. Liu Software Research Office Sampo Research Institute correspond to letters in English. However, there are no spaces to mark the beginning and end of a word as in English. Until recently, this problem has been considered difficult to solve without elaborated syntactical and semantic analyses [Chen, 1988]. Recent research advances may lead to the development of viable book indexing methods for Chinese books. These include the availability of efficient and high precision word segmentation methods for Chinese text [Chang et al., 1991; Sproat and Shih, 1990; Wang et al., 1990], the availability of statistical analysis of a Chinese corpus [Liu et al., 1975] and large-scale electronic Chinese dictionaries with partof-speech inforznation [Chang et al., 1988; BDC, 1992], the corpus-based statistical part-of-speech tagger [Church, 1988; DeRose, 1988; Beale, 1988], as well as phrasal and clausal analyzers [Church 1988; Ejerhed 1990] 2. Problem description As being pointed out in [Salton, 1988], back-of-book indexes may consist of more than one word that are derived from a noun phrase. Given the text of a book, an indexing system, must perform some kin</context>
</contexts>
<marker>Sproat, Shih, 1990</marker>
<rawString>Richard Sproat and Chilin Shih, A Statistical Method for Finding Word Boundaries in Chinese Text, Journal of Computer Processing of Chinese and Oriental Languages, 4(4):336-351, March, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ting-chi Tang</author>
</authors>
<title>Studies in Transformational Grammar of Chinese, Volume I. Movement Transformations,</title>
<date>1977</date>
<publisher>Student Book Co.,</publisher>
<location>Taipei,</location>
<note>(in Chinese).</note>
<contexts>
<context position="3515" citStr="Tang, 1977" startWordPosition="519" endWordPosition="520">Rose, 1988; Beale, 1988], as well as phrasal and clausal analyzers [Church 1988; Ejerhed 1990] 2. Problem description As being pointed out in [Salton, 1988], back-of-book indexes may consist of more than one word that are derived from a noun phrase. Given the text of a book, an indexing system, must perform some kind of phrasal and statistical analysis in order to produce a list of candidate indexes and their occurrence statistics in order to generate indexes as shown in Figure 1 which is an excerpt from the reconstruction of indexes of a book on transformational grammar for Mandarin Chinese [Tang, 1977]. Before phrasal analysis can be performed, the text must go through the more fundamental morphological and partof-speech analysis. The morphological analysis for Chinese text is mainly a so-called word segmentation process, which segments a sequence of Chinese character into a sequence of words. See Figure 2 for illustration. The noun phrase generation process described in this paper is based on a corpus-based statistical analysis and does not use an explicit syntactical representation. Examples of noun phrases found are underlined as shown in Figure 2. 147 MNI[liangci] measure word [lienci]</context>
</contexts>
<marker>Tang, 1977</marker>
<rawString>Ting-chi Tang. Studies in Transformational Grammar of Chinese, Volume I. Movement Transformations, Taipei, Student Book Co., 1977, (in Chinese).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>