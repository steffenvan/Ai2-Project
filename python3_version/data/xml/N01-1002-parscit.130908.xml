<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000481">
<title confidence="0.875079">
Corpus-based NP Modifier Generation
</title>
<author confidence="0.966095">
Hua Cheng and Massimo Poesio and Renate Henschelt and Chris Mellish
</author>
<affiliation confidence="0.998823">
Division of Informatics, University of Edinburgh
</affiliation>
<email confidence="0.96116">
thuac,poesiol@cogsci.ed.ac.uk, chrism@dai.ed.ac.uk
</email>
<affiliation confidence="0.55681">
tUniversity of Bremen
</affiliation>
<email confidence="0.396388">
rhenschel@uni-bremen . de
</email>
<sectionHeader confidence="0.978429" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999756">
This paper describes how we annotated and
analysed the NP modifiers in a corpus of mu-
seum descriptions to discover rules for the se-
lection and realisation of such modifiers, in par-
ticular non-referring ones. We implemented the
regularities into an extension of the ILEX sys-
tem to generate complex NPs capable of serving
multiple communicative goals.
</bodyText>
<sectionHeader confidence="0.980099" genericHeader="categories and subject descriptors">
1 Introduction and Motivation
</sectionHeader>
<subsectionHeader confidence="0.971062">
1.1 Generating Complex NPs
</subsectionHeader>
<bodyText confidence="0.998290953125">
In addition to a referring function, noun phrases
(NP) can also serve communicative goals such
as providing new information about the refer-
ent and expressing the speaker&apos;s emotional at-
titude towards the referent (Appelt, 1985; Jor-
dan, 2000). In Example (1) below, the part in
italics refers to an object in a museum, and the
part in boldface provides additional information
about it.
(1) This example from the time of the Qianlong
Emperor 1736-95 is made of lacquered wood with
decoration in gold and red.
Such complex NPs appear frequently in hu-
man written texts. A natural language genera-
tion (NLG) system must be able to produce com-
plex NPs serving multiple goals in order to write
texts as humans do. We divide the components
of an NP into two parts based on the different
functions/communicative goals they serve:
a referring part : intends to refer to an object,
but not necessarily to identify, that is, the
expression denotes an individual object of a
certain class, but it might not be necessary
to know the exact object. The italic part of
(1) gives an example. This part is normally
the task of the NP generation module of an
NLG system.
a non-referring part : intends to provide addi-
tional information about the referent de-
noted by the referring part, such as the part
of (1) in boldface. If an NLG system gen-
erates such modifiers, it usually does this
in its aggregation module, e.g. (Shaw and
McKeown, 1997; O&apos;Donnell et al., 1998).
This division is a functional one rather than
a syntactic one. Except for the head and the
determiner, which are always members of the
referring part, other NP components can belong
to different parts in different circumstances.
In NLG, research on NP generation focuses
on deciding syntactic forms and choosing dis-
ambiguating modifiers for referring, e.g. (Dale,
1992). Other types of modifiers have been given
much less attention, although proposals con-
cerning their realisation are included in gram-
mars such as NIGEL (Mann and Matthiessen,
1985). Work on aggregation is satisfied with
devising a few rules to allow some degrees of
embedding to generate subordinate NP compo-
nents. There is no in-depth discussion of the
problem of generating non-referring modifiers
in general. It has been argued that generating
such modifiers is not a trivial decision because
it interferes with the planning of both local and
global coherence (in the sense of (Grosz and
Sidner, 1986)) (Cheng and Mellish, 2000a). NP
subordination, as an alternative to sententiali-
sation, is a major way to achieve conciseness as
it reduces the number of sentences in generated
texts. However, generating arbitrarily complex
NPs is not often desirable. Therefore, achiev-
ing coherence and conciseness are two conflict-
ing considerations and conciseness should only
be satisfied under coherence constraints.
</bodyText>
<subsectionHeader confidence="0.967432">
1.2 Corpus Analysis for NLG
</subsectionHeader>
<bodyText confidence="0.984961203125">
Corpus analysis has often been used for devis-
ing rules for modifier generation, e.g. (Mann
and Matthiessen, 1985; Robin, 1994; Shaw and
McKeown, 1997). The proposals in NIGEL, in
particular, were the starting point of this work.
However, most of these analyses depend on the
intuitions of an individual researcher, which
might not be shared by other people. In ad-
dition, their analyses mainly target single sen-
tences, so the results emphasise the concise-
ness consideration and might not suit multi-
sentential text.
This paper puts emphasis on the generation
of non-referring NP modifiers in museum de-
scriptions, which provide information for items
displayed in a museum. By analysing descrip-
tions written and revised by human experts, we
wish to find out general rules for the usage of
such modifiers in the domain of museum de-
scriptions (Oberlander et al., 1998), that hope-
fully will be general enough to be applied to
other domains. Since what we will study are
coherent human texts with multiple sentences,
the NP modifiers in them are subject to both
coherence and conciseness constraints.
This work is a part of the GNOME project
(Generating NOMinal Expressions)&apos;, in which
statistical models for NP determination have
been built by training on corpora annotated
with semantic and discourse information (Poe-
sio, 2000a). Such statistical models take the
form of decision trees (Breiman et al., 1984),
which assign probabilities to different NP types
according to the input semantic and discoursal
features. The correctness of the decision trees
relies heavily on the reliability of the annota-
tion. As a result, GNOME emphasises achieving
reliable annotation, a stage which appears to
have been skipped in much other work.
In a similar way, our work aims at finding out
reliable evidence concerning the information hu-
man authors like to convey as an NP modifier
and how they realise it. However, we do not in-
tend to address the content determination prob-
lem in great detail because content selection is
usually domain specific. Our attention is in-
&apos;GNOME is a joint project between the Universities of
Brighton, Durham and Edinburgh. See (Poesio, 2000b)
for features of NPS which are marked up in the GNOME
corpus.
stead on the second problem, i.e. given a piece
of information, how it is realised in an NP. The
relevant factors might include NP forms, the se-
mantic properties of a piece of information, dis-
course properties and communicative goals.
This paper is organised as follows: Section 2
describes the features of modifiers that we stud-
ied; Section 3 analyses the annotated corpus,
including the reliabilities of feature annotation
and the regularities for modifier content selec-
tion and realisation; Section 4 describes the im-
plementation of our observations in an NLG sys-
tem; and finally in Section 5, we propose some
future work.
</bodyText>
<sectionHeader confidence="0.95516" genericHeader="method">
2 Features of NP Modifiers
</sectionHeader>
<bodyText confidence="0.996394">
We have identified three main features for each
NP modifier, which are:
</bodyText>
<listItem confidence="0.9976505">
• The pragmatic feature pragm: why is a
modifier used in an NP?
• The semantic feature sem: which property
of the entity denoted by an NP is expressed
as a modifier in that NP?
• The realisation feature type: which syntac-
</listItem>
<bodyText confidence="0.988339756521739">
tic position is assigned to a given property
in an NP? e.g. prenominal or postnominal,
adjectival or as a relative clause.
Through corpus annotation, we wish to an-
swer the question of what will be the probabil-
ity of a given piece of information occupying a
given syntactic position (a value of type) on the
basis of the semantic and pragmatic properties
of that information and relevant NP features,
for example, whether a certain color attribute
should be expressed by means of a prenominal
adjective or a prepositional phrase in a definite
NP. Notice that it is not possible to use cor-
pus annotation to determine the likelihood of
a given property to be chosen, unless we know
in advance all of the properties that can be at-
tributed to a given object, as in the case of Jor-
dan&apos;s work on the COCONUT domain (Jordan,
2000). Below we briefly introduce the major
values of the three modifier features.
Pragm We observed three modifier functions
in NPs. Firstly, a modifier may specify proper-
ties that uniquely identify the objects or con-
cepts denoted by an NP, i.e. components of the
referring part of an NP. We call such modifiers
uniq modifiers; most modifiers in generic refer-
ences are of this type.
Secondly, a modifier may not be used to con-
strain a unique or unambiguous concept out of
an NP which is either already unique or not
required to have a unique interpretation, but
may be important to the situation presented in
the main proposition containing the NP. We
call this type int modifiers2; they include many
modifiers in indefinite predicative phrases.
Finally, a modifier may be included to pro-
vide additional details about the referent of an
NP which, however, would successfully function
the same way as the NP without these modifiers.
We call them attr modifiers. The effect of such
modifiers is usually local to the heads they de-
scribe rather than to the main propositions as
a whole. This is the main difference between
attr and int modifiers.
The last two types of modifiers form the non-
referring part of an NP. This paper emphasises
attr modifiers and addresses uniq ones to show
the differences between them.
Sem Our values of sem are based on the lin-
guistic literature, e.g. (Levi, 1978; Quirk et al.,
1985; Meyer, 1992). These values are also in-
tended as a refinement of the semantic charac-
terisations of the modifying relations in NIGEL
(Mann and Matthiessen, 1985), where a corre-
lation between certain semantic properties and
the positions of modifiers is proposed. One
of the modifications to this previous work was
to use WordNet (Fellbaum, 1998) to make our
values more standard and improve reliability.
Some sem values are listed in Table 1, where
the numbers are the WordNet sense numbers
for these particular concepts.
These values mainly target prepositional
phrases and nouns, not adjectives. For an
adjective, we use WordNet to derive its cate-
gory rather than directly assigning a predefined
value. In WordNet, if an adjective ascribes a
value to a noun concept, e.g. round gives a
value of shape, WordNet will contain a pointer
between the adjective and the noun by which
the appropriate attribute is lexicalised, e.g. be-
tween round and shape. Using WordNet, anno-
tating the sem feature of an adjective involves
first choosing the correct sense for the adjective
2Some descriptions of int modifiers can be found in
(Cheng and Mellish, 2000b).
and then mapping the word sense to a noun
concept in the WordNet ontology. Satisfactory
agreement among human subjects on choosing
senses for words has been recorded (Fellbaum,
1998) and the mapping to nouns can be done
automatically. So this approach is considerably
better than manually assigning values.
There is a tradeoff between the number of
values and the achievable agreement on feature
annotation because the more values a feature
has, the less agreement the annotation can ex-
pect to achieve. To avoid having too many cate-
gories, we use more general concepts like one of
the following (as defined in WordNet) to mark
the sem feature of an adjective. For example,
round in the round table would be marked as
spatial-property1, which subsumes the shape
concept.
temporal-property1 : a property relating to
time. For modifiers like earlier, final.
visual-property1 : attributes of vision, in-
cluding texture, lightness, colour, etc. For
modifiers like red, dark, superfine.
spatial-property1 : any property relating to
or occupying space, including dimensional-
ity, shape, form, etc. e.g. round, hollow.
quality1 : an essential and distinguishing at-
tribute of something or someone.
Type The values of this attribute specify the
syntactic characterisations of modifiers, and in-
clude appos (appositive modifiers), poss (pos-
sessive determiners), preadj (adjectives before
the head), prenoun (modifiers in the form of
noun or noun compound before the head),
postprep (prepositional phrases), postpart
(present and past participles after the head),
postnp (non-appositive modifiers in the form of
noun phrase after the head) and rel-cls (rela-
tive clauses).
</bodyText>
<sectionHeader confidence="0.99739" genericHeader="method">
3 Results of Corpus Analysis
</sectionHeader>
<bodyText confidence="0.981162857142857">
We wrote an annotation scheme manual for
annotating NP modifiers, describing which el-
ements of an NP should be marked as modifiers
and how to mark their features. XML is used
as the markup language. We trained two anno-
tators to mark the NP modifiers in the GNOME
corpus according to the manual and measured
spatial positioning, for modifiers indicating where the object denoted by a head is
located in physical space, including its origin, e.g.
a pattern of brass and pewter on a tortoiseshell ground
temporal positioning, for modifiers that indicate the time period the object de-
noted by the head is located, e.g. Louis XIV&apos;s possessions in 1720
cases where the modifier indicates the material of/from which the object denoted
by the head is made, e.g. This table&apos;s marquetry of ivory and horn
cases where the modifier names or identifies the referent of the head. The object
denoted by the modifier is more specific than that denoted by the head, e.g.
the practice of veneering furniture with marquetry of pewter and brass
cases where the modifier &amp;quot;paraphrases&amp;quot; the lexical content of the head. In this
case, the modifier and the head are equally specific and of the same type, e.g.
high blood pressure (hypertension)
cases where the modifier provides general &amp;quot;characteristics&amp;quot; of the object denoted
by the head, e.g. Finnish artist Janna Syvanoja
cases in which the modifier occupies the subject or object role of the action denoted
by the head, e.g. the boy&apos;s application (the boy applied for ...), the boy&apos;s release
(... released the boy)
possessive relations between the object(s) denoted by the head and the object(s)
denoted by the NP in the modifier in a general sense. The relations include such
subtypes as whole/part, type/instance, owner/owned etc., e.g.
</bodyText>
<figure confidence="0.356481909090909">
desks with interiors, the name of the maker
location1
time-period1
material1
identify2
rephrase 1
characterize1
sub j ect7 or
obj ect3
possess or
possinv
</figure>
<tableCaption confidence="0.995889">
Table 1: Predefined semantic categories of modifiers
</tableCaption>
<bodyText confidence="0.9998504">
their agreement on a small part of the corpus.
The annotated corpus contains 1863 modifiers.
Using the annotated corpus, we could discover
regularities in the usage of NP modifiers and de-
sign modifier generation algorithms.
</bodyText>
<subsectionHeader confidence="0.999833">
3.1 Agreement on Annotation
</subsectionHeader>
<bodyText confidence="0.997528">
We used the kappa coefficient (K) (Siegel and
Castellan, 1988) to calculate the agreement be-
tween annotators. The agreement on the three
modifier features is:
</bodyText>
<table confidence="0.957125">
Features Type Pragm Sem
Agreement (K) .97 .77 .81
</table>
<bodyText confidence="0.999512133333333">
This demonstrates fairly good agreement on
type and sem and some agreement on pragm.
The agreement on pragm shows that the distinc-
tions we are trying to make are relatively clear
and human subjects can distinguish between the
different uses of NP modifiers to some extent.
The main ambiguity exists between int and
attr modifiers. There seems to be a gradual
difference between them and where to draw the
line is a bit arbitrary. Some disagreement is also
introduced by errors in the annotations of the
NP features on which the annotation of pragm
depends, e.g. logical form type and genericity3,
although good agreements have been achieved
on these features (Poesio, 2000a).
</bodyText>
<subsectionHeader confidence="0.994896">
3.2 What is Expressed as a Modifier?
</subsectionHeader>
<bodyText confidence="0.999871235294118">
Table 2 shows the distributions of the seman-
tic and syntactic features of modifiers with re-
spect to their functions4. Each cell gives the
number of modifiers found in the corpus for
each sem/type and pragm combination and what
percentage such modifiers occupy in those with
the same pragm value (vertically) and sem/type
value (horizontally).
The percentages illustrate the differences in
modifier usage. Concerning the semantic prop-
erties, characterize1, spatial-property1,
visual-property1 and rephrase1 (percent-
ages in boldface in the table) are more often
given as additional information than as other
types of information. Among the attr proper-
ties, some appear more frequently than others,
for example, in decreasing frequencies these
</bodyText>
<footnote confidence="0.887010285714286">
3 Logical form type specifies whether an NP is a quanti-
fier, term or predicative, and genericity specifies whether
the object denoted is a generic or specific reference.
4The table only lists the main semantic and syntac-
tic categories, so they do not necessarily add up to the
amount in Total. We do not include the categories with
very low frequencies.
</footnote>
<table confidence="0.999909318181818">
SEM or TYPE PRAGM
attr(%,%) unig(%,%)
location1 88(17.3,38.3) 119(12.1,51.7)
possess/-iv 59(11.6,16.4) 239(24.4,67.1)
identify2 56(11,31.5) 111(11.3,62.4)
material1 45(8.8,40.9) 52(5.3,47.3)
time-periodl 34(6.7,33.7) 58(5.9,57.4)
characterize1 33(6.5,94.3) 2(,5.7)
spatial-prop1 32(6.3,69.6) 7(45.2)
visual-prop1 21(4.1,41.2) 18(1.8,29.4)
quality1 14(2.8,8.4) 76(7.8,45.5)
rephrasel 8(1.6,100) 0
subj7/obj3 7(,6.9) 77(7.9,75.5)
temporal-prop1 3(,6.8) 32(3.3,72.7)
preadj 135(26.5,20.5) 337(34.4,51.2)
postprep 98(19.3,19.4) 293(29.9,58)
appos 77(15.1,60.2) 49(5,38.3)
postpart 66(13,54.1) 37(3.8,30.3)
prenoun 64(12.6,32.7) 105(10.7,53.6)
rel-cls 45(8.8,54.2) 18(1.8,21.7)
poss 2 124(12.6,97.6)
Total 509(27.4) 981(52.7)
</table>
<tableCaption confidence="0.882114">
Table 2: The distribution of sem and type with
respect to pragm
</tableCaption>
<bodyText confidence="0.95250468">
properties include: location1, identify2,
materia11, time-period1, characterize1,
spatial-property1 and visual-property1.
Properties such as possess/possinv,
location1, identify2, subject7/object3,
quality1, time-period1, material1 and
temporal-property1 (in decreasing frequen-
cies) tend to be used more often for referring.
This gives a possible order for selecting proper-
ties to refer to a discourse entity. It seems to
us that the semantic feature itself is far from
sufficient for deciding the use of int modifiers,
so we do not discuss them here.
Adding attr properties can cause confusion
sometimes. For example, they might be read
as referring information and confuse the reader
about the referent. Avoiding such ambiguities
in generation is important. So we rank sem val-
ues with significant preferences for serving the
attr function, e.g. characterize1, over those
occurring even more frequently as attr modi-
fiers, e.g. location1. This suggests the follow-
ing preferences for selecting attr properties to
describe a discourse entity (A B means A is
preferred over B):
</bodyText>
<equation confidence="0.983884">
rephrase1 characterize1 spatial-
property1 visual-property1
location1 identify2 material1
time-period1
</equation>
<bodyText confidence="0.999650263157895">
And the following properties should not
normally be chosen or should be down the list:
possess, possinv, quality1, subject7,
object3 and temporal-property1.
The distribution of type values in Table 2
shows that a syntactic position can be used for
any type of modifier. There is a tendency for ap-
positive components, posthead participles and
relative clauses (percentages highlighted in the
table) to be used more often for realising attr
properties, and possessive determiners, prehead
adjectives and nouns and prepositional phrases
more often for referring properties.
In addition, we have found a preference for
non-referring information to appear in discourse
new references (67.19%), including bridging de-
scriptions (21.41%). Only 11.79% of such infor-
mation appears in discourse old references and
the rest is in predicative phrases.
</bodyText>
<subsectionHeader confidence="0.995662">
3.3 How to Realise a Property?
</subsectionHeader>
<bodyText confidence="0.9998885">
To get a more precise correlation between a se-
mantic and syntactic feature, we used the wagon
CART building program developed at the Centre
for Speech Technology Research, the University
of Edinburgh to train a statistical model for de-
ciding the syntactic form of a property given its
semantic and pragmatic features. We also in-
cluded the cat feature of the NP in which the
property is realised, specifying its type (proper
name, definite NP, pronoun, etc.) (Poesio,
2000b) as an approximation of the semantic and
discourse features of the NP. The construction
of CART (Classification And Regression Trees)
is a common and powerful method for building
statistical models from simple feature data. The
program has two parts: wagon and wagon_test
which trains and tests a statistical model on
given samples respectively.
Because the size of the annotated corpus
is relatively small, we used a cross-validation
method, which divides the corpus into two
parts, 9/10s for training and 1/10 for testing.
It runs the training and testing circle for 10
times and calculates the average correct predic-
tion rate. The output of the program is a de-
cision tree, whose intermediate nodes are ques-
</bodyText>
<figure confidence="0.99509636923077">
pragm is attr
sem is possinv
sem is identify2
n
y
y
n
y
n
appos 0.75
cat is the_pn
cat is the_np
sem is quality1
y
n
y
n
y
n
appos 0.75
cat is pn
postprep 0.9263
pragm is unique
preadj 0.9726
sem is characterize1
y
n
y
n
y
n
preadj 0.6666
cat is the_np
cat is this_np
cat is the_pn
appos 0.8064
sem is location1
n
n
y
y
y
cat is pn
postprep 0.3170
appos 0.3333
postprep 1
poss 0.5
y n
preadj 0.6666 prenoun 0.5
y
pragm is unique
n
pragm is attr
y
n
n
y
n
y
postprep 0.5
postnp 0.5714
cat is another_np
prenoun 0.4285
preadj 0.5
postprep 0.7464
</figure>
<table confidence="0.954106615384616">
postpart, the global success rate would be 75%.
Type Accuracy Rates
Museum Texts Patient Leaflets
Total Percent Total Percent
appos 124 88.70% 9 77.78%
poss 154 88.31% 55 98.18%
preadj 570 82.10% 59 96.61%
postprep 402 71.64% 44 63.64%
postnp 38 63.15% 2 0%
prenoun 226 45.13% 35 45.71%
postpart 110 25.45% 6 33.33%
rel-cis 74 0% 8 0%
overall 1698 67.5% 218 75%
</table>
<tableCaption confidence="0.999935">
Table 3: The accuracy rates with respect to type
</tableCaption>
<bodyText confidence="0.998745272727273">
The decision tree shows that pragm also plays
a role in modifier realisation. This means that
there are cases where modifier usage determines
or correlates with the syntactic positioning of
modifiers. However, it is difficult to single out
its effect because of the complex dependencies
between sem, pragm and cat.
In Section 4, we will show how the results dis-
cussed in this section can be employed in algo-
rithms for making decisions concerning content
selection and realisation of NP modifiers.
</bodyText>
<subsectionHeader confidence="0.873086">
3.4 Domain Independence
</subsectionHeader>
<bodyText confidence="0.99520775">
The approach we have used allows us to test the
realisation model on a different domain as long
as there is an annotated corpus for that domain.
We annotated a small corpus of patient infor-
mation leaflets, which give instructions on how
to use certain drugs. The average success rate
of our decision tree in syntactic form prediction
in this domain is 75% and its decomposition is
given in the last column of Table 3. In gen-
eral, our model is portable to this new domain.
Some degradation in accuracy might be due to
the small size of the test sample.
Often the same semantic property can be re-
alised in many different ways, whereas Table 3
counts only one of them as correct. If instead re-
alisations with equal probability are all treated
as correct choices, the accuracy rate could be
higher. However, we do not know whether such
realisations are indeed favoured equally by hu-
mans, unless a separate experiment is carried
out. So we did not consider such cases in cal-
culating the accuracy. In addition, higher accu-
racy rate might also be achieved by training on
a larger annotated corpus.
</bodyText>
<sectionHeader confidence="0.947423" genericHeader="method">
4 Implementation in ILEX
</sectionHeader>
<bodyText confidence="0.9999525">
We used the results discussed above in an ex-
tension of the ILEX system (Oberlander et al.,
1998), which adaptively generates online de-
scriptions of museum objects. ILEX uses a mod-
ularised pipeline architecture, which consists
of such modules as content selection, content
structuring, text realisation, post-processing
and presentation. The content of an NP is de-
termined in the post-processing module by the
NP generation and aggregation processes. This
architecture allows us to substitute the original
ILEX NP module with a new module which we
call GNOME-edi.
GNOME-edi not only determines the form
of an NP, but also generates several types of
modifiers, including adjectives, prepositional
phrases, relative clauses and appositive modi-
fiers. It can generate disambiguation modifiers
as well as modifiers providing additional infor-
mation about a discourse entity.
The interface between GNOME-edi and the
ILEX text realisation module includes an
agenda, which specifies the information that
should be included in the NP to be generated ac-
cording to the aggregation component. There-
fore the choice of NP forms takes into account
aggregation considerations. GNOME-edi first de-
termines the NP type, then chooses referring
modifiers (i.e. modifiers that function the same
as those marked as pragm = uniq in the cor-
pus) and finally decides if more information can
be expressed in the NP (i.e. modifiers that func-
tion the same as those marked as pragm = attr
in the corpus). In other words, the NP genera-
tion module decides a modifier function that is
needed in an NP and then chooses a property
and realisation that can fulfill this function.
The generation of non-referring modifiers
needs to consider such factors as NP types, the
semantic feature of a property and the availabil-
ity of syntactic slots around the NP head5. The
selection of non-referring properties starts with
the preferred ones (given in Section 3.2). If the
discourse entity being realised has such a prop-
erty, it is mapped to a syntactic form preferred
by the decision tree in Figure 1. This process
</bodyText>
<footnote confidence="0.974683">
5We assume fixed number of modifiers in an NP, e.g.
three before the head and two after.
</footnote>
<bodyText confidence="0.999729777777778">
continues until there is no more free slot around
the head or preferred properties to be added.
Using GNOME-edi, ILEX is able to produce, in
a globally coherent text, sentences like: This
jewel is a necklace and was made by the im-
portant designer Jessie King from Scotland. In
this example, identify2 (Jessie King) is a re-
ferring property and is realised as an appositive
modifier (the second preferred realisation) be-
cause it does not have a PP form. Properties
of locationl (Scotland) and qualityl (impor-
tant) are chosen as non-referring modifiers and
their realisations follow the decision tree (high-
lighted in Figure 1). The original ILEX NP mod-
ule would however produce the phrase an impor-
tant Scottish designer called Jessie King, where
the realisation of the identify2 property is not
supported by our corpus analysis.
</bodyText>
<sectionHeader confidence="0.99813" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999994714285714">
This paper describes how we annotated and
analysed the NP modifiers in a corpus of mu-
seum descriptions to discover rules for the se-
lection and realisation of such modifiers, in par-
ticular non-referring ones. We implemented the
regularities into an extension of the ILEX sys-
tem to generate complex NPs capable of serving
multiple communicative goals.
The work described here can be improved in
many ways. A more fine-grained analysis of the
annotated corpus is needed. We should also
try to increase the size of the annotated cor-
pus for training statistical models, which might
help achieving higher accuracy rate.
</bodyText>
<sectionHeader confidence="0.999412" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998906263888889">
D. Appelt. 1985. Planning English referring expres-
sions. Artificial Intelligence, 26:1-33.
L. Breiman, J. Friedman, R. Olshen, and C. Stone.
1984. Classification and Regression Trees. Bel-
mont, Calif.: Wadsworth International.
H. Cheng and C. Mellish. 2000a. Capturing the in-
teraction between aggregation and text planning
in two generation systems. In Proceedings of the
1st International Conference on Natural Language
Generation, pages 186-193, Israel.
H. Cheng and C. Mellish. 2000b. An empirical anal-
ysis of constructing non-restrictive np components
to express semantic relations. In Proceedings of
the 1st International Conference on Natural Lan-
guage Generation, Israel.
R. Dale. 1992. Generating Referring Expressions:
Constructing Descriptions in a Domain of Objects
and Processes. The MIT Press.
C. Fellbaum, editor. 1998. WordNet: An Electronic
Lexical Database. The MIT Press.
B. Grosz and C. Sidner. 1986. Attentions, inten-
tions and the structure of discourse. Computa-
tional Linguistics, 12:175-204.
P. Jordan. 2000. Can nominal expressions achieve
multiple goals? an empirical study. In Proceed-
ings of the 38th Annual Meeting of Association for
Computational Linguistics, pages 142-149, Hong
Kong, P.R.China.
J. Levi. 1978. The Syntax and Semantics of Com-
plex Nominals. New York: Academic Press.
W. Mann and C. Matthiessen. 1985. Demonstration
of the NIGEL text generation computer program.
In James Benson and William Greaves, editors,
Systemic Perspectives on Discourse, pages 50-83.
Norwood: Ablex.
C. Meyer. 1992. Apposition in Contemporary En-
glish. Cambridge University Press, Cambridge.
J. Oberlander, M. O&apos;Donnell, A. Knott, and C. Mel-
lish. 1998. Conversation in the museum: Exper-
iments in dynamic hypermedia with the intelli-
gent labelling explorer. New Review of Hyperme-
dia and Multimedia, 4:11-32.
M. O&apos;Donnell, H. Cheng, and J. Hitzeman. 1998. In-
tegrating referring and informing in NP planning.
In Proceedings of COLING-ACL &apos;98 Workshop on
the Computational Treatment of Nominals, pages
46-56, Montreal, Canada.
M. Poesio. 2000a. Annotating a corpus to de-
velop and evaluate discourse entity realization
algorithms: Issues and preliminary results. In
Proceedings of the 2nd International Conference
on Language Resources and Evaluation (LREC),
pages 211-218, Athens, Greece.
M. Poesio. 2000b. The GNOME annotation scheme
manual. Technical Report URL: www.cogsci.ed.
ac.uk/poesio/GNOME/anno_manual_4.html, Di-
vision of Informatics, the University of Edinburgh.
R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik.
1985. A Grammar of Contemporary English.
Longman Group Ltd.
J. Robin. 1994. Revision-based Generation of Nat-
ural Language Summaries Providing Historical
Background: Corpus-based Analysis, Design, Im-
plementation and Evaluation. Ph.D. thesis, Com-
puter Science Department, Columbia University.
J. Shaw and K. McKeown. 1997. An architecture for
aggregation in text generation. In Proceedings of
the 15th International Joint Conference on Artifi-
cial Intelligence, Poster Session, Nagoya, Japan.
S. Siegel and J. Castellan. 1988. Nonpara-
metric Statistics for the Behavioral Sciences.
London:McGraw-Hill.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.698866">
<title confidence="0.995616">Corpus-based NP Modifier Generation</title>
<author confidence="0.774541">Hua Cheng</author>
<author confidence="0.774541">Massimo Poesio</author>
<author confidence="0.774541">Renate Henschelt</author>
<author confidence="0.774541">Chris</author>
<affiliation confidence="0.836016">Division of Informatics, University of</affiliation>
<abstract confidence="0.995933833333333">thuac,poesiol@cogsci.ed.ac.uk, tUniversity of . de Abstract This paper describes how we annotated and the in a corpus of museum descriptions to discover rules for the selection and realisation of such modifiers, in particular non-referring ones. We implemented the into an extension of the system to generate complex NPs capable of serving multiple communicative goals.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Appelt</author>
</authors>
<title>Planning English referring expressions.</title>
<date>1985</date>
<journal>Artificial Intelligence,</journal>
<pages>26--1</pages>
<contexts>
<context position="893" citStr="Appelt, 1985" startWordPosition="128" endWordPosition="129"> how we annotated and analysed the NP modifiers in a corpus of museum descriptions to discover rules for the selection and realisation of such modifiers, in particular non-referring ones. We implemented the regularities into an extension of the ILEX system to generate complex NPs capable of serving multiple communicative goals. 1 Introduction and Motivation 1.1 Generating Complex NPs In addition to a referring function, noun phrases (NP) can also serve communicative goals such as providing new information about the referent and expressing the speaker&apos;s emotional attitude towards the referent (Appelt, 1985; Jordan, 2000). In Example (1) below, the part in italics refers to an object in a museum, and the part in boldface provides additional information about it. (1) This example from the time of the Qianlong Emperor 1736-95 is made of lacquered wood with decoration in gold and red. Such complex NPs appear frequently in human written texts. A natural language generation (NLG) system must be able to produce complex NPs serving multiple goals in order to write texts as humans do. We divide the components of an NP into two parts based on the different functions/communicative goals they serve: a refe</context>
</contexts>
<marker>Appelt, 1985</marker>
<rawString>D. Appelt. 1985. Planning English referring expressions. Artificial Intelligence, 26:1-33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Breiman</author>
<author>J Friedman</author>
<author>R Olshen</author>
<author>C Stone</author>
</authors>
<title>Classification and Regression Trees.</title>
<date>1984</date>
<publisher>Wadsworth International.</publisher>
<location>Belmont, Calif.:</location>
<contexts>
<context position="4921" citStr="Breiman et al., 1984" startWordPosition="788" endWordPosition="791"> of such modifiers in the domain of museum descriptions (Oberlander et al., 1998), that hopefully will be general enough to be applied to other domains. Since what we will study are coherent human texts with multiple sentences, the NP modifiers in them are subject to both coherence and conciseness constraints. This work is a part of the GNOME project (Generating NOMinal Expressions)&apos;, in which statistical models for NP determination have been built by training on corpora annotated with semantic and discourse information (Poesio, 2000a). Such statistical models take the form of decision trees (Breiman et al., 1984), which assign probabilities to different NP types according to the input semantic and discoursal features. The correctness of the decision trees relies heavily on the reliability of the annotation. As a result, GNOME emphasises achieving reliable annotation, a stage which appears to have been skipped in much other work. In a similar way, our work aims at finding out reliable evidence concerning the information human authors like to convey as an NP modifier and how they realise it. However, we do not intend to address the content determination problem in great detail because content selection </context>
</contexts>
<marker>Breiman, Friedman, Olshen, Stone, 1984</marker>
<rawString>L. Breiman, J. Friedman, R. Olshen, and C. Stone. 1984. Classification and Regression Trees. Belmont, Calif.: Wadsworth International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cheng</author>
<author>C Mellish</author>
</authors>
<title>Capturing the interaction between aggregation and text planning in two generation systems.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st International Conference on Natural Language Generation,</booktitle>
<pages>186--193</pages>
<contexts>
<context position="3113" citStr="Cheng and Mellish, 2000" startWordPosition="502" endWordPosition="505">r types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is satisfied with devising a few rules to allow some degrees of embedding to generate subordinate NP components. There is no in-depth discussion of the problem of generating non-referring modifiers in general. It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence (in the sense of (Grosz and Sidner, 1986)) (Cheng and Mellish, 2000a). NP subordination, as an alternative to sententialisation, is a major way to achieve conciseness as it reduces the number of sentences in generated texts. However, generating arbitrarily complex NPs is not often desirable. Therefore, achieving coherence and conciseness are two conflicting considerations and conciseness should only be satisfied under coherence constraints. 1.2 Corpus Analysis for NLG Corpus analysis has often been used for devising rules for modifier generation, e.g. (Mann and Matthiessen, 1985; Robin, 1994; Shaw and McKeown, 1997). The proposals in NIGEL, in particular, wer</context>
<context position="10053" citStr="Cheng and Mellish, 2000" startWordPosition="1661" endWordPosition="1664">These values mainly target prepositional phrases and nouns, not adjectives. For an adjective, we use WordNet to derive its category rather than directly assigning a predefined value. In WordNet, if an adjective ascribes a value to a noun concept, e.g. round gives a value of shape, WordNet will contain a pointer between the adjective and the noun by which the appropriate attribute is lexicalised, e.g. between round and shape. Using WordNet, annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in (Cheng and Mellish, 2000b). and then mapping the word sense to a noun concept in the WordNet ontology. Satisfactory agreement among human subjects on choosing senses for words has been recorded (Fellbaum, 1998) and the mapping to nouns can be done automatically. So this approach is considerably better than manually assigning values. There is a tradeoff between the number of values and the achievable agreement on feature annotation because the more values a feature has, the less agreement the annotation can expect to achieve. To avoid having too many categories, we use more general concepts like one of the following (</context>
</contexts>
<marker>Cheng, Mellish, 2000</marker>
<rawString>H. Cheng and C. Mellish. 2000a. Capturing the interaction between aggregation and text planning in two generation systems. In Proceedings of the 1st International Conference on Natural Language Generation, pages 186-193, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cheng</author>
<author>C Mellish</author>
</authors>
<title>An empirical analysis of constructing non-restrictive np components to express semantic relations.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st International Conference on Natural Language Generation,</booktitle>
<contexts>
<context position="3113" citStr="Cheng and Mellish, 2000" startWordPosition="502" endWordPosition="505">r types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is satisfied with devising a few rules to allow some degrees of embedding to generate subordinate NP components. There is no in-depth discussion of the problem of generating non-referring modifiers in general. It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence (in the sense of (Grosz and Sidner, 1986)) (Cheng and Mellish, 2000a). NP subordination, as an alternative to sententialisation, is a major way to achieve conciseness as it reduces the number of sentences in generated texts. However, generating arbitrarily complex NPs is not often desirable. Therefore, achieving coherence and conciseness are two conflicting considerations and conciseness should only be satisfied under coherence constraints. 1.2 Corpus Analysis for NLG Corpus analysis has often been used for devising rules for modifier generation, e.g. (Mann and Matthiessen, 1985; Robin, 1994; Shaw and McKeown, 1997). The proposals in NIGEL, in particular, wer</context>
<context position="10053" citStr="Cheng and Mellish, 2000" startWordPosition="1661" endWordPosition="1664">These values mainly target prepositional phrases and nouns, not adjectives. For an adjective, we use WordNet to derive its category rather than directly assigning a predefined value. In WordNet, if an adjective ascribes a value to a noun concept, e.g. round gives a value of shape, WordNet will contain a pointer between the adjective and the noun by which the appropriate attribute is lexicalised, e.g. between round and shape. Using WordNet, annotating the sem feature of an adjective involves first choosing the correct sense for the adjective 2Some descriptions of int modifiers can be found in (Cheng and Mellish, 2000b). and then mapping the word sense to a noun concept in the WordNet ontology. Satisfactory agreement among human subjects on choosing senses for words has been recorded (Fellbaum, 1998) and the mapping to nouns can be done automatically. So this approach is considerably better than manually assigning values. There is a tradeoff between the number of values and the achievable agreement on feature annotation because the more values a feature has, the less agreement the annotation can expect to achieve. To avoid having too many categories, we use more general concepts like one of the following (</context>
</contexts>
<marker>Cheng, Mellish, 2000</marker>
<rawString>H. Cheng and C. Mellish. 2000b. An empirical analysis of constructing non-restrictive np components to express semantic relations. In Proceedings of the 1st International Conference on Natural Language Generation, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Dale</author>
</authors>
<title>Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes.</title>
<date>1992</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2484" citStr="Dale, 1992" startWordPosition="403" endWordPosition="404">ormation about the referent denoted by the referring part, such as the part of (1) in boldface. If an NLG system generates such modifiers, it usually does this in its aggregation module, e.g. (Shaw and McKeown, 1997; O&apos;Donnell et al., 1998). This division is a functional one rather than a syntactic one. Except for the head and the determiner, which are always members of the referring part, other NP components can belong to different parts in different circumstances. In NLG, research on NP generation focuses on deciding syntactic forms and choosing disambiguating modifiers for referring, e.g. (Dale, 1992). Other types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is satisfied with devising a few rules to allow some degrees of embedding to generate subordinate NP components. There is no in-depth discussion of the problem of generating non-referring modifiers in general. It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence (in the sense of (Grosz and Sidner, 19</context>
</contexts>
<marker>Dale, 1992</marker>
<rawString>R. Dale. 1992. Generating Referring Expressions: Constructing Descriptions in a Domain of Objects and Processes. The MIT Press.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>C. Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>1998</marker>
<rawString>C. Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attentions, intentions and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<pages>12--175</pages>
<contexts>
<context position="3087" citStr="Grosz and Sidner, 1986" startWordPosition="498" endWordPosition="501">g, e.g. (Dale, 1992). Other types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is satisfied with devising a few rules to allow some degrees of embedding to generate subordinate NP components. There is no in-depth discussion of the problem of generating non-referring modifiers in general. It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence (in the sense of (Grosz and Sidner, 1986)) (Cheng and Mellish, 2000a). NP subordination, as an alternative to sententialisation, is a major way to achieve conciseness as it reduces the number of sentences in generated texts. However, generating arbitrarily complex NPs is not often desirable. Therefore, achieving coherence and conciseness are two conflicting considerations and conciseness should only be satisfied under coherence constraints. 1.2 Corpus Analysis for NLG Corpus analysis has often been used for devising rules for modifier generation, e.g. (Mann and Matthiessen, 1985; Robin, 1994; Shaw and McKeown, 1997). The proposals in</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attentions, intentions and the structure of discourse. Computational Linguistics, 12:175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jordan</author>
</authors>
<title>Can nominal expressions achieve multiple goals? an empirical study.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of Association for Computational Linguistics,</booktitle>
<pages>142--149</pages>
<location>Hong Kong, P.R.China.</location>
<contexts>
<context position="908" citStr="Jordan, 2000" startWordPosition="130" endWordPosition="132">ted and analysed the NP modifiers in a corpus of museum descriptions to discover rules for the selection and realisation of such modifiers, in particular non-referring ones. We implemented the regularities into an extension of the ILEX system to generate complex NPs capable of serving multiple communicative goals. 1 Introduction and Motivation 1.1 Generating Complex NPs In addition to a referring function, noun phrases (NP) can also serve communicative goals such as providing new information about the referent and expressing the speaker&apos;s emotional attitude towards the referent (Appelt, 1985; Jordan, 2000). In Example (1) below, the part in italics refers to an object in a museum, and the part in boldface provides additional information about it. (1) This example from the time of the Qianlong Emperor 1736-95 is made of lacquered wood with decoration in gold and red. Such complex NPs appear frequently in human written texts. A natural language generation (NLG) system must be able to produce complex NPs serving multiple goals in order to write texts as humans do. We divide the components of an NP into two parts based on the different functions/communicative goals they serve: a referring part : in</context>
<context position="7503" citStr="Jordan, 2000" startWordPosition="1234" endWordPosition="1235">ity of a given piece of information occupying a given syntactic position (a value of type) on the basis of the semantic and pragmatic properties of that information and relevant NP features, for example, whether a certain color attribute should be expressed by means of a prenominal adjective or a prepositional phrase in a definite NP. Notice that it is not possible to use corpus annotation to determine the likelihood of a given property to be chosen, unless we know in advance all of the properties that can be attributed to a given object, as in the case of Jordan&apos;s work on the COCONUT domain (Jordan, 2000). Below we briefly introduce the major values of the three modifier features. Pragm We observed three modifier functions in NPs. Firstly, a modifier may specify properties that uniquely identify the objects or concepts denoted by an NP, i.e. components of the referring part of an NP. We call such modifiers uniq modifiers; most modifiers in generic references are of this type. Secondly, a modifier may not be used to constrain a unique or unambiguous concept out of an NP which is either already unique or not required to have a unique interpretation, but may be important to the situation presente</context>
</contexts>
<marker>Jordan, 2000</marker>
<rawString>P. Jordan. 2000. Can nominal expressions achieve multiple goals? an empirical study. In Proceedings of the 38th Annual Meeting of Association for Computational Linguistics, pages 142-149, Hong Kong, P.R.China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Levi</author>
</authors>
<title>The Syntax and Semantics of Complex Nominals.</title>
<date>1978</date>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<contexts>
<context position="8888" citStr="Levi, 1978" startWordPosition="1472" endWordPosition="1473">ed to provide additional details about the referent of an NP which, however, would successfully function the same way as the NP without these modifiers. We call them attr modifiers. The effect of such modifiers is usually local to the heads they describe rather than to the main propositions as a whole. This is the main difference between attr and int modifiers. The last two types of modifiers form the nonreferring part of an NP. This paper emphasises attr modifiers and addresses uniq ones to show the differences between them. Sem Our values of sem are based on the linguistic literature, e.g. (Levi, 1978; Quirk et al., 1985; Meyer, 1992). These values are also intended as a refinement of the semantic characterisations of the modifying relations in NIGEL (Mann and Matthiessen, 1985), where a correlation between certain semantic properties and the positions of modifiers is proposed. One of the modifications to this previous work was to use WordNet (Fellbaum, 1998) to make our values more standard and improve reliability. Some sem values are listed in Table 1, where the numbers are the WordNet sense numbers for these particular concepts. These values mainly target prepositional phrases and nouns</context>
</contexts>
<marker>Levi, 1978</marker>
<rawString>J. Levi. 1978. The Syntax and Semantics of Complex Nominals. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>C Matthiessen</author>
</authors>
<title>Demonstration of the NIGEL text generation computer program.</title>
<date>1985</date>
<booktitle>Systemic Perspectives on Discourse,</booktitle>
<pages>50--83</pages>
<editor>In James Benson and William Greaves, editors,</editor>
<publisher>Ablex.</publisher>
<location>Norwood:</location>
<contexts>
<context position="2663" citStr="Mann and Matthiessen, 1985" startWordPosition="429" endWordPosition="432">its aggregation module, e.g. (Shaw and McKeown, 1997; O&apos;Donnell et al., 1998). This division is a functional one rather than a syntactic one. Except for the head and the determiner, which are always members of the referring part, other NP components can belong to different parts in different circumstances. In NLG, research on NP generation focuses on deciding syntactic forms and choosing disambiguating modifiers for referring, e.g. (Dale, 1992). Other types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is satisfied with devising a few rules to allow some degrees of embedding to generate subordinate NP components. There is no in-depth discussion of the problem of generating non-referring modifiers in general. It has been argued that generating such modifiers is not a trivial decision because it interferes with the planning of both local and global coherence (in the sense of (Grosz and Sidner, 1986)) (Cheng and Mellish, 2000a). NP subordination, as an alternative to sententialisation, is a major way to achieve conciseness as it reduces the number of sentences in generated</context>
<context position="9069" citStr="Mann and Matthiessen, 1985" startWordPosition="1500" endWordPosition="1503">m attr modifiers. The effect of such modifiers is usually local to the heads they describe rather than to the main propositions as a whole. This is the main difference between attr and int modifiers. The last two types of modifiers form the nonreferring part of an NP. This paper emphasises attr modifiers and addresses uniq ones to show the differences between them. Sem Our values of sem are based on the linguistic literature, e.g. (Levi, 1978; Quirk et al., 1985; Meyer, 1992). These values are also intended as a refinement of the semantic characterisations of the modifying relations in NIGEL (Mann and Matthiessen, 1985), where a correlation between certain semantic properties and the positions of modifiers is proposed. One of the modifications to this previous work was to use WordNet (Fellbaum, 1998) to make our values more standard and improve reliability. Some sem values are listed in Table 1, where the numbers are the WordNet sense numbers for these particular concepts. These values mainly target prepositional phrases and nouns, not adjectives. For an adjective, we use WordNet to derive its category rather than directly assigning a predefined value. In WordNet, if an adjective ascribes a value to a noun c</context>
</contexts>
<marker>Mann, Matthiessen, 1985</marker>
<rawString>W. Mann and C. Matthiessen. 1985. Demonstration of the NIGEL text generation computer program. In James Benson and William Greaves, editors, Systemic Perspectives on Discourse, pages 50-83. Norwood: Ablex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Meyer</author>
</authors>
<title>Apposition in Contemporary English.</title>
<date>1992</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="8922" citStr="Meyer, 1992" startWordPosition="1478" endWordPosition="1479"> about the referent of an NP which, however, would successfully function the same way as the NP without these modifiers. We call them attr modifiers. The effect of such modifiers is usually local to the heads they describe rather than to the main propositions as a whole. This is the main difference between attr and int modifiers. The last two types of modifiers form the nonreferring part of an NP. This paper emphasises attr modifiers and addresses uniq ones to show the differences between them. Sem Our values of sem are based on the linguistic literature, e.g. (Levi, 1978; Quirk et al., 1985; Meyer, 1992). These values are also intended as a refinement of the semantic characterisations of the modifying relations in NIGEL (Mann and Matthiessen, 1985), where a correlation between certain semantic properties and the positions of modifiers is proposed. One of the modifications to this previous work was to use WordNet (Fellbaum, 1998) to make our values more standard and improve reliability. Some sem values are listed in Table 1, where the numbers are the WordNet sense numbers for these particular concepts. These values mainly target prepositional phrases and nouns, not adjectives. For an adjective</context>
</contexts>
<marker>Meyer, 1992</marker>
<rawString>C. Meyer. 1992. Apposition in Contemporary English. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Oberlander</author>
<author>M O&apos;Donnell</author>
<author>A Knott</author>
<author>C Mellish</author>
</authors>
<title>Conversation in the museum: Experiments in dynamic hypermedia with the intelligent labelling explorer. New Review of Hypermedia and Multimedia,</title>
<date>1998</date>
<pages>4--11</pages>
<contexts>
<context position="4381" citStr="Oberlander et al., 1998" startWordPosition="702" endWordPosition="705">most of these analyses depend on the intuitions of an individual researcher, which might not be shared by other people. In addition, their analyses mainly target single sentences, so the results emphasise the conciseness consideration and might not suit multisentential text. This paper puts emphasis on the generation of non-referring NP modifiers in museum descriptions, which provide information for items displayed in a museum. By analysing descriptions written and revised by human experts, we wish to find out general rules for the usage of such modifiers in the domain of museum descriptions (Oberlander et al., 1998), that hopefully will be general enough to be applied to other domains. Since what we will study are coherent human texts with multiple sentences, the NP modifiers in them are subject to both coherence and conciseness constraints. This work is a part of the GNOME project (Generating NOMinal Expressions)&apos;, in which statistical models for NP determination have been built by training on corpora annotated with semantic and discourse information (Poesio, 2000a). Such statistical models take the form of decision trees (Breiman et al., 1984), which assign probabilities to different NP types according</context>
<context position="22688" citStr="Oberlander et al., 1998" startWordPosition="3667" endWordPosition="3670"> be realised in many different ways, whereas Table 3 counts only one of them as correct. If instead realisations with equal probability are all treated as correct choices, the accuracy rate could be higher. However, we do not know whether such realisations are indeed favoured equally by humans, unless a separate experiment is carried out. So we did not consider such cases in calculating the accuracy. In addition, higher accuracy rate might also be achieved by training on a larger annotated corpus. 4 Implementation in ILEX We used the results discussed above in an extension of the ILEX system (Oberlander et al., 1998), which adaptively generates online descriptions of museum objects. ILEX uses a modularised pipeline architecture, which consists of such modules as content selection, content structuring, text realisation, post-processing and presentation. The content of an NP is determined in the post-processing module by the NP generation and aggregation processes. This architecture allows us to substitute the original ILEX NP module with a new module which we call GNOME-edi. GNOME-edi not only determines the form of an NP, but also generates several types of modifiers, including adjectives, prepositional p</context>
</contexts>
<marker>Oberlander, O&apos;Donnell, Knott, Mellish, 1998</marker>
<rawString>J. Oberlander, M. O&apos;Donnell, A. Knott, and C. Mellish. 1998. Conversation in the museum: Experiments in dynamic hypermedia with the intelligent labelling explorer. New Review of Hypermedia and Multimedia, 4:11-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M O&apos;Donnell</author>
<author>H Cheng</author>
<author>J Hitzeman</author>
</authors>
<title>Integrating referring and informing in NP planning.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL &apos;98 Workshop on the Computational Treatment of Nominals,</booktitle>
<pages>46--56</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2113" citStr="O&apos;Donnell et al., 1998" startWordPosition="343" endWordPosition="346">eferring part : intends to refer to an object, but not necessarily to identify, that is, the expression denotes an individual object of a certain class, but it might not be necessary to know the exact object. The italic part of (1) gives an example. This part is normally the task of the NP generation module of an NLG system. a non-referring part : intends to provide additional information about the referent denoted by the referring part, such as the part of (1) in boldface. If an NLG system generates such modifiers, it usually does this in its aggregation module, e.g. (Shaw and McKeown, 1997; O&apos;Donnell et al., 1998). This division is a functional one rather than a syntactic one. Except for the head and the determiner, which are always members of the referring part, other NP components can belong to different parts in different circumstances. In NLG, research on NP generation focuses on deciding syntactic forms and choosing disambiguating modifiers for referring, e.g. (Dale, 1992). Other types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is satisfied with devising a</context>
</contexts>
<marker>O&apos;Donnell, Cheng, Hitzeman, 1998</marker>
<rawString>M. O&apos;Donnell, H. Cheng, and J. Hitzeman. 1998. Integrating referring and informing in NP planning. In Proceedings of COLING-ACL &apos;98 Workshop on the Computational Treatment of Nominals, pages 46-56, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
</authors>
<title>Annotating a corpus to develop and evaluate discourse entity realization algorithms: Issues and preliminary results.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>211--218</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="4839" citStr="Poesio, 2000" startWordPosition="776" endWordPosition="778">revised by human experts, we wish to find out general rules for the usage of such modifiers in the domain of museum descriptions (Oberlander et al., 1998), that hopefully will be general enough to be applied to other domains. Since what we will study are coherent human texts with multiple sentences, the NP modifiers in them are subject to both coherence and conciseness constraints. This work is a part of the GNOME project (Generating NOMinal Expressions)&apos;, in which statistical models for NP determination have been built by training on corpora annotated with semantic and discourse information (Poesio, 2000a). Such statistical models take the form of decision trees (Breiman et al., 1984), which assign probabilities to different NP types according to the input semantic and discoursal features. The correctness of the decision trees relies heavily on the reliability of the annotation. As a result, GNOME emphasises achieving reliable annotation, a stage which appears to have been skipped in much other work. In a similar way, our work aims at finding out reliable evidence concerning the information human authors like to convey as an NP modifier and how they realise it. However, we do not intend to ad</context>
<context position="14851" citStr="Poesio, 2000" startWordPosition="2431" endWordPosition="2432">some agreement on pragm. The agreement on pragm shows that the distinctions we are trying to make are relatively clear and human subjects can distinguish between the different uses of NP modifiers to some extent. The main ambiguity exists between int and attr modifiers. There seems to be a gradual difference between them and where to draw the line is a bit arbitrary. Some disagreement is also introduced by errors in the annotations of the NP features on which the annotation of pragm depends, e.g. logical form type and genericity3, although good agreements have been achieved on these features (Poesio, 2000a). 3.2 What is Expressed as a Modifier? Table 2 shows the distributions of the semantic and syntactic features of modifiers with respect to their functions4. Each cell gives the number of modifiers found in the corpus for each sem/type and pragm combination and what percentage such modifiers occupy in those with the same pragm value (vertically) and sem/type value (horizontally). The percentages illustrate the differences in modifier usage. Concerning the semantic properties, characterize1, spatial-property1, visual-property1 and rephrase1 (percentages in boldface in the table) are more often</context>
<context position="19289" citStr="Poesio, 2000" startWordPosition="3063" endWordPosition="3064">. Only 11.79% of such information appears in discourse old references and the rest is in predicative phrases. 3.3 How to Realise a Property? To get a more precise correlation between a semantic and syntactic feature, we used the wagon CART building program developed at the Centre for Speech Technology Research, the University of Edinburgh to train a statistical model for deciding the syntactic form of a property given its semantic and pragmatic features. We also included the cat feature of the NP in which the property is realised, specifying its type (proper name, definite NP, pronoun, etc.) (Poesio, 2000b) as an approximation of the semantic and discourse features of the NP. The construction of CART (Classification And Regression Trees) is a common and powerful method for building statistical models from simple feature data. The program has two parts: wagon and wagon_test which trains and tests a statistical model on given samples respectively. Because the size of the annotated corpus is relatively small, we used a cross-validation method, which divides the corpus into two parts, 9/10s for training and 1/10 for testing. It runs the training and testing circle for 10 times and calculates the a</context>
</contexts>
<marker>Poesio, 2000</marker>
<rawString>M. Poesio. 2000a. Annotating a corpus to develop and evaluate discourse entity realization algorithms: Issues and preliminary results. In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC), pages 211-218, Athens, Greece.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Poesio</author>
</authors>
<booktitle>2000b. The GNOME annotation scheme manual. Technical Report URL: www.cogsci.ed. ac.uk/poesio/GNOME/anno_manual_4.html, Division of Informatics, the</booktitle>
<institution>University of Edinburgh.</institution>
<marker>Poesio, </marker>
<rawString>M. Poesio. 2000b. The GNOME annotation scheme manual. Technical Report URL: www.cogsci.ed. ac.uk/poesio/GNOME/anno_manual_4.html, Division of Informatics, the University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<title>A Grammar of Contemporary English.</title>
<date>1985</date>
<publisher>Longman Group Ltd.</publisher>
<contexts>
<context position="8908" citStr="Quirk et al., 1985" startWordPosition="1474" endWordPosition="1477">e additional details about the referent of an NP which, however, would successfully function the same way as the NP without these modifiers. We call them attr modifiers. The effect of such modifiers is usually local to the heads they describe rather than to the main propositions as a whole. This is the main difference between attr and int modifiers. The last two types of modifiers form the nonreferring part of an NP. This paper emphasises attr modifiers and addresses uniq ones to show the differences between them. Sem Our values of sem are based on the linguistic literature, e.g. (Levi, 1978; Quirk et al., 1985; Meyer, 1992). These values are also intended as a refinement of the semantic characterisations of the modifying relations in NIGEL (Mann and Matthiessen, 1985), where a correlation between certain semantic properties and the positions of modifiers is proposed. One of the modifications to this previous work was to use WordNet (Fellbaum, 1998) to make our values more standard and improve reliability. Some sem values are listed in Table 1, where the numbers are the WordNet sense numbers for these particular concepts. These values mainly target prepositional phrases and nouns, not adjectives. Fo</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985. A Grammar of Contemporary English. Longman Group Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robin</author>
</authors>
<title>Revision-based Generation of Natural Language Summaries Providing Historical Background: Corpus-based Analysis, Design, Implementation and Evaluation.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Computer Science Department, Columbia University.</institution>
<contexts>
<context position="3644" citStr="Robin, 1994" startWordPosition="583" endWordPosition="584">al coherence (in the sense of (Grosz and Sidner, 1986)) (Cheng and Mellish, 2000a). NP subordination, as an alternative to sententialisation, is a major way to achieve conciseness as it reduces the number of sentences in generated texts. However, generating arbitrarily complex NPs is not often desirable. Therefore, achieving coherence and conciseness are two conflicting considerations and conciseness should only be satisfied under coherence constraints. 1.2 Corpus Analysis for NLG Corpus analysis has often been used for devising rules for modifier generation, e.g. (Mann and Matthiessen, 1985; Robin, 1994; Shaw and McKeown, 1997). The proposals in NIGEL, in particular, were the starting point of this work. However, most of these analyses depend on the intuitions of an individual researcher, which might not be shared by other people. In addition, their analyses mainly target single sentences, so the results emphasise the conciseness consideration and might not suit multisentential text. This paper puts emphasis on the generation of non-referring NP modifiers in museum descriptions, which provide information for items displayed in a museum. By analysing descriptions written and revised by human </context>
</contexts>
<marker>Robin, 1994</marker>
<rawString>J. Robin. 1994. Revision-based Generation of Natural Language Summaries Providing Historical Background: Corpus-based Analysis, Design, Implementation and Evaluation. Ph.D. thesis, Computer Science Department, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Shaw</author>
<author>K McKeown</author>
</authors>
<title>An architecture for aggregation in text generation.</title>
<date>1997</date>
<booktitle>In Proceedings of the 15th International Joint Conference on Artificial Intelligence,</booktitle>
<location>Poster Session, Nagoya, Japan.</location>
<contexts>
<context position="2088" citStr="Shaw and McKeown, 1997" startWordPosition="339" endWordPosition="342">ve goals they serve: a referring part : intends to refer to an object, but not necessarily to identify, that is, the expression denotes an individual object of a certain class, but it might not be necessary to know the exact object. The italic part of (1) gives an example. This part is normally the task of the NP generation module of an NLG system. a non-referring part : intends to provide additional information about the referent denoted by the referring part, such as the part of (1) in boldface. If an NLG system generates such modifiers, it usually does this in its aggregation module, e.g. (Shaw and McKeown, 1997; O&apos;Donnell et al., 1998). This division is a functional one rather than a syntactic one. Except for the head and the determiner, which are always members of the referring part, other NP components can belong to different parts in different circumstances. In NLG, research on NP generation focuses on deciding syntactic forms and choosing disambiguating modifiers for referring, e.g. (Dale, 1992). Other types of modifiers have been given much less attention, although proposals concerning their realisation are included in grammars such as NIGEL (Mann and Matthiessen, 1985). Work on aggregation is </context>
<context position="3669" citStr="Shaw and McKeown, 1997" startWordPosition="585" endWordPosition="588">(in the sense of (Grosz and Sidner, 1986)) (Cheng and Mellish, 2000a). NP subordination, as an alternative to sententialisation, is a major way to achieve conciseness as it reduces the number of sentences in generated texts. However, generating arbitrarily complex NPs is not often desirable. Therefore, achieving coherence and conciseness are two conflicting considerations and conciseness should only be satisfied under coherence constraints. 1.2 Corpus Analysis for NLG Corpus analysis has often been used for devising rules for modifier generation, e.g. (Mann and Matthiessen, 1985; Robin, 1994; Shaw and McKeown, 1997). The proposals in NIGEL, in particular, were the starting point of this work. However, most of these analyses depend on the intuitions of an individual researcher, which might not be shared by other people. In addition, their analyses mainly target single sentences, so the results emphasise the conciseness consideration and might not suit multisentential text. This paper puts emphasis on the generation of non-referring NP modifiers in museum descriptions, which provide information for items displayed in a museum. By analysing descriptions written and revised by human experts, we wish to find </context>
</contexts>
<marker>Shaw, McKeown, 1997</marker>
<rawString>J. Shaw and K. McKeown. 1997. An architecture for aggregation in text generation. In Proceedings of the 15th International Joint Conference on Artificial Intelligence, Poster Session, Nagoya, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>J Castellan</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences.</title>
<date>1988</date>
<location>London:McGraw-Hill.</location>
<contexts>
<context position="14032" citStr="Siegel and Castellan, 1988" startWordPosition="2293" endWordPosition="2296">a general sense. The relations include such subtypes as whole/part, type/instance, owner/owned etc., e.g. desks with interiors, the name of the maker location1 time-period1 material1 identify2 rephrase 1 characterize1 sub j ect7 or obj ect3 possess or possinv Table 1: Predefined semantic categories of modifiers their agreement on a small part of the corpus. The annotated corpus contains 1863 modifiers. Using the annotated corpus, we could discover regularities in the usage of NP modifiers and design modifier generation algorithms. 3.1 Agreement on Annotation We used the kappa coefficient (K) (Siegel and Castellan, 1988) to calculate the agreement between annotators. The agreement on the three modifier features is: Features Type Pragm Sem Agreement (K) .97 .77 .81 This demonstrates fairly good agreement on type and sem and some agreement on pragm. The agreement on pragm shows that the distinctions we are trying to make are relatively clear and human subjects can distinguish between the different uses of NP modifiers to some extent. The main ambiguity exists between int and attr modifiers. There seems to be a gradual difference between them and where to draw the line is a bit arbitrary. Some disagreement is al</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and J. Castellan. 1988. Nonparametric Statistics for the Behavioral Sciences. London:McGraw-Hill.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>