<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001286">
<note confidence="0.774646">
Picking them up and Figuring them out:
Verb-Particle Constructions, Noise and Idiomaticity
</note>
<author confidence="0.981746">
Carlos Ramisch♣♦, Aline Villavicencio♣♠, Leonardo Moura♣ and Marco Idiart♥♣Institute of Informatics, Federal University of Rio Grande do Sul (Brazil)
</author>
<affiliation confidence="0.994869">
♦GETALP Laboratory, Joseph Fourier University - Grenoble INP (France)
♠Department of Computer Sciences, Bath University (UK)
♥Institute of Physics, Federal University of Rio Grande do Sul (Brazil)
</affiliation>
<email confidence="0.996769">
{ceramisch,avillavicencio,lfsmoura}@inf.ufrgs.br, idiart@if.ufrgs.br
</email>
<sectionHeader confidence="0.997368" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988595">
This paper investigates, in a first stage,
some methods for the automatic acquisi-
tion of verb-particle constructions (VPCs)
taking into account their statistical prop-
erties and some regular patterns found in
productive combinations of verbs and par-
ticles. Given the limited coverage pro-
vided by lexical resources, such as dictio-
naries, and the constantly growing number
of VPCs, possible ways of automatically
identifying them are crucial for any NLP
task that requires some degree of semantic
interpretation. In a second stage we also
study whether the combination of statis-
tical and linguistic properties can provide
some indication of the degree of idiomatic-
ity of a given VPC. The results obtained
show that such combination can success-
fully be used to detect VPCs and distin-
guish idiomatic from compositional cases.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999401909090909">
Considerable investigative effort has focused on
the automatic identification of Multiword Expres-
sions (MWEs), like compound nouns (science fic-
tion) and phrasal verbs (carry out) (e.g. Pearce
(2002), Evert and Krenn (2005) and Zhang et
al. (2006)). Some of them employ language
and/or type dependent linguistic knowledge for
the task, while others employ independent statis-
tical methods, such as Mutual Information and
Log-likelihood (e.g. Pearce (2002) and, Zhang et
al. (2006)), or even a combination of them (e.g.
</bodyText>
<footnote confidence="0.903308">
© 2008. Licensed under the Creative Commons
Attribution-Noncommercial-Share Alike 3.0 Unported li-
cense (http://creativecommons.org/licenses/by-nc-sa/3.0/).
Some rights reserved.
</footnote>
<bodyText confidence="0.9997295">
Baldwin (2005) and Sharoff (2004)), as basis for
helping to determine whether a given sequence
of words is in fact an MWE. Although some re-
search aims at developing methods for dealing
with MWEs in general (e.g. Zhang et al. (2006),
Ramisch et al. (2008)), there is also some work that
deals with specific types of MWEs (e.g. Pearce
(2002) on collocations and Villavicencio (2005)
on verb-particle constructions (VPCs)) as each of
these MWE types has distinct distributional and
linguistic characteristics.
VPCs are combinations of verbs and particles,
such as take off in Our plane took off late, that due
to their complex characteristics and flexible na-
ture, provide a real challenge for NLP. In particu-
lar, there is a lack of adequate resources to identify
and treat them, and those that are available provide
only limited coverage, in face of the huge number
of combinations in use. For tasks like parsing and
generation, it is essential to know whether a given
VPC is possible or not, to avoid for example us-
ing combinations that sound unnatural or ungram-
matical to native speakers (e.g. give/lend/?grant
out for the conveying of something to someone or
some place - (Fraser, 1976)).1 Thus, the knowl-
edge of which combinations are possible is cru-
cial for precision grammar engineering. In ad-
dition, as the semantics of VPCs varies from the
idiomatic to the more compositional cases, meth-
ods for the automatic detection and handling of id-
iomaticity are very important for any NLP task that
involves some degree of semantic interpretation
such as Machine Translation (in this case avoiding
the problem of producing an unrelated translation
for a source sentence). Automatic methods for the
identification of idiomaticity in MWEs have been
</bodyText>
<footnote confidence="0.9324485">
1See Baldwin et al. (2004) for a discussion of the effects of
multiword expressions like VPCs on a parser’s performance.
</footnote>
<page confidence="0.987774">
49
</page>
<note confidence="0.8811745">
CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 49–56
Manchester, August 2008
</note>
<bodyText confidence="0.9998316">
proposed using a variety of approaches such as
statistical, substitutional, distributional, etc. (e.g.
McCarthy et al. (2003), Bannard (2005) and Fa-
zly and Stevenson (2006)). In particular, Fazly
and Stevenson (2006) look at the correlation be-
tween syntactic fixedness (in terms of e.g. pas-
sivisation, choice of determiner type and pluralisa-
tion) and non-compositionality of verb-noun com-
pounds such as shoot the breeze.
In this work we investigate the automatic extrac-
tion of VPCs, looking into a variety of methods,
combining linguistic with statistical information,
ranging from frequencies to association measures:
Mutual Information (MI), χ2 and Entropy. We also
investigate the determination of compositionality
of VPCs verifying whether the degree of semantic
flexibility of a VPC combined with some statisti-
cal information can be used to determine if it is
idiomatic or compositional.
This paper starts with a brief description of
VPCs, research on their automatic identification
and determination of their semantics (§ 2). We then
explain the research questions and the assumptions
that serve as the basis for the application of statis-
tical measures (§ 3) on the dataset (§ 4). Our meth-
ods and experiments are then detailed (§ 5), and
the results obtained are analysed (§ 6). We con-
clude with a discussion of the contributions that
this work brings to the research on verb-particle
constructions (§ 7).
</bodyText>
<sectionHeader confidence="0.906483" genericHeader="method">
2 Verb-Particle Constructions in Theory
</sectionHeader>
<subsectionHeader confidence="0.614038">
and Practice
</subsectionHeader>
<bodyText confidence="0.971034217391305">
Particles in VPCs are characterised by containing
features of motion-through-location and of com-
pletion or result in their core meaning (Bolinger,
1971). VPCs can range from idiosyncratic or semi-
idiosyncratic combinations, such as get on (in e.g.
Bill got on well with his new colleagues), to more
regular ones, such as tear up (e.g. in In a rage she
tore up the letter Jack gave her). A three way clas-
sification is adopted by (Deh´e, 2002) and (Jack-
endoff, 2002), where a VPC can be classified as
compositional, idiomatic or aspectual, depending
on its sense. In compositional VPCs the meaning
of the construction is determined by the literal in-
terpretations of the particle and the verb. These
VPCs usually involve particles with directional or
spatial meaning, and these can often be replaced
by the appropriate directional PPs (e.g. carry in
in Sheila carried the bags in/into the house Deh´e
(2002)). Idiomatic VPCs, on the other hand, can-
not have their meaning determined by interpreting
their components literally (e.g. get on, meaning to
be on friendly terms with someone). The third class
is that of aspectual VPCs, which have the parti-
cle providing the verb with an endpoint, suggesting
that the action described by the verb is performed
completely, thoroughly or continuously (e.g. tear
up meaning to tear something into a lot of small
pieces).
From a syntactic point of view, a given combi-
nation can occur in several different subcategorisa-
tion frames. For example, give up can occur as an
intransitive VPC (e.g. in I give up! Tell me the an-
swer), where no other complement is required, or
it may occur as a transitive VPC which requires a
further NP complement (e.g. in She gave up alco-
hol while she was pregnant). Since in English par-
ticles tend to be homographs with prepositions (up,
out, in), a verb followed by a preposition/particle
and an NP can be ambiguous between a transitive
VPC and a prepositional verb (e.g. rely on, in He
relies on his wife for everything). Some criteria
that characterise VPCs are discussed by Bolinger
(1971):2
C1 In a transitive VPC the particle may come ei-
ther before or after the NP (e.g. He backed
up the team vs. He backed the team up).
However, whether a particle can be separated
or not from the verb may depend on the de-
gree of bonding between them, the size of the
NP, and the kind of NP. This is considered by
many to be sufficient condition for diagnos-
ing a VPC, as prepositions can only appear in
a position contiguous to the verb (e.g. *He
got the bus off).
C2 Unstressed personal pronouns must precede
the particle (e.g. They ate it up but not *They
ate up it).
C3 If the particle precedes a simple definite NP,
the particle does not take the NP as its object
(e.g. in He brought along his girlfriend) un-
like with PP complements or modifiers (e.g.
in He slept in the hotel). This means that in
the first example the NP is not a complement
of the particle along, while in the second it is.
2The distinction between a VPC and a prepositional verb
may be quite subtle, and as pointed out by Bolinger, many
of the criteria proposed for diagnosing VPCs give different
results for the same combination, frequently including un-
wanted combinations and excluding genuine VPCs.
</bodyText>
<page confidence="0.99461">
50
</page>
<bodyText confidence="0.99979951923077">
In this paper we use the first two criteria, therefore
the candidates may contain noise (in the form of
prepositional verbs and related constructions).
VPCs have been the subject of a considerable
amount of interest, and some analysis has been
done on the subject of productive VPCs. In many
cases the particle seems to be compositionally
adding a specific meaning to the construction and
following a productive pattern (e.g. in tear up,
cut up and split up, where the verbs are seman-
tically related and up adds a sense of completion
to the action of these verbs). Fraser (1976) points
out that semantic properties of verbs can affect
their ability to combine with particles: for exam-
ple, bolt/cement/clamp/glue/paste/nail are seman-
tically similar verbs where the objects represented
by the verbs are used to join material, and they can
all combine with down. There is clearly a com-
mon semantic thread running through this list, so
that a new verb that is semantically similar to them
can also be reasonably assumed to combine with
down. Indeed, frequently new VPCs are formed by
analogy with existing ones, where often the verb is
varied and the particle remains (e.g. hang on, hold
on and wait on). Similarly, particles from a given
semantic class can be replaced by other particles
from the same class in compositional combina-
tions: send up/in/back/away (Wurmbrand, 2000).
By identifying classes of verbs that follow patterns
such as these in VPCs, we can help in the identi-
fication of a new unknown candidate combination,
using the degree of productivity of a class to which
the verb belongs as a back-off strategy.
In terms of methods for automatic identifica-
tion of VPCs from corpora, Baldwin (2005) pro-
poses the extraction of VPCs with valence infor-
mation from raw text, exploring a range of tech-
niques (using (a) a POS tagger, (b) a chunker, (c) a
chunk grammar, (d) a dependency parser, and (e) a
combination of all methods). Villavicencio (2005)
uses the Web as a corpus and productive patterns
of combination to generate and validate candidate
VPCs. The identification of compositionality in
VPCs is addressed by McCarthy et al. (2003) who
examine the overlap of similar words in an auto-
matically acquired distributional thesaurus for verb
and VPCs, and by Bannard (2005) who uses a
distributional approach to determine when and to
what extent the components of a VPC contribute
their simplex meanings to the interpretation of the
VPC. Both report a correlation between some of
the measures and compositionality judgements.
</bodyText>
<sectionHeader confidence="0.973547" genericHeader="method">
3 The Underlying Hypotheses
</sectionHeader>
<bodyText confidence="0.998956709677419">
The problem of the automatic detection and classi-
fication of VPCs can be summarised as, for a given
VPC candidate, to answer to the questions:
Q1 Is it a real VPC or some free combination
of verb and preposition/adverb or a preposi-
tional verb?
Q2 If it is a true VPC, is it idiomatic or composi-
tional?
In order to answer the first question, we use two
assumptions. Firstly, we consider that the elements
of a true VPC co-occur above chance. The greater
the correlation between the verb and the particle
the greater the chance that the candidate is a true
VPC. Secondly, based on criterion C1 we also as-
sume that VPCs have more flexible syntax and are
more productive than non-VPCs. This second as-
sumption goes against what is usually adopted for
general MWEs, since it is the prepositional verbs
that allow less syntactic configurations than VPCs
and are therefore more rigid (§ 2). To further dis-
tinguish VPCs from prepositional verbs and other
related constructions we also verify the possibil-
ity of the particle to be immediately followed by
an indirect prepositional complement (like in The
plane took off from London), which is a good in-
dicator/delimiter of a VPC since in non-VPC con-
structions like prepositional verbs the preposition
needs to have an NP complement. Therefore, we
will assume that a true VPC occurs in the following
configurations, according to Villavicencio (2005)
and Ramisch et al. (2008):
</bodyText>
<listItem confidence="0.839874">
S1 VERB + PARTICLE + DELIMITER, for intran-
sitive VPCs;
S2 VERB + NP + PARTICLE + DELIMITER, for
transitive split VPCs and;
S3 VERB + PARTICLE + NP + DELIMITER, for
transitive joint VPCs.
</listItem>
<bodyText confidence="0.999889">
In order to answer Q2, we look at the link be-
tween productivity and compositionality and as-
sume that a compositional VPC accepts the sub-
stitution of one of its members by a semantically
related term. This is in accordance to Fraser
(1976), who shows that semantic properties of
</bodyText>
<page confidence="0.991373">
51
</page>
<bodyText confidence="0.999546928571428">
verbs can affect their ability to combine with par-
ticles: for example verbs of hunting combining
with the resultative down (hunt/track/trail/follow
down) and verbs of cooking with the aspectual up
(bake/cook/fry/broil up), forming essentially pro-
ductive VPCs. Idiomatic VPCs, however, will
not accept the substitution of one of its members
by a related term (e.g. get and its synonyms in
get/*obtain/*receive over), even if at first glance
this could seem natural. In our experiments, we
will consider that a VPC is compositional if it ac-
cepts: the replacement of the verb by a synonym,
or of the preposition by another preposition. Sum-
marising our hypothesis, we get:
</bodyText>
<listItem confidence="0.9970574">
• For Q1: Is the candidate syntactically flexi-
ble, i.e. does it allow the configurations S1
through S3?
– NO: non-VPC
– YES: VPC
• For Q2: Is the candidate semantically flexi-
ble, allowing the substitution of a member by
a related word?
– NO: idiomatic VPC
– YES: compositional VPC
</listItem>
<sectionHeader confidence="0.915259" genericHeader="method">
4 Data Sources
</sectionHeader>
<bodyText confidence="0.99949725">
To generate a gold standard, we used the Bald-
win VPC candidates dataset (henceforth Baldwin
CD)3, which contains 3,078 English VPC candi-
dates annotated with information about idiomatic-
ity (14.5% are considered idiomatic). We fur-
ther annotated this dataset with information about
whether each candidate is a genuine VPC or not,
where a candidate is consider genuine if it be-
longs to at least one of a set of machine-readable
dictionaries: the Alvey Natural Language Tools
(ANLT) lexicon (Carroll and Grover, 1989), the
Comlex lexicon (Macleod and Grishman, 1998),
and the LinGO English Resource Grammar (ERG)
(Copestake and Flickinger, 2000)4. With this crite-
rion 81.8% of them are considered genuine VPCs.
To gather information about the candidates in
this work we employ both a fragment of 1.8M
sentences from the British National Corpus (BNC
Burnard (2000)) and the Web as corpora. The
BNC fragment is used to calculate the correlation
</bodyText>
<footnote confidence="0.902890666666667">
3This dataset was provided by Timothy Baldwin for the
MWE2008 Workshop.
4Version of November 2001.
</footnote>
<bodyText confidence="0.999947413793104">
measures since they require a corpus with known
size. The Web is used to generate frequencies
for the entropy measures, as discussed in § 5.2.
Web frequencies are approximated by the number
of pages containing a candidate and indexed by
Yahoo Search API. In order to keep the searches
as simple and self-sufficient as possible, no addi-
tional sources of information are used (Villavicen-
cio, 2005). Therefore, the frequencies are quite
conservative in the sense that by employing in-
flected forms of verbs, potentially much more evi-
dence could be gathered.
For the generation of semantic variational pat-
terns, we use both Wordnet 3.0 (Fellbaum, 1998)
and Levin’s English Verb Classes and Alternations
(Levin, 1993). Wordnet is organised as a graph of
concepts, called synsets, linked by relations of syn-
onymy, hyponymy, etc. Each synset contains a list
of words that represent the concept. The verbs in
a synset and its synonym synsets are used to gen-
erate variations of a VPC candidate. Likewise we
use Levin’s classes, which define 190 fine-grained
classes for English verbs, based on their syntactic
and semantic features.
It is important to highlight that the generation
of the semantic variations strongly relies on these
resources. Therefore, cross-language extension
would depend on the availability of similar tools
for the target language.
</bodyText>
<sectionHeader confidence="0.924956" genericHeader="method">
5 Carrying out the experiments
</sectionHeader>
<bodyText confidence="0.999960857142857">
Our experiments are composed of two stages, each
one consisting of three steps (corresponding to the
next three sections). The first stage filters out ev-
ery candidate that is evaluated as not being a VPC,
while the second one intends to identify the id-
iomatic VPCs among the remaining candidates of
the previous stage.
</bodyText>
<subsectionHeader confidence="0.992937">
5.1 Generating candidates
</subsectionHeader>
<bodyText confidence="0.999915727272727">
For each of the 3,078 items in the Baldwin CD we
generated 2 sets of variations, syntactic and seman-
tic, and we will refer to these as alternative forms
or variations of a candidate.
The syntactic variations are generated using the
patterns S1 to S3 described in section 3. Following
the work of Villavicencio (2005) 3 frequently used
prepositions for, from and with are used as delim-
iters and we search for NPs in the form of pronouns
like this and definite NPs like the boy. The use of
alternative search patterns also helps to give an in-
</bodyText>
<page confidence="0.992572">
52
</page>
<bodyText confidence="0.839176181818182">
dication about the syntactic distribution of a can-
didate VPC, and consequently if it has a preferred
syntactic realisation. For instance, for eat up and
the delimiter with, we propose a list of Web search
queries for its respective variations vi, shown with
their corresponding Web frequencies in table 1.5
Variation (vi) Frequency (nY ahoo(vi))
eat up with 49200
eat the * up with 2240
eat this up with 1120
eat up the * with 3110
</bodyText>
<tableCaption confidence="0.842749">
Table 1: Distribution of syntactic variations for the
candidate eat up.
</tableCaption>
<bodyText confidence="0.999729838709678">
For the semantic variations, in order to capture
the idiomaticity of VPCs we generate the alterna-
tive forms by replacing the verb by its synonym
verbs as follows:
WNS Wordnet Strict variations. When using Word-
net, we consider any verb that belongs to the
same synset of the candidate as a synonym.
WNL Wordnet Loose variations. This is an indi-
rect synonymy relation capturing any verb
in Wordnet that belongs either to the same
synset or to a synset that is synonym of the
synset in which the candidate verb is con-
tained.
Levin These include all verbs in the same Levin
class as the candidate.
Multiword synonyms are ignored in this step to
avoid noisy search patterns, (e.g. *eat up up). The
examples for these variations are shown in table 2
for the candidate act in.
Wordnet and Levin are considered ambiguous
resources because one verb is potentially contained
in several synsets or classes. However, as Word
Sense Disambiguation is not within the scope of
this work we employ some heuristics to select a
given sense for the candidate verb. In order to test
the effect of frequency, the first heuristic adopts the
first synset in the list, as Wordnet organises synsets
in descending order of frequency (denoted as first).
To study the influence of the number of synonyms,
the second and third heuristics use respectively the
biggest (max) and smallest (min) synsets. The last
</bodyText>
<footnote confidence="0.923528">
5The Yahoo wildcard used in these searches matches any
word occurring in that particular position.
</footnote>
<table confidence="0.997298666666667">
playact in WN5 0
play in WN5 167000
behave in WNL 98
do in WNL 24600
pose in Levin 1610
qualify in Levin 358
rank in Levin 706
rate in Levin 16700
serve in Levin 2240
</table>
<tableCaption confidence="0.928234">
Table 2: Distribution of syntactic variations for the
candidate eat up.
</tableCaption>
<bodyText confidence="0.999930125">
heuristic is the union of all synonyms (all). These
heuristics are indicated using a subscript notation,
where e.g. WN5all symbolizes the WNS varia-
tions set using the union of all synsets as disam-
biguation heuristic. Finally, we generated two
additional sets of candidates by replacing the par-
ticle by one of the 48 prepositions listed in the
ANLT dictionary (prep) and also by one of 9 cho-
sen locative prepositions (loc-prep). It is impor-
tant to also verify possible variations of the prepo-
sition because compositional VPCs combine pro-
ductively with one or more groups of particles, e.g.
locatives, and present consequently a wider prob-
ability distribution among the variations, while an
idiomatic VPC presents a higher frequency for a
chosen preposition.
</bodyText>
<subsectionHeader confidence="0.998572">
5.2 Working the statistical measures out
</subsectionHeader>
<bodyText confidence="0.999694888888889">
The classifications of the candidate VPCs are done
using a set of measures: the frequencies of the
VPC candidates and of their individual words,
their Mutual Information (MI), x2 and Entropies.
We calculate the MI and x2 indices of a candidate
formed by a verb and a particle based on their in-
dividual frequencies and on their co-occurrence in
the BNC fragment.
The Entropy measure is given by
</bodyText>
<equation confidence="0.989414">
n
H(V ) = − p(vi) ln [ p(vi) ]
i=1
</equation>
<bodyText confidence="0.789218">
where
</bodyText>
<equation confidence="0.97625975">
n(vi)
p(vi) =
E n(vj)
∀ vj∈V
</equation>
<bodyText confidence="0.9818755">
is the probability of the variation vi to occur
among the set of all possible variations V =
</bodyText>
<table confidence="0.6201285">
Variation (vi) Source nY ahoo(vi)
act in — 2690
</table>
<page confidence="0.930228">
53
</page>
<equation confidence="0.894355571428571">
H(V ) ≤ 0.001081
nBNC(p) ≤ 51611
nYahoo(vtransitive) ≤ 1
nYahoo(v) ≤ 2020000000 : yes
nYahoo(v) &gt; 2020000000
x2 ≤ 25.99
· · ·
</equation>
<figureCaption confidence="0.9979905">
Figure 1: Fragment of the decision tree that filters
out non-VPCs.
</figureCaption>
<bodyText confidence="0.99923632">
{v1, v2, ... , vn}, and n(vi) is the Web frequency
for the variation vi.
The entropy of a probability distribution gives
us some clues about its shape. A very low en-
tropy is a sign of a heterogeneous distribution that
contains a peak. On the other hand, a distribution
that presents uniformity will lead to a high entropy
value.
The interest of H(V ) for the detection of VPCs
is in that true instances are more likely to not prefer
a canonical form, more widely distributing proba-
bilities over all alternative syntactic frames (S1 to
S3), while non-VPCs are more likely to choose one
frame and present low frequencies for the proposed
variations.
For the semantic variations, the entropy is cal-
culated from a set V of variations generated by the
Wordnet synset, Levin class and preposition sub-
stitutions described in § 5.1. The interpretation of
the entropy at this point is that high entropy indi-
cates compositionality while low entropy indicates
idiomaticity, since compositional VPCs are more
productive and distribute well over a class of verbs
or a class of prepositions and idiomatic VPCs pre-
fer a specific verb or preposition.
</bodyText>
<subsectionHeader confidence="0.999445">
5.3 Bringing estimations together
</subsectionHeader>
<bodyText confidence="0.999822875">
Once we got a set of measures to predict
VPCs and another to predict their idiomatic-
ity/compositionality, we would like to know which
measures are useful. Therefore, we combine our
measures automatically by building a decision tree
with the J48 algorithm, a version of the traditional
entropy-based C4.5 algorithm implemented in the
Weka package.6
</bodyText>
<sectionHeader confidence="0.926861" genericHeader="method">
6 Weighting the results up
</sectionHeader>
<bodyText confidence="0.91236">
The first stage of our experiments applied to the
3,078 VPC candidates generated a decision tree us-
</bodyText>
<footnote confidence="0.886475">
6http://www.cs.waikato.ac.nz/ml/weka/
</footnote>
<bodyText confidence="0.9998780625">
ing 10-fold cross validation that is partially repro-
duced in figure 1. From these, 2,848 candidates
were considered genuine VPCs, with 2,419 true
positives, 100 false negatives and 429 false posi-
tives. This leads to a recall of 96% of the VPCs
being kept in the list with a precision of 84.9%,
and an f-measure of 90.1%. We interpret this as a
very positive result since although some false neg-
atives have been filtered out, the remaining candi-
dates are now less noisy.
Figure 1 shows that the entropy of the variations
is the best predictor since it is at the root of the
tree. We can also see that there are several types
of raw frequencies being used before a correlation
measure appears (x2). We can conclude that the
frequency of each transitive, intransitive and split
configurations are also good predictors to detect
false from true VPCs. At this point, MI does not
seem to contribute to the classification task.
For our second stage, we generated Wordnet
synonym, Levin class and preposition variations
for a list of the 2,867 VPC candidates classified
as genuine cases. We also took into account the
proportion of synonyms that are MWEs (vpc-syn)
and the proportion of synonyms that contain the
candidate itself (self-syn).
In order to know what kind of contribution each
measure gives to the construction of the decision
tree, we used a simple iterative algorithm that con-
structs the set U of useful attributes. It first ini-
tialises U with all attributes, then calculates the
precision for each class (yes and no)7 on a cross
validation using all attributes in U. For each at-
tribute a ∈ U, it ignores a and recalculates preci-
sions. If both precisions decrease, the contribution
of a is positive, if both increase then a is negative,
else its contribution remains unknown. All fea-
tures that contribute negatively are removed from
U, and the algorithm is repeated until there is no
negative attribute left.
The step-by-step execution of the algorithm
can be observed in table 3, where the inconclu-
sive steps are hidden. We found out that the
optimal features are U∗ = {self-syn, H(prep),
H(Levinfirst), H(WN5first), H(WN5min),
H(Levinmax), H(Levinmin).} The self-syn in-
formation seems to be very important, as without
it precisions of both classes decrease considerably
</bodyText>
<footnote confidence="0.9860225">
7We use the precision as a quality estimator since it gives
a good idea of the amount of work that a grammar engineer
or lexicographer must perform in order to clear the list from
false positives.
</footnote>
<page confidence="0.988523">
54
</page>
<table confidence="0.999979916666667">
Precision
# Ignored No Yes +/−
1st iteration
0 — 86.6% 54.9%
1 vpc-syn 86.7% 56.6% −
2 self-syn 85.2% 28.7% +
4 H(loc-prep) 86.7% 56.1% −
6 H(WN5ma,) 87.5% 57.4% −
9 H(WNLfirst) 86.7% 57.9% −
10 H(WNLma,) 86.7% 57.8% −
11 H(WNLmin) 86.9% 57.6% −
16 H(Levinall) 86.7% 55.1% −
2nd iteration
17 — 87.7% 60.3%
18 H(prep) 87.6% 59.2% +
21 H(WN5all) 87.8% 61.6% −
22 H(WNLall) 87.8% 61.0% −
23 H(Levinfirst) 87.5% 60.2% +
3rd iteration
26 — 87.8% 61.9%
27 H(WN5first) 87.8% 61.9% +
28 H(WN5min) 87.7% 61.1% +
29 H(Levinma,) 87.8% 61.6 +
30 H(Levinmin) 87.7% 61.5% +
</table>
<tableCaption confidence="0.8431125">
Table 3: Iterative attributes selection process. Pre-
cision in each class is used as quality estimator.
</tableCaption>
<bodyText confidence="0.993960615384615">
(experiment #2).
All entropies of the WNL heuristics are of little
or no utility. This could probably be explained by
either the choice of simple WSD heuristics for se-
lecting synsets, or because the indirect synonymy
information is too far related to the original verb to
be used in variational patterns. Inspecting the gen-
erated variations, we notice that most of the syn-
onym synsets are related to secondary senses or
very specific uses of a verb and are thus not cor-
rectly disambiguated.
In what concerns the WNS sets, only the small-
est and first synset were kept, suggesting again that
it may not be a good idea to maximise the syn-
onyms set and for future work, we intent to es-
tablish a threshold for a synset to be taken into
account. In addition, we can also infer a posi-
tive contribution of the frequency of a sense with
the choice of the first synset returned by Word-
net resulting in a reasonable WSD heuristic (which
is compatible with the results by McCarthy et al.
(2004)).
On the other hand, the algorithm selected the
first, the smallest and the biggest of the Levin’s
sets. This probably happens because the major-
ity of these verbs belongs only to one or two, but
never to a great number of classes. Since the gran-
ularity of the classes is coarser than for synsets,
the heuristics often offer four equal or very close
entropies and thus redundant information. As an
overall result, the last iteration shown in table 3
indicates a precision of 61.9% for the classifier in
detecting idiomatic VPCs, that is to say that we au-
tomatically retrieved 176 VPCs where 67 are false
positives and 109 are truly idiomatic. This value is
a quality estimator for the resulting VPCs that will
potentially be used in the construction of a lexi-
con. Recall of idiomatic VPCs goes from 16.7%
to 24.9%.
</bodyText>
<sectionHeader confidence="0.999427" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999988290322581">
One of the important challenges for robust natu-
ral language processing systems is to be able to
successfully deal with Multiword Expressions and
related constructions. We investigated the identifi-
cation of VPCs using a combination of statistical
methods and linguistic information, and whether
there is a correlation between the productivity of
VPCs and their semantics that could help us detect
if a VPC is idiomatic or compositional.
The results confirm that the use of statistical
and linguistic information to automatically iden-
tify verb-particle constructions presents a reason-
able way of improving coverage of existing lexi-
cal resources in a very simple and straightforward
manner. In terms of grammar engineering, the in-
formation about compositional candidates belong-
ing to productive classes provides us with the ba-
sis for constructing a family of fine-grained redun-
dancy rules for these classes. These rules are ap-
plied in a constrained way to verbs already in the
lexicon, according to their semantic classes. The
VPCs identified as idiomatic, on the other hand,
need to be explicitly added to the lexicon, after
their semantic is determined. This study can also
be complemented with the results of investigations
into the semantics of VPCs, as discussed by both
Bannard (2005) and McCarthy et al. (2003).
In addition, the use of clustering methods is an
interesting possibility for automatically identify-
ing clusters of productive classes of both verbs and
of particles that combine well together.
</bodyText>
<page confidence="0.997383">
55
</page>
<sectionHeader confidence="0.977815" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9963836">
This research was partly supported by the CNPq
research project Recuperac¸˜ao de Informac¸˜oes
Multil´ıng¨ues (CNPq Universal 484585/2007-0).
Macleod, Catherine and Ralph Grishman. 1998. Comlex syn-
tax reference manual, Proteus Project.
McCarthy, Diana, Bill Keller, and John Carroll. 2003. De-
tecting a continuum of compositionality in phrasal verbs.
In Proceedings of the ACL 2003 workshop on Multiword
expressions, pages 73–80, Morristown, NJ, USA. Associ-
ation for Computational Linguistics.
</bodyText>
<sectionHeader confidence="0.998473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999837602564103">
Baldwin, Timothy, Emily M. Bender, Dan Flickinger, Ara
Kim, and Stephan Oepen. 2004. Road-testing the English
Resource Grammar over the British National Corpus. In
Fourth International Conference on Language Resources
and Evaluation (LREC 2004), Lisbon, Portugal.
Baldwin, Timothy. 2005. Deep lexical acquisition of verb-
particle constructions. Computer Speech and Language,
19(4):398–414.
Bannard, Colin J. 2005. Learning about the meaning of verb-
particle constructions from corpora. Computer Speech and
Language, 19(4):467–478.
Bolinger, Dwight. 1971. The phrasal verb in English. Har-
vard University Press, Harvard, USA.
Burnard, Lou. 2000. User reference guide for the British Na-
tional Corpus. Technical report, Oxford University Com-
puting Services.
Carroll, John and Claire Grover. 1989. The derivation of a
large computational lexicon of English from LDOCE. In
Boguraev, B. and E. Briscoe, editors, Computational Lexi-
cography for Natural Language Processing. Longman.
Copestake, Ann and Dan Flickinger. 2000. An open-source
grammar development environment and broad-coverage
English grammar using HPSG. In Proceedings of the
2nd International Conference on Language Resources and
Evaluation (LREC 2000).
Deh´e, Nicole. 2002. Particle verbs in English: syntax, in-
formation structure and intonation. John Benjamins, Am-
sterdam/Philadelphia.
Evert, Stefan and Brigitte Krenn. 2005. Using small random
samples for the manual evaluation of statistical association
measures. Computer Speech and Language, 19(4):450–
466.
Fazly, Afsaneh and Suzanne Stevenson. 2006. Automatically
constructing a lexicon of verb phrase idiomatic combina-
tions. In EACL. The Association for Computer Linguis-
tics.
Fellbaum, Christiane, editor. 1998. WordNet: An Electronic
Lexical Database (Language, Speech, and Communica-
tion). The MIT Press, May.
Fraser, Bruce. 1976. The Verb-Particle Combination in En-
glish. Academic Press, New York, USA.
Jackendoff, Ray. 2002. English particle constructions, the
lexicon, and the autonomy of syntax. In N. Deh´e, R. Jack-
endoff, A. McIntyre and S. Urban, editors, Verb-Particle
Explorations. Berlin: Mouton de Gruyter.
Levin, Beth. 1993. English Verb Classes and Alternations:
a preliminary investigation. University of Chicago Press,
Chicago and London.
McCarthy, Diana, Rob Koeling, Julie Weeds, and John Car-
roll. 2004. Finding predominant word senses in untagged
text. In Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, page 279. Associa-
tion for Computational Linguistics.
Pearce, Darren. 2002. A comparative evaluation of colloca-
tion extraction techniques. In Third International Confer-
ence on Language Resources and Evaluation, Las Palmas,
Canary Islands, Spain.
Ramisch, Carlos, Paulo Schreiner, Marco Idiart, and Aline
Villavicencio. 2008. An evaluation of methods for the ex-
traction of multiword expressions. In Proceedings of the
LREC Workshop - Towards a Shared Task for Multiword
Expressions (MWE 2008), pages 50–53, Marrakech, Mo-
rocco, June.
Sharoff, Serge. 2004. What is at stake: a case study of rus-
sian expressions starting with a preposition. pages 17–23,
Barcelona, Spain.
Villavicencio, Aline. 2005. The availability of verb-particle
constructions in lexical resources: How much is enough?
Journal of Computer Speech and Language Processing,
19(4):415–432.
Wurmbrand, S. 2000. The structure(s) of particle verbs. Ms.,
McGill University.
Zhang, Yi, Valia Kordoni, Aline Villavicencio, and Marco
Idiart. 2006. Automated multiword expression prediction
for grammar engineering. In Proceedings of the Workshop
on Multiword Expressions: Identifying and Exploiting Un-
derlying Properties, pages 36–44, Sydney, Australia. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.998418">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.797995">
<title confidence="0.9896415">Picking them up and Figuring them out: Verb-Particle Constructions, Noise and Idiomaticity</title>
<author confidence="0.999419">Aline Leonardo Marco of Informatics</author>
<author confidence="0.999419">Federal University of Rio Grande do Sul</author>
<affiliation confidence="0.946241">GETALP Laboratory, Joseph Fourier University - Grenoble INP (France) of Computer Sciences, Bath University (UK) of Physics, Federal University of Rio Grande do Sul (Brazil)</affiliation>
<abstract confidence="0.998335">This paper investigates, in a first stage, some methods for the automatic acquisition of verb-particle constructions (VPCs) taking into account their statistical properties and some regular patterns found in productive combinations of verbs and particles. Given the limited coverage provided by lexical resources, such as dictionaries, and the constantly growing number of VPCs, possible ways of automatically identifying them are crucial for any NLP task that requires some degree of semantic interpretation. In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC. The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Emily M Bender</author>
<author>Dan Flickinger</author>
<author>Ara Kim</author>
<author>Stephan Oepen</author>
</authors>
<title>Road-testing the English Resource Grammar over the British National Corpus.</title>
<date>2004</date>
<booktitle>In Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3815" citStr="Baldwin et al. (2004)" startWordPosition="575" endWordPosition="578"> someone or some place - (Fraser, 1976)).1 Thus, the knowledge of which combinations are possible is crucial for precision grammar engineering. In addition, as the semantics of VPCs varies from the idiomatic to the more compositional cases, methods for the automatic detection and handling of idiomaticity are very important for any NLP task that involves some degree of semantic interpretation such as Machine Translation (in this case avoiding the problem of producing an unrelated translation for a source sentence). Automatic methods for the identification of idiomaticity in MWEs have been 1See Baldwin et al. (2004) for a discussion of the effects of multiword expressions like VPCs on a parser’s performance. 49 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 49–56 Manchester, August 2008 proposed using a variety of approaches such as statistical, substitutional, distributional, etc. (e.g. McCarthy et al. (2003), Bannard (2005) and Fazly and Stevenson (2006)). In particular, Fazly and Stevenson (2006) look at the correlation between syntactic fixedness (in terms of e.g. passivisation, choice of determiner type and pluralisation) and non-compositionality of </context>
</contexts>
<marker>Baldwin, Bender, Flickinger, Kim, Oepen, 2004</marker>
<rawString>Baldwin, Timothy, Emily M. Bender, Dan Flickinger, Ara Kim, and Stephan Oepen. 2004. Road-testing the English Resource Grammar over the British National Corpus. In Fourth International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
</authors>
<title>Deep lexical acquisition of verbparticle constructions.</title>
<date>2005</date>
<journal>Computer Speech and Language,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="2061" citStr="Baldwin (2005)" startWordPosition="287" endWordPosition="288">essions (MWEs), like compound nouns (science fiction) and phrasal verbs (carry out) (e.g. Pearce (2002), Evert and Krenn (2005) and Zhang et al. (2006)). Some of them employ language and/or type dependent linguistic knowledge for the task, while others employ independent statistical methods, such as Mutual Information and Log-likelihood (e.g. Pearce (2002) and, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words is in fact an MWE. Although some research aims at developing methods for dealing with MWEs in general (e.g. Zhang et al. (2006), Ramisch et al. (2008)), there is also some work that deals with specific types of MWEs (e.g. Pearce (2002) on collocations and Villavicencio (2005) on verb-particle constructions (VPCs)) as each of these MWE types has distinct distributional and linguistic characteristics. VPCs are combinations of verbs and particles, such as take off in Our plane took off late, that due to thei</context>
<context position="10442" citStr="Baldwin (2005)" startWordPosition="1689" endWordPosition="1690">h existing ones, where often the verb is varied and the particle remains (e.g. hang on, hold on and wait on). Similarly, particles from a given semantic class can be replaced by other particles from the same class in compositional combinations: send up/in/back/away (Wurmbrand, 2000). By identifying classes of verbs that follow patterns such as these in VPCs, we can help in the identification of a new unknown candidate combination, using the degree of productivity of a class to which the verb belongs as a back-off strategy. In terms of methods for automatic identification of VPCs from corpora, Baldwin (2005) proposes the extraction of VPCs with valence information from raw text, exploring a range of techniques (using (a) a POS tagger, (b) a chunker, (c) a chunk grammar, (d) a dependency parser, and (e) a combination of all methods). Villavicencio (2005) uses the Web as a corpus and productive patterns of combination to generate and validate candidate VPCs. The identification of compositionality in VPCs is addressed by McCarthy et al. (2003) who examine the overlap of similar words in an automatically acquired distributional thesaurus for verb and VPCs, and by Bannard (2005) who uses a distributio</context>
</contexts>
<marker>Baldwin, 2005</marker>
<rawString>Baldwin, Timothy. 2005. Deep lexical acquisition of verbparticle constructions. Computer Speech and Language, 19(4):398–414.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin J Bannard</author>
</authors>
<title>Learning about the meaning of verbparticle constructions from corpora. Computer Speech and Language,</title>
<date>2005</date>
<contexts>
<context position="4181" citStr="Bannard (2005)" startWordPosition="629" endWordPosition="630">mantic interpretation such as Machine Translation (in this case avoiding the problem of producing an unrelated translation for a source sentence). Automatic methods for the identification of idiomaticity in MWEs have been 1See Baldwin et al. (2004) for a discussion of the effects of multiword expressions like VPCs on a parser’s performance. 49 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 49–56 Manchester, August 2008 proposed using a variety of approaches such as statistical, substitutional, distributional, etc. (e.g. McCarthy et al. (2003), Bannard (2005) and Fazly and Stevenson (2006)). In particular, Fazly and Stevenson (2006) look at the correlation between syntactic fixedness (in terms of e.g. passivisation, choice of determiner type and pluralisation) and non-compositionality of verb-noun compounds such as shoot the breeze. In this work we investigate the automatic extraction of VPCs, looking into a variety of methods, combining linguistic with statistical information, ranging from frequencies to association measures: Mutual Information (MI), χ2 and Entropy. We also investigate the determination of compositionality of VPCs verifying wheth</context>
<context position="11019" citStr="Bannard (2005)" startWordPosition="1785" endWordPosition="1786"> of VPCs from corpora, Baldwin (2005) proposes the extraction of VPCs with valence information from raw text, exploring a range of techniques (using (a) a POS tagger, (b) a chunker, (c) a chunk grammar, (d) a dependency parser, and (e) a combination of all methods). Villavicencio (2005) uses the Web as a corpus and productive patterns of combination to generate and validate candidate VPCs. The identification of compositionality in VPCs is addressed by McCarthy et al. (2003) who examine the overlap of similar words in an automatically acquired distributional thesaurus for verb and VPCs, and by Bannard (2005) who uses a distributional approach to determine when and to what extent the components of a VPC contribute their simplex meanings to the interpretation of the VPC. Both report a correlation between some of the measures and compositionality judgements. 3 The Underlying Hypotheses The problem of the automatic detection and classification of VPCs can be summarised as, for a given VPC candidate, to answer to the questions: Q1 Is it a real VPC or some free combination of verb and preposition/adverb or a prepositional verb? Q2 If it is a true VPC, is it idiomatic or compositional? In order to answe</context>
<context position="29193" citStr="Bannard (2005)" startWordPosition="4857" endWordPosition="4858">orward manner. In terms of grammar engineering, the information about compositional candidates belonging to productive classes provides us with the basis for constructing a family of fine-grained redundancy rules for these classes. These rules are applied in a constrained way to verbs already in the lexicon, according to their semantic classes. The VPCs identified as idiomatic, on the other hand, need to be explicitly added to the lexicon, after their semantic is determined. This study can also be complemented with the results of investigations into the semantics of VPCs, as discussed by both Bannard (2005) and McCarthy et al. (2003). In addition, the use of clustering methods is an interesting possibility for automatically identifying clusters of productive classes of both verbs and of particles that combine well together. 55 Acknowledgments This research was partly supported by the CNPq research project Recuperac¸˜ao de Informac¸˜oes Multil´ıng¨ues (CNPq Universal 484585/2007-0). Macleod, Catherine and Ralph Grishman. 1998. Comlex syntax reference manual, Proteus Project. McCarthy, Diana, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In Procee</context>
</contexts>
<marker>Bannard, 2005</marker>
<rawString>Bannard, Colin J. 2005. Learning about the meaning of verbparticle constructions from corpora. Computer Speech and Language, 19(4):467–478.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dwight Bolinger</author>
</authors>
<title>The phrasal verb in English.</title>
<date>1971</date>
<publisher>Harvard University Press,</publisher>
<location>Harvard, USA.</location>
<contexts>
<context position="5657" citStr="Bolinger, 1971" startWordPosition="860" endWordPosition="861">ion of their semantics (§ 2). We then explain the research questions and the assumptions that serve as the basis for the application of statistical measures (§ 3) on the dataset (§ 4). Our methods and experiments are then detailed (§ 5), and the results obtained are analysed (§ 6). We conclude with a discussion of the contributions that this work brings to the research on verb-particle constructions (§ 7). 2 Verb-Particle Constructions in Theory and Practice Particles in VPCs are characterised by containing features of motion-through-location and of completion or result in their core meaning (Bolinger, 1971). VPCs can range from idiosyncratic or semiidiosyncratic combinations, such as get on (in e.g. Bill got on well with his new colleagues), to more regular ones, such as tear up (e.g. in In a rage she tore up the letter Jack gave her). A three way classification is adopted by (Deh´e, 2002) and (Jackendoff, 2002), where a VPC can be classified as compositional, idiomatic or aspectual, depending on its sense. In compositional VPCs the meaning of the construction is determined by the literal interpretations of the particle and the verb. These VPCs usually involve particles with directional or spati</context>
<context position="7560" citStr="Bolinger (1971)" startWordPosition="1186" endWordPosition="1187">ubcategorisation frames. For example, give up can occur as an intransitive VPC (e.g. in I give up! Tell me the answer), where no other complement is required, or it may occur as a transitive VPC which requires a further NP complement (e.g. in She gave up alcohol while she was pregnant). Since in English particles tend to be homographs with prepositions (up, out, in), a verb followed by a preposition/particle and an NP can be ambiguous between a transitive VPC and a prepositional verb (e.g. rely on, in He relies on his wife for everything). Some criteria that characterise VPCs are discussed by Bolinger (1971):2 C1 In a transitive VPC the particle may come either before or after the NP (e.g. He backed up the team vs. He backed the team up). However, whether a particle can be separated or not from the verb may depend on the degree of bonding between them, the size of the NP, and the kind of NP. This is considered by many to be sufficient condition for diagnosing a VPC, as prepositions can only appear in a position contiguous to the verb (e.g. *He got the bus off). C2 Unstressed personal pronouns must precede the particle (e.g. They ate it up but not *They ate up it). C3 If the particle precedes a si</context>
</contexts>
<marker>Bolinger, 1971</marker>
<rawString>Bolinger, Dwight. 1971. The phrasal verb in English. Harvard University Press, Harvard, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>User reference guide for the British National Corpus.</title>
<date>2000</date>
<tech>Technical report,</tech>
<institution>Oxford University Computing Services.</institution>
<contexts>
<context position="15007" citStr="Burnard (2000)" startWordPosition="2451" endWordPosition="2452">his dataset with information about whether each candidate is a genuine VPC or not, where a candidate is consider genuine if it belongs to at least one of a set of machine-readable dictionaries: the Alvey Natural Language Tools (ANLT) lexicon (Carroll and Grover, 1989), the Comlex lexicon (Macleod and Grishman, 1998), and the LinGO English Resource Grammar (ERG) (Copestake and Flickinger, 2000)4. With this criterion 81.8% of them are considered genuine VPCs. To gather information about the candidates in this work we employ both a fragment of 1.8M sentences from the British National Corpus (BNC Burnard (2000)) and the Web as corpora. The BNC fragment is used to calculate the correlation 3This dataset was provided by Timothy Baldwin for the MWE2008 Workshop. 4Version of November 2001. measures since they require a corpus with known size. The Web is used to generate frequencies for the entropy measures, as discussed in § 5.2. Web frequencies are approximated by the number of pages containing a candidate and indexed by Yahoo Search API. In order to keep the searches as simple and self-sufficient as possible, no additional sources of information are used (Villavicencio, 2005). Therefore, the frequenci</context>
</contexts>
<marker>Burnard, 2000</marker>
<rawString>Burnard, Lou. 2000. User reference guide for the British National Corpus. Technical report, Oxford University Computing Services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Claire Grover</author>
</authors>
<title>The derivation of a large computational lexicon of English from LDOCE.</title>
<date>1989</date>
<booktitle>Computational Lexicography for Natural Language Processing.</booktitle>
<editor>In Boguraev, B. and E. Briscoe, editors,</editor>
<publisher>Longman.</publisher>
<contexts>
<context position="14661" citStr="Carroll and Grover, 1989" startWordPosition="2395" endWordPosition="2398">wing the substitution of a member by a related word? – NO: idiomatic VPC – YES: compositional VPC 4 Data Sources To generate a gold standard, we used the Baldwin VPC candidates dataset (henceforth Baldwin CD)3, which contains 3,078 English VPC candidates annotated with information about idiomaticity (14.5% are considered idiomatic). We further annotated this dataset with information about whether each candidate is a genuine VPC or not, where a candidate is consider genuine if it belongs to at least one of a set of machine-readable dictionaries: the Alvey Natural Language Tools (ANLT) lexicon (Carroll and Grover, 1989), the Comlex lexicon (Macleod and Grishman, 1998), and the LinGO English Resource Grammar (ERG) (Copestake and Flickinger, 2000)4. With this criterion 81.8% of them are considered genuine VPCs. To gather information about the candidates in this work we employ both a fragment of 1.8M sentences from the British National Corpus (BNC Burnard (2000)) and the Web as corpora. The BNC fragment is used to calculate the correlation 3This dataset was provided by Timothy Baldwin for the MWE2008 Workshop. 4Version of November 2001. measures since they require a corpus with known size. The Web is used to ge</context>
</contexts>
<marker>Carroll, Grover, 1989</marker>
<rawString>Carroll, John and Claire Grover. 1989. The derivation of a large computational lexicon of English from LDOCE. In Boguraev, B. and E. Briscoe, editors, Computational Lexicography for Natural Language Processing. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>An open-source grammar development environment and broad-coverage English grammar using HPSG.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="14789" citStr="Copestake and Flickinger, 2000" startWordPosition="2413" endWordPosition="2416">te a gold standard, we used the Baldwin VPC candidates dataset (henceforth Baldwin CD)3, which contains 3,078 English VPC candidates annotated with information about idiomaticity (14.5% are considered idiomatic). We further annotated this dataset with information about whether each candidate is a genuine VPC or not, where a candidate is consider genuine if it belongs to at least one of a set of machine-readable dictionaries: the Alvey Natural Language Tools (ANLT) lexicon (Carroll and Grover, 1989), the Comlex lexicon (Macleod and Grishman, 1998), and the LinGO English Resource Grammar (ERG) (Copestake and Flickinger, 2000)4. With this criterion 81.8% of them are considered genuine VPCs. To gather information about the candidates in this work we employ both a fragment of 1.8M sentences from the British National Corpus (BNC Burnard (2000)) and the Web as corpora. The BNC fragment is used to calculate the correlation 3This dataset was provided by Timothy Baldwin for the MWE2008 Workshop. 4Version of November 2001. measures since they require a corpus with known size. The Web is used to generate frequencies for the entropy measures, as discussed in § 5.2. Web frequencies are approximated by the number of pages cont</context>
</contexts>
<marker>Copestake, Flickinger, 2000</marker>
<rawString>Copestake, Ann and Dan Flickinger. 2000. An open-source grammar development environment and broad-coverage English grammar using HPSG. In Proceedings of the 2nd International Conference on Language Resources and Evaluation (LREC 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicole Deh´e</author>
</authors>
<title>Particle verbs in English: syntax, information structure and intonation.</title>
<date>2002</date>
<journal>John Benjamins, Amsterdam/Philadelphia.</journal>
<marker>Deh´e, 2002</marker>
<rawString>Deh´e, Nicole. 2002. Particle verbs in English: syntax, information structure and intonation. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
<author>Brigitte Krenn</author>
</authors>
<title>Using small random samples for the manual evaluation of statistical association measures.</title>
<date>2005</date>
<journal>Computer Speech and Language,</journal>
<volume>19</volume>
<issue>4</issue>
<pages>466</pages>
<contexts>
<context position="1574" citStr="Evert and Krenn (2005)" startWordPosition="220" endWordPosition="223">al for any NLP task that requires some degree of semantic interpretation. In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC. The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases. 1 Introduction Considerable investigative effort has focused on the automatic identification of Multiword Expressions (MWEs), like compound nouns (science fiction) and phrasal verbs (carry out) (e.g. Pearce (2002), Evert and Krenn (2005) and Zhang et al. (2006)). Some of them employ language and/or type dependent linguistic knowledge for the task, while others employ independent statistical methods, such as Mutual Information and Log-likelihood (e.g. Pearce (2002) and, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words is in fact an MWE. Alth</context>
</contexts>
<marker>Evert, Krenn, 2005</marker>
<rawString>Evert, Stefan and Brigitte Krenn. 2005. Using small random samples for the manual evaluation of statistical association measures. Computer Speech and Language, 19(4):450– 466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In EACL. The Association</booktitle>
<institution>for Computer Linguistics.</institution>
<contexts>
<context position="4212" citStr="Fazly and Stevenson (2006)" startWordPosition="632" endWordPosition="636">on such as Machine Translation (in this case avoiding the problem of producing an unrelated translation for a source sentence). Automatic methods for the identification of idiomaticity in MWEs have been 1See Baldwin et al. (2004) for a discussion of the effects of multiword expressions like VPCs on a parser’s performance. 49 CoNLL 2008: Proceedings of the 12th Conference on Computational Natural Language Learning, pages 49–56 Manchester, August 2008 proposed using a variety of approaches such as statistical, substitutional, distributional, etc. (e.g. McCarthy et al. (2003), Bannard (2005) and Fazly and Stevenson (2006)). In particular, Fazly and Stevenson (2006) look at the correlation between syntactic fixedness (in terms of e.g. passivisation, choice of determiner type and pluralisation) and non-compositionality of verb-noun compounds such as shoot the breeze. In this work we investigate the automatic extraction of VPCs, looking into a variety of methods, combining linguistic with statistical information, ranging from frequencies to association measures: Mutual Information (MI), χ2 and Entropy. We also investigate the determination of compositionality of VPCs verifying whether the degree of semantic flexi</context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Fazly, Afsaneh and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In EACL. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database (Language, Speech, and Communication).</title>
<date>1998</date>
<editor>Fellbaum, Christiane, editor.</editor>
<publisher>The MIT Press,</publisher>
<marker>1998</marker>
<rawString>Fellbaum, Christiane, editor. 1998. WordNet: An Electronic Lexical Database (Language, Speech, and Communication). The MIT Press, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Fraser</author>
</authors>
<title>The Verb-Particle Combination in English.</title>
<date>1976</date>
<publisher>Academic Press,</publisher>
<location>New York, USA.</location>
<contexts>
<context position="3233" citStr="Fraser, 1976" startWordPosition="484" endWordPosition="485">Our plane took off late, that due to their complex characteristics and flexible nature, provide a real challenge for NLP. In particular, there is a lack of adequate resources to identify and treat them, and those that are available provide only limited coverage, in face of the huge number of combinations in use. For tasks like parsing and generation, it is essential to know whether a given VPC is possible or not, to avoid for example using combinations that sound unnatural or ungrammatical to native speakers (e.g. give/lend/?grant out for the conveying of something to someone or some place - (Fraser, 1976)).1 Thus, the knowledge of which combinations are possible is crucial for precision grammar engineering. In addition, as the semantics of VPCs varies from the idiomatic to the more compositional cases, methods for the automatic detection and handling of idiomaticity are very important for any NLP task that involves some degree of semantic interpretation such as Machine Translation (in this case avoiding the problem of producing an unrelated translation for a source sentence). Automatic methods for the identification of idiomaticity in MWEs have been 1See Baldwin et al. (2004) for a discussion </context>
<context position="9315" citStr="Fraser (1976)" startWordPosition="1503" endWordPosition="1504">ons and excluding genuine VPCs. 50 In this paper we use the first two criteria, therefore the candidates may contain noise (in the form of prepositional verbs and related constructions). VPCs have been the subject of a considerable amount of interest, and some analysis has been done on the subject of productive VPCs. In many cases the particle seems to be compositionally adding a specific meaning to the construction and following a productive pattern (e.g. in tear up, cut up and split up, where the verbs are semantically related and up adds a sense of completion to the action of these verbs). Fraser (1976) points out that semantic properties of verbs can affect their ability to combine with particles: for example, bolt/cement/clamp/glue/paste/nail are semantically similar verbs where the objects represented by the verbs are used to join material, and they can all combine with down. There is clearly a common semantic thread running through this list, so that a new verb that is semantically similar to them can also be reasonably assumed to combine with down. Indeed, frequently new VPCs are formed by analogy with existing ones, where often the verb is varied and the particle remains (e.g. hang on,</context>
<context position="13141" citStr="Fraser (1976)" startWordPosition="2147" endWordPosition="2148"> preposition needs to have an NP complement. Therefore, we will assume that a true VPC occurs in the following configurations, according to Villavicencio (2005) and Ramisch et al. (2008): S1 VERB + PARTICLE + DELIMITER, for intransitive VPCs; S2 VERB + NP + PARTICLE + DELIMITER, for transitive split VPCs and; S3 VERB + PARTICLE + NP + DELIMITER, for transitive joint VPCs. In order to answer Q2, we look at the link between productivity and compositionality and assume that a compositional VPC accepts the substitution of one of its members by a semantically related term. This is in accordance to Fraser (1976), who shows that semantic properties of 51 verbs can affect their ability to combine with particles: for example verbs of hunting combining with the resultative down (hunt/track/trail/follow down) and verbs of cooking with the aspectual up (bake/cook/fry/broil up), forming essentially productive VPCs. Idiomatic VPCs, however, will not accept the substitution of one of its members by a related term (e.g. get and its synonyms in get/*obtain/*receive over), even if at first glance this could seem natural. In our experiments, we will consider that a VPC is compositional if it accepts: the replacem</context>
</contexts>
<marker>Fraser, 1976</marker>
<rawString>Fraser, Bruce. 1976. The Verb-Particle Combination in English. Academic Press, New York, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>English particle constructions, the lexicon, and the autonomy of syntax. In</title>
<date>2002</date>
<editor>N. Deh´e, R. Jackendoff, A. McIntyre and S. Urban, editors,</editor>
<location>Berlin: Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="5968" citStr="Jackendoff, 2002" startWordPosition="917" endWordPosition="919">ion of the contributions that this work brings to the research on verb-particle constructions (§ 7). 2 Verb-Particle Constructions in Theory and Practice Particles in VPCs are characterised by containing features of motion-through-location and of completion or result in their core meaning (Bolinger, 1971). VPCs can range from idiosyncratic or semiidiosyncratic combinations, such as get on (in e.g. Bill got on well with his new colleagues), to more regular ones, such as tear up (e.g. in In a rage she tore up the letter Jack gave her). A three way classification is adopted by (Deh´e, 2002) and (Jackendoff, 2002), where a VPC can be classified as compositional, idiomatic or aspectual, depending on its sense. In compositional VPCs the meaning of the construction is determined by the literal interpretations of the particle and the verb. These VPCs usually involve particles with directional or spatial meaning, and these can often be replaced by the appropriate directional PPs (e.g. carry in in Sheila carried the bags in/into the house Deh´e (2002)). Idiomatic VPCs, on the other hand, cannot have their meaning determined by interpreting their components literally (e.g. get on, meaning to be on friendly te</context>
</contexts>
<marker>Jackendoff, 2002</marker>
<rawString>Jackendoff, Ray. 2002. English particle constructions, the lexicon, and the autonomy of syntax. In N. Deh´e, R. Jackendoff, A. McIntyre and S. Urban, editors, Verb-Particle Explorations. Berlin: Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations: a preliminary investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago and London.</location>
<contexts>
<context position="15897" citStr="Levin, 1993" startWordPosition="2595" endWordPosition="2596">he entropy measures, as discussed in § 5.2. Web frequencies are approximated by the number of pages containing a candidate and indexed by Yahoo Search API. In order to keep the searches as simple and self-sufficient as possible, no additional sources of information are used (Villavicencio, 2005). Therefore, the frequencies are quite conservative in the sense that by employing inflected forms of verbs, potentially much more evidence could be gathered. For the generation of semantic variational patterns, we use both Wordnet 3.0 (Fellbaum, 1998) and Levin’s English Verb Classes and Alternations (Levin, 1993). Wordnet is organised as a graph of concepts, called synsets, linked by relations of synonymy, hyponymy, etc. Each synset contains a list of words that represent the concept. The verbs in a synset and its synonym synsets are used to generate variations of a VPC candidate. Likewise we use Levin’s classes, which define 190 fine-grained classes for English verbs, based on their syntactic and semantic features. It is important to highlight that the generation of the semantic variations strongly relies on these resources. Therefore, cross-language extension would depend on the availability of simi</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, Beth. 1993. English Verb Classes and Alternations: a preliminary investigation. University of Chicago Press, Chicago and London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding predominant word senses in untagged text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>279</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27077" citStr="McCarthy et al. (2004)" startWordPosition="4508" endWordPosition="4511">t of the synonym synsets are related to secondary senses or very specific uses of a verb and are thus not correctly disambiguated. In what concerns the WNS sets, only the smallest and first synset were kept, suggesting again that it may not be a good idea to maximise the synonyms set and for future work, we intent to establish a threshold for a synset to be taken into account. In addition, we can also infer a positive contribution of the frequency of a sense with the choice of the first synset returned by Wordnet resulting in a reasonable WSD heuristic (which is compatible with the results by McCarthy et al. (2004)). On the other hand, the algorithm selected the first, the smallest and the biggest of the Levin’s sets. This probably happens because the majority of these verbs belongs only to one or two, but never to a great number of classes. Since the granularity of the classes is coarser than for synsets, the heuristics often offer four equal or very close entropies and thus redundant information. As an overall result, the last iteration shown in table 3 indicates a precision of 61.9% for the classifier in detecting idiomatic VPCs, that is to say that we automatically retrieved 176 VPCs where 67 are fa</context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>McCarthy, Diana, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding predominant word senses in untagged text. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 279. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darren Pearce</author>
</authors>
<title>A comparative evaluation of collocation extraction techniques.</title>
<date>2002</date>
<booktitle>In Third International Conference on Language Resources and Evaluation,</booktitle>
<location>Las Palmas, Canary Islands,</location>
<contexts>
<context position="1550" citStr="Pearce (2002)" startWordPosition="218" endWordPosition="219"> them are crucial for any NLP task that requires some degree of semantic interpretation. In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC. The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases. 1 Introduction Considerable investigative effort has focused on the automatic identification of Multiword Expressions (MWEs), like compound nouns (science fiction) and phrasal verbs (carry out) (e.g. Pearce (2002), Evert and Krenn (2005) and Zhang et al. (2006)). Some of them employ language and/or type dependent linguistic knowledge for the task, while others employ independent statistical methods, such as Mutual Information and Log-likelihood (e.g. Pearce (2002) and, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words</context>
</contexts>
<marker>Pearce, 2002</marker>
<rawString>Pearce, Darren. 2002. A comparative evaluation of collocation extraction techniques. In Third International Conference on Language Resources and Evaluation, Las Palmas, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Ramisch</author>
<author>Paulo Schreiner</author>
<author>Marco Idiart</author>
<author>Aline Villavicencio</author>
</authors>
<title>An evaluation of methods for the extraction of multiword expressions.</title>
<date>2008</date>
<booktitle>In Proceedings of the LREC Workshop - Towards a Shared Task for Multiword Expressions (MWE</booktitle>
<pages>50--53</pages>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="2301" citStr="Ramisch et al. (2008)" startWordPosition="328" endWordPosition="331"> task, while others employ independent statistical methods, such as Mutual Information and Log-likelihood (e.g. Pearce (2002) and, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words is in fact an MWE. Although some research aims at developing methods for dealing with MWEs in general (e.g. Zhang et al. (2006), Ramisch et al. (2008)), there is also some work that deals with specific types of MWEs (e.g. Pearce (2002) on collocations and Villavicencio (2005) on verb-particle constructions (VPCs)) as each of these MWE types has distinct distributional and linguistic characteristics. VPCs are combinations of verbs and particles, such as take off in Our plane took off late, that due to their complex characteristics and flexible nature, provide a real challenge for NLP. In particular, there is a lack of adequate resources to identify and treat them, and those that are available provide only limited coverage, in face of the hug</context>
<context position="12714" citStr="Ramisch et al. (2008)" startWordPosition="2067" endWordPosition="2070">bs that allow less syntactic configurations than VPCs and are therefore more rigid (§ 2). To further distinguish VPCs from prepositional verbs and other related constructions we also verify the possibility of the particle to be immediately followed by an indirect prepositional complement (like in The plane took off from London), which is a good indicator/delimiter of a VPC since in non-VPC constructions like prepositional verbs the preposition needs to have an NP complement. Therefore, we will assume that a true VPC occurs in the following configurations, according to Villavicencio (2005) and Ramisch et al. (2008): S1 VERB + PARTICLE + DELIMITER, for intransitive VPCs; S2 VERB + NP + PARTICLE + DELIMITER, for transitive split VPCs and; S3 VERB + PARTICLE + NP + DELIMITER, for transitive joint VPCs. In order to answer Q2, we look at the link between productivity and compositionality and assume that a compositional VPC accepts the substitution of one of its members by a semantically related term. This is in accordance to Fraser (1976), who shows that semantic properties of 51 verbs can affect their ability to combine with particles: for example verbs of hunting combining with the resultative down (hunt/t</context>
</contexts>
<marker>Ramisch, Schreiner, Idiart, Villavicencio, 2008</marker>
<rawString>Ramisch, Carlos, Paulo Schreiner, Marco Idiart, and Aline Villavicencio. 2008. An evaluation of methods for the extraction of multiword expressions. In Proceedings of the LREC Workshop - Towards a Shared Task for Multiword Expressions (MWE 2008), pages 50–53, Marrakech, Morocco, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serge Sharoff</author>
</authors>
<title>What is at stake: a case study of russian expressions starting with a preposition.</title>
<date>2004</date>
<pages>17--23</pages>
<location>Barcelona,</location>
<contexts>
<context position="2080" citStr="Sharoff (2004)" startWordPosition="290" endWordPosition="291">e compound nouns (science fiction) and phrasal verbs (carry out) (e.g. Pearce (2002), Evert and Krenn (2005) and Zhang et al. (2006)). Some of them employ language and/or type dependent linguistic knowledge for the task, while others employ independent statistical methods, such as Mutual Information and Log-likelihood (e.g. Pearce (2002) and, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words is in fact an MWE. Although some research aims at developing methods for dealing with MWEs in general (e.g. Zhang et al. (2006), Ramisch et al. (2008)), there is also some work that deals with specific types of MWEs (e.g. Pearce (2002) on collocations and Villavicencio (2005) on verb-particle constructions (VPCs)) as each of these MWE types has distinct distributional and linguistic characteristics. VPCs are combinations of verbs and particles, such as take off in Our plane took off late, that due to their complex character</context>
</contexts>
<marker>Sharoff, 2004</marker>
<rawString>Sharoff, Serge. 2004. What is at stake: a case study of russian expressions starting with a preposition. pages 17–23, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aline Villavicencio</author>
</authors>
<title>The availability of verb-particle constructions in lexical resources: How much is enough?</title>
<date>2005</date>
<journal>Journal of Computer Speech and Language Processing,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="2427" citStr="Villavicencio (2005)" startWordPosition="350" endWordPosition="351">nd, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words is in fact an MWE. Although some research aims at developing methods for dealing with MWEs in general (e.g. Zhang et al. (2006), Ramisch et al. (2008)), there is also some work that deals with specific types of MWEs (e.g. Pearce (2002) on collocations and Villavicencio (2005) on verb-particle constructions (VPCs)) as each of these MWE types has distinct distributional and linguistic characteristics. VPCs are combinations of verbs and particles, such as take off in Our plane took off late, that due to their complex characteristics and flexible nature, provide a real challenge for NLP. In particular, there is a lack of adequate resources to identify and treat them, and those that are available provide only limited coverage, in face of the huge number of combinations in use. For tasks like parsing and generation, it is essential to know whether a given VPC is possibl</context>
<context position="10692" citStr="Villavicencio (2005)" startWordPosition="1733" endWordPosition="1734"> send up/in/back/away (Wurmbrand, 2000). By identifying classes of verbs that follow patterns such as these in VPCs, we can help in the identification of a new unknown candidate combination, using the degree of productivity of a class to which the verb belongs as a back-off strategy. In terms of methods for automatic identification of VPCs from corpora, Baldwin (2005) proposes the extraction of VPCs with valence information from raw text, exploring a range of techniques (using (a) a POS tagger, (b) a chunker, (c) a chunk grammar, (d) a dependency parser, and (e) a combination of all methods). Villavicencio (2005) uses the Web as a corpus and productive patterns of combination to generate and validate candidate VPCs. The identification of compositionality in VPCs is addressed by McCarthy et al. (2003) who examine the overlap of similar words in an automatically acquired distributional thesaurus for verb and VPCs, and by Bannard (2005) who uses a distributional approach to determine when and to what extent the components of a VPC contribute their simplex meanings to the interpretation of the VPC. Both report a correlation between some of the measures and compositionality judgements. 3 The Underlying Hyp</context>
<context position="12688" citStr="Villavicencio (2005)" startWordPosition="2064" endWordPosition="2065"> is the prepositional verbs that allow less syntactic configurations than VPCs and are therefore more rigid (§ 2). To further distinguish VPCs from prepositional verbs and other related constructions we also verify the possibility of the particle to be immediately followed by an indirect prepositional complement (like in The plane took off from London), which is a good indicator/delimiter of a VPC since in non-VPC constructions like prepositional verbs the preposition needs to have an NP complement. Therefore, we will assume that a true VPC occurs in the following configurations, according to Villavicencio (2005) and Ramisch et al. (2008): S1 VERB + PARTICLE + DELIMITER, for intransitive VPCs; S2 VERB + NP + PARTICLE + DELIMITER, for transitive split VPCs and; S3 VERB + PARTICLE + NP + DELIMITER, for transitive joint VPCs. In order to answer Q2, we look at the link between productivity and compositionality and assume that a compositional VPC accepts the substitution of one of its members by a semantically related term. This is in accordance to Fraser (1976), who shows that semantic properties of 51 verbs can affect their ability to combine with particles: for example verbs of hunting combining with th</context>
<context position="15581" citStr="Villavicencio, 2005" startWordPosition="2545" endWordPosition="2547">he British National Corpus (BNC Burnard (2000)) and the Web as corpora. The BNC fragment is used to calculate the correlation 3This dataset was provided by Timothy Baldwin for the MWE2008 Workshop. 4Version of November 2001. measures since they require a corpus with known size. The Web is used to generate frequencies for the entropy measures, as discussed in § 5.2. Web frequencies are approximated by the number of pages containing a candidate and indexed by Yahoo Search API. In order to keep the searches as simple and self-sufficient as possible, no additional sources of information are used (Villavicencio, 2005). Therefore, the frequencies are quite conservative in the sense that by employing inflected forms of verbs, potentially much more evidence could be gathered. For the generation of semantic variational patterns, we use both Wordnet 3.0 (Fellbaum, 1998) and Levin’s English Verb Classes and Alternations (Levin, 1993). Wordnet is organised as a graph of concepts, called synsets, linked by relations of synonymy, hyponymy, etc. Each synset contains a list of words that represent the concept. The verbs in a synset and its synonym synsets are used to generate variations of a VPC candidate. Likewise w</context>
<context position="17224" citStr="Villavicencio (2005)" startWordPosition="2812" endWordPosition="2813">s, each one consisting of three steps (corresponding to the next three sections). The first stage filters out every candidate that is evaluated as not being a VPC, while the second one intends to identify the idiomatic VPCs among the remaining candidates of the previous stage. 5.1 Generating candidates For each of the 3,078 items in the Baldwin CD we generated 2 sets of variations, syntactic and semantic, and we will refer to these as alternative forms or variations of a candidate. The syntactic variations are generated using the patterns S1 to S3 described in section 3. Following the work of Villavicencio (2005) 3 frequently used prepositions for, from and with are used as delimiters and we search for NPs in the form of pronouns like this and definite NPs like the boy. The use of alternative search patterns also helps to give an in52 dication about the syntactic distribution of a candidate VPC, and consequently if it has a preferred syntactic realisation. For instance, for eat up and the delimiter with, we propose a list of Web search queries for its respective variations vi, shown with their corresponding Web frequencies in table 1.5 Variation (vi) Frequency (nY ahoo(vi)) eat up with 49200 eat the *</context>
</contexts>
<marker>Villavicencio, 2005</marker>
<rawString>Villavicencio, Aline. 2005. The availability of verb-particle constructions in lexical resources: How much is enough? Journal of Computer Speech and Language Processing, 19(4):415–432.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Wurmbrand</author>
</authors>
<title>The structure(s) of particle verbs.</title>
<date>2000</date>
<institution>Ms., McGill University.</institution>
<contexts>
<context position="10111" citStr="Wurmbrand, 2000" startWordPosition="1632" endWordPosition="1633">e the objects represented by the verbs are used to join material, and they can all combine with down. There is clearly a common semantic thread running through this list, so that a new verb that is semantically similar to them can also be reasonably assumed to combine with down. Indeed, frequently new VPCs are formed by analogy with existing ones, where often the verb is varied and the particle remains (e.g. hang on, hold on and wait on). Similarly, particles from a given semantic class can be replaced by other particles from the same class in compositional combinations: send up/in/back/away (Wurmbrand, 2000). By identifying classes of verbs that follow patterns such as these in VPCs, we can help in the identification of a new unknown candidate combination, using the degree of productivity of a class to which the verb belongs as a back-off strategy. In terms of methods for automatic identification of VPCs from corpora, Baldwin (2005) proposes the extraction of VPCs with valence information from raw text, exploring a range of techniques (using (a) a POS tagger, (b) a chunker, (c) a chunk grammar, (d) a dependency parser, and (e) a combination of all methods). Villavicencio (2005) uses the Web as a </context>
</contexts>
<marker>Wurmbrand, 2000</marker>
<rawString>Wurmbrand, S. 2000. The structure(s) of particle verbs. Ms., McGill University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Zhang</author>
<author>Valia Kordoni</author>
<author>Aline Villavicencio</author>
<author>Marco Idiart</author>
</authors>
<title>Automated multiword expression prediction for grammar engineering.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties,</booktitle>
<pages>36--44</pages>
<institution>Sydney, Australia. Association for Computational Linguistics.</institution>
<contexts>
<context position="1598" citStr="Zhang et al. (2006)" startWordPosition="225" endWordPosition="228">quires some degree of semantic interpretation. In a second stage we also study whether the combination of statistical and linguistic properties can provide some indication of the degree of idiomaticity of a given VPC. The results obtained show that such combination can successfully be used to detect VPCs and distinguish idiomatic from compositional cases. 1 Introduction Considerable investigative effort has focused on the automatic identification of Multiword Expressions (MWEs), like compound nouns (science fiction) and phrasal verbs (carry out) (e.g. Pearce (2002), Evert and Krenn (2005) and Zhang et al. (2006)). Some of them employ language and/or type dependent linguistic knowledge for the task, while others employ independent statistical methods, such as Mutual Information and Log-likelihood (e.g. Pearce (2002) and, Zhang et al. (2006)), or even a combination of them (e.g. © 2008. Licensed under the Creative Commons Attribution-Noncommercial-Share Alike 3.0 Unported license (http://creativecommons.org/licenses/by-nc-sa/3.0/). Some rights reserved. Baldwin (2005) and Sharoff (2004)), as basis for helping to determine whether a given sequence of words is in fact an MWE. Although some research aims </context>
</contexts>
<marker>Zhang, Kordoni, Villavicencio, Idiart, 2006</marker>
<rawString>Zhang, Yi, Valia Kordoni, Aline Villavicencio, and Marco Idiart. 2006. Automated multiword expression prediction for grammar engineering. In Proceedings of the Workshop on Multiword Expressions: Identifying and Exploiting Underlying Properties, pages 36–44, Sydney, Australia. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>