<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.090916">
<title confidence="0.9393455">
Fluid Construction Grammar:
The New Kid on the Block
</title>
<author confidence="0.793538">
Remi van Trijp&apos;, Luc Steels&apos; 2, Katrien Beuls3, Pieter Wellens3
</author>
<affiliation confidence="0.781584">
&apos;Sony Computer Science 2ICREA Institute for 3 VUB AI Lab
Laboratory Paris Evolutionary Biology (UPF-CSIC) Pleinlaan 2
</affiliation>
<address confidence="0.8621745">
6 Rue Amyot PRBB, Dr Aiguidar 88 1050 Brussels (Belgium)
75005 Paris (France) 08003 Barcelona (Spain) katrien|pieter@
</address>
<email confidence="0.997976">
remi@csl.sony.fr steels@ai.vub.ac.be ai.vub.ac.be
</email>
<sectionHeader confidence="0.995603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999665">
Cognitive linguistics has reached a stage
of maturity where many researchers are
looking for an explicit formal grounding
of their work. Unfortunately, most current
models of deep language processing incor-
porate assumptions from generative gram-
mar that are at odds with the cognitive
movement in linguistics. This demonstra-
tion shows how Fluid Construction Gram-
mar (FCG), a fully operational and bidi-
rectional unification-based grammar for-
malism, caters for this increasing demand.
FCG features many of the tools that were
pioneered in computational linguistics in
the 70s-90s, but combines them in an inno-
vative way. This demonstration highlights
the main differences between FCG and re-
lated formalisms.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971">
The “cognitive linguistics enterprise” (Evans
et al., 2007) is a rapidly expanding research dis-
cipline that has so far avoided rigorous formal-
izations. This choice was wholly justified in the
70s-90s when the foundations of this scientific
movement were laid (Rosch, 1975; Lakoff, 1987;
Langacker, 1987), and it remained so during the
past two decades while the enterprise worked on
getting its facts straight through empirical stud-
ies in various subfields such as language acqui-
sition (Tomasello, 2003; Goldberg et al., 2004;
Lieven, 2009), language change and grammati-
calization (Heine et al., 1991; Barðdal and Chel-
liah, 2009), and corpus research (Boas, 2003; Ste-
fanowitsch and Gries, 2003). However, with nu-
merous textbooks on the market (Lee, 2001; Croft
and Cruse, 2004; Evans and Green, 2006), cogni-
tive linguistics has by now established itself as a
serious branch in the study of language, and many
cognitive linguists are looking for ways of explic-
itly formalizing their work through computational
models (McClelland, 2009).
Unfortunately, it turns out to be very difficult
to adequately formalize a cognitive linguistic ap-
proach to grammar (or “construction grammar”)
using the tools for precision-grammars developed
in the 70s-90s such as unification (Kay, 1979;
Carpenter, 1992), because these tools are typi-
cally incorporated in a generative grammar (such
as HPSG; Ginzburg and Sag, 2000) whose as-
sumptions are incompatible with the foundations
of construction grammar. First, cognitive linguis-
tics blurs the distinction between ‘competence’
and ‘performance’, which means giving up the
sharp distinction between declarative and proce-
dural representations. Next, construction gram-
marians argue for a usage-based approach (Lan-
gacker, 2000), so the constraints on features may
change and features may emerge or disappear
from a grammar at any given time.
This demonstration introduces Fluid Construc-
tion Grammar (FCG; Steels, 2011, 2012a), a
novel unification-based grammar formalism that
addresses these issues, and which is available as
open-source software at www.fcg-net.org.
After more than a decade of development, FCG
is now ready to handle sophisticated linguistic
issues. FCG revisits many of the technologies
developed by computational linguists and intro-
duces several key innovations that are of inter-
est to anyone working on deep language process-
ing. The demonstration illustrates these innova-
tions through FCG’s interactive web interface.
</bodyText>
<page confidence="0.994274">
63
</page>
<note confidence="0.6793255">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 63–68,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.997462323529412">
construction
semantic
pole
syntactic
pole
transient structure
semantic
pole
syntactic
pole
matching phase
first
merging
phase
second
merging
phase
transient structure
semantic
pole
syntactic
pole
matching phase
second
merging
phase
first
merging
phase
construction
semantic
pole
syntactic
pole
</figure>
<figureCaption confidence="0.99758575">
Figure 1: FCG allows the implementation of efficient and strongly reversible grammars. Left: In production,
conditional units of the semantic pole of a construction are matched against a transient structure, before additional
semantic constraints and the syntactic pole are merged with the structure. Right: In parsing, the same algorithm
applies but in the opposite direction.
</figureCaption>
<sectionHeader confidence="0.822228" genericHeader="introduction">
2 Strong and Efficient Reversibility
</sectionHeader>
<bodyText confidence="0.999974707317073">
Reversible or bidirectional grammar formalisms
can achieve both production and parsing (Strza-
lkowski, 1994). Several platforms, such as the
LKB (Copestake, 2002), already achieve bidirec-
tionality, but they do so through separate algo-
rithms for parsing and production (mainly for effi-
ciency reasons). One problem with this approach
is that there may be a loss of coherence in gram-
mar engineering. For instance, the LKB parser
can handle a wider variety of structures than its
generator.
FCG uses one core engine that handles both
parsing and production with a single linguistic
inventory (see Figure 1). When processing, the
FCG-system builds a transient structure that con-
tains all the information concerning the utterance
that the system has to parse or produce, divided
into a semantic and syntactic pole (both of whom
are feature structures). Grammar rules or “con-
structions” are coupled feature structures as well
and thus contain a semantic and syntactic pole.
When applying constructions, the FCG-system
goes through three phases. In production, FCG
first matches all feature-value pairs of the seman-
tic pole of a construction with the semantic pole
of the transient structure, except fv-pairs that are
marked for being attributed by the construction
(De Beule and Steels, 2005). Matching is a more
strict form of unification that resembles a sub-
sumption test (see Steels and De Beule, 2006).
If matching is successful, all the marked fv-pairs
of the semantic pole are merged with the tran-
sient structure in a first merge phase, after which
the whole syntactic pole is merged in a second
phase. FCG-merge is equivalent to “unification”
in other formalisms. The same three-phase algo-
rithm is applied in parsing as well, but this time in
the opposite direction: if the syntactic pole of the
construction matches with the transient structure,
the attributable syntactic fv-pairs and the seman-
tic pole are merged.
</bodyText>
<sectionHeader confidence="0.994957" genericHeader="method">
3 WYSIWYG Grammar Engineering
</sectionHeader>
<bodyText confidence="0.999874285714286">
Most unification grammars use non-directional
linguistic representations that are designed to be
independent of any model of processing (Sag
and Wasow, 2011). Whereas this may be de-
sirable from a ‘mathematical’ point-of-view, it
puts the burden of efficient processing on the
shoulders of computational linguists, who have to
find a balance between faithfulness to the hand-
written theory and computational efficiency (Mel-
nik, 2005). For instance, there is no HPSG imple-
mentation, but rather several platforms that sup-
port the implementation of ‘HPSG-like’ gram-
mars: ALE (Carpenter and Penn, 1995), ALEP
(Schmidt et al., 1996), CUF (Dörre and Dorna,
</bodyText>
<page confidence="0.987011">
64
</page>
<figure confidence="0.9752195">
nominal-adjectival-cxn
cxn-applied
</figure>
<figureCaption confidence="0.998558666666667">
Figure 2: FCG comes equipped with an interactive web interface for inspecting the linguistic inventory, con-
struction application and search. This Figure shows an example construction where two units are opened up for
closer inspection of their feature structures.
</figureCaption>
<figure confidence="0.9995415">
word-
ballon-
1
word-
rouge-
1
sem-subunits
footprints
args
sem-cat
nominal-adjectival-phrase-1
(word-ballon-1
word-rouge-1)
(nominal-adjectival-cxn)
(red-ball-15 context-19)
((sem-function
identifier))
word-le-1
top
sem syn
top
form
syn-subunits
syn-cat
footprints
word-le-1
nominal-adjectival-phrase-1
(word-ballon-1
word-rouge-1)
((number singular)
(gender masculine)
(syn-function nominal))
(nominal-adjectival-cxn)
((meets
word-ballon-1
word-rouge-1))
word-
rouge-
1
word-
ballon-
1
</figure>
<bodyText confidence="0.9862179">
1993), LIGHT (Ciortuz, 2002), LKB (Copestake,
2002), ProFIT (Erbach, 1995), TDL (Krieger and
Schäfer, 1994), TFS (Emele, 1994), and others
(see Bolc et al., 1996, for a survey). Unfortu-
nately, the optimizations and technologies devel-
oped within these platforms are often considered
by theoretical linguists as engineering solutions
rather than scientific contributions.
FCG, on the other hand, adheres to the cogni-
tive linguistics assumption that linguistic perfor-
mance is equally important as linguistic compe-
tence, hence processing becomes a central notion
in the formalism. FCG representations therefore
offer a ‘what you see is what you get’ approach
to grammar engineering where the representations
have a direct impact on processing and vice versa.
For instance, a construction’s division between a
semantic and syntactic pole is informative with re-
spect to how the construction is applied.
Some grammarians may object that this design
choice forces linguists to worry about process-
ing, but that is entirely the point. It has already
been demonstrated in other unification-based for-
malisms that different grammar representations
have a significant impact on processing efficiency
(Flickinger, 2000). Moreover, FCG-style repre-
sentations can be directly implemented and tested
without having to compromise on either faithful-
ness to a theory or computational efficiency.
Since writing grammars is highly complex,
however, FCG also features a ‘design level’ on top
of its operational level (Steels, 2012b). On this
level, grammar engineers can use templates that
build detailed constructions. The demonstration
shows how to write a grammar in FCG, switch-
ing between its design level, its operational level
and its interactive web interface (see Figure 2).
The web interface allows FCG-users to inspect the
linguistic inventory, the search tree in processing,
and so on.
</bodyText>
<sectionHeader confidence="0.98445" genericHeader="method">
4 Robustness and Learning
</sectionHeader>
<bodyText confidence="0.9999715">
Unification-based grammars have the reputation
of being brittle when it comes to processing nov-
elty or ungrammatical utterances (Tomuro, 1999).
Since cognitive linguistics adheres to a usage-
based view on language (Langacker, 2000), how-
ever, an adequate formalization must be robust
and open-ended.
A first requirement is that there can be differ-
ent degrees of ‘entrenchment’ in the grammar:
while some features might still be emergent, oth-
ers are already part of well-conventionalized lin-
guistic patterns. Moreover, new features and con-
structions may appear (or disappear) from a gram-
mar at any given time. These requirements are
hard to reconcile with the type hierarchy approach
of other formalisms, so FCG does not imple-
ment typed feature structures. The demonstra-
tion shows how FCG can nevertheless prevent
over-licensing of linguistic structures through its
matching phase and how it captures generaliza-
tions through its templates – two benefits typically
associated with type hierarchies.
Secondly, FCG renders linguistic processing
fluid and robust through a meta-level architec-
ture, which consists of two layers of processing,
as shown in Figure 3 (Beuls et al., 2012). There
is a routine layer in which constructional process-
ing takes place. At the same time, a meta-layer
</bodyText>
<page confidence="0.996524">
65
</page>
<figure confidence="0.999382625">
meta-layer processing
routine processing
diagnostic
repair
diagnostic diagnostic diagnostic
problem
problem
repair
</figure>
<figureCaption confidence="0.998121">
Figure 3: There are two layers of processing in FCG. On the routine level, constructional processing takes place.
At the same time, a meta-layer of diagnostics and repairs try to detect and solve problems that occur in the routine
layer.
</figureCaption>
<bodyText confidence="0.999941888888889">
is active that runs diagnostics for detecting prob-
lems in routine processing, and repairs for solving
those problems. The demonstration shows how
the meta-layer is used for solving common prob-
lems such as missing lexical entries and coercion
(Steels and van Trijp, 2011), and how its archi-
tecture offers a uniform way of implementing the
various solutions for robustness already pioneered
in the aforementioned grammar platforms.
</bodyText>
<sectionHeader confidence="0.99815" genericHeader="evaluation">
5 Efficiency
</sectionHeader>
<bodyText confidence="0.999836454545455">
Unification is computationally expensive, and
many technical solutions have been proposed for
efficient processing of rich and expressive fea-
ture structures (Tomuro, 1999; Flickinger, 2000;
Callmeier, 2001). In FCG, however, research
on efficiency takes a different dimension because
performance is considered to be an integral part of
the linguistic theory that needs to be operational-
ized. The demonstration allows conference par-
ticipants to inspect the following research results
on the interplay between grammar and efficiency:
</bodyText>
<listItem confidence="0.931641461538462">
• In line with construction grammar, there is
no distinction between the lexicon and the
grammar. Based on language usage, the lin-
guistic inventory can nevertheless organize
itself in the form of dependency networks
that regulate which construction should be
considered when in processing (Wellens and
De Beule, 2010; Wellens, 2011).
• There is abundant psycholinguistic evidence
that language usage contains many ready-
made language structures. FCG incorporates
a chunking mechanism that is able to cre-
ate such canned phrases for faster processing
(Stadler, 2012).
• Morphological paradigms, such as the Ger-
man case system, can be represented in the
form of ‘feature matrices’, which reduce
syntactic and semantic ambiguity and hence
speed up processing efficiency and reliability
(van Trijp, 2011).
• Many linguistic domains, such as spatial lan-
guage, are known for their high degree of
polysemy. By distinguishing between actual
and potential values, such polysemous struc-
tures can be processed smoothly (Spranger
and Loetzsch, 2011).
</listItem>
<sectionHeader confidence="0.988129" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9998349">
With many well-developed unification-based
grammar formalisms available to the community,
one might wonder whether any ‘new kid on the
block’ can still claim relevance today. With this
demonstration, we hope to show that Fluid Con-
struction Grammar allows grammar engineers to
unchart new territory, most notably in the relation
between linguistic competence and performance,
and in modeling usage-based approaches to lan-
guage.
</bodyText>
<page confidence="0.989804">
66
</page>
<sectionHeader confidence="0.960184" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996393510638298">
Johanna Barðdal and Shobhana Chelliah, edi-
tors. The Role of Semantic, Pragmatic and
Discourse Factors in the Development of Case.
John Benjamins, Amsterdam, 2009.
Katrien Beuls, Remi van Trijp, and Pieter
Wellens. Diagnostics and repairs in Fluid Con-
struction Grammar. In Luc Steels, editor, Com-
putational Issues in Fluid Construction Gram-
mar. Springer Verlag, Berlin, 2012.
Hans C. Boas. A Constructional Approach to Re-
sultatives. Stanford Monograph in Linguistics.
CSLI, Stanford, 2003.
Leonard Bolc, Krzysztof Czuba, Anna
Kup´s´c, Malgorzata Marciniak, Agnieszka
Mykowiecka, and Adam Przepiórkowski. A
survey of systems for implementing HPSG
grammars. Research Report 814 of IPI
PAN (Institute of Computer Science, Polish
Academy of Sciences), 1996.
Ulrich Callmeier. Efficient parsing with large-
scale unification grammars. Master’s thesis,
Universität des Saarlandes, 2001.
Bob Carpenter. The Logic of Typed Feature Struc-
tures. Cambridge UP, Cambridge, 1992.
Bob Carpenter and Gerald Penn. The Attribute
Logic Engine (Version 2.0.1). Pittsburgh, 1995.
Liviu Ciortuz. LIGHT – a constraint language and
compiler system for typed-unification gram-
mars. In Proceedings of The 25th German Con-
ferences on Artificial Intelligence (KI 2002),
volume 2479 of LNAI, pages 3–17, Berlin,
2002. Springer-Verlag.
Ann Copestake. Implementing Typed Feature
Structure Grammars. CSLI Publications, Stan-
ford, 2002.
William Croft and D. Alan Cruse. Cognitive Lin-
guistics. Cambridge Textbooks in Linguistics.
Cambridge University Press, Cambridge, 2004.
J. De Beule and L. Steels. Hierarchy in fluid con-
struction grammar. In U. Furbach, editor, Pro-
ceedings of the 28th Annual German Confer-
ence on Artificial Intelligence, volume 3698 of
Lecture Notes in Artificial Intelligence, pages
1–15, Berlin, Germany, 2005. Springer Verlag.
Jochen Dörre and Michael Dorna. CUF – a
formalism for linguistic knowledge represen-
tation. In Jochen Dörre, editor, Computa-
tional Aspects of Constraint Based Linguistic
Descriptions, volume I, pages 1–22. DYANA-2
Project, Amsterdam, 1993.
Martin C. Emele. The typed feature structure rep-
resentation formalism. In Proceedings of the
International Workshop on Sharable Natural
Language Resources, Ikoma, Nara, 1994.
Gregor Erbach. ProFIT: Prolog with features,
inheritance and templates. In Proceedings of
EACL-95, 1995.
Vyvyan Evans and Melanie Green. Cognitive Lin-
guistics: An Introduction. Lawrence Erlbaum
Associates / Edinburgh University Press, Hills-
dale, NJ/Edinburgh, 2006.
Vyvyan Evans, Benjamin K. Bergen, and Jörg
Zinken. The cognitive linguistics enterprise:
An overview. In V. Evans, B.K. Bergen, and
J. Zinken, editors, The Cognitive Linguistics
Reader. Equinox Publishing, London, 2007.
Daniel P. Flickinger. On building a more efficient
grammar by exploiting types. Natural Lan-
guage Engineering, 6(1):15–28, 2000.
Jonathan Ginzburg and Ivan A. Sag. Interroga-
tive Investigations: the Form, the Meaning, and
Use of English Interrogatives. CSLI Publica-
tions, Stanford, 2000.
Adele E. Goldberg, Devin M. Casenhiser, and
Nitya Sethuraman. Learning argument struc-
ture generalizations. Cognitive Linguistics, 15
(3):289–316, 2004.
Bernd Heine, Ulrike Claudi, and Friederike Hün-
nemeyer. Grammaticalization: A Concep-
tual Framework. University of Chicago Press,
Chicago, 1991.
Martin Kay. Functional grammar. In Proceedings
of the Fifth Annual Meeting of the Berkeley Lin-
guistics Society, pages 142–158. Berkeley Lin-
guistics Society, 1979.
Hans-Ulrich Krieger and Ulrich Schäfer. TDL –
a type description language for HPSG. part 1:
Overview. In Proceedings of the 15th Interna-
tional Conference on Computational Linguis-
tics, pages 893–899, Kyoto, 1994.
George Lakoff. Women, Fire, and Danger-
ous Things: What Categories Reveal about
the Mind. The University of Chicago Press,
Chicago, 1987.
</reference>
<page confidence="0.995515">
67
</page>
<reference confidence="0.999376378947369">
Ronald W. Langacker. Foundations of Cognitive
Grammar: Theoretical Prerequisites. Stanford
University Press, Stanford, 1987.
Ronald W. Langacker. A dynamic usage-based
model. In Michael Barlow and Suzanne Kem-
mer, editors, Usage-Based Models of Lan-
guage, pages 1–63. Chicago University Press,
Chicago, 2000.
David Lee. Cognitive Linguistics: An Introduc-
tion. Oxford University Press, Oxford, 2001.
Elena Lieven. Developing constructions. Cogni-
tive Linguistics, 20(1):191–199, 2009.
James L. McClelland. The place of modeling in
cognitive science. Topics in Cognitive Science,
1:11–38, 2009.
Nurit Melnik. From “hand-written” to computa-
tionally implemented HPSG theories. In Ste-
fan Müller, editor, Proceedings of the HPSG05
Conference, Stanford, 2005. CSLI Publica-
tions.
Eleanor Rosch. Cognitive representations of se-
mantic categories. Journal of Experimental
Psychology: General, 104:192–233, 1975.
Ivan A. Sag and Thomas Wasow. Performance-
compatible competence grammar. In Robert D.
Borsley and Kersti Börjars, editors, Non-
Transformational Syntax: Formal and Explicit
Models of Grammar, pages 359–377. Wiley-
Blackwell, 2011.
Paul Schmidt, Sibylle Rieder, Axel Theofilidis,
and Thierry Declerck. Lean formalisms, lin-
guistic theory, and applications. grammar de-
velopment in ALEP. In Proceedings of the
16th International Conference on Computa-
tional Linguistics (COLING-96), pages 286–
291, Copenhagen, 1996.
Michael Spranger and Martin Loetzsch. Syntac-
tic indeterminacy and semantic ambiguity: A
case study for German spatial phrases. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar. John Benjamins, Amster-
dam, 2011.
Kevin Stadler. Chunking constructions. In
Luc Steels, editor, Computational Issues in
Fluid Construction Grammar. Springer Verlag,
Berlin, 2012.
Luc Steels, editor. Design Patterns in Fluid Con-
struction Grammar. John Benjamins, Amster-
dam, 2011.
Luc Steels, editor. Computational Issues in
Fluid Construction Grammar. Springer, Berlin,
2012a.
Luc Steels. Design methods for Fluid Construc-
tion Grammar. In Luc Steels, editor, Computa-
tional Issues in Fluid Construction Grammar.
Springer Verlag, Berlin, 2012b.
Luc Steels and Joachim De Beule. Unify and
merge in Fluid Construction Grammar. In
P. Vogt, Y. Sugita, E. Tuci, and C. Nehaniv,
editors, Symbol Grounding and Beyond., LNAI
4211, pages 197–223, Berlin, 2006. Springer.
Luc Steels and Remi van Trijp. How to make con-
struction grammars fluid and robust. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar, pages 301–330. John Ben-
jamins, Amsterdam, 2011.
Anatol Stefanowitsch and Stefan Th. Gries. Col-
lostructions: Investigating the interaction of
words and constructions. International Journal
of Corpus Linguistics, 2(8):209–243, 2003.
Tomek Strzalkowski, editor. Reversible Grammar
in Natural Language Processing. Kluwer Aca-
demic Publishers, Boston, 1994.
Michael Tomasello. Constructing a Language. A
Usage Based Theory of Language Acquisition.
Harvard University Press, 2003.
Noriko Tomuro. Left-Corner Parsing Algorithm
for Unification Grammars. PhD thesis, DePaul
University, Chicago, 1999.
Remi van Trijp. Feature matrices and agree-
ment: A case study for German case. In Luc
Steels, editor, Design Patterns in Fluid Con-
struction Grammar, pages 205–236. John Ben-
jamins, Amsterdam, 2011.
Pieter Wellens. Organizing constructions in net-
works. In Luc Steels, editor, Design Patterns in
Fluid Construction Grammar. John Benjamins,
Amsterdam, 2011.
Pieter Wellens and Joachim De Beule. Prim-
ing through constructional dependencies: A
case study in Fluid Construction Grammar.
In A. Smith, M. Schouwstra, Bart de Boer,
and K. Smith, editors, The Evolution of Lan-
guage (EVOLANG8), pages 344–351, Singa-
pore, 2010. World Scientific.
</reference>
<page confidence="0.999446">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.536469">
<title confidence="0.961184">Fluid Construction The New Kid on the Block</title>
<author confidence="0.99756">van_Luc Katrien Pieter</author>
<affiliation confidence="0.991712">Computer Science Institute for 3VUB AI Lab</affiliation>
<address confidence="0.863088666666667">Laboratory Paris Evolutionary Biology (UPF-CSIC) Pleinlaan 2 6 Rue Amyot PRBB, Dr Aiguidar 88 1050 Brussels (Belgium) Paris (France) 08003 Barcelona (Spain)</address>
<email confidence="0.881663">remi@csl.sony.frsteels@ai.vub.ac.beai.vub.ac.be</email>
<abstract confidence="0.996373736842105">Cognitive linguistics has reached a stage of maturity where many researchers are looking for an explicit formal grounding of their work. Unfortunately, most current models of deep language processing incorporate assumptions from generative grammar that are at odds with the cognitive movement in linguistics. This demonstration shows how Fluid Construction Grammar (FCG), a fully operational and bidirectional unification-based grammar formalism, caters for this increasing demand. FCG features many of the tools that were pioneered in computational linguistics in the 70s-90s, but combines them in an innovative way. This demonstration highlights the main differences between FCG and related formalisms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2009</date>
<booktitle>The Role of Semantic, Pragmatic and Discourse Factors in the Development of Case. John Benjamins,</booktitle>
<editor>Johanna Barðdal and Shobhana Chelliah, editors.</editor>
<location>Amsterdam,</location>
<marker>2009</marker>
<rawString>Johanna Barðdal and Shobhana Chelliah, editors. The Role of Semantic, Pragmatic and Discourse Factors in the Development of Case. John Benjamins, Amsterdam, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrien Beuls</author>
</authors>
<title>Remi van Trijp, and Pieter Wellens. Diagnostics and repairs in Fluid Construction Grammar.</title>
<date>2012</date>
<booktitle>In Luc Steels, editor, Computational Issues in Fluid Construction Grammar.</booktitle>
<publisher>Springer Verlag,</publisher>
<location>Berlin,</location>
<marker>Beuls, 2012</marker>
<rawString>Katrien Beuls, Remi van Trijp, and Pieter Wellens. Diagnostics and repairs in Fluid Construction Grammar. In Luc Steels, editor, Computational Issues in Fluid Construction Grammar. Springer Verlag, Berlin, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans C Boas</author>
</authors>
<title>A Constructional Approach to Resultatives. Stanford Monograph in Linguistics.</title>
<date>2003</date>
<location>CSLI, Stanford,</location>
<contexts>
<context position="1794" citStr="Boas, 2003" startWordPosition="266" endWordPosition="267">, 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unificatio</context>
</contexts>
<marker>Boas, 2003</marker>
<rawString>Hans C. Boas. A Constructional Approach to Resultatives. Stanford Monograph in Linguistics. CSLI, Stanford, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Bolc</author>
<author>Krzysztof Czuba</author>
<author>Anna Kup´s´c</author>
<author>Malgorzata Marciniak</author>
<author>Agnieszka Mykowiecka</author>
<author>Adam Przepiórkowski</author>
</authors>
<title>A survey of systems for implementing HPSG grammars.</title>
<date>1996</date>
<journal>Research Report 814 of IPI PAN (Institute of Computer Science, Polish Academy of Sciences),</journal>
<marker>Bolc, Czuba, Kup´s´c, Marciniak, Mykowiecka, Przepiórkowski, 1996</marker>
<rawString>Leonard Bolc, Krzysztof Czuba, Anna Kup´s´c, Malgorzata Marciniak, Agnieszka Mykowiecka, and Adam Przepiórkowski. A survey of systems for implementing HPSG grammars. Research Report 814 of IPI PAN (Institute of Computer Science, Polish Academy of Sciences), 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Callmeier</author>
</authors>
<title>Efficient parsing with largescale unification grammars.</title>
<date>2001</date>
<booktitle>Master’s thesis, Universität des Saarlandes,</booktitle>
<contexts>
<context position="12071" citStr="Callmeier, 2001" startWordPosition="1788" endWordPosition="1789">or detecting problems in routine processing, and repairs for solving those problems. The demonstration shows how the meta-layer is used for solving common problems such as missing lexical entries and coercion (Steels and van Trijp, 2011), and how its architecture offers a uniform way of implementing the various solutions for robustness already pioneered in the aforementioned grammar platforms. 5 Efficiency Unification is computationally expensive, and many technical solutions have been proposed for efficient processing of rich and expressive feature structures (Tomuro, 1999; Flickinger, 2000; Callmeier, 2001). In FCG, however, research on efficiency takes a different dimension because performance is considered to be an integral part of the linguistic theory that needs to be operationalized. The demonstration allows conference participants to inspect the following research results on the interplay between grammar and efficiency: • In line with construction grammar, there is no distinction between the lexicon and the grammar. Based on language usage, the linguistic inventory can nevertheless organize itself in the form of dependency networks that regulate which construction should be considered when</context>
</contexts>
<marker>Callmeier, 2001</marker>
<rawString>Ulrich Callmeier. Efficient parsing with largescale unification grammars. Master’s thesis, Universität des Saarlandes, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>The Logic of Typed Feature Structures. Cambridge UP,</title>
<date>1992</date>
<location>Cambridge,</location>
<contexts>
<context position="2424" citStr="Carpenter, 1992" startWordPosition="362" endWordPosition="363">h and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HPSG; Ginzburg and Sag, 2000) whose assumptions are incompatible with the foundations of construction grammar. First, cognitive linguistics blurs the distinction between ‘competence’ and ‘performance’, which means giving up the sharp distinction between declarative and procedural representations. Next, construction grammarians argue for a usage-based approach (Langacker, 2000), so the constraints on features may change and features may emerge or disappear from a grammar at any given time. This demonstration intro</context>
</contexts>
<marker>Carpenter, 1992</marker>
<rawString>Bob Carpenter. The Logic of Typed Feature Structures. Cambridge UP, Cambridge, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
<author>Gerald Penn</author>
</authors>
<title>The Attribute Logic Engine (Version 2.0.1).</title>
<date>1995</date>
<location>Pittsburgh,</location>
<contexts>
<context position="7059" citStr="Carpenter and Penn, 1995" startWordPosition="1058" endWordPosition="1061"> WYSIWYG Grammar Engineering Most unification grammars use non-directional linguistic representations that are designed to be independent of any model of processing (Sag and Wasow, 2011). Whereas this may be desirable from a ‘mathematical’ point-of-view, it puts the burden of efficient processing on the shoulders of computational linguists, who have to find a balance between faithfulness to the handwritten theory and computational efficiency (Melnik, 2005). For instance, there is no HPSG implementation, but rather several platforms that support the implementation of ‘HPSG-like’ grammars: ALE (Carpenter and Penn, 1995), ALEP (Schmidt et al., 1996), CUF (Dörre and Dorna, 64 nominal-adjectival-cxn cxn-applied Figure 2: FCG comes equipped with an interactive web interface for inspecting the linguistic inventory, construction application and search. This Figure shows an example construction where two units are opened up for closer inspection of their feature structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) (nominal-adjectival-cxn) (red-ball-15 context-19) ((sem-function identifier)) word-le-1 top sem syn top form syn-subunits syn-ca</context>
</contexts>
<marker>Carpenter, Penn, 1995</marker>
<rawString>Bob Carpenter and Gerald Penn. The Attribute Logic Engine (Version 2.0.1). Pittsburgh, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liviu Ciortuz</author>
</authors>
<title>LIGHT – a constraint language and compiler system for typed-unification grammars.</title>
<date>2002</date>
<booktitle>In Proceedings of The 25th German Conferences on Artificial Intelligence (KI</booktitle>
<volume>2479</volume>
<pages>3--17</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin,</location>
<contexts>
<context position="7914" citStr="Ciortuz, 2002" startWordPosition="1162" endWordPosition="1163">re shows an example construction where two units are opened up for closer inspection of their feature structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) (nominal-adjectival-cxn) (red-ball-15 context-19) ((sem-function identifier)) word-le-1 top sem syn top form syn-subunits syn-cat footprints word-le-1 nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) ((number singular) (gender masculine) (syn-function nominal)) (nominal-adjectival-cxn) ((meets word-ballon-1 word-rouge-1)) wordrouge1 wordballon1 1993), LIGHT (Ciortuz, 2002), LKB (Copestake, 2002), ProFIT (Erbach, 1995), TDL (Krieger and Schäfer, 1994), TFS (Emele, 1994), and others (see Bolc et al., 1996, for a survey). Unfortunately, the optimizations and technologies developed within these platforms are often considered by theoretical linguists as engineering solutions rather than scientific contributions. FCG, on the other hand, adheres to the cognitive linguistics assumption that linguistic performance is equally important as linguistic competence, hence processing becomes a central notion in the formalism. FCG representations therefore offer a ‘what you see</context>
</contexts>
<marker>Ciortuz, 2002</marker>
<rawString>Liviu Ciortuz. LIGHT – a constraint language and compiler system for typed-unification grammars. In Proceedings of The 25th German Conferences on Artificial Intelligence (KI 2002), volume 2479 of LNAI, pages 3–17, Berlin, 2002. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Copestake</author>
</authors>
<title>Implementing Typed Feature Structure Grammars.</title>
<date>2002</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford,</location>
<contexts>
<context position="4678" citStr="Copestake, 2002" startWordPosition="682" endWordPosition="683">nstruction semantic pole syntactic pole Figure 1: FCG allows the implementation of efficient and strongly reversible grammars. Left: In production, conditional units of the semantic pole of a construction are matched against a transient structure, before additional semantic constraints and the syntactic pole are merged with the structure. Right: In parsing, the same algorithm applies but in the opposite direction. 2 Strong and Efficient Reversibility Reversible or bidirectional grammar formalisms can achieve both production and parsing (Strzalkowski, 1994). Several platforms, such as the LKB (Copestake, 2002), already achieve bidirectionality, but they do so through separate algorithms for parsing and production (mainly for efficiency reasons). One problem with this approach is that there may be a loss of coherence in grammar engineering. For instance, the LKB parser can handle a wider variety of structures than its generator. FCG uses one core engine that handles both parsing and production with a single linguistic inventory (see Figure 1). When processing, the FCG-system builds a transient structure that contains all the information concerning the utterance that the system has to parse or produc</context>
<context position="7937" citStr="Copestake, 2002" startWordPosition="1165" endWordPosition="1166">onstruction where two units are opened up for closer inspection of their feature structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) (nominal-adjectival-cxn) (red-ball-15 context-19) ((sem-function identifier)) word-le-1 top sem syn top form syn-subunits syn-cat footprints word-le-1 nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) ((number singular) (gender masculine) (syn-function nominal)) (nominal-adjectival-cxn) ((meets word-ballon-1 word-rouge-1)) wordrouge1 wordballon1 1993), LIGHT (Ciortuz, 2002), LKB (Copestake, 2002), ProFIT (Erbach, 1995), TDL (Krieger and Schäfer, 1994), TFS (Emele, 1994), and others (see Bolc et al., 1996, for a survey). Unfortunately, the optimizations and technologies developed within these platforms are often considered by theoretical linguists as engineering solutions rather than scientific contributions. FCG, on the other hand, adheres to the cognitive linguistics assumption that linguistic performance is equally important as linguistic competence, hence processing becomes a central notion in the formalism. FCG representations therefore offer a ‘what you see is what you get’ appro</context>
</contexts>
<marker>Copestake, 2002</marker>
<rawString>Ann Copestake. Implementing Typed Feature Structure Grammars. CSLI Publications, Stanford, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Croft</author>
<author>D Alan Cruse</author>
</authors>
<title>Cognitive Linguistics. Cambridge Textbooks in Linguistics.</title>
<date>2004</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge,</location>
<contexts>
<context position="1908" citStr="Croft and Cruse, 2004" startWordPosition="283" endWordPosition="286">s choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HP</context>
</contexts>
<marker>Croft, Cruse, 2004</marker>
<rawString>William Croft and D. Alan Cruse. Cognitive Linguistics. Cambridge Textbooks in Linguistics. Cambridge University Press, Cambridge, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J De Beule</author>
<author>L Steels</author>
</authors>
<title>Hierarchy in fluid construction grammar.</title>
<date>2005</date>
<booktitle>Proceedings of the 28th Annual German Conference on Artificial Intelligence,</booktitle>
<volume>3698</volume>
<pages>1--15</pages>
<editor>In U. Furbach, editor,</editor>
<publisher>Springer Verlag.</publisher>
<location>Berlin, Germany,</location>
<marker>De Beule, Steels, 2005</marker>
<rawString>J. De Beule and L. Steels. Hierarchy in fluid construction grammar. In U. Furbach, editor, Proceedings of the 28th Annual German Conference on Artificial Intelligence, volume 3698 of Lecture Notes in Artificial Intelligence, pages 1–15, Berlin, Germany, 2005. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen Dörre</author>
<author>Michael Dorna</author>
</authors>
<title>CUF – a formalism for linguistic knowledge representation.</title>
<date>1993</date>
<booktitle>In Jochen Dörre, editor, Computational Aspects of Constraint Based Linguistic Descriptions, volume I,</booktitle>
<pages>1--22</pages>
<location>Project, Amsterdam,</location>
<marker>Dörre, Dorna, 1993</marker>
<rawString>Jochen Dörre and Michael Dorna. CUF – a formalism for linguistic knowledge representation. In Jochen Dörre, editor, Computational Aspects of Constraint Based Linguistic Descriptions, volume I, pages 1–22. DYANA-2 Project, Amsterdam, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin C Emele</author>
</authors>
<title>The typed feature structure representation formalism.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Workshop on Sharable Natural Language Resources,</booktitle>
<location>Ikoma, Nara,</location>
<contexts>
<context position="8012" citStr="Emele, 1994" startWordPosition="1176" endWordPosition="1177">e structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) (nominal-adjectival-cxn) (red-ball-15 context-19) ((sem-function identifier)) word-le-1 top sem syn top form syn-subunits syn-cat footprints word-le-1 nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) ((number singular) (gender masculine) (syn-function nominal)) (nominal-adjectival-cxn) ((meets word-ballon-1 word-rouge-1)) wordrouge1 wordballon1 1993), LIGHT (Ciortuz, 2002), LKB (Copestake, 2002), ProFIT (Erbach, 1995), TDL (Krieger and Schäfer, 1994), TFS (Emele, 1994), and others (see Bolc et al., 1996, for a survey). Unfortunately, the optimizations and technologies developed within these platforms are often considered by theoretical linguists as engineering solutions rather than scientific contributions. FCG, on the other hand, adheres to the cognitive linguistics assumption that linguistic performance is equally important as linguistic competence, hence processing becomes a central notion in the formalism. FCG representations therefore offer a ‘what you see is what you get’ approach to grammar engineering where the representations have a direct impact o</context>
</contexts>
<marker>Emele, 1994</marker>
<rawString>Martin C. Emele. The typed feature structure representation formalism. In Proceedings of the International Workshop on Sharable Natural Language Resources, Ikoma, Nara, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Erbach</author>
</authors>
<title>ProFIT: Prolog with features, inheritance and templates.</title>
<date>1995</date>
<booktitle>In Proceedings of EACL-95,</booktitle>
<contexts>
<context position="7960" citStr="Erbach, 1995" startWordPosition="1168" endWordPosition="1169">s are opened up for closer inspection of their feature structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) (nominal-adjectival-cxn) (red-ball-15 context-19) ((sem-function identifier)) word-le-1 top sem syn top form syn-subunits syn-cat footprints word-le-1 nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) ((number singular) (gender masculine) (syn-function nominal)) (nominal-adjectival-cxn) ((meets word-ballon-1 word-rouge-1)) wordrouge1 wordballon1 1993), LIGHT (Ciortuz, 2002), LKB (Copestake, 2002), ProFIT (Erbach, 1995), TDL (Krieger and Schäfer, 1994), TFS (Emele, 1994), and others (see Bolc et al., 1996, for a survey). Unfortunately, the optimizations and technologies developed within these platforms are often considered by theoretical linguists as engineering solutions rather than scientific contributions. FCG, on the other hand, adheres to the cognitive linguistics assumption that linguistic performance is equally important as linguistic competence, hence processing becomes a central notion in the formalism. FCG representations therefore offer a ‘what you see is what you get’ approach to grammar engineer</context>
</contexts>
<marker>Erbach, 1995</marker>
<rawString>Gregor Erbach. ProFIT: Prolog with features, inheritance and templates. In Proceedings of EACL-95, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vyvyan Evans</author>
<author>Melanie Green</author>
</authors>
<title>Cognitive Linguistics: An Introduction. Lawrence Erlbaum Associates /</title>
<date>2006</date>
<publisher>Edinburgh University Press,</publisher>
<location>Hillsdale, NJ/Edinburgh,</location>
<contexts>
<context position="1932" citStr="Evans and Green, 2006" startWordPosition="287" endWordPosition="290">tified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HPSG; Ginzburg and Sag, 20</context>
</contexts>
<marker>Evans, Green, 2006</marker>
<rawString>Vyvyan Evans and Melanie Green. Cognitive Linguistics: An Introduction. Lawrence Erlbaum Associates / Edinburgh University Press, Hillsdale, NJ/Edinburgh, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vyvyan Evans</author>
<author>Benjamin K Bergen</author>
<author>Jörg Zinken</author>
</authors>
<title>The cognitive linguistics enterprise: An overview. In</title>
<date>2007</date>
<editor>V. Evans, B.K. Bergen, and J. Zinken, editors,</editor>
<publisher>Equinox Publishing,</publisher>
<location>London,</location>
<contexts>
<context position="1191" citStr="Evans et al., 2007" startWordPosition="169" endWordPosition="172">rent models of deep language processing incorporate assumptions from generative grammar that are at odds with the cognitive movement in linguistics. This demonstration shows how Fluid Construction Grammar (FCG), a fully operational and bidirectional unification-based grammar formalism, caters for this increasing demand. FCG features many of the tools that were pioneered in computational linguistics in the 70s-90s, but combines them in an innovative way. This demonstration highlights the main differences between FCG and related formalisms. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2</context>
</contexts>
<marker>Evans, Bergen, Zinken, 2007</marker>
<rawString>Vyvyan Evans, Benjamin K. Bergen, and Jörg Zinken. The cognitive linguistics enterprise: An overview. In V. Evans, B.K. Bergen, and J. Zinken, editors, The Cognitive Linguistics Reader. Equinox Publishing, London, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel P Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="9090" citStr="Flickinger, 2000" startWordPosition="1336" endWordPosition="1337">entations therefore offer a ‘what you see is what you get’ approach to grammar engineering where the representations have a direct impact on processing and vice versa. For instance, a construction’s division between a semantic and syntactic pole is informative with respect to how the construction is applied. Some grammarians may object that this design choice forces linguists to worry about processing, but that is entirely the point. It has already been demonstrated in other unification-based formalisms that different grammar representations have a significant impact on processing efficiency (Flickinger, 2000). Moreover, FCG-style representations can be directly implemented and tested without having to compromise on either faithfulness to a theory or computational efficiency. Since writing grammars is highly complex, however, FCG also features a ‘design level’ on top of its operational level (Steels, 2012b). On this level, grammar engineers can use templates that build detailed constructions. The demonstration shows how to write a grammar in FCG, switching between its design level, its operational level and its interactive web interface (see Figure 2). The web interface allows FCG-users to inspect </context>
<context position="12053" citStr="Flickinger, 2000" startWordPosition="1786" endWordPosition="1787">runs diagnostics for detecting problems in routine processing, and repairs for solving those problems. The demonstration shows how the meta-layer is used for solving common problems such as missing lexical entries and coercion (Steels and van Trijp, 2011), and how its architecture offers a uniform way of implementing the various solutions for robustness already pioneered in the aforementioned grammar platforms. 5 Efficiency Unification is computationally expensive, and many technical solutions have been proposed for efficient processing of rich and expressive feature structures (Tomuro, 1999; Flickinger, 2000; Callmeier, 2001). In FCG, however, research on efficiency takes a different dimension because performance is considered to be an integral part of the linguistic theory that needs to be operationalized. The demonstration allows conference participants to inspect the following research results on the interplay between grammar and efficiency: • In line with construction grammar, there is no distinction between the lexicon and the grammar. Based on language usage, the linguistic inventory can nevertheless organize itself in the form of dependency networks that regulate which construction should </context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Daniel P. Flickinger. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6(1):15–28, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Ginzburg</author>
<author>Ivan A Sag</author>
</authors>
<title>Interrogative Investigations: the Form, the Meaning, and Use of English Interrogatives.</title>
<date>2000</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford,</location>
<contexts>
<context position="2535" citStr="Ginzburg and Sag, 2000" startWordPosition="378" endWordPosition="381">ans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HPSG; Ginzburg and Sag, 2000) whose assumptions are incompatible with the foundations of construction grammar. First, cognitive linguistics blurs the distinction between ‘competence’ and ‘performance’, which means giving up the sharp distinction between declarative and procedural representations. Next, construction grammarians argue for a usage-based approach (Langacker, 2000), so the constraints on features may change and features may emerge or disappear from a grammar at any given time. This demonstration introduces Fluid Construction Grammar (FCG; Steels, 2011, 2012a), a novel unification-based grammar formalism that a</context>
</contexts>
<marker>Ginzburg, Sag, 2000</marker>
<rawString>Jonathan Ginzburg and Ivan A. Sag. Interrogative Investigations: the Form, the Meaning, and Use of English Interrogatives. CSLI Publications, Stanford, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adele E Goldberg</author>
<author>Devin M Casenhiser</author>
<author>Nitya Sethuraman</author>
</authors>
<title>Learning argument structure generalizations.</title>
<date>2004</date>
<journal>Cognitive Linguistics,</journal>
<volume>15</volume>
<pages>3--289</pages>
<contexts>
<context position="1657" citStr="Goldberg et al., 2004" startWordPosition="243" endWordPosition="246">emonstration highlights the main differences between FCG and related formalisms. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive ling</context>
</contexts>
<marker>Goldberg, Casenhiser, Sethuraman, 2004</marker>
<rawString>Adele E. Goldberg, Devin M. Casenhiser, and Nitya Sethuraman. Learning argument structure generalizations. Cognitive Linguistics, 15 (3):289–316, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Heine</author>
<author>Ulrike Claudi</author>
<author>Friederike Hünnemeyer</author>
</authors>
<title>Grammaticalization: A Conceptual Framework.</title>
<date>1991</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago,</location>
<contexts>
<context position="1732" citStr="Heine et al., 1991" startWordPosition="254" endWordPosition="257">s. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for </context>
</contexts>
<marker>Heine, Claudi, Hünnemeyer, 1991</marker>
<rawString>Bernd Heine, Ulrike Claudi, and Friederike Hünnemeyer. Grammaticalization: A Conceptual Framework. University of Chicago Press, Chicago, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional grammar.</title>
<date>1979</date>
<booktitle>In Proceedings of the Fifth Annual Meeting of the Berkeley Linguistics Society,</booktitle>
<pages>142--158</pages>
<institution>Berkeley Linguistics Society,</institution>
<contexts>
<context position="2406" citStr="Kay, 1979" startWordPosition="360" endWordPosition="361">tefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HPSG; Ginzburg and Sag, 2000) whose assumptions are incompatible with the foundations of construction grammar. First, cognitive linguistics blurs the distinction between ‘competence’ and ‘performance’, which means giving up the sharp distinction between declarative and procedural representations. Next, construction grammarians argue for a usage-based approach (Langacker, 2000), so the constraints on features may change and features may emerge or disappear from a grammar at any given time. This d</context>
</contexts>
<marker>Kay, 1979</marker>
<rawString>Martin Kay. Functional grammar. In Proceedings of the Fifth Annual Meeting of the Berkeley Linguistics Society, pages 142–158. Berkeley Linguistics Society, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Ulrich Krieger</author>
<author>Ulrich Schäfer</author>
</authors>
<title>TDL – a type description language for HPSG. part 1: Overview.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>893--899</pages>
<location>Kyoto,</location>
<contexts>
<context position="7993" citStr="Krieger and Schäfer, 1994" startWordPosition="1171" endWordPosition="1174">closer inspection of their feature structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) (nominal-adjectival-cxn) (red-ball-15 context-19) ((sem-function identifier)) word-le-1 top sem syn top form syn-subunits syn-cat footprints word-le-1 nominal-adjectival-phrase-1 (word-ballon-1 word-rouge-1) ((number singular) (gender masculine) (syn-function nominal)) (nominal-adjectival-cxn) ((meets word-ballon-1 word-rouge-1)) wordrouge1 wordballon1 1993), LIGHT (Ciortuz, 2002), LKB (Copestake, 2002), ProFIT (Erbach, 1995), TDL (Krieger and Schäfer, 1994), TFS (Emele, 1994), and others (see Bolc et al., 1996, for a survey). Unfortunately, the optimizations and technologies developed within these platforms are often considered by theoretical linguists as engineering solutions rather than scientific contributions. FCG, on the other hand, adheres to the cognitive linguistics assumption that linguistic performance is equally important as linguistic competence, hence processing becomes a central notion in the formalism. FCG representations therefore offer a ‘what you see is what you get’ approach to grammar engineering where the representations hav</context>
</contexts>
<marker>Krieger, Schäfer, 1994</marker>
<rawString>Hans-Ulrich Krieger and Ulrich Schäfer. TDL – a type description language for HPSG. part 1: Overview. In Proceedings of the 15th International Conference on Computational Linguistics, pages 893–899, Kyoto, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fire Women</author>
</authors>
<title>and Dangerous Things: What Categories Reveal about the Mind.</title>
<date>1987</date>
<publisher>The University of Chicago Press,</publisher>
<location>Chicago,</location>
<marker>Women, 1987</marker>
<rawString>George Lakoff. Women, Fire, and Dangerous Things: What Categories Reveal about the Mind. The University of Chicago Press, Chicago, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald W Langacker</author>
</authors>
<title>Foundations of Cognitive Grammar: Theoretical Prerequisites.</title>
<date>1987</date>
<publisher>Stanford University Press,</publisher>
<location>Stanford,</location>
<contexts>
<context position="1435" citStr="Langacker, 1987" startWordPosition="209" endWordPosition="210">al unification-based grammar formalism, caters for this increasing demand. FCG features many of the tools that were pioneered in computational linguistics in the 70s-90s, but combines them in an innovative way. This demonstration highlights the main differences between FCG and related formalisms. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and</context>
</contexts>
<marker>Langacker, 1987</marker>
<rawString>Ronald W. Langacker. Foundations of Cognitive Grammar: Theoretical Prerequisites. Stanford University Press, Stanford, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald W Langacker</author>
</authors>
<title>A dynamic usage-based model.</title>
<date>2000</date>
<booktitle>Usage-Based Models of Language,</booktitle>
<pages>1--63</pages>
<editor>In Michael Barlow and Suzanne Kemmer, editors,</editor>
<publisher>Chicago University Press,</publisher>
<location>Chicago,</location>
<contexts>
<context position="2885" citStr="Langacker, 2000" startWordPosition="426" endWordPosition="428">ach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HPSG; Ginzburg and Sag, 2000) whose assumptions are incompatible with the foundations of construction grammar. First, cognitive linguistics blurs the distinction between ‘competence’ and ‘performance’, which means giving up the sharp distinction between declarative and procedural representations. Next, construction grammarians argue for a usage-based approach (Langacker, 2000), so the constraints on features may change and features may emerge or disappear from a grammar at any given time. This demonstration introduces Fluid Construction Grammar (FCG; Steels, 2011, 2012a), a novel unification-based grammar formalism that addresses these issues, and which is available as open-source software at www.fcg-net.org. After more than a decade of development, FCG is now ready to handle sophisticated linguistic issues. FCG revisits many of the technologies developed by computational linguists and introduces several key innovations that are of interest to anyone working on dee</context>
<context position="10014" citStr="Langacker, 2000" startWordPosition="1475" endWordPosition="1476">this level, grammar engineers can use templates that build detailed constructions. The demonstration shows how to write a grammar in FCG, switching between its design level, its operational level and its interactive web interface (see Figure 2). The web interface allows FCG-users to inspect the linguistic inventory, the search tree in processing, and so on. 4 Robustness and Learning Unification-based grammars have the reputation of being brittle when it comes to processing novelty or ungrammatical utterances (Tomuro, 1999). Since cognitive linguistics adheres to a usagebased view on language (Langacker, 2000), however, an adequate formalization must be robust and open-ended. A first requirement is that there can be different degrees of ‘entrenchment’ in the grammar: while some features might still be emergent, others are already part of well-conventionalized linguistic patterns. Moreover, new features and constructions may appear (or disappear) from a grammar at any given time. These requirements are hard to reconcile with the type hierarchy approach of other formalisms, so FCG does not implement typed feature structures. The demonstration shows how FCG can nevertheless prevent over-licensing of l</context>
</contexts>
<marker>Langacker, 2000</marker>
<rawString>Ronald W. Langacker. A dynamic usage-based model. In Michael Barlow and Suzanne Kemmer, editors, Usage-Based Models of Language, pages 1–63. Chicago University Press, Chicago, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Lee</author>
</authors>
<title>Cognitive Linguistics: An Introduction.</title>
<date>2001</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford,</location>
<contexts>
<context position="1885" citStr="Lee, 2001" startWordPosition="281" endWordPosition="282">ations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generat</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>David Lee. Cognitive Linguistics: An Introduction. Oxford University Press, Oxford, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Lieven</author>
</authors>
<title>Developing constructions.</title>
<date>2009</date>
<journal>Cognitive Linguistics,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="1672" citStr="Lieven, 2009" startWordPosition="247" endWordPosition="248"> the main differences between FCG and related formalisms. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach</context>
</contexts>
<marker>Lieven, 2009</marker>
<rawString>Elena Lieven. Developing constructions. Cognitive Linguistics, 20(1):191–199, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James L McClelland</author>
</authors>
<title>The place of modeling in cognitive science.</title>
<date>2009</date>
<journal>Topics in Cognitive Science,</journal>
<volume>1</volume>
<contexts>
<context position="2166" citStr="McClelland, 2009" startWordPosition="325" endWordPosition="326"> empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), because these tools are typically incorporated in a generative grammar (such as HPSG; Ginzburg and Sag, 2000) whose assumptions are incompatible with the foundations of construction grammar. First, cognitive linguistics blurs the distinction between ‘competence’ and ‘performance’, which means giving up the sharp distinction between declar</context>
</contexts>
<marker>McClelland, 2009</marker>
<rawString>James L. McClelland. The place of modeling in cognitive science. Topics in Cognitive Science, 1:11–38, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nurit Melnik</author>
</authors>
<title>From “hand-written” to computationally implemented HPSG theories.</title>
<date>2005</date>
<booktitle>Proceedings of the HPSG05 Conference,</booktitle>
<editor>In Stefan Müller, editor,</editor>
<publisher>CSLI Publications.</publisher>
<location>Stanford,</location>
<contexts>
<context position="6894" citStr="Melnik, 2005" startWordPosition="1033" endWordPosition="1035">: if the syntactic pole of the construction matches with the transient structure, the attributable syntactic fv-pairs and the semantic pole are merged. 3 WYSIWYG Grammar Engineering Most unification grammars use non-directional linguistic representations that are designed to be independent of any model of processing (Sag and Wasow, 2011). Whereas this may be desirable from a ‘mathematical’ point-of-view, it puts the burden of efficient processing on the shoulders of computational linguists, who have to find a balance between faithfulness to the handwritten theory and computational efficiency (Melnik, 2005). For instance, there is no HPSG implementation, but rather several platforms that support the implementation of ‘HPSG-like’ grammars: ALE (Carpenter and Penn, 1995), ALEP (Schmidt et al., 1996), CUF (Dörre and Dorna, 64 nominal-adjectival-cxn cxn-applied Figure 2: FCG comes equipped with an interactive web interface for inspecting the linguistic inventory, construction application and search. This Figure shows an example construction where two units are opened up for closer inspection of their feature structures. wordballon1 wordrouge1 sem-subunits footprints args sem-cat nominal-adjectival-p</context>
</contexts>
<marker>Melnik, 2005</marker>
<rawString>Nurit Melnik. From “hand-written” to computationally implemented HPSG theories. In Stefan Müller, editor, Proceedings of the HPSG05 Conference, Stanford, 2005. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Rosch</author>
</authors>
<title>Cognitive representations of semantic categories.</title>
<date>1975</date>
<journal>Journal of Experimental Psychology: General,</journal>
<volume>104</volume>
<contexts>
<context position="1403" citStr="Rosch, 1975" startWordPosition="205" endWordPosition="206">operational and bidirectional unification-based grammar formalism, caters for this increasing demand. FCG features many of the tools that were pioneered in computational linguistics in the 70s-90s, but combines them in an innovative way. This demonstration highlights the main differences between FCG and related formalisms. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious bran</context>
</contexts>
<marker>Rosch, 1975</marker>
<rawString>Eleanor Rosch. Cognitive representations of semantic categories. Journal of Experimental Psychology: General, 104:192–233, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ivan</author>
</authors>
<title>Sag and Thomas Wasow. Performancecompatible competence grammar.</title>
<date>2011</date>
<booktitle>NonTransformational Syntax: Formal and Explicit Models of Grammar,</booktitle>
<pages>359--377</pages>
<editor>In Robert D. Borsley and Kersti Börjars, editors,</editor>
<publisher>WileyBlackwell,</publisher>
<marker>Ivan, 2011</marker>
<rawString>Ivan A. Sag and Thomas Wasow. Performancecompatible competence grammar. In Robert D. Borsley and Kersti Börjars, editors, NonTransformational Syntax: Formal and Explicit Models of Grammar, pages 359–377. WileyBlackwell, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Schmidt</author>
<author>Sibylle Rieder</author>
</authors>
<title>Axel Theofilidis, and Thierry Declerck. Lean formalisms, linguistic theory, and applications. grammar development in ALEP.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96),</booktitle>
<pages>286--291</pages>
<location>Copenhagen,</location>
<marker>Schmidt, Rieder, 1996</marker>
<rawString>Paul Schmidt, Sibylle Rieder, Axel Theofilidis, and Thierry Declerck. Lean formalisms, linguistic theory, and applications. grammar development in ALEP. In Proceedings of the 16th International Conference on Computational Linguistics (COLING-96), pages 286– 291, Copenhagen, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Spranger</author>
<author>Martin Loetzsch</author>
</authors>
<title>Syntactic indeterminacy and semantic ambiguity: A case study for German spatial phrases.</title>
<date>2011</date>
<booktitle>In Luc Steels, editor, Design Patterns in Fluid Construction Grammar. John Benjamins,</booktitle>
<location>Amsterdam,</location>
<marker>Spranger, Loetzsch, 2011</marker>
<rawString>Michael Spranger and Martin Loetzsch. Syntactic indeterminacy and semantic ambiguity: A case study for German spatial phrases. In Luc Steels, editor, Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Stadler</author>
</authors>
<title>Chunking constructions. In</title>
<date>2012</date>
<booktitle>Computational Issues in Fluid Construction Grammar.</booktitle>
<editor>Luc Steels, editor,</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin,</location>
<contexts>
<context position="12960" citStr="Stadler, 2012" startWordPosition="1921" endWordPosition="1922">s on the interplay between grammar and efficiency: • In line with construction grammar, there is no distinction between the lexicon and the grammar. Based on language usage, the linguistic inventory can nevertheless organize itself in the form of dependency networks that regulate which construction should be considered when in processing (Wellens and De Beule, 2010; Wellens, 2011). • There is abundant psycholinguistic evidence that language usage contains many readymade language structures. FCG incorporates a chunking mechanism that is able to create such canned phrases for faster processing (Stadler, 2012). • Morphological paradigms, such as the German case system, can be represented in the form of ‘feature matrices’, which reduce syntactic and semantic ambiguity and hence speed up processing efficiency and reliability (van Trijp, 2011). • Many linguistic domains, such as spatial language, are known for their high degree of polysemy. By distinguishing between actual and potential values, such polysemous structures can be processed smoothly (Spranger and Loetzsch, 2011). 6 Conclusion With many well-developed unification-based grammar formalisms available to the community, one might wonder whethe</context>
</contexts>
<marker>Stadler, 2012</marker>
<rawString>Kevin Stadler. Chunking constructions. In Luc Steels, editor, Computational Issues in Fluid Construction Grammar. Springer Verlag, Berlin, 2012.</rawString>
</citation>
<citation valid="true">
<date>2011</date>
<booktitle>Design Patterns in Fluid Construction Grammar. John Benjamins,</booktitle>
<editor>Luc Steels, editor.</editor>
<location>Amsterdam,</location>
<marker>2011</marker>
<rawString>Luc Steels, editor. Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam, 2011.</rawString>
</citation>
<citation valid="true">
<date>2012</date>
<booktitle>Computational Issues in Fluid Construction Grammar.</booktitle>
<editor>Luc Steels, editor.</editor>
<publisher>Springer,</publisher>
<location>Berlin,</location>
<marker>2012</marker>
<rawString>Luc Steels, editor. Computational Issues in Fluid Construction Grammar. Springer, Berlin, 2012a.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
</authors>
<title>Design methods for Fluid Construction Grammar. In</title>
<date>2012</date>
<booktitle>Computational Issues in Fluid Construction Grammar.</booktitle>
<editor>Luc Steels, editor,</editor>
<publisher>Springer Verlag,</publisher>
<location>Berlin,</location>
<contexts>
<context position="9391" citStr="Steels, 2012" startWordPosition="1381" endWordPosition="1382">ed. Some grammarians may object that this design choice forces linguists to worry about processing, but that is entirely the point. It has already been demonstrated in other unification-based formalisms that different grammar representations have a significant impact on processing efficiency (Flickinger, 2000). Moreover, FCG-style representations can be directly implemented and tested without having to compromise on either faithfulness to a theory or computational efficiency. Since writing grammars is highly complex, however, FCG also features a ‘design level’ on top of its operational level (Steels, 2012b). On this level, grammar engineers can use templates that build detailed constructions. The demonstration shows how to write a grammar in FCG, switching between its design level, its operational level and its interactive web interface (see Figure 2). The web interface allows FCG-users to inspect the linguistic inventory, the search tree in processing, and so on. 4 Robustness and Learning Unification-based grammars have the reputation of being brittle when it comes to processing novelty or ungrammatical utterances (Tomuro, 1999). Since cognitive linguistics adheres to a usagebased view on lan</context>
</contexts>
<marker>Steels, 2012</marker>
<rawString>Luc Steels. Design methods for Fluid Construction Grammar. In Luc Steels, editor, Computational Issues in Fluid Construction Grammar. Springer Verlag, Berlin, 2012b.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
<author>Joachim De Beule</author>
</authors>
<title>Unify and merge in Fluid Construction Grammar. In</title>
<date>2006</date>
<booktitle>Symbol Grounding and Beyond., LNAI 4211,</booktitle>
<pages>197--223</pages>
<editor>P. Vogt, Y. Sugita, E. Tuci, and C. Nehaniv, editors,</editor>
<publisher>Springer.</publisher>
<location>Berlin,</location>
<marker>Steels, De Beule, 2006</marker>
<rawString>Luc Steels and Joachim De Beule. Unify and merge in Fluid Construction Grammar. In P. Vogt, Y. Sugita, E. Tuci, and C. Nehaniv, editors, Symbol Grounding and Beyond., LNAI 4211, pages 197–223, Berlin, 2006. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luc Steels</author>
<author>Remi van Trijp</author>
</authors>
<title>How to make construction grammars fluid and robust.</title>
<date>2011</date>
<booktitle>In Luc Steels, editor, Design Patterns in Fluid Construction Grammar,</booktitle>
<pages>301--330</pages>
<publisher>John Benjamins,</publisher>
<location>Amsterdam,</location>
<marker>Steels, van Trijp, 2011</marker>
<rawString>Luc Steels and Remi van Trijp. How to make construction grammars fluid and robust. In Luc Steels, editor, Design Patterns in Fluid Construction Grammar, pages 301–330. John Benjamins, Amsterdam, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gries</author>
</authors>
<title>Collostructions: Investigating the interaction of words and constructions.</title>
<date>2003</date>
<journal>International Journal of Corpus Linguistics,</journal>
<volume>2</volume>
<issue>8</issue>
<contexts>
<context position="1826" citStr="Gries, 2003" startWordPosition="271" endWordPosition="272"> research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately formalize a cognitive linguistic approach to grammar (or “construction grammar”) using the tools for precision-grammars developed in the 70s-90s such as unification (Kay, 1979; Carpenter, 1992), </context>
</contexts>
<marker>Gries, 2003</marker>
<rawString>Anatol Stefanowitsch and Stefan Th. Gries. Collostructions: Investigating the interaction of words and constructions. International Journal of Corpus Linguistics, 2(8):209–243, 2003.</rawString>
</citation>
<citation valid="true">
<date>1994</date>
<booktitle>Reversible Grammar in Natural Language Processing.</booktitle>
<editor>Tomek Strzalkowski, editor.</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston,</location>
<marker>1994</marker>
<rawString>Tomek Strzalkowski, editor. Reversible Grammar in Natural Language Processing. Kluwer Academic Publishers, Boston, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Tomasello</author>
</authors>
<title>Constructing a Language. A Usage Based Theory of Language Acquisition.</title>
<date>2003</date>
<publisher>Harvard University Press,</publisher>
<contexts>
<context position="1634" citStr="Tomasello, 2003" startWordPosition="241" endWordPosition="242">ative way. This demonstration highlights the main differences between FCG and related formalisms. 1 Introduction The “cognitive linguistics enterprise” (Evans et al., 2007) is a rapidly expanding research discipline that has so far avoided rigorous formalizations. This choice was wholly justified in the 70s-90s when the foundations of this scientific movement were laid (Rosch, 1975; Lakoff, 1987; Langacker, 1987), and it remained so during the past two decades while the enterprise worked on getting its facts straight through empirical studies in various subfields such as language acquisition (Tomasello, 2003; Goldberg et al., 2004; Lieven, 2009), language change and grammaticalization (Heine et al., 1991; Barðdal and Chelliah, 2009), and corpus research (Boas, 2003; Stefanowitsch and Gries, 2003). However, with numerous textbooks on the market (Lee, 2001; Croft and Cruse, 2004; Evans and Green, 2006), cognitive linguistics has by now established itself as a serious branch in the study of language, and many cognitive linguists are looking for ways of explicitly formalizing their work through computational models (McClelland, 2009). Unfortunately, it turns out to be very difficult to adequately for</context>
</contexts>
<marker>Tomasello, 2003</marker>
<rawString>Michael Tomasello. Constructing a Language. A Usage Based Theory of Language Acquisition. Harvard University Press, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noriko Tomuro</author>
</authors>
<title>Left-Corner Parsing Algorithm for Unification Grammars.</title>
<date>1999</date>
<tech>PhD thesis,</tech>
<institution>DePaul University,</institution>
<location>Chicago,</location>
<contexts>
<context position="9926" citStr="Tomuro, 1999" startWordPosition="1462" endWordPosition="1463">G also features a ‘design level’ on top of its operational level (Steels, 2012b). On this level, grammar engineers can use templates that build detailed constructions. The demonstration shows how to write a grammar in FCG, switching between its design level, its operational level and its interactive web interface (see Figure 2). The web interface allows FCG-users to inspect the linguistic inventory, the search tree in processing, and so on. 4 Robustness and Learning Unification-based grammars have the reputation of being brittle when it comes to processing novelty or ungrammatical utterances (Tomuro, 1999). Since cognitive linguistics adheres to a usagebased view on language (Langacker, 2000), however, an adequate formalization must be robust and open-ended. A first requirement is that there can be different degrees of ‘entrenchment’ in the grammar: while some features might still be emergent, others are already part of well-conventionalized linguistic patterns. Moreover, new features and constructions may appear (or disappear) from a grammar at any given time. These requirements are hard to reconcile with the type hierarchy approach of other formalisms, so FCG does not implement typed feature </context>
<context position="12035" citStr="Tomuro, 1999" startWordPosition="1784" endWordPosition="1785">s active that runs diagnostics for detecting problems in routine processing, and repairs for solving those problems. The demonstration shows how the meta-layer is used for solving common problems such as missing lexical entries and coercion (Steels and van Trijp, 2011), and how its architecture offers a uniform way of implementing the various solutions for robustness already pioneered in the aforementioned grammar platforms. 5 Efficiency Unification is computationally expensive, and many technical solutions have been proposed for efficient processing of rich and expressive feature structures (Tomuro, 1999; Flickinger, 2000; Callmeier, 2001). In FCG, however, research on efficiency takes a different dimension because performance is considered to be an integral part of the linguistic theory that needs to be operationalized. The demonstration allows conference participants to inspect the following research results on the interplay between grammar and efficiency: • In line with construction grammar, there is no distinction between the lexicon and the grammar. Based on language usage, the linguistic inventory can nevertheless organize itself in the form of dependency networks that regulate which co</context>
</contexts>
<marker>Tomuro, 1999</marker>
<rawString>Noriko Tomuro. Left-Corner Parsing Algorithm for Unification Grammars. PhD thesis, DePaul University, Chicago, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remi van Trijp</author>
</authors>
<title>Feature matrices and agreement: A case study for German case.</title>
<date>2011</date>
<booktitle>In Luc Steels, editor, Design Patterns in Fluid Construction Grammar,</booktitle>
<pages>205--236</pages>
<publisher>John Benjamins,</publisher>
<location>Amsterdam,</location>
<marker>van Trijp, 2011</marker>
<rawString>Remi van Trijp. Feature matrices and agreement: A case study for German case. In Luc Steels, editor, Design Patterns in Fluid Construction Grammar, pages 205–236. John Benjamins, Amsterdam, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pieter Wellens</author>
</authors>
<title>Organizing constructions in networks.</title>
<date>2011</date>
<booktitle>In Luc Steels, editor, Design Patterns in Fluid Construction Grammar. John Benjamins,</booktitle>
<location>Amsterdam,</location>
<contexts>
<context position="12729" citStr="Wellens, 2011" startWordPosition="1887" endWordPosition="1888">kes a different dimension because performance is considered to be an integral part of the linguistic theory that needs to be operationalized. The demonstration allows conference participants to inspect the following research results on the interplay between grammar and efficiency: • In line with construction grammar, there is no distinction between the lexicon and the grammar. Based on language usage, the linguistic inventory can nevertheless organize itself in the form of dependency networks that regulate which construction should be considered when in processing (Wellens and De Beule, 2010; Wellens, 2011). • There is abundant psycholinguistic evidence that language usage contains many readymade language structures. FCG incorporates a chunking mechanism that is able to create such canned phrases for faster processing (Stadler, 2012). • Morphological paradigms, such as the German case system, can be represented in the form of ‘feature matrices’, which reduce syntactic and semantic ambiguity and hence speed up processing efficiency and reliability (van Trijp, 2011). • Many linguistic domains, such as spatial language, are known for their high degree of polysemy. By distinguishing between actual a</context>
</contexts>
<marker>Wellens, 2011</marker>
<rawString>Pieter Wellens. Organizing constructions in networks. In Luc Steels, editor, Design Patterns in Fluid Construction Grammar. John Benjamins, Amsterdam, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pieter Wellens</author>
<author>Joachim De Beule</author>
</authors>
<title>Priming through constructional dependencies: A case study in Fluid Construction Grammar. In</title>
<date>2010</date>
<booktitle>The Evolution of Language (EVOLANG8),</booktitle>
<pages>344--351</pages>
<editor>A. Smith, M. Schouwstra, Bart de Boer, and K. Smith, editors,</editor>
<publisher>World Scientific.</publisher>
<marker>Wellens, De Beule, 2010</marker>
<rawString>Pieter Wellens and Joachim De Beule. Priming through constructional dependencies: A case study in Fluid Construction Grammar. In A. Smith, M. Schouwstra, Bart de Boer, and K. Smith, editors, The Evolution of Language (EVOLANG8), pages 344–351, Singapore, 2010. World Scientific.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>