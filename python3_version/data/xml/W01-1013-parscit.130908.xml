<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000932">
<title confidence="0.956199">
Multilingual Authoring: the NAMIC approach
</title>
<author confidence="0.984193">
R. Basili, M.T. Pazienza
F. Zanzotto
</author>
<affiliation confidence="0.998482">
Dept. of Computer Science
University of Rome, Tor Vergata
</affiliation>
<address confidence="0.638248">
Via di Tor Vergata,
00133 Roma
Italy
</address>
<email confidence="0.843983666666667">
basili@info.uniroma2.it
pazienza@info.uniroma2.it
zanzotto@info.uniroma2.it
</email>
<author confidence="0.747169">
R. Catizone, A. Setzer
N. Webb, Y. Wilks
</author>
<affiliation confidence="0.858550666666667">
Department of Computer Science
University of Sheffield
Regent Court
</affiliation>
<address confidence="0.9683505">
211 Portobello Street,
Sheffield S1 4DP, UK
</address>
<email confidence="0.904319">
R.Catizone@dcs.shef.ac.uk
A.Setzer@dcs.shef.ac.uk
N.Webb@dcs.shef.ac.uk
Y.Wilks@dcs.shef.ac.uk
</email>
<author confidence="0.44043">
Universitat Polit`ecnica de Catalunya
</author>
<affiliation confidence="0.75671">
Centre de Recerca TALP
</affiliation>
<address confidence="0.754148666666667">
Jordi Girona Salgado 1-3,
08034 Barcelona
Spain
</address>
<email confidence="0.951308">
padro@lsi.upc.es
g.rigau@lsi.upc.es
</email>
<note confidence="0.9105655">
L. Padr´o, G. Rigau
Dept. Llenguatges i Sistemes Inform`atics
</note>
<sectionHeader confidence="0.928186" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999717105263158">
With increasing amounts of elec-
tronic information available, and the
increase in the variety of languages
used to produce documents of the
same type, the problem of how to
manage similar documents in dif-
ferent languages arises. This pa-
per proposes an approach to process-
ing/structuring text so that Multi-
lingual Authoring (creating hyper-
text links) can be effectively car-
ried out. This work, funded by
the European Union, is applied to
the Multilingual Authoring of news
agency text. We have applied meth-
ods from Natural Language Process-
ing, especially Information Extrac-
tion technology, to both monolingual
and Multilingual Authoring.
</bodyText>
<sectionHeader confidence="0.997715" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999815489361702">
Modern Information Technologies are faced
with the problem of selecting, filtering and
managing growing amounts of multilingual
information to which access is usually criti-
cal. Traditional Information Retrieval (IR)
approaches are too general in their selection
of relevant documents where as traditional
Information Extraction (IE) (Gaizauskas and
Wilks, 1998; Pazienza, 1997) approaches are
too specific and inflexible. Automatic Au-
thoring is a good example of how these two
methods can be improved and used to cre-
ate a hypertextual organisation of (multilin-
gual) information. This kind of information
is ‘added value’ to the information embodied
in the text and is not in contrast with other
retrieval paradigms. Automatic Authoring
is the activity of processing news items in
streams, detecting and extracting relevant in-
formation from them and, accordingly, organ-
ising texts in a non-linear fashion.
While IE systems like the ones participat-
ing in the Message Understanding Conference
(MUC, 1998) are oriented towards specific
phenomena (e.g. joint ventures) in restricted
domains, the scope of Automatic Authoring
is wider. In Automatic Authoring, the hy-
pertextual structure has to provide naviga-
tion guidelines to the final user which can also
refuse the system suggestions.
In this paper an architecture for Automatic
Multilingual Authoring is presented based on
knowledge-intensive and large-scale Informa-
tion Extraction. The general architecture
is presented capitalising robust methods of
Information Extraction (Cunningham et al.,
1999) and large-scale multilingual resources
(e.g. EuroWordNet). The system is de-
veloped within a European project in the
Human Language Technologies area, called
NAMIC (News Agencies Multilingual Infor-
mation Categorisation)1. It aims to extract
relevant facts from the news streams of large
European news agencies and newspaper pro-
ducers2, to provide hypertextual structures
within each (monolingual) stream and then
produce cross-lingual links between streams.
</bodyText>
<sectionHeader confidence="0.995118" genericHeader="introduction">
2 Authoring
</sectionHeader>
<subsectionHeader confidence="0.998495">
2.1 Automatic Authoring
</subsectionHeader>
<bodyText confidence="0.99546548">
As Automatic Authoring is the task of au-
tomatically deriving a hypertextual structure
from a set of available news articles (in three
different languages English, Spanish and Ital-
ian in our case), the complexity of the overall
framework requires a suitable decomposition:
Text processing requires at least the de-
tection of morphosyntactic information char-
acterising the source texts: recognition, nor-
malisation, and assignment of roles is required
for the main participants for the different
events/facts described.
Event Matching is then the activity of
selecting the relevant facts of a news arti-
cle, in terms of their general type (e.g. sell-
ing or buying companies, winning a football
match), their participants and their related
roles (e.g. the company sold or the winning
football team).
Authoring is thus the activity of gener-
ating links between news articles according
to relationships established among facts de-
tected in the previous phase.
For instance, a company acquisition can be
referred to in one (or more) news items as:
</bodyText>
<listItem confidence="0.982811666666667">
• Intel, the world’s largest chipmaker,
bought a unit of Danish cable maker NKT
that designs high-speed computer chips ...
</listItem>
<footnote confidence="0.98163825">
1See http://namic.itaca.it.
2EFE and ANSA, the major news agencies in Spain
and Italy respectively, and the Financial Times are all
members of the NAMIC consortium.
</footnote>
<listItem confidence="0.996354666666667">
• The giant chip maker Intel said it ac-
quired the closely held ICP Vortex Com-
putersysteme, a German maker of sys-
tems ...
• Intel ha acquistato Xircom inc. per 748
milioni di dollari.
</listItem>
<bodyText confidence="0.9999604375">
The hypothesis underlying Authoring is
that all the above news items deal with facts
in the same area of interest to a potential class
of readers. They should be thus linked and
links should suggest to the user that the un-
derlying motivation (used to decide whether
or not to follow an available link) is that they
all refer to Intel acquisitions.
Notice that a link generation process based
only upon words would fail in the above case
as the common word (that could play the role
of anchor in linking) is the proper noun Intel.
As no other information is available, the re-
sulting set of potential matches can be huge
and the connectivity too high.
In order to get the suitable links the equiv-
alence between the senses of bought and ac-
quired in the first two news items must be
known. Although such a relation can be
drawn by mechanisms like query expansion or
thesauri of synonyms (e.g. WordNet (Miller,
1990)), word polysemy and noise may re-
sult in an inherent proliferation of irrelevant
matches. Contextual information is critical
here. Notice that the senses of ‘buy’ and ‘ac-
quire’ are constrained by the role played by
Intel as ‘agent’ and NKT or ICP Vortex be-
ing the sold companies. In fact, Intel buys
silicon represents an unwanted sense of the
verb and should be distinguished.
The relevant information concerning Intel
should be thus limited to:
</bodyText>
<listItem confidence="0.999679">
• Intel buys a unit of NKT
• Intel acquires ICP Vortex.
</listItem>
<bodyText confidence="0.999838977777778">
These descriptions provide the core infor-
mation able to establish equivalence among
the underlying events. Whenever base event
descriptions are available the linking process
can be carried out via simpler equivalence in-
ferences. The Authoring problem is thus a
side effect of the overall language-processing
task.
According to the suggested decomposition
all the above steps are mandatory. First text
processing is responsible for morpho-syntactic
recognition. Morphological units and syntac-
tic relations are produced for each sentence at
this stage. However, syntactic relations (e.g.
among subjects and verbs) are not sufficient
for proper event characterisation. In the ex-
ample(s), the subject of the verb acquire is
a pronoun only anaphorically referring to In-
tel. Co-reference resolution is usually applied
to this kind of mismatch at the surface level.
This capability is under the responsibility of
the event matching phase. Moreover, in or-
der to keep track of events over syntactic rep-
resentations, references to a target ontology
are required. In such an ontology, equiva-
lence among facts (e.g. buying companies) is
represented. For instance, the relation among
buy and acquire can be encoded under a more
general notion of financial acquisition. On-
tologies also define the set of relevant facts of
the target domain. A financial acquisition is
a perfect example of what is needed in cor-
porate industrial news but is less important,
for example, in sports news, where hiring of
players seems a more relevant event class.
Conceptual differences among facts (de-
tected during event matching) motivate a se-
lective notion of hyperlinking. These links
can be thus generated during the automatic
authoring phase. They are ontologically jus-
tified as their conceptual representation is al-
ready available at this stage. Types as same
acquisition fact, same person, or company can
be used to distinguish links and make expla-
nations available to the user.
</bodyText>
<subsectionHeader confidence="0.9206875">
2.2 Multilingual Automatic
Authoring
</subsectionHeader>
<bodyText confidence="0.999921615384615">
¿From a multilingual perspective, the prob-
lem is to establish links among news in dif-
ferent languages. Full-text approaches can
rely only on language independent phenom-
ena (e.g. proper nouns like Intel) that are
very limited in texts. Most of the above-
mentioned inferences require language neu-
tral information (i.e. conceptual and not lexi-
cal constraints). The inherent overgeneration
related to word polysemy affects the results
of translation-based approaches. Again prin-
cipled representations made available by IE
processes (i.e. templates) provide a viable
solution. The different event realisations (in
the different languages) can be handled dur-
ing the overall event matching. A lexical in-
terface to the ontology is able to factor the
language specific information. As syntactic
differences are handled during text process-
ing, the result is a common domain model for
IE plus independent lexical interfaces. The
unified representation of the set of facts ac-
tivates multilingual linking at a conceptual
level, thus making the Authoring a language
independent process. Some challenges of such
a framework are:
</bodyText>
<listItem confidence="0.882277583333333">
• the size of the ontological resources re-
quired in terms of taxonomic (i.e. IS A
relations) and conceptual information
(i.e. classes of events and implied
participant-event relations)
• the size of the lexical interfaces to the
ontology available for the different lan-
guages
• the amount of task dependent knowledge.
For example the definition of the set of
events useful for the target application is
underspecified.
</listItem>
<bodyText confidence="0.999915214285714">
In the following, we propose a complex ar-
chitecture where the above problems are
approached according to well-assessed tech-
niques presented elsewhere. Robust Informa-
tion Extraction is adopted (Humphreys et al.,
1998) as an overall method for text process-
ing and event matching. Target events are
semiautomatically derived from domain texts
and represented in the IE engine ontology. Fi-
nally, multilinguality is realised by assuming a
large-scale multilingual lexical hierarchy as a
reference ontology for nominal concepts. The
resulting architecture for Multilingual Auto-
matic Authoring is presented in Section 3.4.
</bodyText>
<sectionHeader confidence="0.981997" genericHeader="method">
3 The NAMIC system
</sectionHeader>
<subsectionHeader confidence="0.871714">
3.1 Large scale IE for Automatic
Authoring
</subsectionHeader>
<bodyText confidence="0.999954211538462">
Information Extraction is a very good ap-
proach to Automatic Authoring for a num-
ber of reasons. The key components of an IE
system are events and objects - the kind of
components that trigger hyperlinks in an Au-
thoring system. Coreference is a significant
part of Information Extraction and indeed a
necessary component in Authoring. Named
Entities - people, places, and organisations,
etc. - play an important part in Authoring
and again are firmly addressed in Information
Extraction systems.
The role of a world model as a method
for event matching and coreferencing
The world model is an ontological represen-
tation of events and objects for a particular
domain or set of domains. The world model
is made up of a set of event and object types,
with attributes. The event types characterise
a set of events in a particular domain and
are usually represented in a text by verbs.
Object Types on the other hand, are best
thought of as characterising a set of people,
places or things and are usually represented
in a text by nouns (both proper and com-
mon). When used as part of an Information
Extraction system, the instances of each type
are inserted/added to the world model. Once
the instances have been added, a procedure
is carried out to link those instances that re-
fer to the same thing - achieving coreference
resolution.
In NAMIC, the world model is created
using the XI cross-classification hierarchy
(Gaizauskas and Humphreys, 1996). The def-
inition of a XI cross-classification hierarchy is
referred to as an ontology, and this together
with an association of attributes with nodes
in the ontology forms the world model. Pro-
cessing a text acts to populate this initially
bare world model with the various instances
and relations mentioned in the text, convert-
ing it into a discourse model specific to the
particular text.
The attributes associated with nodes in
the ontology are simple attribute:value pairs
where the value may either be fixed, as in
the attribute animate:yes which is associ-
ated with the person node, or where the value
may be dependent on various conditions, the
evaluation of which makes reference to other
information in the model.
</bodyText>
<subsubsectionHeader confidence="0.955311">
3.1.1 The Description of LaSIE
</subsubsectionHeader>
<bodyText confidence="0.994313083333333">
LaSIE is a Large-scale Information Ex-
traction system, developed for MUC (Mes-
sage Understanding Conference) competi-
tions, comprised of a variety of modules, see
(Humphreys et al., 1998; MUC, 1998). Al-
though we are not using the complete LaSIE
system in NAMIC, we are using 2 of the key
modules - the Named Entity Matcher and the
Discourse Processor. Below is a description of
each of these modules.
Named Entity Matcher The Named En-
tity Matcher finds named entities through
a secondary phase of parsing which uses a
named entity grammar and a set of gazetteer
lists. It takes as input parsed text from the
first phase of parsing and the named entity
grammar which contains rules for finding a
predefined set of named entities and a set of
gazetteer lists containing proper nouns. The
Name Entity Matcher returns the text with
the Named Entities marked. The Named En-
tities in NAMIC are PERSONS, ORGANI-
SATIONS, LOCATIONS, and DATES. The
Named Entity grammar contains rules for
coreferring abbreviations as well as different
ways of expressing the same named entity
such as Dr. Smith, John Smith and Mr.
Smith occurring in the same article.
Discourse Processor The Discourse Pro-
cessor module translates the semantic rep-
resentation produced by the parser into a
representation of instances, their ontolog-
ical classes and their attributes, in the
XI knowledge representation language (see
Gaizauskas(1996)). XI allows a straightfor-
ward definition of cross-classification hierar-
chies, the association of arbitrary attributes
with classes or instances, and a simple mech-
anism to inherit attributes from classes or in-
stances higher in the hierarchy.
The semantic representation produced by
the parser for a single sentence is processed
by adding its instances, together with their
attributes, to the discourse model which has
been constructed so far for the text.
Following the addition of the instances
mentioned in the current sentence, together
with any presuppositions that they inherit,
the coreference algorithm is applied to at-
tempt to resolve, or in fact merge, each of
the newly added instances with instances cur-
rently in the discourse model.
The merging of instances involves the re-
moval of the least specific instance (i.e. the
highest in the ontology) and the addition of
all its attributes to the other instance. This
results in a single instance with more than one
realisation attribute, which corresponds to a
single entity mentioned more than once in the
text, i.e. a coreference.
</bodyText>
<subsectionHeader confidence="0.994739">
3.2 Ontological Modeling
</subsectionHeader>
<bodyText confidence="0.99956">
As we have seen in section 3.1, some critical
issues of the NAMIC project rely on the per-
formance of the lexical and conceptual compo-
nents of all linguistic processors. As NAMIC
faces large-scale coverage of news in several
languages we decided to adopt EuroWordNet
(Vossen, 1998) as a common semantic formal-
ism to support:
</bodyText>
<listItem confidence="0.990793833333333">
• lexical semantic inferences (e.g. general-
isation, disambiguation)
• broad coverage (e.g. lexical and semanti-
cal) and
• a common interlingual platform for link-
ing events from different documents.
</listItem>
<bodyText confidence="0.9994564">
The NAMIC ontology consists of 40 prede-
fined object classes and 46 attribute types re-
lated to Name Entity objects and nearly 1000
objects relating to EuroWordNet base con-
cepts.
</bodyText>
<subsectionHeader confidence="0.6593375">
3.2.1 EuroWordNet as a Multilingual
Lexical Knowledge Base
</subsectionHeader>
<bodyText confidence="0.999836416666667">
Since the world model aims to describe the
language used in a given domain via events
and objects, the accuracy and breadth of the
model will impact how well the information
extraction works.
EuroWordNet (Vossen, 1998) is a multilin-
gual lexical knowledge base (LKB) with word-
nets for several European languages (Dutch,
Italian, Spanish, German, French, Czech and
Estonian). The wordnets are structured
in the same way as the American wordnet
for English developed at Princeton (Miller,
1990) containing synsets (sets of synonymous
words) with basic semantic relations between
them.
Each wordnet represents a unique
language-internal system of lexicalisa-
tions. In addition, the wordnets are linked
to an Inter-Lingual-Index (ILI), based on
the Princeton WordNet 1.5. WordNet 1.6 is
also connected to the ILI as another English
WordNet (Daude et al., 2000). Via this
index, the languages are interconnected so
that it is possible to go from the words in
one language to words in any other language
having similar meaning. The index also
gives access to a shared top-ontology and
a subset of 1024 Base Concepts (BC). The
Base Concepts provide a common seman-
tic framework for all the languages, while
language specific properties are maintained
in the individual wordnets. The LKB can
be used, among others, for monolingual and
cross-lingual information retrieval, which
has been demonstrated in other projects
(Gonzalo et al., 1998).
</bodyText>
<subsectionHeader confidence="0.99677">
3.3 Multilingual Event description
</subsectionHeader>
<bodyText confidence="0.999926777777778">
The traditional limitations of a knowledge-
based information extraction system such as
LaSIE have been the need to hand-code in-
formation for the world model - specifically
relating to the event structure of the domain.
For the NAMIC project, we have decided
to semi-automate the process of adding new
‘event descriptions’ to the World Model. To
us, event descriptions can be categorised as a
set of regularly occurring verbs within our do-
main, complete with their subcategorisation
information.
These verbs can be extracted with simple
statistical techniques and are, for the moment
subjected to hand pruning. Once a list of
verbs has been extracted, subcategorisation
patterns can be generated automatically using
a Galois lattice (as described in (Basili et al.,
2000b)). These frames can then be uploaded
into the event hierarchy of the discourse in-
terpreter world model.
The world model can have a structure
which is essentially language independent in
all but the lowest level - at which stage lexi-
calisations relating to each representative lan-
guage are required. Associated with these lex-
icalisations are language dependent scenario
rules which control the behaviour of instances
of these events with a Discourse Model. These
rules are expected to differ across languages in
the way they control coreference for languages
which are constrained to lesser or greater de-
gree.
The lattice generates patterns which refer
to synsets in the WordNet hierarchy. For
our purposes, we will use patterns referring to
Base Concepts in the EuroWordNet hierarchy
- which allows us to exploit the Inter-Lingual-
Index as described in the previous section.
These Base Concepts serve as a level of mul-
tilingual abstraction for the conceptual con-
straints of our events, and allow us to extend
the number of semantic classes from seven
(the MUC Named Entity classifications) to
1024 - the number of base concepts in EWN.
</bodyText>
<subsectionHeader confidence="0.970728">
3.4 The NAMIC Architecture
</subsectionHeader>
<bodyText confidence="0.998182421052631">
The complexity of the overall NAMIC sys-
tem required the adoption of a distributed
computing paradigm in the design. The sys-
tem is a distributed object oriented system
where services (like text processing or Multi-
lingual Authoring) are provided by indepen-
dent components and asynchronous communi-
cation is allowed. Independent news streams
for the different languages (English, Spanish,
and Italian) are assumed. Language specific
processors (LPs) are thus responsible for text
processing and event matching in indepen-
dent text units in each stream. LPs com-
pile an objective representation (see Fig. 1)
for each source texts, including the detected
morphosyntactic information, categorisation
in news standards (IPTC classes) and descrip-
tion of the relevant events. Any later Au-
thoring activity is based on this canonical
representation of the news. In particular a
monolingual process is carried out within any
stream by the three monolingual Authoring
Engines (English AE, Spanish AE, and Ital-
ian AE). A second phase is foreseen to take
into account links across streams, i.e. multi-
lingual hyper-linking: a Multilingual Author-
ing Engine (M-AE) is here foreseen. Figure
1 represents the overall flow of information.
The Language Processors are composed of a
morphosyntactic (Eng, Ita and Spa MS) and
an event-matching component (EM). The lex-
ical interfaces (ELI, SLI and ItLI) to the uni-
fied Domain model are also used during event
matching.
The linguistic processors are in charge of
producing the objective representation of in-
coming news. This task is performed during
MS analysis by two main subprocessors:
</bodyText>
<listItem confidence="0.998565846153846">
• a modular and lexicalised shallow
morpho-syntactic parser (Basili et al.,
2000c), providing name entity match-
ing and extracting dependency graphs
from source sentences. Ambiguity is
controlled by part-of-speech tagging and
domain verb-subcategorisation frames
that guide the dependency recognition
phase.
• a statistical linear text classifier based
upon some of the derived linguistic fea-
tures (Basili et al., 2000a) (lemmas, POS
tags and proper nouns)
</listItem>
<bodyText confidence="0.999988269230769">
The results are then input to the event
matcher that by means of the discourse in-
terpreter (Humphreys et al., 1998) derive the
objective representation. As discussed in sec-
tion 3.1, coreferencing is a side effect of the
discourse interpretation (Humphreys et al.,
1998). It is based on the multilingual domain
model where relevant events are described and
nominal concepts represented.
The overall architecture is highly modular
and open to load balancing activity as well as
to adaptation and porting. The communica-
tion interfaces among the MS and EM com-
ponents as well as among the AEs and the M-
AE processors are specified via XML DTDs.
This allows for user-friendly uploading of a
back-end database with the detected material
as well as the easy design and management of
the front-end databases (available for tempo-
rary tasks, like event matching after MS). All
the servers are objects in a distributed archi-
tecture within a CORBA environment. The
current version includes the linguistic proces-
sors (MS and EM) for all the three languages.
The English and Italian linguistic processors
are fully object oriented modules based on
</bodyText>
<figure confidence="0.998966588235294">
news
Language Processors
Spanish
MS
English
MS
Italian
MS
ItLI
ELI
SLI
Domain
Model
Spanish
EM
English
EM
Italian
EM
Objective
Representation
Spanish
AE
Multi-
Lingual
Authoring
Engine
English
AE
Italian
AE
Monolingual Links
Multilingual
Links
</figure>
<figureCaption confidence="0.999986">
Figure 1: Namic Architecture
</figureCaption>
<bodyText confidence="0.999749055555556">
Java. They integrate libraries written in C,
C++, Prolog, and Perl for specific functional-
ities (e.g. parsing) running under a Windows
NT platform. The Spanish linguistic proces-
sor shares the discourse interpreter and the
text classifier with the other modules, while
the morpho syntactic component is currently
a Unix server based on Perl. The use of a dis-
tributed architecture under CORBA allowed
a flexible solution to its integration into the
overall architecture. The servers can be in-
stantiated in multiple copies throughout the
network if the amount of required computa-
tion exceeds the capability of a current con-
figuration. As the workload of a news stream
is not easily predictable, distribution and dy-
namic load balancing is the only realistic ap-
proach.
</bodyText>
<sectionHeader confidence="0.985307" genericHeader="discussions">
4 Discussion and future Work
</sectionHeader>
<bodyText confidence="0.999982014925373">
The above sections have provided the out-
line of a general NLP-based approach to auto-
matic authoring. The emphasis given to tra-
ditional capabilities of Information Extraction
depends on the relevance of news content in
the target Web service scenarios as well as
on their inherent multilinguality. The bet-
ter is the generalisation provided by the IE
component, the higher is the independence
from the text source language. As a result,
IE is here seen as a natural approach to cross-
lingual hypertextual authoring. Other works
in this area make extensive use of traditional
IR techniques (e.g. full text search) or rely
on already traced (i.e. manually coded) hy-
perlinks (e.g. (Chakrabarti et al., 1998; Klein-
berg, 1999)). The suggested NAMIC architec-
ture exploits linguistic capabilities for deriv-
ing entirely original (ex novo) resources, over
dynamic, previously unreleased, streams of in-
formation.
The result is a large-scale multilingual NLP
application capitalising existing methods and
resources within an advanced software engi-
neering process. The use of a distributed
Java/CORBA architecture makes the system
very attractive for its scalability and adaptiv-
ity. It results in a very complex (but realis-
tic) NLP architecture. Its organisation (lexi-
cal interfaces with respect to the multilingual
ontology) makes it very well suited for cus-
tomisation and porting to large domains. Al-
though the current version is a prototype, it
realises the complete set of core functionali-
ties, including the main IE steps and the dis-
tributed Java/CORBA layer.
It is worth noticing that a set of extensions
are made viable within the proposed architec-
ture. A first line is the extension of the avail-
able multilingual lexical knowledge. The Dis-
course Model can be used to better reflect on-
tological relationships within a particular do-
main. These relationships could be examined
to confirm known word sense usage as well
as to postulate/propose novel word sense us-
age. Using the mechanism for the addition of
events (as categorised by verbs) to the world
model, users can specify new events which can
be added to the IE system, to achieve User
Driven IE, and deliver a form of adaptive in-
formation extraction.
The instantiated domain models can be
thus used as a basis for ontological resource
expansion as a form of adaptive process.
For example, the stored instantiations of dis-
course models within a specific domain can be
compared: it may be thus possible to recog-
nise new sets of events or objects which are
not currently utilised within the system.
The evaluation strategy that is made possi-
ble within the NAMIC consortium will make
use of the current users (i.e. news agencies)
expertise. The agreed evaluation methods
will provide evidence about the viability of
the proposed large-scale IE-based approach to
authoring, as a valuable paradigm for infor-
mation access.
</bodyText>
<sectionHeader confidence="0.986133" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999909">
This research is funded by the European
Union, grant number IST-1999-12392. We
would also like to thank all of the partners
in the NAMIC consortium.
</bodyText>
<sectionHeader confidence="0.998822" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999356724637682">
R. Basili, A. Moschitti, and M.T. Pazienza. 2000a.
Language sensitive text classification. In In
proceeding of 6th RIAO Conference (RIAO
2000), Content-Based Multimedia Information
Access, Coll ge de France, Paris, France.
R. Basili, M.T. Pazienza, and M. Vindigni. 2000b.
Corpus-driven learning of event recognition
rules. In Proc. of Machine Learning for Infor-
mation Extraction workshop, held jointly with
the ECAI2000, Berlin, Germany.
R. Basili, M.T. Pazienza, and F.M. Zanzotto.
2000c. Customizable modular lexicalized pars-
ing. In Proc. of the 6th International Workshop
on Parsing Technology, IWPT2000, Trento,
Italy.
S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg,
P. Raghavan, and S. Rajagopalan. 1998. Auto-
matic resource compilation by analysing hyper-
link structure and associated text. In Proceed-
ings of the 7th International World Wide Web
Conference, Brisbane, Australia.
C. Cunningham, R. Gaizauskas, K. Humphreys,
and Y. Wilks. 1999. Experience with a lan-
guage engineering architecture: 3 years of gate.
In Proceedings of the AISB’99 Workshop on
Reference Architectures and Data Standards for
NLP, Edinburgh, UK.
J. Daude, L. Padro, and G. Rigau. 2000. Map-
ping wordnets using structural information.
In Proceedings of the 38th Annual Meeting of
the Association for Computational Linguistics
ACL’00, Hong Kong, China.
R. Gaizauskas and K. Humphreys. 1996. Xi:
A simple prolog-based language for cross-
classification and inheritance. In Proceedings of
the 6th International Conference on Artificial
Intelligence: Methodologies, Systems, Applica-
tions (AIMSA96), pages 86–95.
R. Gaizauskas and Y. Wilks. 1998. Information
Extraction: Beyond Document Retrieval. Jour-
nal of Documentation, 54(1):70–105.
J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigar-
ran. 1998. Indexing with wordnet synsets
can improve text retrieval. In Proceedings of
the COLING/ACL’98 Workshop on Usage of
WordNet for NLP, Montreal, Canada.
K. Humphreys, R. Gaizauskas, S. Azzam,
C. Huyck, B. Mitchell, H. Cunningham, and
Y. Wilks. 1998. University of sheffield: De-
scription of the lasie-ii system as used for muc-7.
In Proceedings of the Seventh Message Under-
standing Conferences (MUC-7). Morgan Kauf-
man. Available at http://www.saic.com.
Jon M. Kleinberg. 1999. Authoritative sources
in a hyperlinked environment. Journal of the
ACM, 46(5):604–632.
G. Miller. 1990. Five papers on wordnet. Inter-
national Journal of Lexicography, 4(3).
1998. Proceedings of the Seventh Message Under-
standing Conference (MUC-7). Morgan Kauf-
man. Available at http://www.saic.com.
M.T. Pazienza, editor. 1997. Information Ex-
traction. A Multidisciplinary Approach to an
Emerging Information Technology. Number
1299 in LNAI. Springer-Verlag, Heidelberg,
Germany.
P. Vossen. 1998. EuroWordNet: A Multilin-
gual Database with Lexical Semantic Networks.
Kluwer Academic Publishers, Dordrecht.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.130942">
<title confidence="0.987271">Multilingual Authoring: the NAMIC approach</title>
<author confidence="0.936528">R Basili</author>
<author confidence="0.936528">M T</author>
<affiliation confidence="0.94251725">F. Dept. of Computer University of Rome, Tor Via di Tor</affiliation>
<address confidence="0.980137">00133</address>
<email confidence="0.933494">zanzotto@info.uniroma2.it</email>
<note confidence="0.5733885">R. Catizone, A. N. Webb, Y.</note>
<affiliation confidence="0.953760666666667">Department of Computer University of Regent</affiliation>
<address confidence="0.751709">211 Portobello Sheffield S1 4DP,</address>
<email confidence="0.996753">Y.Wilks@dcs.shef.ac.uk</email>
<affiliation confidence="0.955248">Universitat Polit`ecnica de Centre de Recerca Jordi Girona Salgado</affiliation>
<address confidence="0.992326">08034</address>
<email confidence="0.940871">g.rigau@lsi.upc.es</email>
<author confidence="0.9763">L Padr´o</author>
<author confidence="0.9763">G Rigau</author>
<affiliation confidence="0.90264">Dept. Llenguatges i Sistemes Inform`atics</affiliation>
<abstract confidence="0.9936219">With increasing amounts of electronic information available, and the increase in the variety of languages used to produce documents of the same type, the problem of how to manage similar documents in different languages arises. This paper proposes an approach to processing/structuring text so that Multilingual Authoring (creating hypertext links) can be effectively carried out. This work, funded by the European Union, is applied to the Multilingual Authoring of news agency text. We have applied methods from Natural Language Processing, especially Information Extraction technology, to both monolingual and Multilingual Authoring.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>A Moschitti</author>
<author>M T Pazienza</author>
</authors>
<title>Language sensitive text classification.</title>
<date>2000</date>
<booktitle>In In proceeding of 6th RIAO Conference (RIAO</booktitle>
<location>Paris, France.</location>
<contexts>
<context position="18228" citStr="Basili et al., 2000" startWordPosition="2863" endWordPosition="2866"> model - specifically relating to the event structure of the domain. For the NAMIC project, we have decided to semi-automate the process of adding new ‘event descriptions’ to the World Model. To us, event descriptions can be categorised as a set of regularly occurring verbs within our domain, complete with their subcategorisation information. These verbs can be extracted with simple statistical techniques and are, for the moment subjected to hand pruning. Once a list of verbs has been extracted, subcategorisation patterns can be generated automatically using a Galois lattice (as described in (Basili et al., 2000b)). These frames can then be uploaded into the event hierarchy of the discourse interpreter world model. The world model can have a structure which is essentially language independent in all but the lowest level - at which stage lexicalisations relating to each representative language are required. Associated with these lexicalisations are language dependent scenario rules which control the behaviour of instances of these events with a Discourse Model. These rules are expected to differ across languages in the way they control coreference for languages which are constrained to lesser or great</context>
<context position="21082" citStr="Basili et al., 2000" startWordPosition="3314" endWordPosition="3317"> i.e. multilingual hyper-linking: a Multilingual Authoring Engine (M-AE) is here foreseen. Figure 1 represents the overall flow of information. The Language Processors are composed of a morphosyntactic (Eng, Ita and Spa MS) and an event-matching component (EM). The lexical interfaces (ELI, SLI and ItLI) to the unified Domain model are also used during event matching. The linguistic processors are in charge of producing the objective representation of incoming news. This task is performed during MS analysis by two main subprocessors: • a modular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000c), providing name entity matching and extracting dependency graphs from source sentences. Ambiguity is controlled by part-of-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. • a statistical linear text classifier based upon some of the derived linguistic features (Basili et al., 2000a) (lemmas, POS tags and proper nouns) The results are then input to the event matcher that by means of the discourse interpreter (Humphreys et al., 1998) derive the objective representation. As discussed in section 3.1, coreferencing is a side effect of the disc</context>
</contexts>
<marker>Basili, Moschitti, Pazienza, 2000</marker>
<rawString>R. Basili, A. Moschitti, and M.T. Pazienza. 2000a. Language sensitive text classification. In In proceeding of 6th RIAO Conference (RIAO 2000), Content-Based Multimedia Information Access, Coll ge de France, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>M Vindigni</author>
</authors>
<title>Corpus-driven learning of event recognition rules.</title>
<date>2000</date>
<booktitle>In Proc. of Machine Learning for Information Extraction workshop, held jointly with the ECAI2000,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="18228" citStr="Basili et al., 2000" startWordPosition="2863" endWordPosition="2866"> model - specifically relating to the event structure of the domain. For the NAMIC project, we have decided to semi-automate the process of adding new ‘event descriptions’ to the World Model. To us, event descriptions can be categorised as a set of regularly occurring verbs within our domain, complete with their subcategorisation information. These verbs can be extracted with simple statistical techniques and are, for the moment subjected to hand pruning. Once a list of verbs has been extracted, subcategorisation patterns can be generated automatically using a Galois lattice (as described in (Basili et al., 2000b)). These frames can then be uploaded into the event hierarchy of the discourse interpreter world model. The world model can have a structure which is essentially language independent in all but the lowest level - at which stage lexicalisations relating to each representative language are required. Associated with these lexicalisations are language dependent scenario rules which control the behaviour of instances of these events with a Discourse Model. These rules are expected to differ across languages in the way they control coreference for languages which are constrained to lesser or great</context>
<context position="21082" citStr="Basili et al., 2000" startWordPosition="3314" endWordPosition="3317"> i.e. multilingual hyper-linking: a Multilingual Authoring Engine (M-AE) is here foreseen. Figure 1 represents the overall flow of information. The Language Processors are composed of a morphosyntactic (Eng, Ita and Spa MS) and an event-matching component (EM). The lexical interfaces (ELI, SLI and ItLI) to the unified Domain model are also used during event matching. The linguistic processors are in charge of producing the objective representation of incoming news. This task is performed during MS analysis by two main subprocessors: • a modular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000c), providing name entity matching and extracting dependency graphs from source sentences. Ambiguity is controlled by part-of-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. • a statistical linear text classifier based upon some of the derived linguistic features (Basili et al., 2000a) (lemmas, POS tags and proper nouns) The results are then input to the event matcher that by means of the discourse interpreter (Humphreys et al., 1998) derive the objective representation. As discussed in section 3.1, coreferencing is a side effect of the disc</context>
</contexts>
<marker>Basili, Pazienza, Vindigni, 2000</marker>
<rawString>R. Basili, M.T. Pazienza, and M. Vindigni. 2000b. Corpus-driven learning of event recognition rules. In Proc. of Machine Learning for Information Extraction workshop, held jointly with the ECAI2000, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Basili</author>
<author>M T Pazienza</author>
<author>F M Zanzotto</author>
</authors>
<title>Customizable modular lexicalized parsing.</title>
<date>2000</date>
<booktitle>In Proc. of the 6th International Workshop on Parsing Technology, IWPT2000,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="18228" citStr="Basili et al., 2000" startWordPosition="2863" endWordPosition="2866"> model - specifically relating to the event structure of the domain. For the NAMIC project, we have decided to semi-automate the process of adding new ‘event descriptions’ to the World Model. To us, event descriptions can be categorised as a set of regularly occurring verbs within our domain, complete with their subcategorisation information. These verbs can be extracted with simple statistical techniques and are, for the moment subjected to hand pruning. Once a list of verbs has been extracted, subcategorisation patterns can be generated automatically using a Galois lattice (as described in (Basili et al., 2000b)). These frames can then be uploaded into the event hierarchy of the discourse interpreter world model. The world model can have a structure which is essentially language independent in all but the lowest level - at which stage lexicalisations relating to each representative language are required. Associated with these lexicalisations are language dependent scenario rules which control the behaviour of instances of these events with a Discourse Model. These rules are expected to differ across languages in the way they control coreference for languages which are constrained to lesser or great</context>
<context position="21082" citStr="Basili et al., 2000" startWordPosition="3314" endWordPosition="3317"> i.e. multilingual hyper-linking: a Multilingual Authoring Engine (M-AE) is here foreseen. Figure 1 represents the overall flow of information. The Language Processors are composed of a morphosyntactic (Eng, Ita and Spa MS) and an event-matching component (EM). The lexical interfaces (ELI, SLI and ItLI) to the unified Domain model are also used during event matching. The linguistic processors are in charge of producing the objective representation of incoming news. This task is performed during MS analysis by two main subprocessors: • a modular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000c), providing name entity matching and extracting dependency graphs from source sentences. Ambiguity is controlled by part-of-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. • a statistical linear text classifier based upon some of the derived linguistic features (Basili et al., 2000a) (lemmas, POS tags and proper nouns) The results are then input to the event matcher that by means of the discourse interpreter (Humphreys et al., 1998) derive the objective representation. As discussed in section 3.1, coreferencing is a side effect of the disc</context>
</contexts>
<marker>Basili, Pazienza, Zanzotto, 2000</marker>
<rawString>R. Basili, M.T. Pazienza, and F.M. Zanzotto. 2000c. Customizable modular lexicalized parsing. In Proc. of the 6th International Workshop on Parsing Technology, IWPT2000, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Chakrabarti</author>
<author>B Dom</author>
<author>D Gibson</author>
<author>J Kleinberg</author>
<author>P Raghavan</author>
<author>S Rajagopalan</author>
</authors>
<title>Automatic resource compilation by analysing hyperlink structure and associated text.</title>
<date>1998</date>
<booktitle>In Proceedings of the 7th International World Wide Web Conference,</booktitle>
<location>Brisbane, Australia.</location>
<contexts>
<context position="24354" citStr="Chakrabarti et al., 1998" startWordPosition="3835" endWordPosition="3838"> to automatic authoring. The emphasis given to traditional capabilities of Information Extraction depends on the relevance of news content in the target Web service scenarios as well as on their inherent multilinguality. The better is the generalisation provided by the IE component, the higher is the independence from the text source language. As a result, IE is here seen as a natural approach to crosslingual hypertextual authoring. Other works in this area make extensive use of traditional IR techniques (e.g. full text search) or rely on already traced (i.e. manually coded) hyperlinks (e.g. (Chakrabarti et al., 1998; Kleinberg, 1999)). The suggested NAMIC architecture exploits linguistic capabilities for deriving entirely original (ex novo) resources, over dynamic, previously unreleased, streams of information. The result is a large-scale multilingual NLP application capitalising existing methods and resources within an advanced software engineering process. The use of a distributed Java/CORBA architecture makes the system very attractive for its scalability and adaptivity. It results in a very complex (but realistic) NLP architecture. Its organisation (lexical interfaces with respect to the multilingual</context>
</contexts>
<marker>Chakrabarti, Dom, Gibson, Kleinberg, Raghavan, Rajagopalan, 1998</marker>
<rawString>S. Chakrabarti, B. Dom, D. Gibson, J. Kleinberg, P. Raghavan, and S. Rajagopalan. 1998. Automatic resource compilation by analysing hyperlink structure and associated text. In Proceedings of the 7th International World Wide Web Conference, Brisbane, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cunningham</author>
<author>R Gaizauskas</author>
<author>K Humphreys</author>
<author>Y Wilks</author>
</authors>
<title>Experience with a language engineering architecture: 3 years of gate.</title>
<date>1999</date>
<booktitle>In Proceedings of the AISB’99 Workshop on Reference Architectures and Data Standards for NLP,</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="2914" citStr="Cunningham et al., 1999" startWordPosition="409" endWordPosition="412">ke the ones participating in the Message Understanding Conference (MUC, 1998) are oriented towards specific phenomena (e.g. joint ventures) in restricted domains, the scope of Automatic Authoring is wider. In Automatic Authoring, the hypertextual structure has to provide navigation guidelines to the final user which can also refuse the system suggestions. In this paper an architecture for Automatic Multilingual Authoring is presented based on knowledge-intensive and large-scale Information Extraction. The general architecture is presented capitalising robust methods of Information Extraction (Cunningham et al., 1999) and large-scale multilingual resources (e.g. EuroWordNet). The system is developed within a European project in the Human Language Technologies area, called NAMIC (News Agencies Multilingual Information Categorisation)1. It aims to extract relevant facts from the news streams of large European news agencies and newspaper producers2, to provide hypertextual structures within each (monolingual) stream and then produce cross-lingual links between streams. 2 Authoring 2.1 Automatic Authoring As Automatic Authoring is the task of automatically deriving a hypertextual structure from a set of availa</context>
</contexts>
<marker>Cunningham, Gaizauskas, Humphreys, Wilks, 1999</marker>
<rawString>C. Cunningham, R. Gaizauskas, K. Humphreys, and Y. Wilks. 1999. Experience with a language engineering architecture: 3 years of gate. In Proceedings of the AISB’99 Workshop on Reference Architectures and Data Standards for NLP, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Daude</author>
<author>L Padro</author>
<author>G Rigau</author>
</authors>
<title>Mapping wordnets using structural information.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics ACL’00,</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="16848" citStr="Daude et al., 2000" startWordPosition="2645" endWordPosition="2648">l lexical knowledge base (LKB) with wordnets for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). The wordnets are structured in the same way as the American wordnet for English developed at Princeton (Miller, 1990) containing synsets (sets of synonymous words) with basic semantic relations between them. Each wordnet represents a unique language-internal system of lexicalisations. In addition, the wordnets are linked to an Inter-Lingual-Index (ILI), based on the Princeton WordNet 1.5. WordNet 1.6 is also connected to the ILI as another English WordNet (Daude et al., 2000). Via this index, the languages are interconnected so that it is possible to go from the words in one language to words in any other language having similar meaning. The index also gives access to a shared top-ontology and a subset of 1024 Base Concepts (BC). The Base Concepts provide a common semantic framework for all the languages, while language specific properties are maintained in the individual wordnets. The LKB can be used, among others, for monolingual and cross-lingual information retrieval, which has been demonstrated in other projects (Gonzalo et al., 1998). 3.3 Multilingual Event </context>
</contexts>
<marker>Daude, Padro, Rigau, 2000</marker>
<rawString>J. Daude, L. Padro, and G. Rigau. 2000. Mapping wordnets using structural information. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics ACL’00, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>K Humphreys</author>
</authors>
<title>Xi: A simple prolog-based language for crossclassification and inheritance.</title>
<date>1996</date>
<booktitle>In Proceedings of the 6th International Conference on Artificial Intelligence: Methodologies, Systems, Applications (AIMSA96),</booktitle>
<pages>86--95</pages>
<contexts>
<context position="11971" citStr="Gaizauskas and Humphreys, 1996" startWordPosition="1861" endWordPosition="1864">a particular domain and are usually represented in a text by verbs. Object Types on the other hand, are best thought of as characterising a set of people, places or things and are usually represented in a text by nouns (both proper and common). When used as part of an Information Extraction system, the instances of each type are inserted/added to the world model. Once the instances have been added, a procedure is carried out to link those instances that refer to the same thing - achieving coreference resolution. In NAMIC, the world model is created using the XI cross-classification hierarchy (Gaizauskas and Humphreys, 1996). The definition of a XI cross-classification hierarchy is referred to as an ontology, and this together with an association of attributes with nodes in the ontology forms the world model. Processing a text acts to populate this initially bare world model with the various instances and relations mentioned in the text, converting it into a discourse model specific to the particular text. The attributes associated with nodes in the ontology are simple attribute:value pairs where the value may either be fixed, as in the attribute animate:yes which is associated with the person node, or where the </context>
</contexts>
<marker>Gaizauskas, Humphreys, 1996</marker>
<rawString>R. Gaizauskas and K. Humphreys. 1996. Xi: A simple prolog-based language for crossclassification and inheritance. In Proceedings of the 6th International Conference on Artificial Intelligence: Methodologies, Systems, Applications (AIMSA96), pages 86–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Gaizauskas</author>
<author>Y Wilks</author>
</authors>
<title>Information Extraction: Beyond Document Retrieval.</title>
<date>1998</date>
<journal>Journal of Documentation,</journal>
<volume>54</volume>
<issue>1</issue>
<contexts>
<context position="1726" citStr="Gaizauskas and Wilks, 1998" startWordPosition="232" endWordPosition="235"> work, funded by the European Union, is applied to the Multilingual Authoring of news agency text. We have applied methods from Natural Language Processing, especially Information Extraction technology, to both monolingual and Multilingual Authoring. 1 Introduction Modern Information Technologies are faced with the problem of selecting, filtering and managing growing amounts of multilingual information to which access is usually critical. Traditional Information Retrieval (IR) approaches are too general in their selection of relevant documents where as traditional Information Extraction (IE) (Gaizauskas and Wilks, 1998; Pazienza, 1997) approaches are too specific and inflexible. Automatic Authoring is a good example of how these two methods can be improved and used to create a hypertextual organisation of (multilingual) information. This kind of information is ‘added value’ to the information embodied in the text and is not in contrast with other retrieval paradigms. Automatic Authoring is the activity of processing news items in streams, detecting and extracting relevant information from them and, accordingly, organising texts in a non-linear fashion. While IE systems like the ones participating in the Mes</context>
</contexts>
<marker>Gaizauskas, Wilks, 1998</marker>
<rawString>R. Gaizauskas and Y. Wilks. 1998. Information Extraction: Beyond Document Retrieval. Journal of Documentation, 54(1):70–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gonzalo</author>
<author>F Verdejo</author>
<author>I Chugur</author>
<author>J Cigarran</author>
</authors>
<title>Indexing with wordnet synsets can improve text retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING/ACL’98 Workshop on Usage of WordNet for NLP,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="17423" citStr="Gonzalo et al., 1998" startWordPosition="2738" endWordPosition="2741">s another English WordNet (Daude et al., 2000). Via this index, the languages are interconnected so that it is possible to go from the words in one language to words in any other language having similar meaning. The index also gives access to a shared top-ontology and a subset of 1024 Base Concepts (BC). The Base Concepts provide a common semantic framework for all the languages, while language specific properties are maintained in the individual wordnets. The LKB can be used, among others, for monolingual and cross-lingual information retrieval, which has been demonstrated in other projects (Gonzalo et al., 1998). 3.3 Multilingual Event description The traditional limitations of a knowledgebased information extraction system such as LaSIE have been the need to hand-code information for the world model - specifically relating to the event structure of the domain. For the NAMIC project, we have decided to semi-automate the process of adding new ‘event descriptions’ to the World Model. To us, event descriptions can be categorised as a set of regularly occurring verbs within our domain, complete with their subcategorisation information. These verbs can be extracted with simple statistical techniques and a</context>
</contexts>
<marker>Gonzalo, Verdejo, Chugur, Cigarran, 1998</marker>
<rawString>J. Gonzalo, F. Verdejo, I. Chugur, and J. Cigarran. 1998. Indexing with wordnet synsets can improve text retrieval. In Proceedings of the COLING/ACL’98 Workshop on Usage of WordNet for NLP, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Humphreys</author>
<author>R Gaizauskas</author>
<author>S Azzam</author>
<author>C Huyck</author>
<author>B Mitchell</author>
<author>H Cunningham</author>
<author>Y Wilks</author>
</authors>
<title>University of sheffield: Description of the lasie-ii system as used for muc-7.</title>
<date>1998</date>
<booktitle>In Proceedings of the Seventh Message Understanding Conferences (MUC-7).</booktitle>
<publisher>Morgan</publisher>
<contexts>
<context position="10067" citStr="Humphreys et al., 1998" startWordPosition="1546" endWordPosition="1549">f the ontological resources required in terms of taxonomic (i.e. IS A relations) and conceptual information (i.e. classes of events and implied participant-event relations) • the size of the lexical interfaces to the ontology available for the different languages • the amount of task dependent knowledge. For example the definition of the set of events useful for the target application is underspecified. In the following, we propose a complex architecture where the above problems are approached according to well-assessed techniques presented elsewhere. Robust Information Extraction is adopted (Humphreys et al., 1998) as an overall method for text processing and event matching. Target events are semiautomatically derived from domain texts and represented in the IE engine ontology. Finally, multilinguality is realised by assuming a large-scale multilingual lexical hierarchy as a reference ontology for nominal concepts. The resulting architecture for Multilingual Automatic Authoring is presented in Section 3.4. 3 The NAMIC system 3.1 Large scale IE for Automatic Authoring Information Extraction is a very good approach to Automatic Authoring for a number of reasons. The key components of an IE system are even</context>
<context position="12906" citStr="Humphreys et al., 1998" startWordPosition="2013" endWordPosition="2016"> text, converting it into a discourse model specific to the particular text. The attributes associated with nodes in the ontology are simple attribute:value pairs where the value may either be fixed, as in the attribute animate:yes which is associated with the person node, or where the value may be dependent on various conditions, the evaluation of which makes reference to other information in the model. 3.1.1 The Description of LaSIE LaSIE is a Large-scale Information Extraction system, developed for MUC (Message Understanding Conference) competitions, comprised of a variety of modules, see (Humphreys et al., 1998; MUC, 1998). Although we are not using the complete LaSIE system in NAMIC, we are using 2 of the key modules - the Named Entity Matcher and the Discourse Processor. Below is a description of each of these modules. Named Entity Matcher The Named Entity Matcher finds named entities through a secondary phase of parsing which uses a named entity grammar and a set of gazetteer lists. It takes as input parsed text from the first phase of parsing and the named entity grammar which contains rules for finding a predefined set of named entities and a set of gazetteer lists containing proper nouns. The </context>
<context position="21573" citStr="Humphreys et al., 1998" startWordPosition="3388" endWordPosition="3391">ormed during MS analysis by two main subprocessors: • a modular and lexicalised shallow morpho-syntactic parser (Basili et al., 2000c), providing name entity matching and extracting dependency graphs from source sentences. Ambiguity is controlled by part-of-speech tagging and domain verb-subcategorisation frames that guide the dependency recognition phase. • a statistical linear text classifier based upon some of the derived linguistic features (Basili et al., 2000a) (lemmas, POS tags and proper nouns) The results are then input to the event matcher that by means of the discourse interpreter (Humphreys et al., 1998) derive the objective representation. As discussed in section 3.1, coreferencing is a side effect of the discourse interpretation (Humphreys et al., 1998). It is based on the multilingual domain model where relevant events are described and nominal concepts represented. The overall architecture is highly modular and open to load balancing activity as well as to adaptation and porting. The communication interfaces among the MS and EM components as well as among the AEs and the MAE processors are specified via XML DTDs. This allows for user-friendly uploading of a back-end database with the dete</context>
</contexts>
<marker>Humphreys, Gaizauskas, Azzam, Huyck, Mitchell, Cunningham, Wilks, 1998</marker>
<rawString>K. Humphreys, R. Gaizauskas, S. Azzam, C. Huyck, B. Mitchell, H. Cunningham, and Y. Wilks. 1998. University of sheffield: Description of the lasie-ii system as used for muc-7. In Proceedings of the Seventh Message Understanding Conferences (MUC-7). Morgan Kaufman. Available at http://www.saic.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>Journal of the ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="24372" citStr="Kleinberg, 1999" startWordPosition="3839" endWordPosition="3841">he emphasis given to traditional capabilities of Information Extraction depends on the relevance of news content in the target Web service scenarios as well as on their inherent multilinguality. The better is the generalisation provided by the IE component, the higher is the independence from the text source language. As a result, IE is here seen as a natural approach to crosslingual hypertextual authoring. Other works in this area make extensive use of traditional IR techniques (e.g. full text search) or rely on already traced (i.e. manually coded) hyperlinks (e.g. (Chakrabarti et al., 1998; Kleinberg, 1999)). The suggested NAMIC architecture exploits linguistic capabilities for deriving entirely original (ex novo) resources, over dynamic, previously unreleased, streams of information. The result is a large-scale multilingual NLP application capitalising existing methods and resources within an advanced software engineering process. The use of a distributed Java/CORBA architecture makes the system very attractive for its scalability and adaptivity. It results in a very complex (but realistic) NLP architecture. Its organisation (lexical interfaces with respect to the multilingual ontology) makes i</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>Five papers on wordnet.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="5826" citStr="Miller, 1990" startWordPosition="886" endWordPosition="887">nk) is that they all refer to Intel acquisitions. Notice that a link generation process based only upon words would fail in the above case as the common word (that could play the role of anchor in linking) is the proper noun Intel. As no other information is available, the resulting set of potential matches can be huge and the connectivity too high. In order to get the suitable links the equivalence between the senses of bought and acquired in the first two news items must be known. Although such a relation can be drawn by mechanisms like query expansion or thesauri of synonyms (e.g. WordNet (Miller, 1990)), word polysemy and noise may result in an inherent proliferation of irrelevant matches. Contextual information is critical here. Notice that the senses of ‘buy’ and ‘acquire’ are constrained by the role played by Intel as ‘agent’ and NKT or ICP Vortex being the sold companies. In fact, Intel buys silicon represents an unwanted sense of the verb and should be distinguished. The relevant information concerning Intel should be thus limited to: • Intel buys a unit of NKT • Intel acquires ICP Vortex. These descriptions provide the core information able to establish equivalence among the underlyin</context>
<context position="16485" citStr="Miller, 1990" startWordPosition="2593" endWordPosition="2594">and nearly 1000 objects relating to EuroWordNet base concepts. 3.2.1 EuroWordNet as a Multilingual Lexical Knowledge Base Since the world model aims to describe the language used in a given domain via events and objects, the accuracy and breadth of the model will impact how well the information extraction works. EuroWordNet (Vossen, 1998) is a multilingual lexical knowledge base (LKB) with wordnets for several European languages (Dutch, Italian, Spanish, German, French, Czech and Estonian). The wordnets are structured in the same way as the American wordnet for English developed at Princeton (Miller, 1990) containing synsets (sets of synonymous words) with basic semantic relations between them. Each wordnet represents a unique language-internal system of lexicalisations. In addition, the wordnets are linked to an Inter-Lingual-Index (ILI), based on the Princeton WordNet 1.5. WordNet 1.6 is also connected to the ILI as another English WordNet (Daude et al., 2000). Via this index, the languages are interconnected so that it is possible to go from the words in one language to words in any other language having similar meaning. The index also gives access to a shared top-ontology and a subset of 10</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. Five papers on wordnet. International Journal of Lexicography, 4(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaufman</author>
</authors>
<date>1998</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference (MUC-7).</booktitle>
<publisher>Morgan</publisher>
<note>Available at http://www.saic.com.</note>
<marker>Kaufman, 1998</marker>
<rawString>1998. Proceedings of the Seventh Message Understanding Conference (MUC-7). Morgan Kaufman. Available at http://www.saic.com.</rawString>
</citation>
<citation valid="true">
<title>Information Extraction. A Multidisciplinary Approach to an Emerging Information Technology.</title>
<date>1997</date>
<journal>Number</journal>
<volume>1299</volume>
<editor>M.T. Pazienza, editor.</editor>
<publisher>Springer-Verlag,</publisher>
<location>Heidelberg, Germany.</location>
<marker>1997</marker>
<rawString>M.T. Pazienza, editor. 1997. Information Extraction. A Multidisciplinary Approach to an Emerging Information Technology. Number 1299 in LNAI. Springer-Verlag, Heidelberg, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="15517" citStr="Vossen, 1998" startWordPosition="2440" endWordPosition="2441"> removal of the least specific instance (i.e. the highest in the ontology) and the addition of all its attributes to the other instance. This results in a single instance with more than one realisation attribute, which corresponds to a single entity mentioned more than once in the text, i.e. a coreference. 3.2 Ontological Modeling As we have seen in section 3.1, some critical issues of the NAMIC project rely on the performance of the lexical and conceptual components of all linguistic processors. As NAMIC faces large-scale coverage of news in several languages we decided to adopt EuroWordNet (Vossen, 1998) as a common semantic formalism to support: • lexical semantic inferences (e.g. generalisation, disambiguation) • broad coverage (e.g. lexical and semantical) and • a common interlingual platform for linking events from different documents. The NAMIC ontology consists of 40 predefined object classes and 46 attribute types related to Name Entity objects and nearly 1000 objects relating to EuroWordNet base concepts. 3.2.1 EuroWordNet as a Multilingual Lexical Knowledge Base Since the world model aims to describe the language used in a given domain via events and objects, the accuracy and breadth</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>P. Vossen. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>