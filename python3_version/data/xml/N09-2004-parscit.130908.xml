<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.191963">
<title confidence="0.993294">
Semantic Roles for SMT: A Hybrid Two-Pass Model
</title>
<author confidence="0.997546">
Dekai WU1 Pascale FUNG2
</author>
<affiliation confidence="0.994267">
Human Language Technology Center
HKUST
1Department of Computer Science and Engineering
2Department of Electronic and Computer Engineering
University of Science and Technology, Clear Water Bay, Hong Kong
</affiliation>
<email confidence="0.989436">
dekai@cs.ust.hk pascale@ee.ust.hk
</email>
<sectionHeader confidence="0.998538" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998578470588235">
We present results on a novel hybrid semantic
SMT model that incorporates the strengths of
both semantic role labeling and phrase-based
statistical machine translation. The approach
avoids major complexity limitations via a
two-pass architecture. The first pass is per-
formed using a conventional phrase-based
SMT model. The second pass is performed by
a re-ordering strategy guided by shallow se-
mantic parsers that produce both semantic
frame and role labels. Evaluation on a Wall
Street Journal newswire genre test set showed
the hybrid model to yield an improvement of
roughly half a point in BLEU score over a
strong pure phrase-based SMT baseline – to
our knowledge, the first successful application
of semantic role labeling to SMT.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977">
Many of the most glaring errors made by to-
day’s statistical machine translation systems are
those resulting from confusion of semantic roles.
Translation errors of this type frequently result in
critical misunderstandings of the essential meaning
of the original input language sentences – who did
what to whom, for whom or what, how, where,
when, and why.
Semantic role confusions are errors of adequacy
rather than fluency. It has often been noted that
the dominance of lexically-oriented, precision-
based metrics such as BLEU (Papineni et al. 2002)
tend to reward fluency more than adequacy. The
length penalty in the BLEU metric, in particular, is
only an indirect and weak indicator of adequacy.
As a result, SMT work has been driven to optimize
</bodyText>
<page confidence="0.985305">
13
</page>
<bodyText confidence="0.999905684210526">
systems such that they often produce translations
that contain significant role confusion errors de-
spite reading fluently.
The present work is inspired by the question of
whether we can improve translation utility via a
strategy of favoring semantic adequacy slightly
more – possibly at the expense of slight degrada-
tions in lexical fluency.
Shallow semantic parsing models have attained
increasing levels of accuracy in recent years
(Gildea and Jurafsky 2000; Sun and Jurafsky 2004;
Pradhan et al. 2004, 2005; Pradhan 2005; Fung et
al. 2006, 2007; Gim6nez and Mˆrquez 2007a,
2008). Such models, which identify semantic
frames within input sentences by marking its
predicates, and labeling their arguments with the
semantic roles that they fill.
Evidence has begun to accumulate that semantic
frames – predicates and semantic roles – tend to
preserve consistency across translations better than
syntactic roles do. This is, of course, by design; it
follows from the definition of semantic roles,
which are less language-dependent than syntactic
roles. Across Chinese and English, for example, it
has been reported that approximately 84% of se-
mantic roles are preserved consistently (Fung et al.
2006). Of these, roughly 15% do not preserve syn-
tactic roles consistently.
Since this directly targets the task of determin-
ing semantic correctness, we believe that the ade-
quacy of MT output could be improved by
leveraging the predictions of semantic parsers. We
would like to exploit automatic semantic parsers to
identify inconsistent semantic frame and role map-
pings between the input source sentences and their
output translations.
However, we take note of the difficult experi-
ence in making syntactic and semantic models con-
</bodyText>
<subsubsectionHeader confidence="0.834095">
Proceedings of NAACL HLT 2009: Short Papers, pages 13–16,
</subsubsectionHeader>
<bodyText confidence="0.98625975">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
tribute to improving SMT accuracy. On the one
hand, there is reason to be optimistic. Over the
past decade, we have seen an accumulation of evi-
dence that SMT accuracy can be improved via
tree-structured and syntactic models (e.g., Wu
1997; Wu and Chiang 2009), and more recently,
work from lexical semantics has also at long last
been successfully applied to increasing SMT accu-
racy, in the form of techniques adapted from word
sense disambiguation models (Chan et al. 2007;
Gimenez and Mˆrquez 2007b; Carpuat and Wu
2007). On the other hand, both directions saw un-
expected disappointments along the way (e.g., Och
et al. 2003; Carpuat and Wu 2005). We are there-
fore forewarned that it is likely to be at least as
difficult to successfully adapt the even more com-
plex types of lexical semantics modeling from se-
mantic parsing and role labeling to the translation
task.
In this paper, we present a novel hybrid model
that, for the first time to our knowledge, success-
fully applies semantic parsing technology to the
challenge of improving the quality of Chinese-
English statistical machine translation. The model
makes use of a typical representative SMT system
based on Moses, plus shallow semantic parsers for
both English and Chinese.
</bodyText>
<sectionHeader confidence="0.944532" genericHeader="method">
2 Hybrid two-pass semantic SMT
</sectionHeader>
<bodyText confidence="0.999939069767442">
While the accuracy of shallow semantic parsers
has been approaching reasonably high levels in
recent years for well-studied languages like Eng-
lish, and to a lesser extent, Chinese, the problem of
excessive computational complexity is one of the
primary challenges in adapting semantic parsing
technology to the translation task.
Semantic parses, by definition, are less likely
than syntactic parses to obey clearly nested hierar-
chical composition rules. Moreover, the semantic
parses are less likely to share an exactly isomor-
phic structure across the input and output lan-
guages, since the raison d’être of semantic parsing
is to capture semantic frame and role regularities
independent of syntactic variation – monolingually
and cross-lingually.
This makes it difficult to incorporate semantic
parsing into SMT merely by applying the sort of
dynamic programming techniques found in current
syntactic and tree-structured SMT models, most of
which rely on being able to factor the computation
into independent computations on the subtrees. In
other words, the key computational obstacle is that
the semantic parse of a larger string (or string pair,
in the case of translation) is not in general strictly
mechanically composable from the semantic parses
of its smaller substrings (or substring pairs).
In fact, the lack of easy compositionality is the
reason that today’s most accurate shallow semantic
parsers rely not primarily on compositional parsing
techniques, but rather on ensembles of predictors
that independently rate/rank a wide variety of fac-
tors supporting the role assignments given a broad
sentence-wide range of context features. But while
this improves semantic parsing accuracy, it poses a
major obstacle for efficient tight integration into
the sub-hypothesis construction and maintenance
loops within SMT decoders.
To circumvent this computational obstacle, the
hybrid two-pass model defers application of the
non-compositional semantic parsing information
until a second error-correcting pass. This imposes
a division of labor between the two passes.
</bodyText>
<listItem confidence="0.996544310344828">
1. Apply a semantic parser for the input language to the input
source sentence.
2. Apply a semantic parser for the output language to the baseline
translation that was output by the first pass. Note: this also pro-
duces a shallow syntactic parse as a byproduct.
3. If the semantic frames (target predicates and their associated
semantic roles) are all consistent between the input and output
sentences, and are aligned to each other by the phrase alignments
from the first pass, then finish immediately and output the base-
line translation.
4. Segment the baseline translation by introducing segment
boundaries around every constituent phrase whose shallow syn-
tactic parse category (from step 2) was V, NP, or PP. This
breaks the baseline translation into a small number of coarse
chunks to consider during re-ordering, instead of a large number
of individual words.
5. Generate a set of candidate re-ordered translation hypotheses by
iteratively moving constituent phrases whose predicate or se-
mantic role label was mismatched to the input sentence. Each
new candidate generated may in turn spawn a further set of can-
didates (especially since moving one constituent phrase may
cause another’s predicate or semantic role label to change from
matched to mismatched). This search is performed breadth-first
to favor fewer re-orderings (in case the hypothesis generation
grows beyond allotted time).
6. Apply a semantic parser for the output language to each candi-
date re-ordered translation hypothesis as it is generated.
7. Return the re-ordered translation hypothesis with the maximum
match of semantic predicates and arguments.
</listItem>
<figureCaption confidence="0.994644">
Figure 1. Algorithm for second pass.
</figureCaption>
<page confidence="0.976116">
14
</page>
<figureCaption confidence="0.999505">
Figure 2. Example, showing translations after SMT first pass and after re-ordering second pass.
</figureCaption>
<bodyText confidence="0.999972081081081">
The first pass is performed using a conventional
phrase-based SMT model. The phrase-based SMT
model is assigned to the tasks of (a) providing an
initial baseline hypothesis translation, and (b) fix-
ing the lexical choice decisions. Note that the lexi-
cal choice decisions are not only at the single-word
level, but are in general at the phrasal level.
The second pass takes the output of the first
pass, and re-orders constituent phrases correspond-
ing to semantic predicates and arguments, seeking
to maximize the cross-lingual match of the seman-
tic parse of the re-ordered translation to that of the
original input sentence. The second pass algorithm
performs the error correction shown in Figure 1.
The design decision to allow the first pass to fix
all lexical choices follows an insight inspired by an
empirical observation from our error analyses: the
lexical choice decisions being made by today’s
SMT models have attained fairly reasonable levels,
and are not where the major problems of adequacy
lie. Rather, the ordering of arguments in relation
to their predicates is often where the main failures
of adequacy occur. By avoiding lexical choice
variations while considering re-ordering hypothe-
ses, a significantly larger amount of re-ordering
can be done without further increasing computa-
tional complexity. So we sacrifice a small amount
of fluency by allowing re-ordering without com-
pensating lexical choice – in exchange for gaining
potentially a larger amount of fluency by getting
the predicate-argument structure right.
The model has a similar rationale for employing
a re-ordering pass instead of re-ranking n-best lists
or lattices. Oracle analysis of n-best lists and lat-
tices show that they often focus on lexical choice
alternatives rather than re-ordering / role variations
which are more important to semantic adequacy.
</bodyText>
<sectionHeader confidence="0.999552" genericHeader="method">
3 Experiment
</sectionHeader>
<bodyText confidence="0.995878583333333">
A Chinese-English experiment was conducted
on the two-pass hybrid model. A phrase-based
SMT baseline model was built by augmenting the
open source statistical machine translation decoder
Moses (Koehn et al. 2007) with additional pre-
processors. English and Chinese shallow semantic
parsers followed those discussed in Section 1.
The model was trained on LDC newswire paral-
lel text consisting of 3.42 million sentence pairs,
containing 64.1 million English words and 56.9
million Chinese words. The English was tokenized
and case-normalized; the Chinese was tokenized
via a maximum-entropy model (Fung et al. 2004).
Phrase translations were extracted via the grow-
diag-final heuristic.
The language model is a 6-gram model trained
with Kneser-Ney smoothing using the SRI lan-
guage modeling toolkit (Stolcke 2002).
The test set of Wall Street Journal newswire
sentences was randomly extracted from the Chi-
nese-English Bilingual Propbank. Although we
did not make use of the Propbank annotations, this
would potentially allow other types of analyses in
the future.
The phrase-based SMT model used for the first
pass achieves a BLEU score of 42.99, establishing
a fairly strong baseline to begin with.
In comparison, the automatically error-
corrected translations that are output by the second
pass achieve a BLEU score of 43.51. This repre-
sents approximately half a point improvement over
the strong baseline.
An example is seen in Figure 2. The SMT first
pass translation has an ARG0 National Develop-
ment Bank of Japan in the capital market which is
badly mismatched to both the input sentence’s
</bodyText>
<page confidence="0.991968">
15
</page>
<note confidence="0.5615">
ARG0 IN* 开发 银ff and ARGM-LOC 4tE p
</note>
<bodyText confidence="0.997354375">
资* r J 场. The second pass ends up re-ordering
the constituent phrase corresponding to the mis-
matched ARGM-LOC, of Japan in the capital
market, to follow the PRED issued, where the new
English semantic parse now assigns most of its
words the correctly matched ARGM-LOC seman-
tic role label. Similarly, samurai bonds 30 billion
yen is re-ordered to 30 billion yen samurai bonds.
</bodyText>
<sectionHeader confidence="0.980559" genericHeader="discussions">
4 Discussion and conclusion
</sectionHeader>
<bodyText confidence="0.999992314285714">
To our knowledge, this is a first result demonstrat-
ing that shallow semantic parsing can improve
translation accuracy of SMT models. We note that
accuracy here was measured via BLEU, and it has
been widely observed that the negative impacts of
semantic predicate-argument errors on the utility of
the translation are underestimated by evaluation
metrics based on lexical criteria such as BLEU.
We conjecture that more expensive manual evalua-
tion techniques which directly measure translation
utility could even more strongly reveal improve-
ment in role confusion errors.
The hybrid two-pass approach can be compared
with the greedy re-ordering based strategy of the
ReWrite decoder (Germann et al. 2001), although
our search is breadth-first rather than purely
greedy. Whereas ReWrite was based on word-
level re-ordering, however, our approach is based
on constituent phrase re-ordering, and the phrases
to be re-ordered are more selectively chosen via
the semantic parse labels. Moreover, the objective
function being maximized by ReWrite is still the
SMT model score; whereas in our case the new
objective function is cross-lingual semantic predi-
cate-argument match (plus an implicit search bias
toward fewer re-orderings).
The hybrid two-pass approach can also be com-
pared with serial combination architectures for hy-
brid MT (e.g., Ueffing et al. 2008). But whereas
Ueffing et al. take the output from a first-pass rule-
based MT system, and then correct it using a sec-
ond-pass SMT system, our two-pass semantic
SMT model does the reverse: it takes the output
from a first-pass SMT system, and then corrects it
with the aid of semantic analyzers.
</bodyText>
<footnote confidence="0.979579">
Acknowledgments. Thanks to Chi-kiu Lo and Zhaojun Wu. This material is
based upon work supported in part by the Defense Advanced Research Projects
Agency (DARPA) under GALE Contract No. HR0011-06-C-0023, and by the
Hong Kong Research Grants Council (RGC) research grants GRF621008,
GRF612806, DAG03/04.EG09, RGC6256/00E, and RGC6083/99E.
</footnote>
<sectionHeader confidence="0.883507" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999334461538462">
Marine Carpuat and Dekai Wu. 2005. Word sense disambiguation vs. statistical
machine translation. 43rd Annual Meeting of the Association for Computa-
tional Linguistics (ACL-2005). Ann Arbor, MI: Jun 2005.
Marine Carpuat and Dekai Wu. 2007. Improving statistical machine translation
using word sense disambiguation. 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL 2007). Prague: Jun 2007. 61-72.
Yee Seng Chan, Hwee Tou Ng and David Chiang 2007. Word sense disam-
biguation improves statistical machine translation. 45th Annual Meeting of
the Association for Computational Linguistics (ACL-07), Prague: Jun 2007.
Pascale Fung, Grace Ngai, Yongsheng Yang and Benfeng Chen. 2004. A maxi-
mum-entropy Chinese parser augmented by transformation-based learning.
ACM Transactions on Asian Language Information Processing (TALIP)
3(2): 159-168.
Pascale Fung, Zhaojun Wu, Yongsheng Yang and Dekai Wu. 2006. Automatic
learning of Chinese/English semantic structure mapping. IEEE/ACL 2006
Workshop on Spoken Language Technology (SLT 2006). Aruba: Dec 2006.
230-233.
Pascale Fung, Zhaojun Wu, Yongsheng Yang and Dekai Wu. 2007. Learning
Bilingual Semantic Frames: Shallow Semantic Parsing vs. Semantic Role
Projection. 11th Conference on Theoretical and Methodological Issues in
Machine Translation (TMI 2007). Skšvde, Sweden: Sep 2007. 75-84.
Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu and Kenji Yamada.
Fast Decoding and Optimal Decoding for Machine Translation. 2001. 39th
Annual Meeting of the Association for Computational Linguistics (ACL-
2001). Toulouse: July 2001.
Daniel Gildea and Daniel Jurafsky. 2000. Automatic Labeling of Semantic
Roles. 38th Annual Conference of the Association for Computational Lin-
guistics (ACL-2000). 512–520, Hong Kong: Oct 2000.
Jesœs Gim6nez and Llu’s Mˆrquez. 2007. Linguistic Features for Automatic
Evaluation of Heterogeneous MT Systems. WMT 2007 (ACL&apos;07).
Jesœs Gim6nez and Llu’s Mˆrquez. 2007. Discriminative Phrase Selection for
Statistical Machine Translation. Learning Machine Translation. NIPS
Workshop Series. MIT Press.
Jesœs Gim6nez and Llu’s Mˆrquez. 2008. A Smorgasbord of Features for Auto-
matic MT Evaluation. 3rd ACL Workshop on Statistical Machine Transla-
tion (shared evaluation task). Pages 195-198, Columbus, Ohio: Jun 2008.
Alessandro Moschitti and Roberto Basili. 2005. Verb subcategorization kernels
for automatic semantic labeling. ACL-SIGLEX Workshop on Deep Lexical
Acquisition. Ann Arbor: Jun 2005. 10-17.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji
Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine
Eng, Viren Jain, Zhen Jin and Dragomir Radev. 2004. A smorgasbord of
features for statistical machine translation. Human Language Technology
Conference of the North American Chapter of the Association for Computa-
tional Linguistics (HLT/NAACL-2004). Boston: May 2004.
Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu. 2002. BLEU:
A method for automatic evaluation of machine translation. 40th Annual
Meeting of the Association for Computational Linguistics (ACL-2002).
Sameer Pradhan. 2005. ASSERT: Automatic Statistical SEmantic Role Tagger.
http://oak.colorado.edu/assert/.
Sameer Pradhan, Kadri Hacioglu, Valerie Krugler, Wayne Ward, James H.
Martin and Daniel Jurafsky. 2005. Support Vector Learning for Semantic
Argument Classification. Machine Learning 60(1-3): 11-39.
Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James Martin and Daniel Juraf-
sky. 2004. Shallow Semantic Parsing using Support Vector Machines. Hu-
man Language Technology/North American Chapter of the Association for
Computational Linguistics (HLT/NAACL-2004). Boston: May 2004.
Andreas Stolcke. 2002. SRILM – An Extensible Language Modeling Toolkit.
International Conference on Spoken Language Processing (ICSLP-2002).
Denver, Colorado: Sep 2002.
Honglin Sun and Daniel Jurafsky. 2004. Shallow Semantic Parsing of Chinese.
Human Language Technology Conference of the North American Chapter of
the Association for Computational Linguistics (HLT/NAACL-2004). 249-
256. Boston: May 2004.
Nicola Ueffing, Jens Stephan, Evgeny Matusov, Lo•c Dugast, George Foster,
Roland Kuhn, Jean Senellart and Jin Yang. 2008. Tighter Integration of
Rule-based and Statistical MT in Serial System Combination. 22nd Interna-
tional Conference on Computational Linguistics (COLING 2008). Manches-
ter: Aug 2008.
Dekai Wu. 1997. Stochastic Inversion Transduction Grammars and bilingual
parsing of parallel corpora. Computational Linguistics 23(3): 377-404.
Dekai Wu and David Chiang (eds). 2009. Proceedings of SSST-3, Third Work-
shop on Syntax and Structure in Statistical Translation (NAACL-HLT
2009). Boulder, CO: Jun 2009.
Nianwen Xue and Martha Palmer. 2005. Automatic Semantic Role Labeling for
Chinese Verbs. 19th International Joint Conference on Artificial Intelli-
gence. Edinburgh, Scotland.
</reference>
<page confidence="0.998701">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.301502">
<title confidence="0.752626">Semantic Roles for SMT: A Hybrid Two-Pass Model Pascale</title>
<author confidence="0.723406">Human Language Technology</author>
<affiliation confidence="0.937490333333333">of Computer Science and of Electronic and Computer University of Science and Technology, Clear Water Bay, Hong Kong</affiliation>
<email confidence="0.828169">dekai@cs.ust.hkpascale@ee.ust.hk</email>
<abstract confidence="0.995493277777778">We present results on a novel hybrid semantic SMT model that incorporates the strengths of both semantic role labeling and phrase-based statistical machine translation. The approach avoids major complexity limitations via a two-pass architecture. The first pass is performed using a conventional phrase-based SMT model. The second pass is performed by a re-ordering strategy guided by shallow semantic parsers that produce both semantic frame and role labels. Evaluation on a Wall Street Journal newswire genre test set showed the hybrid model to yield an improvement of roughly half a point in BLEU score over a strong pure phrase-based SMT baseline – to our knowledge, the first successful application of semantic role labeling to SMT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Word sense disambiguation vs. statistical machine translation.</title>
<date>2005</date>
<booktitle>43rd Annual Meeting of the Association for Computational Linguistics (ACL-2005).</booktitle>
<location>Ann Arbor, MI:</location>
<contexts>
<context position="4333" citStr="Carpuat and Wu 2005" startWordPosition="675" endWordPosition="678">uracy. On the one hand, there is reason to be optimistic. Over the past decade, we have seen an accumulation of evidence that SMT accuracy can be improved via tree-structured and syntactic models (e.g., Wu 1997; Wu and Chiang 2009), and more recently, work from lexical semantics has also at long last been successfully applied to increasing SMT accuracy, in the form of techniques adapted from word sense disambiguation models (Chan et al. 2007; Gimenez and Mˆrquez 2007b; Carpuat and Wu 2007). On the other hand, both directions saw unexpected disappointments along the way (e.g., Och et al. 2003; Carpuat and Wu 2005). We are therefore forewarned that it is likely to be at least as difficult to successfully adapt the even more complex types of lexical semantics modeling from semantic parsing and role labeling to the translation task. In this paper, we present a novel hybrid model that, for the first time to our knowledge, successfully applies semantic parsing technology to the challenge of improving the quality of ChineseEnglish statistical machine translation. The model makes use of a typical representative SMT system based on Moses, plus shallow semantic parsers for both English and Chinese. 2 Hybrid two</context>
</contexts>
<marker>Carpuat, Wu, 2005</marker>
<rawString>Marine Carpuat and Dekai Wu. 2005. Word sense disambiguation vs. statistical machine translation. 43rd Annual Meeting of the Association for Computational Linguistics (ACL-2005). Ann Arbor, MI: Jun 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007).</booktitle>
<pages>61--72</pages>
<location>Prague:</location>
<contexts>
<context position="4207" citStr="Carpuat and Wu 2007" startWordPosition="653" endWordPosition="656">pers, pages 13–16, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics tribute to improving SMT accuracy. On the one hand, there is reason to be optimistic. Over the past decade, we have seen an accumulation of evidence that SMT accuracy can be improved via tree-structured and syntactic models (e.g., Wu 1997; Wu and Chiang 2009), and more recently, work from lexical semantics has also at long last been successfully applied to increasing SMT accuracy, in the form of techniques adapted from word sense disambiguation models (Chan et al. 2007; Gimenez and Mˆrquez 2007b; Carpuat and Wu 2007). On the other hand, both directions saw unexpected disappointments along the way (e.g., Och et al. 2003; Carpuat and Wu 2005). We are therefore forewarned that it is likely to be at least as difficult to successfully adapt the even more complex types of lexical semantics modeling from semantic parsing and role labeling to the translation task. In this paper, we present a novel hybrid model that, for the first time to our knowledge, successfully applies semantic parsing technology to the challenge of improving the quality of ChineseEnglish statistical machine translation. The model makes use o</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving statistical machine translation using word sense disambiguation. 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007). Prague: Jun 2007. 61-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Seng Chan</author>
</authors>
<title>Hwee Tou Ng and David Chiang</title>
<date>2007</date>
<booktitle>45th Annual Meeting of the Association for Computational Linguistics (ACL-07),</booktitle>
<location>Prague:</location>
<marker>Chan, 2007</marker>
<rawString>Yee Seng Chan, Hwee Tou Ng and David Chiang 2007. Word sense disambiguation improves statistical machine translation. 45th Annual Meeting of the Association for Computational Linguistics (ACL-07), Prague: Jun 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Grace Ngai</author>
<author>Yongsheng Yang</author>
<author>Benfeng Chen</author>
</authors>
<title>A maximum-entropy Chinese parser augmented by transformation-based learning.</title>
<date>2004</date>
<journal>ACM Transactions on Asian Language Information Processing (TALIP)</journal>
<volume>3</volume>
<issue>2</issue>
<pages>159--168</pages>
<contexts>
<context position="11252" citStr="Fung et al. 2004" startWordPosition="1740" endWordPosition="1743">ment A Chinese-English experiment was conducted on the two-pass hybrid model. A phrase-based SMT baseline model was built by augmenting the open source statistical machine translation decoder Moses (Koehn et al. 2007) with additional preprocessors. English and Chinese shallow semantic parsers followed those discussed in Section 1. The model was trained on LDC newswire parallel text consisting of 3.42 million sentence pairs, containing 64.1 million English words and 56.9 million Chinese words. The English was tokenized and case-normalized; the Chinese was tokenized via a maximum-entropy model (Fung et al. 2004). Phrase translations were extracted via the growdiag-final heuristic. The language model is a 6-gram model trained with Kneser-Ney smoothing using the SRI language modeling toolkit (Stolcke 2002). The test set of Wall Street Journal newswire sentences was randomly extracted from the Chinese-English Bilingual Propbank. Although we did not make use of the Propbank annotations, this would potentially allow other types of analyses in the future. The phrase-based SMT model used for the first pass achieves a BLEU score of 42.99, establishing a fairly strong baseline to begin with. In comparison, th</context>
</contexts>
<marker>Fung, Ngai, Yang, Chen, 2004</marker>
<rawString>Pascale Fung, Grace Ngai, Yongsheng Yang and Benfeng Chen. 2004. A maximum-entropy Chinese parser augmented by transformation-based learning. ACM Transactions on Asian Language Information Processing (TALIP) 3(2): 159-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Zhaojun Wu</author>
<author>Yongsheng Yang</author>
<author>Dekai Wu</author>
</authors>
<title>Automatic learning of Chinese/English semantic structure mapping.</title>
<date>2006</date>
<booktitle>IEEE/ACL 2006 Workshop on Spoken Language Technology (SLT</booktitle>
<pages>230--233</pages>
<location>Aruba:</location>
<contexts>
<context position="2365" citStr="Fung et al. 2006" startWordPosition="364" endWordPosition="367">ndicator of adequacy. As a result, SMT work has been driven to optimize 13 systems such that they often produce translations that contain significant role confusion errors despite reading fluently. The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more – possibly at the expense of slight degradations in lexical fluency. Shallow semantic parsing models have attained increasing levels of accuracy in recent years (Gildea and Jurafsky 2000; Sun and Jurafsky 2004; Pradhan et al. 2004, 2005; Pradhan 2005; Fung et al. 2006, 2007; Gim6nez and Mˆrquez 2007a, 2008). Such models, which identify semantic frames within input sentences by marking its predicates, and labeling their arguments with the semantic roles that they fill. Evidence has begun to accumulate that semantic frames – predicates and semantic roles – tend to preserve consistency across translations better than syntactic roles do. This is, of course, by design; it follows from the definition of semantic roles, which are less language-dependent than syntactic roles. Across Chinese and English, for example, it has been reported that approximately 84% of s</context>
</contexts>
<marker>Fung, Wu, Yang, Wu, 2006</marker>
<rawString>Pascale Fung, Zhaojun Wu, Yongsheng Yang and Dekai Wu. 2006. Automatic learning of Chinese/English semantic structure mapping. IEEE/ACL 2006 Workshop on Spoken Language Technology (SLT 2006). Aruba: Dec 2006. 230-233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Zhaojun Wu</author>
<author>Yongsheng Yang</author>
<author>Dekai Wu</author>
</authors>
<title>Learning Bilingual Semantic Frames: Shallow Semantic Parsing vs.</title>
<date>2007</date>
<booktitle>Semantic Role Projection. 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI 2007). Skšvde,</booktitle>
<pages>75--84</pages>
<location>Sweden:</location>
<marker>Fung, Wu, Yang, Wu, 2007</marker>
<rawString>Pascale Fung, Zhaojun Wu, Yongsheng Yang and Dekai Wu. 2007. Learning Bilingual Semantic Frames: Shallow Semantic Parsing vs. Semantic Role Projection. 11th Conference on Theoretical and Methodological Issues in Machine Translation (TMI 2007). Skšvde, Sweden: Sep 2007. 75-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Germann</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Kenji Yamada</author>
</authors>
<title>Fast Decoding and Optimal Decoding for Machine Translation.</title>
<date>2001</date>
<booktitle>39th Annual Meeting of the Association for Computational Linguistics (ACL2001).</booktitle>
<location>Toulouse:</location>
<contexts>
<context position="13374" citStr="Germann et al. 2001" startWordPosition="2082" endWordPosition="2085">ng can improve translation accuracy of SMT models. We note that accuracy here was measured via BLEU, and it has been widely observed that the negative impacts of semantic predicate-argument errors on the utility of the translation are underestimated by evaluation metrics based on lexical criteria such as BLEU. We conjecture that more expensive manual evaluation techniques which directly measure translation utility could even more strongly reveal improvement in role confusion errors. The hybrid two-pass approach can be compared with the greedy re-ordering based strategy of the ReWrite decoder (Germann et al. 2001), although our search is breadth-first rather than purely greedy. Whereas ReWrite was based on wordlevel re-ordering, however, our approach is based on constituent phrase re-ordering, and the phrases to be re-ordered are more selectively chosen via the semantic parse labels. Moreover, the objective function being maximized by ReWrite is still the SMT model score; whereas in our case the new objective function is cross-lingual semantic predicate-argument match (plus an implicit search bias toward fewer re-orderings). The hybrid two-pass approach can also be compared with serial combination arch</context>
</contexts>
<marker>Germann, Jahr, Knight, Marcu, Yamada, 2001</marker>
<rawString>Ulrich Germann, Michael Jahr, Kevin Knight, Daniel Marcu and Kenji Yamada. Fast Decoding and Optimal Decoding for Machine Translation. 2001. 39th Annual Meeting of the Association for Computational Linguistics (ACL2001). Toulouse: July 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic Labeling of Semantic Roles.</title>
<date>2000</date>
<booktitle>38th Annual Conference of the Association for Computational Linguistics (ACL-2000). 512–520,</booktitle>
<location>Hong Kong:</location>
<contexts>
<context position="2283" citStr="Gildea and Jurafsky 2000" startWordPosition="349" endWordPosition="352">uacy. The length penalty in the BLEU metric, in particular, is only an indirect and weak indicator of adequacy. As a result, SMT work has been driven to optimize 13 systems such that they often produce translations that contain significant role confusion errors despite reading fluently. The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more – possibly at the expense of slight degradations in lexical fluency. Shallow semantic parsing models have attained increasing levels of accuracy in recent years (Gildea and Jurafsky 2000; Sun and Jurafsky 2004; Pradhan et al. 2004, 2005; Pradhan 2005; Fung et al. 2006, 2007; Gim6nez and Mˆrquez 2007a, 2008). Such models, which identify semantic frames within input sentences by marking its predicates, and labeling their arguments with the semantic roles that they fill. Evidence has begun to accumulate that semantic frames – predicates and semantic roles – tend to preserve consistency across translations better than syntactic roles do. This is, of course, by design; it follows from the definition of semantic roles, which are less language-dependent than syntactic roles. Across </context>
</contexts>
<marker>Gildea, Jurafsky, 2000</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2000. Automatic Labeling of Semantic Roles. 38th Annual Conference of the Association for Computational Linguistics (ACL-2000). 512–520, Hong Kong: Oct 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesœs Gim6nez</author>
<author>Llu’s Mˆrquez</author>
</authors>
<title>Linguistic Features for Automatic Evaluation of Heterogeneous MT Systems. WMT</title>
<date>2007</date>
<marker>Gim6nez, Mˆrquez, 2007</marker>
<rawString>Jesœs Gim6nez and Llu’s Mˆrquez. 2007. Linguistic Features for Automatic Evaluation of Heterogeneous MT Systems. WMT 2007 (ACL&apos;07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesœs Gim6nez</author>
<author>Llu’s Mˆrquez</author>
</authors>
<title>Discriminative Phrase Selection for Statistical Machine Translation. Learning Machine Translation. NIPS Workshop Series.</title>
<date>2007</date>
<publisher>MIT Press.</publisher>
<marker>Gim6nez, Mˆrquez, 2007</marker>
<rawString>Jesœs Gim6nez and Llu’s Mˆrquez. 2007. Discriminative Phrase Selection for Statistical Machine Translation. Learning Machine Translation. NIPS Workshop Series. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesœs Gim6nez</author>
<author>Llu’s Mˆrquez</author>
</authors>
<title>A Smorgasbord of Features for Automatic</title>
<date>2008</date>
<booktitle>MT Evaluation. 3rd ACL Workshop on Statistical Machine Translation (shared evaluation task). Pages 195-198,</booktitle>
<location>Columbus, Ohio:</location>
<marker>Gim6nez, Mˆrquez, 2008</marker>
<rawString>Jesœs Gim6nez and Llu’s Mˆrquez. 2008. A Smorgasbord of Features for Automatic MT Evaluation. 3rd ACL Workshop on Statistical Machine Translation (shared evaluation task). Pages 195-198, Columbus, Ohio: Jun 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Verb subcategorization kernels for automatic semantic labeling.</title>
<date>2005</date>
<booktitle>ACL-SIGLEX Workshop on Deep Lexical Acquisition.</booktitle>
<pages>10--17</pages>
<location>Ann Arbor:</location>
<marker>Moschitti, Basili, 2005</marker>
<rawString>Alessandro Moschitti and Roberto Basili. 2005. Verb subcategorization kernels for automatic semantic labeling. ACL-SIGLEX Workshop on Deep Lexical Acquisition. Ann Arbor: Jun 2005. 10-17.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Franz Josef Och</author>
<author>Daniel Gildea</author>
</authors>
<title>Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar,</title>
<date>2004</date>
<booktitle>Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2004).</booktitle>
<location>Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin</location>
<marker>Och, Gildea, 2004</marker>
<rawString>Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, Anoop Sarkar, Kenji Yamada, Alex Fraser, Shankar Kumar, Libin Shen, David Smith, Katherine Eng, Viren Jain, Zhen Jin and Dragomir Radev. 2004. A smorgasbord of features for statistical machine translation. Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2004). Boston: May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-Jing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>40th Annual Meeting of the Association for Computational Linguistics (ACL-2002).</booktitle>
<contexts>
<context position="1621" citStr="Papineni et al. 2002" startWordPosition="243" endWordPosition="246">uccessful application of semantic role labeling to SMT. 1 Introduction Many of the most glaring errors made by today’s statistical machine translation systems are those resulting from confusion of semantic roles. Translation errors of this type frequently result in critical misunderstandings of the essential meaning of the original input language sentences – who did what to whom, for whom or what, how, where, when, and why. Semantic role confusions are errors of adequacy rather than fluency. It has often been noted that the dominance of lexically-oriented, precisionbased metrics such as BLEU (Papineni et al. 2002) tend to reward fluency more than adequacy. The length penalty in the BLEU metric, in particular, is only an indirect and weak indicator of adequacy. As a result, SMT work has been driven to optimize 13 systems such that they often produce translations that contain significant role confusion errors despite reading fluently. The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more – possibly at the expense of slight degradations in lexical fluency. Shallow semantic parsing models have attained increasin</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward and Wei-Jing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. 40th Annual Meeting of the Association for Computational Linguistics (ACL-2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
</authors>
<title>ASSERT: Automatic Statistical SEmantic Role Tagger.</title>
<date>2005</date>
<note>http://oak.colorado.edu/assert/.</note>
<contexts>
<context position="2347" citStr="Pradhan 2005" startWordPosition="362" endWordPosition="363">ect and weak indicator of adequacy. As a result, SMT work has been driven to optimize 13 systems such that they often produce translations that contain significant role confusion errors despite reading fluently. The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more – possibly at the expense of slight degradations in lexical fluency. Shallow semantic parsing models have attained increasing levels of accuracy in recent years (Gildea and Jurafsky 2000; Sun and Jurafsky 2004; Pradhan et al. 2004, 2005; Pradhan 2005; Fung et al. 2006, 2007; Gim6nez and Mˆrquez 2007a, 2008). Such models, which identify semantic frames within input sentences by marking its predicates, and labeling their arguments with the semantic roles that they fill. Evidence has begun to accumulate that semantic frames – predicates and semantic roles – tend to preserve consistency across translations better than syntactic roles do. This is, of course, by design; it follows from the definition of semantic roles, which are less language-dependent than syntactic roles. Across Chinese and English, for example, it has been reported that appr</context>
</contexts>
<marker>Pradhan, 2005</marker>
<rawString>Sameer Pradhan. 2005. ASSERT: Automatic Statistical SEmantic Role Tagger. http://oak.colorado.edu/assert/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Kadri Hacioglu</author>
<author>Valerie Krugler</author>
<author>Wayne Ward</author>
<author>James H Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Support Vector Learning for Semantic Argument Classification.</title>
<date>2005</date>
<journal>Machine Learning</journal>
<volume>60</volume>
<issue>1</issue>
<pages>11--39</pages>
<marker>Pradhan, Hacioglu, Krugler, Ward, Martin, Jurafsky, 2005</marker>
<rawString>Sameer Pradhan, Kadri Hacioglu, Valerie Krugler, Wayne Ward, James H. Martin and Daniel Jurafsky. 2005. Support Vector Learning for Semantic Argument Classification. Machine Learning 60(1-3): 11-39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Wayne Ward</author>
<author>Kadri Hacioglu</author>
<author>James Martin</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Shallow Semantic Parsing using Support Vector Machines.</title>
<date>2004</date>
<booktitle>Human Language Technology/North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2004).</booktitle>
<location>Boston:</location>
<contexts>
<context position="2327" citStr="Pradhan et al. 2004" startWordPosition="357" endWordPosition="360">articular, is only an indirect and weak indicator of adequacy. As a result, SMT work has been driven to optimize 13 systems such that they often produce translations that contain significant role confusion errors despite reading fluently. The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more – possibly at the expense of slight degradations in lexical fluency. Shallow semantic parsing models have attained increasing levels of accuracy in recent years (Gildea and Jurafsky 2000; Sun and Jurafsky 2004; Pradhan et al. 2004, 2005; Pradhan 2005; Fung et al. 2006, 2007; Gim6nez and Mˆrquez 2007a, 2008). Such models, which identify semantic frames within input sentences by marking its predicates, and labeling their arguments with the semantic roles that they fill. Evidence has begun to accumulate that semantic frames – predicates and semantic roles – tend to preserve consistency across translations better than syntactic roles do. This is, of course, by design; it follows from the definition of semantic roles, which are less language-dependent than syntactic roles. Across Chinese and English, for example, it has bee</context>
</contexts>
<marker>Pradhan, Ward, Hacioglu, Martin, Jurafsky, 2004</marker>
<rawString>Sameer Pradhan, Wayne Ward, Kadri Hacioglu, James Martin and Daniel Jurafsky. 2004. Shallow Semantic Parsing using Support Vector Machines. Human Language Technology/North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2004). Boston: May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – An Extensible Language Modeling</title>
<date>2002</date>
<booktitle>Toolkit. International Conference on Spoken Language Processing (ICSLP-2002).</booktitle>
<location>Denver, Colorado:</location>
<contexts>
<context position="11448" citStr="Stolcke 2002" startWordPosition="1771" endWordPosition="1772">oehn et al. 2007) with additional preprocessors. English and Chinese shallow semantic parsers followed those discussed in Section 1. The model was trained on LDC newswire parallel text consisting of 3.42 million sentence pairs, containing 64.1 million English words and 56.9 million Chinese words. The English was tokenized and case-normalized; the Chinese was tokenized via a maximum-entropy model (Fung et al. 2004). Phrase translations were extracted via the growdiag-final heuristic. The language model is a 6-gram model trained with Kneser-Ney smoothing using the SRI language modeling toolkit (Stolcke 2002). The test set of Wall Street Journal newswire sentences was randomly extracted from the Chinese-English Bilingual Propbank. Although we did not make use of the Propbank annotations, this would potentially allow other types of analyses in the future. The phrase-based SMT model used for the first pass achieves a BLEU score of 42.99, establishing a fairly strong baseline to begin with. In comparison, the automatically errorcorrected translations that are output by the second pass achieve a BLEU score of 43.51. This represents approximately half a point improvement over the strong baseline. An ex</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – An Extensible Language Modeling Toolkit. International Conference on Spoken Language Processing (ICSLP-2002). Denver, Colorado: Sep 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglin Sun</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Shallow Semantic Parsing of Chinese.</title>
<date>2004</date>
<booktitle>Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2004).</booktitle>
<pages>249--256</pages>
<location>Boston:</location>
<contexts>
<context position="2306" citStr="Sun and Jurafsky 2004" startWordPosition="353" endWordPosition="356">n the BLEU metric, in particular, is only an indirect and weak indicator of adequacy. As a result, SMT work has been driven to optimize 13 systems such that they often produce translations that contain significant role confusion errors despite reading fluently. The present work is inspired by the question of whether we can improve translation utility via a strategy of favoring semantic adequacy slightly more – possibly at the expense of slight degradations in lexical fluency. Shallow semantic parsing models have attained increasing levels of accuracy in recent years (Gildea and Jurafsky 2000; Sun and Jurafsky 2004; Pradhan et al. 2004, 2005; Pradhan 2005; Fung et al. 2006, 2007; Gim6nez and Mˆrquez 2007a, 2008). Such models, which identify semantic frames within input sentences by marking its predicates, and labeling their arguments with the semantic roles that they fill. Evidence has begun to accumulate that semantic frames – predicates and semantic roles – tend to preserve consistency across translations better than syntactic roles do. This is, of course, by design; it follows from the definition of semantic roles, which are less language-dependent than syntactic roles. Across Chinese and English, fo</context>
</contexts>
<marker>Sun, Jurafsky, 2004</marker>
<rawString>Honglin Sun and Daniel Jurafsky. 2004. Shallow Semantic Parsing of Chinese. Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL-2004). 249-256. Boston: May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Jens Stephan</author>
<author>Evgeny Matusov</author>
<author>Lo•c Dugast</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
<author>Jean Senellart</author>
<author>Jin Yang</author>
</authors>
<date>2008</date>
<booktitle>Tighter Integration of Rule-based and Statistical MT in Serial System Combination. 22nd International Conference on Computational Linguistics (COLING 2008).</booktitle>
<location>Manchester:</location>
<contexts>
<context position="14025" citStr="Ueffing et al. 2008" startWordPosition="2181" endWordPosition="2184">h-first rather than purely greedy. Whereas ReWrite was based on wordlevel re-ordering, however, our approach is based on constituent phrase re-ordering, and the phrases to be re-ordered are more selectively chosen via the semantic parse labels. Moreover, the objective function being maximized by ReWrite is still the SMT model score; whereas in our case the new objective function is cross-lingual semantic predicate-argument match (plus an implicit search bias toward fewer re-orderings). The hybrid two-pass approach can also be compared with serial combination architectures for hybrid MT (e.g., Ueffing et al. 2008). But whereas Ueffing et al. take the output from a first-pass rulebased MT system, and then correct it using a second-pass SMT system, our two-pass semantic SMT model does the reverse: it takes the output from a first-pass SMT system, and then corrects it with the aid of semantic analyzers. Acknowledgments. Thanks to Chi-kiu Lo and Zhaojun Wu. This material is based upon work supported in part by the Defense Advanced Research Projects Agency (DARPA) under GALE Contract No. HR0011-06-C-0023, and by the Hong Kong Research Grants Council (RGC) research grants GRF621008, GRF612806, DAG03/04.EG09,</context>
</contexts>
<marker>Ueffing, Stephan, Matusov, Dugast, Foster, Kuhn, Senellart, Yang, 2008</marker>
<rawString>Nicola Ueffing, Jens Stephan, Evgeny Matusov, Lo•c Dugast, George Foster, Roland Kuhn, Jean Senellart and Jin Yang. 2008. Tighter Integration of Rule-based and Statistical MT in Serial System Combination. 22nd International Conference on Computational Linguistics (COLING 2008). Manchester: Aug 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic Inversion Transduction Grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics</journal>
<volume>23</volume>
<issue>3</issue>
<pages>377--404</pages>
<contexts>
<context position="3923" citStr="Wu 1997" startWordPosition="608" endWordPosition="609">mantic parsers to identify inconsistent semantic frame and role mappings between the input source sentences and their output translations. However, we take note of the difficult experience in making syntactic and semantic models conProceedings of NAACL HLT 2009: Short Papers, pages 13–16, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics tribute to improving SMT accuracy. On the one hand, there is reason to be optimistic. Over the past decade, we have seen an accumulation of evidence that SMT accuracy can be improved via tree-structured and syntactic models (e.g., Wu 1997; Wu and Chiang 2009), and more recently, work from lexical semantics has also at long last been successfully applied to increasing SMT accuracy, in the form of techniques adapted from word sense disambiguation models (Chan et al. 2007; Gimenez and Mˆrquez 2007b; Carpuat and Wu 2007). On the other hand, both directions saw unexpected disappointments along the way (e.g., Och et al. 2003; Carpuat and Wu 2005). We are therefore forewarned that it is likely to be at least as difficult to successfully adapt the even more complex types of lexical semantics modeling from semantic parsing and role lab</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic Inversion Transduction Grammars and bilingual parsing of parallel corpora. Computational Linguistics 23(3): 377-404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>David Chiang</author>
</authors>
<date>2009</date>
<booktitle>Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation (NAACL-HLT 2009).</booktitle>
<location>Boulder, CO:</location>
<contexts>
<context position="3944" citStr="Wu and Chiang 2009" startWordPosition="610" endWordPosition="613">rsers to identify inconsistent semantic frame and role mappings between the input source sentences and their output translations. However, we take note of the difficult experience in making syntactic and semantic models conProceedings of NAACL HLT 2009: Short Papers, pages 13–16, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics tribute to improving SMT accuracy. On the one hand, there is reason to be optimistic. Over the past decade, we have seen an accumulation of evidence that SMT accuracy can be improved via tree-structured and syntactic models (e.g., Wu 1997; Wu and Chiang 2009), and more recently, work from lexical semantics has also at long last been successfully applied to increasing SMT accuracy, in the form of techniques adapted from word sense disambiguation models (Chan et al. 2007; Gimenez and Mˆrquez 2007b; Carpuat and Wu 2007). On the other hand, both directions saw unexpected disappointments along the way (e.g., Och et al. 2003; Carpuat and Wu 2005). We are therefore forewarned that it is likely to be at least as difficult to successfully adapt the even more complex types of lexical semantics modeling from semantic parsing and role labeling to the translat</context>
</contexts>
<marker>Wu, Chiang, 2009</marker>
<rawString>Dekai Wu and David Chiang (eds). 2009. Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation (NAACL-HLT 2009). Boulder, CO: Jun 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Automatic Semantic Role Labeling for Chinese Verbs.</title>
<date>2005</date>
<booktitle>19th International Joint Conference on Artificial Intelligence.</booktitle>
<location>Edinburgh, Scotland.</location>
<marker>Xue, Palmer, 2005</marker>
<rawString>Nianwen Xue and Martha Palmer. 2005. Automatic Semantic Role Labeling for Chinese Verbs. 19th International Joint Conference on Artificial Intelligence. Edinburgh, Scotland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>