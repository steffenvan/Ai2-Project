<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.098618">
<title confidence="0.9813">
TESLA: A Tool for Annotating Geospatial Language Corpora
</title>
<author confidence="0.935244">
Nate Blaylock and Bradley Swain and James Allen
</author>
<affiliation confidence="0.898388">
Institute for Human and Machine Cognition (IHMC)
</affiliation>
<address confidence="0.642033">
Pensacola, Florida, USA
</address>
<email confidence="0.998927">
{blaylock,bswain,jallen}@ihmc.us
</email>
<sectionHeader confidence="0.9939" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999663636363636">
In this paper, we present The gEoSpatial
Language Annotator (TESLA)—a tool which
supports human annotation of geospatial lan-
guage corpora. TESLA interfaces with a GIS
database for annotating grounded geospatial
entities and uses Google Earth for visualiza-
tion of both entity search results and evolving
object and speaker position from GPS tracks.
We also discuss a current annotation effort us-
ing TESLA to annotate location descriptions
in a geospatial language corpus.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999899636363637">
We are interested in geospatial language under-
standing— the understanding of natural language
(NL) descriptions of spatial locations, orientation,
movement and paths that are grounded in the real
world. Such algorithms would enable a number of
applications, including automated geotagging of text
and speech, robots that can follow human route in-
structions, and NL-description based localization.
To aide development of training and testing cor-
pora for this area, we have built The gEoSpa-
tial Language Annotator (TESLA)—a tool which
supports the visualization and hand-annotation of
both text and speech-based geospatial language cor-
pora. TESLA can be used to create a gold-standard
for training and testing geospatial language under-
standing algorithms by allowing the user to anno-
tate geospatial references with object (e.g., streets,
businesses, and parks) and latitude and longitude
(lat/lon) coordinates. An integrated search capa-
bility to a GIS database with results presented in
Google Earth allow the human annotator to eas-
ily annotate geospatial references with ground truth.
</bodyText>
<page confidence="0.997869">
45
</page>
<figureCaption confidence="0.999827">
Figure 1: A session in the PURSUIT Corpus
</figureCaption>
<bodyText confidence="0.999943923076923">
Furthermore, TESLA supports the playback of GPS
tracks of multiple objects for corpora associated
with synchronized speaker or object movement, al-
lowing the annotator to take this positional context
into account. TESLA is currently being used to an-
notate a corpus of first-person, spoken path descrip-
tions of car routes.
In this paper, we first briefly describe the corpus
that we are annotating, which provides a grounded
example of using TESLA. We then discuss the
TESLA annotation tool and its use in annotating that
corpus. Finally, we describe related work and our
plans for future work.
</bodyText>
<sectionHeader confidence="0.978006" genericHeader="method">
2 The PURSUIT Corpus
</sectionHeader>
<bodyText confidence="0.999843909090909">
The PURSUIT Corpus (Blaylock and Allen, 2008)
is a collection of speech data in which subjects de-
scribe their path in real time (i.e., while they are trav-
eling it) and a GPS receiver simultaneously records
the actual paths taken. (These GPS tracks of the
actual path can aide the annotator in determining
what geospatial entities and events were meant by
the speaker’s description.)
Figure 1 shows an example of the experimental
setup for the corpus collection. Each session con-
sisted of a lead car and a follow car. The driver of the
</bodyText>
<subsubsectionHeader confidence="0.739114">
Proceedings of NAACL HLT 2009: Short Papers, pages 45–48,
</subsubsectionHeader>
<note confidence="0.611991">
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999767">
Figure 2: The TESLA annotation and visualization windows
</figureCaption>
<bodyText confidence="0.9999816">
lead car was instructed to drive wherever he wanted
for an approximate amount of time (around 15 min-
utes). The driver of the follow car was instructed to
follow the lead car. One person in the lead car (usu-
ally a passenger) and one person in the follow car
(usually the driver) were given close-speaking head-
set microphones and instructed to describe, during
the ride, where the lead car was going, as if they
were speaking to someone in a remote location who
was trying to follow the car on a map. The speak-
ers were also instructed to try to be verbose, and
that they did not need to restrict themselves to street
names—they could use businesses, landmarks, or
whatever was natural. Both speakers’ speech was
recorded during the session. In addition, a GPS re-
ceiver was placed in each car and the GPS track was
recorded at a high sampling rate. The corpus con-
sists of 13 audio recordings1 of seven paths along
with the corresponding GPS tracks. The average
session length was 19 minutes.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="method">
3 TESLA
</sectionHeader>
<bodyText confidence="0.999918888888889">
TESLA is an extensible tool for geospatial language
annotation and visualization. It is built on the NXT
Toolkit (Carletta et al., 2003) and data model (Car-
letta et al., 2005) and uses Google Earth for visu-
alization. It supports geospatial entity search using
the TerraFly GIS database (Rishe et al., 2005). Cur-
rently, TESLA supports annotation of geospatial lo-
cation referring expressions, but is designed to be
easily extended to other annotation tasks for geospa-
</bodyText>
<footnote confidence="0.584204">
1In one session, there was no speaker in the lead car.
</footnote>
<bodyText confidence="0.998546464285714">
tial language corpora. (Our plans for extensions are
described in Section 6.)
Figure 2 shows a screenshot of the main view
in the TESLA annotator, showing a session of the
PURSUIT Corpus. In the top-left corner is a wid-
get with playback controls for the session. This pro-
vides synchronized playback of the speech and GPS
tracks. When the session is playing, audio from a
single speaker (lead or follow) is played back, and
the blue car icon in the Google Earth window on the
right moves in synchronized fashion. Although this
Google Earth playback is somewhat analogous to a
video of the movement, Google Earth remains us-
able and the user can move the display or zoom in
and out as desired. If location annotations have pre-
viously been made, these pop up at the given lat/lon
as they are mentioned in the audio, allowing the an-
notator to verify that the location has been correctly
annotated. In the center, on the left-hand side is a
display of the audio transcription, which also moves
in sync with the audio and Google Earth visualiza-
tion. The user creates an annotation by highlighting
a group of words, and choosing the appropriate type
of annotation. The currently selected annotation ap-
pears to the right where the corresponding geospatial
entity information (e.g., name, address, lat/lon) can
be entered by hand, or by searching for the entity in
a GIS database.
</bodyText>
<subsectionHeader confidence="0.996365">
3.1 GIS Search and Visualization
</subsectionHeader>
<bodyText confidence="0.999883">
In addition to allowing information on annotated
geospatial entities to be entered by hand, TESLA
also supports search with a GIS database. Cur-
</bodyText>
<page confidence="0.99905">
46
</page>
<figureCaption confidence="0.998625">
Figure 3: Search results display in TESLA
</figureCaption>
<bodyText confidence="0.999912636363636">
rently, TESLA supports search queries to the Ter-
raFly database (Rishe et al., 2005), although other
databases could be easily added. TerraFly contains
a large aggregation of GIS data from major distrib-
utors including NavTeq and Tiger streets and roads,
12 million U.S. Businesses through Yellow Pages,
and other various freely available geospatial data.
It supports keyword searches on database fields as
well as radius-bounded searches from a given point.
TESLA, by default, uses the position of the GPS
track of the car at the time of the utterance as the
center for search queries, although any point can be
chosen.
Search results are shown to the user in Google
Earth as illustrated in Figure 3. This figure shows
the result of searching for intersections with the key-
word “Romana”. The annotator can then select one
of the search results, which will automatically pop-
ulate the geospatial entity information for that an-
notation. Such visualization is important in geospa-
tial language annotation, as it allows the annotator
to verify that the correct entity is chosen.
</bodyText>
<sectionHeader confidence="0.7594" genericHeader="method">
4 Annotation of the PURSUIT Corpus
</sectionHeader>
<bodyText confidence="0.9999818">
To illustrate the use of TESLA, we briefly describe
our current annotation efforts on the PURSUIT Cor-
pus. We are currently involved in annotating refer-
ring expressions to locations in the corpus, although
later work will involve annotating movement and
orientation descriptions as well.
Location references can occur in a number of syn-
tactic forms, including proper nouns (Waffle House),
definite (the street) and indefinite (a park) refer-
ences, and often, complex noun phrases (one of the
historic churches of Pensacola). Regardless of its
syntactic form, we annotate all references to loca-
tions in the corpus that correspond to types found
in our GIS database. References to such things as
fields, parking lots, and fire hydrants are not anno-
tated, as our database does not contain these types
of entities. (Although, with access to certain local
government resources or advanced computer vision
systems, these references could be resolved as well.)
In PURSUIT, we markup the entire noun phrase (as
opposed to e.g., the head word) and annotate that
grouping.
Rather than annotate a location reference with just
latitude and longitude coordinates, we annotate it
with the geospatial entity being referred to, such
as a street or a business. The reasons for this are
twofold: first, lat/lon coordinates are real numbers,
and it would be difficult to guarantee that each ref-
erence to the same entity was marked with the same
coordinates (e.g., to identify coreference). Secondly,
targeting the entity allows us to include more infor-
mation about that entity (as detailed below).
In the corpus, we have found four types of en-
tities that are references, which are also in our
database: streets, intersections, addresses (e.g., 127
Main Street), and other points (a catch-all category
containing other point-like entities such as busi-
nesses, parks, bridges, etc.)
An annotation example is shown in Figure 4,
in which the utterance contains references to two
</bodyText>
<page confidence="0.999363">
47
</page>
<figureCaption confidence="0.9868555">
Figure 4: Sample annotations of referring expressions to
geospatial locations
</figureCaption>
<bodyText confidence="0.999940666666667">
streets and an intersection. Here the intersection re-
ferring expression spans two referring expressions to
streets, and each is annotated with a canonical name
as well as lat/lon coordinates. Note also that our
annotation schema allows us to annotate embedded
references (here the streets within the intersection).
</bodyText>
<sectionHeader confidence="0.999888" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99993605882353">
The SpatialML module for the Callisto annotator
(Mani et al., 2008) was designed for human anno-
tation of geospatial locations with ground truth by
looking up targets in a gazetteer. It does not, how-
ever, have a geographic visualization components
such as Google Earth and does not support GPS
track playback.
The TAME annotator (Leidner, 2004) is a simi-
lar tool, supporting hand annotation of toponym ref-
erences by gazetteer lookup. It too does not, as
far as we are aware, have a visualization compo-
nent nor GPS track information, likely because the
level of geospatial entities being looked at were at
the city/state/country level. The PURSUIT Corpus
mostly contains references to geospatial entities at
a sub-city level, which may introduce more uncer-
tainty as to the intended referent.
</bodyText>
<sectionHeader confidence="0.997012" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999976041666667">
In this paper, we have presented TESLA—a gen-
eral human annotation tool for geospatial language.
TESLA uses a GIS database, GPS tracks, and
Google Earth to allow a user to annotate refer-
ences to geospatial entities. We also discussed how
TESLA is being used to annotate a corpus of spoken
path descriptions.
Though currently we are only annotating PUR-
SUIT with location references, future plans in-
clude extending TESLA to support the annotation
of movement, orientation, and path descriptions. We
also plan to use this corpus as test and training data
for algorithms to automatically annotate such infor-
mation.
Finally, the path descriptions in the PURSUIT
Corpus were all done from a first-person, ground-
level perspective. As TESLA allows us to replay the
actual routes from GPS tracks within Google Earth,
we believe we could use this tool to gather more spo-
ken descriptions of the paths from an aerial perspec-
tive from different subjects. This would give us sev-
eral more versions of descriptions of the same path
and allow the comparison of descriptions from the
two different perspectives.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999885807692308">
Nate Blaylock and James Allen. 2008. Real-time path
descriptions grounded with gps tracks: a preliminary
report. In LREC Workshop on Methodologies and Re-
sources for Processing Spatial Language, pages 25–
27, Marrakech, Morocco, May 31.
Jean Carletta, Stefan Evert, Ulrich Heid, Jonathan Kil-
gour, Judy Robertson, and Holger Voormann. 2003.
The NITE XML toolkit: flexible annotation for multi-
modal language data. Behavior Research Methods, In-
struments, and Computers, 35(3):353–363.
Jean Carletta, Stefan Evert, Ulrich Heid, and Jonathan
Kilgour. 2005. The NITE XML toolkit: data model
and query language. Language Resources and Evalu-
ation Journal, 39(4):313–334.
Jochen L. Leidner. 2004. Towards a reference corpus
for automatic toponym resolution evaluation. In Work-
shop on Geographic Information Retrieval, Sheffield,
UK.
Inderjeet Mani, Janet Hitzeman, Justin Richer, Dave Har-
ris, Rob Quimby, and Ben Wellner. 2008. SpatialML:
Annotation scheme, corpora, and tools. In 6th Interna-
tional Conference on Language Resources and Evalu-
ation (LREC 2008), Marrakech, Morocco, May.
N. Rishe, M. Gutierrez, A. Selivonenko, and S. Graham.
2005. TerraFly: A tool for visualizing and dispensing
geospatial data. Imaging Notes, 20(2):22–23.
</reference>
<page confidence="0.999353">
48
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.987425">
<title confidence="0.999615">TESLA: A Tool for Annotating Geospatial Language Corpora</title>
<author confidence="0.99965">Blaylock Swain</author>
<affiliation confidence="0.999343">Institute for Human and Machine Cognition</affiliation>
<address confidence="0.995182">Pensacola, Florida, USA</address>
<abstract confidence="0.999400583333333">In this paper, we present The gEoSpatial Language Annotator (TESLA)—a tool which supports human annotation of geospatial language corpora. TESLA interfaces with a GIS database for annotating grounded geospatial entities and uses Google Earth for visualization of both entity search results and evolving object and speaker position from GPS tracks. We also discuss a current annotation effort using TESLA to annotate location descriptions in a geospatial language corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nate Blaylock</author>
<author>James Allen</author>
</authors>
<title>Real-time path descriptions grounded with gps tracks: a preliminary report.</title>
<date>2008</date>
<booktitle>In LREC Workshop on Methodologies and Resources for Processing Spatial Language,</booktitle>
<pages>25--27</pages>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="2494" citStr="Blaylock and Allen, 2008" startWordPosition="373" endWordPosition="376">ayback of GPS tracks of multiple objects for corpora associated with synchronized speaker or object movement, allowing the annotator to take this positional context into account. TESLA is currently being used to annotate a corpus of first-person, spoken path descriptions of car routes. In this paper, we first briefly describe the corpus that we are annotating, which provides a grounded example of using TESLA. We then discuss the TESLA annotation tool and its use in annotating that corpus. Finally, we describe related work and our plans for future work. 2 The PURSUIT Corpus The PURSUIT Corpus (Blaylock and Allen, 2008) is a collection of speech data in which subjects describe their path in real time (i.e., while they are traveling it) and a GPS receiver simultaneously records the actual paths taken. (These GPS tracks of the actual path can aide the annotator in determining what geospatial entities and events were meant by the speaker’s description.) Figure 1 shows an example of the experimental setup for the corpus collection. Each session consisted of a lead car and a follow car. The driver of the Proceedings of NAACL HLT 2009: Short Papers, pages 45–48, Boulder, Colorado, June 2009. c�2009 Association for</context>
</contexts>
<marker>Blaylock, Allen, 2008</marker>
<rawString>Nate Blaylock and James Allen. 2008. Real-time path descriptions grounded with gps tracks: a preliminary report. In LREC Workshop on Methodologies and Resources for Processing Spatial Language, pages 25– 27, Marrakech, Morocco, May 31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
<author>Stefan Evert</author>
<author>Ulrich Heid</author>
<author>Jonathan Kilgour</author>
<author>Judy Robertson</author>
<author>Holger Voormann</author>
</authors>
<title>The NITE XML toolkit: flexible annotation for multimodal language data.</title>
<date>2003</date>
<journal>Behavior Research Methods, Instruments, and Computers,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="4311" citStr="Carletta et al., 2003" startWordPosition="686" endWordPosition="689"> were also instructed to try to be verbose, and that they did not need to restrict themselves to street names—they could use businesses, landmarks, or whatever was natural. Both speakers’ speech was recorded during the session. In addition, a GPS receiver was placed in each car and the GPS track was recorded at a high sampling rate. The corpus consists of 13 audio recordings1 of seven paths along with the corresponding GPS tracks. The average session length was 19 minutes. 3 TESLA TESLA is an extensible tool for geospatial language annotation and visualization. It is built on the NXT Toolkit (Carletta et al., 2003) and data model (Carletta et al., 2005) and uses Google Earth for visualization. It supports geospatial entity search using the TerraFly GIS database (Rishe et al., 2005). Currently, TESLA supports annotation of geospatial location referring expressions, but is designed to be easily extended to other annotation tasks for geospa1In one session, there was no speaker in the lead car. tial language corpora. (Our plans for extensions are described in Section 6.) Figure 2 shows a screenshot of the main view in the TESLA annotator, showing a session of the PURSUIT Corpus. In the top-left corner is a </context>
</contexts>
<marker>Carletta, Evert, Heid, Kilgour, Robertson, Voormann, 2003</marker>
<rawString>Jean Carletta, Stefan Evert, Ulrich Heid, Jonathan Kilgour, Judy Robertson, and Holger Voormann. 2003. The NITE XML toolkit: flexible annotation for multimodal language data. Behavior Research Methods, Instruments, and Computers, 35(3):353–363.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Carletta</author>
<author>Stefan Evert</author>
<author>Ulrich Heid</author>
<author>Jonathan Kilgour</author>
</authors>
<title>The NITE XML toolkit: data model and query language.</title>
<date>2005</date>
<journal>Language Resources and Evaluation Journal,</journal>
<volume>39</volume>
<issue>4</issue>
<contexts>
<context position="4350" citStr="Carletta et al., 2005" startWordPosition="693" endWordPosition="697">ose, and that they did not need to restrict themselves to street names—they could use businesses, landmarks, or whatever was natural. Both speakers’ speech was recorded during the session. In addition, a GPS receiver was placed in each car and the GPS track was recorded at a high sampling rate. The corpus consists of 13 audio recordings1 of seven paths along with the corresponding GPS tracks. The average session length was 19 minutes. 3 TESLA TESLA is an extensible tool for geospatial language annotation and visualization. It is built on the NXT Toolkit (Carletta et al., 2003) and data model (Carletta et al., 2005) and uses Google Earth for visualization. It supports geospatial entity search using the TerraFly GIS database (Rishe et al., 2005). Currently, TESLA supports annotation of geospatial location referring expressions, but is designed to be easily extended to other annotation tasks for geospa1In one session, there was no speaker in the lead car. tial language corpora. (Our plans for extensions are described in Section 6.) Figure 2 shows a screenshot of the main view in the TESLA annotator, showing a session of the PURSUIT Corpus. In the top-left corner is a widget with playback controls for the s</context>
</contexts>
<marker>Carletta, Evert, Heid, Kilgour, 2005</marker>
<rawString>Jean Carletta, Stefan Evert, Ulrich Heid, and Jonathan Kilgour. 2005. The NITE XML toolkit: data model and query language. Language Resources and Evaluation Journal, 39(4):313–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen L Leidner</author>
</authors>
<title>Towards a reference corpus for automatic toponym resolution evaluation.</title>
<date>2004</date>
<booktitle>In Workshop on Geographic Information Retrieval,</booktitle>
<location>Sheffield, UK.</location>
<contexts>
<context position="10101" citStr="Leidner, 2004" startWordPosition="1635" endWordPosition="1636">g expression spans two referring expressions to streets, and each is annotated with a canonical name as well as lat/lon coordinates. Note also that our annotation schema allows us to annotate embedded references (here the streets within the intersection). 5 Related Work The SpatialML module for the Callisto annotator (Mani et al., 2008) was designed for human annotation of geospatial locations with ground truth by looking up targets in a gazetteer. It does not, however, have a geographic visualization components such as Google Earth and does not support GPS track playback. The TAME annotator (Leidner, 2004) is a similar tool, supporting hand annotation of toponym references by gazetteer lookup. It too does not, as far as we are aware, have a visualization component nor GPS track information, likely because the level of geospatial entities being looked at were at the city/state/country level. The PURSUIT Corpus mostly contains references to geospatial entities at a sub-city level, which may introduce more uncertainty as to the intended referent. 6 Conclusion and Future Work In this paper, we have presented TESLA—a general human annotation tool for geospatial language. TESLA uses a GIS database, G</context>
</contexts>
<marker>Leidner, 2004</marker>
<rawString>Jochen L. Leidner. 2004. Towards a reference corpus for automatic toponym resolution evaluation. In Workshop on Geographic Information Retrieval, Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Janet Hitzeman</author>
<author>Justin Richer</author>
<author>Dave Harris</author>
<author>Rob Quimby</author>
<author>Ben Wellner</author>
</authors>
<title>SpatialML: Annotation scheme, corpora, and tools.</title>
<date>2008</date>
<booktitle>In 6th International Conference on Language Resources and Evaluation (LREC 2008),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="9825" citStr="Mani et al., 2008" startWordPosition="1588" endWordPosition="1591">ies such as businesses, parks, bridges, etc.) An annotation example is shown in Figure 4, in which the utterance contains references to two 47 Figure 4: Sample annotations of referring expressions to geospatial locations streets and an intersection. Here the intersection referring expression spans two referring expressions to streets, and each is annotated with a canonical name as well as lat/lon coordinates. Note also that our annotation schema allows us to annotate embedded references (here the streets within the intersection). 5 Related Work The SpatialML module for the Callisto annotator (Mani et al., 2008) was designed for human annotation of geospatial locations with ground truth by looking up targets in a gazetteer. It does not, however, have a geographic visualization components such as Google Earth and does not support GPS track playback. The TAME annotator (Leidner, 2004) is a similar tool, supporting hand annotation of toponym references by gazetteer lookup. It too does not, as far as we are aware, have a visualization component nor GPS track information, likely because the level of geospatial entities being looked at were at the city/state/country level. The PURSUIT Corpus mostly contain</context>
</contexts>
<marker>Mani, Hitzeman, Richer, Harris, Quimby, Wellner, 2008</marker>
<rawString>Inderjeet Mani, Janet Hitzeman, Justin Richer, Dave Harris, Rob Quimby, and Ben Wellner. 2008. SpatialML: Annotation scheme, corpora, and tools. In 6th International Conference on Language Resources and Evaluation (LREC 2008), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Rishe</author>
<author>M Gutierrez</author>
<author>A Selivonenko</author>
<author>S Graham</author>
</authors>
<title>TerraFly: A tool for visualizing and dispensing geospatial data. Imaging Notes,</title>
<date>2005</date>
<contexts>
<context position="4481" citStr="Rishe et al., 2005" startWordPosition="715" endWordPosition="718">Both speakers’ speech was recorded during the session. In addition, a GPS receiver was placed in each car and the GPS track was recorded at a high sampling rate. The corpus consists of 13 audio recordings1 of seven paths along with the corresponding GPS tracks. The average session length was 19 minutes. 3 TESLA TESLA is an extensible tool for geospatial language annotation and visualization. It is built on the NXT Toolkit (Carletta et al., 2003) and data model (Carletta et al., 2005) and uses Google Earth for visualization. It supports geospatial entity search using the TerraFly GIS database (Rishe et al., 2005). Currently, TESLA supports annotation of geospatial location referring expressions, but is designed to be easily extended to other annotation tasks for geospa1In one session, there was no speaker in the lead car. tial language corpora. (Our plans for extensions are described in Section 6.) Figure 2 shows a screenshot of the main view in the TESLA annotator, showing a session of the PURSUIT Corpus. In the top-left corner is a widget with playback controls for the session. This provides synchronized playback of the speech and GPS tracks. When the session is playing, audio from a single speaker </context>
<context position="6370" citStr="Rishe et al., 2005" startWordPosition="1037" endWordPosition="1040">tes an annotation by highlighting a group of words, and choosing the appropriate type of annotation. The currently selected annotation appears to the right where the corresponding geospatial entity information (e.g., name, address, lat/lon) can be entered by hand, or by searching for the entity in a GIS database. 3.1 GIS Search and Visualization In addition to allowing information on annotated geospatial entities to be entered by hand, TESLA also supports search with a GIS database. Cur46 Figure 3: Search results display in TESLA rently, TESLA supports search queries to the TerraFly database (Rishe et al., 2005), although other databases could be easily added. TerraFly contains a large aggregation of GIS data from major distributors including NavTeq and Tiger streets and roads, 12 million U.S. Businesses through Yellow Pages, and other various freely available geospatial data. It supports keyword searches on database fields as well as radius-bounded searches from a given point. TESLA, by default, uses the position of the GPS track of the car at the time of the utterance as the center for search queries, although any point can be chosen. Search results are shown to the user in Google Earth as illustra</context>
</contexts>
<marker>Rishe, Gutierrez, Selivonenko, Graham, 2005</marker>
<rawString>N. Rishe, M. Gutierrez, A. Selivonenko, and S. Graham. 2005. TerraFly: A tool for visualizing and dispensing geospatial data. Imaging Notes, 20(2):22–23.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>