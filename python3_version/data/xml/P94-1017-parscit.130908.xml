<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.956407">
AN OPTIMAL TABULAR PARSING ALGORITHM
</title>
<author confidence="0.990361">
Mark-Jan Nederhof *
</author>
<affiliation confidence="0.997892">
University of Nijmegen, Department of Computer Science
</affiliation>
<address confidence="0.781298">
Toernooiveld, 6525 ED Nijmegen, The Netherlands
</address>
<email confidence="0.908222">
markjaacs.kun.n1
</email>
<sectionHeader confidence="0.991656" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999462">
In this paper we relate a number of parsing algorithms
which have been developed in very different areas of
parsing theory, and which include deterministic algo-
rithms, tabular algorithms, and a parallel algorithm.
We show that these algorithms are based on the same
underlying ideas.
By relating existing ideas, we hope to provide an op-
portunity to improve some algorithms based on features
of others. A second purpose of this paper is to answer a
question which has come up in the area of tabular pars-
ing, namely how to obtain a parsing algorithm with the
property that the table will contain as little entries as
possible, but without the possibility that two entries
represent the same subderivation.
</bodyText>
<sectionHeader confidence="0.9625" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.992285285714286">
Left-corner (LC) parsing is a parsing strategy which
has been used in different guises in various areas of com-
puter science. Deterministic LC parsing with k symbols
of lookahead can handle the class of LC(k) grammars.
Since LC parsing is a very simple parsing technique and
at the same time is able to deal with left recursion, it is
often used as an alternative to top-down (TD) parsing,
which cannot handle left recursion and is generally less
efficient.
Nondeterministic LC parsing is the foundation of a
very efficient parsing algorithm [7], related to Tomita&apos;s
algorithm and Earley&apos;s algorithm. It has one disad-
vantage however, which becomes noticeable when the
grammar contains many rules whose right-hand sides
begin with the same few grammars symbols, e.g.
A a/31 Iath ...
where a is not the empty string. After an LC parser
has recognized the first symbol X of such an a, it will
as next step predict all aforementioned rules. This
amounts to much nondeterminism, which is detrimental
both to the time-complexity and the space-complexity.
</bodyText>
<note confidence="0.4950905">
*Supported by the Dutch Organisation for Scientific Re-
search (NWO), under grant 00-62-518
</note>
<bodyText confidence="0.999877976744186">
A first attempt to solve this problem is to use predic-
tive LR (PLR) parsing. PLR parsing allows simulta-
neous processing of a common prefix a, provided that
the left-hand sides of the rules are the same. However,
in case we have e.g. the rules A a01 and B —4 al32,
where again a is not the empty string but now A B,
then PLR parsing will not improve the efficiency. We
therefore go one step further and discuss extended LR
(ELR) and common-prefix (CP) parsing, which are al-
gorithms capable of simultaneous processing of all com-
mon prefixes. ELR and CP parsing are the foundation
of tabular parsing algorithms and a parallel parsing al-
gorithm from the existing literature, but they have not
been described in their own right.
To the best of the author&apos;s knowledge, the various
parsing algorithms mentioned above have not been dis-
cussed together in the existing literature. The main
purpose of this paper is to make explicit the connec-
tions between these algorithms.
A second purpose of this paper is to show that CP
and ELR parsing are obvious solutions to a problem of
tabular parsing which can be described as follows. For
each parsing algorithm working on a stack there is a
realisation using a parse table, where the parse table
allows sharing of computation between different search
paths. For example, Tomita&apos;s algorithm [18] can be seen
as a tabular realisation of nondeterministic LR parsing.
At this point we use the term state to indicate the
symbols occurring on the stack of the original algo-
rithm, which also occur as entries in the parse table
of its tabular realisation.
In general, powerful algorithms working on a stack
lead to efficient tabular parsing algorithms, provided
the grammar can be handled almost deterministically.
In case the stack algorithm is very nondeterministic for
a certain grammar however, sophistication which in-
creases the number of states may lead to an increasing
number of entries in the parse table of the tabular re-
alization. This can be informally explained by the fact
that each state represents the computation of a number
of subderivations. If the number of states is increased
then it is inevitable that at some point some states
represent an overlapping collection of subderivations,
</bodyText>
<page confidence="0.995774">
117
</page>
<bodyText confidence="0.997662337209303">
which may lead to work being repeated during parsing.
Furthermore, the parse forest (a compact representa-
tion of all parse trees) which is output by a tabular
algorithm may in this case not be optimally dense.
We conclude that we have a tradeoff between the case
that the grammar allows almost deterministic parsing
and the case that the stack algorithm is very nondeter-
ministic for a certain grammar. In the former case, so-
phistication leads to less entries in the table, and in the
latter case, sophistication leads to more entries, pro-
vided this sophistication is realised by an increase in
the number of states. This is corroborated by empirical
data from [1, 4], which deal with tabular LR parsing.
As we will explain, CP and ELR parsing are more
deterministic than most other parsing algorithms for
many grammars, but their tabular realizations can
never compute the same subderivation twice. This rep-
resents an optimum in a range of possible parsing algo-
rithms.
This paper is organized as follows. First we discuss
nondeterministic left-corner parsing, and demonstrate
how common prefixes in a grammar may be a source of
bad performance for this technique.
Then, a multitude of parsing techniques which ex-
hibit better treatment of common prefixes is dis-
cussed. These techniques, including nondeterministic
PLR, ELR, and CP parsing, have their origins in theory
of deterministic, parallel, and tabular parsing. Subse-
quently, the application to parallel and tabular parsing
is investigated more closely.
Further, we briefly describe how rules with empty
right-hand sides complicate the parsing process.
The ideas described in this paper can be generalized
to head-driven parsing, as argued in [9].
We will take some liberty in describing algorithms
from the existing literature, since using the original de-
scriptions would blur the similarities of the algorithms
to one another. In particular, we will not treat the use
of lookahead, and we will consider all algorithms work-
ing on a stack to be nondeterministic. We will only
describe recognition algorithms. Each of the algorithms
can however be easily extended to yield parse trees as
a side-effect of recognition.
The notation used in the sequel is for the most part
standard and is summarised below.
A context-free grammar G = (T, N, P, S) consists of
two finite disjoint sets N and T of nonterminals and
terminals, respectively, a start symbol S E N, and a
finite set of rules P. Every rule has the form A —&gt; a,
where the left-hand side (lhs) A is an element from N
and the right-hand side (rhs) a is an element from V* ,
where V denotes (N U T). P can also be seen as a
relation on N x V.
We use symbols A, B, C,... to range over N, symbols
a, b, c,... to range over T, symbols X, Y, Z to range over
V, symbols a, 0, to range over V*, and v, w, x,
to range over T*. We let c denote the empty string. The
notation of rules A —&gt; al, A —&gt; a,... with the same
lhs is often simplified to A
&apos;011a2
A rule of the form A --&gt; e is called an epsilon rule.
1...
We assume grammars do not have epsilon rules unless
stated otherwise.
The relation P is extended to a relation —* on V* x V*
as usual. The reflexive and transitive closure of is
denoted by -4*.
We define: B L. A if and only if A —&gt; Ba for some a.
The reflexive and transitive closure of is denoted by
L*, and is called the left-corner relation.
We say two rules A —&gt; al and B a2 have a com-
mon prefix 0 if al = 0-yi and a2 = 13&apos;y2, for some
and 1,2, where 0 e.
A recognition algorithm can be specified by means
of a push-down automaton A = (T, Alph, mit, H, Fin),
which manipulates configurations of the form (F, v),
where r E Alph* is the stack, constructed from left
to right, and v E T* is the remaining input.
The initial configuration is (Init, w), where mit E
Alph is a distinguished stack symbol, and w is the input.
The steps of an automaton are specified by means of the
relation H. Thus, (r,v) H (F&apos;, v&apos;) denotes that (r&apos;,
is obtainable from (r, v) by one step of the automaton.
The reflexive and transitive closure of H is denoted by
I-4. The input w is accepted if (Init, w) H* (Fine),
where Fin E Alph is a distinguished stack symbol.
</bodyText>
<subsectionHeader confidence="0.52906">
LC parsing
</subsectionHeader>
<bodyText confidence="0.999680285714286">
For the definition of left-corner (LC) recognition [7] we
need stack symbols (items) of the form [A —&gt; a • 0],
where A a0 is a rule, and a E. (Remember that
we do not allow epsilon rules.) The informal meaning
of an item is &amp;quot;The part before the dot has just been
recognized, the first symbol after the dot is to be rec-
ognized next&amp;quot;. For technical reasons we also need the
</bodyText>
<equation confidence="0.9600685">
items [S&apos; • S] and [S&apos; S s], where S&apos; is a fresh
symbol. Formally:
&apos;Lc {[A
0] A a0 E Pt A(a EVA --= S&apos;)}
</equation>
<bodyText confidence="0.9983515">
where Pt represents the augmented set of rules, consist-
ing of the rules in P plus the extra rule S&apos; --+ S.
</bodyText>
<equation confidence="0.82754">
Algorithm 1 (Left-corner)
ALC = (T, I&apos;&apos;, Init,H , Fin), mit [S&apos; • S], Fin =
[S&apos; S •]. Transitions are allowed according to the
following clauses.
1. (r[B • C-y],av)H
(F[B —+ 0 • C-y][A a. a], v)
</equation>
<bodyText confidence="0.949796">
where there is A —&gt; aa E Pt such that A Z&amp;quot;` C
</bodyText>
<listItem confidence="0.976126">
2. (F[A —&gt; a • a0], av) H (r[A aa • 0], v)
3. (F[B —&gt; 0 • C&apos;y][A —&gt; a .],v) H
</listItem>
<equation confidence="0.79507">
(F[B —* 0 • C-y][D A •
</equation>
<bodyText confidence="0.935452">
where there is D —* Ab ePt such that D Z* C
</bodyText>
<listItem confidence="0.635065">
4. (r[B —&gt; 0 • A-y][A —* a •], v) H (r[B 0A • -y], v)
</listItem>
<bodyText confidence="0.989433">
The conditions using the left-corner relation Z* in the
first and third clauses together form a feature which is
</bodyText>
<equation confidence="0.732856">
1 1 8
</equation>
<bodyText confidence="0.9611758">
called top-down (TD) filtering. TD filtering makes sure
that subderivations that are being computed bottom-
up may eventually grow into subderivations with the re-
quired root. TD filtering is not necessary for a correct
algorithm, but it reduces nondeterminism, and guar-
antees the correct-prefix property, which means that in
case of incorrect input the parser does not read past the
first incorrect character.
Example 1 Consider the grammar with the following
rules:
</bodyText>
<equation confidence="0.847464666666667">
E E+TITTEIT
T T*FiT**FiF
-o a
</equation>
<bodyText confidence="0.9959458">
It is easy to see that EL E,T L E,T LT, FL T.
The relation L* contains L but from the reflexive closure
it also contains F F and from the transitive closure
it also contains F L4 E.
The recognition of a * a is realised by:
</bodyText>
<equation confidence="0.592039888888889">
[E&apos; -o • E] a * a
1 E&apos; -+ • E [F --+ a.] * a
2 E&apos; -o • E T -0 F 41] * a
3 E&apos; --o • E T --o T • * F] * a
4 E&apos; -o • E [T -o T * • F] a
5 E&apos; -0 • E [T --■ T * • F][F --* a .]
6 E&apos; -0 • E [T -o T * F .]
7 E&apos; -o • E E -+ T .]
8 E&apos; -o E •
</equation>
<bodyText confidence="0.9966322">
Note that since the automaton does not use any looka-
head, Step 3 may also have replaced [T F e] by
any other item besides [T -o T • * F] whose rhs starts
with T and whose lhs satisfies the condition of top-
down filtering with regard to E, i.e. by [T -o T •
</bodyText>
<equation confidence="0.921994">
[E --o T • E], or [E T .].
</equation>
<bodyText confidence="0.985442">
LC parsing with k symbols of lookahead can handle
deterministically the so called LC(k) grammars. This
class of grammars is formalized in [13].1 How LC pars-
ing can be improved to handle common suffixes effi-
ciently is discussed in [6]; in this paper we restrict our
attention to common prefixes.
PLR, ELR, and CP parsing
In this section we investigate a number of algorithms
which exhibit a better treatment of common prefixes.
</bodyText>
<subsectionHeader confidence="0.961945">
Predictive LR parsing
</subsectionHeader>
<bodyText confidence="0.9770637">
Predictive LR (PLR) parsing with k symbols of looka-
head was introduced in [17] as an algorithm which yields
efficient parsers for a subset of the LR(k) grammars [16]
and a superset of the LC(k) grammars. How determin-
istic PLR parsing succeeds in handling a larger class
of grammars (the PLR(k) grammars) than the LC(k)
grammars can be explained by identifying PLR parsing
1In [171 a different definition of the LC(k) grammars may
be found, which is not completely equivalent.
for some grammar G with LC parsing for some gram-
mar G&apos; which results after applying a transformation
called left-factoring.
Left-factoring consists of replacing two or more rules
A 011021... with a common prefix a by the rules
A aA&apos; and A&apos; -0 011021—, where A&apos; is a fresh non-
terminal. The effect on LC parsing is that a choice
between rules is postponed until after all symbols of a
are completely recognized. Investigation of the next k
symbols of the remaining input may then allow a choice
between the rules to be made deterministically.
The PLR algorithm is formalised in [17] by trans-
forming a PLR(k) grammar into an LL(k) grammar
and then assuming the standard realisation of LL(k)
parsing. When we consider nondeterministic top-down
parsing instead of LL(k) parsing, then we obtain the
new formulation of nondeterministic PLR(0) parsing
below.
We first need to define another kind of item, viz, of
the form [A --+ a] such that there is at least one rule of
the form A ad3 for some /3. Formally:
</bodyText>
<equation confidence="0.84819">
IPLR { [A
a] A--aPEPtA(a0EVA--=S1)}
</equation>
<bodyText confidence="0.935648">
Informally, an item [A a] E IPLR represents one or
more items [A -4 a • 0] E /LC.
</bodyText>
<equation confidence="0.6419345">
Algorithm 2 (Predictive LR)
APR = (T, IP&amp;quot;, Init,h, Fin), Mit = [S&apos; -0 ], Fin
[S&apos; 5], and I- defined by:
1. (11B 0], a v) (r[B i3][A a], v)
</equation>
<bodyText confidence="0.79916">
where there are A -4 aa,B OCry E Pt such that
A L* C
2. (r[A -0 a], av) (r[A aa], v)
where there is A ---■ aa/3E Pt
</bodyText>
<listItem confidence="0.899088">
3. (r[B 0][A -o a], v) F (r[B 13][D -o A], v)
</listItem>
<bodyText confidence="0.959327857142857">
where A a E Pt and where there are D
Afi, B --o pc7 E Pt such that D 1* C
4. (r[B --0 13][A a], t)) 1- (1[B -o OA], v)
where A -4 a E Pt and where there is B 0,47 E
Pt
Example 2 Consider the grammar from Example 1.
Using Predictive LR, recognition of a *a is realised by:
Comparing these configurations with those reached by
the LC recognizer, we see that here after Step 3 the
stack element [T --■ T] represents both [T --0 T • * F]
and [T T • **F], so that nondeterminism is reduced.
Still some nondeterminism remains, since Step 3 could
also have replaced [T -o F] by [E -o T], which repre-
sents both [E -o T • I E] and [E -o T •].
</bodyText>
<figure confidence="0.991989833333333">
[E&apos; -o ]
[E&apos; ][F a]
[E&apos; ][T -o F]
[E&apos; --o liT -0T]
[E&apos; ][T T *]
[E&apos; --o E.]
1
2
3
4
8
1 1 9
</figure>
<subsectionHeader confidence="0.618556">
Extended LR parsing
</subsectionHeader>
<bodyText confidence="0.999938058823529">
An extended context-free grammar has right-hand sides
consisting of arbitrary regular expressions over V. This
requires an LR parser for an extended grammar (an
ELR parser) to behave differently from normal LR
parsers.
The behaviour of a normal LR parser upon a reduc-
tion with some rule A -4 a is very simple: it pops la!
states from the stack, revealing, say, state Q; it then
pushes state goto(Q, A). (We identify a state with its
corresponding set of items.)
For extended grammars the behaviour upon a reduc-
tion cannot be realised in this way since the regular
expression of which the rhs is composed may describe
strings of various lengths, so that it is unknown how
many states need to be popped.
In [11] this problem is solved by forcing the parser to
decide at each call goto(Q, X) whether
</bodyText>
<equation confidence="0.88802325">
a) X is one more symbol of an item in Q of which some
symbols have already been recognized, or whether
b) X is the first symbol of an item which has been
introduced in Q by means of the closure function.
</equation>
<bodyText confidence="0.99031625">
In the second case, a state which is a variant of
goto(Q, X) is pushed on top of state Q as usual. In
the first case, however, state Q on top of the stack is
replaced by a variant of goto(Q, X). This is safe since
we will never need to return to Q if after some more
steps we succeed in recognizing some rule correspond-
ing with one of the items in Q. A consequence of the
action in the first case is that upon reduction we need
to pop only one state off the stack.
Further work in this area is reported in [5], which
treats nondeterministic ELR parsing and therefore does
not regard it as an obstacle if a choice between cases a)
and b) cannot be uniquely made.
We are not concerned with extended context-free
grammars in this paper. However, a very interesting
algorithm results from ELR parsing if we restrict its ap-
plication to ordinary context-free grammars. (We will
maintain the name &amp;quot;extended LR&amp;quot; to stress the origin
of the algorithm.) This results in the new nondetermin-
istic ELR(0) algorithm that we describe below, derived
from the formulation of ELR parsing in [5].
First, we define a set of items as
/ = {[A --+ a • 0] A a0 E Pt}
Note that /Lc c I. If we define for each Q C I:
</bodyText>
<equation confidence="0.9363246">
closure(Q)
Q U {[A &amp;quot; • al I [B-40•C-y]EQAAL*C}
then the goto function for LR(0) parsing is defined by
goto(Q, X) --,-
closure({[A aX • 0] [A --+ a • X13] E Q})
</equation>
<bodyText confidence="0.99989675">
For ELR parsing however, we need two goto func-
tions, gotoi and goto2, one for kernel items (i.e. those
in IW) and one for nonkernel items (the others). These
are defined by
</bodyText>
<equation confidence="0.9997986">
gotoi(Q, X) =
closure({[A -&gt; aX • (3] I [A -&gt; a X[3] E Q A
(a E VA =S&apos;)})
goto2(Q, X) =
closure({[A -+ x • p] I [A-+•X0]EQAA S&apos;})
</equation>
<bodyText confidence="0.9965016">
At each shift (where X is some terminal) and each re-
duce with some rule A -&gt; a (where X is A) we may non-
deterministically apply gotoi, which corresponds with
case a), or goto2, which corresponds with case b). Of
course, one or both may not be defined on Q and X,
because goto(Q, X) may be 0, for i E {1, 2}.
Now remark that when using gotoi and goto2, each
reachable set of items contains only items of the form
A -&gt; a • 0, for some fixed string a, plus some nonkernel
items. We will ignore the nonkernel items since they
can be derived from the kernel items by means of the
closure function.
This suggests representing each set of items by a new
kind of item of the form [{A1, A2, , An} --+ a], which
represents all items A -&gt; a • 0 for some 0 and A E
</bodyText>
<equation confidence="0.890933666666667">
{Ai, A2, An}. Formally:
TELR = {[A-&gt;allOCAC{AIA-&gt; a0 E Pt} A
(a V Z = {S&apos;})}
</equation>
<bodyText confidence="0.99528">
where we use the symbol A to range over sets of non-
terminals.
</bodyText>
<figure confidence="0.4664575">
Algorithm 3 (Extended LR)
AELR = (T, IELR Fin), Mit = [{S&apos;} -+], Fin =
</figure>
<listItem confidence="0.616964538461538">
[{S&apos;} S], and F- defined by:
1. (F[A 0], av) F- (r[6. o][A&apos; a], v)
where A&apos; = {A I 3A ---&gt; acy, B i3C7 E
A A A 7* CD is non-empty
2. (r[6, a], av) H (F[A&apos; aa], v)
where A&apos; = {A EAI A -4 aa/3 E Pt} is non-empty
3. (r[A #][A&apos; -* a], v) (F[A /3][A&amp;quot; -4 A], v)
where there is A -4 a E Pt with A E A&apos;, and A&amp;quot; =
{D I 3D -&gt; A6, B 0C-y E Pt[B E AAD L* Cif is
non-empty
4. (r[6. -+ a], v) H (F[A&amp;quot; -&gt; 0A], v)
where there is A -&gt; a E Pt with A E A&apos;, and A&amp;quot;
E A I /3 -&gt; 0A-y E Pt} is non-empty
</listItem>
<bodyText confidence="0.8909696">
Note that Clauses 1 and 3 correspond with goto2 and
that Clauses 2 and 4 correspond with goto1.
Example 3 Consider again the grammar from Exam-
ple 1. Using the ELR algorithm, recognition of a * a is
realised by:
</bodyText>
<figure confidence="0.933415583333333">
[{E&apos;}
[{E&apos;} ][{F} -&gt; a]
[{E&apos;} --+ ][{T} F]
[{E&apos;} ][{T, E} T]
[{E&apos;} ][{T} T *1
•
[{E&apos;} -4 E].
1
2
3
4
pt {B E
</figure>
<page confidence="0.979411">
120
</page>
<bodyText confidence="0.986387">
Comparing these configurations with those reached by
the PLR recognizer, we see that here after Step 3 the
stack element [{T, E} T] represents both [T T •
</bodyText>
<equation confidence="0.890315666666667">
* F] and [T T • * * F], but also [E -&gt; T ID] and
[E -+ T • I E], so that nondeterminism is even further
reduced.
</equation>
<bodyText confidence="0.9996672">
A simplified ELR algorithm, which we call the pseudo
ELR algorithm, results from avoiding reference to A in
Clauses 1 and 3. In Clause 1 we then have a simplified
definition of A&apos;, viz. A&apos; = {A I 3A -&gt; aa, B -&gt; /3C E
Pt [A L* C]} , and in the same way we have in Clause 3
the new definition A&amp;quot; = {D 3D Ab, B -&gt; OC -y E
Pt[D L* C]l. Pseudo ELR parsing can be more easily
realised than full ELR parsing, but the correct-prefix
property can no longer be guaranteed. Pseudo ELR
parsing is the foundation of a tabular algorithm in [20].
</bodyText>
<subsectionHeader confidence="0.652788">
Common-prefix parsing
</subsectionHeader>
<bodyText confidence="0.999978181818182">
One of the more complicated aspects of the ELR algo-
rithm is the treatment of the sets of nonterminals in
the left-hand sides of items. A drastically simplified
algorithm is the basis of a tabular algorithm in [21].
Since in [21] the algorithm itself is not described but
only its tabular realisation,2 we take the liberty of giv-
ing this algorithm our own name: common-prefix (CP)
parsing, since it treats all rules with a common prefix
simultaneously.3
The simplification consists of omitting the sets of
nonterminals in the left-hand sides of items:
</bodyText>
<equation confidence="0.5805498">
/GP {[- cf] I A a 0 E Pt}
A1jjorithm 4 (Common-prefix)
A = (T, I c P , , Fin), mit = [-H, Fin = S],
and I- defined by:
1. (rl, 0], av) F (r[, o][, a], v)
</equation>
<bodyText confidence="0.997827">
where there are A -&gt; aa, B --&gt; i3C-y E Pt such that
A L* C
</bodyText>
<listItem confidence="0.776595666666667">
2. (r[. a], av) F (r[-, aa], v)
where there is A aaf3 E pt
3. (r[-. o][,- a], v) F (F[-&gt; 0]-&gt; A], v)
</listItem>
<bodyText confidence="0.9935073">
where there are A a, D -4 AS, B OC E Pt
such that D L* C
4. (r[--+ o][, a], v) F (r[.-4 v)
where there are A a, B -&gt; 3A7 E Pt
The simplification which leads to the CP algorithm
inevitably causes the correct-prefix property to be lost.
Example 4 Consider again the grammar from Exam-
ple 1. It is clear that a+a j a is not a correct string
according to this grammar. The CP algorithm may go
through the following sequence of configurations:
</bodyText>
<footnote confidence="0.9892765">
2An attempt has been made in [19] but this paper does
not describe the algorithm in its full generality.
3The original algorithm in [21] applies an optimization
concerning unit rules, irrelevant to our discussion.
</footnote>
<figure confidence="0.816128416666667">
1 {H —&gt; a] al-ala
—+] -Fala
2 -H[—&gt; -Fala
F]
3 -•-• -&gt; T] -Fala
4 --d -4 El +ala
5 _.4] - ■ E -I- ala
6 -- -&gt; .E + [-- a] I a
7 -H .E + [-&gt; F] 1 a
8 [--■][— E +][.- T] I a
9 -4 -■E-F[ --*TT] a
10 --- ---&gt; E + [-* T T][- a]
</figure>
<bodyText confidence="0.99974275">
We see that in Step 9 the first incorrect symbol I is read,
but recognition then continues. Eventually, the recog-
nition process is blocked in some unsuccessful configu-
ration, which is guaranteed to happen for any incorrect
input4. In general however, after reading the first incor-
rect symbol, the algorithm may perform an unbounded
number of steps before it halts. (Imagine what happens
for input of the form a+a a+ a+a+ + a.) 13
</bodyText>
<subsectionHeader confidence="0.914669">
Tabular parsing
</subsectionHeader>
<bodyText confidence="0.999915636363636">
Nondeterministic push-down automata can be realised
efficiently using parse tables [1]. A parse table consists
of sets Ti,j of items, for 0 &lt; i &lt; j &lt; n, where al . • • an
represents the input. The idea is that an item is only
stored in a set Tid if the item represents recognition of
the part of the input ai+i ai.
We will first discuss a tabular form of CP parsing,
since this is the most simple parsing technique discussed
above. We will then move on to the more difficult ELR
technique. Tabular PLR parsing is fairly straightfor-
ward and will not be discussed in this paper.
</bodyText>
<subsectionHeader confidence="0.857709">
Tabular CP parsing
</subsectionHeader>
<bodyText confidence="0.972918">
CP parsing has the following tabular realization:
</bodyText>
<subsectionHeader confidence="0.585843">
Algorithm 5 (Tabular common-prefix)
</subsectionHeader>
<bodyText confidence="0.999236">
Sets Ti,j of the table are to be subsets of /cP. Start
with an empty table. Add [---+] to T0,0. Perform one of
the following steps until no more items can be added.
</bodyText>
<listItem confidence="0.960259">
1. Add [-&gt; a] to for a = ai and [-&gt; 0] E
</listItem>
<bodyText confidence="0.83582525">
where there are A ---&gt; aa, B flCy E Pt such that
A L* C
2. Add aa] to T3, for a = ai and [-&gt; a] E
where there is A •-■ aa/3 E Pt
</bodyText>
<listItem confidence="0.762426">
3. Add [-+ A] to for a] E and [---4 0] E Th,
where there are A -+ a, D -4 AS, B -&gt; /3C &apos;y Pt
such that D L* C
4. Add [-+ OA] to Th,,i for [-&gt; a] E Tbi and [--4 0] E Th,3
</listItem>
<bodyText confidence="0.924485428571429">
where there are A a, B 3 A-y E Pt
Report recognition of the input if S] E To,n.
For an example, see Figure 1.
Tabular CP parsing is related to a variant of CYK
parsing with TD filtering in [5]. A form of tabular
&apos;unless the grammar is cyclic, in which case the parser
may not terminate, both on correct and on incorrect input
</bodyText>
<page confidence="0.992394">
121
</page>
<table confidence="0.617303285714286">
1 2 3 4 5
[—&gt;1 (0) [---+ a] (1) [—&gt; E H(5) [—&gt; E T]
0 [—F} [—E] 0 0
[—*T]
[—+E]
1 0 0 0 0
[--■ a] (6) T 11(9) [—&gt; T E]
2 [—IF]
[—FT]
3 0 0
a] (10)
4 [—&gt; F]
[—&gt; T]
[—*E]
</table>
<figureCaption confidence="0.998977">
Figure 1: Tabular CP parsing
</figureCaption>
<bodyText confidence="0.995703375">
Consider again the grammar from
Example 1 and the (incorrect) in-
put a + a a. After execution
of the tabular common-prefix al-
gorithm, the table is as given here.
The sets are given at the j-th
row and i-th column.
The items which correspond with
those from Example 4 are labelled
with (0), (1), ... These labels also
indicate the order in which these
items are added to the table.
CP parsing without top-down filtering (i.e. without the
checks concerning the left-corner relation 7*) is the
main algorithm in [21].
Without the use of top-down filtering, the references
</bodyText>
<listItem confidence="0.6075345">
to 0] in Clauses 1 and 3 are clearly not of much use
any more. When we also remove the use of these items,
then these clauses become:
1. Add [—+ a] to for a = ai
</listItem>
<bodyText confidence="0.886464">
where there is A —&gt; aa E PI
</bodyText>
<listItem confidence="0.668766">
3. Add [—+ A] to for a] E
</listItem>
<bodyText confidence="0.871722857142857">
where there are A —4 a, D —&gt;A5 E pt
In the resulting algorithm, no set depends on any
set Tg,h with g &lt; i. In [15] this fact is used to construct
a parallel parser with n processors Po, , Pri_1, with
each P, processing the sets Ti,i for all j &gt; i. The flow
of data is strictly from right to left, i.e. items computed
by Pi are only passed on to Po,. • • ,
</bodyText>
<subsectionHeader confidence="0.926842">
Tabular ELR parsing
</subsectionHeader>
<bodyText confidence="0.9996358">
The tabular form of ELR parsing allows an optimiza-
tion which constitutes an interesting example of how a
tabular algorithm can have a property not shared by its
nondeterministic origin.5
First note that we can compute the columns of a
parse table strictly from left to right, that is, for fixed i
we can compute all sets T3,i. before we compute the sets
If we formulate a tabular ELR algorithm in a naive
way analogously to Algorithm 5, as is done in [5], then
for example the first clause is given by:
</bodyText>
<listItem confidence="0.564914">
1. Add [A&apos; —&gt; a] to for a = ai and
</listItem>
<equation confidence="0.59799">
[A —&gt; )3] E Tj,i—t
</equation>
<bodyText confidence="0.7530825">
where A&apos; = {A I 3A aa, B OC-y E Pt[B E
A A A 7* C]} is non-empty
</bodyText>
<footnote confidence="0.837049333333333">
5This is reminiscent of the admissibility tests [3], which
are applicable to tabular realisations of logical push-down
automata, but not to these automata themselves.
</footnote>
<bodyText confidence="0.995285">
However, for certain i there may be many [A —&gt; 0] E
for some j, and each may give rise to a different
A&apos; which is non-empty. In this way, Clause 1 may add
several items [A&apos; —&gt; a] to some possibly with
overlapping sets A&apos;. Since items represent computation
of subderivations, the algorithm may therefore compute
the same subderivation several times.
We propose an optimization which makes use of the
fact that all possible items [A —&gt; 0] E T3,i_i are already
present when we compute items in we compute
one single item [A&apos; ---&gt; a], where A&apos; is a large set com-
puted using all [A —÷ 0] E for any j. A similar
optimization can be made for the third clause.
</bodyText>
<subsectionHeader confidence="0.689085">
Algorithm 6 (Tabular extended LR)
</subsectionHeader>
<bodyText confidence="0.99614525">
Sets Ti,j of the table are to be subsets of IELR. Start
with an empty table. Add [{S&apos;} —&gt; ] to T0,0. For
i = 1, ,n, in this order, perform one of the following
steps until no more items can be added.
</bodyText>
<listItem confidence="0.903287">
1. Add [A&apos; —4 a] to for a = ai
</listItem>
<bodyText confidence="0.578245">
where A&apos; = {A I 3j3[A —&gt; 13] E T3,2_13A —&gt; aa, B
Pay E Pt[B EA AA 7* C]} is non-empty
</bodyText>
<listItem confidence="0.990928666666667">
2. Add [A&apos; aa] to Tj, for a = ai and
[A a] E
where A&apos; = {A E A A ---&gt; aa/3 E Pt} is non-empty
3. Add [A&amp;quot; --&gt; A] to Tj, for [A&apos; a] E T3,,
where there is A a E Pt with A E A&apos;, and A&amp;quot; =
{D I 31/3[A --&gt; 0] E Th,j3D —■ A6, B —&gt; OC-y E
Pt[B EAAD 7* C]} is non-empty
4. Add [A&amp;quot; —&gt; 0A] to Th, i for [A&apos; --&gt; a] E T3,i and
[A ---&gt; 0] E Th,3
</listItem>
<bodyText confidence="0.933660833333333">
where there is A —&gt; a E Pt with A E A&apos;, and A&amp;quot; =
{B EAIB —&gt; 0A7 E Pt} is non-empty
Report recognition of the input if [{S&apos;} --&gt; S] E To,.
Informally, the top-down filtering in the first and
third clauses is realised by investigating all left corners
D of nonterminals C (i.e. D 7* C) which are expected
</bodyText>
<page confidence="0.994675">
122
</page>
<bodyText confidence="0.9868255">
from a certain input position. For input position i these
nonterminals D are given by
</bodyText>
<equation confidence="0.979452">
Si = {D 2j3[A p] E
3B OCT E Pt[B EAAD /*
</equation>
<bodyText confidence="0.948236">
Provided each set Si is computed just after comple-
tion of the i-th column of the table, the first and third
clauses can be simplified to:
</bodyText>
<listItem confidence="0.452448">
1. Add [A&apos; a] to for a = ai
where A&apos; ,--{A I A aa E Pt} n Si_1 is non-empty
3. Add [A&amp;quot; Al to for [A&apos; a] E
</listItem>
<bodyText confidence="0.998440375">
where there is A a E Pt with A E A&apos;, and A&amp;quot; =-
ID I D —4 Ab E Pt} n s; is non-empty
which may lead to more practical implementations.
Note that we may have that the tabular ELR algo-
rithm manipulates items of the form [A a] which
would not occur in any search path of the nondeter-
ministic ELR algorithm, because in general such a A
is the union of many sets A&apos; of items [A&apos; a] which
would be manipulated at the same input position by the
nondeterministic algorithm in different search paths.
With minor differences, the above tabular ELR algo-
rithm is described in [21]. A tabular version of pseudo
ELR parsing is presented in [20]. Some useful data
structures for practical implementation of tabular and
non-tabular PLR, ELR and CP parsing are described
in [8].
</bodyText>
<subsectionHeader confidence="0.691823">
Finding an optimal tabular algorithm
</subsectionHeader>
<bodyText confidence="0.99983752173913">
In [14] Schabes derives the LC algorithm from LR pars-
ing similar to the way that ELR parsing can be derived
from LR parsing. The LC algorithm is obtained by not
only splitting up the goto function into gotoi and goto2
but also splitting up goto2 even further, so that it non-
deterministically yields the closure of one single kernel
item. (This idea was described earlier in [5], and more
recently in [10].)
Schabes then argues that the LC algorithm can be
determinized (i.e. made more deterministic) by manip-
ulating the goto functions. One application of this idea
is to take a fixed grammar and choose different goto
functions for different parts of the grammar, in order
to tune the parser to the grammar.
In this section we discuss a different application of
this idea: we consider various goto functions which are
global, i.e. which are the same for all parts of a grammar.
One example is ELR parsing, as its goto2 function can
be seen as a determinized version of the goto2 function
of LC parsing. In a similar way we obtain PLR parsing.
Traditional LR parsing is obtained by taking the full
determinization, i.e. by taking the normal goto function
which is not split up.6
</bodyText>
<footnote confidence="0.6244855">
6Schabes more or less also argues that LC itself can be
obtained by determinizing TD parsing. (In lieu of TD pars-
ing he mentions Earley&apos;s algorithm, which is its tabular
realisation.)
</footnote>
<bodyText confidence="0.999984428571429">
We conclude that we have a family consisting of LC,
PLR, ELR, and LR parsing, which are increasingly de-
terministic. In general, the more deterministic an algo-
rithm is, the more parser states it requires. For exam-
ple, the LC algorithm requires a number of states (the
items in /LC) which is linear in the size of the gram-
mar. By contrast, the LR algorithm requires a number
of states (the sets of items) which is exponential in the
size of the grammar [2].
The differences in the number of states complicates
the choice of a tabular algorithm as the one giving op-
timal behaviour for all grammars. If a grammar is very
simple, then a sophisticated algorithm such as LR may
allow completely deterministic parsing, which requires a
linear number of entries to be added to the parse table,
measured in the size of the grammar.
If, on the other hand, the grammar is very ambigu-
ous such that even LR parsing is very nondeterministic,
then the tabular realisation may at worst add each state
to each set Ti,j, so that the more states there are, the
more work the parser needs to do. This favours sim-
ple algorithms such as LC over more sophisticated ones
such as LR. Furthermore, if more than one state repre-
sents the same subderivation, then computation of that
subderivation may be done more than once, which leads
to parse forests (compact representations of collections
of parse trees) which are not optimally dense [1, 12, 7].
Schabes proposes to tune a parser to a grammar, or
in other words, to use a combination of parsing tech-
niques in order to find an optimal parser for a certain
grammar.7 This idea has until now not been realised.
However, when we try to find a single parsing algorithm
which performs well for all grammars, then the tabu-
lar ELR algorithm we have presented may be a serious
candidate, for the following reasons:
</bodyText>
<listItem confidence="0.910001">
• For all i, j, and a at most one item of the form
</listItem>
<bodyText confidence="0.809443631578947">
[A a] is added to Ti,j. Therefore, identical sub-
derivations are not computed more than once. (This
is a consequence of our optimization in Algorithm 6.)
Note that this also holds for the tabular CP algo-
rithm.
• ELR parsing guarantees the correct-prefix property,
contrary to the CP algorithm. This prevents com-
putation of all subderivations which are useless with
regard to the already processed input.
• ELR parsing is more deterministic than LC and PLR
parsing, because it allows shared processing of all
common prefixes. It is hard to imagine a practical
parsing technique more deterministic than ELR pars-
ing which also satisfies the previous two properties.
In particular, we argue in [8] that refinement of the
LR technique in such a way that the first property
above holds whould require an impractically large
number of LR states.
&apos;This is reminiscent of the idea of &amp;quot;optimal cover&amp;quot; [5].
</bodyText>
<page confidence="0.997252">
123
</page>
<sectionHeader confidence="0.587754" genericHeader="method">
Epsilon rules
</sectionHeader>
<bodyText confidence="0.9999439">
Epsilon rules cause two problems for bottom-up pars-
ing. The first is non-termination for simple realisations
of nondeterminism (such as backtrack parsing) caused
by hidden left recursion [7]. The second problem occurs
when we optimize TD filtering e.g. using the sets Si: it
is no longer possible to completely construct a set Si be-
fore it is used, because the computation of a derivation
deriving the empty string requires Si for TD filtering
but at the same time its result causes new elements to
be added to Si. Both problems can be overcome [8].
</bodyText>
<sectionHeader confidence="0.801073" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.999893545454546">
We have discussed a range of different parsing algo-
rithms, which have their roots in compiler construction,
expression parsing, and natural language processing.
We have shown that these algorithms can be described
in a common framework.
We further discussed tabular realisations of these al-
gorithms, and concluded that we have found an opti-
mal algorithm, which in most cases leads to parse tables
containing fewer entries than for other algorithms, but
which avoids computing identical subderivations more
than once.
</bodyText>
<sectionHeader confidence="0.998351" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.819117666666667">
The author acknowledges valuable correspondence with
Klaas Sikkel, Rene Leermakers, Francois Barthelemy,
Giorgio Satta, Yves Schabes, and Frederic Voisin.
</bodyText>
<sectionHeader confidence="0.99591" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999144753246753">
[1] S. Billot and B. Lang. The structure of shared
forests in ambiguous parsing. In 27th Annual Meet-
ing of the ACL, 143-151, 1989.
[2] M. Johnson. The computational complexity of
GLR parsing. In M. Tomita, editor, Generalized
LR Parsing, chapter 3, 35-42. Kluwer Academic
Publishers, 1991.
[3] B. Lang. Complete evaluation of Horn clauses:
An automata theoretic approach. Rapport de
Recherche 913, Institut National de Recherche en
Informatique et en Automatique, Rocquencourt,
France, November 1988.
[4] M. Lankhorst. An empirical comparison of gener-
alized LR tables. In R. Heemels, A. Nijholt, and
K. Sikkel, editors, Tomita&apos;s Algorithm: Extensions
and Applications, Proc. of the first Twente Work-
shop on Language Technology, 87-93. University of
Twente, September 1991. Memoranda Informatica
91-68.
[7] M.J. Nederhof. Generalized left-corner parsing. In
Sixth Conference of the European Chapter of the
ACL, 305-314, 1993.
[8] M.J. Nederhof. A multidisciplinary approach to
a parsing algorithm. In K. Sikkel and A. Ni-
jholt, editors, Natural Language Parsing: Methods
and Formalisms, Proc. of the sixth Twente Work-
shop on Language Technology, 85-98. University
of Twente, 1993.
[9] M.J. Nederhof and G. Satta. An extended theory
of head-driven parsing. In this proceedings.
[10] P. Oude Luttighuis and K. Sikkel. Generalized LR
parsing and attribute evaluation. In Third Inter-
national Workshop on Parsing Technologies, 219-
233, Tilburg (The Netherlands) and Durbuy (Bel-
gium), August 1993.
[11] P.W. Purdom, Jr. and C.A. Brown. Parsing
extended LR(k) grammars. Acta Informatica,
15:115-127, 1981.
[12] J. Rekers. Parser Generation for Interactive Envi-
ronments. PhD thesis, University of Amsterdam,
1992.
[13] D.J. Rosenkrantz and P.M. Lewis II. Deterministic
left corner parsing. In IEEE Conference Record
of the 11th Annual Symposium on Switching and
Automata Theory, 139-152, 1970.
[14] Y. Schabes. Polynomial time and space shift-
reduce parsing of arbitrary context-free grammars.
In 29th Annual Meeting of the ACL, 106-113, 1991.
[15] K. Sikkel and M. Lankhorst. A parallel bottom-
up Tomita parser. In 1. Konferenz &amp;quot;Verarbeitung
Natiirlicher Sprache&amp;quot;, 238-247, Nürnberg, October
1992. Springer-Verlag.
[16] S. Sippu and E. Soisalon-Soininen. Parsing The-
ory, Vol. II: LR(k) and LL(k) Parsing, EATCS
Monographs on Theoretical Computer Science,
volume 20. Springer-Verlag, 1990.
[17] E. Soisalon-Soininen and E. Ukkonen. A method
for transforming grammars into LL(k) form. Acta
Informatica, 12:339-369, 1979.
[18] M. Tomita. Efficient Parsing for Natural Lan-
guage. Kluwer Academic Publishers, 1986.
[19] F. Voisin. CIGALE: A tool for interactive grammar
construction and expression parsing. Science of
Computer Programming, 7:61-86, 1986.
[20] F. Voisin. A bottom-up adaptation of Earley&apos;s
parsing algorithm. In Programming Languages
Implementation and Logic Programming, Interna-
tional Workshop, LNCS 348, 146-160, Orleans,
France, May 1988. Springer-Verlag.
[21] F. Voisin and J.-C. Raoult. A new, bottom-up,
general parsing algorithm. BIGRE, 70:221-235,
September 1990.
[5] R. Leermakers. How to cover a grammar. In 27th
Annual Meeting of the ACL, 135-142, 1989.
[6] R. Leermakers. A recursive ascent Earley
parser. Information Processing Letters, 41(2):87-
91, February 1992.
</reference>
<page confidence="0.998223">
124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.414810">
<title confidence="0.988872">AN OPTIMAL TABULAR PARSING ALGORITHM</title>
<author confidence="0.948693">Mark-Jan Nederhof</author>
<affiliation confidence="0.999747">University of Nijmegen, Department of Computer Science</affiliation>
<address confidence="0.974875">Toernooiveld, 6525 ED Nijmegen, The Netherlands</address>
<email confidence="0.441249">markjaacs.kun.n1</email>
<abstract confidence="0.999854666666667">In this paper we relate a number of parsing algorithms which have been developed in very different areas of parsing theory, and which include deterministic algorithms, tabular algorithms, and a parallel algorithm. We show that these algorithms are based on the same underlying ideas. By relating existing ideas, we hope to provide an opportunity to improve some algorithms based on features of others. A second purpose of this paper is to answer a question which has come up in the area of tabular parsing, namely how to obtain a parsing algorithm with the property that the table will contain as little entries as possible, but without the possibility that two entries represent the same subderivation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Billot</author>
<author>B Lang</author>
</authors>
<title>The structure of shared forests in ambiguous parsing.</title>
<date>1989</date>
<booktitle>In 27th Annual Meeting of the ACL,</booktitle>
<pages>143--151</pages>
<contexts>
<context position="4945" citStr="[1, 4]" startWordPosition="819" endWordPosition="820">rmore, the parse forest (a compact representation of all parse trees) which is output by a tabular algorithm may in this case not be optimally dense. We conclude that we have a tradeoff between the case that the grammar allows almost deterministic parsing and the case that the stack algorithm is very nondeterministic for a certain grammar. In the former case, sophistication leads to less entries in the table, and in the latter case, sophistication leads to more entries, provided this sophistication is realised by an increase in the number of states. This is corroborated by empirical data from [1, 4], which deal with tabular LR parsing. As we will explain, CP and ELR parsing are more deterministic than most other parsing algorithms for many grammars, but their tabular realizations can never compute the same subderivation twice. This represents an optimum in a range of possible parsing algorithms. This paper is organized as follows. First we discuss nondeterministic left-corner parsing, and demonstrate how common prefixes in a grammar may be a source of bad performance for this technique. Then, a multitude of parsing techniques which exhibit better treatment of common prefixes is discussed</context>
<context position="21435" citStr="[1]" startWordPosition="4120" endWordPosition="4120">■][— E +][.- T] I a 9 -4 -■E-F[ --*TT] a 10 --- ---&gt; E + [-* T T][- a] We see that in Step 9 the first incorrect symbol I is read, but recognition then continues. Eventually, the recognition process is blocked in some unsuccessful configuration, which is guaranteed to happen for any incorrect input4. In general however, after reading the first incorrect symbol, the algorithm may perform an unbounded number of steps before it halts. (Imagine what happens for input of the form a+a a+ a+a+ + a.) 13 Tabular parsing Nondeterministic push-down automata can be realised efficiently using parse tables [1]. A parse table consists of sets Ti,j of items, for 0 &lt; i &lt; j &lt; n, where al . • • an represents the input. The idea is that an item is only stored in a set Tid if the item represents recognition of the part of the input ai+i ai. We will first discuss a tabular form of CP parsing, since this is the most simple parsing technique discussed above. We will then move on to the more difficult ELR technique. Tabular PLR parsing is fairly straightforward and will not be discussed in this paper. Tabular CP parsing CP parsing has the following tabular realization: Algorithm 5 (Tabular common-prefix) Sets</context>
<context position="30607" citStr="[1, 12, 7]" startWordPosition="5944" endWordPosition="5946">e grammar. If, on the other hand, the grammar is very ambiguous such that even LR parsing is very nondeterministic, then the tabular realisation may at worst add each state to each set Ti,j, so that the more states there are, the more work the parser needs to do. This favours simple algorithms such as LC over more sophisticated ones such as LR. Furthermore, if more than one state represents the same subderivation, then computation of that subderivation may be done more than once, which leads to parse forests (compact representations of collections of parse trees) which are not optimally dense [1, 12, 7]. Schabes proposes to tune a parser to a grammar, or in other words, to use a combination of parsing techniques in order to find an optimal parser for a certain grammar.7 This idea has until now not been realised. However, when we try to find a single parsing algorithm which performs well for all grammars, then the tabular ELR algorithm we have presented may be a serious candidate, for the following reasons: • For all i, j, and a at most one item of the form [A a] is added to Ti,j. Therefore, identical subderivations are not computed more than once. (This is a consequence of our optimization i</context>
</contexts>
<marker>[1]</marker>
<rawString>S. Billot and B. Lang. The structure of shared forests in ambiguous parsing. In 27th Annual Meeting of the ACL, 143-151, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>The computational complexity of GLR parsing.</title>
<date>1991</date>
<booktitle>Generalized LR Parsing, chapter 3,</booktitle>
<pages>35--42</pages>
<editor>In M. Tomita, editor,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="29640" citStr="[2]" startWordPosition="5778" endWordPosition="5778">hat LC itself can be obtained by determinizing TD parsing. (In lieu of TD parsing he mentions Earley&apos;s algorithm, which is its tabular realisation.) We conclude that we have a family consisting of LC, PLR, ELR, and LR parsing, which are increasingly deterministic. In general, the more deterministic an algorithm is, the more parser states it requires. For example, the LC algorithm requires a number of states (the items in /LC) which is linear in the size of the grammar. By contrast, the LR algorithm requires a number of states (the sets of items) which is exponential in the size of the grammar [2]. The differences in the number of states complicates the choice of a tabular algorithm as the one giving optimal behaviour for all grammars. If a grammar is very simple, then a sophisticated algorithm such as LR may allow completely deterministic parsing, which requires a linear number of entries to be added to the parse table, measured in the size of the grammar. If, on the other hand, the grammar is very ambiguous such that even LR parsing is very nondeterministic, then the tabular realisation may at worst add each state to each set Ti,j, so that the more states there are, the more work the</context>
</contexts>
<marker>[2]</marker>
<rawString>M. Johnson. The computational complexity of GLR parsing. In M. Tomita, editor, Generalized LR Parsing, chapter 3, 35-42. Kluwer Academic Publishers, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>Complete evaluation of Horn clauses: An automata theoretic approach.</title>
<date>1988</date>
<booktitle>Rapport de Recherche 913, Institut National de Recherche en Informatique et en Automatique,</booktitle>
<location>Rocquencourt, France,</location>
<contexts>
<context position="16495" citStr="[3]" startWordPosition="3090" endWordPosition="3090">terministic ELR(0) algorithm that we describe below, derived from the formulation of ELR parsing in [5]. First, we define a set of items as / = {[A --+ a • 0] A a0 E Pt} Note that /Lc c I. If we define for each Q C I: closure(Q) Q U {[A &amp;quot; • al I [B-40•C-y]EQAAL*C} then the goto function for LR(0) parsing is defined by goto(Q, X) --,- closure({[A aX • 0] [A --+ a • X13] E Q}) For ELR parsing however, we need two goto functions, gotoi and goto2, one for kernel items (i.e. those in IW) and one for nonkernel items (the others). These are defined by gotoi(Q, X) = closure({[A -&gt; aX • (3] I [A -&gt; a X[3] E Q A (a E VA =S&apos;)}) goto2(Q, X) = closure({[A -+ x • p] I [A-+•X0]EQAA S&apos;}) At each shift (where X is some terminal) and each reduce with some rule A -&gt; a (where X is A) we may nondeterministically apply gotoi, which corresponds with case a), or goto2, which corresponds with case b). Of course, one or both may not be defined on Q and X, because goto(Q, X) may be 0, for i E {1, 2}. Now remark that when using gotoi and goto2, each reachable set of items contains only items of the form A -&gt; a • 0, for some fixed string a, plus some nonkernel items. We will ignore the nonkernel items since they </context>
<context position="24897" citStr="[3]" startWordPosition="4851" endWordPosition="4851">es an interesting example of how a tabular algorithm can have a property not shared by its nondeterministic origin.5 First note that we can compute the columns of a parse table strictly from left to right, that is, for fixed i we can compute all sets T3,i. before we compute the sets If we formulate a tabular ELR algorithm in a naive way analogously to Algorithm 5, as is done in [5], then for example the first clause is given by: 1. Add [A&apos; —&gt; a] to for a = ai and [A —&gt; )3] E Tj,i—t where A&apos; = {A I 3A aa, B OC-y E Pt[B E A A A 7* C]} is non-empty 5This is reminiscent of the admissibility tests [3], which are applicable to tabular realisations of logical push-down automata, but not to these automata themselves. However, for certain i there may be many [A —&gt; 0] E for some j, and each may give rise to a different A&apos; which is non-empty. In this way, Clause 1 may add several items [A&apos; —&gt; a] to some possibly with overlapping sets A&apos;. Since items represent computation of subderivations, the algorithm may therefore compute the same subderivation several times. We propose an optimization which makes use of the fact that all possible items [A —&gt; 0] E T3,i_i are already present when we compute it</context>
</contexts>
<marker>[3]</marker>
<rawString>B. Lang. Complete evaluation of Horn clauses: An automata theoretic approach. Rapport de Recherche 913, Institut National de Recherche en Informatique et en Automatique, Rocquencourt, France, November 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lankhorst</author>
</authors>
<title>An empirical comparison of generalized LR tables. In</title>
<date>1991</date>
<journal>Memoranda Informatica</journal>
<booktitle>Tomita&apos;s Algorithm: Extensions and Applications, Proc. of the first Twente Workshop on Language Technology,</booktitle>
<pages>87--93</pages>
<editor>R. Heemels, A. Nijholt, and K. Sikkel, editors,</editor>
<institution>University of Twente,</institution>
<contexts>
<context position="4945" citStr="[1, 4]" startWordPosition="819" endWordPosition="820">rmore, the parse forest (a compact representation of all parse trees) which is output by a tabular algorithm may in this case not be optimally dense. We conclude that we have a tradeoff between the case that the grammar allows almost deterministic parsing and the case that the stack algorithm is very nondeterministic for a certain grammar. In the former case, sophistication leads to less entries in the table, and in the latter case, sophistication leads to more entries, provided this sophistication is realised by an increase in the number of states. This is corroborated by empirical data from [1, 4], which deal with tabular LR parsing. As we will explain, CP and ELR parsing are more deterministic than most other parsing algorithms for many grammars, but their tabular realizations can never compute the same subderivation twice. This represents an optimum in a range of possible parsing algorithms. This paper is organized as follows. First we discuss nondeterministic left-corner parsing, and demonstrate how common prefixes in a grammar may be a source of bad performance for this technique. Then, a multitude of parsing techniques which exhibit better treatment of common prefixes is discussed</context>
</contexts>
<marker>[4]</marker>
<rawString>M. Lankhorst. An empirical comparison of generalized LR tables. In R. Heemels, A. Nijholt, and K. Sikkel, editors, Tomita&apos;s Algorithm: Extensions and Applications, Proc. of the first Twente Workshop on Language Technology, 87-93. University of Twente, September 1991. Memoranda Informatica 91-68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
</authors>
<title>Generalized left-corner parsing.</title>
<date>1993</date>
<booktitle>In Sixth Conference of the European Chapter of the ACL,</booktitle>
<pages>305--314</pages>
<contexts>
<context position="1447" citStr="[7]" startWordPosition="232" endWordPosition="232">two entries represent the same subderivation. Introduction Left-corner (LC) parsing is a parsing strategy which has been used in different guises in various areas of computer science. Deterministic LC parsing with k symbols of lookahead can handle the class of LC(k) grammars. Since LC parsing is a very simple parsing technique and at the same time is able to deal with left recursion, it is often used as an alternative to top-down (TD) parsing, which cannot handle left recursion and is generally less efficient. Nondeterministic LC parsing is the foundation of a very efficient parsing algorithm [7], related to Tomita&apos;s algorithm and Earley&apos;s algorithm. It has one disadvantage however, which becomes noticeable when the grammar contains many rules whose right-hand sides begin with the same few grammars symbols, e.g. A a/31 Iath ... where a is not the empty string. After an LC parser has recognized the first symbol X of such an a, it will as next step predict all aforementioned rules. This amounts to much nondeterminism, which is detrimental both to the time-complexity and the space-complexity. *Supported by the Dutch Organisation for Scientific Research (NWO), under grant 00-62-518 A firs</context>
<context position="8503" citStr="[7]" startWordPosition="1475" endWordPosition="1475">F, v), where r E Alph* is the stack, constructed from left to right, and v E T* is the remaining input. The initial configuration is (Init, w), where mit E Alph is a distinguished stack symbol, and w is the input. The steps of an automaton are specified by means of the relation H. Thus, (r,v) H (F&apos;, v&apos;) denotes that (r&apos;, is obtainable from (r, v) by one step of the automaton. The reflexive and transitive closure of H is denoted by I-4. The input w is accepted if (Init, w) H* (Fine), where Fin E Alph is a distinguished stack symbol. LC parsing For the definition of left-corner (LC) recognition [7] we need stack symbols (items) of the form [A —&gt; a • 0], where A a0 is a rule, and a E. (Remember that we do not allow epsilon rules.) The informal meaning of an item is &amp;quot;The part before the dot has just been recognized, the first symbol after the dot is to be recognized next&amp;quot;. For technical reasons we also need the items [S&apos; • S] and [S&apos; S s], where S&apos; is a fresh symbol. Formally: &apos;Lc {[A 0] A a0 E Pt A(a EVA --= S&apos;)} where Pt represents the augmented set of rules, consisting of the rules in P plus the extra rule S&apos; --+ S. Algorithm 1 (Left-corner) ALC = (T, I&apos;&apos;, Init,H , Fin), mit [S&apos; • S], </context>
<context position="30607" citStr="[1, 12, 7]" startWordPosition="5944" endWordPosition="5946">e grammar. If, on the other hand, the grammar is very ambiguous such that even LR parsing is very nondeterministic, then the tabular realisation may at worst add each state to each set Ti,j, so that the more states there are, the more work the parser needs to do. This favours simple algorithms such as LC over more sophisticated ones such as LR. Furthermore, if more than one state represents the same subderivation, then computation of that subderivation may be done more than once, which leads to parse forests (compact representations of collections of parse trees) which are not optimally dense [1, 12, 7]. Schabes proposes to tune a parser to a grammar, or in other words, to use a combination of parsing techniques in order to find an optimal parser for a certain grammar.7 This idea has until now not been realised. However, when we try to find a single parsing algorithm which performs well for all grammars, then the tabular ELR algorithm we have presented may be a serious candidate, for the following reasons: • For all i, j, and a at most one item of the form [A a] is added to Ti,j. Therefore, identical subderivations are not computed more than once. (This is a consequence of our optimization i</context>
<context position="32173" citStr="[7]" startWordPosition="6214" endWordPosition="6214">of all common prefixes. It is hard to imagine a practical parsing technique more deterministic than ELR parsing which also satisfies the previous two properties. In particular, we argue in [8] that refinement of the LR technique in such a way that the first property above holds whould require an impractically large number of LR states. &apos;This is reminiscent of the idea of &amp;quot;optimal cover&amp;quot; [5]. 123 Epsilon rules Epsilon rules cause two problems for bottom-up parsing. The first is non-termination for simple realisations of nondeterminism (such as backtrack parsing) caused by hidden left recursion [7]. The second problem occurs when we optimize TD filtering e.g. using the sets Si: it is no longer possible to completely construct a set Si before it is used, because the computation of a derivation deriving the empty string requires Si for TD filtering but at the same time its result causes new elements to be added to Si. Both problems can be overcome [8]. Conclusions We have discussed a range of different parsing algorithms, which have their roots in compiler construction, expression parsing, and natural language processing. We have shown that these algorithms can be described in a common fr</context>
</contexts>
<marker>[7]</marker>
<rawString>M.J. Nederhof. Generalized left-corner parsing. In Sixth Conference of the European Chapter of the ACL, 305-314, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
</authors>
<title>A multidisciplinary approach to a parsing algorithm. In</title>
<date>1993</date>
<booktitle>Natural Language Parsing: Methods and Formalisms, Proc. of the sixth Twente Workshop on Language Technology,</booktitle>
<pages>85--98</pages>
<editor>K. Sikkel and A. Nijholt, editors,</editor>
<institution>University of Twente,</institution>
<contexts>
<context position="27785" citStr="[8]" startWordPosition="5451" endWordPosition="5451">that the tabular ELR algorithm manipulates items of the form [A a] which would not occur in any search path of the nondeterministic ELR algorithm, because in general such a A is the union of many sets A&apos; of items [A&apos; a] which would be manipulated at the same input position by the nondeterministic algorithm in different search paths. With minor differences, the above tabular ELR algorithm is described in [21]. A tabular version of pseudo ELR parsing is presented in [20]. Some useful data structures for practical implementation of tabular and non-tabular PLR, ELR and CP parsing are described in [8]. Finding an optimal tabular algorithm In [14] Schabes derives the LC algorithm from LR parsing similar to the way that ELR parsing can be derived from LR parsing. The LC algorithm is obtained by not only splitting up the goto function into gotoi and goto2 but also splitting up goto2 even further, so that it nondeterministically yields the closure of one single kernel item. (This idea was described earlier in [5], and more recently in [10].) Schabes then argues that the LC algorithm can be determinized (i.e. made more deterministic) by manipulating the goto functions. One application of this i</context>
<context position="31762" citStr="[8]" startWordPosition="6148" endWordPosition="6148">ce. (This is a consequence of our optimization in Algorithm 6.) Note that this also holds for the tabular CP algorithm. • ELR parsing guarantees the correct-prefix property, contrary to the CP algorithm. This prevents computation of all subderivations which are useless with regard to the already processed input. • ELR parsing is more deterministic than LC and PLR parsing, because it allows shared processing of all common prefixes. It is hard to imagine a practical parsing technique more deterministic than ELR parsing which also satisfies the previous two properties. In particular, we argue in [8] that refinement of the LR technique in such a way that the first property above holds whould require an impractically large number of LR states. &apos;This is reminiscent of the idea of &amp;quot;optimal cover&amp;quot; [5]. 123 Epsilon rules Epsilon rules cause two problems for bottom-up parsing. The first is non-termination for simple realisations of nondeterminism (such as backtrack parsing) caused by hidden left recursion [7]. The second problem occurs when we optimize TD filtering e.g. using the sets Si: it is no longer possible to completely construct a set Si before it is used, because the computation of a d</context>
</contexts>
<marker>[8]</marker>
<rawString>M.J. Nederhof. A multidisciplinary approach to a parsing algorithm. In K. Sikkel and A. Nijholt, editors, Natural Language Parsing: Methods and Formalisms, Proc. of the sixth Twente Workshop on Language Technology, 85-98. University of Twente, 1993.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M J Nederhof</author>
<author>G Satta</author>
</authors>
<title>An extended theory of head-driven parsing. In this proceedings.</title>
<contexts>
<context position="5980" citStr="[9]" startWordPosition="979" endWordPosition="979"> a grammar may be a source of bad performance for this technique. Then, a multitude of parsing techniques which exhibit better treatment of common prefixes is discussed. These techniques, including nondeterministic PLR, ELR, and CP parsing, have their origins in theory of deterministic, parallel, and tabular parsing. Subsequently, the application to parallel and tabular parsing is investigated more closely. Further, we briefly describe how rules with empty right-hand sides complicate the parsing process. The ideas described in this paper can be generalized to head-driven parsing, as argued in [9]. We will take some liberty in describing algorithms from the existing literature, since using the original descriptions would blur the similarities of the algorithms to one another. In particular, we will not treat the use of lookahead, and we will consider all algorithms working on a stack to be nondeterministic. We will only describe recognition algorithms. Each of the algorithms can however be easily extended to yield parse trees as a side-effect of recognition. The notation used in the sequel is for the most part standard and is summarised below. A context-free grammar G = (T, N, P, S) co</context>
</contexts>
<marker>[9]</marker>
<rawString>M.J. Nederhof and G. Satta. An extended theory of head-driven parsing. In this proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Oude Luttighuis</author>
<author>K Sikkel</author>
</authors>
<title>Generalized LR parsing and attribute evaluation.</title>
<date>1993</date>
<booktitle>In Third International Workshop on Parsing Technologies,</booktitle>
<pages>219--233</pages>
<institution>Tilburg (The Netherlands) and Durbuy (Belgium),</institution>
<contexts>
<context position="28228" citStr="[10]" startWordPosition="5529" endWordPosition="5529">LR parsing is presented in [20]. Some useful data structures for practical implementation of tabular and non-tabular PLR, ELR and CP parsing are described in [8]. Finding an optimal tabular algorithm In [14] Schabes derives the LC algorithm from LR parsing similar to the way that ELR parsing can be derived from LR parsing. The LC algorithm is obtained by not only splitting up the goto function into gotoi and goto2 but also splitting up goto2 even further, so that it nondeterministically yields the closure of one single kernel item. (This idea was described earlier in [5], and more recently in [10].) Schabes then argues that the LC algorithm can be determinized (i.e. made more deterministic) by manipulating the goto functions. One application of this idea is to take a fixed grammar and choose different goto functions for different parts of the grammar, in order to tune the parser to the grammar. In this section we discuss a different application of this idea: we consider various goto functions which are global, i.e. which are the same for all parts of a grammar. One example is ELR parsing, as its goto2 function can be seen as a determinized version of the goto2 function of LC parsing. I</context>
</contexts>
<marker>[10]</marker>
<rawString>P. Oude Luttighuis and K. Sikkel. Generalized LR parsing and attribute evaluation. In Third International Workshop on Parsing Technologies, 219-233, Tilburg (The Netherlands) and Durbuy (Belgium), August 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C A Brown</author>
</authors>
<title>Parsing extended LR(k) grammars.</title>
<date>1981</date>
<journal>Acta Informatica,</journal>
<pages>15--115</pages>
<contexts>
<context position="14627" citStr="[11]" startWordPosition="2724" endWordPosition="2724"> This requires an LR parser for an extended grammar (an ELR parser) to behave differently from normal LR parsers. The behaviour of a normal LR parser upon a reduction with some rule A -4 a is very simple: it pops la! states from the stack, revealing, say, state Q; it then pushes state goto(Q, A). (We identify a state with its corresponding set of items.) For extended grammars the behaviour upon a reduction cannot be realised in this way since the regular expression of which the rhs is composed may describe strings of various lengths, so that it is unknown how many states need to be popped. In [11] this problem is solved by forcing the parser to decide at each call goto(Q, X) whether a) X is one more symbol of an item in Q of which some symbols have already been recognized, or whether b) X is the first symbol of an item which has been introduced in Q by means of the closure function. In the second case, a state which is a variant of goto(Q, X) is pushed on top of state Q as usual. In the first case, however, state Q on top of the stack is replaced by a variant of goto(Q, X). This is safe since we will never need to return to Q if after some more steps we succeed in recognizing some rule</context>
</contexts>
<marker>[11]</marker>
<rawString>P.W. Purdom, Jr. and C.A. Brown. Parsing extended LR(k) grammars. Acta Informatica, 15:115-127, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rekers</author>
</authors>
<title>Parser Generation for Interactive Environments.</title>
<date>1992</date>
<tech>PhD thesis,</tech>
<institution>University of Amsterdam,</institution>
<contexts>
<context position="30607" citStr="[1, 12, 7]" startWordPosition="5944" endWordPosition="5946">e grammar. If, on the other hand, the grammar is very ambiguous such that even LR parsing is very nondeterministic, then the tabular realisation may at worst add each state to each set Ti,j, so that the more states there are, the more work the parser needs to do. This favours simple algorithms such as LC over more sophisticated ones such as LR. Furthermore, if more than one state represents the same subderivation, then computation of that subderivation may be done more than once, which leads to parse forests (compact representations of collections of parse trees) which are not optimally dense [1, 12, 7]. Schabes proposes to tune a parser to a grammar, or in other words, to use a combination of parsing techniques in order to find an optimal parser for a certain grammar.7 This idea has until now not been realised. However, when we try to find a single parsing algorithm which performs well for all grammars, then the tabular ELR algorithm we have presented may be a serious candidate, for the following reasons: • For all i, j, and a at most one item of the form [A a] is added to Ti,j. Therefore, identical subderivations are not computed more than once. (This is a consequence of our optimization i</context>
</contexts>
<marker>[12]</marker>
<rawString>J. Rekers. Parser Generation for Interactive Environments. PhD thesis, University of Amsterdam, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Rosenkrantz</author>
<author>P M Lewis</author>
</authors>
<title>Deterministic left corner parsing.</title>
<date>1970</date>
<booktitle>In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata Theory,</booktitle>
<pages>139--152</pages>
<contexts>
<context position="10968" citStr="[13]" startWordPosition="2026" endWordPosition="2026"> E T -0 F 41] * a 3 E&apos; --o • E T --o T • * F] * a 4 E&apos; -o • E [T -o T * • F] a 5 E&apos; -0 • E [T --■ T * • F][F --* a .] 6 E&apos; -0 • E [T -o T * F .] 7 E&apos; -o • E E -+ T .] 8 E&apos; -o E • Note that since the automaton does not use any lookahead, Step 3 may also have replaced [T F e] by any other item besides [T -o T • * F] whose rhs starts with T and whose lhs satisfies the condition of topdown filtering with regard to E, i.e. by [T -o T • [E --o T • E], or [E T .]. LC parsing with k symbols of lookahead can handle deterministically the so called LC(k) grammars. This class of grammars is formalized in [13].1 How LC parsing can be improved to handle common suffixes efficiently is discussed in [6]; in this paper we restrict our attention to common prefixes. PLR, ELR, and CP parsing In this section we investigate a number of algorithms which exhibit a better treatment of common prefixes. Predictive LR parsing Predictive LR (PLR) parsing with k symbols of lookahead was introduced in [17] as an algorithm which yields efficient parsers for a subset of the LR(k) grammars [16] and a superset of the LC(k) grammars. How deterministic PLR parsing succeeds in handling a larger class of grammars (the PLR(k)</context>
</contexts>
<marker>[13]</marker>
<rawString>D.J. Rosenkrantz and P.M. Lewis II. Deterministic left corner parsing. In IEEE Conference Record of the 11th Annual Symposium on Switching and Automata Theory, 139-152, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
</authors>
<title>Polynomial time and space shiftreduce parsing of arbitrary context-free grammars.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the ACL,</booktitle>
<pages>106--113</pages>
<contexts>
<context position="27831" citStr="[14]" startWordPosition="5458" endWordPosition="5458">ems of the form [A a] which would not occur in any search path of the nondeterministic ELR algorithm, because in general such a A is the union of many sets A&apos; of items [A&apos; a] which would be manipulated at the same input position by the nondeterministic algorithm in different search paths. With minor differences, the above tabular ELR algorithm is described in [21]. A tabular version of pseudo ELR parsing is presented in [20]. Some useful data structures for practical implementation of tabular and non-tabular PLR, ELR and CP parsing are described in [8]. Finding an optimal tabular algorithm In [14] Schabes derives the LC algorithm from LR parsing similar to the way that ELR parsing can be derived from LR parsing. The LC algorithm is obtained by not only splitting up the goto function into gotoi and goto2 but also splitting up goto2 even further, so that it nondeterministically yields the closure of one single kernel item. (This idea was described earlier in [5], and more recently in [10].) Schabes then argues that the LC algorithm can be determinized (i.e. made more deterministic) by manipulating the goto functions. One application of this idea is to take a fixed grammar and choose diff</context>
</contexts>
<marker>[14]</marker>
<rawString>Y. Schabes. Polynomial time and space shiftreduce parsing of arbitrary context-free grammars. In 29th Annual Meeting of the ACL, 106-113, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sikkel</author>
<author>M Lankhorst</author>
</authors>
<title>A parallel bottomup Tomita parser. In 1. Konferenz &amp;quot;Verarbeitung Natiirlicher Sprache&amp;quot;,</title>
<date>1992</date>
<pages>238--247</pages>
<publisher>Springer-Verlag.</publisher>
<location>Nürnberg,</location>
<contexts>
<context position="23962" citStr="[15]" startWordPosition="4662" endWordPosition="4662">... These labels also indicate the order in which these items are added to the table. CP parsing without top-down filtering (i.e. without the checks concerning the left-corner relation 7*) is the main algorithm in [21]. Without the use of top-down filtering, the references to 0] in Clauses 1 and 3 are clearly not of much use any more. When we also remove the use of these items, then these clauses become: 1. Add [—+ a] to for a = ai where there is A —&gt; aa E PI 3. Add [—+ A] to for a] E where there are A —4 a, D —&gt;A5 E pt In the resulting algorithm, no set depends on any set Tg,h with g &lt; i. In [15] this fact is used to construct a parallel parser with n processors Po, , Pri_1, with each P, processing the sets Ti,i for all j &gt; i. The flow of data is strictly from right to left, i.e. items computed by Pi are only passed on to Po,. • • , Tabular ELR parsing The tabular form of ELR parsing allows an optimization which constitutes an interesting example of how a tabular algorithm can have a property not shared by its nondeterministic origin.5 First note that we can compute the columns of a parse table strictly from left to right, that is, for fixed i we can compute all sets T3,i. before we c</context>
</contexts>
<marker>[15]</marker>
<rawString>K. Sikkel and M. Lankhorst. A parallel bottomup Tomita parser. In 1. Konferenz &amp;quot;Verarbeitung Natiirlicher Sprache&amp;quot;, 238-247, Nürnberg, October 1992. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sippu</author>
<author>E Soisalon-Soininen</author>
</authors>
<title>Parsing Theory, Vol. II: LR(k) and LL(k)</title>
<date>1990</date>
<booktitle>Parsing, EATCS Monographs on Theoretical Computer Science,</booktitle>
<volume>20</volume>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="11440" citStr="[16]" startWordPosition="2107" endWordPosition="2107"> with k symbols of lookahead can handle deterministically the so called LC(k) grammars. This class of grammars is formalized in [13].1 How LC parsing can be improved to handle common suffixes efficiently is discussed in [6]; in this paper we restrict our attention to common prefixes. PLR, ELR, and CP parsing In this section we investigate a number of algorithms which exhibit a better treatment of common prefixes. Predictive LR parsing Predictive LR (PLR) parsing with k symbols of lookahead was introduced in [17] as an algorithm which yields efficient parsers for a subset of the LR(k) grammars [16] and a superset of the LC(k) grammars. How deterministic PLR parsing succeeds in handling a larger class of grammars (the PLR(k) grammars) than the LC(k) grammars can be explained by identifying PLR parsing 1In [171 a different definition of the LC(k) grammars may be found, which is not completely equivalent. for some grammar G with LC parsing for some grammar G&apos; which results after applying a transformation called left-factoring. Left-factoring consists of replacing two or more rules A 011021... with a common prefix a by the rules A aA&apos; and A&apos; -0 011021—, where A&apos; is a fresh nonterminal. The </context>
</contexts>
<marker>[16]</marker>
<rawString>S. Sippu and E. Soisalon-Soininen. Parsing Theory, Vol. II: LR(k) and LL(k) Parsing, EATCS Monographs on Theoretical Computer Science, volume 20. Springer-Verlag, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Soisalon-Soininen</author>
<author>E Ukkonen</author>
</authors>
<title>A method for transforming grammars into LL(k) form.</title>
<date>1979</date>
<journal>Acta Informatica,</journal>
<pages>12--339</pages>
<contexts>
<context position="11353" citStr="[17]" startWordPosition="2092" endWordPosition="2092">own filtering with regard to E, i.e. by [T -o T • [E --o T • E], or [E T .]. LC parsing with k symbols of lookahead can handle deterministically the so called LC(k) grammars. This class of grammars is formalized in [13].1 How LC parsing can be improved to handle common suffixes efficiently is discussed in [6]; in this paper we restrict our attention to common prefixes. PLR, ELR, and CP parsing In this section we investigate a number of algorithms which exhibit a better treatment of common prefixes. Predictive LR parsing Predictive LR (PLR) parsing with k symbols of lookahead was introduced in [17] as an algorithm which yields efficient parsers for a subset of the LR(k) grammars [16] and a superset of the LC(k) grammars. How deterministic PLR parsing succeeds in handling a larger class of grammars (the PLR(k) grammars) than the LC(k) grammars can be explained by identifying PLR parsing 1In [171 a different definition of the LC(k) grammars may be found, which is not completely equivalent. for some grammar G with LC parsing for some grammar G&apos; which results after applying a transformation called left-factoring. Left-factoring consists of replacing two or more rules A 011021... with a comm</context>
</contexts>
<marker>[17]</marker>
<rawString>E. Soisalon-Soininen and E. Ukkonen. A method for transforming grammars into LL(k) form. Acta Informatica, 12:339-369, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language.</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers,</publisher>
<contexts>
<context position="3370" citStr="[18]" startWordPosition="558" endWordPosition="558">o the best of the author&apos;s knowledge, the various parsing algorithms mentioned above have not been discussed together in the existing literature. The main purpose of this paper is to make explicit the connections between these algorithms. A second purpose of this paper is to show that CP and ELR parsing are obvious solutions to a problem of tabular parsing which can be described as follows. For each parsing algorithm working on a stack there is a realisation using a parse table, where the parse table allows sharing of computation between different search paths. For example, Tomita&apos;s algorithm [18] can be seen as a tabular realisation of nondeterministic LR parsing. At this point we use the term state to indicate the symbols occurring on the stack of the original algorithm, which also occur as entries in the parse table of its tabular realisation. In general, powerful algorithms working on a stack lead to efficient tabular parsing algorithms, provided the grammar can be handled almost deterministically. In case the stack algorithm is very nondeterministic for a certain grammar however, sophistication which increases the number of states may lead to an increasing number of entries in the</context>
</contexts>
<marker>[18]</marker>
<rawString>M. Tomita. Efficient Parsing for Natural Language. Kluwer Academic Publishers, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Voisin</author>
</authors>
<title>CIGALE: A tool for interactive grammar construction and expression parsing.</title>
<date>1986</date>
<journal>Science of Computer Programming,</journal>
<pages>7--61</pages>
<contexts>
<context position="20499" citStr="[19]" startWordPosition="3940" endWordPosition="3940">--&gt; i3C-y E Pt such that A L* C 2. (r[. a], av) F (r[-, aa], v) where there is A aaf3 E pt 3. (r[-. o][,- a], v) F (F[-&gt; 0]-&gt; A], v) where there are A a, D -4 AS, B OC E Pt such that D L* C 4. (r[--+ o][, a], v) F (r[.-4 v) where there are A a, B -&gt; 3A7 E Pt The simplification which leads to the CP algorithm inevitably causes the correct-prefix property to be lost. Example 4 Consider again the grammar from Example 1. It is clear that a+a j a is not a correct string according to this grammar. The CP algorithm may go through the following sequence of configurations: 2An attempt has been made in [19] but this paper does not describe the algorithm in its full generality. 3The original algorithm in [21] applies an optimization concerning unit rules, irrelevant to our discussion. 1 {H —&gt; a] al-ala —+] -Fala 2 -H[—&gt; -Fala F] 3 -•-• -&gt; T] -Fala 4 --d -4 El +ala 5 _.4] - ■ E -I- ala 6 -- -&gt; .E + [-- a] I a 7 -H .E + [-&gt; F] 1 a 8 [--■][— E +][.- T] I a 9 -4 -■E-F[ --*TT] a 10 --- ---&gt; E + [-* T T][- a] We see that in Step 9 the first incorrect symbol I is read, but recognition then continues. Eventually, the recognition process is blocked in some unsuccessful configuration, which is guaranteed t</context>
</contexts>
<marker>[19]</marker>
<rawString>F. Voisin. CIGALE: A tool for interactive grammar construction and expression parsing. Science of Computer Programming, 7:61-86, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Voisin</author>
</authors>
<title>A bottom-up adaptation of Earley&apos;s parsing algorithm.</title>
<date>1988</date>
<booktitle>In Programming Languages Implementation and Logic Programming, International Workshop, LNCS 348,</booktitle>
<pages>146--160</pages>
<publisher>Springer-Verlag.</publisher>
<location>Orleans, France,</location>
<contexts>
<context position="19139" citStr="[20]" startWordPosition="3670" endWordPosition="3670">T ID] and [E -+ T • I E], so that nondeterminism is even further reduced. A simplified ELR algorithm, which we call the pseudo ELR algorithm, results from avoiding reference to A in Clauses 1 and 3. In Clause 1 we then have a simplified definition of A&apos;, viz. A&apos; = {A I 3A -&gt; aa, B -&gt; /3C E Pt [A L* C]} , and in the same way we have in Clause 3 the new definition A&amp;quot; = {D 3D Ab, B -&gt; OC -y E Pt[D L* C]l. Pseudo ELR parsing can be more easily realised than full ELR parsing, but the correct-prefix property can no longer be guaranteed. Pseudo ELR parsing is the foundation of a tabular algorithm in [20]. Common-prefix parsing One of the more complicated aspects of the ELR algorithm is the treatment of the sets of nonterminals in the left-hand sides of items. A drastically simplified algorithm is the basis of a tabular algorithm in [21]. Since in [21] the algorithm itself is not described but only its tabular realisation,2 we take the liberty of giving this algorithm our own name: common-prefix (CP) parsing, since it treats all rules with a common prefix simultaneously.3 The simplification consists of omitting the sets of nonterminals in the left-hand sides of items: /GP {[- cf] I A a 0 E Pt}</context>
<context position="27655" citStr="[20]" startWordPosition="5431" endWordPosition="5431">ith A E A&apos;, and A&amp;quot; =- ID I D —4 Ab E Pt} n s; is non-empty which may lead to more practical implementations. Note that we may have that the tabular ELR algorithm manipulates items of the form [A a] which would not occur in any search path of the nondeterministic ELR algorithm, because in general such a A is the union of many sets A&apos; of items [A&apos; a] which would be manipulated at the same input position by the nondeterministic algorithm in different search paths. With minor differences, the above tabular ELR algorithm is described in [21]. A tabular version of pseudo ELR parsing is presented in [20]. Some useful data structures for practical implementation of tabular and non-tabular PLR, ELR and CP parsing are described in [8]. Finding an optimal tabular algorithm In [14] Schabes derives the LC algorithm from LR parsing similar to the way that ELR parsing can be derived from LR parsing. The LC algorithm is obtained by not only splitting up the goto function into gotoi and goto2 but also splitting up goto2 even further, so that it nondeterministically yields the closure of one single kernel item. (This idea was described earlier in [5], and more recently in [10].) Schabes then argues that</context>
</contexts>
<marker>[20]</marker>
<rawString>F. Voisin. A bottom-up adaptation of Earley&apos;s parsing algorithm. In Programming Languages Implementation and Logic Programming, International Workshop, LNCS 348, 146-160, Orleans, France, May 1988. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Voisin</author>
<author>J-C Raoult</author>
</authors>
<title>A new, bottom-up, general parsing algorithm.</title>
<date>1990</date>
<journal>BIGRE,</journal>
<pages>70--221</pages>
<contexts>
<context position="19376" citStr="[21]" startWordPosition="3710" endWordPosition="3710">definition of A&apos;, viz. A&apos; = {A I 3A -&gt; aa, B -&gt; /3C E Pt [A L* C]} , and in the same way we have in Clause 3 the new definition A&amp;quot; = {D 3D Ab, B -&gt; OC -y E Pt[D L* C]l. Pseudo ELR parsing can be more easily realised than full ELR parsing, but the correct-prefix property can no longer be guaranteed. Pseudo ELR parsing is the foundation of a tabular algorithm in [20]. Common-prefix parsing One of the more complicated aspects of the ELR algorithm is the treatment of the sets of nonterminals in the left-hand sides of items. A drastically simplified algorithm is the basis of a tabular algorithm in [21]. Since in [21] the algorithm itself is not described but only its tabular realisation,2 we take the liberty of giving this algorithm our own name: common-prefix (CP) parsing, since it treats all rules with a common prefix simultaneously.3 The simplification consists of omitting the sets of nonterminals in the left-hand sides of items: /GP {[- cf] I A a 0 E Pt} A1jjorithm 4 (Common-prefix) A = (T, I c P , , Fin), mit = [-H, Fin = S], and I- defined by: 1. (rl, 0], av) F (r[, o][, a], v) where there are A -&gt; aa, B --&gt; i3C-y E Pt such that A L* C 2. (r[. a], av) F (r[-, aa], v) where there is A </context>
<context position="20602" citStr="[21]" startWordPosition="3957" endWordPosition="3957">,- a], v) F (F[-&gt; 0]-&gt; A], v) where there are A a, D -4 AS, B OC E Pt such that D L* C 4. (r[--+ o][, a], v) F (r[.-4 v) where there are A a, B -&gt; 3A7 E Pt The simplification which leads to the CP algorithm inevitably causes the correct-prefix property to be lost. Example 4 Consider again the grammar from Example 1. It is clear that a+a j a is not a correct string according to this grammar. The CP algorithm may go through the following sequence of configurations: 2An attempt has been made in [19] but this paper does not describe the algorithm in its full generality. 3The original algorithm in [21] applies an optimization concerning unit rules, irrelevant to our discussion. 1 {H —&gt; a] al-ala —+] -Fala 2 -H[—&gt; -Fala F] 3 -•-• -&gt; T] -Fala 4 --d -4 El +ala 5 _.4] - ■ E -I- ala 6 -- -&gt; .E + [-- a] I a 7 -H .E + [-&gt; F] 1 a 8 [--■][— E +][.- T] I a 9 -4 -■E-F[ --*TT] a 10 --- ---&gt; E + [-* T T][- a] We see that in Step 9 the first incorrect symbol I is read, but recognition then continues. Eventually, the recognition process is blocked in some unsuccessful configuration, which is guaranteed to happen for any incorrect input4. In general however, after reading the first incorrect symbol, the al</context>
<context position="23576" citStr="[21]" startWordPosition="4574" endWordPosition="4574">(9) [—&gt; T E] 2 [—IF] [—FT] 3 0 0 a] (10) 4 [—&gt; F] [—&gt; T] [—*E] Figure 1: Tabular CP parsing Consider again the grammar from Example 1 and the (incorrect) input a + a a. After execution of the tabular common-prefix algorithm, the table is as given here. The sets are given at the j-th row and i-th column. The items which correspond with those from Example 4 are labelled with (0), (1), ... These labels also indicate the order in which these items are added to the table. CP parsing without top-down filtering (i.e. without the checks concerning the left-corner relation 7*) is the main algorithm in [21]. Without the use of top-down filtering, the references to 0] in Clauses 1 and 3 are clearly not of much use any more. When we also remove the use of these items, then these clauses become: 1. Add [—+ a] to for a = ai where there is A —&gt; aa E PI 3. Add [—+ A] to for a] E where there are A —4 a, D —&gt;A5 E pt In the resulting algorithm, no set depends on any set Tg,h with g &lt; i. In [15] this fact is used to construct a parallel parser with n processors Po, , Pri_1, with each P, processing the sets Ti,i for all j &gt; i. The flow of data is strictly from right to left, i.e. items computed by Pi are o</context>
<context position="27593" citStr="[21]" startWordPosition="5420" endWordPosition="5420">-empty 3. Add [A&amp;quot; Al to for [A&apos; a] E where there is A a E Pt with A E A&apos;, and A&amp;quot; =- ID I D —4 Ab E Pt} n s; is non-empty which may lead to more practical implementations. Note that we may have that the tabular ELR algorithm manipulates items of the form [A a] which would not occur in any search path of the nondeterministic ELR algorithm, because in general such a A is the union of many sets A&apos; of items [A&apos; a] which would be manipulated at the same input position by the nondeterministic algorithm in different search paths. With minor differences, the above tabular ELR algorithm is described in [21]. A tabular version of pseudo ELR parsing is presented in [20]. Some useful data structures for practical implementation of tabular and non-tabular PLR, ELR and CP parsing are described in [8]. Finding an optimal tabular algorithm In [14] Schabes derives the LC algorithm from LR parsing similar to the way that ELR parsing can be derived from LR parsing. The LC algorithm is obtained by not only splitting up the goto function into gotoi and goto2 but also splitting up goto2 even further, so that it nondeterministically yields the closure of one single kernel item. (This idea was described earlie</context>
</contexts>
<marker>[21]</marker>
<rawString>F. Voisin and J.-C. Raoult. A new, bottom-up, general parsing algorithm. BIGRE, 70:221-235, September 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>How to cover a grammar.</title>
<date>1989</date>
<booktitle>In 27th Annual Meeting of the ACL,</booktitle>
<pages>135--142</pages>
<contexts>
<context position="15428" citStr="[5]" startWordPosition="2888" endWordPosition="2888"> the first symbol of an item which has been introduced in Q by means of the closure function. In the second case, a state which is a variant of goto(Q, X) is pushed on top of state Q as usual. In the first case, however, state Q on top of the stack is replaced by a variant of goto(Q, X). This is safe since we will never need to return to Q if after some more steps we succeed in recognizing some rule corresponding with one of the items in Q. A consequence of the action in the first case is that upon reduction we need to pop only one state off the stack. Further work in this area is reported in [5], which treats nondeterministic ELR parsing and therefore does not regard it as an obstacle if a choice between cases a) and b) cannot be uniquely made. We are not concerned with extended context-free grammars in this paper. However, a very interesting algorithm results from ELR parsing if we restrict its application to ordinary context-free grammars. (We will maintain the name &amp;quot;extended LR&amp;quot; to stress the origin of the algorithm.) This results in the new nondeterministic ELR(0) algorithm that we describe below, derived from the formulation of ELR parsing in [5]. First, we define a set of items</context>
<context position="22728" citStr="[5]" startWordPosition="4403" endWordPosition="4403">. Perform one of the following steps until no more items can be added. 1. Add [-&gt; a] to for a = ai and [-&gt; 0] E where there are A ---&gt; aa, B flCy E Pt such that A L* C 2. Add aa] to T3, for a = ai and [-&gt; a] E where there is A •-■ aa/3 E Pt 3. Add [-+ A] to for a] E and [---4 0] E Th, where there are A -+ a, D -4 AS, B -&gt; /3C &apos;y Pt such that D L* C 4. Add [-+ OA] to Th,,i for [-&gt; a] E Tbi and [--4 0] E Th,3 where there are A a, B 3 A-y E Pt Report recognition of the input if S] E To,n. For an example, see Figure 1. Tabular CP parsing is related to a variant of CYK parsing with TD filtering in [5]. A form of tabular &apos;unless the grammar is cyclic, in which case the parser may not terminate, both on correct and on incorrect input 121 1 2 3 4 5 [—&gt;1 (0) [---+ a] (1) [—&gt; E H(5) [—&gt; E T] 0 [—F} [—E] 0 0 [—*T] [—+E] 1 0 0 0 0 [--■ a] (6) T 11(9) [—&gt; T E] 2 [—IF] [—FT] 3 0 0 a] (10) 4 [—&gt; F] [—&gt; T] [—*E] Figure 1: Tabular CP parsing Consider again the grammar from Example 1 and the (incorrect) input a + a a. After execution of the tabular common-prefix algorithm, the table is as given here. The sets are given at the j-th row and i-th column. The items which correspond with those from Example </context>
<context position="24678" citStr="[5]" startWordPosition="4799" endWordPosition="4799"> Ti,i for all j &gt; i. The flow of data is strictly from right to left, i.e. items computed by Pi are only passed on to Po,. • • , Tabular ELR parsing The tabular form of ELR parsing allows an optimization which constitutes an interesting example of how a tabular algorithm can have a property not shared by its nondeterministic origin.5 First note that we can compute the columns of a parse table strictly from left to right, that is, for fixed i we can compute all sets T3,i. before we compute the sets If we formulate a tabular ELR algorithm in a naive way analogously to Algorithm 5, as is done in [5], then for example the first clause is given by: 1. Add [A&apos; —&gt; a] to for a = ai and [A —&gt; )3] E Tj,i—t where A&apos; = {A I 3A aa, B OC-y E Pt[B E A A A 7* C]} is non-empty 5This is reminiscent of the admissibility tests [3], which are applicable to tabular realisations of logical push-down automata, but not to these automata themselves. However, for certain i there may be many [A —&gt; 0] E for some j, and each may give rise to a different A&apos; which is non-empty. In this way, Clause 1 may add several items [A&apos; —&gt; a] to some possibly with overlapping sets A&apos;. Since items represent computation of subder</context>
<context position="28201" citStr="[5]" startWordPosition="5524" endWordPosition="5524">abular version of pseudo ELR parsing is presented in [20]. Some useful data structures for practical implementation of tabular and non-tabular PLR, ELR and CP parsing are described in [8]. Finding an optimal tabular algorithm In [14] Schabes derives the LC algorithm from LR parsing similar to the way that ELR parsing can be derived from LR parsing. The LC algorithm is obtained by not only splitting up the goto function into gotoi and goto2 but also splitting up goto2 even further, so that it nondeterministically yields the closure of one single kernel item. (This idea was described earlier in [5], and more recently in [10].) Schabes then argues that the LC algorithm can be determinized (i.e. made more deterministic) by manipulating the goto functions. One application of this idea is to take a fixed grammar and choose different goto functions for different parts of the grammar, in order to tune the parser to the grammar. In this section we discuss a different application of this idea: we consider various goto functions which are global, i.e. which are the same for all parts of a grammar. One example is ELR parsing, as its goto2 function can be seen as a determinized version of the goto</context>
<context position="31963" citStr="[5]" startWordPosition="6183" endWordPosition="6183">m. This prevents computation of all subderivations which are useless with regard to the already processed input. • ELR parsing is more deterministic than LC and PLR parsing, because it allows shared processing of all common prefixes. It is hard to imagine a practical parsing technique more deterministic than ELR parsing which also satisfies the previous two properties. In particular, we argue in [8] that refinement of the LR technique in such a way that the first property above holds whould require an impractically large number of LR states. &apos;This is reminiscent of the idea of &amp;quot;optimal cover&amp;quot; [5]. 123 Epsilon rules Epsilon rules cause two problems for bottom-up parsing. The first is non-termination for simple realisations of nondeterminism (such as backtrack parsing) caused by hidden left recursion [7]. The second problem occurs when we optimize TD filtering e.g. using the sets Si: it is no longer possible to completely construct a set Si before it is used, because the computation of a derivation deriving the empty string requires Si for TD filtering but at the same time its result causes new elements to be added to Si. Both problems can be overcome [8]. Conclusions We have discussed </context>
</contexts>
<marker>[5]</marker>
<rawString>R. Leermakers. How to cover a grammar. In 27th Annual Meeting of the ACL, 135-142, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>A recursive ascent Earley parser.</title>
<date>1992</date>
<journal>Information Processing Letters,</journal>
<pages>41--2</pages>
<contexts>
<context position="11059" citStr="[6]" startWordPosition="2043" endWordPosition="2043">T --■ T * • F][F --* a .] 6 E&apos; -0 • E [T -o T * F .] 7 E&apos; -o • E E -+ T .] 8 E&apos; -o E • Note that since the automaton does not use any lookahead, Step 3 may also have replaced [T F e] by any other item besides [T -o T • * F] whose rhs starts with T and whose lhs satisfies the condition of topdown filtering with regard to E, i.e. by [T -o T • [E --o T • E], or [E T .]. LC parsing with k symbols of lookahead can handle deterministically the so called LC(k) grammars. This class of grammars is formalized in [13].1 How LC parsing can be improved to handle common suffixes efficiently is discussed in [6]; in this paper we restrict our attention to common prefixes. PLR, ELR, and CP parsing In this section we investigate a number of algorithms which exhibit a better treatment of common prefixes. Predictive LR parsing Predictive LR (PLR) parsing with k symbols of lookahead was introduced in [17] as an algorithm which yields efficient parsers for a subset of the LR(k) grammars [16] and a superset of the LC(k) grammars. How deterministic PLR parsing succeeds in handling a larger class of grammars (the PLR(k) grammars) than the LC(k) grammars can be explained by identifying PLR parsing 1In [171 a d</context>
<context position="17677" citStr="[6, a]" startWordPosition="3342" endWordPosition="3343">kernel items since they can be derived from the kernel items by means of the closure function. This suggests representing each set of items by a new kind of item of the form [{A1, A2, , An} --+ a], which represents all items A -&gt; a • 0 for some 0 and A E {Ai, A2, An}. Formally: TELR = {[A-&gt;allOCAC{AIA-&gt; a0 E Pt} A (a V Z = {S&apos;})} where we use the symbol A to range over sets of nonterminals. Algorithm 3 (Extended LR) AELR = (T, IELR Fin), Mit = [{S&apos;} -+], Fin = [{S&apos;} S], and F- defined by: 1. (F[A 0], av) F- (r[6. o][A&apos; a], v) where A&apos; = {A I 3A ---&gt; acy, B i3C7 E A A A 7* CD is non-empty 2. (r[6, a], av) H (F[A&apos; aa], v) where A&apos; = {A EAI A -4 aa/3 E Pt} is non-empty 3. (r[A #][A&apos; -* a], v) (F[A /3][A&amp;quot; -4 A], v) where there is A -4 a E Pt with A E A&apos;, and A&amp;quot; = {D I 3D -&gt; A6, B 0C-y E Pt[B E AAD L* Cif is non-empty 4. (r[6. -+ a], v) H (F[A&amp;quot; -&gt; 0A], v) where there is A -&gt; a E Pt with A E A&apos;, and A&amp;quot; E A I /3 -&gt; 0A-y E Pt} is non-empty Note that Clauses 1 and 3 correspond with goto2 and that Clauses 2 and 4 correspond with goto1. Example 3 Consider again the grammar from Example 1. Using the ELR algorithm, recognition of a * a is realised by: [{E&apos;} [{E&apos;} ][{F} -&gt; a] [{E&apos;} --+ ][{T} F] [{E&apos;} </context>
</contexts>
<marker>[6]</marker>
<rawString>R. Leermakers. A recursive ascent Earley parser. Information Processing Letters, 41(2):87-91, February 1992.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>