<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.108670">
<title confidence="0.935844">
Computational psycholinguistics
</title>
<author confidence="0.981885">
Roger Levy, Klinton Bicknell, and Nathaniel Smith
</author>
<affiliation confidence="0.991325">
University of California, San Diego
</affiliation>
<sectionHeader confidence="0.58879" genericHeader="abstract">
1. Brief Description
</sectionHeader>
<bodyText confidence="0.999835615384615">
Over the last two decades, computational linguistics has been revolutionized as a result
of three closely related developments, two empirical and one theoretical: increases in
computing power, the new availability of large linguistic datasets, and a paradigm shift
toward the view that language processing by computers is best approached through the
tools of statistical inference. During roughly the same time frame, there have been
similar theoretical developments in cognitive psychology towards a view of major
aspects of human cognition as instances of rational statistical inference. Developments
in these two fields have set the stage for renewed interest in computational approaches
to human language processing. In this tutorial, we briefly survey some of the key
theoretical issues at the forefront of this interdisciplinary field today, and show how
modeling techniques from NLP are being employed, extended, and coupled with
experimental techniques from psycholinguistics to further our understanding of real-time
human language use.
</bodyText>
<listItem confidence="0.9927433125">
2. Tutorial structure
1. Introduction &amp; summary of current state of key areas in psycholinguistics
(a) Key empirical findings involving ambiguity resolution, prediction, integration of
diverse information sources, and speaker choice in real-time language comprehen-
sion and production (-10 minutes)
(b) Framing of empirical findings and concomitant theoretical issues in terms that
can be cleanly related to leading NLP models and algorithms (-10 minutes)
2. Review of exact inference techniques for stochastic grammatical formalisms
(a) Weighted finite-state automata and context-free grammars (-10 minutes)
(b) Probabilistic Earley algorithm (-10 minutes)
(c) Weighted intersection of FSA and CFG (-10 minutes)
3. Modeling key results in ambiguity resolution and expectation-based facilitation
(a) Global disambiguation preferences (-5 minutes)
(b) Measuring online processing difficulty: intro to self-paced reading (-5 minutes)
(c) Expectation-based facilitation in unambiguous contexts (-5–10 minutes)
4. Coffee break
</listItem>
<page confidence="0.866167">
19
</page>
<listItem confidence="0.993871761904762">
5. Online production: speaker choice
(a) Zipfʼs second law (frequency &amp; word length) and information-theoretic interpre-
tations (∼10 minutes)
(b) Phonetic duration &amp; reduction effects in online word production (∼5 minutes)
(c) Morphological- and lexical-level reduction phenomena: modeling and empirical
investigation (∼10 minutes)
6. Cognitive limitations and implications for modeling
(a) Memory limitations &amp; garden pathing: empirical results (∼10 minutes)
(b) Modeling approach I: incremental beam search &amp; garden pathing (∼5 minutes)
(c) Modeling approach II: stochastic incremental search &amp; “digging-in” effects (∼10
minutes)
7. Additional theoretical challenges
(a) Bounds on rationality in real-time language use? “Good-enough” comprehension
effects and “local-coherence” effects (∼10 minutes)
(b) Possible avenues of attack: more refined models introducing input uncertainty
(∼10 minutes)
(c) More sophisticated experimental tools: eye-tracking (∼5 minutes)
(d) New experimental findings on input uncertainty, “hallucinated” garden paths (∼5
minutes)
(e) Future directions (∼5 minutes)
8. Summary and questions (∼5–10 minutes)
</listItem>
<sectionHeader confidence="0.688241" genericHeader="keywords">
3. Instructor
</sectionHeader>
<bodyText confidence="0.913603545454545">
Roger Levy, rlevy@ling.ucsd.edu
My research focuses on theoretical and applied questions in the processing of natural
language. Inherently, linguistic communication involves the resolution of uncertainty
over a potentially unbounded set of possible signals and meanings. How can a fixed set
of knowledge and resources be deployed to manage this uncertainty? To address these
questions I use a combination of computational modelling and psycholinguistic
experimentation. This work furthers our understanding of the cognitive underpinning of
language processing, and helps us design models and algorithms that will allow
machines to process human language.
Klinton Bicknell and Nathaniel Smith are PhD students at the University of California,
San Diego.
</bodyText>
<page confidence="0.992051">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.416834">
<title confidence="0.923988">Computational psycholinguistics</title>
<author confidence="0.999915">Roger Levy</author>
<author confidence="0.999915">Klinton Bicknell</author>
<author confidence="0.999915">Nathaniel Smith</author>
<affiliation confidence="0.743652">University of California, San Diego 1. Brief Description</affiliation>
<abstract confidence="0.995823153846154">Over the last two decades, computational linguistics has been revolutionized as a result of three closely related developments, two empirical and one theoretical: increases in computing power, the new availability of large linguistic datasets, and a paradigm shift toward the view that language processing by computers is best approached through the tools of statistical inference. During roughly the same time frame, there have been similar theoretical developments in cognitive psychology towards a view of major aspects of human cognition as instances of rational statistical inference. Developments in these two fields have set the stage for renewed interest in computational approaches to human language processing. In this tutorial, we briefly survey some of the key theoretical issues at the forefront of this interdisciplinary field today, and show how modeling techniques from NLP are being employed, extended, and coupled with experimental techniques from psycholinguistics to further our understanding of real-time human language use.</abstract>
<intro confidence="0.97869">2. Tutorial structure</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>