<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9772275">
Pseudo Relevance Feedback Method Based on Taylor Expansion of Re-
trieval Function in NTCIR-3 Patent Retrieval Task
</title>
<author confidence="0.98724">
Kazuaki KISHIDA
</author>
<affiliation confidence="0.9950835">
Faculty of Cultural Information Resources
Surugadai University
</affiliation>
<address confidence="0.89036">
698 Azu, Hanno, Saitama 357-8555 JAPAN
</address>
<email confidence="0.999391">
kishida@surugadai.ac.jp
</email>
<sectionHeader confidence="0.99481" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980631578947">
Pseudo relevance feedback is empirically
known as a useful method for enhancing
retrieval performance. For example, we
can apply the Rocchio method, which is
well-known relevance feedback method,
to the results of an initial search by as-
suming that the top-ranked documents are
relevant. In this paper, for searching the
NTCIR-3 patent test collection through
pseudo feedback, we employ two rele-
vance feedback mechanism; (1) the Roc-
chio method, and (2) a new method that is
based on Taylor formula of linear search
functions. The test collection consists of
near 700,000 records including full text of
Japanese patent materials. Unfortunately,
effectiveness of our pseudo feedback
methods was not empirically observed at
all in the experiment.
</bodyText>
<sectionHeader confidence="0.998873" genericHeader="categories and subject descriptors">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948094339623">
Relevance feedback is widely recognized as an
effective method for improving retrieval effective-
ness in the context of interactive IR. As often
pointed out, it is difficult for users to represent
their own information needs into a well-defined set
of search terms or statements. The resulting short
or poor queries would bring them unsatisfactory
results. However, if a few relevant documents hap-
pen to be found by the search, we could automati-
cally or manually extract some useful terms from
the documents, and add them to the initial search
expression. It is obviously expected that search
effectiveness of the second search using the ex-
tended query will be improved significantly. This
is a basic idea of relevance feedback.
Inevitably, for executing automatic relevance
feedback, the system has to obtain relevance in-
formation, i.e., relevant or irrelevant documents,
from the users interactively. However, some re-
searchers have tried to employ relevance feedback
techniques with no relevance information. The ob-
jective is to enhance search performance of re-
trieval models such as vector space model,
probabilistic model and so on, without interaction
on relevance information between system and us-
ers. The technique is usually called pseudo rele-
vance feedback, in which a standard feedback
method (e.g., the Rocchio method) is applied by
assuming that top-ranked documents searched by
the initial search are relevant.
The purpose of this paper is to report results of
retrieval experiments for examining effectiveness
of pseudo relevance feedback in the case of search-
ing a patent collection. In particular, we attempt to
compare search performance of the traditional
Rocchio method with that of an alternative method,
which is based on Taylor approximation of re-
trieval function proposed by Kishida[1]. This re-
port is based on two experiments using the
NTCIR-1 test collection and the NTCIR-3 patent
test collection, respectively. As to the latter, the
results were obtained at the time of NTCIR-3
Workshop held in October 2002 [2].
The rest of this paper is organized as follows. In
Section 2, the Rocchio method and an alternative
method proposed by Kishida[1] will be introduced.
In Section 3 a preliminary experiment for confirm-
ing how well the alternative method works in a
normal relevance feedback situation will be de-
scribed. The NTCIR-1 test collection with rele-
vance judgment information is used for the
preliminary experiment. In Section 4, results of an
experiment on pseudo relevance feedback method
</bodyText>
<equation confidence="0.8680725">
wqj = (log + . 10)log nj (3)
xqj ( N )
</equation>
<bodyText confidence="0.822116">
where
xij : frequency of a term tj in a document di,
using the NTCIR-3 patent test collection will be
shown.
</bodyText>
<sectionHeader confidence="0.494687" genericHeader="general terms">
2 Relevance Feedback Methods
</sectionHeader>
<bodyText confidence="0.416957">
xqj
: frequency of a term t in the query,
j
</bodyText>
<subsectionHeader confidence="0.862209">
2.1 Rocchio Method
</subsectionHeader>
<bodyText confidence="0.979279933333333">
The most typical approach to relevance feedback
would be so-called the Rocchio method [3]. A ba-
sic idea of the method is to add an average weight
of each term within a set of relevant documents to
the original query vector, and to subtract an aver-
age weight within a set of irrelevant ones from the
vector.
We denote a document vector and a query vec-
tor by d = (w 1,...,w )T and q = (wq ,...,wqM)T , where
i i iM 1wij is a weight of a term within a document and wqj
is a weight of a term within the query (M is the
total number of distinct terms in the database, and
T indicates transposition).
A modified query vector is obtained by a for-
mula,
</bodyText>
<equation confidence="0.956509333333333">
(1)
q=αq+ β Edi Edi— ∑di
D iA∈D D i:di∈D
</equation>
<bodyText confidence="0.999345">
where D is the set of relevant documents, D is the
set of irrelevant documents, and α β and γ
are constants.
It has been empirically shown that the perform-
ance of the Rocchio method is very good [4], and
in recent, many researchers have examined the
method directly or indirectly [5-8]. Also, due to its
effectiveness and simplicity, the Rocchio method
has been widely applied in other research areas, for
example, image retrieval [0] or text categorization
[10].
</bodyText>
<subsectionHeader confidence="0.998">
2.2 Feedback Method Using Taylor Formula
of Retrieval Function
</subsectionHeader>
<bodyText confidence="0.999505444444444">
Kishida[1] has proposed an alternative relevance
feedback method, which is suitable for the situa-
tion that the degree of relevance is given as a nu-
merical value, not dichotomous value (i.e.,
relevance or not), from actual users. In this section,
according to Kishida[1], the method will be ex-
plained.
In vector space model [10], typical formulas for
determining term weights are as follows:
</bodyText>
<equation confidence="0.962812333333333">
wij = log xij +1.0 (2)
nj : the number of documents including t ,
j
</equation>
<bodyText confidence="0.98745525">
N : the total number of documents in the data-
base.
For calculating the degree of similarity between
a document vector di and the query vector q , a
</bodyText>
<equation confidence="0.9491125">
cosine formula is normally used:
M 2 2 (4)
</equation>
<bodyText confidence="0.996912833333333">
where is a numerical score indicating similarity
si
of the document given a query vector.
On the other hand, a well-known formula based
on probabilistic model derived from an assumption
of two-Poisson distribution [12] is
</bodyText>
<equation confidence="0.996632333333333">
 3.0x
= M
∑ =  ij
j
j
(5)
</equation>
<bodyText confidence="0.541129">
where
</bodyText>
<equation confidence="0.994716">
M N
= −1
li = ∑ =1 j , and l N
x i ∑ = li ,
j i 1
</equation>
<bodyText confidence="0.999191857142857">
i.e., the former is a document length, and the latter
is an average of the length over documents within
the database. The formula (5) is a version of so-
called Okapi weighting [12] under a particular set-
ting of its parameters.
We can represent concisely the two important
retrieval models as a linear function of vector,
</bodyText>
<equation confidence="0.999252666666667">
s = f (b) = Ab , (6)
where s is a N dimensional vector of document
scores, s = ( , sN)T
s ..., , is a linear function of vec-
f
1
tor ( M ×1 N× 1
f :R → R ), and A is a N × M matrix of
which each element is
</equation>
<bodyText confidence="0.974846">
in the case of vector space model (see (2) and (4)),
or
in the case of the Okapi formula (see (5)).
</bodyText>
<equation confidence="0.863214428571429">
Also, b is a M dimensional vector of which
each element is defined as
bj wqj
= ∑ = 2
M 1 j
w q
j
</equation>
<bodyText confidence="0.90596">
where wqj = (log + . 10) log nj) in the case of
</bodyText>
<equation confidence="0.958603866666667">
xqj ( N
vector space model (see (3)), or
a = (log x + 1.0)
ij ij
∑M = (logx +
j 1 ij
1.0)2, (7)
a
ij (0.5+1 .5li l)+xij
3.0 xij (8)
=
M M
wij w ∑
j wij j
∑ w
s i
xij
× ×
x qj
n
log
N n
−
+
0.5
j
+
0.5  

(9)
</equation>
<bodyText confidence="0.9847295">
An approach to estimating b~ is to pay our at-
tention to a difference between initial score fX (b)
</bodyText>
<equation confidence="0.973310666666667">
j
+
05 .
N n
−
log
(10)
bj = xqj
j
+
n
05 .
</equation>
<bodyText confidence="0.998503714285714">
and secondary score fX (~)b , and to apply so-called
Taylor approximation for obtaining a vector func-
tion fX (~)b , i.e.,
in the case of the Okapi formula (see (5)).
The most important thing is that both of two
well-known formulas for estimating scores to rank
documents are able to be represented by a simple
</bodyText>
<equation confidence="0.982272">
∂f X ( b ) (~ )
form (6). f X f X K, (13)
(b) (b)
= b−b +
+ b T
∂
~
</equation>
<bodyText confidence="0.840512714285714">
For making ranked output, documents have to
be sorted in the decreasing order of scores, s
i
(i = 1,...,N). This means that each score is assumed
to indicate the degree of relevance. In other words,
the score is expected to be an estimate of ‘true’
degree of relevance ri .
</bodyText>
<equation confidence="0.823813">
Let r = (r ,..., rN)T be a vector representing ‘true’
1
</equation>
<bodyText confidence="0.977464684210526">
relevance degrees. By using this notation, we can
describe operationally a purpose of retrieval sys-
tem as “to estimate a vector s that is the closest to
vector r when a search request is given.”
Of course, r is unknown in real situations, but
it is possible to obtain information on a part of r
through the process of relevance feedback. For ex-
ample, if a user replies a set of scores indicating
the degrees of relevance for top-ranked n docu-
ments searched by the initial query, the scores al-
low us to estimate the part of r corresponding to
the n documents
We denote a set of the top-ranked n documents
by X and the part of r corresponding to the set X
by , which is actually n dimensional vector re-
rX
constructed by extracting n elements of the docu-
ments from the original vector r. According to (6),
we can write that
</bodyText>
<equation confidence="0.87535925">
sX = fX (b) = AXb , (11)
where
A X : an n × M matrix,
sX : an n dimensional vector, and
</equation>
<bodyText confidence="0.9946255">
Both of the matrix and the vector are constructed
by the same way with rX .
If we establish a distance measure φ between
rX and s , the objective of relevance feedback can
</bodyText>
<equation confidence="0.657237">
X
</equation>
<bodyText confidence="0.996546">
be formally described as follows: the relevance
feedback aims at estimating a modified query vec-
tor such that
</bodyText>
<equation confidence="0.818182666666667">
=
b~ arg min φ(rX, s X) = argmin ( , ( ))
φ r X fX b . (12)
</equation>
<subsectionHeader confidence="0.583272">
b b
</subsectionHeader>
<bodyText confidence="0.992245">
Then we can use b~ for the secondary search.
where K is a residual term (see [13]). If we em-
ploy (11) and assume that
</bodyText>
<equation confidence="0.693526666666667">
rX =fX (b),
according to a target condition (12), we can obtain
that
b ~ =b+A ( r −s
− 1 ), (14)
X X X
</equation>
<bodyText confidence="0.999453166666667">
(see Appendix for detail calculation). It should be
noted that K = 0 due to the linearity of Equation
(11). This means (14) is not an approximation but
an exact relation.
The Equation (14) contains an abnormal inverse
matrix AX , which is an
</bodyText>
<equation confidence="0.9937484">
−1 M × n matrix and
A X AX
− =
1 IM where is a
IM M × M matrix of which
</equation>
<bodyText confidence="0.659088333333333">
all diagonal elements are 1 and others are 0. Using
singular value decomposition (SVD), transpose
matrix of A X can be represented as
</bodyText>
<equation confidence="0.735257">
AT = UΛVT,
</equation>
<bodyText confidence="0.842605">
where
U : an M × n orthogonal matrix,
Λ : an n × n diagonal matrix, and
V: an n × n orthogonal matrix.
By employing the decomposition, we can finally
represent (14) such as
</bodyText>
<equation confidence="0.880305">
b~ = b+ UΛ−1VT(rX − sX ) (15)
</equation>
<bodyText confidence="0.99914">
(see Appendix for details). This is a final formula
of our relevance feedback algorithm. For conven-
ience, we call the algorithm “the Taylor formula
based method” in this paper.
</bodyText>
<sectionHeader confidence="0.807864" genericHeader="keywords">
Information
</sectionHeader>
<subsectionHeader confidence="0.999346">
3.1 Purpose and Test Data
</subsectionHeader>
<bodyText confidence="0.999433428571429">
Before applying pseudo relevance feedback
based on the Equation (15) to the patent test collec-
tion, we try checking retrieval performance of the
Taylor formula based method by using other test
collection with relevance judgment information.
To do this, we employ a well-known Japanese Test
Collection NTCIR-1 (NII/NACSIS Test Collection
</bodyText>
<figure confidence="0.5557665">
fX:RM×1 →Rn×1 .
3 Preliminary Experiment with Relevance
</figure>
<bodyText confidence="0.998836352941177">
for Information Retrieval - 1)1, which consists of
about 330,000 bibliographic records of proceed-
ings at conferences held in Japan. It should be
noted that, in the preliminary experiment, rele-
vance judgment information was used (i.e., not
pseudo feedback).
Fifty-three topics of NTCIR-1 were employed
for the experiment (from No.31 to No.83). The
format of these topics is also very similar with that
of TREC, i.e., a record of each topic consists of
fields of &lt;title&gt;, &lt;description&gt;, &lt;narrative&gt; and so
on. For realistic situation in which feedback meth-
ods are used, it would be more reasonable to as-
sume that original search statements are short.
Thus we employed only &lt;title&gt; and &lt;description&gt;
fields for representing each topic. This means that
a kind of ‘short query’ was used for the experiment.
</bodyText>
<subsectionHeader confidence="0.978531">
3.2 Procedure and type of runs
</subsectionHeader>
<bodyText confidence="0.949776">
Procedure of the preliminary experiment is as fol-
lows:
</bodyText>
<listItem confidence="0.947379181818182">
(a) Initial search: two initial search runs were car-
ried out, i.e., the first is based on vector space
model from (2) to (4) and the second is
probabilistic model (5). We denote the initial
search runs as ORGVEC and ORGPRB, re-
spectively.
(b) Query modification through relevance feed-
back: initial queries were modified by using
relevance judgment information on top-ranked
n documents of each initial run. In this paper,
we set 10 and 20 as the value of n ,
</listItem>
<bodyText confidence="0.988727166666667">
- In the case of vector space model, we can
attempt two modification methods, i.e.,
the Rocchio method (1) (where α = 8 ,
p = 16 and y = 4 ) and the Taylor formula
based method (7), (9) and (15). The run
using the Rocchio method is denoted as
ROCCHI, and the run by the Taylor for-
mula based method as TYLVEC.
- In the case of probabilistic model, only
the Taylor formula based method was
applied using (8), (10) and (15). We de-
note this run as TYLPRB.
</bodyText>
<listItem confidence="0.7823946">
(c) Secondary search: each modified query was
used for second run
- In the case of ROCCHI, modified queries
were matched with document vectors by
cosine formula (4).
</listItem>
<footnote confidence="0.841349">
1 http://research.nii.ac.jp/ntcir/
</footnote>
<bodyText confidence="0.995083">
- In the case of runs based on the Taylor
formula, TYLVEC and TYLPRB, the
linear function (6) was used for matching
operation.
</bodyText>
<subsectionHeader confidence="0.958071">
3.3 Conversion of binary judgment into con-
tinuous value
</subsectionHeader>
<bodyText confidence="0.999388111111111">
One of the advantages of the Taylor formula based
method (15) is to allow us for making use of con-
tinuous values representing the degree to which
each document is relevant. Unfortunately, in the
experiment, such values were not available be-
cause only results of binary judgments are offi-
cially provided as relevance information.
Therefore, in order to testify the Taylor formula
based method, we need to develop a special algo-
rithm for converting each binary judgment to a
continuous score. An easy way for converting a
value of binary judgment into a continuous degree
of relevance is to predict the degree from a docu-
ment score in initial search by using a simple
regression, ri = Asi + B.
It would be straightforward that the constants A
and B are determined based on maximum and
minimum values of s and for relevant and ir-
</bodyText>
<equation confidence="0.9349115">
ri
i
</equation>
<bodyText confidence="0.93941025">
relevant documents independently. That is, we use
a set of eight values for parameter estimation as
follows.
- s and s : maximum and minimum values of
</bodyText>
<figure confidence="0.94755105882353">
1 1
max min
si for ‘relevant’ documents in top-ranked n
documents,
- s and s : maximum and minimum values of
0 0
max min
si for ‘irrelevant’ documents in top-ranked n
documents,
- r and r : maximum and minimum values of
1 1
max min
ri for ‘relevant’ documents in top-ranked n
documents,
- r and r : maximum and minimum values
0 0
max min
</figure>
<bodyText confidence="0.6935088">
of for ‘irrelevant’ documents in top-ranked
ri
n documents.
For the set of relevant documents, we can ob-
tain estimates of A and B by solving equations,
</bodyText>
<equation confidence="0.836029">
r 11
= As
max max
r As
1 1
=
min min
It is easy to show that
A = (r max1− rm1in) / (s1 − s1 ) and
min
B = ( smaxrmin − rmaxsmin ) ( smax − smin
1 1 1 1 1 1 ) .



+
+
B
B
</equation>
<bodyText confidence="0.9995185">
Similarly, for the set of irrelevant documents,
we obtain that
Furthermore, we have to determine a priori val-
ues of rmax , r , r and r ,
</bodyText>
<figure confidence="0.949792727272727">
1 1 0 0
min max min
(a) For vector space model, it is reasonable
that r is assumed to be 1.0 and r is
1 0
max min
0.0 according to cosine function (4). As
for and , it is necessary to set a
rmin
1 rmax
0
</figure>
<bodyText confidence="0.757211">
margin between them, i.e., amount of
difference from minimum value for rele-
vant documents to maximum value for
irrelevant ones. If we take the margin as
2.0, it is automatically determined that
</bodyText>
<equation confidence="0.6104314">
rmin
1 = 6.0 and r 0 x = 4.0. As a result, target
ma
values for relevant and irrelevant
r i
</equation>
<bodyText confidence="0.674602">
documents are distributed from 0.6 to
1.0, and from 0.0 and 0.4, respectively.
</bodyText>
<listItem confidence="0.389914">
(b) For probabilistic model, we set arbitrar-
</listItem>
<equation confidence="0.900048">
ily that r 1 1 , rmin smax
1 1
max = 2s = and
max
</equation>
<bodyText confidence="0.988221928571429">
Japanese text, and selected each longest entry
matched with a portion of text as a index term.
Also, an
string was decomposed ac-
cording to change of kinds of character, Hiragana,
Katakana, Kanji and so on (Hiragana strings were
not taken as index terms).
Also, for identifying compound words as con-
tent-bearing terms, we employed a heuristic rule
that an
“unknown”
adjacent pair of index terms identified by
dictionary matching is automatically combined
into a compound word.
</bodyText>
<sectionHeader confidence="0.932327" genericHeader="introduction">
3.5 Results
</sectionHeader>
<equation confidence="0.984326571428571">
A = (rmax − rmin) / (smax − smin
0 0 0 0 ) and
B = (smaxrmin − rmaxsmin) (s max − smin
0 0 0 0 0 0 )
.
rmin . as a trial in the experiment.
0 = 0 0
</equation>
<bodyText confidence="0.9021546">
This means that range of document
scores is enlarged doubly, and each r
i
for relevant documents is to be distrib-
uted in the range from s to 2 . On
</bodyText>
<equation confidence="0.891875090909091">
1 smax
1
max
the other hand, maximum value of r for
i
irrelevant documents is complicated a
little, i.e.,
)
[max( , ) min( , 0 )]/ 2
1 0
+ s max s − s s
1 ,
max min min
since there is no guarantee that s is al-
1
max
ways greater than s , and s is always
0 0
max min
smaller than s
1
min
</equation>
<subsectionHeader confidence="0.997894">
3.4 Segmentation of Japanese text
</subsectionHeader>
<bodyText confidence="0.993349">
om .228 to .459).
</bodyText>
<sectionHeader confidence="0.958587666666667" genericHeader="method">
4 Experiment on Pseudo Relevance Feed-
back using NTCIR-3 Patent Test Col-
lection
</sectionHeader>
<subsectionHeader confidence="0.993124">
4.1 Procedure
</subsectionHeader>
<equation confidence="0.654554666666667">
max = min min
r
dic-
</equation>
<bodyText confidence="0.857581">
tionary. We used a dictionary of the ChaSen[14],
which is a well-known morphological an
</bodyText>
<figure confidence="0.475643">
a machine-readable
alyzer for
0 min( , 0
s s
1
</figure>
<bodyText confidence="0.999272923076923">
The test collection NTCIR-1 basically consists of
documents written in Japanese (as well as the
NTCIR-3 patent test collection). We need to seg-
ment each text into a set of terms automatically for
indexing the Japanese documents and queries, of
which text has no explicit boundary between terms
unlike English.
In the experiment, each term was identified by
matching with entries in
The NTCIR-1 collection includes 332,918 records,
and average document length, i.e., average of the
total number of terms appearing in each document,
was 118.0. Table 1 shows values of mean average
precision of each run.
As shown in Table 1, the Taylor formula based
method outperforms the Rocchio method slightly,
but clearly there is no statistically significant dif-
ference between ROCCHI and TYLVEC (.376
and .378 at top 10, and .434 and .459 at top 20).
The rate of improvement by feedback in vector
space model is greater than that in probabilistic
model. The run showing best performance in Table
1 is the Taylor formula based method in the vector
space model (TYLVEC) using top-ranked 20
documents, which increases mean average preci-
sion at 101.6% from ORGVEC (fr
In the previous section, the Taylor formula based
method has proven to work well at the experiment
using the NTCIR-1 test collection with relevance
information. Next, we attempt to examine the ef-
fectiveness of pseudo relevance feedback method
using the Taylor formula based feedback in the
case of searching the NTCIR-3 patent test collec-
tion (with no relevance information).
The method an
d procedure are almost same
with those in the previous section. However, in the
Rocchio method, D is assumed to be empty (y is
0 in the Equation (1)).
</bodyText>
<tableCaption confidence="0.959476">
Table 1. Mean average precision (using the
</tableCaption>
<table confidence="0.96603">
NTCIR-1 collection with relevance information)
model Vector space Probabilis-
tic
initial search ORGVEC ORGPRB
(baseline) .228 .268
feedback ROCCHI TYLVEC TYLPRB
top 10 docu- .376 .378 .396
ments (+65.2%) (+66.3%) (+48.0%)
top 20 docu- .434 .459 .450
ments (+90.4%) (+101.6%) (+68.1%)
</table>
<bodyText confidence="0.999274916666667">
In the experiment, only six runs were executed
as shown in Table 2 (at the time of the NTCIR-3
Workshop, only the six runs were submitted). We
discern two kinds of run according to query (topic)
fields used for run; (I) &lt;ARTICLE&gt; and &lt;SUP-
PLEMENT&gt; fields and (II) &lt;DESCRIPTION&gt; and
&lt;NARRATIVE&gt; fields. The &lt;ARTICLE&gt; field
includes a news article, i.e., in the NTCIR-3 Patent
Task, the participants were asked to search the
document collection for a news article related to
the information needs of users. The number of top-
ics is 32.
</bodyText>
<tableCaption confidence="0.9197685">
Table 2. Runs in the experiment using patent test
collection
</tableCaption>
<table confidence="0.965906142857143">
Initial run feedback Topic fields
&lt;A&gt;&lt;S&gt;* &lt;D&gt;&lt;N&gt;**
OKAPI TAYLOR Run1 Run2
VECTOR ROCCHIO Run3 Run4
OKAPI none Run5 Run6
*&lt;A&gt;:&lt;ARTICLE&gt;, &lt;S&gt;:&lt;SUPPLEMENT&gt;
**&lt;D&gt;:&lt;DESCRIPTION&gt;,&lt;N&gt;:&lt;NARRATIVE
</table>
<subsectionHeader confidence="0.768562">
4.2 Results
</subsectionHeader>
<bodyText confidence="0.997509625">
In the indexing phase, 697,262 records were proc-
essed and average length of documents is 393.32.
Table 3 shows search performance of each run.
Unfortunately, pseudo relevance feedback using
relevance feedback techniques has no effect on the
performance. It seems that there are no statistically
significant differences between any pairs of runs.
However,
</bodyText>
<figure confidence="0.8068455">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
OKAPI-none (baseline)
</figure>
<figureCaption confidence="0.999389">
Figure 1. Topic-by-topic Analysis (in the case of
using &lt;DESCRIPTION&gt; and &lt;NARRATIVE&gt;)
</figureCaption>
<bodyText confidence="0.960170083333333">
Figure 1 is a plot of values of average precision
by topic. We can compare the Taylor formula
based method (OKAPI-TAYLOR) and the Roc-
chio method (VECTOR-ROCCHIO) with normal
Okapi formula (OKAPI-none), in level of each
topic. It should be noted that, in Figure 1, square
indicates ROCCHIO and circle TAYLOR.
Figure 1 shows that for most of topics, normal
Okapi formula outperforms the Rocchio method
and Taylor formula based method although the
Rocchio method and Taylor formula based method
are superior in some topics.
</bodyText>
<figure confidence="0.996575615384615">
TAYLOR and ROCCHIO
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
ROCCHIO
TAYLOR
</figure>
<tableCaption confidence="0.995224">
Table 3. Average Precision and R-precision (Using NTCIR-3 Patent Test Collection)
</tableCaption>
<table confidence="0.999646777777778">
Topic Fields Initial run feedback Average precision R-precision
&lt;ARTICLE&gt; OKAPI TAYLOR 0.1152 0.1421
&lt;SUPPLEMENT&gt;
VECTOR ROCCHIO 0.1281 0.1565
OKAPI none 0.1282 0.1565
&lt;DESCRIPTION&gt; OKAPI TAYLOR 0.1370 0.1820
&lt;NARRATIVE&gt;
VECTOR ROCCHIO 0.1581 0.1896
OKAPI none 0.1583 0.1813
</table>
<sectionHeader confidence="0.99775" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999717523809524">
Although the Rocchio method and Taylor formula
based method have shown good performance in the
preliminary experiment using the NTCIR-1 test
collection with relevance judgment with relevance
judgment information, unfortunately the pseudo
relevance feedback was not able to show im-
provement of search effectiveness. A main reason
for the failure may be that term selection process
was omitted. In standard pseudo relevance feed-
back methods, better terms are usually selected
from the set of top-ranked documents according to
the term weights. We can expect that if the term
selection process is applied, the performance is
improved in the case of the Rocchio method. How-
ever, how can we select better terms in the case of
the Taylor formula based method?
The behavior of the Taylor formula based
method in the process of term re-weighting is a
little complicated. For example, we assume that
there are only 6 distinct terms (from term1 to
term6) in a database, and that
</bodyText>
<equation confidence="0.472461">
b = (05 . ,05 . ,05 . ,05 . ,05 . ,05 . ) T ,
</equation>
<bodyText confidence="0.80488775">
which means that all term weights in the initial
query vector are equal. The matrix of weights of
terms in top-ranked 4 documents (from doc1 to
doc4) is supposed to be that
</bodyText>
<equation confidence="0.934892272727273">
1 2 0 0 1 1.
2 1 0 0 1 1
(16)
AX =   
 


0 0 2 1 1 1
A row of the matrix represents each document vec-
tor, e.g.,d1 =(2,1,0,0,1,1)
T
</equation>
<bodyText confidence="0.99873175">
Furthermore, it is assumed that a set of numeri-
cal values indicating degree of relevance for each
document was given by a user, and difference from
initial document scores was calculates such that
</bodyText>
<equation confidence="0.992438666666667">
rX sX
− = (01 . ,0.2,−01 . ,−0.2) . (17)
T
</equation>
<bodyText confidence="0.9922308">
Under these assumptions, relevance feedback by
the Taylor formula based method is as follows.
First, by the SVD algorithm, the transpose matrix
of the AX can be decomposed as UAVT, and after
simple calculation, we can finally obtain that
</bodyText>
<equation confidence="0.967319">
UA−1VT(rX − sX) = (0.0,0.1,−0.1,0.0,0.0,0.0)T . (18)
</equation>
<bodyText confidence="0.978053153846154">
This example represents well characteristics of
the Taylor formula based method. From (17) we
understand that scores of doc1 and doc2 have to be
increased and those of doc3 and doc4 decreased.
Intuitively, it seems that weights of both term1 and
term2 should be augmented because they are only
appearing in doc1 and doc2, neither doc3 nor doc4
at all. However, a solution by (18) indicates that
the weight of term1 is unchanged (only to that of
term2, 0.1 is added). This is a result so as to keep
the condition (17), which means that scores of
doc1 and doc2 have to be increased by 0.1 and 0.2,
respectively, for reaching at an ideal situation. Ac-
tually, we can calculate from (16) such that
2x 0.0+ 1x 0.1= 01
. for doc1 and that
1 0 0 2 01 0
x . + x . = .2 for doc2. The results indicate
that the condition (17) is completely satisfied. As
shown in the simple calculation, the Taylor for-
mula based method takes the difference rX − sX
into consideration for re-weighting of search terms.
On the other hand, in the case of the Rocchio
method, re-weighting of search terms is done by
looking into only A regardless of . We sup-
sX
</bodyText>
<equation confidence="0.688294">
X
</equation>
<bodyText confidence="0.999985133333333">
pose that doc1 and doc2 were judged as relevant
documents, and doc3 and doc4 irrelevant. In the
condition, the Rocchio method adds simply
(1+2)/2=1.5 to weights of both of term1 and term2,
not considering document scores in an initial
search.
As shown in above example, in the case of the
Taylor formula based method, term re-weighting is
dependent on the values of rX − sX . Therefore, we
can not use simply the vector (18) for selecting
better terms. We have to consider carefully how to
use the Equation (18) for term selection. Further
investigation will be needed for executing term
selection for pseudo relevance feedback in the case
of the Taylor formula based method.
</bodyText>
<sectionHeader confidence="0.9801" genericHeader="conclusions">
6 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.99991125">
In this paper, results of two experiments on rele-
vance feedback have been reported. The purpose of
first experiment is to check performance of a new
feedback method proposed by Kishida[1] (the Tay-
lor formula based method) in a normal situation
with relevance information. The result has shown
that the Taylor formula based method works well.
The second experiment aims at examining effec-
tiveness of pseudo relevance feedback using the
Taylor formula based method for searching a pat-
ent collection. Unfortunately, the pseudo relevance
feedback did not show good performance. We need
to devise a technique for selecting better terms
0 0 1 2 1 1
from top-ranked documents in the case of applying
the new feedback method.
</bodyText>
<sectionHeader confidence="0.994325" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995589138461539">
[1] K. Kishida. 2001. Feedback method for docu-
ment retrieval using numerical values on rele-
vance given by users. IPSJ SIG Notes
Fundamental Infology, 61: 189-196. (in Japa-
nese)
[2] K. Kishida. 2003. Experiment on Pseudo Rele-
vance Feedback Method Using Taylor Formula
at NTCIR-3 Patent Retrieval Task. Proceed-
ings of the Third NTCIR Workshop on Re-
search in Information Retrieval, Automatic
Text Summarization and Question Answering,
NII, Tokyo. http://research.nii.ac.jp/ntcir/
[3] J. J. Rocchio, Jr. 1971. Relevance feedback in
information retrieval. in G. Salton ed., The
SMART Retrieval System: Experiments in
Automatic Document Processing, Prentice-
Hall, Englewood Cliffs, NJ, 313-323.
[10] M. F. Moens and J. Dumortier. 2000. Text
categorization: the assignment of subject de-
scriptors to magazine articles. Information
Processing and Management, 36: 841-861.
[11] C. Buckley, J. Allan, and G. Salton. 1994.
Automatic routing and ad-hoc retrieval using
SMART: TREC2. in D.K. Harman ed., The
Second Text Retrieval Conference (TREC2).
National Institute of Standards and Technology,
Gaithersburg MD, 45-55.
[12] S. E. Robertson, et al. 1995. Okapi at TERC-3.
in D.K. Harman ed. Overview of the Third
Text Retrieval Conference (TREC-3). National
Institute of Standards and Technology,
Gaithersburg MD, 109-126.
[13] D. A. Harville. 1997. Matrix Algebra from a
Statistician’s Perspective. Springer, New York.
[14] Yuji Matsumoto, Akira Kitauchi, Tatsuo
Yamashita, Yoshitaka Hirano, Hiroshi Matsuda,
Kazuma Takaoka and Masayuki Asahara. 2000.
Morphological Analysis System ChaSen version
2.2.1 Manual. http://chasen.aist-nara.ac.jp/
[4] G. Salton and C. Buckley. 1990. Improving
retrieval performance by relevance feedback.
Journal of the American Society for Informa-
tion Science, 41: 288-297. Appendix. Detail of Calculation
[5] P. Sarinivasan. 1996. Query expansion and
MEDLINE. Information Processing and
Management, 32: 431-443.
[6] J. H. Lee. 1998. Combining the evidence of
different relevance feedback methods for in-
formation retrieval. Information Processing
and Management, 34: 681-691.
[7] R. Mandala, T. Tokunaga and H. Tanaka. 2000.
Query expansion using heterogeneous thesauri.
Information Processing and Management, 36:
361-378.
[8] M. Iwayama. 2000. Relevance feedback with a
small number of relevance judgments: incre-
mental relevance feedback vs. Document clus-
tering. in Proceedings of the 23rd Annual
International ACM SIGIR Conference on Re-
search and Development in Information Re-
trieval, ACM Press, 10-16.
[9] G. Ciocca. and R. Schettini.1999. A relevance
feedback mechanism for content-based image
retrieval. Information Processing and Man-
agement, 35: 605-632.
</reference>
<bodyText confidence="0.960373">
If we assume a linear function (11),
</bodyText>
<equation confidence="0.942154">
(b) ( )
∂ A b
X
= =
T
∂ b ∂ b
</equation>
<bodyText confidence="0.943858166666667">
which is a well-known result in the field of linear
algebra [13]. Therefore (13) becomes that
fX b(~) = fX (b) + AX
(it should be noted that K = 0 ).
By following our assumption that rX is equal to
fX (~)b and noting that fX (b) = s , we obtain that
</bodyText>
<equation confidence="0.887378333333333">
X
A X (~ b − b ) = r X − s
The (14) is easily derived from (A.1).
</equation>
<bodyText confidence="0.997652">
By using singular value decomposition we can
obtain that AX U V . The transposition is that
</bodyText>
<equation confidence="0.998735333333333">
T = Λ T
T T T T
AX (A X ) (U V ) V U
= Λ ,
T
= = Λ
</equation>
<bodyText confidence="0.993309">
because U and V are orthogonal matrixes and Λ is
a diagonal matrix. Substituting (A.2) into (A.1), we
finally obtain that
</bodyText>
<figure confidence="0.839745416666667">
VΛUT b b r s
(~ − ) = X − X .
∴ b =b+UΛ−1VT(rX −sX)
∂fX
A
T X
,
)
(~b − b
X . (A.1)
(A.2)
.
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.313636">
<title confidence="0.997855">Relevance Feedback Method Based on Taylor Expansion of trieval Function in NTCIR-3 Patent Retrieval Task</title>
<author confidence="0.522346">Kazuaki</author>
<affiliation confidence="0.4739925">Faculty of Cultural Information Surugadai</affiliation>
<address confidence="0.938903">698 Azu, Hanno, Saitama 357-8555 JAPAN</address>
<email confidence="0.980032">kishida@surugadai.ac.jp</email>
<abstract confidence="0.9987927">Pseudo relevance feedback is empirically known as a useful method for enhancing retrieval performance. For example, we can apply the Rocchio method, which is well-known relevance feedback method, to the results of an initial search by assuming that the top-ranked documents are relevant. In this paper, for searching the NTCIR-3 patent test collection through pseudo feedback, we employ two relevance feedback mechanism; (1) the Rocchio method, and (2) a new method that is based on Taylor formula of linear search functions. The test collection consists of near 700,000 records including full text of Japanese patent materials. Unfortunately, effectiveness of our pseudo feedback methods was not empirically observed at all in the experiment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Kishida</author>
</authors>
<title>Feedback method for document retrieval using numerical values on relevance given by users.</title>
<date>2001</date>
<journal>IPSJ SIG Notes Fundamental Infology,</journal>
<volume>61</volume>
<pages>189--196</pages>
<note>(in Japanese)</note>
<contexts>
<context position="2831" citStr="[1]" startWordPosition="431" endWordPosition="431">s. The technique is usually called pseudo relevance feedback, in which a standard feedback method (e.g., the Rocchio method) is applied by assuming that top-ranked documents searched by the initial search are relevant. The purpose of this paper is to report results of retrieval experiments for examining effectiveness of pseudo relevance feedback in the case of searching a patent collection. In particular, we attempt to compare search performance of the traditional Rocchio method with that of an alternative method, which is based on Taylor approximation of retrieval function proposed by Kishida[1]. This report is based on two experiments using the NTCIR-1 test collection and the NTCIR-3 patent test collection, respectively. As to the latter, the results were obtained at the time of NTCIR-3 Workshop held in October 2002 [2]. The rest of this paper is organized as follows. In Section 2, the Rocchio method and an alternative method proposed by Kishida[1] will be introduced. In Section 3 a preliminary experiment for confirming how well the alternative method works in a normal relevance feedback situation will be described. The NTCIR-1 test collection with relevance judgment information is </context>
<context position="5013" citStr="[1]" startWordPosition="826" endWordPosition="826">ned by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishida[1], the method will be explained. In vector space model [10], typical formulas for determining term weights are as follows: wij = log xij +1.0 (2) nj : the number of documents including t , j N : the total number of documents in the database. For calculating the degree of similarity between a document vector di and the query vector q , a cos</context>
</contexts>
<marker>[1]</marker>
<rawString>K. Kishida. 2001. Feedback method for document retrieval using numerical values on relevance given by users. IPSJ SIG Notes Fundamental Infology, 61: 189-196. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kishida</author>
</authors>
<title>Experiment on Pseudo Relevance Feedback Method Using Taylor Formula at NTCIR-3 Patent Retrieval Task.</title>
<date>2003</date>
<booktitle>Proceedings of the Third NTCIR Workshop on Research in Information Retrieval, Automatic Text Summarization and Question Answering,</booktitle>
<location>NII, Tokyo. http://research.nii.ac.jp/ntcir/</location>
<contexts>
<context position="3061" citStr="[2]" startWordPosition="470" endWordPosition="470"> of this paper is to report results of retrieval experiments for examining effectiveness of pseudo relevance feedback in the case of searching a patent collection. In particular, we attempt to compare search performance of the traditional Rocchio method with that of an alternative method, which is based on Taylor approximation of retrieval function proposed by Kishida[1]. This report is based on two experiments using the NTCIR-1 test collection and the NTCIR-3 patent test collection, respectively. As to the latter, the results were obtained at the time of NTCIR-3 Workshop held in October 2002 [2]. The rest of this paper is organized as follows. In Section 2, the Rocchio method and an alternative method proposed by Kishida[1] will be introduced. In Section 3 a preliminary experiment for confirming how well the alternative method works in a normal relevance feedback situation will be described. The NTCIR-1 test collection with relevance judgment information is used for the preliminary experiment. In Section 4, results of an experiment on pseudo relevance feedback method wqj = (log + . 10)log nj (3) xqj ( N ) where xij : frequency of a term tj in a document di, using the NTCIR-3 patent t</context>
</contexts>
<marker>[2]</marker>
<rawString>K. Kishida. 2003. Experiment on Pseudo Relevance Feedback Method Using Taylor Formula at NTCIR-3 Patent Retrieval Task. Proceedings of the Third NTCIR Workshop on Research in Information Retrieval, Automatic Text Summarization and Question Answering, NII, Tokyo. http://research.nii.ac.jp/ntcir/</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Rocchio</author>
</authors>
<title>Relevance feedback in information retrieval.</title>
<date>1971</date>
<booktitle>The SMART Retrieval System: Experiments in Automatic Document Processing, PrenticeHall, Englewood Cliffs, NJ,</booktitle>
<pages>313--323</pages>
<editor>in G. Salton ed.,</editor>
<contexts>
<context position="3872" citStr="[3]" startWordPosition="612" endWordPosition="612"> well the alternative method works in a normal relevance feedback situation will be described. The NTCIR-1 test collection with relevance judgment information is used for the preliminary experiment. In Section 4, results of an experiment on pseudo relevance feedback method wqj = (log + . 10)log nj (3) xqj ( N ) where xij : frequency of a term tj in a document di, using the NTCIR-3 patent test collection will be shown. 2 Relevance Feedback Methods xqj : frequency of a term t in the query, j 2.1 Rocchio Method The most typical approach to relevance feedback would be so-called the Rocchio method [3]. A basic idea of the method is to add an average weight of each term within a set of relevant documents to the original query vector, and to subtract an average weight within a set of irrelevant ones from the vector. We denote a document vector and a query vector by d = (w 1,...,w )T and q = (wq ,...,wqM)T , where i i iM 1wij is a weight of a term within a document and wqj is a weight of a term within the query (M is the total number of distinct terms in the database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D whe</context>
</contexts>
<marker>[3]</marker>
<rawString>J. J. Rocchio, Jr. 1971. Relevance feedback in information retrieval. in G. Salton ed., The SMART Retrieval System: Experiments in Automatic Document Processing, PrenticeHall, Englewood Cliffs, NJ, 313-323.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Moens</author>
<author>J Dumortier</author>
</authors>
<title>Text categorization: the assignment of subject descriptors to magazine articles.</title>
<date>2000</date>
<journal>Information Processing and Management,</journal>
<volume>36</volume>
<pages>841--861</pages>
<contexts>
<context position="4938" citStr="[10]" startWordPosition="816" endWordPosition="816">e database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishida[1], the method will be explained. In vector space model [10], typical formulas for determining term weights are as follows: wij = log xij +1.0 (2) nj : the number of documents including t , j N : the total number of documents in the database. For calculating the degre</context>
</contexts>
<marker>[10]</marker>
<rawString>M. F. Moens and J. Dumortier. 2000. Text categorization: the assignment of subject descriptors to magazine articles. Information Processing and Management, 36: 841-861.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Buckley</author>
<author>J Allan</author>
<author>G Salton</author>
</authors>
<title>Automatic routing and ad-hoc retrieval using SMART: TREC2.</title>
<date>1994</date>
<booktitle>The Second Text Retrieval Conference (TREC2). National Institute of Standards and Technology, Gaithersburg MD,</booktitle>
<pages>45--55</pages>
<editor>in D.K. Harman ed.,</editor>
<marker>[11]</marker>
<rawString>C. Buckley, J. Allan, and G. Salton. 1994. Automatic routing and ad-hoc retrieval using SMART: TREC2. in D.K. Harman ed., The Second Text Retrieval Conference (TREC2). National Institute of Standards and Technology, Gaithersburg MD, 45-55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Robertson</author>
</authors>
<title>Okapi at TERC-3.</title>
<date>1995</date>
<booktitle>Overview of the Third Text Retrieval Conference (TREC-3). National Institute of Standards and Technology, Gaithersburg MD,</booktitle>
<pages>109--126</pages>
<editor>in D.K. Harman ed.</editor>
<contexts>
<context position="5871" citStr="[12]" startWordPosition="976" endWordPosition="976">da[1], the method will be explained. In vector space model [10], typical formulas for determining term weights are as follows: wij = log xij +1.0 (2) nj : the number of documents including t , j N : the total number of documents in the database. For calculating the degree of similarity between a document vector di and the query vector q , a cosine formula is normally used: M 2 2 (4) where is a numerical score indicating similarity si of the document given a query vector. On the other hand, a well-known formula based on probabilistic model derived from an assumption of two-Poisson distribution [12] is  3.0x = M ∑ =  ij j j (5) where M N = −1 li = ∑ =1 j , and l N x i ∑ = li , j i 1 i.e., the former is a document length, and the latter is an average of the length over documents within the database. The formula (5) is a version of socalled Okapi weighting [12] under a particular setting of its parameters. We can represent concisely the two important retrieval models as a linear function of vector, s = f (b) = Ab , (6) where s is a N dimensional vector of document scores, s = ( , sN)T s ..., , is a linear function of vecf 1 tor ( M ×1 N× 1 f :R → R ), and A is a N × M matrix of which eac</context>
</contexts>
<marker>[12]</marker>
<rawString>S. E. Robertson, et al. 1995. Okapi at TERC-3. in D.K. Harman ed. Overview of the Third Text Retrieval Conference (TREC-3). National Institute of Standards and Technology, Gaithersburg MD, 109-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Harville</author>
</authors>
<title>Matrix Algebra from a Statistician’s Perspective.</title>
<date>1997</date>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="9129" citStr="[13]" startWordPosition="1702" endWordPosition="1702">ments of the documents from the original vector r. According to (6), we can write that sX = fX (b) = AXb , (11) where A X : an n × M matrix, sX : an n dimensional vector, and Both of the matrix and the vector are constructed by the same way with rX . If we establish a distance measure φ between rX and s , the objective of relevance feedback can X be formally described as follows: the relevance feedback aims at estimating a modified query vector such that = b~ arg min φ(rX, s X) = argmin ( , ( )) φ r X fX b . (12) b b Then we can use b~ for the secondary search. where K is a residual term (see [13]). If we employ (11) and assume that rX =fX (b), according to a target condition (12), we can obtain that b ~ =b+A ( r −s − 1 ), (14) X X X (see Appendix for detail calculation). It should be noted that K = 0 due to the linearity of Equation (11). This means (14) is not an approximation but an exact relation. The Equation (14) contains an abnormal inverse matrix AX , which is an −1 M × n matrix and A X AX − = 1 IM where is a IM M × M matrix of which all diagonal elements are 1 and others are 0. Using singular value decomposition (SVD), transpose matrix of A X can be represented as AT = UΛVT, w</context>
</contexts>
<marker>[13]</marker>
<rawString>D. A. Harville. 1997. Matrix Algebra from a Statistician’s Perspective. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuji Matsumoto</author>
</authors>
<title>Akira Kitauchi, Tatsuo Yamashita, Yoshitaka Hirano, Hiroshi Matsuda, Kazuma Takaoka and Masayuki Asahara.</title>
<date>2000</date>
<note>Manual. http://chasen.aist-nara.ac.jp/</note>
<contexts>
<context position="16448" citStr="[14]" startWordPosition="3103" endWordPosition="3103">is enlarged doubly, and each r i for relevant documents is to be distributed in the range from s to 2 . On 1 smax 1 max the other hand, maximum value of r for i irrelevant documents is complicated a little, i.e., ) [max( , ) min( , 0 )]/ 2 1 0 + s max s − s s 1 , max min min since there is no guarantee that s is al1 max ways greater than s , and s is always 0 0 max min smaller than s 1 min 3.4 Segmentation of Japanese text om .228 to .459). 4 Experiment on Pseudo Relevance Feedback using NTCIR-3 Patent Test Collection 4.1 Procedure max = min min r dictionary. We used a dictionary of the ChaSen[14], which is a well-known morphological an a machine-readable alyzer for 0 min( , 0 s s 1 The test collection NTCIR-1 basically consists of documents written in Japanese (as well as the NTCIR-3 patent test collection). We need to segment each text into a set of terms automatically for indexing the Japanese documents and queries, of which text has no explicit boundary between terms unlike English. In the experiment, each term was identified by matching with entries in The NTCIR-1 collection includes 332,918 records, and average document length, i.e., average of the total number of terms appearing</context>
</contexts>
<marker>[14]</marker>
<rawString>Yuji Matsumoto, Akira Kitauchi, Tatsuo Yamashita, Yoshitaka Hirano, Hiroshi Matsuda, Kazuma Takaoka and Masayuki Asahara. 2000. Morphological Analysis System ChaSen version 2.2.1 Manual. http://chasen.aist-nara.ac.jp/</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>C Buckley</author>
</authors>
<title>Improving retrieval performance by relevance feedback.</title>
<date>1990</date>
<journal>Journal of the American Society for Information Science,</journal>
<volume>41</volume>
<pages>288--297</pages>
<contexts>
<context position="4667" citStr="[4]" startWordPosition="776" endWordPosition="776">ant ones from the vector. We denote a document vector and a query vector by d = (w 1,...,w )T and q = (wq ,...,wqM)T , where i i iM 1wij is a weight of a term within a document and wqj is a weight of a term within the query (M is the total number of distinct terms in the database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishi</context>
</contexts>
<marker>[4]</marker>
<rawString>G. Salton and C. Buckley. 1990. Improving retrieval performance by relevance feedback. Journal of the American Society for Information Science, 41: 288-297. Appendix. Detail of Calculation</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sarinivasan</author>
</authors>
<title>Query expansion and MEDLINE.</title>
<date>1996</date>
<journal>Information Processing and Management,</journal>
<volume>32</volume>
<pages>431--443</pages>
<contexts>
<context position="4761" citStr="[5, 6, 7, 8]" startWordPosition="789" endWordPosition="789">...,w )T and q = (wq ,...,wqM)T , where i i iM 1wij is a weight of a term within a document and wqj is a weight of a term within the query (M is the total number of distinct terms in the database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishida[1], the method will be explained. In vector space model [10], typical formulas for determin</context>
</contexts>
<marker>[5]</marker>
<rawString>P. Sarinivasan. 1996. Query expansion and MEDLINE. Information Processing and Management, 32: 431-443.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J H Lee</author>
</authors>
<title>Combining the evidence of different relevance feedback methods for information retrieval.</title>
<date>1998</date>
<journal>Information Processing and Management,</journal>
<volume>34</volume>
<pages>681--691</pages>
<contexts>
<context position="4761" citStr="[5, 6, 7, 8]" startWordPosition="789" endWordPosition="789">...,w )T and q = (wq ,...,wqM)T , where i i iM 1wij is a weight of a term within a document and wqj is a weight of a term within the query (M is the total number of distinct terms in the database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishida[1], the method will be explained. In vector space model [10], typical formulas for determin</context>
</contexts>
<marker>[6]</marker>
<rawString>J. H. Lee. 1998. Combining the evidence of different relevance feedback methods for information retrieval. Information Processing and Management, 34: 681-691.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mandala</author>
<author>T Tokunaga</author>
<author>H Tanaka</author>
</authors>
<title>Query expansion using heterogeneous thesauri.</title>
<date>2000</date>
<journal>Information Processing and Management,</journal>
<volume>36</volume>
<pages>361--378</pages>
<contexts>
<context position="4761" citStr="[5, 6, 7, 8]" startWordPosition="789" endWordPosition="789">...,w )T and q = (wq ,...,wqM)T , where i i iM 1wij is a weight of a term within a document and wqj is a weight of a term within the query (M is the total number of distinct terms in the database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishida[1], the method will be explained. In vector space model [10], typical formulas for determin</context>
</contexts>
<marker>[7]</marker>
<rawString>R. Mandala, T. Tokunaga and H. Tanaka. 2000. Query expansion using heterogeneous thesauri. Information Processing and Management, 36: 361-378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Iwayama</author>
</authors>
<title>Relevance feedback with a small number of relevance judgments: incremental relevance feedback vs. Document clustering.</title>
<date>2000</date>
<booktitle>in Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>10--16</pages>
<publisher>ACM Press,</publisher>
<contexts>
<context position="4761" citStr="[5, 6, 7, 8]" startWordPosition="789" endWordPosition="789">...,w )T and q = (wq ,...,wqM)T , where i i iM 1wij is a weight of a term within a document and wqj is a weight of a term within the query (M is the total number of distinct terms in the database, and T indicates transposition). A modified query vector is obtained by a formula, (1) q=αq+ β Edi Edi— ∑di D iA∈D D i:di∈D where D is the set of relevant documents, D is the set of irrelevant documents, and α β and γ are constants. It has been empirically shown that the performance of the Rocchio method is very good [4], and in recent, many researchers have examined the method directly or indirectly [5, 6, 7, 8]. Also, due to its effectiveness and simplicity, the Rocchio method has been widely applied in other research areas, for example, image retrieval [0] or text categorization [10]. 2.2 Feedback Method Using Taylor Formula of Retrieval Function Kishida[1] has proposed an alternative relevance feedback method, which is suitable for the situation that the degree of relevance is given as a numerical value, not dichotomous value (i.e., relevance or not), from actual users. In this section, according to Kishida[1], the method will be explained. In vector space model [10], typical formulas for determin</context>
</contexts>
<marker>[8]</marker>
<rawString>M. Iwayama. 2000. Relevance feedback with a small number of relevance judgments: incremental relevance feedback vs. Document clustering. in Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, ACM Press, 10-16.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Schettini 1999</author>
</authors>
<title>A relevance feedback mechanism for content-based image retrieval.</title>
<journal>Information Processing and Management,</journal>
<volume>35</volume>
<pages>605--632</pages>
<marker>[9]</marker>
<rawString>G. Ciocca. and R. Schettini.1999. A relevance feedback mechanism for content-based image retrieval. Information Processing and Management, 35: 605-632.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>