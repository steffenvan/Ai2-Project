<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992727">
Polylingual Topic Models
</title>
<author confidence="0.997902">
David Mimno Hanna M. Wallach Jason Naradowsky David A. Smith Andrew McCallum
</author>
<affiliation confidence="0.999137">
University of Massachusetts, Amherst
</affiliation>
<address confidence="0.339753">
Amherst, MA 01003
</address>
<email confidence="0.240815">
{mimno, wallach, narad, dasmith, mccallum}cs.umass.edu
</email>
<sectionHeader confidence="0.982763" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999591875">
Topic models are a useful tool for analyz-
ing large text collections, but have previ-
ously been applied in only monolingual,
or at most bilingual, contexts. Mean-
while, massive collections of interlinked
documents in dozens of languages, such
as Wikipedia, are now widely available,
calling for tools that can characterize con-
tent in many languages. We introduce a
polylingual topic model that discovers top-
ics aligned across multiple languages. We
explore the model’s characteristics using
two large corpora, each with over ten dif-
ferent languages, and demonstrate its use-
fulness in supporting machine translation
and tracking topic trends across languages.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953">
Statistical topic models have emerged as an in-
creasingly useful analysis tool for large text col-
lections. Topic models have been used for analyz-
ing topic trends in research literature (Mann et al.,
2006; Hall et al., 2008), inferring captions for im-
ages (Blei and Jordan, 2003), social network anal-
ysis in email (McCallum et al., 2005), and expand-
ing queries with topically related words in infor-
mation retrieval (Wei and Croft, 2006). Much of
this work, however, has occurred in monolingual
contexts. In an increasingly connected world, the
ability to access documents in many languages has
become both a strategic asset and a personally en-
riching experience. In this paper, we present the
polylingual topic model (PLTM). We demonstrate
its utility and explore its characteristics using two
polylingual corpora: proceedings of the European
parliament (in eleven languages) and a collection
of Wikipedia articles (in twelve languages).
There are many potential applications for
polylingual topic models. Although research liter-
ature is typically written in English, bibliographic
databases often contain substantial quantities of
work in other languages. To perform topic-based
bibliometric analysis on these collections, it is
necessary to have topic models that are aligned
across languages. Such analysis could be sig-
nificant in tracking international research trends,
where language barriers slow the transfer of ideas.
Previous work on bilingual topic modeling
has focused on machine translation applications,
which rely on sentence-aligned parallel transla-
tions. However, the growth of the internet, and
in particular Wikipedia, has made vast corpora
of topically comparable texts—documents that are
topically similar but are not direct translations of
one another—considerably more abundant than
ever before. We argue that topic modeling is
both a useful and appropriate tool for leveraging
correspondences between semantically compara-
ble documents in multiple different languages.
In this paper, we use two polylingual corpora
to answer various critical questions related to
polylingual topic models. We employ a set of di-
rect translations, the EuroParl corpus, to evaluate
whether PLTM can accurately infer topics when
documents genuinely contain the same content.
We also explore how the characteristics of dif-
ferent languages affect topic model performance.
The second corpus, Wikipedia articles in twelve
languages, contains sets of documents that are not
translations of one another, but are very likely to
be about similar concepts. We use this corpus
to explore the ability of the model both to infer
similarities between vocabularies in different lan-
guages, and to detect differences in topic emphasis
between languages. The internet makes it possible
for people all over the world to access documents
from different cultures, but readers will not be flu-
ent in this wide variety of languages. By linking
topics across languages, polylingual topic mod-
els can increase cross-cultural understanding by
providing readers with the ability to characterize
</bodyText>
<page confidence="0.961409">
880
</page>
<note confidence="0.996637">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 880–889,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.973659">
the contents of collections in unfamiliar languages
and identify trends in topic prevalence.
</bodyText>
<sectionHeader confidence="0.999243" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99989425">
Bilingual topic models for parallel texts with
word-to-word alignments have been studied pre-
viously using the HM-bitam model (Zhao and
Xing, 2007). Tam, Lane and Schultz (Tam et
al., 2007) also show improvements in machine
translation using bilingual topic models. Both
of these translation-focused topic models infer
word-to-word alignments as part of their inference
procedures, which would become exponentially
more complex if additional languages were added.
We take a simpler approach that is more suit-
able for topically similar document tuples (where
documents are not direct translations of one an-
other) in more than two languages. A recent ex-
tended abstract, developed concurrently by Ni et
al. (Ni et al., 2009), discusses a multilingual topic
model similar to the one presented here. How-
ever, they evaluate their model on only two lan-
guages (English and Chinese), and do not use the
model to detect differences between languages.
They also provide little analysis of the differ-
ences between polylingual and single-language
topic models. Outside of the field of topic mod-
eling, Kawaba et al. (Kawaba et al., 2008) use
a Wikipedia-based model to perform sentiment
analysis of blog posts. They find, for example,
that English blog posts about the Nintendo Wii of-
ten relate to a hack, which cannot be mentioned in
Japanese posts due to Japanese intellectual prop-
erty law. Similarly, posts about whaling often
use (positive) nationalist language in Japanese and
(negative) environmentalist language in English.
</bodyText>
<sectionHeader confidence="0.998704" genericHeader="method">
3 Polylingual Topic Model
</sectionHeader>
<bodyText confidence="0.997487384615385">
The polylingual topic model (PLTM) is an exten-
sion of latent Dirichlet allocation (LDA) (Blei et
al., 2003) for modeling polylingual document tu-
ples. Each tuple is a set of documents that are
loosely equivalent to each other, but written in dif-
ferent languages, e.g., corresponding Wikipedia
articles in French, English and German. PLTM as-
sumes that the documents in a tuple share the same
tuple-specific distribution over topics. This is un-
like LDA, in which each document is assumed to
have its own document-specific distribution over
topics. Additionally, PLTM assumes that each
“topic” consists of a set of discrete distributions
</bodyText>
<figureCaption confidence="0.985456">
Figure 1: Graphical model for PLTM.
</figureCaption>
<bodyText confidence="0.999695333333333">
over words—one for each language l = 1, ... , L.
In other words, rather than using a single set of
topics Φ = {φ1, ... , φT}, as in LDA, there are L
sets of language-specific topics, Φ1, ... , ΦL, each
of which is drawn from a language-specific sym-
metric Dirichlet with concentration parameter βl.
</bodyText>
<subsectionHeader confidence="0.847937">
3.1 Generative Process
</subsectionHeader>
<bodyText confidence="0.99958875">
Anew document tuple w = (w1, ... , wL) is gen-
erated by first drawing a tuple-specific topic dis-
tribution from an asymmetric Dirichlet prior with
concentration parameter α and base measure m:
</bodyText>
<equation confidence="0.869926">
θ ∼ Dir (θ, αm). (1)
</equation>
<bodyText confidence="0.9970095">
Then, for each language l, a latent topic assign-
ment is drawn for each token in that language:
</bodyText>
<equation confidence="0.927044">
zl ∼ P(zl |θ) = 11n θzl . (2)
</equation>
<bodyText confidence="0.76290275">
Finally, the observed tokens are themselves drawn
using the language-specific topic parameters:
wl ∼ P(wl  |zl,Φl) = 11n φlwl |zl .(3)
The graphical model is shown in figure 1.
</bodyText>
<subsectionHeader confidence="0.943629">
3.2 Inference
</subsectionHeader>
<bodyText confidence="0.9860838">
Given a corpus of training and test document
tuples—W and W&apos;, respectively—two possible
inference tasks of interest are: computing the
probability of the test tuples given the training
tuples and inferring latent topic assignments for
test documents. These tasks can either be accom-
plished by averaging over samples of Φ1, . . . , ΦL
and αm from P(Φ1, ... , ΦL, αm  |W&apos;, β) or by
evaluating a point estimate. We take the lat-
ter approach, and use the MAP estimate for αm
and the predictive distributions over words for
Φ1, . . . , ΦL.The probability of held-out docu-
ment tuples W&apos; given training tuples W is then
approximated by
Topic assignments for a test document tuple
</bodyText>
<equation confidence="0.566415529411765">
w = (w1, ... , wL) can be inferred using Gibbs
α 0
...
Z
Z W
W
N1
NL
D
EP1
S1
...
EPL
T
SL
P( &apos;I L )
W �,..., � ,am .
</equation>
<page confidence="0.962869">
881
</page>
<bodyText confidence="0.9298455">
sampling. Gibbs sampling involves sequentially
resampling each zln from its conditional posterior:
</bodyText>
<equation confidence="0.997946">
l L
�1 , ... , ,
P(zn = t  |w, z\l,n, αm)
</equation>
<bodyText confidence="0.99995525">
where z\l,n is the current set of topic assignments
for all other tokens in the tuple, while (Nt)\l,n is
the number of occurrences of topic t in the tuple,
excluding zln, the variable being resampled.
</bodyText>
<sectionHeader confidence="0.999106" genericHeader="method">
4 Results on Parallel Text
</sectionHeader>
<bodyText confidence="0.99996925">
Our first set of experiments focuses on document
tuples that are known to consist of direct transla-
tions. In this case, we can be confident that the
topic distribution is genuinely shared across all
languages. Although direct translations in multi-
ple languages are relatively rare (in contrast with
comparable documents), we use direct translations
to explore the characteristics of the model.
</bodyText>
<subsectionHeader confidence="0.998922">
4.1 Data Set
</subsectionHeader>
<bodyText confidence="0.9999615">
The EuroParl corpus consists of parallel texts in
eleven western European languages: Danish, Ger-
man, Greek, English, Spanish, Finnish, French,
Italian, Dutch, Portuguese and Swedish. These
texts consist of roughly a decade of proceedings
of the European parliament. For our purposes we
use alignments at the speech level rather than the
sentence level, as in many translation tasks using
this corpus. We also remove the twenty-five most
frequent word types for efficiency reasons. The
remaining collection consists of over 121 million
words. Details by language are shown in Table 1.
</bodyText>
<tableCaption confidence="0.9915845">
Table 1: Average document length, # documents, and
unique word types per 10,000 tokens in the EuroParl corpus.
</tableCaption>
<table confidence="0.965148117647059">
Lang. Avg. leng. # docs types/10k
DA 160.153 65245 121.4
DE 178.689 66497 124.5
EL 171.289 46317 124.2
EN 176.450 69522 43.1
ES 170.536 65929 59.5
FI 161.293 60822 336.2
FR 186.742 67430 54.8
IT 187.451 66035 69.5
NL 176.114 66952 80.8
PT 183.410 65718 68.2
SV 154.605 58011 136.1
Models are trained using 1000 iterations of
Gibbs sampling. Each language-specific topic–
word concentration parameter βl is set to 0.01.
DA centralbank europeaiske ecb s lŒn centralbanks
DE zentralbank ezb bank europŠischen investitionsbank darlehen
EL τράπεζα τράπεζας κεντρική εκτ κεντρικής τράπεζες
EN bank central ecb banks european monetary
ES banco central europeo bce bancos centrales
FI keskuspankin ekp n euroopan keskuspankki eip
FR banque centrale bce europ6enne banques mon6taire
IT banca centrale bce europea banche prestiti
NL bank centrale ecb europese banken leningen
PT banco central europeu bce bancos empr6stimos
SV centralbanken europeiska ecb centralbankens s lŒn
DA b¿rn familie udnyttelse b¿rns b¿rnene seksuel
DE kinder kindern familie ausbeutung familien eltern
EL παιδιά παιδιών οικογένεια οικογένειας γονείς παιδικής
EN children family child sexual families exploitation
ES ni–os familia hijos sexual infantil menores
FI lasten lapsia lapset perheen lapsen lapsiin
FR enfants famille enfant parents exploitation familles
IT bambini famiglia figli minori sessuale sfruttamento
NL kinderen kind gezin seksuele ouders familie
PT criangas fam’lia filhos sexual crianga infantil
SV barn barnen familjen sexuellt familj utnyttjande
DA mŒl nŒ mŒlseatninger mŒlet mŒlseatning opnŒ
DE ziel ziele erreichen zielen erreicht zielsetzungen
EL στόχους στόχο στόχος στόχων στόχοι επίτευξη
EN objective objectives achieve aim ambitious set
ES objetivo objetivos alcanzar conseguir lograr estos
FI tavoite tavoitteet tavoitteena tavoitteiden tavoitteita tavoitteen
FR objectif objectifs atteindre but cet ambitieux
IT obiettivo obiettivi raggiungere degli scopo quello
NL doelstellingen doel doelstelling bereiken bereikt doelen
PT objectivo objectivos alcangar atingir ambicioso conseguir
SV mŒl mŒlet uppnŒ mŒlen mŒlsŠttningar mŒlsŠttning
DA andre anden side ene andet ¿vrige
DE anderen andere einen wie andererseits anderer
EL άλλες άλλα άλλη άλλων άλλους όπως
</table>
<tableCaption confidence="0.32485">
EN other one hand others another there
</tableCaption>
<bodyText confidence="0.882881571428571">
ES otros otras otro otra parte dem‡s
FI muiden toisaalta muita muut muihin muun
FR autres autre part cTMt6 ailleurs m6me
IT altri altre altro altra dall parte
NL andere anderzijds anderen ander als kant
PT outros outras outro lado outra noutros
SV andra sidan Œ annat ena annan
</bodyText>
<figureCaption confidence="0.997028">
Figure 2: EuroParl topics (T=400)
</figureCaption>
<bodyText confidence="0.9999888">
The concentration parameter α for the prior over
document-specific topic distributions is initialized
to 0.01 T, while the base measure m is initialized
to the uniform distribution. Hyperparameters αm
are re-estimated every 10 Gibbs iterations.
</bodyText>
<subsectionHeader confidence="0.999903">
4.2 Analysis of Trained Models
</subsectionHeader>
<bodyText confidence="0.9999405">
Figure 2 shows the most probable words in all lan-
guages for four example topics, from PLTM with
400 topics. The first topic contains words relating
to the European Central Bank. This topic provides
an illustration of the variation in technical ter-
minology captured by PLTM, including the wide
array of acronyms used by different languages.
The second topic, concerning children, demon-
strates the variability of everyday terminology: al-
though the four Romance languages are closely
</bodyText>
<equation confidence="0.9013568">
∝l
�t
φwln
Et Nt − 1 + α, (4)
(Nt)\l,n + αmt
</equation>
<page confidence="0.980435">
882
</page>
<bodyText confidence="0.99998725">
related, they use etymologically unrelated words
for children. (Interestingly, all languages except
Greek and Finnish use closely related words for
“youth” or “young” in a separate topic.) The third
topic demonstrates differences in inflectional vari-
ation. English and the Romance languages use
only singular and plural versions of “objective.”
The other Germanic languages include compound
words, while Greek and Finnish are dominated by
inflected variants of the same lexical item. The fi-
nal topic demonstrates that PLTM effectively clus-
ters “syntactic” words, as well as more semanti-
cally specific nouns, adjectives and verbs.
Although the topics in figure 2 seem highly fo-
cused, it is interesting to ask whether the model
is genuinely learning mixtures of topics or simply
assigning entire document tuples to single topics.
To answer this question, we compute the posterior
probability of each topic in each tuple under the
trained model. If the model assigns all tokens in
a tuple to a single topic, the maximum posterior
topic probability for that tuple will be near to 1.0.
If the model assigns topics uniformly, the maxi-
mum topic probability will be near 1/T. We com-
pute histograms of these maximum topic prob-
abilities for T ∈ {50,100, 200, 400, 800}. For
clarity, rather than overlaying five histograms, fig-
ure 3 shows the histograms converted into smooth
curves using a kernel density estimator.1 Although
there is a small bump around 1.0 (for extremely
short documents, e.g., “Applause”), values are
generally closer to, but greater than, 1/T.
</bodyText>
<subsectionHeader confidence="0.741266">
Smoothed histograms of max(P(t))
</subsectionHeader>
<bodyText confidence="0.405996">
Maximum topic probability in document
</bodyText>
<figureCaption confidence="0.994746">
Figure 3: Smoothed histograms of the probability of the
most probable topic in a document tuple.
</figureCaption>
<bodyText confidence="0.97795978125">
Although the posterior distribution over topics
for each tuple is not concentrated on one topic,
it is worth checking that this is not simply be-
cause the model is assigning a single topic to the
1We use the R density function.
tokens in each of the languages. Although the
model does not distinguish between topic assign-
ment variables within a given document tuple (so
it is technically incorrect to speak of different pos-
terior distributions over topics for different docu-
ments in a given tuple), we can nevertheless divide
topic assignment variables between languages and
use them to estimate a Dirichlet-multinomial pos-
terior distribution for each language in each tuple.
For each tuple we can then calculate the Jensen-
Shannon divergence (the average of the KL di-
vergences between each distribution and a mean
distribution) between these distributions. Figure 4
shows the density of these divergences for differ-
ent numbers of topics. As with the previous fig-
ure, there are a small number of documents that
contain only one topic in all languages, and thus
have zero divergence. These tend to be very short,
formulaic parliamentary responses, however. The
vast majority of divergences are relatively low (1.0
indicates no overlap in topics between languages
in a given document tuple) indicating that, for each
tuple, the model is not simply assigning all tokens
in a particular language to a single topic. As the
number of topics increases, greater variability in
topic distributions causes divergence to increase.
Smoothed histograms of inter−language JS divergence
</bodyText>
<figure confidence="0.343649">
Jensen−Shannon Divergence
</figure>
<figureCaption confidence="0.995937333333333">
Figure 4: Smoothed histograms of the Jensen-Shannon
divergences between the posterior probability of topics be-
tween languages.
</figureCaption>
<subsectionHeader confidence="0.984156">
4.3 Language Model Evaluation
</subsectionHeader>
<bodyText confidence="0.999878444444444">
A topic model specifies a probability distribution
over documents, or in the case of PLTM, docu-
ment tuples. Given a set of training document tu-
ples, PLTM can be used to obtain posterior esti-
mates of Φ&apos;, ... , ΦL and αm. The probability of
previously unseen held-out document tuples given
these estimates can then be computed. The higher
the probability of the held-out document tuples,
the better the generalization ability of the model.
</bodyText>
<figure confidence="0.995806625">
0.0 0.2 0.4 0.6 0.8 1.0
Density
0 2 4 6 8 10 12
800 topics
400 topics
200 topics
100 topics
50 topics
0.0 0.1 0.2 0.3 0.4 0.5
Density
0 5 10 15 20
800 topics
400 topics
200 topics
100 topics
50 topics
</figure>
<page confidence="0.995768">
883
</page>
<bodyText confidence="0.999983904761905">
Analytically calculating the probability of a set
of held-out document tuples given Φ1, ... , ΦL and
αm is intractable, due to the summation over an
exponential number of topic assignments for these
held-out documents. However, recently developed
methods provide efficient, accurate estimates of
this probability. We use the “left-to-right” method
of (Wallach et al., 2009). We perform five esti-
mation runs for each document and then calculate
standard errors using a bootstrap method.
Table 2 shows the log probability of held-out
data in nats per word for PLTM and LDA, both
trained with 200 topics. There is substantial varia-
tion between languages. Additionally, the predic-
tive ability of PLTM is consistently slightly worse
than that of (monolingual) LDA. It is important to
note, however, that these results do not imply that
LDA should be preferred over PLTM—that choice
depends upon the needs of the modeler. Rather,
these results are intended as a quantitative analy-
sis of the difference between the two models.
</bodyText>
<tableCaption confidence="0.98107025">
Table 2: Held-out log probability in nats/word. (Smaller
magnitude implies better language modeling performance.)
PLTM does slightly worse than monolingual LDA models,
but the variation between languages is much larger.
</tableCaption>
<table confidence="0.999284333333333">
Lang PLTM sd LDA sd
DA -8.11 0.00067 -8.02 0.00066
DE -8.17 0.00057 -8.08 0.00072
EL -8.44 0.00079 -8.36 0.00087
EN -7.51 0.00064 -7.42 0.00069
ES -7.98 0.00073 -7.87 0.00070
FI -9.25 0.00089 -9.21 0.00065
FR -8.26 0.00072 -8.19 0.00058
IT -8.11 0.00071 -8.02 0.00058
NL -7.84 0.00067 -7.75 0.00099
PT -7.87 0.00085 -7.80 0.00060
SV -8.25 0.00091 -8.16 0.00086
</table>
<bodyText confidence="0.999072">
As the number of topics is increased, the word
counts per topic become very sparse in mono-
lingual LDA models, proportional to the size of
the vocabulary. Figure 5 shows the proportion
of all tokens in English and Finnish assigned to
each topic under LDA and PLTM with 800 topics.
More than 350 topics in the Finnish LDA model
have zero tokens assigned to them, and almost all
tokens are assigned to the largest 200 topics. En-
glish has a larger tail, with non-zero counts in all
but 16 topics. In contrast, PLTM assigns a sig-
nificant number of tokens to almost all 800 top-
ics, in very similar proportions in both languages.
PLTM topics therefore have a higher granularity –
i.e., they are more specific. This result is impor-
tant: informally, we have found that increasing the
granularity of topics correlates strongly with user
perceptions of the utility of a topic model.
</bodyText>
<figure confidence="0.883501">
0 200 400 BOO 800
Sorted topic rank
</figure>
<figureCaption confidence="0.994584">
Figure 5: Topics sorted by number of words assigned.
Finnish is in black, English is in red; LDA is solid, PLTM is
dashed. LDA in Finnish essentially learns a 200 topic model
when given 800 topics, while PLTM uses all 800 topics.
</figureCaption>
<subsectionHeader confidence="0.992512">
4.4 Partly Comparable Corpora
</subsectionHeader>
<bodyText confidence="0.99996265625">
An important application for polylingual topic
modeling is to use small numbers of comparable
document tuples to link topics in larger collections
of distinct, non-comparable documents in multiple
languages. For example, a journal might publish
papers in English, French, German and Italian. No
paper is exactly comparable to any other paper, but
they are all roughly topically similar. If we wish
to perform topic-based bibliometric analysis, it is
vital to be able to track the same topics across all
languages. One simple way to achieve this topic
alignment is to add a small set of comparable doc-
ument tuples that provide sufficient “glue” to bind
the topics together. Continuing with the exam-
ple above, one might extract a set of connected
Wikipedia articles related to the focus of the jour-
nal and then train PLTM on a joint corpus consist-
ing of journal papers and Wikipedia articles.
In order to simulate this scenario we create a
set of variations of the EuroParl corpus by treat-
ing some documents as if they have no paral-
lel/comparable texts – i.e., we put each of these
documents in a single-document tuple. To do this,
we divide the corpus W into two sets of document
tuples: a “glue” set G and a “separate” set S such
that |G |/ |W |= p. In other words, the proportion
of tuples in the corpus that are treated as “glue”
(i.e., placed in G) is p. For every tuple in S, we
assign each document in that tuple to a new single-
document tuple. By doing this, every document in
S has its own distribution over topics, independent
of any other documents. Ideally, the “glue” doc-
</bodyText>
<figure confidence="0.5828875">
0.00 0.01 0.02 0.03 0.04
Percentage of tokens
</figure>
<page confidence="0.987638">
884
</page>
<bodyText confidence="0.99986475">
uments in g will be sufficient to align the topics
across languages, and will cause comparable doc-
uments in S to have similar distributions over top-
ics even though they are modeled independently.
</bodyText>
<tableCaption confidence="0.9996654">
Table 3: The effect of the proportion P of “glue” tuples on
mean Jensen-Shannon divergence in estimated topic distribu-
tions for pairs of documents in S that were originally part of
a document tuple. Lower divergence means the topic distri-
butions distributions are more similar to each other.
</tableCaption>
<table confidence="0.999604833333333">
P Mean JS # of pairs Std. Err.
0.01 0.83755 487670 0.00018
0.05 0.79144 467288 0.00021
0.1 0.70228 443753 0.00026
0.25 0.38480 369608 0.00029
0.5 0.29712 246380 0.00030
</table>
<tableCaption confidence="0.7758186">
Table 4: Topics are meaningful within languages but di-
verge between languages when only 1% of tuples are treated
as “glue” tuples. With 25% “glue” tuples, topics are aligned.
DE rußland russland russischen tschetschenien sicherheit
EN china rights human country s burma
</tableCaption>
<bodyText confidence="0.922499368421053">
FR russie tch´etch´enie union avec russe r´egion
IT ho presidente mi perch´e relazione votato
lang Topics at P = 0.25
DE rußland russland russischen tschetschenien ukraine
EN russia russian chechnya cooperation region belarus
FR russie tch´etch´enie avec russe russes situation
IT russia unione cooperazione cecenia regione russa
We train PLTM with 100 topics on corpora with
p E 10.01, 0.05, 0.1, 0.25, 0.5}. We use 1000 it-
erations of Gibbs sampling with Q = 0.01. Hy-
perparameters αm are re-estimated every 10 it-
erations. We calculate the Jensen-Shannon diver-
gence between the topic distributions for each pair
of individual documents in S that were originally
part of the same tuple prior to separation. The
lower the divergence, the more similar the distri-
butions are to each other. From the results in fig-
ure 4, we know that leaving all document tuples
intact should result in a mean JS divergence of
less than 0.1. Table 3 shows mean JS divergences
for each value of p. As expected, JS divergence is
greater than that obtained when all tuples are left
intact. Divergence drops significantly when the
proportion of “glue” tuples increases from 0.01 to
0.25. Example topics for p = 0.01 and p = 0.25
are shown in table 4. At p = 0.01 (1% “glue” doc-
uments), German and French both include words
relating to Russia, while the English and Italian
word distributions appear locally consistent but
unrelated to Russia. At p = 0.25, the top words
for all four languages are related to Russia.
These results demonstrate that PLTM is appro-
priate for aligning topics in corpora that have only
a small subset of comparable documents. One area
for future work is to explore whether initializa-
tion techniques or better representations of topic
co-occurrence might result in alignment of topics
with a smaller proportion of comparable texts.
</bodyText>
<subsectionHeader confidence="0.976978">
4.5 Machine Translation
</subsectionHeader>
<bodyText confidence="0.991273365853658">
Although the PLTM is clearly not a substitute for
a machine translation system—it has no way to
represent syntax or even multi-word phrases—it is
clear from the examples in figure 2 that the sets of
high probability words in different languages for a
given topic are likely to include translations. We
therefore evaluate the ability of the PLTM to gen-
erate bilingual lexica, similar to other work in un-
supervised translation modeling (Haghighi et al.,
2008). In the early statistical translation model
work at IBM, these representations were called
“cepts,” short for concepts (Brown et al., 1993).
We evaluate sets of high-probability words in
each topic and multilingual “synsets” by compar-
ing them to entries in human-constructed bilingual
dictionaries, as done by Haghighi et al. (2008).
Unlike previous work (Koehn and Knight, 2002),
we evaluate all words, not just nouns. We col-
lected bilingual lexica mapping English words to
German, Greek, Spanish, French, Italian, Dutch
and Swedish. Each lexicon is a set of pairs con-
sisting of an English word and a translated word,
1we, wt}. We do not consider multi-word terms.
We expect that simple analysis of topic assign-
ments for sequential words would yield such col-
locations, but we leave this for future work.
For every topic t we select a small number K
of the most probable words in English (e) and
in each “translation” language (E): Wte and Wtt,
respectively. We then add the Cartesian product
of these sets for every topic to a set of candidate
translations C. We report the number of elements
of C that appear in the reference lexica. Results
for K = 1, that is, considering only the single
most probable word for each language, are shown
in figure 6. Precision at this level is relatively
high, above 50% for Spanish, French and Italian
with T = 400 and 800. Many of the candidate
pairs that were not in the bilingual lexica were
valid translations (e.g. EN “comitology” and IT
lang Topics at P = 0.01
</bodyText>
<page confidence="0.91571">
885
</page>
<figure confidence="0.996819285714286">
% of transl at rank
Rank 1
Rank 5
Rank 10
Rank 20
40 50 60 70 80 90 100
0 50 100 200
</figure>
<bodyText confidence="0.996420142857143">
“comitalogia”) that simply were not in the lexica.
We also do not count morphological variants: the
model finds EN “rules” and DE “vorschriften,” but
the lexicon contains only “rule” and “vorschrift.”
Results remain strong as we increase K. With
K = 3, T = 800, 1349 of the 7200 candidate
pairs for Spanish appeared in the lexicon.
</bodyText>
<figure confidence="0.854313333333333">
Min query doc length
Translation pairs at K=1
Topics
</figure>
<figureCaption confidence="0.986474">
Figure 6: Are the single most probable words for a given
</figureCaption>
<bodyText confidence="0.76760975">
topic in different languages translations of each other? The
number of such pairs that appear in bilingual lexica is shown
on the y-axis. For T = 800, the top English and Spanish
words in 448 topics were exact translations of one another.
</bodyText>
<subsectionHeader confidence="0.997086">
4.6 Finding Translations
</subsectionHeader>
<bodyText confidence="0.998903269230769">
In addition to enhancing lexicons by aligning
topic-specific vocabulary, PLTM may also be use-
ful for adapting machine translation systems to
new domains by finding translations or near trans-
lations in an unstructured corpus. These aligned
document pairs could then be fed into standard
machine translation systems as training data. To
evaluate this scenario, we train PLTM on a set of
document tuples from EuroParl, infer topic distri-
butions for a set of held-out documents, and then
measure our ability to align documents in one lan-
guage with their translations in another language.
It is not necessarily clear that PLTM will be ef-
fective at identifying translations. In finding a low-
dimensional semantic representation, topic mod-
els deliberately smooth over much of the varia-
tion present in language. We are therefore inter-
ested in determining whether the information in
the document-specific topic distributions is suffi-
cient to identify semantically identical documents.
We begin by dividing the data into a training
set of 69,550 document tuples and a test set of
17,435 document tuples. In order to make the task
more difficult, we train a relatively coarse-grained
PLTM with 50 topics on the training set. We then
use this model to infer topic distributions for each
</bodyText>
<figureCaption confidence="0.982607">
Figure 7: Percent of query language documents for which
the target language translation is ranked at or above 1, 5, 10
or 20 by JS divergence, averaged over all language pairs.
</figureCaption>
<bodyText confidence="0.999983322580645">
of the 11 documents in each of the held-out doc-
ument tuples using a method similar to that used
to calculate held-out probabilities (Wallach et al.,
2009). Finally, for each pair of languages (“query”
and “target”) we calculate the difference between
the topic distribution for each held-out document
in the query language and the topic distribution for
each held-out document in the target language. We
use both Jensen-Shannon divergence and cosine
distance. For each document in the query language
we rank all documents in the target language and
record the rank of the actual translation.
Results averaged over all query/target language
pairs are shown in figure 7 for Jensen-Shannon
divergence. Cosine-based rankings are signifi-
cantly worse. It is important to note that the
length of documents matters. As noted before,
many of the documents in the EuroParl collection
consist of short, formulaic sentences. Restrict-
ing the query/target pairs to only those with query
and target documents that are both longer than 50
words results in significant improvement and re-
duced variance: the average proportion of query
documents for which the true translation is ranked
highest goes from 53.9% to 72.7%. Performance
continues to improve with longer documents, most
likely due to better topic inference. Results vary
by language. Table 5 shows results for all tar-
get languages with English as a query language.
Again, English generally performs better with Ro-
mance languages than Germanic languages.
</bodyText>
<sectionHeader confidence="0.998763" genericHeader="evaluation">
5 Results on Comparable Texts
</sectionHeader>
<bodyText confidence="0.9346525">
Directly parallel translations are rare in many lan-
guages and can be extremely expensive to pro-
duce. However, the growth of the web, and in par-
ticular Wikipedia, has made comparable text cor-
</bodyText>
<figure confidence="0.992672210526316">
200 400 600 800
Correct translations
0 100 200 300 400 500
●
●●
ES
FR
IT
DE
SV
EL
●
●
● ●
●
●
●
●
●
●
●
886
FI
EN
PL
RU
DE
FR
IT
HE
CY
EL
FA
TR
IT
FR
EL
TR
FA
CY
EN
RU
CY
EN
DE
PL
RU
FI
FI
PL
DE
EL
TR
FA
FR
IT
HE
</figure>
<figureCaption confidence="0.60884925">
Figure 8: Squares represent the proportion of tokens in each language assigned to a topic. The left topic, world ski km won,
centers around Nordic counties. The center topic, actor role television actress, is relatively uniform. The right topic, ottoman
empire khan byzantine, is popular in all languages but especially in regions near Istanbul.
Table 5: Percent of English query documents for which the
translation was in the top n ∈ {1, 5, 10, 20} documents by JS
divergence between topic distributions. To reduce the effect
of short documents we consider only document pairs where
the query and target documents are longer than 100 words.
</figureCaption>
<table confidence="0.999707272727273">
Lang 1 5 10 20
DA 78.0 90.7 93.8 95.8
DE 76.6 90.0 93.4 95.5
EL 77.1 90.4 93.3 95.2
ES 81.2 92.3 94.8 96.7
FI 76.7 91.0 94.0 96.3
FR 80.1 91.7 94.3 96.2
IT 79.1 91.2 94.1 96.2
NL 76.6 90.1 93.4 95.5
PT 80.8 92.0 94.7 96.5
SV 80.4 92.1 94.9 96.5
</table>
<bodyText confidence="0.999301315789474">
pora – documents that are topically similar but are
not direct translations of one another – consider-
ably more abundant than true parallel corpora.
In this section, we explore two questions re-
lating to comparable text corpora and polylingual
topic modeling. First, we explore whether com-
parable document tuples support the alignment of
fine-grained topics, as demonstrated earlier using
parallel documents. This property is useful for
building machine translation systems as well as
for human readers who are either learning new
languages or analyzing texts in languages they do
not know. Second, because comparable texts may
not use exactly the same topics, it becomes cru-
cially important to be able to characterize differ-
ences in topic prevalence at the document level (do
different languages have different perspectives on
the same article?) and at the language-wide level
(which topics do particular languages focus on?).
</bodyText>
<subsectionHeader confidence="0.975852">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.9999835">
We downloaded XML copies of all Wikipedia ar-
ticles in twelve different languages: Welsh, Ger-
man, Greek, English, Farsi, Finnish, French, He-
brew, Italian, Polish, Russian and Turkish. These
versions of Wikipedia were selected to provide a
diverse range of language families, geographic ar-
eas, and quantities of text. We preprocessed the
data by removing tables, references, images and
info-boxes. We dropped all articles in non-English
languages that did not link to an English article. In
the English version of Wikipedia we dropped all
articles that were not linked to by any other lan-
guage in our set. For efficiency, we truncated each
article to the nearest word after 1000 characters
and dropped the 50 most common word types in
each language. Even with these restrictions, the
size of the corpus is 148.5 million words.
We present results for a PLTM with 400 topics.
1000 Gibbs sampling iterations took roughly four
days on one CPU with current hardware.
</bodyText>
<subsectionHeader confidence="0.6345965">
5.2 Which Languages Have High Topic
Divergence?
</subsectionHeader>
<bodyText confidence="0.999950461538462">
As with EuroParl, we can calculate the Jensen-
Shannon divergence between pairs of documents
within a comparable document tuple. We can then
average over all such document-document diver-
gences for each pair of languages to get an over-
all “disagreement” score between languages. In-
terestingly, we find that almost all languages in
our corpus, including several pairs that have his-
torically been in conflict, show average JS diver-
gences of between approximately 0.08 and 0.12
for T = 400, consistent with our findings for
EuroParl translations. Subtle differences of sen-
timent may be below the granularity of the model.
</bodyText>
<page confidence="0.990502">
887
</page>
<bodyText confidence="0.98411575">
sadwrn blaned gallair at lloeren mytholeg
space nasa sojus flug mission
διαστημικό sts nasa αγγλ small
space mission launch satellite nasa spacecraft
</bodyText>
<equation confidence="0.609661">
ﻩﺭ ﺍﻮﻫ ﺎﻣ
</equation>
<bodyText confidence="0.948708272727273">
sojuz nasa apollo ensimmŠinen space lento
spatiale mission orbite mars satellite spatial
תינכות א רודכ לל ח ץר אה ללחה
spaziale missione programma space sojuz stazione
misja kosmicznej stacji misji space nasa
космический союз космического спутник станции
uzay soyuz ay uzaya salyut sovyetler
sbaen madrid el la jos6 sbaeneg
de spanischer spanischen spanien madrid la
ισπανίας ισπανία de ισπανός ντε μαδρίτη
de spanish spain la madrid y
</bodyText>
<equation confidence="0.72034">
ﺪﯾﺭﺩ ﺎﻣ ﺎﺑﻮ3 ﯽﯾ ﺎﯿﻧ ﺎﭙﺳ ﺍ ﺎﯿﻧ ﺎﭙﺳ ﺍ de ﻦﯾﺮﺗ
</equation>
<bodyText confidence="0.8531125">
espanja de espanjan madrid la real
espagnol espagne madrid espagnole juan y
de spagna spagnolo spagnola madrid el
de hiszpański hiszpanii la juan y
де мадрид испании испания испанский de
ispanya ispanyol madrid la kOba real
bardd gerddi iaith beirdd fardd gymraeg
dichter schriftsteller literatur gedichte gedicht werk
ποιητής ποίηση ποιητή έργο ποιητές ποιήματα
poet poetry literature literary poems poem
runoilija kirjailija kirjallisuuden kirjoitti runo julkaisi
poste 6crivain litt6rature po6sie litt6raire ses
</bodyText>
<figure confidence="0.8229206">
ררו שמה ם יריש רפוס הר יש תורפס ררו שמ
poeta letteratura poesia opere versi poema
poeta literatury poezji pisarz in jego
поэт его писатель литературы поэзии драматург
şair edebiyat şiir yazar edebiyatõ adlõ
</figure>
<figureCaption confidence="0.999872">
Figure 9: Wikipedia topics (T=400).
</figureCaption>
<bodyText confidence="0.999161333333333">
Overall, these scores indicate that although indi-
vidual pages may show disagreement, Wikipedia
is on average consistent between languages.
</bodyText>
<subsectionHeader confidence="0.9873065">
5.3 Are Topics Emphasized Differently
Between Languages?
</subsectionHeader>
<bodyText confidence="0.999983210526316">
Although we find that if Wikipedia contains an ar-
ticle on a particular subject in some language, the
article will tend to be topically similar to the arti-
cles about that subject in other languages, we also
find that across the whole collection different lan-
guages emphasize topics to different extents. To
demonstrate the wide variation in topics, we cal-
culated the proportion of tokens in each language
assigned to each topic. Figure 8 represents the es-
timated probabilities of topics given a specific lan-
guage. Competitive cross-country skiing (left) ac-
counts for a significant proportion of the text in
Finnish, but barely exists in Welsh and the lan-
guages in the Southeastern region. Meanwhile,
interest in actors and actresses (center) is consis-
tent across all languages. Finally, historical topics,
such as the Byzantine and Ottoman empires (right)
are strong in all languages, but show geographical
variation: interest centers around the empires.
</bodyText>
<sectionHeader confidence="0.999285" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999995444444445">
We introduced a polylingual topic model (PLTM)
that discovers topics aligned across multiple lan-
guages. We analyzed the characteristics of PLTM
in comparison to monolingual LDA, and demon-
strated that it is possible to discover aligned top-
ics. We also demonstrated that relatively small
numbers of topically comparable document tu-
ples are sufficient to align topics between lan-
guages in non-comparable corpora. Additionally,
PLTM can support the creation of bilingual lexica
for low resource language pairs, providing candi-
date translations for more computationally intense
alignment processes without the sentence-aligned
translations typically used in such tasks. When
applied to comparable document collections such
as Wikipedia, PLTM supports data-driven analysis
of differences and similarities across all languages
for readers who understand any one language.
</bodyText>
<sectionHeader confidence="0.999215" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999985071428572">
The authors thank Limin Yao, who was involved
in early stages of this project. This work was
supported in part by the Center for Intelligent In-
formation Retrieval, in part by The Central In-
telligence Agency, the National Security Agency
and National Science Foundation under NSF grant
number IIS-0326249, and in part by Army prime
contract number W911NF-07-1-0216 and Uni-
versity of Pennsylvania subaward number 103-
548106, and in part by National Science Founda-
tion under NSF grant #CNS-0619337. Any opin-
ions, findings and conclusions or recommenda-
tions expressed in this material are the authors’
and do not necessarily reflect those of the sponsor.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999637125">
David Blei and Michael Jordan. 2003. Modeling an-
notated data. In SIGIR.
David Blei, Andrew Ng, and Michael Jordan. 2003.
Latent Dirichlet allocation. JMLR.
Peter F Brown, Stephen A Della Pietra, Vincent J Della
Pietra, and Robert L Mercer. 1993. The mathemat-
ics of statistical machine translation: Parameter esti-
mation. CL, 19(2):263–311.
</reference>
<figure confidence="0.99940901724138">
הבו
ידרפסה דירדמ הד ת
ידרפס דרפס
ק ת
ﺩ
ﺎﺷ
ﺕ
ﺭ
ﺍ ﺮﻌﺷ
ﺮﻋ
ﯿﺑ
ﺎﺛﺁ ﯽﺑ
ﺩ ﺍ ﯽﺳﺭﺎﻓ
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
CY
DE
EL
EN
FA
FI
FR
HE
IT
PL
RU
TR
ﺭ
ﺎﻀﻓ
ﺎﻀﻓ
ﺎﻣ
ﯽﯾ
ﺍ ﺪﻣ ﺎﺳ ﺎﻧ
ﺩﺭﻮﻧ
ﺭﻮﻣ
ﺖﯾ
</figure>
<page confidence="0.971305">
888
</page>
<reference confidence="0.999808342857143">
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In ACL, pages 771–779.
David Hall, Daniel Jurafsky, and Christopher D. Man-
ning. 2008. Studying the history of ideas using
topic models. In EMNLP.
Mariko Kawaba, Hiroyuki Nakasaki, Takehito Utsuro,
and Tomohiro Fukuhara. 2008. Cross-lingual blog
analysis based on multilingual blog distillation from
multilingual Wikipedia entries. In ICWSM.
Philipp Koehn and Kevin Knight. 2002. Learn-
ing a translation lexicon from monolingual corpora.
In Proceedings of ACL Workshop on Unsupervised
Lexical Acquisition.
Gideon Mann, David Mimno, and Andrew McCal-
lum. 2006. Bibliometric impact measures leverag-
ing topic analysis. In JCDL.
Andrew McCallum, Andr´es Corrada-Emmanuel, and
Xuerui Wang. 2005. Topic and role discovery in
social networks. In IJCAI.
Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2009. Mining multilingual topics from Wikipedia.
In WWW.
Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007.
Bilingual LSA-based adaptation for statistical ma-
chine translation. Machine Translation, 28:187–
207.
Hanna Wallach, Iain Murray, Ruslan Salakhutdinov,
and David Mimno. 2009. Evaluation methods for
topic models. In ICML.
Xing Wei and Bruce Croft. 2006. LDA-based docu-
ment models for ad-hoc retrieval. In SIGIR.
Bing Zhao and Eric P. Xing. 2007. HM-BiTAM: Bilin-
gual topic exploration, word alignment, and transla-
tion. In NIPS.
</reference>
<page confidence="0.998969">
889
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.982456">
<title confidence="0.999907">Polylingual Topic Models</title>
<author confidence="0.999923">David Mimno Hanna M Wallach Jason Naradowsky David A Smith Andrew McCallum</author>
<affiliation confidence="0.997974">University of Massachusetts, Amherst</affiliation>
<address confidence="0.999983">Amherst, MA 01003</address>
<email confidence="0.989297">wallach,narad,dasmith,</email>
<abstract confidence="0.999705235294118">Topic models are a useful tool for analyzing large text collections, but have previously been applied in only monolingual, or at most bilingual, contexts. Meanwhile, massive collections of interlinked documents in dozens of languages, such as Wikipedia, are now widely available, calling for tools that can characterize content in many languages. We introduce a polylingual topic model that discovers topics aligned across multiple languages. We explore the model’s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Michael Jordan</author>
</authors>
<title>Modeling annotated data.</title>
<date>2003</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="1169" citStr="Blei and Jordan, 2003" startWordPosition="173" endWordPosition="176">t in many languages. We introduce a polylingual topic model that discovers topics aligned across multiple languages. We explore the model’s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages. 1 Introduction Statistical topic models have emerged as an increasingly useful analysis tool for large text collections. Topic models have been used for analyzing topic trends in research literature (Mann et al., 2006; Hall et al., 2008), inferring captions for images (Blei and Jordan, 2003), social network analysis in email (McCallum et al., 2005), and expanding queries with topically related words in information retrieval (Wei and Croft, 2006). Much of this work, however, has occurred in monolingual contexts. In an increasingly connected world, the ability to access documents in many languages has become both a strategic asset and a personally enriching experience. In this paper, we present the polylingual topic model (PLTM). We demonstrate its utility and explore its characteristics using two polylingual corpora: proceedings of the European parliament (in eleven languages) and</context>
</contexts>
<marker>Blei, Jordan, 2003</marker>
<rawString>David Blei and Michael Jordan. 2003. Modeling annotated data. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<publisher>JMLR.</publisher>
<contexts>
<context position="5871" citStr="Blei et al., 2003" startWordPosition="884" endWordPosition="887">e topic models. Outside of the field of topic modeling, Kawaba et al. (Kawaba et al., 2008) use a Wikipedia-based model to perform sentiment analysis of blog posts. They find, for example, that English blog posts about the Nintendo Wii often relate to a hack, which cannot be mentioned in Japanese posts due to Japanese intellectual property law. Similarly, posts about whaling often use (positive) nationalist language in Japanese and (negative) environmentalist language in English. 3 Polylingual Topic Model The polylingual topic model (PLTM) is an extension of latent Dirichlet allocation (LDA) (Blei et al., 2003) for modeling polylingual document tuples. Each tuple is a set of documents that are loosely equivalent to each other, but written in different languages, e.g., corresponding Wikipedia articles in French, English and German. PLTM assumes that the documents in a tuple share the same tuple-specific distribution over topics. This is unlike LDA, in which each document is assumed to have its own document-specific distribution over topics. Additionally, PLTM assumes that each “topic” consists of a set of discrete distributions Figure 1: Graphical model for PLTM. over words—one for each language l = </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David Blei, Andrew Ng, and Michael Jordan. 2003. Latent Dirichlet allocation. JMLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>CL,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="24857" citStr="Brown et al., 1993" startWordPosition="4010" endWordPosition="4013">5 Machine Translation Although the PLTM is clearly not a substitute for a machine translation system—it has no way to represent syntax or even multi-word phrases—it is clear from the examples in figure 2 that the sets of high probability words in different languages for a given topic are likely to include translations. We therefore evaluate the ability of the PLTM to generate bilingual lexica, similar to other work in unsupervised translation modeling (Haghighi et al., 2008). In the early statistical translation model work at IBM, these representations were called “cepts,” short for concepts (Brown et al., 1993). We evaluate sets of high-probability words in each topic and multilingual “synsets” by comparing them to entries in human-constructed bilingual dictionaries, as done by Haghighi et al. (2008). Unlike previous work (Koehn and Knight, 2002), we evaluate all words, not just nouns. We collected bilingual lexica mapping English words to German, Greek, Spanish, French, Italian, Dutch and Swedish. Each lexicon is a set of pairs consisting of an English word and a translated word, 1we, wt}. We do not consider multi-word terms. We expect that simple analysis of topic assignments for sequential words </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F Brown, Stephen A Della Pietra, Vincent J Della Pietra, and Robert L Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. CL, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In ACL,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="24717" citStr="Haghighi et al., 2008" startWordPosition="3989" endWordPosition="3992">chniques or better representations of topic co-occurrence might result in alignment of topics with a smaller proportion of comparable texts. 4.5 Machine Translation Although the PLTM is clearly not a substitute for a machine translation system—it has no way to represent syntax or even multi-word phrases—it is clear from the examples in figure 2 that the sets of high probability words in different languages for a given topic are likely to include translations. We therefore evaluate the ability of the PLTM to generate bilingual lexica, similar to other work in unsupervised translation modeling (Haghighi et al., 2008). In the early statistical translation model work at IBM, these representations were called “cepts,” short for concepts (Brown et al., 1993). We evaluate sets of high-probability words in each topic and multilingual “synsets” by comparing them to entries in human-constructed bilingual dictionaries, as done by Haghighi et al. (2008). Unlike previous work (Koehn and Knight, 2002), we evaluate all words, not just nouns. We collected bilingual lexica mapping English words to German, Greek, Spanish, French, Italian, Dutch and Swedish. Each lexicon is a set of pairs consisting of an English word and</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In ACL, pages 771–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Studying the history of ideas using topic models.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1114" citStr="Hall et al., 2008" startWordPosition="164" endWordPosition="167">ble, calling for tools that can characterize content in many languages. We introduce a polylingual topic model that discovers topics aligned across multiple languages. We explore the model’s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages. 1 Introduction Statistical topic models have emerged as an increasingly useful analysis tool for large text collections. Topic models have been used for analyzing topic trends in research literature (Mann et al., 2006; Hall et al., 2008), inferring captions for images (Blei and Jordan, 2003), social network analysis in email (McCallum et al., 2005), and expanding queries with topically related words in information retrieval (Wei and Croft, 2006). Much of this work, however, has occurred in monolingual contexts. In an increasingly connected world, the ability to access documents in many languages has become both a strategic asset and a personally enriching experience. In this paper, we present the polylingual topic model (PLTM). We demonstrate its utility and explore its characteristics using two polylingual corpora: proceedin</context>
</contexts>
<marker>Hall, Jurafsky, Manning, 2008</marker>
<rawString>David Hall, Daniel Jurafsky, and Christopher D. Manning. 2008. Studying the history of ideas using topic models. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariko Kawaba</author>
</authors>
<title>Hiroyuki Nakasaki, Takehito Utsuro, and Tomohiro Fukuhara.</title>
<date>2008</date>
<booktitle>In ICWSM.</booktitle>
<marker>Kawaba, 2008</marker>
<rawString>Mariko Kawaba, Hiroyuki Nakasaki, Takehito Utsuro, and Tomohiro Fukuhara. 2008. Cross-lingual blog analysis based on multilingual blog distillation from multilingual Wikipedia entries. In ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL Workshop on Unsupervised Lexical Acquisition.</booktitle>
<contexts>
<context position="25097" citStr="Koehn and Knight, 2002" startWordPosition="4046" endWordPosition="4049">y words in different languages for a given topic are likely to include translations. We therefore evaluate the ability of the PLTM to generate bilingual lexica, similar to other work in unsupervised translation modeling (Haghighi et al., 2008). In the early statistical translation model work at IBM, these representations were called “cepts,” short for concepts (Brown et al., 1993). We evaluate sets of high-probability words in each topic and multilingual “synsets” by comparing them to entries in human-constructed bilingual dictionaries, as done by Haghighi et al. (2008). Unlike previous work (Koehn and Knight, 2002), we evaluate all words, not just nouns. We collected bilingual lexica mapping English words to German, Greek, Spanish, French, Italian, Dutch and Swedish. Each lexicon is a set of pairs consisting of an English word and a translated word, 1we, wt}. We do not consider multi-word terms. We expect that simple analysis of topic assignments for sequential words would yield such collocations, but we leave this for future work. For every topic t we select a small number K of the most probable words in English (e) and in each “translation” language (E): Wte and Wtt, respectively. We then add the Cart</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of ACL Workshop on Unsupervised Lexical Acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Mann</author>
<author>David Mimno</author>
<author>Andrew McCallum</author>
</authors>
<title>Bibliometric impact measures leveraging topic analysis.</title>
<date>2006</date>
<booktitle>In JCDL.</booktitle>
<contexts>
<context position="1094" citStr="Mann et al., 2006" startWordPosition="160" endWordPosition="163">e now widely available, calling for tools that can characterize content in many languages. We introduce a polylingual topic model that discovers topics aligned across multiple languages. We explore the model’s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages. 1 Introduction Statistical topic models have emerged as an increasingly useful analysis tool for large text collections. Topic models have been used for analyzing topic trends in research literature (Mann et al., 2006; Hall et al., 2008), inferring captions for images (Blei and Jordan, 2003), social network analysis in email (McCallum et al., 2005), and expanding queries with topically related words in information retrieval (Wei and Croft, 2006). Much of this work, however, has occurred in monolingual contexts. In an increasingly connected world, the ability to access documents in many languages has become both a strategic asset and a personally enriching experience. In this paper, we present the polylingual topic model (PLTM). We demonstrate its utility and explore its characteristics using two polylingua</context>
</contexts>
<marker>Mann, Mimno, McCallum, 2006</marker>
<rawString>Gideon Mann, David Mimno, and Andrew McCallum. 2006. Bibliometric impact measures leveraging topic analysis. In JCDL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Andr´es Corrada-Emmanuel</author>
<author>Xuerui Wang</author>
</authors>
<title>Topic and role discovery in social networks.</title>
<date>2005</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="1227" citStr="McCallum et al., 2005" startWordPosition="183" endWordPosition="186">l that discovers topics aligned across multiple languages. We explore the model’s characteristics using two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages. 1 Introduction Statistical topic models have emerged as an increasingly useful analysis tool for large text collections. Topic models have been used for analyzing topic trends in research literature (Mann et al., 2006; Hall et al., 2008), inferring captions for images (Blei and Jordan, 2003), social network analysis in email (McCallum et al., 2005), and expanding queries with topically related words in information retrieval (Wei and Croft, 2006). Much of this work, however, has occurred in monolingual contexts. In an increasingly connected world, the ability to access documents in many languages has become both a strategic asset and a personally enriching experience. In this paper, we present the polylingual topic model (PLTM). We demonstrate its utility and explore its characteristics using two polylingual corpora: proceedings of the European parliament (in eleven languages) and a collection of Wikipedia articles (in twelve languages).</context>
</contexts>
<marker>McCallum, Corrada-Emmanuel, Wang, 2005</marker>
<rawString>Andrew McCallum, Andr´es Corrada-Emmanuel, and Xuerui Wang. 2005. Topic and role discovery in social networks. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaochuan Ni</author>
<author>Jian-Tao Sun</author>
<author>Jian Hu</author>
<author>Zheng Chen</author>
</authors>
<title>Mining multilingual topics from Wikipedia.</title>
<date>2009</date>
<booktitle>In WWW.</booktitle>
<contexts>
<context position="4942" citStr="Ni et al., 2009" startWordPosition="736" endWordPosition="739">g the HM-bitam model (Zhao and Xing, 2007). Tam, Lane and Schultz (Tam et al., 2007) also show improvements in machine translation using bilingual topic models. Both of these translation-focused topic models infer word-to-word alignments as part of their inference procedures, which would become exponentially more complex if additional languages were added. We take a simpler approach that is more suitable for topically similar document tuples (where documents are not direct translations of one another) in more than two languages. A recent extended abstract, developed concurrently by Ni et al. (Ni et al., 2009), discusses a multilingual topic model similar to the one presented here. However, they evaluate their model on only two languages (English and Chinese), and do not use the model to detect differences between languages. They also provide little analysis of the differences between polylingual and single-language topic models. Outside of the field of topic modeling, Kawaba et al. (Kawaba et al., 2008) use a Wikipedia-based model to perform sentiment analysis of blog posts. They find, for example, that English blog posts about the Nintendo Wii often relate to a hack, which cannot be mentioned in </context>
</contexts>
<marker>Ni, Sun, Hu, Chen, 2009</marker>
<rawString>Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen. 2009. Mining multilingual topics from Wikipedia. In WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yik-Cheung Tam</author>
<author>Ian Lane</author>
<author>Tanja Schultz</author>
</authors>
<title>Bilingual LSA-based adaptation for statistical machine translation. Machine Translation,</title>
<date>2007</date>
<pages>28--187</pages>
<contexts>
<context position="4410" citStr="Tam et al., 2007" startWordPosition="655" endWordPosition="658">guages. By linking topics across languages, polylingual topic models can increase cross-cultural understanding by providing readers with the ability to characterize 880 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 880–889, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP the contents of collections in unfamiliar languages and identify trends in topic prevalence. 2 Related Work Bilingual topic models for parallel texts with word-to-word alignments have been studied previously using the HM-bitam model (Zhao and Xing, 2007). Tam, Lane and Schultz (Tam et al., 2007) also show improvements in machine translation using bilingual topic models. Both of these translation-focused topic models infer word-to-word alignments as part of their inference procedures, which would become exponentially more complex if additional languages were added. We take a simpler approach that is more suitable for topically similar document tuples (where documents are not direct translations of one another) in more than two languages. A recent extended abstract, developed concurrently by Ni et al. (Ni et al., 2009), discusses a multilingual topic model similar to the one presented </context>
</contexts>
<marker>Tam, Lane, Schultz, 2007</marker>
<rawString>Yik-Cheung Tam, Ian Lane, and Tanja Schultz. 2007. Bilingual LSA-based adaptation for statistical machine translation. Machine Translation, 28:187– 207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hanna Wallach</author>
<author>Iain Murray</author>
<author>Ruslan Salakhutdinov</author>
<author>David Mimno</author>
</authors>
<title>Evaluation methods for topic models.</title>
<date>2009</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="17450" citStr="Wallach et al., 2009" startWordPosition="2760" endWordPosition="2763">r the generalization ability of the model. 0.0 0.2 0.4 0.6 0.8 1.0 Density 0 2 4 6 8 10 12 800 topics 400 topics 200 topics 100 topics 50 topics 0.0 0.1 0.2 0.3 0.4 0.5 Density 0 5 10 15 20 800 topics 400 topics 200 topics 100 topics 50 topics 883 Analytically calculating the probability of a set of held-out document tuples given Φ1, ... , ΦL and αm is intractable, due to the summation over an exponential number of topic assignments for these held-out documents. However, recently developed methods provide efficient, accurate estimates of this probability. We use the “left-to-right” method of (Wallach et al., 2009). We perform five estimation runs for each document and then calculate standard errors using a bootstrap method. Table 2 shows the log probability of held-out data in nats per word for PLTM and LDA, both trained with 200 topics. There is substantial variation between languages. Additionally, the predictive ability of PLTM is consistently slightly worse than that of (monolingual) LDA. It is important to note, however, that these results do not imply that LDA should be preferred over PLTM—that choice depends upon the needs of the modeler. Rather, these results are intended as a quantitative anal</context>
<context position="28622" citStr="Wallach et al., 2009" startWordPosition="4658" endWordPosition="4661">by dividing the data into a training set of 69,550 document tuples and a test set of 17,435 document tuples. In order to make the task more difficult, we train a relatively coarse-grained PLTM with 50 topics on the training set. We then use this model to infer topic distributions for each Figure 7: Percent of query language documents for which the target language translation is ranked at or above 1, 5, 10 or 20 by JS divergence, averaged over all language pairs. of the 11 documents in each of the held-out document tuples using a method similar to that used to calculate held-out probabilities (Wallach et al., 2009). Finally, for each pair of languages (“query” and “target”) we calculate the difference between the topic distribution for each held-out document in the query language and the topic distribution for each held-out document in the target language. We use both Jensen-Shannon divergence and cosine distance. For each document in the query language we rank all documents in the target language and record the rank of the actual translation. Results averaged over all query/target language pairs are shown in figure 7 for Jensen-Shannon divergence. Cosine-based rankings are significantly worse. It is im</context>
</contexts>
<marker>Wallach, Murray, Salakhutdinov, Mimno, 2009</marker>
<rawString>Hanna Wallach, Iain Murray, Ruslan Salakhutdinov, and David Mimno. 2009. Evaluation methods for topic models. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xing Wei</author>
<author>Bruce Croft</author>
</authors>
<title>LDA-based document models for ad-hoc retrieval.</title>
<date>2006</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="1326" citStr="Wei and Croft, 2006" startWordPosition="199" endWordPosition="202">ng two large corpora, each with over ten different languages, and demonstrate its usefulness in supporting machine translation and tracking topic trends across languages. 1 Introduction Statistical topic models have emerged as an increasingly useful analysis tool for large text collections. Topic models have been used for analyzing topic trends in research literature (Mann et al., 2006; Hall et al., 2008), inferring captions for images (Blei and Jordan, 2003), social network analysis in email (McCallum et al., 2005), and expanding queries with topically related words in information retrieval (Wei and Croft, 2006). Much of this work, however, has occurred in monolingual contexts. In an increasingly connected world, the ability to access documents in many languages has become both a strategic asset and a personally enriching experience. In this paper, we present the polylingual topic model (PLTM). We demonstrate its utility and explore its characteristics using two polylingual corpora: proceedings of the European parliament (in eleven languages) and a collection of Wikipedia articles (in twelve languages). There are many potential applications for polylingual topic models. Although research literature i</context>
</contexts>
<marker>Wei, Croft, 2006</marker>
<rawString>Xing Wei and Bruce Croft. 2006. LDA-based document models for ad-hoc retrieval. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Eric P Xing</author>
</authors>
<title>HM-BiTAM: Bilingual topic exploration, word alignment, and translation.</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="4368" citStr="Zhao and Xing, 2007" startWordPosition="647" endWordPosition="650">ill not be fluent in this wide variety of languages. By linking topics across languages, polylingual topic models can increase cross-cultural understanding by providing readers with the ability to characterize 880 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 880–889, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP the contents of collections in unfamiliar languages and identify trends in topic prevalence. 2 Related Work Bilingual topic models for parallel texts with word-to-word alignments have been studied previously using the HM-bitam model (Zhao and Xing, 2007). Tam, Lane and Schultz (Tam et al., 2007) also show improvements in machine translation using bilingual topic models. Both of these translation-focused topic models infer word-to-word alignments as part of their inference procedures, which would become exponentially more complex if additional languages were added. We take a simpler approach that is more suitable for topically similar document tuples (where documents are not direct translations of one another) in more than two languages. A recent extended abstract, developed concurrently by Ni et al. (Ni et al., 2009), discusses a multilingual</context>
</contexts>
<marker>Zhao, Xing, 2007</marker>
<rawString>Bing Zhao and Eric P. Xing. 2007. HM-BiTAM: Bilingual topic exploration, word alignment, and translation. In NIPS.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>