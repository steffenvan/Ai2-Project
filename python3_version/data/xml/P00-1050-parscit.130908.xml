<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000009">
<title confidence="0.9828755">
Chinese-Korean Word Alignment Based on Linguistic
Comparison
</title>
<author confidence="0.998522">
Jin-Xia Huang&amp;quot;&apos;&amp;quot;&amp;quot;
</author>
<affiliation confidence="0.882451285714286">
&amp;quot;KORTERM, AITrc, Computer Science
Department, Korea Advanced Institute of
Science and Technology
373-1 Yusong-gu, Gusong-dong, Daejon
305-701, Republic of Korea
Yanbian University of Science &amp; Technology
Yanji City, Jilin Province, 133001, P.R.China
</affiliation>
<email confidence="0.99028">
hgh@world.kaist.ac.kr
</email>
<sectionHeader confidence="0.974403" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999336083333333">
Word alignment problem between parallel
corpora is based on the similar
characteristics of two aligned words in two
languages. We investigate
linguistic-knowledge-based word similarity
measures while other previous works
heavily rely on statistical information, and
their limits will be discussed. Linguistic
knowledge is acquired from linguistic
comparison of all layers between two
languages, for Chinese and Korean in this
paper.
</bodyText>
<sectionHeader confidence="0.995012" genericHeader="introduction">
1 Introduction
</sectionHeader>
<subsectionHeader confidence="0.853508">
1.1 Previous works
</subsectionHeader>
<bodyText confidence="0.997797">
The bilingual corpus provides more information
than the monolingual one (Dagan, 1991). In
recent years, much works have been done on
word alignment after the research on section,
paragraph, sentence, and phrase level alignment.
Word alignment works for the automatic
construction of bilingual dictionaries, bilingual
patterns and other useful resources, and further,
it works for the various applications such as
machine translation and word sense
disambiguation.
Statistical approach has been used as a main
technique in most alignment systems (Gale,
1991; Brown, 1993; Dagan, 1994; Kay, 1993;
Wu, 1994; Smadja, 1996; Tanaka, 1999).
Correlation information is mainly employed in
statistical approach, and other similarities like
character, word length and position are
employed in it (Dagan, 1994; Fung, 1998; Kevin,
1999). Clues for alignment are investigated, for
</bodyText>
<author confidence="0.609337">
Key-Sun Choi
</author>
<affiliation confidence="0.6879904">
KORTERM, AITrc, Computer Science
Department, Korea Advanced Institute of
Science and Technology
373-1 Yusong-gu, Gusong-dong, Daejon
305-701, Republic of Korea
</affiliation>
<email confidence="0.95111">
kschoi@world.kaist.ac.kr
</email>
<bodyText confidence="0.999847">
example, functional word and context seed word
in (Brown, 1993; Shin &amp; Choi, 1996).
In contrast to the systems that mainly rely on
statistical approach, Ker (1997) uses a
class-based algorithm without any statistical
technique in the English-Chinese word
alignment. Ker&apos;s approach is claimed to
overcome the lower coverage of statistical
approaches while gaining high precision. Her
work shows us the feasibility of pure linguistic
approach to enhance the resolution of alignment
problem.
</bodyText>
<subsectionHeader confidence="0.838391">
1.2 Problem Definition
</subsectionHeader>
<bodyText confidence="0.993639085714286">
In the most previous studies, the &amp;quot;alignment&amp;quot;
was usually defined by &amp;quot;aligning word (or text,
phrase, section, etc.) to its translation&amp;quot; (Gale,
1991; Shin &amp; Choi, 1996). It seems that the
concept of alignment is so obvious that no one
has concerned for the problem, &amp;quot;what is the
translation of an original word&amp;quot;. In this paper,
we would like to clarify the definition as
follows:
&amp;quot;Alignment&amp;quot; is to find out the translated version of
the given source language. &amp;quot;Word/phrase
alignment&amp;quot;, therefore, is to find out, from the
aligned pairs of sentences, two words/phrases with
the highest semantic similarities and the highest
syntactic similarities.
Based on this definition given above, we can
easily point out that alignment problem is
essentially the problem of bilingual word sense
and syntactic similarity.
Traditional statistical approaches have been
testified to be effective in the resolution of
alignment problem: statistical information
reflects word similarity in some stages. But this
approach gets good result mainly in the
alignment of between the languages that belong
to the same language family (Brown, 1993;
Dagan, 1994; Dan, 1997), and shows limitation
in coverage even after training with extremely
large bilingual corpus (Ker, 1997). To the
languages that do not belong to the same
language family, statistical approaches have
shown limited coverage and low precision, even
after the employment of additional information
(Shin and Choi, 1996; Turcato, 1998). This
result is not surprising because statistical
approach is just an indirect way to obtain the
word similarity.
Then, what is the more direct information in
getting bilingual word similarity? In
monolingual processing, some resources such as
dictionary, thesaurus and WordNet have been
used customarily. Alignment needs bilingual
information, so we attempt to use bilingual
dictionary instead of the monolingual dictionary.
Thesaurus and WordNet have almost never been
used in bilingual alignment except Ker (1997)
because they normally contain only monolingual
information, but Ker shows us a sound approach
to make use of monolingual thesaurus in
bilingual alignment.
Though there are many differences between
some Asian language pairs like Chinese and
Korean (or Japanese and Chinese, or Japanese
and Korean), but we know that there are also
many similarities between them. And so, as the
result, we believe that linguistic knowledge will
be more close to the bilingual word sense or
syntactic similarity than some statistical
information or only word position in sentence.
2 Linguistic comparison between Chinese and
Korean
Korean language belongs to Altai language
family while Chinese language belongs to
Sino-Tibetan, so it is not surprising that there are
many differences between them. To get useful
information for the word alignment, we will
focus mainly on their common points more than
their differences. We will compare the linguistic
properties of Chinese and Korean from the three
viewpoints - character, lexicon, and syntax.
</bodyText>
<subsectionHeader confidence="0.894111">
2.1 Character Comparison
</subsectionHeader>
<bodyText confidence="0.999938909090909">
Differently from the language pairs such as
French-English or some Europe language pairs,
Chinese-Korean characters look very different
from each other, because Chinese characters are
ideograph while Korean characters are
phonogram. But actually, because Korean
characters are phonogram, and there is historical
relation between Chinese and Korean, almost all
of the Chinese characters can be converted to
one or several Korean characters, these Korean
characters express the pronunciation of the
Chinese characters in Korean (e.g., for &apos;&apos; in
Chinese, which pronunciation is &apos;ming&apos;, it can be
unically converted to Korean character &apos; &apos;
pronounced by &apos;myung&apos;).
We have constructed a Chinese-Korean
Character Transfer Table (CKCT Table) to
reflect the correspondence relation between
them. The 6763 Chinese characters that are
listed in GB2313-80 Chinese standard code table
can be converted to 436 Korean characters for
their Korean localized pronuncation.
</bodyText>
<subsectionHeader confidence="0.994796">
2.2 Word Comparison
</subsectionHeader>
<bodyText confidence="0.99919825">
We can try to find the lexical similarities
between Chinese and Korean languages from
three aspects: word formation, part-of-speech
(POS) and lexical internal structure.
</bodyText>
<subsubsectionHeader confidence="0.977222">
2.2.1 Word Formation
</subsubsectionHeader>
<bodyText confidence="0.999852179487179">
About 60% of the Korean colloquial words are
derived from Chinese words (Chinese-Korean
words) (Choi, 1989). Normally, these Korean
words have similar forms with the related
Chinese words when transferring the Chinese
words to their Korean pronunciation. (e.g.,&amp;quot;[C]
fn &amp;quot; (heping) 4 [CK](hwapyeong) q
[K]ffJ*(pyeonghwa)&amp;quot;, &amp;quot;[C],JjM�(bangongshi)
4 [CK](pangongsil) q [K]A}- AJI(samusil)),
where [C], [CK] and [K] stand for Chinese word,
Korean pronuncation of Chinese, and its
corresponding Korean word, respectively.
It seems that word formation similarity between
Chinese and Korean gives good word alignment.
But because of the long history of Chinese
character use in Korea, the word formation and
their concept are quite different. For example,
zhailu (MR) in Chinese stands for &amp;quot;excerpt&amp;quot; in
English, which is expressed by balcwi (4A ) in
Korean, but bacui ( 4A ) in contemporary
Chinese normally stands for &amp;quot;supereminence&amp;quot; in
English. Besides this, there is noise when using
word formation similarity in alignment, for
example, &amp;quot;oaz&apos;(ceungsil)&amp;quot; (means &amp;quot;blue thread&amp;quot;)
contains a similar word formation with &amp;quot;ELLz&apos;
(gyosil)&amp;quot; ( ft 1� ; &amp;quot;classroom&amp;quot;) while their
meanings are very different from each other.
Such noise will be more serious for the &amp;quot;short&amp;quot;
words that are composed of only one or two
characters. For example, &amp;quot;sir&amp;quot; in Korean is
mapped into many different Chinese characters
like &amp;quot;X }c, �&amp;quot; in corresponding Chinese
pronunciation &amp;quot;shi&amp;quot;.
Similarity of the lexical formation is on the
prolongation of the character similarity.
Similarity of lexical formation exists between
other language pairs also, and this property has
already been used in the other previous works
(Church, 1993).
</bodyText>
<subsubsectionHeader confidence="0.999135">
2.2.2 Part-of-Speech (POS)
</subsubsectionHeader>
<bodyText confidence="0.999968523809524">
POS similarity indicates the regularity between
the POS of the source word and its translation.
For example, if a word is a pronoun in source
language, then it is highly probable that the
translation of the word also belongs to a pronoun.
POS similarity attracted much attention by
computational linguistic researchers long before,
and has been made use in several previous
alignment systems (Dagan, 1994; Shin and Choi,
1996).
There is POS similarity between Chinese and
Korean also. Our experiment shows that about
77.1% Chinese nouns are mapped to Korean
noun (common noun), while only less than 8%
of them are translated to Korean verb. But it is
not always so optimistic, for example, only
34.4% of Chinese verbs are translated into
Korean verb, while 35.1% of them are translated
to Korean noun. It is the reason why we try to
use more kinds of linguistic knowledge in our
alignment study.
</bodyText>
<subsubsectionHeader confidence="0.991505">
2.2.3 Lexical Internal Structure
</subsubsectionHeader>
<bodyText confidence="0.999703">
Different from other language words, Chinese
words have internal structure. For example, the
verb &amp;quot; Tfff(xiayu) (rain)&amp;quot; is composed of two
words, one is verb &amp;quot;T(xia)(fall,drop...)&amp;quot; and the
other one is noun &amp;quot;fff(yu)(rain)&amp;quot;, therefore, the
internal structure of the word &amp;quot; T fff
(xiayu)(rain)&amp;quot; is &amp;quot;verb+noun&amp;quot;. We call it
&amp;quot;phrasal word&amp;quot; because there is a phrasal
structure inside of word.
We found that in most cases of 1:n (where n is
the number of corresponding words)
correspondence, Chinese words have some
specific POS and internal structures. Chinese
phrasal words and their corresponding Korean
phrases hold similar syntactic structure. We
name it &amp;quot;lexical internal structure similarity&amp;quot;.
For example, consider a fragment &amp;quot;it rains&amp;quot;:
[C] xia+yu (Tfff)&amp;quot;[K] bi/ga+o/da (H 1) [ 2U)
verb+noun &amp;quot; noun/SUBJ+verb/ending
([E] come down+rain&amp;quot; rain+come down)
The lexical structure transfer rules (e.g., &amp;quot;[C]
verb+noun &amp;quot; [K]noun/CASE +verb/ending&amp;quot;)
can be constructed semi-automatically.
</bodyText>
<subsectionHeader confidence="0.976638">
2.3 Syntactic Comparison
</subsectionHeader>
<bodyText confidence="0.991995125">
Word position (e.g., between English and
French), functional word (e.g., between Korean
and English) or POS information reflects
syntactic information. They have been used with
statistical approach in many previous works
(Gale, 1991; Brown 1993; Shin &amp; Choi, 1996).
But in the alignment of Chinese and Korean,
word positions in a sentence are not
synchronized enough because their word orders
are quite different. Chinese is SVO type
language while Korean is SOV one, and both of
their word orders are quite flexible. Additionally,
Chinese word order is reflected more by
semantic element than by syntactic one (Li,
1981).
But it does not mean that there is no syntactic
similarity between Chinese and Korean.
Syntactic similarity indicates that there is
syntactic regularity in syntactic structure
transformation. This property can be described
in simple transfer patterns that contain no
embedded structure (as in right hand side of next
examples).
&amp;quot;[C]�f/adj --�/noun(xin shu)&amp;quot; &amp;quot; &amp;quot;[K] J,H/adj
/noun (sae caeg)&amp;quot; ([C]adj noun &amp;quot; [K]adj noun)
&amp;quot;[C]i-1i,E/v i-1i,E/v (taolun taolun)&amp;quot; &amp;quot; &amp;quot;[K]��
/noun+8[01 -Y-T[ (yinonhayeo boja)&amp;quot; ( [C]verbl
verbl &amp;quot; [K]noun+8[01 -Y-T[ )
In Chinese-Korean alignment, using word
position in simple transfer pattern is more
accurate than only using word position in
sentence. And the precision of simple transfer
pattern is higher than of POS information,
because POS information reflects only the
information of one word without context, while
the simple transfer pattern reflects the context
information of the word.
In practice, we can employ probabilistic
information instead of transfer pattern. We will
describe it in the session 3.3.
</bodyText>
<sectionHeader confidence="0.959782" genericHeader="method">
3 Chinese-Korean Word Alignment
</sectionHeader>
<subsectionHeader confidence="0.789957">
3.1 Alignment Object
</subsectionHeader>
<bodyText confidence="0.990846">
Alignment objects are restricted to some
substantive (content words) in both Chinese and
Korean. The standard of the exclusion is that, if
most words of one POS have one to zero (1:0)
correspondence relation in alignment, it will be
excluded. As a result, all of the expletives and
quantifier of Chinese, and all of the function
words of Korean are excluded.
</bodyText>
<subsectionHeader confidence="0.921132">
3.2 Resource and Information Used in the System
</subsectionHeader>
<bodyText confidence="0.8703555">
Table 1 shows the linguistic resources we use in
our system and information they can provide.
</bodyText>
<table confidence="0.997517333333333">
Resource Information
CKCT Table Similarity of lexical formation
Bilingual Dictionary Semantic similarity and lexical internal structure information
Bilingual ClassNet Conceptual Similarity
Simple Pattern with Probability Syntactic Similarity
Bilingual Corpus Correlation information of bilingual words
</table>
<tableCaption confidence="0.999885">
Table 1. Resource and information used in the system
</tableCaption>
<bodyText confidence="0.9952755">
Bilingual dictionary provides us the target
words that have the highest semantic similarity
with the source words, and it is useful in
obtaining the lexical structure similarity.
Bilingual ClassNet is constructed with Korean
and Chinese monolingual thesauri, and it
provides us the conceptual similarity between
Chinese and Korean words. CKCT Table helps
us get similarity of the word formation. Simple
pattern database with probabilistic information
will be helpful in getting syntactic similarity,
and we reflect the lexical internal structure
similarity with simple pattern also. Finally,
bilingual corpus provides us correlation
information of bilingual words as it is known to
us.
</bodyText>
<figure confidence="0.999297">
Bilingual Corpus
Simple Pattern
CKCT Table
Bilingual Dic.
Bilingual
Class-Net
Similarity of Sense
and Formation
Correlation
Information
Bilingual Conceptual
Similarity
Syntactic Similarity
Similarity of Lexical
Internal Structure
Chinese Sentence Korean Sentence
POS tagger
Simple-Pattern-based alignment
Dictionary-based alignment
Aligned bilingual sentences
Statistic-based alignment
Filtering &amp; Best Selection
Class-based alignment
Midterm Filtering
</figure>
<figureCaption confidence="0.999913">
Figure 1. Chinese-Korean alignment system architecture
</figureCaption>
<subsectionHeader confidence="0.993537">
3.3 Alignment Algorithm
</subsectionHeader>
<bodyText confidence="0.999954666666667">
We use Chinese and Korean POS tagger as
preprocessor of our system. Figure 1 is the
Chinese-Korean alignment system architecture.
</bodyText>
<subsubsectionHeader confidence="0.989272">
3.3.1 Dictionary-Based Alignment
</subsubsectionHeader>
<bodyText confidence="0.9999585">
We use CKCT and bilingual dictionary in this
stage, and employed dice coefficient equation
(Dice, 1945) to measure the similarity of lexical
formation. The algorithm is as follows:
</bodyText>
<listItem confidence="0.986608214285714">
1. Using CKCT table, transferfing the given
Chinese word c; to its Korean character
string by converting characters one by one,
add it to empty set kc,.
2. Search the Korean translations of c; from
bilingual dictionary. Add them to the set kc,.
We consider one Korean phrase that contains
no space as a word. Delete postfix of the
Korean word when it is verb, adverb or
adjective.
3. Calculate similarity of c; and k; -
WordSim(c;,kj) with equation (1). Only the
result WordSim(c;, k;)&gt; t,(t, is threshold) will
remain.
</listItem>
<equation confidence="0.899261333333333">
WordSim
(c, k) 11 ❑max
k Ilk I kc; I I k
2❑I kc; ❑kI (1)
Where
c = Chinese word of given sentence
kc = Korean lexical set corresponding to c
kci = i th element of set kc
k = Korean morpheme of given sentence
� k I = Total number of the characters in k
� kci = Total number of the characters in ith
element of set kc
</equation>
<bodyText confidence="0.774121333333333">
d : A constant. (If kci and k have diffirent
POS tagger, or jcj=1 and lkl=1, d&lt;1.00;
otherwise d = 1.00)
</bodyText>
<subsubsectionHeader confidence="0.982807">
3.3.2 Statistic-Based Alignment
</subsubsectionHeader>
<bodyText confidence="0.9911219375">
We will align high co-occurred words that share
low formation similarity or can not be found in
bilingual dictionary. T-score was used by Fung
(1996) as a confidence measure after using MI
information. Because it does not favour rare
words as much as the MI does, and for time
saving&apos;, we choose only t-score in our system.
T-score reflects correlation of bilingual words as
equation (2). Only the result that is bigger than
threshold will remain.
c = Chinese word of given sentence
k = Korean morpheme of given sentence
Nc = Occurrence times of c in corpus
Nk = Occurrence times of k in corpus
Nck = Co-occurrence times of c and k
Total = Sentence pair number of corpus
</bodyText>
<subsubsectionHeader confidence="0.988963">
3.3.3 Class-Based Alignment
</subsubsectionHeader>
<bodyText confidence="0.868752">
We constructed Bilingual ClassNet with
Chinese Tongyici Cilin (Synonym Forest, Mei
and et.al, 1983) and Korean Thesaurus
</bodyText>
<listItem confidence="0.595790666666667">
automatically (Huang &amp; Choi, 1999), and
employed it in this stage. Here are examples of
the ClassNet:
</listItem>
<equation confidence="0.954461666666667">
ClassSim([C]Ab01,[K]12040)2 = 0.548;
(Ab01:man,woman;12040: man and woman)
ClassSim([C]Ab01,[K]12050) = 0.514;
(Ab01:man,woman;12050:oldie and younger)
ClassSim([C]Ab01,[K]12100) = 0.324;
(Ab01: man, woman; 12100: family)
</equation>
<footnote confidence="0.6622456">
where c; ∈{C„C,.Z, ... ,C;n,}, kj ∈{Kj„Kj2
&apos; In fact, we found that the statistic-based alignment
spents the most of the time in word aligning.
2 ClassSim(C,K): A concept similarity of Chinese
class C and Korean class K (Huang &amp; Choi, 1999)
</footnote>
<bodyText confidence="0.996965285714286">
Search all of the classes {Cil, Ct2, ... C�j of the
given word ci from Chinese thesarus Cilin, and
all of the classes {Kjj, Kj ... K~~} that the
��
Korean word kj belongs to. Get the word
similarity of ci and kj by equation (3). If the
similarity is bigger than threshold t2, remain it.
</bodyText>
<subsubsectionHeader confidence="0.968324">
3.3.4 Midterm Filtering
</subsubsectionHeader>
<bodyText confidence="0.9999623">
To raise the precision, system will filter the
alignment result before stage 4 with heuristics.
In this stage, all of the alignment candidates will
be marked with different level by their
similarity that have been gotten in
dictionary-based, statistical-based and
class-based alignment. If there are more than
two alignment candidates to one Chinese word,
the best one will be selected. If the similarities
are very close, then they will be all remained.
</bodyText>
<subsubsectionHeader confidence="0.983509">
3.3.5 Simple-Pattern-Based Alignment
</subsubsectionHeader>
<bodyText confidence="0.998755166666667">
In this stage, we will align the words that have
failed to be aligned yet, using simple pattern
that with probabilistic information. Aligned
word information and word position information
will be employed, and only the word position
inside the range of simple pattern will be
considered useful. Let&apos;s look at the algorithm of
this stage with an example.
Assume that in a given Chinese sentence, there
is a Chinese word sequence &amp;quot; Cad�..b+ Cadj,,&amp;quot; that
can be matched to a Chinese simple pattern
&amp;quot;adv+adj&amp;quot;, Cadverb has not been aligned yet, and
C has been aligned to Korean word
������
&amp;quot;Kstative�noun&amp;quot;. Assume that the context of the
Korean word &amp;quot;Kstative�noun&amp;quot; in the given sentence
is &amp;quot;Kgeneral_adverb+Kstative_noun+K.i1ia x_yerb&amp;quot;, and
onlyKstative�noun has been aligned (as in figure 2).
</bodyText>
<equation confidence="0.480747">
Cadverb + Cadject
Kgeneral_adverb + Kstative_noun+ Kauziliary_verb
</equation>
<figureCaption confidence="0.72469275">
Figure 2. Simple-pattern-based alignment
Calculate the alignment probability of &amp;quot; Cadverb
4 Kgeneral_adverb&amp;quot; and &amp;quot;Cadverb 4K..jlta�y_verb&amp;quot; with
equation (4).
</figureCaption>
<bodyText confidence="0.917730333333333">
where
Pcpattern is the occurrence probability of
Chinese pattern &amp;quot;adv+adj&amp;quot; in Chinese tree
bank.
Pcpos4Kros is the Chinese-Korean POS
transferring probability.
</bodyText>
<figure confidence="0.941473882352941">
t −score(c,k) = N- ×Total 11 N ×N,,
Total Total
×
(2)
Where
� � � �
�
woraSin. (c. k.) =A&amp;quot;X(ClassSin(C.
&amp;quot; J PQ9m p
)),
,Kj9
PAlignment d \Pcpattern Pcpos Kpos )
= × × →
(4)
}
(3)
,...,Kjm
</figure>
<bodyText confidence="0.997240416666667">
d is a constant that is in inverse
proportion to the interval between the
Chinese/Korean word to be aligned and the
Chinese/Korean reference word that has been
aligned.
In the given example, the probability of Chinese
adverb transferring to Korean general adverb is
37.9%, when the probability of Chinese adverb
transferring to Korean auxiliary verb is 26.0%.
All probabilities that bigger than the given
threshold will remain until filterring and
selecting the best stage.
</bodyText>
<subsectionHeader confidence="0.538864">
3.3.6 Filtering and Best Selection
</subsectionHeader>
<bodyText confidence="0.999294666666667">
In this stage, we will filter the alignment
candidates that we&apos;ve gotten, and remain only
the best one. If the similarities among
candidates are very close, then they will all
remain as a result of 1:n (one to many) or n:n
(many to many) alignment.
For example, the similarity of &amp;quot;[C]-Ffff(xiayu)
q [K]H I(bi)&amp;quot; and &amp;quot;[C]-FRff(xiayu) q [K]LH
z1(naeri)&amp;quot; are very close to each other, then it
will be considered that &amp;quot;[C] TW(xiayu)&amp;quot; is
aligned to Korean phrase &amp;quot;[K] H I LH z1 (bi
nari)&amp;quot;.
</bodyText>
<sectionHeader confidence="0.990968" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999894428571428">
We used bilingual dictionary that contains
140,000 items in dictionary-based alignment.
And we used 60,000 sentence pairs as training
corpus in the statistic-based alignment. In the
simple pattern-based alignment, about 300 of
simple patterns are employed. There are 120
bilingual sentences in the test set, with 13.7
Chinese words and 9.5 Korean content words
(17.9 Korean words) in a sentence pair on
average. The sentences of the test set are not
contained in the training corpus.
The first experiment is designed to demonstrate
the effectiveness of every algorithm
independently. The experimental result (Table 2)
shows that the dictionary-based alignment
shows high precision and low coverage. When
we try to rise up the coverage, the precision falls
down remarkably. Statistic-based algorithm
shows limitation in both of coverage and
precision, this result is not surprising because of
the reason that we have discussed in our paper.
The class-based algorithm is inefficient even
than statistic-based algorithm, actually it is out
of our imagination, and this result is much more
different from the Ker&apos;s (1997). The main reason
of it is that when we use Dic-coefficient eqution
to calculate the Chinese-Korean word similarity,
the noise that we have mentioned in our paper is
more serious than that is in the English-Chinese.
Simple-pattern-based algorithm is not listed
below, because this stage aligns words by using
the aligned word information, it means that this
stage can not work independently. Filtering
stage are employed after every algorithm in the
below.
</bodyText>
<table confidence="0.9988172">
Algorithm and Threshold Coverage Precision
Dictionary-based, (&gt;0.90) 25.5% 94.4%
(&gt;0.81) 33.7% 89.2%
(&gt;0.66) 45.6% 86.1%
(&gt;0.49) 55.8% 78.4%
Statistic-based, (&gt;0.20) 26.7% 84.6%
(&gt;0.05) 38.1% 72.8%
Class-based, (&gt;1.1) 20.0% 65.7%
(&gt;0.75) 31.6% 57.8%
(&gt;0.5) 47.3% 47.2%
</table>
<tableCaption confidence="0.999847">
Table 2. Effectiveness of every independent algorithm
</tableCaption>
<bodyText confidence="0.999758208333333">
In table 2, the recall of the dictionary-based
alignment looks quite low, considering the fact
that 60% of Korean colloquial words are
derived from Chinese words, and most of them
share formation similarity. Besides the reasons
that we have discussed in session 2.2.1, the
experiment shows us that the percentage of the
Chinese Korean words in corpus is much lower
than the percentage in the dictionary. For
T
example, there are a Korean word &amp;quot; T U
(busuda)&amp;quot; and Chinese Korean word &amp;quot;d:Ho fU
(bunswaehada) q [C]*4 (�ensui)&amp;quot; in Korean
that corresponds to the same meaning of &amp;quot;break T
into pieces&amp;quot;, but the Korean word &amp;quot; T U
(busuda)&amp;quot; is used more frequently in corpus
than the Chinese Korean word &amp;quot; d 1H o f U
(bunswaehada)&amp;quot;.
The second experiment is designed to
demonstrate the effectiveness when more than
two algorithms are employed together. The
experimental result (Table 3) shows that
statistic-based algorithm and class-based
algorithm are helpful to improve the coverage
without the falling down of the precision, when
they are used with dictionary-based approach.
Though the improvement of the coverage maybe
seems not so conspicuous, considering our
another experimental result that the upturn of
the coverage is only 3% under the same
precision when we upgrade our bilingual
dictionary from 6,000 items to 140,000, the
result in the Table 3 is quite remarkable.
From the experiment result, we can see that to
get high precision with higher coverage, using
different knowledge is useful - as we have
previously stated, using only one or two kinds
of information will cause the low correctness
inescapably.
The last line of the table 3 demonstrates the
effectiveness when all algorithms employed
together. Simple-pattern-based alignment is
done additionally to its previous stage. Our
simple-patterns are mainly gotten by statistical
information without enough manual editing. We
believe the precision and coverage of this stage
will be improved if we check the patterns
throughly.
</bodyText>
<table confidence="0.997194555555556">
Algorithm and Condition Coverage Precision
Dictionary &amp; Statistic-based 36.5% 92.6%
(dic&gt;0.66 &amp;&amp; sta&gt;0.05) II (dic&gt;0.9) II (sta &gt;0.20)
Dictionary &amp; Class-based 29.1% 92.7%
(dic&gt;0.66 &amp;&amp; cls&gt;0.50) II (dic&gt;0.9)
Dictionary &amp; Statistic &amp; Class-based 39.1% 93.0%
(dic&gt;0.66 &amp;&amp; sta&gt;0.05) II (dic&gt;0.66 &amp;&amp; cls&gt;0.50) II
(dic&gt;0.81 &amp;&amp; cls&gt;0.35) II (dic&gt;0.9) II (sta &gt;0.20)
+ Simple-pattern-based alignment 55.1% 89.2%
</table>
<tableCaption confidence="0.999844">
Table 3. Effectiveness when different algorithms used together
</tableCaption>
<bodyText confidence="0.999891666666667">
As a result of the experiment, we can see that
60% of Chinese-Korean corresponding relations
are 1:1 relations. When including the 1:2 and
2:1 relations, the percentage can raise up to 95%.
And in the most of the 1:2 relations, the Chinese
words have specific POS and internal structure.
</bodyText>
<sectionHeader confidence="0.996004" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999792">
This paper clarifies the definition of alignment
from the viewpoint of linguistic similarity.
Based on our clarified definition, we can easily
see that the alignment problem is essentially the
problem of bilingual word similarity. We
propose that linguistic knowledge would be
more efficient than traditional statistical
information in the word and phrase alignment,
especially between the languages that are not
from the same language family. The result of
the experiments sustains our proposal to some
degree.
We make a linguistic comparison between
Chinese and Korean from the viewpoints of
character, lexicon, and syntax The lexical and
syntactic similarities proposed in the paper exist
in the other language pairs also. And the use of
such similarities is helpful to raise coverage and
precision, especially in the alignment between
the languages that do not belong to the same
language family.
The coverage is not very high even though we
employed serious approachs in our system, we
will try to do more works to enhance it. Another
work has to be done for the alignment features,
they are selected heuristically more than
theoretically now. We would like to extend
word-level alignment to phrase-level in next
step, it will be helpful to the construction of
translation patterns.
</bodyText>
<sectionHeader confidence="0.98834" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9913023">
This work was supported by the Korea Science
and Engineering Foundation (KOSEF) through
the &amp;quot;Multilingual Informaton Retrieval&amp;quot; project
at the Advanced Information Technology
Research Center (AITrc).
This work was also supported by the Korea
Science and Engineering Foundation (KOSEF)
through the project of &amp;quot;Translation Knowledge
Acquisition Through Chinese-Korean
Alignment&amp;quot;.
</bodyText>
<sectionHeader confidence="0.979024" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99983351">
Brown, P.F., S.A. Della Pietra, V.J. Della Pietra and
R.L. Mercer (1993) The Mathematics of Statistical
Machine Translation: Parameter Estimation. in
Computational Linguistics, 19 (2), pp. 263-311.
Choi, Feng Chen (1989), The Lexicon Comparison
between Korean and Chinese, The Press of
Yanbian University. (In Chinese)
Church, K. (1993) Char�align: A Program for
Aligning Parallel Texts at the Character Level. In
Proceedings of the 31st Annual Conference of the
Association for Computional Linguistics. pp.1-8
Dagan, Ido, Alon Itai, and Ulrike Schwall (1991)
Two languages are more informative than one. In
Processing of the 29h Annual Meeting of the
Association for Computational Linguistics,
pp.130-173.
Dagan Ido, K.W. Church and W.A.Gale (1994)
Robust Bilingual Word Alignment for
Machine-Aided Translation, In Proceedings of 4t&apos;
conference on Applied Natural Language
Processing (ANLP-94), pp.34-40.
Dan, I. Melaned (1997) A Portable Algorithm for
Mapping bitext Correspondence, In Proceedings of
35th Conference of the Association for
Computational Linguistics
Dice,L.R.(1945) Measures of the amount of ecologic
association between species. Journal of Ecology,
26:297-302
Gale, W.A. and K.W. Church (1991) A program for
aligning sentences in bilingual corpora. In
Proceedings of the 29h Annual Conference of the
Association for Computational Linguistics,
pp.177-184.
Frank Smadja, Kathleen McKeown, and Vasileios
Hatzsivassiloglou (1996) Translating collocations
for bilingual lexicons: A statistical approach. In
Computational Linguistics, 21 (4): pp.1-38.
Fung, Pascale (1995) A Pattern Matching Method for
Finding Noun and Proper Noun Translations from
Noisy Parallel Corpora, In Proceeding of the 33th
Annual Conference of the Association for
Computational Linguistics, pp. 236-243
Fung, Pascale and Lo Yuen Yee (1998) An /R
Approach for Translating New Words from
Nonparallel, Comparable Texts, In Proceeding of
the COLING-ACL&apos;98, pp.414-420
Huang, Jin-Xia and Key-Sun Choi (1999) Automatic
Construction of Lexical Classification Net for Two
Languages, In Proceeding of the 11th Conference
of the Korean Language and Information
Processing, pp.389 — 396 (In Korean)
Ker, Sue J., Jason S. Chang (1997) A Class-based
Approach to Word Alignement. Computational
Linguistics (1997 Volume 23, Number 2 , pp.313 -
343
Kevin McTait, Arturo Trujillo (1999) A
Language-Neutral Sparse-Data Algorithm for
Extracting Translation Patterns, In Proceedings of
8t&apos; International Conference on Theoretical and
Methodological Issues in Machine Translation, pp.
98 - 108.
Li, Charles N. &amp; Sandra A. Thompson (1981)
(Translated by Bak Jeong-Gu,Bak Jong-Han, Baek
Eun-Yyi, O Mun-Yi, Coe Yheong-Ha). Standard
Chinese Grammar. pp. 34- 45
Li, Jun-Jie, Key-Sun Choi (1997) Design and
/mplementation of a Chinese-Korean Machine
Translation System. In Proceedings of the 17th
International Conference on Computer Processing
of Oriental Languages (ICCPOL&apos;97), pp. 400-403,
Martin Kay and Martin Roscheisen (1993)
Text-Translation alignment. In computational
Linguistics, 19 (1): pp.121-142.
Mei, Jia-Ju, Yi-Ming Zhu, Yun-Qi Gao, Hong-Xiang
Yin, (1983), Tongyici Cilin (Chinese Synonym
Forest), ShangHai Press of Lexicon and Books (in
Chinese)
Shin, Jung H., Young S.Han and Key-Sun Choi
(1996) Bilingual Knowledge Acquisition from
Korean-English Parallel Corpus Using Alignment
Method (Korean-English Alignment at Word and
Phrase Level), In Proceedings of the 15th
International Conference on Computational
Linguistics, pp.230-235.
Tanaka Takaaki and Yoshihiro Matsuo (1999)
Extraction of Translation Equivalents from
Non-Parallel Corpora, In 8h Proceedings of
International Conference on Theoretical and
Methodological Issues in Machine Translation,
pages 88 - 97.
Turcato Davide (1998) Automatically creating
bilingual lexicons for machine translation from
bilingual text. In Proceedings of the 16th
International Conference on Computational
Linguistics. pp.1299-1306
Wu, Dekai (1994) Aligning a parallel
English-chinese corpus statistically with lexical
criteria. In Proceedings of the 32th Annual
Meeting of the Association for Computational
Linguistics (ACL&apos;94), pp.80-87.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.250782">
<title confidence="0.727621">Chinese-Korean Word Alignment Based on Linguistic Comparison</title>
<affiliation confidence="0.930614">AITrc, Computer Science Department, Korea Advanced Institute of Science and Technology</affiliation>
<address confidence="0.8889565">373-1 Yusong-gu, Gusong-dong, Daejon 305-701, Republic of Korea</address>
<affiliation confidence="0.998166">Yanbian University of Science &amp; Technology</affiliation>
<address confidence="0.997802">Yanji City, Jilin Province, 133001, P.R.China</address>
<email confidence="0.872851">hgh@world.kaist.ac.kr</email>
<abstract confidence="0.993113538461538">Word alignment problem between parallel corpora is based on the similar characteristics of two aligned words in two languages. We investigate linguistic-knowledge-based word similarity measures while other previous works heavily rely on statistical information, and their limits will be discussed. Linguistic knowledge is acquired from linguistic comparison of all layers between two languages, for Chinese and Korean in this paper.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>in Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<pages>263--311</pages>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Brown, P.F., S.A. Della Pietra, V.J. Della Pietra and R.L. Mercer (1993) The Mathematics of Statistical Machine Translation: Parameter Estimation. in Computational Linguistics, 19 (2), pp. 263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng Chen Choi</author>
</authors>
<title>The Lexicon Comparison between Korean and Chinese, The Press of Yanbian University.</title>
<date>1989</date>
<publisher>(In Chinese)</publisher>
<contexts>
<context position="6723" citStr="Choi, 1989" startWordPosition="979" endWordPosition="980">have constructed a Chinese-Korean Character Transfer Table (CKCT Table) to reflect the correspondence relation between them. The 6763 Chinese characters that are listed in GB2313-80 Chinese standard code table can be converted to 436 Korean characters for their Korean localized pronuncation. 2.2 Word Comparison We can try to find the lexical similarities between Chinese and Korean languages from three aspects: word formation, part-of-speech (POS) and lexical internal structure. 2.2.1 Word Formation About 60% of the Korean colloquial words are derived from Chinese words (Chinese-Korean words) (Choi, 1989). Normally, these Korean words have similar forms with the related Chinese words when transferring the Chinese words to their Korean pronunciation. (e.g.,&amp;quot;[C] fn &amp;quot; (heping) 4 [CK](hwapyeong) q [K]ffJ*(pyeonghwa)&amp;quot;, &amp;quot;[C],JjM�(bangongshi) 4 [CK](pangongsil) q [K]A}- AJI(samusil)), where [C], [CK] and [K] stand for Chinese word, Korean pronuncation of Chinese, and its corresponding Korean word, respectively. It seems that word formation similarity between Chinese and Korean gives good word alignment. But because of the long history of Chinese character use in Korea, the word formation and their co</context>
</contexts>
<marker>Choi, 1989</marker>
<rawString>Choi, Feng Chen (1989), The Lexicon Comparison between Korean and Chinese, The Press of Yanbian University. (In Chinese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>Char�align: A Program for Aligning Parallel Texts at the Character Level.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Conference of the Association for Computional Linguistics.</booktitle>
<pages>1--8</pages>
<contexts>
<context position="8308" citStr="Church, 1993" startWordPosition="1219" endWordPosition="1220">a similar word formation with &amp;quot;ELLz&apos; (gyosil)&amp;quot; ( ft 1� ; &amp;quot;classroom&amp;quot;) while their meanings are very different from each other. Such noise will be more serious for the &amp;quot;short&amp;quot; words that are composed of only one or two characters. For example, &amp;quot;sir&amp;quot; in Korean is mapped into many different Chinese characters like &amp;quot;X }c, �&amp;quot; in corresponding Chinese pronunciation &amp;quot;shi&amp;quot;. Similarity of the lexical formation is on the prolongation of the character similarity. Similarity of lexical formation exists between other language pairs also, and this property has already been used in the other previous works (Church, 1993). 2.2.2 Part-of-Speech (POS) POS similarity indicates the regularity between the POS of the source word and its translation. For example, if a word is a pronoun in source language, then it is highly probable that the translation of the word also belongs to a pronoun. POS similarity attracted much attention by computational linguistic researchers long before, and has been made use in several previous alignment systems (Dagan, 1994; Shin and Choi, 1996). There is POS similarity between Chinese and Korean also. Our experiment shows that about 77.1% Chinese nouns are mapped to Korean noun (common </context>
</contexts>
<marker>Church, 1993</marker>
<rawString>Church, K. (1993) Char�align: A Program for Aligning Parallel Texts at the Character Level. In Proceedings of the 31st Annual Conference of the Association for Computional Linguistics. pp.1-8</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Alon Itai</author>
<author>Ulrike Schwall</author>
</authors>
<title>Two languages are more informative than one.</title>
<date>1991</date>
<booktitle>In Processing of the 29h Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>130--173</pages>
<marker>Dagan, Itai, Schwall, 1991</marker>
<rawString>Dagan, Ido, Alon Itai, and Ulrike Schwall (1991) Two languages are more informative than one. In Processing of the 29h Annual Meeting of the Association for Computational Linguistics, pp.130-173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dagan Ido</author>
<author>K W</author>
</authors>
<title>Church and W.A.Gale</title>
<date>1994</date>
<booktitle>In Proceedings of 4t&apos; conference on Applied Natural Language Processing (ANLP-94),</booktitle>
<pages>34--40</pages>
<marker>Ido, W, 1994</marker>
<rawString>Dagan Ido, K.W. Church and W.A.Gale (1994) Robust Bilingual Word Alignment for Machine-Aided Translation, In Proceedings of 4t&apos; conference on Applied Natural Language Processing (ANLP-94), pp.34-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan</author>
</authors>
<title>Melaned</title>
<date>1997</date>
<booktitle>In Proceedings of 35th Conference of the Association for Computational Linguistics</booktitle>
<contexts>
<context position="3549" citStr="Dan, 1997" startWordPosition="509" endWordPosition="510">of sentences, two words/phrases with the highest semantic similarities and the highest syntactic similarities. Based on this definition given above, we can easily point out that alignment problem is essentially the problem of bilingual word sense and syntactic similarity. Traditional statistical approaches have been testified to be effective in the resolution of alignment problem: statistical information reflects word similarity in some stages. But this approach gets good result mainly in the alignment of between the languages that belong to the same language family (Brown, 1993; Dagan, 1994; Dan, 1997), and shows limitation in coverage even after training with extremely large bilingual corpus (Ker, 1997). To the languages that do not belong to the same language family, statistical approaches have shown limited coverage and low precision, even after the employment of additional information (Shin and Choi, 1996; Turcato, 1998). This result is not surprising because statistical approach is just an indirect way to obtain the word similarity. Then, what is the more direct information in getting bilingual word similarity? In monolingual processing, some resources such as dictionary, thesaurus and</context>
</contexts>
<marker>Dan, 1997</marker>
<rawString>Dan, I. Melaned (1997) A Portable Algorithm for Mapping bitext Correspondence, In Proceedings of 35th Conference of the Association for Computational Linguistics</rawString>
</citation>
<citation valid="false">
<title>Dice,L.R.(1945) Measures of the amount of ecologic association between species.</title>
<journal>Journal of Ecology,</journal>
<pages>26--297</pages>
<marker></marker>
<rawString>Dice,L.R.(1945) Measures of the amount of ecologic association between species. Journal of Ecology, 26:297-302</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29h Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>177--184</pages>
<marker>Gale, Church, 1991</marker>
<rawString>Gale, W.A. and K.W. Church (1991) A program for aligning sentences in bilingual corpora. In Proceedings of the 29h Annual Conference of the Association for Computational Linguistics, pp.177-184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Smadja</author>
<author>Kathleen McKeown</author>
<author>Vasileios Hatzsivassiloglou</author>
</authors>
<title>Translating collocations for bilingual lexicons: A statistical approach.</title>
<date>1996</date>
<booktitle>In Computational Linguistics,</booktitle>
<volume>21</volume>
<issue>4</issue>
<pages>1--38</pages>
<marker>Smadja, McKeown, Hatzsivassiloglou, 1996</marker>
<rawString>Frank Smadja, Kathleen McKeown, and Vasileios Hatzsivassiloglou (1996) Translating collocations for bilingual lexicons: A statistical approach. In Computational Linguistics, 21 (4): pp.1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A Pattern Matching Method for Finding Noun and Proper Noun Translations from Noisy Parallel Corpora,</title>
<date>1995</date>
<booktitle>In Proceeding of the 33th Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>236--243</pages>
<marker>Fung, 1995</marker>
<rawString>Fung, Pascale (1995) A Pattern Matching Method for Finding Noun and Proper Noun Translations from Noisy Parallel Corpora, In Proceeding of the 33th Annual Conference of the Association for Computational Linguistics, pp. 236-243</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An /R Approach for Translating New Words from Nonparallel, Comparable Texts,</title>
<date>1998</date>
<booktitle>In Proceeding of the COLING-ACL&apos;98,</booktitle>
<pages>414--420</pages>
<marker>Fung, Yee, 1998</marker>
<rawString>Fung, Pascale and Lo Yuen Yee (1998) An /R Approach for Translating New Words from Nonparallel, Comparable Texts, In Proceeding of the COLING-ACL&apos;98, pp.414-420</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Xia Huang</author>
<author>Key-Sun Choi</author>
</authors>
<title>Automatic Construction of Lexical Classification Net for Two Languages,</title>
<date>1999</date>
<booktitle>In Proceeding of the 11th Conference of the Korean Language and Information Processing, pp.389 — 396 (In Korean)</booktitle>
<contexts>
<context position="16240" citStr="Huang &amp; Choi, 1999" startWordPosition="2452" endWordPosition="2455">ords as much as the MI does, and for time saving&apos;, we choose only t-score in our system. T-score reflects correlation of bilingual words as equation (2). Only the result that is bigger than threshold will remain. c = Chinese word of given sentence k = Korean morpheme of given sentence Nc = Occurrence times of c in corpus Nk = Occurrence times of k in corpus Nck = Co-occurrence times of c and k Total = Sentence pair number of corpus 3.3.3 Class-Based Alignment We constructed Bilingual ClassNet with Chinese Tongyici Cilin (Synonym Forest, Mei and et.al, 1983) and Korean Thesaurus automatically (Huang &amp; Choi, 1999), and employed it in this stage. Here are examples of the ClassNet: ClassSim([C]Ab01,[K]12040)2 = 0.548; (Ab01:man,woman;12040: man and woman) ClassSim([C]Ab01,[K]12050) = 0.514; (Ab01:man,woman;12050:oldie and younger) ClassSim([C]Ab01,[K]12100) = 0.324; (Ab01: man, woman; 12100: family) where c; ∈{C„C,.Z, ... ,C;n,}, kj ∈{Kj„Kj2 &apos; In fact, we found that the statistic-based alignment spents the most of the time in word aligning. 2 ClassSim(C,K): A concept similarity of Chinese class C and Korean class K (Huang &amp; Choi, 1999) Search all of the classes {Cil, Ct2, ... C�j of the given word ci fro</context>
</contexts>
<marker>Huang, Choi, 1999</marker>
<rawString>Huang, Jin-Xia and Key-Sun Choi (1999) Automatic Construction of Lexical Classification Net for Two Languages, In Proceeding of the 11th Conference of the Korean Language and Information Processing, pp.389 — 396 (In Korean)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sue J Ker</author>
<author>Jason S Chang</author>
</authors>
<title>A Class-based Approach to Word Alignement. Computational Linguistics</title>
<date>1997</date>
<volume>23</volume>
<pages>313--343</pages>
<marker>Ker, Chang, 1997</marker>
<rawString>Ker, Sue J., Jason S. Chang (1997) A Class-based Approach to Word Alignement. Computational Linguistics (1997 Volume 23, Number 2 , pp.313 -343</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin McTait</author>
</authors>
<title>Arturo Trujillo</title>
<date>1999</date>
<booktitle>In Proceedings of 8t&apos; International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>98--108</pages>
<marker>McTait, 1999</marker>
<rawString>Kevin McTait, Arturo Trujillo (1999) A Language-Neutral Sparse-Data Algorithm for Extracting Translation Patterns, In Proceedings of 8t&apos; International Conference on Theoretical and Methodological Issues in Machine Translation, pp. 98 - 108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles N Li</author>
<author>Sandra A Thompson</author>
</authors>
<date>1981</date>
<journal>(Translated by Bak Jeong-Gu,Bak Jong-Han, Baek Eun-Yyi, O Mun-Yi, Coe Yheong-Ha). Standard Chinese Grammar.</journal>
<pages>34--45</pages>
<marker>Li, Thompson, 1981</marker>
<rawString>Li, Charles N. &amp; Sandra A. Thompson (1981) (Translated by Bak Jeong-Gu,Bak Jong-Han, Baek Eun-Yyi, O Mun-Yi, Coe Yheong-Ha). Standard Chinese Grammar. pp. 34- 45</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun-Jie Li</author>
</authors>
<title>Key-Sun Choi</title>
<date>1997</date>
<booktitle>In Proceedings of the 17th International Conference on Computer Processing of Oriental Languages (ICCPOL&apos;97),</booktitle>
<pages>400--403</pages>
<marker>Li, 1997</marker>
<rawString>Li, Jun-Jie, Key-Sun Choi (1997) Design and /mplementation of a Chinese-Korean Machine Translation System. In Proceedings of the 17th International Conference on Computer Processing of Oriental Languages (ICCPOL&apos;97), pp. 400-403,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
<author>Martin Roscheisen</author>
</authors>
<title>Text-Translation alignment.</title>
<date>1993</date>
<booktitle>In computational Linguistics,</booktitle>
<volume>19</volume>
<issue>1</issue>
<pages>121--142</pages>
<marker>Kay, Roscheisen, 1993</marker>
<rawString>Martin Kay and Martin Roscheisen (1993) Text-Translation alignment. In computational Linguistics, 19 (1): pp.121-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jia-Ju Mei</author>
</authors>
<title>Yi-Ming Zhu, Yun-Qi Gao, Hong-Xiang Yin,</title>
<date>1983</date>
<booktitle>Tongyici Cilin (Chinese Synonym Forest), ShangHai Press of Lexicon and Books (in Chinese)</booktitle>
<marker>Mei, 1983</marker>
<rawString>Mei, Jia-Ju, Yi-Ming Zhu, Yun-Qi Gao, Hong-Xiang Yin, (1983), Tongyici Cilin (Chinese Synonym Forest), ShangHai Press of Lexicon and Books (in Chinese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung H Shin</author>
<author>Young S Han</author>
<author>Key-Sun Choi</author>
</authors>
<title>Bilingual Knowledge Acquisition from Korean-English Parallel Corpus Using Alignment Method (Korean-English Alignment at Word and Phrase Level),</title>
<date>1996</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>230--235</pages>
<marker>Shin, Han, Choi, 1996</marker>
<rawString>Shin, Jung H., Young S.Han and Key-Sun Choi (1996) Bilingual Knowledge Acquisition from Korean-English Parallel Corpus Using Alignment Method (Korean-English Alignment at Word and Phrase Level), In Proceedings of the 15th International Conference on Computational Linguistics, pp.230-235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tanaka Takaaki</author>
<author>Yoshihiro Matsuo</author>
</authors>
<title>Extraction of Translation Equivalents from Non-Parallel Corpora,</title>
<date>1999</date>
<booktitle>In 8h Proceedings of International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>88--97</pages>
<marker>Takaaki, Matsuo, 1999</marker>
<rawString>Tanaka Takaaki and Yoshihiro Matsuo (1999) Extraction of Translation Equivalents from Non-Parallel Corpora, In 8h Proceedings of International Conference on Theoretical and Methodological Issues in Machine Translation, pages 88 - 97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Turcato Davide</author>
</authors>
<title>Automatically creating bilingual lexicons for machine translation from bilingual text.</title>
<date>1998</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics.</booktitle>
<pages>1299--1306</pages>
<marker>Davide, 1998</marker>
<rawString>Turcato Davide (1998) Automatically creating bilingual lexicons for machine translation from bilingual text. In Proceedings of the 16th International Conference on Computational Linguistics. pp.1299-1306</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Aligning a parallel English-chinese corpus statistically with lexical criteria.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32th Annual Meeting of the Association for Computational Linguistics (ACL&apos;94),</booktitle>
<pages>80--87</pages>
<contexts>
<context position="1430" citStr="Wu, 1994" startWordPosition="195" endWordPosition="196">orks The bilingual corpus provides more information than the monolingual one (Dagan, 1991). In recent years, much works have been done on word alignment after the research on section, paragraph, sentence, and phrase level alignment. Word alignment works for the automatic construction of bilingual dictionaries, bilingual patterns and other useful resources, and further, it works for the various applications such as machine translation and word sense disambiguation. Statistical approach has been used as a main technique in most alignment systems (Gale, 1991; Brown, 1993; Dagan, 1994; Kay, 1993; Wu, 1994; Smadja, 1996; Tanaka, 1999). Correlation information is mainly employed in statistical approach, and other similarities like character, word length and position are employed in it (Dagan, 1994; Fung, 1998; Kevin, 1999). Clues for alignment are investigated, for Key-Sun Choi KORTERM, AITrc, Computer Science Department, Korea Advanced Institute of Science and Technology 373-1 Yusong-gu, Gusong-dong, Daejon 305-701, Republic of Korea kschoi@world.kaist.ac.kr example, functional word and context seed word in (Brown, 1993; Shin &amp; Choi, 1996). In contrast to the systems that mainly rely on statist</context>
</contexts>
<marker>Wu, 1994</marker>
<rawString>Wu, Dekai (1994) Aligning a parallel English-chinese corpus statistically with lexical criteria. In Proceedings of the 32th Annual Meeting of the Association for Computational Linguistics (ACL&apos;94), pp.80-87.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>