<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.991965">
Non-Cooperation in Dialogue
</title>
<author confidence="0.994114">
Brian Pl¨uss
</author>
<affiliation confidence="0.974558">
Centre for Research in Computing
The Open University
</affiliation>
<address confidence="0.693771">
Milton Keynes, UK
</address>
<email confidence="0.998266">
b.pluss@open.ac.uk
</email>
<sectionHeader confidence="0.993884" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906083333333">
This paper presents ongoing research on
computational models for non-cooperative
dialogue. We start by analysing differ-
ent levels of cooperation in conversation.
Then, inspired by findings from an em-
pirical study, we propose a technique for
measuring non-cooperation in political in-
terviews. Finally, we describe a research
programme towards obtaining a suitable
model and discuss previous accounts for
conflictive dialogue, identifying the differ-
ences with our work.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999259076923077">
Most approaches to modeling conversation are
based on a strong notion of cooperation be-
tween the dialogue participants (DPs). Traditional
models using intentions (Cohen and Levesque,
1991), dialogue games (Power, 1979), shared
plans (Grosz and Sidner, 1990) or collaborative
problem-solving (Blaylock and Allen, 2005) ex-
plain dialogue situations in which DPs recognise
each other’s intentions and, at least to a certain ex-
tent, accept each other’s goals when deciding on
their actions. These assumptions are theoretically
grounded, as most work in linguistics has consid-
ered situations in which DPs share a common goal
and cooperate to achieve it by means of conver-
sation (Grice, 1975; Clark and Schaefer, 1989).
They are also practically sound: dialogue models
are usually implemented in the form of dialogue
systems, built for the purpose of providing a ser-
vice to their users (e.g., TRAINS (Allen and Schu-
bert, 1991)). In this scenario, failure to cooperate,
either on the side of the system or of the user, is
against the premises on which the system is con-
ceived and used.
In everyday conversation, however, a great
many situations escape the arguments above. Con-
sider the following example1:
</bodyText>
<listItem confidence="0.5200015">
(1) PAXMAN [1]: (interrupting) Did you threaten to over-
rule him?
</listItem>
<construct confidence="0.335618181818182">
HOWARD [2]: I, I, was not entitled to instruct Derek
Lewis, and I did not instruct him.
PAXMAN [3]: Did you threaten to overrule him?
HOWARD [4]: The truth of the matter is that Mr. Mar-
riott was not suspended. I...
PAXMAN [5]: (overlappling) Did you threaten to
overrule him?
HOWARD [6]: ... did not overrule Derek Lewis.
PAXMAN [7]: Did you threaten to overrule him?
HOWARD [8]: I took advice on what I could or could
not do...
</construct>
<note confidence="0.9009475">
PAXMAN [9]: (overlappling) Did you threaten to
overrule him, Mr. Howard?
HOWARD[10]:... and I acted scrupulously in accor-
dance with that advice, I did not over-
rule Derek Lewis...
PAXMAN [11]: (overlapping) Did you threaten to over-
rule him?
HOWARD[12]: ... Mr. Marriott was not suspended.
PAXMAN [13]: Did you threaten to overrule him?
HOWARD[14]: (pauses) I have accounted for my deci-
</note>
<bodyText confidence="0.707089411764706">
sion to dismiss Derek Lewis...
PAXMAN [15]: (overlapping) Did you threaten to over-
rule him?
HOWARD[16]:... in great detail, before the House of
Commons.
PAXMAN [17]: I note that you’re not answering the
question of whether you threatened to
overrule him.
(Newsnight, BBC, 1997)
We take it for granted that, at some level, Pax-
man and Howard are sharing a goal, for otherwise
they would not be having an interview. Still, the
exchange is clearly conflictive, to the point that
their behaviour compromises the flow of the con-
versation.
Heritage (1998) analyses the distinctive roles of
DPs in news interviews:
</bodyText>
<footnote confidence="0.932378888888889">
1BBC presenter Jeremy Paxman questions former UK
Home Secretary Michael Howard with respect to a meeting
in 1995 between Howard and the head of the Prison Service,
Derek Lewis, about the dismissal of the governor of Parkhurst
Prison, John Marriott, due to repeated security failures. The
case was given considerable attention in the media, as a result
of accusations by Lewis that Howard had instructed him, thus
exceeding the powers of his office.
1
</footnote>
<note confidence="0.6779995">
Proceedings of the ACL 2010 Student Research Workshop, pages 1–6,
Uppsala, Sweden, 13 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999355733333333">
“the participants -IRs [=interviewers] and IEs
[=interviewees]- exclude themselves from a wide
variety of actions that they are normally free to
do in the give and take of ordinary conversa-
tion. If IRs restrict themselves to asking ques-
tions, then they cannot - at least overtly - express
opinions, or argue with, debate or criticize the in-
terviewees’ positions nor, conversely, agree with,
support or defend them. Correspondingly, if IEs
restrict themselves to answers (or responses) to
questions, then they cannot ask questions (of IRs
or other IEs), nor make unsolicited comments on
previous remarks, initiate changes of topic, or di-
vert the discussion into criticisms of the IR or the
broadcasting organization.”
</bodyText>
<equation confidence="0.59019">
(Heritage, 1998, p.8)
</equation>
<bodyText confidence="0.725077">
Now, consider the fragment below2:
</bodyText>
<construct confidence="0.657161388888889">
(2) PAXMAN[1]: Can you clear up whether or not you
did threaten to overrule Derek Lewis
when you were Home Secretary?
HOWARD[2]: Oh, come on, Jeremy, you are really
going to go back over that again? As...
PAXMAN [3]: (overlapping) You’ve had seven years
to think about it!
HOWARD[4]: (overlapping)... as, as it happens, I
didn’t. Are you satisfied now?
PAXMAN [5]: Thank you. Why didn’t you say that at
the time?
HOWARD[6]: I, well, we’ve been over this many,
many times. I, I, I knew that everyone
was crawling over every syllable I said
about that, and I wanted to check very
carefully what I said before answering
your question.
(Newsnight, BBC, 2004)
</construct>
<bodyText confidence="0.9998915">
On this occasion, Howard provides an answer
almost immediately and the flow of the conver-
sation contrasts noticeably with that in (1). The
investigation reported in this article aims at shed-
ding light on the nature of non-cooperation in dia-
logue, by capturing the intuitions that allow us to
differentiate between both conversations in terms
of participant behaviour.
Dialogue games supporters could say that there
is a game that describes the interaction in the first
example. While this might be true, such an ap-
proach would force us, in the limit, to define one
game for each possible conversation that would
not fit a certain standard. Walton and Krabbe
(1995) attempt a game-based approach in their
study of natural argumentation. They claim that
a rigorous model of conversational interaction is
useful, but accept that most of the huge variety of
everyday conversation escapes it. Dialogue games
are based on strict rules that capture typical dia-
logue situations while leaving out considerable de-
tail. As example (1) shows, DPs behaviour can
</bodyText>
<footnote confidence="0.978125">
2This exchange took place seven years after (1), when
public awareness of the 1995 affair had dissipated.
</footnote>
<bodyText confidence="0.9999395">
divert from the typical case in unexpected ways,
falling outside the characterisation3.
Nevertheless, the rules and patterns captured by
game models are useful, as they describe the ex-
pected behaviour of the DPs under a certain con-
versational scenario. In our research, we aim at
reconciling two worlds, using the insights from di-
alogue games to provide a description of expected
behaviour in the form of social obligations, but
looking at naturally occurring cases that deviate
from the norm. This, in turn, calls for a technique
to measure non-cooperation in dialogue and in this
paper we provide one that is theoretically sound
and supported by empirical evidence.
The following section discusses levels of co-
operation in dialogue; Section 3 presents an em-
pirical study and a practical measure of non-
cooperation in political interviews; in Section 4 we
discuss related work, our working hypothesis and
a methodology; and Section 5 has the conclusions.
</bodyText>
<sectionHeader confidence="0.83533" genericHeader="introduction">
2 Linguistic and Non-Linguistic
Cooperation
</sectionHeader>
<bodyText confidence="0.997212592592592">
Cooperation in dialogue can happen at different
levels. In most cases, conversation supports a so-
cial activity that constrains the behaviour accept-
able or expected from the participants. In addi-
tion, conversational behaviour determines how co-
operatively participants engage in a social activity.
However, cooperation at the conversational level
does not necessarily translate to the social level.
Consider, for instance, a witness under interroga-
tion in a U.S. trial refusing to answer a question by
appealing to the Fifth Amendment of the Constitu-
tion4. Such behaviour will be accepted in the con-
versational setting as established by law, although
it is not cooperative in relation with the goals of
the trial. Non-cooperation at the conversational
level, on the other hand, usually results in lack of
cooperation at the social level. Take as an exam-
ple, the same witness remaining silent, rather than
answering or appealing to the Fifth Amendment.
To illustrate further, consider a fictional alter-
native to (1), where Howard replies by saying “I
will not answer that question, as it is not relevant
to whether I exceeded the powers of my office”.
3Consider, for instance, Giznburg’s QUD model
(Ginzburg, 1996) when applied to dialogue (1), in which
Howard repeatedly fails to either accept or reject Paxman’s
question.
</bodyText>
<footnote confidence="0.6607285">
4“No person shall (...) be compelled in any criminal case
to be a witness against himself”.
</footnote>
<page confidence="0.983487">
2
</page>
<bodyText confidence="0.999993947368422">
This is not cooperative for the interview, but it is
so at the linguistic level. It would help in preserv-
ing the flow of the conversation, e.g., by triggering
a sub-dialogue to solve the disagreement.
The distinction between linguistic and non-
linguistic (also called task-related, high-level or
social) cooperation has been addressed before. At-
tardo (1997) revisits Gricean pragmatics, relat-
ing non-linguistic cooperation to participants’ be-
haviour towards realising task-related goals, and
linguistic cooperation to assumptions on their re-
spective behaviour in order to encode and decode
intended meaning. From a computational perspec-
tive, Bunt (1994) relies on a similar distinction for
defining dialogue acts. Also, Traum and Allen
(1994) introduce discourse obligations as an alter-
native to joint intentions and shared plans, to al-
low for models of dialogues in which participants
do not share the same high-level goals and where
behaviour is also determined by “a sense of obli-
gation to behave within limits set by the society”
(Traum and Allen, 1994, p.2).
Walton and Krabbe (1995) proposed a typology
of dialogue based on the initial situation trigger-
ing the exchange and participants’ shared aims and
individual goals. Based on their work, Reed and
Long (1997) distinguish cases where participants
follow a common set of dialogue rules and stay
within a mutually acknowledged framework from
a stronger notion in which their individual goals
are in the same direction. Borrowing from the lat-
ter, in the rest of the paper, we will speak of collab-
oration when DPs share the same task-level goals,
and use cooperation when participants follow the
conversational obligations imposed by the social
activity (i.e., linguistic cooperation as discussed
above). We will not deal with collaboration here,
though, as our focus is on non-cooperation.
</bodyText>
<sectionHeader confidence="0.973504" genericHeader="method">
3 An Empirical Study
</sectionHeader>
<bodyText confidence="0.9999708">
In this section, we describe an empirical pilot
study aimed at identifying a set of features that
distinguish cooperative from non-cooperative con-
versational behaviour and at establishing a suitable
domain in which to focus our work.
</bodyText>
<subsectionHeader confidence="0.993623">
3.1 The Corpus
</subsectionHeader>
<bodyText confidence="0.999792875">
We collected the transcripts of 10 adversarial di-
alogues: 4 political interviews, 2 entertainment
interviews, 1 parliamentary inquiry, 1 courtroom
confrontation, 1 courtroom interrogation and 1
dispute. The corpus includes 2 collaborative polit-
ical interviews for result comparison and is nearly
14,500 words long5.
In a first analysis, we identified those surface
features that characterised each conversation as
conflictive: e.g., interruptions, short turns, unfin-
ished adjacency pairs, verbatim repetition. Next,
looking for a better understanding, we preformed
an in-depth case study of one of the examples, ap-
proaching the analysis from different angles.
By studying, e.g., the observance of turn-taking
rules, the implicatures of the participants and,
more extensively, how the case fitted within the
normative framework proposed by Walton and
Krabbe (1995), we were able to better identify the
nature of non-cooperative features present in the
dialogue and establish a formalisable framework
for approaching non-cooperative dialogue.
As for the domain, the wealth of interesting con-
versational situations that arise in political inter-
views make a suitable context for this research. In
the English-speaking world, journalists are well-
known for their incisive approach to public ser-
vants. At the same time, politicians are usually
well trained to deliver a set of key messages when
speaking in public, and to avoid issues unfavorable
to their image. We will only consider naturally oc-
curring (i.e. non-scripted) two-party interviews.
</bodyText>
<subsectionHeader confidence="0.999924">
3.2 Degrees of Non-Cooperation
</subsectionHeader>
<bodyText confidence="0.999894157894737">
Based on the analysis described above, we pro-
pose a technique for measuring non-cooperation in
political interviews using a set of non-cooperative
features (NCFs). The number of occurrences of
these features will determine the degree of non-
cooperation (DNC) of an exchange.
We grouped NCFs following three aspects of
conversation: turn-taking, grounding and speech
acts (see Table 1 for a complete list).
Turn-taking rules (Sacks et al., 1974) estab-
lish that speakers make their contributions at ad-
equate places and in particular ways. Interlocu-
tors in a political interview are expected to respect
transition-relevance places, openings and closings
according to social conventions. Failing to do so
(e.g., by interrupting each other) constitutes a non-
cooperative feature.
Grounding (Clark and Schaefer, 1989) refers
to participants’ acknowledgement of each other’s
</bodyText>
<footnote confidence="0.964473">
5These resources are available at http://www.open.
ac.uk/blogs/brianpluss/pilot-study/.
</footnote>
<page confidence="0.987272">
3
</page>
<table confidence="0.9328505">
Turn- For both speakers:
Taking • interrupting
</table>
<listItem confidence="0.9368273">
• overlapping
• ending the exchange abruptly
Grounding Interviewer fails to either:
• ask next relevant question
• move to next topical issue
• state irrelevance of answer
Interviewee fails to either:
• give relevant answer
• reject question
Speech Interviewer either:
Acts • expresses personal opinion
• argues, debates with or criticises
interviewee’s position subjectively
• agrees with, supports or defends
interviewee’s position subjectively
Interviewee either:
• asks (non-CR) question
• makes irrelevant comment
• initiates change of topic
• criticises interviewer
</listItem>
<tableCaption confidence="0.993317">
Table 1: NCFs for political interviews
</tableCaption>
<bodyText confidence="0.999183964285714">
contributions by providing evidence of under-
standing (e.g, continued attention, relevant next
contribution). In political interviews a question is
acknowledged by rejecting it or by providing a di-
rect answer. Likewise, answers are acknowledged
by rejecting their relevance, by asking a next rel-
evant question or by moving on to a new topical
issue. Failing to provide sufficient evidence of un-
derstanding is also a non-cooperative feature.
Speech Act theory (Searle, 1979) classifies ut-
terances according to their associated force and
propositional content. Going back to Heritage’s
comment, in a political interview participants can
fail to restrict their speech acts to the force and
content expected for their role. Non-cooperative
features related to speech acts include the inter-
viewer expressing a personal opinion or criticising
subjectively the interviewee’s positions and the in-
terviewee asking questions (except for clarifica-
tion requests) or making irrelevant comments.
We define the degree of non-cooperation (DNC)
of a dialogue as the proportion of utterances with
one of more occurrences of these non-cooperative
features6. Furthermore, the DNC could be thus
computed for the whole conversation and also for
each participant, by counting only occurrences of
features and utterances from each DP.
As an example, consider an extended fragment
</bodyText>
<footnote confidence="0.48537675">
6At this stage, all NCFs are weighted equally. This is
a simplifying assumption we will remove in the future so
that, e.g., an interviewee attempting a change of topic has
a stronger impact on the DNC than, say, one interrupting.
</footnote>
<listItem confidence="0.5285808">
of (1) annotated with non-cooperative features (O:
overlap; GF: grounding failure; UC: unsolicited
comment; I: interruption; TC: topic change):
(3) P [11] : Uir.1 (overlapping) Did you threaten to O
overrule him?
</listItem>
<equation confidence="0.701963772727273">
H[12] : Uie.1 ... Mr. Marriot was not suspended. GF
P [13] : Uir.2 Did you threaten to overrule him? GF
H[14] : Uie.2 (pauses) I have accounted for my de-
cision to dismiss Derek Lewis...
P [15] : Uir.3 (overlapping) Did you threaten to
overrule him?
H[16] : Uie.2 ... in great detail before the House of
Commons.
P [17] : Uir.4 I note that you’re not answering the
question whether you threatened to
overrule him.
H[18] : Uie.3 Well, the important aspect of this
which it’s very clear to bear in
mind...
P [19] : Uir.5 (interrupting) I’m sorry, I’m going to
be frightfully rude but...
H[20] : Uie.4 Yes, you can...
P [21] : Uir.6 (overlapping) I’m sorry... O
H[22] : Uie.4 (overlapping) ... you can put the
question and I will give you, I will
give you an answer.
P [23] : Uir.7 ... it’s a straight yes-or-no question
</equation>
<tableCaption confidence="0.672555">
and a straight yes-or-no answer:
Uir.8 did you threaten to overrule him?
H[24] : Uie.5 I discussed the matter with Derek
Lewis.
Uie.6 I gave him the benefit of my opinion.
Uie.7 I gave him the benefit of my opin-
ion in strong language, but I did not
instruct him because I was not, er,
entitled to instruct him.
Uie.8 I was entitled to express my opinion
and that is what I did.
P [25] : Uir.9 With respect, that is not answering
the question of whether you threat-
ened to overrule him.
</tableCaption>
<bodyText confidence="0.627223">
H[26] : Uie.9 It’s dealing with the relevant point
which was what I was entitled to do
and what I was not entitled to do,
Uie.10 and I have dealt with this in detail
before the House of Commons and
before the select committee.
Table 2 summarises non-cooperative features,
utterances and the degree of non-cooperation for
each participant and for the whole fragment.
</bodyText>
<table confidence="0.999287555555555">
P (ir) H (ie) Fragment
Interruptions 1 0 1
Overlaps 3 1 4
Grounding Failure 1 2 3
Unsolicited Comments 0 4 4
Topic Change 0 1 1
Total NCFs 5 8 13
Utterances 9 10 19
DNC 0.56 0.80 0.68
</table>
<tableCaption confidence="0.999448">
Table 2: Computing the DNC for dialogue (3)
</tableCaption>
<bodyText confidence="0.9492455">
The DNC was computed for all the political in-
terviews in the corpus. Table 3 shows the val-
</bodyText>
<figure confidence="0.998400666666667">
O
UC
GF
I
O
UC
UC
TC
UC
</figure>
<page confidence="0.985129">
4
</page>
<tableCaption confidence="0.994742">
Table 3: DNC of political interviews in the corpus
</tableCaption>
<bodyText confidence="0.99875725">
ues obtained. Adversarial interviews have a large
number of NCFs, thus a high value for the DNC.
On the other hand, collaborative exchanges have
low occurrence of NCFs (or none at all)7.
</bodyText>
<sectionHeader confidence="0.998711" genericHeader="method">
4 Discussion
</sectionHeader>
<bodyText confidence="0.978386631578947">
There have been previous approaches to modeling
dialogue on the basis that participants are not al-
ways fully cooperative. Jameson (1989) presents
an extensive study for modeling bias, individual
goals, projected image and belief ascription in
conversation. User-model approaches are flexi-
ble to account for intricate situations but, as noted
by Taylor et al. (1996), can lead to problems like
infinite regress in nested beliefs. Taylor (1994)
addressed non-cooperative dialogue behaviour by
implementing CYNIC, a dialogue system able to
generate and recognise deception; a notion of non-
cooperation weaker than the one we address.
More recently, Traum (2008) brought attention
to the need for computational accounts of dia-
logue situations in which a broader notion of co-
operation is not assumed: e.g., intelligent tutoring
systems, bargaining agents, role-playing training
7These results and the validity of DNC measure need fur-
ther evaluation. We are currently performing two studies: one
to determine inter-annotator agreement of the coding scheme
for NCFs, and another to test how NCFs correlate to human
judgements of non-cooperative conversational behaviour.
agents8. Traum’s work on conflictive dialogue is
mainly aimed at creating virtual humans with abil-
ities to engage in adversarial dialogue. Traum et
al. (2008) present a model of conversation strate-
gies for negotiation, that includes variables repre-
senting trust, politeness and emotions, and a set of
conversational strategies. Despite being adversar-
ial in nature, the conversational scenarios are mod-
eled by means of rules, that are followed by the
interlocutors, according to the values of some of
the variables. Hence, the dialogues are adversar-
ial, but cooperative under our characterisation of
linguistic non-cooperation, and it is not clear how
effectively the model accounts for cases in which
participants fail to follow the rules of a scenario.
</bodyText>
<subsectionHeader confidence="0.995894">
4.1 Working Hypothesis
</subsectionHeader>
<bodyText confidence="0.999987944444444">
Finding a suitable model of non-cooperative dia-
logue involves bridging the gap between the the-
oretical aspects mentioned so far and the evi-
dence in the empirical data of the previous section.
Following Traum and Allen (1994), we base on
the hypothesis that non-cooperative features result
from decisions that participants make during the
conversation, by considering the obligations im-
posed by the social activity and their individual
goals, with an adequate configuration of the pri-
orities for goals and obligations.
Thus, a participant with high priorities for in-
dividual goals might compromise the workings of
a conversation by choosing contributions that go
against the norms of the social activity. On the
other hand, participants with higher priorities as-
sociated with obligations will favour contributions
consistent with the rules of the social activity.
</bodyText>
<subsectionHeader confidence="0.961026">
4.2 Research Methodology
</subsectionHeader>
<bodyText confidence="0.999961">
For the next steps of the project, we will construct
a model based on the hypothesis and test it by
means of simulation9.
The construction of the model is a formaliza-
tion of the working hypothesis, including rules for
political interviews, goals, obligations, priorities
and a dialogue management component. At the
</bodyText>
<footnote confidence="0.765896222222222">
8Traum also provides a list of “behaviours of interest”,
along the lines of the NCFs we identified above: e.g., uni-
lateral topic shifts or topic maintenance, unhelpful criticism,
withholding of information, lying, deception, antagonism.
9The use of simulation in dialogue modeling was pio-
neered by Power (1979). It suits our project better than al-
ternatives (e.g., Wizard-of-Oz, dialogue systems), by making
it easier to introduce modifications, do re-runs, and generate
a large number of cases with different parameter settings.
</footnote>
<page confidence="0.991404">
5
</page>
<bodyText confidence="0.999867583333333">
moment of writing, we are investigating the line
of research on obligation-driven dialogue model-
ing, initiated by Traum and Allen (1994) and de-
veloped further by Poesio and Traum (1998) and
Kreutel and Matheson (2003).
For the simulation, DPs will be autonomous
conversational agents with a cognitive state con-
sisting of goals, a notion of their expected be-
haviour in a political interview, priorities, and
some knowledge of the world. We are currently
implementing a prototype based on EDIS (Mathe-
son et al., 2000).
</bodyText>
<sectionHeader confidence="0.999409" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9987876">
In this paper we presented an attempt to shed light
on non-cooperation in dialogue by proposing a
practical measure of the degree of linguistic non-
cooperation in political interviews and a method-
ology towards a suitable computational model.
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999860333333333">
We would like to thank the NLG group at The
Open University (especially Paul Piwek, Richard
Power and Sandra Williams) for helpful dis-
cussion and comments on previous versions of
this paper; and three anonymous reviewers for
thoughtful feedback and suggestions.
</bodyText>
<sectionHeader confidence="0.998426" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997472075">
J.F. Allen and L.K. Schubert. 1991. The TRAINS
project. TRAINS Technical Note 91-1. Computer
Science Dept. University of Rochester.
S. Attardo. 1997. Locutionary and perlocutionary co-
operation: The perlocutionary cooperative principle.
Journal of Pragmatics, 27(6):753–779.
N. Blaylock and J. Allen. 2005. A collaborative
problem-solving model of dialogue. In Proceedings
of the 6th SIGdial Workshop on Discourse and Dia-
logue, pages 200–211, Lisbon, Portugal.
Harry Bunt. 1994. Context and dialogue control.
THINK Quarterly, 3.
H.H. Clark and E.F. Schaefer. 1989. Contributing to
discourse. Cognitive science, 13(2):259–294.
P.R. Cohen and H.J. Levesque. 1991. Confirmations
and joint action. In Proceedings of the 12 th Inter-
national Joint Conference on Artificial Intelligence,
pages 951–957.
J. Ginzburg. 1996. Interrogatives: Questions, facts and
dialogue. The handbook of contemporary semantic
theory, 5:359–423.
H. P. Grice. 1975. Logic and conversation. Syntax and
Semantics, 3:41–58.
B.J. Grosz and C.L. Sidner. 1990. Plans for discourse.
Intentions in communication, pages 417–444.
J. Heritage. 1998. Conversation analysis and insti-
tutional talk. Analyzing distinctive turn-taking sys-
tems. In Proceedings of the 6th International
Congress of IADA, Tubingen, Niemeyer.
A. Jameson. 1989. But what will the listener think?
Belief ascription and image maintenance in dialog.
User Models in Dialog Systems. Springer-Verlag,
pages 255–312.
J. Kreutel and C. Matheson. 2003. Incremental in-
formation state updates in an obligation-driven dia-
logue model. Logic Journal of IGPL, 11(4):485.
C. Matheson, M. Poesio, and D. Traum. 2000. Mod-
elling grounding and discourse obligations using up-
date rules. In Proceedings of the 1st NAACL confer-
ence, pages 1–8, San Francisco, CA, USA.
M. Poesio and D. Traum. 1998. Towards an ax-
iomatization of dialogue acts. In Proceedings of
the Twente Workshop on the Formal Semantics and
Pragmatics of Dialogues, pages 207–222.
R. Power. 1979. The organisation of purposeful dia-
logues. Linguistics, 17:107–152.
C. Reed and D. Long. 1997. Collaboration, cooper-
ation and dialogue classification. Working Notes of
the IJCAI97 Workshop on Collaboration, Cooper-
ation and Conflict in Dialogue Systems, IJCAI 97,
pages 73–78.
H. Sacks, E.A. Schegloff, and G. Jefferson. 1974. A
simplest systematics for the organization of turn-
taking for conversation. Language, pages 696–735.
J.R. Searle. 1979. A Taxonomy of lllocutionary Acts.
Expression and meaning: studies in the theory of
speech acts, pages 1–29.
J. A. Taylor, J. Carletta, and C. Mellish. 1996. Re-
quirements for belief models in cooperative dia-
logue. User Modeling and User-Adapted Interac-
tion, 6(1):23–68.
J.A. Taylor. 1994. A multi-agent planner for mod-
elling dialogue. Ph.D. Thesis, School of Cognitive
and Computing Sciences, University of Sussex.
D.R. Traum and J.F. Allen. 1994. Discourse obli-
gations in dialogue processing. In Proceedings of
the 32nd annual meeting of ACL, pages 1–8. Mor-
ristown, NJ, USA.
D. Traum, W. Swartout, J. Gratch, and S. Marsella.
2008. A virtual human dialogue model for non-team
interaction. Recent Trends in Discourse and Dia-
logue. Springer.
D. Traum. 2008. Extended Abstract: Computational
Models of Non-cooperative dialogue. In Proceed-
ings of LONDIAL 2008, the 12th Workshop on the
Semantics and Pragmatics of Dialogue, pages 11–
14, London, UK.
D. Walton and E. Krabbe. 1995. Commitment in di-
alogue: Basic concepts of interpersonal reasoning.
State University of New York Press.
</reference>
<page confidence="0.998791">
6
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.922819">
<title confidence="0.999945">Non-Cooperation in Dialogue</title>
<author confidence="0.997852">Brian Pl¨uss</author>
<affiliation confidence="0.996164">Centre for Research in Computing The Open University</affiliation>
<address confidence="0.985239">Milton Keynes, UK</address>
<email confidence="0.998032">b.pluss@open.ac.uk</email>
<abstract confidence="0.995813153846154">This paper presents ongoing research on computational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J F Allen</author>
<author>L K Schubert</author>
</authors>
<title>The TRAINS project.</title>
<date>1991</date>
<tech>TRAINS Technical Note 91-1.</tech>
<institution>Computer Science Dept. University of Rochester.</institution>
<contexts>
<context position="1542" citStr="Allen and Schubert, 1991" startWordPosition="226" endWordPosition="230">aylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in the form of dialogue systems, built for the purpose of providing a service to their users (e.g., TRAINS (Allen and Schubert, 1991)). In this scenario, failure to cooperate, either on the side of the system or of the user, is against the premises on which the system is conceived and used. In everyday conversation, however, a great many situations escape the arguments above. Consider the following example1: (1) PAXMAN [1]: (interrupting) Did you threaten to overrule him? HOWARD [2]: I, I, was not entitled to instruct Derek Lewis, and I did not instruct him. PAXMAN [3]: Did you threaten to overrule him? HOWARD [4]: The truth of the matter is that Mr. Marriott was not suspended. I... PAXMAN [5]: (overlappling) Did you threat</context>
</contexts>
<marker>Allen, Schubert, 1991</marker>
<rawString>J.F. Allen and L.K. Schubert. 1991. The TRAINS project. TRAINS Technical Note 91-1. Computer Science Dept. University of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Attardo</author>
</authors>
<title>Locutionary and perlocutionary cooperation: The perlocutionary cooperative principle.</title>
<date>1997</date>
<journal>Journal of Pragmatics,</journal>
<volume>27</volume>
<issue>6</issue>
<contexts>
<context position="9257" citStr="Attardo (1997)" startWordPosition="1483" endWordPosition="1485">r, for instance, Giznburg’s QUD model (Ginzburg, 1996) when applied to dialogue (1), in which Howard repeatedly fails to either accept or reject Paxman’s question. 4“No person shall (...) be compelled in any criminal case to be a witness against himself”. 2 This is not cooperative for the interview, but it is so at the linguistic level. It would help in preserving the flow of the conversation, e.g., by triggering a sub-dialogue to solve the disagreement. The distinction between linguistic and nonlinguistic (also called task-related, high-level or social) cooperation has been addressed before. Attardo (1997) revisits Gricean pragmatics, relating non-linguistic cooperation to participants’ behaviour towards realising task-related goals, and linguistic cooperation to assumptions on their respective behaviour in order to encode and decode intended meaning. From a computational perspective, Bunt (1994) relies on a similar distinction for defining dialogue acts. Also, Traum and Allen (1994) introduce discourse obligations as an alternative to joint intentions and shared plans, to allow for models of dialogues in which participants do not share the same high-level goals and where behaviour is also dete</context>
</contexts>
<marker>Attardo, 1997</marker>
<rawString>S. Attardo. 1997. Locutionary and perlocutionary cooperation: The perlocutionary cooperative principle. Journal of Pragmatics, 27(6):753–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Blaylock</author>
<author>J Allen</author>
</authors>
<title>A collaborative problem-solving model of dialogue.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>200--211</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="940" citStr="Blaylock and Allen, 2005" startWordPosition="127" endWordPosition="130">d by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work. 1 Introduction Most approaches to modeling conversation are based on a strong notion of cooperation between the dialogue participants (DPs). Traditional models using intentions (Cohen and Levesque, 1991), dialogue games (Power, 1979), shared plans (Grosz and Sidner, 1990) or collaborative problem-solving (Blaylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in the form of dialogue systems, built for the purpose of providing a service to their users (e.g., TRAINS (Allen and Schubert, 199</context>
</contexts>
<marker>Blaylock, Allen, 2005</marker>
<rawString>N. Blaylock and J. Allen. 2005. A collaborative problem-solving model of dialogue. In Proceedings of the 6th SIGdial Workshop on Discourse and Dialogue, pages 200–211, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harry Bunt</author>
</authors>
<title>Context and dialogue control.</title>
<date>1994</date>
<journal>THINK Quarterly,</journal>
<volume>3</volume>
<contexts>
<context position="9553" citStr="Bunt (1994)" startWordPosition="1524" endWordPosition="1525">, but it is so at the linguistic level. It would help in preserving the flow of the conversation, e.g., by triggering a sub-dialogue to solve the disagreement. The distinction between linguistic and nonlinguistic (also called task-related, high-level or social) cooperation has been addressed before. Attardo (1997) revisits Gricean pragmatics, relating non-linguistic cooperation to participants’ behaviour towards realising task-related goals, and linguistic cooperation to assumptions on their respective behaviour in order to encode and decode intended meaning. From a computational perspective, Bunt (1994) relies on a similar distinction for defining dialogue acts. Also, Traum and Allen (1994) introduce discourse obligations as an alternative to joint intentions and shared plans, to allow for models of dialogues in which participants do not share the same high-level goals and where behaviour is also determined by “a sense of obligation to behave within limits set by the society” (Traum and Allen, 1994, p.2). Walton and Krabbe (1995) proposed a typology of dialogue based on the initial situation triggering the exchange and participants’ shared aims and individual goals. Based on their work, Reed</context>
</contexts>
<marker>Bunt, 1994</marker>
<rawString>Harry Bunt. 1994. Context and dialogue control. THINK Quarterly, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Clark</author>
<author>E F Schaefer</author>
</authors>
<title>Contributing to discourse. Cognitive science,</title>
<date>1989</date>
<pages>13--2</pages>
<contexts>
<context position="1334" citStr="Clark and Schaefer, 1989" startWordPosition="192" endWordPosition="195">etween the dialogue participants (DPs). Traditional models using intentions (Cohen and Levesque, 1991), dialogue games (Power, 1979), shared plans (Grosz and Sidner, 1990) or collaborative problem-solving (Blaylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in the form of dialogue systems, built for the purpose of providing a service to their users (e.g., TRAINS (Allen and Schubert, 1991)). In this scenario, failure to cooperate, either on the side of the system or of the user, is against the premises on which the system is conceived and used. In everyday conversation, however, a great many situations escape the arguments above. Consider the following example1: (1) PAXMAN [1]: (interrupting) Did you threaten to overrule him? HOWARD [2]: I, I, was not entitled to instruct D</context>
<context position="13397" citStr="Clark and Schaefer, 1989" startWordPosition="2108" endWordPosition="2111">ences of these features will determine the degree of noncooperation (DNC) of an exchange. We grouped NCFs following three aspects of conversation: turn-taking, grounding and speech acts (see Table 1 for a complete list). Turn-taking rules (Sacks et al., 1974) establish that speakers make their contributions at adequate places and in particular ways. Interlocutors in a political interview are expected to respect transition-relevance places, openings and closings according to social conventions. Failing to do so (e.g., by interrupting each other) constitutes a noncooperative feature. Grounding (Clark and Schaefer, 1989) refers to participants’ acknowledgement of each other’s 5These resources are available at http://www.open. ac.uk/blogs/brianpluss/pilot-study/. 3 Turn- For both speakers: Taking • interrupting • overlapping • ending the exchange abruptly Grounding Interviewer fails to either: • ask next relevant question • move to next topical issue • state irrelevance of answer Interviewee fails to either: • give relevant answer • reject question Speech Interviewer either: Acts • expresses personal opinion • argues, debates with or criticises interviewee’s position subjectively • agrees with, supports or def</context>
</contexts>
<marker>Clark, Schaefer, 1989</marker>
<rawString>H.H. Clark and E.F. Schaefer. 1989. Contributing to discourse. Cognitive science, 13(2):259–294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
<author>H J Levesque</author>
</authors>
<title>Confirmations and joint action.</title>
<date>1991</date>
<booktitle>In Proceedings of the 12 th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>951--957</pages>
<contexts>
<context position="811" citStr="Cohen and Levesque, 1991" startWordPosition="110" endWordPosition="113">ational models for non-cooperative dialogue. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work. 1 Introduction Most approaches to modeling conversation are based on a strong notion of cooperation between the dialogue participants (DPs). Traditional models using intentions (Cohen and Levesque, 1991), dialogue games (Power, 1979), shared plans (Grosz and Sidner, 1990) or collaborative problem-solving (Blaylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in</context>
</contexts>
<marker>Cohen, Levesque, 1991</marker>
<rawString>P.R. Cohen and H.J. Levesque. 1991. Confirmations and joint action. In Proceedings of the 12 th International Joint Conference on Artificial Intelligence, pages 951–957.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ginzburg</author>
</authors>
<title>Interrogatives: Questions, facts and dialogue. The handbook of contemporary semantic theory,</title>
<date>1996</date>
<pages>5--359</pages>
<contexts>
<context position="8697" citStr="Ginzburg, 1996" startWordPosition="1394" endWordPosition="1395">nversational setting as established by law, although it is not cooperative in relation with the goals of the trial. Non-cooperation at the conversational level, on the other hand, usually results in lack of cooperation at the social level. Take as an example, the same witness remaining silent, rather than answering or appealing to the Fifth Amendment. To illustrate further, consider a fictional alternative to (1), where Howard replies by saying “I will not answer that question, as it is not relevant to whether I exceeded the powers of my office”. 3Consider, for instance, Giznburg’s QUD model (Ginzburg, 1996) when applied to dialogue (1), in which Howard repeatedly fails to either accept or reject Paxman’s question. 4“No person shall (...) be compelled in any criminal case to be a witness against himself”. 2 This is not cooperative for the interview, but it is so at the linguistic level. It would help in preserving the flow of the conversation, e.g., by triggering a sub-dialogue to solve the disagreement. The distinction between linguistic and nonlinguistic (also called task-related, high-level or social) cooperation has been addressed before. Attardo (1997) revisits Gricean pragmatics, relating n</context>
</contexts>
<marker>Ginzburg, 1996</marker>
<rawString>J. Ginzburg. 1996. Interrogatives: Questions, facts and dialogue. The handbook of contemporary semantic theory, 5:359–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<date>1975</date>
<booktitle>Logic and conversation. Syntax and Semantics,</booktitle>
<pages>3--41</pages>
<contexts>
<context position="1307" citStr="Grice, 1975" startWordPosition="190" endWordPosition="191">cooperation between the dialogue participants (DPs). Traditional models using intentions (Cohen and Levesque, 1991), dialogue games (Power, 1979), shared plans (Grosz and Sidner, 1990) or collaborative problem-solving (Blaylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in the form of dialogue systems, built for the purpose of providing a service to their users (e.g., TRAINS (Allen and Schubert, 1991)). In this scenario, failure to cooperate, either on the side of the system or of the user, is against the premises on which the system is conceived and used. In everyday conversation, however, a great many situations escape the arguments above. Consider the following example1: (1) PAXMAN [1]: (interrupting) Did you threaten to overrule him? HOWARD [2]: I, I, was</context>
</contexts>
<marker>Grice, 1975</marker>
<rawString>H. P. Grice. 1975. Logic and conversation. Syntax and Semantics, 3:41–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>C L Sidner</author>
</authors>
<title>Plans for discourse. Intentions in communication,</title>
<date>1990</date>
<pages>417--444</pages>
<contexts>
<context position="880" citStr="Grosz and Sidner, 1990" startWordPosition="120" endWordPosition="123">erent levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work. 1 Introduction Most approaches to modeling conversation are based on a strong notion of cooperation between the dialogue participants (DPs). Traditional models using intentions (Cohen and Levesque, 1991), dialogue games (Power, 1979), shared plans (Grosz and Sidner, 1990) or collaborative problem-solving (Blaylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in the form of dialogue systems, built for the purpose of providing a s</context>
</contexts>
<marker>Grosz, Sidner, 1990</marker>
<rawString>B.J. Grosz and C.L. Sidner. 1990. Plans for discourse. Intentions in communication, pages 417–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Heritage</author>
</authors>
<title>Conversation analysis and institutional talk. Analyzing distinctive turn-taking systems.</title>
<date>1998</date>
<booktitle>In Proceedings of the 6th International Congress of IADA,</booktitle>
<location>Tubingen, Niemeyer.</location>
<contexts>
<context position="3247" citStr="Heritage (1998)" startWordPosition="519" endWordPosition="520"> to overrule him? HOWARD[14]: (pauses) I have accounted for my decision to dismiss Derek Lewis... PAXMAN [15]: (overlapping) Did you threaten to overrule him? HOWARD[16]:... in great detail, before the House of Commons. PAXMAN [17]: I note that you’re not answering the question of whether you threatened to overrule him. (Newsnight, BBC, 1997) We take it for granted that, at some level, Paxman and Howard are sharing a goal, for otherwise they would not be having an interview. Still, the exchange is clearly conflictive, to the point that their behaviour compromises the flow of the conversation. Heritage (1998) analyses the distinctive roles of DPs in news interviews: 1BBC presenter Jeremy Paxman questions former UK Home Secretary Michael Howard with respect to a meeting in 1995 between Howard and the head of the Prison Service, Derek Lewis, about the dismissal of the governor of Parkhurst Prison, John Marriott, due to repeated security failures. The case was given considerable attention in the media, as a result of accusations by Lewis that Howard had instructed him, thus exceeding the powers of his office. 1 Proceedings of the ACL 2010 Student Research Workshop, pages 1–6, Uppsala, Sweden, 13 July</context>
<context position="4635" citStr="Heritage, 1998" startWordPosition="737" endWordPosition="738"> they are normally free to do in the give and take of ordinary conversation. If IRs restrict themselves to asking questions, then they cannot - at least overtly - express opinions, or argue with, debate or criticize the interviewees’ positions nor, conversely, agree with, support or defend them. Correspondingly, if IEs restrict themselves to answers (or responses) to questions, then they cannot ask questions (of IRs or other IEs), nor make unsolicited comments on previous remarks, initiate changes of topic, or divert the discussion into criticisms of the IR or the broadcasting organization.” (Heritage, 1998, p.8) Now, consider the fragment below2: (2) PAXMAN[1]: Can you clear up whether or not you did threaten to overrule Derek Lewis when you were Home Secretary? HOWARD[2]: Oh, come on, Jeremy, you are really going to go back over that again? As... PAXMAN [3]: (overlapping) You’ve had seven years to think about it! HOWARD[4]: (overlapping)... as, as it happens, I didn’t. Are you satisfied now? PAXMAN [5]: Thank you. Why didn’t you say that at the time? HOWARD[6]: I, well, we’ve been over this many, many times. I, I, I knew that everyone was crawling over every syllable I said about that, and I w</context>
</contexts>
<marker>Heritage, 1998</marker>
<rawString>J. Heritage. 1998. Conversation analysis and institutional talk. Analyzing distinctive turn-taking systems. In Proceedings of the 6th International Congress of IADA, Tubingen, Niemeyer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Jameson</author>
</authors>
<title>But what will the listener think? Belief ascription and image maintenance in dialog. User Models in Dialog Systems.</title>
<date>1989</date>
<pages>255--312</pages>
<publisher>Springer-Verlag,</publisher>
<contexts>
<context position="18399" citStr="Jameson (1989)" startWordPosition="2945" endWordPosition="2946">ange 0 1 1 Total NCFs 5 8 13 Utterances 9 10 19 DNC 0.56 0.80 0.68 Table 2: Computing the DNC for dialogue (3) The DNC was computed for all the political interviews in the corpus. Table 3 shows the valO UC GF I O UC UC TC UC 4 Table 3: DNC of political interviews in the corpus ues obtained. Adversarial interviews have a large number of NCFs, thus a high value for the DNC. On the other hand, collaborative exchanges have low occurrence of NCFs (or none at all)7. 4 Discussion There have been previous approaches to modeling dialogue on the basis that participants are not always fully cooperative. Jameson (1989) presents an extensive study for modeling bias, individual goals, projected image and belief ascription in conversation. User-model approaches are flexible to account for intricate situations but, as noted by Taylor et al. (1996), can lead to problems like infinite regress in nested beliefs. Taylor (1994) addressed non-cooperative dialogue behaviour by implementing CYNIC, a dialogue system able to generate and recognise deception; a notion of noncooperation weaker than the one we address. More recently, Traum (2008) brought attention to the need for computational accounts of dialogue situation</context>
</contexts>
<marker>Jameson, 1989</marker>
<rawString>A. Jameson. 1989. But what will the listener think? Belief ascription and image maintenance in dialog. User Models in Dialog Systems. Springer-Verlag, pages 255–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kreutel</author>
<author>C Matheson</author>
</authors>
<title>Incremental information state updates in an obligation-driven dialogue model.</title>
<date>2003</date>
<journal>Logic Journal of IGPL,</journal>
<volume>11</volume>
<issue>4</issue>
<contexts>
<context position="22155" citStr="Kreutel and Matheson (2003)" startWordPosition="3515" endWordPosition="3518"> topic shifts or topic maintenance, unhelpful criticism, withholding of information, lying, deception, antagonism. 9The use of simulation in dialogue modeling was pioneered by Power (1979). It suits our project better than alternatives (e.g., Wizard-of-Oz, dialogue systems), by making it easier to introduce modifications, do re-runs, and generate a large number of cases with different parameter settings. 5 moment of writing, we are investigating the line of research on obligation-driven dialogue modeling, initiated by Traum and Allen (1994) and developed further by Poesio and Traum (1998) and Kreutel and Matheson (2003). For the simulation, DPs will be autonomous conversational agents with a cognitive state consisting of goals, a notion of their expected behaviour in a political interview, priorities, and some knowledge of the world. We are currently implementing a prototype based on EDIS (Matheson et al., 2000). 5 Conclusions In this paper we presented an attempt to shed light on non-cooperation in dialogue by proposing a practical measure of the degree of linguistic noncooperation in political interviews and a methodology towards a suitable computational model. Acknowledgments We would like to thank the NL</context>
</contexts>
<marker>Kreutel, Matheson, 2003</marker>
<rawString>J. Kreutel and C. Matheson. 2003. Incremental information state updates in an obligation-driven dialogue model. Logic Journal of IGPL, 11(4):485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Matheson</author>
<author>M Poesio</author>
<author>D Traum</author>
</authors>
<title>Modelling grounding and discourse obligations using update rules.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st NAACL conference,</booktitle>
<pages>1--8</pages>
<location>San Francisco, CA, USA.</location>
<marker>Matheson, Poesio, Traum, 2000</marker>
<rawString>C. Matheson, M. Poesio, and D. Traum. 2000. Modelling grounding and discourse obligations using update rules. In Proceedings of the 1st NAACL conference, pages 1–8, San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>D Traum</author>
</authors>
<title>Towards an axiomatization of dialogue acts.</title>
<date>1998</date>
<booktitle>In Proceedings of the Twente Workshop on the Formal Semantics and Pragmatics of Dialogues,</booktitle>
<pages>207--222</pages>
<contexts>
<context position="22123" citStr="Poesio and Traum (1998)" startWordPosition="3510" endWordPosition="3513">fied above: e.g., unilateral topic shifts or topic maintenance, unhelpful criticism, withholding of information, lying, deception, antagonism. 9The use of simulation in dialogue modeling was pioneered by Power (1979). It suits our project better than alternatives (e.g., Wizard-of-Oz, dialogue systems), by making it easier to introduce modifications, do re-runs, and generate a large number of cases with different parameter settings. 5 moment of writing, we are investigating the line of research on obligation-driven dialogue modeling, initiated by Traum and Allen (1994) and developed further by Poesio and Traum (1998) and Kreutel and Matheson (2003). For the simulation, DPs will be autonomous conversational agents with a cognitive state consisting of goals, a notion of their expected behaviour in a political interview, priorities, and some knowledge of the world. We are currently implementing a prototype based on EDIS (Matheson et al., 2000). 5 Conclusions In this paper we presented an attempt to shed light on non-cooperation in dialogue by proposing a practical measure of the degree of linguistic noncooperation in political interviews and a methodology towards a suitable computational model. Acknowledgmen</context>
</contexts>
<marker>Poesio, Traum, 1998</marker>
<rawString>M. Poesio and D. Traum. 1998. Towards an axiomatization of dialogue acts. In Proceedings of the Twente Workshop on the Formal Semantics and Pragmatics of Dialogues, pages 207–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Power</author>
</authors>
<title>The organisation of purposeful dialogues.</title>
<date>1979</date>
<journal>Linguistics,</journal>
<pages>17--107</pages>
<contexts>
<context position="841" citStr="Power, 1979" startWordPosition="116" endWordPosition="117">. We start by analysing different levels of cooperation in conversation. Then, inspired by findings from an empirical study, we propose a technique for measuring non-cooperation in political interviews. Finally, we describe a research programme towards obtaining a suitable model and discuss previous accounts for conflictive dialogue, identifying the differences with our work. 1 Introduction Most approaches to modeling conversation are based on a strong notion of cooperation between the dialogue participants (DPs). Traditional models using intentions (Cohen and Levesque, 1991), dialogue games (Power, 1979), shared plans (Grosz and Sidner, 1990) or collaborative problem-solving (Blaylock and Allen, 2005) explain dialogue situations in which DPs recognise each other’s intentions and, at least to a certain extent, accept each other’s goals when deciding on their actions. These assumptions are theoretically grounded, as most work in linguistics has considered situations in which DPs share a common goal and cooperate to achieve it by means of conversation (Grice, 1975; Clark and Schaefer, 1989). They are also practically sound: dialogue models are usually implemented in the form of dialogue systems,</context>
<context position="21716" citStr="Power (1979)" startWordPosition="3449" endWordPosition="3450">steps of the project, we will construct a model based on the hypothesis and test it by means of simulation9. The construction of the model is a formalization of the working hypothesis, including rules for political interviews, goals, obligations, priorities and a dialogue management component. At the 8Traum also provides a list of “behaviours of interest”, along the lines of the NCFs we identified above: e.g., unilateral topic shifts or topic maintenance, unhelpful criticism, withholding of information, lying, deception, antagonism. 9The use of simulation in dialogue modeling was pioneered by Power (1979). It suits our project better than alternatives (e.g., Wizard-of-Oz, dialogue systems), by making it easier to introduce modifications, do re-runs, and generate a large number of cases with different parameter settings. 5 moment of writing, we are investigating the line of research on obligation-driven dialogue modeling, initiated by Traum and Allen (1994) and developed further by Poesio and Traum (1998) and Kreutel and Matheson (2003). For the simulation, DPs will be autonomous conversational agents with a cognitive state consisting of goals, a notion of their expected behaviour in a politica</context>
</contexts>
<marker>Power, 1979</marker>
<rawString>R. Power. 1979. The organisation of purposeful dialogues. Linguistics, 17:107–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Reed</author>
<author>D Long</author>
</authors>
<title>Collaboration, cooperation and dialogue classification.</title>
<date>1997</date>
<booktitle>Working Notes of the IJCAI97 Workshop on Collaboration, Cooperation and Conflict in Dialogue Systems, IJCAI 97,</booktitle>
<pages>73--78</pages>
<contexts>
<context position="10169" citStr="Reed and Long (1997)" startWordPosition="1624" endWordPosition="1627">994) relies on a similar distinction for defining dialogue acts. Also, Traum and Allen (1994) introduce discourse obligations as an alternative to joint intentions and shared plans, to allow for models of dialogues in which participants do not share the same high-level goals and where behaviour is also determined by “a sense of obligation to behave within limits set by the society” (Traum and Allen, 1994, p.2). Walton and Krabbe (1995) proposed a typology of dialogue based on the initial situation triggering the exchange and participants’ shared aims and individual goals. Based on their work, Reed and Long (1997) distinguish cases where participants follow a common set of dialogue rules and stay within a mutually acknowledged framework from a stronger notion in which their individual goals are in the same direction. Borrowing from the latter, in the rest of the paper, we will speak of collaboration when DPs share the same task-level goals, and use cooperation when participants follow the conversational obligations imposed by the social activity (i.e., linguistic cooperation as discussed above). We will not deal with collaboration here, though, as our focus is on non-cooperation. 3 An Empirical Study I</context>
</contexts>
<marker>Reed, Long, 1997</marker>
<rawString>C. Reed and D. Long. 1997. Collaboration, cooperation and dialogue classification. Working Notes of the IJCAI97 Workshop on Collaboration, Cooperation and Conflict in Dialogue Systems, IJCAI 97, pages 73–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sacks</author>
<author>E A Schegloff</author>
<author>G Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turntaking for conversation. Language,</title>
<date>1974</date>
<pages>696--735</pages>
<contexts>
<context position="13031" citStr="Sacks et al., 1974" startWordPosition="2055" endWordPosition="2058">g in public, and to avoid issues unfavorable to their image. We will only consider naturally occurring (i.e. non-scripted) two-party interviews. 3.2 Degrees of Non-Cooperation Based on the analysis described above, we propose a technique for measuring non-cooperation in political interviews using a set of non-cooperative features (NCFs). The number of occurrences of these features will determine the degree of noncooperation (DNC) of an exchange. We grouped NCFs following three aspects of conversation: turn-taking, grounding and speech acts (see Table 1 for a complete list). Turn-taking rules (Sacks et al., 1974) establish that speakers make their contributions at adequate places and in particular ways. Interlocutors in a political interview are expected to respect transition-relevance places, openings and closings according to social conventions. Failing to do so (e.g., by interrupting each other) constitutes a noncooperative feature. Grounding (Clark and Schaefer, 1989) refers to participants’ acknowledgement of each other’s 5These resources are available at http://www.open. ac.uk/blogs/brianpluss/pilot-study/. 3 Turn- For both speakers: Taking • interrupting • overlapping • ending the exchange abru</context>
</contexts>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>H. Sacks, E.A. Schegloff, and G. Jefferson. 1974. A simplest systematics for the organization of turntaking for conversation. Language, pages 696–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>A Taxonomy of lllocutionary Acts. Expression and meaning: studies in the theory of speech acts,</title>
<date>1979</date>
<pages>1--29</pages>
<contexts>
<context position="14674" citStr="Searle, 1979" startWordPosition="2293" endWordPosition="2294">sks (non-CR) question • makes irrelevant comment • initiates change of topic • criticises interviewer Table 1: NCFs for political interviews contributions by providing evidence of understanding (e.g, continued attention, relevant next contribution). In political interviews a question is acknowledged by rejecting it or by providing a direct answer. Likewise, answers are acknowledged by rejecting their relevance, by asking a next relevant question or by moving on to a new topical issue. Failing to provide sufficient evidence of understanding is also a non-cooperative feature. Speech Act theory (Searle, 1979) classifies utterances according to their associated force and propositional content. Going back to Heritage’s comment, in a political interview participants can fail to restrict their speech acts to the force and content expected for their role. Non-cooperative features related to speech acts include the interviewer expressing a personal opinion or criticising subjectively the interviewee’s positions and the interviewee asking questions (except for clarification requests) or making irrelevant comments. We define the degree of non-cooperation (DNC) of a dialogue as the proportion of utterances</context>
</contexts>
<marker>Searle, 1979</marker>
<rawString>J.R. Searle. 1979. A Taxonomy of lllocutionary Acts. Expression and meaning: studies in the theory of speech acts, pages 1–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Taylor</author>
<author>J Carletta</author>
<author>C Mellish</author>
</authors>
<title>Requirements for belief models in cooperative dialogue. User Modeling and User-Adapted Interaction,</title>
<date>1996</date>
<pages>6--1</pages>
<contexts>
<context position="18628" citStr="Taylor et al. (1996)" startWordPosition="2977" endWordPosition="2980">C 4 Table 3: DNC of political interviews in the corpus ues obtained. Adversarial interviews have a large number of NCFs, thus a high value for the DNC. On the other hand, collaborative exchanges have low occurrence of NCFs (or none at all)7. 4 Discussion There have been previous approaches to modeling dialogue on the basis that participants are not always fully cooperative. Jameson (1989) presents an extensive study for modeling bias, individual goals, projected image and belief ascription in conversation. User-model approaches are flexible to account for intricate situations but, as noted by Taylor et al. (1996), can lead to problems like infinite regress in nested beliefs. Taylor (1994) addressed non-cooperative dialogue behaviour by implementing CYNIC, a dialogue system able to generate and recognise deception; a notion of noncooperation weaker than the one we address. More recently, Traum (2008) brought attention to the need for computational accounts of dialogue situations in which a broader notion of cooperation is not assumed: e.g., intelligent tutoring systems, bargaining agents, role-playing training 7These results and the validity of DNC measure need further evaluation. We are currently perf</context>
</contexts>
<marker>Taylor, Carletta, Mellish, 1996</marker>
<rawString>J. A. Taylor, J. Carletta, and C. Mellish. 1996. Requirements for belief models in cooperative dialogue. User Modeling and User-Adapted Interaction, 6(1):23–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Taylor</author>
</authors>
<title>A multi-agent planner for modelling dialogue.</title>
<date>1994</date>
<tech>Ph.D. Thesis,</tech>
<institution>School of Cognitive and Computing Sciences, University of Sussex.</institution>
<contexts>
<context position="18705" citStr="Taylor (1994)" startWordPosition="2991" endWordPosition="2992">erviews have a large number of NCFs, thus a high value for the DNC. On the other hand, collaborative exchanges have low occurrence of NCFs (or none at all)7. 4 Discussion There have been previous approaches to modeling dialogue on the basis that participants are not always fully cooperative. Jameson (1989) presents an extensive study for modeling bias, individual goals, projected image and belief ascription in conversation. User-model approaches are flexible to account for intricate situations but, as noted by Taylor et al. (1996), can lead to problems like infinite regress in nested beliefs. Taylor (1994) addressed non-cooperative dialogue behaviour by implementing CYNIC, a dialogue system able to generate and recognise deception; a notion of noncooperation weaker than the one we address. More recently, Traum (2008) brought attention to the need for computational accounts of dialogue situations in which a broader notion of cooperation is not assumed: e.g., intelligent tutoring systems, bargaining agents, role-playing training 7These results and the validity of DNC measure need further evaluation. We are currently performing two studies: one to determine inter-annotator agreement of the coding </context>
</contexts>
<marker>Taylor, 1994</marker>
<rawString>J.A. Taylor. 1994. A multi-agent planner for modelling dialogue. Ph.D. Thesis, School of Cognitive and Computing Sciences, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Traum</author>
<author>J F Allen</author>
</authors>
<title>Discourse obligations in dialogue processing.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd annual meeting of ACL,</booktitle>
<pages>1--8</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="9642" citStr="Traum and Allen (1994)" startWordPosition="1536" endWordPosition="1539">f the conversation, e.g., by triggering a sub-dialogue to solve the disagreement. The distinction between linguistic and nonlinguistic (also called task-related, high-level or social) cooperation has been addressed before. Attardo (1997) revisits Gricean pragmatics, relating non-linguistic cooperation to participants’ behaviour towards realising task-related goals, and linguistic cooperation to assumptions on their respective behaviour in order to encode and decode intended meaning. From a computational perspective, Bunt (1994) relies on a similar distinction for defining dialogue acts. Also, Traum and Allen (1994) introduce discourse obligations as an alternative to joint intentions and shared plans, to allow for models of dialogues in which participants do not share the same high-level goals and where behaviour is also determined by “a sense of obligation to behave within limits set by the society” (Traum and Allen, 1994, p.2). Walton and Krabbe (1995) proposed a typology of dialogue based on the initial situation triggering the exchange and participants’ shared aims and individual goals. Based on their work, Reed and Long (1997) distinguish cases where participants follow a common set of dialogue rul</context>
<context position="20427" citStr="Traum and Allen (1994)" startWordPosition="3251" endWordPosition="3254">onal scenarios are modeled by means of rules, that are followed by the interlocutors, according to the values of some of the variables. Hence, the dialogues are adversarial, but cooperative under our characterisation of linguistic non-cooperation, and it is not clear how effectively the model accounts for cases in which participants fail to follow the rules of a scenario. 4.1 Working Hypothesis Finding a suitable model of non-cooperative dialogue involves bridging the gap between the theoretical aspects mentioned so far and the evidence in the empirical data of the previous section. Following Traum and Allen (1994), we base on the hypothesis that non-cooperative features result from decisions that participants make during the conversation, by considering the obligations imposed by the social activity and their individual goals, with an adequate configuration of the priorities for goals and obligations. Thus, a participant with high priorities for individual goals might compromise the workings of a conversation by choosing contributions that go against the norms of the social activity. On the other hand, participants with higher priorities associated with obligations will favour contributions consistent </context>
<context position="22074" citStr="Traum and Allen (1994)" startWordPosition="3501" endWordPosition="3504">interest”, along the lines of the NCFs we identified above: e.g., unilateral topic shifts or topic maintenance, unhelpful criticism, withholding of information, lying, deception, antagonism. 9The use of simulation in dialogue modeling was pioneered by Power (1979). It suits our project better than alternatives (e.g., Wizard-of-Oz, dialogue systems), by making it easier to introduce modifications, do re-runs, and generate a large number of cases with different parameter settings. 5 moment of writing, we are investigating the line of research on obligation-driven dialogue modeling, initiated by Traum and Allen (1994) and developed further by Poesio and Traum (1998) and Kreutel and Matheson (2003). For the simulation, DPs will be autonomous conversational agents with a cognitive state consisting of goals, a notion of their expected behaviour in a political interview, priorities, and some knowledge of the world. We are currently implementing a prototype based on EDIS (Matheson et al., 2000). 5 Conclusions In this paper we presented an attempt to shed light on non-cooperation in dialogue by proposing a practical measure of the degree of linguistic noncooperation in political interviews and a methodology towa</context>
</contexts>
<marker>Traum, Allen, 1994</marker>
<rawString>D.R. Traum and J.F. Allen. 1994. Discourse obligations in dialogue processing. In Proceedings of the 32nd annual meeting of ACL, pages 1–8. Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
<author>W Swartout</author>
<author>J Gratch</author>
<author>S Marsella</author>
</authors>
<title>A virtual human dialogue model for non-team interaction. Recent Trends in Discourse and Dialogue.</title>
<date>2008</date>
<publisher>Springer.</publisher>
<contexts>
<context position="19584" citStr="Traum et al. (2008)" startWordPosition="3119" endWordPosition="3122">nal accounts of dialogue situations in which a broader notion of cooperation is not assumed: e.g., intelligent tutoring systems, bargaining agents, role-playing training 7These results and the validity of DNC measure need further evaluation. We are currently performing two studies: one to determine inter-annotator agreement of the coding scheme for NCFs, and another to test how NCFs correlate to human judgements of non-cooperative conversational behaviour. agents8. Traum’s work on conflictive dialogue is mainly aimed at creating virtual humans with abilities to engage in adversarial dialogue. Traum et al. (2008) present a model of conversation strategies for negotiation, that includes variables representing trust, politeness and emotions, and a set of conversational strategies. Despite being adversarial in nature, the conversational scenarios are modeled by means of rules, that are followed by the interlocutors, according to the values of some of the variables. Hence, the dialogues are adversarial, but cooperative under our characterisation of linguistic non-cooperation, and it is not clear how effectively the model accounts for cases in which participants fail to follow the rules of a scenario. 4.1 </context>
</contexts>
<marker>Traum, Swartout, Gratch, Marsella, 2008</marker>
<rawString>D. Traum, W. Swartout, J. Gratch, and S. Marsella. 2008. A virtual human dialogue model for non-team interaction. Recent Trends in Discourse and Dialogue. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>Extended Abstract: Computational Models of Non-cooperative dialogue.</title>
<date>2008</date>
<booktitle>In Proceedings of LONDIAL 2008, the 12th Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<pages>11--14</pages>
<location>London, UK.</location>
<contexts>
<context position="18920" citStr="Traum (2008)" startWordPosition="3022" endWordPosition="3023">ng dialogue on the basis that participants are not always fully cooperative. Jameson (1989) presents an extensive study for modeling bias, individual goals, projected image and belief ascription in conversation. User-model approaches are flexible to account for intricate situations but, as noted by Taylor et al. (1996), can lead to problems like infinite regress in nested beliefs. Taylor (1994) addressed non-cooperative dialogue behaviour by implementing CYNIC, a dialogue system able to generate and recognise deception; a notion of noncooperation weaker than the one we address. More recently, Traum (2008) brought attention to the need for computational accounts of dialogue situations in which a broader notion of cooperation is not assumed: e.g., intelligent tutoring systems, bargaining agents, role-playing training 7These results and the validity of DNC measure need further evaluation. We are currently performing two studies: one to determine inter-annotator agreement of the coding scheme for NCFs, and another to test how NCFs correlate to human judgements of non-cooperative conversational behaviour. agents8. Traum’s work on conflictive dialogue is mainly aimed at creating virtual humans with </context>
</contexts>
<marker>Traum, 2008</marker>
<rawString>D. Traum. 2008. Extended Abstract: Computational Models of Non-cooperative dialogue. In Proceedings of LONDIAL 2008, the 12th Workshop on the Semantics and Pragmatics of Dialogue, pages 11– 14, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Walton</author>
<author>E Krabbe</author>
</authors>
<title>Commitment in dialogue: Basic concepts of interpersonal reasoning.</title>
<date>1995</date>
<publisher>Press.</publisher>
<institution>State University of New York</institution>
<contexts>
<context position="5996" citStr="Walton and Krabbe (1995)" startWordPosition="965" endWordPosition="968">wer almost immediately and the flow of the conversation contrasts noticeably with that in (1). The investigation reported in this article aims at shedding light on the nature of non-cooperation in dialogue, by capturing the intuitions that allow us to differentiate between both conversations in terms of participant behaviour. Dialogue games supporters could say that there is a game that describes the interaction in the first example. While this might be true, such an approach would force us, in the limit, to define one game for each possible conversation that would not fit a certain standard. Walton and Krabbe (1995) attempt a game-based approach in their study of natural argumentation. They claim that a rigorous model of conversational interaction is useful, but accept that most of the huge variety of everyday conversation escapes it. Dialogue games are based on strict rules that capture typical dialogue situations while leaving out considerable detail. As example (1) shows, DPs behaviour can 2This exchange took place seven years after (1), when public awareness of the 1995 affair had dissipated. divert from the typical case in unexpected ways, falling outside the characterisation3. Nevertheless, the rul</context>
<context position="9988" citStr="Walton and Krabbe (1995)" startWordPosition="1595" endWordPosition="1598">ing task-related goals, and linguistic cooperation to assumptions on their respective behaviour in order to encode and decode intended meaning. From a computational perspective, Bunt (1994) relies on a similar distinction for defining dialogue acts. Also, Traum and Allen (1994) introduce discourse obligations as an alternative to joint intentions and shared plans, to allow for models of dialogues in which participants do not share the same high-level goals and where behaviour is also determined by “a sense of obligation to behave within limits set by the society” (Traum and Allen, 1994, p.2). Walton and Krabbe (1995) proposed a typology of dialogue based on the initial situation triggering the exchange and participants’ shared aims and individual goals. Based on their work, Reed and Long (1997) distinguish cases where participants follow a common set of dialogue rules and stay within a mutually acknowledged framework from a stronger notion in which their individual goals are in the same direction. Borrowing from the latter, in the rest of the paper, we will speak of collaboration when DPs share the same task-level goals, and use cooperation when participants follow the conversational obligations imposed b</context>
<context position="11880" citStr="Walton and Krabbe (1995)" startWordPosition="1880" endWordPosition="1883">political interviews for result comparison and is nearly 14,500 words long5. In a first analysis, we identified those surface features that characterised each conversation as conflictive: e.g., interruptions, short turns, unfinished adjacency pairs, verbatim repetition. Next, looking for a better understanding, we preformed an in-depth case study of one of the examples, approaching the analysis from different angles. By studying, e.g., the observance of turn-taking rules, the implicatures of the participants and, more extensively, how the case fitted within the normative framework proposed by Walton and Krabbe (1995), we were able to better identify the nature of non-cooperative features present in the dialogue and establish a formalisable framework for approaching non-cooperative dialogue. As for the domain, the wealth of interesting conversational situations that arise in political interviews make a suitable context for this research. In the English-speaking world, journalists are wellknown for their incisive approach to public servants. At the same time, politicians are usually well trained to deliver a set of key messages when speaking in public, and to avoid issues unfavorable to their image. We will</context>
</contexts>
<marker>Walton, Krabbe, 1995</marker>
<rawString>D. Walton and E. Krabbe. 1995. Commitment in dialogue: Basic concepts of interpersonal reasoning. State University of New York Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>