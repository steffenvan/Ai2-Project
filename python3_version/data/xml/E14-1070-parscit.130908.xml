<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000018">
<title confidence="0.996557">
Encoding Semantic Resources in Syntactic Structures
for Passage Reranking
</title>
<note confidence="0.322057666666667">
Kateryna Tymoshenko
Trento RISE
38123 Povo (TN), Italy
</note>
<email confidence="0.9779">
k.tymoshenko@trentorise.eu
</email>
<author confidence="0.990386">
Alessandro Moschitti
</author>
<affiliation confidence="0.989103">
Qatar Computing Research Instit.
</affiliation>
<address confidence="0.630956">
5825 Doha, Qatar
</address>
<email confidence="0.995241">
amoschitti@qf.org.qa
</email>
<author confidence="0.990149">
Aliaksei Severyn
</author>
<affiliation confidence="0.997718">
University of Trento
</affiliation>
<address confidence="0.69832">
38123 Povo (TN), Italy
</address>
<email confidence="0.99688">
severyn@disi.unitn.it
</email>
<sectionHeader confidence="0.993851" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99985605882353">
In this paper, we propose to use seman-
tic knowledge from Wikipedia and large-
scale structured knowledge datasets avail-
able as Linked Open Data (LOD) for
the answer passage reranking task. We
represent question and candidate answer
passages with pairs of shallow syntac-
tic/semantic trees, whose constituents are
connected using LOD. The trees are pro-
cessed by SVMs and tree kernels, which
can automatically exploit tree fragments.
The experiments with our SVM rank algo-
rithm on the TREC Question Answering
(QA) corpus show that the added relational
information highly improves over the state
of the art, e.g., about 15.4% of relative im-
provement in P@1.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999468428571429">
Past work in TREC QA, e.g. (Voorhees, 2001),
and more recent work (Ferrucci et al., 2010) in
QA has shown that, to achieve human perfor-
mance, semantic resources, e.g., Wikipedia1,
must be utilized by QA systems. This requires
the design of rules or machine learning features
that exploit such knowledge by also satisfying
syntactic constraints, e.g., the semantic type of
the answer must match the question focus words.
The engineering of such rules for open domain
QA is typically very costly. For instance, for
automatically deriving the correctness of the
answer passage in the following question/answer
passage (Q/AP) pair (from the TREC corpus2):
</bodyText>
<note confidence="0.434601">
Q: What company owns the soft drink brand “Gatorade”?
</note>
<footnote confidence="0.732713636363636">
A: Stokely-Van Camp bought the formula and started
marketing the drink as Gatorade in 1967. Quaker Oats Co.
took over Stokely-Van Camp in 1983.
1http://www.wikipedia.org
2It will be our a running example for the rest of the paper.
we would need to write the following complex
rules:
is(Quaker Oats Co.,company),
own(Stokely-Van Camp,Gatorade),
took over(Quaker Oats Co.,Stokely-Van Camp),
took over(Y, Z)→own(Z,Y),
</footnote>
<bodyText confidence="0.999870352941176">
and carry out logic unification and resolution.
Therefore, approaches that can automatically
generate patterns (i.e., features) from syntactic
and semantic representations of the Q/AP are
needed. In this respect, our previous work, e.g.,
(Moschitti et al., 2007; Moschitti and Quarteroni,
2008; Moschitti, 2009), has shown that tree
kernels for NLP, e.g., (Moschitti, 2006), can
exploit syntactic patterns for answer passage
reranking significantly improving search engine
baselines. Our more recent work, (Severyn and
Moschitti, 2012; Severyn et al., 2013b; Severyn
et al., 2013a), has shown that using automatically
produced semantic labels in shallow syntactic
trees, such as question category and question
focus, can further improve passage reranking and
answer extraction (Severyn and Moschitti, 2013).
However, such methods cannot solve the class
of examples above as they do not use background
knowledge, which is essential to answer com-
plex questions. On the other hand, Kalyanpur
et al. (2011) and Murdock et al. (2012) showed
that semantic match features extracted from large-
scale background knowledge sources, including
the LOD ones, are beneficial for answer rerank-
ing.
In this paper, we tackle the candidate answer
passage reranking task. We define kernel func-
tions that can automatically learn structural pat-
terns enriched by semantic knowledge, e.g., from
LOD. For this purpose, we carry out the follow-
ing steps: first, we design a representation for the
Q/AP pair by engineering a pair of shallow syn-
tactic trees connected with relational nodes (i.e.,
</bodyText>
<page confidence="0.973815">
664
</page>
<note confidence="0.996111">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 664–672,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999823">
Figure 1: Kernel-based Answer Passage Reranking System
</figureCaption>
<bodyText confidence="0.999897947368421">
those matching the same words in the question and
in the answer passages).
Secondly, we use YAGO (Suchanek et al.,
2007), DBpedia (Bizer et al., 2009) and Word-
Net (Fellbaum, 1998) to match constituents from
Q/AP pairs and use their generalizations in our
syntactic/semantic structures. We employ word
sense disambiguation to match the right entities in
YAGO and DBpedia, and consider all senses of an
ambiguous word from WordNet.
Finally, we experiment with TREC QA and sev-
eral models combining traditional feature vectors
with automatic semantic labels derived by statis-
tical classifiers and relational structures enriched
with LOD relations. The results show that our
methods greatly improve over strong IR baseline,
e.g., BM25, by 96%, and on our previous state-
of-the-art reranking models, up to 15.4% (relative
improvement) in P@1.
</bodyText>
<sectionHeader confidence="0.681393" genericHeader="method">
2 Reranking with Tree Kernels
</sectionHeader>
<bodyText confidence="0.999855944444444">
In contrast to ad-hoc document retrieval, struc-
tured representation of sentences and paragraphs
helps to improve question answering (Bilotti et al.,
2010). Typically, rules considering syntactic and
semantic properties of the question and its candi-
date answer are handcrafted. Their modeling is in
general time-consuming and costly. In contrast,
we rely on machine learning and automatic fea-
ture engineering with tree kernels. We used our
state-of-the-art reranking models, i.e., (Severyn et
al., 2013b; Severyn et al., 2013a) as a baseline.
Our major difference with such approach is that
we encode knowledge and semantics in different
ways, using knowledge from LOD. The next sec-
tions outline our new kernel-based framework, al-
though the detailed descriptions of the most inno-
vative aspects such as new LOD-based representa-
tions are reported in Section 3.
</bodyText>
<subsectionHeader confidence="0.995014">
2.1 Framework Overview
</subsectionHeader>
<bodyText confidence="0.999961171428572">
Our QA system is based on a rather simple rerank-
ing framework as displayed in Figure 1: given a
question Q, a search engine retrieves a list of can-
didate APs ranked by their relevancy. Next, the
question together with its APs are processed by
a rich NLP pipeline, which performs basic tok-
enization, sentence splitting, lemmatization, stop-
word removal. Various NLP components, em-
bedded in the pipeline as UIMA3 annotators, per-
form more involved linguistic analysis, e.g., POS-
tagging, chunking, NE recognition, constituency
and dependency parsing, etc.
Each Q/AP pair is processed by a Wikipedia
link annotator. It automatically recognizes n-
grams in plain text, which may be linked to
Wikipedia and disambiguates them to Wikipedia
URLs. Given that question passages are typically
short, we concatenate them with the candidate an-
swers to provide a larger disambiguation context
to the annotator.
These annotations are then used to produce
computational structures (see Sec. 2.2) input to the
reranker. The semantics of such relational struc-
tures can be further enriched by adding links be-
tween Q/AP constituents. Such relational links
can be also generated by: (i) matching lemmas
as in (Severyn and Moschitti, 2012); (ii) match-
ing the question focus type derived by the ques-
tion classifiers with the type of the target NE as
in (Severyn et al., 2013a); or (iii) by matching the
constituent types based on LOD (proposed in this
paper). The resulting pairs of trees connected by
semantic links are then used to train a kernel-based
reranker, which is used to re-order the retrieved
answer passages.
</bodyText>
<subsectionHeader confidence="0.996532">
2.2 Relational Q/AP structures
</subsectionHeader>
<bodyText confidence="0.999755">
We use the shallow tree representation that we
proposed in (Severyn and Moschitti, 2012) as a
baseline structural model. More in detail, each Q
and its candidate AP are encoded into two trees,
where lemmas constitute the leaf level, the part-
of-speech (POS) tags are at the pre-terminal level
and the sequences of POS tags are organized into
the third level of chunk nodes. We encoded struc-
tural relations using the REL tag, which links the
related structures in Q/AP, when there is a match
</bodyText>
<footnote confidence="0.645529">
3http://uima.apache.org/
</footnote>
<figure confidence="0.998918761904762">
Focus and
Focus and
Question classifers
Question classifier
Wikipedia link
Wikipedia lin
annotator
annotato
Wikipedia
Wikipedi
NLP
NLP
Annotators
Annotator
Question
UIMA pipeline
Search engine
Search engn
Candidate
AP
syntactic/semantic
syntactic/semanti
graph
graph
LOD type annotator
LOD type annotato
LOD datasets
LOD dataset
q/a similarity
q/a similarit
features
features
Kernel-based
Kernelbase
reranker
reranke
Reranked
AP
train/test
data
Evaluation
Evaluatio
</figure>
<page confidence="0.881925">
665
</page>
<figureCaption confidence="0.998048">
Figure 2: Basic structural representations using a shallow chunk tree structure for the Q/AP in the running example. Curved
line indicates the tree fragments in the question and its answer passage linked by the relational REL tag.
</figureCaption>
<bodyText confidence="0.976676717391304">
between the lemmas in Q and AP. We marked the
parent (POS tags) and grand parent (chunk) nodes
of such lemmas by prepending a REL tag.
However, more general semantic relations, e.g.,
derived from the question focus and category, can
be encoded using the REL-FOCUS-&lt;QC&gt; tag,
where &lt;QC&gt; stands for the question class. In
(Severyn et al., 2013b; Severyn et al., 2013a), we
used statistical classifiers to derive question focus
and categories of the question and of the named
entities in the AP. We again mark (i) the focus
chunk in the question and (ii) the AP chunks con-
taining named entities of type compatible with the
question class, by prepending the above tags to
their labels. The compatibility between the cat-
egories of named entities and questions is evalu-
ated with a lookup to a manually predefined map-
ping (see Table 1 in (Severyn et al., 2013b)). We
also prune the trees by removing the nodes beyond
a certain distance (in terms of chunk nodes) from
the REL and REL-FOCUS nodes. This removes
irrelevant information and speeds up learning and
classification. We showed that such model outper-
forms bag-of-words and POS-tag sequence mod-
els (Severyn et al., 2013a).
An example of a Q/AP pair encoded using shal-
low chunk trees is given in Figure 2. Here, for ex-
ample, the lemma “drink” occurs in both Q and AP
(we highlighted it with a solid line box in the fig-
ure). “Company” was correctly recognized as a fo-
cus4, however it was misclassified as “HUMAN”
(“HUM”). As no entities of the matching type
“PERSON” were found in the answer by a NER
system, no chunks were marked as REL-FOCUS
on the answer passage side.
We slightly modify the REL-FOCUS encod-
ing into the tree. Instead of prepending REL-
FOCUS-&lt;QC&gt;, we only prepend REL-FOCUS
to the target chunk node, and add a new node
QC as the rightmost child of the chunk node, e.g,
in Figure 2, the focus node would be marked as
REL-FOCUS and the sequence of its children
would be [WP NN HUM]. This modification in-
4We used the same approach to focus detection and ques-
tion classification used in (Severyn et al., 2013b)
tends to reduce the feature sparsity.
</bodyText>
<sectionHeader confidence="0.998394" genericHeader="method">
3 LOD for Semantic Structures
</sectionHeader>
<bodyText confidence="0.999983642857143">
We aim at exploiting semantic resources for build-
ing more powerful rerankers. More specifically,
we use structured knowledge about properties of
the objects referred to in a Q/AP pair. A large
amount of knowledge has been made available as
LOD datasets, which can be used for finding addi-
tional semantic links between Q/AP passages.
In the next sections, we (i) formally define novel
semantic links between Q/AP structures that we
introduce in this paper; (ii) provide basic notions
of Linked Open Data along with three of its most
widely used datasets, YAGO, DBpedia and Word-
Net; and, finally, (iii) describe our algorithm to
generate linked Q/AP structures.
</bodyText>
<subsectionHeader confidence="0.993952">
3.1 Matching Q/AP Structures: Type Match
</subsectionHeader>
<bodyText confidence="0.9993228">
We look for token sequences (e.g., complex nomi-
nal groups) in Q/AP pairs that refer to entities and
entity classes related by isa (Eq. 1) and isSubclas-
sOf (Eq. 2) relations and then link them in the
structural Q/AP representations.
</bodyText>
<equation confidence="0.9998385">
isa : entity x class → {true, false} (1)
isSubclassOf : class x class → {true, false} (2)
</equation>
<bodyText confidence="0.999669684210526">
Here, entities are all the objects in the world
both real or abstract, while classes are sets of en-
tities that share some common features. Informa-
tion about entities, classes and their relations can
be obtained from the external knowledge sources
such as the LOD resources. isa returns true if an
entity is an element of a class (false otherwise),
while isSubclassOf(class1,class2) returns true if
all elements of class1 belong also to class2.
We refer to the token sequences introduced
above as to anchors and the entities/classes they
refer to as references. We define anchors to be in
a Type Match (TM) relation if the entities/classes
they refer to are in isa or isSubclassOf relation.
More formally, given two anchors a1 and a2 be-
longing to two text passages, p1 and p2, respec-
tively, and given an R(a, p) function, which re-
turns a reference of an anchor a in passage p, we
define TM (r1, r2) as
</bodyText>
<page confidence="0.889544">
666
</page>
<equation confidence="0.917211">
isa (r1, r2) : if isEntity (r1) n isClass (r2) 3)
subClassO f (r1, r2) : if isClass (r1) n isClass (r2)(
</equation>
<bodyText confidence="0.999535833333333">
where r1 = R(a1, p1), r2 = R(a2, p2) and isEn-
tity(r) and isClass(r) return true if r is an entity or
a class, respectively, and false otherwise. It should
be noted that, due to the ambiguity of natural lan-
guage, the same anchor may have different refer-
ences depending on the context.
</bodyText>
<subsectionHeader confidence="0.985517">
3.2 LOD for linking Q/A structures
</subsectionHeader>
<bodyText confidence="0.999964304347826">
LOD consists of datasets published online accord-
ing to the Linked Data (LD) principles5 and avail-
able in open access. LOD knowledge is repre-
sented following the Resource Description Frame-
work (RDF)6 specification as a set of statements.
A statement is a subject-predicate-object triple,
where predicate denotes the directed relation, e.g.,
hasSurname or owns, between subject and object.
Each object described by RDF, e.g., a class or
an entity, is called a resource and is assigned a
Unique Resource Identifier (URI).
LOD includes a number of common schemas,
i.e., sets of classes and predicates to be reused
when describing knowledge. For example, one
of them is RDF Schema (RDFS)7, which contains
predicates rdf:type and rdfs:SubClassOf
similar to the isa and subClassOf functions above.
LOD contains a number of large-scale cross-
domain datasets, e.g., YAGO (Suchanek et al.,
2007) and DBpedia (Bizer et al., 2009). Datasets
created before the emergence of LD, e.g., Word-
Net, are brought into correspondence with the LD
principles and added to the LOD as well.
</bodyText>
<sectionHeader confidence="0.637611" genericHeader="method">
3.2.1 Algorithm for detecting TM
</sectionHeader>
<bodyText confidence="0.999923923076923">
Algorithm 1 detects n-grams in the Q/AP struc-
tures that are in TM relation and encodes TM
knowledge in the shallow chunk tree representa-
tions of Q/AP pairs. It takes two text passages, P1
and P2, and a LOD knowledge source, LODKS,
as input. We run the algorithm twice, first with
AP as P1 and Q as P2 and then vice versa. For
example, P1 and P2 in the first run could be, ac-
cording to our running example, Q and AP candi-
date, respectively, and LODKS could be YAGO,
DBpedia or WordNet.
Detecting anchors. getAnchors(P2,LODKS)
in line 1 of Algorithm 1 returns all anchors in the
</bodyText>
<footnote confidence="0.999792">
5http://www.w3.org/DesignIssues/
LinkedData.html
6http://www.w3.org/TR/rdf-concepts/
7http://www.w3.org/TR/rdf-schema/
</footnote>
<construct confidence="0.525029">
Algorithm 1 Type Match algorithm
</construct>
<bodyText confidence="0.4732855">
Input: P1, P2 - text passages; LODKS - LOD knowledge
source.
</bodyText>
<listItem confidence="0.937309428571429">
1: for all anchor E getAnchors(P2,LODKS) do
2: for all uri E getURIs(anchor,P2,LODKS) do
3: for all type E getTypes(uri,LODKS) do
4: for all ch E getChunks(P1) do
5: matchedTokens +— checkMatch(ch,
type.labels)
6: if matchedTokens =� 0 then
</listItem>
<equation confidence="0.622791666666667">
7: markAsTM(anchor,P2.parseTree)
8: markAsTM(matchedTokens,
P1.parseTree)
</equation>
<bodyText confidence="0.999882657894737">
given text passage, P2. Depending on LODKS
one may have various implementations of this pro-
cedure. For example, when LODKS is Word-
Net, getAnchor returns token subsequences of the
chunks in P2 of lengths n-k, where n is the number
of tokens in the chunk and k = [1, .., n − 1).
In case when LODKS is YAGO or DBpedia,
we benefit from the fact that both YAGO and DB-
pedia are aligned with Wikipedia on entity level by
construction and we can use the so-called wikifica-
tion tools, e.g., (Milne and Witten, 2009), to detect
the anchors. The wikification tools recognize n-
grams that may denote Wikipedia pages in plain
text and disambiguate them to obtain a unique
Wikipedia page. Such tools determine whether
a certain n-gram may denote a Wikipedia page(s)
by looking it up in a precomputed vocabulary cre-
ated using Wikipedia page titles and internal link
network (Csomai and Mihalcea, 2008; Milne and
Witten, 2009).
Obtaining references. In line 2 of Algorithm 1
for each anchor, we determine the URIs of enti-
ties/classes it refers to in LODKS. Here again,
we have different strategies for different LODKS.
In case of WordNet, we use the all-senses strat-
egy, i.e., getURI procedure returns a set of URIs
of synsets that contain the anchor lemma.
In case when LODKS is YAGO or DBpedia,
we use wikification tools to correctly disambiguate
an anchor to a Wikipedia page. Then, Wikipedia
page URLs may be converted to DBpedia URIs by
substituting the en.wikipedia.org/wiki/
prefix to the dbpedia.org/resource/; and
YAGO URIs by querying it for subjects of the
RDF triples with yago:hasWikipediaUrl8
as a predicate and Wikipedia URL as an object.
For instance, one of the anchors detected in
the running example AP would be “Quaker oats”,
</bodyText>
<footnote confidence="0.9892865">
8yago: is a shorthand for the http prefix http://
yago-knowledge.org/resource/
</footnote>
<page confidence="0.992445">
667
</page>
<bodyText confidence="0.998055632653061">
a wikification tool would map it to wiki:
Quaker_Oats_Company9, and the respective
YAGO URI would be yago:Quaker_Oats_
Company.
Obtaining type information. Given a uri, if it
is an entity, we look for all the classes it belongs
to, or if it is a class, we look for all classes for
which it is a subclass. This process is incorpo-
rated in the getTypes procedure in line 3 of Algo-
rithm 1. We call such classes types. If LODKS
is WordNet, then our types are simply the URIs of
the hypernyms of uri. If LODKS is DBpedia or
YAGO, we query these datasets for the values of
the rdf:type and rdfs:subClassOf prop-
erties of the uri (i.e., objects of the triples with uri
as subject and type/subClassOf as predicates) and
add their values (which are also URIs) to the types
set. Then, we recursively repeat the same queries
for each retrieved type URI and add their results to
the types. Finally, the getTypes procedure returns
the resulting types set.
The extracted URIs returned by getTypes are
HTTP ids, however, frequently they have human-
readable names, or labels, specified by the rdfs:
label property. If no label information for a
URI is available, we can create the label by re-
moving the technical information from the type
URI, e.g., http prefix and underscores. type.labels
denotes a set of type human-readable labels for
a specific type. For example, one of the types
extracted for yago:Quaker_Oats_Company
would have label ”company”.
Checking for TM. Further, the checkMatch
procedure checks whether any of the labels in the
type.labels matches any of the chunks in P1 re-
turned by getChunks, fully or partially (line 5 of
Algorithm 1). Here, getChunks procedure returns
a list of chunks recognized in P1 by an external
chunker.
More specifically, given a chunk, ch, and a type
label, type.label, checkMatch checks whether the
ch string matches10 type.label or its last word(s).
If no match is observed, we remove the first to-
ken from ch and repeat the procedure. We stop
when the match is observed or when no tokens
in ch are left. If the match is observed, check-
Match returns all the tokens remaining in ch as
matchedTokens. Otherwise, it returns an empty
set. For example, the question of the running ex-
</bodyText>
<footnote confidence="0.941624666666667">
9wiki: is a shorthand for the http prefix http://en.
wikipedia.org/wiki/
10case-insensitive exact string match
</footnote>
<bodyText confidence="0.998780483870968">
ample contains the chunk “what company”, which
partially matches the human readable “company”
label of one of the types retrieved for the “Quaker
oats” anchor from the answer. Our implemen-
tation of the checkMatch procedure would re-
turn “company” from the question as one of the
matchedTokens.
If the matchedTokens set is not empty,
this means that TM(R(anchor, P2), R(
matchedTokens, P1)) in Eq. 3 returns true.
Indeed, a1 is an anchor and a2 is the matched-
Tokens sequence (see Eq. 3), and their respective
references, i.e., URI assigned to the anchor and
URI of one of its types, are either in subClassOf
or in isa relation by construction. Naturally, this
is only one of the possible ways to evaluate the
TM function, and it may be noise-prone.
Marking TM in tree structures. Finally,
if the TM match is observed, i.e., matchedTo-
kens is not an empty set, we mark tree substruc-
tures corresponding to the anchor in the struc-
tural representation of P2 (P2.parseTree) and
those corresponding to matchedTokens in that of
P1 (P1.parseTree) as being in a TM relation. In
our running example, we would mark the substruc-
tures corresponding to ”Quaker oats” anchor in the
answer (our P2) and the “company” matchedTo-
ken in the question (our P1) shallow syntactic tree
representations. We can encode TM match infor-
mation into a tree in a variety of ways, which we
describe below.
</bodyText>
<subsectionHeader confidence="0.794704">
3.2.2 Encoding TM knowledge in the trees
</subsectionHeader>
<bodyText confidence="0.999941105263158">
a1 and a2 from Eq. 3 are n-grams, therefore they
correspond to the leaf nodes in the shallow syn-
tactic trees of p1 and p2. We denote the set of
their preterminal parents as NTM. We consid-
ered the following strategies of encoding TM re-
lation in the trees: (i) TM node (TMN). Add leaf
sibling tagged with TM to all the nodes in NTM.
(ii) Directed TM node (TMND). Add leaf sib-
ling tagged with TM-CHILD to all the nodes in
NTM corresponding to the anchor, and leaf sib-
lings tagged with TM-PARENT to the nodes cor-
responding to matchedTokens. (iii) Focus TM
(TMNF). Add leaf siblings to all the nodes in
NTM. If matchedTokens is a part of a question
focus label them as TM-FOCUS. Otherwise, la-
bel them as TM. (iv) Combo TMNDF. Encode
using the TMND strategy. If matchedTokens is a
part of a question focus label then also add a child
labeled FOCUS to each of the TM labels. Intu-
</bodyText>
<page confidence="0.996569">
668
</page>
<figureCaption confidence="0.9966985">
Figure 3: Fragments of a shallow chunk parse tree anno-
tated in TMND mode.
</figureCaption>
<bodyText confidence="0.999508333333333">
itively, T MND, T MNF, T MNDF are likely to re-
sult in more expressive patterns. Fig. 3 shows an
example of the T MND annotation.
</bodyText>
<subsectionHeader confidence="0.993694">
3.3 Wikipedia-based matching
</subsectionHeader>
<bodyText confidence="0.999934111111111">
Lemma matching for detecting REL may result in
low coverage, e.g., it is not able to match differ-
ent variants for the same name. We remedy this
by using Wikipedia link annotation. We consider
two word sequences (in Q and AP, respectively)
that are annotated with the same Wikipedia link
to be in a matching relation. Thus, we add new
REL tags to Q/AP structural representations as de-
scribed in Sec. 2.2.
</bodyText>
<sectionHeader confidence="0.999742" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999718">
We evaluated our different rerankers encoding sev-
eral semantic structures on passage retrieval task,
using a factoid open-domain TREC QA corpus.
</bodyText>
<subsectionHeader confidence="0.974523">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999505421052632">
TREC QA 2002/2003. In our experiments, we
opted for questions from years 2002 and 2003,
which totals to 824 factoid questions. The
AQUAINT corpus11 is used for searching the sup-
porting passages.
Pruning. Following (Severyn and Moschitti,
2012) we prune the shallow trees by removing the
nodes beyond distance of 2 from the REL, REL-
FOCUS or TM nodes.
LOD datasets. We used the core RDF distribu-
tion of YAGO212, WordNet 3.0 in RDF13, and the
datasets from the 3.9 DBpedia distribution14.
Feature Vectors. We used a subset of the sim-
ilarity functions between Q and AP described in
(Severyn et al., 2013b). These are used along
with the structural models. More explicitly: Term-
overlap features: i.e., a cosine similarity over
question/answer, simCOS(Q, AP), where the in-
put vectors are composed of lemma or POS-tag
</bodyText>
<footnote confidence="0.962425">
11http://catalog.ldc.upenn.edu/
LDC2002T31
12http://www.mpi-inf.mpg.de/yago-naga/
yago1_yago2/download/yago2/yago2core_
20120109.rdfs.7z
13http://semanticweb.cs.vu.nl/lod/wn30/
14http://dbpedia.org/Downloads39
</footnote>
<bodyText confidence="0.999934733333334">
n-grams with n = 1,.., 4. PTK score: i.e., out-
put of the Partial Tree Kernel (PTK), defined in
(Moschitti, 2006), when applied to the structural
representations of Q and AP, simPTK(Q, AP) =
PTK(Q, AP) (note that, this is computed within
a pair). PTK defines similarity in terms of the
number of substructures shared by two trees.
Search engine ranking score: the ranking score of
our search engine assigned to AP divided by a nor-
malizing factor.
SVM re-ranker. To train our models, we use
SVM-light-TK15, which enables the use of struc-
tural kernels (Moschitti, 2006) in SVM-light
(Joachims, 2002). We use default parameters and
the preference reranking model described in (Sev-
eryn and Moschitti, 2012; Severyn et al., 2013b).
We used PTK and the polynomial kernel of degree
3 on standard features.
Pipeline. We built the entire processing pipeline
on top of the UIMA framework.We included many
off-the-shelf NLP tools wrapping them as UIMA
annotators to perform sentence detection, tok-
enization, NE Recognition, parsing, chunking and
lemmatization. Moreover, we used annotators
for building new sentence representations starting
from tools’ annotations and classifiers for question
focus and question class.
Search engines. We adopted Terrier16 using the
accurate BM25 scoring model with default param-
eters. We trained it on the TREC corpus (3Gb),
containing about 1 million documents. We per-
formed indexing at the paragraph level by splitting
each document into a set of paragraphs, which are
then added to the search index. We retrieve a list of
50 candidate answer passages for each question.
Wikipedia link annotators. We use the
Wikipedia Miner (WM) (Milne and Witten,
2009)17 tool and the Machine Linking (ML)18
web-service to annotate Q/AP pairs with links to
Wikipedia. Both tools output annotation confi-
dence. We use all WM and ML annotations with
confidence exceeding 0.2 and 0.05, respectively.
We obtained these figures heuristically, they are
low because we aimed to maximize the Recall of
the Wikipedia link annotators in order to maxi-
</bodyText>
<footnote confidence="0.997650625">
15http://disi.unitn.it/moschitti/
Tree-Kernel.htm
16http://terrier.org
17http://sourceforge.net/projects/
wikipedia-miner/files/wikipedia-miner/
wikipedia-miner_1.1, we use only topic detector
module which detects and disambiguates anchors
18http://www.machinelinking.com/wp
</footnote>
<page confidence="0.991724">
669
</page>
<table confidence="0.999851">
System MRR MAP P@1
BM25 28.02±2.94 0.22±0.02 18.17±3.79
CH+V (CoNLL, 2013) 37.45 0.3 27.91
CH+V+QC+TFC 39.49 0.32 30
(CoNLL, 2013)
CH + V 36.82±2.68 0.30±0.02 26.34±2.17
CH + V+ QC+TFC 40.20±1.84 0.33±0.01 30.85±2.35
CH+V+QC+TFC* 40.50±2.32 0.33±0.02 31.46±2.42
</table>
<tableCaption confidence="0.99948">
Table 1: Baseline systems
</tableCaption>
<bodyText confidence="0.9991162">
mize the number of TMs. In all the experiments,
we used a union of the sets of the annotations pro-
vided by WM and ML.
Metrics. We used common QA metrics: Precision
at rank 1 (P@1), i.e., the percentage of questions
with a correct answer ranked at the first position,
and Mean Reciprocal Rank (MRR). We also report
the Mean Average Precision (MAP). We perform
5-fold cross-validation and report the metrics aver-
aged across all the folds together with the std.dev.
</bodyText>
<subsectionHeader confidence="0.994961">
4.2 Baseline Structural Reranking
</subsectionHeader>
<bodyText confidence="0.999893625">
In these experiments, we evaluated the accuracy
of the following baseline models: BM25 is the
BM25 scoring model, which also provides the ini-
tial ranking; CH+V is a combination of tree struc-
tures encoding Q/AP pairs using relational links
with the feature vector; and CH+V+QC+TFC is
CH+V extended with the semantic categorial links
introduced in (Severyn et al., 2013b).
Table 1 reports the performance of our base-
line systems. The lines marked with (CoNLL,
2013) contain the results we reported in (Sev-
eryn et al., 2013b). Lines four and five report
the performance of the same systems, i.e., CH+V
and CH+V+QC+TFC, after small improvement
and changes. Note that in our last version, we
have a different set of V features than in (CoNLL,
2013). Finally, CH+V+QC+TFC* refers to the
performance of CH+V+QC+TFC with question
type information of semantic REL-FOCUS links
represented as a distinct node (see Section 2.2).
The results show that this modification yields a
slight improvement over the baseline, thus, in
the next experiments, we add LOD knowledge to
CH+V+QC+TFC*.
</bodyText>
<subsectionHeader confidence="0.999524">
4.3 Impact of LOD in Semantic Structures
</subsectionHeader>
<bodyText confidence="0.999918084745763">
These experiments evaluated the accuracy of the
following models (described in the previous sec-
tions): (i) a system using Wikipedia to establish
the REL links; and (ii) systems which use LOD
knowledge to find type matches (TM).
The first header line of the Table 2 shows which
baseline system was enriched with the TM knowl-
edge. Type column reports the TM encoding strat-
egy employed (see Section 3.2.2). Dataset column
reports which knowledge source was employed to
find TM relations. Here, yago is YAGO2, db is
DBpedia, and wn is WordNet 3.0. The first re-
sult line in Table 2 reports the performance of
the strong CH+V and CH+V+QC+TFC* base-
line systems. Line with the “wiki” dataset re-
ports on CH+V and CH+V+QC+TFC* using
both Wikipedia link annotations provided by ML
and MW and hard lemma matching to find the re-
lated structures to be marked by REL (see Sec-
tion 3.3 for details of the Wikipedia-based REL
matching). The remainder of the systems is built
on top of the baselines using both hard lemma and
Wikipedia-based matching. We used bold font to
mark the top scores for each encoding strategy.
The tables show that all the systems ex-
ploiting LOD knowledge, excluding those us-
ing DBpedia only, outperform the strong CH+V
and CH+V+QC+TFC* baselines. Note that
CH+V enriched with TM tags performs com-
parably to, and in some cases even outper-
forms, CH+V+QC+TFC*. Compare, for exam-
ple, the outputs of CH+V+TMNDF using YAGO,
WordNet and DBpedia knowledge and those of
CH+V+QC+TFC* with no LOD knowledge.
Adding TM tags to the top-performing base-
line system, CH+V+QC+TFC*, typically re-
sults in further increase in performance. The
best-performing system in terms of MRR and
P@1 is CH+V+QC+TFC*+TMNF system us-
ing the combination of WordNet and YAGO2 as
source of TM knowledge and Wikipedia for REL-
matching. It outperforms the CH+V+QC+TFC*
baseline by 3.82% and 4.15% in terms of MRR
and P@1, respectively. Regarding MAP, a num-
ber of systems employing YAGO2 in combina-
tion with WordNet and Wikipedia-based REL-
matching obtain 0.37 MAP score thus outperform-
ing the CH+V+QC+TFC* baseline by 4%.
We used paired two-tailed t-test for evaluating
the statistical significance of the results reported in
Table 2. ‡ and † correspond to the significance lev-
els of 0.05 and 0.1, respectively. We compared (i)
the results in the wiki line to those in the none line;
and (ii) the results for the TM systems to those in
the wiki line.
The table shows that we typically obtain bet-
ter results when using YAGO2 and/or WordNet.
In our intuition this is due to the fact that these
resources are large-scale, have fine-grained class
</bodyText>
<page confidence="0.992585">
670
</page>
<table confidence="0.999923">
Type Dataset CH + V CH + V + QC + TFC*
MRR MAP P@1 MRR MAP P@1
- none 36.82±2.68 0.30±0.02 26.34±2.17 40.50±2.32 0.33±0.02 31.46±2.42
- wiki 39.17±1.29$ 0.31±0.01$ 28.66±1.43$ 41.33±1.17 0.34±0.01 31.46±1.40
TMN db 40.60±1.88 0.33±0.01$ 31.10±2.991 40.80±1.01 0.34±0.01 30.37±1.90
TMN wn 41.39±1.96$ 0.33±0.01$ 31.34±2.94 42.43±0.56 0.35±0.01 32.80±0.67
TMN wn+db 40.85±1.52$ 0.33±0.01$ 30.37±2.34 42.37±1.12 0.35±0.01 32.44±2.64
TMN yago 40.71±2.07 0.33±0.031 30.24±2.09$ 43.28±1.911 0.36±0.011 33.90±2.75
TMN yago+db 41.25±1.57$ 0.34±0.02$ 31.10±1.88$ 42.39±1.83 0.35±0.01 32.93±3.14
TMN yago+wn 42.01±2.26$ 0.34±0.02$ 32.07±3.04$ 43.98±1.08$ 0.36±0.01$ 35.24±1.46$
TMN yago+wn+db 41.52±1.85$ 0.34±0.02$ 30.98±2.71$ 43.13±1.38 0.36±0.01 33.66±2.77
TMNF db 40.67±1.941 0.33±0.01$ 30.85±2.221 41.43±0.70 0.35±0.01 31.22±1.09
TMNF wn 40.95±2.27$ 0.33±0.01$ 30.98±3.74 42.37±0.98 0.35±0.01 32.56±1.76
TMNF wn+db 40.84±2.181 0.34±0.01$ 30.73±3.04 43.08±0.831 0.36±0.011 33.54±1.291
TMNF yago 42.01±2.441 0.34±0.02$ 32.07±3.01$ 43.82±2.361 0.36±0.02$ 34.88±3.35
TMNF yago+db 41.32±1.701 0.34±0.02$ 31.10±2.48$ 43.19±1.171 0.36±0.011 33.90±1.86
TMNF yago+wn 41.69±1.66$ 0.34±0.02$ 31.10±2.44$ 44.32±0.70$ 0.36±0.01$ 35.61±1.11$
TMNF yago+wn+db 41.56±1.41$ 0.34±0.02$ 30.85±2.221 43.79±0.73$ 0.37±0.011 34.88±1.69$
TMND db 40.37±1.87 0.33±0.01$ 30.37±2.17 41.58±1.02 0.35±0.011 31.46±1.59
TMND wn 41.13±2.14$ 0.33±0.01$ 30.73±2.75 42.19±1.39 0.35±0.01 32.32±1.36
TMND wn+db 41.28±1.03$ 0.34±0.01$ 30.73±0.82$ 42.37±1.16 0.36±0.01 32.44±2.71
TMND yago 42.11±3.24$ 0.34±0.02$ 32.07±4.061 44.04±2.05$ 0.36±0.01$ 34.63±2.17$
TMND yago+db 42.28±2.01$ 0.35±0.01$ 32.44±1.99$ 43.77±2.021 0.37±0.011 34.27±2.42
TMND yago+wn 42.96±1.45$ 0.35±0.01$ 33.05±2.04$ 44.25±1.32$ 0.37±0.00$ 34.76±1.61$
TMND yago+wn+db 42.56±1.25$ 0.35±0.01$ 32.56±1.91$ 43.91±1.01$ 0.37±0.011 34.63±1.32$
TMNDF db 40.40±1.931 0.33±0.01$ 30.49±1.78$ 41.85±1.05 0.35±0.01$ 31.83±0.80
TMNDF wn 40.84±1.69$ 0.33±0.01$ 30.49±2.24 41.89±0.99 0.35±0.01 31.71±0.86
TMNDF wn+db 41.14±1.29$ 0.34±0.01$ 30.73±1.40$ 42.31±0.92 0.36±0.01 32.32±2.36
TMNDF yago 42.31±2.57$ 0.35±0.02$ 32.68±3.01$ 44.22±2.38$ 0.37±0.02$ 35.00±2.88$
TMNDF yago+db 41.96±1.82$ 0.35±0.01$ 32.32±2.24$ 43.82±1.95$ 0.37±0.01$ 34.51±2.391
TMNDF yago+wn 42.80±1.19$ 0.35±0.01$ 33.17±1.86$ 43.91±0.98$ 0.37±0.01$ 34.63±0.90$
TMNDF yago+wn+db 43.15±0.93$ 0.35±0.01$ 33.78±1.59$ 43.96±0.94$ 0.37±0.01$ 34.88±1.69$
</table>
<tableCaption confidence="0.99992">
Table 2: Results in 5-fold cross-validation on TREC QA corpus
</tableCaption>
<bodyText confidence="0.99982475">
taxonomy and contain many synonymous labels
per class/entity thus allowing us to have a good
coverage with TM-links. DBpedia ontology that
we employed in the db experiments is more shal-
low and contains fewer labels for classes, there-
fore the amount of discovered TM matches is
not always sufficient for increasing performance.
YAGO2 provides better coverage for TM relations
between entities and their classes, while Word-
Net contains more relations between classes19.
Note that in (Severyn and Moschitti, 2012), we
also used supersenses of WordNet (unsuccess-
fully) whereas here we use hypernymy relations
and a different technique to incorporate semantic
match into the tree structures.
Different TM-knowledge encoding strategies,
TMN, TMND, TMNF, TMNDF produce small
changes in accuracy. We believe, that the differ-
ence between them would become more signifi-
cant when experimenting with larger corpora.
</bodyText>
<sectionHeader confidence="0.999688" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.995031523809524">
This paper proposes syntactic structures whose
nodes are enriched with semantic information
from statistical classifiers and knowledge from
LOD. In particular, YAGO, DBpedia and Word-
Net are used to match and generalize constituents
from QA pairs: such matches are then used in
19We consider the WordNet synsets to be classes in the
scope of our experiments
syntactic/semantic structures. The experiments
with TREC QA and the above representations
also combined with traditional features greatly im-
prove over a strong IR baseline, e.g., 96% on
BM25, and on previous state-of-the-art rerank-
ing models, up to 15.4% (relative improvement)
in P@1. In particular, differently from previous
work, our models can effectively use semantic
knowledge in statistical learning to rank methods.
These promising results open interesting future
directions in designing novel semantic structures
and using innovative semantic representations in
learning algorithms.
</bodyText>
<sectionHeader confidence="0.998965" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999313625">
This research is partially supported by the EU’s 7th
Framework Program (FP7/2007-2013) (#288024
LIMOSINE project) and by a Shared University
Research award from the IBM Watson Research
Center - Yorktown Heights, USA and the IBM
Center for Advanced Studies of Trento, Italy. The
third author is supported by the Google Europe
Fellowship 2013 award in Machine Learning.
</bodyText>
<sectionHeader confidence="0.999587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9945255">
Matthew W. Bilotti, Jonathan L. Elsas, Jaime Car-
bonell, and Eric Nyberg. 2010. Rank learning
for factoid question answering with linguistic and
semantic constraints. In Proceedings of the 19th
</reference>
<page confidence="0.98832">
671
</page>
<reference confidence="0.994581933333334">
ACM international Conference on Information and
Knowledge Management (CIKM), pages 459–468.
Christian Bizer, Jens Lehmann, Georgi Kobilarov,
S¨oren Auer, Christian Becker, Richard Cyganiak,
and Sebastian Hellmann. 2009. Dbpedia - a crys-
tallization point for the web of data. Web Seman-
tics: Science, Services and Agents on the World Wide
Web, 7(3):154–165, September.
Andras Csomai and Rada Mihalcea. 2008. Linking
documents to encyclopedic knowledge. IEEE Intel-
ligent Systems, 23(5):34–41.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
David Ferrucci, Eric Brown, Jennifer Chu-Carroll,
James Fan, David Gondek, Aditya Kalyanpur, Adam
Lally, J. William Murdock, Eric Nyberg, John
Prager, Nico Schlaefer, and Chris Welty. 2010.
Building watson: An overview of the deepqa
project. AI Magazine, 31(3).
Thorsten Joachims. 2002. Optimizing search engines
using clickthrough data. In ACM SIGKDD Con-
ference on Knowledge Discovery and Data Mining
(KDD), pages 133–142. ACM.
Aditya Kalyanpur, J William Murdock, James Fan, and
Christopher Welty. 2011. Leveraging community-
built knowledge for type coercion in question an-
swering. In The Semantic Web–ISWC 2011, pages
144–156. Springer.
David Milne and Ian H Witten. 2009. An open-source
toolkit for mining wikipedia. In New Zealand Com-
puter Science Research Student Conference (NZC-
SRSC).
Alessandro Moschitti and Silvia Quarteroni. 2008.
Kernels on linguistic structures for answer extrac-
tion. In Proceedings of the 46th Annual Meet-
ing of the Association for Computational Linguis-
tics on Human Language Technologies: Short Pa-
pers (ACL), pages 113–116.
Alessandro Moschitti, Silvia Quarteroni, Roberto
Basili, and Suresh Manandhar. 2007. Exploiting
syntactic and shallow semantic kernels for ques-
tion/answer classification. In Proceedings of the
45th Annual Meeting of the Association of Compu-
tational Linguistics (ACL), pages 776–783.
Alessandro Moschitti. 2006. Efficient convolution
kernels for dependency and constituent syntactic
trees. In Proceedings of the 17th European Confer-
ence on Machine Learning (ECML), pages 318–329.
Springer.
Alessandro Moschitti. 2009. Syntactic and seman-
tic kernels for short text pair categorization. In
Proceedings of the 12th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL), pages 576–584. Association for
Computational Linguistics.
J William Murdock, Aditya Kalyanpur, Chris Welty,
James Fan, David A Ferrucci, DC Gondek, Lei
Zhang, and Hiroshi Kanayama. 2012. Typing can-
didate answers using type coercion. IBM Journal of
Research and Development, 56(3.4):7–1.
Aliaksei Severyn and Alessandro Moschitti. 2012.
Structural relationships for large-scale learning of
answer re-ranking. In Proceedings of the 35th in-
ternational ACM SIGIR conference on Research and
development in information retrieval (SIGIR), pages
741–750. ACM.
Aliaksei Severyn and Alessandro Moschitti. 2013. Au-
tomatic feature engineering for answer selection and
extraction. In Proceedings of the 2013 Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 458–467.
Aliaksei Severyn, Massimo Nicosia, and Alessandro
Moschitti. 2013a. Building structures from clas-
sifiers for passage reranking. In Proceedings of the
22nd ACM international conference on Conference
on information &amp; knowledge management (CIKM),
pages 969–978. ACM.
Aliaksei Severyn, Massimo Nicosia, and Alessandro
Moschitti. 2013b. Learning adaptable patterns for
passage reranking. In Proceedings of the Seven-
teenth Conference on Computational Natural Lan-
guage Learning (CoNLL).
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: a core of semantic knowl-
edge. In Proceedings of the 16th international con-
ference on World Wide Web (WWW), pages 697–706.
ACM Press.
Ellen M Voorhees. 2001. Overview of the TREC
2001 Question Answering Track. In Proceedings of
TREC, pages 42–51.
</reference>
<page confidence="0.998262">
672
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.199438">
<title confidence="0.9980975">Encoding Semantic Resources in Syntactic Structures for Passage Reranking</title>
<author confidence="0.642924">Kateryna</author>
<affiliation confidence="0.646871">Trento</affiliation>
<address confidence="0.999165">38123 Povo (TN), Italy</address>
<email confidence="0.996166">k.tymoshenko@trentorise.eu</email>
<author confidence="0.964696">Alessandro</author>
<affiliation confidence="0.999591">Qatar Computing Research</affiliation>
<address confidence="0.999922">5825 Doha, Qatar</address>
<email confidence="0.984642">amoschitti@qf.org.qa</email>
<author confidence="0.58743">Aliaksei</author>
<affiliation confidence="0.99965">University of</affiliation>
<address confidence="0.998462">38123 Povo (TN), Italy</address>
<email confidence="0.998698">severyn@disi.unitn.it</email>
<abstract confidence="0.981258666666667">In this paper, we propose to use semantic knowledge from Wikipedia and largescale structured knowledge datasets available as Linked Open Data (LOD) for the answer passage reranking task. We represent question and candidate answer passages with pairs of shallow syntactic/semantic trees, whose constituents are connected using LOD. The trees are processed by SVMs and tree kernels, which can automatically exploit tree fragments. The experiments with our SVM rank algorithm on the TREC Question Answering (QA) corpus show that the added relational information highly improves over the state of the art, e.g., about 15.4% of relative improvement in P@1.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Matthew W Bilotti</author>
<author>Jonathan L Elsas</author>
<author>Jaime Carbonell</author>
<author>Eric Nyberg</author>
</authors>
<title>Rank learning for factoid question answering with linguistic and semantic constraints.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>459--468</pages>
<contexts>
<context position="4986" citStr="Bilotti et al., 2010" startWordPosition="742" endWordPosition="745">n ambiguous word from WordNet. Finally, we experiment with TREC QA and several models combining traditional feature vectors with automatic semantic labels derived by statistical classifiers and relational structures enriched with LOD relations. The results show that our methods greatly improve over strong IR baseline, e.g., BM25, by 96%, and on our previous stateof-the-art reranking models, up to 15.4% (relative improvement) in P@1. 2 Reranking with Tree Kernels In contrast to ad-hoc document retrieval, structured representation of sentences and paragraphs helps to improve question answering (Bilotti et al., 2010). Typically, rules considering syntactic and semantic properties of the question and its candidate answer are handcrafted. Their modeling is in general time-consuming and costly. In contrast, we rely on machine learning and automatic feature engineering with tree kernels. We used our state-of-the-art reranking models, i.e., (Severyn et al., 2013b; Severyn et al., 2013a) as a baseline. Our major difference with such approach is that we encode knowledge and semantics in different ways, using knowledge from LOD. The next sections outline our new kernel-based framework, although the detailed descr</context>
</contexts>
<marker>Bilotti, Elsas, Carbonell, Nyberg, 2010</marker>
<rawString>Matthew W. Bilotti, Jonathan L. Elsas, Jaime Carbonell, and Eric Nyberg. 2010. Rank learning for factoid question answering with linguistic and semantic constraints. In Proceedings of the 19th ACM international Conference on Information and Knowledge Management (CIKM), pages 459–468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Bizer</author>
<author>Jens Lehmann</author>
<author>Georgi Kobilarov</author>
<author>S¨oren Auer</author>
<author>Christian Becker</author>
<author>Richard Cyganiak</author>
<author>Sebastian Hellmann</author>
</authors>
<title>Dbpedia - a crystallization point for the web of data. Web Semantics: Science, Services and Agents on the World Wide Web,</title>
<date>2009</date>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="4116" citStr="Bizer et al., 2009" startWordPosition="611" endWordPosition="614">m LOD. For this purpose, we carry out the following steps: first, we design a representation for the Q/AP pair by engineering a pair of shallow syntactic trees connected with relational nodes (i.e., 664 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 664–672, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 1: Kernel-based Answer Passage Reranking System those matching the same words in the question and in the answer passages). Secondly, we use YAGO (Suchanek et al., 2007), DBpedia (Bizer et al., 2009) and WordNet (Fellbaum, 1998) to match constituents from Q/AP pairs and use their generalizations in our syntactic/semantic structures. We employ word sense disambiguation to match the right entities in YAGO and DBpedia, and consider all senses of an ambiguous word from WordNet. Finally, we experiment with TREC QA and several models combining traditional feature vectors with automatic semantic labels derived by statistical classifiers and relational structures enriched with LOD relations. The results show that our methods greatly improve over strong IR baseline, e.g., BM25, by 96%, and on our </context>
<context position="13963" citStr="Bizer et al., 2009" startWordPosition="2232" endWordPosition="2235">cate denotes the directed relation, e.g., hasSurname or owns, between subject and object. Each object described by RDF, e.g., a class or an entity, is called a resource and is assigned a Unique Resource Identifier (URI). LOD includes a number of common schemas, i.e., sets of classes and predicates to be reused when describing knowledge. For example, one of them is RDF Schema (RDFS)7, which contains predicates rdf:type and rdfs:SubClassOf similar to the isa and subClassOf functions above. LOD contains a number of large-scale crossdomain datasets, e.g., YAGO (Suchanek et al., 2007) and DBpedia (Bizer et al., 2009). Datasets created before the emergence of LD, e.g., WordNet, are brought into correspondence with the LD principles and added to the LOD as well. 3.2.1 Algorithm for detecting TM Algorithm 1 detects n-grams in the Q/AP structures that are in TM relation and encodes TM knowledge in the shallow chunk tree representations of Q/AP pairs. It takes two text passages, P1 and P2, and a LOD knowledge source, LODKS, as input. We run the algorithm twice, first with AP as P1 and Q as P2 and then vice versa. For example, P1 and P2 in the first run could be, according to our running example, Q and AP candi</context>
</contexts>
<marker>Bizer, Lehmann, Kobilarov, Auer, Becker, Cyganiak, Hellmann, 2009</marker>
<rawString>Christian Bizer, Jens Lehmann, Georgi Kobilarov, S¨oren Auer, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. 2009. Dbpedia - a crystallization point for the web of data. Web Semantics: Science, Services and Agents on the World Wide Web, 7(3):154–165, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andras Csomai</author>
<author>Rada Mihalcea</author>
</authors>
<title>Linking documents to encyclopedic knowledge.</title>
<date>2008</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>23</volume>
<issue>5</issue>
<contexts>
<context position="16132" citStr="Csomai and Mihalcea, 2008" startWordPosition="2589" endWordPosition="2592">= [1, .., n − 1). In case when LODKS is YAGO or DBpedia, we benefit from the fact that both YAGO and DBpedia are aligned with Wikipedia on entity level by construction and we can use the so-called wikification tools, e.g., (Milne and Witten, 2009), to detect the anchors. The wikification tools recognize ngrams that may denote Wikipedia pages in plain text and disambiguate them to obtain a unique Wikipedia page. Such tools determine whether a certain n-gram may denote a Wikipedia page(s) by looking it up in a precomputed vocabulary created using Wikipedia page titles and internal link network (Csomai and Mihalcea, 2008; Milne and Witten, 2009). Obtaining references. In line 2 of Algorithm 1 for each anchor, we determine the URIs of entities/classes it refers to in LODKS. Here again, we have different strategies for different LODKS. In case of WordNet, we use the all-senses strategy, i.e., getURI procedure returns a set of URIs of synsets that contain the anchor lemma. In case when LODKS is YAGO or DBpedia, we use wikification tools to correctly disambiguate an anchor to a Wikipedia page. Then, Wikipedia page URLs may be converted to DBpedia URIs by substituting the en.wikipedia.org/wiki/ prefix to the dbped</context>
</contexts>
<marker>Csomai, Mihalcea, 2008</marker>
<rawString>Andras Csomai and Rada Mihalcea. 2008. Linking documents to encyclopedic knowledge. IEEE Intelligent Systems, 23(5):34–41.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Eric Brown</author>
<author>Jennifer Chu-Carroll</author>
<author>James Fan</author>
<author>David Gondek</author>
<author>Aditya Kalyanpur</author>
<author>Adam Lally</author>
<author>J William Murdock</author>
</authors>
<title>Eric Nyberg,</title>
<date>2010</date>
<journal>AI Magazine,</journal>
<volume>31</volume>
<issue>3</issue>
<location>John Prager, Nico</location>
<contexts>
<context position="1096" citStr="Ferrucci et al., 2010" startWordPosition="158" endWordPosition="161">en Data (LOD) for the answer passage reranking task. We represent question and candidate answer passages with pairs of shallow syntactic/semantic trees, whose constituents are connected using LOD. The trees are processed by SVMs and tree kernels, which can automatically exploit tree fragments. The experiments with our SVM rank algorithm on the TREC Question Answering (QA) corpus show that the added relational information highly improves over the state of the art, e.g., about 15.4% of relative improvement in P@1. 1 Introduction Past work in TREC QA, e.g. (Voorhees, 2001), and more recent work (Ferrucci et al., 2010) in QA has shown that, to achieve human performance, semantic resources, e.g., Wikipedia1, must be utilized by QA systems. This requires the design of rules or machine learning features that exploit such knowledge by also satisfying syntactic constraints, e.g., the semantic type of the answer must match the question focus words. The engineering of such rules for open domain QA is typically very costly. For instance, for automatically deriving the correctness of the answer passage in the following question/answer passage (Q/AP) pair (from the TREC corpus2): Q: What company owns the soft drink b</context>
</contexts>
<marker>Ferrucci, Brown, Chu-Carroll, Fan, Gondek, Kalyanpur, Lally, Murdock, 2010</marker>
<rawString>David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya Kalyanpur, Adam Lally, J. William Murdock, Eric Nyberg, John Prager, Nico Schlaefer, and Chris Welty. 2010. Building watson: An overview of the deepqa project. AI Magazine, 31(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD),</booktitle>
<pages>133--142</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="24098" citStr="Joachims, 2002" startWordPosition="3927" endWordPosition="3928">ia.org/Downloads39 n-grams with n = 1,.., 4. PTK score: i.e., output of the Partial Tree Kernel (PTK), defined in (Moschitti, 2006), when applied to the structural representations of Q and AP, simPTK(Q, AP) = PTK(Q, AP) (note that, this is computed within a pair). PTK defines similarity in terms of the number of substructures shared by two trees. Search engine ranking score: the ranking score of our search engine assigned to AP divided by a normalizing factor. SVM re-ranker. To train our models, we use SVM-light-TK15, which enables the use of structural kernels (Moschitti, 2006) in SVM-light (Joachims, 2002). We use default parameters and the preference reranking model described in (Severyn and Moschitti, 2012; Severyn et al., 2013b). We used PTK and the polynomial kernel of degree 3 on standard features. Pipeline. We built the entire processing pipeline on top of the UIMA framework.We included many off-the-shelf NLP tools wrapping them as UIMA annotators to perform sentence detection, tokenization, NE Recognition, parsing, chunking and lemmatization. Moreover, we used annotators for building new sentence representations starting from tools’ annotations and classifiers for question focus and ques</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 133–142. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aditya Kalyanpur</author>
<author>J William Murdock</author>
<author>James Fan</author>
<author>Christopher Welty</author>
</authors>
<title>Leveraging communitybuilt knowledge for type coercion in question answering.</title>
<date>2011</date>
<booktitle>In The Semantic Web–ISWC 2011,</booktitle>
<pages>144--156</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3130" citStr="Kalyanpur et al. (2011)" startWordPosition="460" endWordPosition="463">exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other hand, Kalyanpur et al. (2011) and Murdock et al. (2012) showed that semantic match features extracted from largescale background knowledge sources, including the LOD ones, are beneficial for answer reranking. In this paper, we tackle the candidate answer passage reranking task. We define kernel functions that can automatically learn structural patterns enriched by semantic knowledge, e.g., from LOD. For this purpose, we carry out the following steps: first, we design a representation for the Q/AP pair by engineering a pair of shallow syntactic trees connected with relational nodes (i.e., 664 Proceedings of the 14th Confer</context>
</contexts>
<marker>Kalyanpur, Murdock, Fan, Welty, 2011</marker>
<rawString>Aditya Kalyanpur, J William Murdock, James Fan, and Christopher Welty. 2011. Leveraging communitybuilt knowledge for type coercion in question answering. In The Semantic Web–ISWC 2011, pages 144–156. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>An open-source toolkit for mining wikipedia.</title>
<date>2009</date>
<booktitle>In New Zealand Computer Science Research Student Conference (NZCSRSC).</booktitle>
<contexts>
<context position="15754" citStr="Milne and Witten, 2009" startWordPosition="2528" endWordPosition="2531">type.labels) 6: if matchedTokens =� 0 then 7: markAsTM(anchor,P2.parseTree) 8: markAsTM(matchedTokens, P1.parseTree) given text passage, P2. Depending on LODKS one may have various implementations of this procedure. For example, when LODKS is WordNet, getAnchor returns token subsequences of the chunks in P2 of lengths n-k, where n is the number of tokens in the chunk and k = [1, .., n − 1). In case when LODKS is YAGO or DBpedia, we benefit from the fact that both YAGO and DBpedia are aligned with Wikipedia on entity level by construction and we can use the so-called wikification tools, e.g., (Milne and Witten, 2009), to detect the anchors. The wikification tools recognize ngrams that may denote Wikipedia pages in plain text and disambiguate them to obtain a unique Wikipedia page. Such tools determine whether a certain n-gram may denote a Wikipedia page(s) by looking it up in a precomputed vocabulary created using Wikipedia page titles and internal link network (Csomai and Mihalcea, 2008; Milne and Witten, 2009). Obtaining references. In line 2 of Algorithm 1 for each anchor, we determine the URIs of entities/classes it refers to in LODKS. Here again, we have different strategies for different LODKS. In c</context>
<context position="25181" citStr="Milne and Witten, 2009" startWordPosition="4092" endWordPosition="4095">r, we used annotators for building new sentence representations starting from tools’ annotations and classifiers for question focus and question class. Search engines. We adopted Terrier16 using the accurate BM25 scoring model with default parameters. We trained it on the TREC corpus (3Gb), containing about 1 million documents. We performed indexing at the paragraph level by splitting each document into a set of paragraphs, which are then added to the search index. We retrieve a list of 50 candidate answer passages for each question. Wikipedia link annotators. We use the Wikipedia Miner (WM) (Milne and Witten, 2009)17 tool and the Machine Linking (ML)18 web-service to annotate Q/AP pairs with links to Wikipedia. Both tools output annotation confidence. We use all WM and ML annotations with confidence exceeding 0.2 and 0.05, respectively. We obtained these figures heuristically, they are low because we aimed to maximize the Recall of the Wikipedia link annotators in order to maxi15http://disi.unitn.it/moschitti/ Tree-Kernel.htm 16http://terrier.org 17http://sourceforge.net/projects/ wikipedia-miner/files/wikipedia-miner/ wikipedia-miner_1.1, we use only topic detector module which detects and disambiguate</context>
</contexts>
<marker>Milne, Witten, 2009</marker>
<rawString>David Milne and Ian H Witten. 2009. An open-source toolkit for mining wikipedia. In New Zealand Computer Science Research Student Conference (NZCSRSC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
</authors>
<title>Kernels on linguistic structures for answer extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers (ACL),</booktitle>
<pages>113--116</pages>
<contexts>
<context position="2421" citStr="Moschitti and Quarteroni, 2008" startWordPosition="355" endWordPosition="358">rade in 1967. Quaker Oats Co. took over Stokely-Van Camp in 1983. 1http://www.wikipedia.org 2It will be our a running example for the rest of the paper. we would need to write the following complex rules: is(Quaker Oats Co.,company), own(Stokely-Van Camp,Gatorade), took over(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use bac</context>
</contexts>
<marker>Moschitti, Quarteroni, 2008</marker>
<rawString>Alessandro Moschitti and Silvia Quarteroni. 2008. Kernels on linguistic structures for answer extraction. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers (ACL), pages 113–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
<author>Silvia Quarteroni</author>
<author>Roberto Basili</author>
<author>Suresh Manandhar</author>
</authors>
<title>Exploiting syntactic and shallow semantic kernels for question/answer classification.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL),</booktitle>
<pages>776--783</pages>
<contexts>
<context position="2389" citStr="Moschitti et al., 2007" startWordPosition="351" endWordPosition="354">keting the drink as Gatorade in 1967. Quaker Oats Co. took over Stokely-Van Camp in 1983. 1http://www.wikipedia.org 2It will be our a running example for the rest of the paper. we would need to write the following complex rules: is(Quaker Oats Co.,company), own(Stokely-Van Camp,Gatorade), took over(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examp</context>
</contexts>
<marker>Moschitti, Quarteroni, Basili, Manandhar, 2007</marker>
<rawString>Alessandro Moschitti, Silvia Quarteroni, Roberto Basili, and Suresh Manandhar. 2007. Exploiting syntactic and shallow semantic kernels for question/answer classification. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics (ACL), pages 776–783.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In Proceedings of the 17th European Conference on Machine Learning (ECML),</booktitle>
<pages>318--329</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2501" citStr="Moschitti, 2006" startWordPosition="369" endWordPosition="370">t will be our a running example for the rest of the paper. we would need to write the following complex rules: is(Quaker Oats Co.,company), own(Stokely-Van Camp,Gatorade), took over(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other </context>
<context position="23614" citStr="Moschitti, 2006" startWordPosition="3847" endWordPosition="3848">et of the similarity functions between Q and AP described in (Severyn et al., 2013b). These are used along with the structural models. More explicitly: Termoverlap features: i.e., a cosine similarity over question/answer, simCOS(Q, AP), where the input vectors are composed of lemma or POS-tag 11http://catalog.ldc.upenn.edu/ LDC2002T31 12http://www.mpi-inf.mpg.de/yago-naga/ yago1_yago2/download/yago2/yago2core_ 20120109.rdfs.7z 13http://semanticweb.cs.vu.nl/lod/wn30/ 14http://dbpedia.org/Downloads39 n-grams with n = 1,.., 4. PTK score: i.e., output of the Partial Tree Kernel (PTK), defined in (Moschitti, 2006), when applied to the structural representations of Q and AP, simPTK(Q, AP) = PTK(Q, AP) (note that, this is computed within a pair). PTK defines similarity in terms of the number of substructures shared by two trees. Search engine ranking score: the ranking score of our search engine assigned to AP divided by a normalizing factor. SVM re-ranker. To train our models, we use SVM-light-TK15, which enables the use of structural kernels (Moschitti, 2006) in SVM-light (Joachims, 2002). We use default parameters and the preference reranking model described in (Severyn and Moschitti, 2012; Severyn et</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient convolution kernels for dependency and constituent syntactic trees. In Proceedings of the 17th European Conference on Machine Learning (ECML), pages 318–329. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Syntactic and semantic kernels for short text pair categorization.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>576--584</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2439" citStr="Moschitti, 2009" startWordPosition="359" endWordPosition="360">ok over Stokely-Van Camp in 1983. 1http://www.wikipedia.org 2It will be our a running example for the rest of the paper. we would need to write the following complex rules: is(Quaker Oats Co.,company), own(Stokely-Van Camp,Gatorade), took over(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge,</context>
</contexts>
<marker>Moschitti, 2009</marker>
<rawString>Alessandro Moschitti. 2009. Syntactic and semantic kernels for short text pair categorization. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL), pages 576–584. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J William Murdock</author>
<author>Aditya Kalyanpur</author>
<author>Chris Welty</author>
<author>James Fan</author>
<author>David A Ferrucci</author>
<author>DC Gondek</author>
<author>Lei Zhang</author>
<author>Hiroshi Kanayama</author>
</authors>
<title>Typing candidate answers using type coercion.</title>
<date>2012</date>
<journal>IBM Journal of Research and Development,</journal>
<pages>56--3</pages>
<contexts>
<context position="3156" citStr="Murdock et al. (2012)" startWordPosition="465" endWordPosition="468">or answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other hand, Kalyanpur et al. (2011) and Murdock et al. (2012) showed that semantic match features extracted from largescale background knowledge sources, including the LOD ones, are beneficial for answer reranking. In this paper, we tackle the candidate answer passage reranking task. We define kernel functions that can automatically learn structural patterns enriched by semantic knowledge, e.g., from LOD. For this purpose, we carry out the following steps: first, we design a representation for the Q/AP pair by engineering a pair of shallow syntactic trees connected with relational nodes (i.e., 664 Proceedings of the 14th Conference of the European Chapt</context>
</contexts>
<marker>Murdock, Kalyanpur, Welty, Fan, Ferrucci, Gondek, Zhang, Kanayama, 2012</marker>
<rawString>J William Murdock, Aditya Kalyanpur, Chris Welty, James Fan, David A Ferrucci, DC Gondek, Lei Zhang, and Hiroshi Kanayama. 2012. Typing candidate answers using type coercion. IBM Journal of Research and Development, 56(3.4):7–1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Structural relationships for large-scale learning of answer re-ranking.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval (SIGIR),</booktitle>
<pages>741--750</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2662" citStr="Severyn and Moschitti, 2012" startWordPosition="388" endWordPosition="391">y-Van Camp,Gatorade), took over(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other hand, Kalyanpur et al. (2011) and Murdock et al. (2012) showed that semantic match features extracted from largescale background knowledge sources, including the</context>
<context position="6926" citStr="Severyn and Moschitti, 2012" startWordPosition="1047" endWordPosition="1050">ikipedia link annotator. It automatically recognizes ngrams in plain text, which may be linked to Wikipedia and disambiguates them to Wikipedia URLs. Given that question passages are typically short, we concatenate them with the candidate answers to provide a larger disambiguation context to the annotator. These annotations are then used to produce computational structures (see Sec. 2.2) input to the reranker. The semantics of such relational structures can be further enriched by adding links between Q/AP constituents. Such relational links can be also generated by: (i) matching lemmas as in (Severyn and Moschitti, 2012); (ii) matching the question focus type derived by the question classifiers with the type of the target NE as in (Severyn et al., 2013a); or (iii) by matching the constituent types based on LOD (proposed in this paper). The resulting pairs of trees connected by semantic links are then used to train a kernel-based reranker, which is used to re-order the retrieved answer passages. 2.2 Relational Q/AP structures We use the shallow tree representation that we proposed in (Severyn and Moschitti, 2012) as a baseline structural model. More in detail, each Q and its candidate AP are encoded into two t</context>
<context position="22724" citStr="Severyn and Moschitti, 2012" startWordPosition="3720" endWordPosition="3723">sequences (in Q and AP, respectively) that are annotated with the same Wikipedia link to be in a matching relation. Thus, we add new REL tags to Q/AP structural representations as described in Sec. 2.2. 4 Experiments We evaluated our different rerankers encoding several semantic structures on passage retrieval task, using a factoid open-domain TREC QA corpus. 4.1 Experimental Setup TREC QA 2002/2003. In our experiments, we opted for questions from years 2002 and 2003, which totals to 824 factoid questions. The AQUAINT corpus11 is used for searching the supporting passages. Pruning. Following (Severyn and Moschitti, 2012) we prune the shallow trees by removing the nodes beyond distance of 2 from the REL, RELFOCUS or TM nodes. LOD datasets. We used the core RDF distribution of YAGO212, WordNet 3.0 in RDF13, and the datasets from the 3.9 DBpedia distribution14. Feature Vectors. We used a subset of the similarity functions between Q and AP described in (Severyn et al., 2013b). These are used along with the structural models. More explicitly: Termoverlap features: i.e., a cosine similarity over question/answer, simCOS(Q, AP), where the input vectors are composed of lemma or POS-tag 11http://catalog.ldc.upenn.edu/ </context>
<context position="24202" citStr="Severyn and Moschitti, 2012" startWordPosition="3940" endWordPosition="3944">nel (PTK), defined in (Moschitti, 2006), when applied to the structural representations of Q and AP, simPTK(Q, AP) = PTK(Q, AP) (note that, this is computed within a pair). PTK defines similarity in terms of the number of substructures shared by two trees. Search engine ranking score: the ranking score of our search engine assigned to AP divided by a normalizing factor. SVM re-ranker. To train our models, we use SVM-light-TK15, which enables the use of structural kernels (Moschitti, 2006) in SVM-light (Joachims, 2002). We use default parameters and the preference reranking model described in (Severyn and Moschitti, 2012; Severyn et al., 2013b). We used PTK and the polynomial kernel of degree 3 on standard features. Pipeline. We built the entire processing pipeline on top of the UIMA framework.We included many off-the-shelf NLP tools wrapping them as UIMA annotators to perform sentence detection, tokenization, NE Recognition, parsing, chunking and lemmatization. Moreover, we used annotators for building new sentence representations starting from tools’ annotations and classifiers for question focus and question class. Search engines. We adopted Terrier16 using the accurate BM25 scoring model with default para</context>
<context position="33350" citStr="Severyn and Moschitti, 2012" startWordPosition="5265" endWordPosition="5268">35±0.01$ 33.78±1.59$ 43.96±0.94$ 0.37±0.01$ 34.88±1.69$ Table 2: Results in 5-fold cross-validation on TREC QA corpus taxonomy and contain many synonymous labels per class/entity thus allowing us to have a good coverage with TM-links. DBpedia ontology that we employed in the db experiments is more shallow and contains fewer labels for classes, therefore the amount of discovered TM matches is not always sufficient for increasing performance. YAGO2 provides better coverage for TM relations between entities and their classes, while WordNet contains more relations between classes19. Note that in (Severyn and Moschitti, 2012), we also used supersenses of WordNet (unsuccessfully) whereas here we use hypernymy relations and a different technique to incorporate semantic match into the tree structures. Different TM-knowledge encoding strategies, TMN, TMND, TMNF, TMNDF produce small changes in accuracy. We believe, that the difference between them would become more significant when experimenting with larger corpora. 5 Conclusions This paper proposes syntactic structures whose nodes are enriched with semantic information from statistical classifiers and knowledge from LOD. In particular, YAGO, DBpedia and WordNet are us</context>
</contexts>
<marker>Severyn, Moschitti, 2012</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2012. Structural relationships for large-scale learning of answer re-ranking. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval (SIGIR), pages 741–750. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Automatic feature engineering for answer selection and extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>458--467</pages>
<contexts>
<context position="2934" citStr="Severyn and Moschitti, 2013" startWordPosition="427" endWordPosition="430"> Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other hand, Kalyanpur et al. (2011) and Murdock et al. (2012) showed that semantic match features extracted from largescale background knowledge sources, including the LOD ones, are beneficial for answer reranking. In this paper, we tackle the candidate answer passage reranking task. We define kernel functions that can automatically learn structural patterns enriched by semantic knowledge, e.g., from LOD. For this purpose, we carry out</context>
</contexts>
<marker>Severyn, Moschitti, 2013</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2013. Automatic feature engineering for answer selection and extraction. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 458–467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Massimo Nicosia</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Building structures from classifiers for passage reranking.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management (CIKM),</booktitle>
<pages>969--978</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2684" citStr="Severyn et al., 2013" startWordPosition="392" endWordPosition="395">er(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other hand, Kalyanpur et al. (2011) and Murdock et al. (2012) showed that semantic match features extracted from largescale background knowledge sources, including the LOD ones, are benefic</context>
<context position="5333" citStr="Severyn et al., 2013" startWordPosition="793" endWordPosition="796">ur previous stateof-the-art reranking models, up to 15.4% (relative improvement) in P@1. 2 Reranking with Tree Kernels In contrast to ad-hoc document retrieval, structured representation of sentences and paragraphs helps to improve question answering (Bilotti et al., 2010). Typically, rules considering syntactic and semantic properties of the question and its candidate answer are handcrafted. Their modeling is in general time-consuming and costly. In contrast, we rely on machine learning and automatic feature engineering with tree kernels. We used our state-of-the-art reranking models, i.e., (Severyn et al., 2013b; Severyn et al., 2013a) as a baseline. Our major difference with such approach is that we encode knowledge and semantics in different ways, using knowledge from LOD. The next sections outline our new kernel-based framework, although the detailed descriptions of the most innovative aspects such as new LOD-based representations are reported in Section 3. 2.1 Framework Overview Our QA system is based on a rather simple reranking framework as displayed in Figure 1: given a question Q, a search engine retrieves a list of candidate APs ranked by their relevancy. Next, the question together with it</context>
<context position="7060" citStr="Severyn et al., 2013" startWordPosition="1073" endWordPosition="1076">a URLs. Given that question passages are typically short, we concatenate them with the candidate answers to provide a larger disambiguation context to the annotator. These annotations are then used to produce computational structures (see Sec. 2.2) input to the reranker. The semantics of such relational structures can be further enriched by adding links between Q/AP constituents. Such relational links can be also generated by: (i) matching lemmas as in (Severyn and Moschitti, 2012); (ii) matching the question focus type derived by the question classifiers with the type of the target NE as in (Severyn et al., 2013a); or (iii) by matching the constituent types based on LOD (proposed in this paper). The resulting pairs of trees connected by semantic links are then used to train a kernel-based reranker, which is used to re-order the retrieved answer passages. 2.2 Relational Q/AP structures We use the shallow tree representation that we proposed in (Severyn and Moschitti, 2012) as a baseline structural model. More in detail, each Q and its candidate AP are encoded into two trees, where lemmas constitute the leaf level, the partof-speech (POS) tags are at the pre-terminal level and the sequences of POS tags</context>
<context position="8895" citStr="Severyn et al., 2013" startWordPosition="1358" endWordPosition="1361">nked AP train/test data Evaluation Evaluatio 665 Figure 2: Basic structural representations using a shallow chunk tree structure for the Q/AP in the running example. Curved line indicates the tree fragments in the question and its answer passage linked by the relational REL tag. between the lemmas in Q and AP. We marked the parent (POS tags) and grand parent (chunk) nodes of such lemmas by prepending a REL tag. However, more general semantic relations, e.g., derived from the question focus and category, can be encoded using the REL-FOCUS-&lt;QC&gt; tag, where &lt;QC&gt; stands for the question class. In (Severyn et al., 2013b; Severyn et al., 2013a), we used statistical classifiers to derive question focus and categories of the question and of the named entities in the AP. We again mark (i) the focus chunk in the question and (ii) the AP chunks containing named entities of type compatible with the question class, by prepending the above tags to their labels. The compatibility between the categories of named entities and questions is evaluated with a lookup to a manually predefined mapping (see Table 1 in (Severyn et al., 2013b)). We also prune the trees by removing the nodes beyond a certain distance (in terms of</context>
<context position="10623" citStr="Severyn et al., 2013" startWordPosition="1666" endWordPosition="1669">as “HUMAN” (“HUM”). As no entities of the matching type “PERSON” were found in the answer by a NER system, no chunks were marked as REL-FOCUS on the answer passage side. We slightly modify the REL-FOCUS encoding into the tree. Instead of prepending RELFOCUS-&lt;QC&gt;, we only prepend REL-FOCUS to the target chunk node, and add a new node QC as the rightmost child of the chunk node, e.g, in Figure 2, the focus node would be marked as REL-FOCUS and the sequence of its children would be [WP NN HUM]. This modification in4We used the same approach to focus detection and question classification used in (Severyn et al., 2013b) tends to reduce the feature sparsity. 3 LOD for Semantic Structures We aim at exploiting semantic resources for building more powerful rerankers. More specifically, we use structured knowledge about properties of the objects referred to in a Q/AP pair. A large amount of knowledge has been made available as LOD datasets, which can be used for finding additional semantic links between Q/AP passages. In the next sections, we (i) formally define novel semantic links between Q/AP structures that we introduce in this paper; (ii) provide basic notions of Linked Open Data along with three of its mo</context>
<context position="23080" citStr="Severyn et al., 2013" startWordPosition="3785" endWordPosition="3788">1 Experimental Setup TREC QA 2002/2003. In our experiments, we opted for questions from years 2002 and 2003, which totals to 824 factoid questions. The AQUAINT corpus11 is used for searching the supporting passages. Pruning. Following (Severyn and Moschitti, 2012) we prune the shallow trees by removing the nodes beyond distance of 2 from the REL, RELFOCUS or TM nodes. LOD datasets. We used the core RDF distribution of YAGO212, WordNet 3.0 in RDF13, and the datasets from the 3.9 DBpedia distribution14. Feature Vectors. We used a subset of the similarity functions between Q and AP described in (Severyn et al., 2013b). These are used along with the structural models. More explicitly: Termoverlap features: i.e., a cosine similarity over question/answer, simCOS(Q, AP), where the input vectors are composed of lemma or POS-tag 11http://catalog.ldc.upenn.edu/ LDC2002T31 12http://www.mpi-inf.mpg.de/yago-naga/ yago1_yago2/download/yago2/yago2core_ 20120109.rdfs.7z 13http://semanticweb.cs.vu.nl/lod/wn30/ 14http://dbpedia.org/Downloads39 n-grams with n = 1,.., 4. PTK score: i.e., output of the Partial Tree Kernel (PTK), defined in (Moschitti, 2006), when applied to the structural representations of Q and AP, simP</context>
<context position="26982" citStr="Severyn et al., 2013" startWordPosition="4355" endWordPosition="4358">at the first position, and Mean Reciprocal Rank (MRR). We also report the Mean Average Precision (MAP). We perform 5-fold cross-validation and report the metrics averaged across all the folds together with the std.dev. 4.2 Baseline Structural Reranking In these experiments, we evaluated the accuracy of the following baseline models: BM25 is the BM25 scoring model, which also provides the initial ranking; CH+V is a combination of tree structures encoding Q/AP pairs using relational links with the feature vector; and CH+V+QC+TFC is CH+V extended with the semantic categorial links introduced in (Severyn et al., 2013b). Table 1 reports the performance of our baseline systems. The lines marked with (CoNLL, 2013) contain the results we reported in (Severyn et al., 2013b). Lines four and five report the performance of the same systems, i.e., CH+V and CH+V+QC+TFC, after small improvement and changes. Note that in our last version, we have a different set of V features than in (CoNLL, 2013). Finally, CH+V+QC+TFC* refers to the performance of CH+V+QC+TFC with question type information of semantic REL-FOCUS links represented as a distinct node (see Section 2.2). The results show that this modification yields a s</context>
</contexts>
<marker>Severyn, Nicosia, Moschitti, 2013</marker>
<rawString>Aliaksei Severyn, Massimo Nicosia, and Alessandro Moschitti. 2013a. Building structures from classifiers for passage reranking. In Proceedings of the 22nd ACM international conference on Conference on information &amp; knowledge management (CIKM), pages 969–978. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Massimo Nicosia</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Learning adaptable patterns for passage reranking.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventeenth Conference on Computational Natural Language Learning (CoNLL).</booktitle>
<contexts>
<context position="2684" citStr="Severyn et al., 2013" startWordPosition="392" endWordPosition="395">er(Quaker Oats Co.,Stokely-Van Camp), took over(Y, Z)→own(Z,Y), and carry out logic unification and resolution. Therefore, approaches that can automatically generate patterns (i.e., features) from syntactic and semantic representations of the Q/AP are needed. In this respect, our previous work, e.g., (Moschitti et al., 2007; Moschitti and Quarteroni, 2008; Moschitti, 2009), has shown that tree kernels for NLP, e.g., (Moschitti, 2006), can exploit syntactic patterns for answer passage reranking significantly improving search engine baselines. Our more recent work, (Severyn and Moschitti, 2012; Severyn et al., 2013b; Severyn et al., 2013a), has shown that using automatically produced semantic labels in shallow syntactic trees, such as question category and question focus, can further improve passage reranking and answer extraction (Severyn and Moschitti, 2013). However, such methods cannot solve the class of examples above as they do not use background knowledge, which is essential to answer complex questions. On the other hand, Kalyanpur et al. (2011) and Murdock et al. (2012) showed that semantic match features extracted from largescale background knowledge sources, including the LOD ones, are benefic</context>
<context position="5333" citStr="Severyn et al., 2013" startWordPosition="793" endWordPosition="796">ur previous stateof-the-art reranking models, up to 15.4% (relative improvement) in P@1. 2 Reranking with Tree Kernels In contrast to ad-hoc document retrieval, structured representation of sentences and paragraphs helps to improve question answering (Bilotti et al., 2010). Typically, rules considering syntactic and semantic properties of the question and its candidate answer are handcrafted. Their modeling is in general time-consuming and costly. In contrast, we rely on machine learning and automatic feature engineering with tree kernels. We used our state-of-the-art reranking models, i.e., (Severyn et al., 2013b; Severyn et al., 2013a) as a baseline. Our major difference with such approach is that we encode knowledge and semantics in different ways, using knowledge from LOD. The next sections outline our new kernel-based framework, although the detailed descriptions of the most innovative aspects such as new LOD-based representations are reported in Section 3. 2.1 Framework Overview Our QA system is based on a rather simple reranking framework as displayed in Figure 1: given a question Q, a search engine retrieves a list of candidate APs ranked by their relevancy. Next, the question together with it</context>
<context position="7060" citStr="Severyn et al., 2013" startWordPosition="1073" endWordPosition="1076">a URLs. Given that question passages are typically short, we concatenate them with the candidate answers to provide a larger disambiguation context to the annotator. These annotations are then used to produce computational structures (see Sec. 2.2) input to the reranker. The semantics of such relational structures can be further enriched by adding links between Q/AP constituents. Such relational links can be also generated by: (i) matching lemmas as in (Severyn and Moschitti, 2012); (ii) matching the question focus type derived by the question classifiers with the type of the target NE as in (Severyn et al., 2013a); or (iii) by matching the constituent types based on LOD (proposed in this paper). The resulting pairs of trees connected by semantic links are then used to train a kernel-based reranker, which is used to re-order the retrieved answer passages. 2.2 Relational Q/AP structures We use the shallow tree representation that we proposed in (Severyn and Moschitti, 2012) as a baseline structural model. More in detail, each Q and its candidate AP are encoded into two trees, where lemmas constitute the leaf level, the partof-speech (POS) tags are at the pre-terminal level and the sequences of POS tags</context>
<context position="8895" citStr="Severyn et al., 2013" startWordPosition="1358" endWordPosition="1361">nked AP train/test data Evaluation Evaluatio 665 Figure 2: Basic structural representations using a shallow chunk tree structure for the Q/AP in the running example. Curved line indicates the tree fragments in the question and its answer passage linked by the relational REL tag. between the lemmas in Q and AP. We marked the parent (POS tags) and grand parent (chunk) nodes of such lemmas by prepending a REL tag. However, more general semantic relations, e.g., derived from the question focus and category, can be encoded using the REL-FOCUS-&lt;QC&gt; tag, where &lt;QC&gt; stands for the question class. In (Severyn et al., 2013b; Severyn et al., 2013a), we used statistical classifiers to derive question focus and categories of the question and of the named entities in the AP. We again mark (i) the focus chunk in the question and (ii) the AP chunks containing named entities of type compatible with the question class, by prepending the above tags to their labels. The compatibility between the categories of named entities and questions is evaluated with a lookup to a manually predefined mapping (see Table 1 in (Severyn et al., 2013b)). We also prune the trees by removing the nodes beyond a certain distance (in terms of</context>
<context position="10623" citStr="Severyn et al., 2013" startWordPosition="1666" endWordPosition="1669">as “HUMAN” (“HUM”). As no entities of the matching type “PERSON” were found in the answer by a NER system, no chunks were marked as REL-FOCUS on the answer passage side. We slightly modify the REL-FOCUS encoding into the tree. Instead of prepending RELFOCUS-&lt;QC&gt;, we only prepend REL-FOCUS to the target chunk node, and add a new node QC as the rightmost child of the chunk node, e.g, in Figure 2, the focus node would be marked as REL-FOCUS and the sequence of its children would be [WP NN HUM]. This modification in4We used the same approach to focus detection and question classification used in (Severyn et al., 2013b) tends to reduce the feature sparsity. 3 LOD for Semantic Structures We aim at exploiting semantic resources for building more powerful rerankers. More specifically, we use structured knowledge about properties of the objects referred to in a Q/AP pair. A large amount of knowledge has been made available as LOD datasets, which can be used for finding additional semantic links between Q/AP passages. In the next sections, we (i) formally define novel semantic links between Q/AP structures that we introduce in this paper; (ii) provide basic notions of Linked Open Data along with three of its mo</context>
<context position="23080" citStr="Severyn et al., 2013" startWordPosition="3785" endWordPosition="3788">1 Experimental Setup TREC QA 2002/2003. In our experiments, we opted for questions from years 2002 and 2003, which totals to 824 factoid questions. The AQUAINT corpus11 is used for searching the supporting passages. Pruning. Following (Severyn and Moschitti, 2012) we prune the shallow trees by removing the nodes beyond distance of 2 from the REL, RELFOCUS or TM nodes. LOD datasets. We used the core RDF distribution of YAGO212, WordNet 3.0 in RDF13, and the datasets from the 3.9 DBpedia distribution14. Feature Vectors. We used a subset of the similarity functions between Q and AP described in (Severyn et al., 2013b). These are used along with the structural models. More explicitly: Termoverlap features: i.e., a cosine similarity over question/answer, simCOS(Q, AP), where the input vectors are composed of lemma or POS-tag 11http://catalog.ldc.upenn.edu/ LDC2002T31 12http://www.mpi-inf.mpg.de/yago-naga/ yago1_yago2/download/yago2/yago2core_ 20120109.rdfs.7z 13http://semanticweb.cs.vu.nl/lod/wn30/ 14http://dbpedia.org/Downloads39 n-grams with n = 1,.., 4. PTK score: i.e., output of the Partial Tree Kernel (PTK), defined in (Moschitti, 2006), when applied to the structural representations of Q and AP, simP</context>
<context position="26982" citStr="Severyn et al., 2013" startWordPosition="4355" endWordPosition="4358">at the first position, and Mean Reciprocal Rank (MRR). We also report the Mean Average Precision (MAP). We perform 5-fold cross-validation and report the metrics averaged across all the folds together with the std.dev. 4.2 Baseline Structural Reranking In these experiments, we evaluated the accuracy of the following baseline models: BM25 is the BM25 scoring model, which also provides the initial ranking; CH+V is a combination of tree structures encoding Q/AP pairs using relational links with the feature vector; and CH+V+QC+TFC is CH+V extended with the semantic categorial links introduced in (Severyn et al., 2013b). Table 1 reports the performance of our baseline systems. The lines marked with (CoNLL, 2013) contain the results we reported in (Severyn et al., 2013b). Lines four and five report the performance of the same systems, i.e., CH+V and CH+V+QC+TFC, after small improvement and changes. Note that in our last version, we have a different set of V features than in (CoNLL, 2013). Finally, CH+V+QC+TFC* refers to the performance of CH+V+QC+TFC with question type information of semantic REL-FOCUS links represented as a distinct node (see Section 2.2). The results show that this modification yields a s</context>
</contexts>
<marker>Severyn, Nicosia, Moschitti, 2013</marker>
<rawString>Aliaksei Severyn, Massimo Nicosia, and Alessandro Moschitti. 2013b. Learning adaptable patterns for passage reranking. In Proceedings of the Seventeenth Conference on Computational Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a core of semantic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th international conference on World Wide Web (WWW),</booktitle>
<pages>697--706</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="4086" citStr="Suchanek et al., 2007" startWordPosition="606" endWordPosition="609"> by semantic knowledge, e.g., from LOD. For this purpose, we carry out the following steps: first, we design a representation for the Q/AP pair by engineering a pair of shallow syntactic trees connected with relational nodes (i.e., 664 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 664–672, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics Figure 1: Kernel-based Answer Passage Reranking System those matching the same words in the question and in the answer passages). Secondly, we use YAGO (Suchanek et al., 2007), DBpedia (Bizer et al., 2009) and WordNet (Fellbaum, 1998) to match constituents from Q/AP pairs and use their generalizations in our syntactic/semantic structures. We employ word sense disambiguation to match the right entities in YAGO and DBpedia, and consider all senses of an ambiguous word from WordNet. Finally, we experiment with TREC QA and several models combining traditional feature vectors with automatic semantic labels derived by statistical classifiers and relational structures enriched with LOD relations. The results show that our methods greatly improve over strong IR baseline, e</context>
<context position="13930" citStr="Suchanek et al., 2007" startWordPosition="2226" endWordPosition="2229">predicate-object triple, where predicate denotes the directed relation, e.g., hasSurname or owns, between subject and object. Each object described by RDF, e.g., a class or an entity, is called a resource and is assigned a Unique Resource Identifier (URI). LOD includes a number of common schemas, i.e., sets of classes and predicates to be reused when describing knowledge. For example, one of them is RDF Schema (RDFS)7, which contains predicates rdf:type and rdfs:SubClassOf similar to the isa and subClassOf functions above. LOD contains a number of large-scale crossdomain datasets, e.g., YAGO (Suchanek et al., 2007) and DBpedia (Bizer et al., 2009). Datasets created before the emergence of LD, e.g., WordNet, are brought into correspondence with the LD principles and added to the LOD as well. 3.2.1 Algorithm for detecting TM Algorithm 1 detects n-grams in the Q/AP structures that are in TM relation and encodes TM knowledge in the shallow chunk tree representations of Q/AP pairs. It takes two text passages, P1 and P2, and a LOD knowledge source, LODKS, as input. We run the algorithm twice, first with AP as P1 and Q as P2 and then vice versa. For example, P1 and P2 in the first run could be, according to ou</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of the 16th international conference on World Wide Web (WWW), pages 697–706. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Overview of the TREC</title>
<date>2001</date>
<booktitle>In Proceedings of TREC,</booktitle>
<pages>42--51</pages>
<contexts>
<context position="1050" citStr="Voorhees, 2001" startWordPosition="152" endWordPosition="153">owledge datasets available as Linked Open Data (LOD) for the answer passage reranking task. We represent question and candidate answer passages with pairs of shallow syntactic/semantic trees, whose constituents are connected using LOD. The trees are processed by SVMs and tree kernels, which can automatically exploit tree fragments. The experiments with our SVM rank algorithm on the TREC Question Answering (QA) corpus show that the added relational information highly improves over the state of the art, e.g., about 15.4% of relative improvement in P@1. 1 Introduction Past work in TREC QA, e.g. (Voorhees, 2001), and more recent work (Ferrucci et al., 2010) in QA has shown that, to achieve human performance, semantic resources, e.g., Wikipedia1, must be utilized by QA systems. This requires the design of rules or machine learning features that exploit such knowledge by also satisfying syntactic constraints, e.g., the semantic type of the answer must match the question focus words. The engineering of such rules for open domain QA is typically very costly. For instance, for automatically deriving the correctness of the answer passage in the following question/answer passage (Q/AP) pair (from the TREC c</context>
</contexts>
<marker>Voorhees, 2001</marker>
<rawString>Ellen M Voorhees. 2001. Overview of the TREC 2001 Question Answering Track. In Proceedings of TREC, pages 42–51.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>