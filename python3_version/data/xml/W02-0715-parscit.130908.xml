<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.807947666666667">
Proceedings of the Workshop on Speech-to-Speech Translation:
Algorithms and Systems, Philadelphia, July 2002, pp. 109-116.
Association for Computational Linguistics.
</note>
<title confidence="0.978041">
Quality-Sensitive Test Set Selection for a Speech Translation System
</title>
<author confidence="0.967313">
Fumiaki Sugaya1, Keiji Yasuda2, Toshiyuki Takezawa and Seiichi Yamamoto
</author>
<affiliation confidence="0.610228">
ATR Spoken Language Translation Research Laboratories
</affiliation>
<address confidence="0.783146">
2-2-2 Hikari-dai Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan
{fumiaki.sugaya, keiji.yasuda, toshiyuki.takezawa,
</address>
<email confidence="0.992369">
seiichi.yamamoto}@atr.co.jp
</email>
<sectionHeader confidence="0.998585" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9992798">
We propose a test set selection method to
sensitively evaluate the performance of a
speech translation system. The proposed
method chooses the most sensitive test
sentences by removing insensitive
sentences iteratively. Experiments are
conducted on the ATR-MATRIX speech
translation system, developed at ATR
Interpreting Telecommunications
Research Laboratories. The results show
the effectiveness of the proposed method.
According to the results, the proposed
method can reduce the test set size to less
than 40% of the original size while
improving evaluation reliability.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999854368421052">
The translation paired comparison method
precisely measures the capability of a speech
translation system. In this method, native speakers
compare a system’s translation and the translations,
made by examinees who have various TOEIC
scores. The method requires two human costs: the
data collection of examinees’ translations and the
comparison by native speakers. In this paper, we
propose a test set size reduction method that
reduces the number of test set utterances. The
method chooses the most sensitive test utterances
by removing the most insensitive utterances
iteratively.
In section 2, the translation paired comparison
method is described. Section 3 explains the
proposed method. In section 4, evaluation results
for ATR-MATRIX are shown. Section 5 discusses
the experimental results. In section 6, we state our
conclusions.
</bodyText>
<sectionHeader confidence="0.947473" genericHeader="method">
2 Translation paired comparison method
</sectionHeader>
<bodyText confidence="0.999814">
The translation paired comparison method
(Sugaya, 2000) is an effective evaluation method
for precisely measuring the capability of a speech
translation system. In this section, a description of
the method is given.
</bodyText>
<subsectionHeader confidence="0.7278715">
2.1 Methodology of the translation paired
comparison method
</subsectionHeader>
<bodyText confidence="0.999576388888889">
Figure 1 shows a diagram of the translation paired
comparison method in the case of Japanese to
English translation. The Japanese native-speaking
examinees are asked to listen to Japanese text and
provide an English translation on paper. The
Japanese text is spoken twice within one minute,
with a pause in-between. To measure the English
capability of the Japanese native speakers, the
TOEIC score is used. The examinees are requested
to present an official TOEIC score certificate
showing that they have taken the test within the
past six months. A questionnaire is given to them
and the results show that the answer time is
moderately difficult for the examinees.
The test text is the SLTA1 test set, which
consists of 330 utterances in 23 conversations from
a bilingual travel conversation database (Morimoto,
1994; Takezawa, 1999). The SLTA1 test set is
</bodyText>
<footnote confidence="0.989387">
1Current affiliation: KDDI R&amp;D Laboratories. Also at Graduate School of Science and Technology, Kobe University.
2Also at Graduate School of Engineering, Doshisha University.
</footnote>
<figure confidence="0.9931878">
Japanese Test
Text
Translation
Result by
Human
Accurate Text
Typing
Evaluation
Sheet
Paired Comparison
</figure>
<figureCaption confidence="0.999701">
Figure 1: Diagram of translation pair comparison method
</figureCaption>
<figure confidence="0.9966504">
Japanese-to-English
Language Translation
(J-E TDMT)
Japanese Recognition
(Japanese SPREC)
Choose A, B, C, or D rank
No
No
Yes
Same rank?
Yes
Consider naturalness
Same?
Select better result
EVEN
</figure>
<bodyText confidence="0.998810833333333">
information and grammar; (B) Fair: easy-to-
understand with some unimportant information
missing or flawed grammar; (C) Acceptable:
broken but understandable with effort; (D)
Nonsense: important information has been
translated incorrectly.
</bodyText>
<subsectionHeader confidence="0.922313">
2.2 Evaluation result using the translation
paired comparison method
</subsectionHeader>
<bodyText confidence="0.999887555555556">
Figure 3 shows the result of a comparison between
a language translation subsystem (TDMT) and the
examinees. The input for TDMT included accurate
transcriptions. The total number of examinees was
thirty, with five people having scores in every
hundred-point TOEIC range between the 300s and
800s. In Figure 3, the horizontal axis represents the
TOEIC score and the vertical axis the system
winning rate (SWR) given by following equation:
</bodyText>
<equation confidence="0.904074714285714">
+
0.5
SWR
× NEVEN
=
(1)
NTOTAL
</equation>
<figureCaption confidence="0.970308">
Figure 2: Procedure of comparison
by native speaker
</figureCaption>
<equation confidence="0.480132">
NTDmT
</equation>
<bodyText confidence="0.99768178125">
open for both speech recognition and language
translation. The answers written on paper are typed.
In the proposed method, the typed translations
made by the examinees and the outputs of the
system are merged into evaluation sheets and are
then compared by an evaluator who is a native
English speaker. Each utterance information is
shown on the evaluation sheets as the Japanese test
text and the two translation results, i.e., translations
by an examinee and by the system. The two
translations are presented in random order to
eliminate bias by the evaluator. The evaluator is
asked to follow the procedure illustrated in Figure
2. The four ranks in Figure 2 are the same as those
used in Sumita (1999). The ranks A, B, C, and D
indicate: (A) Perfect: no problems in both
where NTOTAL denotes the total number of
utterances in the test set, NTDmT represents the
number of &amp;quot;TDMT won&amp;quot; utterances, and NEVEN,
indicates the number of even (non-winner)
utterances, i.e., no difference between the results of
the TDMT and humans. The SWR ranges from 0
to 1.0, signifying the degree of capability of the
MT system relative to that of the examinee. An
SWR of 0.5 means that the TDMT has the same
capability as the human examinee.
Figure 3 shows that the SWR of TDMT is
greater than 0.5 at TOEIC scores of around 300
and 400, i.e., the TDMT system wins over humans
with TOEIC scores of 300 and 400. Examinees, in
contrast, win at scores of around 800. The
capability balanced area is around a score of 600 to
</bodyText>
<figure confidence="0.9984743">
;k#* 0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
300 400 500 600 700 800 900
TOEIC score
</figure>
<figureCaption confidence="0.8807205">
Figure 3: Evaluation results using translation
paired comparison method
</figureCaption>
<bodyText confidence="0.994282125">
700. To precisely determine the balanced point, we
used regression analysis. The straight line in Figure
3 is the regression line. The capability balanced
point between the TDMT subsystem and the
examinees is 0.5 of SWR. In Figure 3, the exact
point is a TOEIC score of 708. We call this point
the system&apos;s TOEIC score. Consequently, the
translation capability of the language translation
system equals that of the examinees at around a
score of 700 points on the TOEIC.
The experimental result for ATR-MATRIX,
which consists of a speech recognition subsystem
and TDMT, has been also reported (Sugaya, 2000).
This system’s TOEIC score is 548, where the
number of speech recognition errors is a factor in
the degradation of the score.
</bodyText>
<subsectionHeader confidence="0.851794">
2.3 Error in the system’s TOEIC score
</subsectionHeader>
<bodyText confidence="0.992122333333333">
The SWR (Yi) and TOEIC scores for the examinees
(Xi) are assumed to satisfy the population
regression equation:
</bodyText>
<equation confidence="0.999289">
Yi = β + β + ε ( 1 ,2 , . . .,
1 2 X i i i = n
</equation>
<bodyText confidence="0.991031428571429">
where β1 and β2 are population regression
coefficients. The error term ( εi ) is assumed to
satisfy the following condition:
Under the above condition, the stan
dard deviation
of the system&apos;s TOEIC score is calculated by
where n is the number of examinees,
is the
system&apos;s TOEIC score, and X is the average of
the examinees&apos; TOEIC scores. Equation (4)
indicates that the minimum error is given when the
system&apos;s TOEIC score equals the average of the
examinees&apos; TOEIC scores.
By using a t-distri
</bodyText>
<equation confidence="0.4355615">
C0
bution, the confidence
</equation>
<bodyText confidence="0.9756645">
interval (CI) of the system&apos;s TOEIC score with
confidence coefficient 1-α is given by
</bodyText>
<equation confidence="0.9844934">
[ C I C I
0 , 0
− + ]
−2) (5)
α .
</equation>
<bodyText confidence="0.9589076875">
2.4 Costs for the translation paired comparison
method
express a
performance as a TOEIC (Test
of English for International Communication)
score. However, this method has excessive
evaluation costs.
Roughly speaking, one of these costs is the need
to collect translations made by examinees of
various TOEIC scores. As shown in Equations (4)
an
system’s
d (5), n, the number of examinees, affects the
confidence interval of the system’s TOEIC score.
Therefore, a reduction in this number makes it
difficult to obtain a reliable evaluation result.
</bodyText>
<equation confidence="0.968198212121212">
2
1 + (C
∑ (Xi −X
β2
n
2
)
σt
(4)
) (2)
CI
α
I = ×
σ t n
( ;
t 2
(a) ε i 0
E ( )
(3)
(b) ( )
2
V ε i
ε ε
, ) ( , ) 0 if
=E ε ε = i j
≠
i j i j
(d) 0
ε ≅
i
σ
X)
0−
</equation>
<bodyText confidence="0.999944071428571">
In the current study, we employ 0.01 for the
value of
The translation paired comparison method is an
effective evaluation method because it can clearly
The other cost is for the evaluation. Compared
to a conventional evaluation method, such as a
simple rank evaluation method, the translation
paired comparison method uses a larger amount of
labor because the evaluator must work on n
evaluation sheets. Each sheet consists of 330 pairs
of translation results to be evaluated. Even for an
accomplished evaluator, it takes more than two
weeks to finish the work, following the method
explained in section 2.2.
</bodyText>
<equation confidence="0.8255808">
,
σ 2
i =1,2, ... , n
(c) (
Cov
</equation>
<sectionHeader confidence="0.98877" genericHeader="method">
3 Proposed method
</sectionHeader>
<bodyText confidence="0.999987181818182">
As explained in the previous section, the
translation paired comparison method has an
excessive evaluation cost. Nevertheless, it is an
effective evaluation method for measuring the
capability of a speech translation system.
Therefore, cost reduction for this evaluation
method is an important subject for study.
The proposed method reduces the evaluation
cost by removing insensitive test utterances from
the test set. In this section, we explain the
optimization procedure of the proposed method.
</bodyText>
<subsectionHeader confidence="0.997797">
3.1 Optimization basis
</subsectionHeader>
<bodyText confidence="0.99864855">
In the proposed method, the basis of test set
optimization is the minimization of σ . As shown
in Equations (4) and (5), this value has an
influence on the confidence interval of the system&apos;s
TOEIC score. Therefore, minimizing σ brings
about a reliable evaluation result.
We introduce σ iteration, which is calculated in
each iteration step. σ iteration is also calculated by
using Equations (2) and (3). The difference
between σ iteration andσ is the test set to be used
for calculation. σ iteration is calculated using
residual test utterances in each iteration step.
However, the values of β7 and β2 are fixed, i.e.,
for the calculation of σ iteration, these β7 and β2
are calculated using the original test set consisting
of 330 test utterances.
Optimization is conducted iteratively by
picking up the test utterance that causes maximum
σ iteration in each iteration step. The details of this
procedure is explained in the next subsection.
</bodyText>
<subsectionHeader confidence="0.999753">
3.2 Methodology of the proposed method
</subsectionHeader>
<bodyText confidence="0.9997125">
Figure 4 shows a diagram of the proposed method.
In the first step, the number of iterations is set.
This number is an actual number of removed test
utterances. During the iterations, test utterances are
removed one-by-one. To decide which test
utterance to remove in each iteration, σ iteration is
calculated for the condition of removing each test
utterance. This calculation is done for all
candidates, i.e., all constituents of residual test
utterances.
At the end of each iteration step, the test
utterance to be removed is decided. The removed
</bodyText>
<figure confidence="0.923756333333333">
Yes
Remove worst utterances from
candidates
</figure>
<figureCaption confidence="0.999778">
Figure 4: Procedure of proposed method
</figureCaption>
<bodyText confidence="0.96770625">
test utterance is the one that maximizesσ iteration.
We regard the utterance as maximizingσ iteration if
removing it from the test set gives minimum
σ iteration.
</bodyText>
<figure confidence="0.986088166666667">
Set the number of iterations
Yes
Is iteration
achieved?
No
No
Get next candidate
Calculate iteration
σ
Update worst sentence,
which causes maximum
σ iteration
All candidates
are calculated?
760
740
**+f� INKM
720
700
680
660
(upper) C0opt + Iopt
C0opt C0opt - Iopt
(lower)
0 50 100 150 200 250 300
40
30
20
10
0
Random selection (Averaging of 10 trials)
Optimized (Open)
Optimized (Closed)
0 50 100 150 200 250 300
σ► Kp►
Iteration
</figure>
<figureCaption confidence="0.9954055">
Figure 5: Relationship between iteration
and system’s TOEIC score
</figureCaption>
<sectionHeader confidence="0.996801" genericHeader="method">
4 Experimental results
</sectionHeader>
<bodyText confidence="0.999957">
In this section, we show experimental results of the
proposed method. Here, we introduce the suffix
“opt” to distinguish a variable calculated with the
optimized test set from a variable calculated with
the original test set. All of the above variables are
calculated with the original test set. By joining the
suffix “opt” to these variables, we refer to variables
calculated with the optimized test set, e.g., σ opt 3,
σ t opt, Iopt, C0 opt, CI opt, and so on.
</bodyText>
<subsectionHeader confidence="0.997367">
4.1 Closed experiment
</subsectionHeader>
<bodyText confidence="0.9997745">
This subsection discusses an experimental result
obtained for the same test set and examinees
described in Section 2. Namely, the target test set
for optimization consists of 330 utterances and the
number of examinees is 30.
Figure 5 shows the relationship between
iteration and the system’s TOEIC score (C0 opt). In
this figure, the horizontal axis represents the
iteration number and the vertical axis the TOEIC
score. The solid line represents C0 opt, which is the
system’s TOEIC score using the optimized test in
each iteration. The dotted line above the solid line
represents the value of C0 opt + Iopt, and the dotted
line below the solid line C0 opt - Iopt.
</bodyText>
<page confidence="0.295845">
3 σ opt is different fromσ iteration. σ opt is calculated based on
β1 opt and β2 opt (not β1 and β2 ) for the optimized test set.
</page>
<figure confidence="0.590496">
Iteration
</figure>
<figureCaption confidence="0.993688">
Figure 6: Relationship between iteration
and σ t opt
</figureCaption>
<bodyText confidence="0.999832571428571">
As shown in the figure, from iteration 1 to
iteration 250, the value of C0 opt is stable and does
not deviate from C0, which is 708. Furthermore,
until around iteration 200, the value of Iopt
decreases concurrently with the iteration.
This result suggests that the proposed may
provide low-cost evaluation with high reliability.
</bodyText>
<subsectionHeader confidence="0.9984">
4.2 Experiment opened for examinees
</subsectionHeader>
<bodyText confidence="0.999965136363636">
In the result shown in the previous subsection, the
optimization and evaluation were conducted on the
same examinees, i.e., the evaluation is closed for
examinees. In this subsection, we look into the
robustness of the proposed method against
different examinees. We divided the group,
consisting of 30 examinees, into two groups: a
group of odd-numbered examinees and a group of
even-numbered examinees. Individuals were sorted
by TOEIC score from lowest to highest.
One of the groups is used to optimize the test set.
The other group is used for the translation paired
comparison method. We use the term
“optimization group” to refer to the first group and
“evaluation group” to refer to the second group.
Figure 6 shows the relationship between
iteration and σ t opt. In this figure, the horizontal
axis represents the iteration and the vertical axis
showsσ t opt. Three kinds of experimental results
are shown in this figure. In each of three
experiments, the translation paired comparison is
conducted by the evaluation group. The differences
</bodyText>
<figure confidence="0.896741">
0 50 100 150 200 250 300
Iteration
</figure>
<figureCaption confidence="0.899367">
Figure 7: Relationship between iteration and
</figureCaption>
<equation confidence="0.618053">
C0 opt
</equation>
<bodyText confidence="0.97119537037037">
among the three experiments are in the group to be
used for optimization of the test set or the method
used to reduce it. The double line represents the
closed result using the test set, optimized on the
evaluation group. The solid line represents the
open result using the test set, optimized on the
optimization group. The broken line represents the
result using the test set, which is reduced by
randomly removing test utterances one-by-one.
The actual plotted broken line is averaged over 10
random trials.
As shown in Figure 6, in the random selection
result, t opt is on the rise. On the other hand, the
σ
open result is on the decline.
Figure 7 shows the relationship between
iteration and the system’s TOEIC score. In this
figure, the horizontal axis represents the iteration
and the vertical axis the TOEIC score. The
denotation of each line is the same as that in Figure
6. The error bar from the broken line represents
σ random, which is the standard deviation of the
system’s TOEIC score over 10 random trials.
In Figure 7, considering σ random, C0 opt of the
open evaluation is more approximate to C0 than
that of random selection, whereas C0 opt of the
closed evaluation is much more approximate to C0.
</bodyText>
<subsectionHeader confidence="0.997376">
4.3 Experiment on ATR-MATRIX
</subsectionHeader>
<bodyText confidence="0.99981">
To be of actual use, the test set optimized for some
system must be applicable for evaluation of other
systems. In this subsection, we show the results of
an experiment aimed at verifying this requirement
is met. In this experiment, we apply the test set,
</bodyText>
<figure confidence="0.928907666666667">
0 50 100 150 200 250 300
Iteration
Figure 8: Relationship between iteration and
σ t opt
0 50 100 150 200 250 300
Iteration
</figure>
<figureCaption confidence="0.815416">
Figure 9: Relationship between iteration and
</figureCaption>
<equation confidence="0.367086">
C0 opt
</equation>
<bodyText confidence="0.929989285714286">
which is optimized for TDMT, to evaluate ATR-
MATRIX. The experimental conditions are the
same as in Section 4.1, except for the evaluation
target. The results are shown in Figure 8 and
Figure 9.
Figure 8 shows the relationship between
iteration and σ t opt. In this figure, the horizontal
axis represents the iteration and the vertical axis
shows σ t opt. The double line represents the result
using the test set, optimized for ATR-MATRIX.
The solid line represents the result using the test
set, optimized for TDMT. The broken line
represents the result using the test set, which is
reduced by randomly removing test utterances one-
</bodyText>
<figure confidence="0.99353553125">
750
700
850
800
650
600
550
Random selection (Averaging of 10 trials)
Optimized (Open)
Optimized (Closed)
σt opt
30
25
20
15
10
5
0
Random selection (Averaging of 10 trials)
Optimized for TDMT
Optimized for ATR-MATRIX
C0 opt
580
560
540
520
500
480
460
Optimized for TDMT
Optimized for ATR-MATRIX
C0 opt
</figure>
<bodyText confidence="0.986987882352941">
by-one. The actual plotted broken line is averaged 6 Conclusions
over 10 random trials.
Figure 9 shows the relationship between We proposed a test set selection method for
iteration and the system’s TOEIC score. In this evaluating a speech translation system. This
figure, the horizontal axis represents the iteration, method optimizes and drastically reduces the test
and the vertical axis TOEIC score. The broken line set required by the translation paired comparison
and the solid line are plotted using the same method.
denotation as that in Figure 8. Translation paired comparison is an effective
In Figure 8, the solid line always lies on a lower method for measuring a system’s performance as a
position than the broken line. In Figure 9, from TOEIC score. However, this method has excessive
iteration 1 to around iteration 200, the broken line evaluation costs. Therefore, cost reduction for this
does not deviate from the actual system’s TOEIC evaluation method is an important subject for study.
score, which is 548. We applied the proposed method in an evaluation
Considering these results, the test set optimized of ATR-MATRIX. Experimental results showed
for TDMT is shown to be applicable for evaluating the effectiveness of the proposed method. This
ATR-MATRIX. method reduced evaluation costs by more than
60% and also improved the reliability of the
</bodyText>
<sectionHeader confidence="0.991146" genericHeader="method">
5 Discussion evaluation result.
</sectionHeader>
<bodyText confidence="0.98944509375">
In this section, we discuss the experimental results
shown in Section 4.
Looking at the broken lines in Figure 6 and
Figure 8, test set reduction using random selection
always causes an increase of G t opt i.e., an increase
in the scale of confidence interval. Therefore, this
method causes the reliability of the evaluation
result to deteriorate. Meanwhile, in the case of
using the proposed method, looking at the solid
lines on these figures, G t opt is on the decline until
around iteration 200. This means that we can
achieve a more reliable evaluation result with a
lower evaluation cost than when using the original
test set. Here, looking at the solid lines in Figure 7
and Figure 9, the Co opt system’s TOEIC score is
nearly stable until iteration 200, and it does not
deviate from Co. As mentioned before, Co for
Figure 7 is 708 and Co for Figure 9 is 548.
Considering these results, the proposed method
can reduce the 330-utterance test set to a 130-
utterance test set while reducing the scale of
confidence interval. In other words, the proposed
method both reduces evaluation costs by 60% and
improves reliability of the evaluation result.
Looking at Equations (4) and (5), the scale of
confidence interval is also influenced by n. When
we allow the scale of confidence interval obtained
from the original test set, we can use the proposed
method’s reduction effect of G t to compensate the
G t &apos;s increase by reducing n. In this case, the
actual achievable cost reduction will be more than
60%.
</bodyText>
<sectionHeader confidence="0.980453" genericHeader="conclusions">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9999788">
The research reported here was supported in part
by a contract with the Telecommunications
Advancement Organization of Japan entitled, &amp;quot;A
study of speech dialogue translation technology
based on a large corpus.&amp;quot;
</bodyText>
<sectionHeader confidence="0.999263" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99988237037037">
Morimoto, T., Uratani, N., Takezawa, T., Furuse,
O., Sobashima, Y., Iida, H., Nakamura, A.,
Sagisaka, Y., Higuchi, N. and Yamazaki, Y.
1994. A speech and language database for
speech translation research. In Proceedings of
ICSLP `94, pages 1791-1794.
Sugaya, F., Takezawa, T., Yokoo, A., Sagisaka, Y.
and Yamamoto, S. 2000. Evaluation of the
ATR-MATRIX Speech Translation System with
a Pair Comparison Method between the System
and Humans. In Proceedings of ICSLP 2000,
pages 1105-1108.
Sumita, E., Yamada, S., Yamamoto K., Paul, M.,
Kashioka, H., Ishikawa, K. and Shirai, S. 1999.
Solutions to Problems Inherent in Spoken-
language Translation: The ATR-MATRIX
Approach. In Proceedings of MT Summit `99,
pages 229-235.
Takezawa, T. 1999. Building a bilingual travel
conversation database for speech recognition
research. In Proceedings of Oriental COCOSDA
Workshop, pages 17-20.
Takezawa, T., Morimoto, T., Sagisaka, Y.,
Campbell, N., Iida., H., Sugaya, F., Yokoo, A.
and Yamamoto, S. 1998. A Japanese-to-English
speech translation system: ATR-MATRIX. In
Proceedings of ICSLP 1998, pages 2779-2782.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.667736">
<note confidence="0.915222666666667">Proceedings of the Workshop on Speech-to-Speech Translation: Algorithms and Systems, Philadelphia, July 2002, pp. 109-116. Association for Computational Linguistics.</note>
<title confidence="0.997622">Quality-Sensitive Test Set Selection for a Speech Translation System</title>
<author confidence="0.998372">Keiji Toshiyuki Takezawa</author>
<author confidence="0.998372">Seiichi Yamamoto</author>
<affiliation confidence="0.999523">ATR Spoken Language Translation Research Laboratories</affiliation>
<address confidence="0.988568">2-2-2 Hikari-dai Seika-cho, Soraku-gun, Kyoto, 619-0288, Japan</address>
<email confidence="0.9464985">fumiaki.sugaya@atr.co.jp</email>
<email confidence="0.9464985">keiji.yasuda@atr.co.jp</email>
<email confidence="0.9464985">seiichi.yamamoto@atr.co.jp</email>
<abstract confidence="0.9995491875">We propose a test set selection method to sensitively evaluate the performance of a speech translation system. The proposed method chooses the most sensitive test sentences by removing insensitive sentences iteratively. Experiments are conducted on the ATR-MATRIX speech translation system, developed at ATR Interpreting Research Laboratories. The results show the effectiveness of the proposed method. According to the results, the proposed method can reduce the test set size to less than 40% of the original size while improving evaluation reliability.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Morimoto</author>
<author>N Uratani</author>
<author>T Takezawa</author>
<author>O Furuse</author>
<author>Y Sobashima</author>
<author>H Iida</author>
<author>A Nakamura</author>
<author>Y Sagisaka</author>
<author>N Higuchi</author>
<author>Y Yamazaki</author>
</authors>
<title>A speech and language database for speech translation research.</title>
<date>1994</date>
<booktitle>In Proceedings of ICSLP `94,</booktitle>
<pages>1791--1794</pages>
<marker>Morimoto, Uratani, Takezawa, Furuse, Sobashima, Iida, Nakamura, Sagisaka, Higuchi, Yamazaki, 1994</marker>
<rawString>Morimoto, T., Uratani, N., Takezawa, T., Furuse, O., Sobashima, Y., Iida, H., Nakamura, A., Sagisaka, Y., Higuchi, N. and Yamazaki, Y. 1994. A speech and language database for speech translation research. In Proceedings of ICSLP `94, pages 1791-1794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sugaya</author>
<author>T Takezawa</author>
<author>A Yokoo</author>
<author>Y Sagisaka</author>
<author>S Yamamoto</author>
</authors>
<title>Evaluation of the ATR-MATRIX Speech Translation System with a Pair Comparison Method between the System and Humans.</title>
<date>2000</date>
<booktitle>In Proceedings of ICSLP</booktitle>
<pages>1105--1108</pages>
<marker>Sugaya, Takezawa, Yokoo, Sagisaka, Yamamoto, 2000</marker>
<rawString>Sugaya, F., Takezawa, T., Yokoo, A., Sagisaka, Y. and Yamamoto, S. 2000. Evaluation of the ATR-MATRIX Speech Translation System with a Pair Comparison Method between the System and Humans. In Proceedings of ICSLP 2000, pages 1105-1108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Sumita</author>
<author>S Yamada</author>
<author>K Yamamoto</author>
<author>M Paul</author>
<author>H Kashioka</author>
<author>K Ishikawa</author>
<author>S Shirai</author>
</authors>
<title>Solutions to Problems Inherent in Spokenlanguage Translation: The ATR-MATRIX Approach.</title>
<date>1999</date>
<booktitle>In Proceedings of MT Summit `99,</booktitle>
<pages>229--235</pages>
<marker>Sumita, Yamada, Yamamoto, Paul, Kashioka, Ishikawa, Shirai, 1999</marker>
<rawString>Sumita, E., Yamada, S., Yamamoto K., Paul, M., Kashioka, H., Ishikawa, K. and Shirai, S. 1999. Solutions to Problems Inherent in Spokenlanguage Translation: The ATR-MATRIX Approach. In Proceedings of MT Summit `99, pages 229-235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Takezawa</author>
</authors>
<title>Building a bilingual travel conversation database for speech recognition research.</title>
<date>1999</date>
<booktitle>In Proceedings of Oriental COCOSDA Workshop,</booktitle>
<pages>17--20</pages>
<contexts>
<context position="3088" citStr="Takezawa, 1999" startWordPosition="439" endWordPosition="440">slation on paper. The Japanese text is spoken twice within one minute, with a pause in-between. To measure the English capability of the Japanese native speakers, the TOEIC score is used. The examinees are requested to present an official TOEIC score certificate showing that they have taken the test within the past six months. A questionnaire is given to them and the results show that the answer time is moderately difficult for the examinees. The test text is the SLTA1 test set, which consists of 330 utterances in 23 conversations from a bilingual travel conversation database (Morimoto, 1994; Takezawa, 1999). The SLTA1 test set is 1Current affiliation: KDDI R&amp;D Laboratories. Also at Graduate School of Science and Technology, Kobe University. 2Also at Graduate School of Engineering, Doshisha University. Japanese Test Text Translation Result by Human Accurate Text Typing Evaluation Sheet Paired Comparison Figure 1: Diagram of translation pair comparison method Japanese-to-English Language Translation (J-E TDMT) Japanese Recognition (Japanese SPREC) Choose A, B, C, or D rank No No Yes Same rank? Yes Consider naturalness Same? Select better result EVEN information and grammar; (B) Fair: easy-tounders</context>
</contexts>
<marker>Takezawa, 1999</marker>
<rawString>Takezawa, T. 1999. Building a bilingual travel conversation database for speech recognition research. In Proceedings of Oriental COCOSDA Workshop, pages 17-20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Takezawa</author>
<author>T Morimoto</author>
<author>Y Sagisaka</author>
<author>N Campbell</author>
<author>H Iida</author>
<author>F Sugaya</author>
<author>A Yokoo</author>
<author>S Yamamoto</author>
</authors>
<title>A Japanese-to-English speech translation system: ATR-MATRIX.</title>
<date>1998</date>
<booktitle>In Proceedings of ICSLP</booktitle>
<pages>2779--2782</pages>
<marker>Takezawa, Morimoto, Sagisaka, Campbell, Iida, Sugaya, Yokoo, Yamamoto, 1998</marker>
<rawString>Takezawa, T., Morimoto, T., Sagisaka, Y., Campbell, N., Iida., H., Sugaya, F., Yokoo, A. and Yamamoto, S. 1998. A Japanese-to-English speech translation system: ATR-MATRIX. In Proceedings of ICSLP 1998, pages 2779-2782.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>