<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.038577">
<note confidence="0.959746333333333">
Proceedings of HLT-NAACL 2003
Main Papers , pp. 17-23
Edmonton, May-June 2003
</note>
<title confidence="0.998892">
A Categorial Variation Database for English
</title>
<author confidence="0.998843">
Nizar Habash
</author>
<affiliation confidence="0.9972345">
Institute for Advanced Computer Studies
University of Maryland
</affiliation>
<address confidence="0.945612">
College Park, MD 20740
</address>
<email confidence="0.999252">
habash@umiacs.umd.edu
</email>
<author confidence="0.998199">
Bonnie Dorr
</author>
<affiliation confidence="0.9972395">
Institute for Advanced Computer Studies
University of Maryland
</affiliation>
<address confidence="0.945705">
College Park, MD 20740
</address>
<email confidence="0.999523">
bonnie@umiacs.umd.edu
</email>
<sectionHeader confidence="0.995651" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961857142857">
We describe our approach to the construction
and evaluation of a large-scale database called
“CatVar” which contains categorial variations
of English lexemes. Due to the prevalence of
cross-language categorial variation in multilin-
gual applications, our categorial-variation re-
source may serve as an integral part of a di-
verse range of natural language applications.
Thus, the research reported herein overlaps
heavily with that of the machine-translation,
lexicon-construction, and information-retrieval
communities.
We apply the information-retrieval metrics of
precision and recall to evaluate the accuracy
and coverage of our database with respect
to a human-produced gold standard. This
evaluation reveals that the categorial database
achieves a high degree of precision and recall.
Additionally, we demonstrate that the database
improves on the linkability of Porter stemmer
by over 30%.
</bodyText>
<sectionHeader confidence="0.999331" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999300027027027">
Natural Language Processing (NLP) applications may
only be as good as the resources upon which they rely.
Resources specifying the relations among lexical items
such as WordNet (Fellbaum, 1998) and HowNet (Dong,
2000) (among others) have inspired the work of many re-
searchers in NLP (Carpuat et al., 2002; Dorr et al., 2000;
Resnik, 1999; Hearst, 1998; Voorhees, 1993).
In this paper we introduce a new resource called Cat-
Var which specifies the lexical relation Categorial Vari-
ation on a large scale for English. This resource has al-
ready been used effectively in a wide range of monolin-
gual and multilingual NLP applications. Upon its first
public release, CatVar will be freely available to the re-
search community. We expect that the contribution of this
resource will become more widely recognized through its
future incorporation into additional NLP applications.
A categorial variation of a word with a certain part-
of-speech is a derivationally-related word with possi-
bly a different part-of-speech. For example, hunger ,
hunger and hungry are categorial variations of each
other, as are cross and across , and stab and stab .
Although this relation seems basic on the surface, this
relation is critical to work in Information Retrieval (IR),
Natural Language Generation (NLG) and Machine Trans-
lation (MT)—yet there is no large scale resource avail-
able for English that focuses on categorial variations.&apos;
In the rest of this paper, we discuss other available re-
sources and how they differ from the CatVar database.
We then discuss how and what resources were used to
build CatVar. Afterwards, we present three applications
that use CatVar in different ways: Generation-Heavy MT,
headline generation, and cross-language divergence un-
raveling for bilingual alignment. Finally, we present a
multi-component evaluation of the database. Our evalu-
ation reveals that the categorial database achieves a high
degree of precision and recall and that it improves on the
linkability of Porter stemmer by over 30%.
</bodyText>
<sectionHeader confidence="0.989203" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.99941325">
Lexical relations describe relative relationships among
different lexemes. Lexical relations are either hierarchi-
cal taxonomic relations (such as hypernymy, hyponymy
and entailments) or non-hierarchical congruence rela-
</bodyText>
<footnote confidence="0.825784142857143">
&apos;It is the intention of the WordNet 1.7 developers to in-
clude such information in their next version, but only for nouns
and verbs (Christiane Fellbaum, pc.), not other pairings such as
noun-adjective, verb-preposition relationships. Discussions are
currently underway for sharing the CatVar database with Word-
Net developers for more rapid development, extension, and mu-
tual validation of both resources.
</footnote>
<bodyText confidence="0.999619690476191">
tions (such as identity, overlap, synonymy and antonymy)
(Cruse, 1986).
WordNet is the most well-developed and widely used
lexical database of English (Fellbaum, 1998). In Word-
Net, both types of lexical relations are specified among
words with the same part of speech (verbs, nouns, ad-
jectives and adverbs). WordNet has been used by many
researchers for different purposes ranging from the con-
struction or extension of knowledge bases such as SEN-
SUS (Knight and Luk, 1994) or the Lexical Conceptual
Structure Verb Database (LVD) (Green et al., 2001) to the
faking of meaning ambiguity as part of system evaluation
(Bangalore and Rambow, 2000). In the context of these
projects, one criticism of WordNet is its lack of cross-
categorial links, such as verb-noun or noun-adjective re-
lations.
Mel’ˇcuk approaches lexical relations by defining a lex-
ical combinatorial zone that specifies semantically related
lexemes through Lexical Functions (LF). These functions
define a correspondence between a key lexical item and a
set of related lexical items (Mel’ˇcuk, 1988). There are
two types of functions: paradigmatic and syntagmatic
(Ramos et al., 1994). Paradigmatic LFs associate a lex-
ical item with related lexical items. The relation can
be semantic or syntactic. Semantic LFs include Syn-
onym(calling) = vocation, Antonym(small) = big, and
Generic(fruit) = apple. Syntactic LFs include Derived-
Noun(expand)= expansion and Adjective(female) = fem-
inine.
Syntagmatic LFs specify collocations with a lexeme
given a specified relationship. For example, there is a
LF that returns a light verb associated with the LF’s key:
Light-Verb(attention) = pay. Other LFs specify certain
semantic associations such as Intensify-Qualifier(escape)
= narrow and Degradation(milk) = sour. Lexical Func-
tions have been used in MT and Generation (e.g. (Ramos
et al., 1994)).
Although research on Lexical Functions provides an
intriguing theoretical discussion, there are no large scale
resources available for categorial variations induced by
lexical functions. This lack of resources shouldn’t sug-
gest that the problem is too trivial to be worthy of in-
vestigation or that a solution would not be a significant
contribution. On the contrary, categorial variations are
necessary for handling many NLP problems. For exam-
ple, in the context of MT, (Habash et al., 2002) claims
that 98% of all translation divergences (variations in how
source and target languages structure meaning) involve
some form of categorial variation. Moreover, most IR
systems require some way to reduce variant words to
common roots to improve the ability to match queries (Xu
and Croft, 1998; Hull and Grefenstette, 1996; Krovetz,
1993).
Given the lack of large-scale resources containing cat-
egorial variations, researchers frequently develop and
use alternative algorithmic approximations of such a re-
source. These approximations can be divided into Reduc-
tionist (Analytical) or Expansionist (Generative) approxi-
mations. The former focuses on the conversion of several
surface forms into a common root. Stemmers such as the
Porter stemmer (Porter, 1980) are a typical example. The
latter, or expansionist approaches, overgenerate possibili-
ties and rely on a statistical language model to rank/select
among them. The morphological generator in Nitrogen
is an example of such an approximation (Langkilde and
Knight, 1998).
There are two types of problems with approximations
of this type: (1) They are uni-directional and thus lim-
ited in usability—A stemmer cannot be used for genera-
tion and a morphological overgenerator cannot be used
for stemming; (2) The crude approximating nature of
such systems cause many problems in quality and ef-
ficiency from over-stemming/under-stemming or over-
generation/under-generation.
Consider, for example, the Porter stemmer, which
stems commune , communication and communism
to . And yet, it does not produce this same
stem for communist or communicable (stemmed to
and respectively).2 Another ex-
ample is the expansionist Nitrogen morphological gener-
ator, where the morphological feature
applied to returns eleven variations includ-
ing ,and .Only
two are correct ( and
</bodyText>
<sectionHeader confidence="0.940633" genericHeader="method">
3 Building the CatVar
</sectionHeader>
<bodyText confidence="0.998677625">
The CatVar database was developed using a combina-
tion of resources and algorithms including the Lexi-
cal Conceptual Structure (LCS) Verb and Preposition
Databases (Dorr, 2001), the Brown Corpus section of the
Penn Treebank (Marcus et al., 1993), an English mor-
phological analysis lexicon developed for PC-Kimmo
(Englex) (Antworth, 1990), NOMLEX (Macleod et al.,
1998), Longman Dictionary of Contemporary English
</bodyText>
<footnote confidence="0.878746">
2For a deeper discussion and classification of Porter stem-
mer’s errors, see (Krovetz, 1993).
</footnote>
<bodyText confidence="0.998878285714285">
). Such
overgeneration multiplied out at different points in a sen-
tence expands the search space exponentially, and given
various cut-offs in the search algorithm, might even ap-
pear in some of the top ranked choices.
Given these issues, our goal is to build a database of
categorial variations that can be used with both expan-
sionist and reductionist approaches without the cost of
over/under-stemming/generation. The research reported
herein is relevant to MT, IR, and lexicon construction.
(LDOCE)3 (Procter, 1983), WordNet 1.6 (Fellbaum,
1998), and the Porter stemmer. The contribution of each
of these sources is clearly labeled in the CatVar database,
thus enabling the use of different cross-sections of the re-
source for different applications.4
Some of these resources were used to extract seed links
between different words (Englex lexicon, NOMLEX and
LDOCE). Others were used to provide a large-scale cov-
erage of lexemes. In the case of the Brown Corpus, which
doesn’t provide lexemes for its words, the Englex mor-
phological analyzer was used together with the part of
speech specified in the Penn Tree Bank to extract the lex-
eme form. The Porter stemmer was later used as part of a
clustering step to expand the seed links to create clusters
of words that are categorial variants of each other, e.g.,
hunger , hungry , hunger , hungriness .
The current version of the CatVar (version 2.0) in-
cludes 62,232 clusters covering 96,368 unique lexemes.
The lexemes belong to one of four parts-of-speech (Noun
62%, Adjective 24%, Verb 10% and Adverb 4%). Al-
most half of the clusters currently include one word only.
Three-quarters of these single-word clusters are nouns
and one-fifth are adjectives. The other half of the words
is distributed in a Zipf fashion over clusters from size 2
to 27. Figure 1 shows the word-cluster distribution.
</bodyText>
<figureCaption confidence="0.998847">
Figure 1: CatVar Distribution
</figureCaption>
<bodyText confidence="0.999650714285714">
A smaller supplementary database devoted to verb-
preposition variations was constructed solely from the
LCS verb and preposition lexicon using shared LCS
primitives to cluster. The database was inspired by
pairs such as cross and across which are used in
Generation-Heavy MT. But since verb-preposition clus-
ters are not typically morphologically related, they are
</bodyText>
<footnote confidence="0.979219166666667">
3An English Verb-Noun list extracted from LDOCE was
provided by Rebecca Green.
4For example, in a headline generation system (HeadGen),
higher Bleu scores were obtained when using the portions of the
CatVar database that are most relevant to nominalized events
(e.g., NOMLEX).
</footnote>
<bodyText confidence="0.9939281">
kept separate from the rest of the CatVar database and
they were not included in the evaluation presented in this
paper.5
The CatVar is web-browseable at
http://clipdemos.umiacs.umd.edu/catvar/. Figure 2
shows the CatVar web-based interface with the hunger
cluster as an example. The interface allows searching
clusters using regular expressions as well as cluster
length restrictions. The database is also available for
researchers in perl/C and lisp searchable formats.
</bodyText>
<figureCaption confidence="0.996217">
Figure 2: Web Interface
</figureCaption>
<sectionHeader confidence="0.997383" genericHeader="method">
4 Applications
</sectionHeader>
<bodyText confidence="0.999970333333333">
Our project is focused on resource building and evalua-
tion. However, the CatVar database is relevant to a num-
ber of natural language applications, including generation
for MT, headline generation, and cross-language diver-
gence unraveling for bilingual alignment. Each of these
are discussed below, in turn.
</bodyText>
<subsectionHeader confidence="0.985821">
4.1 Generation-Heavy Machine Translation
</subsectionHeader>
<bodyText confidence="0.983493857142857">
The Generation-Heavy Hybrid Machine Translation
(GHMT) model was introduced in (Habash, 2002) to han-
dle translation divergences between language pairs with
asymmetrical (poor-source/rich-target) resources. The
approach does not rely on a transfer lexicon or a com-
mon interlingual representation to map between divergent
structural configurations from source to target language.
Instead, different alternative structural configurations are
over-generated and these are statistically ranked using a
language model.
5This supplementary database includes 242 clusters for
more than 230 verbs and 29 prepositions. Other examples
of verb-preposition clusters include: avoid and away from ;
enter and into ; and border and beside (or next to ).
The CatVar database is used as one of the constraints
on the structural expansion step. For example, to allow
the conflation of verbs such as make or cause and an
argument such as development , the first condition for
conflatability is finding a verb categorial variant of the
argument development . In this case the verb categorial
variant is develop .6
</bodyText>
<subsectionHeader confidence="0.967566">
4.2 Headline Generation
</subsectionHeader>
<bodyText confidence="0.999563565217392">
The HeadGen headline generator was introduced in (Za-
jic et al., 2002) to create headlines automatically from
newspaper text. The goal is to generate an informa-
tive headline (one that specifies the event and its partic-
ipants) not just an indicative headline (which specifies
the topic only). The system is implemented as a Hidden
Markov Model enhanced with a postprocessor that filters
out headlines that do not contain a verbal or nominalized
event. This is achieved by verifying that there is at least
one word in the generated headline that appears in CatVar
as a V (a verbal event) or as a N whose verbal counterpart
is in the same cluster (a nominalized event).
A recent study indicates that there is a significant im-
provement in Bleu scores (using human-generated head-
lines as our references) when running headline generation
with the CatVar filter:7
HeadGen with CatVar filter: 0.1740
HeadGen with no CatVar filter: 0.1687
This quantitative distinction correlates with human-
perceived differences, e.g., between the two headlines
Washingtoniansfight over drugs and In the nation’s capi-
tal (generated for the same story—with and without Cat-
Var, respectively).
</bodyText>
<subsectionHeader confidence="0.981165">
4.3 DUSTer
</subsectionHeader>
<bodyText confidence="0.999811153846154">
DUSTer—Divergence Unraveling for Statistical
Translation—was introduced in (Dorr et al., 2002).
In this system, common divergence types are systemat-
ically identified and English sentences are transformed
to bear a closer resemblance to that of another language
using a mapping referred to as -to- . The objective
is to enable more accurate alignment and projection of
dependency trees in another language without requiring
any training on dependency-tree data in that language.
The CatVar database has been incorporated into two
components of the DUSTer system: (1) In the -to-
mapping, e.g., the transformation from kick to LightVB
kick (corresponding to the English/Spanish divergence
</bodyText>
<footnote confidence="0.9954228">
6The other conditions on conflatability and some detailed
examples are discussed in (Habash, 2002) and (Habash and
Dorr, 2002).
7For details about the Bleu evaluation metric, see (Papineni
et al., 2002).
</footnote>
<bodyText confidence="0.999849">
pair kick/dar patada); and (2) During an automatic mark-
up phase prior to this transformation, where the partic-
ular -to- mapping is selected from a set of possi-
bilities based on the 2 input sentences. For example,
the rule V[CatVar=N] -&gt; LightVB N is selected
for the transformation above by first checking that the
verb V is associated with a word of category N in Cat-
Var. Transforming divergent English sentences using this
mechanism has been shown to facilitate word-level align-
ment by reducing the number of unaligned and multiply-
aligned words.
</bodyText>
<sectionHeader confidence="0.99866" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9998006">
This section includes two evaluations concerned with dif-
ferent aspects of the CatVar database. The first evalua-
tion calculates the recall and precision of CatVar’s clus-
tering and the second determines the contribution of Cat-
Var over Porter stemmer.
</bodyText>
<subsectionHeader confidence="0.6813575">
5.1 CatVar Clustering Evaluation: Recall and
Precision
</subsectionHeader>
<bodyText confidence="0.997069166666667">
To determine the recall and precision of CatVar given the
lack of a gold standard, we asked 8 native speakers to
evaluate 400 randomly-selected clusters. Each annotator
was given a set of 100 clusters (with two annotators per
set). Figure 3 shows a segment of the evaluation interface
which was web-browseable.
</bodyText>
<figureCaption confidence="0.998654">
Figure 3: Evaluation
</figureCaption>
<bodyText confidence="0.975727">
The annotators were given detailed instructions and
many examples to help them with the task. They were
asked to classify each word in every cluster as belonging
to one of the following categories:
Perfect: This word definitely belongs in this cluster.
Perfect (except for part of speech problem).
Perfect (except for spelling problem).
</bodyText>
<listItem confidence="0.596062">
Not Sure: It is not clear whether a word that is
derivationally correct belongs in a set or not.
Doesn’t Belong: This word doesn’t belong in this
cluster.
</listItem>
<bodyText confidence="0.998981509803922">
May not be a Real Word: This word is not known
and couldn’t be found it in a dictionary.
The interface also provided an input text box to add
missing words to a cluster.
In calculating the inter-annotator agreement, we did
not consider mismatches in word additions as disagree-
ment since some annotators could not think up as many
possible variations as others. After all, this was not
an evaluation of their ability to think up variations, but
rather of the coverage of the CatVar database. The
inter-annotator agreement was calculated as the percent-
age of words where both annotators agreed out of all
words. Even though there were six fine-grained classi-
fications, the average inter-annotator agreement was high
(80.75%). Many of the disagreements, however, resulted
from the fine-grainedness of the options available to the
annotators.
In a second calculation of inter-annotator agreement,
we simplified the annotators’ choices by placing them
into three groups corresponding to Perfect (Perfect and
Perfect-but), Not-sure (Not-sure and May-not-be-a-real-
word) and Wrong (Does-not-belong). This annotation-
grouping approach is comparable to the clustering tech-
niques used by (Veronis, 1998) to “super-tag” fine
grained annotations. After grouping the annotations, av-
erage inter-annotator agreement rose up to 98.35%.
The cluster modifications produced by each pair of an-
notators assigned to the same cluster were then combined
automatically in an approximation to post-annotation
inter-annotator discussion, which traditionally results in
agreement: (1) If both annotators agreed on a category,
then it stands; (2) One annotator overrides another in
cases where one is more sure than the other (i.e., Per-
fect overrides Perfect-but-with-error/Not-sureand Wrong
overrides Not-sure); (3) In cases where one annotator
considers a word Perfect while the other annotator con-
sidered it Wrong, we compromise at Not-sure. The union
of all added words was included in the combined cluster.
The 400 combined clusters covered 808 words. 68%
of the words were ranked as Perfect. None had spelling
errors and only one word had a part-of-speech issue. 23
words (less than 3%) were marked as Not-sures. And
only 6 words (less than 1%) were marked as Wrong.
There were 209 added words (about 26%). However 128
words (or 61% of missing words) were not actually miss-
ing, but rather not linked into the set of clusters evaluated
by a particular annotator. Some of these words were clus-
tered separately in the database.8 The rest of the missing
words (81 words or 10% of all words) were not present
in the database, but 50 of them (or 62%) were linkable to
existing words in the CatVar using simple stemming (e.g.,
</bodyText>
<footnote confidence="0.9387405">
8The 128 words that were “not really missing” were clus-
tered in 89 other clusters not included in the evaluation sample.
</footnote>
<bodyText confidence="0.997007333333333">
the Porter stemmer, whose relevance is described next).
The precision was calculated as the ratio of perfect
words to all original (i.e. not added) words: 91.82%. The
recall was calculated as the ratio of perfect words divided
by all perfect plus all added words: 72.46%. However,
if we exclude the not-really missing words, the adjusted
recall value becomes 87.16%. The harmonic mean or F-
score9 of the precision and recall is 81.00% (or 89.43%
for adjusted recall).
</bodyText>
<subsectionHeader confidence="0.9968055">
5.2 Linkability Evaluation: Comparison to Porter
Stemmer
</subsectionHeader>
<bodyText confidence="0.999063052631579">
To measure the contribution of CatVar with respect to the
“linking together” of related words, it is important to de-
fine the concept of linkability as the percentage of word-
to-word links in the database resulting from a specific
source. For example, Natural linkability refers to pairs
of words whose form doesn’t change across categories
such as zip and zip or afghan and afghan . Porter
linkability refers to words linkable by reduction to a com-
mon Porter stem. CatVar linkability is the linkability of
two words appearing in the same CatVar cluster.
Figure 4 shows an example of all three types of links
in the hunger cluster. Here, hunger and hunger are
linked in three ways, Naturally (N), by the Porter stem-
mer (P), and in CatVar (C). Porter links hungry and
hungriness via the common stem hungri but Porter
doesn’t link either of these to hunger or hunger (stem
hunger). The total number of links in this cluster is six,
two of which are Porter-determinable and only one of
which is naturally-determinable.
</bodyText>
<figureCaption confidence="0.982229">
Figure 4: Three Types of Links
</figureCaption>
<bodyText confidence="0.9996118">
The calculation of linkability applies only to the por-
tion of the database containing multi-word clusters (about
half of the database) since single-word clusters have zero
links. The 48,867 linked words are distributed over
14,731 clusters with 89,638 total number of links. About
12% of these links are naturally-determinable and 70%
are Porter-linkable. The last 30% of the links is a sig-
nificant contribution of the CatVar database, compared to
the Porter stemmer, particularly since this stemmer is an
industry standard in the IR community.10
</bodyText>
<equation confidence="0.891390727272727">
9F-score = .
10A reviewer points out that the Porter stemmer could be
HungrinessN HungryAJ
N
N P C Hunger
Hunger V
C
C C
P
C
C
</equation>
<bodyText confidence="0.999968111111111">
It is important to point out that, for CatVar to be used
in IR, it must be accompanied by an inflectional ana-
lyzer that reduces words to their lexeme form (remov-
ing plural endings from nouns or gerund ending from
verbs).11 The contribution of CatVar is in its linking of
words related derivationally not inflectionally. Work by
(Krovetz, 1993) demonstrates an improved performance
with derivational stemming over the Porter stemmer most
of the time.
</bodyText>
<sectionHeader confidence="0.990527" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999969583333333">
We have presented our approach to constructing and eval-
uating a new large-scale database containing categorial
variations of English words. In addition, we have de-
scribed different applications for which it has proven use-
ful. Our evaluation indicates that CatVar has coverage
and accuracy of over 80% (F-score) and also that the
database improves the linkability of Porter stemmer by
about 30%. These findings are significant contributions
to several different communities, including Information
Retrieval and Machine Translation.
Future work includes improving the word-cluster ra-
tio and absorbing more of the single-word clusters into
existing clusters or other single-word clusters. We are
also considering enrichment of the clusters with types of
derivational relations such as “nominal-event” or “doer”
to complement part-of-speech labels. Other lexical
semantic features such telicity, sentience and change-
of-state can also be induced from morphological cues
(Light, 1996).
Additionally, we are interested in measuring the ap-
plied contribution of using the CatVar in natural-language
applications such as Information Retrieval. And finally,
we intend to incorporate CatVar into new applications
such as parallel corpus word alignment.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.866224">
This work has been supported, in part, by ONR MURI
Contract FCPO.810548265, Mitre Contract 010418-
7712, and NSF CISE Research Infrastructure Award
EIA0130422. We would like to thank all the annotators
who participated in the evaluation of the database.
viewed as a weak link in our comparison since it does not pro-
vide a deep analysis as would be produced by morphological
analysis systems. However, we have found that most morpho-
logical analyzers, including ones with large-scale coverage such
as the Xtag system (Karp et al., 1992), address inflectional—not
derivational—morphology; thus, their basis for comparison is
even weaker than would be provided by the Porter stemmer.
&amp;quot;This is, in fact, the approach used in the HeadGen and
DUSTer applications described above.
</bodyText>
<sectionHeader confidence="0.969758" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999799195488722">
E.L. Antworth. 1990. PC-KIMMO: A Two-Level Proces-
sor for Morphological Analysis. Dallas Summer Insti-
tute of Linguistics.
S. Bangalore and O. Rambow. 2000. Exploiting a proba-
bilistic hierarchical model for generation.
Marine Carpuat, Grace Ngai, Pascale Fung, and Ken-
neth Church. 2002. Creating a Bilingual Ontology:
A Corpus-Based Approach for Aligning WordNet and
HowNet. In Proceedings of the 1st Global WordNet
Conference, Mysore, India.
D. Cruse. 1986. Lexical Semantics. Cambridge Univer-
sity Press.
Zhendong Dong. 2000. HowNet Chinese-English Con-
ceptual Database. Technical Report Online Software
Database, Released at ACL. http://www.keenage.com.
Bonnie J. Dorr, Gina-Anne Levow, and Dekang Lin.
2000. Building a Chinese-English Mapping between
Verb Concepts for Multilingual Applications. In Pro-
ceedings of the Fourth Conference of the Associa-
tion for Machine Translation in the Americas (AMTA),
Cuernavaca, Mexico, pages 1–12.
Bonnie J. Dorr, Lisa Pearl, Rebecca Hwa, and Nizar
Habash. 2002. DUSTer: A Method for Unravel-
ing Cross-Language Divergences for Statistical Word-
Level Alignment. In Proceedings of the Fifth Confer-
ence of the Association for Machine Translation in the
Americas, AMTA-2002, Tiburon, California.
Bonnie J. Dorr. 2001. LCS Verb Database. Technical
Report Online Software Database, University of Mary-
land, College Park, MD. http://www.umiacs.umd.edu/
˜bonnie/LCS Database Docmentation.html.
Christiane Fellbaum. 1998. WordNet: An
Electronic Lexical Database. MIT Press.
http://www.cogsci.princeton.edu/˜wn [2000, Septem-
ber 7].
Rebecca Green, Lisa Pearl, Bonnie J. Dorr, and Philip
Resnik. 2001. Mapping WordNet Senses to a Lexical
Database of Verbs. In Proceedings of the 39th Annual
Meeting of the Association for Computational Linguis-
tics, pages 244–251, Toulouse, France.
Nizar Habash and Bonnie J. Dorr. 2002. Handling
Translation Divergences: Combining Statistical and
Symbolic Techniques in Generation-Heavy Machine
Translation. In Fifth Conference of the Association
for Machine Translation in the Americas, AMTA-2002,
Tiburon, California.
Nizar Habash, Bonnie J. Dorr, and David Traum. 2002.
Efficient Language Independent Generation from Lex-
ical Conceptual Structures. Machine Translation.
Nizar Habash. 2002. Generation-Heavy Machine Trans-
lation. In Proceedings of the International Natural
Language Generation Conference (INLG’02) Student
Session, New York.
M.A. Hearst. 1998. Automated Discovery of WordNet
Relations. In Christiane Fellbaum, editor, WordNet:
an Electronic Lexical Database. MIT Press.
David A. Hull and Gregory Grefenstette. 1996. Exper-
iments in Multilingual Information Retrieval. In Pro-
ceedings of the 19th Annual International ACM SIGIR
Conference on Research and Development in Informa-
tion Retrieval. http://www.xerox.fr /people /grenoble
/hull /papers /sigir96.ps.
Daniel Karp, Yves Schabes, Martin Zaidel, and Dania
Egedi. 1992. A Freely Available Wide Coverage
Morphological Analyzer for English. In Proceedings
of Fourteenth International Conference on Computa-
tional Linguistics (COLING-92), Nantes, France.
K. Knight and S. Luk. 1994. Building a Large Knowl-
edge Base for Machine Translation. In Proceedings of
AAAI-94.
R. Krovetz. 1993. Viewing Morphology as an Inference
Process,. In Proceedings of the Sixteenth Annual In-
ternational ACM SIGIR Conference on Research and
Development in Information Retrieval, pages 191–203.
Irene Langkilde and Kevin Knight. 1998. Generation
that Exploits Corpus-Based Statistical Knowledge. In
ACL/COLING 98, Proceedings of the 36th Annual
Meeting of the Association for Computational Linguis-
tics (joint with the 17th International Conference on
Computational Linguistics), pages 704–710, Montreal,
Canada.
Marc Light. 1996. Morphological Cues for Lexical Se-
mantics. In Proceedings of the 34th Annual Meeting of
the Association for Computational Linguistics.
Catherine Macleod, Ralph Grishman, Adam Meyers,
Leslie Barrett, and Ruth Reeves. 1998. NOMLEX:
A Lexicon of Nominalizations. In Proceedings of EU-
RALEX’98, Liege, Belgium.
Mitchell Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a Large Annotated
Corpus of English: the Penn Treebank. Computational
Linguistics, 19(2):313–330.
Igor Mel’ˇcuk. 1988. Dependency Syntax: Theory and
Practice. State University of New York Press, New
York.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
Bleu: a Method for Automatic Evaluation of Machine
Translation. In Proceedings ofAssociation of Compu-
tational Linguistics, Philadelphia, PA.
M.F. Porter. 1980. An algorithm for suffix stripping.
Program, 14(3):130–137.
P. Procter. 1983. Longman Dictionary of Contempo-
rary English: Computer Codes for the Definition Space
Other than the Subject Field. Longman Group LTD.
Margarita Alonso Ramos, Agnes Tutin, and Guy La-
palme. 1994. Lexical Functions of the Explanatory
Combinatorial Dictionary for Lexicalization in Text
Generation. In Patrick Saint-Dizier and Evelyne Vie-
gas, editors, Computational Lexical Semantics. Cam-
bridge University Press.
Philip Resnik. 1999. Disambiguating Noun Groupings
with Respect to WordNet Senses. In S. Armstrong,
K. Church, P. Isabelle, S. Manzi, E. Tzoukermann, and
D. Yarowsky, editors, Natural Language Processing
Using Very Large Corpora, pages 77–98. Kluwer Aca-
demic, Dordrecht.
J. Veronis. 1998. A study of polysemy judgements
and inter-annotator agreement. In Programme and ad-
vanced papers of the Senseval workshop, Herstmon-
ceux Castle, England.
Ellen M. Voorhees. 1993. Using WordNet to Disam-
biguate Word Senses for Text Retrieval. In Robert
Korfhage, Edie Rasmussen, and Peter Willett, edi-
tors, Proceedings of the Sixteenth Annual International
ACM SIGIR Conference on Research and Development
in Information Retrieval, pages 171–180. ACM, June.
Jinxi Xu and W. Bruce Croft. 1998. Corpus-based
stemming using cooccurrence of word variants. ACM
Transactions on Information Systems, 16(1):61–81.
David M. Zajic, Bonnie J. Dorr, and Rich Schwartz.
2002. Automatic headline generation for newspaper
stories. In Proceedings of the ACL-2002 Workshop on
Text Summarization, Philadelphia, PA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.349177">
<note confidence="0.907344666666667">Proceedings of HLT-NAACL 2003 Main Papers , pp. 17-23 Edmonton, May-June 2003</note>
<title confidence="0.92915">A Categorial Variation Database for English</title>
<author confidence="0.681412">Nizar</author>
<affiliation confidence="0.988649">Institute for Advanced Computer University of</affiliation>
<address confidence="0.982549">College Park, MD</address>
<email confidence="0.99155">habash@umiacs.umd.edu</email>
<author confidence="0.819365">Bonnie</author>
<affiliation confidence="0.9976775">Institute for Advanced Computer University of</affiliation>
<address confidence="0.984271">College Park, MD</address>
<email confidence="0.999282">bonnie@umiacs.umd.edu</email>
<abstract confidence="0.995506909090909">We describe our approach to the construction and evaluation of a large-scale database called “CatVar” which contains categorial variations of English lexemes. Due to the prevalence of cross-language categorial variation in multilingual applications, our categorial-variation resource may serve as an integral part of a diverse range of natural language applications. Thus, the research reported herein overlaps heavily with that of the machine-translation, lexicon-construction, and information-retrieval communities. We apply the information-retrieval metrics of precision and recall to evaluate the accuracy and coverage of our database with respect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E L Antworth</author>
</authors>
<title>PC-KIMMO: A Two-Level Processor for Morphological Analysis. Dallas Summer Institute of Linguistics.</title>
<date>1990</date>
<contexts>
<context position="8433" citStr="Antworth, 1990" startWordPosition="1263" endWordPosition="1264">his same stem for communist or communicable (stemmed to and respectively).2 Another example is the expansionist Nitrogen morphological generator, where the morphological feature applied to returns eleven variations including ,and .Only two are correct ( and 3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al., 1998), Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation. The research repo</context>
</contexts>
<marker>Antworth, 1990</marker>
<rawString>E.L. Antworth. 1990. PC-KIMMO: A Two-Level Processor for Morphological Analysis. Dallas Summer Institute of Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
</authors>
<title>Exploiting a probabilistic hierarchical model for generation.</title>
<date>2000</date>
<contexts>
<context position="4567" citStr="Bangalore and Rambow, 2000" startWordPosition="682" endWordPosition="685">identity, overlap, synonymy and antonymy) (Cruse, 1986). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of crosscategorial links, such as verb-noun or noun-adjective relations. Mel’ˇcuk approaches lexical relations by defining a lexical combinatorial zone that specifies semantically related lexemes through Lexical Functions (LF). These functions define a correspondence between a key lexical item and a set of related lexical items (Mel’ˇcuk, 1988). There are two types of functions: paradigmatic and syntagmatic (Ramos et al., 1994). Paradigmatic LFs associate a lexical item with related lexical items. The relation can be sema</context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>S. Bangalore and O. Rambow. 2000. Exploiting a probabilistic hierarchical model for generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Grace Ngai</author>
<author>Pascale Fung</author>
<author>Kenneth Church</author>
</authors>
<title>Creating a Bilingual Ontology: A Corpus-Based Approach for Aligning WordNet and HowNet.</title>
<date>2002</date>
<booktitle>In Proceedings of the 1st Global WordNet Conference,</booktitle>
<location>Mysore, India.</location>
<contexts>
<context position="1585" citStr="Carpuat et al., 2002" startWordPosition="221" endWordPosition="224">ate the accuracy and coverage of our database with respect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely recognized through its future incorporation into additional NLP applications. A categorial variation of a word wi</context>
</contexts>
<marker>Carpuat, Ngai, Fung, Church, 2002</marker>
<rawString>Marine Carpuat, Grace Ngai, Pascale Fung, and Kenneth Church. 2002. Creating a Bilingual Ontology: A Corpus-Based Approach for Aligning WordNet and HowNet. In Proceedings of the 1st Global WordNet Conference, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cruse</author>
</authors>
<title>Lexical Semantics.</title>
<date>1986</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3995" citStr="Cruse, 1986" startWordPosition="591" endWordPosition="592">l relations are either hierarchical taxonomic relations (such as hypernymy, hyponymy and entailments) or non-hierarchical congruence rela&apos;It is the intention of the WordNet 1.7 developers to include such information in their next version, but only for nouns and verbs (Christiane Fellbaum, pc.), not other pairings such as noun-adjective, verb-preposition relationships. Discussions are currently underway for sharing the CatVar database with WordNet developers for more rapid development, extension, and mutual validation of both resources. tions (such as identity, overlap, synonymy and antonymy) (Cruse, 1986). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these pr</context>
</contexts>
<marker>Cruse, 1986</marker>
<rawString>D. Cruse. 1986. Lexical Semantics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
</authors>
<title>HowNet Chinese-English Conceptual Database.</title>
<date>2000</date>
<booktitle>Online Software Database, Released at ACL. http://www.keenage.com.</booktitle>
<tech>Technical Report</tech>
<contexts>
<context position="1498" citStr="Dong, 2000" startWordPosition="207" endWordPosition="208">s. We apply the information-retrieval metrics of precision and recall to evaluate the accuracy and coverage of our database with respect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely recognized through its fut</context>
</contexts>
<marker>Dong, 2000</marker>
<rawString>Zhendong Dong. 2000. HowNet Chinese-English Conceptual Database. Technical Report Online Software Database, Released at ACL. http://www.keenage.com.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Gina-Anne Levow</author>
<author>Dekang Lin</author>
</authors>
<title>Building a Chinese-English Mapping between Verb Concepts for Multilingual Applications.</title>
<date>2000</date>
<booktitle>In Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<pages>1--12</pages>
<location>Cuernavaca, Mexico,</location>
<contexts>
<context position="1604" citStr="Dorr et al., 2000" startWordPosition="225" endWordPosition="228">overage of our database with respect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely recognized through its future incorporation into additional NLP applications. A categorial variation of a word with a certain partof</context>
</contexts>
<marker>Dorr, Levow, Lin, 2000</marker>
<rawString>Bonnie J. Dorr, Gina-Anne Levow, and Dekang Lin. 2000. Building a Chinese-English Mapping between Verb Concepts for Multilingual Applications. In Proceedings of the Fourth Conference of the Association for Machine Translation in the Americas (AMTA), Cuernavaca, Mexico, pages 1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Lisa Pearl</author>
<author>Rebecca Hwa</author>
<author>Nizar Habash</author>
</authors>
<title>DUSTer: A Method for Unraveling Cross-Language Divergences for Statistical WordLevel Alignment.</title>
<date>2002</date>
<booktitle>In Proceedings of the Fifth Conference of the Association for Machine Translation in the Americas, AMTA-2002,</booktitle>
<location>Tiburon, California.</location>
<contexts>
<context position="14360" citStr="Dorr et al., 2002" startWordPosition="2177" endWordPosition="2180">alized event). A recent study indicates that there is a significant improvement in Bleu scores (using human-generated headlines as our references) when running headline generation with the CatVar filter:7 HeadGen with CatVar filter: 0.1740 HeadGen with no CatVar filter: 0.1687 This quantitative distinction correlates with humanperceived differences, e.g., between the two headlines Washingtoniansfight over drugs and In the nation’s capital (generated for the same story—with and without CatVar, respectively). 4.3 DUSTer DUSTer—Divergence Unraveling for Statistical Translation—was introduced in (Dorr et al., 2002). In this system, common divergence types are systematically identified and English sentences are transformed to bear a closer resemblance to that of another language using a mapping referred to as -to- . The objective is to enable more accurate alignment and projection of dependency trees in another language without requiring any training on dependency-tree data in that language. The CatVar database has been incorporated into two components of the DUSTer system: (1) In the -tomapping, e.g., the transformation from kick to LightVB kick (corresponding to the English/Spanish divergence 6The othe</context>
</contexts>
<marker>Dorr, Pearl, Hwa, Habash, 2002</marker>
<rawString>Bonnie J. Dorr, Lisa Pearl, Rebecca Hwa, and Nizar Habash. 2002. DUSTer: A Method for Unraveling Cross-Language Divergences for Statistical WordLevel Alignment. In Proceedings of the Fifth Conference of the Association for Machine Translation in the Americas, AMTA-2002, Tiburon, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>LCS Verb Database.</title>
<date>2001</date>
<tech>Technical Report</tech>
<institution>Online Software Database, University of Maryland, College Park, MD.</institution>
<note>http://www.umiacs.umd.edu/ ˜bonnie/LCS Database Docmentation.html.</note>
<contexts>
<context position="8272" citStr="Dorr, 2001" startWordPosition="1239" endWordPosition="1240">generation/under-generation. Consider, for example, the Porter stemmer, which stems commune , communication and communism to . And yet, it does not produce this same stem for communist or communicable (stemmed to and respectively).2 Another example is the expansionist Nitrogen morphological generator, where the morphological feature applied to returns eleven variations including ,and .Only two are correct ( and 3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al., 1998), Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database o</context>
</contexts>
<marker>Dorr, 2001</marker>
<rawString>Bonnie J. Dorr. 2001. LCS Verb Database. Technical Report Online Software Database, University of Maryland, College Park, MD. http://www.umiacs.umd.edu/ ˜bonnie/LCS Database Docmentation.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>http://www.cogsci.princeton.edu/˜wn</location>
<contexts>
<context position="1474" citStr="Fellbaum, 1998" startWordPosition="203" endWordPosition="204">rmation-retrieval communities. We apply the information-retrieval metrics of precision and recall to evaluate the accuracy and coverage of our database with respect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely re</context>
<context position="4092" citStr="Fellbaum, 1998" startWordPosition="605" endWordPosition="606">lments) or non-hierarchical congruence rela&apos;It is the intention of the WordNet 1.7 developers to include such information in their next version, but only for nouns and verbs (Christiane Fellbaum, pc.), not other pairings such as noun-adjective, verb-preposition relationships. Discussions are currently underway for sharing the CatVar database with WordNet developers for more rapid development, extension, and mutual validation of both resources. tions (such as identity, overlap, synonymy and antonymy) (Cruse, 1986). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of crosscategorial links, such as verb-noun or noun-</context>
<context position="9148" citStr="Fellbaum, 1998" startWordPosition="1371" endWordPosition="1372"> and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation. The research reported herein is relevant to MT, IR, and lexicon construction. (LDOCE)3 (Procter, 1983), WordNet 1.6 (Fellbaum, 1998), and the Porter stemmer. The contribution of each of these sources is clearly labeled in the CatVar database, thus enabling the use of different cross-sections of the resource for different applications.4 Some of these resources were used to extract seed links between different words (Englex lexicon, NOMLEX and LDOCE). Others were used to provide a large-scale coverage of lexemes. In the case of the Brown Corpus, which doesn’t provide lexemes for its words, the Englex morphological analyzer was used together with the part of speech specified in the Penn Tree Bank to extract the lexeme form. T</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press. http://www.cogsci.princeton.edu/˜wn [2000, September 7].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Green</author>
<author>Lisa Pearl</author>
<author>Bonnie J Dorr</author>
<author>Philip Resnik</author>
</authors>
<title>Mapping WordNet Senses to a Lexical Database of Verbs.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>244--251</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="4474" citStr="Green et al., 2001" startWordPosition="667" endWordPosition="670">apid development, extension, and mutual validation of both resources. tions (such as identity, overlap, synonymy and antonymy) (Cruse, 1986). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of crosscategorial links, such as verb-noun or noun-adjective relations. Mel’ˇcuk approaches lexical relations by defining a lexical combinatorial zone that specifies semantically related lexemes through Lexical Functions (LF). These functions define a correspondence between a key lexical item and a set of related lexical items (Mel’ˇcuk, 1988). There are two types of functions: paradigmatic and syntagmatic (Ramos et al., 1994). P</context>
</contexts>
<marker>Green, Pearl, Dorr, Resnik, 2001</marker>
<rawString>Rebecca Green, Lisa Pearl, Bonnie J. Dorr, and Philip Resnik. 2001. Mapping WordNet Senses to a Lexical Database of Verbs. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics, pages 244–251, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Handling Translation Divergences: Combining Statistical and Symbolic Techniques in Generation-Heavy Machine Translation.</title>
<date>2002</date>
<booktitle>In Fifth Conference of the Association for Machine Translation in the Americas, AMTA-2002,</booktitle>
<location>Tiburon, California.</location>
<contexts>
<context position="15077" citStr="Habash and Dorr, 2002" startWordPosition="2286" endWordPosition="2289">re transformed to bear a closer resemblance to that of another language using a mapping referred to as -to- . The objective is to enable more accurate alignment and projection of dependency trees in another language without requiring any training on dependency-tree data in that language. The CatVar database has been incorporated into two components of the DUSTer system: (1) In the -tomapping, e.g., the transformation from kick to LightVB kick (corresponding to the English/Spanish divergence 6The other conditions on conflatability and some detailed examples are discussed in (Habash, 2002) and (Habash and Dorr, 2002). 7For details about the Bleu evaluation metric, see (Papineni et al., 2002). pair kick/dar patada); and (2) During an automatic markup phase prior to this transformation, where the particular -to- mapping is selected from a set of possibilities based on the 2 input sentences. For example, the rule V[CatVar=N] -&gt; LightVB N is selected for the transformation above by first checking that the verb V is associated with a word of category N in CatVar. Transforming divergent English sentences using this mechanism has been shown to facilitate word-level alignment by reducing the number of unaligned a</context>
</contexts>
<marker>Habash, Dorr, 2002</marker>
<rawString>Nizar Habash and Bonnie J. Dorr. 2002. Handling Translation Divergences: Combining Statistical and Symbolic Techniques in Generation-Heavy Machine Translation. In Fifth Conference of the Association for Machine Translation in the Americas, AMTA-2002, Tiburon, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Bonnie J Dorr</author>
<author>David Traum</author>
</authors>
<title>Efficient Language Independent Generation from Lexical Conceptual Structures. Machine Translation.</title>
<date>2002</date>
<contexts>
<context position="6265" citStr="Habash et al., 2002" startWordPosition="938" endWordPosition="941">scape) = narrow and Degradation(milk) = sour. Lexical Functions have been used in MT and Generation (e.g. (Ramos et al., 1994)). Although research on Lexical Functions provides an intriguing theoretical discussion, there are no large scale resources available for categorial variations induced by lexical functions. This lack of resources shouldn’t suggest that the problem is too trivial to be worthy of investigation or that a solution would not be a significant contribution. On the contrary, categorial variations are necessary for handling many NLP problems. For example, in the context of MT, (Habash et al., 2002) claims that 98% of all translation divergences (variations in how source and target languages structure meaning) involve some form of categorial variation. Moreover, most IR systems require some way to reduce variant words to common roots to improve the ability to match queries (Xu and Croft, 1998; Hull and Grefenstette, 1996; Krovetz, 1993). Given the lack of large-scale resources containing categorial variations, researchers frequently develop and use alternative algorithmic approximations of such a resource. These approximations can be divided into Reductionist (Analytical) or Expansionist</context>
</contexts>
<marker>Habash, Dorr, Traum, 2002</marker>
<rawString>Nizar Habash, Bonnie J. Dorr, and David Traum. 2002. Efficient Language Independent Generation from Lexical Conceptual Structures. Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Generation-Heavy Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Natural Language Generation Conference (INLG’02) Student Session,</booktitle>
<location>New York.</location>
<contexts>
<context position="12067" citStr="Habash, 2002" startWordPosition="1825" endWordPosition="1826">ssions as well as cluster length restrictions. The database is also available for researchers in perl/C and lisp searchable formats. Figure 2: Web Interface 4 Applications Our project is focused on resource building and evaluation. However, the CatVar database is relevant to a number of natural language applications, including generation for MT, headline generation, and cross-language divergence unraveling for bilingual alignment. Each of these are discussed below, in turn. 4.1 Generation-Heavy Machine Translation The Generation-Heavy Hybrid Machine Translation (GHMT) model was introduced in (Habash, 2002) to handle translation divergences between language pairs with asymmetrical (poor-source/rich-target) resources. The approach does not rely on a transfer lexicon or a common interlingual representation to map between divergent structural configurations from source to target language. Instead, different alternative structural configurations are over-generated and these are statistically ranked using a language model. 5This supplementary database includes 242 clusters for more than 230 verbs and 29 prepositions. Other examples of verb-preposition clusters include: avoid and away from ; enter and</context>
<context position="15049" citStr="Habash, 2002" startWordPosition="2283" endWordPosition="2284">English sentences are transformed to bear a closer resemblance to that of another language using a mapping referred to as -to- . The objective is to enable more accurate alignment and projection of dependency trees in another language without requiring any training on dependency-tree data in that language. The CatVar database has been incorporated into two components of the DUSTer system: (1) In the -tomapping, e.g., the transformation from kick to LightVB kick (corresponding to the English/Spanish divergence 6The other conditions on conflatability and some detailed examples are discussed in (Habash, 2002) and (Habash and Dorr, 2002). 7For details about the Bleu evaluation metric, see (Papineni et al., 2002). pair kick/dar patada); and (2) During an automatic markup phase prior to this transformation, where the particular -to- mapping is selected from a set of possibilities based on the 2 input sentences. For example, the rule V[CatVar=N] -&gt; LightVB N is selected for the transformation above by first checking that the verb V is associated with a word of category N in CatVar. Transforming divergent English sentences using this mechanism has been shown to facilitate word-level alignment by reduci</context>
</contexts>
<marker>Habash, 2002</marker>
<rawString>Nizar Habash. 2002. Generation-Heavy Machine Translation. In Proceedings of the International Natural Language Generation Conference (INLG’02) Student Session, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Automated Discovery of WordNet Relations.</title>
<date>1998</date>
<booktitle>WordNet: an Electronic Lexical Database.</booktitle>
<editor>In Christiane Fellbaum, editor,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1632" citStr="Hearst, 1998" startWordPosition="231" endWordPosition="232">ect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely recognized through its future incorporation into additional NLP applications. A categorial variation of a word with a certain partof-speech is a derivationally-</context>
</contexts>
<marker>Hearst, 1998</marker>
<rawString>M.A. Hearst. 1998. Automated Discovery of WordNet Relations. In Christiane Fellbaum, editor, WordNet: an Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Hull</author>
<author>Gregory Grefenstette</author>
</authors>
<title>Experiments in Multilingual Information Retrieval.</title>
<date>1996</date>
<booktitle>In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. http://www.xerox.fr</booktitle>
<contexts>
<context position="6593" citStr="Hull and Grefenstette, 1996" startWordPosition="989" endWordPosition="992">lack of resources shouldn’t suggest that the problem is too trivial to be worthy of investigation or that a solution would not be a significant contribution. On the contrary, categorial variations are necessary for handling many NLP problems. For example, in the context of MT, (Habash et al., 2002) claims that 98% of all translation divergences (variations in how source and target languages structure meaning) involve some form of categorial variation. Moreover, most IR systems require some way to reduce variant words to common roots to improve the ability to match queries (Xu and Croft, 1998; Hull and Grefenstette, 1996; Krovetz, 1993). Given the lack of large-scale resources containing categorial variations, researchers frequently develop and use alternative algorithmic approximations of such a resource. These approximations can be divided into Reductionist (Analytical) or Expansionist (Generative) approximations. The former focuses on the conversion of several surface forms into a common root. Stemmers such as the Porter stemmer (Porter, 1980) are a typical example. The latter, or expansionist approaches, overgenerate possibilities and rely on a statistical language model to rank/select among them. The mor</context>
</contexts>
<marker>Hull, Grefenstette, 1996</marker>
<rawString>David A. Hull and Gregory Grefenstette. 1996. Experiments in Multilingual Information Retrieval. In Proceedings of the 19th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. http://www.xerox.fr /people /grenoble /hull /papers /sigir96.ps.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Karp</author>
<author>Yves Schabes</author>
<author>Martin Zaidel</author>
<author>Dania Egedi</author>
</authors>
<title>A Freely Available Wide Coverage Morphological Analyzer for English.</title>
<date>1992</date>
<booktitle>In Proceedings of Fourteenth International Conference on Computational Linguistics (COLING-92),</booktitle>
<location>Nantes, France.</location>
<marker>Karp, Schabes, Zaidel, Egedi, 1992</marker>
<rawString>Daniel Karp, Yves Schabes, Martin Zaidel, and Dania Egedi. 1992. A Freely Available Wide Coverage Morphological Analyzer for English. In Proceedings of Fourteenth International Conference on Computational Linguistics (COLING-92), Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>S Luk</author>
</authors>
<title>Building a Large Knowledge Base for Machine Translation.</title>
<date>1994</date>
<booktitle>In Proceedings of AAAI-94.</booktitle>
<contexts>
<context position="4397" citStr="Knight and Luk, 1994" startWordPosition="655" endWordPosition="658">tly underway for sharing the CatVar database with WordNet developers for more rapid development, extension, and mutual validation of both resources. tions (such as identity, overlap, synonymy and antonymy) (Cruse, 1986). WordNet is the most well-developed and widely used lexical database of English (Fellbaum, 1998). In WordNet, both types of lexical relations are specified among words with the same part of speech (verbs, nouns, adjectives and adverbs). WordNet has been used by many researchers for different purposes ranging from the construction or extension of knowledge bases such as SENSUS (Knight and Luk, 1994) or the Lexical Conceptual Structure Verb Database (LVD) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of crosscategorial links, such as verb-noun or noun-adjective relations. Mel’ˇcuk approaches lexical relations by defining a lexical combinatorial zone that specifies semantically related lexemes through Lexical Functions (LF). These functions define a correspondence between a key lexical item and a set of related lexical items (Mel’ˇcuk, 1988). There are</context>
</contexts>
<marker>Knight, Luk, 1994</marker>
<rawString>K. Knight and S. Luk. 1994. Building a Large Knowledge Base for Machine Translation. In Proceedings of AAAI-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Krovetz</author>
</authors>
<title>Viewing Morphology as an Inference Process,.</title>
<date>1993</date>
<booktitle>In Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>191--203</pages>
<contexts>
<context position="6609" citStr="Krovetz, 1993" startWordPosition="993" endWordPosition="994">uggest that the problem is too trivial to be worthy of investigation or that a solution would not be a significant contribution. On the contrary, categorial variations are necessary for handling many NLP problems. For example, in the context of MT, (Habash et al., 2002) claims that 98% of all translation divergences (variations in how source and target languages structure meaning) involve some form of categorial variation. Moreover, most IR systems require some way to reduce variant words to common roots to improve the ability to match queries (Xu and Croft, 1998; Hull and Grefenstette, 1996; Krovetz, 1993). Given the lack of large-scale resources containing categorial variations, researchers frequently develop and use alternative algorithmic approximations of such a resource. These approximations can be divided into Reductionist (Analytical) or Expansionist (Generative) approximations. The former focuses on the conversion of several surface forms into a common root. Stemmers such as the Porter stemmer (Porter, 1980) are a typical example. The latter, or expansionist approaches, overgenerate possibilities and rely on a statistical language model to rank/select among them. The morphological gener</context>
<context position="8600" citStr="Krovetz, 1993" startWordPosition="1287" endWordPosition="1288">l feature applied to returns eleven variations including ,and .Only two are correct ( and 3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al., 1998), Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation. The research reported herein is relevant to MT, IR, and lexicon construction. (LDOCE)3 (Procter, 1983), WordNet 1.6 (Fellbaum, 1998), and the Porter stemmer. The contribution of each o</context>
<context position="22246" citStr="Krovetz, 1993" startWordPosition="3460" endWordPosition="3461">ribution of the CatVar database, compared to the Porter stemmer, particularly since this stemmer is an industry standard in the IR community.10 9F-score = . 10A reviewer points out that the Porter stemmer could be HungrinessN HungryAJ N N P C Hunger Hunger V C C C P C C It is important to point out that, for CatVar to be used in IR, it must be accompanied by an inflectional analyzer that reduces words to their lexeme form (removing plural endings from nouns or gerund ending from verbs).11 The contribution of CatVar is in its linking of words related derivationally not inflectionally. Work by (Krovetz, 1993) demonstrates an improved performance with derivational stemming over the Porter stemmer most of the time. 6 Conclusions and Future Work We have presented our approach to constructing and evaluating a new large-scale database containing categorial variations of English words. In addition, we have described different applications for which it has proven useful. Our evaluation indicates that CatVar has coverage and accuracy of over 80% (F-score) and also that the database improves the linkability of Porter stemmer by about 30%. These findings are significant contributions to several different co</context>
</contexts>
<marker>Krovetz, 1993</marker>
<rawString>R. Krovetz. 1993. Viewing Morphology as an Inference Process,. In Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 191–203.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that Exploits Corpus-Based Statistical Knowledge. In</title>
<date>1998</date>
<booktitle>ACL/COLING 98, Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (joint with the 17th International Conference on Computational Linguistics),</booktitle>
<pages>704--710</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="7293" citStr="Langkilde and Knight, 1998" startWordPosition="1089" endWordPosition="1092">gorial variations, researchers frequently develop and use alternative algorithmic approximations of such a resource. These approximations can be divided into Reductionist (Analytical) or Expansionist (Generative) approximations. The former focuses on the conversion of several surface forms into a common root. Stemmers such as the Porter stemmer (Porter, 1980) are a typical example. The latter, or expansionist approaches, overgenerate possibilities and rely on a statistical language model to rank/select among them. The morphological generator in Nitrogen is an example of such an approximation (Langkilde and Knight, 1998). There are two types of problems with approximations of this type: (1) They are uni-directional and thus limited in usability—A stemmer cannot be used for generation and a morphological overgenerator cannot be used for stemming; (2) The crude approximating nature of such systems cause many problems in quality and efficiency from over-stemming/under-stemming or overgeneration/under-generation. Consider, for example, the Porter stemmer, which stems commune , communication and communism to . And yet, it does not produce this same stem for communist or communicable (stemmed to and respectively).2</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. Generation that Exploits Corpus-Based Statistical Knowledge. In ACL/COLING 98, Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics (joint with the 17th International Conference on Computational Linguistics), pages 704–710, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Light</author>
</authors>
<title>Morphological Cues for Lexical Semantics.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="23361" citStr="Light, 1996" startWordPosition="3620" endWordPosition="3621">Porter stemmer by about 30%. These findings are significant contributions to several different communities, including Information Retrieval and Machine Translation. Future work includes improving the word-cluster ratio and absorbing more of the single-word clusters into existing clusters or other single-word clusters. We are also considering enrichment of the clusters with types of derivational relations such as “nominal-event” or “doer” to complement part-of-speech labels. Other lexical semantic features such telicity, sentience and changeof-state can also be induced from morphological cues (Light, 1996). Additionally, we are interested in measuring the applied contribution of using the CatVar in natural-language applications such as Information Retrieval. And finally, we intend to incorporate CatVar into new applications such as parallel corpus word alignment. Acknowledgments This work has been supported, in part, by ONR MURI Contract FCPO.810548265, Mitre Contract 010418- 7712, and NSF CISE Research Infrastructure Award EIA0130422. We would like to thank all the annotators who participated in the evaluation of the database. viewed as a weak link in our comparison since it does not provide a</context>
</contexts>
<marker>Light, 1996</marker>
<rawString>Marc Light. 1996. Morphological Cues for Lexical Semantics. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Macleod</author>
<author>Ralph Grishman</author>
<author>Adam Meyers</author>
<author>Leslie Barrett</author>
<author>Ruth Reeves</author>
</authors>
<title>NOMLEX: A Lexicon of Nominalizations.</title>
<date>1998</date>
<booktitle>In Proceedings of EURALEX’98, Liege,</booktitle>
<location>Belgium.</location>
<contexts>
<context position="8464" citStr="Macleod et al., 1998" startWordPosition="1266" endWordPosition="1269">st or communicable (stemmed to and respectively).2 Another example is the expansionist Nitrogen morphological generator, where the morphological feature applied to returns eleven variations including ,and .Only two are correct ( and 3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al., 1998), Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation. The research reported herein is relevant to MT, </context>
</contexts>
<marker>Macleod, Grishman, Meyers, Barrett, Reeves, 1998</marker>
<rawString>Catherine Macleod, Ralph Grishman, Adam Meyers, Leslie Barrett, and Ruth Reeves. 1998. NOMLEX: A Lexicon of Nominalizations. In Proceedings of EURALEX’98, Liege, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="8341" citStr="Marcus et al., 1993" startWordPosition="1249" endWordPosition="1252">er stemmer, which stems commune , communication and communism to . And yet, it does not produce this same stem for communist or communicable (stemmed to and respectively).2 Another example is the expansionist Nitrogen morphological generator, where the morphological feature applied to returns eleven variations including ,and .Only two are correct ( and 3 Building the CatVar The CatVar database was developed using a combination of resources and algorithms including the Lexical Conceptual Structure (LCS) Verb and Preposition Databases (Dorr, 2001), the Brown Corpus section of the Penn Treebank (Marcus et al., 1993), an English morphological analysis lexicon developed for PC-Kimmo (Englex) (Antworth, 1990), NOMLEX (Macleod et al., 1998), Longman Dictionary of Contemporary English 2For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and r</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: the Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor Mel’ˇcuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>New York.</location>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>Igor Mel’ˇcuk. 1988. Dependency Syntax: Theory and Practice. State University of New York Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofAssociation of Computational Linguistics,</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="15153" citStr="Papineni et al., 2002" startWordPosition="2298" endWordPosition="2301">g a mapping referred to as -to- . The objective is to enable more accurate alignment and projection of dependency trees in another language without requiring any training on dependency-tree data in that language. The CatVar database has been incorporated into two components of the DUSTer system: (1) In the -tomapping, e.g., the transformation from kick to LightVB kick (corresponding to the English/Spanish divergence 6The other conditions on conflatability and some detailed examples are discussed in (Habash, 2002) and (Habash and Dorr, 2002). 7For details about the Bleu evaluation metric, see (Papineni et al., 2002). pair kick/dar patada); and (2) During an automatic markup phase prior to this transformation, where the particular -to- mapping is selected from a set of possibilities based on the 2 input sentences. For example, the rule V[CatVar=N] -&gt; LightVB N is selected for the transformation above by first checking that the verb V is associated with a word of category N in CatVar. Transforming divergent English sentences using this mechanism has been shown to facilitate word-level alignment by reducing the number of unaligned and multiplyaligned words. 5 Evaluation This section includes two evaluations</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings ofAssociation of Computational Linguistics, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Porter</author>
</authors>
<title>An algorithm for suffix stripping.</title>
<date>1980</date>
<journal>Program,</journal>
<volume>14</volume>
<issue>3</issue>
<contexts>
<context position="7027" citStr="Porter, 1980" startWordPosition="1052" endWordPosition="1053">iation. Moreover, most IR systems require some way to reduce variant words to common roots to improve the ability to match queries (Xu and Croft, 1998; Hull and Grefenstette, 1996; Krovetz, 1993). Given the lack of large-scale resources containing categorial variations, researchers frequently develop and use alternative algorithmic approximations of such a resource. These approximations can be divided into Reductionist (Analytical) or Expansionist (Generative) approximations. The former focuses on the conversion of several surface forms into a common root. Stemmers such as the Porter stemmer (Porter, 1980) are a typical example. The latter, or expansionist approaches, overgenerate possibilities and rely on a statistical language model to rank/select among them. The morphological generator in Nitrogen is an example of such an approximation (Langkilde and Knight, 1998). There are two types of problems with approximations of this type: (1) They are uni-directional and thus limited in usability—A stemmer cannot be used for generation and a morphological overgenerator cannot be used for stemming; (2) The crude approximating nature of such systems cause many problems in quality and efficiency from ov</context>
</contexts>
<marker>Porter, 1980</marker>
<rawString>M.F. Porter. 1980. An algorithm for suffix stripping. Program, 14(3):130–137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Procter</author>
</authors>
<title>Longman Dictionary of Contemporary English: Computer Codes for the Definition Space Other than the Subject Field.</title>
<date>1983</date>
<publisher>Longman Group LTD.</publisher>
<contexts>
<context position="9118" citStr="Procter, 1983" startWordPosition="1367" endWordPosition="1368">lish 2For a deeper discussion and classification of Porter stemmer’s errors, see (Krovetz, 1993). ). Such overgeneration multiplied out at different points in a sentence expands the search space exponentially, and given various cut-offs in the search algorithm, might even appear in some of the top ranked choices. Given these issues, our goal is to build a database of categorial variations that can be used with both expansionist and reductionist approaches without the cost of over/under-stemming/generation. The research reported herein is relevant to MT, IR, and lexicon construction. (LDOCE)3 (Procter, 1983), WordNet 1.6 (Fellbaum, 1998), and the Porter stemmer. The contribution of each of these sources is clearly labeled in the CatVar database, thus enabling the use of different cross-sections of the resource for different applications.4 Some of these resources were used to extract seed links between different words (Englex lexicon, NOMLEX and LDOCE). Others were used to provide a large-scale coverage of lexemes. In the case of the Brown Corpus, which doesn’t provide lexemes for its words, the Englex morphological analyzer was used together with the part of speech specified in the Penn Tree Bank</context>
</contexts>
<marker>Procter, 1983</marker>
<rawString>P. Procter. 1983. Longman Dictionary of Contemporary English: Computer Codes for the Definition Space Other than the Subject Field. Longman Group LTD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Margarita Alonso Ramos</author>
<author>Agnes Tutin</author>
<author>Guy Lapalme</author>
</authors>
<date>1994</date>
<booktitle>Lexical Functions of the Explanatory Combinatorial Dictionary for Lexicalization in Text Generation. In Patrick Saint-Dizier and Evelyne Viegas, editors, Computational Lexical Semantics.</booktitle>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5071" citStr="Ramos et al., 1994" startWordPosition="758" endWordPosition="761">) (Green et al., 2001) to the faking of meaning ambiguity as part of system evaluation (Bangalore and Rambow, 2000). In the context of these projects, one criticism of WordNet is its lack of crosscategorial links, such as verb-noun or noun-adjective relations. Mel’ˇcuk approaches lexical relations by defining a lexical combinatorial zone that specifies semantically related lexemes through Lexical Functions (LF). These functions define a correspondence between a key lexical item and a set of related lexical items (Mel’ˇcuk, 1988). There are two types of functions: paradigmatic and syntagmatic (Ramos et al., 1994). Paradigmatic LFs associate a lexical item with related lexical items. The relation can be semantic or syntactic. Semantic LFs include Synonym(calling) = vocation, Antonym(small) = big, and Generic(fruit) = apple. Syntactic LFs include DerivedNoun(expand)= expansion and Adjective(female) = feminine. Syntagmatic LFs specify collocations with a lexeme given a specified relationship. For example, there is a LF that returns a light verb associated with the LF’s key: Light-Verb(attention) = pay. Other LFs specify certain semantic associations such as Intensify-Qualifier(escape) = narrow and Degrad</context>
</contexts>
<marker>Ramos, Tutin, Lapalme, 1994</marker>
<rawString>Margarita Alonso Ramos, Agnes Tutin, and Guy Lapalme. 1994. Lexical Functions of the Explanatory Combinatorial Dictionary for Lexicalization in Text Generation. In Patrick Saint-Dizier and Evelyne Viegas, editors, Computational Lexical Semantics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Disambiguating Noun Groupings with Respect to WordNet Senses.</title>
<date>1999</date>
<booktitle>Natural Language Processing Using Very Large Corpora,</booktitle>
<pages>77--98</pages>
<editor>In S. Armstrong, K. Church, P. Isabelle, S. Manzi, E. Tzoukermann, and D. Yarowsky, editors,</editor>
<publisher>Kluwer Academic,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="1618" citStr="Resnik, 1999" startWordPosition="229" endWordPosition="230">base with respect to a human-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely recognized through its future incorporation into additional NLP applications. A categorial variation of a word with a certain partof-speech is a d</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Disambiguating Noun Groupings with Respect to WordNet Senses. In S. Armstrong, K. Church, P. Isabelle, S. Manzi, E. Tzoukermann, and D. Yarowsky, editors, Natural Language Processing Using Very Large Corpora, pages 77–98. Kluwer Academic, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Veronis</author>
</authors>
<title>A study of polysemy judgements and inter-annotator agreement.</title>
<date>1998</date>
<booktitle>In Programme and advanced papers of the Senseval workshop,</booktitle>
<location>Herstmonceux Castle, England.</location>
<contexts>
<context position="18035" citStr="Veronis, 1998" startWordPosition="2758" endWordPosition="2759">otators agreed out of all words. Even though there were six fine-grained classifications, the average inter-annotator agreement was high (80.75%). Many of the disagreements, however, resulted from the fine-grainedness of the options available to the annotators. In a second calculation of inter-annotator agreement, we simplified the annotators’ choices by placing them into three groups corresponding to Perfect (Perfect and Perfect-but), Not-sure (Not-sure and May-not-be-a-realword) and Wrong (Does-not-belong). This annotationgrouping approach is comparable to the clustering techniques used by (Veronis, 1998) to “super-tag” fine grained annotations. After grouping the annotations, average inter-annotator agreement rose up to 98.35%. The cluster modifications produced by each pair of annotators assigned to the same cluster were then combined automatically in an approximation to post-annotation inter-annotator discussion, which traditionally results in agreement: (1) If both annotators agreed on a category, then it stands; (2) One annotator overrides another in cases where one is more sure than the other (i.e., Perfect overrides Perfect-but-with-error/Not-sureand Wrong overrides Not-sure); (3) In ca</context>
</contexts>
<marker>Veronis, 1998</marker>
<rawString>J. Veronis. 1998. A study of polysemy judgements and inter-annotator agreement. In Programme and advanced papers of the Senseval workshop, Herstmonceux Castle, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Using WordNet to Disambiguate Word Senses for Text Retrieval.</title>
<date>1993</date>
<booktitle>Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>171--180</pages>
<editor>In Robert Korfhage, Edie Rasmussen, and Peter Willett, editors,</editor>
<publisher>ACM,</publisher>
<contexts>
<context position="1649" citStr="Voorhees, 1993" startWordPosition="233" endWordPosition="234">-produced gold standard. This evaluation reveals that the categorial database achieves a high degree of precision and recall. Additionally, we demonstrate that the database improves on the linkability of Porter stemmer by over 30%. 1 Introduction Natural Language Processing (NLP) applications may only be as good as the resources upon which they rely. Resources specifying the relations among lexical items such as WordNet (Fellbaum, 1998) and HowNet (Dong, 2000) (among others) have inspired the work of many researchers in NLP (Carpuat et al., 2002; Dorr et al., 2000; Resnik, 1999; Hearst, 1998; Voorhees, 1993). In this paper we introduce a new resource called CatVar which specifies the lexical relation Categorial Variation on a large scale for English. This resource has already been used effectively in a wide range of monolingual and multilingual NLP applications. Upon its first public release, CatVar will be freely available to the research community. We expect that the contribution of this resource will become more widely recognized through its future incorporation into additional NLP applications. A categorial variation of a word with a certain partof-speech is a derivationally-related word with</context>
</contexts>
<marker>Voorhees, 1993</marker>
<rawString>Ellen M. Voorhees. 1993. Using WordNet to Disambiguate Word Senses for Text Retrieval. In Robert Korfhage, Edie Rasmussen, and Peter Willett, editors, Proceedings of the Sixteenth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 171–180. ACM, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>W Bruce Croft</author>
</authors>
<title>Corpus-based stemming using cooccurrence of word variants.</title>
<date>1998</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="6564" citStr="Xu and Croft, 1998" startWordPosition="985" endWordPosition="988">cal functions. This lack of resources shouldn’t suggest that the problem is too trivial to be worthy of investigation or that a solution would not be a significant contribution. On the contrary, categorial variations are necessary for handling many NLP problems. For example, in the context of MT, (Habash et al., 2002) claims that 98% of all translation divergences (variations in how source and target languages structure meaning) involve some form of categorial variation. Moreover, most IR systems require some way to reduce variant words to common roots to improve the ability to match queries (Xu and Croft, 1998; Hull and Grefenstette, 1996; Krovetz, 1993). Given the lack of large-scale resources containing categorial variations, researchers frequently develop and use alternative algorithmic approximations of such a resource. These approximations can be divided into Reductionist (Analytical) or Expansionist (Generative) approximations. The former focuses on the conversion of several surface forms into a common root. Stemmers such as the Porter stemmer (Porter, 1980) are a typical example. The latter, or expansionist approaches, overgenerate possibilities and rely on a statistical language model to ra</context>
</contexts>
<marker>Xu, Croft, 1998</marker>
<rawString>Jinxi Xu and W. Bruce Croft. 1998. Corpus-based stemming using cooccurrence of word variants. ACM Transactions on Information Systems, 16(1):61–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Zajic</author>
<author>Bonnie J Dorr</author>
<author>Rich Schwartz</author>
</authors>
<title>Automatic headline generation for newspaper stories.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-2002 Workshop on Text Summarization,</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="13160" citStr="Zajic et al., 2002" startWordPosition="1989" endWordPosition="1993"> more than 230 verbs and 29 prepositions. Other examples of verb-preposition clusters include: avoid and away from ; enter and into ; and border and beside (or next to ). The CatVar database is used as one of the constraints on the structural expansion step. For example, to allow the conflation of verbs such as make or cause and an argument such as development , the first condition for conflatability is finding a verb categorial variant of the argument development . In this case the verb categorial variant is develop .6 4.2 Headline Generation The HeadGen headline generator was introduced in (Zajic et al., 2002) to create headlines automatically from newspaper text. The goal is to generate an informative headline (one that specifies the event and its participants) not just an indicative headline (which specifies the topic only). The system is implemented as a Hidden Markov Model enhanced with a postprocessor that filters out headlines that do not contain a verbal or nominalized event. This is achieved by verifying that there is at least one word in the generated headline that appears in CatVar as a V (a verbal event) or as a N whose verbal counterpart is in the same cluster (a nominalized event). A r</context>
</contexts>
<marker>Zajic, Dorr, Schwartz, 2002</marker>
<rawString>David M. Zajic, Bonnie J. Dorr, and Rich Schwartz. 2002. Automatic headline generation for newspaper stories. In Proceedings of the ACL-2002 Workshop on Text Summarization, Philadelphia, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>