<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026810">
<title confidence="0.922502">
Edinburgh-LTG: TempEval-2 System Description
</title>
<author confidence="0.999238">
Claire Grover, Richard Tobin, Beatrice Alex and Kate Byrne
</author>
<affiliation confidence="0.9336775">
University of Edinburgh
Edinburgh, United Kingdom
</affiliation>
<email confidence="0.932832">
{grover, richard, balex, kbyrne3}@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.992716" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9990467">
We describe the Edinburgh information
extraction system which we are currently
adapting for analysis of newspaper text
as part of the SYNC3 project. Our most
recent focus is geospatial and temporal
grounding of entities and it has been use-
ful to participate in TempEval-2 to mea-
sure the performance of our system and to
guide further development. We took part
in Tasks A and B for English.
</bodyText>
<sectionHeader confidence="0.988132" genericHeader="keywords">
1 Background
</sectionHeader>
<bodyText confidence="0.99994371875">
The Language Technology Group (LTG) at Edin-
burgh has been active in the field of information
extraction (IE) for a number of years. Up until re-
cently our main focus has been in biomedical IE
(Alex et al., 2008) but we have also been pursuing
projects in other domains, e.g. digitised histori-
cal documents (Grover et al., 2010) and we are
currently participants in the EU-funded SYNC3
project where our role is to analyse news arti-
cles and establish spatio-temporal and other re-
lations between news events. As a step towards
this goal, we have been extending and adapting
our IE pipeline to ground spatial and temporal en-
tities. We have developed the Edinburgh Geop-
arser for georeferencing documents and have eval-
uated our system against the SpatialML corpus,
as reported in Tobin et al. (2010). We are cur-
rently in the process of developing a rule-based
date and time grounding component and it is this
component that we used for Task A, which re-
quires systems to identify the extents of tempo-
ral named entities and provide their interpreta-
tion. The TempEval-2 data also contains event en-
tities and we have adapted the output of our in-
house chunker (Grover and Tobin, 2006) to iden-
tify events for Task B, which requires systems to
identify event denoting words and to compute a
range of attributes for them. In future work we will
adapt our machine-learning-based relation extrac-
tion component (Haddow, 2008) to recognise re-
lations between spatial and temporal entities and
event entities along the lines of the linking tasks.
</bodyText>
<sectionHeader confidence="0.949838" genericHeader="introduction">
2 The Edinburgh IE System
</sectionHeader>
<bodyText confidence="0.999910114285714">
Our IE system is a modular pipeline system built
around the LT-XML21 and LT-TTT22 toolsets.
Documents are converted into our internal doc-
ument format and are then passed through a se-
quence of linguistic components which each add
XML mark-up. Early stages identify paragraphs,
sentences and tokens. Part-of-speech (POS) tag-
ging is done using the C&amp;C tagger (Curran and
Clark, 2003a) and lemmatisation is done using
morpha (Minnen et al., 2000).
We use both rule-based and machine-learning
named entity recognition (NER) components, the
former implemented using LT-TTT2 and the lat-
ter using the C&amp;C maximum entropy NER tagger
(Curran and Clark, 2003b). We are experiment-
ing to find the best combination of the two dif-
ferent NER views but this is not an issue in the
case of date and time entities since we have taken
the decision to use the rule-based output for these.
The main motivation for this decision arises from
the need to ground (provide temporal values for)
these entities and the rules for the grounding are
most naturally implemented as an elaboration of
the rules for recognition.
Our IE pipeline also uses the LT-TTT2 chun-
ker to provide a very shallow syntactic analysis.
Figure 1 shows an example of the results of pro-
cessing at the point where the rule-based NER
and chunker have both applied. As can be seen
from Figure 1, a positive feature for TempEval-
2 is that the verb group analysis provides in-
formation about tense, aspect, voice, modality
and polarity which translate relatively straightfor-
wardly into the Task B attributes. The noun group
analysis provides verbal stem information (e.g.
</bodyText>
<footnote confidence="0.9983435">
1www.ltg.ed.ac.uk/software/ltxml2
2www.ltg.ed.ac.uk/software/lt-ttt2
</footnote>
<page confidence="0.979954">
333
</page>
<note confidence="0.441009">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 333–336,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.760565222222222">
&lt;s id=&amp;quot;s1&amp;quot;&gt;
&lt;ng&gt;
&lt;w p=&amp;quot;DT&amp;quot; id=&amp;quot;w13&amp;quot;&gt;The&lt;/w&gt;
&lt;w p=&amp;quot;NN&amp;quot; id=&amp;quot;w17&amp;quot; l=&amp;quot;announcement&amp;quot; vstem=&amp;quot;announce&amp;quot; headn=&amp;quot;yes&amp;quot;&gt;announcement&lt;/w&gt;
&lt;/ng&gt;
&lt;vg tense=&amp;quot;pres&amp;quot; voice=&amp;quot;pass&amp;quot; asp=&amp;quot;simple&amp;quot; modal=&amp;quot;yes&amp;quot; neg=&amp;quot;yes&amp;quot;&gt;
&lt;w p=&amp;quot;MD&amp;quot; id=&amp;quot;w30&amp;quot; pws=&amp;quot;yes&amp;quot; l=&amp;quot;must&amp;quot; neg=&amp;quot;yes&amp;quot;&gt;must&lt;/w&gt;
&lt;w p=&amp;quot;RB&amp;quot; id=&amp;quot;w35&amp;quot; pws=&amp;quot;yes&amp;quot; neg=&amp;quot;yes&amp;quot;&gt;not&lt;/w&gt;
&lt;w p=&amp;quot;VB&amp;quot; id=&amp;quot;w39&amp;quot; pws=&amp;quot;yes&amp;quot; l=&amp;quot;be&amp;quot;&gt;be&lt;/w&gt;
&lt;w p=&amp;quot;VBN&amp;quot; id=&amp;quot;w42&amp;quot; pws=&amp;quot;yes&amp;quot; l=&amp;quot;make&amp;quot; headv=&amp;quot;yes&amp;quot;&gt;made&lt;/w&gt;
&lt;/vg&gt;
&lt;ng&gt;
&lt;timex unit=&amp;quot;day&amp;quot; trel=&amp;quot;same&amp;quot; type=&amp;quot;date&amp;quot; id=&amp;quot;rb1&amp;quot;&gt;
&lt;w unit=&amp;quot;day&amp;quot; trel=&amp;quot;same&amp;quot; p=&amp;quot;NN&amp;quot; id=&amp;quot;w47&amp;quot; l=&amp;quot;today&amp;quot;&gt;today&lt;/w&gt;
&lt;/timex&gt;
&lt;/ng&gt;
&lt;w p=&amp;quot;.&amp;quot; id=&amp;quot;w52&amp;quot; sb=&amp;quot;true&amp;quot;&gt;.&lt;/w&gt;
&lt;/s&gt;
</figure>
<figureCaption confidence="0.994805">
Figure 1: Example of NER tagger and chunker output for the sentence “The announcement must not be
made today.”
</figureCaption>
<bodyText confidence="0.813057076923077">
vstem=&amp;quot;announce&amp;quot;) about nominalisations.
Various attributes are computed for &lt;timex&gt;
elements and these are used by a temporal resolu-
tion component to provide a grounding for them.
The final output of the IE pipeline contains entity
mark-up in “standoff” format where the entities
point at the word elements using ids. The date
and event entities for “made” and “today” are as
follows:
&lt;ent tense=&amp;quot;pres&amp;quot; voice=&amp;quot;pass&amp;quot; neg=&amp;quot;yes&amp;quot;
modal=&amp;quot;yes&amp;quot; asp=&amp;quot;simple&amp;quot; id=&amp;quot;ev1&amp;quot;
subtype=&amp;quot;make&amp;quot; type=&amp;quot;event&amp;quot;&gt;
&lt;parts&gt;
&lt;part ew=&amp;quot;w39&amp;quot; sw=&amp;quot;w39&amp;quot;&gt;made&lt;/part&gt;
&lt;/parts&gt;
&lt;/ent&gt;
&lt;ent wdaynum=&amp;quot;5&amp;quot; day=&amp;quot;Friday&amp;quot; date=&amp;quot;16&amp;quot;
month=&amp;quot;4&amp;quot; year=&amp;quot;2010&amp;quot; unit=&amp;quot;day&amp;quot;
day-number=&amp;quot;733877&amp;quot; trel=&amp;quot;same&amp;quot;
type=&amp;quot;date&amp;quot; id=&amp;quot;rb1&amp;quot;&gt;
&lt;parts&gt;
&lt;part ew=&amp;quot;w47&amp;quot; sw=&amp;quot;w47&amp;quot;&gt;today&lt;/part&gt;
&lt;/parts&gt;
&lt;/ent&gt;
The date entity has been grounded with respect
to the date of writing (16th April 2010). To do the
grounding we calculate a day-number value for
each date where the day number count starts from
1st January 1 AD. Using this unique day number
we are able to calculate the date for any given day
number as well as the day of the week. We use
the day number to perform simple arithmetic to
ground date expressions such as “last Monday”,
“the day after tomorrow” etc. Grounding informa-
tion is spread across the attributes for day, date,
month and year. A fully grounded date has a
value for all of these while an underspecified date,
e.g. “2009”, “March 13th”, “next year”, etc., only
has values for some of these attributes.
</bodyText>
<sectionHeader confidence="0.998719" genericHeader="method">
3 Adaptations for TempEval-2
</sectionHeader>
<bodyText confidence="0.999942588235294">
Our system has been developed independently of
TimeML or TempEval-2 and there is therefore a
gap between what our system outputs and what is
contained in the TempEval-2 data. In order to run
our system over the data we needed to convert it
into our XML input format while preserving the
tokenisation decisions from the original. Certain
tokenisation mismatches required that we extend
various rules to allow for alternative token bound-
aries, for example, we tokenise “wasn’t” as was +
n’t whereas the TempEval-2 data contains was
+ n + ’t or occasionally wasn + ’t.
Other adaptations fall broadly into two classes:
extension of our system to cover entities in
TempEval-2 that we didn’t previously recognise,
and mapping of our output to fit TempEval-2 re-
quirements.
</bodyText>
<subsectionHeader confidence="0.992893">
3.1 Extensions
</subsectionHeader>
<bodyText confidence="0.999976625">
The date and time entities that our system recog-
nises are more like the MUC7 TIMEX entities
(Chinchor, 1998) than TIMEX3 ones. In partic-
ular, we have focused on dates which can either
be fully grounded or which, though underspeci-
fied, can be grounded to a precise range, e.g. “last
month” can be grounded to a particular month and
year given a document creation date and it can be
precisely specified if we take it to express a range
from the first to last days of the month. TIMEX3
entities can be vaguer than this, for example, en-
tities of type DURATION such as “twenty years”,
“some time”, etc. can be recognised as denoting
a temporal period but cannot easily be grounded.
To align our output more closely to TempEval-
2, we added NER rules to recognise examples
</bodyText>
<page confidence="0.995414">
334
</page>
<bodyText confidence="0.999995825">
such as “a long time”, “recent years”, “the past”,
“years”, “some weeks”, “10 minutes”. In addition
we needed to compute appropriate information to
allow us to create TempEval-2 values such as P1W
(period of 1 week).
For event recognition, our initial system created
an event entity for every head verb and for ev-
ery head noun which was a nominalisation. This
simple approach goes a long way towards captur-
ing the TempEval-2 events but results in too many
false positives and false negatives for nouns. In
addition our system did not calculate the informa-
tion needed to compute the TempEval-2 class at-
tribute. To help improve performance we added
attributes to potential event entities based on look-
up in lexicons compiled from the training data and
from WordNet (Fellbaum, 1998). These attributes
contribute to the decision as to whether a noun
or verb chunk head should be an event entity or
not3. The lexicons derived from the training data
contain the stems of all the nouns which acted
more than once as events as well as information
about those predicates which occurred more than
once as class ASPECTUAL, I STATE, REPORT-
ING or STATE in the training data. Where look-
up succeeds for event, if class look-up also suc-
ceeds then the class attribute is set accordingly. If
class look-up fails, the default, OCCURRENCE,
is used. The WordNet derived lexicon contains in-
formation about whether the first sense of a noun
has event or state as a hypernym. As a result of the
lexical look-up stage, the noun “work”, for exam-
ple, is marked as having occurred in the training
data as an event and as having event as a hyper-
nym for its first sense. The conjunction of these
cause it to be considered to be an event entity. For
verbs, the only substantive change in our system
was to not consider as events all main verb uses
of “be” (be happy), “have” (have a meal) and “do”
(do the dishes).
</bodyText>
<subsectionHeader confidence="0.999238">
3.2 Mapping
</subsectionHeader>
<bodyText confidence="0.999118222222222">
For both timex and event entities the creation
of the extents files was a straightforward map-
ping. For the creation of the attributes files,
on the other hand, we used stylesheets to con-
struct appropriate values for the TempEval-2 at-
tributes based on the attributes in our output
XML. The construction of event attributes is not
overly complex: for example, where an event
entity is specified as tense=&amp;quot;nonfin&amp;quot; and
</bodyText>
<tableCaption confidence="0.71794925">
3Our system does not recognise adjective events. How-
ever, passive participles, which are sometimes treated as ad-
jectives in TempEval-2, are frequently treated as verbs in our
system and are therefore recognised.
</tableCaption>
<bodyText confidence="0.999957">
voice=&amp;quot;pass&amp;quot; the TempEval-2 tense attribute
is given the value PASTPART. For modality our
attribute only records whether a modal verb is
present or not, so it was necessary to set the
TempEval-2 modality attribute to the actual modal
verb inside the verb group.
For timex entities, a single value for the value
attribute had to be constructed from the values
of a set of attributes on our entity. For example,
the information in date=&amp;quot;16&amp;quot;, month=&amp;quot;4&amp;quot;
year=&amp;quot;2010&amp;quot; has to be converted to 2010-04-
16. For durations other attributes provide the rel-
evant information, for example for “two days” the
attributes unit=&amp;quot;day&amp;quot;, quty=&amp;quot;2&amp;quot; are used
to create the value P2D (period of 2 days).
</bodyText>
<sectionHeader confidence="0.984086" genericHeader="evaluation">
4 Evaluation and Error Analysis
</sectionHeader>
<bodyText confidence="0.9995682">
The recognition results for both timex and event
extents are shown in Table 1. For Task A (timex)
we achieved a close balance between precision and
recall, while for Task B (events) we erred towards
recall at some cost to precision.
</bodyText>
<table confidence="0.998607333333334">
Task Precision Recall F1
Task A 0.85 0.82 0.84
Task B 0.75 0.85 0.80
</table>
<tableCaption confidence="0.999709">
Table 1: Extent Results
</tableCaption>
<bodyText confidence="0.9996358">
For timex entities our false negatives were all
entities of the vaguest kind, for example, “10-
hour”, “currently”, “third-quarter”, “overnight”,
“the week”: these are ones which the original sys-
tem did not recognise and for which we added ex-
tra rules, though evidently we were not thorough
enough. The false positives were mostly of the
kind that would usually be a date entity but which
were not considered to be so in the key, for exam-
ple, “1969”, “Oct 25”, “now”, “the past”, “a few
days”. In two cases the system mistakenly identi-
fied numbers as times (“1.02”, “2.41”).
For event entities we had 73 false negatives.
Some of these were caused by verbs being
mistagged as nouns (“complies”, “stretch”, “suit”)
while others were nouns which didn’t occur in
the WordNet derived lexicon as events. There
were 143 event false positives. Some of these
are clearly wrong, for example, “destruction” in
“weapons of mass destruction” while others are
a consequence of the subtle distinctions that the
TempEval-2 guidelines make and which our shal-
low approach cannot easily mimic.
Table 2 shows the results for attribute detec-
tion for both tasks. In the case of timex attributes
</bodyText>
<page confidence="0.996502">
335
</page>
<table confidence="0.999655111111111">
Task Attribute Score
Task A type 0.84
value 0.63
Task B polarity 0.99
pos 0.97
modality 0.99
tense 0.92
aspect 0.98
class 0.76
</table>
<tableCaption confidence="0.998251">
Table 2: Attribute Results
</tableCaption>
<bodyText confidence="0.999939659574468">
there was a set of entities which had systematically
wrong values for both type and value: these were
dates such as “this week” and “last week”. These
should have had DATE as their type and a value
such as 1998-W19 to indicate exactly which week
in which year they denote. Our date grounding
does not currently cover the numbering of weeks
in a year and so it would not have been possible
to create appropriate values. Instead we incor-
rectly treated these entities as being of type DU-
RATION with value P1W. Many of the remaining
errors were value errors where the system resolved
relative dates as past references when they should
have been future or vice versa. For example, the
value for “Monday” in “He and Palestinian leader
Yasser Arafat meet separately Monday with ...”
should have been 1998-05-04 but our system in-
terpreted it as the past Monday, 1998-04-27. There
were a few cases where the value was correct but
insufficient, for example for “a year ago” the sys-
tem returned 1988 when it should have produced
1988-Q3.
Our scores for event attributes were high for all
attributes except for class. The high scoring at-
tributes were derived from the output of our chun-
ker and demonstrate the quality of this component.
There does not appear to be a particular pattern
behind the small number of errors for these at-
tributes except that errors for the pos attribute re-
flect POS tagger errors and there were some com-
bined tense and modality errors where “will” and
“would” should have been interpreted as future
tense but were instead treated as modals. The class
attribute represents information that our system
had not previously been designed to determine.
We computed the class attribute in a relatively
minimal way. Since the class value is OCCUR-
RENCE in nearly 60% of events in the training
data, we use this as the default but, as described in
Section 3, we override this for events which are in
our training data-derived lexicon as REPORTING,
ASPECTUAL, I STATE or STATE. We do not at-
tempt to assign the I ACTION class value and
nearly half of our class errors result from this. An-
other set of errors comes from missing REPORT-
ING events such as “alleging”, “telegraphed” and
“acknowledged”.
</bodyText>
<sectionHeader confidence="0.992143" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999386666666667">
The current phase of development of the Ed-
inburgh IE system is supported by the SYNC3
project (FP7-231854)4.
</bodyText>
<sectionHeader confidence="0.99916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999846268292683">
Beatrice Alex, Claire Grover, Barry Haddow, Mijail
Kabadjov, Ewan Klein, Michael Matthews, Richard
Tobin, and Xinglong Wang. 2008. Automating cu-
ration using a natural language processing pipeline.
Genome Biology, 9(Suppl 2).
Nancy A. Chinchor. 1998. Proceedings of the Sev-
enth Message Understanding Conference (MUC-7).
Fairfax, Virginia.
James R. Curran and Stephen Clark. 2003a. Inves-
tigating GIS and smoothing for maximum entropy
taggers. In Proceedings of the 11th Meeting of the
European Chapter of the Association for Compu-
tational Linguistics (EACL-03), pages 91–98. Bu-
dapest, Hungary.
James R. Curran and Stephen Clark. 2003b. Language
independent NER using a maximum entropy tagger.
In Proceedings of the 7th Conference on Natural
Language Learning, Edmonton, Alberta, Canada.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
MA.
Claire Grover and Richard Tobin. 2006. Rule-based
chunking and reusability. In Proceedings of the Fifth
International Conference on Language Resources
and Evaluation (LREC 2006).
Claire Grover, Richard Tobin, Kate Byrne, Matthew
Woollard, James Reid, Stuart Dunn, and Julian Ball.
2010. Use of the Edinburgh geoparser for georefer-
encing digitised historical collections. Phil. Trans.
R. Soc. A.
Barry Haddow. 2008. Using automated feature op-
timisation to create an adaptable relation extraction
system. In Proc. of BioNLP 2008, Columbus, Ohio.
Guido Minnen, John Carroll, and Darren Pearce. 2000.
Robust, applied morphological generation. In Pro-
ceedings of the 1st International Natural Language
Generation Conference, Mitzpe Ramon, Israel.
Richard Tobin, Claire Grover, Kate Byrne, James Reid,
and Jo Walsh. 2010. Evaluation of georeferencing.
In Proceedings of Workshop on Geographic Infor-
mation Retrieval (GIR’10).
</reference>
<footnote confidence="0.846327">
4http://www.sync3.eu/
</footnote>
<page confidence="0.996789">
336
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002714">
<title confidence="0.996075">Edinburgh-LTG: TempEval-2 System Description</title>
<author confidence="0.999836">Claire Grover</author>
<author confidence="0.999836">Richard Tobin</author>
<author confidence="0.999836">Beatrice Alex</author>
<author confidence="0.999836">Kate Byrne</author>
<affiliation confidence="0.999983">University of Edinburgh</affiliation>
<address confidence="0.929894">Edinburgh, United Kingdom</address>
<email confidence="0.948595">richard,balex,</email>
<abstract confidence="0.993750152941177">We describe the Edinburgh information extraction system which we are currently adapting for analysis of newspaper text as part of the SYNC3 project. Our most recent focus is geospatial and temporal grounding of entities and it has been useful to participate in TempEval-2 to measure the performance of our system and to guide further development. We took part in Tasks A and B for English. 1 Background The Language Technology Group (LTG) at Edinburgh has been active in the field of information extraction (IE) for a number of years. Up until recently our main focus has been in biomedical IE (Alex et al., 2008) but we have also been pursuing projects in other domains, e.g. digitised historical documents (Grover et al., 2010) and we are currently participants in the EU-funded SYNC3 project where our role is to analyse news articles and establish spatio-temporal and other relations between news events. As a step towards this goal, we have been extending and adapting our IE pipeline to ground spatial and temporal entities. We have developed the Edinburgh Geoparser for georeferencing documents and have evaluated our system against the SpatialML corpus, as reported in Tobin et al. (2010). We are currently in the process of developing a rule-based date and time grounding component and it is this component that we used for Task A, which requires systems to identify the extents of temporal named entities and provide their interpretation. The TempEval-2 data also contains event entities and we have adapted the output of our inhouse chunker (Grover and Tobin, 2006) to identify events for Task B, which requires systems to identify event denoting words and to compute a range of attributes for them. In future work we will our machine-learning-based relation extraction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks. 2 The Edinburgh IE System Our IE system is a modular pipeline system built the and toolsets. Documents are converted into our internal document format and are then passed through a sequence of linguistic components which each add XML mark-up. Early stages identify paragraphs, sentences and tokens. Part-of-speech (POS) tagging is done using the C&amp;C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al., 2000). We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&amp;C maximum entropy NER tagger (Curran and Clark, 2003b). We are experimenting to find the best combination of the two different NER views but this is not an issue in the case of date and time entities since we have taken the decision to use the rule-based output for these. The main motivation for this decision arises from the need to ground (provide temporal values for) these entities and the rules for the grounding are most naturally implemented as an elaboration of the rules for recognition. Our IE pipeline also uses the LT-TTT2 chunker to provide a very shallow syntactic analysis. Figure 1 shows an example of the results of processing at the point where the rule-based NER and chunker have both applied. As can be seen from Figure 1, a positive feature for TempEval- 2 is that the verb group analysis provides information about tense, aspect, voice, modality and polarity which translate relatively straightforwardly into the Task B attributes. The noun group analysis provides verbal stem information (e.g. 333 of the 5th International Workshop on Semantic Evaluation, ACL pages 333–336, Sweden, 15-16 July 2010. Association for Computational Linguistics &lt;s id=&amp;quot;s1&amp;quot;&gt; &lt;ng&gt; &lt;w p=&amp;quot;DT&amp;quot; id=&amp;quot;w13&amp;quot;&gt;The&lt;/w&gt; &lt;w p=&amp;quot;NN&amp;quot; id=&amp;quot;w17&amp;quot; l=&amp;quot;announcement&amp;quot; vstem=&amp;quot;announce&amp;quot; headn=&amp;quot;yes&amp;quot;&gt;announcement&lt;/w&gt; &lt;/ng&gt; &lt;vg tense=&amp;quot;pres&amp;quot; voice=&amp;quot;pass&amp;quot; asp=&amp;quot;simple&amp;quot; modal=&amp;quot;yes&amp;quot; neg=&amp;quot;yes&amp;quot;&gt; &lt;w p=&amp;quot;MD&amp;quot; id=&amp;quot;w30&amp;quot; pws=&amp;quot;yes&amp;quot; l=&amp;quot;must&amp;quot; neg=&amp;quot;yes&amp;quot;&gt;must&lt;/w&gt; &lt;w p=&amp;quot;RB&amp;quot; id=&amp;quot;w35&amp;quot; pws=&amp;quot;yes&amp;quot; neg=&amp;quot;yes&amp;quot;&gt;not&lt;/w&gt; &lt;w p=&amp;quot;VB&amp;quot; id=&amp;quot;w39&amp;quot; pws=&amp;quot;yes&amp;quot; l=&amp;quot;be&amp;quot;&gt;be&lt;/w&gt; &lt;w p=&amp;quot;VBN&amp;quot; id=&amp;quot;w42&amp;quot; pws=&amp;quot;yes&amp;quot; l=&amp;quot;make&amp;quot; headv=&amp;quot;yes&amp;quot;&gt;made&lt;/w&gt; &lt;/vg&gt; &lt;ng&gt; &lt;timex unit=&amp;quot;day&amp;quot; trel=&amp;quot;same&amp;quot; type=&amp;quot;date&amp;quot; id=&amp;quot;rb1&amp;quot;&gt; &lt;w unit=&amp;quot;day&amp;quot; trel=&amp;quot;same&amp;quot; p=&amp;quot;NN&amp;quot; id=&amp;quot;w47&amp;quot; l=&amp;quot;today&amp;quot;&gt;today&lt;/w&gt; &lt;/timex&gt; &lt;/ng&gt; &lt;w p=&amp;quot;.&amp;quot; id=&amp;quot;w52&amp;quot; sb=&amp;quot;true&amp;quot;&gt;.&lt;/w&gt; &lt;/s&gt; Figure 1: Example of NER tagger and chunker output for the sentence “The announcement must not be made today.” about nominalisations. attributes are computed for elements and these are used by a temporal resolution component to provide a grounding for them. The final output of the IE pipeline contains entity mark-up in “standoff” format where the entities point at the word elements using ids. The date and event entities for “made” and “today” are as follows: &lt;ent tense=&amp;quot;pres&amp;quot; voice=&amp;quot;pass&amp;quot; neg=&amp;quot;yes&amp;quot; modal=&amp;quot;yes&amp;quot; asp=&amp;quot;simple&amp;quot; id=&amp;quot;ev1&amp;quot; subtype=&amp;quot;make&amp;quot; type=&amp;quot;event&amp;quot;&gt; &lt;parts&gt; &lt;part ew=&amp;quot;w39&amp;quot; sw=&amp;quot;w39&amp;quot;&gt;made&lt;/part&gt; &lt;/parts&gt; &lt;/ent&gt; &lt;ent wdaynum=&amp;quot;5&amp;quot; day=&amp;quot;Friday&amp;quot; date=&amp;quot;16&amp;quot; month=&amp;quot;4&amp;quot; year=&amp;quot;2010&amp;quot; unit=&amp;quot;day&amp;quot; day-number=&amp;quot;733877&amp;quot; trel=&amp;quot;same&amp;quot; type=&amp;quot;date&amp;quot; id=&amp;quot;rb1&amp;quot;&gt; &lt;parts&gt; &lt;part ew=&amp;quot;w47&amp;quot; sw=&amp;quot;w47&amp;quot;&gt;today&lt;/part&gt; &lt;/parts&gt; &lt;/ent&gt; The date entity has been grounded with respect to the date of writing (16th April 2010). To do the we calculate a for each date where the day number count starts from 1st January 1 AD. Using this unique day number we are able to calculate the date for any given day number as well as the day of the week. We use the day number to perform simple arithmetic to ground date expressions such as “last Monday”, “the day after tomorrow” etc. Grounding informais spread across the attributes for A fully grounded date has a value for all of these while an underspecified date, e.g. “2009”, “March 13th”, “next year”, etc., only has values for some of these attributes. 3 Adaptations for TempEval-2 Our system has been developed independently of TimeML or TempEval-2 and there is therefore a gap between what our system outputs and what is contained in the TempEval-2 data. In order to run our system over the data we needed to convert it into our XML input format while preserving the tokenisation decisions from the original. Certain tokenisation mismatches required that we extend various rules to allow for alternative token boundfor example, we tokenise “wasn’t” as the TempEval-2 data contains occasionally Other adaptations fall broadly into two classes: extension of our system to cover entities in TempEval-2 that we didn’t previously recognise, and mapping of our output to fit TempEval-2 requirements. 3.1 Extensions The date and time entities that our system recognises are more like the MUC7 TIMEX entities (Chinchor, 1998) than TIMEX3 ones. In particular, we have focused on dates which can either be fully grounded or which, though underspecified, can be grounded to a precise range, e.g. “last month” can be grounded to a particular month and year given a document creation date and it can be precisely specified if we take it to express a range from the first to last days of the month. TIMEX3 entities can be vaguer than this, for example, entities of type DURATION such as “twenty years”, “some time”, etc. can be recognised as denoting a temporal period but cannot easily be grounded. To align our output more closely to TempEval- 2, we added NER rules to recognise examples 334 such as “a long time”, “recent years”, “the past”, “years”, “some weeks”, “10 minutes”. In addition we needed to compute appropriate information to us to create TempEval-2 values such as (period of 1 week). For event recognition, our initial system created an event entity for every head verb and for every head noun which was a nominalisation. This simple approach goes a long way towards capturing the TempEval-2 events but results in too many false positives and false negatives for nouns. In addition our system did not calculate the information needed to compute the TempEval-2 class attribute. To help improve performance we added attributes to potential event entities based on lookup in lexicons compiled from the training data and from WordNet (Fellbaum, 1998). These attributes contribute to the decision as to whether a noun or verb chunk head should be an event entity or The lexicons derived from the training data contain the stems of all the nouns which acted more than once as events as well as information about those predicates which occurred more than once as class ASPECTUAL, I STATE, REPORT- ING or STATE in the training data. Where lookup succeeds for event, if class look-up also succeeds then the class attribute is set accordingly. If class look-up fails, the default, OCCURRENCE, is used. The WordNet derived lexicon contains information about whether the first sense of a noun has event or state as a hypernym. As a result of the lexical look-up stage, the noun “work”, for example, is marked as having occurred in the training data as an event and as having event as a hypernym for its first sense. The conjunction of these cause it to be considered to be an event entity. For verbs, the only substantive change in our system was to not consider as events all main verb uses of “be” (be happy), “have” (have a meal) and “do” (do the dishes). 3.2 Mapping For both timex and event entities the creation of the extents files was a straightforward mapping. For the creation of the attributes files, on the other hand, we used stylesheets to construct appropriate values for the TempEval-2 attributes based on the attributes in our output XML. The construction of event attributes is not overly complex: for example, where an event is specified as system does not recognise adjective events. However, passive participles, which are sometimes treated as adjectives in TempEval-2, are frequently treated as verbs in our system and are therefore recognised. TempEval-2 tense attribute is given the value PASTPART. For modality our attribute only records whether a modal verb is present or not, so it was necessary to set the TempEval-2 modality attribute to the actual modal verb inside the verb group. For timex entities, a single value for the value attribute had to be constructed from the values of a set of attributes on our entity. For example, information in month=&amp;quot;4&amp;quot; to be converted to 2010-04- 16. For durations other attributes provide the relevant information, for example for “two days” the quty=&amp;quot;2&amp;quot; used to create the value P2D (period of 2 days). 4 Evaluation and Error Analysis The recognition results for both timex and event extents are shown in Table 1. For Task A (timex) we achieved a close balance between precision and recall, while for Task B (events) we erred towards recall at some cost to precision. Task Precision Recall F1 Task A 0.85 0.82 0.84 Task B 0.75 0.85 0.80 Table 1: Extent Results For timex entities our false negatives were all entities of the vaguest kind, for example, “10hour”, “currently”, “third-quarter”, “overnight”, “the week”: these are ones which the original system did not recognise and for which we added extra rules, though evidently we were not thorough enough. The false positives were mostly of the kind that would usually be a date entity but which were not considered to be so in the key, for example, “1969”, “Oct 25”, “now”, “the past”, “a few days”. In two cases the system mistakenly identified numbers as times (“1.02”, “2.41”). For event entities we had 73 false negatives. Some of these were caused by verbs being mistagged as nouns (“complies”, “stretch”, “suit”) while others were nouns which didn’t occur in the WordNet derived lexicon as events. There were 143 event false positives. Some of these are clearly wrong, for example, “destruction” in “weapons of mass destruction” while others are a consequence of the subtle distinctions that the TempEval-2 guidelines make and which our shallow approach cannot easily mimic. Table 2 shows the results for attribute detection for both tasks. In the case of timex attributes 335 Task Attribute Score Task A type 0.84 value 0.63 Task B polarity 0.99 pos 0.97 modality 0.99 tense 0.92 aspect 0.98 class 0.76 Table 2: Attribute Results there was a set of entities which had systematically wrong values for both type and value: these were dates such as “this week” and “last week”. These should have had DATE as their type and a value such as 1998-W19 to indicate exactly which week in which year they denote. Our date grounding does not currently cover the numbering of weeks in a year and so it would not have been possible to create appropriate values. Instead we incorrectly treated these entities as being of type DU- RATION with value P1W. Many of the remaining errors were value errors where the system resolved relative dates as past references when they should have been future or vice versa. For example, the value for “Monday” in “He and Palestinian leader Yasser Arafat meet separately Monday with ...” should have been 1998-05-04 but our system interpreted it as the past Monday, 1998-04-27. There were a few cases where the value was correct but insufficient, for example for “a year ago” the system returned 1988 when it should have produced 1988-Q3. Our scores for event attributes were high for all attributes except for class. The high scoring attributes were derived from the output of our chunker and demonstrate the quality of this component. There does not appear to be a particular pattern behind the small number of errors for these attributes except that errors for the pos attribute reflect POS tagger errors and there were some combined tense and modality errors where “will” and “would” should have been interpreted as future tense but were instead treated as modals. The class attribute represents information that our system had not previously been designed to determine. We computed the class attribute in a relatively minimal way. Since the class value is OCCUR- RENCE in nearly 60% of events in the training data, we use this as the default but, as described in Section 3, we override this for events which are in our training data-derived lexicon as REPORTING, ASPECTUAL, I STATE or STATE. We do not attempt to assign the I ACTION class value and nearly half of our class errors result from this. Another set of errors comes from missing REPORT- ING events such as “alleging”, “telegraphed” and “acknowledged”.</abstract>
<note confidence="0.827216222222222">Acknowledgements The current phase of development of the Edinburgh IE system is supported by the SYNC3 References Beatrice Alex, Claire Grover, Barry Haddow, Mijail Kabadjov, Ewan Klein, Michael Matthews, Richard Tobin, and Xinglong Wang. 2008. Automating curation using a natural language processing pipeline. 9(Suppl 2). A. Chinchor. 1998. of the Sev- Message Understanding Conference Fairfax, Virginia. James R. Curran and Stephen Clark. 2003a. Investigating GIS and smoothing for maximum entropy In of the 11th Meeting of the European Chapter of the Association for Compu- Linguistics pages 91–98. Budapest, Hungary. James R. Curran and Stephen Clark. 2003b. Language independent NER using a maximum entropy tagger. of the 7th Conference on Natural Edmonton, Alberta, Canada. Fellbaum, editor. 1998. An Elec- Lexical MIT Press, Cambridge, MA. Claire Grover and Richard Tobin. 2006. Rule-based and reusability. In of the Fifth</note>
<title confidence="0.9432385">International Conference on Language Resources Evaluation (LREC</title>
<author confidence="0.7836685">Claire Grover</author>
<author confidence="0.7836685">Richard Tobin</author>
<author confidence="0.7836685">Kate Byrne</author>
<author confidence="0.7836685">Matthew Woollard</author>
<author confidence="0.7836685">James Reid</author>
<author confidence="0.7836685">Stuart Dunn</author>
<author confidence="0.7836685">Julian Ball</author>
<note confidence="0.728850866666667">2010. Use of the Edinburgh geoparser for georeferdigitised historical collections. Trans. Soc. Barry Haddow. 2008. Using automated feature optimisation to create an adaptable relation extraction In of BioNLP Columbus, Ohio. Guido Minnen, John Carroll, and Darren Pearce. 2000. applied morphological generation. In Proceedings of the 1st International Natural Language Mitzpe Ramon, Israel. Richard Tobin, Claire Grover, Kate Byrne, James Reid, and Jo Walsh. 2010. Evaluation of georeferencing. of Workshop on Geographic Infor- Retrieval 336</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Beatrice Alex</author>
<author>Claire Grover</author>
<author>Barry Haddow</author>
<author>Mijail Kabadjov</author>
<author>Ewan Klein</author>
<author>Michael Matthews</author>
<author>Richard Tobin</author>
<author>Xinglong Wang</author>
</authors>
<title>Automating curation using a natural language processing pipeline. Genome Biology, 9(Suppl 2).</title>
<date>2008</date>
<contexts>
<context position="823" citStr="Alex et al., 2008" startWordPosition="128" endWordPosition="131">ract We describe the Edinburgh information extraction system which we are currently adapting for analysis of newspaper text as part of the SYNC3 project. Our most recent focus is geospatial and temporal grounding of entities and it has been useful to participate in TempEval-2 to measure the performance of our system and to guide further development. We took part in Tasks A and B for English. 1 Background The Language Technology Group (LTG) at Edinburgh has been active in the field of information extraction (IE) for a number of years. Up until recently our main focus has been in biomedical IE (Alex et al., 2008) but we have also been pursuing projects in other domains, e.g. digitised historical documents (Grover et al., 2010) and we are currently participants in the EU-funded SYNC3 project where our role is to analyse news articles and establish spatio-temporal and other relations between news events. As a step towards this goal, we have been extending and adapting our IE pipeline to ground spatial and temporal entities. We have developed the Edinburgh Geoparser for georeferencing documents and have evaluated our system against the SpatialML corpus, as reported in Tobin et al. (2010). We are currentl</context>
</contexts>
<marker>Alex, Grover, Haddow, Kabadjov, Klein, Matthews, Tobin, Wang, 2008</marker>
<rawString>Beatrice Alex, Claire Grover, Barry Haddow, Mijail Kabadjov, Ewan Klein, Michael Matthews, Richard Tobin, and Xinglong Wang. 2008. Automating curation using a natural language processing pipeline. Genome Biology, 9(Suppl 2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy A Chinchor</author>
</authors>
<date>1998</date>
<booktitle>Proceedings of the Seventh Message Understanding Conference (MUC-7).</booktitle>
<location>Fairfax, Virginia.</location>
<contexts>
<context position="7100" citStr="Chinchor, 1998" startWordPosition="1106" endWordPosition="1107">eserving the tokenisation decisions from the original. Certain tokenisation mismatches required that we extend various rules to allow for alternative token boundaries, for example, we tokenise “wasn’t” as was + n’t whereas the TempEval-2 data contains was + n + ’t or occasionally wasn + ’t. Other adaptations fall broadly into two classes: extension of our system to cover entities in TempEval-2 that we didn’t previously recognise, and mapping of our output to fit TempEval-2 requirements. 3.1 Extensions The date and time entities that our system recognises are more like the MUC7 TIMEX entities (Chinchor, 1998) than TIMEX3 ones. In particular, we have focused on dates which can either be fully grounded or which, though underspecified, can be grounded to a precise range, e.g. “last month” can be grounded to a particular month and year given a document creation date and it can be precisely specified if we take it to express a range from the first to last days of the month. TIMEX3 entities can be vaguer than this, for example, entities of type DURATION such as “twenty years”, “some time”, etc. can be recognised as denoting a temporal period but cannot easily be grounded. To align our output more closel</context>
</contexts>
<marker>Chinchor, 1998</marker>
<rawString>Nancy A. Chinchor. 1998. Proceedings of the Seventh Message Understanding Conference (MUC-7). Fairfax, Virginia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Stephen Clark</author>
</authors>
<title>Investigating GIS and smoothing for maximum entropy taggers.</title>
<date>2003</date>
<booktitle>In Proceedings of the 11th Meeting of the European Chapter of the Association for Computational Linguistics (EACL-03),</booktitle>
<pages>91--98</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="2545" citStr="Curran and Clark, 2003" startWordPosition="416" endWordPosition="419"> future work we will adapt our machine-learning-based relation extraction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks. 2 The Edinburgh IE System Our IE system is a modular pipeline system built around the LT-XML21 and LT-TTT22 toolsets. Documents are converted into our internal document format and are then passed through a sequence of linguistic components which each add XML mark-up. Early stages identify paragraphs, sentences and tokens. Part-of-speech (POS) tagging is done using the C&amp;C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al., 2000). We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&amp;C maximum entropy NER tagger (Curran and Clark, 2003b). We are experimenting to find the best combination of the two different NER views but this is not an issue in the case of date and time entities since we have taken the decision to use the rule-based output for these. The main motivation for this decision arises from the need to ground (provide temporal values for) these entiti</context>
</contexts>
<marker>Curran, Clark, 2003</marker>
<rawString>James R. Curran and Stephen Clark. 2003a. Investigating GIS and smoothing for maximum entropy taggers. In Proceedings of the 11th Meeting of the European Chapter of the Association for Computational Linguistics (EACL-03), pages 91–98. Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Stephen Clark</author>
</authors>
<title>Language independent NER using a maximum entropy tagger.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th Conference on Natural Language Learning,</booktitle>
<location>Edmonton, Alberta, Canada.</location>
<contexts>
<context position="2545" citStr="Curran and Clark, 2003" startWordPosition="416" endWordPosition="419"> future work we will adapt our machine-learning-based relation extraction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks. 2 The Edinburgh IE System Our IE system is a modular pipeline system built around the LT-XML21 and LT-TTT22 toolsets. Documents are converted into our internal document format and are then passed through a sequence of linguistic components which each add XML mark-up. Early stages identify paragraphs, sentences and tokens. Part-of-speech (POS) tagging is done using the C&amp;C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al., 2000). We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&amp;C maximum entropy NER tagger (Curran and Clark, 2003b). We are experimenting to find the best combination of the two different NER views but this is not an issue in the case of date and time entities since we have taken the decision to use the rule-based output for these. The main motivation for this decision arises from the need to ground (provide temporal values for) these entiti</context>
</contexts>
<marker>Curran, Clark, 2003</marker>
<rawString>James R. Curran and Stephen Clark. 2003b. Language independent NER using a maximum entropy tagger. In Proceedings of the 7th Conference on Natural Language Learning, Edmonton, Alberta, Canada.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Richard Tobin</author>
</authors>
<title>Rule-based chunking and reusability.</title>
<date>2006</date>
<booktitle>In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="1786" citStr="Grover and Tobin, 2006" startWordPosition="293" endWordPosition="296">tending and adapting our IE pipeline to ground spatial and temporal entities. We have developed the Edinburgh Geoparser for georeferencing documents and have evaluated our system against the SpatialML corpus, as reported in Tobin et al. (2010). We are currently in the process of developing a rule-based date and time grounding component and it is this component that we used for Task A, which requires systems to identify the extents of temporal named entities and provide their interpretation. The TempEval-2 data also contains event entities and we have adapted the output of our inhouse chunker (Grover and Tobin, 2006) to identify events for Task B, which requires systems to identify event denoting words and to compute a range of attributes for them. In future work we will adapt our machine-learning-based relation extraction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks. 2 The Edinburgh IE System Our IE system is a modular pipeline system built around the LT-XML21 and LT-TTT22 toolsets. Documents are converted into our internal document format and are then passed through a sequence of linguistic components which </context>
</contexts>
<marker>Grover, Tobin, 2006</marker>
<rawString>Claire Grover and Richard Tobin. 2006. Rule-based chunking and reusability. In Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Grover</author>
<author>Richard Tobin</author>
<author>Kate Byrne</author>
<author>Matthew Woollard</author>
<author>James Reid</author>
<author>Stuart Dunn</author>
<author>Julian Ball</author>
</authors>
<title>Use of the Edinburgh geoparser for georeferencing digitised historical collections.</title>
<date>2010</date>
<journal>Phil. Trans. R. Soc. A.</journal>
<contexts>
<context position="939" citStr="Grover et al., 2010" startWordPosition="147" endWordPosition="150">aper text as part of the SYNC3 project. Our most recent focus is geospatial and temporal grounding of entities and it has been useful to participate in TempEval-2 to measure the performance of our system and to guide further development. We took part in Tasks A and B for English. 1 Background The Language Technology Group (LTG) at Edinburgh has been active in the field of information extraction (IE) for a number of years. Up until recently our main focus has been in biomedical IE (Alex et al., 2008) but we have also been pursuing projects in other domains, e.g. digitised historical documents (Grover et al., 2010) and we are currently participants in the EU-funded SYNC3 project where our role is to analyse news articles and establish spatio-temporal and other relations between news events. As a step towards this goal, we have been extending and adapting our IE pipeline to ground spatial and temporal entities. We have developed the Edinburgh Geoparser for georeferencing documents and have evaluated our system against the SpatialML corpus, as reported in Tobin et al. (2010). We are currently in the process of developing a rule-based date and time grounding component and it is this component that we used </context>
</contexts>
<marker>Grover, Tobin, Byrne, Woollard, Reid, Dunn, Ball, 2010</marker>
<rawString>Claire Grover, Richard Tobin, Kate Byrne, Matthew Woollard, James Reid, Stuart Dunn, and Julian Ball. 2010. Use of the Edinburgh geoparser for georeferencing digitised historical collections. Phil. Trans. R. Soc. A.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barry Haddow</author>
</authors>
<title>Using automated feature optimisation to create an adaptable relation extraction system.</title>
<date>2008</date>
<booktitle>In Proc. of BioNLP</booktitle>
<location>Columbus, Ohio.</location>
<contexts>
<context position="2021" citStr="Haddow, 2008" startWordPosition="333" endWordPosition="334">We are currently in the process of developing a rule-based date and time grounding component and it is this component that we used for Task A, which requires systems to identify the extents of temporal named entities and provide their interpretation. The TempEval-2 data also contains event entities and we have adapted the output of our inhouse chunker (Grover and Tobin, 2006) to identify events for Task B, which requires systems to identify event denoting words and to compute a range of attributes for them. In future work we will adapt our machine-learning-based relation extraction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks. 2 The Edinburgh IE System Our IE system is a modular pipeline system built around the LT-XML21 and LT-TTT22 toolsets. Documents are converted into our internal document format and are then passed through a sequence of linguistic components which each add XML mark-up. Early stages identify paragraphs, sentences and tokens. Part-of-speech (POS) tagging is done using the C&amp;C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al., 2000). We use both</context>
</contexts>
<marker>Haddow, 2008</marker>
<rawString>Barry Haddow. 2008. Using automated feature optimisation to create an adaptable relation extraction system. In Proc. of BioNLP 2008, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Robust, applied morphological generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st International Natural Language Generation Conference,</booktitle>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="2608" citStr="Minnen et al., 2000" startWordPosition="426" endWordPosition="429">traction component (Haddow, 2008) to recognise relations between spatial and temporal entities and event entities along the lines of the linking tasks. 2 The Edinburgh IE System Our IE system is a modular pipeline system built around the LT-XML21 and LT-TTT22 toolsets. Documents are converted into our internal document format and are then passed through a sequence of linguistic components which each add XML mark-up. Early stages identify paragraphs, sentences and tokens. Part-of-speech (POS) tagging is done using the C&amp;C tagger (Curran and Clark, 2003a) and lemmatisation is done using morpha (Minnen et al., 2000). We use both rule-based and machine-learning named entity recognition (NER) components, the former implemented using LT-TTT2 and the latter using the C&amp;C maximum entropy NER tagger (Curran and Clark, 2003b). We are experimenting to find the best combination of the two different NER views but this is not an issue in the case of date and time entities since we have taken the decision to use the rule-based output for these. The main motivation for this decision arises from the need to ground (provide temporal values for) these entities and the rules for the grounding are most naturally implement</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2000</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2000. Robust, applied morphological generation. In Proceedings of the 1st International Natural Language Generation Conference, Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Tobin</author>
<author>Claire Grover</author>
<author>Kate Byrne</author>
<author>James Reid</author>
<author>Jo Walsh</author>
</authors>
<title>Evaluation of georeferencing.</title>
<date>2010</date>
<booktitle>In Proceedings of Workshop on Geographic Information Retrieval (GIR’10).</booktitle>
<contexts>
<context position="1406" citStr="Tobin et al. (2010)" startWordPosition="225" endWordPosition="228">in biomedical IE (Alex et al., 2008) but we have also been pursuing projects in other domains, e.g. digitised historical documents (Grover et al., 2010) and we are currently participants in the EU-funded SYNC3 project where our role is to analyse news articles and establish spatio-temporal and other relations between news events. As a step towards this goal, we have been extending and adapting our IE pipeline to ground spatial and temporal entities. We have developed the Edinburgh Geoparser for georeferencing documents and have evaluated our system against the SpatialML corpus, as reported in Tobin et al. (2010). We are currently in the process of developing a rule-based date and time grounding component and it is this component that we used for Task A, which requires systems to identify the extents of temporal named entities and provide their interpretation. The TempEval-2 data also contains event entities and we have adapted the output of our inhouse chunker (Grover and Tobin, 2006) to identify events for Task B, which requires systems to identify event denoting words and to compute a range of attributes for them. In future work we will adapt our machine-learning-based relation extraction component</context>
</contexts>
<marker>Tobin, Grover, Byrne, Reid, Walsh, 2010</marker>
<rawString>Richard Tobin, Claire Grover, Kate Byrne, James Reid, and Jo Walsh. 2010. Evaluation of georeferencing. In Proceedings of Workshop on Geographic Information Retrieval (GIR’10).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>