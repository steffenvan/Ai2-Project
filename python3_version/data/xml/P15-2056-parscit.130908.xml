<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<note confidence="0.866762">
Learning to Mine Query Subtopics from Query Log
</note>
<author confidence="0.943259">
Zhenzhong Zhang, Le Sun, Xianpei Han
</author>
<affiliation confidence="0.948983">
Institute of Software, Chinese Academy of Sciences, Beijing, China
</affiliation>
<email confidence="0.963869">
{zhenzhong, sunle, xianpei}@nfs.iscas.ac.cn
</email>
<sectionHeader confidence="0.99481" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999725130434783">
Many queries in web search are ambiguous or
multifaceted. Identifying the major senses or
facets of queries is very important for web
search. In this paper, we represent the major
senses or facets of queries as subtopics and re-
fer to indentifying senses or facets of queries
as query subtopic mining, where query subtop-
ic are represented as a number of clusters of
queries. Then the challenges of query subtopic
mining are how to measure the similarity be-
tween queries and group them semantically.
This paper proposes an approach for mining
subtopics from query log, which jointly learns
a similarity measure and groups queries by
explicitly modeling the structure among them.
Compared with previous approaches using
manually defined similarity measures, our ap-
proach produces more desirable query subtop-
ics by learning a similarity measure. Experi-
mental results on real queries collected from a
search engine log confirm the effectiveness of
the proposed approach in mining query sub-
topics.
</bodyText>
<sectionHeader confidence="0.998127" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999753507462687">
Understanding the search intents of queries is
essential for satisfying users’ information needs
and is very important for many search tasks such
as personalized search, query suggestion, and
search result presentation. However, it is not a
trivial task because the underlying intents of the
same query may be different for different users.
Two well-known types of such queries are am-
biguous queries and multifaceted queries. For
example, the ambiguous query ‘michael jordon’
may refer to a basketball player or a professor of
statistics in Berkeley. The multifaceted query
‘harry potter’ may refer to different search in-
tents such as films, books, or games and so on.
Many approaches have been proposed to identi-
fy the search intents of a query which are repre-
sented by search goals, topics, or subtopics. For
example, Broder (2002) classified query intents
into three search goals: informational, naviga-
tional, and transactional. Broder et al. (2007) and
Li et al. (2005) represented query intents by top-
ics. Clarke et al. (2009) represented query intents
by subtopics which denote different senses or
multiple facets of queries.
Previous work on query subtopic mining is
mostly based on clustering framework by manu-
ally defining a similarity measure with few fac-
tors. Hu et al. (2012) employed an agglomerative
clustering algorithm with a similarity measure
combining string similarities, click similarities,
and keyword similarities linearly. Wang et al.
(2013) applied affinity propagation algorithm
(Frey and Dueck, 2009) with a sense-based simi-
larity. Tsukuda et al. (2013) used a hierarchical
clustering algorithm with the similarity measure
based on search results.
In this paper, we argue that the similarity be-
tween queries is affected by many different fac-
tors and it could produce more desirable query
subtopics by learning a similarity measure. To
learn a similarity measure for query subtopic
mining, a natural approach is to use a binary
classifier, that is, the classifier targets pairs of
queries and makes predictions about whether
they belong to the same subtopic. However, be-
cause such pairwise classifiers assume that pairs
are independent, they might make inconsistent
predictions: e.g., predicting queries qi and qj, qj
and qk to belong to the same subtopic, but qi and
qk to belong to different subtopics. For example,
given three queries, ‘luxury car’, ‘sport car’ and
‘XJ sport’, for the query ‘jaguar’, a lexicon-
similarity-based classifier is easy to learn that
‘luxury car’ and ‘sport car’, and ‘sport car’ and
‘XJ sport’ belong to the same subtopic; but diffi-
cult to learn that ‘luxury car’ and ‘XJ sport’ be-
long to the same subtopic. From this example,
we can see that a learner should exploit these
transitive dependencies among queries to learn a
more effective similarity measure. Hence, in this
paper, our first contribution is that we learn a
similarity measure by explicitly modeling the
dependencies among queries in the same subtop-
ic. The second contribution is that we analyze the
performance of the proposed approach with dif-
ferent dependencies among queries. The third
contribution is that we conduct experiments on
</bodyText>
<page confidence="0.563651">
341
</page>
<note confidence="0.588130333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 341–345,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.998732333333333">
real-world data and the experimental results con-
firm the effectiveness of the proposed approach
in mining query subtopics.
</bodyText>
<subsectionHeader confidence="0.375261">
2 Learning to Mine Query Subtopics
</subsectionHeader>
<bodyText confidence="0.9998692">
In this section, we present our approach in details.
First, we collect queries as subtopic candidates
from query log using a heuristic method. Then,
we learn a similarity measure to mine query sub-
topics from these candidates.
</bodyText>
<subsectionHeader confidence="0.9994335">
2.1 Collecting Subtopic Candidates from
Query Log
</subsectionHeader>
<bodyText confidence="0.999994476190476">
In web search, users usually add additional
words to clarify the underlying intents of a query
(Hu et al., 2012). For example, if the ambiguous
query ‘jaguar’ does not satisfy a user’s infor-
mation need, he/she may submit ‘jaguar sport
car’ as an expanded query to specify the subtopic.
Therefore, for a given query q, we collect its re-
formulations with additional words from query
log as query subtopic candidates, e.g., we collect
{‘jaguar sports car’, ‘jaguar XJ sport’, ‘jaguar
diet’, ...} for query ‘jaguar’. We say query q’ is a
subtopic candidate of q if (1) q’ is superset of q
(e.g. q’= ’jaguar sports car’ and q = ’jaguar’), and
(2) q’ occurred at least five times in query log. In
this way, we collect a series of subtopic candi-
dates for each query. Many subtopic candidates,
however, belong to the same subtopic, e.g., ‘jag-
uar sports car’ and ‘jaguar XJ sport’. Thus, to
obtain the subtopics of a query, we need to group
its subtopic candidates into clusters, each of
which corresponds to an individual subtopic.
</bodyText>
<subsectionHeader confidence="0.999893">
2.2 Mining Query Subtopics
</subsectionHeader>
<bodyText confidence="0.99898578125">
As we described above, we need to group the
subtopic candidates of a query into clusters to
obtain its subtopics. The key to producing desir-
able subtopics is how to measure the similarity
between subtopic candidates. In this paper, we
learn a similarity measure by exploiting the de-
pendencies among subtopic candidates in the
same subtopic.
We represent each pair of subtopic candidates
qi and qj as a feature vector 4(qi, qj), each dimen-
sion of which describes a factor. The similarity
measure Simw parameterized by w is defined as
Simw(qi, qj) = wT•4(qi, qj), which maps pairs of
subtopic candidates to a real number indicating
how similar the pair is: positive for similar and
negative for dissimilar. As argued in the intro-
duction, the dependencies among subtopic can-
didates within the same subtopic are useful for
learning an effective similarity measure. We de-
note the dependencies among subtopic candi-
dates as a graph h, whose vertices are subtopic
candidates and edges connect two vertices be-
longing to the same subtopic. In this paper, we
employ two different graphs. The first one is the
all-connection structure, where all subtopic can-
didates belonging to the same subtopic associate
with each other. Figure 1 gives an example of the
all-connection structure. The second one is the
strong-connection structure, where each subtopic
candidate only associates with its ‘most similar’
subtopic candidate within the same subtopic.
Figure 2 gives an example.
</bodyText>
<figure confidence="0.986773333333333">
0.2
-0.1
0.2 6
</figure>
<figureCaption confidence="0.982259">
Figure 1. An example of the all-connection struc-
</figureCaption>
<bodyText confidence="0.9627175">
ture. The dashed circles denote the subtopics.
The subtopic candidates (small solid circles) in
the same dashed circle belong to the same sub-
topic. The weights indicate how similar the pair
of two vertices is.
Figure 2. An example of the strong-connection
structure.
Formally, we denote the set of subtopic candi-
dates for a given query q as S = {q1, q2, ..., qN}.
The label y is a partition of the N subtopic candi-
dates into subtopic clusters. h is the correspond-
ing graph that is consistent with y. h is consistent
with a clustering y if every cluster in y is a con-
nected component in h, and there are no edges in
h that connect two distinct clusters in y. Given S,
our approach makes predictions by maximizing
the sum of similarities for subtopic candidate
pairs that are adjacent in h, that is,
</bodyText>
<equation confidence="0.819112333333333">
arg max Z Simw(qi, qj) =argmax Z wT.
O(qi,qj
(y,h)EYxH (i,j)Eh (y,h)EYxH (i,j)Eh
</equation>
<bodyText confidence="0.991380333333333">
where Y and H are the sets of possible y and h
respectively. (i, j) ∈h denotes qi and qj are di-
rectly connected in h.
</bodyText>
<figure confidence="0.985658565217391">
0.2
0.3
2
0.1
1
3
0.5 0.3
5
0.1
4
7
0.3 0.2
2
1
3
4
0.5 0.3
5
0.2
6
7
(1)
342
</figure>
<bodyText confidence="0.928953142857143">
To predict a partition y with the all-connection
structure, we use the algorithm in (Bansal et al.,
2002) with the objective function Eq (1). To pre-
dict a partition y with the strong-connection
structure, we run Kruskal’s algorithm on h and
each tree corresponds to a subtopic, as shown in
Algorithm 1.
</bodyText>
<table confidence="0.640938666666667">
Algorithm 1: Mining Query Subtopic with Strong-
connection Structure
Input: the set of query subtopic candidates S = {q1,
q2, ..., qN}, feature vectors ϕ(qi, qj) (1&lt;i, j&lt;N,
i�j) and the weight w
Output: the partition y
//search for the strong-connection structure h, MST-
KRUSKAL(G) denotes the Minimum Spanning Tree
algorithm- Kruskal’s algorithm
for i = 1...N-1 do
for j = i+1...N do
sim = wT- ϕ(qi, qj);
G(i, j)=−sim;
end
end
h’= MST-KRUSKAL(G);
for i = 1...N-1 do
for j = i+1...N do
if h’(i, j)&lt;0 then
h(i, j) = 1;
end
end
end
// construct the partition y
</table>
<equation confidence="0.994403882352941">
t = 0;
y(1)=0;
for i = 2...N do
j = 1;
while j &lt; i-1 do
if h(j, i) = 1 then
y(i)= y(j);
break;
end
j = j+1;
end
if j &gt; i then
t = t + 1;
y(i) = t;
end
end
return y
</equation>
<subsectionHeader confidence="0.997424">
2.3 Solving the Proposed Approach
</subsectionHeader>
<bodyText confidence="0.998226444444444">
For a given set of subtopic candidates with anno-
tated subtopics, {(Sn, yn)} (1&lt;n&lt;N), we need to
estimate the optimal weight w. Empirically, the
optimal weight w should minimize the error be-
tween the predicted partition y’ and the true parti-
tion y, and it should also have a good generaliza-
tion capability. Therefore, it is learnt by solving
the following optimization problem (Yu and Joa-
chims, 2009):
</bodyText>
<equation confidence="0.999503923076923">
2  
h H
 (i,j)h

w,  2 n 1
s.t.  n, max wT  
 ( , )
q q
i j
 
max [wT  (qi,q) (yn,y,h)]
(y,h)YH &apos;
(i,j)  h
</equation>
<bodyText confidence="0.9999001">
where ∆(yn, y’, h’) indicates a loss between a true
partition yn and the predicted partition y’ speci-
fied by h’, �n (1≤n≤N) is a set of slack variables
to allow errors in the training data, and C con-
trols the trade-off between empirical loss and
model complexity.
Intuitively, the loss function ∆(yn, y’, h’) should
satisfy that ∆(yn, y’, h’) = 0 if yn = y’, and rises as
yn and y’ become more dissimilar. Because the
all-connection structure is observable in the
training data while the strong-connection struc-
ture is hidden, we define different loss functions
for them. For the all-connection structure, we
define the loss function as,
where T is the total number of pairs of subtopic
candidates in the set partitioned by yn and y’, and
D is the total number of pairs where yn and y’
disagree about their cluster membership.
Since the strong-connection structure hn for yn
is hidden in the training data, we cannot measure
the loss between (yn, hn) and (y’, h’). According to
(Yu and Joachims, 2009), we define the loss
function based on the inferred structure h’ as,
where n(yn) and k(yn) are the number of subtopic
candidates and the number of clusters in the cor-
rect clustering yn. l(yn, (i, j) ) = 1 if qi and qj are in
the same cluster in yn, otherwise l(yn, (i, j) ) = −1.
Then the optimization problem introduced in Eq.
(2) can be solved by the Concave-Convex Proce-
dure (CCCP) (Yuille and Rangarajan, 2003).
</bodyText>
<subsectionHeader confidence="0.995727">
2.4 Pairwise Similarity Features
</subsectionHeader>
<bodyText confidence="0.999985076923077">
The proposed approach requires a set of features
to measure the similarity between two subtopic
candidates. Table 1 lists the features employed in
our approach. These features are categorized into
two types: lexicon-based similarity and URL-
based similarity. The lexicon-based similarity
features are employed to measure the string simi-
larity between two subtopic candidates. And the
URL-based similarity features are used to meas-
ure the semantic similarity between two subtopic
candidates. The basic idea is that if two queries
share many clicked URLs, they have similar
search intent to each other (Li et al., 2008). To
</bodyText>
<equation confidence="0.908379555555555">
N
n
||w||
(2)
n
min 1
C

343
</equation>
<bodyText confidence="0.961428333333333">
make the features comparable with each other,
we normalize them into range of [0, 1] accord-
ingly.
</bodyText>
<figure confidence="0.824704545454545">
Feature Description
COS cosine similarity between qi and qj
EUC Euclidean distance between qi and qj
JAC Jaccard coeff between qi and qj
EDIT norm edit distance between qi and qj
LEN jlength(qi)-length(qj)j
SUBSET whether one is a subset of the other
UCOS cosine similarity between the clicked
URL sets of qi and qj
UJAC Jaccard coeff between the clicked URL
sets of qi and qj
</figure>
<tableCaption confidence="0.945621">
Table 1: pairwise similarity features employed in
our approach
</tableCaption>
<sectionHeader confidence="0.99519" genericHeader="introduction">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999417">
3.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999986941176471">
To illustrate the effectiveness of our approach,
we use 100 ambiguous/multifaceted queries pro-
vided by the NTCIR-9 intent task as original
queries and collect their subtopic candidates
from SogouQ dataset (http://www.sogou.com)
using the method mentioned in section 2.1. For
the 100 queries, we totally collect 2,280 query
subtopic candidates. Three annotators manually
label these candidates with their subtopics ac-
cording to the content words of these candidates
and their clicked web pages (if there are clicked
URLs for the candidate in query log). A candi-
date belongs to a specific subtopic if at least two
annotators agree with it. At last we obtain 1,086
subtopics. We randomly split the original queries
into two parts: half used for training and the rest
for testing.
</bodyText>
<equation confidence="0.992831727272727">
&apos; &apos; &apos; &apos;
 ( , ( ))
R g R  ( , ( ))
R g R
 
i i i i i i
p( , ) , r 
&apos; &apos; ( , ))
  R R R R

i i i j j j
</equation>
<subsectionHeader confidence="0.999694">
3.2 Evaluation Metrics and Baselines
</subsectionHeader>
<bodyText confidence="0.999838444444444">
To evaluate the performance of our approach, we
employ the measures in (Luo, 2005), which are
computed as follows,
where R’ is the predicted partition and R is the
ground-truth partition; π(A, B) is a similarity
measure between set A and B, which is Jaccard
coefficient in this paper; and g(.) is the optimal
mapping between R’ and R. Based on p and r, f-
measure can be calculated as,
</bodyText>
<figure confidence="0.389966">
2x px r
f measure
p r

</figure>
<bodyText confidence="0.998396">
The higher the f-measure score is, the better per-
formance an approach achieves.
We used the following approaches as baselines:
</bodyText>
<listItem confidence="0.9219552">
• K-means: we perform the standard k-means
clustering algorithm with different manually
defined similarity measures to mine query sub-
topics. COS, JAC, EUC, EDIT refer to cosine
similarity, Jaccard similarity, Euclidean dis-
tance, and edit distance, respectively.
• Binary Classification Cluster with the all-
connection structure (BCC-AC): BCC-AC uses
a SVM classifier to learn the weight w and
clusters with correlation clustering method.
• Binary Classification Cluster with the strong-
connection structure (BCC-SC): BCC-SC uses
a SVM classifier to learn the weight w and
clusters with the method presented in Algo-
rithm 1.
</listItem>
<bodyText confidence="0.999865166666667">
For the proposed methods, we denote the
method with the all-connection structure as AC
and the method with the strong-connection struc-
ture as SC. The parameter C in Eq. (2) is picked
from10-2 to 104 using a 10-fold cross validation
procedure.
</bodyText>
<subsectionHeader confidence="0.948803">
3.3 Experimental Results
</subsectionHeader>
<table confidence="0.998414777777778">
Methods p r f-measure
K-Means-COS 0.6885 0.6589 0.6734
K-Means-JAC 0.6872 0.6616 0.6742
K-Means-EUC 0.6899 0.6652 0.6774
K-Means-EDIT 0.6325 0.6275 0.6300
BCC-AC 0.7347 0.7263 0.7305
BCC-SC 0.7406 0.7258 0.7331
AC 0.8027 0.7911 0.7968
SC 0.8213* 0.8187* 0.8200*
</table>
<bodyText confidence="0.996603">
Table2: the performance of all methods. “*” in-
dicates significant difference at 0.05 level using a
paired t-test.
Table 2 presents the experimental results. Com-
pared with K-Means methods with different
manually defined similarity measures, SC
achieves at least 13.14% precision improvement,
15.35% recall improvement, and 14.26% F-
Measure improvement. And AC achieves at least
11.28% precision improvement, 12.59% recall
improvement, and 11.94% F-Measure improve-
ment. These results confirm that the similarity
between two subtopic candidates is affected by
many factors and our methods can achieve more
desirable query subtopics by learning a similarity
measure.
Compared with BCC-AC and BCC-SC, SC
achieves at least 8.07% precision improvement,
9.29% recall improvement, and 8.69% F-
Measure improvement. And AC achieves at least
6.21% precision improvement, 6.53% recall im-
</bodyText>
<equation confidence="0.422893">
 
</equation>
<page confidence="0.52265">
344
</page>
<bodyText confidence="0.998960625">
provement, and 6.37% F-Measure improvement.
These results confirm that the dependencies
among the subtopic candidates within the same
subtopic are useful for learning a similarity
measure for query subtopic mining.
Compared with AC, SC achieves 1.86% preci-
sion improvement, 2.76% recall improvement,
and 2.32% F-Measure improvement. These re-
sults confirm that a subtopic candidate belonging
to a given query subtopic does not need to simi-
lar with all subtopic candidates within the given
subtopic.
In order to understand which pairwise similari-
ty feature is important for the problem of query
subtopic mining, we list the features and their
weights learned by SC, AC, and BCC (Binary
</bodyText>
<table confidence="0.985922181818182">
Classification Cluster) in Table 3.
Method SC AC BCC
Feature
COS 0.08 0.04 0.19
EUC −1.74 −1.07 −0.73
JAC 4.44 4.73 4.90
EDIT −1.60 −1.01 −0.48
LEN −1.34 −0.91 −1.07
SUBSET 0.21 0.11 −0.05
UCOS 0.01 0.01 0.04
UJAC 0.06 0.07 0.09
</table>
<tableCaption confidence="0.693136">
Table 3: the features and their weights learned by
the different methods.
</tableCaption>
<bodyText confidence="0.9985975">
As can be seen in Table 3, JAC has the largest
importance weight for mining query subtopics in
the three methods. The URL-based features
(UCOS and UJAC) have small importance
weight. The reason is that clicked URLs are
sparse in our query log and many long-tail sub-
topic candidates in the same subtopic do not
share any common URLs.
</bodyText>
<sectionHeader confidence="0.999753" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999956111111111">
In this paper, we propose an approach for mining
query subtopics from query log. Compared with
previous approaches, our approach learns a simi-
larity measure by explicitly modeling the de-
pendencies among subtopic candidates within the
same subtopic. Experimental results on real que-
ries collected from a search engine log confirm
our approach produces more desirable query sub-
topics by using the learned similarity measure.
</bodyText>
<sectionHeader confidence="0.995206" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999279571428571">
The work is supported by the National Natural
Science Foundation of China under Grants no.
61433015 and 61272324, and the National High
Technology Development 863 Program of China
under Grants no. 2015AA015405. Moreover, we
sincerely thank the reviewers for their valuable
comments.
</bodyText>
<sectionHeader confidence="0.998456" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999951195652174">
N. Bansal, A. Blum, and S. Chawla. 2002. Correlation
clustering. In Machine Learning, 56, 89-113.
A. Z. Broder. A taxonomy of web search. 2002. In
Sigir Forum, 36:3-10.
A. Z. Broder, M. Fontoura, E. Gabrilovich, A. Joshi,
V. Josifovski, and T. Zhang. 2007. Robust classifi-
cation of rare queries using web knowledge. In
SIGIR, pp. 231-238.
C. L. A. Clarke, N. Craswell, and I. Soboroff. 2009.
Overview of the trec 2009 web track. In TREC’09,
pp. 1-9.
Y. Hu, Y. Qian, H. Li, D. Jiang, J.Pei, and Q. Zheng.
2012. Ming query subtopics from search log data.
In SIGIR’12, pp. 305-314.
T. Finley and T. Joachims. 2005. Supervised cluster-
ing with support vector machines. In ICML, pp.
217-224.
B. J. Frey and D. Dueck. 2007. Clustering by passing
messages between data points. In science,
315(5814):972-976.
Y. Li, Z. Zheng, and H. K. Dai. 2005. Kdd cup-2005
report: facing a great challenge. In SIGKDD Explor.
Newsl., 7:91-99.
L. Li, Z. Yang, L. Liu, and M. Kitsuregawa. 2008.
Query-url bipartite based approach to personalized
query recommendation. In AAAI’08, pp. 1189-
1194.
X. Luo. 2005. On Coreference resolution performance
metrics. In HLTBrEMNLP, pp. 25-32.
F. Radlinski, M. Szummer, and N. Craswell. 2010.
Inferring Query Intent from Reformulations and
Clicks. In WWW, pp. 1171-1172.
R. Song et, al. 2011. Overview of the ntcir-9 intent
task, In NTCIR-9, pp.82-105.
K. Tsukuda, Z. Dou, and T. Sakai. 2013. Microsoft
research asia at the ntcir-10 intent task. In NTCIR-
10, pp. 152-158.
J. Wang, G. Tang, Y. Xia, Q. Hu, S. Na, Y. Huang, Q.
Zhou, and F. Zheng. 2013. Understanding the que-
ry: THCIB and THUIS at ntcir-10 intent task. In
NTCIR-10, pp. 132-139.
C. J. Yu and T. Joachims. 2009. Learning Structural
SVMs with Latent Variables. In ICML, pp. 1169-
1176
A. Yuille, and A. Rangarajan. 2003. The concave-
convex procedure. In Neural Computation, 15, 915.
</reference>
<page confidence="0.953157">
345
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.764353">
<title confidence="0.999943">Learning to Mine Query Subtopics from Query Log</title>
<author confidence="0.972809">Han</author>
<affiliation confidence="0.999653">Institute of Software, Chinese Academy of Sciences, Beijing,</affiliation>
<email confidence="0.977801">sunle,</email>
<abstract confidence="0.991771666666667">Many queries in web search are ambiguous or multifaceted. Identifying the major senses or facets of queries is very important for web search. In this paper, we represent the major senses or facets of queries as subtopics and refer to indentifying senses or facets of queries as query subtopic mining, where query subtopic are represented as a number of clusters of queries. Then the challenges of query subtopic mining are how to measure the similarity between queries and group them semantically. This paper proposes an approach for mining subtopics from query log, which jointly learns a similarity measure and groups queries by explicitly modeling the structure among them. Compared with previous approaches using manually defined similarity measures, our approach produces more desirable query subtopics by learning a similarity measure. Experimental results on real queries collected from a search engine log confirm the effectiveness of the proposed approach in mining query subtopics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N Bansal</author>
<author>A Blum</author>
<author>S Chawla</author>
</authors>
<title>Correlation clustering.</title>
<date>2002</date>
<booktitle>In Machine Learning,</booktitle>
<volume>56</volume>
<pages>89--113</pages>
<contexts>
<context position="8842" citStr="Bansal et al., 2002" startWordPosition="1450" endWordPosition="1453"> a connected component in h, and there are no edges in h that connect two distinct clusters in y. Given S, our approach makes predictions by maximizing the sum of similarities for subtopic candidate pairs that are adjacent in h, that is, arg max Z Simw(qi, qj) =argmax Z wT. O(qi,qj (y,h)EYxH (i,j)Eh (y,h)EYxH (i,j)Eh where Y and H are the sets of possible y and h respectively. (i, j) ∈h denotes qi and qj are directly connected in h. 0.2 0.3 2 0.1 1 3 0.5 0.3 5 0.1 4 7 0.3 0.2 2 1 3 4 0.5 0.3 5 0.2 6 7 (1) 342 To predict a partition y with the all-connection structure, we use the algorithm in (Bansal et al., 2002) with the objective function Eq (1). To predict a partition y with the strong-connection structure, we run Kruskal’s algorithm on h and each tree corresponds to a subtopic, as shown in Algorithm 1. Algorithm 1: Mining Query Subtopic with Strongconnection Structure Input: the set of query subtopic candidates S = {q1, q2, ..., qN}, feature vectors ϕ(qi, qj) (1&lt;i, j&lt;N, i�j) and the weight w Output: the partition y //search for the strong-connection structure h, MSTKRUSKAL(G) denotes the Minimum Spanning Tree algorithm- Kruskal’s algorithm for i = 1...N-1 do for j = i+1...N do sim = wT- ϕ(qi, qj);</context>
</contexts>
<marker>Bansal, Blum, Chawla, 2002</marker>
<rawString>N. Bansal, A. Blum, and S. Chawla. 2002. Correlation clustering. In Machine Learning, 56, 89-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Z Broder</author>
</authors>
<title>A taxonomy of web search.</title>
<date>2002</date>
<booktitle>In Sigir Forum,</booktitle>
<pages>36--3</pages>
<contexts>
<context position="2045" citStr="Broder (2002)" startWordPosition="319" endWordPosition="320">However, it is not a trivial task because the underlying intents of the same query may be different for different users. Two well-known types of such queries are ambiguous queries and multifaceted queries. For example, the ambiguous query ‘michael jordon’ may refer to a basketball player or a professor of statistics in Berkeley. The multifaceted query ‘harry potter’ may refer to different search intents such as films, books, or games and so on. Many approaches have been proposed to identify the search intents of a query which are represented by search goals, topics, or subtopics. For example, Broder (2002) classified query intents into three search goals: informational, navigational, and transactional. Broder et al. (2007) and Li et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarit</context>
</contexts>
<marker>Broder, 2002</marker>
<rawString>A. Z. Broder. A taxonomy of web search. 2002. In Sigir Forum, 36:3-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Z Broder</author>
<author>M Fontoura</author>
<author>E Gabrilovich</author>
<author>A Joshi</author>
<author>V Josifovski</author>
<author>T Zhang</author>
</authors>
<title>Robust classification of rare queries using web knowledge.</title>
<date>2007</date>
<booktitle>In SIGIR,</booktitle>
<pages>231--238</pages>
<contexts>
<context position="2164" citStr="Broder et al. (2007)" startWordPosition="333" endWordPosition="336">t users. Two well-known types of such queries are ambiguous queries and multifaceted queries. For example, the ambiguous query ‘michael jordon’ may refer to a basketball player or a professor of statistics in Berkeley. The multifaceted query ‘harry potter’ may refer to different search intents such as films, books, or games and so on. Many approaches have been proposed to identify the search intents of a query which are represented by search goals, topics, or subtopics. For example, Broder (2002) classified query intents into three search goals: informational, navigational, and transactional. Broder et al. (2007) and Li et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly. Wang et al. (2013) applied affinity propagation algorithm (Frey and Dueck, 2009) with a sense-based simil</context>
</contexts>
<marker>Broder, Fontoura, Gabrilovich, Joshi, Josifovski, Zhang, 2007</marker>
<rawString>A. Z. Broder, M. Fontoura, E. Gabrilovich, A. Joshi, V. Josifovski, and T. Zhang. 2007. Robust classification of rare queries using web knowledge. In SIGIR, pp. 231-238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L A Clarke</author>
<author>N Craswell</author>
<author>I Soboroff</author>
</authors>
<title>Overview of the trec 2009 web track.</title>
<date>2009</date>
<booktitle>In TREC’09,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="2243" citStr="Clarke et al. (2009)" startWordPosition="348" endWordPosition="351">ceted queries. For example, the ambiguous query ‘michael jordon’ may refer to a basketball player or a professor of statistics in Berkeley. The multifaceted query ‘harry potter’ may refer to different search intents such as films, books, or games and so on. Many approaches have been proposed to identify the search intents of a query which are represented by search goals, topics, or subtopics. For example, Broder (2002) classified query intents into three search goals: informational, navigational, and transactional. Broder et al. (2007) and Li et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly. Wang et al. (2013) applied affinity propagation algorithm (Frey and Dueck, 2009) with a sense-based similarity. Tsukuda et al. (2013) used a hierarchical clustering algorithm with the </context>
</contexts>
<marker>Clarke, Craswell, Soboroff, 2009</marker>
<rawString>C. L. A. Clarke, N. Craswell, and I. Soboroff. 2009. Overview of the trec 2009 web track. In TREC’09, pp. 1-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Hu</author>
<author>Y Qian</author>
<author>H Li</author>
<author>D Jiang</author>
<author>J Pei</author>
<author>Q Zheng</author>
</authors>
<title>Ming query subtopics from search log data. In</title>
<date>2012</date>
<booktitle>SIGIR’12,</booktitle>
<pages>305--314</pages>
<contexts>
<context position="2499" citStr="Hu et al. (2012)" startWordPosition="389" endWordPosition="392">ny approaches have been proposed to identify the search intents of a query which are represented by search goals, topics, or subtopics. For example, Broder (2002) classified query intents into three search goals: informational, navigational, and transactional. Broder et al. (2007) and Li et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly. Wang et al. (2013) applied affinity propagation algorithm (Frey and Dueck, 2009) with a sense-based similarity. Tsukuda et al. (2013) used a hierarchical clustering algorithm with the similarity measure based on search results. In this paper, we argue that the similarity between queries is affected by many different factors and it could produce more desirable query subtopics by learning a similarity measure. To learn a similarity measur</context>
<context position="5196" citStr="Hu et al., 2012" startWordPosition="809" endWordPosition="812">a, July 26-31, 2015. c�2015 Association for Computational Linguistics real-world data and the experimental results confirm the effectiveness of the proposed approach in mining query subtopics. 2 Learning to Mine Query Subtopics In this section, we present our approach in details. First, we collect queries as subtopic candidates from query log using a heuristic method. Then, we learn a similarity measure to mine query subtopics from these candidates. 2.1 Collecting Subtopic Candidates from Query Log In web search, users usually add additional words to clarify the underlying intents of a query (Hu et al., 2012). For example, if the ambiguous query ‘jaguar’ does not satisfy a user’s information need, he/she may submit ‘jaguar sport car’ as an expanded query to specify the subtopic. Therefore, for a given query q, we collect its reformulations with additional words from query log as query subtopic candidates, e.g., we collect {‘jaguar sports car’, ‘jaguar XJ sport’, ‘jaguar diet’, ...} for query ‘jaguar’. We say query q’ is a subtopic candidate of q if (1) q’ is superset of q (e.g. q’= ’jaguar sports car’ and q = ’jaguar’), and (2) q’ occurred at least five times in query log. In this way, we collect </context>
</contexts>
<marker>Hu, Qian, Li, Jiang, Pei, Zheng, 2012</marker>
<rawString>Y. Hu, Y. Qian, H. Li, D. Jiang, J.Pei, and Q. Zheng. 2012. Ming query subtopics from search log data. In SIGIR’12, pp. 305-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Finley</author>
<author>T Joachims</author>
</authors>
<title>Supervised clustering with support vector machines.</title>
<date>2005</date>
<booktitle>In ICML,</booktitle>
<pages>217--224</pages>
<marker>Finley, Joachims, 2005</marker>
<rawString>T. Finley and T. Joachims. 2005. Supervised clustering with support vector machines. In ICML, pp. 217-224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Frey</author>
<author>D Dueck</author>
</authors>
<title>Clustering by passing messages between data points.</title>
<date>2007</date>
<booktitle>In science,</booktitle>
<pages>315--5814</pages>
<marker>Frey, Dueck, 2007</marker>
<rawString>B. J. Frey and D. Dueck. 2007. Clustering by passing messages between data points. In science, 315(5814):972-976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Li</author>
<author>Z Zheng</author>
<author>H K Dai</author>
</authors>
<title>Kdd cup-2005 report: facing a great challenge.</title>
<date>2005</date>
<booktitle>In SIGKDD Explor. Newsl.,</booktitle>
<pages>7--91</pages>
<contexts>
<context position="2185" citStr="Li et al. (2005)" startWordPosition="338" endWordPosition="341">ypes of such queries are ambiguous queries and multifaceted queries. For example, the ambiguous query ‘michael jordon’ may refer to a basketball player or a professor of statistics in Berkeley. The multifaceted query ‘harry potter’ may refer to different search intents such as films, books, or games and so on. Many approaches have been proposed to identify the search intents of a query which are represented by search goals, topics, or subtopics. For example, Broder (2002) classified query intents into three search goals: informational, navigational, and transactional. Broder et al. (2007) and Li et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly. Wang et al. (2013) applied affinity propagation algorithm (Frey and Dueck, 2009) with a sense-based similarity. Tsukuda et al.</context>
</contexts>
<marker>Li, Zheng, Dai, 2005</marker>
<rawString>Y. Li, Z. Zheng, and H. K. Dai. 2005. Kdd cup-2005 report: facing a great challenge. In SIGKDD Explor. Newsl., 7:91-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Li</author>
<author>Z Yang</author>
<author>L Liu</author>
<author>M Kitsuregawa</author>
</authors>
<title>Query-url bipartite based approach to personalized query recommendation.</title>
<date>2008</date>
<booktitle>In AAAI’08,</booktitle>
<pages>1189--1194</pages>
<contexts>
<context position="12388" citStr="Li et al., 2008" startWordPosition="2098" endWordPosition="2101">The proposed approach requires a set of features to measure the similarity between two subtopic candidates. Table 1 lists the features employed in our approach. These features are categorized into two types: lexicon-based similarity and URLbased similarity. The lexicon-based similarity features are employed to measure the string similarity between two subtopic candidates. And the URL-based similarity features are used to measure the semantic similarity between two subtopic candidates. The basic idea is that if two queries share many clicked URLs, they have similar search intent to each other (Li et al., 2008). To N n ||w|| (2) n min 1 C  343 make the features comparable with each other, we normalize them into range of [0, 1] accordingly. Feature Description COS cosine similarity between qi and qj EUC Euclidean distance between qi and qj JAC Jaccard coeff between qi and qj EDIT norm edit distance between qi and qj LEN jlength(qi)-length(qj)j SUBSET whether one is a subset of the other UCOS cosine similarity between the clicked URL sets of qi and qj UJAC Jaccard coeff between the clicked URL sets of qi and qj Table 1: pairwise similarity features employed in our approach 3 Experiments 3.1 Data Set</context>
</contexts>
<marker>Li, Yang, Liu, Kitsuregawa, 2008</marker>
<rawString>L. Li, Z. Yang, L. Liu, and M. Kitsuregawa. 2008. Query-url bipartite based approach to personalized query recommendation. In AAAI’08, pp. 1189-1194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Luo</author>
</authors>
<title>On Coreference resolution performance metrics.</title>
<date>2005</date>
<booktitle>In HLTBrEMNLP,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="13995" citStr="Luo, 2005" startWordPosition="2402" endWordPosition="2403">h their subtopics according to the content words of these candidates and their clicked web pages (if there are clicked URLs for the candidate in query log). A candidate belongs to a specific subtopic if at least two annotators agree with it. At last we obtain 1,086 subtopics. We randomly split the original queries into two parts: half used for training and the rest for testing. &apos; &apos; &apos; &apos;  ( , ( )) R g R  ( , ( )) R g R   i i i i i i p( , ) , r  &apos; &apos; ( , ))   R R R R  i i i j j j 3.2 Evaluation Metrics and Baselines To evaluate the performance of our approach, we employ the measures in (Luo, 2005), which are computed as follows, where R’ is the predicted partition and R is the ground-truth partition; π(A, B) is a similarity measure between set A and B, which is Jaccard coefficient in this paper; and g(.) is the optimal mapping between R’ and R. Based on p and r, fmeasure can be calculated as, 2x px r f measure p r  The higher the f-measure score is, the better performance an approach achieves. We used the following approaches as baselines: • K-means: we perform the standard k-means clustering algorithm with different manually defined similarity measures to mine query subtopics. COS, J</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>X. Luo. 2005. On Coreference resolution performance metrics. In HLTBrEMNLP, pp. 25-32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Radlinski</author>
<author>M Szummer</author>
<author>N Craswell</author>
</authors>
<title>Inferring Query Intent from Reformulations and Clicks.</title>
<date>2010</date>
<booktitle>In WWW,</booktitle>
<pages>1171--1172</pages>
<marker>Radlinski, Szummer, Craswell, 2010</marker>
<rawString>F. Radlinski, M. Szummer, and N. Craswell. 2010. Inferring Query Intent from Reformulations and Clicks. In WWW, pp. 1171-1172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Song et</author>
<author>al</author>
</authors>
<title>Overview of the ntcir-9 intent task,</title>
<date>2011</date>
<booktitle>In NTCIR-9,</booktitle>
<pages>82--105</pages>
<marker>et, al, 2011</marker>
<rawString>R. Song et, al. 2011. Overview of the ntcir-9 intent task, In NTCIR-9, pp.82-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tsukuda</author>
<author>Z Dou</author>
<author>T Sakai</author>
</authors>
<title>Microsoft research asia at the ntcir-10 intent task.</title>
<date>2013</date>
<booktitle>In NTCIR10,</booktitle>
<pages>152--158</pages>
<contexts>
<context position="2792" citStr="Tsukuda et al. (2013)" startWordPosition="428" endWordPosition="431"> et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly. Wang et al. (2013) applied affinity propagation algorithm (Frey and Dueck, 2009) with a sense-based similarity. Tsukuda et al. (2013) used a hierarchical clustering algorithm with the similarity measure based on search results. In this paper, we argue that the similarity between queries is affected by many different factors and it could produce more desirable query subtopics by learning a similarity measure. To learn a similarity measure for query subtopic mining, a natural approach is to use a binary classifier, that is, the classifier targets pairs of queries and makes predictions about whether they belong to the same subtopic. However, because such pairwise classifiers assume that pairs are independent, they might make i</context>
</contexts>
<marker>Tsukuda, Dou, Sakai, 2013</marker>
<rawString>K. Tsukuda, Z. Dou, and T. Sakai. 2013. Microsoft research asia at the ntcir-10 intent task. In NTCIR10, pp. 152-158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Wang</author>
<author>G Tang</author>
<author>Y Xia</author>
<author>Q Hu</author>
<author>S Na</author>
<author>Y Huang</author>
<author>Q Zhou</author>
<author>F Zheng</author>
</authors>
<date>2013</date>
<booktitle>Understanding the query: THCIB and THUIS at ntcir-10 intent task. In NTCIR-10,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="2677" citStr="Wang et al. (2013)" startWordPosition="411" endWordPosition="414">ery intents into three search goals: informational, navigational, and transactional. Broder et al. (2007) and Li et al. (2005) represented query intents by topics. Clarke et al. (2009) represented query intents by subtopics which denote different senses or multiple facets of queries. Previous work on query subtopic mining is mostly based on clustering framework by manually defining a similarity measure with few factors. Hu et al. (2012) employed an agglomerative clustering algorithm with a similarity measure combining string similarities, click similarities, and keyword similarities linearly. Wang et al. (2013) applied affinity propagation algorithm (Frey and Dueck, 2009) with a sense-based similarity. Tsukuda et al. (2013) used a hierarchical clustering algorithm with the similarity measure based on search results. In this paper, we argue that the similarity between queries is affected by many different factors and it could produce more desirable query subtopics by learning a similarity measure. To learn a similarity measure for query subtopic mining, a natural approach is to use a binary classifier, that is, the classifier targets pairs of queries and makes predictions about whether they belong to</context>
</contexts>
<marker>Wang, Tang, Xia, Hu, Na, Huang, Zhou, Zheng, 2013</marker>
<rawString>J. Wang, G. Tang, Y. Xia, Q. Hu, S. Na, Y. Huang, Q. Zhou, and F. Zheng. 2013. Understanding the query: THCIB and THUIS at ntcir-10 intent task. In NTCIR-10, pp. 132-139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Yu</author>
<author>T Joachims</author>
</authors>
<title>Learning Structural SVMs with Latent Variables.</title>
<date>2009</date>
<booktitle>In ICML,</booktitle>
<pages>1169--1176</pages>
<contexts>
<context position="10193" citStr="Yu and Joachims, 2009" startWordPosition="1704" endWordPosition="1708">onstruct the partition y t = 0; y(1)=0; for i = 2...N do j = 1; while j &lt; i-1 do if h(j, i) = 1 then y(i)= y(j); break; end j = j+1; end if j &gt; i then t = t + 1; y(i) = t; end end return y 2.3 Solving the Proposed Approach For a given set of subtopic candidates with annotated subtopics, {(Sn, yn)} (1&lt;n&lt;N), we need to estimate the optimal weight w. Empirically, the optimal weight w should minimize the error between the predicted partition y’ and the true partition y, and it should also have a good generalization capability. Therefore, it is learnt by solving the following optimization problem (Yu and Joachims, 2009): 2   h H  (i,j)h  w,  2 n 1 s.t.  n, max wT    ( , ) q q i j   max [wT  (qi,q) (yn,y,h)] (y,h)YH &apos; (i,j)  h where ∆(yn, y’, h’) indicates a loss between a true partition yn and the predicted partition y’ specified by h’, �n (1≤n≤N) is a set of slack variables to allow errors in the training data, and C controls the trade-off between empirical loss and model complexity. Intuitively, the loss function ∆(yn, y’, h’) should satisfy that ∆(yn, y’, h’) = 0 if yn = y’, and rises as yn and y’ become more dissimilar. Because the all-connection structure is observable in the trainin</context>
</contexts>
<marker>Yu, Joachims, 2009</marker>
<rawString>C. J. Yu and T. Joachims. 2009. Learning Structural SVMs with Latent Variables. In ICML, pp. 1169-1176</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Yuille</author>
<author>A Rangarajan</author>
</authors>
<title>The concaveconvex procedure.</title>
<date>2003</date>
<journal>In Neural Computation,</journal>
<volume>15</volume>
<pages>915</pages>
<contexts>
<context position="11737" citStr="Yuille and Rangarajan, 2003" startWordPosition="1999" endWordPosition="2002">isagree about their cluster membership. Since the strong-connection structure hn for yn is hidden in the training data, we cannot measure the loss between (yn, hn) and (y’, h’). According to (Yu and Joachims, 2009), we define the loss function based on the inferred structure h’ as, where n(yn) and k(yn) are the number of subtopic candidates and the number of clusters in the correct clustering yn. l(yn, (i, j) ) = 1 if qi and qj are in the same cluster in yn, otherwise l(yn, (i, j) ) = −1. Then the optimization problem introduced in Eq. (2) can be solved by the Concave-Convex Procedure (CCCP) (Yuille and Rangarajan, 2003). 2.4 Pairwise Similarity Features The proposed approach requires a set of features to measure the similarity between two subtopic candidates. Table 1 lists the features employed in our approach. These features are categorized into two types: lexicon-based similarity and URLbased similarity. The lexicon-based similarity features are employed to measure the string similarity between two subtopic candidates. And the URL-based similarity features are used to measure the semantic similarity between two subtopic candidates. The basic idea is that if two queries share many clicked URLs, they have si</context>
</contexts>
<marker>Yuille, Rangarajan, 2003</marker>
<rawString>A. Yuille, and A. Rangarajan. 2003. The concaveconvex procedure. In Neural Computation, 15, 915.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>