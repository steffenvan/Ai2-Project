<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000215">
<title confidence="0.96451">
Creating a Knowledge Base From a Collaboratively Generated Encyclopedia
</title>
<author confidence="0.744664">
Simone Paolo Ponzetto
</author>
<affiliation confidence="0.558125">
EML Research gGmbH
</affiliation>
<address confidence="0.8456065">
Schloss-Wolfsbrunnenweg 33
69118 Heidelberg, Germany
</address>
<email confidence="0.956229">
http://www.eml-research.de/∼ponzetto
</email>
<sectionHeader confidence="0.992907" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999966636363636">
We present our work on using Wikipedia
as a knowledge source for Natural Lan-
guage Processing. We first describe our
previous work on computing semantic re-
latedness from Wikipedia, and its applica-
tion to a machine learning based corefer-
ence resolution system. Our results sug-
gest that Wikipedia represents a semantic
resource to be treasured for NLP applica-
tions, and accordingly present the work di-
rections to be explored in the future.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996935">
The last decade has seen statistical techniques for
Natural Language Processing (NLP) gaining the
status of standard approaches to most NLP tasks.
While advances towards robust statistical inference
methods (cf. e.g. Domingos et al. (2006) and Pun-
yakanok et al. (2006)) will certainly improve the
computational modelling of natural language, we
believe that crucial advances will also come from re-
discovering the use of symbolic knowledge, i.e. the
deployment of large scale knowledge bases.
Arguments for the necessity of symbolically en-
coded knowledge for AI and NLP date back at least
to McCarthy (1959). Symbolic approaches using
knowledge bases, however, are expensive and time-
consuming to maintain. They also have a limited
and arbitrary coverage. In our work we try to over-
come such problems by relying on a wide coverage
on-line encyclopedia developed by a large amount of
users, namely Wikipedia. That is, we are interested
in whether and how Wikipedia can be integrated into
</bodyText>
<page confidence="0.957169">
9
</page>
<bodyText confidence="0.998963">
NLP applications as a knowledge base. The motiva-
tion comes from the necessity to overcome the brit-
tleness and knowledge acquisition bottlenecks that
NLP applications suffer.
</bodyText>
<sectionHeader confidence="0.956706" genericHeader="method">
2 Previous Work: WikiRelate! and
Semantic Knowledge Sources for
Coreference Resolution
</sectionHeader>
<bodyText confidence="0.999889">
Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto
(2006) aimed at showing that ‘the encyclopedia that
anyone can edit’ can be indeed used as a semantic
resource for research in NLP. In particular, we as-
sumed its category tree to represent a semantic net-
work modelling relations between concepts, and we
computed measures of semantic relatedness from it.
We did not show only that Wikipedia-based mea-
sures of semantic relatedness are competitive with
the ones computed from a widely used standard
resource such as WordNet (Fellbaum, 1998), but
also that including semantic knowledge mined from
Wikipedia into an NLP system dealing with corefer-
ence resolution is in fact beneficial.
</bodyText>
<subsectionHeader confidence="0.99892">
2.1 WikiRelate! Computing Semantic
Relatedness Using Wikipedia
</subsectionHeader>
<bodyText confidence="0.8983575">
Semantic relatedness measures have been proven to
be useful in many NLP applications such as word
sense disambiguation (Kohomban &amp; Lee, 2005; Pat-
wardhan et al., 2005), information retrieval (Finkel-
stein et al., 2002), information extraction pattern
induction (Stevenson &amp; Greenwood, 2005), inter-
pretation of noun compounds (Kim &amp; Baldwin,
2005), paraphrase detection (Mihalcea et al., 2006)
and spelling correction (Budanitsky &amp; Hirst, 2006).
Approaches to measuring semantic relatedness that
Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12,
Rochester, April 2007. c�2007 Association for Computational Linguistics
</bodyText>
<figure confidence="0.9567417">
&amp;quot;John Zorn&amp;quot; query
&amp;quot;Fela Kuti&amp;quot; query
page : John Zorn
Jazz composers
Composers
Musicians
Musical activists
page : Fela Kuti
relatedness measure(s) computation
page query and retrieval, category extraction search for a connecting path along the category network
</figure>
<figureCaption confidence="0.6779258">
Figure 1: Wikipedia-based semantic relatedness computation. First, target pages for the given queries are re-
trieved, possibly via disambiguation. Next, categories are extracted to provide an entry point to the category
network. Connecting paths are then searched along the category network using a depth-limited search. The
paths found are scored and the ones satisfying the measure definitions (i.e. the shortest one for path-length
measures, and the most informative one for information-content measures) are returned.
</figureCaption>
<bodyText confidence="0.99651065">
use lexical resources transform that resource into
a network or graph and compute relatedness us-
ing paths in it1. For instance, Rada et al. (1989)
traverse MeSH, a term hierarchy for indexing arti-
cles in Medline, and compute semantic relatedness
as the edge distance between terms in the hierar-
chy. Jarmasz &amp; Szpakowicz (2003) use the same
approach with Roget’s Thesaurus while Hirst &amp; St-
Onge (1998) apply a similar strategy to WordNet.
The novel idea presented in Strube &amp; Ponzetto
(2006) was to induce a semantic network from the
Wikipedia categorization graph to compute mea-
sures of semantic relatedness. Wikipedia, a multi-
lingual Web-based free-content encyclopedia, al-
lows for structured access by means of categories:
the encyclopedia articles can be assigned one or
more categories, which are further categorized to
provide a so-called “category tree”. Though not de-
1An overview of lexical resource-based approaches to mea-
suring semantic relatedness is presented in Budanitsky &amp; Hirst
(2006). Note that here we do not distinguish between seman-
tic similarity (computed using hyponymy/hyperonymy, i.e. is-
a, relations only) and semantic relatedness (using all relations
in the taxonomy, including antonymic, meronymic, functional
relations such as is-made-of, etc.), since the relations between
categories in Wikipedia are neither semantically typed nor show
a uniform semantics (see Section 3).
signed as a strict hierarchy or tree, the categories
form a graph which can be used as a taxonomy to
compute semantic relatedness. We showed (1) how
to retrieve Wikipedia articles from textual queries
and resolve ambiguous queries based on the arti-
cles’ link structure; (2) compute semantic related-
ness as a function of the articles found and the paths
between them along the categorization graph (Fig-
ure 1). We evaluated the Wikipedia-based measures
against the ones computed from WordNet on bench-
marking datasets from the literature (e.g. Miller and
Charles’ (1991) list of 30 noun pairs) and found
Wikipedia to be competitive with WordNet.
</bodyText>
<subsectionHeader confidence="0.999102">
2.2 Semantic Knowledge Sources for
Coreference Resolution
</subsectionHeader>
<bodyText confidence="0.9999747">
Evaluating measures of semantic relatedness on
word pair datasets poses non-trivial problems, i.e.
all available datasets are small in size, and it is not
always clear which linguistic notion (i.e. similar-
ity vs. relatedness) underlies them. Accordingly, in
Ponzetto &amp; Strube (2006) we used a machine learn-
ing based coreference resolution system to provide
an extrinsic evaluation of the utility of WordNet and
Wikipedia relatedness measures for NLP applica-
tions. We started with the machine learning based
</bodyText>
<page confidence="0.887307">
10
</page>
<figure confidence="0.98506475">
Pre
processing
pipeline
PoS tagger
Chunker
NER
SEMANTICS
(Soon
Semantic Feature
extractor
Wikipedia
WordNet
Baseline Feature Extractor
et al., 2001)
Raw text
MaxEnt
classifier
Text annotated
nce chains
Prince
Fela Kuti
the pioneer of Afrobeat music
The Minneapolis Genius
he
The artist formerly known as Prince
TAFKAP
The Artist
Prince
Fela Kuti
the pioneer of Afrobeat music
The Minneapolis Genius
he
The artist formerly known as Prince
TAFKAP
The Artist
ce variations.
</figure>
<figureCaption confidence="0.458057">
features from WordNet and Wikipedia and register performan
</figureCaption>
<bodyText confidence="0.998751">
ce only
slightly worse than when using WordNet.
induced from Wikipedia gives a performan
</bodyText>
<sectionHeader confidence="0.753937666666667" genericHeader="method">
3 Future Work: Inducing an Ontology
from a Collaboratively Generated
Encyclopedia
</sectionHeader>
<bodyText confidence="0.924740169230769">
than
semantic relatedness (Budanitsky &amp;Hirst,
2006), which is more suitable for coreference res-
olution. That is, we assume that the availability
of hyponymic/hyperonymic relations will allow us
to compute lexical semantic measures which will
further increase the performance of our coreference
resolution system, as well as further bringing for-
ward Wikipedia as a direct competitor of manually-
designed resources such as WordNet.
In order to make the task feasible, we are currently
concentrating on inducing is-a
not-is-a semantic
relations. This simplifies the task, but still allows
us to compute measures of semantic similarity. As
we made limited use of the large amount of text in
Wikipedia, we are now trying to integrate text and
categorization. This includes extracting semantic re-
lations expressed in the encyclopedic definitions by
means of Hearst patterns (Hearst, 1992), detection
of semantic variations (Morin &amp;Jacquemin, 1999)
between category labels, as well as using the cat-
egorized pages as
to compute scores
of
semantic overlap
&amp; de Rijke,
2001) between categories. Further work will then
concentrate on making this information available to
our coreference resolution system, e.g.
semantic
similarity computation.
Finally, since Wikipedia is available in many lan-
guages, we believe it is worth performing experi-
ments in a multilingual setting. Accordingly, we are
currently testing a website2 that will allow us to col-
vs.
bag-of-words
idf-based
(Monz
via
speak-
Our results so far suggest that Wikipedia can be con-
sidered asemantic resource in its own right. Un-
fortunately, the Wikipedia categorization still suf-
fers from some limitations: it cannot be considered
an ontology, as the relations between categories are
not semantically-typed, i.e. the links between cate-
gories do not have an explicit semantics such as is-a,
part-of, etc. Work in the near future will accordingly
concentrate on automatically inducing the semantics
of the relations between Wikipedia categories. This
aims at transforming the unlabeled graph in Figure
3(a) into the semantic network in Figure 3(b), where
the links between categories are augmented with a
clearly defined semantics.
The availability of explicit semantic relations
would allow to compute semantic similarity rather
lect word relatedness judgements from native
baseline system from Soon et al. (2001), and an-
alyzed the performance variations given by includ-
ing the relatedness measures in the feature set (Fig-
ure 2). The results showed that coreference resolu-
tion benefits from information mined from seman-
tic knowledge sources and also, that using features
</bodyText>
<figure confidence="0.476377">
with corefere
</figure>
<figureCaption confidence="0.969844">
Figure 2: Overview of the coreference system for extrinsic evaluation of WordNet and Wikipedia relatedness
measures. We start with a baseline system from Soon et al. (2001). We then include at different times
</figureCaption>
<footnote confidence="0.995659">
2Available at http://www.eml-research.de/nlp/353-TC.
</footnote>
<page confidence="0.997992">
11
</page>
<figure confidence="0.99479782">
Artificial Intelligence applications Cognitive architecture
Cybernetics
Artificial Intelligence
Natural Language Processing
Speech recognition
Computer Science
Cognitive Science
Cognition
Computational Linguistics
Linguistics
Mathematics
Abstraction
Mathematical logic Pataphysics
Thought
Philosophy
Branches of philosophy
Logic Metaphysics
Belief
Ontology
PART-OF
Artificial Intelligence applications Cognitive architecture
Cybernetics
Natural Language Processing
Artificial Intelligence
Speech recognition
IS-A PART-OF
Computer Science
Cognitive Science
Linguistics
PART-OF
IS-A
Computational Linguistics
Mathematics
Cognition
Mathematical logic
PART-OF
Abstraction
Thought
Logic Metaphysics
IS-A
Ontology
PART-OF
Belief
Philosophy
IS-A
Branches of philosophy
IS-A
Pataphysics
IS-NOT
(a) current category graph (b) category graph augmented with semantic relations
</figure>
<figureCaption confidence="0.999826">
Figure 3: Inducing explicit semantic relations between categories in Wikipedia
</figureCaption>
<bodyText confidence="0.9983605">
ers of German, French and Italian, in order to trans-
late the semantic relatedness dataset from Finkel-
stein et al. (2002) and test our methodology with
languages other than English.
</bodyText>
<sectionHeader confidence="0.99979" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999407928571429">
In this paper we presented our previous efforts on us-
ing Wikipedia as a semantic knowledge source. We
aim in the future to induce an ontology from its col-
laboratively generated categorization graph. We be-
lieve that our work opens up exciting new challenges
for the AI and NLP research community, e.g. how to
handle the noise included in such knowledge bases
and how to fully structure the information given in
the form of only partially structured text and rela-
tions between knowledge base entries.
Acknowledgements: This work has been funded
by the Klaus Tschira Foundation, Heidelberg, Ger-
many. The author has been supported by a KTF
grant (09.003.2004).
</bodyText>
<sectionHeader confidence="0.998587" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999795523809524">
Budanitsky, A. &amp; G. Hirst (2006). Evaluating WordNet-based
measures of semantic distance. Computational Linguistics,
32(1).
Domingos, P., S. Kok, H. Poon, M. Richardson &amp; P. Singla
(2006). Unifying logical and statistical AI. In Proc. ofAAAI-
06, pp. 2–7.
Fellbaum, C. (Ed.) (1998). WordNet: An Electronic Lexical
Database. Cambridge, Mass.: MIT Press.
Finkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan,
G. Wolfman &amp; E. Ruppin (2002). Placing search in context:
The concept revisited. ACM Transactions on Information
Systems, 20(1):116–131.
Hearst, M. A. (1992). Automatic acquisition ofhyponyms from
large text corpora. In Proc. of COLING-92, pp. 539–545.
Hirst, G. &amp; D. St-Onge (1998). Lexical chains as repre-
sentations of context for the detection and correction of
malapropisms. In C. Fellbaum (Ed.), WordNet: An Elec-
tronic Lexical Database, pp. 305–332. Cambridge, Mass.:
MIT Press.
Jarmasz, M. &amp; S. Szpakowicz (2003). Roget’s Thesaurus and
semantic similarity. In Proc. ofRANLP-03, pp. 212–219.
Kim, S. N. &amp; T. Baldwin (2005). Automatic interpretation
of noun compounds using WordNet similarity. In Proc. of
IJCNLP-05, pp. 945–956.
Kohomban, U. S. &amp; W. S. Lee (2005). Learning semantic
classes for word sense disambiguation. In Proc. of ACL-05,
pp. 34–41.
McCarthy, J. (1959). Programs with common sense. In Pro-
ceedings of the Teddington Conference on the Mechanization
of Thought Processes, pp. 75–91.
Mihalcea, R., C. Corley &amp; C. Strapparava (2006). Corpus-based
and knowledge-based measures of text semantic similarity.
In Proc. ofAAAI-06, pp. 775–780.
Miller, G. A. &amp; W. G. Charles (1991). Contextual correlates
of semantic similarity. Language and Cognitive Processes,
6(1):1–28.
Monz, C. &amp; M. de Rijke (2001). Light-weight entailment
checking for computational semantics. In Proc. of ICoS-3,
pp. 59–72.
Morin, E. &amp; C. Jacquemin (1999). Projecting corpus-based se-
mantic links on a thesaurus. In Proc. of ACL-99, pp. 389–
396.
Patwardhan, S., S. Banerjee &amp; T. Pedersen (2005). SenseRe-
late::TargetWord – A generalized framework for word sense
disambiguation. In Proc. ofAAAI-05.
Ponzetto, S. P. &amp; M. Strube (2006). Exploiting semantic role
labeling, WordNet and Wikipedia for coreference resolution.
In Proc. of HLT-NAACL-06, pp. 192–199.
Punyakanok, V., D. Roth, W. Yih &amp; D. Zimak (2006). Learning
and inference over constrained output. In Proc. ofIJCAI-05,
pp. 1117–1123.
Rada, R., H. Mili, E. Bicknell &amp; M. Blettner (1989). Devel-
opment and application of a metric to semantic nets. IEEE
Transactions on Systems, Man and Cybernetics, 19(1):17–
30.
Soon, W. M., H. T. Ng &amp; D. C. Y. Lim (2001). A machine
learning approach to coreference resolution of noun phrases.
Computational Linguistics, 27(4):521–544.
Stevenson, M. &amp; M. Greenwood (2005). A semantic approach
to IE pattern induction. In Proc. ofACL-05, pp. 379–386.
Strube, M. &amp; S. P. Ponzetto (2006). WikiRelate! Computing
semantic relatedness using Wikipedia. In Proc. of AAAI-06,
pp. 1419–1424.
</reference>
<page confidence="0.99846">
12
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.818015">
<title confidence="0.999524">Creating a Knowledge Base From a Collaboratively Generated Encyclopedia</title>
<author confidence="0.998856">Simone Paolo Ponzetto</author>
<affiliation confidence="0.969692">EML Research gGmbH</affiliation>
<address confidence="0.967257">Schloss-Wolfsbrunnenweg 33 69118 Heidelberg, Germany</address>
<abstract confidence="0.99063825">We present our work on using Wikipedia as a knowledge source for Natural Language Processing. We first describe our previous work on computing semantic relatedness from Wikipedia, and its application to a machine learning based coreference resolution system. Our results suggest that Wikipedia represents a semantic resource to be treasured for NLP applications, and accordingly present the work directions to be explored in the future.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Budanitsky</author>
<author>G Hirst</author>
</authors>
<title>Evaluating WordNet-based measures of semantic distance.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<contexts>
<context position="3094" citStr="Budanitsky &amp; Hirst, 2006" startWordPosition="466" endWordPosition="469">ng semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists page : Fela Kuti relatedness measure(s) computation page query and retrieval, category extraction search for a connecting path along the category network Figure 1: Wikipedia-based semantic relatedness computation. First, target pages for the given queries are retrieved, possibly via disambiguation. Nex</context>
<context position="5064" citStr="Budanitsky &amp; Hirst (2006)" startWordPosition="758" endWordPosition="761">hile Hirst &amp; StOnge (1998) apply a similar strategy to WordNet. The novel idea presented in Strube &amp; Ponzetto (2006) was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness. Wikipedia, a multilingual Web-based free-content encyclopedia, allows for structured access by means of categories: the encyclopedia articles can be assigned one or more categories, which are further categorized to provide a so-called “category tree”. Though not de1An overview of lexical resource-based approaches to measuring semantic relatedness is presented in Budanitsky &amp; Hirst (2006). Note that here we do not distinguish between semantic similarity (computed using hyponymy/hyperonymy, i.e. isa, relations only) and semantic relatedness (using all relations in the taxonomy, including antonymic, meronymic, functional relations such as is-made-of, etc.), since the relations between categories in Wikipedia are neither semantically typed nor show a uniform semantics (see Section 3). signed as a strict hierarchy or tree, the categories form a graph which can be used as a taxonomy to compute semantic relatedness. We showed (1) how to retrieve Wikipedia articles from textual queri</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Budanitsky, A. &amp; G. Hirst (2006). Evaluating WordNet-based measures of semantic distance. Computational Linguistics, 32(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Domingos</author>
<author>S Kok</author>
<author>H Poon</author>
<author>M Richardson</author>
<author>P Singla</author>
</authors>
<title>Unifying logical and statistical AI.</title>
<date>2006</date>
<booktitle>In Proc. ofAAAI06,</booktitle>
<pages>2--7</pages>
<contexts>
<context position="903" citStr="Domingos et al. (2006)" startWordPosition="127" endWordPosition="130">ral Language Processing. We first describe our previous work on computing semantic relatedness from Wikipedia, and its application to a machine learning based coreference resolution system. Our results suggest that Wikipedia represents a semantic resource to be treasured for NLP applications, and accordingly present the work directions to be explored in the future. 1 Introduction The last decade has seen statistical techniques for Natural Language Processing (NLP) gaining the status of standard approaches to most NLP tasks. While advances towards robust statistical inference methods (cf. e.g. Domingos et al. (2006) and Punyakanok et al. (2006)) will certainly improve the computational modelling of natural language, we believe that crucial advances will also come from rediscovering the use of symbolic knowledge, i.e. the deployment of large scale knowledge bases. Arguments for the necessity of symbolically encoded knowledge for AI and NLP date back at least to McCarthy (1959). Symbolic approaches using knowledge bases, however, are expensive and timeconsuming to maintain. They also have a limited and arbitrary coverage. In our work we try to overcome such problems by relying on a wide coverage on-line en</context>
</contexts>
<marker>Domingos, Kok, Poon, Richardson, Singla, 2006</marker>
<rawString>Domingos, P., S. Kok, H. Poon, M. Richardson &amp; P. Singla (2006). Unifying logical and statistical AI. In Proc. ofAAAI06, pp. 2–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="2446" citStr="Fellbaum, 1998" startWordPosition="375" endWordPosition="376">ious Work: WikiRelate! and Semantic Knowledge Sources for Coreference Resolution Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto (2006) aimed at showing that ‘the encyclopedia that anyone can edit’ can be indeed used as a semantic resource for research in NLP. In particular, we assumed its category tree to represent a semantic network modelling relations between concepts, and we computed measures of semantic relatedness from it. We did not show only that Wikipedia-based measures of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) an</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. (Ed.) (1998). WordNet: An Electronic Lexical Database. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Finkelstein</author>
<author>E Gabrilovich</author>
<author>Y Matias</author>
<author>E Rivlin</author>
<author>Z Solan</author>
<author>G Wolfman</author>
<author>E Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2002</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="2869" citStr="Finkelstein et al., 2002" startWordPosition="435" endWordPosition="439">latedness from it. We did not show only that Wikipedia-based measures of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists page : Fela Kuti relatedness measure(s) computation page query and retrieval, </context>
<context position="11341" citStr="Finkelstein et al. (2002)" startWordPosition="1667" endWordPosition="1671">ural Language Processing Artificial Intelligence Speech recognition IS-A PART-OF Computer Science Cognitive Science Linguistics PART-OF IS-A Computational Linguistics Mathematics Cognition Mathematical logic PART-OF Abstraction Thought Logic Metaphysics IS-A Ontology PART-OF Belief Philosophy IS-A Branches of philosophy IS-A Pataphysics IS-NOT (a) current category graph (b) category graph augmented with semantic relations Figure 3: Inducing explicit semantic relations between categories in Wikipedia ers of German, French and Italian, in order to translate the semantic relatedness dataset from Finkelstein et al. (2002) and test our methodology with languages other than English. 4 Conclusions In this paper we presented our previous efforts on using Wikipedia as a semantic knowledge source. We aim in the future to induce an ontology from its collaboratively generated categorization graph. We believe that our work opens up exciting new challenges for the AI and NLP research community, e.g. how to handle the noise included in such knowledge bases and how to fully structure the information given in the form of only partially structured text and relations between knowledge base entries. Acknowledgements: This wor</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2002</marker>
<rawString>Finkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin, Z. Solan, G. Wolfman &amp; E. Ruppin (2002). Placing search in context: The concept revisited. ACM Transactions on Information Systems, 20(1):116–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Hearst</author>
</authors>
<title>Automatic acquisition ofhyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of COLING-92,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="8259" citStr="Hearst, 1992" startWordPosition="1244" endWordPosition="1245">rmance of our coreference resolution system, as well as further bringing forward Wikipedia as a direct competitor of manuallydesigned resources such as WordNet. In order to make the task feasible, we are currently concentrating on inducing is-a not-is-a semantic relations. This simplifies the task, but still allows us to compute measures of semantic similarity. As we made limited use of the large amount of text in Wikipedia, we are now trying to integrate text and categorization. This includes extracting semantic relations expressed in the encyclopedic definitions by means of Hearst patterns (Hearst, 1992), detection of semantic variations (Morin &amp;Jacquemin, 1999) between category labels, as well as using the categorized pages as to compute scores of semantic overlap &amp; de Rijke, 2001) between categories. Further work will then concentrate on making this information available to our coreference resolution system, e.g. semantic similarity computation. Finally, since Wikipedia is available in many languages, we believe it is worth performing experiments in a multilingual setting. Accordingly, we are currently testing a website2 that will allow us to colvs. bag-of-words idf-based (Monz via speakOur</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Hearst, M. A. (1992). Automatic acquisition ofhyponyms from large text corpora. In Proc. of COLING-92, pp. 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hirst</author>
<author>D St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms.</title>
<date>1998</date>
<booktitle>In C. Fellbaum (Ed.), WordNet: An Electronic Lexical Database,</booktitle>
<pages>305--332</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Hirst, G. &amp; D. St-Onge (1998). Lexical chains as representations of context for the detection and correction of malapropisms. In C. Fellbaum (Ed.), WordNet: An Electronic Lexical Database, pp. 305–332. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jarmasz</author>
<author>S Szpakowicz</author>
</authors>
<title>Roget’s Thesaurus and semantic similarity.</title>
<date>2003</date>
<booktitle>In Proc. ofRANLP-03,</booktitle>
<pages>212--219</pages>
<contexts>
<context position="4392" citStr="Jarmasz &amp; Szpakowicz (2003)" startWordPosition="655" endWordPosition="658">etwork. Connecting paths are then searched along the category network using a depth-limited search. The paths found are scored and the ones satisfying the measure definitions (i.e. the shortest one for path-length measures, and the most informative one for information-content measures) are returned. use lexical resources transform that resource into a network or graph and compute relatedness using paths in it1. For instance, Rada et al. (1989) traverse MeSH, a term hierarchy for indexing articles in Medline, and compute semantic relatedness as the edge distance between terms in the hierarchy. Jarmasz &amp; Szpakowicz (2003) use the same approach with Roget’s Thesaurus while Hirst &amp; StOnge (1998) apply a similar strategy to WordNet. The novel idea presented in Strube &amp; Ponzetto (2006) was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness. Wikipedia, a multilingual Web-based free-content encyclopedia, allows for structured access by means of categories: the encyclopedia articles can be assigned one or more categories, which are further categorized to provide a so-called “category tree”. Though not de1An overview of lexical resource-based approaches to </context>
</contexts>
<marker>Jarmasz, Szpakowicz, 2003</marker>
<rawString>Jarmasz, M. &amp; S. Szpakowicz (2003). Roget’s Thesaurus and semantic similarity. In Proc. ofRANLP-03, pp. 212–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S N Kim</author>
<author>T Baldwin</author>
</authors>
<title>Automatic interpretation of noun compounds using WordNet similarity.</title>
<date>2005</date>
<booktitle>In Proc. of IJCNLP-05,</booktitle>
<pages>945--956</pages>
<contexts>
<context position="2997" citStr="Kim &amp; Baldwin, 2005" startWordPosition="453" endWordPosition="456">from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists page : Fela Kuti relatedness measure(s) computation page query and retrieval, category extraction search for a connecting path along the category network Figure 1: Wikipedia-based semantic relatedness compu</context>
</contexts>
<marker>Kim, Baldwin, 2005</marker>
<rawString>Kim, S. N. &amp; T. Baldwin (2005). Automatic interpretation of noun compounds using WordNet similarity. In Proc. of IJCNLP-05, pp. 945–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U S Kohomban</author>
<author>W S Lee</author>
</authors>
<title>Learning semantic classes for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proc. of ACL-05,</booktitle>
<pages>34--41</pages>
<contexts>
<context position="2793" citStr="Kohomban &amp; Lee, 2005" startWordPosition="424" endWordPosition="427">ing relations between concepts, and we computed measures of semantic relatedness from it. We did not show only that Wikipedia-based measures of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists pa</context>
</contexts>
<marker>Kohomban, Lee, 2005</marker>
<rawString>Kohomban, U. S. &amp; W. S. Lee (2005). Learning semantic classes for word sense disambiguation. In Proc. of ACL-05, pp. 34–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McCarthy</author>
</authors>
<title>Programs with common sense.</title>
<date>1959</date>
<booktitle>In Proceedings of the Teddington Conference on the Mechanization of Thought Processes,</booktitle>
<pages>75--91</pages>
<contexts>
<context position="1270" citStr="McCarthy (1959)" startWordPosition="188" endWordPosition="189">oduction The last decade has seen statistical techniques for Natural Language Processing (NLP) gaining the status of standard approaches to most NLP tasks. While advances towards robust statistical inference methods (cf. e.g. Domingos et al. (2006) and Punyakanok et al. (2006)) will certainly improve the computational modelling of natural language, we believe that crucial advances will also come from rediscovering the use of symbolic knowledge, i.e. the deployment of large scale knowledge bases. Arguments for the necessity of symbolically encoded knowledge for AI and NLP date back at least to McCarthy (1959). Symbolic approaches using knowledge bases, however, are expensive and timeconsuming to maintain. They also have a limited and arbitrary coverage. In our work we try to overcome such problems by relying on a wide coverage on-line encyclopedia developed by a large amount of users, namely Wikipedia. That is, we are interested in whether and how Wikipedia can be integrated into 9 NLP applications as a knowledge base. The motivation comes from the necessity to overcome the brittleness and knowledge acquisition bottlenecks that NLP applications suffer. 2 Previous Work: WikiRelate! and Semantic Kno</context>
</contexts>
<marker>McCarthy, 1959</marker>
<rawString>McCarthy, J. (1959). Programs with common sense. In Proceedings of the Teddington Conference on the Mechanization of Thought Processes, pp. 75–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Corley</author>
<author>C Strapparava</author>
</authors>
<title>Corpus-based and knowledge-based measures of text semantic similarity.</title>
<date>2006</date>
<booktitle>In Proc. ofAAAI-06,</booktitle>
<pages>775--780</pages>
<contexts>
<context position="3043" citStr="Mihalcea et al., 2006" startWordPosition="459" endWordPosition="462"> WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists page : Fela Kuti relatedness measure(s) computation page query and retrieval, category extraction search for a connecting path along the category network Figure 1: Wikipedia-based semantic relatedness computation. First, target pages for the given quer</context>
</contexts>
<marker>Mihalcea, Corley, Strapparava, 2006</marker>
<rawString>Mihalcea, R., C. Corley &amp; C. Strapparava (2006). Corpus-based and knowledge-based measures of text semantic similarity. In Proc. ofAAAI-06, pp. 775–780.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>W G Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<marker>Miller, Charles, 1991</marker>
<rawString>Miller, G. A. &amp; W. G. Charles (1991). Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monz</author>
<author>M de Rijke</author>
</authors>
<title>Light-weight entailment checking for computational semantics.</title>
<date>2001</date>
<booktitle>In Proc. of ICoS-3,</booktitle>
<pages>59--72</pages>
<marker>Monz, de Rijke, 2001</marker>
<rawString>Monz, C. &amp; M. de Rijke (2001). Light-weight entailment checking for computational semantics. In Proc. of ICoS-3, pp. 59–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Morin</author>
<author>C Jacquemin</author>
</authors>
<title>Projecting corpus-based semantic links on a thesaurus.</title>
<date>1999</date>
<booktitle>In Proc. of ACL-99,</booktitle>
<pages>389--396</pages>
<marker>Morin, Jacquemin, 1999</marker>
<rawString>Morin, E. &amp; C. Jacquemin (1999). Projecting corpus-based semantic links on a thesaurus. In Proc. of ACL-99, pp. 389– 396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Patwardhan</author>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>SenseRelate::TargetWord – A generalized framework for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proc. ofAAAI-05.</booktitle>
<contexts>
<context position="2819" citStr="Patwardhan et al., 2005" startWordPosition="428" endWordPosition="432">concepts, and we computed measures of semantic relatedness from it. We did not show only that Wikipedia-based measures of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists page : Fela Kuti relatedness</context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2005</marker>
<rawString>Patwardhan, S., S. Banerjee &amp; T. Pedersen (2005). SenseRelate::TargetWord – A generalized framework for word sense disambiguation. In Proc. ofAAAI-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S P Ponzetto</author>
<author>M Strube</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution.</title>
<date>2006</date>
<booktitle>In Proc. of HLT-NAACL-06,</booktitle>
<pages>192--199</pages>
<contexts>
<context position="1936" citStr="Ponzetto &amp; Strube (2006)" startWordPosition="290" endWordPosition="293">s, however, are expensive and timeconsuming to maintain. They also have a limited and arbitrary coverage. In our work we try to overcome such problems by relying on a wide coverage on-line encyclopedia developed by a large amount of users, namely Wikipedia. That is, we are interested in whether and how Wikipedia can be integrated into 9 NLP applications as a knowledge base. The motivation comes from the necessity to overcome the brittleness and knowledge acquisition bottlenecks that NLP applications suffer. 2 Previous Work: WikiRelate! and Semantic Knowledge Sources for Coreference Resolution Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto (2006) aimed at showing that ‘the encyclopedia that anyone can edit’ can be indeed used as a semantic resource for research in NLP. In particular, we assumed its category tree to represent a semantic network modelling relations between concepts, and we computed measures of semantic relatedness from it. We did not show only that Wikipedia-based measures of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system deali</context>
<context position="6449" citStr="Ponzetto &amp; Strube (2006)" startWordPosition="968" endWordPosition="971">n them along the categorization graph (Figure 1). We evaluated the Wikipedia-based measures against the ones computed from WordNet on benchmarking datasets from the literature (e.g. Miller and Charles’ (1991) list of 30 noun pairs) and found Wikipedia to be competitive with WordNet. 2.2 Semantic Knowledge Sources for Coreference Resolution Evaluating measures of semantic relatedness on word pair datasets poses non-trivial problems, i.e. all available datasets are small in size, and it is not always clear which linguistic notion (i.e. similarity vs. relatedness) underlies them. Accordingly, in Ponzetto &amp; Strube (2006) we used a machine learning based coreference resolution system to provide an extrinsic evaluation of the utility of WordNet and Wikipedia relatedness measures for NLP applications. We started with the machine learning based 10 Pre processing pipeline PoS tagger Chunker NER SEMANTICS (Soon Semantic Feature extractor Wikipedia WordNet Baseline Feature Extractor et al., 2001) Raw text MaxEnt classifier Text annotated nce chains Prince Fela Kuti the pioneer of Afrobeat music The Minneapolis Genius he The artist formerly known as Prince TAFKAP The Artist Prince Fela Kuti the pioneer of Afrobeat mu</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Ponzetto, S. P. &amp; M. Strube (2006). Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In Proc. of HLT-NAACL-06, pp. 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
<author>D Zimak</author>
</authors>
<title>Learning and inference over constrained output.</title>
<date>2006</date>
<booktitle>In Proc. ofIJCAI-05,</booktitle>
<pages>1117--1123</pages>
<contexts>
<context position="932" citStr="Punyakanok et al. (2006)" startWordPosition="132" endWordPosition="136"> first describe our previous work on computing semantic relatedness from Wikipedia, and its application to a machine learning based coreference resolution system. Our results suggest that Wikipedia represents a semantic resource to be treasured for NLP applications, and accordingly present the work directions to be explored in the future. 1 Introduction The last decade has seen statistical techniques for Natural Language Processing (NLP) gaining the status of standard approaches to most NLP tasks. While advances towards robust statistical inference methods (cf. e.g. Domingos et al. (2006) and Punyakanok et al. (2006)) will certainly improve the computational modelling of natural language, we believe that crucial advances will also come from rediscovering the use of symbolic knowledge, i.e. the deployment of large scale knowledge bases. Arguments for the necessity of symbolically encoded knowledge for AI and NLP date back at least to McCarthy (1959). Symbolic approaches using knowledge bases, however, are expensive and timeconsuming to maintain. They also have a limited and arbitrary coverage. In our work we try to overcome such problems by relying on a wide coverage on-line encyclopedia developed by a lar</context>
</contexts>
<marker>Punyakanok, Roth, Yih, Zimak, 2006</marker>
<rawString>Punyakanok, V., D. Roth, W. Yih &amp; D. Zimak (2006). Learning and inference over constrained output. In Proc. ofIJCAI-05, pp. 1117–1123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Rada</author>
<author>H Mili</author>
<author>E Bicknell</author>
<author>M Blettner</author>
</authors>
<title>Development and application of a metric to semantic nets.</title>
<date>1989</date>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>30</pages>
<contexts>
<context position="4212" citStr="Rada et al. (1989)" startWordPosition="626" endWordPosition="629">mputation. First, target pages for the given queries are retrieved, possibly via disambiguation. Next, categories are extracted to provide an entry point to the category network. Connecting paths are then searched along the category network using a depth-limited search. The paths found are scored and the ones satisfying the measure definitions (i.e. the shortest one for path-length measures, and the most informative one for information-content measures) are returned. use lexical resources transform that resource into a network or graph and compute relatedness using paths in it1. For instance, Rada et al. (1989) traverse MeSH, a term hierarchy for indexing articles in Medline, and compute semantic relatedness as the edge distance between terms in the hierarchy. Jarmasz &amp; Szpakowicz (2003) use the same approach with Roget’s Thesaurus while Hirst &amp; StOnge (1998) apply a similar strategy to WordNet. The novel idea presented in Strube &amp; Ponzetto (2006) was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness. Wikipedia, a multilingual Web-based free-content encyclopedia, allows for structured access by means of categories: the encyclopedia artic</context>
</contexts>
<marker>Rada, Mili, Bicknell, Blettner, 1989</marker>
<rawString>Rada, R., H. Mili, E. Bicknell &amp; M. Blettner (1989). Development and application of a metric to semantic nets. IEEE Transactions on Systems, Man and Cybernetics, 19(1):17– 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M Soon</author>
<author>H T Ng</author>
<author>D C Y Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrases.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<contexts>
<context position="9739" citStr="Soon et al. (2001)" startWordPosition="1465" endWordPosition="1468">ically-typed, i.e. the links between categories do not have an explicit semantics such as is-a, part-of, etc. Work in the near future will accordingly concentrate on automatically inducing the semantics of the relations between Wikipedia categories. This aims at transforming the unlabeled graph in Figure 3(a) into the semantic network in Figure 3(b), where the links between categories are augmented with a clearly defined semantics. The availability of explicit semantic relations would allow to compute semantic similarity rather lect word relatedness judgements from native baseline system from Soon et al. (2001), and analyzed the performance variations given by including the relatedness measures in the feature set (Figure 2). The results showed that coreference resolution benefits from information mined from semantic knowledge sources and also, that using features with corefere Figure 2: Overview of the coreference system for extrinsic evaluation of WordNet and Wikipedia relatedness measures. We start with a baseline system from Soon et al. (2001). We then include at different times 2Available at http://www.eml-research.de/nlp/353-TC. 11 Artificial Intelligence applications Cognitive architecture Cyb</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Soon, W. M., H. T. Ng &amp; D. C. Y. Lim (2001). A machine learning approach to coreference resolution of noun phrases. Computational Linguistics, 27(4):521–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
<author>M Greenwood</author>
</authors>
<title>A semantic approach to IE pattern induction.</title>
<date>2005</date>
<booktitle>In Proc. ofACL-05,</booktitle>
<pages>379--386</pages>
<contexts>
<context position="2941" citStr="Stevenson &amp; Greenwood, 2005" startWordPosition="444" endWordPosition="447"> of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolution is in fact beneficial. 2.1 WikiRelate! Computing Semantic Relatedness Using Wikipedia Semantic relatedness measures have been proven to be useful in many NLP applications such as word sense disambiguation (Kohomban &amp; Lee, 2005; Patwardhan et al., 2005), information retrieval (Finkelstein et al., 2002), information extraction pattern induction (Stevenson &amp; Greenwood, 2005), interpretation of noun compounds (Kim &amp; Baldwin, 2005), paraphrase detection (Mihalcea et al., 2006) and spelling correction (Budanitsky &amp; Hirst, 2006). Approaches to measuring semantic relatedness that Proceedings of the NAACL-HLT 2007 Doctoral Consortium, pages 9–12, Rochester, April 2007. c�2007 Association for Computational Linguistics &amp;quot;John Zorn&amp;quot; query &amp;quot;Fela Kuti&amp;quot; query page : John Zorn Jazz composers Composers Musicians Musical activists page : Fela Kuti relatedness measure(s) computation page query and retrieval, category extraction search for a connecting path along the category netw</context>
</contexts>
<marker>Stevenson, Greenwood, 2005</marker>
<rawString>Stevenson, M. &amp; M. Greenwood (2005). A semantic approach to IE pattern induction. In Proc. ofACL-05, pp. 379–386.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S P Ponzetto</author>
</authors>
<title>WikiRelate! Computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<booktitle>In Proc. of AAAI-06,</booktitle>
<pages>1419--1424</pages>
<contexts>
<context position="1965" citStr="Strube &amp; Ponzetto (2006)" startWordPosition="295" endWordPosition="298"> timeconsuming to maintain. They also have a limited and arbitrary coverage. In our work we try to overcome such problems by relying on a wide coverage on-line encyclopedia developed by a large amount of users, namely Wikipedia. That is, we are interested in whether and how Wikipedia can be integrated into 9 NLP applications as a knowledge base. The motivation comes from the necessity to overcome the brittleness and knowledge acquisition bottlenecks that NLP applications suffer. 2 Previous Work: WikiRelate! and Semantic Knowledge Sources for Coreference Resolution Ponzetto &amp; Strube (2006) and Strube &amp; Ponzetto (2006) aimed at showing that ‘the encyclopedia that anyone can edit’ can be indeed used as a semantic resource for research in NLP. In particular, we assumed its category tree to represent a semantic network modelling relations between concepts, and we computed measures of semantic relatedness from it. We did not show only that Wikipedia-based measures of semantic relatedness are competitive with the ones computed from a widely used standard resource such as WordNet (Fellbaum, 1998), but also that including semantic knowledge mined from Wikipedia into an NLP system dealing with coreference resolutio</context>
<context position="4555" citStr="Strube &amp; Ponzetto (2006)" startWordPosition="683" endWordPosition="686">initions (i.e. the shortest one for path-length measures, and the most informative one for information-content measures) are returned. use lexical resources transform that resource into a network or graph and compute relatedness using paths in it1. For instance, Rada et al. (1989) traverse MeSH, a term hierarchy for indexing articles in Medline, and compute semantic relatedness as the edge distance between terms in the hierarchy. Jarmasz &amp; Szpakowicz (2003) use the same approach with Roget’s Thesaurus while Hirst &amp; StOnge (1998) apply a similar strategy to WordNet. The novel idea presented in Strube &amp; Ponzetto (2006) was to induce a semantic network from the Wikipedia categorization graph to compute measures of semantic relatedness. Wikipedia, a multilingual Web-based free-content encyclopedia, allows for structured access by means of categories: the encyclopedia articles can be assigned one or more categories, which are further categorized to provide a so-called “category tree”. Though not de1An overview of lexical resource-based approaches to measuring semantic relatedness is presented in Budanitsky &amp; Hirst (2006). Note that here we do not distinguish between semantic similarity (computed using hyponymy</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, M. &amp; S. P. Ponzetto (2006). WikiRelate! Computing semantic relatedness using Wikipedia. In Proc. of AAAI-06, pp. 1419–1424.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>