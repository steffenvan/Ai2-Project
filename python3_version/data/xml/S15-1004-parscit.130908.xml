<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.992337">
Distributional semantics for ontology verification ∗
</title>
<author confidence="0.996244">
Julien Corman Nathalie Aussenac-Gilles Laure Vieu
</author>
<affiliation confidence="0.9815285">
IRIT, University of Toulouse CNRS CNRS
julien.corman@irit.fr IRIT, University of Toulouse IRIT, University of Toulouse
</affiliation>
<email confidence="0.996257">
aussenac@irit.fr vieu@irit.fr
</email>
<sectionHeader confidence="0.998577" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99877075">
As they grow in size, OWL ontologies tend to
comprise intuitively incompatible statements,
even when they remain logically consistent.
This is true in particular of lightweight on-
tologies, especially the ones which aggregate
knowledge from different sources. The article
investigates how distributional semantics can
help detect and repair violation of common
sense in consistent ontologies, based on the
identification of consequences which are un-
likely to hold if the rest of the ontology does.
A score evaluating the plausibility for a con-
sequence to hold with regard to distributional
evidence is defined, as well as several methods
in order to decide which statements should be
preferably amended or discarded. A conclu-
sive evaluation is also provided, which con-
sists in extending an input ontology with ran-
domly generated statements, before trying to
discard them automatically.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.971266">
Ontology learning from texts deals with the auto-
mated extraction of knowledge from linguistic ev-
idence. This article investigates a slightly differ-
ent problem, which is how Natural Language Pro-
cessing may provide hints for the identification of
statements of an input ontology which are unlikely
to hold if the rest of it does. As a minimal exam-
ple, consider the following set A of statements, from
DBpedia (Mendes et al., 2012), and assume that A is
∗ The research reported here was supported by a Marie
Curie FP7 Career Integration Grant, Grant Agreement Number
PCIG13-GA-2013-618550.
a subset of a larger set of statements K (for instance
DBpedia itself, or some subset of it) :
</bodyText>
<equation confidence="0.328162">
Ex 1.
A = {(1) keyPerson(Caixa Bank, CEO),
</equation>
<listItem confidence="0.958111">
(2) keyPerson(BrookField Office Properties,
Peter Munk)
(3) occupation(PeterMunk, CEO) }
</listItem>
<bodyText confidence="0.999586041666667">
There is a clear violation of common sense in A :
the individual CEO must be both a key person of
Caixa Bank, and the occupation of another individ-
ual (Peter Munk), who is himself a key person of
some company. Detecting such cases within (larger)
sets of logical statements is of particular interest in
OWL, which facilitates the aggregation of knowl-
edge from multiple sources with overlapping signa-
tures, yielding datasets in which several incompati-
ble understandings of a same individual or predicate
may coexist. This easily leads to undesired infer-
ences, even when the dataset is logically consistent.1
But as the example illustrates, the problem may also
occur within a single knowledge base, especially if
it has been built semi-automatically, and/or is issued
from a collaborative effort.
Another problem of interest consists in deciding
which statement(s) should be preferably discarded
or amended in order to get rid of the nonsense. In
example 1, without further information, it would be
intuitively relevant to discard or modify either (1) or
(2). Unfortunately though, A alone does not give
any indication of which of the two should be prefer-
ably discarded. But the whole input ontology K D
</bodyText>
<footnote confidence="0.985034">
1and coherent in the Description Logics sense, i.e. whose
signature contains unsatisfiable DL atomic concepts/OWL
named classes
</footnote>
<page confidence="0.912702">
30
</page>
<note confidence="0.956877">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 30–39,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.99515235483871">
A may. To keep the example simple, let us assume
that Peter Munk, CEO and occupation do not ap-
pear in K \ A. Then a reasonable assumption is that
the overall understanding of keyPerson within K
should be the decisive factor. If it generally ranges
over person functions (i.e. if in most instances of the
relation according to K, the second argument is a
person function), then it is to be understood as “has
as a key person someone whose function is”, and
(2) should be preferably discarded. Alternatively, if
keyPerson generally ranges over human beings,
then (1) should be preferably discarded.
The article investigates the use of linguistic evi-
dence to solve both of these problems : identifying
violations of common sense, and selecting the state-
ment(s) to be preferably amended or discarded. This
may be viewed as a small paradigm shift, in that
it questions an assumption commonly made in the
knowledge extraction literature, namely that manu-
ally crafted knowledge strictly prevails over the one
obtained from linguistic sources. By default, the
case of a consistent2 input ontology K will be stud-
ied, but section 6 discusses the application of the ap-
proach to an inconsistent K as well.
As a concrete contribution, section 5 evaluates
the adaptation of relatively simple techniques issued
from named entity classification/ontology popula-
tion, and based on distributional semantics. To il-
lustrate how this works, let us assume that the only
other appearance of keyPerson within K is the
following OWL statement:
</bodyText>
<listItem confidence="0.780144666666667">
(4) hasRange(keyPerson, Person)
i.e. in FOL :
(4) bxy(keyPerson(x, y) → Person(y))
</listItem>
<bodyText confidence="0.992838516666667">
Then K |= 01 = Person(CEO), and K |=
02 = Person(PeterMunk). Assume also that
there are other instances of Person according to
K, and that most of them are actually human be-
ings (like Peter Munk). Then 01 is an undesirable
consequence of K, whereas 02 on the other hand
reinforces it.
Distributional semantics characterizes a word (or
possibly a multi word unit) by some algebraic rep-
resentation of the linguistic contexts with which it is
observed. These representations have already been
2and coherent (see footnote 1)
used for ontology population, for instance by (Tanev
and Magnini, 2008), the main intuition being that
individuals denoted by linguistic terms with similar
contexts tend to instantiate the same classes. The
underlying linguistic phenomenon is known as se-
lectional preference, i.e. the fact that some contexts
tend to select or rule out certain categories of in-
dividuals : e.g. the context “X was born in” tends
to select a human being, whereas “X was launched”
tends to rule it out. Back to the example, one can
expect the similarity between the distributional rep-
resentation of the term “C.E.O” and other terms de-
noting instances of Person according to K to be
relatively low, hindering the plausibility of 01 with
regard to K. In other words, 01 should stand as an
outlier among consequences of K, and therefore is
probably undesirable. Conversely, the similarity be-
tween “Peter Munk” and terms denoting other in-
stances of Person should be relatively high. For
simplicity, suppose that (1), (2), (3) and (4) are the
only 4 statements of K which are candidate for re-
moval. Then in order to give up the belief in 01
while preserving 02, it is necessary to discard (1),
and retain (2) and (4). It is also sufficient to discard
(1), i.e. discarding (3) as well would result in an un-
necessary information loss. So in this case, the ev-
idence provided by distributional semantics should
suggest the removal of (1), or at least its modifica-
tion, which is also intuitively the correct solution.
Section 4 formalizes this approach, by defining a
score which estimates the plausibility of some con-
sequences a subbases P of K, given distributional
evidence. Section 5 then provides an original eval-
uation of this strategy, based on the prior exten-
sion of a small OWL ontology with randomly gener-
ated statements. The approach is evaluated for both
problems, i.e. the identification of undesired con-
sequences and statements. Performances of several
forms of distributional representations are also com-
pared. Section 6 discusses immediate applications,
in particular for (consistent and inconsistent) ontol-
ogy debugging. Finally, section 7 considers possi-
ble extensions of this framework, as well as their
limitations. Section 2 is a brief overview of related
works in the fields of ontology learning and debug-
ging, whereas section 3 introduces notational con-
ventions, and lists some preliminary requirements to
be met by the input K.
</bodyText>
<page confidence="0.999846">
31
</page>
<sectionHeader confidence="0.600008" genericHeader="method">
2 State of the art
</sectionHeader>
<bodyText confidence="0.999818388888889">
Ontology learning from texts (Cimiano, 2006;
Buitelaar et al., 2005) aims to automatically build or
enriching a set of logical statements out of linguistic
evidence, and is closely related to the field of infor-
mation extraction. The work presented here borrows
from a subtask called ontology population (which it-
self borrows from named entity classification), but
only when the individuals and concepts of inter-
est are already known (Cimiano and V¨olker, 2005;
Tanev and Magnini, 2008; Giuliano and Gliozzo,
2008), which is not standard. A comparison may
also be drawn with the use of linguistic evidence by
(Suchanek et al., 2009) for information extraction in
the presence of conflicting data.
But the objective of the present work is different,
pertaining to ontology debugging, which covers a
wide range of techniques, from syntactic verifica-
tions (Poveda-Villal´on et al., 2012) to anti-patterns
detection (Roussey and Zamazal, 2013), both based
on common modeling mistakes, or the submission
of models (Ferr´e and Rudolph, 2012; Benevides
et al., 2010) or consequences (Pammer, 2010) of
the input ontology to the user. As discussed in
section 6, the framework depicted here presents an
interesting complementarity with debugging tech-
niques developed in the Description Logics com-
munity, prototypically based on diagnosis (Friedrich
and Shchekotykhin, 2005; Kalyanpur et al., 2006;
Qi et al., 2008; Ribeiro and Wassermann, 2009), be-
cause they require the prior identification of some
undesired consequence of K (be it ⊥). But distribu-
tional evidence may also provide a principled way
of selecting most relevant diagnoses among a poten-
tially large number of candidates, as well as an al-
ternative to their exhaustive computation, which has
been shown costly by (Schlobach, 2005).
</bodyText>
<sectionHeader confidence="0.95614" genericHeader="method">
3 Conventions and presuppositions
</sectionHeader>
<bodyText confidence="0.9999780625">
The prototypical input is a set of statements in OWL
DL or OWL 2, although the approach may be gener-
alized to other representation languages. OWL DL
and OWL 2 are based on Description Logics (DL),
which are themselves decidable fragments of first-
order logic (FOL). The OWL notation is preferred
to the DL one for readability, and FOL translations
are given when not obvious.
An ontology is just understood here as a (finite)
set of logical statements. A class will designate a
named class in OWL, i.e. a FOL unary predicate,
like Person, whereas a named individual, or just
individual, designates a constant, like Peter Munk.
The input ontology K must provide English terms
denoting some of its named individuals (e.g. the
term “Peter Munk”). These terms are prototypically
named entities, but may also occasionally be com-
mon nouns (or common noun phrases), as shown
in example 1 with “C.E.O”. There may be multiple
terms for a same individual. The approach cannot
handle polysemy though, in particular the fact that
some individuals of K may have homonyms (within
K or not), for instance that the term “JFK” can stand
for a politician, airport or movie. Ideally, no dis-
tributional representation should be built for indi-
viduals of K with potential homonyms. Some of
them may be identified with simple strategies, like
checking the existence of a Wikipedia disambigua-
tion page. On the opposite, labels for classes of
K (prototypically common nouns or common noun
phrases, which are arguably more ambiguous) are
never used during the process.
</bodyText>
<sectionHeader confidence="0.994478" genericHeader="method">
4 Proposition
</sectionHeader>
<bodyText confidence="0.999939583333333">
Given a subbase P of the input ontology K (possi-
bly K itself), the ontology verification strategy pre-
sented in introduction relies on the evaluation of a
set &apos;&amp;r of consequences of P. This section first de-
fines a score scr(0) for each 0 E &apos;&amp;r, which intu-
itively evaluates the plausibility of 0 wrt P, provided
some distributional representation for each named
individual appearing in &apos;&amp;r. Then it discusses how
this score can be used to select statements of the in-
put ontology K which, according to distributional
evidence, should be preferably discarded, or at least
amended.
</bodyText>
<subsectionHeader confidence="0.99655">
4.1 Plausibility of a consequence 0 E &apos;&amp;r
</subsectionHeader>
<bodyText confidence="0.999961">
For the experiments described in section 5, &apos;&amp;r is
the set of consequences of P of the form A(e) or
¬A(e), with e a constant (like CEO) and A a unary
predicate (like Person), and for which linguistic
occurrences of a term denoting e could be retrieved.
Possible extension of &apos;&amp;r with other types of formu-
las is discussed in section 7.
</bodyText>
<page confidence="0.996005">
32
</page>
<bodyText confidence="0.999831487179487">
Let ψ be a formula of Ψr, of the form
A(e), e.g. ψ = Person(CEO) or ψ =
Person(Peter Munk). Then instr(A) will des-
ignate all instances of A according to Γ for
which linguistic occurrences could be retrieved, i.e.
instr(A) = {e&apos;  |A(e&apos;) E Ψr}, and instr(A) \ {e}
will be called the support set for A(e). Similarly,
instr(T) will designate all named individuals ap-
pearing in Ψr.
Let sim(e1, e2) be a measure of similarity be-
tween the distributional representations of individ-
uals e1 and e2 (prototypically the cosine similar-
ity between some vector representations of the lin-
guistic contexts of e1 and e2). Then for each e&apos; E
instr(A) \ {e}, if sim(e, e&apos;) is lower than what
could be expected if e&apos; was a random individual of
instr(T) \ {e} (i.e. not necessarily an instance of
A), the hypothesis that A(e) is an outlier within Ψr
will be reinforced.
For instance, in example 1, let ψ =
Person(CEO) and Γ = K. Then the sup-
port set instr(A) \ {e} is composed of all other
instances of Person according to Γ. For each indi-
vidual e&apos; of this support set, if sim(CEO, e&apos;) is lower
than what can be expected for a random individual
of K with linguistic occurrences (and different
from CEO), then the confidence in Person(CEO)
should decline. Conversely, if sim(e, e&apos;) is higher
that expected, the hypothesis that ψ is in line with
Ψr will be reinforced.
Here is a cost-efficient and relatively simple
method to compute a plausibility score scr(A(e)).
Let S = instr(A)\{e} designate the support set for
Γ and e, and |S |the cardinality of S, i.e. the number
of other instances of A according to Γ. And let us
assume a set W of |S |randomly chosen elements
of instr(T) \ {e}, i.e. of |S |individuals which are
different from e, but not necessarily instances of A.
Finally, let the random variable Xre,|S |model the
</bodyText>
<equation confidence="0.8124635">
sim(e,e0)
|S |, i.e. the mean of the
</equation>
<bodyText confidence="0.997722833333333">
similarities between e and each individual of W.
In other words, if |S |individuals were randomly
chosen instead of those of the support set, Xre,|S|
models what the average similarity between e and
these individuals can be expected to be. Then the
plausibility scr(A(e)) of A(e) can be defined by :
</bodyText>
<equation confidence="0.880722333333333">
Definition 4.1. If S = instr(A) \ {e}, then
scr(A(e)) = p(Xre,|S |≤ E
e0ES
</equation>
<bodyText confidence="0.99747727027027">
scr(A(e)) estimates of how surprisingly high the
similarity between e and the individuals of the sup-
port set S is, considering the overall similarity be-
tween e and the individuals of Γ.
For the evaluation described in section 5, the
random variable Xre,|S |was assumed to follow a
beta distribution Beta(α, o), which intuitively al-
lows taking the size |S |of the support set into ac-
count. For instance, if S = {e&apos;}, i.e. |S |= 1,
then ceteris paribus a high similarity between e
and e&apos; will be less informative than an equally high
average similarity between e and all elements of
a large S. Stated another way, the lower |S |is,
the more uniform the distribution of Xre,|S |should
be. This can be obtained by setting Xre,|S |∼
Beta(m|S |+ 1,(1 − m)|S |+ 1), where m is the
average similarity between e and all other individu-
als of the signature of Γ, i.e. m = E
e0Er\{el
A possible interrogation here is the choice of
instr(A) \ {e} as the support set for A(e). For in-
stances, if ψ = Person(Peter Munk), a case could
be made for using instr(¬A) as well, i.e. for ex-
ploiting the (dis)similarity between Peter Munk and
individuals which, according to K, are instances of
¬Person.3 This is quite unrealistic though from
a linguistic point of view, which can be intuitively
seen in this example by replacing Peter Munk with
CEO. Assume for instance that Thelonious Monk
and Beijing are (reliable) instances of Person
and ¬Person respectively according to Γ. There
is no reason to expect that sim(CEO, Beijing) &gt;
sim(CEO, Thelonious Monk). In other words, it is
implausible to assume that elements of instr(¬A)
should a priori share similar contexts.
Interestingly enough, and for the same reason,
the support set for a consequence of Γ of the
</bodyText>
<equation confidence="0.800617333333333">
form ¬A(e) is not instr(¬A), but instr(A), which
yields :
Definition 4.2. If S = instr(A), then
scr(¬A(e)) = p(Xre,|S |≥ E
e0ES
3i.e. r |= ¬Person(e0) not only r V�- Person(e0)
</equation>
<bodyText confidence="0.365837">
expected value of E
</bodyText>
<figure confidence="0.937243857142857">
e0EW
sim(e,e0) )
|S|
sim(e,e0)
|r|−1 .
sim(e,e0)
|S |)
</figure>
<page confidence="0.976467">
33
</page>
<subsectionHeader confidence="0.95886">
4.2 Linguistic compliance of Γ
</subsectionHeader>
<bodyText confidence="0.9997671">
This does not directly address the second problem
mentioned in introduction though. For practical on-
tology verification, it is also desirable to identify the
cause of this nonsense, i.e. statements (axioms in the
DL terminology) which are intuitively problematic.
For instance, in example 1, computing scΓ(0) for
each 0 E ΨK may signal that the consequence 01
is unlikely to hold wrt the larger ontology K. And
discarding either (1) or (4) is sufficient to get rid of
the belief in 0. But given the additional assump-
tions made about K, discarding the former is prefer-
able, in that discarding the latter would also result in
the loss of 02. In other words, some subbases of K
(like K\(1) here) are more relevant than others (e.g.
K \ (4)), which can be simply captured as follows.
Let comp(Γ) be an estimation of the compliance of
a subbase Γ of K with the gathered linguistic evi-
dence. A straightforward option consists in setting
comp(Γ) to be the mean of the scores of evaluated
consequences for Γ, i.e. :
</bodyText>
<equation confidence="0.873479">
Definition 4.3. comp(Γ) =
ψ∈Ψr
</equation>
<bodyText confidence="0.999928411764706">
Then a strict partial order � over 2K can sim-
ply be defined by Γ1 � Γ2 iff either comp(Γ1) &lt;
comp(Γ2), or (comp(Γ1) = comp(Γ2) and Γ1 C
Γ2),4 and a subbase Γ of K can be viewed as opti-
mal if it is maximal wrt �.5
In practice though, identifying optimal subbases
is a non trivial task. To see this, note that the func-
tion to be maximized is not directly a function of
the statements in Γ, but of ΨΓ, i.e. some of the
consequences of Γ. So even if one could identify
a subset Ψ0 of ΨK which maximizes this function,
there may not exist a subbase Γ of K such that
ΨΓ = Ψ0. Another difficulty comes from the fact
that for two subbases Γ1 and Γ2 of K, and a con-
sequence 0 E ΨΓ1 n ΨΓ2, it doesn’t hold in gen-
eral that scΓ1(0) = scΓ2(0), because the support
set for 0 in Γ1 may differ from its support set in
</bodyText>
<footnote confidence="0.896741625">
4The assumption is made that a minimum of syntactic in-
formation should be lost whenever possible, i.e. r1 and r2
are primarily viewed as bases, not as theories. In particular,
if Cn(r1) = Cn(r2), but r1 9 r2 and r2 g r1, then r1 and
r2 are not comparable wrt -&lt;. Redundancies in this view should
also be preserved when possible, i.e. if Cn(r1) = Cn(r2) and
r1 C r2, then r1 -&lt; r2 still holds.
5There may be several several optimal subbases.
</footnote>
<bodyText confidence="0.961235673913043">
Γ2. In particular, it may be the case that Γ1 C_ Γ2
but scΓ1(0) &gt; scΓ2(0), which greatly reduces the
possible uses of monotonicity (if Γ1 C_ Γ2, then
Cn(Γ1) C_ Cn(Γ2)) to optimize the exploration of
2K. More generally, if the optimal subbases of K
are small (say twice smaller that K), it can be right-
fully argued that dropping so many statements for
the sake of linguistic evidence is not a viable debug-
ging strategy.
Therefore a more plausible application scenario
is one in which the search space has been previously
circumscribed, either by setting a maximal (small)
number of statements to discard, or by identifying a
set of potentially erroneous statements, through ax-
iom pinpointing, as explained in section 6. This is
also why the evaluation presented in section 5 fo-
cuses on the simplest possible case, i.e. the removal
from K of one statement only, whereas the integra-
tion of distributional evidence to more complex de-
bugging strategies is discussed in section 6.
As an alternative to the function comp, and in or-
der to avoid the fact that a same consequence may
have different plausibility scores wrt two subbases
of K, one may choose to discard unlikely conse-
quences based on their respective scores in K, i.e.
to use the score compK(Γ),6 defined by :
Definition 4.4. compK(Γ) = E
ψ∈Ψr
This solution is arguably less satisfying, but more
amenable to optimizations. A trivial example is that
of a subbase Γ1 with max
ψ∈Ψr1
for some already evaluated subbase Γ2, in which
case no subbase of Γ1 can be optimal wrt �.
Additionally, instead of taking the mean of the
scores of evaluated consequences of Γ, one may
want to penalize the subbases of K with the most
unlikely consequences, which gives a standard (to-
tal) lexicographic ordering Alex on 2K, defined as
follows. Let wΓ = ω1Γ, .., ω|Ψr|
Γ be the vector of
formulas of ΨΓ order by increasing score scΓ, and
let scΓ(wΓ) = scΓ(ω1Γ), .., scΓ(ω|Ψr|
Γ ). Then Alex
is defined by Γ1 Alex Γ2 iff either scΓ1(wΓ1) =
scΓ2(wΓ2), or (there is a 1 &lt; i &lt; |ΨΓ2 |such that
</bodyText>
<equation confidence="0.8723075">
scΓ1(ωjΓ1) = scΓ2(ωjΓ2) for all 1 &lt; j &lt; i, and either
scΓ1(ωiΓ1) &lt; scΓ2(ωiΓ2) or |ΨΓ1 |= i − 1). Then
6or more generally comer,(r), for some r&apos; D r
scr(ψ)
|Ψr|
scK(ψ)
|Ψr|
scK(0) &lt; compK(Γ2)
</equation>
<page confidence="0.9923">
34
</page>
<bodyText confidence="0.999614666666667">
as previously, a strict partial order � over 2K can
be defined by Γ1 � Γ2 iff either Γ1 Γ2, or
(Γ1 =lex Γ2 and Γ1 C Γ2).
Again, scK(ψ) may be used instead of scr(ψ),
yielding the lexical ordering �lexK. This last possi-
bility corresponds to a relatively intuitive operation,
which consists in giving up in priority the most im-
plausible consequences of K. All four possibilities
are evaluated in what follows.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999989542857143">
The dataset used for this evaluation is a fragment
of the fisheries ontology from the NEON project.7
It has been automatically built out of 10 randomly
selected named individuals, applying a module ex-
traction procedure, followed by a trimming algo-
rithm. The fragment contains 1038 (logical) state-
ments, and involves 71 named individuals (mostly
geographical or administrative entities), the least ex-
pressive underlying DL being SZ.
The linguistic input is a small corpus of approxi-
mately 6300 web pages, retrieved with a search en-
gine, using the labels of named individuals of F as
queries. The HTML documents were cleaned with
the BootCat library (Baroni and Bernardini, 2004).
The construction of the distributional representa-
tions of the named individuals of F was basic, the
use of more elaborate methods (SVD,... ) being left
for future work. The approach presented in this ar-
ticle remains generic enough to be applied to most
existing distributional frameworks, the only require-
ment being a real-valued similarity measure.
Two different forms of linguistic contexts were
alternatively tested. The first option considers as a
context any n-gram (2 &lt; n &lt; 5) without punc-
tuation mark which immediately precedes or fol-
lows a term t denoting an individual of F. The
other option is a more customized one, extracting se-
quences of lemmatized words (lemmaPOS in what
follows) surrounding t, in a shifting window of 3
to 5 tokens + the size of t, ignoring certain cat-
egories of word. Part-of-speech tagging was per-
formed thanks to the Stanford Parser (Toutanova
et al., 2003), with a pre-trained model for English.
If Cont designates the set of contexts observed with
at least 2 individuals, then an individual was rep-
</bodyText>
<subsectionHeader confidence="0.550217">
7http://www.neon-project.org/nw/Ontologies
</subsectionHeader>
<bodyText confidence="0.999934127659574">
resented by the vector of its respective frequencies
with each context c E Cont. Different possibilities
were compared to weight these frequencies. The
pointwise mutual information (PMI) was used in a
standard way for n-grams and lemmaPOS contexts
(with possible negative resulting frequencies set to
0). Following (Giuliano and Gliozzo, 2008), the
self-information self(c) was also used for n-grams,
defined by self(c) = − log p(c), the probability
p(c) being estimated thanks to the Microsoft Web
N-gram Services. A combined weighting by PMI
and self-information was also tested for n-grams.
These alternative settings are represented by capi-
tal letters in tables 1 and 2 : LP for lemmaPOS with
PMI, and NP, NS and NPS for n-grams with PMI,
self-information and both respectively.
The ontology F has been extended for the sake
of the evaluation, with statements randomly gener-
ated out of its signature. The underlying assumption
is that adding such statements to F is very likely
to generate violations of common sense (although
nothing prevents in theory the generation of plausi-
ble statements too). The goal for the evaluation was
then to automatically retrieve proper consequences
of each extension of F on the one hand, and the ran-
dom statements themselves on the other hand.
To prevent any misunderstanding, it should be
emphasized that this is not a realistic application
case. The input ontology was selected for its quality,
and degraded through random statement generation,
allowing an arguably artificial, but also very objec-
tive evaluation procedure (the only bias may come
from randomly generated statements which are ac-
tually plausible). By contrast, using a non modified
input dataset, and evaluating whether or not the ax-
ioms/consequences spotted by the algorithm are ac-
tually erroneous is a complex and subjective task,
with a possibly low inter-annotator agreement.
The generation procedure randomly selects a
statement 0 E F, and yields a statement 0&apos; with the
same syntactic structure as 0, but in which individ-
uals and predicates have been replaced by random
individuals and predicates appearing in F. For in-
stance, if 0 = bxy(A(x) n r(x, y) → �B(y)), then
0&apos; = bxy(C(x) n s(x, y) → �D(y)), with C and
D (resp. s) randomly chosen among classes (resp.
binary predicates) of the signature of F.
</bodyText>
<footnote confidence="0.257686">
100 randomly generated statements 01, ... , 0100
</footnote>
<page confidence="0.829627">
35
</page>
<table confidence="0.999391">
rank p-val
LP 4.15 / 216.1 &lt;0.001
NP 9.73 / 216.1 &lt;0.001
NS 7.33 / 216.1 &lt;0.001
NPS 5.59 / 216.1 &lt;0.001
</table>
<tableCaption confidence="0.6068338">
Table 1: Average ranking among TKi of the lowest-
ranked formula of T, and p-value for the rankings of
Ki
all formulas of all T&apos;
d
</tableCaption>
<bodyText confidence="0.974684282051282">
were added independently to F, yielding 100 in-
put ontologies K1, ... , K100, such that each Ki was
consistent, and that there was at least one conse-
quence of the form A(e) or �A(e) entailed by Ki
but not by F, with e sharing at least one linguistic
context with some other individual of F. All 100
input ontologies are available online.8
The first part of the evaluation was performed
as follows. For each Ki and each ψ E TKi, the
plausibility scKi(ψ) was computed as in definitions
4.1/4.2, and TKi was ordered by increasing plausi-
bility.9 Within TKi are consequences which were
not initially entailed by F, but have been obtained
after the extension of F with the random statement
φi. So in a sense, these consequences are ran-
domly generated too, and therefore one may expect
many of them to convey absurd information (for in-
stance Architect(Belgium)), or at least to be out-
liers (like Person(CEO) in ex 1) within TKi. Let
Trand
Ki designate these additional consequences, i.e.
Trand
Ki = TKi \ TF. If ψ E Trand
Ki , and if scKi(ψ) is
actually lower than for most other formulas of TKi,
this would indicate that the plausibility score, as for-
mulated in definitions 4.1/4.2, is actually a good es-
timator.
In order to evaluate this, column “rank” in table
1 gives the average ranking (for all 100 ontologies)
within TKi of the formula ψi E Trand
Ki with low-
est score. The lower this ranking, the more efficient
the plausibility score is at detecting outlier conse-
quences. Column “pVal” gives the probability (t-
test) for the cumulated rankings of all formulas in all
Trand
Ki to be as low as the observed ones, if all conse-
quences in all TKi had been randomly ordered.
</bodyText>
<footnote confidence="0.98741875">
8http://www.irit.fr/~Julien.Corman/index en.php
9 The ranking was a strict ordering : if two consequences
had the same score, one of them was randomly designated as
strictly lower ranked.
</footnote>
<bodyText confidence="0.989435428571429">
Results are convincing, with a significant p-value
for all four settings. For most ontologies (75/100),
there was only one formula in Trand
Ki . A closer look
at the data revealed that, for the best setting (LP),
in most of theses cases (57/75), the only formula in
Trand was also the one with lowest plausibility in
Ki
TKi, over 216.1 on average, i.e. the only randomly
generated consequence was also the least plausible
one according to linguistic evidence. This is very
encouraging, especially considering the relatively
small number of named individuals (71) in F, i.e.
the fact that the support to evaluate the plausibility of
a consequence ψ E TKi was limited. On the other
hand, performances were generally poor when the
cardinality of Trand Kiwas important (&gt; 0.25 * |TKi|),
which may be explained by the fact that support sets
for some classes of F were significantly modified
after the extension of F with φi.
As for the settings, unsurprisingly, the two most
beneficial (but unfortunately incompatible) factors
were the use of lemmatized contexts on the one hand
(LP), and the queries over the Web N-gram corpus
on the other hand (NS and NPS)
The second part of the evaluation focused on the
retrieval of the random statements φ1, .., φ100, for
the LP setting only, because it gave the best re-
sults in the previous experiment. For each extended
base Ki, all immediate subbases Pi,1, .., Pi,|F|+1 of
Ki were generated, i.e. each Pi,j was such that
Ki = Pi,j U {φj} for some statement φj of Ki.
The different Pi,j were ordered by decreasing com-
pliance score comp(Pi,j) (resp. compKi(Pi,j)),
or by decreasing lexicographic ordering ex (resp.
</bodyText>
<equation confidence="0.8518945">
�iK) 10 Intuitively, this yields a ranking on Ki
_ i
</equation>
<bodyText confidence="0.990349">
where the least reliable statements wrt linguistic ev-
idence should appear first : if φj E Ki, and if the
subbase of Ki obtained by discarding φj (i.e. Pi,j)
has a higher linguistic compliance score than Ki,
then discarding Pi,j can be viewed as an improve-
ment over Ki. And if Pi,j is among the best ranked
subbases of Ki, then φj is among the least reliable
statements of Ki wrt distributional evidence. For in-
stance, in example 1, one may expect the subbase
K \ (1) to have a maximal linguistic compliance
score among immediate subbases of K (or to be
10Again, the ranking was randomly turned into a strict order-
ing (see footnote 9).
</bodyText>
<page confidence="0.993447">
36
</page>
<table confidence="0.9993988">
rank p-val
comp(P) 7.86 / 80.03 &lt; 0.001
compKi(P) 8.05 / 80.03 &lt; 0.001
telex 6.51 / 80.03 &lt; 0.001
�lexKi 2.47 / 80.03 &lt; 0.001
</table>
<tableCaption confidence="0.966804">
Table 2: Average ranking of the randomly generated
statement Oi for each Ki, and p-value for the rankings
of all Oi
</tableCaption>
<bodyText confidence="0.999821032258065">
maximal wrt the lexicographic ordering), such that
(1) is the best candidate for removal. So back to the
test data, if Ki = F U fOil, i.e. if Oi is, among the
|F+1 |statements of Ki, the one which has been ran-
domly generated, and if Pi,i = Ki \ Oi is among the
best ranked immediate subbases of Ki, this would
indicate that the linguistic compliance score in def-
initions 4.3 (resp. 4.4), or the corresponding lexi-
cographic ordering ex (resp. �lexKi) is actually a
good estimator of faulty statements.
An additional precaution was taken in order to
avoid artificially good results. For most statements
Oj E Ki, discarding Oj did not have any impact
on the set TΓi,; of consequences to be evaluated,
i.e. TΓi,; = TKi, and therefore comp(Pi,j) =
comp(Ki). Let Di C_ Ki be the set of statements
whose removal did have an impact instead (on av-
erage, there were 79.3 statements in Di). Then the
compliance of a subbase Pi,j of Ki was evaluated
only if Oj E Di, i.e. only if the removal of Oj made a
difference. Ki was also added to this set of evaluated
subbases, yielding a ranking of 79.03 + 1 = 80.03
bases on average.
Results are again positive. Column “rank” in table
2 gives the average ranking of Pi,i, i.e. the base ob-
tained after the removal of the randomly generated
statement Oi. Both lexicographic orderings outper-
formed the compliance scores (i.e. the mean of plau-
sibility scores), and the best configuration was the
fourth presented in section 4.2, using scKi(ψ) as a
plausibility score instead of scΓi,;(ψ).
</bodyText>
<sectionHeader confidence="0.999124" genericHeader="method">
6 Applications
</sectionHeader>
<bodyText confidence="0.999992477272727">
This section describes a few concrete use cases of
the propositions made in section 4. A first basic
but useful application is the identification of unde-
sired consequences of a consistent input ontology
K. As illustrated by example 1, violations of com-
mon sense often go unnoticed in publicly available
OWL datasets, even though effective procedures can
detect inconsistency11 in most DLs. This is corre-
lated with the overall sparse usage of negation in
OWL, yielding ontologies which are consistent by
default rather than by design. The identification of
such cases can be very simply performed, by return-
ing to the user the formulas of TK with lower plausi-
bility scores, like Person(CEO) in example 1. Ax-
iom pinpointing algorithms (Schlobach and Cornet,
2003; Kalyanpur et al., 2007; Horridge, 2011) may
then be used to compute all justifications for each
returned consequence ψ, i.e. all (set-inclusion) min-
imal subsets of K which have ψ as a consequence.
In a more automated fashion, the greedy trimming
approach described in (Corman et al., 2015) returns
n statements of K which are candidate for removal,
n being given as a parameter, by incrementally se-
lecting the immediate subbase of P with maximal
linguistic compliance score, starting with P = K.
But inconsistent12 ontology debugging may also
benefit from distributional evidence. As discussed
in section 2, state-of-the-art approaches to ontology
debugging suffer from the number of candidate out-
puts, i.e. of (set-inclusion) maximal consistent sub-
sets of K, as well as from the cost of their compu-
tation. If the set J of justifications for the inconsis-
tency of K is known though, and if some (discrim-
inant enough) preference relation �a over U J can
be obtained, then prioritized base revision, as it is
defined in (Nebel, 1992), provides a principled and
computationally attractive solution to these prob-
lems. Even if the whole process cannot be depicted
here, may actually be obtained through distri-
butional evidence, by evaluating, for each statement
O E U J , the plausibility of some consequences of
candidate subbases in which O does or does not ap-
pear. The support set in this case is reduced to con-
sequences of the “safe” part of K, i.e. K \ U J .
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="method">
7 Extensions
</sectionHeader>
<bodyText confidence="0.9940565">
A first straightforward extension of this framework
consists in taking more complex classes into ac-
</bodyText>
<footnote confidence="0.783527333333333">
11or incoherence (see footnote1)
12or incoherent (see footnote 1), or for which a set of unde-
sired consequences has already been identified
</footnote>
<page confidence="0.999096">
37
</page>
<bodyText confidence="0.999969243243243">
count. OWL (and most Description Logics) fa-
vor the recursive construction of arbitrarily com-
plex classes out of the signature of Γ, and this
mechanism could naturally be used to extend Ψr
with more consequences of the form C(e), where
C is one of these complex classes. For instance,
in example 1, if C1 and C2 are respectively de-
fined by bx(C1(x) � Ely(occupation(y,x))
and bx(C2(x) � Ely(occupation(x, y)), then
ΨK can be extended “for free” with C1(CEO) and
C2(Peter Munk). Unfortunately, if Ψr is the set of
all consequences of Γ which can be built this way,
there is in general no finite subset Ψr of Ψr such
that Ψr 0 for all 0 E Ψ�r . Therefore the com-
plex classes to be used must be selected, which is
not trivial. Intuitively, some complex classes are
more relevant than other (e.g. the class of “phys-
ical objects owned by someone” may be linguisti-
cally relevant, but probably not “Moldavian or Mus-
lim lawyers whose father lives in an apartment”).
Another simple variation of the framework pre-
sented here consists in setting Ψr to be all con-
sequences of Γ of the form e1 =Y� e2, i.e. the
fact that that e1 and e2 are not the same individ-
ual according to Γ. The unique name assumption
is not made in OWL, which means that two dis-
tinct named individuals can be interpreted identi-
cally, and therefore these consequences do not hold
by default. They may be explicitly stated in Γ
(owl:differentIndividuals(e1, e2)), but are in most
cases entailed by Γ, provided it contains some form
of negation (e.g. instances of two disjoint classes
cannot be the same individual). If Γ1 and Γ2 are
two subbases of K such that Γ1 �= e1 =Y� e2, but
Γ2 V- e1 =Y� e2, and if the similarity between e1 and
e2 is lower than expected, then ceteris paribus, Γ1
will be preferred to Γ2.
</bodyText>
<sectionHeader confidence="0.968126" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999948739130435">
This article is centered on the use of distributional
representations of (labels of) named individuals of
an input ontology K, in order to identify and repair
violations of commonsense within K. For a set of
statements Γ C_ K, and Ψr a specific set of con-
sequences of Γ, a score scr(0) is attributed to each
0 E Ψr, which evaluates the plausibility of 0 wrt Γ
according to distributional evidence. Several meth-
ods based on this plausibility score are then pro-
posed in order to compare two subbases Γ1 and Γ2 of
K, leading to the identification of potentially erro-
neous statements. An evaluation is provided, which
consists in extending a test ontology with randomly
generated statements before trying to spot them au-
tomatically, with significant results. A more thor-
ough evaluation is still required though, testing in
particular the impact of a higher number of named
individuals and/or classes. Scalability of the ap-
proach may also be limited by its heavy reliance on a
reasoner. Finally, potential improvements may come
from using more elaborated distributional represen-
tations, like the one described in (Mikolov et al.,
2013).
</bodyText>
<page confidence="0.998789">
38
</page>
<sectionHeader confidence="0.99833" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.919027675">
Baroni, M. and S. Bernardini (2004). BootCaT:
Bootstrapping Corpora and Terms from the Web.
In LREC proceedings.
Benevides, A., G. Guizzardi, B. Braga, and
J. Almeida (2010). Validating modal aspects
of OntoUML conceptual models using automat-
ically generated visual world structures. Journal
of Universal Computer Science 16(20).
Buitelaar, P., P. Cimiano, and B. Magnini (2005).
Ontology Learning from Text: Methods, Evalua-
tion And Applications. IOS Press.
Cimiano, P. (2006). Ontology learning and popula-
tion from text: algorithms, evaluation and appli-
cations. Springer.
Cimiano, P. and J. V¨olker (2005). Towards large-
scale, open-domain and ontology-based named
entity classification. In RANLP proceedings.
Corman, J., N. Aussenac-Gilles, and L. Vieu (2015).
Trimming a consistent OWL knowledge base, re-
lying on linguistic evidence. In LangAndOnto
proceedings.
Ferr´e, S. and S. Rudolph (2012). Advocatus Dia-
boli–Exploratory Enrichment of Ontologies with
Negative Constraints. EKAW proceedings.
Friedrich, G. and K. Shchekotykhin (2005). A gen-
eral diagnosis method for ontologies. In ISWC
proceedings.
Giuliano, C. and A. Gliozzo (2008). Instance-based
ontology population exploiting named-entity sub-
stitution. In COLING proceedings.
Horridge, M. (2011). Justification based explana-
tion in ontologies. Ph. D. thesis, the University of
Manchester.
Kalyanpur, A., B. Parsia, M. Horridge, and E. Sirin
(2007). Finding all justifications of OWL DL en-
tailments. In The Semantic Web. Springer.
Kalyanpur, A., B. Parsia, E. Sirin, and B. Cuenca-
Grau (2006). Repairing unsatisfiable concepts in
OWL ontologies. In ESWC proceedings.
Mendes, P. N., M. Jakob, and C. Bizer (2012). DB-
pedia: A Multilingual Cross-domain Knowledge
Base. In LREC proceedings.
Mikolov, T., K. Chen, G. Corrado, and J. Dean
(2013). Efficient estimation of word representa-
tions in vector space. ICLR proceedings.
Nebel, B. (1992). Syntax-based approaches to belief
revision. Belief revision 29, 52–88.
Pammer, V. (2010). Automatic Support for Ontol-
ogy Evaluation. Ph. D. thesis, Graz University of
Technology.
Poveda-Villal´on, M., M. C. Su´arez-Figueroa, and
A. G´omez-P´erez (2012). Did you validate your
ontology? OOPS! In ESWC proceedings.
Qi, G., P. Haase, Z. Huang, Q. Ji, J. Z. Pan, and
J. V¨olker (2008). A kernel revision operator for
terminologies - algorithms and evaluation. In
ISWC proceedings.
Ribeiro, M. M. and R. Wassermann (2009). Base
revision for ontology debugging. Journal of Logic
and Computation 19(5).
Roussey, C. and O. Zamazal (2013). Antipattern
Detection: How to Debug an Ontology without
a Reasoner. In WODOOM 2013 proceeding.
Schlobach, S. (2005). Diagnosing terminologies. In
AAAI proceedings.
Schlobach, S. and R. Cornet (2003). Non-standard
reasoning services for the debugging of descrip-
tion logic terminologies. In IJCAI proceedings.
Suchanek, F. M., M. Sozio, and G. Weikum (2009).
SOFIE: a self-organizing framework for informa-
tion extraction. In International World Wide Web
conference proceedings.
Tanev, H. and B. Magnini (2008). Weakly super-
vised approaches for ontology population. In
conference on Ontology Learning and Population
proceedings.
Toutanova, K., D. Klein, C. D. Manning, and
Y. Singer (2003). Feature-rich part-of-speech
tagging with a cyclic dependency network. In
NAACL proceedings.
</reference>
<page confidence="0.999351">
39
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.860409">
<title confidence="0.999204">semantics for ontology verification</title>
<author confidence="0.999461">Julien Corman Nathalie Aussenac-Gilles Laure Vieu</author>
<affiliation confidence="0.9993115">IRIT, University of Toulouse CNRS University of Toulouse IRIT, University of Toulouse</affiliation>
<email confidence="0.913551">aussenac@irit.frvieu@irit.fr</email>
<abstract confidence="0.997229809523809">As they grow in size, OWL ontologies tend to comprise intuitively incompatible statements, even when they remain logically consistent. This is true in particular of lightweight ontologies, especially the ones which aggregate knowledge from different sources. The article investigates how distributional semantics can help detect and repair violation of common sense in consistent ontologies, based on the identification of consequences which are unlikely to hold if the rest of the ontology does. A score evaluating the plausibility for a consequence to hold with regard to distributional evidence is defined, as well as several methods in order to decide which statements should be preferably amended or discarded. A conclusive evaluation is also provided, which consists in extending an input ontology with randomly generated statements, before trying to discard them automatically.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Baroni</author>
<author>S Bernardini</author>
</authors>
<title>BootCaT: Bootstrapping Corpora and Terms from the Web. In LREC proceedings.</title>
<date>2004</date>
<contexts>
<context position="22186" citStr="Baroni and Bernardini, 2004" startWordPosition="3769" endWordPosition="3772">t of the fisheries ontology from the NEON project.7 It has been automatically built out of 10 randomly selected named individuals, applying a module extraction procedure, followed by a trimming algorithm. The fragment contains 1038 (logical) statements, and involves 71 named individuals (mostly geographical or administrative entities), the least expressive underlying DL being SZ. The linguistic input is a small corpus of approximately 6300 web pages, retrieved with a search engine, using the labels of named individuals of F as queries. The HTML documents were cleaned with the BootCat library (Baroni and Bernardini, 2004). The construction of the distributional representations of the named individuals of F was basic, the use of more elaborate methods (SVD,... ) being left for future work. The approach presented in this article remains generic enough to be applied to most existing distributional frameworks, the only requirement being a real-valued similarity measure. Two different forms of linguistic contexts were alternatively tested. The first option considers as a context any n-gram (2 &lt; n &lt; 5) without punctuation mark which immediately precedes or follows a term t denoting an individual of F. The other opti</context>
</contexts>
<marker>Baroni, Bernardini, 2004</marker>
<rawString>Baroni, M. and S. Bernardini (2004). BootCaT: Bootstrapping Corpora and Terms from the Web. In LREC proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Benevides</author>
<author>G Guizzardi</author>
<author>B Braga</author>
<author>J Almeida</author>
</authors>
<title>Validating modal aspects of OntoUML conceptual models using automatically generated visual world structures.</title>
<date>2010</date>
<journal>Journal of Universal Computer Science</journal>
<volume>16</volume>
<issue>20</issue>
<contexts>
<context position="9075" citStr="Benevides et al., 2010" startWordPosition="1451" endWordPosition="1454">imiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the presence of conflicting data. But the objective of the present work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distributional evidence may also provide a principled way of selecting most relevant diagnoses among a potentially large number</context>
</contexts>
<marker>Benevides, Guizzardi, Braga, Almeida, 2010</marker>
<rawString>Benevides, A., G. Guizzardi, B. Braga, and J. Almeida (2010). Validating modal aspects of OntoUML conceptual models using automatically generated visual world structures. Journal of Universal Computer Science 16(20).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
<author>P Cimiano</author>
<author>B Magnini</author>
</authors>
<title>Ontology Learning from Text: Methods, Evaluation And Applications.</title>
<date>2005</date>
<publisher>IOS Press.</publisher>
<contexts>
<context position="8085" citStr="Buitelaar et al., 2005" startWordPosition="1297" endWordPosition="1300">quences and statements. Performances of several forms of distributional representations are also compared. Section 6 discusses immediate applications, in particular for (consistent and inconsistent) ontology debugging. Finally, section 7 considers possible extensions of this framework, as well as their limitations. Section 2 is a brief overview of related works in the fields of ontology learning and debugging, whereas section 3 introduces notational conventions, and lists some preliminary requirements to be met by the input K. 31 2 State of the art Ontology learning from texts (Cimiano, 2006; Buitelaar et al., 2005) aims to automatically build or enriching a set of logical statements out of linguistic evidence, and is closely related to the field of information extraction. The work presented here borrows from a subtask called ontology population (which itself borrows from named entity classification), but only when the individuals and concepts of interest are already known (Cimiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the pr</context>
</contexts>
<marker>Buitelaar, Cimiano, Magnini, 2005</marker>
<rawString>Buitelaar, P., P. Cimiano, and B. Magnini (2005). Ontology Learning from Text: Methods, Evaluation And Applications. IOS Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
</authors>
<title>Ontology learning and population from text: algorithms, evaluation and applications.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="8060" citStr="Cimiano, 2006" startWordPosition="1295" endWordPosition="1296">undesired consequences and statements. Performances of several forms of distributional representations are also compared. Section 6 discusses immediate applications, in particular for (consistent and inconsistent) ontology debugging. Finally, section 7 considers possible extensions of this framework, as well as their limitations. Section 2 is a brief overview of related works in the fields of ontology learning and debugging, whereas section 3 introduces notational conventions, and lists some preliminary requirements to be met by the input K. 31 2 State of the art Ontology learning from texts (Cimiano, 2006; Buitelaar et al., 2005) aims to automatically build or enriching a set of logical statements out of linguistic evidence, and is closely related to the field of information extraction. The work presented here borrows from a subtask called ontology population (which itself borrows from named entity classification), but only when the individuals and concepts of interest are already known (Cimiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for informa</context>
</contexts>
<marker>Cimiano, 2006</marker>
<rawString>Cimiano, P. (2006). Ontology learning and population from text: algorithms, evaluation and applications. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>J V¨olker</author>
</authors>
<title>Towards largescale, open-domain and ontology-based named entity classification.</title>
<date>2005</date>
<booktitle>In RANLP proceedings.</booktitle>
<marker>Cimiano, V¨olker, 2005</marker>
<rawString>Cimiano, P. and J. V¨olker (2005). Towards largescale, open-domain and ontology-based named entity classification. In RANLP proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Corman</author>
<author>N Aussenac-Gilles</author>
<author>L Vieu</author>
</authors>
<title>Trimming a consistent OWL knowledge base, relying on linguistic evidence. In LangAndOnto proceedings.</title>
<date>2015</date>
<contexts>
<context position="32889" citStr="Corman et al., 2015" startWordPosition="5604" endWordPosition="5607">e usage of negation in OWL, yielding ontologies which are consistent by default rather than by design. The identification of such cases can be very simply performed, by returning to the user the formulas of TK with lower plausibility scores, like Person(CEO) in example 1. Axiom pinpointing algorithms (Schlobach and Cornet, 2003; Kalyanpur et al., 2007; Horridge, 2011) may then be used to compute all justifications for each returned consequence ψ, i.e. all (set-inclusion) minimal subsets of K which have ψ as a consequence. In a more automated fashion, the greedy trimming approach described in (Corman et al., 2015) returns n statements of K which are candidate for removal, n being given as a parameter, by incrementally selecting the immediate subbase of P with maximal linguistic compliance score, starting with P = K. But inconsistent12 ontology debugging may also benefit from distributional evidence. As discussed in section 2, state-of-the-art approaches to ontology debugging suffer from the number of candidate outputs, i.e. of (set-inclusion) maximal consistent subsets of K, as well as from the cost of their computation. If the set J of justifications for the inconsistency of K is known though, and if </context>
</contexts>
<marker>Corman, Aussenac-Gilles, Vieu, 2015</marker>
<rawString>Corman, J., N. Aussenac-Gilles, and L. Vieu (2015). Trimming a consistent OWL knowledge base, relying on linguistic evidence. In LangAndOnto proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ferr´e</author>
<author>S Rudolph</author>
</authors>
<title>Advocatus Diaboli–Exploratory Enrichment of Ontologies with Negative Constraints. EKAW proceedings.</title>
<date>2012</date>
<marker>Ferr´e, Rudolph, 2012</marker>
<rawString>Ferr´e, S. and S. Rudolph (2012). Advocatus Diaboli–Exploratory Enrichment of Ontologies with Negative Constraints. EKAW proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Friedrich</author>
<author>K Shchekotykhin</author>
</authors>
<title>A general diagnosis method for ontologies.</title>
<date>2005</date>
<booktitle>In ISWC proceedings.</booktitle>
<contexts>
<context position="9378" citStr="Friedrich and Shchekotykhin, 2005" startWordPosition="1494" endWordPosition="1497"> work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distributional evidence may also provide a principled way of selecting most relevant diagnoses among a potentially large number of candidates, as well as an alternative to their exhaustive computation, which has been shown costly by (Schlobach, 2005). 3 Conventions and presuppositions The prototypical input is a set of statements in OWL DL or OWL 2, although the approach may be generalized to other representation languages. OW</context>
</contexts>
<marker>Friedrich, Shchekotykhin, 2005</marker>
<rawString>Friedrich, G. and K. Shchekotykhin (2005). A general diagnosis method for ontologies. In ISWC proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Giuliano</author>
<author>A Gliozzo</author>
</authors>
<title>Instance-based ontology population exploiting named-entity substitution.</title>
<date>2008</date>
<booktitle>In COLING proceedings.</booktitle>
<contexts>
<context position="8530" citStr="Giuliano and Gliozzo, 2008" startWordPosition="1367" endWordPosition="1370">s notational conventions, and lists some preliminary requirements to be met by the input K. 31 2 State of the art Ontology learning from texts (Cimiano, 2006; Buitelaar et al., 2005) aims to automatically build or enriching a set of logical statements out of linguistic evidence, and is closely related to the field of information extraction. The work presented here borrows from a subtask called ontology population (which itself borrows from named entity classification), but only when the individuals and concepts of interest are already known (Cimiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the presence of conflicting data. But the objective of the present work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology t</context>
<context position="23610" citStr="Giuliano and Gliozzo, 2008" startWordPosition="3995" endWordPosition="3998"> word. Part-of-speech tagging was performed thanks to the Stanford Parser (Toutanova et al., 2003), with a pre-trained model for English. If Cont designates the set of contexts observed with at least 2 individuals, then an individual was rep7http://www.neon-project.org/nw/Ontologies resented by the vector of its respective frequencies with each context c E Cont. Different possibilities were compared to weight these frequencies. The pointwise mutual information (PMI) was used in a standard way for n-grams and lemmaPOS contexts (with possible negative resulting frequencies set to 0). Following (Giuliano and Gliozzo, 2008), the self-information self(c) was also used for n-grams, defined by self(c) = − log p(c), the probability p(c) being estimated thanks to the Microsoft Web N-gram Services. A combined weighting by PMI and self-information was also tested for n-grams. These alternative settings are represented by capital letters in tables 1 and 2 : LP for lemmaPOS with PMI, and NP, NS and NPS for n-grams with PMI, self-information and both respectively. The ontology F has been extended for the sake of the evaluation, with statements randomly generated out of its signature. The underlying assumption is that addi</context>
</contexts>
<marker>Giuliano, Gliozzo, 2008</marker>
<rawString>Giuliano, C. and A. Gliozzo (2008). Instance-based ontology population exploiting named-entity substitution. In COLING proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Horridge</author>
</authors>
<title>Justification based explanation in ontologies.</title>
<date>2011</date>
<tech>Ph. D. thesis,</tech>
<institution>the University of Manchester.</institution>
<contexts>
<context position="32639" citStr="Horridge, 2011" startWordPosition="5564" endWordPosition="5565">t input ontology K. As illustrated by example 1, violations of common sense often go unnoticed in publicly available OWL datasets, even though effective procedures can detect inconsistency11 in most DLs. This is correlated with the overall sparse usage of negation in OWL, yielding ontologies which are consistent by default rather than by design. The identification of such cases can be very simply performed, by returning to the user the formulas of TK with lower plausibility scores, like Person(CEO) in example 1. Axiom pinpointing algorithms (Schlobach and Cornet, 2003; Kalyanpur et al., 2007; Horridge, 2011) may then be used to compute all justifications for each returned consequence ψ, i.e. all (set-inclusion) minimal subsets of K which have ψ as a consequence. In a more automated fashion, the greedy trimming approach described in (Corman et al., 2015) returns n statements of K which are candidate for removal, n being given as a parameter, by incrementally selecting the immediate subbase of P with maximal linguistic compliance score, starting with P = K. But inconsistent12 ontology debugging may also benefit from distributional evidence. As discussed in section 2, state-of-the-art approaches to </context>
</contexts>
<marker>Horridge, 2011</marker>
<rawString>Horridge, M. (2011). Justification based explanation in ontologies. Ph. D. thesis, the University of Manchester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kalyanpur</author>
<author>B Parsia</author>
<author>M Horridge</author>
<author>E Sirin</author>
</authors>
<title>Finding all justifications of OWL DL entailments.</title>
<date>2007</date>
<booktitle>In The Semantic</booktitle>
<publisher>Web. Springer.</publisher>
<contexts>
<context position="32622" citStr="Kalyanpur et al., 2007" startWordPosition="5560" endWordPosition="5563">sequences of a consistent input ontology K. As illustrated by example 1, violations of common sense often go unnoticed in publicly available OWL datasets, even though effective procedures can detect inconsistency11 in most DLs. This is correlated with the overall sparse usage of negation in OWL, yielding ontologies which are consistent by default rather than by design. The identification of such cases can be very simply performed, by returning to the user the formulas of TK with lower plausibility scores, like Person(CEO) in example 1. Axiom pinpointing algorithms (Schlobach and Cornet, 2003; Kalyanpur et al., 2007; Horridge, 2011) may then be used to compute all justifications for each returned consequence ψ, i.e. all (set-inclusion) minimal subsets of K which have ψ as a consequence. In a more automated fashion, the greedy trimming approach described in (Corman et al., 2015) returns n statements of K which are candidate for removal, n being given as a parameter, by incrementally selecting the immediate subbase of P with maximal linguistic compliance score, starting with P = K. But inconsistent12 ontology debugging may also benefit from distributional evidence. As discussed in section 2, state-of-the-a</context>
</contexts>
<marker>Kalyanpur, Parsia, Horridge, Sirin, 2007</marker>
<rawString>Kalyanpur, A., B. Parsia, M. Horridge, and E. Sirin (2007). Finding all justifications of OWL DL entailments. In The Semantic Web. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kalyanpur</author>
<author>B Parsia</author>
<author>E Sirin</author>
<author>B CuencaGrau</author>
</authors>
<title>Repairing unsatisfiable concepts in OWL ontologies.</title>
<date>2006</date>
<booktitle>In ESWC proceedings.</booktitle>
<contexts>
<context position="9402" citStr="Kalyanpur et al., 2006" startWordPosition="1498" endWordPosition="1501">ntology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distributional evidence may also provide a principled way of selecting most relevant diagnoses among a potentially large number of candidates, as well as an alternative to their exhaustive computation, which has been shown costly by (Schlobach, 2005). 3 Conventions and presuppositions The prototypical input is a set of statements in OWL DL or OWL 2, although the approach may be generalized to other representation languages. OWL DL and OWL 2 are based</context>
</contexts>
<marker>Kalyanpur, Parsia, Sirin, CuencaGrau, 2006</marker>
<rawString>Kalyanpur, A., B. Parsia, E. Sirin, and B. CuencaGrau (2006). Repairing unsatisfiable concepts in OWL ontologies. In ESWC proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P N Mendes</author>
<author>M Jakob</author>
<author>C Bizer</author>
</authors>
<title>DBpedia: A Multilingual Cross-domain Knowledge Base. In LREC proceedings.</title>
<date>2012</date>
<contexts>
<context position="1589" citStr="Mendes et al., 2012" startWordPosition="235" endWordPosition="238">carded. A conclusive evaluation is also provided, which consists in extending an input ontology with randomly generated statements, before trying to discard them automatically. 1 Introduction Ontology learning from texts deals with the automated extraction of knowledge from linguistic evidence. This article investigates a slightly different problem, which is how Natural Language Processing may provide hints for the identification of statements of an input ontology which are unlikely to hold if the rest of it does. As a minimal example, consider the following set A of statements, from DBpedia (Mendes et al., 2012), and assume that A is ∗ The research reported here was supported by a Marie Curie FP7 Career Integration Grant, Grant Agreement Number PCIG13-GA-2013-618550. a subset of a larger set of statements K (for instance DBpedia itself, or some subset of it) : Ex 1. A = {(1) keyPerson(Caixa Bank, CEO), (2) keyPerson(BrookField Office Properties, Peter Munk) (3) occupation(PeterMunk, CEO) } There is a clear violation of common sense in A : the individual CEO must be both a key person of Caixa Bank, and the occupation of another individual (Peter Munk), who is himself a key person of some company. Dete</context>
</contexts>
<marker>Mendes, Jakob, Bizer, 2012</marker>
<rawString>Mendes, P. N., M. Jakob, and C. Bizer (2012). DBpedia: A Multilingual Cross-domain Knowledge Base. In LREC proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mikolov</author>
<author>K Chen</author>
<author>G Corrado</author>
<author>J Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space. ICLR proceedings.</title>
<date>2013</date>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Mikolov, T., K. Chen, G. Corrado, and J. Dean (2013). Efficient estimation of word representations in vector space. ICLR proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Nebel</author>
</authors>
<title>Syntax-based approaches to belief revision.</title>
<date>1992</date>
<journal>Belief revision</journal>
<volume>29</volume>
<pages>52--88</pages>
<contexts>
<context position="33630" citStr="Nebel, 1992" startWordPosition="5729" endWordPosition="5730">e subbase of P with maximal linguistic compliance score, starting with P = K. But inconsistent12 ontology debugging may also benefit from distributional evidence. As discussed in section 2, state-of-the-art approaches to ontology debugging suffer from the number of candidate outputs, i.e. of (set-inclusion) maximal consistent subsets of K, as well as from the cost of their computation. If the set J of justifications for the inconsistency of K is known though, and if some (discriminant enough) preference relation �a over U J can be obtained, then prioritized base revision, as it is defined in (Nebel, 1992), provides a principled and computationally attractive solution to these problems. Even if the whole process cannot be depicted here, may actually be obtained through distributional evidence, by evaluating, for each statement O E U J , the plausibility of some consequences of candidate subbases in which O does or does not appear. The support set in this case is reduced to consequences of the “safe” part of K, i.e. K \ U J . 7 Extensions A first straightforward extension of this framework consists in taking more complex classes into ac11or incoherence (see footnote1) 12or incoherent (see footno</context>
</contexts>
<marker>Nebel, 1992</marker>
<rawString>Nebel, B. (1992). Syntax-based approaches to belief revision. Belief revision 29, 52–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Pammer</author>
</authors>
<title>Automatic Support for Ontology Evaluation.</title>
<date>2010</date>
<tech>Ph. D. thesis,</tech>
<institution>Graz University of Technology.</institution>
<contexts>
<context position="9106" citStr="Pammer, 2010" startWordPosition="1457" endWordPosition="1458">ni, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the presence of conflicting data. But the objective of the present work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distributional evidence may also provide a principled way of selecting most relevant diagnoses among a potentially large number of candidates, as well as an a</context>
</contexts>
<marker>Pammer, 2010</marker>
<rawString>Pammer, V. (2010). Automatic Support for Ontology Evaluation. Ph. D. thesis, Graz University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poveda-Villal´on</author>
<author>M C Su´arez-Figueroa</author>
<author>A G´omez-P´erez</author>
</authors>
<title>Did you validate your ontology? OOPS! In ESWC proceedings.</title>
<date>2012</date>
<marker>Poveda-Villal´on, Su´arez-Figueroa, G´omez-P´erez, 2012</marker>
<rawString>Poveda-Villal´on, M., M. C. Su´arez-Figueroa, and A. G´omez-P´erez (2012). Did you validate your ontology? OOPS! In ESWC proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Qi</author>
<author>P Haase</author>
<author>Z Huang</author>
<author>Q Ji</author>
<author>J Z Pan</author>
<author>J V¨olker</author>
</authors>
<title>A kernel revision operator for terminologies - algorithms and evaluation.</title>
<date>2008</date>
<booktitle>In ISWC proceedings.</booktitle>
<marker>Qi, Haase, Huang, Ji, Pan, V¨olker, 2008</marker>
<rawString>Qi, G., P. Haase, Z. Huang, Q. Ji, J. Z. Pan, and J. V¨olker (2008). A kernel revision operator for terminologies - algorithms and evaluation. In ISWC proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M M Ribeiro</author>
<author>R Wassermann</author>
</authors>
<title>Base revision for ontology debugging.</title>
<date>2009</date>
<journal>Journal of Logic and Computation</journal>
<volume>19</volume>
<issue>5</issue>
<contexts>
<context position="9450" citStr="Ribeiro and Wassermann, 2009" startWordPosition="1506" endWordPosition="1509">nge of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distributional evidence may also provide a principled way of selecting most relevant diagnoses among a potentially large number of candidates, as well as an alternative to their exhaustive computation, which has been shown costly by (Schlobach, 2005). 3 Conventions and presuppositions The prototypical input is a set of statements in OWL DL or OWL 2, although the approach may be generalized to other representation languages. OWL DL and OWL 2 are based on Description Logics (DL), which are themselve</context>
</contexts>
<marker>Ribeiro, Wassermann, 2009</marker>
<rawString>Ribeiro, M. M. and R. Wassermann (2009). Base revision for ontology debugging. Journal of Logic and Computation 19(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Roussey</author>
<author>O Zamazal</author>
</authors>
<title>Antipattern Detection: How to Debug an Ontology without a Reasoner. In WODOOM</title>
<date>2013</date>
<pages>proceeding.</pages>
<contexts>
<context position="8955" citStr="Roussey and Zamazal, 2013" startWordPosition="1432" endWordPosition="1435">self borrows from named entity classification), but only when the individuals and concepts of interest are already known (Cimiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the presence of conflicting data. But the objective of the present work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distrib</context>
</contexts>
<marker>Roussey, Zamazal, 2013</marker>
<rawString>Roussey, C. and O. Zamazal (2013). Antipattern Detection: How to Debug an Ontology without a Reasoner. In WODOOM 2013 proceeding.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schlobach</author>
</authors>
<title>Diagnosing terminologies.</title>
<date>2005</date>
<booktitle>In AAAI proceedings.</booktitle>
<contexts>
<context position="9798" citStr="Schlobach, 2005" startWordPosition="1565" endWordPosition="1566"> depicted here presents an interesting complementarity with debugging techniques developed in the Description Logics community, prototypically based on diagnosis (Friedrich and Shchekotykhin, 2005; Kalyanpur et al., 2006; Qi et al., 2008; Ribeiro and Wassermann, 2009), because they require the prior identification of some undesired consequence of K (be it ⊥). But distributional evidence may also provide a principled way of selecting most relevant diagnoses among a potentially large number of candidates, as well as an alternative to their exhaustive computation, which has been shown costly by (Schlobach, 2005). 3 Conventions and presuppositions The prototypical input is a set of statements in OWL DL or OWL 2, although the approach may be generalized to other representation languages. OWL DL and OWL 2 are based on Description Logics (DL), which are themselves decidable fragments of firstorder logic (FOL). The OWL notation is preferred to the DL one for readability, and FOL translations are given when not obvious. An ontology is just understood here as a (finite) set of logical statements. A class will designate a named class in OWL, i.e. a FOL unary predicate, like Person, whereas a named individual</context>
</contexts>
<marker>Schlobach, 2005</marker>
<rawString>Schlobach, S. (2005). Diagnosing terminologies. In AAAI proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schlobach</author>
<author>R Cornet</author>
</authors>
<title>Non-standard reasoning services for the debugging of description logic terminologies.</title>
<date>2003</date>
<booktitle>In IJCAI proceedings.</booktitle>
<contexts>
<context position="32598" citStr="Schlobach and Cornet, 2003" startWordPosition="5556" endWordPosition="5559">ntification of undesired consequences of a consistent input ontology K. As illustrated by example 1, violations of common sense often go unnoticed in publicly available OWL datasets, even though effective procedures can detect inconsistency11 in most DLs. This is correlated with the overall sparse usage of negation in OWL, yielding ontologies which are consistent by default rather than by design. The identification of such cases can be very simply performed, by returning to the user the formulas of TK with lower plausibility scores, like Person(CEO) in example 1. Axiom pinpointing algorithms (Schlobach and Cornet, 2003; Kalyanpur et al., 2007; Horridge, 2011) may then be used to compute all justifications for each returned consequence ψ, i.e. all (set-inclusion) minimal subsets of K which have ψ as a consequence. In a more automated fashion, the greedy trimming approach described in (Corman et al., 2015) returns n statements of K which are candidate for removal, n being given as a parameter, by incrementally selecting the immediate subbase of P with maximal linguistic compliance score, starting with P = K. But inconsistent12 ontology debugging may also benefit from distributional evidence. As discussed in s</context>
</contexts>
<marker>Schlobach, Cornet, 2003</marker>
<rawString>Schlobach, S. and R. Cornet (2003). Non-standard reasoning services for the debugging of description logic terminologies. In IJCAI proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Suchanek</author>
<author>M Sozio</author>
<author>G Weikum</author>
</authors>
<title>SOFIE: a self-organizing framework for information extraction.</title>
<date>2009</date>
<booktitle>In International World Wide Web conference proceedings.</booktitle>
<contexts>
<context position="8648" citStr="Suchanek et al., 2009" startWordPosition="1388" endWordPosition="1391">learning from texts (Cimiano, 2006; Buitelaar et al., 2005) aims to automatically build or enriching a set of logical statements out of linguistic evidence, and is closely related to the field of information extraction. The work presented here borrows from a subtask called ontology population (which itself borrows from named entity classification), but only when the individuals and concepts of interest are already known (Cimiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the presence of conflicting data. But the objective of the present work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, 2010) of the input ontology to the user. As discussed in section 6, the framework depicted here presents an interesting complementarity with debugg</context>
</contexts>
<marker>Suchanek, Sozio, Weikum, 2009</marker>
<rawString>Suchanek, F. M., M. Sozio, and G. Weikum (2009). SOFIE: a self-organizing framework for information extraction. In International World Wide Web conference proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tanev</author>
<author>B Magnini</author>
</authors>
<title>Weakly supervised approaches for ontology population.</title>
<date>2008</date>
<booktitle>In conference on Ontology Learning and Population proceedings.</booktitle>
<contexts>
<context position="5644" citStr="Tanev and Magnini, 2008" startWordPosition="892" endWordPosition="895">xy(keyPerson(x, y) → Person(y)) Then K |= 01 = Person(CEO), and K |= 02 = Person(PeterMunk). Assume also that there are other instances of Person according to K, and that most of them are actually human beings (like Peter Munk). Then 01 is an undesirable consequence of K, whereas 02 on the other hand reinforces it. Distributional semantics characterizes a word (or possibly a multi word unit) by some algebraic representation of the linguistic contexts with which it is observed. These representations have already been 2and coherent (see footnote 1) used for ontology population, for instance by (Tanev and Magnini, 2008), the main intuition being that individuals denoted by linguistic terms with similar contexts tend to instantiate the same classes. The underlying linguistic phenomenon is known as selectional preference, i.e. the fact that some contexts tend to select or rule out certain categories of individuals : e.g. the context “X was born in” tends to select a human being, whereas “X was launched” tends to rule it out. Back to the example, one can expect the similarity between the distributional representation of the term “C.E.O” and other terms denoting instances of Person according to K to be relativel</context>
<context position="8501" citStr="Tanev and Magnini, 2008" startWordPosition="1363" endWordPosition="1366">ereas section 3 introduces notational conventions, and lists some preliminary requirements to be met by the input K. 31 2 State of the art Ontology learning from texts (Cimiano, 2006; Buitelaar et al., 2005) aims to automatically build or enriching a set of logical statements out of linguistic evidence, and is closely related to the field of information extraction. The work presented here borrows from a subtask called ontology population (which itself borrows from named entity classification), but only when the individuals and concepts of interest are already known (Cimiano and V¨olker, 2005; Tanev and Magnini, 2008; Giuliano and Gliozzo, 2008), which is not standard. A comparison may also be drawn with the use of linguistic evidence by (Suchanek et al., 2009) for information extraction in the presence of conflicting data. But the objective of the present work is different, pertaining to ontology debugging, which covers a wide range of techniques, from syntactic verifications (Poveda-Villal´on et al., 2012) to anti-patterns detection (Roussey and Zamazal, 2013), both based on common modeling mistakes, or the submission of models (Ferr´e and Rudolph, 2012; Benevides et al., 2010) or consequences (Pammer, </context>
</contexts>
<marker>Tanev, Magnini, 2008</marker>
<rawString>Tanev, H. and B. Magnini (2008). Weakly supervised approaches for ontology population. In conference on Ontology Learning and Population proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C D Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>NAACL proceedings.</booktitle>
<contexts>
<context position="23081" citStr="Toutanova et al., 2003" startWordPosition="3919" endWordPosition="3922">tional frameworks, the only requirement being a real-valued similarity measure. Two different forms of linguistic contexts were alternatively tested. The first option considers as a context any n-gram (2 &lt; n &lt; 5) without punctuation mark which immediately precedes or follows a term t denoting an individual of F. The other option is a more customized one, extracting sequences of lemmatized words (lemmaPOS in what follows) surrounding t, in a shifting window of 3 to 5 tokens + the size of t, ignoring certain categories of word. Part-of-speech tagging was performed thanks to the Stanford Parser (Toutanova et al., 2003), with a pre-trained model for English. If Cont designates the set of contexts observed with at least 2 individuals, then an individual was rep7http://www.neon-project.org/nw/Ontologies resented by the vector of its respective frequencies with each context c E Cont. Different possibilities were compared to weight these frequencies. The pointwise mutual information (PMI) was used in a standard way for n-grams and lemmaPOS contexts (with possible negative resulting frequencies set to 0). Following (Giuliano and Gliozzo, 2008), the self-information self(c) was also used for n-grams, defined by se</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Toutanova, K., D. Klein, C. D. Manning, and Y. Singer (2003). Feature-rich part-of-speech tagging with a cyclic dependency network. In NAACL proceedings.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>