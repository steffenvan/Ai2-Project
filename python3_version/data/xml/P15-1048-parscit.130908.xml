<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.931743">
Efficient Disfluency Detection with Transition-based Parsing
</title>
<author confidence="0.948371">
Shuangzhi Wu† , Dongdong Zhang$ , Ming Zhou$ , Tiejun Zhao††Harbin Institute of Technology
</author>
<affiliation confidence="0.659022">
$Microsoft Research
</affiliation>
<email confidence="0.917267">
{v-shuawu, dozhang, mingzhou}@microsoft.com
tjzhao@hit.edu.cn
</email>
<sectionHeader confidence="0.994616" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999928857142857">
Automatic speech recognition (ASR) out-
puts often contain various disfluencies. It
is necessary to remove these disfluencies
before processing downstream tasks. In
this paper, an efficient disfluency detection
approach based on right-to-left transition-
based parsing is proposed, which can effi-
ciently identify disfluencies and keep ASR
outputs grammatical. Our method exploits
a global view to capture long-range de-
pendencies for disfluency detection by in-
tegrating a rich set of syntactic and dis-
fluency features with linear complexity.
The experimental results show that our
method outperforms state-of-the-art work
and achieves a 85.1% f-score on the com-
monly used English Switchboard test set.
We also apply our method to in-house an-
notated Chinese data and achieve a sig-
nificantly higher f-score compared to the
baseline of CRF-based approach.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998608125">
With the development of the mobile internet,
speech inputs have become more and more popu-
lar in applications where automatic speech recog-
nition (ASR) is the key component to convert
speech into text. ASR outputs often contain var-
ious disfluencies which create barriers to sub-
sequent text processing tasks like parsing, ma-
chine translation and summarization. Usually,
disfluencies can be classified into uncompleted
words, filled pauses (e.g. “uh”, “um”), discourse
markers (e.g. “I mean”), editing terms (e.g. “you
know”) and repairs. To identify and remove dis-
fluencies, straightforward rules can be designed
to tackle the former four classes of disfluencies
since they often belong to a closed set. However,
the repair type disfluency poses particularly more
difficult problems as their form is more arbitrary.
Typically, as shown in Figure 1, a repair disflu-
ency type consists of a reparandum (“to Boston”)
and a filled pause (“um”), followed by its repair
(“to Denver”). This special structure of disfluency
constraint, which exists in many languages such
as English and Chinese, reflects the scenarios of
spontaneous speech and conversation, where peo-
ple often correct preceding words with following
words when they find that the preceding words
are wrong or improper. This procedure might be
interrupted and inserted with filled pauses when
people are thinking or hesitating. The challenges
of detecting repair disfluencies are that reparan-
dums vary in length, may occur everywhere, and
are sometimes nested.
</bodyText>
<figure confidence="0.592558">
correct
</figure>
<figureCaption confidence="0.8017995">
Figure 1: A typical example of repair type disflu-
ency consists of FP (Filled Pause), RM (Reparan-
dum), and RP (Repair). The preceding RM is cor-
rected by the following RP.
</figureCaption>
<bodyText confidence="0.9920816875">
There are many related works on disfluency
detection, that mainly focus on detecting repair
type of disfluencies. Straightforwardly, disflu-
ency detection can be treated as a sequence la-
beling problem and solved by well-known ma-
chine learning algorithms such as conditional ran-
dom fields (CRF) or max-margin markov network
(M3N) (Liu et al., 2006; Georgila, 2009; Qian
and Liu, 2013), and prosodic features are also
concerned in (Kahn et al., 2005; Zhang et al.,
2006). These methods achieve good performance,
but are not powerful enough to capture compli-
cated disfluencies with longer spans or distances.
Recently, syntax-based models such as transition-
based parser have been used for detecting disflu-
I want a flight to Boston um to Denver
</bodyText>
<note confidence="0.446174">
RM FP RP
</note>
<page confidence="0.983672">
495
</page>
<note confidence="0.978374333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 495–503,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.992539102941177">
encies (Honnibal and Johnson, 2014; Rasooli and
Tetreault, 2013). These methods can jointly per-
form dependency parsing and disfluency detec-
tion. But in these methods, great efforts are made
to distinguish normal words from disfluent words
as decisions cannot be made imminently from left
to right, leading to inefficient implementation as
well as performance loss.
In this paper, we propose detecting disfluencies
using a right-to-left transition-based dependency
parsing (R2L parsing), where the words are con-
sumed from right to left to build the parsing tree
based on which the current word is predicted to be
either disfluent or normal. The proposed models
cater to the disfluency constraint and integrate a
rich set of features extracted from contexts of lexi-
cons and partial syntactic tree structure, where the
parsing model and disfluency predicting model are
jointly calculated in a cascaded way. As shown in
Figure 2(b), while the parsing tree is being built,
disfluency tags are predicted and attached to the
disfluency nodes. Our models are quite efficient
with linear complexity of 2*N (N is the length of
input).
Figure 2: An instance of the detection procedure
where ‘N’ stands for a normal word and ‘X’ a dis-
fluency word. Words with italic font are Reparan-
dums. (a) is the L2R detecting procedure and (b)
is the R2L procedure.
Intuitively, compared with previous syntax-
based work such as (Honnibal and Johnson,
2014) that uses left-to-right transition-based pars-
ing (L2R parsing) model, our proposed approach
simplifies disfluency detection by sequentially
processing each word, without going back to mod-
ify the pre-built tree structure of disfluency words.
As shown in Figure 2(a), the L2R parsing based
joint approach needs to cut the pre-built depen-
dency link between “did” and “he” when “was”
is identified as the repair of “did”, which is never
needed in our method as Figure 2(b). Furthermore,
our method overcomes the deficiency issue in de-
coding of L2R parsing based joint method, mean-
ing the number of parsing transitions for each hy-
pothesis path is not identical to 2 * N, which leads
to the failure of performing optimal search during
decoding. For example, the involvement of the ex-
tra cut operation in Figure 2(a) destroys the com-
petition scoring that accumulates over 2 * N tran-
sition actions among hypotheses in the standard
transition-based parsing. Although the heuristic
score, such as the normalization of transition count
(Honnibal and Johnson, 2014), can be introduced,
the total scores of all hypotheses are still not sta-
tistically comparable from a global view.
We conduct the experiments on English Switch-
board corpus. The results show that our method
can achieve a 85.1% f-score with a gain of 0.7
point over state-of-the-art M3N labeling model in
(Qian and Liu, 2013) and a gain of 1 point over
state-of-the-art joint model proposed in (Honnibal
and Johnson, 2014). We also apply our method on
Chinese annotated data. As there is no available
public data in Chinese, we annotate 25k Chinese
sentences manually for training and testing. We
achieve 71.2% f-score with 15 points gained com-
pared to the CRF-based baseline, showing that our
models are robust and language independent.
</bodyText>
<sectionHeader confidence="0.71944" genericHeader="method">
2 Transition-based dependency parsing
</sectionHeader>
<bodyText confidence="0.998245">
In a typical transition-based parsing, the Shift-
Reduce decoding algorithm is applied and a queue
and stack are maintained (Zhang and Clark,
2008). The queue stores the stream of the input
and the front of the queue is indexed as the current
word. The stack stores the unfinished words which
may be linked to the current word or a future word
in the queue. When words in the queue are con-
sumed in sequential order, a set of transition ac-
tions is applied to build a parsing tree. There are
four kinds of transition actions in the parsing pro-
cess (Zhang and Clark, 2008), as described below.
</bodyText>
<listItem confidence="0.99524825">
• Shift : Removes the front of the queue and
pushes it to the stack.
• Reduce: Pops the top of the stack.
• LeftArc : Pops the top of the stack, and links
the popped word to the front of the queue.
• RightArc : Links the front of the queue to the
top of the stack and, removes the front of the
queue and pushes it to the stack.
</listItem>
<bodyText confidence="0.9925825">
The choice of each transition action during pars-
ing is scored by a generalized perceptron (Collins,
</bodyText>
<figure confidence="0.987588071428571">
root root
did
was
was
did
N N N N
(a) (b)
he
X
N
great
great
N X
he
</figure>
<page confidence="0.998934">
496
</page>
<bodyText confidence="0.999947705882353">
2002) which can be trained over a rich set of non-
local features. In decoding, beam search is per-
formed to search the optimal sequence of transi-
tion actions. As each word must be pushed to the
stack once and popped off once, the number of ac-
tions needed to parse a sentence is always 2 * N,
where N is the length of the sentence.
Transition-based dependency parsing (Zhang
and Clark, 2008) can be performed in either a left-
to-right or a right-to-left way, both of which have
a performance that is comparable as illustrated in
Section 4. However, when they are applied to
disfluency detection, their behaviors are very dif-
ferent due to the disfluency structure constraint.
We prove that right-to-left transition-based parsing
is more efficient than left-to-right transition-based
parsing for disfluency detection.
</bodyText>
<sectionHeader confidence="0.99372" genericHeader="method">
3 Our method
</sectionHeader>
<subsectionHeader confidence="0.993068">
3.1 Model
</subsectionHeader>
<bodyText confidence="0.9999161875">
Unlike previous joint methods (Honnibal and
Johnson, 2014; Rasooli and Tetreault, 2013), we
introduce dependency parsing into disfluency de-
tection from theory. In the task of disfluency
detection, we are given a stream of unstructured
words from automatic speech recognition (ASR).
We denote the word sequence with W1n := w1,
w2,w3,...,wn, which is actually the inverse order of
ASR words that should be wn, wn_1,wn_2,...,w1.
The output of the task is a sequence of binary tags
denoted as Dn1 = d1, d2,d3,...,dn, where each di
corresponds to wi, indicating whether wi is a dis-
fluency word (X) or not (N).1
Our task can be modeled as formula (1), which
is to search the best sequence D∗ given the stream
of words W1n .
</bodyText>
<equation confidence="0.999036">
D* = argmaxDP(Dn1 |W1n) (1)
</equation>
<bodyText confidence="0.999122333333333">
The dependency parsing tree is introduced into
model (1) to guide detection. The rewritten for-
mula is shown below:
</bodyText>
<equation confidence="0.9976205">
ED* = argmaxD P(Dn1 , T |W1n) (2)
T
</equation>
<bodyText confidence="0.999691">
We jointly optimize disfluency detection and
parsing with form (3), rather than considering all
possible parsing trees:
</bodyText>
<equation confidence="0.930447">
(D*, T*) = argmax(D,T)P(Dn1 , T |W1n) (3)
</equation>
<bodyText confidence="0.8323042">
1We just use tag ’N’ to represent a normal word, in prac-
tice normal words will not be tagged anything by default.
As both the dependency tree and the disfluency
tags are generated word by word, we decompose
formula (3) into:
</bodyText>
<equation confidence="0.965858">
(D*, T*) = argmax(D,T)
</equation>
<bodyText confidence="0.99969575">
where T1i is the partial tree after word wi is con-
sumed, di is the disfluency tag of wi.
We simplify the joint optimization in a cascaded
way with two different forms (5) and (6).
</bodyText>
<equation confidence="0.9999208">
(D*, T*) = argmax(D,T)
x P(di|Wi1, Ti1) (5)
(D*, T*) = argmax(D,T)
x P(Ti1|Wi1, Ti−1
1 , di) (6)
</equation>
<bodyText confidence="0.961658090909091">
Here, P(Ti1|.) is the parsing model, and P (di|.) is
the disfluency model used to predict the disluency
tags on condition of the contexts of partial trees
that have been built.
In (5), the parsing model is calculated first, fol-
lowed by the calculation of the disfluency model.
Inspired by (Zhang et al., 2013), we associate the
disfluency tags to the transition actions so that the
calculation of P(di|Wi1, Ti1) can be omitted as di
can be inferred from the partial tree Ti1. We then
get
</bodyText>
<equation confidence="0.964446">
(D*, T*) = argmax(D,T)
</equation>
<bodyText confidence="0.999908555555555">
Where the parsing and disfluency detection are
unified into one model. We refer to this model as
the Unified Transition(UT) model.
While in (6), the disfluency model is calculated
first, followed by the calculation of the parsing
model. We model P(di|.) as a binary classifier to
classify whether a word is disfluent or not. We re-
fer to this model as the binary classifier transition
(BCT) model.
</bodyText>
<subsectionHeader confidence="0.997676">
3.2 Unified transition-based model (UT)
</subsectionHeader>
<bodyText confidence="0.999298">
In model (7), in addition to the standard 4 transi-
tion actions mentioned in Section 2, the UT model
</bodyText>
<equation confidence="0.999058833333333">
P(di, Ti1|Wi1, Ti−1
1 )
(4)
n
i=1
P(Ti1|Wi1, Ti−1
1 )
n
i=1
P (di|Wi1, Ti−1
1 )
n
i=1
P(di, Ti1|Wi1, Ti−1
1 )
(7)
n
i=1
</equation>
<page confidence="0.983378">
497
</page>
<bodyText confidence="0.511614333333333">
adds 2 new transition actions which extend the
original Shift and RightArc transitions as shown
below:
</bodyText>
<listItem confidence="0.896873571428571">
• Dis Shift: Performs what Shift does then
marks the pushed word as disfluent.
• Dis RightArc: Adds a virtual link from the
front of the queue to the top of the stack
which is similar to Right Arc, marking the
front of the queue as disfluenct and pushing
it to the stack.
</listItem>
<bodyText confidence="0.9467393">
Figure 3 shows an example of how the UT
model works. Given an input “he did great was
great”, the optimal parsing tree is predicted by the
UT model. According to the parsing tree, we can
get the disfluency tags “N X X N N” which have
been attached to each word. To ensure the normal
words are built grammatical in the parse tree, we
apply a constraint to the UT model.
UT model constraint: When a word is marked
disfluent, all the words in its left and right sub-
trees will be marked disfluent and all the links of
its descendent offsprings will be converted to vir-
tual links, no matter what actions are applied to
these words.
For example, the italic word “great” will be
marked disfluent, no matter what actions are per-
formed on it.
Figure 3: An example of UT model, where ‘N’
means the word is a fluent word and ‘X’ means it is
disfluent. Words with italic font are Reparandums.
</bodyText>
<subsectionHeader confidence="0.7494835">
3.3 A binary classifier transition-based
model (BCT)
</subsectionHeader>
<bodyText confidence="0.6755435">
In model (6), we perform the binary classifier
and the parsing model together by augmenting
</bodyText>
<listItem confidence="0.882596">
the Shift-Reduce algorithm with a binary classifier
transition(BCT) action:
• BCT : Classifies whether the current word is
disfluent or not. If it is, remove it from the
</listItem>
<bodyText confidence="0.998744384615385">
queue, push it into the stack which is simi-
lar to Shift and then mark it as disfluent, oth-
erwise the original transition actions will be
used.
It is noted that when BCT is performed, the next
action must be Reduce. This constraint guarantees
that any disfluent word will not have any descen-
dent offspring. Figure 2(b) shows an example of
the BCT model. When the partial tree “great was”
is built, the next word “did” is obviously disfluent.
Unlike UT model, the BCT will not link the word
“did” to any word. Instead only a virtual link will
add it to the virtual root.
</bodyText>
<subsectionHeader confidence="0.941912">
3.4 Training and decoding
</subsectionHeader>
<bodyText confidence="0.9972685">
In practice, we use the same linear model for both
models (6) and (7) to score a parsing tree as:
</bodyText>
<equation confidence="0.9704705">
�Score(T) = φ(action) · λ�
action
</equation>
<bodyText confidence="0.990890785714286">
Where φ(action) is the feature vector extracted
from partial hypothesis T for a certain action and
λ� is the weight vector. φ(action) ·X calculates the
score of a certain transition action. The score of a
parsing tree T is the sum of action scores.
In addition to the basic features introduced in
(Zhang and Nivre, 2011) that are defined over bag
of words and POS-tags as well as tree-based con-
text, our models also integrate three classes of
new features combined with Brown cluster fea-
tures (Brown et al., 1992) that relate to the right-
to-left transition-based parsing procedure as de-
tailed below.
Simple repetition function
</bodyText>
<listItem confidence="0.96306605882353">
•
δI(a, b): A logic function which indicates
whether a and b are identical.
Syntax-based repetition function
•
δL(a, b): A logic function which indicates
whether a is a left child of b.
• δR(a, b): A logic function which indicates
whether a is a right child of b.
Longest subtree similarity function
•
NI(a, b): The count of identical children on
the left side of the root node between subtrees
rooted at a and b.
• N#(a0..n, b): The count of words among a0
.. an that are on the right of the subtree rooted
at b.
</listItem>
<figure confidence="0.943044111111111">
was
N
great
did
he
N X N
great
X
root
</figure>
<page confidence="0.99372">
498
</page>
<bodyText confidence="0.9930364">
Table 1 summarizes the features we use in the
model computation, where ws denotes the top
word of the stack, w0 denotes the front word of
the queue and w0..2 denotes the top three words of
the queue. Every pi corresponds to the POS-tag
of wi and p0..2 represents the POS-tags of w0..2.
In addition, wic means the Brown cluster of wi.
With these symbols, several new feature templates
are defined in Table 1. Both our models have the
same feature templates.
</bodyText>
<table confidence="0.992162666666667">
Basic All templates in (Zhang and
features Nivre, 2011)
New disfluency features
</table>
<tableCaption confidence="0.9665535">
Table 1: Feature templates designed for disfluency
detection and dependency parsing.
</tableCaption>
<bodyText confidence="0.9920508">
Similar to the work in (Zhang and Clark, 2008;
Zhang and Nivre, 2011), we train our models by
averaged perceptron (Collins, 2002). In decod-
ing, beam search is performed to get the optimal
parsing tree as well as the tag sequence.
</bodyText>
<sectionHeader confidence="0.99992" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996613">
4.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999929981818182">
Our training data is the Switchboard portion of
the English Penn Treebank (Marcus et al., 1993)
corpus, which consists of telephone conversations
about assigned topics. As not all the Switchboard
data has syntactic bracketing, we only use the sub-
corpus of PAESED/MRG/SWBD. Following the
experiment settings in (Charniak and Johnson,
2001), the training subcorpus contains directories
2 and 3 in PAESED/MRG/SWBD and directory
4 is split into test and development sets. We use
the Stanford dependency converter (De Marneffe
et al., 2006) to get the dependency structure from
the Switchboard corpus, as Honnibal and John-
son (2014) prove that Stanford converter is robust
to the Switchboard data.
For our Chinese experiments, no public Chinese
corpus is available. We annotate about 25k spo-
ken sentences with only disfluency annotations ac-
cording to the guideline proposed by Meteer et al.
(1995). In order to generate similar data format
as English Switchboard corpus, we use Chinese
dependency parsing trained on the Chinese Tree-
bank corpus to parse the annotated data and use
these parsed data for training and testing . For our
Chinese experiment setting, we respectively select
about 2k sentences for development and testing.
The rest are used for training.
To train the UT model, we create data for-
mat adaptation by replacing the original Shift and
RightArc of disfluent words with Dis Shift and
Dis RightArc, since they are just extensions of
Shift and RightArc. For the BCT model, disflu-
ent words are directly depended to the root node
and all their links and labels are removed. We
then link all the fluent children of disfluent words
to parents of disfluent words. We also remove
partial words and punctuation from data to simu-
late speech recognizer results where such informa-
tion is not available (Johnson and Charniak, 2004).
Additionally, following Honnibal and Johnson
(2014), we remove all one token sentences as these
sentences are trivial for disfluency detection, then
lowercase the text and discard filled pauses like
“um” and “uh”.
The evaluation metrics of disfluency detection
are precision (Prec.), recall (Rec.) and f-score
(F1). For parsing accuracy metrics, we use unla-
beled attachment score (UAS) and labeled attach-
ment score (LAS). For our primary comparison,
we evaluate the widely used CRF labeling model,
the state-of-the-art M3N model presented by Qian
and Liu (2013) which has been commonly used as
baseline in previous works and the state-of-the-art
L2R parsing based joint model proposed by Hon-
nibal and Johnson (2014).
</bodyText>
<subsectionHeader confidence="0.943427666666667">
4.2 Experimental results
4.2.1 Performance of disfluency detection on
English Swtichboard corpus
</subsectionHeader>
<bodyText confidence="0.997715333333333">
The evaluation results of both disfluency detec-
tion and parsing accuracy are presented in Table
2. The accuracy of M3N directly refers to the re-
</bodyText>
<equation confidence="0.94109615">
δI(ws, w0);δI(ps, p0);
δL(w0, ws);δL(p0, ps);
δR(w0, ws);δR(p0, ps);
NI(w0, ws);NI(p0,ps);
N#(w0..2, ws);N#(p0..2, ps);
δI(ws, w0)δI(ps, p0);
δL(w0, ws)δL(p0, ps);
δR(w0, ws)δR(p0, ps);
NI(w0, ws)NI(p0, ps);
N#(w0..2, ws)N#(p0..2, ps);
δI(ws, w0)wsc;
δI(ws, w0)w0c;
Function
unigrams
Function
bigrams
Function
trigrams
wsw0δI(ws, w0);
wsw0δI(ps, p0);
</equation>
<page confidence="0.997461">
499
</page>
<table confidence="0.999770909090909">
Disfluency detection accuracy Parsing accuracy
Method Prec. Rec. F1 UAS LAS
CRF(BOW) 81.2% 44.9% 57.8% 88.7% 84.7%
CRF(BOW+POS) 88.3% 62.2% 73.1% 89.2% 85.6%
M3N N/A N/A 84.1% N/A N/A
M3N† 90.5% 79.1% 84.4% 91% 88.2%
H&amp;J N/A N/A 84.1% 90.5% N/A
UT(basic features) 86% 72.5% 78.7% 91.9% 89.0%
UT(+new features) 88.8% 75.1% 81.3% 92.1% 89.4%
BCT(basic features) 88.2% 77.9% 82.7% 92.1% 89.3%
BCT(+new features) 90.3% 80.5% 85.1% 92.2% 89.6%
</table>
<tableCaption confidence="0.992855">
Table 2: Disfluency detection and parsing accuracies on English Switchboard data. The accuracy of
</tableCaption>
<bodyText confidence="0.966996941176471">
M3N refers to the result reported in (Qian and Liu, 2013). H&amp;J is the L2R parsing based joint model in
(Honnibal and Johnson, 2014). The results of M3N† come from the experiments with toolkit released by
Qian and Liu (2013) on our pre-processed corpus.
sults reported in (Qian and Liu, 2013). The re-
sults of M3N† come from our experiments with the
toolkit2 released by Qian and Liu (2013) which
uses our data set with the same pre-processing. It
is comparable between our models and the L2R
parsing based joint model presented by Honni-
bal and Johnson (2014), as we all conduct experi-
ments on the same pre-processed data set. In order
to compare parsing accuracy, we use the CRF and
M3N† model to pre-process the test set by remov-
ing all the detected disfluencies, then evaluate the
parsing performance on the processed set. From
the table, our BCT model with new disfluency fea-
tures achieves the best performance on disfluency
detection as well as dependency parsing.
The performance of the CRF model is low, be-
cause the local features are not powerful enough
to capture long span disfluencies. Our main com-
parison is with the M3N† labeling model and the
L2R parsing based model by Honnibal and John-
son (2014). As illustrated in Table 2, the BCT
model outperforms the M3N† model (we got an
accuracy of 84.4%, though 84.1% was reported
in their paper) and the L2R parsing based model
respectively by 0.7 point and 1 point on disflu-
ency detection, which shows our method can ef-
ficiently tackle disfluencies. This is because our
method can cater extremely well to the disfluency
constraint and perform optimal search with iden-
tical transition counts over all hypotheses in beam
search. Furthermore, our global syntactic and dis-
</bodyText>
<footnote confidence="0.8834025">
2The toolkit is available at
https://code.google.com/p/disfluency-detection/downloads.
</footnote>
<bodyText confidence="0.999312692307692">
fluency features can help capture long-range de-
pendencies for disfluency detection. However, the
UT model does not perform as well as BCT. This
is because the UT model suffers from the risk
that normal words may be linked to disfluencies
which may bring error propagation in decoding.
In addition our models with only basic features
respectively score about 3 points below the mod-
els adding new features, which shows that these
features are important for disfluency detection. In
comparing parsing accuracy, our BCT model out-
performs all the other models, showing that this
model is more robust on disfluent parsing.
</bodyText>
<subsectionHeader confidence="0.895581">
4.2.2 Performance of disfluency detection on
different part-of-speeches
</subsectionHeader>
<bodyText confidence="0.9996616">
In this section, we further analyze the frequency
of different part-of-speeches in disfluencies and
test the performance on different part-of-speeches.
Five classes of words take up more than 73% of
all disfluencies as shown in Table 3, which are
pronouns (contain PRP and PRP$), verbs (con-
tain VB,VBD,VBP,VBZ,VBN), determiners (con-
tain DT), prepositions (contain IN) and conjunc-
tions (contain CC). Obviously, these classes of
words appear frequently in our communication.
</bodyText>
<table confidence="0.6570615">
Pron. Verb Dete. Prep. Conj. Others
Dist. 30.2% 14.7% 13% 8.7% 6.7% 26.7%
</table>
<tableCaption confidence="0.985535">
Table 3: Distribution of different part-of-
</tableCaption>
<bodyText confidence="0.465480666666667">
speeches in disfluencies. Conj.=conjunction;
Dete.=determiner; Pron.=pronoun; Prep.= prepo-
sition.
</bodyText>
<page confidence="0.994574">
500
</page>
<tableCaption confidence="0.9011804">
Table 4 illustrates the performance (f-score) on
these classes of words. The results of L2R pars-
ing based joint model in (Honnibal and Johnson,
2014) are not listed because we cannot get such
detailed data.
</tableCaption>
<table confidence="0.999913888888889">
CRF CRF M3N† UT BCT
(BOW) (BOW (+feat.) (+feat.)
+POS)
Pron. 73.9% 85% 92% 91.5% 93.8%
Verb 38.2% 64.8% 84.2% 82.3% 84.7%
Dete. 66.8% 80% 88% 83.7% 87%
Prep. 60% 71.5% 79.1% 76.1% 79.3%
Conj. 75.2% 82.2% 81.6% 79.5% 83.2%
Others 43.2% 61% 78.4% 72.3% 79.1%
</table>
<tableCaption confidence="0.996792">
Table 4: Performance on different classes
</tableCaption>
<bodyText confidence="0.90582325">
of words. Dete.=determiner; Pron.=pronoun;
Conj.=conjunction; Prep.= preposition. feat.=new
disfluency features
As shown in Table 4, our BCT model outper-
forms all other models except that the performance
on determiner is lower than M3N†, which shows
that our algorithm can significantly tackle com-
mon disfluencies.
</bodyText>
<subsectionHeader confidence="0.9789665">
4.2.3 Performance of disfluency detection on
Chinese annotated corpus
</subsectionHeader>
<bodyText confidence="0.995832875">
In addition to English experiments, we also apply
our method on Chinese annotated data. As there
is no standard Chinese corpus, no Chinese experi-
mental results are reported in (Honnibal and John-
son, 2014; Qian and Liu, 2013). We only use the
CRF-based labeling model with lexical and POS-
tag features as baselines. Table 5 shows the results
of Chinese disfluency detection.
</bodyText>
<table confidence="0.99965">
Model Prec. Rec. F1
CRF(BOW) 89.5% 35.6% 50.9%
CRF(BOW+POS) 83.4% 41.6% 55.5%
UT(+new features) 86.7% 59.5% 70.6%
BCT(+new features) 85.5% 61% 71.2%
</table>
<tableCaption confidence="0.9800655">
Table 5: Disfluency detection performance on
Chinese annotated data.
</tableCaption>
<bodyText confidence="0.999731583333333">
Our models outperform the CRF model with
bag of words and POS-tag features by more than
15 points on f-score which shows that our method
is more effective. As shown latter in 4.2.4, the
standard transition-based parsing is not robust in
parsing disfluent text. There are a lot of parsing er-
rors in Chinese training data. Even though we are
still able to get promising results with less data and
un-golden parsing annotations. We believe that if
we were to have the golden Chinese syntactic an-
notations and more data, we would get much better
results.
</bodyText>
<note confidence="0.6152175">
4.2.4 Performance of transition-based
parsing
</note>
<bodyText confidence="0.999895555555556">
In order to show whether the advantage of the BCT
model is caused by the disfluency constraint or the
difference between R2L and L2R parsing models,
in this section, we make a comparison between the
original left-to-right transition-based parsing and
right-to-left parsing. These experiments are per-
formed with the Penn Treebank (PTB) Wall Street
Journal (WSJ) corpus. We follow the standard ap-
proach to split the corpus as 2-21 for training, 22
for development and section 23 for testing (Mc-
Donald et al., 2005). The features for the two
parsers are basic features in Table 1. The POS-
tagger model that we implement for a pre-process
before parsing also uses structured perceptron for
training and can achieve a competitive accuracy of
96.7%. The beam size for both POS-tagger and
parsing is set to 5. Table 6 presents the results on
WSJ test set and Switchboard (SWBD) test set.
</bodyText>
<table confidence="0.99919">
Data sets Model UAS LAS
WSJ L2R Parsing 92.1% 89.8%
R2L Parsing 92.0% 89.6%
SWBD L2R Parsing 88.4% 84.4%
R2L Parsing 88.7% 84.8%
</table>
<tableCaption confidence="0.941157">
Table 6: Performance of our parsers on different
test sets.
</tableCaption>
<bodyText confidence="0.9987759">
The parsing accuracy on SWBD is lower than
WSJ which means that the parsers are more robust
on written text data. The performances of R2L and
L2R parsing are comparable on both SWBD and
WSJ test sets. This demonstrates that the effec-
tiveness of our disfluency detection model mainly
relies on catering to the disfluency constraint by
using R2L parsing based approach, instead of the
difference in parsing models between L2R and
R2L parsings.
</bodyText>
<sectionHeader confidence="0.99997" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.99979175">
In practice, disfluency detection has been exten-
sively studied in both speech processing field and
natural language processing field. Noisy channel
models have been widely used in the past to detect
</bodyText>
<page confidence="0.991222">
501
</page>
<bodyText confidence="0.999953870370371">
disfluencies. Johnson and Charniak (2004) pro-
posed a TAG-based noisy channel model where
the TAG model was used to find rough copies.
Thereafter, a language model and MaxEnt re-
ranker were added to the noisy channel model
by Johnson et al. (2004). Following their frame-
work, Zwarts and Johnson (2011) extended this
model using minimal expected f-loss oriented n-
best reranking with additional corpus for language
model training.
Recently, the max-margin markov networks
(M3N) based model has achieved great improve-
ment in this task. Qian and Liu (2013) presented
a multi-step learning method using weighted M3N
model for disfluency detection. They showed that
M3N model outperformed many other labeling
models such as CRF model. Following this work,
Wang et al. (2014) used a beam-search decoder to
combine multiple models such as M3N and lan-
guage model, they achieved the highest f-score.
However, direct comparison with their work is dif-
ficult as they utilized the whole SWBD data while
we only use the subcorpus with syntactic annota-
tion which is only half the SWBD corpus and they
also used extra corpus for language model train-
ing.
Additionally, syntax-based approaches have
been proposed which concern parsing and dis-
fluency detection together. Lease and Johnson
(2006) involved disfluency detection in a PCFG
parser to parse the input along with detecting dis-
fluencies. Miller and Schuler (2008) used a right
corner transform of syntax trees to produce a syn-
tactic tree with speech repairs. But their perfor-
mance was not as good as labeling models. There
exist two methods published recently which are
similar to ours. Rasooli and Tetreault (2013) de-
signed a joint model for both disfluency detection
and dependency parsing. They regarded the two
tasks as a two step classifications. Honnibal and
Johnson (2014) presented anew joint model by ex-
tending the original transition actions with a new
“Edit” transition. They achieved the state-of-the-
art performance on both disfluency detection and
parsing. But this model suffers from the problem
that the number of transition actions is not identi-
cal for different hypotheses in decoding, leading to
the failure of performing optimal search. In con-
trast, our novel right-to-left transition-based joint
method caters to the disfluency constraint which
can not only overcome the decoding deficiency in
previous work but also achieve significantly higher
performance on disfluency detection as well as de-
pendency parsing.
</bodyText>
<sectionHeader confidence="0.98557" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999990476190476">
In this paper, we propose a novel approach for
disfluency detection. Our models jointly perform
parsing and disfluency detection from right to left
by integrating a rich set of disfluency features
which can yield parsing structure and difluency
tags at the same time with linear complexity. The
algorithm is easy to implement without compli-
cated backtrack operations. Experiential results
show that our approach outperforms the baselines
on the English Switchboard corpus and experi-
ments on the Chinese annotated corpus also show
the language independent nature of our method.
The state-of-the-art performance on disfluency de-
tection and dependency parsing can benefit the
downstream tasks of text processing.
In future work, we will try to add new classes of
features to further improve performance by cap-
turing the property of disfluencies. We would
also like to make an end-to-end MT test over
transcribed speech texts with disfluencies removed
based on the method proposed in this paper.
</bodyText>
<sectionHeader confidence="0.99756" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998265">
We are grateful to the anonymous reviewers for
their insightful comments. We also thank Mu Li,
Shujie Liu, Lei Cui and Nan Yang for the helpful
discussions.
</bodyText>
<sectionHeader confidence="0.996594" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.926756375">
Peter F Brown, Peter V Desouza, Robert L Mercer,
Vincent J Della Pietra, and Jenifer C Lai. 1992.
Class-based n-gram models of natural language.
Computational linguistics, 18(4):467–479.
Eugene Charniak and Mark Johnson. 2001. Edit detec-
tion and parsing for transcribed speech. In Proceed-
ings of the second meeting of the North American
Chapter of the Association for Computational Lin-
guistics on Language technologies, pages 1–9. As-
sociation for Computational Linguistics.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 conference on Empirical methods in
natural language processing-Volume 10, pages 1–8.
Association for Computational Linguistics.
</reference>
<page confidence="0.975675">
502
</page>
<reference confidence="0.999811933962264">
Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Proceedings of LREC, volume 6, pages
449–454.
Kallirroi Georgila. 2009. Using integer linear pro-
gramming for detecting speech disfluencies. In Pro-
ceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, Companion Volume: Short Papers, pages
109–112. Association for Computational Linguis-
tics.
Matthew Honnibal and Mark Johnson. 2014. Joint
incremental disfluency detection and dependency
parsing. Transactions of the Association for Com-
putational Linguistics, 2:131–142.
Mark Johnson and Eugene Charniak. 2004. A tag-
based noisy channel model of speech repairs. In
Proceedings of the 42nd Annual Meeting on Asso-
ciation for Computational Linguistics, page 33. As-
sociation for Computational Linguistics.
Mark Johnson, Eugene Charniak, and Matthew Lease.
2004. An improved model for recognizing disflu-
encies in conversational speech. In Proceedings of
Rich Transcription Workshop.
Jeremy G Kahn, Matthew Lease, Eugene Charniak,
Mark Johnson, and Mari Ostendorf. 2005. Effective
use of prosody in parsing conversational speech. In
Proceedings of the conference on human language
technology and empirical methods in natural lan-
guage processing, pages 233–240. Association for
Computational Linguistics.
Matthew Lease and Mark Johnson. 2006. Early dele-
tion of fillers in processing conversational speech.
In Proceedings of the Human Language Technol-
ogy Conference of the NAACL, Companion Volume:
Short Papers, pages 73–76. Association for Compu-
tational Linguistics.
Yang Liu, Elizabeth Shriberg, Andreas Stolcke, Dustin
Hillard, Mari Ostendorf, and Mary Harper. 2006.
Enriching speech recognition with automatic detec-
tion of sentence boundaries and disfluencies. Audio,
Speech, and Language Processing, IEEE Transac-
tions on, 14(5):1526–1540.
Mitchell P Marcus, Mary Ann Marcinkiewicz, and
Beatrice Santorini. 1993. Building a large anno-
tated corpus of english: The penn treebank. Compu-
tational linguistics, 19(2):313–330.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd an-
nual meeting on association for computational lin-
guistics, pages 91–98. Association for Computa-
tional Linguistics.
Marie W Meteer, Ann A Taylor, Robert MacIntyre,
and Rukmini Iyer. 1995. Dysfluency annotation
stylebook for the switchboard corpus. University of
Pennsylvania.
Tim Miller and William Schuler. 2008. A unified syn-
tactic model for parsing fluent and disfluent speech.
In Proceedings of the 46th Annual Meeting of the As-
sociation for Computational Linguistics on Human
Language Technologies: Short Papers, pages 105–
108. Association for Computational Linguistics.
Xian Qian and Yang Liu. 2013. Disfluency detection
using multi-step stacked learning. In HLT-NAACL,
pages 820–825.
Mohammad Sadegh Rasooli and Joel R Tetreault.
2013. Joint parsing and disfluency detection in lin-
ear time. In EMNLP, pages 124–129.
Xuancong Wang, Hwee Tou Ng, and Khe Chai Sim.
2014. A beam-search decoder for disfluency detec-
tion. In Proc. of COLING.
Yue Zhang and Stephen Clark. 2008. A tale of
two parsers: investigating and combining graph-
based and transition-based dependency parsing us-
ing beam-search. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 562–571. Association for Computa-
tional Linguistics.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers-Volume 2, pages
188–193. Association for Computational Linguis-
tics.
Qi Zhang, Fuliang Weng, and Zhe Feng. 2006. A pro-
gressive feature selection algorithm for ultra large
feature spaces. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
the 44th annual meeting of the Association for Com-
putational Linguistics, pages 561–568. Association
for Computational Linguistics.
Dongdong Zhang, Shuangzhi Wu, Nan Yang, and
Mu Li. 2013. Punctuation prediction with
transition-based parsing. In ACL (1), pages 752–
760.
Simon Zwarts and Mark Johnson. 2011. The impact of
language models and loss functions on repair disflu-
ency detection. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies-Volume 1,
pages 703–711. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.998855">
503
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.553340">
<title confidence="0.999374">Efficient Disfluency Detection with Transition-based Parsing</title>
<author confidence="0.705322">Dongdong Ming Tiejun Institute of</author>
<email confidence="0.803469">dozhang,tjzhao@hit.edu.cn</email>
<abstract confidence="0.999237363636364">Automatic speech recognition (ASR) outputs often contain various disfluencies. It is necessary to remove these disfluencies before processing downstream tasks. In this paper, an efficient disfluency detection approach based on right-to-left transitionbased parsing is proposed, which can efficiently identify disfluencies and keep ASR outputs grammatical. Our method exploits a global view to capture long-range dependencies for disfluency detection by integrating a rich set of syntactic and disfluency features with linear complexity. The experimental results show that our method outperforms state-of-the-art work and achieves a 85.1% f-score on the commonly used English Switchboard test set. We also apply our method to in-house annotated Chinese data and achieve a significantly higher f-score compared to the baseline of CRF-based approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V Desouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="14562" citStr="Brown et al., 1992" startWordPosition="2455" endWordPosition="2458">me linear model for both models (6) and (7) to score a parsing tree as: �Score(T) = φ(action) · λ� action Where φ(action) is the feature vector extracted from partial hypothesis T for a certain action and λ� is the weight vector. φ(action) ·X calculates the score of a certain transition action. The score of a parsing tree T is the sum of action scores. In addition to the basic features introduced in (Zhang and Nivre, 2011) that are defined over bag of words and POS-tags as well as tree-based context, our models also integrate three classes of new features combined with Brown cluster features (Brown et al., 1992) that relate to the rightto-left transition-based parsing procedure as detailed below. Simple repetition function • δI(a, b): A logic function which indicates whether a and b are identical. Syntax-based repetition function • δL(a, b): A logic function which indicates whether a is a left child of b. • δR(a, b): A logic function which indicates whether a is a right child of b. Longest subtree similarity function • NI(a, b): The count of identical children on the left side of the root node between subtrees rooted at a and b. • N#(a0..n, b): The count of words among a0 .. an that are on the right </context>
</contexts>
<marker>Brown, Desouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F Brown, Peter V Desouza, Robert L Mercer, Vincent J Della Pietra, and Jenifer C Lai. 1992. Class-based n-gram models of natural language. Computational linguistics, 18(4):467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Edit detection and parsing for transcribed speech.</title>
<date>2001</date>
<booktitle>In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies,</booktitle>
<pages>1--9</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="16459" citStr="Charniak and Johnson, 2001" startWordPosition="2783" endWordPosition="2786">d dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 Experiments 4.1 Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development sets. We use the Stanford dependency converter (De Marneffe et al., 2006) to get the dependency structure from the Switchboard corpus, as Honnibal and Johnson (2014) prove that Stanford converter is robust to the Switchboard data. For our Chinese experiments, no public Chinese corpus is available. We annotate about 25k spoken sentences with only disfluency annotations according to the guideline proposed by Meteer et al. (1995). In order to generate similar data format as </context>
</contexts>
<marker>Charniak, Johnson, 2001</marker>
<rawString>Eugene Charniak and Mark Johnson. 2001. Edit detection and parsing for transcribed speech. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, pages 1–9. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15983" citStr="Collins, 2002" startWordPosition="2710" endWordPosition="2711"> the queue and w0..2 denotes the top three words of the queue. Every pi corresponds to the POS-tag of wi and p0..2 represents the POS-tags of w0..2. In addition, wic means the Brown cluster of wi. With these symbols, several new feature templates are defined in Table 1. Both our models have the same feature templates. Basic All templates in (Zhang and features Nivre, 2011) New disfluency features Table 1: Feature templates designed for disfluency detection and dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 Experiments 4.1 Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kallirroi Georgila</author>
</authors>
<title>Using integer linear programming for detecting speech disfluencies.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers,</booktitle>
<pages>109--112</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3160" citStr="Georgila, 2009" startWordPosition="474" endWordPosition="475">eparandums vary in length, may occur everywhere, and are sometimes nested. correct Figure 1: A typical example of repair type disfluency consists of FP (Filled Pause), RM (Reparandum), and RP (Repair). The preceding RM is corrected by the following RP. There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China, July 26-31, 20</context>
</contexts>
<marker>Georgila, 2009</marker>
<rawString>Kallirroi Georgila. 2009. Using integer linear programming for detecting speech disfluencies. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers, pages 109–112. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Honnibal</author>
<author>Mark Johnson</author>
</authors>
<title>Joint incremental disfluency detection and dependency parsing.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>2--131</pages>
<contexts>
<context position="3847" citStr="Honnibal and Johnson, 2014" startWordPosition="577" endWordPosition="580">ed in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics encies (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013). These methods can jointly perform dependency parsing and disfluency detection. But in these methods, great efforts are made to distinguish normal words from disfluent words as decisions cannot be made imminently from left to right, leading to inefficient implementation as well as performance loss. In this paper, we propose detecting disfluencies using a right-to-left transition-based dependency parsing (R2L parsing), where the words are consumed from right to left to build the parsing tree based on which the current word is predicted to be either disfluent or no</context>
<context position="5243" citStr="Honnibal and Johnson, 2014" startWordPosition="803" endWordPosition="806">e, where the parsing model and disfluency predicting model are jointly calculated in a cascaded way. As shown in Figure 2(b), while the parsing tree is being built, disfluency tags are predicted and attached to the disfluency nodes. Our models are quite efficient with linear complexity of 2*N (N is the length of input). Figure 2: An instance of the detection procedure where ‘N’ stands for a normal word and ‘X’ a disfluency word. Words with italic font are Reparandums. (a) is the L2R detecting procedure and (b) is the R2L procedure. Intuitively, compared with previous syntaxbased work such as (Honnibal and Johnson, 2014) that uses left-to-right transition-based parsing (L2R parsing) model, our proposed approach simplifies disfluency detection by sequentially processing each word, without going back to modify the pre-built tree structure of disfluency words. As shown in Figure 2(a), the L2R parsing based joint approach needs to cut the pre-built dependency link between “did” and “he” when “was” is identified as the repair of “did”, which is never needed in our method as Figure 2(b). Furthermore, our method overcomes the deficiency issue in decoding of L2R parsing based joint method, meaning the number of parsi</context>
<context position="6717" citStr="Honnibal and Johnson, 2014" startWordPosition="1044" endWordPosition="1047">t accumulates over 2 * N transition actions among hypotheses in the standard transition-based parsing. Although the heuristic score, such as the normalization of transition count (Honnibal and Johnson, 2014), can be introduced, the total scores of all hypotheses are still not statistically comparable from a global view. We conduct the experiments on English Switchboard corpus. The results show that our method can achieve a 85.1% f-score with a gain of 0.7 point over state-of-the-art M3N labeling model in (Qian and Liu, 2013) and a gain of 1 point over state-of-the-art joint model proposed in (Honnibal and Johnson, 2014). We also apply our method on Chinese annotated data. As there is no available public data in Chinese, we annotate 25k Chinese sentences manually for training and testing. We achieve 71.2% f-score with 15 points gained compared to the CRF-based baseline, showing that our models are robust and language independent. 2 Transition-based dependency parsing In a typical transition-based parsing, the ShiftReduce decoding algorithm is applied and a queue and stack are maintained (Zhang and Clark, 2008). The queue stores the stream of the input and the front of the queue is indexed as the current word.</context>
<context position="9052" citStr="Honnibal and Johnson, 2014" startWordPosition="1462" endWordPosition="1465">ntence is always 2 * N, where N is the length of the sentence. Transition-based dependency parsing (Zhang and Clark, 2008) can be performed in either a leftto-right or a right-to-left way, both of which have a performance that is comparable as illustrated in Section 4. However, when they are applied to disfluency detection, their behaviors are very different due to the disfluency structure constraint. We prove that right-to-left transition-based parsing is more efficient than left-to-right transition-based parsing for disfluency detection. 3 Our method 3.1 Model Unlike previous joint methods (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013), we introduce dependency parsing into disfluency detection from theory. In the task of disfluency detection, we are given a stream of unstructured words from automatic speech recognition (ASR). We denote the word sequence with W1n := w1, w2,w3,...,wn, which is actually the inverse order of ASR words that should be wn, wn_1,wn_2,...,w1. The output of the task is a sequence of binary tags denoted as Dn1 = d1, d2,d3,...,dn, where each di corresponds to wi, indicating whether wi is a disfluency word (X) or not (N).1 Our task can be modeled as formula (1), which is to</context>
<context position="16748" citStr="Honnibal and Johnson (2014)" startWordPosition="2828" endWordPosition="2832">Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development sets. We use the Stanford dependency converter (De Marneffe et al., 2006) to get the dependency structure from the Switchboard corpus, as Honnibal and Johnson (2014) prove that Stanford converter is robust to the Switchboard data. For our Chinese experiments, no public Chinese corpus is available. We annotate about 25k spoken sentences with only disfluency annotations according to the guideline proposed by Meteer et al. (1995). In order to generate similar data format as English Switchboard corpus, we use Chinese dependency parsing trained on the Chinese Treebank corpus to parse the annotated data and use these parsed data for training and testing . For our Chinese experiment setting, we respectively select about 2k sentences for development and testing. </context>
<context position="18006" citStr="Honnibal and Johnson (2014)" startWordPosition="3035" endWordPosition="3038"> To train the UT model, we create data format adaptation by replacing the original Shift and RightArc of disfluent words with Dis Shift and Dis RightArc, since they are just extensions of Shift and RightArc. For the BCT model, disfluent words are directly depended to the root node and all their links and labels are removed. We then link all the fluent children of disfluent words to parents of disfluent words. We also remove partial words and punctuation from data to simulate speech recognizer results where such information is not available (Johnson and Charniak, 2004). Additionally, following Honnibal and Johnson (2014), we remove all one token sentences as these sentences are trivial for disfluency detection, then lowercase the text and discard filled pauses like “um” and “uh”. The evaluation metrics of disfluency detection are precision (Prec.), recall (Rec.) and f-score (F1). For parsing accuracy metrics, we use unlabeled attachment score (UAS) and labeled attachment score (LAS). For our primary comparison, we evaluate the widely used CRF labeling model, the state-of-the-art M3N model presented by Qian and Liu (2013) which has been commonly used as baseline in previous works and the state-of-the-art L2R p</context>
<context position="19936" citStr="Honnibal and Johnson, 2014" startWordPosition="3327" endWordPosition="3330">uracy Method Prec. Rec. F1 UAS LAS CRF(BOW) 81.2% 44.9% 57.8% 88.7% 84.7% CRF(BOW+POS) 88.3% 62.2% 73.1% 89.2% 85.6% M3N N/A N/A 84.1% N/A N/A M3N† 90.5% 79.1% 84.4% 91% 88.2% H&amp;J N/A N/A 84.1% 90.5% N/A UT(basic features) 86% 72.5% 78.7% 91.9% 89.0% UT(+new features) 88.8% 75.1% 81.3% 92.1% 89.4% BCT(basic features) 88.2% 77.9% 82.7% 92.1% 89.3% BCT(+new features) 90.3% 80.5% 85.1% 92.2% 89.6% Table 2: Disfluency detection and parsing accuracies on English Switchboard data. The accuracy of M3N refers to the result reported in (Qian and Liu, 2013). H&amp;J is the L2R parsing based joint model in (Honnibal and Johnson, 2014). The results of M3N† come from the experiments with toolkit released by Qian and Liu (2013) on our pre-processed corpus. sults reported in (Qian and Liu, 2013). The results of M3N† come from our experiments with the toolkit2 released by Qian and Liu (2013) which uses our data set with the same pre-processing. It is comparable between our models and the L2R parsing based joint model presented by Honnibal and Johnson (2014), as we all conduct experiments on the same pre-processed data set. In order to compare parsing accuracy, we use the CRF and M3N† model to pre-process the test set by removin</context>
<context position="23145" citStr="Honnibal and Johnson, 2014" startWordPosition="3837" endWordPosition="3840">es as shown in Table 3, which are pronouns (contain PRP and PRP$), verbs (contain VB,VBD,VBP,VBZ,VBN), determiners (contain DT), prepositions (contain IN) and conjunctions (contain CC). Obviously, these classes of words appear frequently in our communication. Pron. Verb Dete. Prep. Conj. Others Dist. 30.2% 14.7% 13% 8.7% 6.7% 26.7% Table 3: Distribution of different part-ofspeeches in disfluencies. Conj.=conjunction; Dete.=determiner; Pron.=pronoun; Prep.= preposition. 500 Table 4 illustrates the performance (f-score) on these classes of words. The results of L2R parsing based joint model in (Honnibal and Johnson, 2014) are not listed because we cannot get such detailed data. CRF CRF M3N† UT BCT (BOW) (BOW (+feat.) (+feat.) +POS) Pron. 73.9% 85% 92% 91.5% 93.8% Verb 38.2% 64.8% 84.2% 82.3% 84.7% Dete. 66.8% 80% 88% 83.7% 87% Prep. 60% 71.5% 79.1% 76.1% 79.3% Conj. 75.2% 82.2% 81.6% 79.5% 83.2% Others 43.2% 61% 78.4% 72.3% 79.1% Table 4: Performance on different classes of words. Dete.=determiner; Pron.=pronoun; Conj.=conjunction; Prep.= preposition. feat.=new disfluency features As shown in Table 4, our BCT model outperforms all other models except that the performance on determiner is lower than M3N†, which</context>
<context position="28620" citStr="Honnibal and Johnson (2014)" startWordPosition="4728" endWordPosition="4731">ed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfluencies. Miller and Schuler (2008) used a right corner transform of syntax trees to produce a syntactic tree with speech repairs. But their performance was not as good as labeling models. There exist two methods published recently which are similar to ours. Rasooli and Tetreault (2013) designed a joint model for both disfluency detection and dependency parsing. They regarded the two tasks as a two step classifications. Honnibal and Johnson (2014) presented anew joint model by extending the original transition actions with a new “Edit” transition. They achieved the state-of-theart performance on both disfluency detection and parsing. But this model suffers from the problem that the number of transition actions is not identical for different hypotheses in decoding, leading to the failure of performing optimal search. In contrast, our novel right-to-left transition-based joint method caters to the disfluency constraint which can not only overcome the decoding deficiency in previous work but also achieve significantly higher performance o</context>
</contexts>
<marker>Honnibal, Johnson, 2014</marker>
<rawString>Matthew Honnibal and Mark Johnson. 2014. Joint incremental disfluency detection and dependency parsing. Transactions of the Association for Computational Linguistics, 2:131–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Eugene Charniak</author>
</authors>
<title>A tagbased noisy channel model of speech repairs.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>page</pages>
<contexts>
<context position="17953" citStr="Johnson and Charniak, 2004" startWordPosition="3029" endWordPosition="3032">elopment and testing. The rest are used for training. To train the UT model, we create data format adaptation by replacing the original Shift and RightArc of disfluent words with Dis Shift and Dis RightArc, since they are just extensions of Shift and RightArc. For the BCT model, disfluent words are directly depended to the root node and all their links and labels are removed. We then link all the fluent children of disfluent words to parents of disfluent words. We also remove partial words and punctuation from data to simulate speech recognizer results where such information is not available (Johnson and Charniak, 2004). Additionally, following Honnibal and Johnson (2014), we remove all one token sentences as these sentences are trivial for disfluency detection, then lowercase the text and discard filled pauses like “um” and “uh”. The evaluation metrics of disfluency detection are precision (Prec.), recall (Rec.) and f-score (F1). For parsing accuracy metrics, we use unlabeled attachment score (UAS) and labeled attachment score (LAS). For our primary comparison, we evaluate the widely used CRF labeling model, the state-of-the-art M3N model presented by Qian and Liu (2013) which has been commonly used as base</context>
<context position="26845" citStr="Johnson and Charniak (2004)" startWordPosition="4441" endWordPosition="4444">s are more robust on written text data. The performances of R2L and L2R parsing are comparable on both SWBD and WSJ test sets. This demonstrates that the effectiveness of our disfluency detection model mainly relies on catering to the disfluency constraint by using R2L parsing based approach, instead of the difference in parsing models between L2R and R2L parsings. 5 Related work In practice, disfluency detection has been extensively studied in both speech processing field and natural language processing field. Noisy channel models have been widely used in the past to detect 501 disfluencies. Johnson and Charniak (2004) proposed a TAG-based noisy channel model where the TAG model was used to find rough copies. Thereafter, a language model and MaxEnt reranker were added to the noisy channel model by Johnson et al. (2004). Following their framework, Zwarts and Johnson (2011) extended this model using minimal expected f-loss oriented nbest reranking with additional corpus for language model training. Recently, the max-margin markov networks (M3N) based model has achieved great improvement in this task. Qian and Liu (2013) presented a multi-step learning method using weighted M3N model for disfluency detection. </context>
</contexts>
<marker>Johnson, Charniak, 2004</marker>
<rawString>Mark Johnson and Eugene Charniak. 2004. A tagbased noisy channel model of speech repairs. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 33. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Eugene Charniak</author>
<author>Matthew Lease</author>
</authors>
<title>An improved model for recognizing disfluencies in conversational speech.</title>
<date>2004</date>
<booktitle>In Proceedings of Rich Transcription Workshop.</booktitle>
<contexts>
<context position="27049" citStr="Johnson et al. (2004)" startWordPosition="4478" endWordPosition="4481">elies on catering to the disfluency constraint by using R2L parsing based approach, instead of the difference in parsing models between L2R and R2L parsings. 5 Related work In practice, disfluency detection has been extensively studied in both speech processing field and natural language processing field. Noisy channel models have been widely used in the past to detect 501 disfluencies. Johnson and Charniak (2004) proposed a TAG-based noisy channel model where the TAG model was used to find rough copies. Thereafter, a language model and MaxEnt reranker were added to the noisy channel model by Johnson et al. (2004). Following their framework, Zwarts and Johnson (2011) extended this model using minimal expected f-loss oriented nbest reranking with additional corpus for language model training. Recently, the max-margin markov networks (M3N) based model has achieved great improvement in this task. Qian and Liu (2013) presented a multi-step learning method using weighted M3N model for disfluency detection. They showed that M3N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3N and language</context>
</contexts>
<marker>Johnson, Charniak, Lease, 2004</marker>
<rawString>Mark Johnson, Eugene Charniak, and Matthew Lease. 2004. An improved model for recognizing disfluencies in conversational speech. In Proceedings of Rich Transcription Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy G Kahn</author>
<author>Matthew Lease</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
<author>Mari Ostendorf</author>
</authors>
<title>Effective use of prosody in parsing conversational speech.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on human language technology and empirical methods in natural language processing,</booktitle>
<pages>233--240</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3245" citStr="Kahn et al., 2005" startWordPosition="487" endWordPosition="490"> Figure 1: A typical example of repair type disfluency consists of FP (Filled Pause), RM (Reparandum), and RP (Repair). The preceding RM is corrected by the following RP. There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics encies (Honnibal and Johnson, 20</context>
</contexts>
<marker>Kahn, Lease, Charniak, Johnson, Ostendorf, 2005</marker>
<rawString>Jeremy G Kahn, Matthew Lease, Eugene Charniak, Mark Johnson, and Mari Ostendorf. 2005. Effective use of prosody in parsing conversational speech. In Proceedings of the conference on human language technology and empirical methods in natural language processing, pages 233–240. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Lease</author>
<author>Mark Johnson</author>
</authors>
<title>Early deletion of fillers in processing conversational speech.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers,</booktitle>
<pages>73--76</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28077" citStr="Lease and Johnson (2006)" startWordPosition="4639" endWordPosition="4642">wed that M3N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfluencies. Miller and Schuler (2008) used a right corner transform of syntax trees to produce a syntactic tree with speech repairs. But their performance was not as good as labeling models. There exist two methods published recently which are similar to ours. Rasooli and Tetreault (2013) designed a joint model for both disfluency detection and dependency parsing. They regarded the two tasks as a two step classifications. Honnibal and Johnson (2014) presented anew joint model by extending the original tra</context>
</contexts>
<marker>Lease, Johnson, 2006</marker>
<rawString>Matthew Lease and Mark Johnson. 2006. Early deletion of fillers in processing conversational speech. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers, pages 73–76. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Liu</author>
<author>Elizabeth Shriberg</author>
<author>Andreas Stolcke</author>
<author>Dustin Hillard</author>
<author>Mari Ostendorf</author>
<author>Mary Harper</author>
</authors>
<title>Enriching speech recognition with automatic detection of sentence boundaries and disfluencies. Audio, Speech, and Language Processing,</title>
<date>2006</date>
<journal>IEEE Transactions on,</journal>
<volume>14</volume>
<issue>5</issue>
<contexts>
<context position="3144" citStr="Liu et al., 2006" startWordPosition="470" endWordPosition="473">uencies are that reparandums vary in length, may occur everywhere, and are sometimes nested. correct Figure 1: A typical example of repair type disfluency consists of FP (Filled Pause), RM (Reparandum), and RP (Repair). The preceding RM is corrected by the following RP. There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China</context>
</contexts>
<marker>Liu, Shriberg, Stolcke, Hillard, Ostendorf, Harper, 2006</marker>
<rawString>Yang Liu, Elizabeth Shriberg, Andreas Stolcke, Dustin Hillard, Mari Ostendorf, and Mary Harper. 2006. Enriching speech recognition with automatic detection of sentence boundaries and disfluencies. Audio, Speech, and Language Processing, IEEE Transactions on, 14(5):1526–1540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Beatrice Santorini</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<booktitle>Computational linguistics,</booktitle>
<pages>19--2</pages>
<contexts>
<context position="16216" citStr="Marcus et al., 1993" startWordPosition="2748" endWordPosition="2751">w feature templates are defined in Table 1. Both our models have the same feature templates. Basic All templates in (Zhang and features Nivre, 2011) New disfluency features Table 1: Feature templates designed for disfluency detection and dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 Experiments 4.1 Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development sets. We use the Stanford dependency converter (De Marneffe et al., 2006) to get the dependency structure from the Switchboard corpus, as Honnibal and Johnson (2014) prove that Stanford converter is robust to the Switchboard data. Fo</context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. 1993. Building a large annotated corpus of english: The penn treebank. Computational linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd annual meeting on association for computational linguistics,</booktitle>
<pages>91--98</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="25587" citStr="McDonald et al., 2005" startWordPosition="4229" endWordPosition="4233">ic annotations and more data, we would get much better results. 4.2.4 Performance of transition-based parsing In order to show whether the advantage of the BCT model is caused by the disfluency constraint or the difference between R2L and L2R parsing models, in this section, we make a comparison between the original left-to-right transition-based parsing and right-to-left parsing. These experiments are performed with the Penn Treebank (PTB) Wall Street Journal (WSJ) corpus. We follow the standard approach to split the corpus as 2-21 for training, 22 for development and section 23 for testing (McDonald et al., 2005). The features for the two parsers are basic features in Table 1. The POStagger model that we implement for a pre-process before parsing also uses structured perceptron for training and can achieve a competitive accuracy of 96.7%. The beam size for both POS-tagger and parsing is set to 5. Table 6 presents the results on WSJ test set and Switchboard (SWBD) test set. Data sets Model UAS LAS WSJ L2R Parsing 92.1% 89.8% R2L Parsing 92.0% 89.6% SWBD L2R Parsing 88.4% 84.4% R2L Parsing 88.7% 84.8% Table 6: Performance of our parsers on different test sets. The parsing accuracy on SWBD is lower than </context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of the 43rd annual meeting on association for computational linguistics, pages 91–98. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie W Meteer</author>
<author>Ann A Taylor</author>
<author>Robert MacIntyre</author>
<author>Rukmini Iyer</author>
</authors>
<title>Dysfluency annotation stylebook for the switchboard corpus.</title>
<date>1995</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="17013" citStr="Meteer et al. (1995)" startWordPosition="2871" endWordPosition="2874"> Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/MRG/SWBD and directory 4 is split into test and development sets. We use the Stanford dependency converter (De Marneffe et al., 2006) to get the dependency structure from the Switchboard corpus, as Honnibal and Johnson (2014) prove that Stanford converter is robust to the Switchboard data. For our Chinese experiments, no public Chinese corpus is available. We annotate about 25k spoken sentences with only disfluency annotations according to the guideline proposed by Meteer et al. (1995). In order to generate similar data format as English Switchboard corpus, we use Chinese dependency parsing trained on the Chinese Treebank corpus to parse the annotated data and use these parsed data for training and testing . For our Chinese experiment setting, we respectively select about 2k sentences for development and testing. The rest are used for training. To train the UT model, we create data format adaptation by replacing the original Shift and RightArc of disfluent words with Dis Shift and Dis RightArc, since they are just extensions of Shift and RightArc. For the BCT model, disflue</context>
</contexts>
<marker>Meteer, Taylor, MacIntyre, Iyer, 1995</marker>
<rawString>Marie W Meteer, Ann A Taylor, Robert MacIntyre, and Rukmini Iyer. 1995. Dysfluency annotation stylebook for the switchboard corpus. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Miller</author>
<author>William Schuler</author>
</authors>
<title>A unified syntactic model for parsing fluent and disfluent speech.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers,</booktitle>
<pages>105--108</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="28204" citStr="Miller and Schuler (2008)" startWordPosition="4659" endWordPosition="4662">eam-search decoder to combine multiple models such as M3N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfluencies. Miller and Schuler (2008) used a right corner transform of syntax trees to produce a syntactic tree with speech repairs. But their performance was not as good as labeling models. There exist two methods published recently which are similar to ours. Rasooli and Tetreault (2013) designed a joint model for both disfluency detection and dependency parsing. They regarded the two tasks as a two step classifications. Honnibal and Johnson (2014) presented anew joint model by extending the original transition actions with a new “Edit” transition. They achieved the state-of-theart performance on both disfluency detection and pa</context>
</contexts>
<marker>Miller, Schuler, 2008</marker>
<rawString>Tim Miller and William Schuler. 2008. A unified syntactic model for parsing fluent and disfluent speech. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics on Human Language Technologies: Short Papers, pages 105– 108. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xian Qian</author>
<author>Yang Liu</author>
</authors>
<title>Disfluency detection using multi-step stacked learning.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>820--825</pages>
<contexts>
<context position="3181" citStr="Qian and Liu, 2013" startWordPosition="476" endWordPosition="479">in length, may occur everywhere, and are sometimes nested. correct Figure 1: A typical example of repair type disfluency consists of FP (Filled Pause), RM (Reparandum), and RP (Repair). The preceding RM is corrected by the following RP. There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China, July 26-31, 2015. c�2015 Associatio</context>
<context position="6620" citStr="Qian and Liu, 2013" startWordPosition="1028" endWordPosition="1031">nvolvement of the extra cut operation in Figure 2(a) destroys the competition scoring that accumulates over 2 * N transition actions among hypotheses in the standard transition-based parsing. Although the heuristic score, such as the normalization of transition count (Honnibal and Johnson, 2014), can be introduced, the total scores of all hypotheses are still not statistically comparable from a global view. We conduct the experiments on English Switchboard corpus. The results show that our method can achieve a 85.1% f-score with a gain of 0.7 point over state-of-the-art M3N labeling model in (Qian and Liu, 2013) and a gain of 1 point over state-of-the-art joint model proposed in (Honnibal and Johnson, 2014). We also apply our method on Chinese annotated data. As there is no available public data in Chinese, we annotate 25k Chinese sentences manually for training and testing. We achieve 71.2% f-score with 15 points gained compared to the CRF-based baseline, showing that our models are robust and language independent. 2 Transition-based dependency parsing In a typical transition-based parsing, the ShiftReduce decoding algorithm is applied and a queue and stack are maintained (Zhang and Clark, 2008). Th</context>
<context position="18516" citStr="Qian and Liu (2013)" startWordPosition="3114" endWordPosition="3117">nformation is not available (Johnson and Charniak, 2004). Additionally, following Honnibal and Johnson (2014), we remove all one token sentences as these sentences are trivial for disfluency detection, then lowercase the text and discard filled pauses like “um” and “uh”. The evaluation metrics of disfluency detection are precision (Prec.), recall (Rec.) and f-score (F1). For parsing accuracy metrics, we use unlabeled attachment score (UAS) and labeled attachment score (LAS). For our primary comparison, we evaluate the widely used CRF labeling model, the state-of-the-art M3N model presented by Qian and Liu (2013) which has been commonly used as baseline in previous works and the state-of-the-art L2R parsing based joint model proposed by Honnibal and Johnson (2014). 4.2 Experimental results 4.2.1 Performance of disfluency detection on English Swtichboard corpus The evaluation results of both disfluency detection and parsing accuracy are presented in Table 2. The accuracy of M3N directly refers to the reδI(ws, w0);δI(ps, p0); δL(w0, ws);δL(p0, ps); δR(w0, ws);δR(p0, ps); NI(w0, ws);NI(p0,ps); N#(w0..2, ws);N#(p0..2, ps); δI(ws, w0)δI(ps, p0); δL(w0, ws)δL(p0, ps); δR(w0, ws)δR(p0, ps); NI(w0, ws)NI(p0, </context>
<context position="19862" citStr="Qian and Liu, 2013" startWordPosition="3314" endWordPosition="3317">w0); wsw0δI(ps, p0); 499 Disfluency detection accuracy Parsing accuracy Method Prec. Rec. F1 UAS LAS CRF(BOW) 81.2% 44.9% 57.8% 88.7% 84.7% CRF(BOW+POS) 88.3% 62.2% 73.1% 89.2% 85.6% M3N N/A N/A 84.1% N/A N/A M3N† 90.5% 79.1% 84.4% 91% 88.2% H&amp;J N/A N/A 84.1% 90.5% N/A UT(basic features) 86% 72.5% 78.7% 91.9% 89.0% UT(+new features) 88.8% 75.1% 81.3% 92.1% 89.4% BCT(basic features) 88.2% 77.9% 82.7% 92.1% 89.3% BCT(+new features) 90.3% 80.5% 85.1% 92.2% 89.6% Table 2: Disfluency detection and parsing accuracies on English Switchboard data. The accuracy of M3N refers to the result reported in (Qian and Liu, 2013). H&amp;J is the L2R parsing based joint model in (Honnibal and Johnson, 2014). The results of M3N† come from the experiments with toolkit released by Qian and Liu (2013) on our pre-processed corpus. sults reported in (Qian and Liu, 2013). The results of M3N† come from our experiments with the toolkit2 released by Qian and Liu (2013) which uses our data set with the same pre-processing. It is comparable between our models and the L2R parsing based joint model presented by Honnibal and Johnson (2014), as we all conduct experiments on the same pre-processed data set. In order to compare parsing accu</context>
<context position="24111" citStr="Qian and Liu, 2013" startWordPosition="3990" endWordPosition="3993">t classes of words. Dete.=determiner; Pron.=pronoun; Conj.=conjunction; Prep.= preposition. feat.=new disfluency features As shown in Table 4, our BCT model outperforms all other models except that the performance on determiner is lower than M3N†, which shows that our algorithm can significantly tackle common disfluencies. 4.2.3 Performance of disfluency detection on Chinese annotated corpus In addition to English experiments, we also apply our method on Chinese annotated data. As there is no standard Chinese corpus, no Chinese experimental results are reported in (Honnibal and Johnson, 2014; Qian and Liu, 2013). We only use the CRF-based labeling model with lexical and POStag features as baselines. Table 5 shows the results of Chinese disfluency detection. Model Prec. Rec. F1 CRF(BOW) 89.5% 35.6% 50.9% CRF(BOW+POS) 83.4% 41.6% 55.5% UT(+new features) 86.7% 59.5% 70.6% BCT(+new features) 85.5% 61% 71.2% Table 5: Disfluency detection performance on Chinese annotated data. Our models outperform the CRF model with bag of words and POS-tag features by more than 15 points on f-score which shows that our method is more effective. As shown latter in 4.2.4, the standard transition-based parsing is not robust</context>
<context position="27354" citStr="Qian and Liu (2013)" startWordPosition="4524" endWordPosition="4527">Noisy channel models have been widely used in the past to detect 501 disfluencies. Johnson and Charniak (2004) proposed a TAG-based noisy channel model where the TAG model was used to find rough copies. Thereafter, a language model and MaxEnt reranker were added to the noisy channel model by Johnson et al. (2004). Following their framework, Zwarts and Johnson (2011) extended this model using minimal expected f-loss oriented nbest reranking with additional corpus for language model training. Recently, the max-margin markov networks (M3N) based model has achieved great improvement in this task. Qian and Liu (2013) presented a multi-step learning method using weighted M3N model for disfluency detection. They showed that M3N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, s</context>
</contexts>
<marker>Qian, Liu, 2013</marker>
<rawString>Xian Qian and Yang Liu. 2013. Disfluency detection using multi-step stacked learning. In HLT-NAACL, pages 820–825.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Sadegh Rasooli</author>
<author>Joel R Tetreault</author>
</authors>
<title>Joint parsing and disfluency detection in linear time.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>124--129</pages>
<contexts>
<context position="3877" citStr="Rasooli and Tetreault, 2013" startWordPosition="581" endWordPosition="584">ang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics encies (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013). These methods can jointly perform dependency parsing and disfluency detection. But in these methods, great efforts are made to distinguish normal words from disfluent words as decisions cannot be made imminently from left to right, leading to inefficient implementation as well as performance loss. In this paper, we propose detecting disfluencies using a right-to-left transition-based dependency parsing (R2L parsing), where the words are consumed from right to left to build the parsing tree based on which the current word is predicted to be either disfluent or normal. The proposed models cate</context>
<context position="9082" citStr="Rasooli and Tetreault, 2013" startWordPosition="1466" endWordPosition="1469">e N is the length of the sentence. Transition-based dependency parsing (Zhang and Clark, 2008) can be performed in either a leftto-right or a right-to-left way, both of which have a performance that is comparable as illustrated in Section 4. However, when they are applied to disfluency detection, their behaviors are very different due to the disfluency structure constraint. We prove that right-to-left transition-based parsing is more efficient than left-to-right transition-based parsing for disfluency detection. 3 Our method 3.1 Model Unlike previous joint methods (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013), we introduce dependency parsing into disfluency detection from theory. In the task of disfluency detection, we are given a stream of unstructured words from automatic speech recognition (ASR). We denote the word sequence with W1n := w1, w2,w3,...,wn, which is actually the inverse order of ASR words that should be wn, wn_1,wn_2,...,w1. The output of the task is a sequence of binary tags denoted as Dn1 = d1, d2,d3,...,dn, where each di corresponds to wi, indicating whether wi is a disfluency word (X) or not (N).1 Our task can be modeled as formula (1), which is to search the best sequence D∗ g</context>
<context position="28456" citStr="Rasooli and Tetreault (2013)" startWordPosition="4702" endWordPosition="4705">tic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfluencies. Miller and Schuler (2008) used a right corner transform of syntax trees to produce a syntactic tree with speech repairs. But their performance was not as good as labeling models. There exist two methods published recently which are similar to ours. Rasooli and Tetreault (2013) designed a joint model for both disfluency detection and dependency parsing. They regarded the two tasks as a two step classifications. Honnibal and Johnson (2014) presented anew joint model by extending the original transition actions with a new “Edit” transition. They achieved the state-of-theart performance on both disfluency detection and parsing. But this model suffers from the problem that the number of transition actions is not identical for different hypotheses in decoding, leading to the failure of performing optimal search. In contrast, our novel right-to-left transition-based joint</context>
</contexts>
<marker>Rasooli, Tetreault, 2013</marker>
<rawString>Mohammad Sadegh Rasooli and Joel R Tetreault. 2013. Joint parsing and disfluency detection in linear time. In EMNLP, pages 124–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuancong Wang</author>
<author>Hwee Tou Ng</author>
<author>Khe Chai Sim</author>
</authors>
<title>A beam-search decoder for disfluency detection.</title>
<date>2014</date>
<booktitle>In Proc. of COLING.</booktitle>
<contexts>
<context position="27570" citStr="Wang et al. (2014)" startWordPosition="4557" endWordPosition="4560">language model and MaxEnt reranker were added to the noisy channel model by Johnson et al. (2004). Following their framework, Zwarts and Johnson (2011) extended this model using minimal expected f-loss oriented nbest reranking with additional corpus for language model training. Recently, the max-margin markov networks (M3N) based model has achieved great improvement in this task. Qian and Liu (2013) presented a multi-step learning method using weighted M3N model for disfluency detection. They showed that M3N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3N and language model, they achieved the highest f-score. However, direct comparison with their work is difficult as they utilized the whole SWBD data while we only use the subcorpus with syntactic annotation which is only half the SWBD corpus and they also used extra corpus for language model training. Additionally, syntax-based approaches have been proposed which concern parsing and disfluency detection together. Lease and Johnson (2006) involved disfluency detection in a PCFG parser to parse the input along with detecting disfl</context>
</contexts>
<marker>Wang, Ng, Sim, 2014</marker>
<rawString>Xuancong Wang, Hwee Tou Ng, and Khe Chai Sim. 2014. A beam-search decoder for disfluency detection. In Proc. of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: investigating and combining graphbased and transition-based dependency parsing using beam-search.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>562--571</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7216" citStr="Zhang and Clark, 2008" startWordPosition="1122" endWordPosition="1125">el in (Qian and Liu, 2013) and a gain of 1 point over state-of-the-art joint model proposed in (Honnibal and Johnson, 2014). We also apply our method on Chinese annotated data. As there is no available public data in Chinese, we annotate 25k Chinese sentences manually for training and testing. We achieve 71.2% f-score with 15 points gained compared to the CRF-based baseline, showing that our models are robust and language independent. 2 Transition-based dependency parsing In a typical transition-based parsing, the ShiftReduce decoding algorithm is applied and a queue and stack are maintained (Zhang and Clark, 2008). The queue stores the stream of the input and the front of the queue is indexed as the current word. The stack stores the unfinished words which may be linked to the current word or a future word in the queue. When words in the queue are consumed in sequential order, a set of transition actions is applied to build a parsing tree. There are four kinds of transition actions in the parsing process (Zhang and Clark, 2008), as described below. • Shift : Removes the front of the queue and pushes it to the stack. • Reduce: Pops the top of the stack. • LeftArc : Pops the top of the stack, and links t</context>
<context position="8548" citStr="Zhang and Clark, 2008" startWordPosition="1387" endWordPosition="1390">d, removes the front of the queue and pushes it to the stack. The choice of each transition action during parsing is scored by a generalized perceptron (Collins, root root did was was did N N N N (a) (b) he X N great great N X he 496 2002) which can be trained over a rich set of nonlocal features. In decoding, beam search is performed to search the optimal sequence of transition actions. As each word must be pushed to the stack once and popped off once, the number of actions needed to parse a sentence is always 2 * N, where N is the length of the sentence. Transition-based dependency parsing (Zhang and Clark, 2008) can be performed in either a leftto-right or a right-to-left way, both of which have a performance that is comparable as illustrated in Section 4. However, when they are applied to disfluency detection, their behaviors are very different due to the disfluency structure constraint. We prove that right-to-left transition-based parsing is more efficient than left-to-right transition-based parsing for disfluency detection. 3 Our method 3.1 Model Unlike previous joint methods (Honnibal and Johnson, 2014; Rasooli and Tetreault, 2013), we introduce dependency parsing into disfluency detection from t</context>
<context position="15899" citStr="Zhang and Clark, 2008" startWordPosition="2695" endWordPosition="2698">model computation, where ws denotes the top word of the stack, w0 denotes the front word of the queue and w0..2 denotes the top three words of the queue. Every pi corresponds to the POS-tag of wi and p0..2 represents the POS-tags of w0..2. In addition, wic means the Brown cluster of wi. With these symbols, several new feature templates are defined in Table 1. Both our models have the same feature templates. Basic All templates in (Zhang and features Nivre, 2011) New disfluency features Table 1: Feature templates designed for disfluency detection and dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 Experiments 4.1 Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains direct</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: investigating and combining graphbased and transition-based dependency parsing using beam-search. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 562–571. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2,</booktitle>
<pages>188--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14369" citStr="Zhang and Nivre, 2011" startWordPosition="2421" endWordPosition="2424">usly disfluent. Unlike UT model, the BCT will not link the word “did” to any word. Instead only a virtual link will add it to the virtual root. 3.4 Training and decoding In practice, we use the same linear model for both models (6) and (7) to score a parsing tree as: �Score(T) = φ(action) · λ� action Where φ(action) is the feature vector extracted from partial hypothesis T for a certain action and λ� is the weight vector. φ(action) ·X calculates the score of a certain transition action. The score of a parsing tree T is the sum of action scores. In addition to the basic features introduced in (Zhang and Nivre, 2011) that are defined over bag of words and POS-tags as well as tree-based context, our models also integrate three classes of new features combined with Brown cluster features (Brown et al., 1992) that relate to the rightto-left transition-based parsing procedure as detailed below. Simple repetition function • δI(a, b): A logic function which indicates whether a and b are identical. Syntax-based repetition function • δL(a, b): A logic function which indicates whether a is a left child of b. • δR(a, b): A logic function which indicates whether a is a right child of b. Longest subtree similarity fu</context>
<context position="15923" citStr="Zhang and Nivre, 2011" startWordPosition="2699" endWordPosition="2702">e ws denotes the top word of the stack, w0 denotes the front word of the queue and w0..2 denotes the top three words of the queue. Every pi corresponds to the POS-tag of wi and p0..2 represents the POS-tags of w0..2. In addition, wic means the Brown cluster of wi. With these symbols, several new feature templates are defined in Table 1. Both our models have the same feature templates. Basic All templates in (Zhang and features Nivre, 2011) New disfluency features Table 1: Feature templates designed for disfluency detection and dependency parsing. Similar to the work in (Zhang and Clark, 2008; Zhang and Nivre, 2011), we train our models by averaged perceptron (Collins, 2002). In decoding, beam search is performed to get the optimal parsing tree as well as the tag sequence. 4 Experiments 4.1 Experimental setup Our training data is the Switchboard portion of the English Penn Treebank (Marcus et al., 1993) corpus, which consists of telephone conversations about assigned topics. As not all the Switchboard data has syntactic bracketing, we only use the subcorpus of PAESED/MRG/SWBD. Following the experiment settings in (Charniak and Johnson, 2001), the training subcorpus contains directories 2 and 3 in PAESED/</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers-Volume 2, pages 188–193. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi Zhang</author>
<author>Fuliang Weng</author>
<author>Zhe Feng</author>
</authors>
<title>A progressive feature selection algorithm for ultra large feature spaces.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>561--568</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3266" citStr="Zhang et al., 2006" startWordPosition="491" endWordPosition="494">l example of repair type disfluency consists of FP (Filled Pause), RM (Reparandum), and RP (Repair). The preceding RM is corrected by the following RP. There are many related works on disfluency detection, that mainly focus on detecting repair type of disfluencies. Straightforwardly, disfluency detection can be treated as a sequence labeling problem and solved by well-known machine learning algorithms such as conditional random fields (CRF) or max-margin markov network (M3N) (Liu et al., 2006; Georgila, 2009; Qian and Liu, 2013), and prosodic features are also concerned in (Kahn et al., 2005; Zhang et al., 2006). These methods achieve good performance, but are not powerful enough to capture complicated disfluencies with longer spans or distances. Recently, syntax-based models such as transitionbased parser have been used for detecting disfluI want a flight to Boston um to Denver RM FP RP 495 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 495–503, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics encies (Honnibal and Johnson, 2014; Rasooli and Tetre</context>
</contexts>
<marker>Zhang, Weng, Feng, 2006</marker>
<rawString>Qi Zhang, Fuliang Weng, and Zhe Feng. 2006. A progressive feature selection algorithm for ultra large feature spaces. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 561–568. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Dongdong Zhang</author>
<author>Shuangzhi Wu</author>
</authors>
<location>Nan Yang, and</location>
<marker>Zhang, Wu, </marker>
<rawString>Dongdong Zhang, Shuangzhi Wu, Nan Yang, and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mu Li</author>
</authors>
<title>Punctuation prediction with transition-based parsing.</title>
<date>2013</date>
<booktitle>In ACL (1),</booktitle>
<pages>752--760</pages>
<marker>Li, 2013</marker>
<rawString>Mu Li. 2013. Punctuation prediction with transition-based parsing. In ACL (1), pages 752– 760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Zwarts</author>
<author>Mark Johnson</author>
</authors>
<title>The impact of language models and loss functions on repair disfluency detection.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>703--711</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="27103" citStr="Zwarts and Johnson (2011)" startWordPosition="4486" endWordPosition="4489">using R2L parsing based approach, instead of the difference in parsing models between L2R and R2L parsings. 5 Related work In practice, disfluency detection has been extensively studied in both speech processing field and natural language processing field. Noisy channel models have been widely used in the past to detect 501 disfluencies. Johnson and Charniak (2004) proposed a TAG-based noisy channel model where the TAG model was used to find rough copies. Thereafter, a language model and MaxEnt reranker were added to the noisy channel model by Johnson et al. (2004). Following their framework, Zwarts and Johnson (2011) extended this model using minimal expected f-loss oriented nbest reranking with additional corpus for language model training. Recently, the max-margin markov networks (M3N) based model has achieved great improvement in this task. Qian and Liu (2013) presented a multi-step learning method using weighted M3N model for disfluency detection. They showed that M3N model outperformed many other labeling models such as CRF model. Following this work, Wang et al. (2014) used a beam-search decoder to combine multiple models such as M3N and language model, they achieved the highest f-score. However, di</context>
</contexts>
<marker>Zwarts, Johnson, 2011</marker>
<rawString>Simon Zwarts and Mark Johnson. 2011. The impact of language models and loss functions on repair disfluency detection. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 703–711. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>