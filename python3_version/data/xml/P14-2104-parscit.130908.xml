<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.026954">
<title confidence="0.984614">
Training a Korean SRL System with Rich Morphological Features
</title>
<author confidence="0.999099">
Young-Bum Kim, Heemoon Chae, Benjamin Snyder and Yu-Seop Kim*
</author>
<affiliation confidence="0.998801">
University of Wisconsin-Madison, Hallym University*
</affiliation>
<email confidence="0.978234">
{ybkim, hmchae21, bsnyder}@cs.wisc.edu, yskim01@hallym.ac.kr*
</email>
<sectionHeader confidence="0.993466" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999325529411765">
In this paper we introduce a semantic role
labeler for Korean, an agglutinative lan-
guage with rich morphology. First, we
create a novel training source by semanti-
cally annotating a Korean corpus contain-
ing fine-grained morphological and syn-
tactic information. We then develop a su-
pervised SRL model by leveraging mor-
phological features of Korean that tend
to correspond with semantic roles. Our
model also employs a variety of latent
morpheme representations induced from a
larger body of unannotated Korean text.
These elements lead to state-of-the-art per-
formance of 81.07% labeled F1, represent-
ing the best SRL performance reported to
date for an agglutinative language.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.985434636363637">
Semantic Role Labeling (SRL) is the task of auto-
matically annotating the predicate-argument struc-
ture in a sentence with semantic roles. Ever since
Gildea and Jurafsky (2002), SRL has become an
important technology used in applications requir-
ing semantic interpretation, ranging from infor-
mation extraction (Frank et al., 2007) and ques-
tion answering (Narayanan and Harabagiu, 2004),
to practical problems including textual entailment
(Burchardt et al., 2007) and pictorial communica-
tion systems (Goldberg et al., 2008).
SRL systems in many languages have been
developed as the necessary linguistic resources
become available (Taul´e et al., 2008; Xue and
Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et
al., 2002). Seven languages were the subject of the
CoNLL-2009 shared task in syntactic and seman-
tic parsing (Hajiˇc et al., 2009). These languages
can be categorized into three broad morphological
types: fusional (4), analytic (2), and one aggluti-
native language.
Paul studies mathematics with Jane at a library
</bodyText>
<subsubsectionHeader confidence="0.71002">
Poleun doseogwaneseo Jeingwa suhageull gongbuhanda
</subsubsectionHeader>
<figureCaption confidence="0.970343">
Figure 1: English (SVO) and Korean (SOV) words
</figureCaption>
<bodyText confidence="0.978129823529412">
alignment. The subject, verb, and object are high-
lighted as red, blue, and green, respectively. Also,
prepositions and suffixes are highlighted as purple.
Bj¨orkelund et al. (2009) report an average la-
beled semantic F1-score of 80.80% across these
languages. The highest performance was achieved
for the analytic language group (82.12%), while
the agglutinative language, Japanese, yielded the
lowest performance (76.30%). Agglutinative lan-
guages such as Japanese, Korean, and Turkish are
computationally difficult due to word-form spar-
sity, variable word order, and the challenge of us-
ing rich morphological features.
In this paper, we describe a Korean SRL system
which achieves 81% labeled semantic F1-score.
As far as we know, this is the highest accuracy
obtained for Korean, as well as any agglutinative
language. Figure 1 displays a English/Korean sen-
tence pair, highlighting the SOV word order of Ko-
rean as well as its rich morphological structure.
Two factors proved crucial in the performance of
our SRL system: (i) The analysis of fine-grained
morphological tags specific to Korean, and (ii) the
use of latent stem and morpheme representations
to deal with sparsity. We incorporated both of
these elements in a CRF (Lafferty et al., 2001) role
labeling model.
Besides the contribution of this model and SRL
system, we also report on the creation and avail-
ability of a new semantically annotated Korean
corpus, covering over 8,000 sentences. We used
this corpus to develop, train, and test our Korean
SRL model. In the next section, we describe the
process of corpus creation in more detail.
</bodyText>
<page confidence="0.97485">
637
</page>
<bodyText confidence="0.545955">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 637–642,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.9243295" genericHeader="introduction">
2 A Semantically Annotated Korean
Corpus
</sectionHeader>
<bodyText confidence="0.999896021276596">
We annotated predicate-argument structure of
verbs in a corpus from the Electronics and
Telecommunications Research Institute of Korea
(ETRI).1 Our corpus was developed over two
years using a specialized annotation tool (Song et
al., 2012), resulting in more than 8,000 semanti-
cally annotated sentences. As much as possible,
annotations followed the PropBank guidelines for
English (Bonial et al., 2010).
We view our work as building on the efforts of
the Penn Korean PropBank (PKPB).2 Our corpus
is roughly similar in size to the PKPB, and taken
together, the two Korean corpora now total about
half the size of the Penn English PropBank. One
advantage of our corpus is that it is built on top of
the ETRI Korean corpus, which uses a richer Ko-
rean morphological tagging scheme than the Penn
Korean Treebank. Our experiments will show that
these finer-grained tags are crucial for achieving
high SRL accuracy.
All annotations were performed by two people
working in a team. At first, each annotator as-
signs semantic roles independently and then they
discuss to reduce disagreement of their annotation
results. Initially, the disagreement rate between
two annotators was about 14%. After 4 months
of this process, the disagreement rate fell to 4%
through the process of building annotation rules
for Korean. The underlying ETRI syntactically-
annotated corpus contains the dependency tree
structure of sentences with morpho-syntactic tags.
It includes 101,602 multiple-clause sentences with
21.66 words on average.
We encountered two major difficulties during
annotation. First, the existing Korean frame files
from the Penn Korean PropBank include 2,749
verbs, covering only 13.87% of all the verbs in the
ETRI corpus. Secondly, no Korean PropBanking
guidelines have previously been published, lead-
ing to uncertainty in the initial stages of annota-
tion. These uncertainties were gradually resolved
through the iterative process of resolving inter-
annotator disagreements.
Table 1 shows the semantic roles considered in
our annotated corpus. Although these are based on
the general English PropBank guidelines (Bonial
et al., 2010), they also differ in that we used only
</bodyText>
<footnote confidence="0.999832">
1http://voice.etri.re.kr/db/db pop.asp?code=88
2http://catalog.ldc.upenn.edu/LDC2006T03
</footnote>
<table confidence="0.999600736842105">
Roles Definition Rate
ARG0 Agent 10.02%
ARG1 Patient 26.73%
ARG2 Start point / 5.18%
Benefactive
ARG3 Ending point 1.10%
ARGM-ADV Adverbial 1.26%
ARGM-CAU Cause 1.17%
ARGM-CND Condition 0.36%
ARGM-DIR Direction 0.35%
ARGM-DIS Discourse 28.71%
ARGM-EXT Extent 4.50%
ARGM-INS Instrument 1.04%
ARGM-LOC Locative 4.51%
ARGM-MNR Manner 8.72%
ARGM-NEG Negation 0.26%
ARGM-PRD Predication 0.27%
ARGM-PRP Purpose 0.77%
ARGM-TMP Temporal 5.05%
</table>
<tableCaption confidence="0.999904">
Table 1: Semantic roles in our annotated corpus.
</tableCaption>
<bodyText confidence="0.9988305">
4 numbered arguments from ARG0 to ARG3 in-
stead of 5 numbered arguments. We thus consider
17 semantic roles in total. Four of them are num-
bered roles, describing the essential arguments of
a predicate. The other roles are called modifier
roles that play more of an adjunct role.
We have annotated semantic roles by following
the PropBank annotation guideline (Bonial et al.,
2010) and by using frame files of the Penn Korean
PropBank built by Palmer et al. (2006). The Prop-
Bank and our corpus are not exactly compatible,
because the former is built on constituency-based
parse trees, whereas our corpus uses dependency
parses.
More importantly, the tagsets of these corpora
are not fully compatible. The PKPB uses much
coarser morpho-syntactic tags than the ETRI
corpus. For example, the PCA tag in PKPB used
for a case suffix covers four different functioning
tags used in our corpus. Using coarser suffix
tags can seriously degrade SRL performance, as
we show in Section 6, where we compare the
performance of our model on both the new corpus
and the older PKPB.
</bodyText>
<page confidence="0.99771">
638
</page>
<sectionHeader confidence="0.997364" genericHeader="method">
3 Previous Work
</sectionHeader>
<bodyText confidence="0.9999765625">
Korean SRL research has been limited to domesti-
cally published Korean research on small corpora.
Therefore, the most direct precedent to the present
work is a section in Bj¨orkelund et al. (2009) on
Japanese SRL. They build a classifier consisting
of 3 stages: predicate disambiguation, argument
identification, and argument classification.
They use an L2-regularized linear logistic re-
gression model cascaded through these three
stages, achieving F1-score of 80.80% on average
for 7 languages (Catalan, Chinese, Czech, English,
German, Japanese and Spanish). The lowest re-
ported performance is for Japanese, the only ag-
glutinative language in their data set, achieving
F1-score of 76.30%. This result showcases the
computational difficulty of dealing with morpho-
logically rich agglutinative languages. As we dis-
cuss in Section 5, we utilize these same features,
but also add a set of Korean-specific features to
capture aspects of Korean morphology.
Besides these morphological features, we also
employ latent continuous and discrete morpheme
representations induced from a larger body of
unannotated Korean text. As our experiments be-
low show, these features improve performance by
dealing with sparsity issues. Such features have
been useful in a variety of English NLP mod-
els, including chunking, named entity recogni-
tion (Turian et al., 2010), and spoken language un-
derstanding (Anastasakos et al., 2014). Unlike the
English models, we use individual morphemes as
our unit of analysis.
</bodyText>
<sectionHeader confidence="0.997848" genericHeader="method">
4 Model
</sectionHeader>
<bodyText confidence="0.999753611111111">
For the semantic role task, the input is a sentence
consisting of a sequence of words x = x1, ... , xn
and the output is a sequence of corresponding se-
mantic tags y = y1, ... , yn. Each word con-
sists of a stem and some number of suffix mor-
phemes, and the semantic tags are drawn from the
set {NONE, ARGo, ... , ARGM-TMP}. We model
the conditional probability p(y|x) using a CRF
model:
that identify the tag bigram (yi−1, yi), and emis-
sion features that combine the current semantic tag
(yi) with instantiated feature templates extracted
from the sentence x and its underlying morpho-
logical and dependency analysis. The function
Z is the normalizing function, which ensures that
p(y|x) is a valid probability distribution. We used
100 iteration of averaged perceptron algorithm to
train the CRF.
</bodyText>
<sectionHeader confidence="0.999564" genericHeader="method">
5 Features
</sectionHeader>
<bodyText confidence="0.999933482758621">
We detail the feature templates used for our ex-
periments in Table 2. These features are catego-
rized as either general features, Korean-specific
features, or latent morpheme representation fea-
tures. Korean-specific features are built upon the
morphological analysis of the suffix agglutination
of the current word xi.
Korean suffixes are traditionally classified into
two groups called Josa and Eomi. Josa is used
to define nominal cases and modify other phrases,
while Eomi is an ending of a verb or an adjective
to define a tense, show an attitude, and connect
or terminate a sentence. Thus, the Eomi and Josa
categorization plays an important role in signaling
semantic roles. Considering the functions of Josa
and Eomi, we expect that numbered roles are rele-
vant to Josa while modifier roles are more closely
related to Eomi. The one exception is adverbial
Josa, making the attached phrase an adverb that
modifies a verb predicate.
For all feature templates, “A-” or “P-” are used
respectively to signify that the feature corresponds
to the argument in question (xi), or rather is de-
rived from the verbal predicate that the argument
depends on.
General features: We use and modify 18 fea-
tures used for Japanese from the prior work of
Bj¨orkelund et al. (2009), excluding SENSE, PO-
SITION, and re-ranker features.
</bodyText>
<listItem confidence="0.984552">
• Stem: a stem without any attachment. For
instance, the first word Poleun at the Figure 1
consists of a stem Pol plus Josa eun.
</listItem>
<bodyText confidence="0.9433484">
Z(x)−1 �x �exp Amfm(yi−1, yi, x, i), • POS Lv1: the first level (coarse classifi-
i=1 m cation) of a POS tag such as noun, verb,
adjective, or adverb.
where fm(yi−1, yi, x, i) are the feature functions.
These feature functions include transition features
</bodyText>
<page confidence="0.998046">
639
</page>
<table confidence="0.999680793103448">
Feature Description
A-Stem, P-Stem Stem of an argument and a predicate
A-POS Lv1, P-POS Lv1 Coarse-grained POS of A-Stem and P-Stem
A-POS Lv2, P-POS Lv2 Fine-grained POS of A-Stem and P-Stem
A-Case, P-Case Case of A-Stem and P-Stem
A-LeftmostChildStem Stem of the leftmost child of an argument
A-LeftSiblingStem Stem of the left sibling of an argument
A-LeftSiblingPOS Lv1 Coarse-grained POS of A-LeftSiblingStem
A-LeftSiblingPOS Lv2 Fine-grained POS of A-LeftSiblingStem
A-RightSiblingPOS Lv1 Coarse-grained POS of a stem of the right sibling of an argument
A-RightSiblingPOS Lv2 Fine-grained POS of a stem of the right sibling of an argument
P-ParentStem Stem of a parent of a predicate
P-ChildStemSet Set of stems of children of a predicate
P-ChildPOSSet Lv1 Set of coarse POS of P-ChildStemSet
P-ChildCaseSet Set of cases of P-childStemSet
A-JosaExist If 1, Josa exists in an argument, otherwise 0.
A-JosaClass Linguistic classification of Josa
A-JosaLength Number of morphemes consisting of Josa
A-JosaMorphemes Each morpheme consisting of Josa
A-JosaIdenity Josa of an argument
A-EomiExist If 1, Eomi exists in an argument, otherwise 0.
A-EomiClass Lv1 Linguistic classification of Eomi
A-EomiClass Lv2 Another linguistic classification of Eomi
A-EomiLength Number of morphemes consisting of Eomi
A-EomiMorphemes Each morpheme consisting of Eomi
A-EomiIdentity Eomi of an argument
A-StemRepr Stem representation of an argument
A-JosaRepr Josa representation of an argument
A-EomiRepr Eomi representation of an argument
</table>
<tableCaption confidence="0.945595">
Table 2: Features used in our SRL experiments. Features are grouped as General, Korean-specific, or
</tableCaption>
<listItem confidence="0.981599375">
Latent Morpheme Representations. For the last group, we employ three different methods to build them:
(i) CCA, (ii) deep learning, and (iii) Brown clustering.
• POS Lv2: the second level (fine classifica-
tion) of a POS tag. If POS Lv1 is noun, ei-
ther a proper noun, common noun, or other
kinds of nouns is the POS Lv2.
• Case: the case type such as SBJ, OBJ, or
COMP.
</listItem>
<bodyText confidence="0.802685666666667">
The above features are also applied to some depen-
dency children, parents, and siblings of arguments
as shown in Table 2.
</bodyText>
<listItem confidence="0.9594985625">
Korean-specific features: We have 11 different
kinds of features for the Josa (5) and Eomi (6). We
highlight several below:
• A-JosaExist: an indicator feature checking
any Josa whether or not exists in an argument.
It is set to 1 if any Josa exists, otherwise 0.
• A-JosaClass: the linguistic classification of
Josa with a total of 8 classes. These classes
are adverbial, auxiliary, complemental, con-
nective, determinative, objective, subjective,
and vocative.
• A-JosaLength: the number of morphemes
consisting of Josa. At most five morphemes
are combined to consist of one Josa in our
data set.
• A-JosaMorphemes: Each morpheme com-
posing the Josa.
• A-JosaIdentity: The Josa itself.
• A-EomiClass Lv1: the linguistic classifica-
tion of Eomi with a total of 14 classes. These
14 classes are adverbial, determinative, coor-
dinate, exclamatory, future tense, honorific,
imperative, interrogative, modesty, nominal,
normal, past tense, petitionary, and subordi-
nate.
• A-EomiClass Lv2: Another linguistic classi-
fication of Eomi with a total of 4 classes. The
four classes are closing, connection, prefinal,
and transmutation. The EomiClass Lv1 and
Lv2 are combined to display the characteris-
tic of Eomi such as ‘Nominal Transmutation
Eomi’, but not all combinations are possible.
</listItem>
<page confidence="0.988633">
640
</page>
<table confidence="0.9922962">
Corpus Gen Gen+Kor Gen+Kor+LMR
CCA Deep Brown All
PKPB 64.83% 75.17% 75.51% 75.43% 75.55% 75.54%
Our annotated corpus 66.88% 80.33% 80.88% 80.84% 80.77% 81.07%
PKPB + our annotated corpus 64.86% 78.61% 79.32% 79.44% 78.91% 79.20%
</table>
<tableCaption confidence="0.9974045">
Table 3: Experimental F1-score results on every experiment. Abbreviation on features are Gen: general
features, Kor: Korean specific features, LMR: latent morpheme representation features.
</tableCaption>
<bodyText confidence="0.995456928571429">
Latent morpheme representation features: To
alleviate the sparsity, a lingering problem in NLP,
we employ three kinds of latent morpheme repre-
sentations induced from a larger body of unsuper-
vised text data. These are (i) linear continuous rep-
resentation through Canonical Correlation Analy-
sis (Dhillon et al., 2012), (ii) non-linear contin-
uous representation through Deep learning (Col-
lobert and Weston, 2008), and (iii) discrete rep-
resentation through Brown Clustering (Tatu and
Moldovan, 2005).
The first two representations are 50 dimensional
continuous vectors for each morpheme, and the
latter is a set of 256 clusters over morphemes.
</bodyText>
<sectionHeader confidence="0.993466" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<bodyText confidence="0.9878539">
We categorized our experiments by the scenarios
below, and all results are summarized in Table 3.
The F1-score results were investigated for each
scenario. We randomly divided our data into 90%
training and 10% test sets for all scenarios.
For latent morpheme representations, we used
the Donga news article corpus.3 The Donga cor-
pus contains 366,636 sentences with 25.09 words
on average. The Domain of this corpus cov-
ers typical news articles such as health, entertain-
ment, technology, politics, world and others. We
ran Kokoma Korean morpheme analyzer4 on each
sentence of the Donga corpus to divide words into
morphemes to build latent morpheme representa-
tions.
1st Scenario: We first tested on general features
in previous work (2nd column in Table 3). We
achieved 64.83% and 66.88% on the PKPB and
our corpus. When the both corpora were com-
bined, we had 64.86%.
</bodyText>
<footnote confidence="0.98408375">
2nd Scenario: We then added the Korean-
specific morphological features to signify its ap-
3http://www.donga.com
4http://kkma.snu.ac.kr/
</footnote>
<bodyText confidence="0.994694684210526">
propriateness in this scenario. These features in-
creased greatly performance improvements (3rd
column in Table 3). Although both the PKPB
and our corpus had improvements, the improve-
ments were the most notable on our corpus. This
is because PKPB POS tags might be too coarse.
We achieved 75.17%, 80.33%, and 78.61% on the
PKPB, our corpus, and the combined one, respec-
tively.
3rd Scenario: This scenario is to reveal the ef-
fects of the different latent morpheme represen-
tations (4-6th columns in Table 3). These three
representations are from CCA, deep learning, and
Brown clustering. The results gave evidences that
all representations increased the performance.
4th Scenario: We augmented our model with all
kinds of features (the last column in Table 3). We
achieved our best F1-score of 81.07% over all sce-
narios on our corpus.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999866636363636">
For Korean SRL, we semantically annotated a
corpus containing detailed morphological annota-
tion. We then developed a supervised model which
leverages Korean-specific features and a variety
of latent morpheme representations to help deal
with a sparsity problem. Our best model achieved
81.07% in F1-score. In the future, we will con-
tinue to build our corpus and look for the way to
use unsupervised learning for SRL to apply to an-
other language which does not have available cor-
pus.
</bodyText>
<sectionHeader confidence="0.998295" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999272666666667">
We thank Na-Rae Han and Asli Celikyilmaz for
helpful discussion and feedback. This research
was supported by the Basic Science Research Pro-
gram of the Korean National Research Foundation
(NRF), and funded by the Korean Ministry of Ed-
ucation, Science and Technology (2010-0010612).
</bodyText>
<page confidence="0.99816">
641
</page>
<sectionHeader confidence="0.98966" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999007130000001">
Tasos Anastasakos, Young-Bum Kim, and Anoop Deo-
ras. 2014. Task specific continuous word represen-
tations for mono and multi-lingual spoken language
understanding. In Proceedings of the IEEE Interna-
tional Conference on Acoustics, Speech, and Signal
Processing (ICASSP).
Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual semantic role labeling. In Pro-
ceedings of the Thirteenth Conference on Compu-
tational Natural Language Learning: Shared Task,
pages 43–48. Association for Computational Lin-
guistics.
Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora
Hladk´a. 2003. The prague dependency treebank. In
Treebanks, pages 103–127. Springer.
Claire Bonial, Olga Babko-Malaya, Jinho D Choi, Jena
Hwang, and Martha Palmer. 2010. Propbank an-
notation guidelines. Center for Computational Lan-
guage and Education Research, CU-Boulder.
Aljoscha Burchardt, Nils Reiter, Stefan Thater, and
Anette Frank. 2007. A semantic approach to tex-
tual entailment: system evaluation and task analy-
sis. In Proceedings of the ACL-PASCAL Workshop
on Textual Entailment and Paraphrasing, RTE ’07,
pages 10–15, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Ronan Collobert and Jason Weston. 2008. A unified
architecture for natural language processing: Deep
neural networks with multitask learning. In Pro-
ceedings of the 25th international conference on
Machine learning, pages 160–167. ACM.
Paramveer Dhillon, Jordan Rodu, Dean Foster, and
Lyle Ungar. 2012. Two step cca: A new spec-
tral method for estimating vector models of words.
arXiv preprint arXiv:1206.6403.
Anette Frank, Hans-Ulrich Krieger, Feiyu Xu, Hans
Uszkoreit, Berthold Crysmann, Brigitte J¨org, and
Ulrich Sch¨afer. 2007. Question answering from
structured knowledge sources. Journal of Applied
Logic, 5(1):20 – 48. Questions and Answers: Theo-
retical and Applied Perspectives.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational linguis-
tics, 28(3):245–288.
Andrew B Goldberg, Xiaojin Zhu, Charles R Dyer,
Mohamed Eldawy, and Lijie Heng. 2008. Easy
as abc?: facilitating pictorial communication via
semantically enhanced layout. In Proceedings of
the Twelfth Conference on Computational Natural
Language Learning, pages 119–126. Association for
Computational Linguistics.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Martf, Llufs
M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, et al. 2009. The conll-2009
shared task: Syntactic and semantic dependencies
in multiple languages. In Proceedings of the Thir-
teenth Conference on Computational Natural Lan-
guage Learning: Shared Task, pages 1–18. Associa-
tion for Computational Linguistics.
Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti
Hasida. 2002. Construction of a japanese relevance-
tagged corpus. In LREC.
John Lafferty, Andrew McCallum, and Fernando CN
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data.
Srini Narayanan and Sanda Harabagiu. 2004. Ques-
tion answering based on semantic structures. In
Proceedings of the 20th international conference on
Computational Linguistics, COLING ’04, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Martha Palmer, Shijong Ryu, Jinyoung Choi, Sinwon
Yoon, and Yeongmi Jeon. 2006. Korean propbank.
Linguistic data consortium.
Hye-Jeong Song, Chan-Young Park, Jung-Kuk Lee,
Min-Ji Lee, Yoon-Jeong Lee, Jong-Dae Kim, and
Yu-Seop Kim. 2012. Construction of korean se-
mantic annotated corpus. In Computer Applications
for Database, Education, and Ubiquitous Comput-
ing, pages 265–271. Springer.
Marta Tatu and Dan Moldovan. 2005. A seman-
tic approach to recognizing textual entailment. In
Proceedings of the conference on Human Language
Technology and Empirical Methods in Natural Lan-
guage Processing, pages 371–378. Association for
Computational Linguistics.
Mariona Taul´e, Maria Ant`onia Martf, and Marta Re-
casens. 2008. Ancora: Multilevel annotated corpora
for catalan and spanish. In LREC.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method
for semi-supervised learning. In Proceedings of the
48th Annual Meeting of the Association for Compu-
tational Linguistics, pages 384–394. Association for
Computational Linguistics.
Nianwen Xue and Martha Palmer. 2009. Adding se-
mantic roles to the chinese treebank. Natural Lan-
guage Engineering, 15(01):143–172.
</reference>
<page confidence="0.998003">
642
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.531489">
<title confidence="0.999953">Training a Korean SRL System with Rich Morphological Features</title>
<author confidence="0.991511">Young-Bum Kim</author>
<author confidence="0.991511">Heemoon Chae</author>
<author confidence="0.991511">Benjamin Snyder</author>
<author confidence="0.991511">Yu-Seop</author>
<affiliation confidence="0.999904">University of Wisconsin-Madison, Hallym University*</affiliation>
<address confidence="0.554627">hmchae21, yskim01@hallym.ac.kr*</address>
<abstract confidence="0.998010388888889">In this paper we introduce a semantic role labeler for Korean, an agglutinative language with rich morphology. First, we create a novel training source by semantically annotating a Korean corpus containing fine-grained morphological and syntactic information. We then develop a supervised SRL model by leveraging morphological features of Korean that tend to correspond with semantic roles. Our model also employs a variety of latent morpheme representations induced from a larger body of unannotated Korean text. These elements lead to state-of-the-art performance of 81.07% labeled F1, representing the best SRL performance reported to date for an agglutinative language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Tasos Anastasakos</author>
<author>Young-Bum Kim</author>
<author>Anoop Deoras</author>
</authors>
<title>Task specific continuous word representations for mono and multi-lingual spoken language understanding.</title>
<date>2014</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</booktitle>
<contexts>
<context position="9143" citStr="Anastasakos et al., 2014" startWordPosition="1384" endWordPosition="1387">inative languages. As we discuss in Section 5, we utilize these same features, but also add a set of Korean-specific features to capture aspects of Korean morphology. Besides these morphological features, we also employ latent continuous and discrete morpheme representations induced from a larger body of unannotated Korean text. As our experiments below show, these features improve performance by dealing with sparsity issues. Such features have been useful in a variety of English NLP models, including chunking, named entity recognition (Turian et al., 2010), and spoken language understanding (Anastasakos et al., 2014). Unlike the English models, we use individual morphemes as our unit of analysis. 4 Model For the semantic role task, the input is a sentence consisting of a sequence of words x = x1, ... , xn and the output is a sequence of corresponding semantic tags y = y1, ... , yn. Each word consists of a stem and some number of suffix morphemes, and the semantic tags are drawn from the set {NONE, ARGo, ... , ARGM-TMP}. We model the conditional probability p(y|x) using a CRF model: that identify the tag bigram (yi−1, yi), and emission features that combine the current semantic tag (yi) with instantiated f</context>
</contexts>
<marker>Anastasakos, Kim, Deoras, 2014</marker>
<rawString>Tasos Anastasakos, Young-Bum Kim, and Anoop Deoras. 2014. Task specific continuous word representations for mono and multi-lingual spoken language understanding. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual semantic role labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>43--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual semantic role labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 43–48. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alena B¨ohmov´a</author>
<author>Jan Hajiˇc</author>
<author>Eva Hajiˇcov´a</author>
<author>Barbora Hladk´a</author>
</authors>
<title>The prague dependency treebank. In Treebanks,</title>
<date>2003</date>
<pages>103--127</pages>
<publisher>Springer.</publisher>
<marker>B¨ohmov´a, Hajiˇc, Hajiˇcov´a, Hladk´a, 2003</marker>
<rawString>Alena B¨ohmov´a, Jan Hajiˇc, Eva Hajiˇcov´a, and Barbora Hladk´a. 2003. The prague dependency treebank. In Treebanks, pages 103–127. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Bonial</author>
<author>Olga Babko-Malaya</author>
<author>Jinho D Choi</author>
<author>Jena Hwang</author>
<author>Martha Palmer</author>
</authors>
<date>2010</date>
<booktitle>Propbank annotation guidelines. Center for Computational Language and Education Research, CU-Boulder.</booktitle>
<contexts>
<context position="4314" citStr="Bonial et al., 2010" startWordPosition="644" endWordPosition="647">ing of the Association for Computational Linguistics (Short Papers), pages 637–642, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 A Semantically Annotated Korean Corpus We annotated predicate-argument structure of verbs in a corpus from the Electronics and Telecommunications Research Institute of Korea (ETRI).1 Our corpus was developed over two years using a specialized annotation tool (Song et al., 2012), resulting in more than 8,000 semantically annotated sentences. As much as possible, annotations followed the PropBank guidelines for English (Bonial et al., 2010). We view our work as building on the efforts of the Penn Korean PropBank (PKPB).2 Our corpus is roughly similar in size to the PKPB, and taken together, the two Korean corpora now total about half the size of the Penn English PropBank. One advantage of our corpus is that it is built on top of the ETRI Korean corpus, which uses a richer Korean morphological tagging scheme than the Penn Korean Treebank. Our experiments will show that these finer-grained tags are crucial for achieving high SRL accuracy. All annotations were performed by two people working in a team. At first, each annotator assi</context>
<context position="6038" citStr="Bonial et al., 2010" startWordPosition="912" endWordPosition="915">age. We encountered two major difficulties during annotation. First, the existing Korean frame files from the Penn Korean PropBank include 2,749 verbs, covering only 13.87% of all the verbs in the ETRI corpus. Secondly, no Korean PropBanking guidelines have previously been published, leading to uncertainty in the initial stages of annotation. These uncertainties were gradually resolved through the iterative process of resolving interannotator disagreements. Table 1 shows the semantic roles considered in our annotated corpus. Although these are based on the general English PropBank guidelines (Bonial et al., 2010), they also differ in that we used only 1http://voice.etri.re.kr/db/db pop.asp?code=88 2http://catalog.ldc.upenn.edu/LDC2006T03 Roles Definition Rate ARG0 Agent 10.02% ARG1 Patient 26.73% ARG2 Start point / 5.18% Benefactive ARG3 Ending point 1.10% ARGM-ADV Adverbial 1.26% ARGM-CAU Cause 1.17% ARGM-CND Condition 0.36% ARGM-DIR Direction 0.35% ARGM-DIS Discourse 28.71% ARGM-EXT Extent 4.50% ARGM-INS Instrument 1.04% ARGM-LOC Locative 4.51% ARGM-MNR Manner 8.72% ARGM-NEG Negation 0.26% ARGM-PRD Predication 0.27% ARGM-PRP Purpose 0.77% ARGM-TMP Temporal 5.05% Table 1: Semantic roles in our annota</context>
</contexts>
<marker>Bonial, Babko-Malaya, Choi, Hwang, Palmer, 2010</marker>
<rawString>Claire Bonial, Olga Babko-Malaya, Jinho D Choi, Jena Hwang, and Martha Palmer. 2010. Propbank annotation guidelines. Center for Computational Language and Education Research, CU-Boulder.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aljoscha Burchardt</author>
<author>Nils Reiter</author>
<author>Stefan Thater</author>
<author>Anette Frank</author>
</authors>
<title>A semantic approach to textual entailment: system evaluation and task analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, RTE ’07,</booktitle>
<pages>10--15</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1395" citStr="Burchardt et al., 2007" startWordPosition="198" endWordPosition="201">nts lead to state-of-the-art performance of 81.07% labeled F1, representing the best SRL performance reported to date for an agglutinative language. 1 Introduction Semantic Role Labeling (SRL) is the task of automatically annotating the predicate-argument structure in a sentence with semantic roles. Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al., 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al., 2007) and pictorial communication systems (Goldberg et al., 2008). SRL systems in many languages have been developed as the necessary linguistic resources become available (Taul´e et al., 2008; Xue and Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et al., 2002). Seven languages were the subject of the CoNLL-2009 shared task in syntactic and semantic parsing (Hajiˇc et al., 2009). These languages can be categorized into three broad morphological types: fusional (4), analytic (2), and one agglutinative language. Paul studies mathematics with Jane at a library Poleun doseogwaneseo Jeingwa suhageull g</context>
</contexts>
<marker>Burchardt, Reiter, Thater, Frank, 2007</marker>
<rawString>Aljoscha Burchardt, Nils Reiter, Stefan Thater, and Anette Frank. 2007. A semantic approach to textual entailment: system evaluation and task analysis. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, RTE ’07, pages 10–15, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: Deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th international conference on Machine learning,</booktitle>
<pages>160--167</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15961" citStr="Collobert and Weston, 2008" startWordPosition="2466" endWordPosition="2470"> 79.32% 79.44% 78.91% 79.20% Table 3: Experimental F1-score results on every experiment. Abbreviation on features are Gen: general features, Kor: Korean specific features, LMR: latent morpheme representation features. Latent morpheme representation features: To alleviate the sparsity, a lingering problem in NLP, we employ three kinds of latent morpheme representations induced from a larger body of unsupervised text data. These are (i) linear continuous representation through Canonical Correlation Analysis (Dhillon et al., 2012), (ii) non-linear continuous representation through Deep learning (Collobert and Weston, 2008), and (iii) discrete representation through Brown Clustering (Tatu and Moldovan, 2005). The first two representations are 50 dimensional continuous vectors for each morpheme, and the latter is a set of 256 clusters over morphemes. 6 Experiments and Results We categorized our experiments by the scenarios below, and all results are summarized in Table 3. The F1-score results were investigated for each scenario. We randomly divided our data into 90% training and 10% test sets for all scenarios. For latent morpheme representations, we used the Donga news article corpus.3 The Donga corpus contains </context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: Deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160–167. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramveer Dhillon</author>
<author>Jordan Rodu</author>
<author>Dean Foster</author>
<author>Lyle Ungar</author>
</authors>
<title>Two step cca: A new spectral method for estimating vector models of words. arXiv preprint arXiv:1206.6403.</title>
<date>2012</date>
<contexts>
<context position="15867" citStr="Dhillon et al., 2012" startWordPosition="2454" endWordPosition="2457">rpus 66.88% 80.33% 80.88% 80.84% 80.77% 81.07% PKPB + our annotated corpus 64.86% 78.61% 79.32% 79.44% 78.91% 79.20% Table 3: Experimental F1-score results on every experiment. Abbreviation on features are Gen: general features, Kor: Korean specific features, LMR: latent morpheme representation features. Latent morpheme representation features: To alleviate the sparsity, a lingering problem in NLP, we employ three kinds of latent morpheme representations induced from a larger body of unsupervised text data. These are (i) linear continuous representation through Canonical Correlation Analysis (Dhillon et al., 2012), (ii) non-linear continuous representation through Deep learning (Collobert and Weston, 2008), and (iii) discrete representation through Brown Clustering (Tatu and Moldovan, 2005). The first two representations are 50 dimensional continuous vectors for each morpheme, and the latter is a set of 256 clusters over morphemes. 6 Experiments and Results We categorized our experiments by the scenarios below, and all results are summarized in Table 3. The F1-score results were investigated for each scenario. We randomly divided our data into 90% training and 10% test sets for all scenarios. For laten</context>
</contexts>
<marker>Dhillon, Rodu, Foster, Ungar, 2012</marker>
<rawString>Paramveer Dhillon, Jordan Rodu, Dean Foster, and Lyle Ungar. 2012. Two step cca: A new spectral method for estimating vector models of words. arXiv preprint arXiv:1206.6403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Frank</author>
<author>Hans-Ulrich Krieger</author>
<author>Feiyu Xu</author>
<author>Hans Uszkoreit</author>
<author>Berthold Crysmann</author>
<author>Brigitte J¨org</author>
<author>Ulrich Sch¨afer</author>
</authors>
<title>Question answering from structured knowledge sources.</title>
<date>2007</date>
<journal>Journal of Applied Logic,</journal>
<volume>5</volume>
<issue>1</issue>
<marker>Frank, Krieger, Xu, Uszkoreit, Crysmann, J¨org, Sch¨afer, 2007</marker>
<rawString>Anette Frank, Hans-Ulrich Krieger, Feiyu Xu, Hans Uszkoreit, Berthold Crysmann, Brigitte J¨org, and Ulrich Sch¨afer. 2007. Question answering from structured knowledge sources. Journal of Applied Logic, 5(1):20 – 48. Questions and Answers: Theoretical and Applied Perspectives.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational linguistics,</journal>
<pages>28--3</pages>
<contexts>
<context position="1110" citStr="Gildea and Jurafsky (2002)" startWordPosition="158" endWordPosition="161">syntactic information. We then develop a supervised SRL model by leveraging morphological features of Korean that tend to correspond with semantic roles. Our model also employs a variety of latent morpheme representations induced from a larger body of unannotated Korean text. These elements lead to state-of-the-art performance of 81.07% labeled F1, representing the best SRL performance reported to date for an agglutinative language. 1 Introduction Semantic Role Labeling (SRL) is the task of automatically annotating the predicate-argument structure in a sentence with semantic roles. Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al., 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al., 2007) and pictorial communication systems (Goldberg et al., 2008). SRL systems in many languages have been developed as the necessary linguistic resources become available (Taul´e et al., 2008; Xue and Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et al., 2002). Seven languages were the subject of the CoNLL-2009 share</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew B Goldberg</author>
<author>Xiaojin Zhu</author>
<author>Charles R Dyer</author>
<author>Mohamed Eldawy</author>
<author>Lijie Heng</author>
</authors>
<title>Easy as abc?: facilitating pictorial communication via semantically enhanced layout.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>119--126</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1455" citStr="Goldberg et al., 2008" startWordPosition="207" endWordPosition="210">, representing the best SRL performance reported to date for an agglutinative language. 1 Introduction Semantic Role Labeling (SRL) is the task of automatically annotating the predicate-argument structure in a sentence with semantic roles. Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al., 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al., 2007) and pictorial communication systems (Goldberg et al., 2008). SRL systems in many languages have been developed as the necessary linguistic resources become available (Taul´e et al., 2008; Xue and Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et al., 2002). Seven languages were the subject of the CoNLL-2009 shared task in syntactic and semantic parsing (Hajiˇc et al., 2009). These languages can be categorized into three broad morphological types: fusional (4), analytic (2), and one agglutinative language. Paul studies mathematics with Jane at a library Poleun doseogwaneseo Jeingwa suhageull gongbuhanda Figure 1: English (SVO) and Korean (SOV) words al</context>
</contexts>
<marker>Goldberg, Zhu, Dyer, Eldawy, Heng, 2008</marker>
<rawString>Andrew B Goldberg, Xiaojin Zhu, Charles R Dyer, Mohamed Eldawy, and Lijie Heng. 2008. Easy as abc?: facilitating pictorial communication via semantically enhanced layout. In Proceedings of the Twelfth Conference on Computational Natural Language Learning, pages 119–126. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
</authors>
<location>Daisuke Kawahara, Maria Ant`onia Martf, Llufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian</location>
<marker>Hajiˇc, Ciaramita, Johansson, </marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Martf, Llufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan ˇStˇep´anek Pad´o</author>
</authors>
<title>The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>1--18</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Pad´o, 2009</marker>
<rawString>Pad´o, Jan ˇStˇep´anek, et al. 2009. The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task, pages 1–18. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
<author>Kˆoiti Hasida</author>
</authors>
<title>Construction of a japanese relevancetagged corpus.</title>
<date>2002</date>
<booktitle>In LREC.</booktitle>
<contexts>
<context position="1652" citStr="Kawahara et al., 2002" startWordPosition="238" endWordPosition="241">ructure in a sentence with semantic roles. Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al., 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al., 2007) and pictorial communication systems (Goldberg et al., 2008). SRL systems in many languages have been developed as the necessary linguistic resources become available (Taul´e et al., 2008; Xue and Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et al., 2002). Seven languages were the subject of the CoNLL-2009 shared task in syntactic and semantic parsing (Hajiˇc et al., 2009). These languages can be categorized into three broad morphological types: fusional (4), analytic (2), and one agglutinative language. Paul studies mathematics with Jane at a library Poleun doseogwaneseo Jeingwa suhageull gongbuhanda Figure 1: English (SVO) and Korean (SOV) words alignment. The subject, verb, and object are highlighted as red, blue, and green, respectively. Also, prepositions and suffixes are highlighted as purple. Bj¨orkelund et al. (2009) report an average </context>
</contexts>
<marker>Kawahara, Kurohashi, Hasida, 2002</marker>
<rawString>Daisuke Kawahara, Sadao Kurohashi, and Kˆoiti Hasida. 2002. Construction of a japanese relevancetagged corpus. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando CN Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<contexts>
<context position="3302" citStr="Lafferty et al., 2001" startWordPosition="492" endWordPosition="495">paper, we describe a Korean SRL system which achieves 81% labeled semantic F1-score. As far as we know, this is the highest accuracy obtained for Korean, as well as any agglutinative language. Figure 1 displays a English/Korean sentence pair, highlighting the SOV word order of Korean as well as its rich morphological structure. Two factors proved crucial in the performance of our SRL system: (i) The analysis of fine-grained morphological tags specific to Korean, and (ii) the use of latent stem and morpheme representations to deal with sparsity. We incorporated both of these elements in a CRF (Lafferty et al., 2001) role labeling model. Besides the contribution of this model and SRL system, we also report on the creation and availability of a new semantically annotated Korean corpus, covering over 8,000 sentences. We used this corpus to develop, train, and test our Korean SRL model. In the next section, we describe the process of corpus creation in more detail. 637 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 637–642, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 A Semantically Annotated Korea</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando CN Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Question answering based on semantic structures.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1318" citStr="Narayanan and Harabagiu, 2004" startWordPosition="188" endWordPosition="191">e representations induced from a larger body of unannotated Korean text. These elements lead to state-of-the-art performance of 81.07% labeled F1, representing the best SRL performance reported to date for an agglutinative language. 1 Introduction Semantic Role Labeling (SRL) is the task of automatically annotating the predicate-argument structure in a sentence with semantic roles. Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al., 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al., 2007) and pictorial communication systems (Goldberg et al., 2008). SRL systems in many languages have been developed as the necessary linguistic resources become available (Taul´e et al., 2008; Xue and Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et al., 2002). Seven languages were the subject of the CoNLL-2009 shared task in syntactic and semantic parsing (Hajiˇc et al., 2009). These languages can be categorized into three broad morphological types: fusional (4), analytic (2), and one agglutinative language. Paul studie</context>
</contexts>
<marker>Narayanan, Harabagiu, 2004</marker>
<rawString>Srini Narayanan and Sanda Harabagiu. 2004. Question answering based on semantic structures. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Shijong Ryu</author>
<author>Jinyoung Choi</author>
<author>Sinwon Yoon</author>
<author>Yeongmi Jeon</author>
</authors>
<title>Korean propbank. Linguistic data consortium.</title>
<date>2006</date>
<contexts>
<context position="7112" citStr="Palmer et al. (2006)" startWordPosition="1069" endWordPosition="1072">nner 8.72% ARGM-NEG Negation 0.26% ARGM-PRD Predication 0.27% ARGM-PRP Purpose 0.77% ARGM-TMP Temporal 5.05% Table 1: Semantic roles in our annotated corpus. 4 numbered arguments from ARG0 to ARG3 instead of 5 numbered arguments. We thus consider 17 semantic roles in total. Four of them are numbered roles, describing the essential arguments of a predicate. The other roles are called modifier roles that play more of an adjunct role. We have annotated semantic roles by following the PropBank annotation guideline (Bonial et al., 2010) and by using frame files of the Penn Korean PropBank built by Palmer et al. (2006). The PropBank and our corpus are not exactly compatible, because the former is built on constituency-based parse trees, whereas our corpus uses dependency parses. More importantly, the tagsets of these corpora are not fully compatible. The PKPB uses much coarser morpho-syntactic tags than the ETRI corpus. For example, the PCA tag in PKPB used for a case suffix covers four different functioning tags used in our corpus. Using coarser suffix tags can seriously degrade SRL performance, as we show in Section 6, where we compare the performance of our model on both the new corpus and the older PKPB</context>
</contexts>
<marker>Palmer, Ryu, Choi, Yoon, Jeon, 2006</marker>
<rawString>Martha Palmer, Shijong Ryu, Jinyoung Choi, Sinwon Yoon, and Yeongmi Jeon. 2006. Korean propbank. Linguistic data consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hye-Jeong Song</author>
<author>Chan-Young Park</author>
<author>Jung-Kuk Lee</author>
<author>Min-Ji Lee</author>
<author>Yoon-Jeong Lee</author>
<author>Jong-Dae Kim</author>
<author>Yu-Seop Kim</author>
</authors>
<title>Construction of korean semantic annotated corpus.</title>
<date>2012</date>
<booktitle>In Computer Applications for Database, Education, and Ubiquitous Computing,</booktitle>
<pages>265--271</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4150" citStr="Song et al., 2012" startWordPosition="620" endWordPosition="623">lop, train, and test our Korean SRL model. In the next section, we describe the process of corpus creation in more detail. 637 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 637–642, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics 2 A Semantically Annotated Korean Corpus We annotated predicate-argument structure of verbs in a corpus from the Electronics and Telecommunications Research Institute of Korea (ETRI).1 Our corpus was developed over two years using a specialized annotation tool (Song et al., 2012), resulting in more than 8,000 semantically annotated sentences. As much as possible, annotations followed the PropBank guidelines for English (Bonial et al., 2010). We view our work as building on the efforts of the Penn Korean PropBank (PKPB).2 Our corpus is roughly similar in size to the PKPB, and taken together, the two Korean corpora now total about half the size of the Penn English PropBank. One advantage of our corpus is that it is built on top of the ETRI Korean corpus, which uses a richer Korean morphological tagging scheme than the Penn Korean Treebank. Our experiments will show that</context>
</contexts>
<marker>Song, Park, Lee, Lee, Lee, Kim, Kim, 2012</marker>
<rawString>Hye-Jeong Song, Chan-Young Park, Jung-Kuk Lee, Min-Ji Lee, Yoon-Jeong Lee, Jong-Dae Kim, and Yu-Seop Kim. 2012. Construction of korean semantic annotated corpus. In Computer Applications for Database, Education, and Ubiquitous Computing, pages 265–271. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Tatu</author>
<author>Dan Moldovan</author>
</authors>
<title>A semantic approach to recognizing textual entailment.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>371--378</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="16047" citStr="Tatu and Moldovan, 2005" startWordPosition="2479" endWordPosition="2482">Abbreviation on features are Gen: general features, Kor: Korean specific features, LMR: latent morpheme representation features. Latent morpheme representation features: To alleviate the sparsity, a lingering problem in NLP, we employ three kinds of latent morpheme representations induced from a larger body of unsupervised text data. These are (i) linear continuous representation through Canonical Correlation Analysis (Dhillon et al., 2012), (ii) non-linear continuous representation through Deep learning (Collobert and Weston, 2008), and (iii) discrete representation through Brown Clustering (Tatu and Moldovan, 2005). The first two representations are 50 dimensional continuous vectors for each morpheme, and the latter is a set of 256 clusters over morphemes. 6 Experiments and Results We categorized our experiments by the scenarios below, and all results are summarized in Table 3. The F1-score results were investigated for each scenario. We randomly divided our data into 90% training and 10% test sets for all scenarios. For latent morpheme representations, we used the Donga news article corpus.3 The Donga corpus contains 366,636 sentences with 25.09 words on average. The Domain of this corpus covers typica</context>
</contexts>
<marker>Tatu, Moldovan, 2005</marker>
<rawString>Marta Tatu and Dan Moldovan. 2005. A semantic approach to recognizing textual entailment. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 371–378. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mariona Taul´e</author>
<author>Maria Ant`onia Martf</author>
<author>Marta Recasens</author>
</authors>
<title>Ancora: Multilevel annotated corpora for catalan and spanish.</title>
<date>2008</date>
<booktitle>In LREC.</booktitle>
<marker>Taul´e, Martf, Recasens, 2008</marker>
<rawString>Mariona Taul´e, Maria Ant`onia Martf, and Marta Recasens. 2008. Ancora: Multilevel annotated corpora for catalan and spanish. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9081" citStr="Turian et al., 2010" startWordPosition="1375" endWordPosition="1378">al difficulty of dealing with morphologically rich agglutinative languages. As we discuss in Section 5, we utilize these same features, but also add a set of Korean-specific features to capture aspects of Korean morphology. Besides these morphological features, we also employ latent continuous and discrete morpheme representations induced from a larger body of unannotated Korean text. As our experiments below show, these features improve performance by dealing with sparsity issues. Such features have been useful in a variety of English NLP models, including chunking, named entity recognition (Turian et al., 2010), and spoken language understanding (Anastasakos et al., 2014). Unlike the English models, we use individual morphemes as our unit of analysis. 4 Model For the semantic role task, the input is a sentence consisting of a sequence of words x = x1, ... , xn and the output is a sequence of corresponding semantic tags y = y1, ... , yn. Each word consists of a stem and some number of suffix morphemes, and the semantic tags are drawn from the set {NONE, ARGo, ... , ARGM-TMP}. We model the conditional probability p(y|x) using a CRF model: that identify the tag bigram (yi−1, yi), and emission features </context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Martha Palmer</author>
</authors>
<title>Adding semantic roles to the chinese treebank.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>01</issue>
<contexts>
<context position="1604" citStr="Xue and Palmer, 2009" startWordPosition="230" endWordPosition="233">matically annotating the predicate-argument structure in a sentence with semantic roles. Ever since Gildea and Jurafsky (2002), SRL has become an important technology used in applications requiring semantic interpretation, ranging from information extraction (Frank et al., 2007) and question answering (Narayanan and Harabagiu, 2004), to practical problems including textual entailment (Burchardt et al., 2007) and pictorial communication systems (Goldberg et al., 2008). SRL systems in many languages have been developed as the necessary linguistic resources become available (Taul´e et al., 2008; Xue and Palmer, 2009; B¨ohmov´a et al., 2003; Kawahara et al., 2002). Seven languages were the subject of the CoNLL-2009 shared task in syntactic and semantic parsing (Hajiˇc et al., 2009). These languages can be categorized into three broad morphological types: fusional (4), analytic (2), and one agglutinative language. Paul studies mathematics with Jane at a library Poleun doseogwaneseo Jeingwa suhageull gongbuhanda Figure 1: English (SVO) and Korean (SOV) words alignment. The subject, verb, and object are highlighted as red, blue, and green, respectively. Also, prepositions and suffixes are highlighted as purp</context>
</contexts>
<marker>Xue, Palmer, 2009</marker>
<rawString>Nianwen Xue and Martha Palmer. 2009. Adding semantic roles to the chinese treebank. Natural Language Engineering, 15(01):143–172.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>