<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003647">
<title confidence="0.938885">
Principle-Based Parsing: Computation and Psycholinguistics
</title>
<author confidence="0.962622">
Robert C. Berwick, Steven P. Abney, and Carol Tenny, editors
</author>
<affiliation confidence="0.870133">
(MIT, Bell Communications Research, and University of Pittsburgh)
Dordrecht: Kluwer Academic
</affiliation>
<bodyText confidence="0.67005775">
Publishers (Studies in Linguistics and
Philosophy 44), 1991, vii + 408 pp.
Hardbound, ISBN 0-7923-1173-6, $89.00,
£58.00, Dfl 165.00
</bodyText>
<figure confidence="0.218445">
Reviewed by
Geoffrey K. Pullum
</figure>
<affiliation confidence="0.930278">
University of California, Santa Cruz
</affiliation>
<bodyText confidence="0.9822435">
This book is a collection of 13 essays on various aspects of parsing:
&amp;quot;Principles of principle-based parsing&amp;quot; (an introduction to the volume)
by Robert Berwick (pp. 1-37)
&amp;quot;Deductive parsing: The use of knowledge of language&amp;quot; by Mark
Johnson (39-64)
&amp;quot;The computational implementation of principle-based parsers&amp;quot; by
Sandiway Fong (65-82)
&amp;quot;Empty categories, chain binding, and parsing&amp;quot; by Nelson Correa
(83-121)
&amp;quot;Parsing Warlpiri—A free word order language&amp;quot; by Michael B. Kashket
(123-151)
&amp;quot;Principle-based parsing for machine translation&amp;quot; by Bonnie Jean Dorr
(153-183)
&amp;quot;Principle-based interpretation of natural language quantifiers&amp;quot; by
Samuel S. Epstein (185-198)
&amp;quot;Avoid the pedestrian&apos;s paradox&amp;quot; by Edward P. Stabler, Jr. (199-237)
&amp;quot;Parsing with changing grammars: Evaluating a language acquisition
model&amp;quot; by Rick Kazman (239-256)
&amp;quot;Parsing by chunks&amp;quot; by Steven P. Abney (257-278)
&amp;quot;Subcategorization and sentence processing&amp;quot; by Paul Gorrell (279-300)
&amp;quot;Subjacency in a principle-based parser&amp;quot; by Bradley L. Pritchett
(301-345)
&amp;quot;Locating wh-traces&amp;quot; by Howard S. Kurtzman, Loren F. Crawford, and
Caylee Nychis-Florence (347-382)
The essays are diverse; they run the gamut from overview-of-my-system term pa-
pers in computational linguistics (Fong&apos;s paper even includes screen dumps of Lisp
machine displays) to experimental papers in psycholinguistics (like the last three pa-
pers and Kazman&apos;s experimental acquisition study).
</bodyText>
<page confidence="0.99719">
393
</page>
<note confidence="0.365678">
Computational Linguistics Volume 19, Number 2
</note>
<bodyText confidence="0.999942549019608">
The &amp;quot;principle-based parsing&amp;quot; that all the essays are supposed to have in common
seems to be entirely a rhetorical construct. Insofar as there is clear and explicit work
on parsing in this book, it all looks suspiciously like plain old context-free parsing
(sometimes, in fact, clearly deterministic context-free). Where the essays are too vague
for this to be said of them, the only connecting theme seems to be a link to MIT-
originated linguistic concepts.
Robert Berwick&apos;s introduction opens in breathlessly self-congratulatory mode:
&amp;quot;This book chronicles the first stirrings of a revolution in the study of natural lan-
guage processing, language variation, and psycholinguistics—what some have called
principle-based parsing&amp;quot; (p. 1). But of course &amp;quot;principle-based parsing&amp;quot; (henceforth PBP)
is the slogan of Berwick&apos;s own group at MIT; it is highly disingenuous for him to im-
ply (with his &amp;quot;what some have called&amp;quot;) that it came from out there in the community
and he is going along with it. PBP is not only a brand name exclusive to Berwick
and his students, but also seems to have an exclusively sociological definition: the
preface of this book suggests that all those who were invited to give papers at the
MIT Parsing Project Lecture Series between 1987 and 1989 get the PBP rosette pinned
on their work no matter what its content, and nobody else does, no matter how much
they may build &amp;quot;principles&amp;quot; into their systems.
I cannot find any sign of an incipient revolution chronicled in this book; not even
the outline of a new position is visible. Berwick&apos;s claim is that once upon a time
people used to use &amp;quot;thousands of individual, language-particular, and construction-
specific rules&amp;quot; when writing grammars or parsers, and PBP &amp;quot;replaces this standard
paradigm with another world view&apos; under which a small number of general &amp;quot;prin-
ciples&amp;quot; do the work. These principles turn out to be vaguely stated generalizations
from Government–Binding (GB) syntax, of course (to a large extent, PBP practitioners
seem to be just GB linguists with Lisp machines). Some of the &amp;quot;principles&amp;quot; are close
to vacuous, e.g., &amp;quot;verb phrases in sentences must either begin with a verb ... or end
with a verb&amp;quot; (trivially true given the Bloomfieldian doctrine that all branching is bi-
nary, which GB syntacticians appear to maintain). Some are quite traditional, e.g., &amp;quot;all
pronounced or lexical noun phrases ... must receive Case&amp;quot; (i.e., Case is an obligatory
grammatical category for nouns—provided you accept that in Chinese or in the En-
glish noun it shows no morphological effects). At least one is false as stated, namely
&amp;quot;every verb must discharge its Thematic arguments and every noun phrase must receive
a thematic role&amp;quot; (i.e., a verb denoting an n-place relation needs exactly n argument
NPs; Berwick seems to have forgotten about nonthematic NPs like idiom chunks and
&apos;dummy&apos; or &apos;expletive&apos; NPs).
It is hard to see any parser design emerging out of such &amp;quot;principles,&amp;quot; and sure
enough, Berwick rapidly admits (p. 8) that &amp;quot;two related computational difficulties lie
at the heart of principle-based parsing: overgeneration and slow parsing.&amp;quot; Producing
incorrect results, and doing it slowly. Not very promising. But Berwick faces this
embarrassment with more feats of rhetoric, drawing inspiration from the language of
product advertising (&amp;quot;Astonishingly .. . Fong&apos;s parser can actually parse basically all of
the several hundred example sentences in Lasnik and Uriagereka&apos;s textbook .. . &amp;quot;—tests
have shown!), political history (&amp;quot;the central achievement of principle-based parsing
stands ... &amp;quot;), revolutionary philosophy (&amp;quot;Thinking about principles liberates us ... &amp;quot;)
and military history (&amp;quot;results described in this volume form the beachhead of a much
broader wave of principle-based research to come&amp;quot;). Such stuff will make some grin
and others wince. Maybe it will convince a few to join the movement — but it is not
clear to me what they will be joining.
The reference to the days when unnamed people proposed &amp;quot;thousands of individ-
ual, language-particular, and construction-specific rules&amp;quot; is, of course, an oblique attack
</bodyText>
<page confidence="0.99362">
394
</page>
<subsectionHeader confidence="0.814951">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.999016823529412">
on generalized phrase structure grammar (GPSG) and all the computational work that
has evolved from it at sites like Hewlett-Packard Laboratories, Stanford, SRI Interna-
tional, Carnegie-Mellon, Ohio State, Edinburgh, Cambridge, Sussex, etc. But anyone
who knows that line of work will be aware that it has always sought general princi-
ples rather than lists of rules (though where rules were called for, they were at least
explicitly stated rather than arm-wavingly assumed). The very earliest publications on
GPSG were interested in general principles such as the Head Feature Convention. And
by about 1984, head-driven phrase structure grammar (HPSG) was emerging from re-
search at Hewlett-Packard Laboratories and had reduced the number of separately
stated syntactic rules in a substantial working grammar for English down to less than
half a dozen (most of the work being done by just two, one for NP-VP structures and
the other for subcategorization structures). The PBP slogan had appeared nowhere
previously when Edward Barton issued an entirely programmatic MIT Al Lab memo
with that title in 1984. But with 1984-style goodthink, Berwick portrays 1984-style
GPSG/HPSG as falling in step with PBP, reporting that they &amp;quot;gradually shifted&amp;quot; (p. 35,
n. 1) toward transconstructional declarative constraints. The alleged &amp;quot;shift&amp;quot; toward
PBP thinking had already taken place before PBP work had even started.
Given Berwick&apos;s anti-rule rhetoric, the innocent reader may be amazed to find
that in the clearer papers in this volume one does encounter rules. We find context-
free expansion rules on pages 87ff of Correa&apos;s paper (a workmanlike though hardly
revolutionary piece of work on formalizing GB-style syntax with attribute grammars);
on page 132 and implicitly elsewhere in Kashket&apos;s paper (an extremely limited effort
to show how one might parse a language with complex morphology but no word
order rules, showing no acquaintance with the relevant literature, e.g., the work on
ID/LP format and liberation schemata); in the schema on page 165 and elsewhere in
Dorr&apos;s paper (153-183); coded in Prolog throughout Stabler&apos;s paper (199-237); and in
pages 262ff of Abney&apos;s paper (a straightforward piece of deterministic context-free LR
parsing). So much for principles replacing rules in actual work.
But of course, parsers are always based on rules (however general and schematic
or detailed and specific they may be), so the enterprise of appearing to recast parsing
without them can only be one of smoke and mirrors. The technique used for keeping
rules from making more of an appearance in this book is a combination of wish-
ful thinking and extreme vagueness. I will give one example. Dorr (p. 158) explains
approvingly how the grammarian describing Spanish will not need these rules:
</bodyText>
<listItem confidence="0.932971285714286">
(1) S-&gt; NP VP
(2) S --- VP
but &amp;quot;need only set the null subject parameter.&amp;quot; Later (p. 167) she explains what this
is: &amp;quot;a minimal binary difference that does or does not allow empty noun phrases to
occupy subject position.&amp;quot; Now, nothing much hangs on the switch from missing noun
phrases to &amp;quot;empty noun phrases&amp;quot;; it means replacing rule (2) by a rule saying
(2&apos;) S -4 NP[+NULL] VP
</listItem>
<bodyText confidence="0.9996706">
(where NP[+NULL] expands to the empty string). Rule (1) is assumed to be available
for all languages (or all SVO languages). The question is whether (2&apos;) is also assumed.
Clearly, what Dorr means by setting the &amp;quot;null subject parameter&amp;quot; to Yes is assuming
that rule (2&apos;) is available to admit local trees rooted in S, and what she means by
setting it to No means assuming that rule (2&apos;) is not available.
</bodyText>
<page confidence="0.995893">
395
</page>
<note confidence="0.631491">
Computational Linguistics Volume 19, Number 2
</note>
<bodyText confidence="0.99947587804878">
Dorr adds a footnote of boilerplate about how a &amp;quot;rule-based approach&amp;quot; like GPSG
would need lots of different rules (p. 180, n. 18), but there is no attempt to show
that this is true (the rules she is talking about are actually reduced to one in GPSG
work of 1985 and later), and there is (crucially) no attempt to show how the notion
&amp;quot;subject position&amp;quot; is defined without rules so that the &amp;quot;null subject parameter&amp;quot; can be
stated. Dorr states nothing relevant with any precision (there is just a casual remark in
her text about whether &amp;quot;empty noun phrases&amp;quot; can &amp;quot;occupy subject position&amp;quot; on page
167). Since Dorr claims to have a machine translation system up and running, she
presumably has something tantamount to a statement of the null subject parameter
buried in the code of her system. But she does not attempt to compare the information
content of this buried statement with the information content of an explicit GPSG
grammar fragment for the same fragment of Spanish so that her vague aspersions can
be given some meaning. As things stand, all one can say with reasonable certainty is
that Dorr wants to be seen as loyal to the approach associated with Berwick&apos;s slogans.
Her assumptions are just those of CB linguistics, and the faults in GB tend to carry
over to her computational work.
There are some papers in this book that are worth reading, and they are generally
the ones that ignore Berwick&apos;s sloganeering completely. Stabler&apos;s paper, for example,
is a small but serious contribution to Prolog-based computational linguistics — though
I find absolutely nothing in it that refers to GB concepts or PM Johnson&apos;s is a clear
statement of a simple if not particularly original idea (that using Prolog, parsing can
be simply a process of deduction in the logical sense — an idea that seemed to be
apparent to Prolog enthusiasts in Europe over a decade ago) and an exploration of a
few (five) different control structures that a GB parser might use; and Correa&apos;s work
on attribute grammars, as noted above, might repay the reader&apos;s attention. But the
level of many of the papers is depressingly low. Fong seems to have built a system for
the purpose of testing alternative orders of application for 16 different principles and
tests a few without noting that there are 16! = 20, 922, 789, 888, 000 alternatives to be
tested; Kashket has a one-page section called &amp;quot;The problem with context-free parsers,&amp;quot;
(pp. 126-7) which does nothing but assert the entirely false claim that a context-free
grammar cannot generate structures for VSO sentence types in NP–VP languages; such
chapters represent feeble contributions at best, managing to sound both amateurish
and insular.
In a way, the most favorable thing I can say about the various kinds of work on
parsing in this book is that the contributors pay so little regard to the promises issued
on their behalf by the blatant markei ing hype of Berwick&apos;s introduction. After all, one
of the ways in which computational linguistics holds out promise for linguistics in
general is by providing practical tests that will inject some honesty into the testing
and comparison of linguistic theories, and that promise is betrayed when routine work
on parsing problems is decked out with the kind of vagueness and self-deception that
are so evident in the introduction to this book.
</bodyText>
<reference confidence="0.654728333333333">
Geoffrey K. Pullum is on the faculty of the University of California, Santa Cruz, where he has been
Professor of Linguistics since 1981 and Dean of Graduate Studies and Research since 1987. Pul-
lum&apos;s address is: Cowell College, UCSC, Santa Cruz, CA 95064; e-mail: pullum@cats.ucsc.edu.
</reference>
<page confidence="0.998826">
396
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.508139">
<title confidence="0.994071">Principle-Based Parsing: Computation and Psycholinguistics</title>
<author confidence="0.99271">Robert C Berwick</author>
<author confidence="0.99271">Steven P Abney</author>
<author confidence="0.99271">Carol Tenny</author>
<author confidence="0.99271">editors</author>
<affiliation confidence="0.854261666666667">(MIT, Bell Communications Research, and University of Pittsburgh) Dordrecht: Kluwer Academic Publishers (Studies in Linguistics and</affiliation>
<note confidence="0.9204425">Philosophy 44), 1991, vii + 408 pp. Hardbound, ISBN 0-7923-1173-6, $89.00, £58.00, Dfl 165.00 Reviewed by</note>
<author confidence="0.998923">Geoffrey K Pullum</author>
<affiliation confidence="0.989611">University of California, Santa Cruz</affiliation>
<note confidence="0.986794">This book is a collection of 13 essays on various aspects of parsing:</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Geoffrey</author>
</authors>
<title>Pullum is on the faculty of the University of California, Santa Cruz, where he has been Professor of Linguistics since</title>
<date>1981</date>
<booktitle>and Dean of Graduate Studies and Research since</booktitle>
<location>Santa Cruz, CA</location>
<note>95064; e-mail: pullum@cats.ucsc.edu.</note>
<marker>Geoffrey, 1981</marker>
<rawString>Geoffrey K. Pullum is on the faculty of the University of California, Santa Cruz, where he has been Professor of Linguistics since 1981 and Dean of Graduate Studies and Research since 1987. Pullum&apos;s address is: Cowell College, UCSC, Santa Cruz, CA 95064; e-mail: pullum@cats.ucsc.edu.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>