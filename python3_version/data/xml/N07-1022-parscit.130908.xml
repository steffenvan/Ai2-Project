<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.999237">
Generation by Inverting a Semantic Parser That Uses
Statistical Machine Translation
</title>
<author confidence="0.947282">
Yuk Wah Wong and Raymond J. Mooney
</author>
<affiliation confidence="0.947995666666667">
Department of Computer Sciences
The University of Texas at Austin
1 University Station C0500
</affiliation>
<address confidence="0.600625">
Austin, TX 78712-0233, USA
</address>
<email confidence="0.998372">
{ywwong,mooney}@cs.utexas.edu
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998948">
This paper explores the use of statisti-
cal machine translation (SMT) methods
for tactical natural language generation.
We present results on using phrase-based
SMT for learning to map meaning repre-
sentations to natural language. Improved
results are obtained by inverting a seman-
tic parser that uses SMT methods to map
sentences into meaning representations.
Finally, we show that hybridizing these
two approaches results in still more accu-
rate generation systems. Automatic and
human evaluation of generated sentences
are presented across two domains and four
languages.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999701928571429">
This paper explores the use of statistical machine
translation (SMT) methods in natural language gen-
eration (NLG), specifically the task of mapping
statements in a formal meaning representation lan-
guage (MRL) into a natural language (NL), i.e. tacti-
cal generation. Given a corpus of NL sentences each
paired with a formal meaning representation (MR),
it is easy to use SMT to construct a tactical gener-
ator, i.e. a statistical model that translates MRL to
NL. However, there has been little, if any, research
on exploiting recent SMT methods for NLG.
In this paper we present results on using a re-
cent phrase-based SMT system, PHARAOH (Koehn
et al., 2003), for NLG.1 Although moderately effec-
</bodyText>
<footnote confidence="0.842213">
1We also tried IBM Model 4/REWRITE (Germann, 2003), a
word-based SMT system, but it gave much worse results.
</footnote>
<bodyText confidence="0.999959555555555">
tive, the inability of PHARAOH to exploit the for-
mal structure and grammar of the MRL limits its ac-
curacy. Unlike natural languages, MRLs typically
have a simple, formal syntax to support effective au-
tomated processing and inference. This MRL struc-
ture can also be used to improve language genera-
tion.
Tactical generation can also be seen as the inverse
of semantic parsing, the task of mapping NL sen-
tences to MRs. In this paper, we show how to “in-
vert” a recent SMT-based semantic parser, WASP
(Wong and Mooney, 2006), in order to produce a
more effective generation system. WASP exploits
the formal syntax of the MRL by learning a trans-
lator (based on a statistical synchronous context-
free grammar) that maps an NL sentence to a lin-
earized parse-tree of its MR rather than to a flat MR
string. In addition to exploiting the formal MRL
grammar, our approach also allows the same learned
grammar to be used for both parsing and genera-
tion, an elegant property that has been widely ad-
vocated (Kay, 1975; Jacobs, 1985; Shieber, 1988).
We present experimental results in two domains pre-
viously used to test WASP’s semantic parsing abil-
ity: mapping NL queries to a formal database query
language, and mapping NL soccer coaching instruc-
tions to a formal robot command language. WASP−1
is shown to produce a more accurate NL generator
than PHARAOH.
We also show how the idea of generating from
linearized parse-trees rather than flat MRs, used
effectively in WASP−1, can also be exploited in
PHARAOH. A version of PHARAOH that exploits
this approach is experimentally shown to produce
more accurate generators that are more competi-
tive with WASP−1’s. Finally, we also show how
</bodyText>
<page confidence="0.945619">
172
</page>
<note confidence="0.7996545">
Proceedings of NAACL HLT 2007, pages 172–179,
Rochester, NY, April 2007. c�2007 Association for Computational Linguistics
</note>
<figure confidence="0.880037875">
((bowner our {4})
(do our {6} (pos (left (half our)))))
If our player 4 has the ball, then our player 6
should stay in the left side of our half.
(a) CLANG
answer(state(traverse 1(riverid(’ohio’))))
What states does the Ohio run through?
(b) GEOQUERY
</figure>
<figureCaption confidence="0.999967">
Figure 1: Sample meaning representations
</figureCaption>
<bodyText confidence="0.999212333333333">
aspects of PHARAOH’s phrase-based model can be
used to improve WASP−1, resulting in a hybrid sys-
tem whose overall performance is the best.
</bodyText>
<sectionHeader confidence="0.714479" genericHeader="introduction">
2 MRLs and Test Domains
</sectionHeader>
<bodyText confidence="0.999960074074074">
In this work, we consider input MRs with a hi-
erarchical structure similar to Moore (2002). The
only restriction on the MRL is that it be defined
by an available unambiguous context-free grammar
(CFG), which is true for almost all computer lan-
guages. We also assume that the order in which MR
predicates appear is relevant, i.e. the order can affect
the meaning of the MR. Note that the order in which
predicates appear need not be the same as the word
order of the target NL, and therefore, the content
planner need not know about the target NL grammar
(Shieber, 1993).
To ground our discussion, we consider two ap-
plication domains which were originally used to
demonstrate semantic parsing. The first domain is
ROBOCUP. In the ROBOCUP Coach Competition
(www.robocup.org), teams of agents compete in a
simulated soccer game and receive coach advice
written in a formal language called CLANG (Chen
et al., 2003). The task is to build a system that trans-
lates this formal advice into English. Figure 1(a)
shows a piece of sample advice.
The second domain is GEOQUERY, where a func-
tional, variable-free query language is used for
querying a small database on U.S. geography (Kate
et al., 2005). The task is to translate formal queries
into NL. Figure 1(b) shows a sample query.
</bodyText>
<sectionHeader confidence="0.974369" genericHeader="method">
3 Generation using SMT Methods
</sectionHeader>
<bodyText confidence="0.998068111111111">
In this section, we show how SMT methods can be
used to construct a tactical generator. This is in con-
trast to existing work that focuses on the use of NLG
in interlingual MT (Whitelock, 1992), in which the
roles of NLG and MT are switched. We first con-
sider using a phrase-based SMT system, PHARAOH,
for NLG. Then we show how to invert an SMT-based
semantic parser, WASP, to produce a more effective
generation system.
</bodyText>
<subsectionHeader confidence="0.999547">
3.1 Generation using PHARAOH
</subsectionHeader>
<bodyText confidence="0.999942764705882">
PHARAOH (Koehn et al., 2003) is an SMT system
that uses phrases as basic translation units. Dur-
ing decoding, the source sentence is segmented into
a sequence of phrases. These phrases are then re-
ordered and translated into phrases in the target lan-
guage, which are joined together to form the output
sentence. Compared to earlier word-based methods
such as IBM Models (Brown et al., 1993), phrase-
based methods such as PHARAOH are much more
effective in producing idiomatic translations, and
are currently the best performing methods in SMT
(Koehn and Monz, 2006).
To use PHARAOH for NLG, we simply treat the
source MRL as an NL, so that phrases in the MRL
are sequences of MR tokens. Note that the grammat-
icality of MRs is not an issue here, as they are given
as input.
</bodyText>
<subsectionHeader confidence="0.997983">
3.2 WASP: The Semantic Parsing Algorithm
</subsectionHeader>
<bodyText confidence="0.9996162">
Before showing how generation can be performed
by inverting a semantic parser, we present a brief
overview of WASP (Wong and Mooney, 2006), the
SMT-based semantic parser on which this work is
based.
To describe WASP, it is best to start with an ex-
ample. Consider the task of translating the English
sentence in Figure 1(a) into CLANG. To do this,
we may first generate a parse tree of the input sen-
tence. The meaning of the sentence is then ob-
tained by combining the meanings of the phrases.
This process can be formalized using a synchronous
context-free grammar (SCFG), originally developed
as a grammar formalism that combines syntax anal-
ysis and code generation in compilers (Aho and Ull-
man, 1972). It has been used in syntax-based SMT
to model the translation of one NL to another (Chi-
ang, 2005). A derivation for a SCFG gives rise to
multiple isomorphic parse trees. Figure 2 shows a
partial parse of the sample sentence and its corre-
</bodyText>
<page confidence="0.997308">
173
</page>
<figure confidence="0.993202625">
RULE RULE
...
...)
If CONDITION
( CONDITION
})
player UNUM
4
has the ball
(bowner TEAM
our
{ UNUM
4
TEAM
our
(a) English (b) CLANG
</figure>
<figureCaption confidence="0.999774">
Figure 2: Partial parse trees for the CLANG statement and its English gloss shown in Figure 1(a)
</figureCaption>
<bodyText confidence="0.999680818181818">
sponding CLANG parse from which an MR is con-
structed. Note that the two parse trees are isomor-
phic (ignoring terminals).
Each SCFG rule consists of a non-terminal, X,
on the left-hand side (LHS), and a pair of strings,
(α, Q), on the right-hand side (RHS). The non-
terminals in Q are a permutation of the non-terminals
in α (indices are used to show their correspondence).
In WASP, α denotes an NL phrase, and X Q is
a production of the MRL grammar. Below are the
SCFG rules that generate the parses in Figure 2:
</bodyText>
<equation confidence="0.531374333333333">
RULE (if CONDITION 1 , DIRECTIVE 2 . ,
(CONDITION 1 DIRECTIVE 2 ))
CONDITION (TEAM 1 player UNUM 2 has the
ball, (bowner TEAM 1 {UNUM 2 }))
TEAM (our , our)
UNUM (4 , 4)
</equation>
<bodyText confidence="0.999953545454546">
All derivations start with a pair of co-indexed start
symbols of the MRL grammar, (51 , 51 ), and each
step involves the rewriting of a pair of co-indexed
non-terminals (by α and Q, respectively). Given an
input sentence, e, the task of semantic parsing is to
find a derivation that yields (e, f), so that f is an MR
translation of e.
Parsing with WASP requires a set of SCFG rules.
These rules are learned using a word alignment
model, which finds an optimal mapping from words
to MR predicates given a set of training sentences
and their correct MRs. Word alignment models have
been widely used for lexical acquisition in SMT
(Brown et al., 1993; Koehn et al., 2003). To use
a word alignment model in the semantic parsing
scenario, we can treat the MRL simply as an NL,
and MR tokens as words, but this often leads to
poor results. First, not all MR tokens carry spe-
cific meanings. For example, in CLANG, parenthe-
ses and braces are delimiters that are semantically
vacuous. Such tokens can easily confuse the word
alignment model. Second, MR tokens may exhibit
polysemy. For example, the CLANG predicate pt
has three meanings based on the types of arguments
it is given (Chen et al., 2003). Judging from the pt
token alone, the word alignment model would not be
able to identify its exact meaning.
A simple, principled way to avoid these difficul-
ties is to represent an MR using a list of productions
used to generate it. This list is used in lieu of the
MR in a word alignment. Figure 3 shows an exam-
ple. Here the list of productions corresponds to the
top-down, left-most derivation of an MR. For each
MR there is a unique linearized parse-tree, since
the MRL grammar is unambiguous. Note that the
structure of the parse tree is preserved through lin-
earization. This allows us to extract SCFG rules in a
bottom-up manner, assuming the alignment is n-to-1
(each word is linked to at most one production). Ex-
traction starts with productions whose RHS is all ter-
minals, followed by those with non-terminals. (De-
tails can be found in Wong and Mooney (2006).)
The rules extracted from Figure 3 would be almost
the same as those used in Figure 2, except the one for
bowner: CONDITION (TEAM 1 player UNUM 2
has (1) ball, (bowner TEAM 1 {UNUM 2 })). The
token (1) denotes a word gap of size 1, due to the un-
aligned word the that comes between has and ball.
It can be seen as a non-terminal that expands to at
most one word, allowing for some flexibility in pat-
tern matching.
In WASP, GIZA++ (Och and Ney, 2003) is used
to obtain the best alignments from the training ex-
amples. Then SCFG rules are extracted from these
alignments. The resulting SCFG, however, can be
</bodyText>
<page confidence="0.991413">
174
</page>
<table confidence="0.772771857142857">
If RULE → (CONDITION DIRECTIVE)
our CONDITION → (bowner TEAM {UNUM})
player TEAM → our
4 UNUM → 4
has
the
ball
</table>
<figureCaption confidence="0.981027">
Figure 3: Partial word alignment for the CLANG statement and its English gloss shown in Figure 1(a)
</figureCaption>
<bodyText confidence="0.99929875">
ambiguous. Therefore, a maximum-entropy model
that defines the conditional probability of deriva-
tions (d) given an input sentence (e) is used for dis-
ambiguation:
</bodyText>
<equation confidence="0.910948666666667">
components:
arg max Pr(e|f) = argmax Pr(e)Pr(f|e) (2)
e e
</equation>
<bodyText confidence="0.9999235">
The feature functions, fi, are the number of times
each rule is used in a derivation. Zλ(e) is the
normalizing factor. The model parameters, Ai, are
trained using L-BFGS (Nocedal, 1980) to maxi-
mize the conditional log-likelihood of the training
examples (with a Gaussian prior). The decoding
task is thus to find a derivation d⋆ that maximizes
Prλ(d⋆|e), and the output MR translation, f⋆, is the
yield of d⋆. This can be done in cubic time with re-
spect to the length of e using an Earley chart parser.
</bodyText>
<subsectionHeader confidence="0.995467">
3.3 Generation by Inverting WASP
</subsectionHeader>
<bodyText confidence="0.9999606">
Now we show how to invert WASP to produce
WASP−1, and use it for NLG. We can use the same
grammar for both parsing and generation, a partic-
ularly appealing aspect of using WASP. Since an
SCFG is fully symmetric with respect to both gen-
erated strings, the same chart used for parsing can
be easily adapted for efficient generation (Shieber,
1988; Kay, 1996).
Given an input MR, f, WASP−1 finds a sentence
e that maximizes Pr(e|f). It is difficult to directly
model Pr(e|f), however, because it has to assign
low probabilities to output sentences that are not
grammatical. There is no such requirement for pars-
ing, because the use of the MRL grammar ensures
the grammaticality of all output MRs. For genera-
tion, we need an NL grammar to ensure grammati-
cality, but this is not available a priori.
This motivates the noisy-channel model for
WASP−1, where Pr(e|f) is divided into two smaller
Pr(e) is the language model, and Pr(f|e) is the
parsing model. The generation task is to find a sen-
tence e such that (1) e is a good sentence a priori,
and (2) its meaning is the same as the input MR. For
the language model, we use an n-gram model, which
is remarkably useful in ranking candidate generated
sentences (Knight and Hatzivassiloglou, 1995; Ban-
galore et al., 2000; Langkilde-Geary, 2002). For the
parsing model, we re-use the one from WASP (Equa-
tion 1). Hence computing (2) means maximizing the
following:
</bodyText>
<equation confidence="0.998373">
Pr(e) Pr(f|e)
Pr(e(d)) Prλ(d|e(d))
Pr(e(d)) · exp Ei Aifi(d) (3)
Zλ(e(d))
</equation>
<bodyText confidence="0.9991514">
where D(f) is the set of derivations that are con-
sistent with f, and e(d) is the output sentence that
a derivation d yields. Compared to most exist-
ing work on generation, WASP−1 has the following
characteristics:
</bodyText>
<listItem confidence="0.910907166666667">
1. It does not require any lexical information in
the input MR, so lexical selection is an integral
part of the decoding algorithm.
2. Each predicate is translated to a phrase. More-
over, it need not be a contiguous phrase (con-
sider the SCFG rule for bowner in Section 3.2).
</listItem>
<bodyText confidence="0.99994975">
For decoding, we use an Earley chart generator
that scans the input MR from left to right. This im-
plies that each chart item covers a certain substring
of the input MR, not a subsequence in general. It
</bodyText>
<equation confidence="0.822762777777778">
1 1:
Prλ(d|e) = Zλ(e) exp Aifi(d) (1)
i
max
e
≈ max
dED(f)
= max
dED(f)
</equation>
<page confidence="0.987154">
175
</page>
<bodyText confidence="0.999903272727273">
requires the order in which MR predicates appear
to be fixed, i.e. the order determines the meaning
of the MR. Since the order need not be identical to
the word order of the target NL, there is no need for
the content planner to know the target NL grammar,
which is learned from the training data.
Overall, the noisy-channel model is a weighted
SCFG, obtained by intersecting the NL side of the
WASP SCFG with the n-gram language model. The
chart generator is very similar to the chart parser, ex-
cept for the following:
</bodyText>
<listItem confidence="0.863707333333333">
1. To facilitate the calculation of Pr(e(d)), chart
items now include a list of (n−1)-grams that encode
the context in which output NL phrases appear. The
size of the list is 2N + 2, where N is the number of
non-terminals to be rewritten in the dotted rule.
2. Words are generated from word gaps through
</listItem>
<bodyText confidence="0.825751428571429">
special rules (g) —* (α, 0), where the word gap,
(g), is treated as a non-terminal, and α is the NL
string that fills the gap (|α |G g). The empty set
symbol indicates that the NL string does not carry
any meaning. There are similar constructs in Car-
roll et al. (1999) that generate function words. Fur-
thermore, to improve efficiency, our generator only
considers gap fillers that have been observed during
training.
3. The normalizing factor in (3), Zλ(e(d)), is not
a constant and varies across the output string, e(d).
(Note that Zλ(e) is fixed for parsing.) This is un-
fortunate because the calculation of Zλ(e(d)) is ex-
pensive, and it is not easy to incorporate it into the
chart generation algorithm. Normalization is done
as follows. First, compute the k-best candidate out-
put strings based on the unnormalized version of (3),
Pr(e(d)) · exp Ei Aifi(d). Then re-rank the list by
normalizing the scores using Zλ(e(d)), which is ob-
tained by running the inside-outside algorithm on
each output string. This results in a decoding al-
gorithm that is approximate—the best output string
might not be in the k-best list—and takes cubic time
with respect to the length of each of the k candidate
output strings (k = 100 in our experiments).
Learning in WASP−1 involves two steps. First, a
back-off n-gram language model with Good-Turing
discounting and no lexical classes2 is built from all
</bodyText>
<footnote confidence="0.880085">
2This is to ensure that the same language model is used in
all systems that we tested.
</footnote>
<bodyText confidence="0.9998795">
training sentences using the SRILM Toolkit (Stolcke,
2002). We use n = 2 since higher values seemed to
cause overfitting in our domains. Next, the parsing
model is trained as described in Section 3.2.
</bodyText>
<sectionHeader confidence="0.951702" genericHeader="method">
4 Improving the SMT-based Generators
</sectionHeader>
<bodyText confidence="0.99985475">
The SMT-based generation algorithms, PHARAOH
and WASP−1, while reasonably effective, can be
substantially improved by borrowing ideas from
each other.
</bodyText>
<subsectionHeader confidence="0.997784">
4.1 Improving the PHARAOH-based Generator
</subsectionHeader>
<bodyText confidence="0.9999771875">
A major weakness of PHARAOH as an NLG sys-
tem is its inability to exploit the formal structure of
the MRL. Like WASP−1, the phrase extraction al-
gorithm of PHARAOH is based on the output of a
word alignment model such as GIZA++ (Koehn et
al., 2003), which performs poorly when applied di-
rectly to MRLs (Section 3.2).
We can improve the PHARAOH-based generator
by supplying linearized parse-trees as input rather
than flat MRs. As a result, the basic translation units
are sequences of MRL productions, rather than se-
quences of MR tokens. This way PHARAOH can
exploit the formal grammar of the MRL to produce
high-quality phrase pairs. The same idea is used in
WASP−1 to produce high-quality SCFG rules. We
call the resulting hybrid NLG system PHARAOH++.
</bodyText>
<subsectionHeader confidence="0.991657">
4.2 Improving the WASP-based Generator
</subsectionHeader>
<bodyText confidence="0.999997428571429">
There are several aspects of PHARAOH that can be
used to improve WASP−1. First, the probabilistic
model of WASP−1 is less than ideal as it requires
an extra re-ranking step for normalization, which is
expensive and prone to over-pruning. To remedy this
situation, we can borrow the probabilistic model of
PHARAOH, and define the parsing model as:
</bodyText>
<equation confidence="0.865053">
Pr(d|e(d)) = � w(r(d)) (4)
dEd
</equation>
<bodyText confidence="0.997311333333333">
which is the product of the weights of the rules used
in a derivation d. The rule weight, w(X —* (α, 0)),
is in turn defined as:
</bodyText>
<equation confidence="0.784109">
P(0|α)λ1P(α|0)λ2Pw(0|α)λ3Pw(α|0)λ4 exp(−|α|)λ5
</equation>
<bodyText confidence="0.999789">
where P(0|α) and P(α|0) are the relative frequen-
cies of 0 and α, and Pw(0|α) and Pw(α|0) are
</bodyText>
<page confidence="0.997391">
176
</page>
<bodyText confidence="0.999977961538461">
the lexical weights (Koehn et al., 2003). The word
penalty, exp(−|α|), allows some control over the
output sentence length. Together with the language
model, the new formulation of Pr(e|f) is a log-
linear model with AZ as parameters. The advantage
of this model is that maximization requires no nor-
malization and can be done exactly and efficiently.
The model parameters are trained using minimum
error-rate training (Och, 2003).
Following the phrase extraction phase in
PHARAOH, we eliminate word gaps by incorpo-
rating unaligned words as part of the extracted
NL phrases (Koehn et al., 2003). The reason is
that while word gaps are useful in dealing with
unknown phrases during semantic parsing, for
generation, using known phrases generally leads to
better fluency. For the same reason, we also allow
the extraction of longer phrases that correspond to
multiple predicates (but no more than 5).
We call the resulting hybrid system WASP−1++.
It is similar to the syntax-based SMT system of Chi-
ang (2005), which uses both SCFG and PHARAOH’s
probabilistic model. The main difference is that we
use the MRL grammar to constrain rule extraction,
so that significantly fewer rules are extracted, mak-
ing it possible to do exact inference.
</bodyText>
<sectionHeader confidence="0.998691" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.998198333333333">
We evaluated all four SMT-based NLG systems in-
troduced in this paper: PHARAOH, WASP−1, and the
hybrid systems, PHARAOH++ and WASP−1++.
We used the ROBOCUP and GEOQUERY corpora
in our experiments. The ROBOCUP corpus consists
of 300 pieces of coach advice taken from the log files
of the 2003 ROBOCUP Coach Competition. The ad-
vice was written in CLANG and manually translated
to English (Kuhlmann et al., 2004). The average
MR length is 29.47 tokens, or 12.82 nodes for lin-
earized parse-trees. The average sentence length is
22.52. The GEOQUERY corpus consists of 880 En-
glish questions gathered from various sources. The
questions were manually translated to the functional
GEOQUERY language (Kate et al., 2005). The av-
erage MR length is 17.55 tokens, or 5.55 nodes for
linearized parse-trees. The average sentence length
is 7.57.
Reference: If our player 2, 3, 7 or 5 has the ball
and the ball is close to our goal line ...
PHARAOH++: Ifplayer 3 has the ball is in 2 5 the
ball is in the area near our goal line ...
WASP−1++: If players 2, 3, 7 and 5 has the ball
and the ball is near our goal line ...
</bodyText>
<figureCaption confidence="0.843899">
Figure 4: Sample partial system output in the
ROBOCUP domain
</figureCaption>
<table confidence="0.999523666666667">
ROBOCUP GEOQUERY
BLEU NIST BLEU NIST
PHARAOH 0.3247 5.0263 0.2070 3.1478
WASP−1 0.4357 5.4486 0.4582 5.9900
PHARAOH++ 0.4336 5.9185 0.5354 6.3637
WASP−1++ 0.6022 6.8976 0.5370 6.4808
</table>
<tableCaption confidence="0.8087845">
Table 1: Results of automatic evaluation; bold type
indicates the best performing system (or systems)
</tableCaption>
<bodyText confidence="0.867985">
for a given domain-metric pair (p &lt; 0.05)
</bodyText>
<subsectionHeader confidence="0.9971">
5.1 Automatic Evaluation
</subsectionHeader>
<bodyText confidence="0.999949925925926">
We performed 4 runs of 10-fold cross validation, and
measured the performance of the learned generators
using the BLEU score (Papineni et al., 2002) and the
NIST score (Doddington, 2002). Both MT metrics
measure the precision of a translation in terms of the
proportion of n-grams that it shares with the refer-
ence translations, with the NIST score focusing more
on n-grams that are less frequent and more informa-
tive. Both metrics have recently been used to eval-
uate generators (Langkilde-Geary, 2002; Nakanishi
et al., 2005; Belz and Reiter, 2006).
All systems were able to generate sentences for
more than 97% of the input. Figure 4 shows some
sample output of the systems. Table 1 shows the
automatic evaluation results. Paired t-tests were
used to measure statistical significance. A few
observations can be made. First, WASP−1 pro-
duced a more accurate generator than PHARAOH.
Second, PHARAOH++ significantly outperformed
PHARAOH, showing the importance of exploiting
the formal structure of the MRL. Third, WASP−1++
significantly outperformed WASP−1. Most of the
gain came from PHARAOH’s probabilistic model.
Decoding was also 4–11 times faster, despite ex-
act inference and a larger grammar due to extrac-
tion of longer phrases. Lastly, WASP−1++ signifi-
cantly outperformed PHARAOH++ in the ROBOCUP
</bodyText>
<page confidence="0.991686">
177
</page>
<table confidence="0.96067475">
ROBOCUP GEOQUERY
Flu. Ade. Flu. Ade.
PHARAOH++ 2.5 2.9 4.3 4.7
WASP−1++ 3.6 4.0 4.1 4.7
</table>
<tableCaption confidence="0.999624">
Table 2: Results of human evaluation
</tableCaption>
<bodyText confidence="0.999861">
domain. This is because WASP−1++ allows dis-
contiguous NL phrases and PHARAOH++ does not.
Such phrases are commonly used in ROBOCUP
for constructions like: players 2 , 3 , 7 and 5;
26.96% of the phrases generated during testing were
discontiguous. When faced with such predicates,
PHARAOH++ would consistently omit some of the
words: e.g. players 2 3 7 5, or not learn any phrases
for those predicates at all. On the other hand, only
4.47% of the phrases generated during testing for
GEOQUERY were discontiguous, so the advantage of
WASP−1++ over PHARAOH++ was not as obvious.
Our BLEU scores are not as high as those re-
ported in Langkilde-Geary (2002) and Nakanishi et
al. (2005), which are around 0.7–0.9. However,
their work involves the regeneration of automati-
cally parsed text, and the MRs that they use, which
are essentially dependency parses, contain extensive
lexical information of the target NL.
</bodyText>
<subsectionHeader confidence="0.999886">
5.2 Human Evaluation
</subsectionHeader>
<bodyText confidence="0.998288866666667">
Automatic evaluation is only an imperfect substitute
for human assessment. While it is found that BLEU
and NIST correlate quite well with human judgments
in evaluating NLG systems (Belz and Reiter, 2006),
it is best to support these figures with human evalu-
ation, which we did on a small scale. We recruited 4
native speakers of English with no previous experi-
ence with the ROBOCUP and GEOQUERY domains.
Each subject was given the same 20 sentences for
each domain, randomly chosen from the test sets.
For each sentence, the subjects were asked to judge
the output of PHARAOH++ and WASP−1++ in terms
of fluency and adequacy. They were presented with
the following definition, adapted from Koehn and
Monz (2006):
</bodyText>
<subsectionHeader confidence="0.410818">
Fluency Adequacy
</subsectionHeader>
<bodyText confidence="0.263685">
Flawless English All meaning
Most meaning
Some meaning
</bodyText>
<table confidence="0.999432166666667">
PHARAOH++ WASP−1++
BLEU NIST BLEU NIST
English 0.5344 5.3289 0.6035 5.7133
Spanish 0.6042 5.6321 0.6175 5.7293
Japanese 0.6171 4.5357 0.6585 4.6648
Turkish 0.4562 4.2220 0.4824 4.3283
</table>
<tableCaption confidence="0.9791505">
Table 3: Results of automatic evaluation on the mul-
tilingual GEOQUERY data set
</tableCaption>
<figure confidence="0.187468666666667">
Fluency Adequacy
2
1
</figure>
<bodyText confidence="0.998644857142857">
For each generated sentence, we computed the av-
erage of the 4 human judges’ scores. No score
normalization was performed. Then we compared
the two systems using a paired t-test. Table 2
shows that WASP−1++ produced better generators
than PHARAOH++ in the ROBOCUP domain, con-
sistent with the results of automatic evaluation.
</bodyText>
<subsectionHeader confidence="0.999087">
5.3 Multilingual Experiments
</subsectionHeader>
<bodyText confidence="0.999969909090909">
Lastly, we describe our experiments on the mul-
tilingual GEOQUERY data set. The 250-example
data set is a subset of the larger GEOQUERY cor-
pus. All English questions in this data set were
manually translated into Spanish, Japanese and
Turkish, while the corresponding MRs remain un-
changed. Table 3 shows the results, which are sim-
ilar to previous results on the larger GEOQUERY
corpus. WASP−1++ outperformed PHARAOH++
for some language-metric pairs, but otherwise per-
formed comparably.
</bodyText>
<sectionHeader confidence="0.999878" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.972491923076923">
Numerous efforts have been made to unify the tasks
of semantic parsing and tactical generation. One of
the earliest espousals of the notion of grammar re-
versability can be found in Kay (1975). Shieber
(1988) further noted that not only a single gram-
mar can be used for parsing and generation, but the
same language-processing architecture can be used
for both tasks. Kay (1996) identified parsing charts
as such an architecture, which led to the develop-
ment of various chart generation algorithms: Car-
roll et al. (1999) for HPSG, Bangalore et al. (2000)
for LTAG, Moore (2002) for unification grammars,
Score
</bodyText>
<page confidence="0.955595333333333">
5
4
3
</page>
<figure confidence="0.994996714285714">
Good English
Non-native English
Score
Disfluent English
Incomprehensible
Little meaning
No meaning
</figure>
<page confidence="0.987391">
178
</page>
<bodyText confidence="0.999837">
White and Baldridge (2003) for CCG. More re-
cently, statistical chart generators have emerged, in-
cluding White (2004) for CCG, Carroll and Oepen
(2005) and Nakanishi et al. (2005) for HPSG. Many
of these systems, however, focus on the task of sur-
face realization—inflecting and ordering words—
which ignores the problem of lexical selection. In
contrast, our SMT-based methods integrate lexical
selection and realization in an elegant framework
and automatically learn all of their linguistic knowl-
edge from an annotated corpus.
</bodyText>
<sectionHeader confidence="0.998372" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999164">
We have presented four tactical generation systems
based on various SMT-based methods. In particular,
the hybrid system produced by inverting the WASP
semantic parser shows the best overall results across
different application domains.
</bodyText>
<sectionHeader confidence="0.997472" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999918">
We would like to thank Kevin Knight, Jason
Baldridge, Razvan Bunescu, and the anonymous re-
viewers for their valuable comments. We also sin-
cerely thank the four annotators who helped us eval-
uate the SMT-based generators. This research was
supported by DARPA under grant HR0011-04-1-
0007 and a gift from Google Inc.
</bodyText>
<sectionHeader confidence="0.999232" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999880583333334">
A. V. Aho and J. D. Ullman. 1972. The Theory of Parsing, Translation,
and Compiling. Prentice Hall, Englewood Cliffs, NJ.
S. Bangalore, O. Rambow, and S. Whittaker. 2000. Evaluation metrics
for generation. In Proc. INLG-00, pages 1–8, Mitzpe Ramon, Israel,
July.
A. Belz and E. Reiter. 2006. Comparing automatic and human evalu-
ation of NLG systems. In Proc. EACL-06, pages 313–320, Trento,
Italy, April.
P. F. Brown, V. J. Della Pietra, S. A. Della Pietra, and R. L. Mercer.
1993. The mathematics of statistical machine translation: Parameter
estimation. Computational Linguistics, 19(2):263–312, June.
J. Carroll and S. Oepen. 2005. High efficiency realization for a wide-
coverage unification grammar. In Proc. IJCNLP-05, pages 165–176,
Jeju Island, Korea, October.
J. Carroll, A. Copestake, D. Flickinger, and V. Pozna´nski. 1999. An
efficient chart generator for (semi-)lexicalist grammars. In Proc.
EWNLG-99, pages 86–95, Toulouse, France.
M. Chen et al. 2003. Users manual: RoboCup soccer server man-
ual for soccer server version 7.07 and later. Available at http:
//sourceforge.net/projects/sserver/.
D. Chiang. 2005. A hierarchical phrase-based model for statistical
machine translation. In Proc. ACL-05, pages 263–270, Ann Arbor,
MI, June.
G. Doddington. 2002. Automatic evaluation of machine translation
quality using n-gram co-occurrence statistics. In Proc. ARPA Work-
shop on Human Language Technology, pages 128–132, San Diego,
CA.
U. Germann. 2003. Greedy decoding for statistical machine translation
in almost linear time. In Proc. HLT/NAACL-03, Edmonton, Canada.
P. S. Jacobs. 1985. PHRED: A generator for natural language inter-
faces. Computational Linguistics, 11(4):219–242.
R. J. Kate, Y. W. Wong, and R. J. Mooney. 2005. Learning to transform
natural to formal languages. In Proc. AAAI-05, pages 1062–1068,
Pittsburgh, PA, July.
M. Kay. 1975. Syntactic processing and functional sentence per-
spective. In Theoretical Issues in Natural Language Processing—
Supplement to the Proceedings, pages 12–15, Cambridge, MA,
June.
M. Kay. 1996. Chart generation. In Proc. ACL-96, pages 200–204, San
Francisco, CA.
K. Knight and V. Hatzivassiloglou. 1995. Two-level, many-paths gen-
eration. In Proc. ACL-95, pages 252–260, Cambridge, MA.
P. Koehn and C. Monz. 2006. Manual and automatic evaluation of
machine translation between European languages. In Proc. SMT-06
Workshop, pages 102–121, New York City, NY, June.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase-based
translation. In Proc. HLT/NAACL-03, Edmonton, Canada.
G. Kuhlmann, P. Stone, R. J. Mooney, and J. W. Shavlik. 2004. Guiding
a reinforcement learner with natural language advice: Initial results
in RoboCup soccer. In Proc. of the AAAI-04 Workshop on Supervi-
sory Control of Learning and Adaptive Systems, San Jose, CA, July.
I. Langkilde-Geary. 2002. An empirical verification of coverage
and correctness for a general-purpose sentence generator. In Proc.
INLG-02, pages 17–24, Harriman, NY, July.
R. C. Moore. 2002. A complete, efficient sentence-realization algo-
rithm for unification grammar. In Proc. INLG-02, pages 41–48,
Harriman, NY, July.
H. Nakanishi, Y. Miyao, and J. Tsujii. 2005. Probabilistic models for
disambiguation of an HPSG-based chart generator. In Proc. IWPT-
05, pages 93–102, Vancouver, Canada, October.
J. Nocedal. 1980. Updating quasi-Newton matrices with limited stor-
age. Mathematics of Computation, 35(151):773–782, July.
F. J. Och and H. Ney. 2003. A systematic comparison of various statis-
tical alignment models. Computational Linguistics, 29(1):19–51.
F. J. Och. 2003. Minimum error rate training in statistical machine
translation. In Proc. ACL-03, pages 160–167, Sapporo, Japan, July.
K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002. BLEU: a
method for automatic evaluation of machine translation. In Proc.
ACL-02, pages 311–318, Philadelphia, PA, July.
S. M. Shieber. 1988. A uniform architecture for parsing and generation.
In Proc. COLING-88, pages 614–619, Budapest, Hungary.
S. M. Shieber. 1993. The problem of logical-form equivalence. Com-
putational Linguistics, 19(1):179–190.
A. Stolcke. 2002. SRILM—an extensible language modeling toolkit.
In Proc. ICSLP-02, pages 901–904, Denver, CO.
M. White and J. Baldridge. 2003. Adapting chart realization to CCG.
In Proc. EWNLG-03, Budapest, Hungary, April.
M. White. 2004. Reining in CCG chart realization. In Proc. INLG-04,
New Forest, UK, July.
P. Whitelock. 1992. Shake-and-bake translation. In Proc. COLING-92,
pages 784–791, Nantes, France.
Y. W. Wong and R. J. Mooney. 2006. Learning for semantic parsing
with statistical machine translation. In Proc. HLT/NAACL-06, pages
439–446, New York City, NY, June.
</reference>
<page confidence="0.99881">
179
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.792356">
<title confidence="0.998082">Generation by Inverting a Semantic Parser That Statistical Machine Translation</title>
<author confidence="0.999844">Yuk Wah Wong</author>
<author confidence="0.999844">J Raymond</author>
<affiliation confidence="0.999232">Department of Computer The University of Texas at 1 University Station</affiliation>
<address confidence="0.838511">Austin, TX 78712-0233,</address>
<abstract confidence="0.9968800625">This paper explores the use of statistical machine translation (SMT) methods for tactical natural language generation. We present results on using phrase-based SMT for learning to map meaning representations to natural language. Improved results are obtained by inverting a semantic parser that uses SMT methods to map sentences into meaning representations. Finally, we show that hybridizing these two approaches results in still more accurate generation systems. Automatic and human evaluation of generated sentences are presented across two domains and four languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<date>1972</date>
<booktitle>The Theory of Parsing, Translation, and Compiling.</booktitle>
<publisher>Prentice Hall,</publisher>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="7186" citStr="Aho and Ullman, 1972" startWordPosition="1197" endWordPosition="1201">e present a brief overview of WASP (Wong and Mooney, 2006), the SMT-based semantic parser on which this work is based. To describe WASP, it is best to start with an example. Consider the task of translating the English sentence in Figure 1(a) into CLANG. To do this, we may first generate a parse tree of the input sentence. The meaning of the sentence is then obtained by combining the meanings of the phrases. This process can be formalized using a synchronous context-free grammar (SCFG), originally developed as a grammar formalism that combines syntax analysis and code generation in compilers (Aho and Ullman, 1972). It has been used in syntax-based SMT to model the translation of one NL to another (Chiang, 2005). A derivation for a SCFG gives rise to multiple isomorphic parse trees. Figure 2 shows a partial parse of the sample sentence and its corre173 RULE RULE ... ...) If CONDITION ( CONDITION }) player UNUM 4 has the ball (bowner TEAM our { UNUM 4 TEAM our (a) English (b) CLANG Figure 2: Partial parse trees for the CLANG statement and its English gloss shown in Figure 1(a) sponding CLANG parse from which an MR is constructed. Note that the two parse trees are isomorphic (ignoring terminals). Each SCF</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>A. V. Aho and J. D. Ullman. 1972. The Theory of Parsing, Translation, and Compiling. Prentice Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
<author>S Whittaker</author>
</authors>
<title>Evaluation metrics for generation.</title>
<date>2000</date>
<booktitle>In Proc. INLG-00,</booktitle>
<pages>1--8</pages>
<location>Mitzpe Ramon, Israel,</location>
<contexts>
<context position="13234" citStr="Bangalore et al., 2000" startWordPosition="2291" endWordPosition="2295">grammar ensures the grammaticality of all output MRs. For generation, we need an NL grammar to ensure grammaticality, but this is not available a priori. This motivates the noisy-channel model for WASP−1, where Pr(e|f) is divided into two smaller Pr(e) is the language model, and Pr(f|e) is the parsing model. The generation task is to find a sentence e such that (1) e is a good sentence a priori, and (2) its meaning is the same as the input MR. For the language model, we use an n-gram model, which is remarkably useful in ranking candidate generated sentences (Knight and Hatzivassiloglou, 1995; Bangalore et al., 2000; Langkilde-Geary, 2002). For the parsing model, we re-use the one from WASP (Equation 1). Hence computing (2) means maximizing the following: Pr(e) Pr(f|e) Pr(e(d)) Prλ(d|e(d)) Pr(e(d)) · exp Ei Aifi(d) (3) Zλ(e(d)) where D(f) is the set of derivations that are consistent with f, and e(d) is the output sentence that a derivation d yields. Compared to most existing work on generation, WASP−1 has the following characteristics: 1. It does not require any lexical information in the input MR, so lexical selection is an integral part of the decoding algorithm. 2. Each predicate is translated to a p</context>
<context position="25983" citStr="Bangalore et al. (2000)" startWordPosition="4422" endWordPosition="4425">uage-metric pairs, but otherwise performed comparably. 6 Related Work Numerous efforts have been made to unify the tasks of semantic parsing and tactical generation. One of the earliest espousals of the notion of grammar reversability can be found in Kay (1975). Shieber (1988) further noted that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realization—inflecting and ordering words— which ignores the problem of lexical selection. In contrast, our SMT-based methods integrate lexical selection and realization in an elegant f</context>
</contexts>
<marker>Bangalore, Rambow, Whittaker, 2000</marker>
<rawString>S. Bangalore, O. Rambow, and S. Whittaker. 2000. Evaluation metrics for generation. In Proc. INLG-00, pages 1–8, Mitzpe Ramon, Israel, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Belz</author>
<author>E Reiter</author>
</authors>
<title>Comparing automatic and human evaluation of NLG systems.</title>
<date>2006</date>
<booktitle>In Proc. EACL-06,</booktitle>
<pages>313--320</pages>
<location>Trento, Italy,</location>
<contexts>
<context position="21698" citStr="Belz and Reiter, 2006" startWordPosition="3733" endWordPosition="3736">tems) for a given domain-metric pair (p &lt; 0.05) 5.1 Automatic Evaluation We performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). Both MT metrics measure the precision of a translation in terms of the proportion of n-grams that it shares with the reference translations, with the NIST score focusing more on n-grams that are less frequent and more informative. Both metrics have recently been used to evaluate generators (Langkilde-Geary, 2002; Nakanishi et al., 2005; Belz and Reiter, 2006). All systems were able to generate sentences for more than 97% of the input. Figure 4 shows some sample output of the systems. Table 1 shows the automatic evaluation results. Paired t-tests were used to measure statistical significance. A few observations can be made. First, WASP−1 produced a more accurate generator than PHARAOH. Second, PHARAOH++ significantly outperformed PHARAOH, showing the importance of exploiting the formal structure of the MRL. Third, WASP−1++ significantly outperformed WASP−1. Most of the gain came from PHARAOH’s probabilistic model. Decoding was also 4–11 times faste</context>
<context position="23712" citStr="Belz and Reiter, 2006" startWordPosition="4055" endWordPosition="4058">s, so the advantage of WASP−1++ over PHARAOH++ was not as obvious. Our BLEU scores are not as high as those reported in Langkilde-Geary (2002) and Nakanishi et al. (2005), which are around 0.7–0.9. However, their work involves the regeneration of automatically parsed text, and the MRs that they use, which are essentially dependency parses, contain extensive lexical information of the target NL. 5.2 Human Evaluation Automatic evaluation is only an imperfect substitute for human assessment. While it is found that BLEU and NIST correlate quite well with human judgments in evaluating NLG systems (Belz and Reiter, 2006), it is best to support these figures with human evaluation, which we did on a small scale. We recruited 4 native speakers of English with no previous experience with the ROBOCUP and GEOQUERY domains. Each subject was given the same 20 sentences for each domain, randomly chosen from the test sets. For each sentence, the subjects were asked to judge the output of PHARAOH++ and WASP−1++ in terms of fluency and adequacy. They were presented with the following definition, adapted from Koehn and Monz (2006): Fluency Adequacy Flawless English All meaning Most meaning Some meaning PHARAOH++ WASP−1++ </context>
</contexts>
<marker>Belz, Reiter, 2006</marker>
<rawString>A. Belz and E. Reiter. 2006. Comparing automatic and human evaluation of NLG systems. In Proc. EACL-06, pages 313–320, Trento, Italy, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J Della Pietra</author>
<author>S A Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="6062" citStr="Brown et al., 1993" startWordPosition="1001" endWordPosition="1004">G and MT are switched. We first consider using a phrase-based SMT system, PHARAOH, for NLG. Then we show how to invert an SMT-based semantic parser, WASP, to produce a more effective generation system. 3.1 Generation using PHARAOH PHARAOH (Koehn et al., 2003) is an SMT system that uses phrases as basic translation units. During decoding, the source sentence is segmented into a sequence of phrases. These phrases are then reordered and translated into phrases in the target language, which are joined together to form the output sentence. Compared to earlier word-based methods such as IBM Models (Brown et al., 1993), phrasebased methods such as PHARAOH are much more effective in producing idiomatic translations, and are currently the best performing methods in SMT (Koehn and Monz, 2006). To use PHARAOH for NLG, we simply treat the source MRL as an NL, so that phrases in the MRL are sequences of MR tokens. Note that the grammaticality of MRs is not an issue here, as they are given as input. 3.2 WASP: The Semantic Parsing Algorithm Before showing how generation can be performed by inverting a semantic parser, we present a brief overview of WASP (Wong and Mooney, 2006), the SMT-based semantic parser on whic</context>
<context position="8986" citStr="Brown et al., 1993" startWordPosition="1536" endWordPosition="1539">pair of co-indexed start symbols of the MRL grammar, (51 , 51 ), and each step involves the rewriting of a pair of co-indexed non-terminals (by α and Q, respectively). Given an input sentence, e, the task of semantic parsing is to find a derivation that yields (e, f), so that f is an MR translation of e. Parsing with WASP requires a set of SCFG rules. These rules are learned using a word alignment model, which finds an optimal mapping from words to MR predicates given a set of training sentences and their correct MRs. Word alignment models have been widely used for lexical acquisition in SMT (Brown et al., 1993; Koehn et al., 2003). To use a word alignment model in the semantic parsing scenario, we can treat the MRL simply as an NL, and MR tokens as words, but this often leads to poor results. First, not all MR tokens carry specific meanings. For example, in CLANG, parentheses and braces are delimiters that are semantically vacuous. Such tokens can easily confuse the word alignment model. Second, MR tokens may exhibit polysemy. For example, the CLANG predicate pt has three meanings based on the types of arguments it is given (Chen et al., 2003). Judging from the pt token alone, the word alignment mo</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, V. J. Della Pietra, S. A. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–312, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>S Oepen</author>
</authors>
<title>High efficiency realization for a widecoverage unification grammar.</title>
<date>2005</date>
<booktitle>In Proc. IJCNLP-05,</booktitle>
<pages>165--176</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="26298" citStr="Carroll and Oepen (2005)" startWordPosition="4470" endWordPosition="4473"> grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realization—inflecting and ordering words— which ignores the problem of lexical selection. In contrast, our SMT-based methods integrate lexical selection and realization in an elegant framework and automatically learn all of their linguistic knowledge from an annotated corpus. 7 Conclusion We have presented four tactical generation systems based on various SMT-based methods. In particular, the hybrid system produced by inverting the WASP semantic parser shows the best overall results across diff</context>
</contexts>
<marker>Carroll, Oepen, 2005</marker>
<rawString>J. Carroll and S. Oepen. 2005. High efficiency realization for a widecoverage unification grammar. In Proc. IJCNLP-05, pages 165–176, Jeju Island, Korea, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>V Pozna´nski</author>
</authors>
<title>An efficient chart generator for (semi-)lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proc. EWNLG-99,</booktitle>
<pages>86--95</pages>
<location>Toulouse, France.</location>
<marker>Carroll, Copestake, Flickinger, Pozna´nski, 1999</marker>
<rawString>J. Carroll, A. Copestake, D. Flickinger, and V. Pozna´nski. 1999. An efficient chart generator for (semi-)lexicalist grammars. In Proc. EWNLG-99, pages 86–95, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chen</author>
</authors>
<title>Users manual: RoboCup soccer server manual for soccer server version 7.07 and later. Available at http: //sourceforge.net/projects/sserver/.</title>
<date>2003</date>
<marker>Chen, 2003</marker>
<rawString>M. Chen et al. 2003. Users manual: RoboCup soccer server manual for soccer server version 7.07 and later. Available at http: //sourceforge.net/projects/sserver/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. ACL-05,</booktitle>
<pages>263--270</pages>
<location>Ann Arbor, MI,</location>
<contexts>
<context position="7285" citStr="Chiang, 2005" startWordPosition="1218" endWordPosition="1220">k is based. To describe WASP, it is best to start with an example. Consider the task of translating the English sentence in Figure 1(a) into CLANG. To do this, we may first generate a parse tree of the input sentence. The meaning of the sentence is then obtained by combining the meanings of the phrases. This process can be formalized using a synchronous context-free grammar (SCFG), originally developed as a grammar formalism that combines syntax analysis and code generation in compilers (Aho and Ullman, 1972). It has been used in syntax-based SMT to model the translation of one NL to another (Chiang, 2005). A derivation for a SCFG gives rise to multiple isomorphic parse trees. Figure 2 shows a partial parse of the sample sentence and its corre173 RULE RULE ... ...) If CONDITION ( CONDITION }) player UNUM 4 has the ball (bowner TEAM our { UNUM 4 TEAM our (a) English (b) CLANG Figure 2: Partial parse trees for the CLANG statement and its English gloss shown in Figure 1(a) sponding CLANG parse from which an MR is constructed. Note that the two parse trees are isomorphic (ignoring terminals). Each SCFG rule consists of a non-terminal, X, on the left-hand side (LHS), and a pair of strings, (α, Q), o</context>
<context position="19390" citStr="Chiang (2005)" startWordPosition="3345" endWordPosition="3347">nimum error-rate training (Och, 2003). Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al., 2003). The reason is that while word gaps are useful in dealing with unknown phrases during semantic parsing, for generation, using known phrases generally leads to better fluency. For the same reason, we also allow the extraction of longer phrases that correspond to multiple predicates (but no more than 5). We call the resulting hybrid system WASP−1++. It is similar to the syntax-based SMT system of Chiang (2005), which uses both SCFG and PHARAOH’s probabilistic model. The main difference is that we use the MRL grammar to constrain rule extraction, so that significantly fewer rules are extracted, making it possible to do exact inference. 5 Experiments We evaluated all four SMT-based NLG systems introduced in this paper: PHARAOH, WASP−1, and the hybrid systems, PHARAOH++ and WASP−1++. We used the ROBOCUP and GEOQUERY corpora in our experiments. The ROBOCUP corpus consists of 300 pieces of coach advice taken from the log files of the 2003 ROBOCUP Coach Competition. The advice was written in CLANG and ma</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>D. Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proc. ACL-05, pages 263–270, Ann Arbor, MI, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
</authors>
<title>Automatic evaluation of machine translation quality using n-gram co-occurrence statistics.</title>
<date>2002</date>
<booktitle>In Proc. ARPA Workshop on Human Language Technology,</booktitle>
<pages>128--132</pages>
<location>San Diego, CA.</location>
<contexts>
<context position="21335" citStr="Doddington, 2002" startWordPosition="3675" endWordPosition="3676">our goal line ... Figure 4: Sample partial system output in the ROBOCUP domain ROBOCUP GEOQUERY BLEU NIST BLEU NIST PHARAOH 0.3247 5.0263 0.2070 3.1478 WASP−1 0.4357 5.4486 0.4582 5.9900 PHARAOH++ 0.4336 5.9185 0.5354 6.3637 WASP−1++ 0.6022 6.8976 0.5370 6.4808 Table 1: Results of automatic evaluation; bold type indicates the best performing system (or systems) for a given domain-metric pair (p &lt; 0.05) 5.1 Automatic Evaluation We performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). Both MT metrics measure the precision of a translation in terms of the proportion of n-grams that it shares with the reference translations, with the NIST score focusing more on n-grams that are less frequent and more informative. Both metrics have recently been used to evaluate generators (Langkilde-Geary, 2002; Nakanishi et al., 2005; Belz and Reiter, 2006). All systems were able to generate sentences for more than 97% of the input. Figure 4 shows some sample output of the systems. Table 1 shows the automatic evaluation results. Paired t-tests were used to measure statistical significance.</context>
</contexts>
<marker>Doddington, 2002</marker>
<rawString>G. Doddington. 2002. Automatic evaluation of machine translation quality using n-gram co-occurrence statistics. In Proc. ARPA Workshop on Human Language Technology, pages 128–132, San Diego, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Germann</author>
</authors>
<title>Greedy decoding for statistical machine translation in almost linear time.</title>
<date>2003</date>
<booktitle>In Proc. HLT/NAACL-03,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1607" citStr="Germann, 2003" startWordPosition="245" endWordPosition="246">the task of mapping statements in a formal meaning representation language (MRL) into a natural language (NL), i.e. tactical generation. Given a corpus of NL sentences each paired with a formal meaning representation (MR), it is easy to use SMT to construct a tactical generator, i.e. a statistical model that translates MRL to NL. However, there has been little, if any, research on exploiting recent SMT methods for NLG. In this paper we present results on using a recent phrase-based SMT system, PHARAOH (Koehn et al., 2003), for NLG.1 Although moderately effec1We also tried IBM Model 4/REWRITE (Germann, 2003), a word-based SMT system, but it gave much worse results. tive, the inability of PHARAOH to exploit the formal structure and grammar of the MRL limits its accuracy. Unlike natural languages, MRLs typically have a simple, formal syntax to support effective automated processing and inference. This MRL structure can also be used to improve language generation. Tactical generation can also be seen as the inverse of semantic parsing, the task of mapping NL sentences to MRs. In this paper, we show how to “invert” a recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce </context>
</contexts>
<marker>Germann, 2003</marker>
<rawString>U. Germann. 2003. Greedy decoding for statistical machine translation in almost linear time. In Proc. HLT/NAACL-03, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P S Jacobs</author>
</authors>
<title>PHRED: A generator for natural language interfaces.</title>
<date>1985</date>
<journal>Computational Linguistics,</journal>
<volume>11</volume>
<issue>4</issue>
<contexts>
<context position="2682" citStr="Jacobs, 1985" startWordPosition="434" endWordPosition="435">ces to MRs. In this paper, we show how to “invert” a recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce a more effective generation system. WASP exploits the formal syntax of the MRL by learning a translator (based on a statistical synchronous contextfree grammar) that maps an NL sentence to a linearized parse-tree of its MR rather than to a flat MR string. In addition to exploiting the formal MRL grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (Kay, 1975; Jacobs, 1985; Shieber, 1988). We present experimental results in two domains previously used to test WASP’s semantic parsing ability: mapping NL queries to a formal database query language, and mapping NL soccer coaching instructions to a formal robot command language. WASP−1 is shown to produce a more accurate NL generator than PHARAOH. We also show how the idea of generating from linearized parse-trees rather than flat MRs, used effectively in WASP−1, can also be exploited in PHARAOH. A version of PHARAOH that exploits this approach is experimentally shown to produce more accurate generators that are mo</context>
</contexts>
<marker>Jacobs, 1985</marker>
<rawString>P. S. Jacobs. 1985. PHRED: A generator for natural language interfaces. Computational Linguistics, 11(4):219–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning to transform natural to formal languages. In</title>
<date>2005</date>
<booktitle>Proc. AAAI-05,</booktitle>
<pages>1062--1068</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="5109" citStr="Kate et al., 2005" startWordPosition="835" endWordPosition="838"> ground our discussion, we consider two application domains which were originally used to demonstrate semantic parsing. The first domain is ROBOCUP. In the ROBOCUP Coach Competition (www.robocup.org), teams of agents compete in a simulated soccer game and receive coach advice written in a formal language called CLANG (Chen et al., 2003). The task is to build a system that translates this formal advice into English. Figure 1(a) shows a piece of sample advice. The second domain is GEOQUERY, where a functional, variable-free query language is used for querying a small database on U.S. geography (Kate et al., 2005). The task is to translate formal queries into NL. Figure 1(b) shows a sample query. 3 Generation using SMT Methods In this section, we show how SMT methods can be used to construct a tactical generator. This is in contrast to existing work that focuses on the use of NLG in interlingual MT (Whitelock, 1992), in which the roles of NLG and MT are switched. We first consider using a phrase-based SMT system, PHARAOH, for NLG. Then we show how to invert an SMT-based semantic parser, WASP, to produce a more effective generation system. 3.1 Generation using PHARAOH PHARAOH (Koehn et al., 2003) is an </context>
<context position="20343" citStr="Kate et al., 2005" startWordPosition="3498" endWordPosition="3501">the hybrid systems, PHARAOH++ and WASP−1++. We used the ROBOCUP and GEOQUERY corpora in our experiments. The ROBOCUP corpus consists of 300 pieces of coach advice taken from the log files of the 2003 ROBOCUP Coach Competition. The advice was written in CLANG and manually translated to English (Kuhlmann et al., 2004). The average MR length is 29.47 tokens, or 12.82 nodes for linearized parse-trees. The average sentence length is 22.52. The GEOQUERY corpus consists of 880 English questions gathered from various sources. The questions were manually translated to the functional GEOQUERY language (Kate et al., 2005). The average MR length is 17.55 tokens, or 5.55 nodes for linearized parse-trees. The average sentence length is 7.57. Reference: If our player 2, 3, 7 or 5 has the ball and the ball is close to our goal line ... PHARAOH++: Ifplayer 3 has the ball is in 2 5 the ball is in the area near our goal line ... WASP−1++: If players 2, 3, 7 and 5 has the ball and the ball is near our goal line ... Figure 4: Sample partial system output in the ROBOCUP domain ROBOCUP GEOQUERY BLEU NIST BLEU NIST PHARAOH 0.3247 5.0263 0.2070 3.1478 WASP−1 0.4357 5.4486 0.4582 5.9900 PHARAOH++ 0.4336 5.9185 0.5354 6.3637 </context>
</contexts>
<marker>Kate, Wong, Mooney, 2005</marker>
<rawString>R. J. Kate, Y. W. Wong, and R. J. Mooney. 2005. Learning to transform natural to formal languages. In Proc. AAAI-05, pages 1062–1068, Pittsburgh, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Syntactic processing and functional sentence perspective.</title>
<date>1975</date>
<booktitle>In Theoretical Issues in Natural Language Processing— Supplement to the Proceedings,</booktitle>
<pages>12--15</pages>
<location>Cambridge, MA,</location>
<contexts>
<context position="2668" citStr="Kay, 1975" startWordPosition="432" endWordPosition="433">g NL sentences to MRs. In this paper, we show how to “invert” a recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce a more effective generation system. WASP exploits the formal syntax of the MRL by learning a translator (based on a statistical synchronous contextfree grammar) that maps an NL sentence to a linearized parse-tree of its MR rather than to a flat MR string. In addition to exploiting the formal MRL grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (Kay, 1975; Jacobs, 1985; Shieber, 1988). We present experimental results in two domains previously used to test WASP’s semantic parsing ability: mapping NL queries to a formal database query language, and mapping NL soccer coaching instructions to a formal robot command language. WASP−1 is shown to produce a more accurate NL generator than PHARAOH. We also show how the idea of generating from linearized parse-trees rather than flat MRs, used effectively in WASP−1, can also be exploited in PHARAOH. A version of PHARAOH that exploits this approach is experimentally shown to produce more accurate generato</context>
<context position="25621" citStr="Kay (1975)" startWordPosition="4364" endWordPosition="4365">0-example data set is a subset of the larger GEOQUERY corpus. All English questions in this data set were manually translated into Spanish, Japanese and Turkish, while the corresponding MRs remain unchanged. Table 3 shows the results, which are similar to previous results on the larger GEOQUERY corpus. WASP−1++ outperformed PHARAOH++ for some language-metric pairs, but otherwise performed comparably. 6 Related Work Numerous efforts have been made to unify the tasks of semantic parsing and tactical generation. One of the earliest espousals of the notion of grammar reversability can be found in Kay (1975). Shieber (1988) further noted that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart gene</context>
</contexts>
<marker>Kay, 1975</marker>
<rawString>M. Kay. 1975. Syntactic processing and functional sentence perspective. In Theoretical Issues in Natural Language Processing— Supplement to the Proceedings, pages 12–15, Cambridge, MA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Chart generation.</title>
<date>1996</date>
<booktitle>In Proc. ACL-96,</booktitle>
<pages>200--204</pages>
<location>San Francisco, CA.</location>
<contexts>
<context position="12328" citStr="Kay, 1996" startWordPosition="2135" endWordPosition="2136"> decoding task is thus to find a derivation d⋆ that maximizes Prλ(d⋆|e), and the output MR translation, f⋆, is the yield of d⋆. This can be done in cubic time with respect to the length of e using an Earley chart parser. 3.3 Generation by Inverting WASP Now we show how to invert WASP to produce WASP−1, and use it for NLG. We can use the same grammar for both parsing and generation, a particularly appealing aspect of using WASP. Since an SCFG is fully symmetric with respect to both generated strings, the same chart used for parsing can be easily adapted for efficient generation (Shieber, 1988; Kay, 1996). Given an input MR, f, WASP−1 finds a sentence e that maximizes Pr(e|f). It is difficult to directly model Pr(e|f), however, because it has to assign low probabilities to output sentences that are not grammatical. There is no such requirement for parsing, because the use of the MRL grammar ensures the grammaticality of all output MRs. For generation, we need an NL grammar to ensure grammaticality, but this is not available a priori. This motivates the noisy-channel model for WASP−1, where Pr(e|f) is divided into two smaller Pr(e) is the language model, and Pr(f|e) is the parsing model. The ge</context>
<context position="25807" citStr="Kay (1996)" startWordPosition="4395" endWordPosition="4396">MRs remain unchanged. Table 3 shows the results, which are similar to previous results on the larger GEOQUERY corpus. WASP−1++ outperformed PHARAOH++ for some language-metric pairs, but otherwise performed comparably. 6 Related Work Numerous efforts have been made to unify the tasks of semantic parsing and tactical generation. One of the earliest espousals of the notion of grammar reversability can be found in Kay (1975). Shieber (1988) further noted that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realizati</context>
</contexts>
<marker>Kay, 1996</marker>
<rawString>M. Kay. 1996. Chart generation. In Proc. ACL-96, pages 200–204, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Two-level, many-paths generation.</title>
<date>1995</date>
<booktitle>In Proc. ACL-95,</booktitle>
<pages>252--260</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="13210" citStr="Knight and Hatzivassiloglou, 1995" startWordPosition="2287" endWordPosition="2290">arsing, because the use of the MRL grammar ensures the grammaticality of all output MRs. For generation, we need an NL grammar to ensure grammaticality, but this is not available a priori. This motivates the noisy-channel model for WASP−1, where Pr(e|f) is divided into two smaller Pr(e) is the language model, and Pr(f|e) is the parsing model. The generation task is to find a sentence e such that (1) e is a good sentence a priori, and (2) its meaning is the same as the input MR. For the language model, we use an n-gram model, which is remarkably useful in ranking candidate generated sentences (Knight and Hatzivassiloglou, 1995; Bangalore et al., 2000; Langkilde-Geary, 2002). For the parsing model, we re-use the one from WASP (Equation 1). Hence computing (2) means maximizing the following: Pr(e) Pr(f|e) Pr(e(d)) Prλ(d|e(d)) Pr(e(d)) · exp Ei Aifi(d) (3) Zλ(e(d)) where D(f) is the set of derivations that are consistent with f, and e(d) is the output sentence that a derivation d yields. Compared to most existing work on generation, WASP−1 has the following characteristics: 1. It does not require any lexical information in the input MR, so lexical selection is an integral part of the decoding algorithm. 2. Each predic</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>K. Knight and V. Hatzivassiloglou. 1995. Two-level, many-paths generation. In Proc. ACL-95, pages 252–260, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>C Monz</author>
</authors>
<title>Manual and automatic evaluation of machine translation between European languages.</title>
<date>2006</date>
<booktitle>In Proc. SMT-06 Workshop,</booktitle>
<pages>102--121</pages>
<location>New York City, NY,</location>
<contexts>
<context position="6236" citStr="Koehn and Monz, 2006" startWordPosition="1028" endWordPosition="1031"> effective generation system. 3.1 Generation using PHARAOH PHARAOH (Koehn et al., 2003) is an SMT system that uses phrases as basic translation units. During decoding, the source sentence is segmented into a sequence of phrases. These phrases are then reordered and translated into phrases in the target language, which are joined together to form the output sentence. Compared to earlier word-based methods such as IBM Models (Brown et al., 1993), phrasebased methods such as PHARAOH are much more effective in producing idiomatic translations, and are currently the best performing methods in SMT (Koehn and Monz, 2006). To use PHARAOH for NLG, we simply treat the source MRL as an NL, so that phrases in the MRL are sequences of MR tokens. Note that the grammaticality of MRs is not an issue here, as they are given as input. 3.2 WASP: The Semantic Parsing Algorithm Before showing how generation can be performed by inverting a semantic parser, we present a brief overview of WASP (Wong and Mooney, 2006), the SMT-based semantic parser on which this work is based. To describe WASP, it is best to start with an example. Consider the task of translating the English sentence in Figure 1(a) into CLANG. To do this, we m</context>
<context position="24219" citStr="Koehn and Monz (2006)" startWordPosition="4142" endWordPosition="4145">und that BLEU and NIST correlate quite well with human judgments in evaluating NLG systems (Belz and Reiter, 2006), it is best to support these figures with human evaluation, which we did on a small scale. We recruited 4 native speakers of English with no previous experience with the ROBOCUP and GEOQUERY domains. Each subject was given the same 20 sentences for each domain, randomly chosen from the test sets. For each sentence, the subjects were asked to judge the output of PHARAOH++ and WASP−1++ in terms of fluency and adequacy. They were presented with the following definition, adapted from Koehn and Monz (2006): Fluency Adequacy Flawless English All meaning Most meaning Some meaning PHARAOH++ WASP−1++ BLEU NIST BLEU NIST English 0.5344 5.3289 0.6035 5.7133 Spanish 0.6042 5.6321 0.6175 5.7293 Japanese 0.6171 4.5357 0.6585 4.6648 Turkish 0.4562 4.2220 0.4824 4.3283 Table 3: Results of automatic evaluation on the multilingual GEOQUERY data set Fluency Adequacy 2 1 For each generated sentence, we computed the average of the 4 human judges’ scores. No score normalization was performed. Then we compared the two systems using a paired t-test. Table 2 shows that WASP−1++ produced better generators than PHAR</context>
</contexts>
<marker>Koehn, Monz, 2006</marker>
<rawString>P. Koehn and C. Monz. 2006. Manual and automatic evaluation of machine translation between European languages. In Proc. SMT-06 Workshop, pages 102–121, New York City, NY, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. HLT/NAACL-03,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="1520" citStr="Koehn et al., 2003" startWordPosition="230" endWordPosition="233">stical machine translation (SMT) methods in natural language generation (NLG), specifically the task of mapping statements in a formal meaning representation language (MRL) into a natural language (NL), i.e. tactical generation. Given a corpus of NL sentences each paired with a formal meaning representation (MR), it is easy to use SMT to construct a tactical generator, i.e. a statistical model that translates MRL to NL. However, there has been little, if any, research on exploiting recent SMT methods for NLG. In this paper we present results on using a recent phrase-based SMT system, PHARAOH (Koehn et al., 2003), for NLG.1 Although moderately effec1We also tried IBM Model 4/REWRITE (Germann, 2003), a word-based SMT system, but it gave much worse results. tive, the inability of PHARAOH to exploit the formal structure and grammar of the MRL limits its accuracy. Unlike natural languages, MRLs typically have a simple, formal syntax to support effective automated processing and inference. This MRL structure can also be used to improve language generation. Tactical generation can also be seen as the inverse of semantic parsing, the task of mapping NL sentences to MRs. In this paper, we show how to “invert”</context>
<context position="5702" citStr="Koehn et al., 2003" startWordPosition="940" endWordPosition="943">graphy (Kate et al., 2005). The task is to translate formal queries into NL. Figure 1(b) shows a sample query. 3 Generation using SMT Methods In this section, we show how SMT methods can be used to construct a tactical generator. This is in contrast to existing work that focuses on the use of NLG in interlingual MT (Whitelock, 1992), in which the roles of NLG and MT are switched. We first consider using a phrase-based SMT system, PHARAOH, for NLG. Then we show how to invert an SMT-based semantic parser, WASP, to produce a more effective generation system. 3.1 Generation using PHARAOH PHARAOH (Koehn et al., 2003) is an SMT system that uses phrases as basic translation units. During decoding, the source sentence is segmented into a sequence of phrases. These phrases are then reordered and translated into phrases in the target language, which are joined together to form the output sentence. Compared to earlier word-based methods such as IBM Models (Brown et al., 1993), phrasebased methods such as PHARAOH are much more effective in producing idiomatic translations, and are currently the best performing methods in SMT (Koehn and Monz, 2006). To use PHARAOH for NLG, we simply treat the source MRL as an NL,</context>
<context position="9007" citStr="Koehn et al., 2003" startWordPosition="1540" endWordPosition="1543">tart symbols of the MRL grammar, (51 , 51 ), and each step involves the rewriting of a pair of co-indexed non-terminals (by α and Q, respectively). Given an input sentence, e, the task of semantic parsing is to find a derivation that yields (e, f), so that f is an MR translation of e. Parsing with WASP requires a set of SCFG rules. These rules are learned using a word alignment model, which finds an optimal mapping from words to MR predicates given a set of training sentences and their correct MRs. Word alignment models have been widely used for lexical acquisition in SMT (Brown et al., 1993; Koehn et al., 2003). To use a word alignment model in the semantic parsing scenario, we can treat the MRL simply as an NL, and MR tokens as words, but this often leads to poor results. First, not all MR tokens carry specific meanings. For example, in CLANG, parentheses and braces are delimiters that are semantically vacuous. Such tokens can easily confuse the word alignment model. Second, MR tokens may exhibit polysemy. For example, the CLANG predicate pt has three meanings based on the types of arguments it is given (Chen et al., 2003). Judging from the pt token alone, the word alignment model would not be able</context>
<context position="17191" citStr="Koehn et al., 2003" startWordPosition="2983" endWordPosition="2986">. We use n = 2 since higher values seemed to cause overfitting in our domains. Next, the parsing model is trained as described in Section 3.2. 4 Improving the SMT-based Generators The SMT-based generation algorithms, PHARAOH and WASP−1, while reasonably effective, can be substantially improved by borrowing ideas from each other. 4.1 Improving the PHARAOH-based Generator A major weakness of PHARAOH as an NLG system is its inability to exploit the formal structure of the MRL. Like WASP−1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++ (Koehn et al., 2003), which performs poorly when applied directly to MRLs (Section 3.2). We can improve the PHARAOH-based generator by supplying linearized parse-trees as input rather than flat MRs. As a result, the basic translation units are sequences of MRL productions, rather than sequences of MR tokens. This way PHARAOH can exploit the formal grammar of the MRL to produce high-quality phrase pairs. The same idea is used in WASP−1 to produce high-quality SCFG rules. We call the resulting hybrid NLG system PHARAOH++. 4.2 Improving the WASP-based Generator There are several aspects of PHARAOH that can be used t</context>
<context position="18427" citStr="Koehn et al., 2003" startWordPosition="3188" endWordPosition="3191"> First, the probabilistic model of WASP−1 is less than ideal as it requires an extra re-ranking step for normalization, which is expensive and prone to over-pruning. To remedy this situation, we can borrow the probabilistic model of PHARAOH, and define the parsing model as: Pr(d|e(d)) = � w(r(d)) (4) dEd which is the product of the weights of the rules used in a derivation d. The rule weight, w(X —* (α, 0)), is in turn defined as: P(0|α)λ1P(α|0)λ2Pw(0|α)λ3Pw(α|0)λ4 exp(−|α|)λ5 where P(0|α) and P(α|0) are the relative frequencies of 0 and α, and Pw(0|α) and Pw(α|0) are 176 the lexical weights (Koehn et al., 2003). The word penalty, exp(−|α|), allows some control over the output sentence length. Together with the language model, the new formulation of Pr(e|f) is a loglinear model with AZ as parameters. The advantage of this model is that maximization requires no normalization and can be done exactly and efficiently. The model parameters are trained using minimum error-rate training (Och, 2003). Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al., 2003). The reason is that while word gaps are useful i</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proc. HLT/NAACL-03, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kuhlmann</author>
<author>P Stone</author>
<author>R J Mooney</author>
<author>J W Shavlik</author>
</authors>
<title>Guiding a reinforcement learner with natural language advice: Initial results in RoboCup soccer.</title>
<date>2004</date>
<booktitle>In Proc. of the AAAI-04 Workshop on Supervisory Control of Learning and Adaptive Systems,</booktitle>
<location>San Jose, CA,</location>
<contexts>
<context position="20042" citStr="Kuhlmann et al., 2004" startWordPosition="3451" endWordPosition="3454">RAOH’s probabilistic model. The main difference is that we use the MRL grammar to constrain rule extraction, so that significantly fewer rules are extracted, making it possible to do exact inference. 5 Experiments We evaluated all four SMT-based NLG systems introduced in this paper: PHARAOH, WASP−1, and the hybrid systems, PHARAOH++ and WASP−1++. We used the ROBOCUP and GEOQUERY corpora in our experiments. The ROBOCUP corpus consists of 300 pieces of coach advice taken from the log files of the 2003 ROBOCUP Coach Competition. The advice was written in CLANG and manually translated to English (Kuhlmann et al., 2004). The average MR length is 29.47 tokens, or 12.82 nodes for linearized parse-trees. The average sentence length is 22.52. The GEOQUERY corpus consists of 880 English questions gathered from various sources. The questions were manually translated to the functional GEOQUERY language (Kate et al., 2005). The average MR length is 17.55 tokens, or 5.55 nodes for linearized parse-trees. The average sentence length is 7.57. Reference: If our player 2, 3, 7 or 5 has the ball and the ball is close to our goal line ... PHARAOH++: Ifplayer 3 has the ball is in 2 5 the ball is in the area near our goal li</context>
</contexts>
<marker>Kuhlmann, Stone, Mooney, Shavlik, 2004</marker>
<rawString>G. Kuhlmann, P. Stone, R. J. Mooney, and J. W. Shavlik. 2004. Guiding a reinforcement learner with natural language advice: Initial results in RoboCup soccer. In Proc. of the AAAI-04 Workshop on Supervisory Control of Learning and Adaptive Systems, San Jose, CA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a general-purpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proc. INLG-02,</booktitle>
<pages>17--24</pages>
<location>Harriman, NY,</location>
<contexts>
<context position="13258" citStr="Langkilde-Geary, 2002" startWordPosition="2296" endWordPosition="2297">maticality of all output MRs. For generation, we need an NL grammar to ensure grammaticality, but this is not available a priori. This motivates the noisy-channel model for WASP−1, where Pr(e|f) is divided into two smaller Pr(e) is the language model, and Pr(f|e) is the parsing model. The generation task is to find a sentence e such that (1) e is a good sentence a priori, and (2) its meaning is the same as the input MR. For the language model, we use an n-gram model, which is remarkably useful in ranking candidate generated sentences (Knight and Hatzivassiloglou, 1995; Bangalore et al., 2000; Langkilde-Geary, 2002). For the parsing model, we re-use the one from WASP (Equation 1). Hence computing (2) means maximizing the following: Pr(e) Pr(f|e) Pr(e(d)) Prλ(d|e(d)) Pr(e(d)) · exp Ei Aifi(d) (3) Zλ(e(d)) where D(f) is the set of derivations that are consistent with f, and e(d) is the output sentence that a derivation d yields. Compared to most existing work on generation, WASP−1 has the following characteristics: 1. It does not require any lexical information in the input MR, so lexical selection is an integral part of the decoding algorithm. 2. Each predicate is translated to a phrase. Moreover, it need</context>
<context position="21650" citStr="Langkilde-Geary, 2002" startWordPosition="3727" endWordPosition="3728">pe indicates the best performing system (or systems) for a given domain-metric pair (p &lt; 0.05) 5.1 Automatic Evaluation We performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). Both MT metrics measure the precision of a translation in terms of the proportion of n-grams that it shares with the reference translations, with the NIST score focusing more on n-grams that are less frequent and more informative. Both metrics have recently been used to evaluate generators (Langkilde-Geary, 2002; Nakanishi et al., 2005; Belz and Reiter, 2006). All systems were able to generate sentences for more than 97% of the input. Figure 4 shows some sample output of the systems. Table 1 shows the automatic evaluation results. Paired t-tests were used to measure statistical significance. A few observations can be made. First, WASP−1 produced a more accurate generator than PHARAOH. Second, PHARAOH++ significantly outperformed PHARAOH, showing the importance of exploiting the formal structure of the MRL. Third, WASP−1++ significantly outperformed WASP−1. Most of the gain came from PHARAOH’s probabi</context>
<context position="23232" citStr="Langkilde-Geary (2002)" startWordPosition="3983" endWordPosition="3984">1++ allows discontiguous NL phrases and PHARAOH++ does not. Such phrases are commonly used in ROBOCUP for constructions like: players 2 , 3 , 7 and 5; 26.96% of the phrases generated during testing were discontiguous. When faced with such predicates, PHARAOH++ would consistently omit some of the words: e.g. players 2 3 7 5, or not learn any phrases for those predicates at all. On the other hand, only 4.47% of the phrases generated during testing for GEOQUERY were discontiguous, so the advantage of WASP−1++ over PHARAOH++ was not as obvious. Our BLEU scores are not as high as those reported in Langkilde-Geary (2002) and Nakanishi et al. (2005), which are around 0.7–0.9. However, their work involves the regeneration of automatically parsed text, and the MRs that they use, which are essentially dependency parses, contain extensive lexical information of the target NL. 5.2 Human Evaluation Automatic evaluation is only an imperfect substitute for human assessment. While it is found that BLEU and NIST correlate quite well with human judgments in evaluating NLG systems (Belz and Reiter, 2006), it is best to support these figures with human evaluation, which we did on a small scale. We recruited 4 native speake</context>
</contexts>
<marker>Langkilde-Geary, 2002</marker>
<rawString>I. Langkilde-Geary. 2002. An empirical verification of coverage and correctness for a general-purpose sentence generator. In Proc. INLG-02, pages 17–24, Harriman, NY, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>A complete, efficient sentence-realization algorithm for unification grammar.</title>
<date>2002</date>
<booktitle>In Proc. INLG-02,</booktitle>
<pages>41--48</pages>
<location>Harriman, NY,</location>
<contexts>
<context position="4008" citStr="Moore (2002)" startWordPosition="649" endWordPosition="650">r, NY, April 2007. c�2007 Association for Computational Linguistics ((bowner our {4}) (do our {6} (pos (left (half our))))) If our player 4 has the ball, then our player 6 should stay in the left side of our half. (a) CLANG answer(state(traverse 1(riverid(’ohio’)))) What states does the Ohio run through? (b) GEOQUERY Figure 1: Sample meaning representations aspects of PHARAOH’s phrase-based model can be used to improve WASP−1, resulting in a hybrid system whose overall performance is the best. 2 MRLs and Test Domains In this work, we consider input MRs with a hierarchical structure similar to Moore (2002). The only restriction on the MRL is that it be defined by an available unambiguous context-free grammar (CFG), which is true for almost all computer languages. We also assume that the order in which MR predicates appear is relevant, i.e. the order can affect the meaning of the MR. Note that the order in which predicates appear need not be the same as the word order of the target NL, and therefore, the content planner need not know about the target NL grammar (Shieber, 1993). To ground our discussion, we consider two application domains which were originally used to demonstrate semantic parsin</context>
<context position="26006" citStr="Moore (2002)" startWordPosition="4428" endWordPosition="4429">erformed comparably. 6 Related Work Numerous efforts have been made to unify the tasks of semantic parsing and tactical generation. One of the earliest espousals of the notion of grammar reversability can be found in Kay (1975). Shieber (1988) further noted that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realization—inflecting and ordering words— which ignores the problem of lexical selection. In contrast, our SMT-based methods integrate lexical selection and realization in an elegant framework and automatica</context>
</contexts>
<marker>Moore, 2002</marker>
<rawString>R. C. Moore. 2002. A complete, efficient sentence-realization algorithm for unification grammar. In Proc. INLG-02, pages 41–48, Harriman, NY, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Nakanishi</author>
<author>Y Miyao</author>
<author>J Tsujii</author>
</authors>
<title>Probabilistic models for disambiguation of an HPSG-based chart generator.</title>
<date>2005</date>
<booktitle>In Proc. IWPT05,</booktitle>
<pages>93--102</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="21674" citStr="Nakanishi et al., 2005" startWordPosition="3729" endWordPosition="3732">erforming system (or systems) for a given domain-metric pair (p &lt; 0.05) 5.1 Automatic Evaluation We performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). Both MT metrics measure the precision of a translation in terms of the proportion of n-grams that it shares with the reference translations, with the NIST score focusing more on n-grams that are less frequent and more informative. Both metrics have recently been used to evaluate generators (Langkilde-Geary, 2002; Nakanishi et al., 2005; Belz and Reiter, 2006). All systems were able to generate sentences for more than 97% of the input. Figure 4 shows some sample output of the systems. Table 1 shows the automatic evaluation results. Paired t-tests were used to measure statistical significance. A few observations can be made. First, WASP−1 produced a more accurate generator than PHARAOH. Second, PHARAOH++ significantly outperformed PHARAOH, showing the importance of exploiting the formal structure of the MRL. Third, WASP−1++ significantly outperformed WASP−1. Most of the gain came from PHARAOH’s probabilistic model. Decoding w</context>
<context position="23260" citStr="Nakanishi et al. (2005)" startWordPosition="3986" endWordPosition="3989"> phrases and PHARAOH++ does not. Such phrases are commonly used in ROBOCUP for constructions like: players 2 , 3 , 7 and 5; 26.96% of the phrases generated during testing were discontiguous. When faced with such predicates, PHARAOH++ would consistently omit some of the words: e.g. players 2 3 7 5, or not learn any phrases for those predicates at all. On the other hand, only 4.47% of the phrases generated during testing for GEOQUERY were discontiguous, so the advantage of WASP−1++ over PHARAOH++ was not as obvious. Our BLEU scores are not as high as those reported in Langkilde-Geary (2002) and Nakanishi et al. (2005), which are around 0.7–0.9. However, their work involves the regeneration of automatically parsed text, and the MRs that they use, which are essentially dependency parses, contain extensive lexical information of the target NL. 5.2 Human Evaluation Automatic evaluation is only an imperfect substitute for human assessment. While it is found that BLEU and NIST correlate quite well with human judgments in evaluating NLG systems (Belz and Reiter, 2006), it is best to support these figures with human evaluation, which we did on a small scale. We recruited 4 native speakers of English with no previo</context>
<context position="26326" citStr="Nakanishi et al. (2005)" startWordPosition="4475" endWordPosition="4478">ing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realization—inflecting and ordering words— which ignores the problem of lexical selection. In contrast, our SMT-based methods integrate lexical selection and realization in an elegant framework and automatically learn all of their linguistic knowledge from an annotated corpus. 7 Conclusion We have presented four tactical generation systems based on various SMT-based methods. In particular, the hybrid system produced by inverting the WASP semantic parser shows the best overall results across different application domains. A</context>
</contexts>
<marker>Nakanishi, Miyao, Tsujii, 2005</marker>
<rawString>H. Nakanishi, Y. Miyao, and J. Tsujii. 2005. Probabilistic models for disambiguation of an HPSG-based chart generator. In Proc. IWPT05, pages 93–102, Vancouver, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nocedal</author>
</authors>
<title>Updating quasi-Newton matrices with limited storage.</title>
<date>1980</date>
<journal>Mathematics of Computation,</journal>
<volume>35</volume>
<issue>151</issue>
<contexts>
<context position="11621" citStr="Nocedal, 1980" startWordPosition="2008" endWordPosition="2009"> RULE → (CONDITION DIRECTIVE) our CONDITION → (bowner TEAM {UNUM}) player TEAM → our 4 UNUM → 4 has the ball Figure 3: Partial word alignment for the CLANG statement and its English gloss shown in Figure 1(a) ambiguous. Therefore, a maximum-entropy model that defines the conditional probability of derivations (d) given an input sentence (e) is used for disambiguation: components: arg max Pr(e|f) = argmax Pr(e)Pr(f|e) (2) e e The feature functions, fi, are the number of times each rule is used in a derivation. Zλ(e) is the normalizing factor. The model parameters, Ai, are trained using L-BFGS (Nocedal, 1980) to maximize the conditional log-likelihood of the training examples (with a Gaussian prior). The decoding task is thus to find a derivation d⋆ that maximizes Prλ(d⋆|e), and the output MR translation, f⋆, is the yield of d⋆. This can be done in cubic time with respect to the length of e using an Earley chart parser. 3.3 Generation by Inverting WASP Now we show how to invert WASP to produce WASP−1, and use it for NLG. We can use the same grammar for both parsing and generation, a particularly appealing aspect of using WASP. Since an SCFG is fully symmetric with respect to both generated strings</context>
</contexts>
<marker>Nocedal, 1980</marker>
<rawString>J. Nocedal. 1980. Updating quasi-Newton matrices with limited storage. Mathematics of Computation, 35(151):773–782, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="10845" citStr="Och and Ney, 2003" startWordPosition="1875" endWordPosition="1878">st one production). Extraction starts with productions whose RHS is all terminals, followed by those with non-terminals. (Details can be found in Wong and Mooney (2006).) The rules extracted from Figure 3 would be almost the same as those used in Figure 2, except the one for bowner: CONDITION (TEAM 1 player UNUM 2 has (1) ball, (bowner TEAM 1 {UNUM 2 })). The token (1) denotes a word gap of size 1, due to the unaligned word the that comes between has and ball. It can be seen as a non-terminal that expands to at most one word, allowing for some flexibility in pattern matching. In WASP, GIZA++ (Och and Ney, 2003) is used to obtain the best alignments from the training examples. Then SCFG rules are extracted from these alignments. The resulting SCFG, however, can be 174 If RULE → (CONDITION DIRECTIVE) our CONDITION → (bowner TEAM {UNUM}) player TEAM → our 4 UNUM → 4 has the ball Figure 3: Partial word alignment for the CLANG statement and its English gloss shown in Figure 1(a) ambiguous. Therefore, a maximum-entropy model that defines the conditional probability of derivations (d) given an input sentence (e) is used for disambiguation: components: arg max Pr(e|f) = argmax Pr(e)Pr(f|e) (2) e e The featu</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL-03,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan,</location>
<contexts>
<context position="18814" citStr="Och, 2003" startWordPosition="3251" endWordPosition="3252">w(X —* (α, 0)), is in turn defined as: P(0|α)λ1P(α|0)λ2Pw(0|α)λ3Pw(α|0)λ4 exp(−|α|)λ5 where P(0|α) and P(α|0) are the relative frequencies of 0 and α, and Pw(0|α) and Pw(α|0) are 176 the lexical weights (Koehn et al., 2003). The word penalty, exp(−|α|), allows some control over the output sentence length. Together with the language model, the new formulation of Pr(e|f) is a loglinear model with AZ as parameters. The advantage of this model is that maximization requires no normalization and can be done exactly and efficiently. The model parameters are trained using minimum error-rate training (Och, 2003). Following the phrase extraction phase in PHARAOH, we eliminate word gaps by incorporating unaligned words as part of the extracted NL phrases (Koehn et al., 2003). The reason is that while word gaps are useful in dealing with unknown phrases during semantic parsing, for generation, using known phrases generally leads to better fluency. For the same reason, we also allow the extraction of longer phrases that correspond to multiple predicates (but no more than 5). We call the resulting hybrid system WASP−1++. It is similar to the syntax-based SMT system of Chiang (2005), which uses both SCFG a</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL-03, pages 160–167, Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W J Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. ACL-02,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA,</location>
<contexts>
<context position="21297" citStr="Papineni et al., 2002" startWordPosition="3667" endWordPosition="3670"> 7 and 5 has the ball and the ball is near our goal line ... Figure 4: Sample partial system output in the ROBOCUP domain ROBOCUP GEOQUERY BLEU NIST BLEU NIST PHARAOH 0.3247 5.0263 0.2070 3.1478 WASP−1 0.4357 5.4486 0.4582 5.9900 PHARAOH++ 0.4336 5.9185 0.5354 6.3637 WASP−1++ 0.6022 6.8976 0.5370 6.4808 Table 1: Results of automatic evaluation; bold type indicates the best performing system (or systems) for a given domain-metric pair (p &lt; 0.05) 5.1 Automatic Evaluation We performed 4 runs of 10-fold cross validation, and measured the performance of the learned generators using the BLEU score (Papineni et al., 2002) and the NIST score (Doddington, 2002). Both MT metrics measure the precision of a translation in terms of the proportion of n-grams that it shares with the reference translations, with the NIST score focusing more on n-grams that are less frequent and more informative. Both metrics have recently been used to evaluate generators (Langkilde-Geary, 2002; Nakanishi et al., 2005; Belz and Reiter, 2006). All systems were able to generate sentences for more than 97% of the input. Figure 4 shows some sample output of the systems. Table 1 shows the automatic evaluation results. Paired t-tests were use</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. J. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proc. ACL-02, pages 311–318, Philadelphia, PA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>A uniform architecture for parsing and generation.</title>
<date>1988</date>
<booktitle>In Proc. COLING-88,</booktitle>
<pages>614--619</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="2698" citStr="Shieber, 1988" startWordPosition="436" endWordPosition="437"> this paper, we show how to “invert” a recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce a more effective generation system. WASP exploits the formal syntax of the MRL by learning a translator (based on a statistical synchronous contextfree grammar) that maps an NL sentence to a linearized parse-tree of its MR rather than to a flat MR string. In addition to exploiting the formal MRL grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (Kay, 1975; Jacobs, 1985; Shieber, 1988). We present experimental results in two domains previously used to test WASP’s semantic parsing ability: mapping NL queries to a formal database query language, and mapping NL soccer coaching instructions to a formal robot command language. WASP−1 is shown to produce a more accurate NL generator than PHARAOH. We also show how the idea of generating from linearized parse-trees rather than flat MRs, used effectively in WASP−1, can also be exploited in PHARAOH. A version of PHARAOH that exploits this approach is experimentally shown to produce more accurate generators that are more competitive w</context>
<context position="12316" citStr="Shieber, 1988" startWordPosition="2133" endWordPosition="2134">ian prior). The decoding task is thus to find a derivation d⋆ that maximizes Prλ(d⋆|e), and the output MR translation, f⋆, is the yield of d⋆. This can be done in cubic time with respect to the length of e using an Earley chart parser. 3.3 Generation by Inverting WASP Now we show how to invert WASP to produce WASP−1, and use it for NLG. We can use the same grammar for both parsing and generation, a particularly appealing aspect of using WASP. Since an SCFG is fully symmetric with respect to both generated strings, the same chart used for parsing can be easily adapted for efficient generation (Shieber, 1988; Kay, 1996). Given an input MR, f, WASP−1 finds a sentence e that maximizes Pr(e|f). It is difficult to directly model Pr(e|f), however, because it has to assign low probabilities to output sentences that are not grammatical. There is no such requirement for parsing, because the use of the MRL grammar ensures the grammaticality of all output MRs. For generation, we need an NL grammar to ensure grammaticality, but this is not available a priori. This motivates the noisy-channel model for WASP−1, where Pr(e|f) is divided into two smaller Pr(e) is the language model, and Pr(f|e) is the parsing m</context>
<context position="25637" citStr="Shieber (1988)" startWordPosition="4366" endWordPosition="4367">ta set is a subset of the larger GEOQUERY corpus. All English questions in this data set were manually translated into Spanish, Japanese and Turkish, while the corresponding MRs remain unchanged. Table 3 shows the results, which are similar to previous results on the larger GEOQUERY corpus. WASP−1++ outperformed PHARAOH++ for some language-metric pairs, but otherwise performed comparably. 6 Related Work Numerous efforts have been made to unify the tasks of semantic parsing and tactical generation. One of the earliest espousals of the notion of grammar reversability can be found in Kay (1975). Shieber (1988) further noted that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emer</context>
</contexts>
<marker>Shieber, 1988</marker>
<rawString>S. M. Shieber. 1988. A uniform architecture for parsing and generation. In Proc. COLING-88, pages 614–619, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>The problem of logical-form equivalence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="4487" citStr="Shieber, 1993" startWordPosition="735" endWordPosition="736">formance is the best. 2 MRLs and Test Domains In this work, we consider input MRs with a hierarchical structure similar to Moore (2002). The only restriction on the MRL is that it be defined by an available unambiguous context-free grammar (CFG), which is true for almost all computer languages. We also assume that the order in which MR predicates appear is relevant, i.e. the order can affect the meaning of the MR. Note that the order in which predicates appear need not be the same as the word order of the target NL, and therefore, the content planner need not know about the target NL grammar (Shieber, 1993). To ground our discussion, we consider two application domains which were originally used to demonstrate semantic parsing. The first domain is ROBOCUP. In the ROBOCUP Coach Competition (www.robocup.org), teams of agents compete in a simulated soccer game and receive coach advice written in a formal language called CLANG (Chen et al., 2003). The task is to build a system that translates this formal advice into English. Figure 1(a) shows a piece of sample advice. The second domain is GEOQUERY, where a functional, variable-free query language is used for querying a small database on U.S. geograp</context>
</contexts>
<marker>Shieber, 1993</marker>
<rawString>S. M. Shieber. 1993. The problem of logical-form equivalence. Computational Linguistics, 19(1):179–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stolcke</author>
</authors>
<title>SRILM—an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proc. ICSLP-02,</booktitle>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="16572" citStr="Stolcke, 2002" startWordPosition="2882" endWordPosition="2883">(d)), which is obtained by running the inside-outside algorithm on each output string. This results in a decoding algorithm that is approximate—the best output string might not be in the k-best list—and takes cubic time with respect to the length of each of the k candidate output strings (k = 100 in our experiments). Learning in WASP−1 involves two steps. First, a back-off n-gram language model with Good-Turing discounting and no lexical classes2 is built from all 2This is to ensure that the same language model is used in all systems that we tested. training sentences using the SRILM Toolkit (Stolcke, 2002). We use n = 2 since higher values seemed to cause overfitting in our domains. Next, the parsing model is trained as described in Section 3.2. 4 Improving the SMT-based Generators The SMT-based generation algorithms, PHARAOH and WASP−1, while reasonably effective, can be substantially improved by borrowing ideas from each other. 4.1 Improving the PHARAOH-based Generator A major weakness of PHARAOH as an NLG system is its inability to exploit the formal structure of the MRL. Like WASP−1, the phrase extraction algorithm of PHARAOH is based on the output of a word alignment model such as GIZA++ (</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>A. Stolcke. 2002. SRILM—an extensible language modeling toolkit. In Proc. ICSLP-02, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
<author>J Baldridge</author>
</authors>
<title>Adapting chart realization to CCG.</title>
<date>2003</date>
<booktitle>In Proc. EWNLG-03,</booktitle>
<location>Budapest, Hungary,</location>
<contexts>
<context position="26174" citStr="White and Baldridge (2003)" startWordPosition="4450" endWordPosition="4453">pousals of the notion of grammar reversability can be found in Kay (1975). Shieber (1988) further noted that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realization—inflecting and ordering words— which ignores the problem of lexical selection. In contrast, our SMT-based methods integrate lexical selection and realization in an elegant framework and automatically learn all of their linguistic knowledge from an annotated corpus. 7 Conclusion We have presented four tactical generation systems based on various SMT-based methods</context>
</contexts>
<marker>White, Baldridge, 2003</marker>
<rawString>M. White and J. Baldridge. 2003. Adapting chart realization to CCG. In Proc. EWNLG-03, Budapest, Hungary, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>Reining in CCG chart realization.</title>
<date>2004</date>
<booktitle>In Proc. INLG-04,</booktitle>
<location>New Forest, UK,</location>
<contexts>
<context position="26264" citStr="White (2004)" startWordPosition="4466" endWordPosition="4467">that not only a single grammar can be used for parsing and generation, but the same language-processing architecture can be used for both tasks. Kay (1996) identified parsing charts as such an architecture, which led to the development of various chart generation algorithms: Carroll et al. (1999) for HPSG, Bangalore et al. (2000) for LTAG, Moore (2002) for unification grammars, Score 5 4 3 Good English Non-native English Score Disfluent English Incomprehensible Little meaning No meaning 178 White and Baldridge (2003) for CCG. More recently, statistical chart generators have emerged, including White (2004) for CCG, Carroll and Oepen (2005) and Nakanishi et al. (2005) for HPSG. Many of these systems, however, focus on the task of surface realization—inflecting and ordering words— which ignores the problem of lexical selection. In contrast, our SMT-based methods integrate lexical selection and realization in an elegant framework and automatically learn all of their linguistic knowledge from an annotated corpus. 7 Conclusion We have presented four tactical generation systems based on various SMT-based methods. In particular, the hybrid system produced by inverting the WASP semantic parser shows th</context>
</contexts>
<marker>White, 2004</marker>
<rawString>M. White. 2004. Reining in CCG chart realization. In Proc. INLG-04, New Forest, UK, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Whitelock</author>
</authors>
<title>Shake-and-bake translation.</title>
<date>1992</date>
<booktitle>In Proc. COLING-92,</booktitle>
<pages>784--791</pages>
<location>Nantes, France.</location>
<contexts>
<context position="5417" citStr="Whitelock, 1992" startWordPosition="893" endWordPosition="894">ed CLANG (Chen et al., 2003). The task is to build a system that translates this formal advice into English. Figure 1(a) shows a piece of sample advice. The second domain is GEOQUERY, where a functional, variable-free query language is used for querying a small database on U.S. geography (Kate et al., 2005). The task is to translate formal queries into NL. Figure 1(b) shows a sample query. 3 Generation using SMT Methods In this section, we show how SMT methods can be used to construct a tactical generator. This is in contrast to existing work that focuses on the use of NLG in interlingual MT (Whitelock, 1992), in which the roles of NLG and MT are switched. We first consider using a phrase-based SMT system, PHARAOH, for NLG. Then we show how to invert an SMT-based semantic parser, WASP, to produce a more effective generation system. 3.1 Generation using PHARAOH PHARAOH (Koehn et al., 2003) is an SMT system that uses phrases as basic translation units. During decoding, the source sentence is segmented into a sequence of phrases. These phrases are then reordered and translated into phrases in the target language, which are joined together to form the output sentence. Compared to earlier word-based me</context>
</contexts>
<marker>Whitelock, 1992</marker>
<rawString>P. Whitelock. 1992. Shake-and-bake translation. In Proc. COLING-92, pages 784–791, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning for semantic parsing with statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. HLT/NAACL-06,</booktitle>
<pages>439--446</pages>
<location>New York City, NY,</location>
<contexts>
<context position="2185" citStr="Wong and Mooney, 2006" startWordPosition="344" endWordPosition="347">so tried IBM Model 4/REWRITE (Germann, 2003), a word-based SMT system, but it gave much worse results. tive, the inability of PHARAOH to exploit the formal structure and grammar of the MRL limits its accuracy. Unlike natural languages, MRLs typically have a simple, formal syntax to support effective automated processing and inference. This MRL structure can also be used to improve language generation. Tactical generation can also be seen as the inverse of semantic parsing, the task of mapping NL sentences to MRs. In this paper, we show how to “invert” a recent SMT-based semantic parser, WASP (Wong and Mooney, 2006), in order to produce a more effective generation system. WASP exploits the formal syntax of the MRL by learning a translator (based on a statistical synchronous contextfree grammar) that maps an NL sentence to a linearized parse-tree of its MR rather than to a flat MR string. In addition to exploiting the formal MRL grammar, our approach also allows the same learned grammar to be used for both parsing and generation, an elegant property that has been widely advocated (Kay, 1975; Jacobs, 1985; Shieber, 1988). We present experimental results in two domains previously used to test WASP’s semanti</context>
<context position="6623" citStr="Wong and Mooney, 2006" startWordPosition="1100" endWordPosition="1103">er word-based methods such as IBM Models (Brown et al., 1993), phrasebased methods such as PHARAOH are much more effective in producing idiomatic translations, and are currently the best performing methods in SMT (Koehn and Monz, 2006). To use PHARAOH for NLG, we simply treat the source MRL as an NL, so that phrases in the MRL are sequences of MR tokens. Note that the grammaticality of MRs is not an issue here, as they are given as input. 3.2 WASP: The Semantic Parsing Algorithm Before showing how generation can be performed by inverting a semantic parser, we present a brief overview of WASP (Wong and Mooney, 2006), the SMT-based semantic parser on which this work is based. To describe WASP, it is best to start with an example. Consider the task of translating the English sentence in Figure 1(a) into CLANG. To do this, we may first generate a parse tree of the input sentence. The meaning of the sentence is then obtained by combining the meanings of the phrases. This process can be formalized using a synchronous context-free grammar (SCFG), originally developed as a grammar formalism that combines syntax analysis and code generation in compilers (Aho and Ullman, 1972). It has been used in syntax-based SM</context>
<context position="10395" citStr="Wong and Mooney (2006)" startWordPosition="1786" endWordPosition="1789">is used in lieu of the MR in a word alignment. Figure 3 shows an example. Here the list of productions corresponds to the top-down, left-most derivation of an MR. For each MR there is a unique linearized parse-tree, since the MRL grammar is unambiguous. Note that the structure of the parse tree is preserved through linearization. This allows us to extract SCFG rules in a bottom-up manner, assuming the alignment is n-to-1 (each word is linked to at most one production). Extraction starts with productions whose RHS is all terminals, followed by those with non-terminals. (Details can be found in Wong and Mooney (2006).) The rules extracted from Figure 3 would be almost the same as those used in Figure 2, except the one for bowner: CONDITION (TEAM 1 player UNUM 2 has (1) ball, (bowner TEAM 1 {UNUM 2 })). The token (1) denotes a word gap of size 1, due to the unaligned word the that comes between has and ball. It can be seen as a non-terminal that expands to at most one word, allowing for some flexibility in pattern matching. In WASP, GIZA++ (Och and Ney, 2003) is used to obtain the best alignments from the training examples. Then SCFG rules are extracted from these alignments. The resulting SCFG, however, c</context>
</contexts>
<marker>Wong, Mooney, 2006</marker>
<rawString>Y. W. Wong and R. J. Mooney. 2006. Learning for semantic parsing with statistical machine translation. In Proc. HLT/NAACL-06, pages 439–446, New York City, NY, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>