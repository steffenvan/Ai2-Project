<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003246">
<title confidence="0.9995585">
Fine-Grained Focus for Pinpointing Positive Implicit Meaning
from Negated Statements
</title>
<author confidence="0.99399">
Eduardo Blanco and Dan Moldovan
</author>
<affiliation confidence="0.981195">
Lymba Corporation
</affiliation>
<address confidence="0.822653">
Richardson, TX 75080 USA
</address>
<email confidence="0.998722">
leduardo,moldovanl@lymba.com
</email>
<sectionHeader confidence="0.998597" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999720090909091">
Negated statements often carry positive im-
plicit meaning. Regardless of the seman-
tic representation one adopts, pinpointing the
positive concepts within a negated statement
is needed in order to encode the statement’s
meaning. In this paper, novel ideas to reveal
positive implicit meaning using focus of nega-
tion are presented. The concept of granular-
ity of focus is introduced and justified. New
annotation and features to detect fine-grained
focus are discussed and results reported.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999651697674419">
Semantic representation of text is an important step
towards text understanding. Current approaches are
based on relatively shallow representations and ig-
nore pervasive linguistic phenomena such as nega-
tion and metaphor. Despite these weaknesses, shal-
low representations have been proven useful for sev-
eral tasks, e.g., coreference resolution (Kong et al.,
2009), machine translation (Wu and Fung, 2009).
Consider statement (1) The company won’t ship
the new product to the United States until next year.
Existing approaches to represent the meaning of (1)
either indicate that the verb ship is negated or disre-
gard the negation altogether. Semantic role labelers
trained over PropBank would link n’t to ship with
MNEG (i.e., negate the verb); any system based on
FrameNet and more recent unsupervised proposals
(Poon and Domingos, 2009; Liang et al., 2011; Titov
and Klementiev, 2011) ignore negation.
In order to represent the meaning of (1), one must
first ascertain that the negation mark n’t is actually
negating the TEMPORAL context linked to ship and
not the verb per se; more specifically, n’t is negating
exclusively the preposition until. Only doing so one
can aim at representing the actual meaning of (1):
The company will ship the new product to the United
States during next year. Note that the verb ship, and
its AGENT, THEME and LOCATION (i.e., The com-
pany, the new product and to the United States) are
positive, as well as the temporal anchor next year.
Regardless of the semantic representation one fa-
vors (logic forms, predicate calculus, semantic re-
lations, semantic frames, etc.), we argue that pin-
pointing the numerous words that contribute to im-
plicit positive meanings within a negated statement
is a required subtask to obtain it. This paper aims
at extracting specific positive implicit meaning from
negated statements. The main contributions are:
(1) interpretation of negation using fine-grained fo-
cus; (2) fine-grained focus of negation annotation
over a subset of PropBank; (3) feature set to de-
tect fine-grained focus of negation; and (4) model
to retrieve precise positive implicit meaning from
negated statements.
</bodyText>
<sectionHeader confidence="0.999947" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9997597">
Negation has been widely studied from a theoreti-
cal point of view. The seminal work by Horn (1989)
presents the main thoughts in philosophy and psy-
chology. Work in linguistics has studied the in-
teraction of negation with quantifiers and anaphora
(Hintikka, 2002), as well as the role in reasoning
(S´anchez Valencia, 1991; Dowty, 1994): one can
perform downward (but not upward) monotone in-
ference with negative statements. Zeijlstra (2007)
analyzes the position and form of negative ele-
</bodyText>
<page confidence="0.658952666666667">
456
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.999889440677966">
ments and negative concords; concepts such as intra
and inter-domain negation and strength of negation
(Ladusaw, 1996), syntactic and semantic negation
(L¨obner, 2000) have been discussed in the extensive
literature, although we do not use them.
In computational linguistics, negation has mainly
drawn attention in sentiment analysis (Wilson et al.,
2009; Wiegand et al., 2010) and the biomedical do-
main. Recently, two events (Morante and Sporleder,
2010; Farkas et al., 2010) targeted negation mostly
on those subfields. Among many others, Morante
and Daelemans (2009) and Li et al. (2010) propose
scope detectors using the BioScope corpus. Consid-
ering scope is indeed a step forward, but focus must
also be taken into account to represent negated state-
ments and detect their positive implicit meanings.
Regarding corpora, BioScope annotates negation
marks and linguistic scopes exclusively on biomed-
ical texts. It does not annotate focus and it pur-
posely disregards negations such as the reactions
in NK3.3 cells are not always identical (Vincze et
al., 2008), which carry the kind of positive meaning
we aim at extracting (the reactions in NK3.3 cells
are sometimes identical). Recently, Morante et al.
(2011) present scope annotation in two Conan Doyle
works, but they dismiss focus and positive meaning
extraction. As stated before, PropBank (Palmer et
al., 2005) treats negation superficially and FrameNet
(Baker et al., 1998) regrettably disregards negation.
Blanco and Moldovan (2011) introduce a seman-
tic representation of negation using focus detection.
They target verbal negation and work on top of Prop-
Bank, selecting as focus the role that corresponds
to the focus of negation. Simply put, they propose
that all roles but the one corresponding to the fo-
cus are actually positive. Their approach, however,
has a major drawback: selecting the whole role often
yields too coarse of a focus and the positive implicit
meaning is not fully specified (Section 3.1).
Focus-Sensitive Phenomena. The literature uses
the term focus for widely distinct phenomena; space
permits only a cursory review. Within functional
generative grammars, focus is defined as what is be-
ing asserted about the topic (Hajiˇcov´a et al., 1995).
The term is also used in pragmatics (Glanzberg,
2005), and in phonetics and phonology (Xu and Xu,
2005; Beaver et al., 2007).
In linguistics, focus is largely associated with the
theory presented in Mats Rooth’s dissertation (1985)
and posterior publications (Rooth, 1992). He ana-
lyzes the effect of focus in diverse phenomena, e.g.,
questions and answers, reasons and counterfactu-
als, conversational implicature, bare remnant ellip-
sis. His alternative semantics (e.g., they didn’t order
the right parts implies that some alternative of the
form they ordered X is true) (Rooth, 1997) was an
inspiration for this work. However, Rooth does not
discuss how to detect focus of negation or its granu-
larity and only provides simple made-up examples.
</bodyText>
<sectionHeader confidence="0.980967" genericHeader="method">
3 Scope and Focus
</sectionHeader>
<bodyText confidence="0.996922689655172">
Negation has both scope and focus and they are key
to capture its meaning. Scope is the part of the
meaning that is negated. Focus is that part of the
scope that is most prominently or explicitly negated
(Huddleston and Pullum, 2002). All elements whose
individual falsity would make the negated statement
strictly true belong to the scope. Focus is the ele-
ment of the scope that is intended to be interpreted
as false to make the overall negative true.
Consider (1) We didn’t get an offer for more than
$40 and its positive counterpart (2) We got an offer
for more than $40. The truth conditions of (2) are:
(a) somebody got something; (b) we got; (c) an of-
fer was gotten; and (d) the offer was for more than
$40. In order for (2) to be true, (a–d) have to be
true. Conversely, the falsity of any of them is suffi-
cient to make (1) true: (1) would be true if nobody
got anything, we didn’t get, an offer wasn’t gotten
or the offer wasn’t for more than $40. Thus, all four
statements (a–d) are inside the scope of (1).
The focus is often more difficult to identify. Text
understanding is needed and context plays an impor-
tant role. The most probable focus for (1) is more
than, which corresponds to the interpretation we got
an offer for $40 or less. Another possible focus is
for more than $40, which yields we got an offer, but
not for more than $40. A third possible focus is an
offer for more than $40, which yields we got some-
thing, but not an offer for more than $40. Section
</bodyText>
<subsectionHeader confidence="0.549466">
3.1 discusses coarse versus fine-grained focus.
</subsectionHeader>
<bodyText confidence="0.99688025">
Both scope and focus are primarily semantic,
highly ambiguous and context-dependent. More ex-
amples can be found in Table 1 and 3, and (Huddle-
ston and Pullum, 2002, Chap. 9).
</bodyText>
<page confidence="0.997457">
457
</page>
<table confidence="0.8769935">
No. Statement Interpretation
1 always follow instructions. People sometimes follow instructions.
People don’t������
2 The new group isn’t doing any better than the old one. The new group is doing equal or worse than the old one.
3 the to�10. The first two games finished below the top 10.
in ��
The first two games didn’t finish ��
4 They don’t sell to as many clients as Maryland Club. They sell to less clients than Maryland Club.
��������
5 She said she is not going home until The Word Series is over. She said she is going home when The Word Series is over.
6 People don’t believe I want to give this money�����away. People believe I want to keep this money.
�����
7 I cannot see ��� news doesn’t������ benefit them. I can see how this news benefits them.
how this ����
8 I don’t believe in this business you can be totally laissez faire I believe in this business you can be only partially laissez-
faire because of the high degree of public interest.
����
because of the high degree of public interest.
</table>
<tableCaption confidence="0.999228">
Table 1: Examples of negated statements and their interpretation using fine-grained focus (regular underline). Using
coarse-grained focus (wavy underline) would yield a much more generic, less preferred interpretation.
</tableCaption>
<subsectionHeader confidence="0.999841">
3.1 Granularity of Focus
</subsectionHeader>
<bodyText confidence="0.998643400000001">
In this paper, we refer to the focus considered by
Blanco and Moldovan (2011) as coarse-grained and
indicate it with a wavy underline; we refer to the
focus we work with as fine-grained and indicate it
with a regular underline, e.g., We didn’t get an �����offer
���for���������� than����$40. Whereas coarse-grained focus is
more
restricted to include all words belonging to a verb
argument (as per their definition and annotation, fo-
cus is the full text of a semantic role in PropBank),
fine-grained focus is not. This allows us to narrow
down the actual negative meaning and pinpoint more
positive implicit meaning.
Considering fine-grained focus is a substantial
step towards a comprehensive semantic representa-
tion of negation. Following with the example above,
encoding that we got something, but not an offer for
more than $40 (coarse-grained) is useful, but encod-
ing we got an offer for $40 or less (fine-grained) is
preferred. Several examples of coarse versus fine-
grained focus and the benefits of using the latter
over the former are provided in Table 1. In all state-
ments, using coarse-grained focus yields an interpre-
tation with all words underlined with a wavy under-
line negative and the rest positive, e.g., statement (8)
would be interpreted as I believe in something be-
cause of the high degree of public interest, but not
that in this business you can be totally laissez-faire.
Selecting the elements that belong to the fine-
grained focus is a difficult task. In example (1), both
coarse and fine-grained foci are the same and yield
the same interpretation. In the rest of examples and
in the vast majority of negations we annotated (Sec-
tion 4), fine-grained focus comprises fewer words
and yields more specific interpretations.
The coarse-grained focus in statements (1, 2) is
an adverbial phrase. In (1) coarse-grained focus is
a single word and thus fine-grained focus is trivially
that word. In statement (2), fine-grained focus al-
lows us to keep the comparison between the new and
old group in the interpretation.
Examples (3, 4) correspond to statements whose
coarse grained focus is a prepositional phrase. Sim-
ple rules based on part-of-speech tags are not suit-
able here, deep understanding of text is needed. The
fine-grained focus in example (3) is the preposition,
but that is not the case in (4). Fine-grained focus
in these statements allows us to obtain more com-
plete interpretations, namely spell out the location
(metaphorically speaking) were the games ended in
(3) and the quantity sold in (4).
Examples (5–8) correspond to statements whose
coarse-grained focus is a subordinate clause. Note
that a verb is contained in the coarse-grained focus
in these examples. In statement (5), the fine-grained
focus is the first word, a preposition. However, that
is not the case in (8), where the MANNER of the
verb within the subordinate clause (i.e., totally) is
selected as fine-grained focus. In (6), the phrasal
verb give away is the fine-grained focus. Statement
(7) is specially interesting because it contains a dou-
ble negation and fine-grained focus is the negation
mark within the coarse-grained focus.
Note that interpreting statements using coarse-
grained focus is by no means wrong, but it is not
optimal. The interpretation using fine-grained focus
entails the one using coarse-grained focus. For ex-
ample, in (2), The new group is doing equal or worse
than the old one (fine) entails The new group is do-
ing, but not any better than the old one (coarse).
</bodyText>
<page confidence="0.995686">
458
</page>
<table confidence="0.9995335">
Node # Negations % Negations
NP 1,051 39.93
PP 570 21.65
ADVP 415 15.75
SBAR 323 12.30
S 202 7.67
ADJP 33 1.26
Other 38 1.43
</table>
<tableCaption confidence="0.997909">
Table 2: Syntactic nodes for coarse-grained focus.
</tableCaption>
<sectionHeader confidence="0.823697" genericHeader="method">
4 Annotating Fine-Grained Focus
</sectionHeader>
<bodyText confidence="0.999956120000001">
We have annotated fine-grained focus of negation on
top of the coarse-grained focus annotated by Blanco
and Moldovan (2011). In this paper, we concen-
trate on negations whose coarse-grained focus is a
prepositional phrase (PP), adverbial phrase (ADVP)
or subordinate clause (SBAR). Excluding cases in
which the verb is the coarse-grained focus, these
syntactic nodes correspond to 49.70% of negations
(Table 2). When a verb is the coarse-grained focus,
it is not advantageous to consider fine-grained focus
because both of them are always the same. e.g., We
urge our citizens not to�����wait until it is too late [inter-
pretation: we urge out citizens to act]. An example
of NP being coarse-grained focus is They realized
they didn’t order the right�����parts.
We chose PP, ADVP and SBAR over noun
phrases (NP, the most common syntactic realiza-
tion) because they offer a variety of lexical and syn-
tactic realizations, and thus allow us to tackle the
task of fine-grained focus prediction in an assort-
ment of constructions (as opposed to target exclu-
sively NP). As we shall see, ADVP are shorter and
easier, whereas PP and SBAR often contain complex
syntactic (and semantic) structures and are tougher.
Annotation is done at the word level. Each word
belonging to the coarse grained focus is marked if it
also belongs to the fine-grained focus. This allows
us to narrow down the actual negative meaning and
reveal the most positive implicit meaning. In some
cases (32%, Table 4), coarse and fine-grained foci
include the same words (e.g., It doesn’t������� always hurt
[interpretation: it hurts sometimes]). However, fine-
grained focus usually (68%) comprises fewer words.
Annotators were first trained with examples sim-
ilar to the ones in Table 1. In a first round,
they were asked to select as fine-grained focus the
words within the coarse-grained focus that they be-
lieved were intended to be negated. These instruc-
tions were purposely vague to analyze disagree-
ments and allow us to define detailed guidelines.
Inter-annotator agreement (exact match) was 41%.
This number is low, but the task is challenging and
a mismatch of one token (potentially a noncontent
word (the, a, etc.) or even a punctuation mark
(comma, dash, etc.) is counted as disagreement.
Conflicts were resolved and their causes analyzed.
In a second round, sentences were annotated follow-
ing the improved guidelines (Section 4.1). In both
rounds, annotators were presented with plain text;
they did not have access to any other information.
</bodyText>
<subsectionHeader confidence="0.998365">
4.1 Annotation Guidelines
</subsectionHeader>
<bodyText confidence="0.897979888888889">
We aim at annotating fine-grained focus in order to
pinpoint the numerous positive concepts within a
negated statement. All concepts but the ones belong-
ing to the fine-grained focus should be interpreted
positive. Our annotation criteria is succinctly sum-
marized by the following principles:
1. We annotate fine-grained focus of negation to
reveal specific positive implicit meaning; we do
not strictly follow any theory of focus.
</bodyText>
<listItem confidence="0.87750845">
2. We assume that fine-grained focus is contained
within the coarse-grained focus.
3. Decisions are made taking into account the cur-
rent sentence and context. Context is limited to
the previous and next sentence.
4. World knowledge is taken into account. Thus,
sentences are fully interpreted to identify posi-
tive implicit meaning.
5. In case of ambiguity, we prioritize:
(a) fine-grained focus that yields novel mean-
ing over foci yielding meaning already
stated elsewhere;
(b) narrow over wide fine-grained focus. The
narrower the focus, the more specific the
positive meaning revealed.
(c) the fine-grained focus that reveals the
most obvious positive implicit meaning,
i.e., meaning requiring the least world
knowledge and assumptions to hold.
6. If there are two options for fine-grained focus
</listItem>
<bodyText confidence="0.953721333333333">
yielding semantically equivalent positive im-
plicit meanings, we select the fine-grained fo-
cus occurring earlier within the sentence.
</bodyText>
<page confidence="0.991725">
459
</page>
<table confidence="0.9998901">
No. Example
1 The plan indeed raises from 40% to 50% the number of freshmen applicants admitted strictly by academic
criteria. But that doesn’t mean “half of the students attending”will be admitted this way.
���������� ����
2 “[... ] and tied it to the stake with a chain,” he says proudly. “And you can’t cut this chain with bolt cutters”.
3 fast enough for us.
Although other parties have stated they have no complaints, it is not growing ���
4 Mr. Katz happily agreed, sliding over the fact that California’s roads and bridges aren’t funded property
by��������
��
taxes but by state and federal gasoline taxes.
����
5 on�a��������� defendant��’s������� failure to testify [... ].
[... ] in a criminal case, a prosecutor can not comment ��
6 to your selling skills.
You think you can go out and turn things around. The reason doesn’t relate ��
7 Respondents don’t think that an economic slowdown would harm the major investment markets very much.
��� ��������
8 10 [... ]
The first two games of the World Series between [... ] didn’t finish in th� etop,�
</table>
<tableCaption confidence="0.999781">
Table 3: Examples of annotation (and relevant context) exemplifying the annotation guidelines.
</tableCaption>
<subsectionHeader confidence="0.998098">
4.2 Examples of Annotation
</subsectionHeader>
<bodyText confidence="0.990771617647058">
In this section, we exemplify our annotation guide-
lines with the statements in Table 3. When example
(1) is interpreted in context [criterion 3], we obtain
at most half of the students will be admitted strictly
by academic criteria. Word knowledge [criterion 4]
allows us to determine that if 40–50% of students
are admitted a certain way, at most half of students
attending will be admitted this way (a student admit-
ted may not enroll). Word knowledge is also used in
example (2): however strong the chain is, one could
cut it with a stronger tool than bolt cutters.
Statement (3) implicitly states that it is growing
fast enough for other parties. Thus, we choose
enough [interpretation: it is growing insufficiently
fast for us] since it reveals novel positive meaning
[criterion 5a]. Another option discarded is us [inter-
pretation: it is growing fast enough for someone, but
not us]. Note that revealing novel positive implicit
meaning is not always possible, e.g., statement (4).
There are several options for statement (5): (5a) a
defendant’s failure to testify [interpretation: a prose-
cutor can comment, but not on a defendant’s failure
to testify]; (5b) a defendant’s [a prosecutor can com-
ment on somebody’s failure to testify, but not the
defendant’s]; and (5c) testify [a prosecutor can com-
ment on the defendant’s failures to do something,
but not to testify]. We prefer (5c) since it reveals the
most specific positive meaning [criterion 5b]. Note
that narrowing down the coarse-grained focus is not
always possible as exemplified in example (6): one
cannot tell if the reason relates to another skill or to
something else (e.g., economy, weather).
In example (7), we choose the fine-grained focus
that reveals the most obvious implicit positive mean-
</bodyText>
<table confidence="0.9991352">
#FGF %(CGF = FGF) #FGF/#CGF
PP 5.53 1.17% 0.44
ADVP 1.38 89.19% 0.94
SBAR 9.79 14.79% 0.32
All 5.25 32.41% 0.57
</table>
<tableCaption confidence="0.9866975">
Table 4: Numeric analysis: average number of words
in fine-grained focus, percentage of negations in which
coarse and fine-grained focus are the same and average
ratio of words in fine versus coarse-grained focus.
</tableCaption>
<bodyText confidence="0.9999164375">
ing [criterion 5c], very much [interpretation: an eco-
nomic slowdown would harm the major investment
markets a little]. Another option is slowdown, yield-
ing the plausible but less felicitous interpretation re-
sponders think that an economic recession/turmoil
(but not a slowdown) would harm the major invest-
ment markets very much. A third option is major
[responders think that an economic slowdown would
harm minor investment markets very much]. The
last two options are plausible but less likely.
Finally, statement (8), there are two semanti-
cally equivalent options: (8a) in [interpretation: the
games finished below the top 10] and (8b) 10 [in-
terpretation: the games finished in the top X, where
X is larger than 10]. We choose the former since it
occurs earlier in the sentence [criterion 6].
</bodyText>
<subsectionHeader confidence="0.999737">
4.3 Annotation Analysis
</subsectionHeader>
<bodyText confidence="0.999778333333333">
The three syntactic realizations of coarse-grained fo-
cus we aim at narrowing down have significantly dif-
ferent characteristics. Table 4 summarizes some ba-
sic numeric analysis. Intuitively, ADVPs are fairly
easy (they are short and coarse-grained and fine-
grained foci are often the same). On the other hand,
PP and SBAR are longer and only 44% and 32% of
words belonging to the coarse grained focus belong
to the fine-grained focus respectively.
</bodyText>
<page confidence="0.997914">
460
</page>
<table confidence="0.999979333333334">
Baseline P R F
PP 1.96 1.89 1.92
ADVP 92.86 92.86 92.86
COARSE
SBAR 15.38 13.33 14.29
All 29.52 27.93 28.70
PP 33.33 32.08 32.69
ADVP 92.86 92.86 92.86
FIRST-WORD
SBAR 35.29 20.00 25.53
All 51.04 44.14 47.34
PP 29.82 32.08 30.91
ADVP 92.86 92.86 92.86
FIRST-JJ
SBAR 15.38 13.33 14.29
All 52.34 42.34 42.34
PP 54.17 49.06 51.49
ADVP 92.86 92.86 92.86
BASIC
SBAR 45.00 30.00 36.00
All 63.54 54.95 58.94
</table>
<tableCaption confidence="0.998321">
Table 5: Precision, recall and f-measure of baselines.
</tableCaption>
<sectionHeader confidence="0.935251" genericHeader="method">
5 Learning Fine-Grained Focus
</sectionHeader>
<bodyText confidence="0.99986044">
We follow a standard supervised learning approach.
Each token from each annotated negation becomes
an instance. The decision to be made is whether or
not an instance is part of the fine-grained focus. The
annotated sentences (comprising several instances)
were divided into training (70%), held-out (15%)
and test (15%). The held-out portion was used to
tune the feature set and results are reported for the
test split only, i.e., using unseen instances.
Detecting fine-grained focus is similar to text
chunking. Text chunking consists of dividing text
into syntactically related nonoverlapping groups of
words (Tjong Kim Sang and Buchholz, 2000). On
the other hand, we aim at dividing the words within
a negated statement into belonging or not belong-
ing to the fine-grained focus. Our problem can be
redefined as detecting one type of chunk indicating
the fine grained focus (FGF). We use the standard
BIO notation, in which the first element of a chunk
is prefixed by B- (beginning) and other elements of
the chunk are preceded by I- (inside). The label O
is used to indicate tokens outside any FGF chunk.
Baselines. We have implemented four baselines to
predict fine-grained focus from the elements within
the coarse-grained focus:
</bodyText>
<listItem confidence="0.931267166666667">
• COARSE: select all words.
• FIRST-WORD: select the first word.
• FIRST-JJ: select the first adjective; if none is
found, apply FIRST-WORD.
• BASIC: same as system in Section 5.2 but using
features POS-tag, word and coarse-chunk.
</listItem>
<bodyText confidence="0.999764571428571">
Table 5 shows the performance of these base-
lines. All of them obtain the same performance
for ADVPs, and BASIC yields the best results.
FIRST-WORD successfully predicts fine-grained fo-
cus mostly in cases in which the fine-grained focus
is a preposition positioned at the beginning of the
coarse-grained focus (e.g., Table 3, statement 8).
</bodyText>
<subsectionHeader confidence="0.999393">
5.1 Selecting Features
</subsectionHeader>
<bodyText confidence="0.9999735">
We use a mixture of features proposed for standard
text chunking, semantic role labeling and novel fea-
tures characterizing negation (Table 6). We only
provide more details for the non-obvious ones.
Features 1–5 characterize the current token with
an emphasis on negation. Neg-prefix indicates if
a word is an adjective, starts with a negation prefix
and the reminder of it is a valid adjective. We con-
sider the following negation prefixes: a-, an-, anti-,
dis-, il-, im-, in-, ir-, non- and un- and check whether
the reminder is a valid adjective querying WordNet.
This successfully allows us to detect irrelevant (pre-
fix ir-; relevant is a valid adjective) and disregard ad-
jectives that just happen to start with a negated pre-
fix, e.g., artistic, intelligent. Any-prefix indicates
if a word starts with any (e.g., anytime). Huddle-
ston and Pullum (2002, p.823) refer to these words
as “any class of items” and include them in the
negatively-oriented polarity-sensitive items (NPIs).
Features signaling other NPIs (until, dare, yet, etc.)
did not bring an improvement on the development
set. Ly-suffix typically signals an adverb indicat-
ing the manner in which something happened.
Features 6–18 describe the coarse-grained focus.
Coarse-path corresponds to four features indicat-
ing paths of length 1–4 from coarse-node to the
token. Including the full path did not yield an im-
provement on the development set. Coarse-head
is calculated following (Collins, 1999).
Finally, features coarse-verb and sem-role
are useful in cases in which the token is not only part
of the semantic role corresponding to the coarse-
grained focus (i.e., a role of verb pred-word), but
also a role of a verb within the coarse-grained focus
(i.e., a role of verb coarse-verb). For example in
Table 3, example (7), for token slowdown we have
word = slowdown, pred-word = think, coarse-role
= A1, coarse-verb = harm and sem-role = A0.
</bodyText>
<page confidence="0.998706">
461
</page>
<table confidence="0.999662823529412">
No. Feature Values Explanation
1–2 POS-tag and word {NN, VBD, ... } POS tag and text of current token
3 neg-preffix (PP, SBAR) {yes, no} does word start with a negation preffix?
4 any-preffix (PP, SBAR) {yes, no} does word start with preffix -any?
5 ly-suffix (SBAR) {yes, no} does word end with suffix -ly?
6–7 coarse-{node,parent} {S, PP, ... } syntactic node of coarse-grained focus and parent
8–9 coarse-{left,right} {NP, VP, ... } syntactic node of coarse-node left and right siblings
10 coarse-struct {IN=NP, IN=S, ... } syntactic nodes of of coarse-node daughters
11 coarse-length N lenght of coarse-grained focus
12–15 coarse-path (PP, SBAR) {PP, PP-NP,... } paths of length 1–4 from coarse-node to token
16 coarse-role {ARG1, MTMP, ... } semantic role of coarse-grained focus
17 coarse-head (PP, SBAR) {clock, detail,... } head of coarse-grained focus
18 coarse-verb (SBAR) {think, predict, ... } first verb within coarse-grained focus
19 pred-word {affected, go, ... } predicate text
20 pred-POS {VB, VBN, ... } predicate POS tag
21 sem-role (SBAR) {ARG1, MLOC, ... } semantic role this token belongs to wrt coarse-verb
22 coarse-chunk {B-CFG, I-CFG, O} coarse-grained annotation using BIO
</table>
<tableCaption confidence="0.991333">
Table 6: Feature set used to predict fine-grained focus of negation. If a feature is especially useful for a particular
syntactic node, we indicate so between parenthesis in the right hand side of column 1 (otherwise it is useful for all).
</tableCaption>
<subsectionHeader confidence="0.99264">
5.2 Experiments and Results
</subsectionHeader>
<bodyText confidence="0.999989407407408">
We have carried our experiments using Yamcha (Ku-
doh and Matsumoto, 2000), a generic, customizable,
and open source text chunker1 implemented using
TinySVM2. Following Yamcha’s design, we distin-
guish between static and dynamic features. Static
features are the ones depicted in Table 6 for a fixed
size window. Dynamic features are the predicted
classes for a fixed set of previous instances. Whereas
values for static features are considered correct, val-
ues for dynamic features are predictions of previous
instances and therefore may contain errors. Varying
window size effectively varies the number of fea-
tures considered, the larger the window the more lo-
cal context is taken into account.
Window sizes are defined using ranges between
instances. The instance to be predicted has index
‘0’, the previous one ‘−1’, the next one ‘1’, and so
on. The range [i..j] indicates we take into account
from the ith to the jth instances to predict the cur-
rent instance. Ranges for dynamic features can only
contain instances preceding the current one.
The best performing system was obtained using a
window including the current and two previous in-
stances, and taking into account dynamic features.
This system uses a total of 68 features: 66 static fea-
tures (22x3 = 66, 22 features per instance, window
contains 3 instances) and 2 dynamic features.
</bodyText>
<footnote confidence="0.9999855">
1http://chasen.org/ taku/software/yamcha/
2http://chasen.org/ taku/software/TinySVM/
</footnote>
<table confidence="0.99805515">
Window Size P R F
static dynamic
[-1..0] none 59.20 66.67 62.71
[-1..-1] 68.27 63.96 66.05
[-1..1] none 66.04 63.06 64.52
[-1..-1] 70.10 61.26 65.38
[0..1] none 57.85 63.06 60.34
[-1..-1] 63.92 55.86 59.62
[-2..0] none 60.00 62.16 61.06
[-2..-1] 71.15 66.67 68.84
[-2..2] none 62.96 61.26 62.10
[-2..-1] 68.42 58.56 63.11
[0..2] none 60.00 59.46 59.73
[-2..-1] 64.21 54.95 59.22
[-3..0] none 55.65 62.16 58.72
[-3..-1] 68.93 63.96 66.36
[-3..3] none 62.62 60.36 61.47
[-3..-1] 67.01 58.56 62.50
[0..3] none 57.80 56.76 57.27
[-3..-1] 64.13 53.15 58.13
</table>
<tableCaption confidence="0.8624885">
Table 7: Results using different window sizes.
Table 7 provides results on the test split for several
</tableCaption>
<bodyText confidence="0.978002555555555">
window sizes considering and not considering dy-
namic features. The best performing system obtains
precision 71.15, recall 66.67 (f-measure 68.84). In
general, windows encompassing the i previous in-
stances (e.g., [−2..0]) perform better than windows
encompassing the i next instances (e.g., [0..2]). Win-
dows not considering the i next instances yield bet-
ter performance when using dynamic features (i.e.,
[−i..0] is superior to [−i..i]). Also, including dy-
</bodyText>
<page confidence="0.99765">
462
</page>
<table confidence="0.9998826">
Phrase P R F
PP 64.71 62.26 63.46
ADVP 92.86 92.86 92.86
SBAR 60.00 50.00 54.55
All 71.15 66.67 68.84
</table>
<tableCaption confidence="0.9449075">
Table 8: Detailed results per phrase using the best win-
dow size of features (in bold in Table 7).
</tableCaption>
<bodyText confidence="0.999550714285714">
namic features is favorable for almost all window
sizes (the only exceptions are [0..1] and [0..2] by a
negligible margin). Larger and discontinuous win-
dows (e.g., [-4..-3, -1..-1]) did not bring an improve-
ment during development and were discarded.
Finally, we report detailed results for the best per-
forming system in Table 8.
</bodyText>
<sectionHeader confidence="0.987157" genericHeader="evaluation">
6 Limitations and Future Work
</sectionHeader>
<bodyText confidence="0.994905952380952">
The work presented here effectively extracts specific
positive implicit meaning from negated statements.
We depict below some limitations and shortcomings
that could be targeted as future work.
Types of negation. We only targeted verbal,
clausal and analytic negation (Huddleston and Pul-
lum, 2002). Analyzing other types (e.g., synthetic,
non-verbal: I ate nothing, Nobody liked the party) is
needed for a more comprehensive approach.
All positive meanings. Not all implicit positive
meanings are always detected. For example, If the
payment isn’t received �by����toda_X, an eviction notice
will be send out [interpretation: If the payment is
received after today, an eviction notice will be send
out]. Our proposal fails to detect that if no payment
is received, the notice will also be send. Allowing
multiple fine-grained foci seems a valid solution.
Fine-grained within coarse-grained. In a few ex-
amples, interpreting a negated statement using fine-
grained focus requires modifications in other parts of
the sentence as well. For example, That increase in
the money supply would not have happened without
�������
the consent of the Federal Reserve. The interpreta-
tion is That increase would have happened with the
consent of the Federal Reserve. This is not wrong,
but a better option is to remove the modal would in
the positive interpretation: the increase did happen
(with the consent of the Federal Reserve).
Overall Interpretation. A complete semantic rep-
resentation for a statement (not only the verbal
negation within) may require the same concept
with two polarities. Consider In the[���������� past]TEMPORAL,
[you]AGENT just wore an unknown brand and didn’t
[care]verb. The verbal negation is correctly inter-
preted now you care, but in the past remains as is
(i.e., positive) for the verb wore [interpretation: in
the past you just wore an unknown brand]. Strictly
speaking, this is not a limitation but something to
take into account to obtain a semantic representation
of the whole statement. Our proposal successfully
retrieves positive implicit meaning.
</bodyText>
<sectionHeader confidence="0.999205" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999982945945946">
In this paper, we have argued that negated statements
often carry positive implicit meaning and that its de-
tection is key in order to capture their semantics, re-
gardless of the semantic representation one favors
(e.g., predicate calculus, semantic relations).
We have introduced the concept of granularity of
focus of negation. Going beyond previous work,
considering fine-grained focus allows us to reveal
narrow positive implicit meaning. In the majority
of cases (68%, Table 4) we are able to detect more
positive implicit meaning than previous work con-
sidering a coarse-grained focus. We do not impose
any syntactic restriction on which parts of a sen-
tence might belong to the fine-grained focus. The
annotation was done selecting words without taking
into account any syntactic or semantic information.
This approach effectively marks only the words that
should be negated, but arguably makes prediction
more difficult since fine-grained focus often does not
correspond to a single node in the syntactic tree.
We have approached the task of fine-grained fo-
cus detection as a chunking problem in which we
predict one chunk, FGF. The best model obtains an
f-measure of 68.84, calculated by considering exact
matches between chunks. In other words, unless the
model predicts as fine-grained focus exactly the ac-
tual fine-grained focus, it is considered wrong when
calculating performance. We believe this is the hon-
est way of evaluating performance, even though par-
tial matches could be useful for an actual applica-
tion. For example, in The U.S.’s largest suppliers
haven’t been filling their quotas the�to�������� full extent ������ [in-
terpretation: they have been fullfilling their quotas
to a partial extent], if the model predicts full as the
only word belonging to fine-grained focus we count
it wrong even though it successfully detects the most
important part of it, i.e., the adjective full.
</bodyText>
<page confidence="0.999588">
463
</page>
<sectionHeader confidence="0.996198" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999840892156863">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Proceed-
ings of the 17th international conference on Computa-
tional Linguistics, Montreal, Canada.
David Beaver, Brady Z. Clark, Edward Flemming, T. Flo-
rian Jaeger, and Maria Wolters. 2007. When Seman-
tics Meets Phonetics: Acoustical Studies of Second-
Occurrence Focus. Language, 83(2):245–276.
Eduardo Blanco and Dan Moldovan. 2011. Semantic
Representation of Negation Using Focus Detection. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 581–589, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. University of Pennsyl-
vania.
David Dowty. 1994. The Role of Negative Polarity
and Concord Marking in Natural Language Reason-
ing. In Proceedings of Semantics and Linguistics The-
ory (SALT) 4, pages 114–144.
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos
Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010
Shared Task: Learning to Detect Hedges and their
Scope in Natural Language Text. In Proceedings of
the Fourteenth Conference on Computational Natural
Language Learning, pages 1–12, Uppsala, Sweden,
July. Association for Computational Linguistics.
Michael Glanzberg. 2005. Focus: A Case Study on
the semanticspragmatics Boundary. In Zoltan G. Sz-
abo, editor, Semantics versus Pragmatics, chapter 3.
Oxford University Press, USA, first edition edition,
February.
Eva Hajiˇcov´a, Petr Sgall, and Hana Skoumalov´a. 1995.
An automatic procedure for topic-focus identification.
Comput. Linguist., 21:81–94, March.
Jaakko Hintikka. 2002. Negation in Logic and in Natural
Language. Linguistics and Philosophy, 25(5/6).
Laurence R. Horn. 1989. A Natural History of Negation.
University Of Chicago Press, June.
Rodney D. Huddleston and Geoffrey K. Pullum. 2002.
The Cambridge Grammar of the English Language.
Cambridge University Press, April.
Fang Kong, GuoDong Zhou, and Qiaoming Zhu. 2009.
Employing the Centering Theory in Pronoun Resolu-
tion from the Semantic Perspective. In Proceedings of
the 2009 Conference on Empirical Methods in Natu-
ral Language Processing, pages 987–996, Singapore,
August. Association for Computational Linguistics.
Taku Kudoh and Yuji Matsumoto. 2000. Use of sup-
port vector learning for chunk identification. In Pro-
ceedings of the 4th conference on Computational nat-
ural language learning (CoNLL-2000), ConLL ’00,
pages 142–144, Stroudsburg, PA, USA. Association
for Computational Linguistics.
William A. Ladusaw. 1996. Negation and polarity items.
In Shalom Lappin, editor, Handbook of Contemporary
Semantic Theory, pages 321–341. Blackwell.
Junhui Li, Guodong Zhou, Hongling Wang, and Qiaom-
ing Zhu. 2010. Learning the Scope of Negation via
Shallow Semantic Parsing. In Proceedings of the 23rd
International Conference on Computational Linguis-
tics (Coling 2010), pages 671–679, Beijing, China,
August. Coling 2010 Organizing Committee.
Percy Liang, Michael Jordan, and Dan Klein. 2011.
Learning Dependency-Based Compositional Seman-
tics. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 590–599, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Sebastian L¨obner. 2000. Polarity in Natural Language:
Predication, Quantification and Negation in Particular
and Characterizing Sentences. Linguistics and Philos-
ophy, 23(3):213–308–308, June.
Roser Morante and Walter Daelemans. 2009. Learn-
ing the Scope of Hedge Cues in Biomedical Texts. In
Proceedings of the BioNLP 2009 Workshop, pages 28–
36, Boulder, Colorado, June. Association for Compu-
tational Linguistics.
Roser Morante and Caroline Sporleder, editors. 2010.
Proceedings of the Workshop on Negation and Specu-
lation in Natural Language Processing. University of
Antwerp, Uppsala, Sweden, July.
Roser Morante, Sara Schrauwen, and Walter Daelemans.
2011. Annotation of negation cues and their scope.
Guidelines v1.0. Technical report, CLiPS, University
of Antwerp.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71–106.
Hoifung Poon and Pedro Domingos. 2009. Unsuper-
vised Semantic Parsing. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1–10, Singapore, August. As-
sociation for Computational Linguistics.
Mats Rooth. 1985. Association with Focus. Ph.D. thesis,
Univeristy of Massachusetts, Amherst.
Mats Rooth. 1992. A Theory of Focus Interpretation.
Natural Language Semantics, 1:75–116.
</reference>
<page confidence="0.994816">
464
</page>
<reference confidence="0.999840387755102">
Mats Rooth. 1997. Focus. In Shalom Lappin, edi-
tor, The Handbook of Contemporary Semantic The-
ory, Blackwell Handbooks in Linguistics, chapter 10.
Wiley-Blackwell, December.
Victor S´anchez Valencia. 1991. Studies on Natural Logic
and Categorial Grammar. Ph.D. thesis, University of
Amsterdam.
Ivan Titov and Alexandre Klementiev. 2011. A Bayesian
Model for Unsupervised Semantic Parsing. In Pro-
ceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, pages 1445–1455, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. In-
troduction to the CoNLL-2000 Shared Task: Chunk-
ing. In Claire Cardie, Walter Daelemans, Claire
Nedellec, and Erik Tjong Kim Sang, editors, Proceed-
ings of CoNLL-2000 and LLL-2000, pages 127–132.
Lisbon, Portugal.
Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gy-
orgy Mora, and Janos Csirik. 2008. The Bio-
Scope corpus: biomedical texts annotated for uncer-
tainty, negation and their scopes. BMC Bioinformat-
ics, 9(Suppl 11):S9+.
Michael Wiegand, Alexandra Balahur, Benjamin Roth,
Dietrich Klakow, and Andr´es Montoyo. 2010. A sur-
vey on the role of negation in sentiment analysis. In
Proceedings of the Workshop on Negation and Specu-
lation in Natural Language Processing, pages 60–68,
Uppsala, Sweden, July. University of Antwerp.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2009. Recognizing Contextual Polarity: An Explo-
ration of Features for Phrase-Level Sentiment Analy-
sis. Computational Linguistics, 35(3):399–433.
Dekai Wu and Pascale Fung. 2009. Semantic Roles
for SMT: A Hybrid Two-Pass Model. In Proceedings
of Human Language Technologies: The 2009 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, Companion
Volume: Short Papers, pages 13–16, Boulder, Col-
orado, June. Association for Computational Linguis-
tics.
Y. Xu and C. Xu. 2005. Phonetic realization of focus in
English declarative intonation. Journal of Phonetics,
33(2):159–197, April.
H. Zeijlstra. 2007. Negation in Natural Language: On
the Form and Meaning of Negative Elements. Lan-
guage and Linguistics Compass, 1(5):498–518.
</reference>
<page confidence="0.999594">
465
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.779667">
<title confidence="0.953545">Fine-Grained Focus for Pinpointing Positive Implicit from Negated Statements</title>
<author confidence="0.829828">Blanco</author>
<affiliation confidence="0.997647">Lymba Corporation</affiliation>
<address confidence="0.989634">Richardson, TX 75080 USA</address>
<abstract confidence="0.997319166666667">Negated statements often carry positive implicit meaning. Regardless of the semantic representation one adopts, pinpointing the positive concepts within a negated statement is needed in order to encode the statement’s meaning. In this paper, novel ideas to reveal positive implicit meaning using focus of negation are presented. The concept of granularity of focus is introduced and justified. New annotation and features to detect fine-grained focus are discussed and results reported.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th international conference on Computational Linguistics,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="5010" citStr="Baker et al., 1998" startWordPosition="765" endWordPosition="768">g corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently, Morante et al. (2011) present scope annotation in two Conan Doyle works, but they dismiss focus and positive meaning extraction. As stated before, PropBank (Palmer et al., 2005) treats negation superficially and FrameNet (Baker et al., 1998) regrettably disregards negation. Blanco and Moldovan (2011) introduce a semantic representation of negation using focus detection. They target verbal negation and work on top of PropBank, selecting as focus the role that corresponds to the focus of negation. Simply put, they propose that all roles but the one corresponding to the focus are actually positive. Their approach, however, has a major drawback: selecting the whole role often yields too coarse of a focus and the positive implicit meaning is not fully specified (Section 3.1). Focus-Sensitive Phenomena. The literature uses the term foc</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 17th international conference on Computational Linguistics, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Beaver</author>
<author>Brady Z Clark</author>
<author>Edward Flemming</author>
<author>T Florian Jaeger</author>
<author>Maria Wolters</author>
</authors>
<title>When Semantics Meets Phonetics: Acoustical Studies of SecondOccurrence Focus.</title>
<date>2007</date>
<journal>Language,</journal>
<volume>83</volume>
<issue>2</issue>
<contexts>
<context position="5930" citStr="Beaver et al., 2007" startWordPosition="912" endWordPosition="915">but the one corresponding to the focus are actually positive. Their approach, however, has a major drawback: selecting the whole role often yields too coarse of a focus and the positive implicit meaning is not fully specified (Section 3.1). Focus-Sensitive Phenomena. The literature uses the term focus for widely distinct phenomena; space permits only a cursory review. Within functional generative grammars, focus is defined as what is being asserted about the topic (Hajiˇcov´a et al., 1995). The term is also used in pragmatics (Glanzberg, 2005), and in phonetics and phonology (Xu and Xu, 2005; Beaver et al., 2007). In linguistics, focus is largely associated with the theory presented in Mats Rooth’s dissertation (1985) and posterior publications (Rooth, 1992). He analyzes the effect of focus in diverse phenomena, e.g., questions and answers, reasons and counterfactuals, conversational implicature, bare remnant ellipsis. His alternative semantics (e.g., they didn’t order the right parts implies that some alternative of the form they ordered X is true) (Rooth, 1997) was an inspiration for this work. However, Rooth does not discuss how to detect focus of negation or its granularity and only provides simpl</context>
</contexts>
<marker>Beaver, Clark, Flemming, Jaeger, Wolters, 2007</marker>
<rawString>David Beaver, Brady Z. Clark, Edward Flemming, T. Florian Jaeger, and Maria Wolters. 2007. When Semantics Meets Phonetics: Acoustical Studies of SecondOccurrence Focus. Language, 83(2):245–276.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduardo Blanco</author>
<author>Dan Moldovan</author>
</authors>
<title>Semantic Representation of Negation Using Focus Detection.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>581--589</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="5070" citStr="Blanco and Moldovan (2011)" startWordPosition="772" endWordPosition="775">uistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently, Morante et al. (2011) present scope annotation in two Conan Doyle works, but they dismiss focus and positive meaning extraction. As stated before, PropBank (Palmer et al., 2005) treats negation superficially and FrameNet (Baker et al., 1998) regrettably disregards negation. Blanco and Moldovan (2011) introduce a semantic representation of negation using focus detection. They target verbal negation and work on top of PropBank, selecting as focus the role that corresponds to the focus of negation. Simply put, they propose that all roles but the one corresponding to the focus are actually positive. Their approach, however, has a major drawback: selecting the whole role often yields too coarse of a focus and the positive implicit meaning is not fully specified (Section 3.1). Focus-Sensitive Phenomena. The literature uses the term focus for widely distinct phenomena; space permits only a curso</context>
<context position="9604" citStr="Blanco and Moldovan (2011)" startWordPosition="1558" endWordPosition="1561">���� benefit them. I can see how this news benefits them. how this ���� 8 I don’t believe in this business you can be totally laissez faire I believe in this business you can be only partially laissezfaire because of the high degree of public interest. ���� because of the high degree of public interest. Table 1: Examples of negated statements and their interpretation using fine-grained focus (regular underline). Using coarse-grained focus (wavy underline) would yield a much more generic, less preferred interpretation. 3.1 Granularity of Focus In this paper, we refer to the focus considered by Blanco and Moldovan (2011) as coarse-grained and indicate it with a wavy underline; we refer to the focus we work with as fine-grained and indicate it with a regular underline, e.g., We didn’t get an �����offer ���for���������� than����$40. Whereas coarse-grained focus is more restricted to include all words belonging to a verb argument (as per their definition and annotation, focus is the full text of a semantic role in PropBank), fine-grained focus is not. This allows us to narrow down the actual negative meaning and pinpoint more positive implicit meaning. Considering fine-grained focus is a substantial step towards</context>
<context position="13350" citStr="Blanco and Moldovan (2011)" startWordPosition="2176" endWordPosition="2179">by no means wrong, but it is not optimal. The interpretation using fine-grained focus entails the one using coarse-grained focus. For example, in (2), The new group is doing equal or worse than the old one (fine) entails The new group is doing, but not any better than the old one (coarse). 458 Node # Negations % Negations NP 1,051 39.93 PP 570 21.65 ADVP 415 15.75 SBAR 323 12.30 S 202 7.67 ADJP 33 1.26 Other 38 1.43 Table 2: Syntactic nodes for coarse-grained focus. 4 Annotating Fine-Grained Focus We have annotated fine-grained focus of negation on top of the coarse-grained focus annotated by Blanco and Moldovan (2011). In this paper, we concentrate on negations whose coarse-grained focus is a prepositional phrase (PP), adverbial phrase (ADVP) or subordinate clause (SBAR). Excluding cases in which the verb is the coarse-grained focus, these syntactic nodes correspond to 49.70% of negations (Table 2). When a verb is the coarse-grained focus, it is not advantageous to consider fine-grained focus because both of them are always the same. e.g., We urge our citizens not to�����wait until it is too late [interpretation: we urge out citizens to act]. An example of NP being coarse-grained focus is They realized the</context>
</contexts>
<marker>Blanco, Moldovan, 2011</marker>
<rawString>Eduardo Blanco and Dan Moldovan. 2011. Semantic Representation of Negation Using Focus Detection. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 581–589, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="25438" citStr="Collins, 1999" startWordPosition="4132" endWordPosition="4133"> (2002, p.823) refer to these words as “any class of items” and include them in the negatively-oriented polarity-sensitive items (NPIs). Features signaling other NPIs (until, dare, yet, etc.) did not bring an improvement on the development set. Ly-suffix typically signals an adverb indicating the manner in which something happened. Features 6–18 describe the coarse-grained focus. Coarse-path corresponds to four features indicating paths of length 1–4 from coarse-node to the token. Including the full path did not yield an improvement on the development set. Coarse-head is calculated following (Collins, 1999). Finally, features coarse-verb and sem-role are useful in cases in which the token is not only part of the semantic role corresponding to the coarsegrained focus (i.e., a role of verb pred-word), but also a role of a verb within the coarse-grained focus (i.e., a role of verb coarse-verb). For example in Table 3, example (7), for token slowdown we have word = slowdown, pred-word = think, coarse-role = A1, coarse-verb = harm and sem-role = A0. 461 No. Feature Values Explanation 1–2 POS-tag and word {NN, VBD, ... } POS tag and text of current token 3 neg-preffix (PP, SBAR) {yes, no} does word st</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Dowty</author>
</authors>
<title>The Role of Negative Polarity and Concord Marking in Natural Language Reasoning.</title>
<date>1994</date>
<booktitle>In Proceedings of Semantics and Linguistics Theory (SALT)</booktitle>
<volume>4</volume>
<pages>114--144</pages>
<contexts>
<context position="3198" citStr="Dowty, 1994" startWordPosition="495" endWordPosition="496">etation of negation using fine-grained focus; (2) fine-grained focus of negation annotation over a subset of PropBank; (3) feature set to detect fine-grained focus of negation; and (4) model to retrieve precise positive implicit meaning from negated statements. 2 Related Work Negation has been widely studied from a theoretical point of view. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Work in linguistics has studied the interaction of negation with quantifiers and anaphora (Hintikka, 2002), as well as the role in reasoning (S´anchez Valencia, 1991; Dowty, 1994): one can perform downward (but not upward) monotone inference with negative statements. Zeijlstra (2007) analyzes the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, alt</context>
</contexts>
<marker>Dowty, 1994</marker>
<rawString>David Dowty. 1994. The Role of Negative Polarity and Concord Marking in Natural Language Reasoning. In Proceedings of Semantics and Linguistics Theory (SALT) 4, pages 114–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 1–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Glanzberg</author>
</authors>
<title>Focus: A Case Study on the semanticspragmatics Boundary. In</title>
<date>2005</date>
<booktitle>Semantics versus Pragmatics, chapter 3.</booktitle>
<editor>Zoltan G. Szabo, editor,</editor>
<publisher>Oxford University Press,</publisher>
<contexts>
<context position="5859" citStr="Glanzberg, 2005" startWordPosition="901" endWordPosition="902"> to the focus of negation. Simply put, they propose that all roles but the one corresponding to the focus are actually positive. Their approach, however, has a major drawback: selecting the whole role often yields too coarse of a focus and the positive implicit meaning is not fully specified (Section 3.1). Focus-Sensitive Phenomena. The literature uses the term focus for widely distinct phenomena; space permits only a cursory review. Within functional generative grammars, focus is defined as what is being asserted about the topic (Hajiˇcov´a et al., 1995). The term is also used in pragmatics (Glanzberg, 2005), and in phonetics and phonology (Xu and Xu, 2005; Beaver et al., 2007). In linguistics, focus is largely associated with the theory presented in Mats Rooth’s dissertation (1985) and posterior publications (Rooth, 1992). He analyzes the effect of focus in diverse phenomena, e.g., questions and answers, reasons and counterfactuals, conversational implicature, bare remnant ellipsis. His alternative semantics (e.g., they didn’t order the right parts implies that some alternative of the form they ordered X is true) (Rooth, 1997) was an inspiration for this work. However, Rooth does not discuss how</context>
</contexts>
<marker>Glanzberg, 2005</marker>
<rawString>Michael Glanzberg. 2005. Focus: A Case Study on the semanticspragmatics Boundary. In Zoltan G. Szabo, editor, Semantics versus Pragmatics, chapter 3. Oxford University Press, USA, first edition edition, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eva Hajiˇcov´a</author>
<author>Petr Sgall</author>
<author>Hana Skoumalov´a</author>
</authors>
<title>An automatic procedure for topic-focus identification.</title>
<date>1995</date>
<journal>Comput. Linguist.,</journal>
<pages>21--81</pages>
<marker>Hajiˇcov´a, Sgall, Skoumalov´a, 1995</marker>
<rawString>Eva Hajiˇcov´a, Petr Sgall, and Hana Skoumalov´a. 1995. An automatic procedure for topic-focus identification. Comput. Linguist., 21:81–94, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaakko Hintikka</author>
</authors>
<date>2002</date>
<booktitle>Negation in Logic and in Natural Language. Linguistics and Philosophy,</booktitle>
<pages>25--5</pages>
<contexts>
<context position="3125" citStr="Hintikka, 2002" startWordPosition="483" endWordPosition="484">cit meaning from negated statements. The main contributions are: (1) interpretation of negation using fine-grained focus; (2) fine-grained focus of negation annotation over a subset of PropBank; (3) feature set to detect fine-grained focus of negation; and (4) model to retrieve precise positive implicit meaning from negated statements. 2 Related Work Negation has been widely studied from a theoretical point of view. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Work in linguistics has studied the interaction of negation with quantifiers and anaphora (Hintikka, 2002), as well as the role in reasoning (S´anchez Valencia, 1991; Dowty, 1994): one can perform downward (but not upward) monotone inference with negative statements. Zeijlstra (2007) analyzes the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic nega</context>
</contexts>
<marker>Hintikka, 2002</marker>
<rawString>Jaakko Hintikka. 2002. Negation in Logic and in Natural Language. Linguistics and Philosophy, 25(5/6).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laurence R Horn</author>
</authors>
<title>A Natural History of Negation.</title>
<date>1989</date>
<publisher>University Of Chicago Press,</publisher>
<contexts>
<context position="2961" citStr="Horn (1989)" startWordPosition="458" endWordPosition="459">at contribute to implicit positive meanings within a negated statement is a required subtask to obtain it. This paper aims at extracting specific positive implicit meaning from negated statements. The main contributions are: (1) interpretation of negation using fine-grained focus; (2) fine-grained focus of negation annotation over a subset of PropBank; (3) feature set to detect fine-grained focus of negation; and (4) model to retrieve precise positive implicit meaning from negated statements. 2 Related Work Negation has been widely studied from a theoretical point of view. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Work in linguistics has studied the interaction of negation with quantifiers and anaphora (Hintikka, 2002), as well as the role in reasoning (S´anchez Valencia, 1991; Dowty, 1994): one can perform downward (but not upward) monotone inference with negative statements. Zeijlstra (2007) analyzes the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computati</context>
</contexts>
<marker>Horn, 1989</marker>
<rawString>Laurence R. Horn. 1989. A Natural History of Negation. University Of Chicago Press, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodney D Huddleston</author>
<author>Geoffrey K Pullum</author>
</authors>
<title>The Cambridge Grammar of the English Language.</title>
<date>2002</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="6801" citStr="Huddleston and Pullum, 2002" startWordPosition="1053" endWordPosition="1056">d counterfactuals, conversational implicature, bare remnant ellipsis. His alternative semantics (e.g., they didn’t order the right parts implies that some alternative of the form they ordered X is true) (Rooth, 1997) was an inspiration for this work. However, Rooth does not discuss how to detect focus of negation or its granularity and only provides simple made-up examples. 3 Scope and Focus Negation has both scope and focus and they are key to capture its meaning. Scope is the part of the meaning that is negated. Focus is that part of the scope that is most prominently or explicitly negated (Huddleston and Pullum, 2002). All elements whose individual falsity would make the negated statement strictly true belong to the scope. Focus is the element of the scope that is intended to be interpreted as false to make the overall negative true. Consider (1) We didn’t get an offer for more than $40 and its positive counterpart (2) We got an offer for more than $40. The truth conditions of (2) are: (a) somebody got something; (b) we got; (c) an offer was gotten; and (d) the offer was for more than $40. In order for (2) to be true, (a–d) have to be true. Conversely, the falsity of any of them is sufficient to make (1) t</context>
<context position="8259" citStr="Huddleston and Pullum, 2002" startWordPosition="1323" endWordPosition="1327"> Text understanding is needed and context plays an important role. The most probable focus for (1) is more than, which corresponds to the interpretation we got an offer for $40 or less. Another possible focus is for more than $40, which yields we got an offer, but not for more than $40. A third possible focus is an offer for more than $40, which yields we got something, but not an offer for more than $40. Section 3.1 discusses coarse versus fine-grained focus. Both scope and focus are primarily semantic, highly ambiguous and context-dependent. More examples can be found in Table 1 and 3, and (Huddleston and Pullum, 2002, Chap. 9). 457 No. Statement Interpretation 1 always follow instructions. People sometimes follow instructions. People don’t������ 2 The new group isn’t doing any better than the old one. The new group is doing equal or worse than the old one. 3 the to�10. The first two games finished below the top 10. in �� The first two games didn’t finish �� 4 They don’t sell to as many clients as Maryland Club. They sell to less clients than Maryland Club. �������� 5 She said she is not going home until The Word Series is over. She said she is going home when The Word Series is over. 6 People don’t believ</context>
<context position="24830" citStr="Huddleston and Pullum (2002" startWordPosition="4038" endWordPosition="4042">he current token with an emphasis on negation. Neg-prefix indicates if a word is an adjective, starts with a negation prefix and the reminder of it is a valid adjective. We consider the following negation prefixes: a-, an-, anti-, dis-, il-, im-, in-, ir-, non- and un- and check whether the reminder is a valid adjective querying WordNet. This successfully allows us to detect irrelevant (prefix ir-; relevant is a valid adjective) and disregard adjectives that just happen to start with a negated prefix, e.g., artistic, intelligent. Any-prefix indicates if a word starts with any (e.g., anytime). Huddleston and Pullum (2002, p.823) refer to these words as “any class of items” and include them in the negatively-oriented polarity-sensitive items (NPIs). Features signaling other NPIs (until, dare, yet, etc.) did not bring an improvement on the development set. Ly-suffix typically signals an adverb indicating the manner in which something happened. Features 6–18 describe the coarse-grained focus. Coarse-path corresponds to four features indicating paths of length 1–4 from coarse-node to the token. Including the full path did not yield an improvement on the development set. Coarse-head is calculated following (Collin</context>
<context position="30752" citStr="Huddleston and Pullum, 2002" startWordPosition="4979" endWordPosition="4983">for almost all window sizes (the only exceptions are [0..1] and [0..2] by a negligible margin). Larger and discontinuous windows (e.g., [-4..-3, -1..-1]) did not bring an improvement during development and were discarded. Finally, we report detailed results for the best performing system in Table 8. 6 Limitations and Future Work The work presented here effectively extracts specific positive implicit meaning from negated statements. We depict below some limitations and shortcomings that could be targeted as future work. Types of negation. We only targeted verbal, clausal and analytic negation (Huddleston and Pullum, 2002). Analyzing other types (e.g., synthetic, non-verbal: I ate nothing, Nobody liked the party) is needed for a more comprehensive approach. All positive meanings. Not all implicit positive meanings are always detected. For example, If the payment isn’t received �by����toda_X, an eviction notice will be send out [interpretation: If the payment is received after today, an eviction notice will be send out]. Our proposal fails to detect that if no payment is received, the notice will also be send. Allowing multiple fine-grained foci seems a valid solution. Fine-grained within coarse-grained. In a fe</context>
</contexts>
<marker>Huddleston, Pullum, 2002</marker>
<rawString>Rodney D. Huddleston and Geoffrey K. Pullum. 2002. The Cambridge Grammar of the English Language. Cambridge University Press, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang Kong</author>
<author>GuoDong Zhou</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Employing the Centering Theory in Pronoun Resolution from the Semantic Perspective.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>987--996</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1062" citStr="Kong et al., 2009" startWordPosition="147" endWordPosition="150">l ideas to reveal positive implicit meaning using focus of negation are presented. The concept of granularity of focus is introduced and justified. New annotation and features to detect fine-grained focus are discussed and results reported. 1 Introduction Semantic representation of text is an important step towards text understanding. Current approaches are based on relatively shallow representations and ignore pervasive linguistic phenomena such as negation and metaphor. Despite these weaknesses, shallow representations have been proven useful for several tasks, e.g., coreference resolution (Kong et al., 2009), machine translation (Wu and Fung, 2009). Consider statement (1) The company won’t ship the new product to the United States until next year. Existing approaches to represent the meaning of (1) either indicate that the verb ship is negated or disregard the negation altogether. Semantic role labelers trained over PropBank would link n’t to ship with MNEG (i.e., negate the verb); any system based on FrameNet and more recent unsupervised proposals (Poon and Domingos, 2009; Liang et al., 2011; Titov and Klementiev, 2011) ignore negation. In order to represent the meaning of (1), one must first as</context>
</contexts>
<marker>Kong, Zhou, Zhu, 2009</marker>
<rawString>Fang Kong, GuoDong Zhou, and Qiaoming Zhu. 2009. Employing the Centering Theory in Pronoun Resolution from the Semantic Perspective. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 987–996, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudoh</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Use of support vector learning for chunk identification.</title>
<date>2000</date>
<booktitle>In Proceedings of the 4th conference on Computational natural language learning (CoNLL-2000), ConLL ’00,</booktitle>
<pages>142--144</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="27429" citStr="Kudoh and Matsumoto, 2000" startWordPosition="4456" endWordPosition="4460">rb within coarse-grained focus 19 pred-word {affected, go, ... } predicate text 20 pred-POS {VB, VBN, ... } predicate POS tag 21 sem-role (SBAR) {ARG1, MLOC, ... } semantic role this token belongs to wrt coarse-verb 22 coarse-chunk {B-CFG, I-CFG, O} coarse-grained annotation using BIO Table 6: Feature set used to predict fine-grained focus of negation. If a feature is especially useful for a particular syntactic node, we indicate so between parenthesis in the right hand side of column 1 (otherwise it is useful for all). 5.2 Experiments and Results We have carried our experiments using Yamcha (Kudoh and Matsumoto, 2000), a generic, customizable, and open source text chunker1 implemented using TinySVM2. Following Yamcha’s design, we distinguish between static and dynamic features. Static features are the ones depicted in Table 6 for a fixed size window. Dynamic features are the predicted classes for a fixed set of previous instances. Whereas values for static features are considered correct, values for dynamic features are predictions of previous instances and therefore may contain errors. Varying window size effectively varies the number of features considered, the larger the window the more local context is</context>
</contexts>
<marker>Kudoh, Matsumoto, 2000</marker>
<rawString>Taku Kudoh and Yuji Matsumoto. 2000. Use of support vector learning for chunk identification. In Proceedings of the 4th conference on Computational natural language learning (CoNLL-2000), ConLL ’00, pages 142–144, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Ladusaw</author>
</authors>
<title>Negation and polarity items.</title>
<date>1996</date>
<booktitle>Handbook of Contemporary Semantic Theory,</booktitle>
<pages>321--341</pages>
<editor>In Shalom Lappin, editor,</editor>
<publisher>Blackwell.</publisher>
<contexts>
<context position="3696" citStr="Ladusaw, 1996" startWordPosition="564" endWordPosition="565">h quantifiers and anaphora (Hintikka, 2002), as well as the role in reasoning (S´anchez Valencia, 1991; Dowty, 1994): one can perform downward (but not upward) monotone inference with negative statements. Zeijlstra (2007) analyzes the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, two events (Morante and Sporleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken int</context>
</contexts>
<marker>Ladusaw, 1996</marker>
<rawString>William A. Ladusaw. 1996. Negation and polarity items. In Shalom Lappin, editor, Handbook of Contemporary Semantic Theory, pages 321–341. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
<author>Guodong Zhou</author>
<author>Hongling Wang</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Learning the Scope of Negation via Shallow Semantic Parsing.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>671--679</pages>
<location>Beijing, China,</location>
<contexts>
<context position="4168" citStr="Li et al. (2010)" startWordPosition="634" endWordPosition="637">Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, two events (Morante and Sporleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently,</context>
</contexts>
<marker>Li, Zhou, Wang, Zhu, 2010</marker>
<rawString>Junhui Li, Guodong Zhou, Hongling Wang, and Qiaoming Zhu. 2010. Learning the Scope of Negation via Shallow Semantic Parsing. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 671–679, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning Dependency-Based Compositional Semantics.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>590--599</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1556" citStr="Liang et al., 2011" startWordPosition="227" endWordPosition="230">knesses, shallow representations have been proven useful for several tasks, e.g., coreference resolution (Kong et al., 2009), machine translation (Wu and Fung, 2009). Consider statement (1) The company won’t ship the new product to the United States until next year. Existing approaches to represent the meaning of (1) either indicate that the verb ship is negated or disregard the negation altogether. Semantic role labelers trained over PropBank would link n’t to ship with MNEG (i.e., negate the verb); any system based on FrameNet and more recent unsupervised proposals (Poon and Domingos, 2009; Liang et al., 2011; Titov and Klementiev, 2011) ignore negation. In order to represent the meaning of (1), one must first ascertain that the negation mark n’t is actually negating the TEMPORAL context linked to ship and not the verb per se; more specifically, n’t is negating exclusively the preposition until. Only doing so one can aim at representing the actual meaning of (1): The company will ship the new product to the United States during next year. Note that the verb ship, and its AGENT, THEME and LOCATION (i.e., The company, the new product and to the United States) are positive, as well as the temporal an</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>Percy Liang, Michael Jordan, and Dan Klein. 2011. Learning Dependency-Based Compositional Semantics. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 590–599, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian L¨obner</author>
</authors>
<title>Polarity in Natural Language: Predication, Quantification and Negation in Particular and Characterizing Sentences.</title>
<date>2000</date>
<journal>Linguistics and Philosophy,</journal>
<volume>23</volume>
<issue>3</issue>
<marker>L¨obner, 2000</marker>
<rawString>Sebastian L¨obner. 2000. Polarity in Natural Language: Predication, Quantification and Negation in Particular and Characterizing Sentences. Linguistics and Philosophy, 23(3):213–308–308, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the Scope of Hedge Cues in Biomedical Texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioNLP 2009 Workshop,</booktitle>
<pages>28--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="4147" citStr="Morante and Daelemans (2009)" startWordPosition="629" endWordPosition="632">-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, two events (Morante and Sporleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes </context>
</contexts>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009. Learning the Scope of Hedge Cues in Biomedical Texts. In Proceedings of the BioNLP 2009 Workshop, pages 28– 36, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<date>2010</date>
<booktitle>Proceedings of the Workshop on Negation and Speculation in Natural Language Processing. University of Antwerp,</booktitle>
<editor>Roser Morante and Caroline Sporleder, editors.</editor>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="4168" citStr="(2010)" startWordPosition="637" endWordPosition="637">nal Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, two events (Morante and Sporleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently,</context>
</contexts>
<marker>2010</marker>
<rawString>Roser Morante and Caroline Sporleder, editors. 2010. Proceedings of the Workshop on Negation and Speculation in Natural Language Processing. University of Antwerp, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Sara Schrauwen</author>
<author>Walter Daelemans</author>
</authors>
<title>Annotation of negation cues and their scope. Guidelines v1.0.</title>
<date>2011</date>
<tech>Technical report, CLiPS,</tech>
<institution>University of Antwerp.</institution>
<contexts>
<context position="4790" citStr="Morante et al. (2011)" startWordPosition="732" endWordPosition="735">propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently, Morante et al. (2011) present scope annotation in two Conan Doyle works, but they dismiss focus and positive meaning extraction. As stated before, PropBank (Palmer et al., 2005) treats negation superficially and FrameNet (Baker et al., 1998) regrettably disregards negation. Blanco and Moldovan (2011) introduce a semantic representation of negation using focus detection. They target verbal negation and work on top of PropBank, selecting as focus the role that corresponds to the focus of negation. Simply put, they propose that all roles but the one corresponding to the focus are actually positive. Their approach, ho</context>
</contexts>
<marker>Morante, Schrauwen, Daelemans, 2011</marker>
<rawString>Roser Morante, Sara Schrauwen, and Walter Daelemans. 2011. Annotation of negation cues and their scope. Guidelines v1.0. Technical report, CLiPS, University of Antwerp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="4946" citStr="Palmer et al., 2005" startWordPosition="756" endWordPosition="759"> statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently, Morante et al. (2011) present scope annotation in two Conan Doyle works, but they dismiss focus and positive meaning extraction. As stated before, PropBank (Palmer et al., 2005) treats negation superficially and FrameNet (Baker et al., 1998) regrettably disregards negation. Blanco and Moldovan (2011) introduce a semantic representation of negation using focus detection. They target verbal negation and work on top of PropBank, selecting as focus the role that corresponds to the focus of negation. Simply put, they propose that all roles but the one corresponding to the focus are actually positive. Their approach, however, has a major drawback: selecting the whole role often yields too coarse of a focus and the positive implicit meaning is not fully specified (Section 3</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised Semantic Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1536" citStr="Poon and Domingos, 2009" startWordPosition="223" endWordPosition="226">taphor. Despite these weaknesses, shallow representations have been proven useful for several tasks, e.g., coreference resolution (Kong et al., 2009), machine translation (Wu and Fung, 2009). Consider statement (1) The company won’t ship the new product to the United States until next year. Existing approaches to represent the meaning of (1) either indicate that the verb ship is negated or disregard the negation altogether. Semantic role labelers trained over PropBank would link n’t to ship with MNEG (i.e., negate the verb); any system based on FrameNet and more recent unsupervised proposals (Poon and Domingos, 2009; Liang et al., 2011; Titov and Klementiev, 2011) ignore negation. In order to represent the meaning of (1), one must first ascertain that the negation mark n’t is actually negating the TEMPORAL context linked to ship and not the verb per se; more specifically, n’t is negating exclusively the preposition until. Only doing so one can aim at representing the actual meaning of (1): The company will ship the new product to the United States during next year. Note that the verb ship, and its AGENT, THEME and LOCATION (i.e., The company, the new product and to the United States) are positive, as wel</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2009. Unsupervised Semantic Parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1–10, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
</authors>
<title>Association with Focus.</title>
<date>1985</date>
<tech>Ph.D. thesis,</tech>
<pages>1--75</pages>
<institution>Univeristy of Massachusetts,</institution>
<location>Amherst. Mats Rooth.</location>
<marker>Rooth, 1985</marker>
<rawString>Mats Rooth. 1985. Association with Focus. Ph.D. thesis, Univeristy of Massachusetts, Amherst. Mats Rooth. 1992. A Theory of Focus Interpretation. Natural Language Semantics, 1:75–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mats Rooth</author>
</authors>
<date>1997</date>
<booktitle>The Handbook of Contemporary Semantic Theory, Blackwell Handbooks in Linguistics, chapter 10. Wiley-Blackwell,</booktitle>
<editor>Focus. In Shalom Lappin, editor,</editor>
<contexts>
<context position="6389" citStr="Rooth, 1997" startWordPosition="982" endWordPosition="983">c (Hajiˇcov´a et al., 1995). The term is also used in pragmatics (Glanzberg, 2005), and in phonetics and phonology (Xu and Xu, 2005; Beaver et al., 2007). In linguistics, focus is largely associated with the theory presented in Mats Rooth’s dissertation (1985) and posterior publications (Rooth, 1992). He analyzes the effect of focus in diverse phenomena, e.g., questions and answers, reasons and counterfactuals, conversational implicature, bare remnant ellipsis. His alternative semantics (e.g., they didn’t order the right parts implies that some alternative of the form they ordered X is true) (Rooth, 1997) was an inspiration for this work. However, Rooth does not discuss how to detect focus of negation or its granularity and only provides simple made-up examples. 3 Scope and Focus Negation has both scope and focus and they are key to capture its meaning. Scope is the part of the meaning that is negated. Focus is that part of the scope that is most prominently or explicitly negated (Huddleston and Pullum, 2002). All elements whose individual falsity would make the negated statement strictly true belong to the scope. Focus is the element of the scope that is intended to be interpreted as false to</context>
</contexts>
<marker>Rooth, 1997</marker>
<rawString>Mats Rooth. 1997. Focus. In Shalom Lappin, editor, The Handbook of Contemporary Semantic Theory, Blackwell Handbooks in Linguistics, chapter 10. Wiley-Blackwell, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor S´anchez Valencia</author>
</authors>
<date>1991</date>
<booktitle>Studies on Natural Logic and Categorial Grammar. Ph.D. thesis,</booktitle>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="3184" citStr="Valencia, 1991" startWordPosition="493" endWordPosition="494">are: (1) interpretation of negation using fine-grained focus; (2) fine-grained focus of negation annotation over a subset of PropBank; (3) feature set to detect fine-grained focus of negation; and (4) model to retrieve precise positive implicit meaning from negated statements. 2 Related Work Negation has been widely studied from a theoretical point of view. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Work in linguistics has studied the interaction of negation with quantifiers and anaphora (Hintikka, 2002), as well as the role in reasoning (S´anchez Valencia, 1991; Dowty, 1994): one can perform downward (but not upward) monotone inference with negative statements. Zeijlstra (2007) analyzes the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive l</context>
</contexts>
<marker>Valencia, 1991</marker>
<rawString>Victor S´anchez Valencia. 1991. Studies on Natural Logic and Categorial Grammar. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A Bayesian Model for Unsupervised Semantic Parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1445--1455</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1585" citStr="Titov and Klementiev, 2011" startWordPosition="231" endWordPosition="234">resentations have been proven useful for several tasks, e.g., coreference resolution (Kong et al., 2009), machine translation (Wu and Fung, 2009). Consider statement (1) The company won’t ship the new product to the United States until next year. Existing approaches to represent the meaning of (1) either indicate that the verb ship is negated or disregard the negation altogether. Semantic role labelers trained over PropBank would link n’t to ship with MNEG (i.e., negate the verb); any system based on FrameNet and more recent unsupervised proposals (Poon and Domingos, 2009; Liang et al., 2011; Titov and Klementiev, 2011) ignore negation. In order to represent the meaning of (1), one must first ascertain that the negation mark n’t is actually negating the TEMPORAL context linked to ship and not the verb per se; more specifically, n’t is negating exclusively the preposition until. Only doing so one can aim at representing the actual meaning of (1): The company will ship the new product to the United States during next year. Note that the verb ship, and its AGENT, THEME and LOCATION (i.e., The company, the new product and to the United States) are positive, as well as the temporal anchor next year. Regardless of</context>
</contexts>
<marker>Titov, Klementiev, 2011</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2011. A Bayesian Model for Unsupervised Semantic Parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 1445–1455, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 Shared Task: Chunking.</title>
<date>2000</date>
<booktitle>Proceedings of CoNLL-2000 and LLL-2000,</booktitle>
<pages>127--132</pages>
<editor>In Claire Cardie, Walter Daelemans, Claire Nedellec, and Erik Tjong Kim Sang, editors,</editor>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="22796" citStr="Sang and Buchholz, 2000" startWordPosition="3704" endWordPosition="3707">upervised learning approach. Each token from each annotated negation becomes an instance. The decision to be made is whether or not an instance is part of the fine-grained focus. The annotated sentences (comprising several instances) were divided into training (70%), held-out (15%) and test (15%). The held-out portion was used to tune the feature set and results are reported for the test split only, i.e., using unseen instances. Detecting fine-grained focus is similar to text chunking. Text chunking consists of dividing text into syntactically related nonoverlapping groups of words (Tjong Kim Sang and Buchholz, 2000). On the other hand, we aim at dividing the words within a negated statement into belonging or not belonging to the fine-grained focus. Our problem can be redefined as detecting one type of chunk indicating the fine grained focus (FGF). We use the standard BIO notation, in which the first element of a chunk is prefixed by B- (beginning) and other elements of the chunk are preceded by I- (inside). The label O is used to indicate tokens outside any FGF chunk. Baselines. We have implemented four baselines to predict fine-grained focus from the elements within the coarse-grained focus: • COARSE: s</context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 Shared Task: Chunking. In Claire Cardie, Walter Daelemans, Claire Nedellec, and Erik Tjong Kim Sang, editors, Proceedings of CoNLL-2000 and LLL-2000, pages 127–132. Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Gyorgy Szarvas</author>
<author>Richard Farkas</author>
<author>Gyorgy Mora</author>
<author>Janos Csirik</author>
</authors>
<title>The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<contexts>
<context position="4639" citStr="Vincze et al., 2008" startWordPosition="708" endWordPosition="711">orleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations such as the reactions in NK3.3 cells are not always identical (Vincze et al., 2008), which carry the kind of positive meaning we aim at extracting (the reactions in NK3.3 cells are sometimes identical). Recently, Morante et al. (2011) present scope annotation in two Conan Doyle works, but they dismiss focus and positive meaning extraction. As stated before, PropBank (Palmer et al., 2005) treats negation superficially and FrameNet (Baker et al., 1998) regrettably disregards negation. Blanco and Moldovan (2011) introduce a semantic representation of negation using focus detection. They target verbal negation and work on top of PropBank, selecting as focus the role that corresp</context>
</contexts>
<marker>Vincze, Szarvas, Farkas, Mora, Csirik, 2008</marker>
<rawString>Veronika Vincze, Gyorgy Szarvas, Richard Farkas, Gyorgy Mora, and Janos Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9+.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wiegand</author>
<author>Alexandra Balahur</author>
<author>Benjamin Roth</author>
<author>Dietrich Klakow</author>
<author>Andr´es Montoyo</author>
</authors>
<title>A survey on the role of negation in sentiment analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<pages>60--68</pages>
<institution>University of Antwerp.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="3955" citStr="Wiegand et al., 2010" startWordPosition="600" endWordPosition="603"> of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, two events (Morante and Sporleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purposely disregards negations</context>
</contexts>
<marker>Wiegand, Balahur, Roth, Klakow, Montoyo, 2010</marker>
<rawString>Michael Wiegand, Alexandra Balahur, Benjamin Roth, Dietrich Klakow, and Andr´es Montoyo. 2010. A survey on the role of negation in sentiment analysis. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, pages 60–68, Uppsala, Sweden, July. University of Antwerp.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>3</issue>
<contexts>
<context position="3932" citStr="Wilson et al., 2009" startWordPosition="596" endWordPosition="599">the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment analysis (Wilson et al., 2009; Wiegand et al., 2010) and the biomedical domain. Recently, two events (Morante and Sporleder, 2010; Farkas et al., 2010) targeted negation mostly on those subfields. Among many others, Morante and Daelemans (2009) and Li et al. (2010) propose scope detectors using the BioScope corpus. Considering scope is indeed a step forward, but focus must also be taken into account to represent negated statements and detect their positive implicit meanings. Regarding corpora, BioScope annotates negation marks and linguistic scopes exclusively on biomedical texts. It does not annotate focus and it purpose</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2009</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2009. Recognizing Contextual Polarity: An Exploration of Features for Phrase-Level Sentiment Analysis. Computational Linguistics, 35(3):399–433.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
<author>Pascale Fung</author>
</authors>
<title>Semantic Roles for SMT: A Hybrid Two-Pass Model.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers,</booktitle>
<pages>13--16</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="1103" citStr="Wu and Fung, 2009" startWordPosition="153" endWordPosition="156">ng using focus of negation are presented. The concept of granularity of focus is introduced and justified. New annotation and features to detect fine-grained focus are discussed and results reported. 1 Introduction Semantic representation of text is an important step towards text understanding. Current approaches are based on relatively shallow representations and ignore pervasive linguistic phenomena such as negation and metaphor. Despite these weaknesses, shallow representations have been proven useful for several tasks, e.g., coreference resolution (Kong et al., 2009), machine translation (Wu and Fung, 2009). Consider statement (1) The company won’t ship the new product to the United States until next year. Existing approaches to represent the meaning of (1) either indicate that the verb ship is negated or disregard the negation altogether. Semantic role labelers trained over PropBank would link n’t to ship with MNEG (i.e., negate the verb); any system based on FrameNet and more recent unsupervised proposals (Poon and Domingos, 2009; Liang et al., 2011; Titov and Klementiev, 2011) ignore negation. In order to represent the meaning of (1), one must first ascertain that the negation mark n’t is act</context>
</contexts>
<marker>Wu, Fung, 2009</marker>
<rawString>Dekai Wu and Pascale Fung. 2009. Semantic Roles for SMT: A Hybrid Two-Pass Model. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers, pages 13–16, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Xu</author>
<author>C Xu</author>
</authors>
<title>Phonetic realization of focus in English declarative intonation.</title>
<date>2005</date>
<journal>Journal of Phonetics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="5908" citStr="Xu and Xu, 2005" startWordPosition="908" endWordPosition="911">e that all roles but the one corresponding to the focus are actually positive. Their approach, however, has a major drawback: selecting the whole role often yields too coarse of a focus and the positive implicit meaning is not fully specified (Section 3.1). Focus-Sensitive Phenomena. The literature uses the term focus for widely distinct phenomena; space permits only a cursory review. Within functional generative grammars, focus is defined as what is being asserted about the topic (Hajiˇcov´a et al., 1995). The term is also used in pragmatics (Glanzberg, 2005), and in phonetics and phonology (Xu and Xu, 2005; Beaver et al., 2007). In linguistics, focus is largely associated with the theory presented in Mats Rooth’s dissertation (1985) and posterior publications (Rooth, 1992). He analyzes the effect of focus in diverse phenomena, e.g., questions and answers, reasons and counterfactuals, conversational implicature, bare remnant ellipsis. His alternative semantics (e.g., they didn’t order the right parts implies that some alternative of the form they ordered X is true) (Rooth, 1997) was an inspiration for this work. However, Rooth does not discuss how to detect focus of negation or its granularity a</context>
</contexts>
<marker>Xu, Xu, 2005</marker>
<rawString>Y. Xu and C. Xu. 2005. Phonetic realization of focus in English declarative intonation. Journal of Phonetics, 33(2):159–197, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zeijlstra</author>
</authors>
<title>Negation in Natural Language: On the Form and Meaning of Negative Elements.</title>
<date>2007</date>
<journal>Language and Linguistics Compass,</journal>
<volume>1</volume>
<issue>5</issue>
<contexts>
<context position="3303" citStr="Zeijlstra (2007)" startWordPosition="510" endWordPosition="511">bset of PropBank; (3) feature set to detect fine-grained focus of negation; and (4) model to retrieve precise positive implicit meaning from negated statements. 2 Related Work Negation has been widely studied from a theoretical point of view. The seminal work by Horn (1989) presents the main thoughts in philosophy and psychology. Work in linguistics has studied the interaction of negation with quantifiers and anaphora (Hintikka, 2002), as well as the role in reasoning (S´anchez Valencia, 1991; Dowty, 1994): one can perform downward (but not upward) monotone inference with negative statements. Zeijlstra (2007) analyzes the position and form of negative ele456 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 456–465, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics ments and negative concords; concepts such as intra and inter-domain negation and strength of negation (Ladusaw, 1996), syntactic and semantic negation (L¨obner, 2000) have been discussed in the extensive literature, although we do not use them. In computational linguistics, negation has mainly drawn attention in sentiment </context>
</contexts>
<marker>Zeijlstra, 2007</marker>
<rawString>H. Zeijlstra. 2007. Negation in Natural Language: On the Form and Meaning of Negative Elements. Language and Linguistics Compass, 1(5):498–518.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>