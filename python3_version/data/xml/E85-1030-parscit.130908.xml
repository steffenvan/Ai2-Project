<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<title confidence="0.687217">
A NATURAL LANGUAGE INTERFACE USING A WORLD MODEL
</title>
<author confidence="0.641164">
Yoshio Izumida, Hiroshi Ishikawa, Toshiaki Yoshino,
Tadashi Hoshiai, and Akifumi Makinouchi
</author>
<affiliation confidence="0.6185235">
Software Laboratory
Fujitsu Laboratories Ltd.
</affiliation>
<address confidence="0.634048">
1015 kamikodanaka, Nakahara-ku, Kawasaki, 211, Japan
</address>
<sectionHeader confidence="0.701571" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999636823529412">
Databases are nowadays used by varied and
diverse users, many of whom are unfamiliar with
the workings of a computer, but who, nevertheless,
want to use those databases more easily. Rising
to meet this demand, authors are developing a
Japanese language interface, called KID, as a
database front-end system. KID incorporates a
world model representing application and database
knowledge to help make databases easier to use.
KID has the following features: (1) parser
extendability and robustness, (2) independence
from the application domain, (3) ease of knowledge
editing, (4) independence from the database. This
paper focuses on the first three features. KID
has already been applied to the fields of housing,
sales, and drug testing, thus confirming its
transportability and practicality.
</bodyText>
<sectionHeader confidence="0.997646" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.996902">
KID (Knowledge-based Interface to Databases) is
a Japanese-language database interface (Izumida,
84). KID has the following four features.
</bodyText>
<sectionHeader confidence="0.571959" genericHeader="method">
Extendability and robustness
</sectionHeader>
<bodyText confidence="0.990077052631579">
Natural language sentences employ a wide
variety of expressions. A parser must always be
extended to understand new sentences. A parser
which can understand one set of sentences is often
incapable of understanding another set of
sentences. In KID, parsing rules are grouped into
packets and the parsing mechanism is simple, thus
-making KID highly extendable. The system must be
robust, in order to handle conversational
sentences, which often contain errors and
ellipses. To interpret these ill-formed
sentences, semantic interpretation must play a
leading role. KID has an integrated knowledge
base called the world model. The world model
represents the semantic model of the domain of the
discourse in an object-oriented manner. Several
systems (e.g., Ginsparg, 83) use a semantic model
to interpret ill-formed sentences, but the use of
the semantic model is unclear. We have made the
semantic interpretation rules clear according to
the structure of the world model and syntactic
information of the input sentences. This helps
the parsing of ill-formed sentences.
Independence from the application domain
The system must be easily adaptable to
different applications. The domain-dependent
knowledge must be separate from the domain-
independent knowledge. In many systems (e.g.,
Waltz, 78 and Hendrix, 78), the domain-dependent
knowledge is embedded within the parsing rules,
thus reducing the system&apos;s transportability. In
KID, the domain-dependent knowledge is integrated
into the world model separately, therefore giving
KID high transportability.
Ease of knowledge editing
The world model contains various kinds of
knowledge, and the editing of this knowledge must
be easy to accommodate various levels of users.
KID provides users with the world model editor,
this having a separate user interface for each
user level. The world model editor makes the
customization and extension of the KID system
easy.
Independence from the database
The system must be able handle changes in the
database system and schema easily. In TEAM
(Grosz, 83), the schema information is separate,
but the user must be familiar with the database
schema such as files and fields. In KID, the
mapping information between the model of the
domain and the database schema is described in the
world model, so the user does not have to worry
about any changes in the database schema.
Knowledge of the query language of a database
system is represented separately as production
rules. Thus, the user only has to change these
rules if there are changes in the database system.
</bodyText>
<subsectionHeader confidence="0.992394">
In this paper we will focus on the first three
</subsectionHeader>
<bodyText confidence="0.99968425">
features of KID. Firstly, we will explain the
world model, then the overall structure of the
KID, the morphological analyzer (required to
process Japanese-language sentences), the model-
based parser, semantic interpretation and the flow
of the parsing process, knowledge for customizing
KID and, lastly, the evaluation of KID and its
results.
</bodyText>
<sectionHeader confidence="0.597517" genericHeader="method">
WORLD MODEL
</sectionHeader>
<bodyText confidence="0.999278857142857">
The world model represents the user&apos;s image of
the application domain. The user&apos;s image does not
match the database schema, because the database
schema reflects the storage structure of the data
and the performance consideration of the database
system. The world model represents the user&apos;s
image as classes and relationships between them.
</bodyText>
<page confidence="0.996451">
205
</page>
<figure confidence="0.741172666666667">
CD: Class
: Attribute relationship
: Super-sub relationship
</figure>
<figureCaption confidence="0.999772">
Figure 1. Part of the world model for sales.
</figureCaption>
<bodyText confidence="0.989198517241379">
A class is represented as an object in the
object-oriented programming sense (Bobrow, 81),
which describes a thing or event in the domain.
There are only two types of relationship;
attribute relationship and super-sub relationship.
This model matches the user&apos;s image and is very
simple, so design and editing of the model is
easy.
Figure 1 shows the part of the world model for
a sales domain. The commodity class has two
attribute classes, commodity&apos;s name and fixed
price. The beer and whisky classes are subclasses
of the commodity class and inherit its attribiltes.
Figure 2 shows a part of the definition of the
sales class. The internal representation of a
class object is a frame expression. A slot
represents a relationship to another class using a
$class facet and mapping information to the
database schema using a $storage facet. The value
of a $storage facet denotes the class name which
has mapping information. The sales class has four
attribute classes: RETAILER, COMMODITY, SALES
PRICE, and SALES QUANTITY. An object may also
include the method for handling data within it.
The system allows the user to define lexical
information in the world model. For example, the
noun &apos;commodity&apos; corresponds to the commodity
class. The verb &apos;sell&apos; and the noun &apos;sale&apos; both
correspond to the sales class. The verb &apos;locate&apos;
</bodyText>
<figure confidence="0.910641">
SALES
RETAILER $class RETAILER
$storage SALES_RETAILERSTORAGE
COMMODITY $class COMMODITY
$storage SALES_COMMODITy_STORAGE
PRICE $class SALES_PRICE
$storage SALES PRICE_STORAGE
QUANTITY $class SALES_QUANTITY
$storage SALES_QUANTITY_STORAGE
</figure>
<figureCaption confidence="0.999678">
Figure 2. Internal representation of a class.
</figureCaption>
<bodyText confidence="0.998289625">
corresponds to the arc between the relation and
location classes. Lexical information is
physically stored in the word dictionary. The
dictionary is represented as a table of the
relational database system. Figure 3 shows part
of the dictionary. The dictionary consists of a
headword, an identifier, a part of speech, parsing
information and other fields. The correspondence
to the world model is represented in the OBJECT
feature of the PARSE field. The verb also has its
case frame information in the PARSE field. All
the information relating to a specific domain is
stored in the world model, so the user need only
create the world model to customize KID to a
specific application. This results in
transportability of the system.
</bodyText>
<page confidence="0.996588">
206
</page>
<table confidence="0.8885712">
HEADWORD IDENTIFIER POS PARSE
SHOUHIN N (OBJECT COMMODITY)
PA NI
(commodity)
N fc HANBAI-SURU VB (OBJECT SALES) CLASS
(sell) (CASE ((RETAILER *GA *WA
(SALES QUANTITY NP)))
ii. RE-RU AUX-VB
WO AUX (P *WO)
(7) NO AUX (P *NO)
</table>
<figureCaption confidence="0.990533">
Figure 3. Word dictionary.
</figureCaption>
<figure confidence="0.966766769230769">
World model editor
Word REALM
dict. Modeling
system
Morphological
analyzer
World
model
Model-based
parser
1)\
Retriever
DBMS
</figure>
<figureCaption confidence="0.999955">
Figure 4. System configuration.
</figureCaption>
<sectionHeader confidence="0.653229" genericHeader="method">
SYSTEM CONFIGURATION
</sectionHeader>
<bodyText confidence="0.999967181818182">
KID is the front-end system of the database
management system, the configuration being shown
in Figure 4. The user enters a query via Japanese
word processing terminal. Since a Japanese-
language sentence is not separated into words, the
morphological analyzer segments the sentence to
get the list of words, using the word dictionary.
The model-based parser analyzes the word list, and
semantically interprets it, using the world model
as a basis. The result is the &amp;quot;meaning structure&amp;quot;
consisting of the parsed tree and the relevant
part of the world model representing the meaning
of the input query. The retriever generates the
Japanese-language paraphrase from the meaning
structure and outputs it to the user terminal for
confirmation. Then, the retriever translates the
meaning structure into the query language of the
target database management system and executes it.
The result is displayed on the user terminal. The
world model is managed by the modeling system,
REALM (REAL world Modeling system), and is edited
by the world model editor.
</bodyText>
<subsectionHeader confidence="0.597377">
MORPHOLOGICAL ANALYZER
</subsectionHeader>
<bodyText confidence="0.933571">
A Japanese-language sentence is not separated
into words. The system must segment a sentence
into its component words. The morphological
</bodyText>
<page confidence="0.968687">
207
</page>
<figure confidence="0.992749545454545">
-7-7&amp;quot;
His hehavior was childish.
0 0 0
3
his behavior was childish
0 0
tc — t: — — o 4
very popular not
0
—A
indication
</figure>
<figureCaption confidence="0.999173">
Figure 5. An example of morphological analysis.
</figureCaption>
<bodyText confidence="0.99237287804878">
of life
analyzer performs this segmentation. KID selects
the segmentation candidate with the least number
of &apos;bunsetsu&apos;. We believe this method to be the
best method for segmenting a Japanese-language
sentence (Yoshimura, 83). This method uses a
breadth-first search of a candidate word graph.
Since many candidate words are generated by this
method, the performance of the segmentation is not
so good. We use the optimum graph search
algorithm, called A* (Nilssen, 80), to search the
candidate word graph.
Figure 5 shows an example of morphological
analysis. This sentence has three possible
segmentations. The first line is the correct
segmentation, having the least number of
&apos;bunsetsu&apos;. The algorithm A* estimates the number
of bunsetsu in the whole sentence at each node of
the candidate word graph, and selects the next
search path. This method eliminates useless
searching of the candidate graph. In Figure 5,
the circled numbers denote the sequence of the
graph search.
The morphological analyzer segments a sentence
using connection information for each word. The
connection information depends on the part of
speech. Detailed classification of words leads to
correct segmentation. However, it is difficult
for an end-user perform this kind of
classification. Thus, we classify words into two
categories: content words and function words.
Content words are nouns, verbs, adjectives, and
adverbs, which depend on the application. They
are classified roughly. Function words include
auxiliaries, conjunctions, and so on, which are
independent of the domain. They are classified in
detail. It is easy for the user to roughly
classify content words. This morphological
analyzer segments sentences precisely and
efficiently, and generates a word list. This word
list is then passed to the model-based parser.
</bodyText>
<sectionHeader confidence="0.979873" genericHeader="method">
MODEL BASED PARSER
</sectionHeader>
<bodyText confidence="0.9971748">
In its first phase the parser generates
&apos;bunsetsu&apos; from the word list. The parser
syntactically analyzes the relationship between
these &apos;bunsetsu&apos;. At the same time, the parser
semantically checks and interprets the
relationships, based on the world model.
&apos;Bunsetsu&apos; sequences of a Japanese-language
sentence are relatively arbitrary. And
conversational sentences may include errors and
ellipses, therefore the parser must be robust, in
order to deal with these ill-formed sentences.
These factors suggest that semantic interpretation
should play an important role in the parser.
The basic rules of semantic interpretation are
the identification rule and the connection rule.
These rules check the relationship between the
classes which correspond to the &apos;bunsetsu&apos; and
interpret the meaning of the unified &apos;bunsetsu&apos;.
The identification rule corresponds to a super-sub
relationship. If two classes, corresponding to
</bodyText>
<figure confidence="0.77255">
20001&apos;I
sales price is 2000 yen
</figure>
<figureCaption confidence="0.945352">
Figure 6. An example of the identification rule.
</figureCaption>
<figure confidence="0.9505855">
Ilk 71 Ma)
retailer name
</figure>
<figureCaption confidence="0.999229">
Figure 7. An example of the connection rule.
</figureCaption>
<page confidence="0.994901">
208
</page>
<bodyText confidence="0.999559772727273">
two phrases, are connected by a super-sub
relationship, this rule selects the subclass as
the meaning of the unified phrase, because the
subclass has a more specific and restricted
meaning than the super class. Figure 6 shows an
example of the identification rule. In this
example, the phrase &apos;sales price&apos; corresponds to
the sales price class, and &apos;2000 yen&apos; corresponds
to the price class. The identification rule
selects the sales price class as the unified
meaning. The connection rule corresponds to an
attribute relationship. If two classes are
connected by an attribute relationship, this rule
selects the root class of the relation as the
meaning of the unified class, because the root
class clarifies the semantic position of the leaf
class in the world model. Figure 7 shows an
example of the connection rule. In this example,
the phrase &apos;retailer&apos; corresponds to the retailer
class, and &apos;name&apos; corresponds to the name class.
The connection rule selects the retailer class as
the unified meaning.
</bodyText>
<figure confidence="0.936401666666667">
Bunsetsu generation
Identification
Connection
</figure>
<figureCaption confidence="0.9538345">
Figure 8. Parsing process.
Figure 8 shows the parsing process of the
</figureCaption>
<bodyText confidence="0.999858565217391">
model-based parser. In each process, input
sentences are scanned from left to right. In the
first phase, &apos;bunsetsu&apos; are generated from the
word list. At the same time the parser attaches
the object which is instanciated from the
corresponding class to each &apos;bunsetsu&apos;. The
following identification and connection phases
perform semantic interpretation using these
instance objects, and determines the relationship
between phrases. The identification process and
connection process are executed repeatedly until
all the relationship between phrases have been
determined. The identification process has
priority over the connection process, because a
super-sub relationship represents a same concept
generalization hierarchy and has stronger
connectivity than an attribute relationship, the
latter representing a property relation between
different concepts. This parsing mechanism is
very simple, allowing the user to expand each
process easily. Each process consists of a number
of production rules, which are grouped into
packets according to the relevant syntactic
patterns. Each packet has an execution priority
according to the syntactic connectivity of each
pattern. Thus the identification or addition of
the rules are localized in the packet concerned
with the modification. This simple parsing
mechanism and the modular construction of the
parsing rules contribute to the expandability of
the parser.
Figures 9 and 10 show an example of parsing.
This query means &apos;What is the name of the retailer
in Geneva who sells commodity A?&apos;. The
morphological analyzer segments the sentence, and
the model-based parser generates the phrases in
the parentheses. The identification process is
not applied to these phrases, because there is no
super-sub relationship between them. Next, the
model-based parser applies the connection process.
The phrase &apos;Geneva&apos; can modify the phrase
&apos;commodity A&apos; syntactically, but not semantically,
because the corresponding classes, &amp;quot;Location&amp;quot; and
&amp;quot;Commodity&amp;quot;, do not have an attribute
relationship. The phrase &apos;commodity A&apos; can modify
the phrase &apos;to sell&apos; both semantically and
</bodyText>
<equation confidence="0.753247428571429">
-7) A PA a fc Jg Z1 F411 ?
(Geneva) (commodity A) (to sell) (retailer) (name)
S(Sales)
C(Sales)
M(Sales -Commodity -0 C-name)
S(Retailer)
C(Sales)
</equation>
<footnote confidence="0.4793345">
M(Sales Commodity C-name)
&apos;Retailer)
</footnote>
<figureCaption confidence="0.988404">
Figure 9. An example of parsing (1).
</figureCaption>
<page confidence="0.949374">
209
</page>
<figure confidence="0.997053714285714">
•7-7&amp;quot;) A gt
(Geneva) (commodity A) (to sell) (retailer) (name)
S (Name)
C(Sales)
M(Sales -.Commodity -0.C-name)
&apos;Retailer ;0-t Location)
R-name)
</figure>
<figureCaption confidence="0.901919">
Figure 10. An example of parsing (2).
</figureCaption>
<figure confidence="0.9835965">
S (Retailer)
C(Sales)
M(Sales -.Commodity -0.C-name
&amp;quot;Retailer -÷Location)
</figure>
<bodyText confidence="0.99909025">
syntactically, because the classes &amp;quot;Commodity&amp;quot; and
&amp;quot;Sales&amp;quot; have an attribute relationship. In this
case, the predicate connection rule is applied,
generating the unified phrase, node 1. The parser
uses these three kinds of objects to check the
connectivity. The syntactic object S represents
the syntactic center of the unified phrase. In
the Japanese-language the last phrase of the
unified phrase is syntactically dominant. The
conceptual object represents the semantic center
of the unified phrase, and is determined by the
identification and connection rule. The meaning
objects M represent the meaning of the unified
phrase using the sub-network of the world model.
The predicate connection rule determines the sales
class to be the conceptual object of node 1,
because the sales class is the root class of the
attribute relationship. The meaning objects are
Sales --&gt; Commodity --&gt; Commodity name. The
predicate connection rule also generates noun
phrase node 2 and the S,C,and M of the node is
determined as described in Figure 9. Next, the
noun phrase connection rule is applied. This rule
is applied to a syntactic pattern such as a noun
phrase with a postposition &apos;no&apos; followed by a noun
phrase with any kind of postposition. The phrase
&apos;Geneva&apos; and the unified phrase 3 are unified to
node 3 by the noun phrase connection rule (see
Figure 10). This rule also generates node 4. The
meaning of this sentence is that of node 4.
Errors or ellipses of postposition, such as
&apos;no&apos; or &apos;ga&apos;, are handled by packets which deal
with the syntactic pattern. On the other hand,
ellipses are handled by the special packets which
deal with non-unified phrases based on the world
model. These special packets have a lower
priority than the standard packets. Different
levels of robustness can be achieved by using the
suitable packet for dealing with errors or
ellipses.
</bodyText>
<sectionHeader confidence="0.725837" genericHeader="method">
CUSTONIZATION
</sectionHeader>
<bodyText confidence="0.999872785714286">
To customize the KID system to a specific
application domain, the user has to perform
several domain-dependent tasks. First, the user
makes a class network for the domain either from
queries, which we call a top-down approach, or
from the database schema, a bottom-up approach.
Then, the user assigns words to the classes or
attributes of the class network. Lastly, the user
describes mapping information between classes and
the database schema within the classes.
The world model editor supports these
customization processes. The world model editor
has three levels of user interface, in order to
assist various users in editing the world model
(see Figure 11). The first level is a
construction description level, in which the user
makes a structure of a class network. The second
level is a word assignment level, in which the
user assigns words to classes or attributes.
These two levels are provided for end-users. The
third level is a class- or word-contents
description level. This level is provided for
more sophisticated users, who understand the
internal knowledge representation. The world
model editor enables users to navigate any of the
interface levels. Various users can edit the
knowledge, according to their own particular view.
Thus, knowledge base editing is made easier.
</bodyText>
<sectionHeader confidence="0.937852" genericHeader="evaluation">
EVALUATION
</sectionHeader>
<bodyText confidence="0.999839611111111">
We have applied KID to three different
applications; housing, sales, and new drug tests.
Figure 12 shows a result of an evaluation of KID.
The target domain is a new drug test. We prepared
400 sentences for the evaluation. In a little
less than a month, 91% of the sentences had been
accepted. We decided a sentence is accepted, if
the sentence is correctly analyzed and the correct
data is retrieved from the database. We divided
the 400 sentences into four groups and performed a
blind test and a full capability test for each
group, in stages. In the blind test, sentences
are tested without changing any knowledge of the
system. In the full capability test, we make all
possible extensions or modifications to accept the
sentences. The acceptance ratio of the blind test
is improving, so we believe KID will soon become
available for practical use.
</bodyText>
<page confidence="0.995834">
210
</page>
<figure confidence="0.8482745">
Construction description
Word assignment
Word contents description
■•••■• Class contents description
</figure>
<figureCaption confidence="0.997729">
Figure 11. The world model editor.
</figureCaption>
<figure confidence="0.6345235">
5 10 15 20 25
Elapsed time (days)
</figure>
<figureCaption confidence="0.995675">
Figure 12. Evaluation of KID.
</figureCaption>
<figure confidence="0.997601947368421">
3rd
98
95
1st
4th
Domain: New drug test
Total 400 sentences
Accepted 91%
100
90
80
70
60
50
40
30
20
10
0
</figure>
<page confidence="0.994588">
211
</page>
<sectionHeader confidence="0.977986" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999974162162162">
In this paper, the three features of the
Japanese-language interface KID were described.
KID has both a simple mechanism of parsing and
modularized grammar rules, so the parser is highly
extendable. The semantic interpretation has clear
principles based on the structure of the world
model and syntactic information of the input
sentence. Thus, the different levels of
robustness are achieved by the adequate portion of
the parser for dealing with the errors or
ellipses. The world model integrates the domain-
dependent knowledge separately. The user only has
to customize the world model to a specific
application. This customization is supported by
the world model editor which provides various
levels of user interfaces to make the world model
editing easy for various users.
KID is now implemented as a front-end system
for the relational database system (Makinouchi,
83). KID is implemented in Utilisp (Chikayama,
81), a dialect of Lisp. The morphological
analyzer is 0.7 ksteps, the model-based parser is
2.3 ksteps, and retriever is 2.2 ksteps. The
grammatical rule is 2.7 ksteps written in a rule
description language, and is made up of 70
packets. KID uses several tools and utilities.
The modeling system REALM is 2 ksteps, the world
model editor is 1.3 ksteps, the window system is
1.7 ksteps, and the knowledge-based programming
system, Minerva, is 3.5 ksteps.
We have several plans for future development.
We will expand the system to accept not only
retrieval sentences but also insertion, deletion,
update, statistical analysis, and graphic
operation. The parser coverage will be extended
to accept wider expressions, including parallel
phrases and sentences.
</bodyText>
<sectionHeader confidence="0.984953" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999864">
To Mr. Tatsuya Hayashi, Manager of the Software
Laboratory we express our gratitude for giving us
an opportunity to make these studies.
</bodyText>
<sectionHeader confidence="0.998692" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999855631578947">
Bobrow, D. G., Stefik, M., The LOOPS Manual: A
Data Oriented and Object Oriented Programming
System for Interlisp, Xerox Knowledge-Based
VLSI Design Group Memo, 1981, KB-VLSI-81-13.
Chikayama, T., Utilisp Manual, METR 81-6,
Mathematical Engineering Section, University of
Tokyo, 1981.
Ginsparg, J. M., A Robust Portable Natural
Language Data Base Interface, Proc. Conf.
Applied Natural Language Processing, 1983,
pp. 25-30.
Grosz, B. J., TEAM: A Transportable Natural-
Language Interface System, Proc. Conf. Applied
Natural Language Processing, 1983, pp.39-45.
Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D.,
Slocum, J., Developing a Natural Language
Interface to Complex Data, ACM TODS, Vol. 3,
No. 2, 1978, pp.105-147.
Izumida, Y. et al., A Database Retrieval System
Using a World Model, Symposium on Database
System, 43-22 Information Processing Society of
Japan, 1984 Lin Japanese].
Makinouchi, A. et al., Relational Databese
Management System RDB/V1, Transactions of
Information Processing Society of Japan, Vol.
24, No. 1, 1983, pp.47-55 [in Japanese].
Nilssen, N. J., Principles of Artificial
Intelligence, Tioga, 1980.
Waltz, D. L., An English Language Question
Answering System for a Large Relational
Database, Communication of the ACM, 1978,
27(7), pp.526-539.
Yoshimura, K., Hitaka, T., Yoshida, S.,
Morphological Analysis of Non-marked-off
Japanese Sentences by the Least BUNSETSU&apos;S
Number Method, Transactions of Information
Processing Society of Japan, Vol. 24, No. 1,
1983, pp.40-46 [in Japanese].
</reference>
<page confidence="0.998489">
212
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.833310">
<title confidence="0.997539">NATURAL LANGUAGE INTERFACE WORLD MODEL</title>
<author confidence="0.936915">Yoshio Izumida</author>
<author confidence="0.936915">Hiroshi Ishikawa</author>
<author confidence="0.936915">Toshiaki Yoshino</author>
<author confidence="0.936915">Tadashi Hoshiai</author>
<author confidence="0.936915">Akifumi Makinouchi</author>
<affiliation confidence="0.9938415">Software Laboratory Fujitsu Laboratories Ltd.</affiliation>
<address confidence="0.992892">1015 kamikodanaka, Nakahara-ku, Kawasaki, 211, Japan</address>
<abstract confidence="0.998358944444445">Databases are nowadays used by varied and diverse users, many of whom are unfamiliar with the workings of a computer, but who, nevertheless, want to use those databases more easily. Rising to meet this demand, authors are developing a Japanese language interface, called KID, as a database front-end system. KID incorporates a world model representing application and database knowledge to help make databases easier to use. KID has the following features: (1) parser extendability and robustness, (2) independence the application domain, (3) ease editing, (4) independence from the database. This paper focuses on the first three features. KID has already been applied to the fields of housing, sales, and drug testing, thus confirming its transportability and practicality.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>M Stefik</author>
</authors>
<title>The LOOPS Manual: A Data Oriented and Object Oriented Programming System for Interlisp, Xerox Knowledge-Based VLSI Design Group Memo,</title>
<date>1981</date>
<pages>81--13</pages>
<marker>Bobrow, Stefik, 1981</marker>
<rawString>Bobrow, D. G., Stefik, M., The LOOPS Manual: A Data Oriented and Object Oriented Programming System for Interlisp, Xerox Knowledge-Based VLSI Design Group Memo, 1981, KB-VLSI-81-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chikayama</author>
<author>Utilisp Manual</author>
</authors>
<date>1981</date>
<tech>METR 81-6,</tech>
<institution>Mathematical Engineering Section, University of Tokyo,</institution>
<marker>Chikayama, Manual, 1981</marker>
<rawString>Chikayama, T., Utilisp Manual, METR 81-6, Mathematical Engineering Section, University of Tokyo, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Ginsparg</author>
</authors>
<title>A Robust Portable Natural Language Data Base Interface,</title>
<date>1983</date>
<booktitle>Proc. Conf. Applied Natural Language Processing,</booktitle>
<pages>25--30</pages>
<marker>Ginsparg, 1983</marker>
<rawString>Ginsparg, J. M., A Robust Portable Natural Language Data Base Interface, Proc. Conf. Applied Natural Language Processing, 1983, pp. 25-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
</authors>
<title>TEAM: A Transportable NaturalLanguage Interface System,</title>
<date>1983</date>
<booktitle>Proc. Conf. Applied Natural Language Processing,</booktitle>
<pages>39--45</pages>
<marker>Grosz, 1983</marker>
<rawString>Grosz, B. J., TEAM: A Transportable NaturalLanguage Interface System, Proc. Conf. Applied Natural Language Processing, 1983, pp.39-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G G Hendrix</author>
<author>E D Sacerdoti</author>
<author>D Sagalowicz</author>
<author>J Slocum</author>
</authors>
<title>Developing a Natural Language Interface to Complex Data,</title>
<date>1978</date>
<journal>ACM TODS,</journal>
<volume>3</volume>
<pages>105--147</pages>
<marker>Hendrix, Sacerdoti, Sagalowicz, Slocum, 1978</marker>
<rawString>Hendrix, G. G., Sacerdoti, E. D., Sagalowicz, D., Slocum, J., Developing a Natural Language Interface to Complex Data, ACM TODS, Vol. 3, No. 2, 1978, pp.105-147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Izumida</author>
</authors>
<title>A Database Retrieval System Using a World Model,</title>
<date>1984</date>
<booktitle>Symposium on Database System, 43-22 Information Processing Society of Japan,</booktitle>
<note>Lin Japanese].</note>
<marker>Izumida, 1984</marker>
<rawString>Izumida, Y. et al., A Database Retrieval System Using a World Model, Symposium on Database System, 43-22 Information Processing Society of Japan, 1984 Lin Japanese].</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Makinouchi</author>
</authors>
<title>Relational Databese Management System RDB/V1,</title>
<date>1983</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<volume>24</volume>
<pages>47--55</pages>
<note>[in Japanese].</note>
<marker>Makinouchi, 1983</marker>
<rawString>Makinouchi, A. et al., Relational Databese Management System RDB/V1, Transactions of Information Processing Society of Japan, Vol. 24, No. 1, 1983, pp.47-55 [in Japanese].</rawString>
</citation>
<citation valid="true">
<authors>
<author>N J Nilssen</author>
</authors>
<date>1980</date>
<journal>Principles of Artificial Intelligence,</journal>
<location>Tioga,</location>
<marker>Nilssen, 1980</marker>
<rawString>Nilssen, N. J., Principles of Artificial Intelligence, Tioga, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Waltz</author>
</authors>
<title>An English Language Question Answering System for a Large Relational Database,</title>
<date>1978</date>
<journal>Communication of the ACM,</journal>
<volume>27</volume>
<issue>7</issue>
<pages>526--539</pages>
<marker>Waltz, 1978</marker>
<rawString>Waltz, D. L., An English Language Question Answering System for a Large Relational Database, Communication of the ACM, 1978, 27(7), pp.526-539.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yoshimura</author>
<author>T Hitaka</author>
<author>S Yoshida</author>
</authors>
<title>Morphological Analysis of Non-marked-off Japanese Sentences by the Least BUNSETSU&apos;S Number Method,</title>
<date>1983</date>
<journal>Transactions of Information Processing Society of Japan,</journal>
<volume>24</volume>
<pages>40--46</pages>
<note>[in Japanese].</note>
<marker>Yoshimura, Hitaka, Yoshida, 1983</marker>
<rawString>Yoshimura, K., Hitaka, T., Yoshida, S., Morphological Analysis of Non-marked-off Japanese Sentences by the Least BUNSETSU&apos;S Number Method, Transactions of Information Processing Society of Japan, Vol. 24, No. 1, 1983, pp.40-46 [in Japanese].</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>