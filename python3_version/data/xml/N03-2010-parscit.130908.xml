<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.071879">
<title confidence="0.9990865">
Question Classification with Support Vector Machines
and Error Correcting Codes
</title>
<author confidence="0.999525">
Kadri Hacioglu, Wayne Ward
</author>
<affiliation confidence="0.997774">
Center for Spoken Language Research
University of Colorado at Boulder
</affiliation>
<email confidence="0.999018">
fhacioglu,whwl@cslr.colorado.edu
</email>
<sectionHeader confidence="0.995657" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999736809523809">
In this paper we consider a machine learning
technique for question classification. The goal
is to replace our regular expression based clas-
sifier with a classifier that learns from a set of
labeled questions. We have realized that an
enourmous amount of time is required to cre-
ate a rich collection of patterns and keywords
for a good coverage of questions in an open-
domain application. We decided to use support
vector machines, since they have been success-
fully used for a number of benchmark prob-
lems. Although the support vector machines
are inherently binary classifiers, it is possible to
extend their use as multi-class classifiers using
binary codes. We represent questions as fre-
quency weighted vectors of salient terms. We
compare our approcah to related work that uses
relatively complex syntactic/semantic process-
ing to create features and a sparse network of
linear units to classify questions. We provide
results to show performance of the method.
</bodyText>
<sectionHeader confidence="0.999335" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99986312">
In current Question Answering (QA) systems it has been
widely accepted that the classification of questions into
one of several question types is very important. Ques-
tion type can be used for both query generation and an-
swer extraction to improve the efficiency and accuracy
of the overall sytsem. Approaches to question classifica-
tion (QC) can be considered in two broad classes; namely,
rule-based and statistical. In a rule-based approach a do-
main expert comes up with a number of regular expres-
sions and keywords. In a probabilistic approach, the ex-
pert knowledge is replaced by a sufficiently large collec-
tion of labelled questions. Then a model is assumed and
trained with the hope that the useful patterns for classi-
fication will be automatically captured. The latter ap-
proach has the advantage of saving expensive expert labor
and having easier portability to other domains.
We assume that a user seeks an answer that fulfills
his/her information need about an entity. Examples to en-
tity types are PERSON and CITY as in the queries &amp;quot;Who
invented the lamp?&amp;quot; and &amp;quot;Which city is the capital of Por-
tugal?&amp;quot;, respectively. We do not focus on questions like
&amp;quot;Who is Bill Clinton?&amp;quot; , &amp;quot;How the earth rotates around
sun?&amp;quot; etc., which are not asking for named entities, and
we map all to a general category called NA (not applica-
ble).
The first step in statistical QC is to design a taxonomy
of question (equivalently, answer) types. One can distin-
guish among taxonomies of having flat and hiererchical
structures, or taxonomies of having a small (10-30) and
large number of categories (above 50). After analyzing
several thousands of questions we created the Q/A entity
type taxonomy shown in figure 1. Although it provides a
detailed hierarcy of question types, one can collapse some
categories or introduce new categories depending on the
specifity required, coverage of the named entity recog-
nizer over the documents, availability of training data,
and required accuracy.
The second step is to create a corpus of labelled ques-
tions and train a classifier in a supervised manner. In this
step the choice of features (to represent the questions) and
the classifier (to assign questions into one of several cate-
gories) are very important. Features may vary from sim-
ple count statistics of words to detailed syntatic/semantic
features derived using computationally demanding lin-
guistic analysis. Classifiers can be implemented in sev-
eral ways. Possible choices are naive Bayes classifiers,
Neural network classifiers, vector-based classifiers, lan-
guage model based classifiers and support vector ma-
chines (SVMs) (Sebastiani, 2002). We have chosen sup-
port vector machines for QC, motivated by the fact that
</bodyText>
<figureCaption confidence="0.998469">
Figure 1: Question/Answer type taxonomy
</figureCaption>
<bodyText confidence="0.999781074074074">
they consistently outperformed other machine learning
techniques in several tasks including the text classifica-
tion (Rennie and Rifkin, 2001).
SVMs are binary classifiers (Burges, 1998). Although
QC is a multi-class classification problem, it can be con-
verted into a number of binary classification problems
(Allwein et al., 2000). Then SVMs can be applied to learn
each of these binary problems. Error correcting output
coding has been found promising to convert a multi-class
problem into a number of two-class problems (Dietterich
and Bakiri, 1991; Berger, 1999).
In a related work (Li and Roth, 2002), words, part-
of-speech (POS) tags, non-overlapping phrases (chunks),
named entities (NEs), head chunks and semantically re-
lated words are derived from questions and used as prim-
itive features. Then a set of operators were used to com-
pose more complex features from the primitive features.
The classifier is based on the SNoW (sparse Network of
Winnows) learning architecture. It is a sparse network of
linear units. The authors have made their training and test
data publicly available. We tested our system on the same
data and compared to their reported results. Using only
words to create features, we have reached a performance
level comparable with the result in (Li and Roth, 2002).
The main advantage of our approach is that computation-
ally expensive linguistic analysis and labor intensive cre-
ation of linguistic knowledge has been avoided.
</bodyText>
<sectionHeader confidence="0.790714" genericHeader="method">
2 Description of the Classifier
</sectionHeader>
<bodyText confidence="0.999102">
Our approach to classification is illustrated in Figure 1.
The interesting aspect of this system is that all of its mod-
ules are constructed using readily available free software
and a question corpus. We believe that our results would
encourage many people to use these resources to deploy
</bodyText>
<figure confidence="0.598006">
Question text
</figure>
<figureCaption confidence="0.9578455">
Figure 2: Classification scheme: (a) Overall system, (b)
Classifier
</figureCaption>
<bodyText confidence="0.998797368421052">
a descent statistical classifier in their systems.
The preprocessor tasks are (1) skipping of everything
but a-z and A-Z characters (2) changing of each charac-
ter to lower case, (3) excluding of each word in a user-
defined &amp;quot;stoplist&amp;quot; and (4) stemming. One can augment
the preprocessor with much sophisticated processing us-
ing a named entity tagger, part of speech tagger, chun-
ker etc. The input to the indexer is a sequence of words
and/or tags, and/or chunks (if a tagger or chunker is used).
Based on the specification of a term, the indexer groups
tokens into terms and accumulates their statistics. Of-
ten the dimensionality of the term space is unnecessarily
high. Because of this, dimensionality reduction is very
common before classification. It helps to reduce noise
in the input space, avoid overfitting during training with
sparse data and lower computational complexity. How-
ever, it should be done with care to minimize the loss
of useful information for classification. Several tech-
niques based on heuristics and information theory have
been proposed. The final reduced space has basis defined
by terms, and those basis may not be the optimal for the
classification task. So it might be useful to transform the
term space into another space. This can be done by com-
puting transformations using singular value decomposi-
tion (SVD) , independent component analysis etc. (Srini-
vasan, 2002).
Question classification is a multi-class classification
problem and SVMs are binary classifiers. An extension
of SVMs to QC is possible using codes. Each class is
assigned a codeword of l&apos;s and -1&apos;s of length m. Here,
m can be selected equal or greater than the number of
classes. This splits the multi-class data into m binary
class data. Therefore, one can design m SVM classi-
fiers, combine their outputs and minimize a loss function
to predict multi-class labels. One-vs-all, random and er-
ror correcting codes can be used for this purpose.
We used Rainbow (McCallum, 1996) for preprocess-
ing, indexing and term reduction, SVDPACKC for
</bodyText>
<figure confidence="0.958021230769231">
&apos;http://www.netlib.org/svdpack/svdpackc.tgz
Preprocessor
lurk-Ain;
Feature Extraction HClassification H
(a)
ore sin class
m SVM labels
Classifiers Combiner
feature vector
Dimension Transformation
Reduction
Class label
Classifier
</figure>
<bodyText confidence="0.956141666666667">
transformation, SvmFu 2 for classification, and BCH
codes 3 as error correcting codes. We used the same train-
ing data as in (Li and Roth, 2002) to train the classifier.
</bodyText>
<sectionHeader confidence="0.987487" genericHeader="method">
3 Experimental Results
</sectionHeader>
<bodyText confidence="0.998225714285714">
The training data consists of 5500 labeled questions
which have been made publicly available 4. The total
number of Q/A types is 50. The test data is 500 la-
beled questions from TREC-10. The final term space
is created by indexing word tokens as N-grams and se-
lecting the first N1 most informative terms. In addition
to &amp;quot;words only&amp;quot; experiments, we carried out experiments
using Identifinder, a named entity (NE) tagger developed
at BBN (Bikel et al., 1997) with 7 and 29 tags. We
used SVD to transform the term space into a new space
spanned by SVD derived basis. We tried 50 x 50 one-
vs-all (OVA) and 63-50 BCH codes. SVMs are trained
using linear kernels. The hinge loss function is used in
combining SVM outputs into a multi-class label.
</bodyText>
<tableCaption confidence="0.972612">
Table 1: Question classification results with and without
named entity (NE) tagger for different n-grams The first most
informative 2000 terms were retained in the feature space.
</tableCaption>
<table confidence="0.9977655">
Method 1-gram 2-gram 3-gram
No NE 79.4% 80.2% (77.8%) 78.4%
NE-7 81.4% 82.0% ( 81.2%) 80.2%
NE-29 75.4 78.6% ( 79.2%) 78.8%
</table>
<bodyText confidence="0.998305384615385">
Inspection of a set of questions has shown that the in-
ferior performance of NE-29 is due to (a) the 29-NE has
a tagging performance worse than that of 7-NE, and (b)
some words which are very discriminative across several
question types are collapsed into a single broad tag (e.g.
GPE_DESC includes words like city, state, country etc.)
Results in parantheses show slightly inferior performance
of the 50 x 50 OVA code.
The best result in (Li and Roth, 2002) for their flat clas-
sifier is 84.0%, using all features derived from words,
NEs, POS tags, chunks, heads and related words. It
should be noted that their &amp;quot;words only&amp;quot; performance is
52.4%.
</bodyText>
<tableCaption confidence="0.9685425">
Table 2: Question classification results with SVD transforma-
tion, NE-7 and BCH codes
</tableCaption>
<footnote confidence="0.999961">
2http://five-percent-nation.mitedu/SvmFu
3http://www.cs.cmu.edur rayid/ecoc/ecoc-codes.tar.gz
4http://12r.cs.uiuc.edur cogcomp/Data/QA/QC
</footnote>
<bodyText confidence="0.9994896">
In Table 2 we compare the results obtained using the
default terms and SVD vectors as basis for the feature
representation. Its seems that the default terms as basis
outperforms the SVD based basis. This agrees with the
results reported in (Srinivasan, 2002).
</bodyText>
<sectionHeader confidence="0.999401" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99998">
We have introduced a statistical question/answer type
classifier with a similar structure that has been recently
considered for text categorization. We have augmented
the system with a named entity tagger and SVD based
transformation. Although the NE tagging has improved
the performance, we have observed some performance
loss with SVD transformation. A comparison with re-
lated work has shown that the approach is very promising
yielding comparable performance with minimal and even
with no linguistic analysis.
</bodyText>
<sectionHeader confidence="0.998855" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99911196969697">
Erin L. Allwein, Robert E. Schapire, and Yoram Singer. 2000.
Reducing multiclass to binary: A unifying approach for
margin classifiers. Journal of Machine Learning Research,
1:113-141.
A. Berger. 1999. Error-correcting output coding for text clas-
sification. Workshop on Machine Learnibg for Information
Filtering, Stockholm, Sweeden.
D. Bikel, S. Miller, R. Schwartz, and R. Weischedel 1997
Nymble: a High-Performance Learning Name-finder. In
Fifth Conference on Applied Natural Language Processing,
pages 194-201.
C. J. Burges 1998. A tutorial on support vector machines for
pattern recognition. Data Mining and Knowledge Discovery.
2(2), pages 121-167, 1998.
Tom G. Dietterich and Ghulum Balciri. 2002. Error correcting
output codes: A general method for improving multiclass in-
ductive learning programs. Ninth National Conference on
Artificial Intelligence, pages 572-577, Anaheim, CA, AAAI
Press.
A. Kachites MCCallum. 1996. Bow: A toolkit for statistical
language modeling, text retrival, classification and cluster-
ing. http://www.cs.cmu.edul- mccalum/bow.
Xin Li, Dan Roth 2002. Learning Question Classifiers. COL-
ING&apos;02.
J.D.M. Rennie, R. Riflcin 2001. Improving multiclass text clas-
sification with the support vector machine. MIT Artificial
Intelligence Laboratory Publications, AIM-2001-026..
F. Sebastiani 2002. Machine learning in automated text cate-
gorization. ACM Computing Surveys, Vol. 34, No. 1, pages
1-47.
S. H. Srinivasan 2002. Features for unsupervised document
classification. Proceedings of CoNLL-2002, pages 36-42.
Taipei, Taiwan,. 2(2):121-167, 1998.
</reference>
<table confidence="0.467261">
Default,2000 Default 1000 SVD, 1000 SVD, 500
82.0% 81.8% 79.8% 79.2%
</table>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.973248">
<title confidence="0.99952">Question Classification with Support Vector and Error Correcting Codes</title>
<author confidence="0.992077">Kadri Hacioglu</author>
<author confidence="0.992077">Wayne</author>
<affiliation confidence="0.998002">Center for Spoken Language University of Colorado at</affiliation>
<email confidence="0.998874">fhacioglu,whwl@cslr.colorado.edu</email>
<abstract confidence="0.999381090909091">In this paper we consider a machine learning technique for question classification. The goal is to replace our regular expression based classifier with a classifier that learns from a set of labeled questions. We have realized that an enourmous amount of time is required to create a rich collection of patterns and keywords for a good coverage of questions in an opendomain application. We decided to use support vector machines, since they have been successfully used for a number of benchmark problems. Although the support vector machines are inherently binary classifiers, it is possible to extend their use as multi-class classifiers using binary codes. We represent questions as frequency weighted vectors of salient terms. We compare our approcah to related work that uses relatively complex syntactic/semantic processing to create features and a sparse network of linear units to classify questions. We provide results to show performance of the method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Erin L Allwein</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Reducing multiclass to binary: A unifying approach for margin classifiers.</title>
<date>2000</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>1--113</pages>
<contexts>
<context position="4270" citStr="Allwein et al., 2000" startWordPosition="671" endWordPosition="674">oices are naive Bayes classifiers, Neural network classifiers, vector-based classifiers, language model based classifiers and support vector machines (SVMs) (Sebastiani, 2002). We have chosen support vector machines for QC, motivated by the fact that Figure 1: Question/Answer type taxonomy they consistently outperformed other machine learning techniques in several tasks including the text classification (Rennie and Rifkin, 2001). SVMs are binary classifiers (Burges, 1998). Although QC is a multi-class classification problem, it can be converted into a number of binary classification problems (Allwein et al., 2000). Then SVMs can be applied to learn each of these binary problems. Error correcting output coding has been found promising to convert a multi-class problem into a number of two-class problems (Dietterich and Bakiri, 1991; Berger, 1999). In a related work (Li and Roth, 2002), words, partof-speech (POS) tags, non-overlapping phrases (chunks), named entities (NEs), head chunks and semantically related words are derived from questions and used as primitive features. Then a set of operators were used to compose more complex features from the primitive features. The classifier is based on the SNoW (</context>
</contexts>
<marker>Allwein, Schapire, Singer, 2000</marker>
<rawString>Erin L. Allwein, Robert E. Schapire, and Yoram Singer. 2000. Reducing multiclass to binary: A unifying approach for margin classifiers. Journal of Machine Learning Research, 1:113-141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
</authors>
<title>Error-correcting output coding for text classification.</title>
<date>1999</date>
<booktitle>Workshop on Machine Learnibg for Information Filtering,</booktitle>
<location>Stockholm, Sweeden.</location>
<contexts>
<context position="4505" citStr="Berger, 1999" startWordPosition="710" endWordPosition="711">ct that Figure 1: Question/Answer type taxonomy they consistently outperformed other machine learning techniques in several tasks including the text classification (Rennie and Rifkin, 2001). SVMs are binary classifiers (Burges, 1998). Although QC is a multi-class classification problem, it can be converted into a number of binary classification problems (Allwein et al., 2000). Then SVMs can be applied to learn each of these binary problems. Error correcting output coding has been found promising to convert a multi-class problem into a number of two-class problems (Dietterich and Bakiri, 1991; Berger, 1999). In a related work (Li and Roth, 2002), words, partof-speech (POS) tags, non-overlapping phrases (chunks), named entities (NEs), head chunks and semantically related words are derived from questions and used as primitive features. Then a set of operators were used to compose more complex features from the primitive features. The classifier is based on the SNoW (sparse Network of Winnows) learning architecture. It is a sparse network of linear units. The authors have made their training and test data publicly available. We tested our system on the same data and compared to their reported resul</context>
</contexts>
<marker>Berger, 1999</marker>
<rawString>A. Berger. 1999. Error-correcting output coding for text classification. Workshop on Machine Learnibg for Information Filtering, Stockholm, Sweeden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bikel</author>
<author>S Miller</author>
<author>R Schwartz</author>
<author>R Weischedel</author>
</authors>
<title>Nymble: a High-Performance Learning Name-finder.</title>
<date>1997</date>
<booktitle>In Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>194--201</pages>
<contexts>
<context position="8708" citStr="Bikel et al., 1997" startWordPosition="1384" endWordPosition="1387">lassification, and BCH codes 3 as error correcting codes. We used the same training data as in (Li and Roth, 2002) to train the classifier. 3 Experimental Results The training data consists of 5500 labeled questions which have been made publicly available 4. The total number of Q/A types is 50. The test data is 500 labeled questions from TREC-10. The final term space is created by indexing word tokens as N-grams and selecting the first N1 most informative terms. In addition to &amp;quot;words only&amp;quot; experiments, we carried out experiments using Identifinder, a named entity (NE) tagger developed at BBN (Bikel et al., 1997) with 7 and 29 tags. We used SVD to transform the term space into a new space spanned by SVD derived basis. We tried 50 x 50 onevs-all (OVA) and 63-50 BCH codes. SVMs are trained using linear kernels. The hinge loss function is used in combining SVM outputs into a multi-class label. Table 1: Question classification results with and without named entity (NE) tagger for different n-grams The first most informative 2000 terms were retained in the feature space. Method 1-gram 2-gram 3-gram No NE 79.4% 80.2% (77.8%) 78.4% NE-7 81.4% 82.0% ( 81.2%) 80.2% NE-29 75.4 78.6% ( 79.2%) 78.8% Inspection of</context>
</contexts>
<marker>Bikel, Miller, Schwartz, Weischedel, 1997</marker>
<rawString>D. Bikel, S. Miller, R. Schwartz, and R. Weischedel 1997 Nymble: a High-Performance Learning Name-finder. In Fifth Conference on Applied Natural Language Processing, pages 194-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Burges</author>
</authors>
<title>A tutorial on support vector machines for pattern recognition.</title>
<date>1998</date>
<journal>Data Mining and Knowledge Discovery.</journal>
<volume>2</volume>
<issue>2</issue>
<pages>121--167</pages>
<contexts>
<context position="4125" citStr="Burges, 1998" startWordPosition="650" endWordPosition="651">emantic features derived using computationally demanding linguistic analysis. Classifiers can be implemented in several ways. Possible choices are naive Bayes classifiers, Neural network classifiers, vector-based classifiers, language model based classifiers and support vector machines (SVMs) (Sebastiani, 2002). We have chosen support vector machines for QC, motivated by the fact that Figure 1: Question/Answer type taxonomy they consistently outperformed other machine learning techniques in several tasks including the text classification (Rennie and Rifkin, 2001). SVMs are binary classifiers (Burges, 1998). Although QC is a multi-class classification problem, it can be converted into a number of binary classification problems (Allwein et al., 2000). Then SVMs can be applied to learn each of these binary problems. Error correcting output coding has been found promising to convert a multi-class problem into a number of two-class problems (Dietterich and Bakiri, 1991; Berger, 1999). In a related work (Li and Roth, 2002), words, partof-speech (POS) tags, non-overlapping phrases (chunks), named entities (NEs), head chunks and semantically related words are derived from questions and used as primitiv</context>
</contexts>
<marker>Burges, 1998</marker>
<rawString>C. J. Burges 1998. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery. 2(2), pages 121-167, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom G Dietterich</author>
<author>Ghulum Balciri</author>
</authors>
<title>Error correcting output codes: A general method for improving multiclass inductive learning programs.</title>
<date>2002</date>
<booktitle>Ninth National Conference on Artificial Intelligence,</booktitle>
<pages>572--577</pages>
<publisher>AAAI Press.</publisher>
<location>Anaheim, CA,</location>
<marker>Dietterich, Balciri, 2002</marker>
<rawString>Tom G. Dietterich and Ghulum Balciri. 2002. Error correcting output codes: A general method for improving multiclass inductive learning programs. Ninth National Conference on Artificial Intelligence, pages 572-577, Anaheim, CA, AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kachites MCCallum</author>
</authors>
<title>Bow: A toolkit for statistical language modeling, text retrival, classification and clustering.</title>
<date>1996</date>
<note>http://www.cs.cmu.edul- mccalum/bow.</note>
<marker>MCCallum, 1996</marker>
<rawString>A. Kachites MCCallum. 1996. Bow: A toolkit for statistical language modeling, text retrival, classification and clustering. http://www.cs.cmu.edul- mccalum/bow.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Li</author>
</authors>
<title>Learning Question Classifiers.</title>
<date>2002</date>
<tech>COLING&apos;02.</tech>
<location>Dan Roth</location>
<marker>Li, 2002</marker>
<rawString>Xin Li, Dan Roth 2002. Learning Question Classifiers. COLING&apos;02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D M Rennie</author>
<author>R Riflcin</author>
</authors>
<title>Improving multiclass text classification with the support vector machine.</title>
<date>2001</date>
<journal>MIT Artificial Intelligence Laboratory Publications,</journal>
<pages>2001--026</pages>
<marker>Rennie, Riflcin, 2001</marker>
<rawString>J.D.M. Rennie, R. Riflcin 2001. Improving multiclass text classification with the support vector machine. MIT Artificial Intelligence Laboratory Publications, AIM-2001-026..</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sebastiani</author>
</authors>
<title>Machine learning in automated text categorization.</title>
<date>2002</date>
<journal>ACM Computing Surveys,</journal>
<volume>34</volume>
<pages>1--47</pages>
<contexts>
<context position="3824" citStr="Sebastiani, 2002" startWordPosition="606" endWordPosition="607"> of labelled questions and train a classifier in a supervised manner. In this step the choice of features (to represent the questions) and the classifier (to assign questions into one of several categories) are very important. Features may vary from simple count statistics of words to detailed syntatic/semantic features derived using computationally demanding linguistic analysis. Classifiers can be implemented in several ways. Possible choices are naive Bayes classifiers, Neural network classifiers, vector-based classifiers, language model based classifiers and support vector machines (SVMs) (Sebastiani, 2002). We have chosen support vector machines for QC, motivated by the fact that Figure 1: Question/Answer type taxonomy they consistently outperformed other machine learning techniques in several tasks including the text classification (Rennie and Rifkin, 2001). SVMs are binary classifiers (Burges, 1998). Although QC is a multi-class classification problem, it can be converted into a number of binary classification problems (Allwein et al., 2000). Then SVMs can be applied to learn each of these binary problems. Error correcting output coding has been found promising to convert a multi-class proble</context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>F. Sebastiani 2002. Machine learning in automated text categorization. ACM Computing Surveys, Vol. 34, No. 1, pages 1-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S H Srinivasan</author>
</authors>
<title>Features for unsupervised document classification.</title>
<date>2002</date>
<booktitle>Proceedings of CoNLL-2002,</booktitle>
<pages>36--42</pages>
<location>Taipei,</location>
<contexts>
<context position="7192" citStr="Srinivasan, 2002" startWordPosition="1145" endWordPosition="1147">e input space, avoid overfitting during training with sparse data and lower computational complexity. However, it should be done with care to minimize the loss of useful information for classification. Several techniques based on heuristics and information theory have been proposed. The final reduced space has basis defined by terms, and those basis may not be the optimal for the classification task. So it might be useful to transform the term space into another space. This can be done by computing transformations using singular value decomposition (SVD) , independent component analysis etc. (Srinivasan, 2002). Question classification is a multi-class classification problem and SVMs are binary classifiers. An extension of SVMs to QC is possible using codes. Each class is assigned a codeword of l&apos;s and -1&apos;s of length m. Here, m can be selected equal or greater than the number of classes. This splits the multi-class data into m binary class data. Therefore, one can design m SVM classifiers, combine their outputs and minimize a loss function to predict multi-class labels. One-vs-all, random and error correcting codes can be used for this purpose. We used Rainbow (McCallum, 1996) for preprocessing, ind</context>
</contexts>
<marker>Srinivasan, 2002</marker>
<rawString>S. H. Srinivasan 2002. Features for unsupervised document classification. Proceedings of CoNLL-2002, pages 36-42. Taipei, Taiwan,. 2(2):121-167, 1998.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>