<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.037617">
<title confidence="0.99769">
A Probabilistic Morphological Analyzer for Syriac
</title>
<author confidence="0.9946715">
Peter McClanahan, George Busby, Robbie Haertel, Kristian Heal †,
Deryle Lonsdale‡, Kevin Seppi, Eric Ringger
</author>
<affiliation confidence="0.954994">
Department of Computer Science, ‡Department of Linguistics,
†Center for the Preservation of Ancient Religious Texts (CPART)
Brigham Young University
</affiliation>
<address confidence="0.641841">
Provo, Utah 84604 USA
</address>
<email confidence="0.956258">
http://nlp.cs.byu.edu/
</email>
<sectionHeader confidence="0.992944" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999722789473684">
We define a probabilistic morphological ana-
lyzer using a data-driven approach for Syriac in
order to facilitate the creation of an annotated
corpus. Syriac is an under-resourced Semitic
language for which there are no available lan-
guage tools such as morphological analyzers.
We introduce novel probabilistic models for
segmentation, dictionary linkage, and morpho-
logical tagging and connect them in a pipeline
to create a probabilistic morphological analyzer
requiring only labeled data. We explore the per-
formance of models with varying amounts of
training data and find that with about 34,500
labeled tokens, we can outperform a reason-
able baseline trained on over 99,000 tokens and
achieve an accuracy of just over 80%. When
trained on all available training data, our joint
model achieves 86.47% accuracy, a 29.7% re-
duction in error rate over the baseline.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979166666667">
Our objective is to facilitate the annotation of a large
corpus of classical Syriac (referred to simply as “Syr-
iac” throughout the remainder of this work). Syr-
iac is an under-resourced Western Semitic language
of the Christian Near East and a dialect of Aramaic.
It is currently employed almost entirely as a liturgi-
cal language but was a true spoken language up un-
til the eighth century, during which time many pro-
lific authors wrote in Syriac. Even today there are
texts still being composed in or translated into Syr-
iac. By automatically annotating these texts with lin-
guistically useful information, we will facilitate sys-
tematic study by scholars of Syriac, the Near East,
and Eastern Christianity. Furthermore, languages
that are linguistically similar to Syriac (e.g., Arabic
and Hebrew) may benefit from the methodology pre-
sented here.
Our desired annotations include morphological
segmentation, links to dictionary entries, and mor-
phological attributes. Typically, annotations of this
kind are made with the assistance of language tools,
such as morphological analyzers, segmenters, or
part-of-speech (POS) taggers. Such tools do not
exist for Syriac, but some labeled data does exist:
Kiraz (1994) compiled an annotated version of the
Peshitta New Testament (1920) and a concordance
thereof. We aim to replicate this kind of annota-
tion on a much larger scale with more modern tools,
building up from the labeled New Testament data,
our only resource. Motivated by this state of affairs,
our learning and annotation framework requires only
labeled data.
We approach the problem of Syriac morphological
annotation by creating five probabilistic sub-models
that can be trained in a supervised fashion and com-
bined in a joint model of morphological annota-
tion. We introduce novel algorithms for segmenta-
tion, dictionary linkage, and morphological tagging.
We then combine these sub-models into a joint n-
best pipeline. This joint model outperforms a strong,
though naïve, baseline for all amounts of training
data over about 9,900 word tokens.
</bodyText>
<subsectionHeader confidence="0.996107">
1.1 Syriac Background
</subsectionHeader>
<bodyText confidence="0.999924833333333">
Since Syriac is an abjad, its writing system does
not require vowels. As a dialect of Aramaic, it
is an inflected language with a templatic (non-
concatenative) morphology, based on a system of
triliteral consonantal roots, with prefixes, suffixes,
infixes, and enclitic particles. Syriac is written from
</bodyText>
<page confidence="0.956872">
810
</page>
<note confidence="0.817175">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 810–820,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.998836555555556">
right to left. For the purposes of this work, all Syr-
iac is transliterated according to the Kiraz (1994)
transliteration1 and is written left-to-right whenever
transliterated; the Syriac appearing in the Serto script
in this paper is shown right-to-left.
Since there is no standardized nomenclature for
the parts of a Syriac word, we define the following
terms to facilitate the definitions of segmentation,
dictionary linkage, and morphological tagging:
</bodyText>
<listItem confidence="0.997786636363636">
• word token - contiguous characters delimited by
whitespace and/or punctuation
• stem - an inflected form of the baseform and
the main part of the word to which prefixes and
suffixes can be attached; the affixes do not in-
flect the stem but include prepositions, object
suffixes, and enclitic pronouns
• baseform - the dictionary citation form; also
known as a lexeme or lemma
• root - the form from which the baseform is de-
rived
</listItem>
<bodyText confidence="0.9999153125">
To clarify, we will use an example word token
ܢŴƄƄƇƊƆ, LMLCCON, which means “to your (mas-
culine plural) king”. For this word, the stem is ƅƇƉ,
MLC; the baseform is ťƄƇƉ, MLCA “king”; and the
root isƅƇƉ, MLC. To clarify, note that the word token
(including the stem) can be spoken and written with
vowels as diacritics; however, since the vowels are
not written in common practice and since most text
does not include them, this work omits any indica-
tion of vowels. Furthermore, the stem is an inflected
baseform and does not necessarily form a word on
its own. Also, the (unvocalized) stem and root are
not necessarily identical. In Syriac, the same root
ƅƇƉ, MLC is the foundation for other words such as
promise, counsel, deliberate, reign, queen, kingdom,
and realm.
</bodyText>
<subsectionHeader confidence="0.987376">
1.2 Sub-tasks
</subsectionHeader>
<bodyText confidence="0.9996525">
Segmentation, or tokenization as it is sometimes
called (e.g., Habash and Rambow, 2007), is the pro-
cess of dividing a word token into its prefix(es) (if
any), a stem, and a suffix (if any). For Syriac, each
</bodyText>
<footnote confidence="0.652106">
1According to this transliteration all capital letters including
A (ܐ, olaph) and O (ܘ, waw) are consonants. Additionally, the
semi-colon (;), representing (ܝ, yod), is also a consonant.
</footnote>
<bodyText confidence="0.999880479166667">
word token consists of exactly one stem, from zero
to three prefixes, and zero or one suffix. Each pre-
fix is exactly one character in length. Segmenta-
tion does not include the process of parsing the stem
for its inflectional morphology; that step is handled
separately in subsequent processes described below.
While segmenting a Syriac word, we can handle all
prefixes as a single unit. It is trivial to segment a
prefix cluster into its individual prefixes (one charac-
ter per prefix). Suffixes may be multiple characters
in length and encode the morphological attributes of
the suffix itself (not of the stem); the suffix usually
encodes the object of the stem and has its own gram-
matical attributes, which we list later. As an example
of token segmentation, for the word token ܢŴƄƄƇƊƆ,
LMLCCON, the prefix is ܠ, L “to”, the stem is ƅƇƉ,
MLC “king”, and the suffix is ܢŴƃ, CON “(masculine
plural) your”.
Dictionary linkage is the process of linking a stem
to its associated baseform and root. In most Syriac
dictionaries, all headwords are either baseforms or
roots, and for a given word these are the only rele-
vant entries in the dictionary. Each Syriac stem is
derived from a baseform, and each baseform is de-
rived from a root. There is ambiguity in this cor-
respondence which can be caused by, among other
things, homographic stems generated from different
roots or even from homographic roots. As such, link-
age may be thought of as two separate processes: (1)
baseform linkage, where the stem is mapped to its
most likely baseform; and (2) root linkage, where
the baseform is mapped to its most likely root. For
our example ܢŴƄƄƇƊƆ, LMLCCON, baseform linkage
would map stem ƅƇƉ, MLC to baseform ťƄƇƉ, MLCA,
and root linkage would map baseform ťƄƇƉ, MLCA to
root ƅƇƉ, MLC.
Morphological tagging is the process of labeling
each word token with its morphological attributes.
Morphological tagging may be thought of as two
separate tagging tasks: (1) tagging the stem and (2)
tagging the suffix. For Syriac, scholars have defined
for this task a set of morphological attributes con-
sisting of twelve attributes for the stem and four at-
tributes for the suffix. The attributes for the stem
are as follows: grammatical category, verb conju-
gation, aspect, state, number, person, gender, pro-
noun type, demonstrative category, noun type, nu-
meral type, and participle type. The morphological
</bodyText>
<page confidence="0.997267">
811
</page>
<table confidence="0.999809153846154">
Attribute Value
Grammatical Category noun
Verb Conjugation N/A
Aspect N/A
State emphatic
Number singular
Person N/A
Gender masculine
Pronoun Type N/A
Demonstrative Category N/A
Noun Type common
Numeral Type N/A
Participle Type N/A
</table>
<tableCaption confidence="0.930885">
Table 1: The values for the morphological attributes of
the stem .�,w, MLC, “king”.
</tableCaption>
<table confidence="0.992619">
Attribute Value
Gender masculine
Person second
Number plural
Contraction normal suffix
</table>
<tableCaption confidence="0.9848925">
Table 2: The values for the morphological attributes of
the suffix ,�, CON, “(masculine plural) your”.
</tableCaption>
<bodyText confidence="0.999770869565217">
attributes for the suffix are gender, person, number,
and contraction. The suffix contraction attribute en-
codes whether the suffix is normal or contracted, a
phonological process involving the attachment of an
enclitic pronoun to a participle. These morphologi-
cal attributes were heavily influenced by those used
by Kiraz (1994), but were streamlined in order to fo-
cus directly on grammatical function. During mor-
phological tagging, each stem is labeled for each of
the stem attributes, and each suffix is labeled for each
of the suffix attributes. For a given grammatical cat-
egory (or POS), only a subset of the morphological
attributes is applicable. For those morphological at-
tributes (both of the stem and of the suffix) that do
not apply, the correct label is “N/A” (not applicable).
Tables 1 and 2 show the correct stem and suffix tags
for the word � -�, LMLCCON.
The remainder of the paper will proceed as fol-
lows: Section 3 outlines our approach. In Section 4,
we describe our experimental setup; we present re-
sults in Section 5. Section 6 contrasts previous work
with our approach. Finally, in Section 7 we briefly
conclude and offer directions for future work.
</bodyText>
<sectionHeader confidence="0.822964" genericHeader="method">
2 The Syromorph Approach
</sectionHeader>
<bodyText confidence="0.999985090909091">
Since lack language tools, we focus on automatically
annotating Syriac text in a data-driven fashion based
on the labeled data we have available. Since seg-
mentation, linkage, and morphological tagging are
not mutually independent tasks, we desire models
for the sub-tasks to influence each other. To accom-
modate these requirements, we use a joint pipeline
model (Finkel et al., 2006). In this section, we will
first discuss this joint pipeline model, which we call
syromorph. We then examine each of the individual
sub-models.
</bodyText>
<subsectionHeader confidence="0.964338">
2.1 Joint Pipeline Model
</subsectionHeader>
<bodyText confidence="0.9999952">
Our approach is to create a joint pipeline model con-
sisting of a segmenter, a baseform linker, a root
linker, a suffix tagger, and a stem tagger. Figure 1
shows the dependencies among the sub-models in
the pipeline for a single word. Each sub-model
(oval) has access to the data and predictions (rect-
angles) indicated by the arrows. For example, for a
given word, the stem tagger has access to the previ-
ously predicted stem, baseform, root, and suffix tag.
The baseform linker has access to the segmentation,
most importantly the stem.
The training of syromorph is straightforward.
Each of the individual sub-models is trained sepa-
rately on the true labeled data. Features are extracted
from the local context in the sentence. The local con-
text consists first of predictions for the entire sen-
tence from earlier sub-tasks (those sub-tasks upon
which the sub-task in question depends). We cre-
ated the dependencies shown in Figure 1 taking into
account the difficulty of the tasks and natural depen-
dencies in the language. In addition to the predic-
tions for the entire sentence from previous sub-tasks,
the local context also includes the previous o tags of
the current sub-task, as the standard order o Markov
model does. For example, when the stem tagger is
being trained on a particular sentence, the local con-
text consists of the words in the sentence, the pre-
dicted segmentation, baseform, root, and suffix tags
for each word in the sentence, and additionally the
labels for the previous o stems. To further elaborate
</bodyText>
<page confidence="0.995128">
812
</page>
<figureCaption confidence="0.936968">
Figure 1: The syromorph model. Each rectangle is an
input or output and each oval is a process employing a
sub-model.
</figureCaption>
<bodyText confidence="0.999981857142857">
on the example, since features are extracted from the
local context, for stem tagging we extract features
such as current stem, previous stem, current base-
form, previous baseform, current root, previous root,
current suffix tags, and previous suffix tags. (Here,
“previous” refers to labels on the immediately pre-
ceding word token.)
</bodyText>
<subsectionHeader confidence="0.998766">
2.2 Segmentation
</subsectionHeader>
<bodyText confidence="0.999972055555556">
The syromorph segmentation model is a hybrid
word- and consonant-level model, based on the
model of Haertel et al. (2010) for data-driven dia-
critization. Each of our probabilistic sequence mod-
els is a maximum entropy Markov model (MEMM).
Haertel et al. (2010) showed that the distribution
over labels is different for known and words and rare
words. In this work, we only consider words not
seen in training (i.e., “unknown”) to be rare. Follow-
ing Haertel et al.’s (2010) model, a separate model
is trained for each word type seen in training with
the intent of choosing the best segmentation given
that word. This approach is closely related to the
idea of ambiguity classes mentioned in Hajič and
Hladká (1998).
To handle unknown words, we back off to a
consonant-level model. Our consonant-level seg-
mentation model uses the notion of BI (Beginning
and Inside) tags, which have proven successful in
named-entity recognition. Since there are three
labels in which we are interested (prefix, stem, and
suffix), we apply the beginning and inside notion
to each of them to create six tags: BEGINNING-
PREFIX, INSIDE-PREFIX, BEGINNING-STEM,
INSIDE-STEM, BEGINNING-SUFFIX, and
INSIDE-SUFFIX. We train an MEMM to predict
one of these six tags for each consonant. Further-
more, we constrain the decoder to allow only legal
possible transitions given the current prediction,
so that prefixes must come before stems and stems
before suffixes. In order to capture the unknown
word distributions, we train the consonant-level
model on words occurring only once during training.
We call this word- and consonant-level segmenta-
tion model hybrid. As far as we are aware, this is a
novel approach to segmentation.
</bodyText>
<subsectionHeader confidence="0.998889">
2.3 Dictionary Linkage
</subsectionHeader>
<bodyText confidence="0.999993041666666">
For dictionary linkage, we divide the problem into
two separate tasks: baseform linkage and root link-
age. For both of these tasks, we use a hybrid model
similar to that used for segmentation, consisting of
a collection of separate MEMMs for each word type
(either a stem or baseform, depending on the linker)
and a model for unknown (or rare) words. For the un-
known words, we compare two distinct approaches.
The first approach for unknown words is based
on the work of Chrupała (2006), including the Mor-
fette system. Instead of predicting a baseform given
a stem, we predict what Chrupała calls a lemma-
class. A lemma-class is the transformation specified
by the minimum edit distance between the baseform
(which he calls a lemma) and the stem. The trans-
formation is a series of tuples, where each tuple in-
cludes (1) whether it was an insertion or deletion,
(2) the letter inserted or deleted, and (3) the position
of the insertion or deletion in the string (positions
begin at zero). All operations are assumed to oc-
cur sequentially, as in Morfette. For example, the
transformation of XE;N to XEA would proceed as
follows: delete ; from position 2, insert A into po-
sition 2, delete N from position 3.
</bodyText>
<page confidence="0.992791">
813
</page>
<bodyText confidence="0.999988814814815">
In hybrid-morfette baseform linkage (respec-
tively, root linkage), we predict a lemma-class (i.e.,
transformation) for each baseform (respectively,
root). The predicted transformation is then applied
to the stem (respectively, baseform) in order to con-
struct the actual target baseform (respectively, root).
The advantage to this method is that common trans-
formations are grouped into a single class, thereby
allowing the model to generalize and adequately
predict baseforms (and roots) that have not been
seen during training, but whose transformations have
been seen. This model is trained on all words in or-
der to capture as many transformations as possible.
The second approach for unknown words, called
hybrid-mazent, uses an MEMM trained on all
words seen in training. Given a stem (respectively,
baseform), this approach predicts only baseforms
(respectively, roots) that were observed in training
data. Thus, this method has a distinct disadvan-
tage when it comes to predicting new forms. This
approach corresponds directly to the approach to
handling unknown -words by Toutanova and Man-
ning (2000) for POS tagging.
With regard to baseform and root linkage, we do
not use the dictionary to constrain possible base-
forms or roots, since we make no initial assumptions
about the completeness of a dictionary.
</bodyText>
<subsectionHeader confidence="0.998817">
2.4 Morphological Tagging
</subsectionHeader>
<bodyText confidence="0.999931">
For morphological tagging, we break the task into
two separate tasks: tagging the suffix and tagging
the stem. Since there are a number of values that
need to be predicted, we define two ways to ap-
proach the problem. We call the first approach the
monolithic approach, in which the label is the con-
catenation of all the morphological attribute values.
Table 3 illustrates the tagging of an example sen-
tence: the stem tag and suffix tag columns contain
the monolithic tags for stem tagging and suffix tag-
ging. We use an MEMM to predict a monolithic tag
for each stem or suffix and call this model mazent-
mono. No co-occurrence restrictions among related
or complementary morphological tags are directly
enforced. Co-occurrence patterns are observed in
the data, learned, and encoded in the models of the
tagging process. It is worth noting further that con-
straints provided by the baseforms – predicted by
dictionary linkage – on the morphological attributes
are likewise not directly enforced. Enforcement of
such constraints would require an infusion of expert
knowledge into the system.
The second approach is to assume that morpho-
logical attributes are independent of each other. We
call this the independent approach. Here, each tag
is predicted by a tagger for a single morphological
attribute. For example, the gender model is ignorant
of the other 11 sub-tags during stem tagging. Using
its local context (which does not include other stem
sub-tags), the model predicts the best gender for a
given word. The top prediction of each of these tag-
gers (12, for stem tagging) is then combined naïvely
with no notion of what combinations may be valid
or invalid. We use MEMMs for each of the single-
attribute taggers. This model is called mazent-ind.
</bodyText>
<subsectionHeader confidence="0.933378">
2.5 Decoding
</subsectionHeader>
<bodyText confidence="0.99944332">
Our per-task decoders are beam decoders, with
beam-size b. In particular, we limit the number of
per-stage back-pointers to b due to the large size of
the tagset for some of our sub-models. Although
Viterbi decoding produces the most probable label
sequence given a sequence of unlabeled words, it is
potentially intractible on our hybrid models due to
the unbounded dependence on previous consonant-
level decisions. Our beam decoders produce a good
approximation when tuned properly.
Decoding in syromorph consists of extending the
per-task decoders to allow transitions from each sub-
model to the next sub-model in the pipe. For exam-
ple, in our pipeline, the first sub-model is segmen-
tation. We predict the top n segmentations for the
sentence (i.e., sequences of segmentations), where n
is the number of transitions to maintain between each
sub-task. Then, we run the remaining sub-tasks with
each of the n sequences as a possible context. After
each sub-task is completed, we narrow the number
of possible contexts back to n.
We swept b and n for various values, and found
b = 5 and n = 5 to be good values that balanced
between accuracy and time; larger values saw only
minute gains in accuracy.
</bodyText>
<page confidence="0.98633">
814
</page>
<table confidence="0.999582142857143">
Word Transliteration Pre. Stem Suffix Baseform Root Suff. Tags Stem Tags
ܬűũƕܘ OEBDT O EBDT EBD EBD 0000 011012200000
ܢŴƌܐ ANON ANON HO HO 0000 300023222000
ܢųƆƧ LALHN L ALH N ALHA ALH 1011 200310200200
ŦܬŴƄƇƉ MLCOTA MLCOTA MLCOTA MLC 0000 200310300200
lj̈ųƃܘ OCHNA O CHNA CHNA CHN 0000 200320200200
ťƄƇ̈Ɖܘ OMLCA O MLCA MLCA MLC 0000 200320200200
</table>
<tableCaption confidence="0.933873">
Table 3: Part of a labeled Syriac sentence ťƄƇ ̈Ɖܘ lj̈ųƃܘ ŦܬŴƄƇƉ ܢųƆƧ ܢŴƌܐ ܬűũƕܘ, “And you have made them a kingdom and
priests and kings for our God.” (Revelation 5:10)
</tableCaption>
<sectionHeader confidence="0.998309" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99970725">
We are using the Syriac Peshitta New Testament in
the form compiled by Kiraz (1994).2 This data is
segmented, annotated with baseform and root, and
labeled with morphological attributes. Kiraz and
others in the Syriac community refined and corrected
the original annotation while preparing a digital and
print concordance of the New Testament. We aug-
mented Kiraz’s version of the data by segmenting
suffixes and by streamlining the tagset. The dataset
consists of 109,640 word tokens.
Table 3 shows part of a tagged Syriac sentence us-
ing this tagset. The suffix and stem tags consist of
indices representing morphological attributes. In the
example sentence, the suffix tag 1011 represents the
values “masculine”, “N/A”, “plural”, “normal suf-
fix” for the suffix attributes of gender, person, num-
ber, and contraction. Each value of 0 for each stem
and suffix attribute represents a value of “N/A”, ex-
cept for that of grammatical category, which always
must have a value other than “N/A”. Therefore, the
suffix tag 0000 means there is no suffix.
For the stem tags, the attribute order is the same
as that shown in Table 1 from top to bottom. The
following describes the interpretation of the stem
values represented in Table 3. Grammatical cate-
gory values 0, 2, and 3 represent “verb”, “noun”,
and “pronoun”, respectively. (Grammatical cate-
gory has no “N/A” value.) The verb conjugation
value 1 represents “peal conjugation”. Aspect value
1 represents “perfect”. State value 3 represents “em-
phatic”. Number values 1 and 2 represent “singular”
and “plural”. Person values 2 and 3 represent “sec-
</bodyText>
<footnote confidence="0.978760333333333">
2The Way International, a Biblical research ministry, anno-
tated this version of the New Testament by hand and required
15 years to do so.
</footnote>
<bodyText confidence="0.999209972222222">
ond” and “third” person. Gender values 2 and 3 rep-
resent “masculine” and “feminine”. Pronoun type
value 2 represents “demonstrative”. Demonstrative
category value 2 represents “far”. Finally, noun type
2 represents “common”. The last two columns of 0
represent “N/A” for numeral type and particle type.
We implement five sub-tasks: segmentation, base-
form linkage, root linkage, suffix tagging, and stem
tagging. We compare each sub-task to a naïve ap-
proach as a baseline. In addition to desiring good
sub-models, we also want a joint pipeline model that
significantly outperforms the naïve joint approach,
which is formed by using each of the following base-
lines in the pipeline framework.
The baseline implementation of segmentation is to
choose the most-frequent label: for a given word,
the baseline predicts the segmentation with which
that word appeared most frequently during training.
For unknown words, it chooses the largest prefix
and largest suffix that is possible for that word from
the list of prefixes and suffixes seen during train-
ing. (This naïve baseline for unknown words does
not take into account the fact that the stem is often at
least three characters in length.)
For dictionary linkage, the baseline is similar:
both baseform linkage and root linkage use the most-
frequent label approach. Given a stem, the baseline
baseform linker predicts the baseform with which
the stem was seen most frequently during training;
likewise, the baseline root linker predicts the root
from the baseform in a similar manner. For the un-
known stem case, the baseline baseform linker pre-
dicts the baseform to be identical to the stem. For
the unknown baseform case, the baseline root linker
predicts a root identical to the first three consonants
of the baseform, since for Syriac the root is exactly
</bodyText>
<page confidence="0.996333">
815
</page>
<bodyText confidence="0.998678153846154">
three consonants in a large majority of the cases.
The baselines for stem and suffix tagging are the
most-frequent label approaches. These baselines
are similar to maxent-mono and maxent-ind, us-
ing the monolithic and independent approaches used
by maxent-mono and maxent-ind. The difference
is that instead of using maximum entropy, the naïve
most-frequent approach is used in its place.
The joint baseline tagger uses each of the compo-
nent baselines in the n-best joint pipeline framework.
Because this framework is modular, we can trivially
swap in and out different models for each of the sub-
tasks.
</bodyText>
<sectionHeader confidence="0.998751" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999994905660377">
Since we are focusing on under-resourced circum-
stances, we sweep the amount of training data and
produce learning curves to better understand how
our models perform in such circumstances. For each
point in our learning curves and for all other eval-
uations, we employ ten-fold cross-validation. The
learning curves use the chosen percentage of the data
for training and a fixed-size test set from each fold
and report the average accuracy.
The reported task accuracy requires the entire out-
put for that task to be correct in order to be counted as
correct. For example, during stem tagging, if one of
the sub-tags is incorrect, then the entire tag is said to
be incorrect. Furthermore, for syromorph, the out-
puts of every sub-task must be correct in order for
the word token to be counted as correct.
Moving beyond token-level metrics, in order to
understand performance of the system at the level
of individual decisions (including N/A decisions),
we compute decision-level accuracy: we call this
metric total-decisions. For the syromorph method
reported here, there are a total of 20 decisions: 2
for segmentation (prefix and suffix boundaries), 1
for baseform linkage, 1 for root linkage, 4 for suf-
fix tagging, and 12 for stem tagging. This accuracy
helps us to assess the number of decisions a human
annotator would need to correct, if data were pre-
annotated by a given model. Excluding N/A deci-
sions, we compute per-decision coverage and accu-
racy. These metrics are called applicable-coverage
and applicable-accuracy.
We show results on both the individual sub-tasks
and the entire joint task. Since previous sub-
tasks can adversely affect tasks further down in
the pipeline, we evaluate the sub-models by plac-
ing them in the pipeline with other (simulated) sub-
models that correctly predict every instance. For
example, when testing a root linker, we place the
root linker to be evaluated in the pipeline with a
segmenter, baseform linker, and taggers that return
the correct label for every prediction. This gives an
upper-bound for the individual model, removes the
possibility of error propagation, and shows how well
that model performs without the effects of the other
models in the pipeline.
For our results, unknown accuracy is the accuracy
of unknown instances, specific to the task, at training
time. In the case of baseform linkage, for example,
a stem is considered unknown if that stem was not
seen during training. It is therefore possible to have
a known word with an unknown stem and vice versa.
As in other NLP problems, unknown instances are a
manifestation of training data sparsity.
</bodyText>
<subsectionHeader confidence="0.993429">
4.1 Baseline Results
</subsectionHeader>
<bodyText confidence="0.999878684210526">
Table 4 is grouped by sub-task and reports the results
of each of the baseline sub-tasks in the first row of
each group. Each of the baselines performs surpris-
ingly well. The accuracies of the baselines for most
of the tasks are high because the ambiguity of the
labels given the instance is quite low: the average
ambiguity across word types for segmentation, base-
form linkage, root linkage, suffix tagging, and stem
tagging are 1.01, 1.05, 1.02, 1.35, and 1.47, respec-
tively.
Preliminary experiments indicated that if we had
trained a baseline model using a single prediction (a
monolithic concatenation of the predictions for all
tasks) per token rather than separating the tasks, the
baseline tagging accuracy would have been lower.
Note that the unknown tagging accuracy for the
monolithic suffix tagger is not applicable, because
there were no test suffixes that were not seen during
training.
</bodyText>
<sectionHeader confidence="0.651356" genericHeader="method">
4.2 Individual Model Results
</sectionHeader>
<bodyText confidence="0.93175875">
Table 4 also shows the results for the individual
models. In the table, SEG, BFL, RTL, SUFFIX,
and STEM represent segmentation, baseform link-
age, root linkage, suffix tagging, and stem tagging,
</bodyText>
<page confidence="0.995421">
816
</page>
<table confidence="0.999926235294118">
Model Total Known Unk
SEG baseline 96.75 99.64 69.11
hybrid 98.87 99.70 90.83
BFL baseline 95.64 98.45 22.28
hybrid-morfette 96.19 98.05 78.40
hybrid-maxent 96.19 99.15 67.86
RTL baseline 98.84 99.56 80.20
hybrid-morfette 99.05 99.44 88.86
hybrid-maxent 98.34 99.45 69.30
SUFFIX mono. baseline 98.75 98.75 N/A
ind. baseline 96.74 98.78 0.01
maxent-mono 98.90 98.90 N/A
maxent-ind 98.90 98.90 N/A
STEM mono. baseline 83.08 86.26 0.01
ind. baseline 53.24 86.90 0.00
maxent-mono 89.48 92.87 57.04
maxent-ind 88.43 90.26 40.59
</table>
<tableCaption confidence="0.97848">
Table 4: Word-level accuracies for the individual sub-
models used in the syromorph approach.
</tableCaption>
<table confidence="0.9999415">
Model Total Known Unk
Baseline 80.76 85.74 28.07
Morfette Monolithic 85.96 89.85 44.86
Maxent Monolithic 86.47 90.77 40.93
</table>
<tableCaption confidence="0.992816">
Table 5: Word-level accuracies for various joint syro-
morph models.
</tableCaption>
<figure confidence="0.998951066666667">
0 10 20 30 40 50 60 70 80 90 100
Percentage of Training Data
Total Accuracy
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
baseline
hybrid / hybrid-maxent / maxent-mono
hybrid / hybrid-morfette / maxent-mono
</figure>
<figureCaption confidence="0.99996">
Figure 2: The total accuracy of the joint model.
</figureCaption>
<bodyText confidence="0.999960714285714">
respectively. Even though the baselines were high,
each individual model outperformed its respective
baseline, with the exception of the root linker. Two
of the most interesting results are the known ac-
curacy of the baseform linkers hybrid-maxent and
hybrid-morfette. As hybrid models, the difference
between them lies only in the treatment of unknown
words; however, the known accuracy of the mor-
fette model drops fairly significantly. This is due
to the unknown words altering the weights for fea-
tures in which those words occur. For instance, if
the previous word is unknown and a baseform that
was never seen was predicted, then the weights on
the next word for all features that contain that un-
known word will be quite different than if that pre-
vious word were a known word.
It is also worth noting that the stem tagger is by
far the worst model in this group of models, but it is
also the most difficult task. The largest gains in im-
proving the entire system would come from focusing
attention on that task.
</bodyText>
<subsectionHeader confidence="0.990333">
4.3 Joint Model Results
</subsectionHeader>
<bodyText confidence="0.999876714285714">
Table 5 shows the accuracies for the joint mod-
els. The joint model incorporating “maxent” vari-
ants performs best overall and on known cases. The
joint model incorporating the “morfette” variants
performs best on unknown cases.
Decision-level metrics for the SEG:hybrid /
BFL and RTL:hybrid-maxent / SUFFIX and
STEM:maxent-mono model are as follows: for
total-decisions, the model achieves an accuracy
of 97.08%, compared to 95.50% accuracy for the
baseline, amounting to a 35.11% reduction in error
rate over the baseline; for applicable-coverage and
applicable-accuracy this model achieved 93.45%
and 93.81%, respectively, compared to the baseline’s
90.03% and 91.44%.
Figures 2, 3, and 4 show learning curves for to-
tal, known, and unknown accuracies for the joint
pipeline model. As can be seen in Figure 2, by the
time we reach 10% of the training data, syromorph
is significantly better than the baseline. In fact, at
35% of the training data, our joint pipeline model
outperforms the baseline trained with all available
training data.
Figure 3 shows the baseline performing quite well
on known words with very low amounts of data.
Since the x-axis varies the amount of training data,
the meaning of “known” and “unknown” evolves as
we move to the right of the graph; consequently, the
</bodyText>
<page confidence="0.985377">
817
</page>
<figure confidence="0.9906205">
0 10 20 30 40 50 60 70 80 90 100
Percentage of Training Data
</figure>
<figureCaption confidence="0.980582">
Figure 3: The accuracy of the joint model on known
words.
</figureCaption>
<figure confidence="0.991361">
0 10 20 30 40 50 60 70 80 90 100
Percentage of Training Data
</figure>
<figureCaption confidence="0.998203">
Figure 4: The accuracy of the joint model on unknown
words.
</figureCaption>
<bodyText confidence="0.99984">
left and right sides of the graph are incomparable.
When the percentage of training data is very low,
the percentage of unknown words is high, and the
number of known words is relatively low. On this
dataset, the more frequent words tend to be less am-
biguous, giving the most-frequent taggers an advan-
tage in a small random sample. For this reason, the
baseline performs very well on known accuracy with
lower amounts of training data.
Figure 4 clearly shows that hybrid-morfette link-
ers outperform hybrid-mazent linkers on unknown
words. However, Figures 2- 4 show that hybrid-
morfette’s advantage on unknown words is coun-
teracted by its lower performance on known words;
therefore, it has slightly lower overall accuracy than
hybrid-mazent.
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999408152173913">
The most closely related work to our approach is
the Morfette tool for labeling inflectional morphol-
ogy (Chrupała et al., 2008). Chrupała et al. cre-
ated a tool that labels Polish, Romanian, and Span-
ish with morphological information as well as base-
forms. It is a supervised learning approach that
requires data labeled with both morphological tags
and baseforms. This approach creates two separate
models (a morphological tagger and a lemmatizer)
and combines the decoding process in order to cre-
ate a joint model that predicts both morphological
tags and the baseform. Morfette uses MEMMs for
both models and has access to predicted labels in
the feature set. Reported accuracy rates are 96.08%,
93.83%, and 81.19% for joint accuracy on datasets
trained with fewer than 100,000 tokens for Roma-
nian, Spanish, and Polish, respectively. The major
difference between this work and ours is the degree
of morphological analysis required by the languages.
Chrupała et al. neglect segmentation, a task not as
intuitive for their languages as it is for Syriac. These
languages also require only linkage to a baseform, as
no root exists.
Also closely related is the work of Daya, Roth, and
Wintner (2008) on Hebrew. The authors use the no-
tion of patterns into which root consonants are in-
jected to compose Semitic words. They employ lin-
guistic knowledge (specifically, lists of prefixes, suf-
fixes, and “knowledge of word-formation processes”
combined with SNoW, a multi-class classifier that
has been shown to work well in other NLP tasks.
The major difference between this approach and the
method presented in this paper is that this method
does not require the extra knowledge required to en-
code word-formation processes. A further point of
difference is our use of hybrid word- and consonant-
level models, after Haertel et al. (2010). Their work
builds on the work of Shacham and Wintner (2007),
which is also related to that of Habash and Rambow,
described below.
Work by Lee et al. (2003) is the most relevant work
for segmentation, since they segment Arabic, closely
related to Syriac, with a data-driven approach. Lee
et al. use an unsupervised algorithm bootstrapped
with manually segmented data to learn the segmen-
tation for Arabic without any additional language re-
</bodyText>
<figure confidence="0.99919484">
0.95
0.85
0.75
0.65
0.9
0.8
0.7
baseline
hybrid / hybrid-maxent / maxent-mono
hybrid / hybrid-morfette / maxent-mono
Unknown Accuracy
0.45
0.35
0.25
0.15
0.05
0.4
0.3
0.2
0.1
0
baseline
hybrid / hybrid-maxent / maxent-mono
hybrid / hybrid-morfette / maxent-mono
Known Accuracy
</figure>
<page confidence="0.990813">
818
</page>
<bodyText confidence="0.999539714285715">
sources. At the heart of the algorithm is a word-level
trigram language model, which captures the correct
weights for prefixes and suffixes. They report an ac-
curacy of 97%. We opted to use our own segmenter
because we felt we could achieve higher accuracy
with the hybrid segmenter.
Mohamed and Kübler (2010a, 2010b) report on
closely related work for morphological tagging.
They use a data-driven approach to find the POS tags
for Arabic, using both word tokens and segmented
words as inputs for their system. Although their seg-
mentation performance is high, they report that ac-
curacy is lower when first segmenting word tokens.
They employ TiMBL, a memory-based learner, as
their model and report an accuracy of 94.74%.
Habash and Rambow (2005) currently have the
most accurate approach for Arabic morphological
analysis using additional language tools. They focus
on morphological disambiguation (tagging), given
morphological segmentation in the output of the
morphological analyzer. For each word, they first
run it through the morphological analyzer to reduce
the number of possible outputs. They then train a
separate Support Vector Machine (SVM) for each
morphological attribute (ten in all). They look at dif-
ferent ways of combining these outputs to match an
output from the morphological analyzer. For their
best model, they report an overall tag accuracy of
97.6%.
Others have used morphological analyzers and
other language tools for morphological disambigua-
tion coupled with segmentation. The following
works exemplify this approach: Diab et al. (2004)
use a POS tagger to jointly segment, POS tag, and
chunk base-phrases for Arabic with SVMs. Kudo
et al. (2004) use SVMs to morphologically tag
Japanese. Smith et al. (2005) use SVMs for seg-
mentation, lemmatization, and POS tagging for Ara-
bic, Korean, and Czech. Petkevič (2001) use a mor-
phological analyzer and additional simple rules for
morphological disambiguation of Czech. Mansour
et al. (2007) and Bar-haim et al. (2008) both use hid-
den Markov models to POS tag Hebrew, with the lat-
ter including segmentation as part of the task.
For Syriac, a morphological analyzer is not avail-
able. Kiraz (2000) created a Syriac morphological
analyzer using finite-state methods; however, it was
developed on outdated and now inaccessible equip-
ment and is no longer working or available to us.
</bodyText>
<sectionHeader confidence="0.994898" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999976833333334">
We have shown that we can effectively model seg-
mentation, linkage to headwords in a dictionary, and
morphological tagging using a joint model called sy-
romorph. We have introduced novel approaches for
segmentation, dictionary linkage, and morphologi-
cal tagging, and each of these approaches has out-
performed its corresponding naïve baseline. Further-
more, we have shown that for Syriac, a data-driven
approach seems to be an appropriate way to solve
these problems in an under-resourced setting.
We hope to use this combined model for pre-
annotation in an active learning setting to aid anno-
tators in labeling a large Syriac corpus. This corpus
will contain data spanning multiple centuries and a
variety of authors and genres. Future work will re-
quire addressing issues encountered in this corpus.
In addition, there is much to do in getting the over-
all tag accuracy closer to the accuracy of individual
decisions. We leave further feature engineering for
the stem tagger and the exploration of possible new
morphological tagging techniques for future work.
Finally, future work includes the application of the
syromorph methodology to other under-resourced
Semitic languages.
</bodyText>
<sectionHeader confidence="0.998226" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999919857142857">
We would like to thank David Taylor of the Oriental
Institute at Oxford University for collaboration on
the design of the simplified tagset. We also recog-
nize the assistance of Ben Hansen of BYU on a sub-
set of the experimental results. Finally, we would
like to thank the anonymous reviewers for helpful
guidance.
</bodyText>
<sectionHeader confidence="0.999275" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998511222222222">
Roy Bar-haim, Khalil Sima’an, and Yoad Winter. 2008.
Part-of-speech tagging of modern hebrew text. Natural
Language Engineering, 14(2):223–251.
British and Foreign Bible Society, editors. 1920. The
New Testament in Syriac. Oxford: Frederick Hall.
Grzegorz Chrupała, Georgiana Dinu, and Josef van Gen-
abith. 2008. Learning morphology with Morfette. In
Proceedings of the Sixth International Language Re-
sources and Evaluation (LREC’08).
</reference>
<page confidence="0.988004">
819
</page>
<reference confidence="0.999549941747573">
Grzegorz Chrupała. 2006. Simple data-driven
context-sensitive lemmatization. In Procesamiento del
Lenguaje Natural, volume 37, pages 121 – 127.
Ezra Daya, Dan Roth, and Shuly Wintner. 2008.
Identifying Semitic roots: Machine learning with
linguistic constraints. Computational Linguistics,
34(3):429–448.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky.
2004. Automatic tagging of Arabic text: From
raw text to base phrase chunks. In Proceedings of
the 5th Meeting of the North American Chapter of
the Association for Computational Linguistics/Human
Language Technologies Conference (HLT-NAACL04),
pages 149–152.
Jenny Rose Finkel, Christopher D. Manning, and An-
drew Y. Ng. 2006. Solving the problem of cascading
errors: Approximate Bayesian inference for linguistic
annotation pipelines. In EMNLP ’06: Proceedings of
the 2006 Conference on Empirical Methods in Natural
Language Processing, pages 618–626. Association for
Computational Linguistics.
Nizar Habash and Owen Rambow. 2005. Arabic to-
kenization, part-of-speech tagging and morphological
disambiguation in one fell swoop. In ACL ’05: Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, pages 573–580. Asso-
ciation for Computational Linguistics.
Nizar Habash and Owen Rambow. 2007. Arabic diacriti-
zation through full morphological tagging. In Human
Language Technologies 2007: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics; Companion Volume, Short Pa-
pers, pages 53–56. Association for Computational Lin-
guistics.
Robbie Haertel, Peter McClanahan, and Eric K. Ring-
ger. 2010. Automatic diacritization for low-resource
languages using a hybrid word and consonant cmm.
In Human Language Technologies: The 2010 Annual
Conference ofthe North American Chapter ofthe Asso-
ciation for Computational Linguistics, pages 519–527.
Association for Computational Linguistics.
Jan Hajič and Barbora Hladká. 1998. Tagging inflective
languages: Prediction of morphological categories for
a rich, structured tagset. In Proceedings of the 17th In-
ternational Conference on Computational Linguistics,
pages 483–490. Association for Computational Lin-
guistics.
George Kiraz. 1994. Automatic concordance generation
of Syriac texts. In R. Lavenant, editor, VI Symposium
Syriacum 1992, pages 461–.
George Anton Kiraz. 2000. Multitiered nonlinear mor-
phology using multitape finite automata: a case study
on Syriac and Arabic. Computational Linguistics,
26:77–105.
Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto.
2004. Applying conditional random fields to japanese
morphological analysis. In Proceedings of EMNLP,
pages 230–237.
Young-Suk Lee, Kishore Papineni, Salim Roukos, Os-
sama Emam, and Hany Hassan. 2003. Language
model based Arabic word segmentation. In ACL ’03:
Proceedings ofthe 41st Annual Meeting on Association
for Computational Linguistics, pages 399–406. Associ-
ation for Computational Linguistics.
Saib Mansour, Khalil Sima’an, and Yoad Winter. 2007.
Smoothing a lexicon-based pos tagger for Arabic and
Hebrew. In Semitic ’07: Proceedings of the 2007
Workshop on Computational Approaches to Semitic
Languages, pages 97–103. Association for Computa-
tional Linguistics.
Emad Mohamed and Sandra Kübler. 2010a. Arabic
part of speech tagging. In Proceedings of the Sev-
enth International Language Resources and Evalua-
tion (LREC’10).
Emad Mohamed and Sandra Kübler. 2010b. Is Arabic
part of speech tagging feasible without word segmen-
tation? In Human Language Technologies: The 2010
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
705–708. Association for Computational Linguistics.
Vladimír Petkevič. 2001. Grammatical agreement
and automatic morphological disambiguation of inflec-
tional languages. In TSD ’01: Proceedings of the
4th International Conference on Text, Speech and Dia-
logue, pages 47–53. Springer-Verlag.
Danny Shacham and Shuly Wintner. 2007. Morpholog-
ical disambiguation of Hebrew: a case study in clas-
sifier combination. In Proceedings of EMNLP-CoNLL
2007, the Conference on Empirical Methods in Natural
Language Processing and the Conference on Compu-
tational Natural Language Learning. Association for
Computational Linguistics.
Noah A. Smith, David A. Smith, and Roy W. Tromble.
2005. Context-based morphological disambiguation
with random fields. In HLT ’05: Proceedings of
the conference on Human Language Technology and
Empirical Methods in Natural Language Processing,
pages 475–482. Association for Computational Lin-
guistics.
K. Toutanova and C. Manning. 2000. Enriching the
knowledge sources used in a maximum entropy part-
of-speech tagger. In Proceedings of EMNLP, pages
63–70.
</reference>
<page confidence="0.997717">
820
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.356379">
<title confidence="0.999946">A Probabilistic Morphological Analyzer for Syriac</title>
<author confidence="0.9666575">Peter McClanahan</author>
<author confidence="0.9666575">George Busby</author>
<author confidence="0.9666575">Robbie Haertel</author>
<author confidence="0.9666575">Kristian Heal Deryle Lonsdale‡</author>
<author confidence="0.9666575">Kevin Seppi</author>
<author confidence="0.9666575">Eric</author>
<affiliation confidence="0.988156">Department of Computer Science, ‡Department of</affiliation>
<title confidence="0.450403">Center for the Preservation of Ancient Religious Texts</title>
<author confidence="0.475031">Brigham Young</author>
<address confidence="0.98819">Provo, Utah 84604</address>
<web confidence="0.99952">http://nlp.cs.byu.edu/</web>
<abstract confidence="0.9955434">We define a probabilistic morphological analyzer using a data-driven approach for Syriac in order to facilitate the creation of an annotated corpus. Syriac is an under-resourced Semitic language for which there are no available language tools such as morphological analyzers. We introduce novel probabilistic models for segmentation, dictionary linkage, and morphological tagging and connect them in a pipeline to create a probabilistic morphological analyzer requiring only labeled data. We explore the performance of models with varying amounts of training data and find that with about 34,500 labeled tokens, we can outperform a reasonable baseline trained on over 99,000 tokens and achieve an accuracy of just over 80%. When trained on all available training data, our joint model achieves 86.47% accuracy, a 29.7% reduction in error rate over the baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Roy Bar-haim</author>
<author>Khalil Sima’an</author>
<author>Yoad Winter</author>
</authors>
<title>Part-of-speech tagging of modern hebrew text.</title>
<date>2008</date>
<journal>Natural Language Engineering,</journal>
<volume>14</volume>
<issue>2</issue>
<marker>Bar-haim, Sima’an, Winter, 2008</marker>
<rawString>Roy Bar-haim, Khalil Sima’an, and Yoad Winter. 2008. Part-of-speech tagging of modern hebrew text. Natural Language Engineering, 14(2):223–251.</rawString>
</citation>
<citation valid="true">
<date>1920</date>
<booktitle>The New Testament in Syriac.</booktitle>
<editor>British and Foreign Bible Society, editors.</editor>
<publisher>Frederick Hall.</publisher>
<location>Oxford:</location>
<contexts>
<context position="2513" citStr="(1920)" startWordPosition="380" endWordPosition="380">ear East, and Eastern Christianity. Furthermore, languages that are linguistically similar to Syriac (e.g., Arabic and Hebrew) may benefit from the methodology presented here. Our desired annotations include morphological segmentation, links to dictionary entries, and morphological attributes. Typically, annotations of this kind are made with the assistance of language tools, such as morphological analyzers, segmenters, or part-of-speech (POS) taggers. Such tools do not exist for Syriac, but some labeled data does exist: Kiraz (1994) compiled an annotated version of the Peshitta New Testament (1920) and a concordance thereof. We aim to replicate this kind of annotation on a much larger scale with more modern tools, building up from the labeled New Testament data, our only resource. Motivated by this state of affairs, our learning and annotation framework requires only labeled data. We approach the problem of Syriac morphological annotation by creating five probabilistic sub-models that can be trained in a supervised fashion and combined in a joint model of morphological annotation. We introduce novel algorithms for segmentation, dictionary linkage, and morphological tagging. We then comb</context>
</contexts>
<marker>1920</marker>
<rawString>British and Foreign Bible Society, editors. 1920. The New Testament in Syriac. Oxford: Frederick Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupała</author>
<author>Georgiana Dinu</author>
<author>Josef van Genabith</author>
</authors>
<title>Learning morphology with Morfette.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</booktitle>
<marker>Chrupała, Dinu, van Genabith, 2008</marker>
<rawString>Grzegorz Chrupała, Georgiana Dinu, and Josef van Genabith. 2008. Learning morphology with Morfette. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupała</author>
</authors>
<title>Simple data-driven context-sensitive lemmatization.</title>
<date>2006</date>
<booktitle>In Procesamiento del Lenguaje Natural,</booktitle>
<volume>37</volume>
<pages>121--127</pages>
<contexts>
<context position="14715" citStr="Chrupała (2006)" startWordPosition="2377" endWordPosition="2378">nsonant-level segmentation model hybrid. As far as we are aware, this is a novel approach to segmentation. 2.3 Dictionary Linkage For dictionary linkage, we divide the problem into two separate tasks: baseform linkage and root linkage. For both of these tasks, we use a hybrid model similar to that used for segmentation, consisting of a collection of separate MEMMs for each word type (either a stem or baseform, depending on the linker) and a model for unknown (or rare) words. For the unknown words, we compare two distinct approaches. The first approach for unknown words is based on the work of Chrupała (2006), including the Morfette system. Instead of predicting a baseform given a stem, we predict what Chrupała calls a lemmaclass. A lemma-class is the transformation specified by the minimum edit distance between the baseform (which he calls a lemma) and the stem. The transformation is a series of tuples, where each tuple includes (1) whether it was an insertion or deletion, (2) the letter inserted or deleted, and (3) the position of the insertion or deletion in the string (positions begin at zero). All operations are assumed to occur sequentially, as in Morfette. For example, the transformation of</context>
</contexts>
<marker>Chrupała, 2006</marker>
<rawString>Grzegorz Chrupała. 2006. Simple data-driven context-sensitive lemmatization. In Procesamiento del Lenguaje Natural, volume 37, pages 121 – 127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ezra Daya</author>
<author>Dan Roth</author>
<author>Shuly Wintner</author>
</authors>
<title>Identifying Semitic roots: Machine learning with linguistic constraints.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<marker>Daya, Roth, Wintner, 2008</marker>
<rawString>Ezra Daya, Dan Roth, and Shuly Wintner. 2008. Identifying Semitic roots: Machine learning with linguistic constraints. Computational Linguistics, 34(3):429–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic tagging of Arabic text: From raw text to base phrase chunks.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL04),</booktitle>
<pages>149--152</pages>
<contexts>
<context position="36685" citStr="Diab et al. (2004)" startWordPosition="5969" endWordPosition="5972">he output of the morphological analyzer. For each word, they first run it through the morphological analyzer to reduce the number of possible outputs. They then train a separate Support Vector Machine (SVM) for each morphological attribute (ten in all). They look at different ways of combining these outputs to match an output from the morphological analyzer. For their best model, they report an overall tag accuracy of 97.6%. Others have used morphological analyzers and other language tools for morphological disambiguation coupled with segmentation. The following works exemplify this approach: Diab et al. (2004) use a POS tagger to jointly segment, POS tag, and chunk base-phrases for Arabic with SVMs. Kudo et al. (2004) use SVMs to morphologically tag Japanese. Smith et al. (2005) use SVMs for segmentation, lemmatization, and POS tagging for Arabic, Korean, and Czech. Petkevič (2001) use a morphological analyzer and additional simple rules for morphological disambiguation of Czech. Mansour et al. (2007) and Bar-haim et al. (2008) both use hidden Markov models to POS tag Hebrew, with the latter including segmentation as part of the task. For Syriac, a morphological analyzer is not available. Kiraz (20</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2004</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2004. Automatic tagging of Arabic text: From raw text to base phrase chunks. In Proceedings of the 5th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL04), pages 149–152.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Solving the problem of cascading errors: Approximate Bayesian inference for linguistic annotation pipelines.</title>
<date>2006</date>
<booktitle>In EMNLP ’06: Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>618--626</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10348" citStr="Finkel et al., 2006" startWordPosition="1656" endWordPosition="1659">ection 4, we describe our experimental setup; we present results in Section 5. Section 6 contrasts previous work with our approach. Finally, in Section 7 we briefly conclude and offer directions for future work. 2 The Syromorph Approach Since lack language tools, we focus on automatically annotating Syriac text in a data-driven fashion based on the labeled data we have available. Since segmentation, linkage, and morphological tagging are not mutually independent tasks, we desire models for the sub-tasks to influence each other. To accommodate these requirements, we use a joint pipeline model (Finkel et al., 2006). In this section, we will first discuss this joint pipeline model, which we call syromorph. We then examine each of the individual sub-models. 2.1 Joint Pipeline Model Our approach is to create a joint pipeline model consisting of a segmenter, a baseform linker, a root linker, a suffix tagger, and a stem tagger. Figure 1 shows the dependencies among the sub-models in the pipeline for a single word. Each sub-model (oval) has access to the data and predictions (rectangles) indicated by the arrows. For example, for a given word, the stem tagger has access to the previously predicted stem, basefo</context>
</contexts>
<marker>Finkel, Manning, Ng, 2006</marker>
<rawString>Jenny Rose Finkel, Christopher D. Manning, and Andrew Y. Ng. 2006. Solving the problem of cascading errors: Approximate Bayesian inference for linguistic annotation pipelines. In EMNLP ’06: Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 618–626. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop.</title>
<date>2005</date>
<booktitle>In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>573--580</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="35866" citStr="Habash and Rambow (2005)" startWordPosition="5849" endWordPosition="5852">ixes and suffixes. They report an accuracy of 97%. We opted to use our own segmenter because we felt we could achieve higher accuracy with the hybrid segmenter. Mohamed and Kübler (2010a, 2010b) report on closely related work for morphological tagging. They use a data-driven approach to find the POS tags for Arabic, using both word tokens and segmented words as inputs for their system. Although their segmentation performance is high, they report that accuracy is lower when first segmenting word tokens. They employ TiMBL, a memory-based learner, as their model and report an accuracy of 94.74%. Habash and Rambow (2005) currently have the most accurate approach for Arabic morphological analysis using additional language tools. They focus on morphological disambiguation (tagging), given morphological segmentation in the output of the morphological analyzer. For each word, they first run it through the morphological analyzer to reduce the number of possible outputs. They then train a separate Support Vector Machine (SVM) for each morphological attribute (ten in all). They look at different ways of combining these outputs to match an output from the morphological analyzer. For their best model, they report an o</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic tokenization, part-of-speech tagging and morphological disambiguation in one fell swoop. In ACL ’05: Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 573–580. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic diacritization through full morphological tagging.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers,</booktitle>
<pages>53--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5569" citStr="Habash and Rambow, 2007" startWordPosition="869" endWordPosition="872">ncluding the stem) can be spoken and written with vowels as diacritics; however, since the vowels are not written in common practice and since most text does not include them, this work omits any indication of vowels. Furthermore, the stem is an inflected baseform and does not necessarily form a word on its own. Also, the (unvocalized) stem and root are not necessarily identical. In Syriac, the same root ƅƇƉ, MLC is the foundation for other words such as promise, counsel, deliberate, reign, queen, kingdom, and realm. 1.2 Sub-tasks Segmentation, or tokenization as it is sometimes called (e.g., Habash and Rambow, 2007), is the process of dividing a word token into its prefix(es) (if any), a stem, and a suffix (if any). For Syriac, each 1According to this transliteration all capital letters including A (ܐ, olaph) and O (ܘ, waw) are consonants. Additionally, the semi-colon (;), representing (ܝ, yod), is also a consonant. word token consists of exactly one stem, from zero to three prefixes, and zero or one suffix. Each prefix is exactly one character in length. Segmentation does not include the process of parsing the stem for its inflectional morphology; that step is handled separately in subsequent processes </context>
</contexts>
<marker>Habash, Rambow, 2007</marker>
<rawString>Nizar Habash and Owen Rambow. 2007. Arabic diacritization through full morphological tagging. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Companion Volume, Short Papers, pages 53–56. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robbie Haertel</author>
<author>Peter McClanahan</author>
<author>Eric K Ringger</author>
</authors>
<title>Automatic diacritization for low-resource languages using a hybrid word and consonant cmm.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference ofthe North American Chapter ofthe Association for Computational Linguistics,</booktitle>
<pages>519--527</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12631" citStr="Haertel et al. (2010)" startWordPosition="2034" endWordPosition="2037">stems. To further elaborate 812 Figure 1: The syromorph model. Each rectangle is an input or output and each oval is a process employing a sub-model. on the example, since features are extracted from the local context, for stem tagging we extract features such as current stem, previous stem, current baseform, previous baseform, current root, previous root, current suffix tags, and previous suffix tags. (Here, “previous” refers to labels on the immediately preceding word token.) 2.2 Segmentation The syromorph segmentation model is a hybrid word- and consonant-level model, based on the model of Haertel et al. (2010) for data-driven diacritization. Each of our probabilistic sequence models is a maximum entropy Markov model (MEMM). Haertel et al. (2010) showed that the distribution over labels is different for known and words and rare words. In this work, we only consider words not seen in training (i.e., “unknown”) to be rare. Following Haertel et al.’s (2010) model, a separate model is trained for each word type seen in training with the intent of choosing the best segmentation given that word. This approach is closely related to the idea of ambiguity classes mentioned in Hajič and Hladká (1998). To hand</context>
<context position="34400" citStr="Haertel et al. (2010)" startWordPosition="5610" endWordPosition="5613">. The authors use the notion of patterns into which root consonants are injected to compose Semitic words. They employ linguistic knowledge (specifically, lists of prefixes, suffixes, and “knowledge of word-formation processes” combined with SNoW, a multi-class classifier that has been shown to work well in other NLP tasks. The major difference between this approach and the method presented in this paper is that this method does not require the extra knowledge required to encode word-formation processes. A further point of difference is our use of hybrid word- and consonantlevel models, after Haertel et al. (2010). Their work builds on the work of Shacham and Wintner (2007), which is also related to that of Habash and Rambow, described below. Work by Lee et al. (2003) is the most relevant work for segmentation, since they segment Arabic, closely related to Syriac, with a data-driven approach. Lee et al. use an unsupervised algorithm bootstrapped with manually segmented data to learn the segmentation for Arabic without any additional language re0.95 0.85 0.75 0.65 0.9 0.8 0.7 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Unknown Accuracy 0.45 0.35 0.25 0.15 0.05 0.</context>
</contexts>
<marker>Haertel, McClanahan, Ringger, 2010</marker>
<rawString>Robbie Haertel, Peter McClanahan, and Eric K. Ringger. 2010. Automatic diacritization for low-resource languages using a hybrid word and consonant cmm. In Human Language Technologies: The 2010 Annual Conference ofthe North American Chapter ofthe Association for Computational Linguistics, pages 519–527. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajič</author>
<author>Barbora Hladká</author>
</authors>
<title>Tagging inflective languages: Prediction of morphological categories for a rich, structured tagset.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics,</booktitle>
<pages>483--490</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13222" citStr="Hajič and Hladká (1998)" startWordPosition="2134" endWordPosition="2137">e model of Haertel et al. (2010) for data-driven diacritization. Each of our probabilistic sequence models is a maximum entropy Markov model (MEMM). Haertel et al. (2010) showed that the distribution over labels is different for known and words and rare words. In this work, we only consider words not seen in training (i.e., “unknown”) to be rare. Following Haertel et al.’s (2010) model, a separate model is trained for each word type seen in training with the intent of choosing the best segmentation given that word. This approach is closely related to the idea of ambiguity classes mentioned in Hajič and Hladká (1998). To handle unknown words, we back off to a consonant-level model. Our consonant-level segmentation model uses the notion of BI (Beginning and Inside) tags, which have proven successful in named-entity recognition. Since there are three labels in which we are interested (prefix, stem, and suffix), we apply the beginning and inside notion to each of them to create six tags: BEGINNINGPREFIX, INSIDE-PREFIX, BEGINNING-STEM, INSIDE-STEM, BEGINNING-SUFFIX, and INSIDE-SUFFIX. We train an MEMM to predict one of these six tags for each consonant. Furthermore, we constrain the decoder to allow only lega</context>
</contexts>
<marker>Hajič, Hladká, 1998</marker>
<rawString>Jan Hajič and Barbora Hladká. 1998. Tagging inflective languages: Prediction of morphological categories for a rich, structured tagset. In Proceedings of the 17th International Conference on Computational Linguistics, pages 483–490. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Kiraz</author>
</authors>
<title>Automatic concordance generation of Syriac texts.</title>
<date>1994</date>
<booktitle>VI Symposium Syriacum</booktitle>
<pages>461</pages>
<editor>In R. Lavenant, editor,</editor>
<contexts>
<context position="2446" citStr="Kiraz (1994)" startWordPosition="369" endWordPosition="370">rmation, we will facilitate systematic study by scholars of Syriac, the Near East, and Eastern Christianity. Furthermore, languages that are linguistically similar to Syriac (e.g., Arabic and Hebrew) may benefit from the methodology presented here. Our desired annotations include morphological segmentation, links to dictionary entries, and morphological attributes. Typically, annotations of this kind are made with the assistance of language tools, such as morphological analyzers, segmenters, or part-of-speech (POS) taggers. Such tools do not exist for Syriac, but some labeled data does exist: Kiraz (1994) compiled an annotated version of the Peshitta New Testament (1920) and a concordance thereof. We aim to replicate this kind of annotation on a much larger scale with more modern tools, building up from the labeled New Testament data, our only resource. Motivated by this state of affairs, our learning and annotation framework requires only labeled data. We approach the problem of Syriac morphological annotation by creating five probabilistic sub-models that can be trained in a supervised fashion and combined in a joint model of morphological annotation. We introduce novel algorithms for segmen</context>
<context position="3917" citStr="Kiraz (1994)" startWordPosition="597" endWordPosition="598">ound Since Syriac is an abjad, its writing system does not require vowels. As a dialect of Aramaic, it is an inflected language with a templatic (nonconcatenative) morphology, based on a system of triliteral consonantal roots, with prefixes, suffixes, infixes, and enclitic particles. Syriac is written from 810 Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 810–820, MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics right to left. For the purposes of this work, all Syriac is transliterated according to the Kiraz (1994) transliteration1 and is written left-to-right whenever transliterated; the Syriac appearing in the Serto script in this paper is shown right-to-left. Since there is no standardized nomenclature for the parts of a Syriac word, we define the following terms to facilitate the definitions of segmentation, dictionary linkage, and morphological tagging: • word token - contiguous characters delimited by whitespace and/or punctuation • stem - an inflected form of the baseform and the main part of the word to which prefixes and suffixes can be attached; the affixes do not inflect the stem but include </context>
<context position="9097" citStr="Kiraz (1994)" startWordPosition="1448" endWordPosition="1449"> Type N/A Table 1: The values for the morphological attributes of the stem .�,w, MLC, “king”. Attribute Value Gender masculine Person second Number plural Contraction normal suffix Table 2: The values for the morphological attributes of the suffix ,�, CON, “(masculine plural) your”. attributes for the suffix are gender, person, number, and contraction. The suffix contraction attribute encodes whether the suffix is normal or contracted, a phonological process involving the attachment of an enclitic pronoun to a participle. These morphological attributes were heavily influenced by those used by Kiraz (1994), but were streamlined in order to focus directly on grammatical function. During morphological tagging, each stem is labeled for each of the stem attributes, and each suffix is labeled for each of the suffix attributes. For a given grammatical category (or POS), only a subset of the morphological attributes is applicable. For those morphological attributes (both of the stem and of the suffix) that do not apply, the correct label is “N/A” (not applicable). Tables 1 and 2 show the correct stem and suffix tags for the word � -�, LMLCCON. The remainder of the paper will proceed as follows: Sectio</context>
<context position="20361" citStr="Kiraz (1994)" startWordPosition="3312" endWordPosition="3313">sliteration Pre. Stem Suffix Baseform Root Suff. Tags Stem Tags ܬűũƕܘ OEBDT O EBDT EBD EBD 0000 011012200000 ܢŴƌܐ ANON ANON HO HO 0000 300023222000 ܢųƆƧ LALHN L ALH N ALHA ALH 1011 200310200200 ŦܬŴƄƇƉ MLCOTA MLCOTA MLCOTA MLC 0000 200310300200 lj̈ųƃܘ OCHNA O CHNA CHNA CHN 0000 200320200200 ťƄƇ̈Ɖܘ OMLCA O MLCA MLCA MLC 0000 200320200200 Table 3: Part of a labeled Syriac sentence ťƄƇ ̈Ɖܘ lj̈ųƃܘ ŦܬŴƄƇƉ ܢųƆƧ ܢŴƌܐ ܬűũƕܘ, “And you have made them a kingdom and priests and kings for our God.” (Revelation 5:10) 3 Experimental Setup We are using the Syriac Peshitta New Testament in the form compiled by Kiraz (1994).2 This data is segmented, annotated with baseform and root, and labeled with morphological attributes. Kiraz and others in the Syriac community refined and corrected the original annotation while preparing a digital and print concordance of the New Testament. We augmented Kiraz’s version of the data by segmenting suffixes and by streamlining the tagset. The dataset consists of 109,640 word tokens. Table 3 shows part of a tagged Syriac sentence using this tagset. The suffix and stem tags consist of indices representing morphological attributes. In the example sentence, the suffix tag 1011 repr</context>
</contexts>
<marker>Kiraz, 1994</marker>
<rawString>George Kiraz. 1994. Automatic concordance generation of Syriac texts. In R. Lavenant, editor, VI Symposium Syriacum 1992, pages 461–.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Anton Kiraz</author>
</authors>
<title>Multitiered nonlinear morphology using multitape finite automata: a case study on</title>
<date>2000</date>
<booktitle>Syriac and Arabic. Computational Linguistics,</booktitle>
<pages>26--77</pages>
<contexts>
<context position="37288" citStr="Kiraz (2000)" startWordPosition="6073" endWordPosition="6074">l. (2004) use a POS tagger to jointly segment, POS tag, and chunk base-phrases for Arabic with SVMs. Kudo et al. (2004) use SVMs to morphologically tag Japanese. Smith et al. (2005) use SVMs for segmentation, lemmatization, and POS tagging for Arabic, Korean, and Czech. Petkevič (2001) use a morphological analyzer and additional simple rules for morphological disambiguation of Czech. Mansour et al. (2007) and Bar-haim et al. (2008) both use hidden Markov models to POS tag Hebrew, with the latter including segmentation as part of the task. For Syriac, a morphological analyzer is not available. Kiraz (2000) created a Syriac morphological analyzer using finite-state methods; however, it was developed on outdated and now inaccessible equipment and is no longer working or available to us. 6 Conclusions and Future Work We have shown that we can effectively model segmentation, linkage to headwords in a dictionary, and morphological tagging using a joint model called syromorph. We have introduced novel approaches for segmentation, dictionary linkage, and morphological tagging, and each of these approaches has outperformed its corresponding naïve baseline. Furthermore, we have shown that for Syriac, a </context>
</contexts>
<marker>Kiraz, 2000</marker>
<rawString>George Anton Kiraz. 2000. Multitiered nonlinear morphology using multitape finite automata: a case study on Syriac and Arabic. Computational Linguistics, 26:77–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Kaoru Yamamoto</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Applying conditional random fields to japanese morphological analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>230--237</pages>
<contexts>
<context position="36795" citStr="Kudo et al. (2004)" startWordPosition="5989" endWordPosition="5992">o reduce the number of possible outputs. They then train a separate Support Vector Machine (SVM) for each morphological attribute (ten in all). They look at different ways of combining these outputs to match an output from the morphological analyzer. For their best model, they report an overall tag accuracy of 97.6%. Others have used morphological analyzers and other language tools for morphological disambiguation coupled with segmentation. The following works exemplify this approach: Diab et al. (2004) use a POS tagger to jointly segment, POS tag, and chunk base-phrases for Arabic with SVMs. Kudo et al. (2004) use SVMs to morphologically tag Japanese. Smith et al. (2005) use SVMs for segmentation, lemmatization, and POS tagging for Arabic, Korean, and Czech. Petkevič (2001) use a morphological analyzer and additional simple rules for morphological disambiguation of Czech. Mansour et al. (2007) and Bar-haim et al. (2008) both use hidden Markov models to POS tag Hebrew, with the latter including segmentation as part of the task. For Syriac, a morphological analyzer is not available. Kiraz (2000) created a Syriac morphological analyzer using finite-state methods; however, it was developed on outdated </context>
</contexts>
<marker>Kudo, Yamamoto, Matsumoto, 2004</marker>
<rawString>Taku Kudo, Kaoru Yamamoto, and Yuji Matsumoto. 2004. Applying conditional random fields to japanese morphological analysis. In Proceedings of EMNLP, pages 230–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Ossama Emam</author>
<author>Hany Hassan</author>
</authors>
<title>Language model based Arabic word segmentation.</title>
<date>2003</date>
<booktitle>In ACL ’03: Proceedings ofthe 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>399--406</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="34557" citStr="Lee et al. (2003)" startWordPosition="5639" endWordPosition="5642">of prefixes, suffixes, and “knowledge of word-formation processes” combined with SNoW, a multi-class classifier that has been shown to work well in other NLP tasks. The major difference between this approach and the method presented in this paper is that this method does not require the extra knowledge required to encode word-formation processes. A further point of difference is our use of hybrid word- and consonantlevel models, after Haertel et al. (2010). Their work builds on the work of Shacham and Wintner (2007), which is also related to that of Habash and Rambow, described below. Work by Lee et al. (2003) is the most relevant work for segmentation, since they segment Arabic, closely related to Syriac, with a data-driven approach. Lee et al. use an unsupervised algorithm bootstrapped with manually segmented data to learn the segmentation for Arabic without any additional language re0.95 0.85 0.75 0.65 0.9 0.8 0.7 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Unknown Accuracy 0.45 0.35 0.25 0.15 0.05 0.4 0.3 0.2 0.1 0 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Known Accuracy 818 sources. At the heart of the algorith</context>
</contexts>
<marker>Lee, Papineni, Roukos, Emam, Hassan, 2003</marker>
<rawString>Young-Suk Lee, Kishore Papineni, Salim Roukos, Ossama Emam, and Hany Hassan. 2003. Language model based Arabic word segmentation. In ACL ’03: Proceedings ofthe 41st Annual Meeting on Association for Computational Linguistics, pages 399–406. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saib Mansour</author>
<author>Khalil Sima’an</author>
<author>Yoad Winter</author>
</authors>
<title>Smoothing a lexicon-based pos tagger for Arabic and Hebrew.</title>
<date>2007</date>
<booktitle>In Semitic ’07: Proceedings of the 2007 Workshop on Computational Approaches to Semitic Languages,</booktitle>
<pages>97--103</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Mansour, Sima’an, Winter, 2007</marker>
<rawString>Saib Mansour, Khalil Sima’an, and Yoad Winter. 2007. Smoothing a lexicon-based pos tagger for Arabic and Hebrew. In Semitic ’07: Proceedings of the 2007 Workshop on Computational Approaches to Semitic Languages, pages 97–103. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emad Mohamed</author>
<author>Sandra Kübler</author>
</authors>
<title>Arabic part of speech tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Language Resources and Evaluation (LREC’10).</booktitle>
<contexts>
<context position="35427" citStr="Mohamed and Kübler (2010" startWordPosition="5778" endWordPosition="5781">c without any additional language re0.95 0.85 0.75 0.65 0.9 0.8 0.7 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Unknown Accuracy 0.45 0.35 0.25 0.15 0.05 0.4 0.3 0.2 0.1 0 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Known Accuracy 818 sources. At the heart of the algorithm is a word-level trigram language model, which captures the correct weights for prefixes and suffixes. They report an accuracy of 97%. We opted to use our own segmenter because we felt we could achieve higher accuracy with the hybrid segmenter. Mohamed and Kübler (2010a, 2010b) report on closely related work for morphological tagging. They use a data-driven approach to find the POS tags for Arabic, using both word tokens and segmented words as inputs for their system. Although their segmentation performance is high, they report that accuracy is lower when first segmenting word tokens. They employ TiMBL, a memory-based learner, as their model and report an accuracy of 94.74%. Habash and Rambow (2005) currently have the most accurate approach for Arabic morphological analysis using additional language tools. They focus on morphological disambiguation (tagging</context>
</contexts>
<marker>Mohamed, Kübler, 2010</marker>
<rawString>Emad Mohamed and Sandra Kübler. 2010a. Arabic part of speech tagging. In Proceedings of the Seventh International Language Resources and Evaluation (LREC’10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emad Mohamed</author>
<author>Sandra Kübler</author>
</authors>
<title>Is Arabic part of speech tagging feasible without word segmentation? In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>705--708</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="35427" citStr="Mohamed and Kübler (2010" startWordPosition="5778" endWordPosition="5781">c without any additional language re0.95 0.85 0.75 0.65 0.9 0.8 0.7 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Unknown Accuracy 0.45 0.35 0.25 0.15 0.05 0.4 0.3 0.2 0.1 0 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Known Accuracy 818 sources. At the heart of the algorithm is a word-level trigram language model, which captures the correct weights for prefixes and suffixes. They report an accuracy of 97%. We opted to use our own segmenter because we felt we could achieve higher accuracy with the hybrid segmenter. Mohamed and Kübler (2010a, 2010b) report on closely related work for morphological tagging. They use a data-driven approach to find the POS tags for Arabic, using both word tokens and segmented words as inputs for their system. Although their segmentation performance is high, they report that accuracy is lower when first segmenting word tokens. They employ TiMBL, a memory-based learner, as their model and report an accuracy of 94.74%. Habash and Rambow (2005) currently have the most accurate approach for Arabic morphological analysis using additional language tools. They focus on morphological disambiguation (tagging</context>
</contexts>
<marker>Mohamed, Kübler, 2010</marker>
<rawString>Emad Mohamed and Sandra Kübler. 2010b. Is Arabic part of speech tagging feasible without word segmentation? In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 705–708. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimír Petkevič</author>
</authors>
<title>Grammatical agreement and automatic morphological disambiguation of inflectional languages.</title>
<date>2001</date>
<booktitle>In TSD ’01: Proceedings of the 4th International Conference on Text, Speech and Dialogue,</booktitle>
<pages>47--53</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="36962" citStr="Petkevič (2001)" startWordPosition="6018" endWordPosition="6019">s of combining these outputs to match an output from the morphological analyzer. For their best model, they report an overall tag accuracy of 97.6%. Others have used morphological analyzers and other language tools for morphological disambiguation coupled with segmentation. The following works exemplify this approach: Diab et al. (2004) use a POS tagger to jointly segment, POS tag, and chunk base-phrases for Arabic with SVMs. Kudo et al. (2004) use SVMs to morphologically tag Japanese. Smith et al. (2005) use SVMs for segmentation, lemmatization, and POS tagging for Arabic, Korean, and Czech. Petkevič (2001) use a morphological analyzer and additional simple rules for morphological disambiguation of Czech. Mansour et al. (2007) and Bar-haim et al. (2008) both use hidden Markov models to POS tag Hebrew, with the latter including segmentation as part of the task. For Syriac, a morphological analyzer is not available. Kiraz (2000) created a Syriac morphological analyzer using finite-state methods; however, it was developed on outdated and now inaccessible equipment and is no longer working or available to us. 6 Conclusions and Future Work We have shown that we can effectively model segmentation, lin</context>
</contexts>
<marker>Petkevič, 2001</marker>
<rawString>Vladimír Petkevič. 2001. Grammatical agreement and automatic morphological disambiguation of inflectional languages. In TSD ’01: Proceedings of the 4th International Conference on Text, Speech and Dialogue, pages 47–53. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danny Shacham</author>
<author>Shuly Wintner</author>
</authors>
<title>Morphological disambiguation of Hebrew: a case study in classifier combination.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL 2007, the Conference on Empirical Methods in Natural Language Processing and the Conference on Computational Natural Language Learning. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="34461" citStr="Shacham and Wintner (2007)" startWordPosition="5621" endWordPosition="5624"> consonants are injected to compose Semitic words. They employ linguistic knowledge (specifically, lists of prefixes, suffixes, and “knowledge of word-formation processes” combined with SNoW, a multi-class classifier that has been shown to work well in other NLP tasks. The major difference between this approach and the method presented in this paper is that this method does not require the extra knowledge required to encode word-formation processes. A further point of difference is our use of hybrid word- and consonantlevel models, after Haertel et al. (2010). Their work builds on the work of Shacham and Wintner (2007), which is also related to that of Habash and Rambow, described below. Work by Lee et al. (2003) is the most relevant work for segmentation, since they segment Arabic, closely related to Syriac, with a data-driven approach. Lee et al. use an unsupervised algorithm bootstrapped with manually segmented data to learn the segmentation for Arabic without any additional language re0.95 0.85 0.75 0.65 0.9 0.8 0.7 baseline hybrid / hybrid-maxent / maxent-mono hybrid / hybrid-morfette / maxent-mono Unknown Accuracy 0.45 0.35 0.25 0.15 0.05 0.4 0.3 0.2 0.1 0 baseline hybrid / hybrid-maxent / maxent-mono</context>
</contexts>
<marker>Shacham, Wintner, 2007</marker>
<rawString>Danny Shacham and Shuly Wintner. 2007. Morphological disambiguation of Hebrew: a case study in classifier combination. In Proceedings of EMNLP-CoNLL 2007, the Conference on Empirical Methods in Natural Language Processing and the Conference on Computational Natural Language Learning. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>David A Smith</author>
<author>Roy W Tromble</author>
</authors>
<title>Context-based morphological disambiguation with random fields.</title>
<date>2005</date>
<booktitle>In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>475--482</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="36857" citStr="Smith et al. (2005)" startWordPosition="5999" endWordPosition="6002">parate Support Vector Machine (SVM) for each morphological attribute (ten in all). They look at different ways of combining these outputs to match an output from the morphological analyzer. For their best model, they report an overall tag accuracy of 97.6%. Others have used morphological analyzers and other language tools for morphological disambiguation coupled with segmentation. The following works exemplify this approach: Diab et al. (2004) use a POS tagger to jointly segment, POS tag, and chunk base-phrases for Arabic with SVMs. Kudo et al. (2004) use SVMs to morphologically tag Japanese. Smith et al. (2005) use SVMs for segmentation, lemmatization, and POS tagging for Arabic, Korean, and Czech. Petkevič (2001) use a morphological analyzer and additional simple rules for morphological disambiguation of Czech. Mansour et al. (2007) and Bar-haim et al. (2008) both use hidden Markov models to POS tag Hebrew, with the latter including segmentation as part of the task. For Syriac, a morphological analyzer is not available. Kiraz (2000) created a Syriac morphological analyzer using finite-state methods; however, it was developed on outdated and now inaccessible equipment and is no longer working or ava</context>
</contexts>
<marker>Smith, Smith, Tromble, 2005</marker>
<rawString>Noah A. Smith, David A. Smith, and Roy W. Tromble. 2005. Context-based morphological disambiguation with random fields. In HLT ’05: Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 475–482. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>C Manning</author>
</authors>
<title>Enriching the knowledge sources used in a maximum entropy partof-speech tagger.</title>
<date>2000</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>63--70</pages>
<contexts>
<context position="16540" citStr="Toutanova and Manning (2000)" startWordPosition="2667" endWordPosition="2671">nd roots) that have not been seen during training, but whose transformations have been seen. This model is trained on all words in order to capture as many transformations as possible. The second approach for unknown words, called hybrid-mazent, uses an MEMM trained on all words seen in training. Given a stem (respectively, baseform), this approach predicts only baseforms (respectively, roots) that were observed in training data. Thus, this method has a distinct disadvantage when it comes to predicting new forms. This approach corresponds directly to the approach to handling unknown -words by Toutanova and Manning (2000) for POS tagging. With regard to baseform and root linkage, we do not use the dictionary to constrain possible baseforms or roots, since we make no initial assumptions about the completeness of a dictionary. 2.4 Morphological Tagging For morphological tagging, we break the task into two separate tasks: tagging the suffix and tagging the stem. Since there are a number of values that need to be predicted, we define two ways to approach the problem. We call the first approach the monolithic approach, in which the label is the concatenation of all the morphological attribute values. Table 3 illust</context>
</contexts>
<marker>Toutanova, Manning, 2000</marker>
<rawString>K. Toutanova and C. Manning. 2000. Enriching the knowledge sources used in a maximum entropy partof-speech tagger. In Proceedings of EMNLP, pages 63–70.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>