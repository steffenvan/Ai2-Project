<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001302">
<title confidence="0.989765">
Decision detection using hierarchical graphical models
</title>
<author confidence="0.978764">
Trung H. Bui
</author>
<affiliation confidence="0.804231666666667">
CSLI
Stanford University
Stanford, CA 94305, USA
</affiliation>
<email confidence="0.995404">
thbui@stanford.edu
</email>
<author confidence="0.968626">
Stanley Peters
</author>
<affiliation confidence="0.797525">
CSLI
Stanford University
Stanford, CA 94305, USA
</affiliation>
<email confidence="0.997223">
peters@csli.stanford.edu
</email>
<sectionHeader confidence="0.997373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999952714285714">
We investigate hierarchical graphical
models (HGMs) for automatically detect-
ing decisions in multi-party discussions.
Several types of dialogue act (DA) are
distinguished on the basis of their roles in
formulating decisions. HGMs enable us
to model dependencies between observed
features of discussions, decision DAs, and
subdialogues that result in a decision. For
the task of detecting decision regions, an
HGM classifier was found to outperform
non-hierarchical graphical models and
support vector machines, raising the
F1-score to 0.80 from 0.55.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999905617647059">
In work environments, people share information
and make decisions in multi-party conversations
known as meetings. The demand for systems that
can automatically process information contained
in audio and video recordings of meetings is grow-
ing rapidly. Our own research, and that of other
contemporary projects (Janin et al., 2004) aim at
meeting this demand.
We are currently investigating the automatic de-
tection of decision discussions. Our approach in-
volves distinguishing between different dialogue
act (DA) types based on their role in the decision-
making process. These DA types are called De-
cision Dialogue Acts (DDAs). Groups of DDAs
combine to form a decision region.
Recent work (Bui et al., 2009) showed that
Directed Graphical Models (DGMs) outperform
other machine learning techniques such as Sup-
port Vector Machines (SVMs) for detecting in-
dividual DDAs. However, the proposed mod-
els, which were non-hierarchical, did not signifi-
cantly improve identification of decision regions.
This paper tests whether giving DGMs hierarchi-
cal structure (making them HGMs) can improve
their performance at this task compared with non-
hierarchical DGMs.
We proceed as follows. Section 2 discusses re-
lated work, and section 3 our data set and anno-
tation scheme for decision discussions. Section
4 summarizes previous decision detection exper-
iments using DGMs. Section 5 presents the HGM
approach, and section 6 describes our HGM exper-
iments. Finally, section 7 draws conclusions and
presents ideas for future work.
</bodyText>
<sectionHeader confidence="0.999892" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999962448275862">
User studies (Banerjee et al., 2005) have con-
firmed that meeting participants consider deci-
sions to be one of the most important meeting
outputs, and Whittaker et al. (2006) found that
the development of an automatic decision de-
tection component is critical for re-using meet-
ing archives. With the new availability of sub-
stantial meeting corpora such as the AMI cor-
pus (McCowan et al., 2005), recent years have
seen an increasing amount of research on decision-
making dialogue. This research has tackled is-
sues such as the automatic detection of agreement
and disagreement (Galley et al., 2004), and of
the level of involvement of conversational partic-
ipants (Gatica-Perez et al., 2005). Recent work
on automatic detection of decisions has been con-
ducted by Hsueh and Moore (2007), Fern´andez et
al. (2008), and Bui et al. (2009).
Fern´andez et al. (2008) proposed an approach
to modeling the structure of decision-making di-
alogue. These authors designed an annotation
scheme that takes account of the different roles
that utterances can play in the decision-making
process—for example it distinguishes between
DDAs that initiate a decision discussion by rais-
ing an issue, those that propose a resolution of the
issue, and those that express agreement to a pro-
posed resolution. The authors annotated a por-
tion of the AMI corpus, and then applied what
</bodyText>
<page confidence="0.981718">
307
</page>
<note confidence="0.506544">
Proceedings of the ACL 2010 Conference Short Papers, pages 307–312,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999808174603175">
they refer to as “hierarchical classification.” Here,
one sub-classifier per DDA class hypothesizes oc-
currences of that type of DDA and then, based
on these hypotheses, a super-classifier determines
which regions of dialogue are decision discus-
sions. All of the classifiers, (sub and super), were
linear kernel binary SVMs. Results were bet-
ter than those obtained with (Hsueh and Moore,
2007)’s approach—the F1-score for detecting de-
cision discussions in manual transcripts was 0.58
vs. 0.50. Purver et al. (2007) had earlier detected
action items with the approach Fern´andez et al.
(2008) extended to decisions.
Bui et al. (2009) built on the promising results
of (Fern´andez et al., 2008), by employing DGMs
in place of SVMs. DGMs are attractive because
they provide a natural framework for modeling se-
quence and dependencies between variables, in-
cluding the DDAs. Bui et al. (2009) were espe-
cially interested in whether DGMs better exploit
non-lexical features. Fern´andez et al. (2008) ob-
tained much more value from lexical than non-
lexical features (and indeed no value at all from
prosodic features), but lexical features have limi-
tations. In particular, they can be domain specific,
increase the size of the feature space dramatically,
and deteriorate more in quality than other features
when automatic speech recognition (ASR) is poor.
More detail about decision detection using DGMs
will be presented in section 4.
Beyond decision detection, DGMs are used for
labeling and segmenting sequences of observa-
tions in many different fields—including bioin-
formatics, ASR, Natural Language Processing
(NLP), and information extraction. In particular,
Dynamic Bayesian Networks (DBNs) are a pop-
ular model for probabilistic sequence modeling
because they exploit structure in the problem to
compactly represent distributions over multi-state
and observation variables. Hidden Markov Mod-
els (HMMs), a special case of DBNs, are a classi-
cal method for important NLP applications such
as unsupervised part-of-speech tagging (Gael et
al., 2009) and grammar induction (Johnson et al.,
2007) as well as for ASR. More complex DBNs
have been used for applications such as DA recog-
nition (Crook et al., 2009) and activity recogni-
tion (Bui et al., 2002).
Undirected graphical models (UGMs) are also
valuable for building probabilistic models for seg-
menting and labeling sequence data. Conditional
Random Fields (CRFs), a simple UGM case, can
avoid the label bias problem (Lafferty et al., 2001)
and outperform maximum entropy Markov mod-
els and HMMs.
However, the graphical models used in these
applications are mainly non-hierarchical, includ-
ing those in Bui et al. (2009). Only Sutton et al.
(2007) proposed a three-level HGM (in the form of
a dynamic CRF) for the joint noun phrase chunk-
ing and part of speech labeling problem; they
showed that this model performs better than a non-
hierarchical counterpart.
</bodyText>
<sectionHeader confidence="0.995727" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.987633055555555">
For the experiments reported in this study, we
used 17 meetings from the AMI Meeting Corpusl,
a freely available corpus of multi-party meetings
with both audio and video recordings, and a wide
range of annotated information including DAs and
topic segmentation. The meetings last around 30
minutes each, and are scenario-driven, wherein
four participants play different roles in a com-
pany’s design team: project manager, marketing
expert, interface designer and industrial designer.
We use the same annotation scheme as
Fern´andez et al. (2008) to model decision-making
dialogue. As stated in section 2, this scheme dis-
tinguishes between a small number of DA types
based on the role which they perform in the for-
mulation of a decision. Besides improving the de-
tection of decision discussions (Fern´andez et al.,
2008), such a scheme also aids in summarization
of them, because it indicates which utterances pro-
vide particular types of information.
The annotation scheme is based on the observa-
tion that a decision discussion typically contains
the following main structural components: (a) A
topic or issue requiring resolution is raised; (b)
One or more possible resolutions are considered;
(c) A particular resolution is agreed upon, and so
adopted as the decision. Hence the scheme dis-
tinguishes between three main DDA classes: issue
(I), resolution (R), and agreement (A). Class R is
further subdivided into resolution proposal (RP)
and resolution restatement (RR). I utterances in-
troduce the topic of the decision discussion, ex-
amples being “Are we going to have a backup?”
and “But would a backup really be necessary?” in
Table 1. In comparison, R utterances specify the
resolution which is ultimately adopted as the deci-
</bodyText>
<footnote confidence="0.989722">
1http://corpus.amiproject.org/
</footnote>
<page confidence="0.991839">
308
</page>
<listItem confidence="0.9681915">
(1) A: Are we going to have a backup? Or we do
just–
</listItem>
<bodyText confidence="0.887736333333333">
B: But would a backup really be necessary?
A: I think maybe we could just go for the
kinetic energy and be bold and innovative.
</bodyText>
<listItem confidence="0.79248125">
C: Yeah.
B: I think– yeah.
A: It could even be one of our selling points.
C: Yeah –laugh–.
D: Environmentally conscious or something.
A: Yeah.
B: Okay, fully kinetic energy.
D: Good.
</listItem>
<tableCaption confidence="0.893636666666667">
Table 1: An excerpt from the AMI dialogue
ES2015c. It has been modified slightly for pre-
sentation purposes.
</tableCaption>
<bodyText confidence="0.999839652173913">
sion. RP utterances propose this resolution (e.g. “I
think maybe we could just go for the kinetic energy
... ”), while RR utterances close the discussion by
confirming/summarizing the decision (e.g. “Okay,
fully kinetic energy”). Finally, A utterances agree
with the proposed resolution, signaling that it is
adopted as the decision, (e.g. “Yeah”, “Good” and
“Okay”). Unsurprisingly, an utterance may be as-
signed to more than one DDA class; and within a
decision discussion, more than one utterance can
be assigned to the same DDA class.
We use manual transcripts in the experiments
described here. Inter-annotator agreement was sat-
isfactory, with kappa values ranging from .63 to
.73 for the four DDA classes. The manual tran-
scripts contain a total of 15,680 utterances, and on
average 40 DDAs per meeting. DDAs are sparse
in the transcripts: for all DDAs, 6.7% of the total-
ity of utterances; for I,1.6%; for RP, 2%; for RR,
0.5%; and forA, 2.6%. In all, 3753 utterances (i.e.,
23.9%) are tagged as decision-related utterances,
and on average there are 221 decision-related ut-
terances per meeting.
</bodyText>
<sectionHeader confidence="0.994605" genericHeader="method">
4 Prior Work on Decision Detection
using Graphical Models
</sectionHeader>
<bodyText confidence="0.999440052631579">
To detect each individual DDA class, Bui et al.
(2009) examined the four simple DGMs shown
in Fig. 1. The DDA node is binary valued, with
value 1 indicating the presence of a DDA and 0
its absence. The evidence node (E) is a multi-
dimensional vector of observed values of non-
lexical features. These include utterance features
(UTT) such as length in words2, duration in mil-
liseconds, position within the meeting (as percent-
age of elapsed time), manually annotated dialogue
act (DA) features3 such as inform, assess, suggest,
and prosodic features (PROS) such as energy and
pitch. These features are the same as the non-
lexical features used by Fern´andez et al. (2008).
The hidden component node (C) in the -mix mod-
els represents the distribution of observable evi-
dence E as a mixture of Gaussian distributions.
The number of Gaussian components was hand-
tuned during the training phase.
</bodyText>
<figureCaption confidence="0.796168666666667">
Figure 1: Simple DGMs for individual decision
dialogue act detection. The clear nodes are hidden,
and the shaded nodes are observable.
</figureCaption>
<bodyText confidence="0.924859857142857">
More complex models were constructed from
the four simple models in Fig. 1 to allow for de-
pendencies between different DDAs. For exam-
ple, the model in Fig. 2 generalizes Fig. 1c with
arcs connecting the DDA classes based on analy-
sis of the annotated AMI data.
time t-1 time t
</bodyText>
<figureCaption confidence="0.95045425">
Figure 2: A DGM that takes the dependencies be-
tween decision dialogue acts into account.
Decision discussion regions were identified us-
ing the DGM output and the following two simple
rules: (1) A decision discussion region begins with
an Issue DDA; (2) A decision discussion region
contains at least one Issue DDA and one Resolu-
tion DDA.
</figureCaption>
<footnote confidence="0.9604808">
2This feature is a manual count of lexical tokens; but word
count was extracted automatically from ASR output by Bui
et al. (2009). We plan experiments to determine how much
using ASR output degrades detection of decision regions.
3The authors used the AMI DA annotations.
</footnote>
<figure confidence="0.999004875">
c) DBN-sim d) DBN-mix
a) BN-sim
b) BN-mix
time t-1 timet
time t-1 timet
DDA
E
DDA
C
E
DDA
E
DDA
E
C
DDA
E
DDA
E
C
I RP RR A
I RP RR
A
E E
</figure>
<page confidence="0.997021">
309
</page>
<bodyText confidence="0.98716375">
The authors conducted experiments using the
AMI corpus and found that when using non-
lexical features, the DGMs outperform the hierar-
chical SVM classification method of (Fern´andez et
al., 2008). The F1-score for the four DDA classes
increased between 0.04 and 0.19 (p &lt; 0.005),
and for identifying decision discussion regions, by
0.05 (p &gt; 0.05).
</bodyText>
<sectionHeader confidence="0.978585" genericHeader="method">
5 Hierarchical graphical models
</sectionHeader>
<bodyText confidence="0.999905487179487">
Although the results just discussed showed graph-
ical models are better than SVMs for detecting de-
cision dialogue acts (Bui et al., 2009), two-level
graphical models like those shown in Figs. 1 and 2
cannot exploit dependencies between high-level
discourse items such as decision discussions and
DDAs; and the “superclassifier” rule (Bui et al.,
2009) used for detecting decision regions did not
significantly improve the F1-score for decisions.
We thus investigate whether HGMs (structured
as three or more levels) are superior for discov-
ering the structure and learning the parameters
of decision recognition. Our approach composes
graphical models to increase hierarchy with an ad-
ditional level above or below previous ones, or in-
serts a new level such as for discourse topics into
the interior of a given model.
Fig. 3 shows a simple structure for three-level
HGMs. The top level corresponds to high-level
discourse regions such as decision discussions.
The segmentation into these regions is represented
in terms of a random variable (at each DR node)
that takes on discrete values: {positive, negative}
(the utterance belongs to a decision region or not)
or {begin, middle, end, outside} (indicating the
position of the utterance relative to a decision dis-
cussion region). The middle level corresponds to
mid-level discourse items such as issues, resolu-
tion proposals, resolution restatements, and agree-
ments. These classes (C1, C2, ..., Cn nodes) are
represented as a collection of random variables,
each corresponding to an individual mid-level ut-
terance class. For example, the middle level of the
three-level HGM Fig. 3 could be the top-level of
the two-level DGM in Fig. 2, each middle level
node containing random variables for the DDA
classes I, RP, RR, and A. The bottom level cor-
responds to vectors of observed features as before,
e.g. lexical, utterance, and prosodic features.
</bodyText>
<figure confidence="0.667186">
current utterance next utterance
</figure>
<figureCaption confidence="0.8246615">
Figure 3: A simple structure of a three-level
HGM: DRs are high-level discourse regions;
C1, C2,..., Cn are mid-level utterance classes; and
Es are vectors of observed features.
</figureCaption>
<sectionHeader confidence="0.998704" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.98500168">
The HGM classifier in Figure 3 was implemented
in Matlab using the BNT software4. The classifier
hypothesizes that an utterance belongs to a deci-
sion region if the marginal probability of the ut-
terance’s DR node is above a hand-tuned thresh-
old. The threshold is selected using the ROC curve
analysis5 to obtain the highest F1-score. To evalu-
ate the accuracy of hypothesized decision regions,
we divided the dialogue into 30-second windows
and evaluated on a per window basis.
The best model structure was selected by com-
paring the performance of various handcrafted
structures. For example, the model in Fig. 4b out-
performs the one in Fig. 4a. Fig. 4b explicitly
models the dependency between the decision re-
gions and the observed features.
Figure 4: Three-level HGMs for recognition of de-
cisions. This illustrates the choice of the structure
for each time slice of the HGM sequence models.
Table 2 shows the results of 17-fold cross-
validation for the hierarchical SVM classifica-
tion (Fern´andez et al., 2008), rule-based classifi-
cation with DGM output (Bui et al., 2009), and
our HGM classification using the best combina-
tion of non-lexical features. All three methods
</bodyText>
<footnote confidence="0.999903">
4http://www.cs.ubc.ca/—murphyk/Software/BNT/bnt.html
5http://en.wikipedia.org/wiki/Receiver operating characteristic
</footnote>
<figure confidence="0.9958794">
Level 3
DR DR
Cn Cn
Level 2
C,
C,
Level ,
E E
a) b)
I RP RR A
DR
E
I RP RR A
DR
E
</figure>
<page confidence="0.995592">
310
</page>
<bodyText confidence="0.999379875">
were implemented by us using exactly the same
data and 17-fold cross-validation. The features
were selected based on the best combination of
non-lexical features for each method. The HGM
classifier outperforms both its SVM and DGM
counterparts (p &lt; 0.0001)6. In fact, even when the
SVM uses lexical as well as non-lexical features,
its F1-score is still lower than the HGM classifier.
</bodyText>
<table confidence="0.99968375">
Classifier Pr Re F1
SVM 0.35 0.88 0.50
DGM 0.39 0.93 0.55
HGM 0.69 0.96 0.80
</table>
<tableCaption confidence="0.96524">
Table 2: Results for detection of decision dis-
</tableCaption>
<bodyText confidence="0.997690413793104">
cussion regions by the SVM super-classifier,
rule-based DGM classifier, and HGM clas-
sifier, each using its best combination of
non-lexical features: SVM (UTT+DA), DGM
(UTT+DA+PROS), HGM (UTT+DA).
In contrast with the hierarchical SVM and rule-
based DGM methods, the HGM method identifies
decision-related utterances by exploiting not just
DDAs but also direct dependencies between deci-
sion regions and UTT, DA, and PROS features. As
mentioned in the second paragraph of this section,
explicitly modeling the dependency between deci-
sion regions and observable features helps to im-
prove detection of decision regions. Furthermore,
a three-level HGM can straightforwardly model
the composition of each high-level decision region
as a sequence of mid-level DDA utterances. While
the hierarchical SVM method can also take depen-
dency between successive utterances into account,
it has no principled way to associate this depen-
dency with more extended decision regions. In
addition, this dependency is only meaningful for
lexical features (Fern´andez et al., 2008).
The HGM result presented in Table 2 was
computed using the three-level DBN model (see
Fig. 4b) using the combination of UTT and DA
features. Without DA features, the F1-score de-
grades from 0.8 to 0.78. However, this difference
is not statistically significant (i.e., p &gt; 0.5).
</bodyText>
<sectionHeader confidence="0.998499" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99958">
To detect decision discussions in multi-party dia-
logue, we investigated HGMs as an extension of
</bodyText>
<footnote confidence="0.9952615">
6We used the paired t test for computing statistical signif-
icance. http://www.graphpad.com/quickcalcs/ttest1.cfm
</footnote>
<bodyText confidence="0.9994815">
the DGMs studied in (Bui et al., 2009). When
using non-lexical features, HGMs outperform the
non-hierarchical DGMs of (Bui et al., 2009) and
also the hierarchical SVM classification method
of Fern´andez et al. (2008). The F1-score for
identifying decision discussion regions increased
to 0.80 from 0.55 and 0.50 respectively (p &lt;
0.0001).
In future work, we plan to (a) investigate cas-
caded learning methods (Sutton et al., 2007) to
improve the detection of DDAs further by using
detected decision regions and (b) extend HGMs
beyond three levels in order to integrate useful se-
mantic information such as topic structure.
</bodyText>
<sectionHeader confidence="0.999158" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999575125">
The research reported in this paper was spon-
sored by the Department of the Navy, Office of
Naval Research, under grants number N00014-
09-1-0106 and N00014-09-1-0122. Any opinions,
findings, and conclusions or recommendations ex-
pressed in this material are those of the authors and
do not necessarily reflect the views of the Office of
Naval Research.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997877259259259">
Satanjeev Banerjee, Carolyn Ros´e, and Alex Rudnicky.
2005. The necessity of a meeting recording and
playback system, and the benefit of topic-level anno-
tations to meeting browsing. In Proceedings of the
10th International Conference on Human-Computer
Interaction.
H. H. Bui, S. Venkatesh, and G. West. 2002. Pol-
icy recognition in the abstract hidden markov model.
Journal of Artificial Intelligence Research, 17:451–
499.
Trung Huu Bui, Matthew Frampton, John Dowding,
and Stanley Peters. 2009. Extracting decisions from
multi-party dialogue using directed graphical mod-
els and semantic similarity. In Proceedings of the
10th Annual SIGDIAL Meeting on Discourse and
Dialogue (SIGdial09).
Nigel Crook, Ramon Granell, and Stephen Pulman.
2009. Unsupervised classification of dialogue acts
using a dirichlet process mixture model. In Pro-
ceedings of SIGDIAL 2009: the 10th Annual Meet-
ing of the Special Interest Group in Discourse and
Dialogue, pages 341–348.
Raquel Fern´andez, Matthew Frampton, Patrick Ehlen,
Matthew Purver, and Stanley Peters. 2008. Mod-
elling and detecting decisions in multi-party dia-
logue. In Proceedings of the 9th SIGdial Workshop
on Discourse and Dialogue.
</reference>
<page confidence="0.984513">
311
</page>
<reference confidence="0.999912552238806">
Jurgen Van Gael, Andreas Vlachos, and Zoubin
Ghahramani. 2009. The infinite HMM for unsu-
pervised PoS tagging. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 678–687.
Michel Galley, Kathleen McKeown, Julia Hirschberg,
and Elizabeth Shriberg. 2004. Identifying agree-
ment and disagreement in conversational speech:
Use of Bayesian networks to model pragmatic de-
pendencies. In Proceedings of the 42nd Annual
Meeting of the Association for Computational Lin-
guistics (ACL).
Daniel Gatica-Perez, Ian McCowan, Dong Zhang, and
Samy Bengio. 2005. Detecting group interest level
in meetings. In Proceedings of ICASSP.
Pey-Yun Hsueh and Johanna Moore. 2007. Automatic
decision detection in meeting speech. In Proceed-
ings of MLMI 2007, Lecture Notes in Computer Sci-
ence. Springer-Verlag.
Adam Janin, Jeremy Ang, Sonali Bhagat, Rajdip
Dhillon, Jane Edwards, Javier Marc´ıas-Guarasa,
Nelson Morgan, Barbara Peskin, Elizabeth Shriberg,
Andreas Stolcke, Chuck Wooters, and Britta Wrede.
2004. The ICSI meeting project: Resources and re-
search. In Proceedings of the 2004 ICASSP NIST
Meeting Recognition Workshop.
Mark Johnson, Thomas Griffiths, and Sharon Gold-
water. 2007. Bayesian inference for PCFGs via
Markov chain Monte Carlo. In Proceedings of
Human Language Technologies 2007: The Confer-
ence of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 139–146,
Rochester, New York, April. Association for Com-
putational Linguistics.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the 18th Interna-
tional Conference on Machine Learning, pages 282–
289. Morgan Kaufmann.
Iain McCowan, Jean Carletta, W. Kraaij, S. Ashby,
S. Bourban, M. Flynn, M. Guillemot, T. Hain,
J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lathoud,
M. Lincoln, A. Lisowska, W. Post, D. Reidsma, and
P. Wellner. 2005. The AMI Meeting Corpus. In
Proceedings of Measuring Behavior, the 5th Inter-
national Conference on Methods and Techniques in
Behavioral Research, Wageningen, Netherlands.
Matthew Purver, John Dowding, John Niekrasz,
Patrick Ehlen, Sharareh Noorbaloochi, and Stanley
Peters. 2007. Detecting and summarizing action
items in multi-party dialogue. In Proceedings of the
8th SIGdial Workshop on Discourse and Dialogue,
Antwerp, Belgium.
Charles Sutton, Andrew McCallum, and Khashayar
Rohanimanesh. 2007. Dynamic conditional random
fields: Factorized probabilistic models for labeling
and segmenting sequence data. Journal of Machine
Learning Research, 8:693–723.
Steve Whittaker, Rachel Laban, and Simon Tucker.
2006. Analysing meeting records: An ethnographic
study and technological implications. In S. Renals
and S. Bengio, editors, Machine Learning for Multi-
modal Interaction: Second International Workshop,
MLMI 2005, Revised Selected Papers, volume 3869
of Lecture Notes in Computer Science, pages 101–
113. Springer.
</reference>
<page confidence="0.998662">
312
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.634039">
<title confidence="0.998942">Decision detection using hierarchical graphical models</title>
<author confidence="0.999994">Trung H Bui</author>
<affiliation confidence="0.989317">CSLI Stanford University</affiliation>
<address confidence="0.999837">Stanford, CA 94305, USA</address>
<email confidence="0.9997">thbui@stanford.edu</email>
<author confidence="0.991941">Stanley Peters</author>
<affiliation confidence="0.9862565">CSLI Stanford University</affiliation>
<address confidence="0.999828">Stanford, CA 94305, USA</address>
<email confidence="0.999656">peters@csli.stanford.edu</email>
<abstract confidence="0.998171571428571">We investigate hierarchical graphical models (HGMs) for automatically detecting decisions in multi-party discussions. Several types of dialogue act (DA) are distinguished on the basis of their roles in formulating decisions. HGMs enable us to model dependencies between observed features of discussions, decision DAs, and subdialogues that result in a decision. For the task of detecting decision regions, an HGM classifier was found to outperform non-hierarchical graphical models and support vector machines, raising the</abstract>
<note confidence="0.695455">F1-score to 0.80 from 0.55.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Carolyn Ros´e</author>
<author>Alex Rudnicky</author>
</authors>
<title>The necessity of a meeting recording and playback system, and the benefit of topic-level annotations to meeting browsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th International Conference on Human-Computer Interaction.</booktitle>
<marker>Banerjee, Ros´e, Rudnicky, 2005</marker>
<rawString>Satanjeev Banerjee, Carolyn Ros´e, and Alex Rudnicky. 2005. The necessity of a meeting recording and playback system, and the benefit of topic-level annotations to meeting browsing. In Proceedings of the 10th International Conference on Human-Computer Interaction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H H Bui</author>
<author>S Venkatesh</author>
<author>G West</author>
</authors>
<title>Policy recognition in the abstract hidden markov model.</title>
<date>2002</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>17</volume>
<pages>499</pages>
<contexts>
<context position="6072" citStr="Bui et al., 2002" startWordPosition="929" endWordPosition="932"> extraction. In particular, Dynamic Bayesian Networks (DBNs) are a popular model for probabilistic sequence modeling because they exploit structure in the problem to compactly represent distributions over multi-state and observation variables. Hidden Markov Models (HMMs), a special case of DBNs, are a classical method for important NLP applications such as unsupervised part-of-speech tagging (Gael et al., 2009) and grammar induction (Johnson et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recognition (Crook et al., 2009) and activity recognition (Bui et al., 2002). Undirected graphical models (UGMs) are also valuable for building probabilistic models for segmenting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov models and HMMs. However, the graphical models used in these applications are mainly non-hierarchical, including those in Bui et al. (2009). Only Sutton et al. (2007) proposed a three-level HGM (in the form of a dynamic CRF) for the joint noun phrase chunking and part of speech labeling problem; they showed that this m</context>
</contexts>
<marker>Bui, Venkatesh, West, 2002</marker>
<rawString>H. H. Bui, S. Venkatesh, and G. West. 2002. Policy recognition in the abstract hidden markov model. Journal of Artificial Intelligence Research, 17:451– 499.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trung Huu Bui</author>
<author>Matthew Frampton</author>
<author>John Dowding</author>
<author>Stanley Peters</author>
</authors>
<title>Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the 10th Annual SIGDIAL Meeting on Discourse and Dialogue (SIGdial09).</booktitle>
<contexts>
<context position="1506" citStr="Bui et al., 2009" startWordPosition="215" endWordPosition="218">tions known as meetings. The demand for systems that can automatically process information contained in audio and video recordings of meetings is growing rapidly. Our own research, and that of other contemporary projects (Janin et al., 2004) aim at meeting this demand. We are currently investigating the automatic detection of decision discussions. Our approach involves distinguishing between different dialogue act (DA) types based on their role in the decisionmaking process. These DA types are called Decision Dialogue Acts (DDAs). Groups of DDAs combine to form a decision region. Recent work (Bui et al., 2009) showed that Directed Graphical Models (DGMs) outperform other machine learning techniques such as Support Vector Machines (SVMs) for detecting individual DDAs. However, the proposed models, which were non-hierarchical, did not significantly improve identification of decision regions. This paper tests whether giving DGMs hierarchical structure (making them HGMs) can improve their performance at this task compared with nonhierarchical DGMs. We proceed as follows. Section 2 discusses related work, and section 3 our data set and annotation scheme for decision discussions. Section 4 summarizes pre</context>
<context position="3153" citStr="Bui et al. (2009)" startWordPosition="477" endWordPosition="480">matic decision detection component is critical for re-using meeting archives. With the new availability of substantial meeting corpora such as the AMI corpus (McCowan et al., 2005), recent years have seen an increasing amount of research on decisionmaking dialogue. This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational participants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been conducted by Hsueh and Moore (2007), Fern´andez et al. (2008), and Bui et al. (2009). Fern´andez et al. (2008) proposed an approach to modeling the structure of decision-making dialogue. These authors designed an annotation scheme that takes account of the different roles that utterances can play in the decision-making process—for example it distinguishes between DDAs that initiate a decision discussion by raising an issue, those that propose a resolution of the issue, and those that express agreement to a proposed resolution. The authors annotated a portion of the AMI corpus, and then applied what 307 Proceedings of the ACL 2010 Conference Short Papers, pages 307–312, Uppsal</context>
<context position="4461" citStr="Bui et al. (2009)" startWordPosition="679" endWordPosition="682">as “hierarchical classification.” Here, one sub-classifier per DDA class hypothesizes occurrences of that type of DDA and then, based on these hypotheses, a super-classifier determines which regions of dialogue are decision discussions. All of the classifiers, (sub and super), were linear kernel binary SVMs. Results were better than those obtained with (Hsueh and Moore, 2007)’s approach—the F1-score for detecting decision discussions in manual transcripts was 0.58 vs. 0.50. Purver et al. (2007) had earlier detected action items with the approach Fern´andez et al. (2008) extended to decisions. Bui et al. (2009) built on the promising results of (Fern´andez et al., 2008), by employing DGMs in place of SVMs. DGMs are attractive because they provide a natural framework for modeling sequence and dependencies between variables, including the DDAs. Bui et al. (2009) were especially interested in whether DGMs better exploit non-lexical features. Fern´andez et al. (2008) obtained much more value from lexical than nonlexical features (and indeed no value at all from prosodic features), but lexical features have limitations. In particular, they can be domain specific, increase the size of the feature space dr</context>
<context position="6491" citStr="Bui et al. (2009)" startWordPosition="993" endWordPosition="996">grammar induction (Johnson et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recognition (Crook et al., 2009) and activity recognition (Bui et al., 2002). Undirected graphical models (UGMs) are also valuable for building probabilistic models for segmenting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov models and HMMs. However, the graphical models used in these applications are mainly non-hierarchical, including those in Bui et al. (2009). Only Sutton et al. (2007) proposed a three-level HGM (in the form of a dynamic CRF) for the joint noun phrase chunking and part of speech labeling problem; they showed that this model performs better than a nonhierarchical counterpart. 3 Data For the experiments reported in this study, we used 17 meetings from the AMI Meeting Corpusl, a freely available corpus of multi-party meetings with both audio and video recordings, and a wide range of annotated information including DAs and topic segmentation. The meetings last around 30 minutes each, and are scenario-driven, wherein four participants </context>
<context position="10181" citStr="Bui et al. (2009)" startWordPosition="1599" endWordPosition="1602">ere. Inter-annotator agreement was satisfactory, with kappa values ranging from .63 to .73 for the four DDA classes. The manual transcripts contain a total of 15,680 utterances, and on average 40 DDAs per meeting. DDAs are sparse in the transcripts: for all DDAs, 6.7% of the totality of utterances; for I,1.6%; for RP, 2%; for RR, 0.5%; and forA, 2.6%. In all, 3753 utterances (i.e., 23.9%) are tagged as decision-related utterances, and on average there are 221 decision-related utterances per meeting. 4 Prior Work on Decision Detection using Graphical Models To detect each individual DDA class, Bui et al. (2009) examined the four simple DGMs shown in Fig. 1. The DDA node is binary valued, with value 1 indicating the presence of a DDA and 0 its absence. The evidence node (E) is a multidimensional vector of observed values of nonlexical features. These include utterance features (UTT) such as length in words2, duration in milliseconds, position within the meeting (as percentage of elapsed time), manually annotated dialogue act (DA) features3 such as inform, assess, suggest, and prosodic features (PROS) such as energy and pitch. These features are the same as the nonlexical features used by Fern´andez e</context>
<context position="11891" citStr="Bui et al. (2009)" startWordPosition="1891" endWordPosition="1894">r example, the model in Fig. 2 generalizes Fig. 1c with arcs connecting the DDA classes based on analysis of the annotated AMI data. time t-1 time t Figure 2: A DGM that takes the dependencies between decision dialogue acts into account. Decision discussion regions were identified using the DGM output and the following two simple rules: (1) A decision discussion region begins with an Issue DDA; (2) A decision discussion region contains at least one Issue DDA and one Resolution DDA. 2This feature is a manual count of lexical tokens; but word count was extracted automatically from ASR output by Bui et al. (2009). We plan experiments to determine how much using ASR output degrades detection of decision regions. 3The authors used the AMI DA annotations. c) DBN-sim d) DBN-mix a) BN-sim b) BN-mix time t-1 timet time t-1 timet DDA E DDA C E DDA E DDA E C DDA E DDA E C I RP RR A I RP RR A E E 309 The authors conducted experiments using the AMI corpus and found that when using nonlexical features, the DGMs outperform the hierarchical SVM classification method of (Fern´andez et al., 2008). The F1-score for the four DDA classes increased between 0.04 and 0.19 (p &lt; 0.005), and for identifying decision discussi</context>
<context position="15744" citStr="Bui et al., 2009" startWordPosition="2524" endWordPosition="2527">n a per window basis. The best model structure was selected by comparing the performance of various handcrafted structures. For example, the model in Fig. 4b outperforms the one in Fig. 4a. Fig. 4b explicitly models the dependency between the decision regions and the observed features. Figure 4: Three-level HGMs for recognition of decisions. This illustrates the choice of the structure for each time slice of the HGM sequence models. Table 2 shows the results of 17-fold crossvalidation for the hierarchical SVM classification (Fern´andez et al., 2008), rule-based classification with DGM output (Bui et al., 2009), and our HGM classification using the best combination of non-lexical features. All three methods 4http://www.cs.ubc.ca/—murphyk/Software/BNT/bnt.html 5http://en.wikipedia.org/wiki/Receiver operating characteristic Level 3 DR DR Cn Cn Level 2 C, C, Level , E E a) b) I RP RR A DR E I RP RR A DR E 310 were implemented by us using exactly the same data and 17-fold cross-validation. The features were selected based on the best combination of non-lexical features for each method. The HGM classifier outperforms both its SVM and DGM counterparts (p &lt; 0.0001)6. In fact, even when the SVM uses lexical</context>
<context position="18166" citStr="Bui et al., 2009" startWordPosition="2901" endWordPosition="2904">nly meaningful for lexical features (Fern´andez et al., 2008). The HGM result presented in Table 2 was computed using the three-level DBN model (see Fig. 4b) using the combination of UTT and DA features. Without DA features, the F1-score degrades from 0.8 to 0.78. However, this difference is not statistically significant (i.e., p &gt; 0.5). 7 Conclusions and Future Work To detect decision discussions in multi-party dialogue, we investigated HGMs as an extension of 6We used the paired t test for computing statistical significance. http://www.graphpad.com/quickcalcs/ttest1.cfm the DGMs studied in (Bui et al., 2009). When using non-lexical features, HGMs outperform the non-hierarchical DGMs of (Bui et al., 2009) and also the hierarchical SVM classification method of Fern´andez et al. (2008). The F1-score for identifying decision discussion regions increased to 0.80 from 0.55 and 0.50 respectively (p &lt; 0.0001). In future work, we plan to (a) investigate cascaded learning methods (Sutton et al., 2007) to improve the detection of DDAs further by using detected decision regions and (b) extend HGMs beyond three levels in order to integrate useful semantic information such as topic structure. Acknowledgments T</context>
</contexts>
<marker>Bui, Frampton, Dowding, Peters, 2009</marker>
<rawString>Trung Huu Bui, Matthew Frampton, John Dowding, and Stanley Peters. 2009. Extracting decisions from multi-party dialogue using directed graphical models and semantic similarity. In Proceedings of the 10th Annual SIGDIAL Meeting on Discourse and Dialogue (SIGdial09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nigel Crook</author>
<author>Ramon Granell</author>
<author>Stephen Pulman</author>
</authors>
<title>Unsupervised classification of dialogue acts using a dirichlet process mixture model.</title>
<date>2009</date>
<booktitle>In Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue,</booktitle>
<pages>341--348</pages>
<contexts>
<context position="6028" citStr="Crook et al., 2009" startWordPosition="921" endWordPosition="924">ral Language Processing (NLP), and information extraction. In particular, Dynamic Bayesian Networks (DBNs) are a popular model for probabilistic sequence modeling because they exploit structure in the problem to compactly represent distributions over multi-state and observation variables. Hidden Markov Models (HMMs), a special case of DBNs, are a classical method for important NLP applications such as unsupervised part-of-speech tagging (Gael et al., 2009) and grammar induction (Johnson et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recognition (Crook et al., 2009) and activity recognition (Bui et al., 2002). Undirected graphical models (UGMs) are also valuable for building probabilistic models for segmenting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov models and HMMs. However, the graphical models used in these applications are mainly non-hierarchical, including those in Bui et al. (2009). Only Sutton et al. (2007) proposed a three-level HGM (in the form of a dynamic CRF) for the joint noun phrase chunking and part of spee</context>
</contexts>
<marker>Crook, Granell, Pulman, 2009</marker>
<rawString>Nigel Crook, Ramon Granell, and Stephen Pulman. 2009. Unsupervised classification of dialogue acts using a dirichlet process mixture model. In Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 341–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raquel Fern´andez</author>
<author>Matthew Frampton</author>
<author>Patrick Ehlen</author>
<author>Matthew Purver</author>
<author>Stanley Peters</author>
</authors>
<title>Modelling and detecting decisions in multi-party dialogue.</title>
<date>2008</date>
<booktitle>In Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue.</booktitle>
<marker>Fern´andez, Frampton, Ehlen, Purver, Peters, 2008</marker>
<rawString>Raquel Fern´andez, Matthew Frampton, Patrick Ehlen, Matthew Purver, and Stanley Peters. 2008. Modelling and detecting decisions in multi-party dialogue. In Proceedings of the 9th SIGdial Workshop on Discourse and Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jurgen Van Gael</author>
<author>Andreas Vlachos</author>
<author>Zoubin Ghahramani</author>
</authors>
<title>The infinite HMM for unsupervised PoS tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>678--687</pages>
<marker>Van Gael, Vlachos, Ghahramani, 2009</marker>
<rawString>Jurgen Van Gael, Andreas Vlachos, and Zoubin Ghahramani. 2009. The infinite HMM for unsupervised PoS tagging. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 678–687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen McKeown</author>
<author>Julia Hirschberg</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Identifying agreement and disagreement in conversational speech: Use of Bayesian networks to model pragmatic dependencies.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="2918" citStr="Galley et al., 2004" startWordPosition="438" endWordPosition="441">uture work. 2 Related work User studies (Banerjee et al., 2005) have confirmed that meeting participants consider decisions to be one of the most important meeting outputs, and Whittaker et al. (2006) found that the development of an automatic decision detection component is critical for re-using meeting archives. With the new availability of substantial meeting corpora such as the AMI corpus (McCowan et al., 2005), recent years have seen an increasing amount of research on decisionmaking dialogue. This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational participants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been conducted by Hsueh and Moore (2007), Fern´andez et al. (2008), and Bui et al. (2009). Fern´andez et al. (2008) proposed an approach to modeling the structure of decision-making dialogue. These authors designed an annotation scheme that takes account of the different roles that utterances can play in the decision-making process—for example it distinguishes between DDAs that initiate a decision discussion by raising an issue, those that propose a </context>
</contexts>
<marker>Galley, McKeown, Hirschberg, Shriberg, 2004</marker>
<rawString>Michel Galley, Kathleen McKeown, Julia Hirschberg, and Elizabeth Shriberg. 2004. Identifying agreement and disagreement in conversational speech: Use of Bayesian networks to model pragmatic dependencies. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gatica-Perez</author>
<author>Ian McCowan</author>
<author>Dong Zhang</author>
<author>Samy Bengio</author>
</authors>
<title>Detecting group interest level in meetings.</title>
<date>2005</date>
<booktitle>In Proceedings of ICASSP.</booktitle>
<contexts>
<context position="3010" citStr="Gatica-Perez et al., 2005" startWordPosition="452" endWordPosition="455">eting participants consider decisions to be one of the most important meeting outputs, and Whittaker et al. (2006) found that the development of an automatic decision detection component is critical for re-using meeting archives. With the new availability of substantial meeting corpora such as the AMI corpus (McCowan et al., 2005), recent years have seen an increasing amount of research on decisionmaking dialogue. This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational participants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been conducted by Hsueh and Moore (2007), Fern´andez et al. (2008), and Bui et al. (2009). Fern´andez et al. (2008) proposed an approach to modeling the structure of decision-making dialogue. These authors designed an annotation scheme that takes account of the different roles that utterances can play in the decision-making process—for example it distinguishes between DDAs that initiate a decision discussion by raising an issue, those that propose a resolution of the issue, and those that express agreement to a proposed resolution. The auth</context>
</contexts>
<marker>Gatica-Perez, McCowan, Zhang, Bengio, 2005</marker>
<rawString>Daniel Gatica-Perez, Ian McCowan, Dong Zhang, and Samy Bengio. 2005. Detecting group interest level in meetings. In Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pey-Yun Hsueh</author>
<author>Johanna Moore</author>
</authors>
<title>Automatic decision detection in meeting speech.</title>
<date>2007</date>
<booktitle>In Proceedings of MLMI 2007, Lecture Notes in Computer Science.</booktitle>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="3104" citStr="Hsueh and Moore (2007)" startWordPosition="468" endWordPosition="471">er et al. (2006) found that the development of an automatic decision detection component is critical for re-using meeting archives. With the new availability of substantial meeting corpora such as the AMI corpus (McCowan et al., 2005), recent years have seen an increasing amount of research on decisionmaking dialogue. This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational participants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been conducted by Hsueh and Moore (2007), Fern´andez et al. (2008), and Bui et al. (2009). Fern´andez et al. (2008) proposed an approach to modeling the structure of decision-making dialogue. These authors designed an annotation scheme that takes account of the different roles that utterances can play in the decision-making process—for example it distinguishes between DDAs that initiate a decision discussion by raising an issue, those that propose a resolution of the issue, and those that express agreement to a proposed resolution. The authors annotated a portion of the AMI corpus, and then applied what 307 Proceedings of the ACL 20</context>
</contexts>
<marker>Hsueh, Moore, 2007</marker>
<rawString>Pey-Yun Hsueh and Johanna Moore. 2007. Automatic decision detection in meeting speech. In Proceedings of MLMI 2007, Lecture Notes in Computer Science. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Janin</author>
<author>Jeremy Ang</author>
<author>Sonali Bhagat</author>
<author>Rajdip Dhillon</author>
<author>Jane Edwards</author>
<author>Javier Marc´ıas-Guarasa</author>
<author>Nelson Morgan</author>
<author>Barbara Peskin</author>
<author>Elizabeth Shriberg</author>
<author>Andreas Stolcke</author>
<author>Chuck Wooters</author>
<author>Britta Wrede</author>
</authors>
<title>The ICSI meeting project: Resources and research.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 ICASSP NIST Meeting Recognition Workshop.</booktitle>
<marker>Janin, Ang, Bhagat, Dhillon, Edwards, Marc´ıas-Guarasa, Morgan, Peskin, Shriberg, Stolcke, Wooters, Wrede, 2004</marker>
<rawString>Adam Janin, Jeremy Ang, Sonali Bhagat, Rajdip Dhillon, Jane Edwards, Javier Marc´ıas-Guarasa, Nelson Morgan, Barbara Peskin, Elizabeth Shriberg, Andreas Stolcke, Chuck Wooters, and Britta Wrede. 2004. The ICSI meeting project: Resources and research. In Proceedings of the 2004 ICASSP NIST Meeting Recognition Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Thomas Griffiths</author>
<author>Sharon Goldwater</author>
</authors>
<title>Bayesian inference for PCFGs via Markov chain Monte Carlo.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>139--146</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York,</location>
<contexts>
<context position="5914" citStr="Johnson et al., 2007" startWordPosition="899" endWordPosition="902">d for labeling and segmenting sequences of observations in many different fields—including bioinformatics, ASR, Natural Language Processing (NLP), and information extraction. In particular, Dynamic Bayesian Networks (DBNs) are a popular model for probabilistic sequence modeling because they exploit structure in the problem to compactly represent distributions over multi-state and observation variables. Hidden Markov Models (HMMs), a special case of DBNs, are a classical method for important NLP applications such as unsupervised part-of-speech tagging (Gael et al., 2009) and grammar induction (Johnson et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recognition (Crook et al., 2009) and activity recognition (Bui et al., 2002). Undirected graphical models (UGMs) are also valuable for building probabilistic models for segmenting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov models and HMMs. However, the graphical models used in these applications are mainly non-hierarchical, including those in Bui et al. (2009). Only Sutton et al. (2</context>
</contexts>
<marker>Johnson, Griffiths, Goldwater, 2007</marker>
<rawString>Mark Johnson, Thomas Griffiths, and Sharon Goldwater. 2007. Bayesian inference for PCFGs via Markov chain Monte Carlo. In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, pages 139–146, Rochester, New York, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="6313" citStr="Lafferty et al., 2001" startWordPosition="965" endWordPosition="968">iables. Hidden Markov Models (HMMs), a special case of DBNs, are a classical method for important NLP applications such as unsupervised part-of-speech tagging (Gael et al., 2009) and grammar induction (Johnson et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recognition (Crook et al., 2009) and activity recognition (Bui et al., 2002). Undirected graphical models (UGMs) are also valuable for building probabilistic models for segmenting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov models and HMMs. However, the graphical models used in these applications are mainly non-hierarchical, including those in Bui et al. (2009). Only Sutton et al. (2007) proposed a three-level HGM (in the form of a dynamic CRF) for the joint noun phrase chunking and part of speech labeling problem; they showed that this model performs better than a nonhierarchical counterpart. 3 Data For the experiments reported in this study, we used 17 meetings from the AMI Meeting Corpusl, a freely available corpus of multi-party meetings with both audio and video recordi</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning, pages 282– 289. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iain McCowan</author>
<author>Jean Carletta</author>
<author>W Kraaij</author>
<author>S Ashby</author>
<author>S Bourban</author>
<author>M Flynn</author>
<author>M Guillemot</author>
<author>T Hain</author>
<author>J Kadlec</author>
<author>V Karaiskos</author>
<author>M Kronenthal</author>
<author>G Lathoud</author>
<author>M Lincoln</author>
<author>A Lisowska</author>
<author>W Post</author>
<author>D Reidsma</author>
<author>P Wellner</author>
</authors>
<title>The AMI Meeting Corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of Measuring Behavior, the 5th International Conference on Methods and Techniques in Behavioral Research,</booktitle>
<location>Wageningen, Netherlands.</location>
<contexts>
<context position="2716" citStr="McCowan et al., 2005" startWordPosition="406" endWordPosition="409">marizes previous decision detection experiments using DGMs. Section 5 presents the HGM approach, and section 6 describes our HGM experiments. Finally, section 7 draws conclusions and presents ideas for future work. 2 Related work User studies (Banerjee et al., 2005) have confirmed that meeting participants consider decisions to be one of the most important meeting outputs, and Whittaker et al. (2006) found that the development of an automatic decision detection component is critical for re-using meeting archives. With the new availability of substantial meeting corpora such as the AMI corpus (McCowan et al., 2005), recent years have seen an increasing amount of research on decisionmaking dialogue. This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational participants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been conducted by Hsueh and Moore (2007), Fern´andez et al. (2008), and Bui et al. (2009). Fern´andez et al. (2008) proposed an approach to modeling the structure of decision-making dialogue. These authors designed an annotation scheme that takes accou</context>
</contexts>
<marker>McCowan, Carletta, Kraaij, Ashby, Bourban, Flynn, Guillemot, Hain, Kadlec, Karaiskos, Kronenthal, Lathoud, Lincoln, Lisowska, Post, Reidsma, Wellner, 2005</marker>
<rawString>Iain McCowan, Jean Carletta, W. Kraaij, S. Ashby, S. Bourban, M. Flynn, M. Guillemot, T. Hain, J. Kadlec, V. Karaiskos, M. Kronenthal, G. Lathoud, M. Lincoln, A. Lisowska, W. Post, D. Reidsma, and P. Wellner. 2005. The AMI Meeting Corpus. In Proceedings of Measuring Behavior, the 5th International Conference on Methods and Techniques in Behavioral Research, Wageningen, Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
<author>John Dowding</author>
<author>John Niekrasz</author>
<author>Patrick Ehlen</author>
<author>Sharareh Noorbaloochi</author>
<author>Stanley Peters</author>
</authors>
<title>Detecting and summarizing action items in multi-party dialogue.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Antwerp, Belgium.</location>
<contexts>
<context position="4343" citStr="Purver et al. (2007)" startWordPosition="660" endWordPosition="663"> Papers, pages 307–312, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics they refer to as “hierarchical classification.” Here, one sub-classifier per DDA class hypothesizes occurrences of that type of DDA and then, based on these hypotheses, a super-classifier determines which regions of dialogue are decision discussions. All of the classifiers, (sub and super), were linear kernel binary SVMs. Results were better than those obtained with (Hsueh and Moore, 2007)’s approach—the F1-score for detecting decision discussions in manual transcripts was 0.58 vs. 0.50. Purver et al. (2007) had earlier detected action items with the approach Fern´andez et al. (2008) extended to decisions. Bui et al. (2009) built on the promising results of (Fern´andez et al., 2008), by employing DGMs in place of SVMs. DGMs are attractive because they provide a natural framework for modeling sequence and dependencies between variables, including the DDAs. Bui et al. (2009) were especially interested in whether DGMs better exploit non-lexical features. Fern´andez et al. (2008) obtained much more value from lexical than nonlexical features (and indeed no value at all from prosodic features), but le</context>
</contexts>
<marker>Purver, Dowding, Niekrasz, Ehlen, Noorbaloochi, Peters, 2007</marker>
<rawString>Matthew Purver, John Dowding, John Niekrasz, Patrick Ehlen, Sharareh Noorbaloochi, and Stanley Peters. 2007. Detecting and summarizing action items in multi-party dialogue. In Proceedings of the 8th SIGdial Workshop on Discourse and Dialogue, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
<author>Khashayar Rohanimanesh</author>
</authors>
<title>Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data.</title>
<date>2007</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>8--693</pages>
<contexts>
<context position="6518" citStr="Sutton et al. (2007)" startWordPosition="998" endWordPosition="1001">on et al., 2007) as well as for ASR. More complex DBNs have been used for applications such as DA recognition (Crook et al., 2009) and activity recognition (Bui et al., 2002). Undirected graphical models (UGMs) are also valuable for building probabilistic models for segmenting and labeling sequence data. Conditional Random Fields (CRFs), a simple UGM case, can avoid the label bias problem (Lafferty et al., 2001) and outperform maximum entropy Markov models and HMMs. However, the graphical models used in these applications are mainly non-hierarchical, including those in Bui et al. (2009). Only Sutton et al. (2007) proposed a three-level HGM (in the form of a dynamic CRF) for the joint noun phrase chunking and part of speech labeling problem; they showed that this model performs better than a nonhierarchical counterpart. 3 Data For the experiments reported in this study, we used 17 meetings from the AMI Meeting Corpusl, a freely available corpus of multi-party meetings with both audio and video recordings, and a wide range of annotated information including DAs and topic segmentation. The meetings last around 30 minutes each, and are scenario-driven, wherein four participants play different roles in a c</context>
</contexts>
<marker>Sutton, McCallum, Rohanimanesh, 2007</marker>
<rawString>Charles Sutton, Andrew McCallum, and Khashayar Rohanimanesh. 2007. Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data. Journal of Machine Learning Research, 8:693–723.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Whittaker</author>
<author>Rachel Laban</author>
<author>Simon Tucker</author>
</authors>
<title>Analysing meeting records: An ethnographic study and technological implications.</title>
<date>2006</date>
<booktitle>Machine Learning for Multimodal Interaction: Second International Workshop, MLMI 2005, Revised Selected Papers,</booktitle>
<volume>3869</volume>
<pages>101--113</pages>
<editor>In S. Renals and S. Bengio, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="2498" citStr="Whittaker et al. (2006)" startWordPosition="369" endWordPosition="372">improve their performance at this task compared with nonhierarchical DGMs. We proceed as follows. Section 2 discusses related work, and section 3 our data set and annotation scheme for decision discussions. Section 4 summarizes previous decision detection experiments using DGMs. Section 5 presents the HGM approach, and section 6 describes our HGM experiments. Finally, section 7 draws conclusions and presents ideas for future work. 2 Related work User studies (Banerjee et al., 2005) have confirmed that meeting participants consider decisions to be one of the most important meeting outputs, and Whittaker et al. (2006) found that the development of an automatic decision detection component is critical for re-using meeting archives. With the new availability of substantial meeting corpora such as the AMI corpus (McCowan et al., 2005), recent years have seen an increasing amount of research on decisionmaking dialogue. This research has tackled issues such as the automatic detection of agreement and disagreement (Galley et al., 2004), and of the level of involvement of conversational participants (Gatica-Perez et al., 2005). Recent work on automatic detection of decisions has been conducted by Hsueh and Moore </context>
</contexts>
<marker>Whittaker, Laban, Tucker, 2006</marker>
<rawString>Steve Whittaker, Rachel Laban, and Simon Tucker. 2006. Analysing meeting records: An ethnographic study and technological implications. In S. Renals and S. Bengio, editors, Machine Learning for Multimodal Interaction: Second International Workshop, MLMI 2005, Revised Selected Papers, volume 3869 of Lecture Notes in Computer Science, pages 101– 113. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>