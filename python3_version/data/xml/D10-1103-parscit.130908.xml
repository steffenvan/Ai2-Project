<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<title confidence="0.860634">
Cross Language Text Classification by Model Translation and
Semi-Supervised Learning
</title>
<author confidence="0.886435">
Lei Shi Rada Mihalcea Mingjun Tian
</author>
<affiliation confidence="0.7324095">
Yahoo! Global R&amp;D University of North Texas Yahoo! Global R&amp;D
Beijing, China Denton, TX, U.S.A. Beijing, China
</affiliation>
<email confidence="0.997668">
lshi@yahoo-inc.com rada@cs.unt.edu mingjun@yahoo-inc.com
</email>
<sectionHeader confidence="0.994781" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999733071428571">
In this paper, we introduce a method that au-
tomatically builds text classifiers in a new lan-
guage by training on already labeled data in
another language. Our method transfers the
classification knowledge across languages by
translating the model features and by using
an Expectation Maximization (EM) algorithm
that naturally takes into account the ambigu-
ity associated with the translation of a word.
We further exploit the readily available un-
labeled data in the target language via semi-
supervised learning, and adapt the translated
model to better fit the data distribution of the
target language.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977690909091">
Given the accelerated growth of the number of mul-
tilingual documents on the Web and elsewhere, the
need for effective multilingual and cross-lingual text
processing techniques is becoming increasingly im-
portant. There is a growing number of methods that
use data available in one language to build text pro-
cessing tools for another language, for diverse tasks
such as word sense disambiguation (Ng et al., 2003),
syntactic parsing (Hwa et al., 2005), information re-
trieval (Monz and Dorr, 2005), subjectivity analysis
(Mihalcea et al., 2007), and others.
In this paper, we address the task of cross-lingual
text classification (CLTC), which builds text classi-
fiers for multiple languages by using training data in
one language, thereby avoiding the costly and time-
consuming process of labeling training data for each
individual language. The main idea underlying our
approach to CLTC is that although content can be
expressed in different forms in different languages,
there is a significant amount of knowledge that is
shared for similar topics that can be effectively used
to port topic classifiers across languages.
Previous methods for CLTC relied mainly on ma-
chine translation, by translating the training data into
the language of the test data or vice versa, so that
both training and test data belong to the same lan-
guage. Monolingual text classification algorithms
can then be applied on these translated data. Al-
though intuitive, these methods suffer from two ma-
jor drawbacks.
First, most off-the-shelf machine translation sys-
tems typically generate only their best translation for
a given text. Since machine translation is known
to be a notoriously hard problem, applying mono-
lingual text classification algorithms directly on the
erroneous translation of training or test data may
severely deteriorate the classification accuracy.
Second, similar to domain adaptation in statisti-
cal machine learning, due to the discrepancy of data
distribution between the training domain and test do-
main, data distribution across languages may vary
because of the difference of culture, people’s inter-
ests, linguistic expression in different language re-
gions. So even if the translation of training or test
data is perfectly correct, the cross language classi-
fier may not perform as well as the monolingual one
trained and tested on the data from the same lan-
guage.
In this paper, we propose a new approach to
CLTC, which trains a classification model in the
source language and ports the model to the target
language, with the translation knowledge learned us-
ing the EM algorithm. Unlike previous methods
based on machine translation (Fortuna and Shawe-
Taylor, 2005), our method takes into account dif-
</bodyText>
<page confidence="0.962431">
1057
</page>
<note confidence="0.8168735">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1057–1067,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999926555555555">
ferent possible translations for model features. The
translated model serves as an initial classifier for a
semi-supervised process, by which the model is fur-
ther adjusted to fit the distribution of the target lan-
guage. Our method does not require any labeled
data in the target language, nor a machine transla-
tion system. Instead, the only requirement is a rea-
sonable amount of unlabeled data in the target lan-
guage, which is often easy to obtain.
In the following sections, we first review related
work. In section 3, we introduce our method that
translates the classification model with the trans-
lation knowledge learned using the EM algorithm.
Section 4 describes model adaptation by training the
translated model with unlabeled documents in the
target language. Experiments and evaluations are
presented in section 5 and finally we conclude the
paper in section 6.
</bodyText>
<sectionHeader confidence="0.999832" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.985310946666666">
Text classification has rightfully received a lot of at-
tention from both the academic and industry com-
munities, being one of the areas in natural language
processing that has a very large number of practi-
cal applications. Text classification techniques have
been applied to many diverse problems, ranging
from topic classification (Joachims, 1997), to genre
detection (Argamon et al., 1998), opinion identifica-
tion (Pang and Lee, 2004), spam detection (Sahami
et al., 1998), gender and age classification (Schler et
al., 2006).
Text classification is typically formulated as a
learning task, where a classifier learns how to distin-
guish between categories in a given set, using fea-
tures automatically extracted from a collection of
documents. In addition to the learning methodol-
ogy itself, the accuracy of the text classifier also de-
pends to a large extent upon the amount of training
data available at hand. For instance, distinguish-
ing between two categories for which thousands of
manually annotated examples are already available
is expected to perform better than trying to separate
categories that have only a handful of labeled docu-
ments.
Some of the most successful approaches to date
for text classification involve the use of machine
learning methods, which assume that enough an-
notated data is available such that a classification
model can be automatically learned. These include
algorithms such as Naive Bayes (Joachims, 1997;
McCallum and Nigam, 1998), Rocchio classifiers
(Joachims, 1997; Moschitti, 2003), Maximum En-
tropy (Nigam et al., 1999) or Support Vector Ma-
chines (Vapnik, 1995; Joachims, 1998). If only
a small amount of annotated data is available, the
alternative is to use semi-supervised bootstrapping
methods such as co-training or self-training, which
can also integrate raw unlabeled data into the learn-
ing model (Blum and Mitchell, 1998; Nigam and
Ghani, 2000).
Despite the attention that monolingual text clas-
sification has received from the research commu-
nity, there is only very little work that was done
on cross-lingual text classification. The work that
is most closely related to ours is (Gliozzo and Strap-
parava, 2006), where a multilingual domain kernel is
learned from comparable corpora, and subsequently
used for the cross-lingual classification of texts. In
experiments run on Italian and English, Gliozzo and
Strapparava showed that the multilingual domain
kernel exceeds by a large margin a bag-of-words ap-
proach. Moreover, they demonstrated that the use
of a bilingual dictionary can drastically improve the
performance of the models learned from corpora.
(Fortuna and Shawe-Taylor, 2005; Olsson et al.,
2005) studied the use of machine translation tools
for the purpose of cross language text classification
and mining. These approaches typically translate
the training data or test data into the same language,
followed by the application of a monolingual classi-
fier. The performance of such classifiers very much
depends on the quality of the machine translation
tools. Unfortunately, the development of statistical
machine translation systems (Brown et al., 1993) is
hindered by the lack of availability of parallel cor-
pora and the quality of their output is often erro-
neous. Several methods were proposed (Shi et al.,
2006; Nie et al., 1999) to automatically acquire a
large quantity of parallel sentences from the web,
but such web data is however predominantly con-
fined to a limited number of domains and language
pairs.
(Dai et al., 2007) experimented with the use of
transfer learning for text classification. Although in
this method the transfer learning is performed across
</bodyText>
<page confidence="0.99393">
1058
</page>
<bodyText confidence="0.999927275862069">
different domains in the same language, the under-
lying principle is similar to CLTC in the sense that
different domains or languages may share a signif-
icant amount of knowledge in similar classification
tasks. (Blum and Mitchell, 1998) employed semi-
supervised learning for training text classifiers. This
method bootstraps text classifiers with only unla-
beled data or a small amount of labeled training data,
which is close to our setting that tries to leverage la-
beled data and unlabeled data in different languages
to build text classifiers.
Finally, also closely related is the work carried out
in the field of sentiment and subjectivity analysis
for cross-lingual classification of opinions. For in-
stance, (Mihalcea et al., 2007) use an English corpus
annotated for subjectivity along with parallel text to
build a subjectivity classifier for Romanian. Sim-
ilarly, (Banea et al., 2008) propose a method based
on machine translation to generate parallel texts, fol-
lowed by a cross-lingual projection of subjectivity
labels, which are used to train subjectivity annota-
tion tools for Romanian and Spanish. A related, yet
more sophisticated technique is proposed in (Wan,
2009), where a co-training approach is used to lever-
age resources from both a source and a target lan-
guage. The technique is tested on the automatic sen-
timent classification of product reviews in Chinese,
and showed to successfully make use of both cross-
language and within-language knowledge.
</bodyText>
<sectionHeader confidence="0.979597" genericHeader="method">
3 Cross Language Model Translation
</sectionHeader>
<bodyText confidence="0.999961766666667">
To make the classifier applicable to documents in
a foreign language, we introduce a method where
model features that are learned from the training
data are translated from the source language into
the target language. Using this translation process,
a feature associated with a word in the source lan-
guage is transferred to a word in the target language
so that the feature is triggered when the word occurs
in the target language test document.
In a typical translation process, the features would
be translated by making use of a bilingual dictio-
nary. However, this translation method has a major
drawback, due to the ambiguity usually associated
with the entries in a bilingual dictionary: a word in
one language can have multiple translations in an-
other language, with possibly disparate meanings.
If an incorrect translation is selected, it can distort
the classification accuracy, by introducing erroneous
features into the learning model. Therefore, our goal
is to minimize the distortion during the model trans-
lation process, in order to maximize the classifica-
tion accuracy in the target language.
In this paper, we introduce a method that em-
ploys the EM algorithm to automatically learn fea-
ture translation probabilities from labeled text in the
source language and unlabeled text in the target lan-
guage. Using the feature translation probabilities,
we can derive a classification model for the target
language from a mixture model with feature transla-
tions.
</bodyText>
<subsectionHeader confidence="0.9672215">
3.1 Learning Feature Translation Probabilities
with EM Algorithm
</subsectionHeader>
<bodyText confidence="0.99997275">
Given a document d from the document collection D
in the target language, the probability of generating
the document P(d) is the mixture of generating d
with different classes c ∈ C:
</bodyText>
<equation confidence="0.993442">
P (d) = ∑ P(d|c)P(c)
c
</equation>
<bodyText confidence="0.999965727272727">
In our cross-lingual setting, we view the generation
of d given a class c as a two step process. In the
first step, a pseudo-document d′ is generated in the
source language, followed by a second step, where
d′ is translated into the observed document d in the
target language. In this generative model, d′ is a la-
tent variable that cannot be directly observed. Since
d could have multiple translations d′ in the source
language, the probability of generating d can then
be reformulated as a mixture of probabilities as in
the following equation.
</bodyText>
<equation confidence="0.99089">
P(d) = ∑ P(c) ∑ P(d|d′, c)P(d′|c)
c d′
</equation>
<bodyText confidence="0.998254166666667">
According to the bag-of-words assumption,
the document translation probability P(d|d′, c) is
the product of the word translation probabilities
P(wZ|w′Z, c) , where w′ Z in d′ is the source language
word that wZ is translated from. P(d′|c) is the prod-
uct of P(w′Z|c). The formula is rewritten as:
</bodyText>
<equation confidence="0.973266">
P (d) = ∑ P(c) ∑ ∏l P(wZ|w′Z, c)P(w′Z|c)
c d′ Z=1
</equation>
<page confidence="0.918663">
1059
</page>
<bodyText confidence="0.993940470588235">
where wi is the ith word of the document d with l
words. The prior probability P(c) and the proba-
bility of the source language word w′ given class c
are estimated using the labeled training data in the
source language, so we use them as known parame-
ters. P(wi|w′i, c) is the probability of translating the
word w′ i in the source language to the word wi in
the target language given class c, and these are the
parameters we want to learn from the corpus in the
target language.
Using the Maximum Likelihood Estimation
(MLE) framework, we learn the model parameters θ
– the translation probability P(wi|w′i, c) – by max-
imizing the log likelihood of a collection of docu-
ments in the target language:
Algorithm 1 EM algorithm for learning translation
probabilities
</bodyText>
<equation confidence="0.697518833333333">
Dl ← labeled data in the source language
Du ← unlabeled data in the target language
L ← bilingual lexicon
1: Initialize P0(w|w′c) = n1 , where (w, w′) ∈ L,
w
otherwise P0(w|w′c) = 0;
</equation>
<listItem confidence="0.9616741">
2: Compute P(w′c) with Dl according to equa-
tion 3
3: repeat
4: Calculate Pt(w′c|w) with Du based on
Pt−1(w|w′c) according to equation 1
5: Calculate Pt(w|w′c) based on Pt−1(w′c|w)
according to equation 2
6: until change of P(w|w′c) is smaller than the
threshold
7: return P(w|w′c)
</listItem>
<equation confidence="0.990189">
b ∑m log(P(dj, θ))
θ = argmaxθ j=1
= argmaxθ ∑m log( ∑ P(c) ∑
j=1 c d′
∏l� P(wi|w′i, c)P(w′i|c))
i=1
</equation>
<bodyText confidence="0.999990727272727">
where m is the number of documents in the corpus
in the target language and lj is the number of words
in the document dj.
In order to estimate the optimal values of the pa-
rameters, we use the EM algorithm (Dempster et al.,
1977). At each iteration of EM we determine those
values by maximizing the expectation using the pa-
rameters from the previous iteration and this itera-
tive process stops when the change in the parameters
is smaller than a given threshold. We can repeat the
following two steps for the purpose above.
</bodyText>
<listItem confidence="0.897267">
• E-step
</listItem>
<equation confidence="0.939243375">
P(cw′w)
P(w′c|w) ←
P (w)
P(w|w′c)P(w′c) =∑ ∑w′ P(w|w′c)P(w′c) (1)
c
• M-step
P(w|w′c) ← f(w)P(w′c|w) (2)
∑w∈K f (w)P(w′c|w)
</equation>
<bodyText confidence="0.999120444444444">
Here f(w) is the occurrence frequency of the word
w in the corpus. K is the set of translation candi-
dates in the target language for the source language
word w′ according to the bilingual lexicon. P(w’c) is
the probability of occurrence of the source language
word w′ under the class c. It can be estimated from
the labeled source language training data available
as follows and it is regarded as a known parameter
of the model.
</bodyText>
<equation confidence="0.997706">
P (w′c) =f(w′c)
∑ (3)
w′∈V f(w′c)
</equation>
<bodyText confidence="0.999981">
where V is the vocabulary of the source language.
Algorithm 1 illustrates the EM learning process,
where nw′ denotes the number of translation candi-
dates for w′ according to the bilingual lexicon.
Our method requires no labeled training data
in the target language. Many statistical machine
translation systems such as IBM models (Brown
et al., 1993) learn word translation probabilities
from millions of parallel sentences which are mu-
tual translations. However, large scale parallel cor-
pora rarely exist for most language pairs. (Koehn
and Knight, 2000) proposed to use the EM algo-
rithm to learn word translation probabilities from
non-parallel monolingual corpora. However, this
method estimates only class independent transla-
tion probabilities P(wi|w′i), while our approach is
able to learn class specific translation probabilities
</bodyText>
<page confidence="0.920953">
1060
</page>
<bodyText confidence="0.9988152">
P(wi|w′i, c) by leveraging available labeled training
data in the source language. For example, the prob-
ability of translating “bush” as “树丛” (small trees)
is higher than translating as “Tji什” (U.S. president)
when the category of the text is “botany.”
</bodyText>
<subsectionHeader confidence="0.999873">
3.2 Model Translation
</subsectionHeader>
<bodyText confidence="0.999301923076923">
In order to classify documents in the target language,
a straightforward approach to transferring the classi-
fication model learned from the labeled source lan-
guage training data is to translate each feature from
the bag-of-words model according to the bilingual
lexicon. However, because of the translation ambi-
guity of each word, a model in the source language
could be potentially translated into many different
models in the target language. Thus, we think of
the probability of the class of a target language doc-
ument as the mixture of the probabilities by each
translated model from the source language model,
weighed by their translation probabilities.
</bodyText>
<equation confidence="0.997304">
P(c|d, mt) ≈ ∑ t|ms, c)P(c|d, m′
m′ t P(m′ t)
</equation>
<bodyText confidence="0.9999868125">
where mt is the target language classification model
and m′t is a candidate model translated from the
model ms trained on the labeled training data in
the source language. This is a very generic rep-
resentation for model translation and the model m
could be any type of text classification. Specifically
in this paper, we take the Maximum Entropy (ME)
model(Berger et al., 1996) as an example for the
model translation across languages, since the ME
model is one of the most widely used text classifica-
tion models. The maximum entropy classifier takes
the form
is invariant to c and hence we can omit it for classi-
fication since our objective is to find the best c. Ac-
cording to the formulation of the Maximum Entropy
model, the document can be classified as follows.
</bodyText>
<equation confidence="0.876918">
∑bc = argmaxc∈C
m′t
</equation>
<bodyText confidence="0.9785838">
The model translation probability P(m′t|ms, c) can
be modeled as the product of the translation proba-
bilities of each of its individual bag-of-words fea-
tures P(m′t|ms, c) ≈ ∏li=1 P(wit|wis, c) and the
classification model can be further written as
</bodyText>
<equation confidence="0.9990815">
P(wit,c)
t|wi s, c)eλwisf(wi
</equation>
<bodyText confidence="0.999977416666667">
where feature translation probabilities P(wit|wis, c)
are estimated with the EM algorithm described in
the previous section. Note that if the average number
of translations for a word w is n and v is the num-
ber of words in the vocabulary there are nv possible
models m′t translated from ms. However, we can
do the following mathematical transformation on the
equation which leads to a polynomial time complex-
ity algorithm. The idea is that instead of enumerat-
ing the exponential number of different translations
of the entire model, we will instead handle one fea-
ture at a time.
</bodyText>
<equation confidence="0.9857725">
P(wit|wis,c)eλwisf(wit,c) =
P(m′t|ms, c) ∏v eλwisf(wi t,c)
i=1
∑bc = argmaxc∈C ∏v
m′t i=1
∏v
i=1
∑
m′t
1 ∏ eλwf(w,c) ∑n1 t ,c) ∑ v P(wit|wis, c)eλif(wit,c)
P(c|d) = Z(d) w∈V j=1 P(w1j ∏
t |w1 s,c)eλ1f(w1j i=2
2,v
mt
</equation>
<bodyText confidence="0.998065923076923">
where: V is the vocabulary of the language; f(w, c)
is the feature function associated with the word w
and class c and its value is set to 1 when w occurs in
d and the class is c or otherwise 0. λw is the feature
weight for f(wi, c) indicating the importance of the
feature in the model. During model translation, the
feature weight for f(wi, c) is transferred to f(w′i, c)
in the target language model, where w′i is the trans-
lation of wi. Z(d) is the normalization factor which
Here w1 is the first word in the vocabulary of the
source language and w1j is a translation of w1 in the
target language with n denoting the number its trans-
lations according to the bilingual lexicon. ∑m2,v
</bodyText>
<equation confidence="0.586004">
t
</equation>
<bodyText confidence="0.9960256">
are all the target language models translated from
the model consisting of the rest of the words w2 ...
wv in the source language. This process is recur-
sive until the last word wvs of the vocabulary and this
transforms the equation into a polynomial form as
</bodyText>
<page confidence="0.898873">
1061
</page>
<bodyText confidence="0.828438">
follows. Algorithm 2 Semi-supervised learning for cross-
</bodyText>
<equation confidence="0.9952835">
P(wit,c)
t|wi s, c)eλwisf(wi
P (wij t ,c)
t |wi s, c)eλwisf(wij
</equation>
<bodyText confidence="0.99916">
Based on the above transformation, the class bc for
the target language document d is then calculated
with the following equation.
</bodyText>
<equation confidence="0.7868145">
P (wij t ,c)
t |wi s, c)eλwisf(wij
</equation>
<bodyText confidence="0.9819325">
The time complexity of computing the above equa-
tion is n × v.
</bodyText>
<sectionHeader confidence="0.982165" genericHeader="method">
4 Model Adaptation with Semi-
</sectionHeader>
<subsectionHeader confidence="0.963249">
Supervised Learning
</subsectionHeader>
<bodyText confidence="0.994675393939394">
In addition to translation ambiguity, another chal-
lenge in building a classifier using training data in
a foreign language is the discrepancy of data distri-
bution in different languages. Direct application of a
classifier translated from a foreign model may not fit
well the distribution of the current language. For ex-
ample, a text about “sports” in (American) English
may talk about “American football,” “baseball,” and
“basketball,” whereas Chinese tend to discuss about
“soccer” or “table tennis.”
To alleviate this problem, we employ semi-
supervised learning in order to adapt the model to
the target language. Specifically, we first start by us-
ing the translated classifier from English as an initial
classifier to label a set of Chinese documents. The
initial classifier is able to correctly classify a num-
ber of unlabeled Chinese documents with the knowl-
edge transferred from English training data. For
instance, words like “game(EL ),” “score(EL3�) ,”
“athlete(LzA learned from English can still ef-
fectively classify Chinese documents. We then pick
a set of labeled Chinese documents with high con-
fidence to train a new Chinese classifier. The new
classifier can then learn new knowledge from these
Chinese documents. E.g. it can discover that words
like “soccer(X4)” or “badminton( ` -T--4)” occur
frequently in the Chinese “sports” documents, while
words that are frequently occurring in English doc-
uments such as “superbowl(ONA)” and “NHL(�
lingual text classification
Ls ← labeled data in the source language
Ut ← unlabeled data in the target lan-
guage
</bodyText>
<listItem confidence="0.997874125">
1: Cs = train(Ls)
2: Ct = translate(Cs)
3: repeat
4: Label(U, Ct)
5: L ← select(confidence(U, Ct))
6: Ct ← train(L)
7: until stopping criterion is met
8: return Ct
</listItem>
<bodyText confidence="0.998698230769231">
XP4RO)” do not occur as often. Re-training the
classifier with the Chinese documents can adjust the
feature weights for these words so that the model fits
better the data distribution of Chinese documents,
and thus it improves the classification accuracy. The
new classifier then re-labels the Chinese documents
and the process is repeated for several iterations. Al-
gorithm 2 illustrates this semi-supervised learning
process.
The confidence score associated with the docu-
ments is calculated based on the probabilities of the
class. For a binary classifier the confidence of clas-
sifying the document d is calculated as:
</bodyText>
<equation confidence="0.9905575">
��log(P(c|d) ����
confidence(d) = ��P(c|d))
</equation>
<bodyText confidence="0.999884666666667">
An unlabeled document is selected as training
data for a new classifier when its confidence score
is above a threshold.
</bodyText>
<sectionHeader confidence="0.995656" genericHeader="method">
5 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.999904666666667">
To evaluate the effectiveness of our method, we
carry out several experiments. First, we compare the
performance of our method on five different cate-
gories, from five different domains, in order to see
its generality and applicability on different domains.
We also run experiments with two different language
pairs - English-Chinese and English-French - to see
if the distance between language families influences
the effectiveness of our method.
To determine the performance of the method with
respect to other approaches, we compare the classi-
fication accuracy with that of a machine translation
</bodyText>
<figure confidence="0.549819933333333">
∏v
i=1
∑
m′t
=
∏v
i=1
∑ni
j=1
b
∏v
i=1
c = argmaxc∈C
∑ni
j=1
</figure>
<page confidence="0.956397">
1062
</page>
<bodyText confidence="0.999978818181818">
approach that translates the training (test) data from
the source language to the target language, as well
as with a classifier trained on monolingual training
data in the target language.
Finally, we evaluate the performance of each of
the two steps of our proposed method. First, we
evaluate the model translated with the parameters
learned with EM, and then the model after the semi-
supervised learning for data distribution adaptation
with different parameters, including the number of
iterations and different amounts of unlabeled data.
</bodyText>
<subsectionHeader confidence="0.997159">
5.1 Data Set
</subsectionHeader>
<bodyText confidence="0.999988222222222">
Since a standard evaluation benchmark for cross-
lingual text classification is not available, we built
our own data set from Yahoo! RSS news feeds. The
news feed contains news articles from October 1st
2009 to December 31st 2009. We collected a total
of 615731 news articles, categorized by their edi-
tors into topics such as “sports” or “business”. We
selected five categories for our experiments, namely
“sports”, “health”, “business”, “entertainment”, “ed-
ucation”. The Yahoo! RSS news feed includes
news in many languages, including English, Chi-
nese, French, Spanish, and others.
We experimented on two language pairs, English-
Chinese and English-French, selected for their diver-
sity: English and Chinese are disparate languages
with very little common vocabulary and syntax,
whereas English and French are regarded as more
similar. We expect to evaluate the impact of the
distance of languages on the effectiveness of our
method. In both cases, English is regarded as the
source language, where training data are available,
and Chinese and French are the target languages
for which we want to build text classifiers. Note
that regardless of the language, the documents are
assigned with one of the five category labels men-
tioned above. Table 1 shows the distribution of doc-
uments across categories and across languages.
</bodyText>
<table confidence="0.997185333333333">
Category English Chinese French
sports 23764 14674 18398
health 15627 11769 12745
business 34619 23692 28740
entertainment 26876 21470 23756
education 16488 14353 15753
</table>
<tableCaption confidence="0.999869">
Table 1: number of documents in each class
</tableCaption>
<bodyText confidence="0.9988743">
Before building the classification model, several
preprocessing steps are applied an all the docu-
ments. First, the HTML tags are removed, and ad-
vertisements and navigational information are also
eliminated. For the Chinese corpus, all the Chinese
characters with BIG5 encoding are converted into
GB2312 and the Chinese texts are segmented into
words. For the translation, we use the LDC bilin-
gual dictionary1 for Chinese English and “stardict”
2 for Spanish English.
</bodyText>
<subsectionHeader confidence="0.999661">
5.2 Model Translation
</subsectionHeader>
<bodyText confidence="0.999961529411765">
To transfer a model learned in one language to an-
other, we can translate all the bag-of-word features
according to a bilingual lexicon. Due to the trans-
lation ambiguity of each feature word, we com-
pare three different ways of model translation. One
method is to equally assign probabilities to all the
translations for a given source language word, and
to translate a word we randomly pick a translation
from all of its translation candidates. We denote this
as “EQUAL” and it is our baseline method. Another
way is to calculate the translation probability based
on the frequencies of the translation words in the tar-
get language itself. For instance, the English word
“bush” can be translated into “Ti ff” , “4 ” or “*
T” . We can obtain the following unigram counts
of these translation words in our Yahoo! RSS news
corpus.
</bodyText>
<subsectionHeader confidence="0.508752">
count translation sense
</subsectionHeader>
<bodyText confidence="0.229239">
582 ;6i* Goerge W. Bush
43 OfA small trees
</bodyText>
<sectionHeader confidence="0.440858" genericHeader="method">
2 ItIft canula
</sectionHeader>
<bodyText confidence="0.9975719">
We can estimate that P(Ti ff|bush) = 582/(582 +
43+2) = 92.8% and so forth. This method often al-
lows us to estimate reasonable translation probabili-
ties and we use “UNIGRAM” to denote this method.
And finally the third model translation approach is
to use the translation probability learned with the
EM algorithm proposed in this paper. The initial
parameters of the EM algorithm are set to the prob-
abilities calculated with the “UNIGRAM” method
and we use 4000 unlabeled documents in Chinese
</bodyText>
<footnote confidence="0.896012666666667">
lhttp://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?
catalogId=LDC2002L27
zhttp://stardict.sourceforge.net/Dictionaries.php
</footnote>
<page confidence="0.942785">
1063
</page>
<bodyText confidence="0.999885714285714">
to learn translation probabilities with EM. We first
train an English classification model for the topic of
“sport” and then translate the model into Chinese us-
ing translation probabilities estimated by the above
three different methods. The three translated models
are applied to Chinese test data and we measure the
precision, recall and F-score as shown in Table 2.
</bodyText>
<table confidence="0.99981825">
Method P R F
EQUAL 71.1 70.6 70.8
UNIGRAM 79.5 77.8 78.6
EM 83.1 84.7 83.9
</table>
<tableCaption confidence="0.9786405">
Table 2: Comparison of different methods for model
translation
</tableCaption>
<bodyText confidence="0.99994605">
From this table we can see that the baseline method
has lowest classification accuracy due to the fact that
it is unable to handle translation ambiguity since
picking any one of the translation word is equally
likely. “UNIGRAM” shows significant improve-
ment over “EQUAL” as the occurrence count of the
translation words in the target language can help
disambiguate the translations. However occurrence
count in a monolingual corpus may not always be
the true translation probability. For instance, the
English word “work” can be translated into “工
作(labor)” and “工厂(factory)” in Chinese. How-
ever, in our Chinese monolingual news corpus, the
count for “工厂(factory)” is more than that of “工
作(labor)” even though “工作(labor)” should be a
more likely translation for “work”. The “EM” algo-
rithm has the best performance as it is able to learn
translation probabilities by looking at documents in
both source language and target language instead of
just a single language corpus.
</bodyText>
<subsectionHeader confidence="0.999633">
5.3 Cross Language Text Classification
</subsectionHeader>
<bodyText confidence="0.998926">
To evaluate the effectiveness of our method on cross
language text classification, we implement several
methods for comparison. In each experiment, we
run a separate classification for each class, using a
one-versus-all binary classification.
ML (Monolingual). We build a monolingual
text classifier by training and testing the text classi-
fication system on documents in the same language.
This method plays the role of an upper-bound, since
the best classification results are expected when
monolingual training data is available.
MT (Machine Translation). We use the Sys-
tran 5.0 machine translation system to translate
the documents from one language into the other
in two directions. The first direction translates the
training data from the source language into the
target language, and then trains a model in the target
language. This direction is denoted as MTS. The
second direction trains a classifier in the source
language and translates the test data into the source
language. This direction is denoted as MTT. In
our experiments, Systran generates the single best
translation of the text as most off-the-shelf machine
translation tools do.
EM (Model Translation with EM). This is the
first step of our proposed method. We used 4,000
unlabeled documents to learn translation proba-
bilities with the EM algorithm and the translation
probabilities are leveraged to translate the model.
The rest of the unlabeled documents are used for
other experimental purpose.
SEMI (Adapted Model after Semi-Supervised
Learning). This is our proposed method, after both
model translation and semi-supervised learning.
In the semi-supervised learning, we use 6,000
unlabeled target language documents with three
training iterations.
In each experiment, the data consists of 4,000 la-
beled documents and 1,000 test documents (e.g., in
the cross-lingual experiments, we use 4,000 English
annotated documents and 1,000 Chinese or French
test documents). For a given language, the same test
data is used across all experiments.
Table 3 shows the performance of the various
classification methods. The ML (Monolingual)
classifier has the best performance, as it is trained
on labeled data in the target language, so that there
is no information loss and no distribution discrep-
ancy due to a model translation. The MT (ma-
chine translation) based approach scores the lowest
accuracy, probably because the machine translation
software produces only its best translation, which
is often error-prone, thus leading to poor classifi-
cation accuracy. In addition, the direct application
of a classification model from one language to an-
</bodyText>
<page confidence="0.946267">
1064
</page>
<table confidence="0.999833428571429">
Category English --+ Chinese
ML MTS MTT EM SEMI
P R F P R F P R F P R F P R F
sports 96.1 94.3 95.2 80.6 81.7 81.2 81.7 83.8 82.7 83.1 84.7 83.9 92.1 91.8 91.9
health 95.1 93.1 94.1 80.8 81.5 81.2 81.6 83.5 82.6 84.5 85.8 85.2 90.2 91.7 90.9
business 91.6 93.1 92.4 81.3 81.9 81.6 80.7 81.0 80.9 81.6 82.0 81.8 87.3 89.3 88.3
entertainment 88.1 88.3 88.2 76.1 78.8 77.5 75.3 78.9 77.1 76.8 79.7 78.2 83.2 83.8 83.5
education 79.1 82.2 80.6 70.2 72.5 71.8 71.1 72.0 71.6 71.2 73.7 72.5 76.2 79.8 78.0
English --+ French
sports 95.8 95.0 95.4 82.8 83.6 83.2 82.1 83.0 82.5 85.3 87.1 86.2 92.5 92.1 92.3
health 94.2 94.5 94.3 82.6 83.9 83.2 81.8 83.0 82.4 86.2 87.2 86.6 92.0 92.2 92.1
business 90.1 92.2 91.1 81.4 82.1 81.7 81.3 81.8 81.8 84.4 84.3 84.4 88.3 89.2 88.8
entertainment 87.4 87.2 87.3 76.6 79.1 77.8 76.0 78.8 77.4 78.9 81.0 80.0 84.3 85.5 84.9
education 78.8 81.8 80.3 72.1 74.8 73.5 72.3 72.7 72.5 73.8 76.2 75.0 76.3 80.1 78.2
</table>
<tableCaption confidence="0.999975">
Table 3: Comparison of different methods and different language pairs
</tableCaption>
<bodyText confidence="0.999881536585366">
other does not adapt to the distribution of the sec-
ond language, even if the documents belong to the
same domain. Comparing the two MT alternatives,
we can see that translating the training data (MTS)
has better performance than translating the test data
(MTT). The reason is that when the model is trained
on the translated training data, the model parame-
ters are learned over an entire collection of translated
documents, which is less sensitive to translation er-
rors than translating a test document on which the
classification is performed individually.
Our EM method for translating model features
outperforms the machine translation approach, since
it does not only rely on the best translation by the
machine translation system, but instead takes into
account all possible translations with knowledge
learned specifically from the target language. Ad-
ditionally, the SEMI (semi-supervised) learning is
shown to further improve the classification accuracy.
The semi-supervised learning is able to not only help
adapt the translated model to fit the words distribu-
tion in the target language, but it also compensates
the distortion or information loss during the model
translation process as it can down-weigh the incor-
rectly translated features.
The improvement in performance for both the
EM and the SEMI methods is consistent across
the five different domains, which indicates that the
methods are robust and they are insensitive to the
domain of the data.
The performance of the two language pairs
English-Chinese and English-French shows a dif-
ference as initially hypothesized. In both the EM
and the SEMI models, the classification accuracy
of English-French exceeds that of English-Chinese,
which is probably explained by the fact that there is
less translation ambiguity in similar languages, and
they have more similar distributions. Note that the
monolingual models in French and Chinese perform
comparably, which means the difficulty of the test
data is similar between the two target languages.
</bodyText>
<subsectionHeader confidence="0.9558285">
5.4 Model Adaptation with Semi-Supervised
Learning
</subsectionHeader>
<bodyText confidence="0.999987636363636">
Finally, to gain further insights into our proposed
adaptation method, we run several experiments with
different parameters for the semi-supervised learn-
ing stage. As these experiments are very time con-
suming, we run them only on Chinese.
For each of the five categories, we train a classi-
fication model using the 4,000 training documents
in English and then translate the model into Chinese
with the translation parameters learned with EM on
20,000 unlabeled Chinese documents. Then we fur-
ther train the translated model on a set of unlabeled
Chinese documents using a different number of it-
erations and a different amount of unlabeled docu-
ments. Figures 1 and 2 show the results of these
evaluations.
As the plots show, the use of unlabeled data in
the target language can improve the cross-language
classification by learning new knowledge in the
target language. Larger amounts of unlabeled
data in general help, although the marginal bene-
fit drops with increasing amounts of data. Regard-
ing the number of iterations, the best performance is
</bodyText>
<page confidence="0.929612">
1065
</page>
<figure confidence="0.980645692307692">
Classification F-score
95
90
85
80
75
70
sports
health
business
entertainment
education
tion.
</figure>
<sectionHeader confidence="0.985923" genericHeader="evaluation">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.996426285714286">
The work of the second author has been partially
supported by National Science Foundation awards
#0917170 and #0747340. Any opinions, findings,
and conclusions or recommendations expressed in
this material are those of the authors and do not
necessarily reflect the views of the National Science
Foundation.
</bodyText>
<figure confidence="0.9935125">
0 1000 2000 3000 4000 5000 6000
Size of unlabeled data
</figure>
<figureCaption confidence="0.996701">
Figure 1: Change in classification F-score for an increas-
ing amount of unlabeled data in the target language
</figureCaption>
<figure confidence="0.9905685">
0 1 2 3 4 5 6
Number of iterations
</figure>
<figureCaption confidence="0.992268">
Figure 2: Change in classification F-score for a different
number of iterations
</figureCaption>
<bodyText confidence="0.942795">
achieved after 3-4 iterations.
</bodyText>
<sectionHeader confidence="0.999607" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999941692307692">
In this paper, we proposed a novel method for cross-
lingual text classification. Our method ports a clas-
sification model trained in a source language to a tar-
get language, with the translation knowledge being
learned using the EM algorithm. The model is fur-
ther tuned to fit the distribution in the target language
via semi-supervised learning. Experiments on dif-
ferent datasets covering different languages and dif-
ferent domains show significant improvement over
previous methods that rely on machine translation.
Moreover, the cross-lingual classification accuracy
obtained with our method was found to be close to
the one achieved using monolingual text classifica-
</bodyText>
<sectionHeader confidence="0.997855" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999855684210526">
S. Argamon, M. Koppel, and G. Avneri. 1998. Style-
based text categorization: What newspaper am i read-
ing? In AAAI-98 Workshop on Learning for Text Cat-
egorization, Madison.
C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan. 2008.
Multilingual subjectivity analysis using machine trans-
lation. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing (EMNLP
2008), Honolulu, Hawaii.
A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A
maximum entropy approach to natural language pro-
cessing. Computational Linguistics, 22(1):39–71.
A. Blum and T. Mitchell. 1998. Combining labeled and
unlabeled data with co-training. In COLT: Proceed-
ings of the Workshop on Computational Learning The-
ory, Morgan Kaufmann Publishers, June.
P. Brown, S. della Pietra, V. della Pietra, and R. Mercer.
1993. The mathematics of statistical machine trans-
lation: parameter estimation. Computational Linguis-
tics, 19(2).
W. Dai, G. Xue, Q. Yang, and Y. Yu. 2007. Transfer-
ring naive bayes classifiers for text classification. In In
Proceedings of the 22nd AAAI Conference on Artificial
Intell igence, pages 540–545.
A.P. Dempster, N.M. Laird, and D.B. Rubin. 1977. Max-
imum likelihood from incomplete data via the em al-
gorithm. Journal of the Royal Statistical Society. Se-
ries B (Methodological), 39(1).
B. Fortuna and J. Shawe-Taylor. 2005. The use of
machine translation tools for cross-lingual text min-
ing. In Learning With Multiple Views, Workshop at
the 22nd International Conference on Machine Learn-
ing (ICML).
A. Gliozzo and C. Strapparava. 2006. Exploiting com-
parable corpora and bilingual dictionaries for cross-
language text categorization. In Proceedings of the
Conference of the Association for Computational Lin-
guistics, Sydney, Australia.
</reference>
<figure confidence="0.997810333333333">
Classification F-score
95
90
85
80
75
70
sports
health
business
entertainment
education
</figure>
<page confidence="0.928673">
1066
</page>
<reference confidence="0.999902792682927">
R. Hwa, P. Resnik, and A. Weinberg. 2005. Bootstrap-
ping parsers via syntactic projection across parallel
texts. Natural Language Engineering. Special issue
on Parallel Texts, editors R. Mihalcea and M. Simard.
T. Joachims. 1997. A probabilistic analysis of the Roc-
chio algorithm with TFIDF for text categorization. In
Proceedings of ICML-97, 14th International Confer-
ence on Machine Learning, Nashville, US.
T. Joachims. 1998. Text categorization with Support
Vector Machines: learning with mny relevant features.
In Proceedings of the European Conference on Ma-
chine Learning, pages 137–142.
P. Koehn and K. Knight. 2000. Estimating word transla-
tion probabilities from unrelated monolingua l corpora
using the em algorithm. In National Conference on
Artificial Intelligence (AAAI 2000) Lang kilde, pages
711–715.
A. McCallum and K. Nigam. 1998. A comparison of
event models for Naive Bayes text classification. In
Proceedings of AAAI-98 Workshop on Learning for
Text Categorization.
R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning
multilingual subjective language via cross-lingual pro-
jections. In Proceedings of the Association for Com-
putational Linguistics, Prague, Czech Republic.
C. Monz and B.J. Dorr. 2005. Iterative translation dis-
ambiguation for cross-language information retrieval.
In Proceedings of the 28th Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, Salvador, Brazil.
A. Moschitti. 2003. A study on optimal paramter tun-
ing for Rocchio text classifier. In Proceedings of the
European Conference on Information Retrieval, Italy.
H.T. Ng, B. Wang, and Y.S. Chan. 2003. Exploiting par-
allel texts for word sense disambiguation: An empiri-
cal study. In Proceedings of the 41st Annual Meeting
of the Association for Computational Linguistics (ACL
2003), Sapporo, Japan, July.
J.-Y. Nie, M. Simard, P. Isabelle, and R. Durand. 1999.
Cross-language information retrieval based on parallel
texts and automatic mining of parallel texts from the
Web. In Proceedings of the 22nd annual international
ACM SIGIR conference on Research and development
in information retrieval.
K. Nigam and R. Ghani. 2000. Analyzing the effec-
tiveness and applicability of co-training. In Proceed-
ings of the Conference on Information and Knowledge
Management (CIKM 2000), McLean, VA, November.
K. Nigam, J. Lafferty, and A. McCallum. 1999. Using
maximum entropy for text classification. In IJCAI-99
Workshop on Machine Learning for Information Fil-
tering.
J.S. Olsson, D. W. Oard, and J. Hajic. 2005. Cross-
language text classification. In Proceedings of the 28th
Annual international ACM SIGIR Conference on Re-
search and Development in information Retrieval.
B. Pang and L. Lee. 2004. A sentimental education:
Sentiment analysis using subjectivity summarization
based on minimum cuts. In Proceedings of the 42nd
Meeting of the Association for Computational Linguis-
tics, Barcelona, Spain, July.
M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz.
1998. A Bayesian approach to filtering junk e-mail.
In AAAI-98 Workshop on Learning for Text Catego-
rization, Madison.
J. Schler, M. Koppel, S. Argamon, and J. Pennebaker.
2006. Effects of age and gender on blogging. In Pro-
ceedings of 2006 AAAI Spring Symposium on Com-
putational Approaches for Analyzing Weblogs, pages
199–204, Stanford.
L. Shi, C. Niu, M. Zhou, and J. Gao. 2006. A dom
tree alignment model for mining parallel data from the
web. In Proceedings of the Annual Meeting of the As-
sociation for Computational Lingusitics (ACL 2006),
Sydney, Australia.
V. Vapnik. 1995. The Nature of Statistical Learning The-
ory. Springer, New York.
X. Wan. 2009. Co-training for cross-lingual sentiment
classification. In Proceedings of the Joint Conference
of the Association of Computational Linguistics and
the International Joint Conference on Natural Lan-
guage Processing, Singapore, August.
</reference>
<page confidence="0.978099">
1067
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.704175">
<title confidence="0.9977175">Cross Language Text Classification by Model Translation and Semi-Supervised Learning</title>
<author confidence="0.993186">Lei Shi Rada Mihalcea Mingjun Tian</author>
<affiliation confidence="0.817897">Yahoo! Global R&amp;D University of North Texas Yahoo! Global R&amp;D</affiliation>
<address confidence="0.844814">Beijing, China Denton, TX, U.S.A. Beijing, China</address>
<email confidence="0.999863">lshi@yahoo-inc.comrada@cs.unt.edumingjun@yahoo-inc.com</email>
<abstract confidence="0.998794933333333">In this paper, we introduce a method that automatically builds text classifiers in a new language by training on already labeled data in another language. Our method transfers the classification knowledge across languages by translating the model features and by using an Expectation Maximization (EM) algorithm that naturally takes into account the ambiguity associated with the translation of a word. We further exploit the readily available unlabeled data in the target language via semisupervised learning, and adapt the translated model to better fit the data distribution of the target language.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Argamon</author>
<author>M Koppel</author>
<author>G Avneri</author>
</authors>
<title>Stylebased text categorization: What newspaper am i reading?</title>
<date>1998</date>
<booktitle>In AAAI-98 Workshop on Learning for Text Categorization,</booktitle>
<location>Madison.</location>
<contexts>
<context position="5091" citStr="Argamon et al., 1998" startWordPosition="786" endWordPosition="789">n 4 describes model adaptation by training the translated model with unlabeled documents in the target language. Experiments and evaluations are presented in section 5 and finally we conclude the paper in section 6. 2 Related Work Text classification has rightfully received a lot of attention from both the academic and industry communities, being one of the areas in natural language processing that has a very large number of practical applications. Text classification techniques have been applied to many diverse problems, ranging from topic classification (Joachims, 1997), to genre detection (Argamon et al., 1998), opinion identification (Pang and Lee, 2004), spam detection (Sahami et al., 1998), gender and age classification (Schler et al., 2006). Text classification is typically formulated as a learning task, where a classifier learns how to distinguish between categories in a given set, using features automatically extracted from a collection of documents. In addition to the learning methodology itself, the accuracy of the text classifier also depends to a large extent upon the amount of training data available at hand. For instance, distinguishing between two categories for which thousands of manua</context>
</contexts>
<marker>Argamon, Koppel, Avneri, 1998</marker>
<rawString>S. Argamon, M. Koppel, and G. Avneri. 1998. Stylebased text categorization: What newspaper am i reading? In AAAI-98 Workshop on Learning for Text Categorization, Madison.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Banea</author>
<author>R Mihalcea</author>
<author>J Wiebe</author>
<author>S Hassan</author>
</authors>
<title>Multilingual subjectivity analysis using machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008),</booktitle>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="9227" citStr="Banea et al., 2008" startWordPosition="1432" endWordPosition="1435">for training text classifiers. This method bootstraps text classifiers with only unlabeled data or a small amount of labeled training data, which is close to our setting that tries to leverage labeled data and unlabeled data in different languages to build text classifiers. Finally, also closely related is the work carried out in the field of sentiment and subjectivity analysis for cross-lingual classification of opinions. For instance, (Mihalcea et al., 2007) use an English corpus annotated for subjectivity along with parallel text to build a subjectivity classifier for Romanian. Similarly, (Banea et al., 2008) propose a method based on machine translation to generate parallel texts, followed by a cross-lingual projection of subjectivity labels, which are used to train subjectivity annotation tools for Romanian and Spanish. A related, yet more sophisticated technique is proposed in (Wan, 2009), where a co-training approach is used to leverage resources from both a source and a target language. The technique is tested on the automatic sentiment classification of product reviews in Chinese, and showed to successfully make use of both crosslanguage and within-language knowledge. 3 Cross Language Model </context>
</contexts>
<marker>Banea, Mihalcea, Wiebe, Hassan, 2008</marker>
<rawString>C. Banea, R. Mihalcea, J. Wiebe, and S. Hassan. 2008. Multilingual subjectivity analysis using machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), Honolulu, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="17159" citStr="Berger et al., 1996" startWordPosition="2763" endWordPosition="2766"> the probability of the class of a target language document as the mixture of the probabilities by each translated model from the source language model, weighed by their translation probabilities. P(c|d, mt) ≈ ∑ t|ms, c)P(c|d, m′ m′ t P(m′ t) where mt is the target language classification model and m′t is a candidate model translated from the model ms trained on the labeled training data in the source language. This is a very generic representation for model translation and the model m could be any type of text classification. Specifically in this paper, we take the Maximum Entropy (ME) model(Berger et al., 1996) as an example for the model translation across languages, since the ME model is one of the most widely used text classification models. The maximum entropy classifier takes the form is invariant to c and hence we can omit it for classification since our objective is to find the best c. According to the formulation of the Maximum Entropy model, the document can be classified as follows. ∑bc = argmaxc∈C m′t The model translation probability P(m′t|ms, c) can be modeled as the product of the translation probabilities of each of its individual bag-of-words features P(m′t|ms, c) ≈ ∏li=1 P(wit|wis, </context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Blum</author>
<author>T Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In COLT: Proceedings of the Workshop on Computational Learning Theory,</booktitle>
<publisher>Morgan Kaufmann Publishers,</publisher>
<contexts>
<context position="6569" citStr="Blum and Mitchell, 1998" startWordPosition="1016" endWordPosition="1019">learning methods, which assume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is learned from comparable corpora, and subsequently used for the cross-lingual classification of texts. In experiments run on Italian and English, Gliozzo and Strapparava showed that the multilingual domain kernel exceeds by a large margin a bag-of-words approach. Moreove</context>
<context position="8574" citStr="Blum and Mitchell, 1998" startWordPosition="1330" endWordPosition="1333">proposed (Shi et al., 2006; Nie et al., 1999) to automatically acquire a large quantity of parallel sentences from the web, but such web data is however predominantly confined to a limited number of domains and language pairs. (Dai et al., 2007) experimented with the use of transfer learning for text classification. Although in this method the transfer learning is performed across 1058 different domains in the same language, the underlying principle is similar to CLTC in the sense that different domains or languages may share a significant amount of knowledge in similar classification tasks. (Blum and Mitchell, 1998) employed semisupervised learning for training text classifiers. This method bootstraps text classifiers with only unlabeled data or a small amount of labeled training data, which is close to our setting that tries to leverage labeled data and unlabeled data in different languages to build text classifiers. Finally, also closely related is the work carried out in the field of sentiment and subjectivity analysis for cross-lingual classification of opinions. For instance, (Mihalcea et al., 2007) use an English corpus annotated for subjectivity along with parallel text to build a subjectivity cla</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>A. Blum and T. Mitchell. 1998. Combining labeled and unlabeled data with co-training. In COLT: Proceedings of the Workshop on Computational Learning Theory, Morgan Kaufmann Publishers, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S della Pietra</author>
<author>V della Pietra</author>
<author>R Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="7816" citStr="Brown et al., 1993" startWordPosition="1204" endWordPosition="1207">e use of a bilingual dictionary can drastically improve the performance of the models learned from corpora. (Fortuna and Shawe-Taylor, 2005; Olsson et al., 2005) studied the use of machine translation tools for the purpose of cross language text classification and mining. These approaches typically translate the training data or test data into the same language, followed by the application of a monolingual classifier. The performance of such classifiers very much depends on the quality of the machine translation tools. Unfortunately, the development of statistical machine translation systems (Brown et al., 1993) is hindered by the lack of availability of parallel corpora and the quality of their output is often erroneous. Several methods were proposed (Shi et al., 2006; Nie et al., 1999) to automatically acquire a large quantity of parallel sentences from the web, but such web data is however predominantly confined to a limited number of domains and language pairs. (Dai et al., 2007) experimented with the use of transfer learning for text classification. Although in this method the transfer learning is performed across 1058 different domains in the same language, the underlying principle is similar t</context>
<context position="15311" citStr="Brown et al., 1993" startWordPosition="2472" endWordPosition="2475">n. P(w’c) is the probability of occurrence of the source language word w′ under the class c. It can be estimated from the labeled source language training data available as follows and it is regarded as a known parameter of the model. P (w′c) =f(w′c) ∑ (3) w′∈V f(w′c) where V is the vocabulary of the source language. Algorithm 1 illustrates the EM learning process, where nw′ denotes the number of translation candidates for w′ according to the bilingual lexicon. Our method requires no labeled training data in the target language. Many statistical machine translation systems such as IBM models (Brown et al., 1993) learn word translation probabilities from millions of parallel sentences which are mutual translations. However, large scale parallel corpora rarely exist for most language pairs. (Koehn and Knight, 2000) proposed to use the EM algorithm to learn word translation probabilities from non-parallel monolingual corpora. However, this method estimates only class independent translation probabilities P(wi|w′i), while our approach is able to learn class specific translation probabilities 1060 P(wi|w′i, c) by leveraging available labeled training data in the source language. For example, the probabili</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. Brown, S. della Pietra, V. della Pietra, and R. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Dai</author>
<author>G Xue</author>
<author>Q Yang</author>
<author>Y Yu</author>
</authors>
<title>Transferring naive bayes classifiers for text classification. In</title>
<date>2007</date>
<booktitle>In Proceedings of the 22nd AAAI Conference on Artificial Intell igence,</booktitle>
<pages>540--545</pages>
<contexts>
<context position="8195" citStr="Dai et al., 2007" startWordPosition="1271" endWordPosition="1274">application of a monolingual classifier. The performance of such classifiers very much depends on the quality of the machine translation tools. Unfortunately, the development of statistical machine translation systems (Brown et al., 1993) is hindered by the lack of availability of parallel corpora and the quality of their output is often erroneous. Several methods were proposed (Shi et al., 2006; Nie et al., 1999) to automatically acquire a large quantity of parallel sentences from the web, but such web data is however predominantly confined to a limited number of domains and language pairs. (Dai et al., 2007) experimented with the use of transfer learning for text classification. Although in this method the transfer learning is performed across 1058 different domains in the same language, the underlying principle is similar to CLTC in the sense that different domains or languages may share a significant amount of knowledge in similar classification tasks. (Blum and Mitchell, 1998) employed semisupervised learning for training text classifiers. This method bootstraps text classifiers with only unlabeled data or a small amount of labeled training data, which is close to our setting that tries to lev</context>
</contexts>
<marker>Dai, Xue, Yang, Yu, 2007</marker>
<rawString>W. Dai, G. Xue, Q. Yang, and Y. Yu. 2007. Transferring naive bayes classifiers for text classification. In In Proceedings of the 22nd AAAI Conference on Artificial Intell igence, pages 540–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the em algorithm.</title>
<date>1977</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="14071" citStr="Dempster et al., 1977" startWordPosition="2260" endWordPosition="2263">w|w′c) = 0; 2: Compute P(w′c) with Dl according to equation 3 3: repeat 4: Calculate Pt(w′c|w) with Du based on Pt−1(w|w′c) according to equation 1 5: Calculate Pt(w|w′c) based on Pt−1(w′c|w) according to equation 2 6: until change of P(w|w′c) is smaller than the threshold 7: return P(w|w′c) b ∑m log(P(dj, θ)) θ = argmaxθ j=1 = argmaxθ ∑m log( ∑ P(c) ∑ j=1 c d′ ∏l� P(wi|w′i, c)P(w′i|c)) i=1 where m is the number of documents in the corpus in the target language and lj is the number of words in the document dj. In order to estimate the optimal values of the parameters, we use the EM algorithm (Dempster et al., 1977). At each iteration of EM we determine those values by maximizing the expectation using the parameters from the previous iteration and this iterative process stops when the change in the parameters is smaller than a given threshold. We can repeat the following two steps for the purpose above. • E-step P(cw′w) P(w′c|w) ← P (w) P(w|w′c)P(w′c) =∑ ∑w′ P(w|w′c)P(w′c) (1) c • M-step P(w|w′c) ← f(w)P(w′c|w) (2) ∑w∈K f (w)P(w′c|w) Here f(w) is the occurrence frequency of the word w in the corpus. K is the set of translation candidates in the target language for the source language word w′ according to</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A.P. Dempster, N.M. Laird, and D.B. Rubin. 1977. Maximum likelihood from incomplete data via the em algorithm. Journal of the Royal Statistical Society. Series B (Methodological), 39(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Fortuna</author>
<author>J Shawe-Taylor</author>
</authors>
<title>The use of machine translation tools for cross-lingual text mining.</title>
<date>2005</date>
<booktitle>In Learning With Multiple Views, Workshop at the 22nd International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="7336" citStr="Fortuna and Shawe-Taylor, 2005" startWordPosition="1132" endWordPosition="1135">nly very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is learned from comparable corpora, and subsequently used for the cross-lingual classification of texts. In experiments run on Italian and English, Gliozzo and Strapparava showed that the multilingual domain kernel exceeds by a large margin a bag-of-words approach. Moreover, they demonstrated that the use of a bilingual dictionary can drastically improve the performance of the models learned from corpora. (Fortuna and Shawe-Taylor, 2005; Olsson et al., 2005) studied the use of machine translation tools for the purpose of cross language text classification and mining. These approaches typically translate the training data or test data into the same language, followed by the application of a monolingual classifier. The performance of such classifiers very much depends on the quality of the machine translation tools. Unfortunately, the development of statistical machine translation systems (Brown et al., 1993) is hindered by the lack of availability of parallel corpora and the quality of their output is often erroneous. Several</context>
</contexts>
<marker>Fortuna, Shawe-Taylor, 2005</marker>
<rawString>B. Fortuna and J. Shawe-Taylor. 2005. The use of machine translation tools for cross-lingual text mining. In Learning With Multiple Views, Workshop at the 22nd International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gliozzo</author>
<author>C Strapparava</author>
</authors>
<title>Exploiting comparable corpora and bilingual dictionaries for crosslanguage text categorization.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="6859" citStr="Gliozzo and Strapparava, 2006" startWordPosition="1062" endWordPosition="1066">um Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is learned from comparable corpora, and subsequently used for the cross-lingual classification of texts. In experiments run on Italian and English, Gliozzo and Strapparava showed that the multilingual domain kernel exceeds by a large margin a bag-of-words approach. Moreover, they demonstrated that the use of a bilingual dictionary can drastically improve the performance of the models learned from corpora. (Fortuna and Shawe-Taylor, 2005; Olsson et al., 2005) studied the use of machine translation tools for the purpose of cross language text classification a</context>
</contexts>
<marker>Gliozzo, Strapparava, 2006</marker>
<rawString>A. Gliozzo and C. Strapparava. 2006. Exploiting comparable corpora and bilingual dictionaries for crosslanguage text categorization. In Proceedings of the Conference of the Association for Computational Linguistics, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering. Special issue on Parallel Texts,</title>
<date>2005</date>
<editor>editors R. Mihalcea and M. Simard.</editor>
<contexts>
<context position="1363" citStr="Hwa et al., 2005" startWordPosition="202" endWordPosition="205">eled data in the target language via semisupervised learning, and adapt the translated model to better fit the data distribution of the target language. 1 Introduction Given the accelerated growth of the number of multilingual documents on the Web and elsewhere, the need for effective multilingual and cross-lingual text processing techniques is becoming increasingly important. There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al., 2003), syntactic parsing (Hwa et al., 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al., 2007), and others. In this paper, we address the task of cross-lingual text classification (CLTC), which builds text classifiers for multiple languages by using training data in one language, thereby avoiding the costly and timeconsuming process of labeling training data for each individual language. The main idea underlying our approach to CLTC is that although content can be expressed in different forms in different languages, there is a significant amount of knowledge that is shared for similar topics tha</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, 2005</marker>
<rawString>R. Hwa, P. Resnik, and A. Weinberg. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering. Special issue on Parallel Texts, editors R. Mihalcea and M. Simard.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization.</title>
<date>1997</date>
<booktitle>In Proceedings of ICML-97, 14th International Conference on Machine Learning,</booktitle>
<location>Nashville, US.</location>
<contexts>
<context position="5048" citStr="Joachims, 1997" startWordPosition="781" endWordPosition="782">earned using the EM algorithm. Section 4 describes model adaptation by training the translated model with unlabeled documents in the target language. Experiments and evaluations are presented in section 5 and finally we conclude the paper in section 6. 2 Related Work Text classification has rightfully received a lot of attention from both the academic and industry communities, being one of the areas in natural language processing that has a very large number of practical applications. Text classification techniques have been applied to many diverse problems, ranging from topic classification (Joachims, 1997), to genre detection (Argamon et al., 1998), opinion identification (Pang and Lee, 2004), spam detection (Sahami et al., 1998), gender and age classification (Schler et al., 2006). Text classification is typically formulated as a learning task, where a classifier learns how to distinguish between categories in a given set, using features automatically extracted from a collection of documents. In addition to the learning methodology itself, the accuracy of the text classifier also depends to a large extent upon the amount of training data available at hand. For instance, distinguishing between </context>
</contexts>
<marker>Joachims, 1997</marker>
<rawString>T. Joachims. 1997. A probabilistic analysis of the Rocchio algorithm with TFIDF for text categorization. In Proceedings of ICML-97, 14th International Conference on Machine Learning, Nashville, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorization with Support Vector Machines: learning with mny relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning,</booktitle>
<pages>137--142</pages>
<contexts>
<context position="6318" citStr="Joachims, 1998" startWordPosition="979" endWordPosition="980">d examples are already available is expected to perform better than trying to separate categories that have only a handful of labeled documents. Some of the most successful approaches to date for text classification involve the use of machine learning methods, which assume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is learned from compar</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>T. Joachims. 1998. Text categorization with Support Vector Machines: learning with mny relevant features. In Proceedings of the European Conference on Machine Learning, pages 137–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Estimating word translation probabilities from unrelated monolingua l corpora using the em algorithm.</title>
<date>2000</date>
<booktitle>In National Conference on Artificial Intelligence (AAAI</booktitle>
<pages>711--715</pages>
<contexts>
<context position="15516" citStr="Koehn and Knight, 2000" startWordPosition="2502" endWordPosition="2505">s a known parameter of the model. P (w′c) =f(w′c) ∑ (3) w′∈V f(w′c) where V is the vocabulary of the source language. Algorithm 1 illustrates the EM learning process, where nw′ denotes the number of translation candidates for w′ according to the bilingual lexicon. Our method requires no labeled training data in the target language. Many statistical machine translation systems such as IBM models (Brown et al., 1993) learn word translation probabilities from millions of parallel sentences which are mutual translations. However, large scale parallel corpora rarely exist for most language pairs. (Koehn and Knight, 2000) proposed to use the EM algorithm to learn word translation probabilities from non-parallel monolingual corpora. However, this method estimates only class independent translation probabilities P(wi|w′i), while our approach is able to learn class specific translation probabilities 1060 P(wi|w′i, c) by leveraging available labeled training data in the source language. For example, the probability of translating “bush” as “树丛” (small trees) is higher than translating as “Tji什” (U.S. president) when the category of the text is “botany.” 3.2 Model Translation In order to classify documents in the t</context>
</contexts>
<marker>Koehn, Knight, 2000</marker>
<rawString>P. Koehn and K. Knight. 2000. Estimating word translation probabilities from unrelated monolingua l corpora using the em algorithm. In National Conference on Artificial Intelligence (AAAI 2000) Lang kilde, pages 711–715.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Nigam</author>
</authors>
<title>A comparison of event models for Naive Bayes text classification.</title>
<date>1998</date>
<booktitle>In Proceedings of AAAI-98 Workshop on Learning for Text Categorization.</booktitle>
<contexts>
<context position="6167" citStr="McCallum and Nigam, 1998" startWordPosition="955" endWordPosition="958">o a large extent upon the amount of training data available at hand. For instance, distinguishing between two categories for which thousands of manually annotated examples are already available is expected to perform better than trying to separate categories that have only a handful of labeled documents. Some of the most successful approaches to date for text classification involve the use of machine learning methods, which assume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text clas</context>
</contexts>
<marker>McCallum, Nigam, 1998</marker>
<rawString>A. McCallum and K. Nigam. 1998. A comparison of event models for Naive Bayes text classification. In Proceedings of AAAI-98 Workshop on Learning for Text Categorization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>C Banea</author>
<author>J Wiebe</author>
</authors>
<title>Learning multilingual subjective language via cross-lingual projections.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1455" citStr="Mihalcea et al., 2007" startWordPosition="215" endWordPosition="218">model to better fit the data distribution of the target language. 1 Introduction Given the accelerated growth of the number of multilingual documents on the Web and elsewhere, the need for effective multilingual and cross-lingual text processing techniques is becoming increasingly important. There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al., 2003), syntactic parsing (Hwa et al., 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al., 2007), and others. In this paper, we address the task of cross-lingual text classification (CLTC), which builds text classifiers for multiple languages by using training data in one language, thereby avoiding the costly and timeconsuming process of labeling training data for each individual language. The main idea underlying our approach to CLTC is that although content can be expressed in different forms in different languages, there is a significant amount of knowledge that is shared for similar topics that can be effectively used to port topic classifiers across languages. Previous methods for C</context>
<context position="9072" citStr="Mihalcea et al., 2007" startWordPosition="1408" endWordPosition="1411"> domains or languages may share a significant amount of knowledge in similar classification tasks. (Blum and Mitchell, 1998) employed semisupervised learning for training text classifiers. This method bootstraps text classifiers with only unlabeled data or a small amount of labeled training data, which is close to our setting that tries to leverage labeled data and unlabeled data in different languages to build text classifiers. Finally, also closely related is the work carried out in the field of sentiment and subjectivity analysis for cross-lingual classification of opinions. For instance, (Mihalcea et al., 2007) use an English corpus annotated for subjectivity along with parallel text to build a subjectivity classifier for Romanian. Similarly, (Banea et al., 2008) propose a method based on machine translation to generate parallel texts, followed by a cross-lingual projection of subjectivity labels, which are used to train subjectivity annotation tools for Romanian and Spanish. A related, yet more sophisticated technique is proposed in (Wan, 2009), where a co-training approach is used to leverage resources from both a source and a target language. The technique is tested on the automatic sentiment cla</context>
</contexts>
<marker>Mihalcea, Banea, Wiebe, 2007</marker>
<rawString>R. Mihalcea, C. Banea, and J. Wiebe. 2007. Learning multilingual subjective language via cross-lingual projections. In Proceedings of the Association for Computational Linguistics, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Monz</author>
<author>B J Dorr</author>
</authors>
<title>Iterative translation disambiguation for cross-language information retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<location>Salvador, Brazil.</location>
<contexts>
<context position="1408" citStr="Monz and Dorr, 2005" startWordPosition="209" endWordPosition="212">upervised learning, and adapt the translated model to better fit the data distribution of the target language. 1 Introduction Given the accelerated growth of the number of multilingual documents on the Web and elsewhere, the need for effective multilingual and cross-lingual text processing techniques is becoming increasingly important. There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al., 2003), syntactic parsing (Hwa et al., 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al., 2007), and others. In this paper, we address the task of cross-lingual text classification (CLTC), which builds text classifiers for multiple languages by using training data in one language, thereby avoiding the costly and timeconsuming process of labeling training data for each individual language. The main idea underlying our approach to CLTC is that although content can be expressed in different forms in different languages, there is a significant amount of knowledge that is shared for similar topics that can be effectively used to port topic class</context>
</contexts>
<marker>Monz, Dorr, 2005</marker>
<rawString>C. Monz and B.J. Dorr. 2005. Iterative translation disambiguation for cross-language information retrieval. In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, Salvador, Brazil.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>A study on optimal paramter tuning for Rocchio text classifier.</title>
<date>2003</date>
<booktitle>In Proceedings of the European Conference on Information Retrieval,</booktitle>
<location>Italy.</location>
<contexts>
<context position="6222" citStr="Moschitti, 2003" startWordPosition="963" endWordPosition="964">and. For instance, distinguishing between two categories for which thousands of manually annotated examples are already available is expected to perform better than trying to separate categories that have only a handful of labeled documents. Some of the most successful approaches to date for text classification involve the use of machine learning methods, which assume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ou</context>
</contexts>
<marker>Moschitti, 2003</marker>
<rawString>A. Moschitti. 2003. A study on optimal paramter tuning for Rocchio text classifier. In Proceedings of the European Conference on Information Retrieval, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>B Wang</author>
<author>Y S Chan</author>
</authors>
<title>Exploiting parallel texts for word sense disambiguation: An empirical study.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL 2003),</booktitle>
<location>Sapporo, Japan,</location>
<contexts>
<context position="1325" citStr="Ng et al., 2003" startWordPosition="196" endWordPosition="199">r exploit the readily available unlabeled data in the target language via semisupervised learning, and adapt the translated model to better fit the data distribution of the target language. 1 Introduction Given the accelerated growth of the number of multilingual documents on the Web and elsewhere, the need for effective multilingual and cross-lingual text processing techniques is becoming increasingly important. There is a growing number of methods that use data available in one language to build text processing tools for another language, for diverse tasks such as word sense disambiguation (Ng et al., 2003), syntactic parsing (Hwa et al., 2005), information retrieval (Monz and Dorr, 2005), subjectivity analysis (Mihalcea et al., 2007), and others. In this paper, we address the task of cross-lingual text classification (CLTC), which builds text classifiers for multiple languages by using training data in one language, thereby avoiding the costly and timeconsuming process of labeling training data for each individual language. The main idea underlying our approach to CLTC is that although content can be expressed in different forms in different languages, there is a significant amount of knowledge</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>H.T. Ng, B. Wang, and Y.S. Chan. 2003. Exploiting parallel texts for word sense disambiguation: An empirical study. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics (ACL 2003), Sapporo, Japan, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-Y Nie</author>
<author>M Simard</author>
<author>P Isabelle</author>
<author>R Durand</author>
</authors>
<title>Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the Web.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<contexts>
<context position="7995" citStr="Nie et al., 1999" startWordPosition="1237" endWordPosition="1240">machine translation tools for the purpose of cross language text classification and mining. These approaches typically translate the training data or test data into the same language, followed by the application of a monolingual classifier. The performance of such classifiers very much depends on the quality of the machine translation tools. Unfortunately, the development of statistical machine translation systems (Brown et al., 1993) is hindered by the lack of availability of parallel corpora and the quality of their output is often erroneous. Several methods were proposed (Shi et al., 2006; Nie et al., 1999) to automatically acquire a large quantity of parallel sentences from the web, but such web data is however predominantly confined to a limited number of domains and language pairs. (Dai et al., 2007) experimented with the use of transfer learning for text classification. Although in this method the transfer learning is performed across 1058 different domains in the same language, the underlying principle is similar to CLTC in the sense that different domains or languages may share a significant amount of knowledge in similar classification tasks. (Blum and Mitchell, 1998) employed semisupervi</context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>J.-Y. Nie, M. Simard, P. Isabelle, and R. Durand. 1999. Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the Web. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>R Ghani</author>
</authors>
<title>Analyzing the effectiveness and applicability of co-training.</title>
<date>2000</date>
<booktitle>In Proceedings of the Conference on Information and Knowledge Management (CIKM</booktitle>
<location>McLean, VA,</location>
<contexts>
<context position="6593" citStr="Nigam and Ghani, 2000" startWordPosition="1020" endWordPosition="1023">ssume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is learned from comparable corpora, and subsequently used for the cross-lingual classification of texts. In experiments run on Italian and English, Gliozzo and Strapparava showed that the multilingual domain kernel exceeds by a large margin a bag-of-words approach. Moreover, they demonstrated tha</context>
</contexts>
<marker>Nigam, Ghani, 2000</marker>
<rawString>K. Nigam and R. Ghani. 2000. Analyzing the effectiveness and applicability of co-training. In Proceedings of the Conference on Information and Knowledge Management (CIKM 2000), McLean, VA, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>J Lafferty</author>
<author>A McCallum</author>
</authors>
<title>Using maximum entropy for text classification.</title>
<date>1999</date>
<booktitle>In IJCAI-99 Workshop on Machine Learning for Information Filtering.</booktitle>
<contexts>
<context position="6260" citStr="Nigam et al., 1999" startWordPosition="968" endWordPosition="971">etween two categories for which thousands of manually annotated examples are already available is expected to perform better than trying to separate categories that have only a handful of labeled documents. Some of the most successful approaches to date for text classification involve the use of machine learning methods, which assume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006),</context>
</contexts>
<marker>Nigam, Lafferty, McCallum, 1999</marker>
<rawString>K. Nigam, J. Lafferty, and A. McCallum. 1999. Using maximum entropy for text classification. In IJCAI-99 Workshop on Machine Learning for Information Filtering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J S Olsson</author>
<author>D W Oard</author>
<author>J Hajic</author>
</authors>
<title>Crosslanguage text classification.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th Annual international ACM SIGIR Conference on Research and Development in information Retrieval.</booktitle>
<contexts>
<context position="7358" citStr="Olsson et al., 2005" startWordPosition="1136" endWordPosition="1139">ne on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is learned from comparable corpora, and subsequently used for the cross-lingual classification of texts. In experiments run on Italian and English, Gliozzo and Strapparava showed that the multilingual domain kernel exceeds by a large margin a bag-of-words approach. Moreover, they demonstrated that the use of a bilingual dictionary can drastically improve the performance of the models learned from corpora. (Fortuna and Shawe-Taylor, 2005; Olsson et al., 2005) studied the use of machine translation tools for the purpose of cross language text classification and mining. These approaches typically translate the training data or test data into the same language, followed by the application of a monolingual classifier. The performance of such classifiers very much depends on the quality of the machine translation tools. Unfortunately, the development of statistical machine translation systems (Brown et al., 1993) is hindered by the lack of availability of parallel corpora and the quality of their output is often erroneous. Several methods were proposed</context>
</contexts>
<marker>Olsson, Oard, Hajic, 2005</marker>
<rawString>J.S. Olsson, D. W. Oard, and J. Hajic. 2005. Crosslanguage text classification. In Proceedings of the 28th Annual international ACM SIGIR Conference on Research and Development in information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics,</booktitle>
<location>Barcelona, Spain,</location>
<contexts>
<context position="5136" citStr="Pang and Lee, 2004" startWordPosition="793" endWordPosition="796">translated model with unlabeled documents in the target language. Experiments and evaluations are presented in section 5 and finally we conclude the paper in section 6. 2 Related Work Text classification has rightfully received a lot of attention from both the academic and industry communities, being one of the areas in natural language processing that has a very large number of practical applications. Text classification techniques have been applied to many diverse problems, ranging from topic classification (Joachims, 1997), to genre detection (Argamon et al., 1998), opinion identification (Pang and Lee, 2004), spam detection (Sahami et al., 1998), gender and age classification (Schler et al., 2006). Text classification is typically formulated as a learning task, where a classifier learns how to distinguish between categories in a given set, using features automatically extracted from a collection of documents. In addition to the learning methodology itself, the accuracy of the text classifier also depends to a large extent upon the amount of training data available at hand. For instance, distinguishing between two categories for which thousands of manually annotated examples are already available </context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sahami</author>
<author>S Dumais</author>
<author>D Heckerman</author>
<author>E Horvitz</author>
</authors>
<title>A Bayesian approach to filtering junk e-mail.</title>
<date>1998</date>
<booktitle>In AAAI-98 Workshop on Learning for Text Categorization,</booktitle>
<location>Madison.</location>
<contexts>
<context position="5174" citStr="Sahami et al., 1998" startWordPosition="799" endWordPosition="802">ents in the target language. Experiments and evaluations are presented in section 5 and finally we conclude the paper in section 6. 2 Related Work Text classification has rightfully received a lot of attention from both the academic and industry communities, being one of the areas in natural language processing that has a very large number of practical applications. Text classification techniques have been applied to many diverse problems, ranging from topic classification (Joachims, 1997), to genre detection (Argamon et al., 1998), opinion identification (Pang and Lee, 2004), spam detection (Sahami et al., 1998), gender and age classification (Schler et al., 2006). Text classification is typically formulated as a learning task, where a classifier learns how to distinguish between categories in a given set, using features automatically extracted from a collection of documents. In addition to the learning methodology itself, the accuracy of the text classifier also depends to a large extent upon the amount of training data available at hand. For instance, distinguishing between two categories for which thousands of manually annotated examples are already available is expected to perform better than try</context>
</contexts>
<marker>Sahami, Dumais, Heckerman, Horvitz, 1998</marker>
<rawString>M. Sahami, S. Dumais, D. Heckerman, and E. Horvitz. 1998. A Bayesian approach to filtering junk e-mail. In AAAI-98 Workshop on Learning for Text Categorization, Madison.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schler</author>
<author>M Koppel</author>
<author>S Argamon</author>
<author>J Pennebaker</author>
</authors>
<title>Effects of age and gender on blogging.</title>
<date>2006</date>
<booktitle>In Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs,</booktitle>
<pages>199--204</pages>
<location>Stanford.</location>
<contexts>
<context position="5227" citStr="Schler et al., 2006" startWordPosition="807" endWordPosition="810">ons are presented in section 5 and finally we conclude the paper in section 6. 2 Related Work Text classification has rightfully received a lot of attention from both the academic and industry communities, being one of the areas in natural language processing that has a very large number of practical applications. Text classification techniques have been applied to many diverse problems, ranging from topic classification (Joachims, 1997), to genre detection (Argamon et al., 1998), opinion identification (Pang and Lee, 2004), spam detection (Sahami et al., 1998), gender and age classification (Schler et al., 2006). Text classification is typically formulated as a learning task, where a classifier learns how to distinguish between categories in a given set, using features automatically extracted from a collection of documents. In addition to the learning methodology itself, the accuracy of the text classifier also depends to a large extent upon the amount of training data available at hand. For instance, distinguishing between two categories for which thousands of manually annotated examples are already available is expected to perform better than trying to separate categories that have only a handful o</context>
</contexts>
<marker>Schler, Koppel, Argamon, Pennebaker, 2006</marker>
<rawString>J. Schler, M. Koppel, S. Argamon, and J. Pennebaker. 2006. Effects of age and gender on blogging. In Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs, pages 199–204, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shi</author>
<author>C Niu</author>
<author>M Zhou</author>
<author>J Gao</author>
</authors>
<title>A dom tree alignment model for mining parallel data from the web.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Lingusitics (ACL</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="7976" citStr="Shi et al., 2006" startWordPosition="1233" endWordPosition="1236">tudied the use of machine translation tools for the purpose of cross language text classification and mining. These approaches typically translate the training data or test data into the same language, followed by the application of a monolingual classifier. The performance of such classifiers very much depends on the quality of the machine translation tools. Unfortunately, the development of statistical machine translation systems (Brown et al., 1993) is hindered by the lack of availability of parallel corpora and the quality of their output is often erroneous. Several methods were proposed (Shi et al., 2006; Nie et al., 1999) to automatically acquire a large quantity of parallel sentences from the web, but such web data is however predominantly confined to a limited number of domains and language pairs. (Dai et al., 2007) experimented with the use of transfer learning for text classification. Although in this method the transfer learning is performed across 1058 different domains in the same language, the underlying principle is similar to CLTC in the sense that different domains or languages may share a significant amount of knowledge in similar classification tasks. (Blum and Mitchell, 1998) e</context>
</contexts>
<marker>Shi, Niu, Zhou, Gao, 2006</marker>
<rawString>L. Shi, C. Niu, M. Zhou, and J. Gao. 2006. A dom tree alignment model for mining parallel data from the web. In Proceedings of the Annual Meeting of the Association for Computational Lingusitics (ACL 2006), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="6301" citStr="Vapnik, 1995" startWordPosition="977" endWordPosition="978">ually annotated examples are already available is expected to perform better than trying to separate categories that have only a handful of labeled documents. Some of the most successful approaches to date for text classification involve the use of machine learning methods, which assume that enough annotated data is available such that a classification model can be automatically learned. These include algorithms such as Naive Bayes (Joachims, 1997; McCallum and Nigam, 1998), Rocchio classifiers (Joachims, 1997; Moschitti, 2003), Maximum Entropy (Nigam et al., 1999) or Support Vector Machines (Vapnik, 1995; Joachims, 1998). If only a small amount of annotated data is available, the alternative is to use semi-supervised bootstrapping methods such as co-training or self-training, which can also integrate raw unlabeled data into the learning model (Blum and Mitchell, 1998; Nigam and Ghani, 2000). Despite the attention that monolingual text classification has received from the research community, there is only very little work that was done on cross-lingual text classification. The work that is most closely related to ours is (Gliozzo and Strapparava, 2006), where a multilingual domain kernel is le</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
</authors>
<title>Co-training for cross-lingual sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the Association of Computational Linguistics and the International Joint Conference on Natural Language Processing,</booktitle>
<location>Singapore,</location>
<contexts>
<context position="9515" citStr="Wan, 2009" startWordPosition="1478" endWordPosition="1479">related is the work carried out in the field of sentiment and subjectivity analysis for cross-lingual classification of opinions. For instance, (Mihalcea et al., 2007) use an English corpus annotated for subjectivity along with parallel text to build a subjectivity classifier for Romanian. Similarly, (Banea et al., 2008) propose a method based on machine translation to generate parallel texts, followed by a cross-lingual projection of subjectivity labels, which are used to train subjectivity annotation tools for Romanian and Spanish. A related, yet more sophisticated technique is proposed in (Wan, 2009), where a co-training approach is used to leverage resources from both a source and a target language. The technique is tested on the automatic sentiment classification of product reviews in Chinese, and showed to successfully make use of both crosslanguage and within-language knowledge. 3 Cross Language Model Translation To make the classifier applicable to documents in a foreign language, we introduce a method where model features that are learned from the training data are translated from the source language into the target language. Using this translation process, a feature associated with</context>
</contexts>
<marker>Wan, 2009</marker>
<rawString>X. Wan. 2009. Co-training for cross-lingual sentiment classification. In Proceedings of the Joint Conference of the Association of Computational Linguistics and the International Joint Conference on Natural Language Processing, Singapore, August.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>