<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012924">
<title confidence="0.963375">
Learning to Find Translations and Transliterations on the Web
</title>
<author confidence="0.99893">
Joseph Z. Chang Jason S. Chang Jyh-Shing Roger Jang
</author>
<affiliation confidence="0.995088">
Department of Computer Science, Department of Computer Science, Department of Computer Science,
National Tsing Hua University National Tsing Hua University National Tsing Hua University
</affiliation>
<address confidence="0.8728175">
101, Kuangfu Road, 101, Kuangfu Road, 101, Kuangfu Road,
Hsinchu, 300, Taiwan Hsinchu, 300, Taiwan Hsinchu, 300, Taiwan
</address>
<email confidence="0.998275">
joseph.nthu.tw@gmail.com jschang@cs.nthu.edu.tw jang@cs.nthu.edu.tw
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999524466666667">
In this paper, we present a new method
for learning to finding translations and
transliterations on the Web for a given
term. The approach involves using a small
set of terms and translations to obtain
mixed-code snippets from a search engine,
and automatically annotating the snippets
with tags and features for training a
conditional random field model. At run-
time, the model is used to extracting
translation candidates for a given term.
Preliminary experiments and evaluation
show our method cleanly combining
various features, resulting in a system that
outperforms previous work.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949863636364">
The phrase translation problem is critical to
machine translation, cross-lingual information
retrieval, and multilingual terminology (Bian and
Chen 2000, Kupiec 1993). Such systems typically
use a parallel corpus. However, the out of
vocabulary problem (OOV) is hard to overcome
even with a very large training corpus due to the
Zipf nature of word distribution, and ever growing
new terminology and named entities. Luckily,
there are an abundant of webpages consisting
mixed-code text, typically written in one language
but interspersed with some sentential or phrasal
translations in another language. By retrieving and
identifying such translation counterparts on the
Web, we can cope with the OOV problem.
Consider the technical term named-entity
recognition. The best places to find the Chinese
translations for named-entity recognition are
probably not some parallel corpus or dictionary,
but rather mixed-code webpages. The following
example is a snippet returned by the Bing search
engine for the query, named entity recognition:
</bodyText>
<figure confidence="0.4760005">
... 語言處理技術,如自然語言剖析 (Natural Language
Parsing)、問題分類 (Question Classification)、專名辨識
(Named Entity Recognition)等等 ...
This snippet contains three technical terms in
Chinese (i.e., 自然語言剖析 zhiran yuyan poxi,
問題分類 wenti fenlei, 專名辨識 zhuanming
</figure>
<bodyText confidence="0.997469411764706">
bianshi), followed by source terms in brackets
(respectively, Natural Language Parsing, Question
Classification, and Named Entity Recognition).
Quoh (2006) points out that submitting the source
term and partial translation to a search engine is a
good strategy used by many translators.
Unfortunately, the user still has to sift through
snippets to find the translations. For a given
English term, such translations can be extracted by
casting the problem as a sequence labeling task for
classifying the Chinese characters in the snippets
as either translation or non-translation. Previous
work has pointed out that such translations usually
exhibit characteristics related to word translation,
word transliteration, surface patterns, and
proximity to the occurrences of the original phrase
(Nagata et. al 2001 and Wu et. al 2005).
</bodyText>
<page confidence="0.990768">
130
</page>
<note confidence="0.6841975">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 130–134,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999988055555556">
Thus, we also associate features to each Chinese
token (characters or words) to reflect the likelihood
of the token being part of the translation. We
describe how to train a CRF model for identifying
translations in more details in Section 3.
At run-time, the system accepts a given phrase
(e.g., named-entity recognition), and then query a
search engine for webpages in the target language
(e.g., Chinese) using the advance search function.
Subsequently, we retrieve mixed-code snippets and
identify the translations of the given term. The
system can potentially be used to assist translators
to find the most common translation for a given
term, or to supplement a bilingual terminology
bank (e.g., adding multilingual titles to existing
Wikipedia); alternatively, they can be used as
additional training data for a machine translation
system, as described in Lin et al. (2008).
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998842333333333">
Phrase translation and transliteration is important
for cross-language tasks. For example, Knight and
Graehl (1998) describe and evaluate a multi-stage
machine translation method for back transliterating
English names into Japanese, while Bian and Chen
(2000) describe cross-language information access
to multilingual collections on the Internet.
Recently, researchers have begun to exploit
mixed code webpages for word and phrase
translation. Nagata et al. (2001) present a system
for finding English translations for a given
Japanese technical term using Japanese-English
snippets returned by a search engine. Kwok et al.
(2005) focus on named entity transliteration and
implemented a cross-language name finder. Wu et
al. (2005) proposed a method to learn surface
patterns to find translations in mixed code snippets.
Some researchers exploited the hyperlinks in
Webpage to find translations. Lu, et al. (2004)
propose a method for mining translations of web
queries from anchor texts. Cheng, et al (2004)
propose a similar method for translating unknown
queries with web corpora for cross-language
information retrieval. Gravano (2006) also propose
similar methods using anchor texts.
In a study more closely related to our work, Lin
et al. (2008) proposed a method that performs
word alignment between translations and phrases
within parentheses in crawled webpages. They use
heuristics to align words and translations, while we
Token TR TL Distance Label
M 0 0 14 O
62 0 0 13 O
62th N 0 0 12 O
艾 3 0 11 B
Emmy X 3 0 10 I
Award 獎 0 5 9 I
頒 0 0 8 O
awarding 獎 0 0 7 O
A 0 0 6 O
ceremony iTt 0 0 5 O
》 0 0 4 O
( 0 0 3 O
the 0 0 2 O
62th 0 0 1 O
Emmy 0 0 0 E
Award 0 0 0 E
) 0 0 -1 O
</bodyText>
<figureCaption confidence="0.998552">
Figure 1. Example training data.
</figureCaption>
<bodyText confidence="0.9872014">
use a learning based approach to find translations.
In contrast to previous work described above,
we exploit surface patterns differently as a soft
constraint, while requiring minimal human
intervention to prepare the training data.
</bodyText>
<sectionHeader confidence="0.981659" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.9999906">
To find translations for a given term on the Web, a
promising approach is automatically learning to
extract phrasal translations or transliterations of
phrase based on machine learning, or more
specifically the conditional random fields (CRF)
model.
We focus on the issue of finding translations in
mixed code snippets returned by a search engine.
The translations are identified, tallied, ranked, and
returned as the output of the system.
</bodyText>
<subsectionHeader confidence="0.999877">
3.1 Preparing Data for CRF Classifier
</subsectionHeader>
<bodyText confidence="0.999794222222222">
We make use a small set of term and translation
pairs as seed data to retrieve and annotate mixed-
code snippets from a search engine. Features are
generated based on other external knowledge
sources as will be described in Section 3.1.2 and
3.1.3. An example data generated with given term
Emmy Award with features and translation/non-
translation labels is shown in Figure 1 using the
common BIO notation.
</bodyText>
<listItem confidence="0.597825">
3.1.1 Retrieving and tagging snippets. We use a
list of randomly selected source and target terms as
seed data (e.g., Wikipedia English titles and their
</listItem>
<page confidence="0.993592">
131
</page>
<bodyText confidence="0.998840533333333">
Chinese counterpart using the language links). We
use the English terms (e.g., Emmy Awards) to
query a search engine with the target webpage
language set to the target language (e.g., Chinese),
biasing the search engine to return Chinese
webpages interspersed with some English phrases.
We then automatically label each Chinese
character of the returned snippets, with B, I, O
indicating respectively beginning, inside, and
outside of translations. In Figure 1, the translation
艾美獎 (ai mei jiang) are labeled as B I I, while all
other Chinese characters are labeled as O. An
additional tag of E is used to indicate the
occurrences of the given term (e.g., Emmy Awards
in Figure 1).
</bodyText>
<subsubsectionHeader confidence="0.954529">
3.1.2 Generating translation feature. We
</subsubsectionHeader>
<bodyText confidence="0.997761181818182">
generate translation features using external
bilingual resources. The φ2 score proposed by Gale
and Church (1991) is used to measure the
correlations between English and Chinese tokens:
where e is an English word and f is a Chinese
character. The scores are calculated by counting
co-occurrence of Chinese characters and English
words in bilingual dictionaries or termbanks,
where P(e, f) represents the probability of the co-
occurrence of English word e and Chinese
character f, and P(e, ̅f) represents the probability
the co-occurrence of e and any Chinese characters
excluding f.
We used the publicly available English-Chinese
Bilingual WordNet and NICT terminology bank to
generate translation features in our
implementation. The bilingual WordNet has
99,642 synset entries, with a total of some 270,000
translation pairs, mainly common nouns. The
NICT database has over 1.1 million bilingual terms
in 72 categories, covering a wide variety of
different fields.
</bodyText>
<subsubsectionHeader confidence="0.865921">
3.1.3 Generating transliteration feature. Since
</subsubsectionHeader>
<bodyText confidence="0.999618192307693">
many terms are transliterated, it is important to
include transliteration feature. We first use a list of
name transliterated pairs, then use Expectation-
Maximization (EM) algorithm to align English
syllables Romanized Chinese characters. Finally,
we use the alignment information to generate
transliteration feature for a Chinese token with
respect to English words in the query.
We extract person or location entries in
Wikipedia as name transliterated pairs to generate
transliteration features in our implementation. This
can be achieved by examining the Wikipedia
categories for each entry. A total of some 15,000
bilingual names of persons and 24,000 bilingual
place names were obtained and forced aligned to
obtain transliteration relationships.
3.1.4 Generating distance feature. In the final
stage of preparing training data, we add the
distance, i.e. number of words, between a Chinese
token feature and the English term in question,
aimed at exploiting the fact that translations tend to
occur near the source term, as noted in Nagata et
al. (2001) and Wu et al. (2005).
Finally, we use the data labeled with translation
tags and three kinds feature values to train a CRF
model.
</bodyText>
<subsectionHeader confidence="0.998669">
3.2 Run-Time Translation Extraction
</subsectionHeader>
<bodyText confidence="0.9999795">
With the trained CRF model, we then attempt to
find translations for a given phrase. The system
begins by submitting the given phrase as query to a
search engine to retrieve snippets, and generate
features for each tokens in the same way as done in
the training phase. We then use the trained model
to tag the snippets, and extract translation
candidates by identifying consecutive Chinese
tokens labeled as B and I.
Finally, we compute the frequency of all the
candidates identified in all snippets, and output the
one with the highest frequency.
</bodyText>
<sectionHeader confidence="0.997186" genericHeader="evaluation">
4 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.999968375">
We extracted the Wikipedia titles of English and
Chinese articles connected through language links
for training and testing. We obtained a total of
155,310 article pairs, from which we then
randomly selected 13,150 and 2,181 titles as seeds
to obtain the training and test data. Since we are
using Wikipedia bilingual titles as the gold
standard, we exclude any snippets from the
wikipedia.org domain, so that we are not using
Wikipedia article content in both training and
testing stage. The test set contains 745,734
snippets or 9,158,141 tokens (Chinese character or
English word). The reference answer appeared a
total of 48,938 times or 180,932 tokens (2%), and
an average of 22.4 redundant answer instances per
input.
</bodyText>
<page confidence="0.995993">
132
</page>
<table confidence="0.969808888888889">
System Coverage Exact match Top5 exact match
Full (En-Ch) 80.4% 43.0% 56.4%
-TL 83.9% 27.5% 40.2%
-TR 81.2% 37.4% 50.3%
-TL-TR 83.2% 21.1% 32.8%
LIN En-Ch 59.6% 27.9% not reported
LIN Ch-En 70.8% 36.4% not reported
LCD (En-Ch) 10.8% 4.8% N/A
NICT (En-Ch) 24.2% 32.1% N/A
</table>
<tableCaption confidence="0.98552425">
Table 1. Automatic evaluation results of 8 experiments:
(1) Full system (2-4) -TL, -TR, -TL-TR : Full system
deprecating TL, TR, and TL+TL features (5,6) LIN En-
Ch and En-Ch : the results in Lin et al. (2008) (6) LDC:
</tableCaption>
<table confidence="0.949215166666667">
LDC E-C dictionary (7) NICT : NICT term bank.
English Wiki Chinese Wiki Extracted Ev.
Pope Celestine IV 塞萊斯廷四世 切萊斯廷四世 A
Fujian 福建省 福建 A
Waste 垃圾 廢物 A
Collateral 落日殺神 抵押 B
Ludwig Erhard 路德維希·艾哈德 艾哈德 P
Osman I 奧斯曼一世 奧斯曼 P
Bubble sort 冒泡排序 排序 P
The Love Suicides 曾根崎情死 夏目漱石 E
at Sonezaki
Ammonium 銨 過硫酸銨 E
</table>
<tableCaption confidence="0.998035">
Table 2. Cases failing the exact match test.
</tableCaption>
<table confidence="0.9551545">
Result Count Percentage
A+B: correct 53 55.8%
P: partially corr. 30 31.6%
E: incorrect 8 8.4%
N: no results 4 4.2%
total 95 100%
</table>
<tableCaption confidence="0.999481">
Table 3. Manual evaluation of unlink titles.
</tableCaption>
<bodyText confidence="0.999951666666667">
To compare our method with previous work, we
used a similar evaluation procedure as described in
Lin et al. (2008). We ran the system and produced
the translations for these 2,181 test data, and
automatically evaluate the results using the metrics
of coverage, i.e. when system was able to produce
translation candidates, and exact match precision.
This precision rate is an under-estimations, since
a term may have many alternative translations that
does not match exactly with one single reference
translation. To give a more accurate estimate of
real precision, we resorted to manual evaluation on
a small part of the 2,181 English phrases and a
small set of English Wikipedia titles without a
Chinese language link.
</bodyText>
<subsectionHeader confidence="0.998452">
4.1 Automatic Evaluation
</subsectionHeader>
<bodyText confidence="0.99997665">
In this section, we describe the evaluation based on
English-Chinese titles extracted from Wikipedia as
the gold standard. Our system produce the top-1
translations by ranking candidates by frequency
and output the most frequent translations. Table 1
shows the results we have obtained as compared to
the results of Lin et al. (2008).
Table 1 shows the evaluation results of 8
experiments. The results indicate that using
external knowledge to generate feature improves
system performance significantly. By adding
translation feature (TL) or transliteration feature
(TR) to the system with no external knowledge
features (-TL-TR) improves exact match precision
by about 6% and 16% respectively. Because many
Wikipedia titles are named entities, transliteration
feature is the most important. Overall, the system
with full features perform the best, finding
reasonably correct translations for 8 out of 10
phrases.
</bodyText>
<subsectionHeader confidence="0.997335">
4.2 Manual Evaluation
</subsectionHeader>
<bodyText confidence="0.999941583333333">
Evaluation based on exact match against a single
reference answer leads to under-estimation,
because an English phrase is often translated into
several Chinese counterparts. Therefore, we asked
a human judge to examine and mark the outputs of
our full system. The judge was instructed to mark
each output as A: correct translation alternative, B:
correct translation but with a difference sense from
the reference, P: partially correct translation, and
E: incorrect translation.
Table 2 shows some translations generated by
the full system that does not match the single
reference translation. Half of the translations are
correct translations (A and B), while a third are
partially correct translation (P). Notice that it is a
common practice to translate only the surname of a
foreign person. Therefore, some partial translations
may still be considered as correct (B).
To Evaluate titles without a language link, we
sampled a list of 95 terms from the unlinked
portion of Wikipedia using the criteria: (1) with a
frequency count of over 2,000 in Google Web 1T.
(2) containing at least three English words. (3) not
a proper name. Table 3 shows the evaluation
</bodyText>
<page confidence="0.997136">
133
</page>
<bodyText confidence="0.999606666666667">
results. Interestingly, our system provides correct
translations for over 50% of the cases, and at least
partially correct almost 90% of the cases.
</bodyText>
<sectionHeader confidence="0.976855" genericHeader="conclusions">
5 Conclusion and Future work
</sectionHeader>
<bodyText confidence="0.999979863636364">
We have presented a new method for finding
translations on the Web for a given term. In our
approach, we use a small set of terms and
translations as seeds to obtain and to tag mixed-
code snippets returned by a search engine, in order
to train a CRF model for sequence labels. This
CRF model is then used to tag the returned
snippets for a given query term to extraction
translation candidates, which are then ranked and
returned as output. Preliminary experiments and
evaluations show our learning-based method
cleanly combining various features, producing
quality translations and transliterations.
Many avenues exist for future research and
improvement. For example, existing query
expansion methods could be implemented to
retrieve more webpages containing translations.
Additionally, an interesting direction to explore is
to identify phrase types and train type-specific
CRF model. In addition, natural language
processing techniques such as word stemming and
word lemmatization could be attempted.
</bodyText>
<sectionHeader confidence="0.998525" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999769885714286">
G. W. Bian, H. H. Chen. Cross-language information
access to multilingual collections on the internet.
2000. Journal of American Society for Information
Science &amp; Technology (JASIST), Special Issue on
Digital Libraries, 51(3), pp.281-296, 2000.
Y. Cao and H. Li. Base Noun Phrase Translation Using
Web Data and the EM Algorithm. 2002. In
Proceedings of the 19th International Conference on
Computational Linguistics (COLING’02), pp.127-
133, 2002.
P. J. Cheng, J. W. Teng, R. C. Chen, J. H. Wang, W. H.
Lu, and L. F. Chien. Translating unknown queries
with web corpora for cross-language information
retrieval. In Proceedings of the 27th ACM
International Conference on Research and
Development in Information Retrieval, pp.146-153,
2004.
F. Huang, S. Vogel, and A. Waibel. Automatic
extraction of named entity translingual equivalence
based on multi-feature cost minimization. In
Proceeding of the 41st ACL, Workshop on
Multilingual and Mixed-Language Named Entity
Recognition, Sapporo, 2003.
K. Knight, J. Graehl. Machine Transliteration. 1998.
Computational Linguistics 24(4), pp.599-612, 1998.
P. Koehn, K. Knight. 2003. Feature-Rich Statistical
Translation of Noun Phrases. In Proceedings of the
41st Annual Meeting on Association for
Computational Linguistics, pp. 311-318, 2003.
J. Kupiec. 1993. An Algorithm for Finding Noun Phrase
Correspondences in Bilingual Corpora. In
Proceedings of the 31st Annual Meeting of the
Association for Computational Linguistics, pp. 17-
22, 1993.
KL Kwok, P Deng, N Dinstl, HL Sun, W Xu, P Peng,
and Doyon, J. 2005. CHINET: a Chinese name finder
system for document triage. In Proceedings of 2005
D. Lin, S. Zhao, B.V. Durme, and M. Paşca. 2008.
Mining Parenthetical Translation from the Web by
Word Alignment, In Proceedings of ACL 2008, pp.
994-1002, 2008.
Y. Li, G. Grefenstette. 2005. Translating Chinese
Romanized name into Chinese idiographic characters
via corpus and web validation. In Proceedings of
CORIA 2005, pp. 323-338, 2005.
M. Nagata, T. Saito, and K. Suzuki. Using the Web as a
bilingual dictionary. 2001. In Proceedings of 39th.
ACL Workshop on Data-Driven Methods in Machine
Translation, pp. 95-102, 2001.
Y. Qu, and G. Grefenstette. 2004. Finding Ideographic
Representations of Japanese Names Written in Latin
Script via Language Identification and Corpus
Validation. In Proceedings of the 42nd Annual
Meeting of the Association for Computational
Linguistics, pp.183-190, 2004.
CK Quah. 2006. Translation and Technology, Palgrave
Textbooks in Translation and Interpretation, Palgrave
MacMillan.
R Sproat and C Shih. Statistical Method for Finding
Word Boundaries in Chinese Text, Computer
Processing of Chinese and Oriental languages. 1990.
J. C. Wu, T. Lin and J. S. Chang. Learning Source-
Target Surface Patterns for Web-based Terminology
Translation. In Proceeding of the ACL 2005 on
Interactive poster and demonstration sessions
(ACLdemo &apos;05). 2005.
Y Zhang, F Huang, S Vogel. 2005. Mining translations
of OOV terms from the web through cross-lingual
query expansion. In Proceedings of the 28th Annual
International ACM SIGIR, pp.669-670, 2005.
</reference>
<page confidence="0.998631">
134
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.968235">
<title confidence="0.999375">Learning to Find Translations and Transliterations on the Web</title>
<author confidence="0.999995">Joseph Z Chang Jason S Chang Jyh-Shing Roger Jang</author>
<affiliation confidence="0.9995505">Department of Computer Science, Department of Computer Science, Department of Computer Science, National Tsing Hua University National Tsing Hua University National Tsing Hua University</affiliation>
<address confidence="0.996939">101, Kuangfu Road, 101, Kuangfu Road, 101, Kuangfu Road, Hsinchu, 300, Taiwan Hsinchu, 300, Taiwan Hsinchu, 300, Taiwan</address>
<email confidence="0.978606">joseph.nthu.tw@gmail.comjschang@cs.nthu.edu.twjang@cs.nthu.edu.tw</email>
<abstract confidence="0.9997921875">In this paper, we present a new method for learning to finding translations and transliterations on the Web for a given approach involves using a small set of terms and translations to obtain mixed-code snippets from a search engine, and automatically annotating the snippets with tags and features for training a conditional random field model. At runtime, the model is used to extracting translation candidates for a given term. Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G W Bian</author>
<author>H H Chen</author>
</authors>
<title>Cross-language information access to multilingual collections on the internet.</title>
<date>2000</date>
<journal>Journal of American Society for Information Science &amp; Technology (JASIST), Special Issue on Digital Libraries,</journal>
<volume>51</volume>
<issue>3</issue>
<pages>281--296</pages>
<contexts>
<context position="1250" citStr="Bian and Chen 2000" startWordPosition="172" endWordPosition="175">ach involves using a small set of terms and translations to obtain mixed-code snippets from a search engine, and automatically annotating the snippets with tags and features for training a conditional random field model. At runtime, the model is used to extracting translation candidates for a given term. Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work. 1 Introduction The phrase translation problem is critical to machine translation, cross-lingual information retrieval, and multilingual terminology (Bian and Chen 2000, Kupiec 1993). Such systems typically use a parallel corpus. However, the out of vocabulary problem (OOV) is hard to overcome even with a very large training corpus due to the Zipf nature of word distribution, and ever growing new terminology and named entities. Luckily, there are an abundant of webpages consisting mixed-code text, typically written in one language but interspersed with some sentential or phrasal translations in another language. By retrieving and identifying such translation counterparts on the Web, we can cope with the OOV problem. Consider the technical term named-entity r</context>
<context position="4558" citStr="Bian and Chen (2000)" startWordPosition="660" endWordPosition="663">. The system can potentially be used to assist translators to find the most common translation for a given term, or to supplement a bilingual terminology bank (e.g., adding multilingual titles to existing Wikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperl</context>
</contexts>
<marker>Bian, Chen, 2000</marker>
<rawString>G. W. Bian, H. H. Chen. Cross-language information access to multilingual collections on the internet. 2000. Journal of American Society for Information Science &amp; Technology (JASIST), Special Issue on Digital Libraries, 51(3), pp.281-296, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Cao</author>
<author>H Li</author>
</authors>
<title>Base Noun Phrase Translation Using Web Data and the EM Algorithm.</title>
<date>2002</date>
<booktitle>In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02),</booktitle>
<pages>127--133</pages>
<marker>Cao, Li, 2002</marker>
<rawString>Y. Cao and H. Li. Base Noun Phrase Translation Using Web Data and the EM Algorithm. 2002. In Proceedings of the 19th International Conference on Computational Linguistics (COLING’02), pp.127-133, 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Cheng</author>
<author>J W Teng</author>
<author>R C Chen</author>
<author>J H Wang</author>
<author>W H Lu</author>
<author>L F Chien</author>
</authors>
<title>Translating unknown queries with web corpora for cross-language information retrieval.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th ACM International Conference on Research and Development in Information Retrieval,</booktitle>
<pages>146--153</pages>
<contexts>
<context position="5308" citStr="Cheng, et al (2004)" startWordPosition="772" endWordPosition="775">t mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown queries with web corpora for cross-language information retrieval. Gravano (2006) also propose similar methods using anchor texts. In a study more closely related to our work, Lin et al. (2008) proposed a method that performs word alignment between translations and phrases within parentheses in crawled webpages. They use heuristics to align words and translations, while we Token TR TL Distance Label M 0 0 14 O 62 0 0 13 O 62th N 0 0 12 O 艾 3 0 11 B Emmy X 3 0 10 I Award 獎 0 5 9 I 頒 0 0 8 O awarding 獎 0 0 7 O A 0 0 6 O ceremony iTt 0 0 5 O 》 0 0</context>
</contexts>
<marker>Cheng, Teng, Chen, Wang, Lu, Chien, 2004</marker>
<rawString>P. J. Cheng, J. W. Teng, R. C. Chen, J. H. Wang, W. H. Lu, and L. F. Chien. Translating unknown queries with web corpora for cross-language information retrieval. In Proceedings of the 27th ACM International Conference on Research and Development in Information Retrieval, pp.146-153, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Huang</author>
<author>S Vogel</author>
<author>A Waibel</author>
</authors>
<title>Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization.</title>
<date>2003</date>
<booktitle>In Proceeding of the 41st ACL, Workshop on Multilingual and Mixed-Language Named Entity Recognition,</booktitle>
<location>Sapporo,</location>
<marker>Huang, Vogel, Waibel, 2003</marker>
<rawString>F. Huang, S. Vogel, and A. Waibel. Automatic extraction of named entity translingual equivalence based on multi-feature cost minimization. In Proceeding of the 41st ACL, Workshop on Multilingual and Mixed-Language Named Entity Recognition, Sapporo, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>Machine Transliteration.</title>
<date>1998</date>
<journal>Computational Linguistics</journal>
<volume>24</volume>
<issue>4</issue>
<pages>599--612</pages>
<contexts>
<context position="4414" citStr="Knight and Graehl (1998)" startWordPosition="640" endWordPosition="643">age (e.g., Chinese) using the advance search function. Subsequently, we retrieve mixed-code snippets and identify the translations of the given term. The system can potentially be used to assist translators to find the most common translation for a given term, or to supplement a bilingual terminology bank (e.g., adding multilingual titles to existing Wikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder.</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight, J. Graehl. Machine Transliteration. 1998. Computational Linguistics 24(4), pp.599-612, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>K Knight</author>
</authors>
<title>Feature-Rich Statistical Translation of Noun Phrases.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<marker>Koehn, Knight, 2003</marker>
<rawString>P. Koehn, K. Knight. 2003. Feature-Rich Statistical Translation of Noun Phrases. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pp. 311-318, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
</authors>
<title>An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora.</title>
<date>1993</date>
<booktitle>In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>17--22</pages>
<contexts>
<context position="1264" citStr="Kupiec 1993" startWordPosition="176" endWordPosition="177"> small set of terms and translations to obtain mixed-code snippets from a search engine, and automatically annotating the snippets with tags and features for training a conditional random field model. At runtime, the model is used to extracting translation candidates for a given term. Preliminary experiments and evaluation show our method cleanly combining various features, resulting in a system that outperforms previous work. 1 Introduction The phrase translation problem is critical to machine translation, cross-lingual information retrieval, and multilingual terminology (Bian and Chen 2000, Kupiec 1993). Such systems typically use a parallel corpus. However, the out of vocabulary problem (OOV) is hard to overcome even with a very large training corpus due to the Zipf nature of word distribution, and ever growing new terminology and named entities. Luckily, there are an abundant of webpages consisting mixed-code text, typically written in one language but interspersed with some sentential or phrasal translations in another language. By retrieving and identifying such translation counterparts on the Web, we can cope with the OOV problem. Consider the technical term named-entity recognition. Th</context>
</contexts>
<marker>Kupiec, 1993</marker>
<rawString>J. Kupiec. 1993. An Algorithm for Finding Noun Phrase Correspondences in Bilingual Corpora. In Proceedings of the 31st Annual Meeting of the Association for Computational Linguistics, pp. 17-22, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>KL Kwok</author>
<author>P Deng</author>
<author>N Dinstl</author>
<author>HL Sun</author>
<author>W Xu</author>
<author>P Peng</author>
<author>J Doyon</author>
</authors>
<title>CHINET: a Chinese name finder system for document triage.</title>
<date>2005</date>
<booktitle>In Proceedings of</booktitle>
<contexts>
<context position="4930" citStr="Kwok et al. (2005)" startWordPosition="713" endWordPosition="716">ation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown queries with web corpora for cross-language information retrieval. Gravano (2006) also propose similar methods using anchor texts. In a study more closely related to our wo</context>
</contexts>
<marker>Kwok, Deng, Dinstl, Sun, Xu, Peng, Doyon, 2005</marker>
<rawString>KL Kwok, P Deng, N Dinstl, HL Sun, W Xu, P Peng, and Doyon, J. 2005. CHINET: a Chinese name finder system for document triage. In Proceedings of 2005</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>S Zhao</author>
<author>B V Durme</author>
<author>M Paşca</author>
</authors>
<title>Mining Parenthetical Translation from the Web by Word Alignment,</title>
<date>2008</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>994--1002</pages>
<contexts>
<context position="4282" citStr="Lin et al. (2008)" startWordPosition="622" endWordPosition="625">stem accepts a given phrase (e.g., named-entity recognition), and then query a search engine for webpages in the target language (e.g., Chinese) using the advance search function. Subsequently, we retrieve mixed-code snippets and identify the translations of the given term. The system can potentially be used to assist translators to find the most common translation for a given term, or to supplement a bilingual terminology bank (e.g., adding multilingual titles to existing Wikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets</context>
<context position="5551" citStr="Lin et al. (2008)" startWordPosition="809" endWordPosition="812">us on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown queries with web corpora for cross-language information retrieval. Gravano (2006) also propose similar methods using anchor texts. In a study more closely related to our work, Lin et al. (2008) proposed a method that performs word alignment between translations and phrases within parentheses in crawled webpages. They use heuristics to align words and translations, while we Token TR TL Distance Label M 0 0 14 O 62 0 0 13 O 62th N 0 0 12 O 艾 3 0 11 B Emmy X 3 0 10 I Award 獎 0 5 9 I 頒 0 0 8 O awarding 獎 0 0 7 O A 0 0 6 O ceremony iTt 0 0 5 O 》 0 0 4 O ( 0 0 3 O the 0 0 2 O 62th 0 0 1 O Emmy 0 0 0 E Award 0 0 0 E ) 0 0 -1 O Figure 1. Example training data. use a learning based approach to find translations. In contrast to previous work described above, we exploit surface patterns differ</context>
<context position="12044" citStr="Lin et al. (2008)" startWordPosition="1895" endWordPosition="1898">reference answer appeared a total of 48,938 times or 180,932 tokens (2%), and an average of 22.4 redundant answer instances per input. 132 System Coverage Exact match Top5 exact match Full (En-Ch) 80.4% 43.0% 56.4% -TL 83.9% 27.5% 40.2% -TR 81.2% 37.4% 50.3% -TL-TR 83.2% 21.1% 32.8% LIN En-Ch 59.6% 27.9% not reported LIN Ch-En 70.8% 36.4% not reported LCD (En-Ch) 10.8% 4.8% N/A NICT (En-Ch) 24.2% 32.1% N/A Table 1. Automatic evaluation results of 8 experiments: (1) Full system (2-4) -TL, -TR, -TL-TR : Full system deprecating TL, TR, and TL+TL features (5,6) LIN EnCh and En-Ch : the results in Lin et al. (2008) (6) LDC: LDC E-C dictionary (7) NICT : NICT term bank. English Wiki Chinese Wiki Extracted Ev. Pope Celestine IV 塞萊斯廷四世 切萊斯廷四世 A Fujian 福建省 福建 A Waste 垃圾 廢物 A Collateral 落日殺神 抵押 B Ludwig Erhard 路德維希·艾哈德 艾哈德 P Osman I 奧斯曼一世 奧斯曼 P Bubble sort 冒泡排序 排序 P The Love Suicides 曾根崎情死 夏目漱石 E at Sonezaki Ammonium 銨 過硫酸銨 E Table 2. Cases failing the exact match test. Result Count Percentage A+B: correct 53 55.8% P: partially corr. 30 31.6% E: incorrect 8 8.4% N: no results 4 4.2% total 95 100% Table 3. Manual evaluation of unlink titles. To compare our method with previous work, we used a similar evaluati</context>
<context position="13654" citStr="Lin et al. (2008)" startWordPosition="2168" endWordPosition="2171">atch exactly with one single reference translation. To give a more accurate estimate of real precision, we resorted to manual evaluation on a small part of the 2,181 English phrases and a small set of English Wikipedia titles without a Chinese language link. 4.1 Automatic Evaluation In this section, we describe the evaluation based on English-Chinese titles extracted from Wikipedia as the gold standard. Our system produce the top-1 translations by ranking candidates by frequency and output the most frequent translations. Table 1 shows the results we have obtained as compared to the results of Lin et al. (2008). Table 1 shows the evaluation results of 8 experiments. The results indicate that using external knowledge to generate feature improves system performance significantly. By adding translation feature (TL) or transliteration feature (TR) to the system with no external knowledge features (-TL-TR) improves exact match precision by about 6% and 16% respectively. Because many Wikipedia titles are named entities, transliteration feature is the most important. Overall, the system with full features perform the best, finding reasonably correct translations for 8 out of 10 phrases. 4.2 Manual Evaluati</context>
</contexts>
<marker>Lin, Zhao, Durme, Paşca, 2008</marker>
<rawString>D. Lin, S. Zhao, B.V. Durme, and M. Paşca. 2008. Mining Parenthetical Translation from the Web by Word Alignment, In Proceedings of ACL 2008, pp. 994-1002, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Li</author>
<author>G Grefenstette</author>
</authors>
<title>Translating Chinese Romanized name into Chinese idiographic characters via corpus and web validation.</title>
<date>2005</date>
<booktitle>In Proceedings of CORIA</booktitle>
<pages>323--338</pages>
<marker>Li, Grefenstette, 2005</marker>
<rawString>Y. Li, G. Grefenstette. 2005. Translating Chinese Romanized name into Chinese idiographic characters via corpus and web validation. In Proceedings of CORIA 2005, pp. 323-338, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nagata</author>
<author>T Saito</author>
<author>K Suzuki</author>
</authors>
<title>Using the Web as a bilingual dictionary.</title>
<date>2001</date>
<booktitle>In Proceedings of 39th. ACL Workshop on Data-Driven Methods in Machine Translation,</booktitle>
<pages>95--102</pages>
<contexts>
<context position="4764" citStr="Nagata et al. (2001)" startWordPosition="688" endWordPosition="691">ikipedia); alternatively, they can be used as additional training data for a machine translation system, as described in Lin et al. (2008). 2 Related Work Phrase translation and transliteration is important for cross-language tasks. For example, Knight and Graehl (1998) describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown querie</context>
<context position="10094" citStr="Nagata et al. (2001)" startWordPosition="1569" endWordPosition="1572"> transliterated pairs to generate transliteration features in our implementation. This can be achieved by examining the Wikipedia categories for each entry. A total of some 15,000 bilingual names of persons and 24,000 bilingual place names were obtained and forced aligned to obtain transliteration relationships. 3.1.4 Generating distance feature. In the final stage of preparing training data, we add the distance, i.e. number of words, between a Chinese token feature and the English term in question, aimed at exploiting the fact that translations tend to occur near the source term, as noted in Nagata et al. (2001) and Wu et al. (2005). Finally, we use the data labeled with translation tags and three kinds feature values to train a CRF model. 3.2 Run-Time Translation Extraction With the trained CRF model, we then attempt to find translations for a given phrase. The system begins by submitting the given phrase as query to a search engine to retrieve snippets, and generate features for each tokens in the same way as done in the training phase. We then use the trained model to tag the snippets, and extract translation candidates by identifying consecutive Chinese tokens labeled as B and I. Finally, we comp</context>
</contexts>
<marker>Nagata, Saito, Suzuki, 2001</marker>
<rawString>M. Nagata, T. Saito, and K. Suzuki. Using the Web as a bilingual dictionary. 2001. In Proceedings of 39th. ACL Workshop on Data-Driven Methods in Machine Translation, pp. 95-102, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Qu</author>
<author>G Grefenstette</author>
</authors>
<title>Finding Ideographic Representations of Japanese Names Written in Latin Script via Language Identification and Corpus Validation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<marker>Qu, Grefenstette, 2004</marker>
<rawString>Y. Qu, and G. Grefenstette. 2004. Finding Ideographic Representations of Japanese Names Written in Latin Script via Language Identification and Corpus Validation. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pp.183-190, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CK Quah</author>
</authors>
<title>Translation and Technology, Palgrave Textbooks in Translation and Interpretation,</title>
<date>2006</date>
<publisher>Palgrave MacMillan.</publisher>
<marker>Quah, 2006</marker>
<rawString>CK Quah. 2006. Translation and Technology, Palgrave Textbooks in Translation and Interpretation, Palgrave MacMillan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sproat</author>
<author>C Shih</author>
</authors>
<title>Statistical Method for Finding Word Boundaries</title>
<date>1990</date>
<booktitle>in Chinese Text, Computer Processing of Chinese and Oriental languages.</booktitle>
<marker>Sproat, Shih, 1990</marker>
<rawString>R Sproat and C Shih. Statistical Method for Finding Word Boundaries in Chinese Text, Computer Processing of Chinese and Oriental languages. 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Wu</author>
<author>T Lin</author>
<author>J S Chang</author>
</authors>
<title>Learning SourceTarget Surface Patterns for Web-based Terminology Translation.</title>
<date>2005</date>
<booktitle>In Proceeding of the ACL 2005 on Interactive poster and demonstration sessions (ACLdemo &apos;05).</booktitle>
<contexts>
<context position="5031" citStr="Wu et al. (2005)" startWordPosition="728" endWordPosition="731">describe and evaluate a multi-stage machine translation method for back transliterating English names into Japanese, while Bian and Chen (2000) describe cross-language information access to multilingual collections on the Internet. Recently, researchers have begun to exploit mixed code webpages for word and phrase translation. Nagata et al. (2001) present a system for finding English translations for a given Japanese technical term using Japanese-English snippets returned by a search engine. Kwok et al. (2005) focus on named entity transliteration and implemented a cross-language name finder. Wu et al. (2005) proposed a method to learn surface patterns to find translations in mixed code snippets. Some researchers exploited the hyperlinks in Webpage to find translations. Lu, et al. (2004) propose a method for mining translations of web queries from anchor texts. Cheng, et al (2004) propose a similar method for translating unknown queries with web corpora for cross-language information retrieval. Gravano (2006) also propose similar methods using anchor texts. In a study more closely related to our work, Lin et al. (2008) proposed a method that performs word alignment between translations and phrases</context>
<context position="10115" citStr="Wu et al. (2005)" startWordPosition="1574" endWordPosition="1577">generate transliteration features in our implementation. This can be achieved by examining the Wikipedia categories for each entry. A total of some 15,000 bilingual names of persons and 24,000 bilingual place names were obtained and forced aligned to obtain transliteration relationships. 3.1.4 Generating distance feature. In the final stage of preparing training data, we add the distance, i.e. number of words, between a Chinese token feature and the English term in question, aimed at exploiting the fact that translations tend to occur near the source term, as noted in Nagata et al. (2001) and Wu et al. (2005). Finally, we use the data labeled with translation tags and three kinds feature values to train a CRF model. 3.2 Run-Time Translation Extraction With the trained CRF model, we then attempt to find translations for a given phrase. The system begins by submitting the given phrase as query to a search engine to retrieve snippets, and generate features for each tokens in the same way as done in the training phase. We then use the trained model to tag the snippets, and extract translation candidates by identifying consecutive Chinese tokens labeled as B and I. Finally, we compute the frequency of </context>
</contexts>
<marker>Wu, Lin, Chang, 2005</marker>
<rawString>J. C. Wu, T. Lin and J. S. Chang. Learning SourceTarget Surface Patterns for Web-based Terminology Translation. In Proceeding of the ACL 2005 on Interactive poster and demonstration sessions (ACLdemo &apos;05). 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>F Huang</author>
<author>S Vogel</author>
</authors>
<title>Mining translations of OOV terms from the web through cross-lingual query expansion.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th Annual International ACM SIGIR,</booktitle>
<pages>669--670</pages>
<marker>Zhang, Huang, Vogel, 2005</marker>
<rawString>Y Zhang, F Huang, S Vogel. 2005. Mining translations of OOV terms from the web through cross-lingual query expansion. In Proceedings of the 28th Annual International ACM SIGIR, pp.669-670, 2005.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>