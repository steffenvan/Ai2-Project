<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000147">
<title confidence="0.997264">
Bipartite spectral graph partitioning to co-cluster varieties and sound
correspondences in dialectology
</title>
<author confidence="0.988959">
Martijn Wieling
</author>
<affiliation confidence="0.845257">
University of Groningen
The Netherlands
</affiliation>
<email confidence="0.993175">
m.b.wieling@rug.nl
</email>
<sectionHeader confidence="0.993723" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914">
In this study we used bipartite spectral
graph partitioning to simultaneously clus-
ter varieties and sound correspondences
in Dutch dialect data. While cluster-
ing geographical varieties with respect to
their pronunciation is not new, the simul-
taneous identification of the sound corre-
spondences giving rise to the geographi-
cal clustering presents a novel opportunity
in dialectometry. Earlier methods aggre-
gated sound differences and clustered on
the basis of aggregate differences. The de-
termination of the significant sound corre-
spondences which co-varied with cluster
membership was carried out on a post hoc
basis. Bipartite spectral graph clustering
simultaneously seeks groups of individual
sound correspondences which are associ-
ated, even while seeking groups of sites
which share sound correspondences. We
show that the application of this method
results in clear and sensible geographi-
cal groupings and discuss the concomitant
sound correspondences.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997017846153846">
Exact methods have been applied successfully to
the analysis of dialect variation for over three
decades (S´eguy, 1973; Goebl, 1982; Nerbonne
et al., 1999), but they have invariably functioned
by first probing the linguistic differences between
each pair of a range of varieties (sites, such as
Whitby and Bristol in the UK) over a body of
carefully controlled material (say the pronuncia-
tion of the vowel in the word ‘put’). Second, the
techniques AGGREGATE over these linguistic dif-
ferences, in order, third, to seek the natural groups
in the data via clustering or multidimensional scal-
ing (MDS) (Nerbonne, 2009).
</bodyText>
<author confidence="0.875317">
John Nerbonne
</author>
<affiliation confidence="0.7803305">
University of Groningen
The Netherlands
</affiliation>
<email confidence="0.969162">
j.nerbonne@rug.nl
</email>
<bodyText confidence="0.999960658536586">
Naturally techniques have been developed to
determine which linguistic variables weigh most
heavily in determining affinity among varieties.
But all of the following studies separate the deter-
mination of varietal relatedness from the question
of its detailed linguistic basis. Kondrak (2002)
adapted a machine translation technique to deter-
mine which sound correspondences occur most
regularly. His focus was not on dialectology, but
rather on diachronic phonology, where the regular
sound correspondences are regarded as strong ev-
idence of historical relatedness. Heeringa (2004:
268–270) calculated which words correlated best
with the first, second and third dimensions of an
MDS analysis of aggregate pronunciation differ-
ences. Shackleton (2004) used a database of ab-
stract linguistic differences in trying to identify
the British sources of American patterns of speech
variation. He applied principal component analy-
sis to his database to identify the common com-
ponents among his variables. Nerbonne (2006)
examined the distance matrices induced by each
of two hundred vowel pronunciations automati-
cally extracted from a large American collection,
and subsequently applied factor analysis to the co-
variance matrices obtained from the collection of
vowel distance matrices. Proki´c (2007) analyzed
Bulgarian pronunciation using an edit distance
algorithm and then collected commonly aligned
sounds. She developed an index to measure how
characteristic a given sound correspondence is for
a given site.
To study varietal relatedness and its linguistic
basis in parallel, we apply bipartite spectral graph
partitioning. Dhillon (2001) was the first to use
spectral graph partitioning on a bipartite graph
of documents and words, effectively clustering
groups of documents and words simultaneously.
Consequently, every document cluster has a direct
connection to a word cluster; the document clus-
tering implies a word clustering and vice versa. In
</bodyText>
<page confidence="0.990531">
14
</page>
<note confidence="0.9997165">
Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 14–22,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999346133333334">
his study, Dhillon (2001) also demonstrated that
his algorithm worked well on real world examples.
The usefulness of this approach is not only lim-
ited to clustering documents and words simulta-
neously. For example, Kluger et al. (2003) used
a somewhat adapted bipartite spectral graph parti-
tioning approach to successfully cluster microar-
ray data simultaneously in clusters of genes and
conditions.
In summary, the contribution of this paper is to
apply a graph-theoretic technique, bipartite spec-
tral graph partitioning, to a new sort of data,
namely dialect pronunciation data, in order to
solve an important problem, namely how to rec-
ognize groups of varieties in this sort of data while
simultaneously characterizing the linguistic basis
of the group. It is worth noting that, in isolat-
ing the linguistic basis of varietal affinities, we
thereby hope to contribute technically to the study
of how cognitive and social dynamics interact in
language variation. Although we shall not pursue
this explicitly in the present paper, our idea is very
simple. The geographic signal in the data is a re-
flection of the social dynamics, where geographic
distance is the rough operationalization of social
contact. In fact, dialectometry is already success-
ful in studying this. We apply techniques to extract
(social) associations among varieties and (linguis-
tic) associations among the speech habits which
the similar varieties share. The latter, linguistic
associations are candidates for cognitive explana-
tion. Although this paper cannot pursue the cogni-
tive explanation, it will provide the material which
a cognitive account might seek to explain.
The remainder of the paper is structured as fol-
lows. Section 2 presents the material we studied,
a large database of contemporary Dutch pronunci-
ations. Section 3 presents the methods, both the
alignment technique used to obtain sound corre-
spondences, as well as the bipartite spectral graph
partitioning we used to simultaneously seek affini-
ties in varieties as well as affinities in sound corre-
spondences. Section 4 presents our results, while
Section 5 concludes with a discussion and some
ideas on avenues for future research.
</bodyText>
<sectionHeader confidence="0.99701" genericHeader="introduction">
2 Material
</sectionHeader>
<bodyText confidence="0.999848853658537">
In this study we use the most recent broad-
coverage Dutch dialect data source available: data
from the Goeman-Taeldeman-Van Reenen-project
(GTRP; Goeman and Taeldeman, 1996; Van den
Berg, 2003). The GTRP consists of digital tran-
scriptions for 613 dialect varieties in the Nether-
lands (424 varieties) and Belgium (189 varieties),
gathered during the period 1980–1995. For every
variety, a maximum of 1876 items was narrowly
transcribed according to the International Phonetic
Alphabet. The items consist of separate words and
phrases, including pronominals, adjectives and
nouns. A detailed overview of the data collection
is given in Taeldeman and Verleyen (1999).
Because the GTRP was compiled with a view
to documenting both phonological and morpho-
logical variation (De Schutter et al., 2005) and
our purpose here is the analysis of sound corre-
spondences, we ignore many items of the GTRP.
We use the same 562 item subset as introduced
and discussed in depth in Wieling et al. (2007).
In short, the 1876 item word list was filtered by
selecting only single word items, plural nouns
(the singular form was preceded by an article and
therefore not included), base forms of adjectives
instead of comparative forms and the first-person
plural verb instead of other forms. We omit words
whose variation is primarily morphological as we
wish to focus on sound correspondences. In all va-
rieties the same lexeme was used for a single item.
Because the GTRP transcriptions of Belgian
varieties are fundamentally different from tran-
scriptions of Netherlandic varieties (Wieling et al.,
2007), we will restrict our analysis to the 424
Netherlandic varieties. The geographic distribu-
tion of these varieties including province names
is shown in Figure 1. Furthermore, note that we
will not look at diacritics, but only at the 82 dis-
tinct phonetic symbols. The average length of ev-
ery item in the GTRP (without diacritics) is 4.7
tokens.
</bodyText>
<sectionHeader confidence="0.997677" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999768916666667">
To obtain the clearest signal of varietal differ-
ences in sound correspondences, we ideally want
to compare the pronunciations of each variety with
a single reference point. We might have used the
pronunciations of a proto-language for this pur-
pose, but these are not available. There are also no
pronunciations in standard Dutch in the GTRP and
transcribing the standard Dutch pronunciations
ourselves would likely have introduced between-
transcriber inconsistencies. Heeringa (2004: 274–
276) identified pronunciations in the variety of
Haarlem as being the closest to standard Dutch.
</bodyText>
<page confidence="0.98862">
15
</page>
<figureCaption confidence="0.979245">
Figure 1: Distribution of GTRP localities includ-
ing province names
</figureCaption>
<bodyText confidence="0.997929">
Because Haarlem was not included in the GTRP
varieties, we chose the transcriptions of Delft (also
close to standard Dutch) as our reference tran-
scriptions. See the discussion section for a con-
sideration of alternatives.
</bodyText>
<subsectionHeader confidence="0.999899">
3.1 Obtaining sound correspondences
</subsectionHeader>
<bodyText confidence="0.999968090909091">
To obtain the sound correspondences for every site
in the GTRP with respect to the reference site
Delft, we used an adapted version of the regular
Levenshtein algorithm (Levenshtein, 1965).
The Levenshtein algorithm aligns two (pho-
netic) strings by minimizing the number of edit
operations (i.e. insertions, deletions and substitu-
tions) required to transform one string into the
other. For example, the Levenshtein distance be-
tween [lEIk@n] and [likh8n], two Dutch variants of
the word ‘seem’, is 4:
</bodyText>
<equation confidence="0.9748392">
lEIk@n delete E 1
lIk@n subst. i/I 1
lik@n insert h 1
likh@n subst. 8/@ 1
likh8n
4
The corresponding alignment is:
l E I k @ n
l i k h 8 n
1 1 1 1
</equation>
<bodyText confidence="0.999809489795919">
When all edit operations have the same cost,
multiple alignments yield a Levenshtein distance
of 4 (i.e. by aligning the [i] with the [E] and/or by
aligning the [@] with the [h]). To obtain only the
best alignments we used an adaptation of the Lev-
enshtein algorithm which uses automatically gen-
erated segment substitution costs. This procedure
was proposed and described in detail by Wieling
et al. (2009) and resulted in significantly better in-
dividual alignments than using the regular Leven-
shtein algorithm.
In brief, the approach consists of obtaining ini-
tial string alignments by using the Levenshtein al-
gorithm with a syllabicity constraint: vowels may
only align with (semi-)vowels, and consonants
only with consonants, except for syllabic conso-
nants which may also be aligned with vowels. Af-
ter the initial run, the substitution cost of every
segment pair (a segment can also be a gap, rep-
resenting insertion and deletion) is calculated ac-
cording to a pointwise mutual information proce-
dure assessing the statistical dependence between
the two segments. I.e. if two segments are aligned
more often than would be expected on the basis of
their frequency in the dataset, the cost of substi-
tuting the two symbols is set relatively low; oth-
erwise it is set relatively high. After the new seg-
ment substitution costs have been calculated, the
strings are aligned again based on the new seg-
ment substitution costs. The previous two steps
are then iterated until the string alignments remain
constant. Our alignments were stable after 12 iter-
ations.
After obtaining the final string alignments, we
use a matrix to store the presence or absence of
each segment substitution for every variety (with
respect to the reference place). We therefore ob-
tain an m × n matrix A of m varieties (in our
case 423; Delft was excluded as it was used as our
reference site) by n segment substitutions (in our
case 957; not all possible segment substitutions
occur). A value of 1 in A (i.e. AZA = 1) indicates
the presence of segment substitution j in variety i,
while a value of 0 indicates the absence. We ex-
perimented with frequency thresholds, but decided
against applying one in this paper as their applica-
tion seemed to lead to poorer results. We postpone
a consideration of frequency-sensitive alternatives
to the discussion section.
</bodyText>
<page confidence="0.981553">
16
</page>
<subsectionHeader confidence="0.999165">
3.2 Bipartite spectral graph partitioning
</subsectionHeader>
<bodyText confidence="0.999025958333334">
An undirected bipartite graph can be represented
by G = (R, S, E), where R and S are two sets
of vertices and E is the set of edges connecting
vertices from R to S. There are no edges between
vertices in a single set. In our case R is the set of
varieties, while S is the set of sound segment sub-
stitutions (i.e. sound correspondences). An edge
between ri and sj indicates that the sound segment
substitution sj occurs in variety ri. It is straight-
forward to see that matrix A is a representation of
an undirected bipartite graph.
Spectral graph theory is used to find the prin-
cipal properties and structure of a graph from its
graph spectrum (Chung, 1997). Dhillon (2001)
was the first to use spectral graph partitioning on
a bipartite graph of documents and words, effec-
tively clustering groups of documents and words
simultaneously. Consequently, every document
cluster has a direct connection to a word cluster. In
similar fashion, we would like to obtain a cluster-
ing of varieties and corresponding segment substi-
tutions. We therefore apply the multipartitioning
algorithm introduced by Dhillon (2001) to find k
clusters:
</bodyText>
<table confidence="0.9987362">
[2]:[I] [d]:[w] [-]:[@]
Vaals (Limburg) 0 1 1
Sittard (Limburg) 0 1 1
Appelscha (Friesland) 1 0 1
Oudega (Friesland) 1 0 1
</table>
<bodyText confidence="0.973651428571429">
We first construct matrices D1 and D2. D1
contains the total number of edges from every va-
riety (in the same row) on the diagonal, while D2
contains the total number of edges from every seg-
ment substitution (in the same column) on the di-
agonal. Both matrices are show below.
Applying the SVD to An yields:
</bodyText>
<figure confidence="0.780389533333333">
D1 = ⎡2 0 0 0 ⎤ ⎡ ⎤
⎢ ⎢0 2 0 0 2 0 0
⎣0 0 2 0 ⎥ ⎥D2 = ⎣0 2 0 ⎦
0 0 0 2 ⎦
0 0 4
We can now calculate An using the formula dis-
played in step 1 of the multipartitioning algorithm:
An = ⎡ 0 .5 .35 ⎤
⎢ ⎢ ⎣ 0 .5 .35 ⎦⎥⎥
.5 0 .35
.5 0 .35
1. Given the m x n variety-by-segment- U = ⎡ −.5 .5 .71 ⎤ ⎡ ⎤
substitution matrix A as discussed previ- ⎢ ⎢ ⎣ −.5 .5 .71 ⎦⎥⎥ 1 0 0 ⎦
ously, form −.5 −.5 0 Λ = ⎣0 .71 0
An = D1−1/2AD2−1/2 −.5 −.5 0 0 0 0
</figure>
<bodyText confidence="0.66367">
with D1 and D2 diagonal matrices such that
D1(i, i) = ΣjAij and D2(j, j) = ΣiAij
</bodyText>
<listItem confidence="0.994845">
2. Calculate the singular value decomposition
(SVD) of the normalized matrix An
</listItem>
<equation confidence="0.962437">
SVD(An) = U * Λ * VT
</equation>
<bodyText confidence="0.796811">
and take the l = Flog2k] singular vectors,
U2, ... ,UI + 1 and v2, ... ,vc + 1
</bodyText>
<figure confidence="0.373173666666667">
1/2
3. Compute Z = ID2−
D11 2 U[2,...,c+1]1 / V[2,...,c+1]
</figure>
<listItem confidence="0.82936">
4. Run the k-means algorithm on Z to obtain
the k-way multipartitioning
</listItem>
<bodyText confidence="0.835146666666667">
To illustrate this procedure, we will co-cluster
the following variety-by-segment-substitution ma-
trix A in k = 2 groups.
</bodyText>
<equation confidence="0.9282115">
⎡
−.5 −.71 −.5
V = ⎣−.5 .71 −.5
−.71 0 .71
</equation>
<bodyText confidence="0.936507333333333">
To cluster in two groups, we look at the second
singular vectors (i.e. columns) of U and V and
compute the 1-dimensional vector Z:
</bodyText>
<equation confidence="0.983339">
Z = [.35 .35 −.35 −.35 −.5 .5 0]T
</equation>
<bodyText confidence="0.999367142857143">
Note that the first four values correspond with the
places (Vaals, Sittard, Appelscha and Oudega) and
the final three values correspond to the segment
substitutions ([2]:[I], [d]:[w] and [-]:[@]).
After running the k-means algorithm on Z, the
items are assigned to one of two clusters as fol-
lows:
</bodyText>
<equation confidence="0.362535333333333">
[1 1 2 2 2 1 1]T
⎤
⎦
</equation>
<page confidence="0.881824">
17
</page>
<figureCaption confidence="0.993707">
Figure 2: Visualizations of co-clustering varieties (y-axis) and segments substitutions (x-axis) in 2 (left),
3 (middle) and 4 (right) clusters
</figureCaption>
<bodyText confidence="0.9986690625">
The clustering shows that Appelscha and
Oudega are clustered together and linked to the
clustered segment substitution of [n]:[I] (cluster
2). Similarly, Vaals and Sittard are clustered to-
gether and linked to the clustered segment substi-
tutions [d]:[w] and [-]:[a] (cluster 1). Note that the
segment substitution [-]:[a] (an insertion of [a]) is
actually not meaningful for the clustering of the
varieties (as can also be observed in A), because
the bottom value of the second column of V cor-
responding to this segment substitution is 0. It
could therefore just as likely be grouped in clus-
ter 2. Nevertheless, the k-means algorithm always
assigns every item to a single cluster.
In the following section we will report the re-
sults on clustering in two, three and four groups.1
</bodyText>
<sectionHeader confidence="0.999964" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999009578947368">
After running the multipartitioning algorithm2 we
obtained a two-way clustering in k clusters of va-
rieties and segment substitutions. Figure 2 tries
to visualize the simultaneous clustering in two
dimensions. A black dot is drawn if the vari-
ety (y-axis) contains the segment substitution (x-
axis). The varieties and segments are sorted in
such a way that the clusters are clearly visible (and
marked) on both axes.
To visualize the clustering of the varieties, we
created geographical maps in which we indicate
1We also experimented with clustering in more than four
groups, but the k-means clustering algorithm did not give sta-
ble results for these groupings. It is possible that the random
initialization of the k-means algorithm caused the instability
of the groupings, but since we are ignoring the majority of
information contained in the alignments it is more likely that
this causes a decrease in the number of clusters we can reli-
ably detect.
</bodyText>
<footnote confidence="0.952428">
2The implementation of the multipartitioning algo-
rithm was obtained from http://adios.tau.ac.il/
SpectralCoClustering
</footnote>
<bodyText confidence="0.990356382352941">
the cluster of each variety by a distinct pattern.
The division in 2, 3 and 4 clusters is shown in Fig-
ure 3.
In the following subsections we will discuss
the most important geographical clusters together
with their simultaneously derived sound corre-
spondences. For brevity, we will only focus on
explaining a few derived sound correspondences
for the most important geographical groups. The
main point to note is that besides a sensible geo-
graphical clustering, we also obtain linguistically
sensible results.
Note that the connection between a cluster of
varieties and sound correspondences does not nec-
essarily imply that those sound correspondences
only occur in that particular cluster of varieties.
This can also be observed in Figure 2, where
sound correspondences in a particular cluster of
varieties also appear in other clusters (but less
dense).3
The Frisian area
The division into two clusters clearly separates the
Frisian language area (in the province of Fries-
land) from the Dutch language area. This is the
expected result as Heeringa (2004: 227–229) also
measured Frisian as the most distant of all the
language varieties spoken in the Netherlands and
Flanders. It is also expected in light of the fact that
Frisian even has the legal status of a different lan-
guage rather than a dialect of Dutch. Note that the
separate “islands” in the Frisian language area (see
Figure 3) correspond to the Frisian cities which
are generally found to deviate from the rest of the
Frisian language area (Heeringa, 2004: 235–241).
</bodyText>
<footnote confidence="0.99470125">
3In this study, we did not focus on identifying the most
important sound correspondences in each cluster. See the
Discussion section for a possible approach to rank the sound
correspondences.
</footnote>
<page confidence="0.998504">
18
</page>
<figureCaption confidence="0.999883">
Figure 3: Clustering of varieties in 2 clusters (left), 3 clusters (middle) and 4 clusters (right)
</figureCaption>
<bodyText confidence="0.97722356097561">
A few interesting sound correspondences be-
tween the reference variety (Delft) and the Frisian
area are displayed in the following table and dis-
cussed below.
Reference [n] [n] [a] [o] [u] [x] [x] [r]
Frisian [I] [i] [i] [e] [e] [�] [z] [x]
In the table we can see that the Dutch /a/ or /n/
is pronounced [i] or [I] in the Frisian area. This
well known sound correspondence can be found
in words such as kamers ‘rooms’, Frisian [kImas]
(pronunciation from Anjum), or draden ‘threads’
and Frisian [trIdn] (Bakkeveen). In addition, the
Dutch (long) /o/ and /u/ both tend to be realized
as [e] in words such as bomen ‘trees’, Frisian
[bjeman] (Bakkeveen) or koeien ‘cows’, Frisian
[kei] (Appelscha).
We also identify clustered correspondences of
[x]:[j] where Dutch /x/ has been lenited, e.g. in
geld (/xelt/) ‘money’, Frisian [jIlt] (Grouw), but
note that [x]:[g] as in [gelt] (Franeker) also oc-
curs, illustrating that sound correspondences from
another cluster (i.e. the rest of the Netherlands)
can indeed also occur in the Frisian area. An-
other sound correspondence co-clustered with the
Frisian area is the Dutch /x/ and Frisian [z] in
zeggen (/zexa/) ‘say’ Frisian [siza] (Appelscha).
Besides the previous results, we also note some
problems. First, the accusative first-person plu-
ral pronoun ons ‘us’ lacks the nasal in Frisian, but
the correspondence was not tallied in this case be-
cause the nasal consonant is also missing in Delft.
Second, some apparently frequent sound corre-
spondences result from historical accidents, e.g.
[r]:[x] corresponds regularly in the Dutch:Frisian
pair [dor]:[trux] ‘through’. Frisian has lost the fi-
nal [x], and Dutch has either lost a final [r] or
experienced metathesis. These two sorts of ex-
amples might be treated more satisfactorily if we
were to compare pronunciations not to a standard
language, but rather to a reconstruction of a proto-
language.
</bodyText>
<subsectionHeader confidence="0.758378">
The Limburg area
</subsectionHeader>
<bodyText confidence="0.996222578947369">
The division into three clusters separates the
southern Limburg area from the rest of the Dutch
and Frisian language area. This result is also in
line with previous studies investigating Dutch di-
alectology; Heeringa (2004: 227–229) found the
Limburg dialects to deviate most strongly from
other different dialects within the Netherlands-
Flanders language area once Frisian was removed
from consideration.
Some important segment correspondences for
Limburg are displayed in the following table and
discussed below.
Reference [r] [r] [k] [n] [n] [w]
Limburg [R] [if] [x] [R] [if] [f]
Southern Limburg uses more uvular versions
of /r/, i.e. the trill [R], but also the voiced uvular
fricative [if]. These occur in words such as over
‘over, about’, but also in breken ‘to break’, i.e.
both pre- and post-vocalically. The bipartite clus-
</bodyText>
<page confidence="0.998172">
19
</page>
<bodyText confidence="0.999983">
tering likewise detected examples of the famous
“second sound shift”, in which Dutch /k/ is lenited
to /x/, e.g. in ook ‘also’ realized as [ox] in Epen
and elsewhere. Interestingly, when looking at
other words there is less evidence of lenition in the
words maken ‘to make’, gebruiken ‘to use’, koken
‘to cook’, and kraken ‘to crack’, where only two
Limburg varieties document a [x] pronunciation of
the expected stem-final [k], namely Kerkrade and
Vaals. The limited linguistic application does ap-
pear to be geographically consistent, but Kerkrade
pronounces /k/ as [x] where Vaals lenites further to
[s] in words such as ruiken ‘to smell’, breken ‘to
break’, and steken ‘to sting’. Further, there is no
evidence of lenition in words such as vloeken ‘to
curse’, spreken ‘to speak’, and zoeken ‘to seek’,
which are lenited in German (fluchen, sprechen,
suchen).
Some regular correspondences merely reflected
other, and sometimes more fundamental differ-
ences. For instance, we found correspondences
between [n] and [R] or [if] for Limburg , but this
turned out to be a reflection of the older plurals
in -r. For example, in the word wijf ‘woman’,
plural wijven in Dutch, wijver in Limburg dialect.
Dutch /w/ is often realized as [f] in the word tarwe
‘wheat’, but this is due to the elision of the final
schwa, which results in a pronunciation such as
[taRof], in which the standard final devoicing rule
of Dutch is applicable.
</bodyText>
<subsectionHeader confidence="0.785028">
The Low Saxon area
</subsectionHeader>
<bodyText confidence="0.992808612903226">
Finally, the division in four clusters also separates
the varieties from Groningen and Drenthe from
the rest of the Netherlands. This result differs
somewhat from the standard scholarship on Dutch
dialectology (see Heeringa, 2004), according to
which the Low Saxon area should include not only
the provinces of Groningen and Drenthe, but also
the province of Overijssel and the northern part
of the province of Gelderland. It is nonetheless
the case that Groningen and Drenthe normally are
seen to form a separate northern subgroup within
Low Saxon (Heeringa, 2004: 227–229).
A few interesting sound correspondences are
displayed in the following table and discussed be-
low.
Reference [a] [a] [a] [-] [a]
Low Saxon [m] [q] [N] [7] [e]
The best known characteristic of this area, the
so-called “final n” (slot n) is instantiated strongly
in words such as strepen, ‘stripes’, realized as
[strepm] in the northern Low Saxon area. It would
be pronounced [strepa] in standard Dutch, so the
differences shows up as an unexpected correspon-
dence of [a] with [m], [q] and [N].
The pronunciation of this area is also distinctive
in normally pronouncing words with initial glottal
stops [7] rather than initial vowels, e.g. af ‘fin-
ished’ is realized as [7af] (Schoonebeek). Further-
more, the long /a/ is often pronounced [e] as in
kaas ‘cheese’, [kes] in Gasselte, Hooghalen and
Norg.
</bodyText>
<sectionHeader confidence="0.997999" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999985513513513">
In this study, we have applied a novel method
to dialectology in simultaneously determining
groups of varieties and their linguistic basis (i.e.
sound segment correspondences). We demon-
strated that the bipartite spectral graph partitioning
method introduced by Dhillon (2001) gave sensi-
ble clustering results in the geographical domain
as well as for the concomitant linguistic basis.
As mentioned above, we did not have transcrip-
tions of standard Dutch, but instead we used tran-
scriptions of a variety (Delft) close to the stan-
dard langueage. While the pronunciations of most
items in Delft were similar to standard Dutch,
there were also items which were pronounced dif-
ferently from the standard. While we do not be-
lieve that this will change our results significantly,
using standard Dutch transcriptions produced by
the transcribers of the GTRP corpus would make
the interpretation of sound correspondences more
straightforward.
We indicated in Section 4 that some sound cor-
respondences, e.g. [r]:[x], would probably not oc-
cur if we used a reconstructed proto-language as
a reference instead of the standard language. A
possible way to reconstruct such a proto-language
is by multiple aligning (see Proki´c, 2009) all pro-
nunciations of a single word and use the most fre-
quent phonetic symbol at each position in the re-
constructed word. It would be interesting to see if
using such a reconstructed proto-language would
improve the results by removing sound correspon-
dences such as [r]:[x].
In this study we did not investigate methods
to identify the most important sound correspon-
dences. A possible option would be to create a
ranking procedure based on the uniqueness of the
sound correspondences in a cluster. I.e. the sound
</bodyText>
<page confidence="0.979913">
20
</page>
<bodyText confidence="0.999963396226416">
correspondence is given a high importance when
it only occurs in the designated cluster, while the
importance goes down when it also occurs in other
clusters).
While sound segment correspondences function
well as a linguistic basis, it might also be fruitful
to investigate morphological distinctions present
in the GTRP corpus. This would enable us to
compare the similarity of the geographic distribu-
tions of pronunciation variation on the one hand
and morphological variation on the other.
As this study was the first to investigate the ef-
fectiveness of a co-clustering approach in dialec-
tometry, we focused on the original bipartite spec-
tral graph partitioning algorithm (Dhillon, 2001).
Investigating other approaches such as bicluster-
ing algorithms for biology (Madeira and Oliveira,
2004) or an information-theoretic co-clustering
approach (Dhillon et al., 2003) would be highly
interesting.
It would likewise be interesting to attempt to
incorporate frequency, by weighting correspon-
dences that occur frequently more heavily than
those which occur only infrequently. While it
stands to reason that more frequently encoun-
tered variation would signal dialectal affinity more
strongly, it is also the case that inverse fre-
quency weightings have occasionally been applied
(Goebl, 1982), and have been shown to function
well. We have the sense that the last word on this
topic has yet to be spoken, and that empirical work
would be valuable.
Our paper has not addressed the interaction be-
tween cognitive and social dynamics directly, but
we feel it has improved our vantage point for un-
derstanding this interaction. In dialect geogra-
phy, social dynamics are operationalized as geog-
raphy, and bipartite spectral graph partitioning has
proven itself capable of detecting the effects of so-
cial contact, i.e. the latent geographic signal in the
data. Other dialectometric techniques have done
this as well.
Linguists have rightly complained, however,
that the linguistic factors have been neglected in
dialectometry (Schneider, 1988:176). The current
approach does not offer a theoretical framework to
explain cognitive effects such as phonemes corre-
sponding across many words, but does enumerate
them clearly. This paper has shown that bipartite
graph clustering can detect the linguistic basis of
dialectal affinity. If deeper cognitive constraints
are reflected in that basis, then we are now in an
improved position to detect them.
</bodyText>
<sectionHeader confidence="0.99549" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999988875">
We would like to thank Assaf Gottlieb for shar-
ing the implementation of the bipartite spectral
graph partitioning method. We also would like to
thank Peter Kleiweg for supplying the L04 pack-
age which was used to generate the maps in this
paper. Finally, we are grateful to Jelena Proki´c and
the anonymous reviewers for their helpful com-
ments on an earlier version of this paper.
</bodyText>
<sectionHeader confidence="0.998947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996031189189189">
Fan Chung. 1997. Spectral graph theory. American
Mathematical Society.
Georges De Schutter, Boudewijn van den Berg, Ton
Goeman, and Thera de Jong. 2005. Morfologische
Atlas van de Nederlandse Dialecten (MAND) Deel
1. Amsterdam University Press, Meertens Instituut
- KNAW, Koninklijke Academie voor Nederlandse
Taal- en Letterkunde, Amsterdam.
Inderjit Dhillon, Subramanyam Mallela, and Dhar-
mendra Modha. 2003. Information-theoretic co-
clustering. In Proceedings of the ninth ACM
SIGKDD international conference on Knowledge
discovery and data mining, pages 89–98. ACM New
York, NY, USA.
Inderjit Dhillon. 2001. Co-clustering documents and
words using bipartite spectral graph partitioning. In
Proceedings of the seventh ACM SIGKDD interna-
tional conference on Knowledge discovery and data
mining, pages 269–274. ACM New York, NY, USA.
Hans Goebl. 1982. Dialektometrie: Prinzipien
und Methoden des Einsatzes der Numerischen
Taxonomie im Bereich der Dialektgeographie.
¨Osterreichische Akademie der Wissenschaften,
Wien.
Ton Goeman and Johan Taeldeman. 1996. Fonolo-
gie en morfologie van de Nederlandse dialecten.
Een nieuwe materiaalverzameling en twee nieuwe
atlasprojecten. Taal en Tongval, 48:38–59.
Wilbert Heeringa. 2004. Measuring Dialect Pronunci-
ation Differences using Levenshtein Distance. Ph.D.
thesis, Rijksuniversiteit Groningen.
Yuval Kluger, Ronen Basri, Joseph Chang, and Mark
Gerstein. 2003. Spectral biclustering of microarray
data: Coclustering genes and conditions. Genome
Research, 13(4):703–716.
Grzegorz Kondrak. 2002. Determining recur-
rent sound correspondences by inducing translation
</reference>
<page confidence="0.985185">
21
</page>
<reference confidence="0.99993478125">
models. In Proceedings of the Nineteenth Inter-
national Conference on Computational Linguistics
(COLING 2002), pages 488–494, Taipei. COLING.
Vladimir Levenshtein. 1965. Binary codes capable of
correcting deletions, insertions and reversals. Dok-
lady Akademii Nauk SSSR, 163:845–848.
Sara Madeira and Arlindo Oliveira. 2004. Bicluster-
ing algorithms for biological data analysis: a survey.
IEEE/ACM Transactions on Computational Biology
and Bioinformatics, 1(1):24–45.
John Nerbonne, Wilbert Heeringa, and Peter Kleiweg.
1999. Edit distance and dialect proximity. In David
Sankoff and Joseph Kruskal, editors, Time Warps,
String Edits and Macromolecules: The Theory and
Practice of Sequence Comparison, 2nd ed., pages v–
xv. CSLI, Stanford, CA.
John Nerbonne. 2006. Identifying linguistic struc-
ture in aggregate comparison. Literary and Lin-
guistic Computing, 21(4):463–476. Special Issue,
J.Nerbonne &amp; W.Kretzschmar (eds.), Progress in
Dialectometry: Toward Explanation.
John Nerbonne. 2009. Data-driven dialectology. Lan-
guage and Linguistics Compass, 3(1):175–198.
Jelena Proki´c, Martijn Wieling, and John Nerbonne.
2009. Multiple sequence alignments in linguistics.
In Lars Borin and Piroska Lendvai, editors, Lan-
guage Technology and Resources for Cultural Her-
itage, Social Sciences, Humanities, and Education,
pages 18–25.
Jelena Proki´c. 2007. Identifying linguistic structure
in a quantitative analysis of dialect pronunciation.
In Proceedings of the ACL 2007 Student Research
Workshop, pages 61–66, Prague, June. Association
for Computational Linguistics.
Edgar Schneider. 1988. Qualitative vs. quantitative
methods of area delimitation in dialectology: A
comparison based on lexical data from georgia and
alabama. Journal of English Linguistics, 21:175–
212.
Jean S´eguy. 1973. La dialectom´etrie dans l’atlas lin-
guistique de gascogne. Revue de Linguistique Ro-
mane, 37(145):1–24.
Robert G. Shackleton, Jr. 2005. English-american
speech relationships: A quantitative approach. Jour-
nal of English Linguistics, 33(2):99–160.
Johan Taeldeman and Geert Verleyen. 1999. De
FAND: een kind van zijn tijd. Taal en Tongval,
51:217–240.
Boudewijn van den Berg. 2003. Phonology &amp; Mor-
phology of Dutch &amp; Frisian Dialects in 1.1 million
transcriptions. Goeman-Taeldeman-Van Reenen
project 1980-1995, Meertens Instituut Electronic
Publications in Linguistics 3. Meertens Instituut
(CD-ROM), Amsterdam.
Martijn Wieling, Wilbert Heeringa, and John Ner-
bonne. 2007. An aggregate analysis of pronuncia-
tion in the Goeman-Taeldeman-Van Reenen-Project
data. Taal en Tongval, 59:84–116.
Martijn Wieling, Jelena Proki´c, and John Nerbonne.
2009. Evaluating the pairwise alignment of pronun-
ciations. In Lars Borin and Piroska Lendvai, editors,
Language Technology and Resources for Cultural
Heritage, Social Sciences, Humanities, and Educa-
tion, pages 26–34.
</reference>
<page confidence="0.999027">
22
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.663183">
<title confidence="0.939732">Bipartite spectral graph partitioning to co-cluster varieties and correspondences in dialectology</title>
<author confidence="0.953674">Martijn</author>
<affiliation confidence="0.884102">University of The</affiliation>
<email confidence="0.960226">m.b.wieling@rug.nl</email>
<abstract confidence="0.99900232">In this study we used bipartite spectral graph partitioning to simultaneously cluster varieties and sound correspondences in Dutch dialect data. While clustering geographical varieties with respect to their pronunciation is not new, the simultaneous identification of the sound correspondences giving rise to the geographical clustering presents a novel opportunity in dialectometry. Earlier methods aggregated sound differences and clustered on the basis of aggregate differences. The determination of the significant sound correspondences which co-varied with cluster was carried out on a hoc basis. Bipartite spectral graph clustering simultaneously seeks groups of individual sound correspondences which are associated, even while seeking groups of sites which share sound correspondences. We show that the application of this method results in clear and sensible geographical groupings and discuss the concomitant sound correspondences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fan Chung</author>
</authors>
<title>Spectral graph theory.</title>
<date>1997</date>
<publisher>American Mathematical Society.</publisher>
<contexts>
<context position="12679" citStr="Chung, 1997" startWordPosition="2001" endWordPosition="2002">nted by G = (R, S, E), where R and S are two sets of vertices and E is the set of edges connecting vertices from R to S. There are no edges between vertices in a single set. In our case R is the set of varieties, while S is the set of sound segment substitutions (i.e. sound correspondences). An edge between ri and sj indicates that the sound segment substitution sj occurs in variety ri. It is straightforward to see that matrix A is a representation of an undirected bipartite graph. Spectral graph theory is used to find the principal properties and structure of a graph from its graph spectrum (Chung, 1997). Dhillon (2001) was the first to use spectral graph partitioning on a bipartite graph of documents and words, effectively clustering groups of documents and words simultaneously. Consequently, every document cluster has a direct connection to a word cluster. In similar fashion, we would like to obtain a clustering of varieties and corresponding segment substitutions. We therefore apply the multipartitioning algorithm introduced by Dhillon (2001) to find k clusters: [2]:[I] [d]:[w] [-]:[@] Vaals (Limburg) 0 1 1 Sittard (Limburg) 0 1 1 Appelscha (Friesland) 1 0 1 Oudega (Friesland) 1 0 1 We fir</context>
</contexts>
<marker>Chung, 1997</marker>
<rawString>Fan Chung. 1997. Spectral graph theory. American Mathematical Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georges De Schutter</author>
<author>Boudewijn van den Berg</author>
<author>Ton Goeman</author>
<author>Thera de Jong</author>
</authors>
<title>Morfologische Atlas van de Nederlandse Dialecten (MAND) Deel 1.</title>
<date>2005</date>
<publisher>Amsterdam University Press,</publisher>
<location>Amsterdam.</location>
<marker>De Schutter, van den Berg, Goeman, de Jong, 2005</marker>
<rawString>Georges De Schutter, Boudewijn van den Berg, Ton Goeman, and Thera de Jong. 2005. Morfologische Atlas van de Nederlandse Dialecten (MAND) Deel 1. Amsterdam University Press, Meertens Instituut - KNAW, Koninklijke Academie voor Nederlandse Taal- en Letterkunde, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjit Dhillon</author>
<author>Subramanyam Mallela</author>
<author>Dharmendra Modha</author>
</authors>
<title>Information-theoretic coclustering.</title>
<date>2003</date>
<booktitle>In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>89--98</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="27054" citStr="Dhillon et al., 2003" startWordPosition="4405" endWordPosition="4408">e fruitful to investigate morphological distinctions present in the GTRP corpus. This would enable us to compare the similarity of the geographic distributions of pronunciation variation on the one hand and morphological variation on the other. As this study was the first to investigate the effectiveness of a co-clustering approach in dialectometry, we focused on the original bipartite spectral graph partitioning algorithm (Dhillon, 2001). Investigating other approaches such as biclustering algorithms for biology (Madeira and Oliveira, 2004) or an information-theoretic co-clustering approach (Dhillon et al., 2003) would be highly interesting. It would likewise be interesting to attempt to incorporate frequency, by weighting correspondences that occur frequently more heavily than those which occur only infrequently. While it stands to reason that more frequently encountered variation would signal dialectal affinity more strongly, it is also the case that inverse frequency weightings have occasionally been applied (Goebl, 1982), and have been shown to function well. We have the sense that the last word on this topic has yet to be spoken, and that empirical work would be valuable. Our paper has not addres</context>
</contexts>
<marker>Dhillon, Mallela, Modha, 2003</marker>
<rawString>Inderjit Dhillon, Subramanyam Mallela, and Dharmendra Modha. 2003. Information-theoretic coclustering. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 89–98. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjit Dhillon</author>
</authors>
<title>Co-clustering documents and words using bipartite spectral graph partitioning.</title>
<date>2001</date>
<booktitle>In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>269--274</pages>
<publisher>ACM</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3486" citStr="Dhillon (2001)" startWordPosition="503" endWordPosition="504">he distance matrices induced by each of two hundred vowel pronunciations automatically extracted from a large American collection, and subsequently applied factor analysis to the covariance matrices obtained from the collection of vowel distance matrices. Proki´c (2007) analyzed Bulgarian pronunciation using an edit distance algorithm and then collected commonly aligned sounds. She developed an index to measure how characteristic a given sound correspondence is for a given site. To study varietal relatedness and its linguistic basis in parallel, we apply bipartite spectral graph partitioning. Dhillon (2001) was the first to use spectral graph partitioning on a bipartite graph of documents and words, effectively clustering groups of documents and words simultaneously. Consequently, every document cluster has a direct connection to a word cluster; the document clustering implies a word clustering and vice versa. In 14 Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 14–22, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP his study, Dhillon (2001) also demonstrated that his algorithm worked well on real world examples. The usefuln</context>
<context position="12695" citStr="Dhillon (2001)" startWordPosition="2003" endWordPosition="2004">, S, E), where R and S are two sets of vertices and E is the set of edges connecting vertices from R to S. There are no edges between vertices in a single set. In our case R is the set of varieties, while S is the set of sound segment substitutions (i.e. sound correspondences). An edge between ri and sj indicates that the sound segment substitution sj occurs in variety ri. It is straightforward to see that matrix A is a representation of an undirected bipartite graph. Spectral graph theory is used to find the principal properties and structure of a graph from its graph spectrum (Chung, 1997). Dhillon (2001) was the first to use spectral graph partitioning on a bipartite graph of documents and words, effectively clustering groups of documents and words simultaneously. Consequently, every document cluster has a direct connection to a word cluster. In similar fashion, we would like to obtain a clustering of varieties and corresponding segment substitutions. We therefore apply the multipartitioning algorithm introduced by Dhillon (2001) to find k clusters: [2]:[I] [d]:[w] [-]:[@] Vaals (Limburg) 0 1 1 Sittard (Limburg) 0 1 1 Appelscha (Friesland) 1 0 1 Oudega (Friesland) 1 0 1 We first construct mat</context>
<context position="24726" citStr="Dhillon (2001)" startWordPosition="4039" endWordPosition="4040">th [m], [q] and [N]. The pronunciation of this area is also distinctive in normally pronouncing words with initial glottal stops [7] rather than initial vowels, e.g. af ‘finished’ is realized as [7af] (Schoonebeek). Furthermore, the long /a/ is often pronounced [e] as in kaas ‘cheese’, [kes] in Gasselte, Hooghalen and Norg. 5 Discussion In this study, we have applied a novel method to dialectology in simultaneously determining groups of varieties and their linguistic basis (i.e. sound segment correspondences). We demonstrated that the bipartite spectral graph partitioning method introduced by Dhillon (2001) gave sensible clustering results in the geographical domain as well as for the concomitant linguistic basis. As mentioned above, we did not have transcriptions of standard Dutch, but instead we used transcriptions of a variety (Delft) close to the standard langueage. While the pronunciations of most items in Delft were similar to standard Dutch, there were also items which were pronounced differently from the standard. While we do not believe that this will change our results significantly, using standard Dutch transcriptions produced by the transcribers of the GTRP corpus would make the inte</context>
<context position="26875" citStr="Dhillon, 2001" startWordPosition="4384" endWordPosition="4385">ted cluster, while the importance goes down when it also occurs in other clusters). While sound segment correspondences function well as a linguistic basis, it might also be fruitful to investigate morphological distinctions present in the GTRP corpus. This would enable us to compare the similarity of the geographic distributions of pronunciation variation on the one hand and morphological variation on the other. As this study was the first to investigate the effectiveness of a co-clustering approach in dialectometry, we focused on the original bipartite spectral graph partitioning algorithm (Dhillon, 2001). Investigating other approaches such as biclustering algorithms for biology (Madeira and Oliveira, 2004) or an information-theoretic co-clustering approach (Dhillon et al., 2003) would be highly interesting. It would likewise be interesting to attempt to incorporate frequency, by weighting correspondences that occur frequently more heavily than those which occur only infrequently. While it stands to reason that more frequently encountered variation would signal dialectal affinity more strongly, it is also the case that inverse frequency weightings have occasionally been applied (Goebl, 1982),</context>
</contexts>
<marker>Dhillon, 2001</marker>
<rawString>Inderjit Dhillon. 2001. Co-clustering documents and words using bipartite spectral graph partitioning. In Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining, pages 269–274. ACM New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Goebl</author>
</authors>
<date>1982</date>
<booktitle>Dialektometrie: Prinzipien und Methoden des Einsatzes der Numerischen Taxonomie im Bereich der Dialektgeographie. ¨Osterreichische Akademie der Wissenschaften,</booktitle>
<location>Wien.</location>
<contexts>
<context position="1292" citStr="Goebl, 1982" startWordPosition="180" endWordPosition="181">nation of the significant sound correspondences which co-varied with cluster membership was carried out on a post hoc basis. Bipartite spectral graph clustering simultaneously seeks groups of individual sound correspondences which are associated, even while seeking groups of sites which share sound correspondences. We show that the application of this method results in clear and sensible geographical groupings and discuss the concomitant sound correspondences. 1 Introduction Exact methods have been applied successfully to the analysis of dialect variation for over three decades (S´eguy, 1973; Goebl, 1982; Nerbonne et al., 1999), but they have invariably functioned by first probing the linguistic differences between each pair of a range of varieties (sites, such as Whitby and Bristol in the UK) over a body of carefully controlled material (say the pronunciation of the vowel in the word ‘put’). Second, the techniques AGGREGATE over these linguistic differences, in order, third, to seek the natural groups in the data via clustering or multidimensional scaling (MDS) (Nerbonne, 2009). John Nerbonne University of Groningen The Netherlands j.nerbonne@rug.nl Naturally techniques have been developed t</context>
<context position="27474" citStr="Goebl, 1982" startWordPosition="4469" endWordPosition="4470">hillon, 2001). Investigating other approaches such as biclustering algorithms for biology (Madeira and Oliveira, 2004) or an information-theoretic co-clustering approach (Dhillon et al., 2003) would be highly interesting. It would likewise be interesting to attempt to incorporate frequency, by weighting correspondences that occur frequently more heavily than those which occur only infrequently. While it stands to reason that more frequently encountered variation would signal dialectal affinity more strongly, it is also the case that inverse frequency weightings have occasionally been applied (Goebl, 1982), and have been shown to function well. We have the sense that the last word on this topic has yet to be spoken, and that empirical work would be valuable. Our paper has not addressed the interaction between cognitive and social dynamics directly, but we feel it has improved our vantage point for understanding this interaction. In dialect geography, social dynamics are operationalized as geography, and bipartite spectral graph partitioning has proven itself capable of detecting the effects of social contact, i.e. the latent geographic signal in the data. Other dialectometric techniques have do</context>
</contexts>
<marker>Goebl, 1982</marker>
<rawString>Hans Goebl. 1982. Dialektometrie: Prinzipien und Methoden des Einsatzes der Numerischen Taxonomie im Bereich der Dialektgeographie. ¨Osterreichische Akademie der Wissenschaften, Wien.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ton Goeman</author>
<author>Johan Taeldeman</author>
</authors>
<title>Fonologie en morfologie van de Nederlandse dialecten. Een nieuwe materiaalverzameling en twee nieuwe atlasprojecten. Taal en Tongval,</title>
<date>1996</date>
<pages>48--38</pages>
<contexts>
<context position="6331" citStr="Goeman and Taeldeman, 1996" startWordPosition="942" endWordPosition="945">e studied, a large database of contemporary Dutch pronunciations. Section 3 presents the methods, both the alignment technique used to obtain sound correspondences, as well as the bipartite spectral graph partitioning we used to simultaneously seek affinities in varieties as well as affinities in sound correspondences. Section 4 presents our results, while Section 5 concludes with a discussion and some ideas on avenues for future research. 2 Material In this study we use the most recent broadcoverage Dutch dialect data source available: data from the Goeman-Taeldeman-Van Reenen-project (GTRP; Goeman and Taeldeman, 1996; Van den Berg, 2003). The GTRP consists of digital transcriptions for 613 dialect varieties in the Netherlands (424 varieties) and Belgium (189 varieties), gathered during the period 1980–1995. For every variety, a maximum of 1876 items was narrowly transcribed according to the International Phonetic Alphabet. The items consist of separate words and phrases, including pronominals, adjectives and nouns. A detailed overview of the data collection is given in Taeldeman and Verleyen (1999). Because the GTRP was compiled with a view to documenting both phonological and morphological variation (De </context>
</contexts>
<marker>Goeman, Taeldeman, 1996</marker>
<rawString>Ton Goeman and Johan Taeldeman. 1996. Fonologie en morfologie van de Nederlandse dialecten. Een nieuwe materiaalverzameling en twee nieuwe atlasprojecten. Taal en Tongval, 48:38–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wilbert Heeringa</author>
</authors>
<title>Measuring Dialect Pronunciation Differences using Levenshtein Distance.</title>
<date>2004</date>
<tech>Ph.D. thesis,</tech>
<institution>Rijksuniversiteit Groningen.</institution>
<contexts>
<context position="2429" citStr="Heeringa (2004" startWordPosition="349" endWordPosition="350"> The Netherlands j.nerbonne@rug.nl Naturally techniques have been developed to determine which linguistic variables weigh most heavily in determining affinity among varieties. But all of the following studies separate the determination of varietal relatedness from the question of its detailed linguistic basis. Kondrak (2002) adapted a machine translation technique to determine which sound correspondences occur most regularly. His focus was not on dialectology, but rather on diachronic phonology, where the regular sound correspondences are regarded as strong evidence of historical relatedness. Heeringa (2004: 268–270) calculated which words correlated best with the first, second and third dimensions of an MDS analysis of aggregate pronunciation differences. Shackleton (2004) used a database of abstract linguistic differences in trying to identify the British sources of American patterns of speech variation. He applied principal component analysis to his database to identify the common components among his variables. Nerbonne (2006) examined the distance matrices induced by each of two hundred vowel pronunciations automatically extracted from a large American collection, and subsequently applied f</context>
<context position="8576" citStr="Heeringa (2004" startWordPosition="1302" endWordPosition="1303">only at the 82 distinct phonetic symbols. The average length of every item in the GTRP (without diacritics) is 4.7 tokens. 3 Methods To obtain the clearest signal of varietal differences in sound correspondences, we ideally want to compare the pronunciations of each variety with a single reference point. We might have used the pronunciations of a proto-language for this purpose, but these are not available. There are also no pronunciations in standard Dutch in the GTRP and transcribing the standard Dutch pronunciations ourselves would likely have introduced betweentranscriber inconsistencies. Heeringa (2004: 274– 276) identified pronunciations in the variety of Haarlem as being the closest to standard Dutch. 15 Figure 1: Distribution of GTRP localities including province names Because Haarlem was not included in the GTRP varieties, we chose the transcriptions of Delft (also close to standard Dutch) as our reference transcriptions. See the discussion section for a consideration of alternatives. 3.1 Obtaining sound correspondences To obtain the sound correspondences for every site in the GTRP with respect to the reference site Delft, we used an adapted version of the regular Levenshtein algorithm </context>
<context position="18111" citStr="Heeringa (2004" startWordPosition="2962" endWordPosition="2963">raphical clustering, we also obtain linguistically sensible results. Note that the connection between a cluster of varieties and sound correspondences does not necessarily imply that those sound correspondences only occur in that particular cluster of varieties. This can also be observed in Figure 2, where sound correspondences in a particular cluster of varieties also appear in other clusters (but less dense).3 The Frisian area The division into two clusters clearly separates the Frisian language area (in the province of Friesland) from the Dutch language area. This is the expected result as Heeringa (2004: 227–229) also measured Frisian as the most distant of all the language varieties spoken in the Netherlands and Flanders. It is also expected in light of the fact that Frisian even has the legal status of a different language rather than a dialect of Dutch. Note that the separate “islands” in the Frisian language area (see Figure 3) correspond to the Frisian cities which are generally found to deviate from the rest of the Frisian language area (Heeringa, 2004: 235–241). 3In this study, we did not focus on identifying the most important sound correspondences in each cluster. See the Discussion</context>
<context position="21008" citStr="Heeringa (2004" startWordPosition="3436" endWordPosition="3437">l accidents, e.g. [r]:[x] corresponds regularly in the Dutch:Frisian pair [dor]:[trux] ‘through’. Frisian has lost the final [x], and Dutch has either lost a final [r] or experienced metathesis. These two sorts of examples might be treated more satisfactorily if we were to compare pronunciations not to a standard language, but rather to a reconstruction of a protolanguage. The Limburg area The division into three clusters separates the southern Limburg area from the rest of the Dutch and Frisian language area. This result is also in line with previous studies investigating Dutch dialectology; Heeringa (2004: 227–229) found the Limburg dialects to deviate most strongly from other different dialects within the NetherlandsFlanders language area once Frisian was removed from consideration. Some important segment correspondences for Limburg are displayed in the following table and discussed below. Reference [r] [r] [k] [n] [n] [w] Limburg [R] [if] [x] [R] [if] [f] Southern Limburg uses more uvular versions of /r/, i.e. the trill [R], but also the voiced uvular fricative [if]. These occur in words such as over ‘over, about’, but also in breken ‘to break’, i.e. both pre- and post-vocalically. The bipar</context>
<context position="23296" citStr="Heeringa, 2004" startWordPosition="3809" endWordPosition="3810">o be a reflection of the older plurals in -r. For example, in the word wijf ‘woman’, plural wijven in Dutch, wijver in Limburg dialect. Dutch /w/ is often realized as [f] in the word tarwe ‘wheat’, but this is due to the elision of the final schwa, which results in a pronunciation such as [taRof], in which the standard final devoicing rule of Dutch is applicable. The Low Saxon area Finally, the division in four clusters also separates the varieties from Groningen and Drenthe from the rest of the Netherlands. This result differs somewhat from the standard scholarship on Dutch dialectology (see Heeringa, 2004), according to which the Low Saxon area should include not only the provinces of Groningen and Drenthe, but also the province of Overijssel and the northern part of the province of Gelderland. It is nonetheless the case that Groningen and Drenthe normally are seen to form a separate northern subgroup within Low Saxon (Heeringa, 2004: 227–229). A few interesting sound correspondences are displayed in the following table and discussed below. Reference [a] [a] [a] [-] [a] Low Saxon [m] [q] [N] [7] [e] The best known characteristic of this area, the so-called “final n” (slot n) is instantiated str</context>
</contexts>
<marker>Heeringa, 2004</marker>
<rawString>Wilbert Heeringa. 2004. Measuring Dialect Pronunciation Differences using Levenshtein Distance. Ph.D. thesis, Rijksuniversiteit Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Kluger</author>
<author>Ronen Basri</author>
<author>Joseph Chang</author>
<author>Mark Gerstein</author>
</authors>
<title>Spectral biclustering of microarray data: Coclustering genes and conditions.</title>
<date>2003</date>
<journal>Genome Research,</journal>
<volume>13</volume>
<issue>4</issue>
<contexts>
<context position="4210" citStr="Kluger et al. (2003)" startWordPosition="613" endWordPosition="616">ly clustering groups of documents and words simultaneously. Consequently, every document cluster has a direct connection to a word cluster; the document clustering implies a word clustering and vice versa. In 14 Proceedings of the 2009 Workshop on Graph-based Methods for Natural Language Processing, ACL-IJCNLP 2009, pages 14–22, Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP his study, Dhillon (2001) also demonstrated that his algorithm worked well on real world examples. The usefulness of this approach is not only limited to clustering documents and words simultaneously. For example, Kluger et al. (2003) used a somewhat adapted bipartite spectral graph partitioning approach to successfully cluster microarray data simultaneously in clusters of genes and conditions. In summary, the contribution of this paper is to apply a graph-theoretic technique, bipartite spectral graph partitioning, to a new sort of data, namely dialect pronunciation data, in order to solve an important problem, namely how to recognize groups of varieties in this sort of data while simultaneously characterizing the linguistic basis of the group. It is worth noting that, in isolating the linguistic basis of varietal affiniti</context>
</contexts>
<marker>Kluger, Basri, Chang, Gerstein, 2003</marker>
<rawString>Yuval Kluger, Ronen Basri, Joseph Chang, and Mark Gerstein. 2003. Spectral biclustering of microarray data: Coclustering genes and conditions. Genome Research, 13(4):703–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Kondrak</author>
</authors>
<title>Determining recurrent sound correspondences by inducing translation models.</title>
<date>2002</date>
<booktitle>In Proceedings of the Nineteenth International Conference on Computational Linguistics (COLING</booktitle>
<pages>488--494</pages>
<location>Taipei. COLING.</location>
<contexts>
<context position="2141" citStr="Kondrak (2002)" startWordPosition="308" endWordPosition="309">ial (say the pronunciation of the vowel in the word ‘put’). Second, the techniques AGGREGATE over these linguistic differences, in order, third, to seek the natural groups in the data via clustering or multidimensional scaling (MDS) (Nerbonne, 2009). John Nerbonne University of Groningen The Netherlands j.nerbonne@rug.nl Naturally techniques have been developed to determine which linguistic variables weigh most heavily in determining affinity among varieties. But all of the following studies separate the determination of varietal relatedness from the question of its detailed linguistic basis. Kondrak (2002) adapted a machine translation technique to determine which sound correspondences occur most regularly. His focus was not on dialectology, but rather on diachronic phonology, where the regular sound correspondences are regarded as strong evidence of historical relatedness. Heeringa (2004: 268–270) calculated which words correlated best with the first, second and third dimensions of an MDS analysis of aggregate pronunciation differences. Shackleton (2004) used a database of abstract linguistic differences in trying to identify the British sources of American patterns of speech variation. He app</context>
</contexts>
<marker>Kondrak, 2002</marker>
<rawString>Grzegorz Kondrak. 2002. Determining recurrent sound correspondences by inducing translation models. In Proceedings of the Nineteenth International Conference on Computational Linguistics (COLING 2002), pages 488–494, Taipei. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions and reversals.</title>
<date>1965</date>
<booktitle>Doklady Akademii Nauk SSSR,</booktitle>
<pages>163--845</pages>
<contexts>
<context position="9195" citStr="Levenshtein, 1965" startWordPosition="1398" endWordPosition="1399"> 274– 276) identified pronunciations in the variety of Haarlem as being the closest to standard Dutch. 15 Figure 1: Distribution of GTRP localities including province names Because Haarlem was not included in the GTRP varieties, we chose the transcriptions of Delft (also close to standard Dutch) as our reference transcriptions. See the discussion section for a consideration of alternatives. 3.1 Obtaining sound correspondences To obtain the sound correspondences for every site in the GTRP with respect to the reference site Delft, we used an adapted version of the regular Levenshtein algorithm (Levenshtein, 1965). The Levenshtein algorithm aligns two (phonetic) strings by minimizing the number of edit operations (i.e. insertions, deletions and substitutions) required to transform one string into the other. For example, the Levenshtein distance between [lEIk@n] and [likh8n], two Dutch variants of the word ‘seem’, is 4: lEIk@n delete E 1 lIk@n subst. i/I 1 lik@n insert h 1 likh@n subst. 8/@ 1 likh8n 4 The corresponding alignment is: l E I k @ n l i k h 8 n 1 1 1 1 When all edit operations have the same cost, multiple alignments yield a Levenshtein distance of 4 (i.e. by aligning the [i] with the [E] and</context>
</contexts>
<marker>Levenshtein, 1965</marker>
<rawString>Vladimir Levenshtein. 1965. Binary codes capable of correcting deletions, insertions and reversals. Doklady Akademii Nauk SSSR, 163:845–848.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sara Madeira</author>
<author>Arlindo Oliveira</author>
</authors>
<title>Biclustering algorithms for biological data analysis: a survey.</title>
<date>2004</date>
<journal>IEEE/ACM Transactions on Computational Biology and Bioinformatics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="26980" citStr="Madeira and Oliveira, 2004" startWordPosition="4396" endWordPosition="4399">und segment correspondences function well as a linguistic basis, it might also be fruitful to investigate morphological distinctions present in the GTRP corpus. This would enable us to compare the similarity of the geographic distributions of pronunciation variation on the one hand and morphological variation on the other. As this study was the first to investigate the effectiveness of a co-clustering approach in dialectometry, we focused on the original bipartite spectral graph partitioning algorithm (Dhillon, 2001). Investigating other approaches such as biclustering algorithms for biology (Madeira and Oliveira, 2004) or an information-theoretic co-clustering approach (Dhillon et al., 2003) would be highly interesting. It would likewise be interesting to attempt to incorporate frequency, by weighting correspondences that occur frequently more heavily than those which occur only infrequently. While it stands to reason that more frequently encountered variation would signal dialectal affinity more strongly, it is also the case that inverse frequency weightings have occasionally been applied (Goebl, 1982), and have been shown to function well. We have the sense that the last word on this topic has yet to be s</context>
</contexts>
<marker>Madeira, Oliveira, 2004</marker>
<rawString>Sara Madeira and Arlindo Oliveira. 2004. Biclustering algorithms for biological data analysis: a survey. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 1(1):24–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
<author>Wilbert Heeringa</author>
<author>Peter Kleiweg</author>
</authors>
<title>Edit distance and dialect proximity.</title>
<date>1999</date>
<booktitle>Time Warps, String Edits and Macromolecules: The Theory and Practice of Sequence Comparison, 2nd ed.,</booktitle>
<pages>pages</pages>
<editor>In David Sankoff and Joseph Kruskal, editors,</editor>
<location>CA.</location>
<contexts>
<context position="1316" citStr="Nerbonne et al., 1999" startWordPosition="182" endWordPosition="185"> significant sound correspondences which co-varied with cluster membership was carried out on a post hoc basis. Bipartite spectral graph clustering simultaneously seeks groups of individual sound correspondences which are associated, even while seeking groups of sites which share sound correspondences. We show that the application of this method results in clear and sensible geographical groupings and discuss the concomitant sound correspondences. 1 Introduction Exact methods have been applied successfully to the analysis of dialect variation for over three decades (S´eguy, 1973; Goebl, 1982; Nerbonne et al., 1999), but they have invariably functioned by first probing the linguistic differences between each pair of a range of varieties (sites, such as Whitby and Bristol in the UK) over a body of carefully controlled material (say the pronunciation of the vowel in the word ‘put’). Second, the techniques AGGREGATE over these linguistic differences, in order, third, to seek the natural groups in the data via clustering or multidimensional scaling (MDS) (Nerbonne, 2009). John Nerbonne University of Groningen The Netherlands j.nerbonne@rug.nl Naturally techniques have been developed to determine which lingui</context>
</contexts>
<marker>Nerbonne, Heeringa, Kleiweg, 1999</marker>
<rawString>John Nerbonne, Wilbert Heeringa, and Peter Kleiweg. 1999. Edit distance and dialect proximity. In David Sankoff and Joseph Kruskal, editors, Time Warps, String Edits and Macromolecules: The Theory and Practice of Sequence Comparison, 2nd ed., pages v– xv. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
</authors>
<title>Identifying linguistic structure in aggregate comparison.</title>
<date>2006</date>
<booktitle>Literary and Linguistic Computing, 21(4):463–476. Special Issue, J.Nerbonne &amp; W.Kretzschmar (eds.), Progress in Dialectometry: Toward Explanation.</booktitle>
<contexts>
<context position="2861" citStr="Nerbonne (2006)" startWordPosition="414" endWordPosition="415">is focus was not on dialectology, but rather on diachronic phonology, where the regular sound correspondences are regarded as strong evidence of historical relatedness. Heeringa (2004: 268–270) calculated which words correlated best with the first, second and third dimensions of an MDS analysis of aggregate pronunciation differences. Shackleton (2004) used a database of abstract linguistic differences in trying to identify the British sources of American patterns of speech variation. He applied principal component analysis to his database to identify the common components among his variables. Nerbonne (2006) examined the distance matrices induced by each of two hundred vowel pronunciations automatically extracted from a large American collection, and subsequently applied factor analysis to the covariance matrices obtained from the collection of vowel distance matrices. Proki´c (2007) analyzed Bulgarian pronunciation using an edit distance algorithm and then collected commonly aligned sounds. She developed an index to measure how characteristic a given sound correspondence is for a given site. To study varietal relatedness and its linguistic basis in parallel, we apply bipartite spectral graph par</context>
</contexts>
<marker>Nerbonne, 2006</marker>
<rawString>John Nerbonne. 2006. Identifying linguistic structure in aggregate comparison. Literary and Linguistic Computing, 21(4):463–476. Special Issue, J.Nerbonne &amp; W.Kretzschmar (eds.), Progress in Dialectometry: Toward Explanation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Nerbonne</author>
</authors>
<title>Data-driven dialectology.</title>
<date>2009</date>
<journal>Language and Linguistics Compass,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="1776" citStr="Nerbonne, 2009" startWordPosition="259" endWordPosition="260">Exact methods have been applied successfully to the analysis of dialect variation for over three decades (S´eguy, 1973; Goebl, 1982; Nerbonne et al., 1999), but they have invariably functioned by first probing the linguistic differences between each pair of a range of varieties (sites, such as Whitby and Bristol in the UK) over a body of carefully controlled material (say the pronunciation of the vowel in the word ‘put’). Second, the techniques AGGREGATE over these linguistic differences, in order, third, to seek the natural groups in the data via clustering or multidimensional scaling (MDS) (Nerbonne, 2009). John Nerbonne University of Groningen The Netherlands j.nerbonne@rug.nl Naturally techniques have been developed to determine which linguistic variables weigh most heavily in determining affinity among varieties. But all of the following studies separate the determination of varietal relatedness from the question of its detailed linguistic basis. Kondrak (2002) adapted a machine translation technique to determine which sound correspondences occur most regularly. His focus was not on dialectology, but rather on diachronic phonology, where the regular sound correspondences are regarded as stro</context>
</contexts>
<marker>Nerbonne, 2009</marker>
<rawString>John Nerbonne. 2009. Data-driven dialectology. Language and Linguistics Compass, 3(1):175–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jelena Proki´c</author>
<author>Martijn Wieling</author>
<author>John Nerbonne</author>
</authors>
<title>Multiple sequence alignments in linguistics.</title>
<date>2009</date>
<booktitle>In Lars Borin and Piroska Lendvai, editors, Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education,</booktitle>
<pages>18--25</pages>
<marker>Proki´c, Wieling, Nerbonne, 2009</marker>
<rawString>Jelena Proki´c, Martijn Wieling, and John Nerbonne. 2009. Multiple sequence alignments in linguistics. In Lars Borin and Piroska Lendvai, editors, Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education, pages 18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jelena Proki´c</author>
</authors>
<title>Identifying linguistic structure in a quantitative analysis of dialect pronunciation.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL 2007 Student Research Workshop,</booktitle>
<pages>61--66</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague,</location>
<marker>Proki´c, 2007</marker>
<rawString>Jelena Proki´c. 2007. Identifying linguistic structure in a quantitative analysis of dialect pronunciation. In Proceedings of the ACL 2007 Student Research Workshop, pages 61–66, Prague, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edgar Schneider</author>
</authors>
<title>Qualitative vs. quantitative methods of area delimitation in dialectology: A comparison based on lexical data from georgia and alabama.</title>
<date>1988</date>
<journal>Journal of English Linguistics,</journal>
<volume>21</volume>
<pages>212</pages>
<contexts>
<context position="28216" citStr="Schneider, 1988" startWordPosition="4587" endWordPosition="4588">ical work would be valuable. Our paper has not addressed the interaction between cognitive and social dynamics directly, but we feel it has improved our vantage point for understanding this interaction. In dialect geography, social dynamics are operationalized as geography, and bipartite spectral graph partitioning has proven itself capable of detecting the effects of social contact, i.e. the latent geographic signal in the data. Other dialectometric techniques have done this as well. Linguists have rightly complained, however, that the linguistic factors have been neglected in dialectometry (Schneider, 1988:176). The current approach does not offer a theoretical framework to explain cognitive effects such as phonemes corresponding across many words, but does enumerate them clearly. This paper has shown that bipartite graph clustering can detect the linguistic basis of dialectal affinity. If deeper cognitive constraints are reflected in that basis, then we are now in an improved position to detect them. Acknowledgments We would like to thank Assaf Gottlieb for sharing the implementation of the bipartite spectral graph partitioning method. We also would like to thank Peter Kleiweg for supplying th</context>
</contexts>
<marker>Schneider, 1988</marker>
<rawString>Edgar Schneider. 1988. Qualitative vs. quantitative methods of area delimitation in dialectology: A comparison based on lexical data from georgia and alabama. Journal of English Linguistics, 21:175– 212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean S´eguy</author>
</authors>
<title>La dialectom´etrie dans l’atlas linguistique de gascogne. Revue de Linguistique Romane,</title>
<date>1973</date>
<pages>37--145</pages>
<marker>S´eguy, 1973</marker>
<rawString>Jean S´eguy. 1973. La dialectom´etrie dans l’atlas linguistique de gascogne. Revue de Linguistique Romane, 37(145):1–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert G Shackleton</author>
</authors>
<title>English-american speech relationships: A quantitative approach.</title>
<date>2005</date>
<journal>Journal of English Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<marker>Shackleton, 2005</marker>
<rawString>Robert G. Shackleton, Jr. 2005. English-american speech relationships: A quantitative approach. Journal of English Linguistics, 33(2):99–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Taeldeman</author>
<author>Geert Verleyen</author>
</authors>
<title>De FAND: een kind van zijn tijd. Taal en Tongval,</title>
<date>1999</date>
<pages>51--217</pages>
<contexts>
<context position="6822" citStr="Taeldeman and Verleyen (1999)" startWordPosition="1016" endWordPosition="1019">ent broadcoverage Dutch dialect data source available: data from the Goeman-Taeldeman-Van Reenen-project (GTRP; Goeman and Taeldeman, 1996; Van den Berg, 2003). The GTRP consists of digital transcriptions for 613 dialect varieties in the Netherlands (424 varieties) and Belgium (189 varieties), gathered during the period 1980–1995. For every variety, a maximum of 1876 items was narrowly transcribed according to the International Phonetic Alphabet. The items consist of separate words and phrases, including pronominals, adjectives and nouns. A detailed overview of the data collection is given in Taeldeman and Verleyen (1999). Because the GTRP was compiled with a view to documenting both phonological and morphological variation (De Schutter et al., 2005) and our purpose here is the analysis of sound correspondences, we ignore many items of the GTRP. We use the same 562 item subset as introduced and discussed in depth in Wieling et al. (2007). In short, the 1876 item word list was filtered by selecting only single word items, plural nouns (the singular form was preceded by an article and therefore not included), base forms of adjectives instead of comparative forms and the first-person plural verb instead of other </context>
</contexts>
<marker>Taeldeman, Verleyen, 1999</marker>
<rawString>Johan Taeldeman and Geert Verleyen. 1999. De FAND: een kind van zijn tijd. Taal en Tongval, 51:217–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Boudewijn van den Berg</author>
</authors>
<date>2003</date>
<booktitle>Phonology &amp; Morphology of Dutch &amp; Frisian Dialects in 1.1 million transcriptions. Goeman-Taeldeman-Van Reenen project 1980-1995, Meertens Instituut Electronic Publications in Linguistics 3. Meertens Instituut (CD-ROM),</booktitle>
<location>Amsterdam.</location>
<marker>van den Berg, 2003</marker>
<rawString>Boudewijn van den Berg. 2003. Phonology &amp; Morphology of Dutch &amp; Frisian Dialects in 1.1 million transcriptions. Goeman-Taeldeman-Van Reenen project 1980-1995, Meertens Instituut Electronic Publications in Linguistics 3. Meertens Instituut (CD-ROM), Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martijn Wieling</author>
<author>Wilbert Heeringa</author>
<author>John Nerbonne</author>
</authors>
<title>An aggregate analysis of pronunciation in the Goeman-Taeldeman-Van Reenen-Project data. Taal en Tongval,</title>
<date>2007</date>
<pages>59--84</pages>
<contexts>
<context position="7144" citStr="Wieling et al. (2007)" startWordPosition="1073" endWordPosition="1076">5. For every variety, a maximum of 1876 items was narrowly transcribed according to the International Phonetic Alphabet. The items consist of separate words and phrases, including pronominals, adjectives and nouns. A detailed overview of the data collection is given in Taeldeman and Verleyen (1999). Because the GTRP was compiled with a view to documenting both phonological and morphological variation (De Schutter et al., 2005) and our purpose here is the analysis of sound correspondences, we ignore many items of the GTRP. We use the same 562 item subset as introduced and discussed in depth in Wieling et al. (2007). In short, the 1876 item word list was filtered by selecting only single word items, plural nouns (the singular form was preceded by an article and therefore not included), base forms of adjectives instead of comparative forms and the first-person plural verb instead of other forms. We omit words whose variation is primarily morphological as we wish to focus on sound correspondences. In all varieties the same lexeme was used for a single item. Because the GTRP transcriptions of Belgian varieties are fundamentally different from transcriptions of Netherlandic varieties (Wieling et al., 2007), </context>
</contexts>
<marker>Wieling, Heeringa, Nerbonne, 2007</marker>
<rawString>Martijn Wieling, Wilbert Heeringa, and John Nerbonne. 2007. An aggregate analysis of pronunciation in the Goeman-Taeldeman-Van Reenen-Project data. Taal en Tongval, 59:84–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martijn Wieling</author>
<author>Jelena Proki´c</author>
<author>John Nerbonne</author>
</authors>
<title>Evaluating the pairwise alignment of pronunciations.</title>
<date>2009</date>
<booktitle>In Lars Borin and Piroska Lendvai, editors, Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education,</booktitle>
<pages>26--34</pages>
<marker>Wieling, Proki´c, Nerbonne, 2009</marker>
<rawString>Martijn Wieling, Jelena Proki´c, and John Nerbonne. 2009. Evaluating the pairwise alignment of pronunciations. In Lars Borin and Piroska Lendvai, editors, Language Technology and Resources for Cultural Heritage, Social Sciences, Humanities, and Education, pages 26–34.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>