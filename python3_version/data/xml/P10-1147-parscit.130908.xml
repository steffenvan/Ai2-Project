<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.991482">
Discriminative Modeling of Extraction Sets for Machine Translation
</title>
<author confidence="0.998235">
John DeNero and Dan Klein
</author>
<affiliation confidence="0.998677">
Computer Science Division
University of California, Berkeley
</affiliation>
<email confidence="0.995056">
{denero,klein}@cs.berkeley.edu
</email>
<sectionHeader confidence="0.997333" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996505">
We present a discriminative model that di-
rectly predicts which set of phrasal transla-
tion rules should be extracted from a sen-
tence pair. Our model scores extraction
sets: nested collections of all the overlap-
ping phrase pairs consistent with an under-
lying word alignment. Extraction set mod-
els provide two principle advantages over
word-factored alignment models. First,
we can incorporate features on phrase
pairs, in addition to word links. Second,
we can optimize for an extraction-based
loss function that relates directly to the
end task of generating translations. Our
model gives improvements in alignment
quality relative to state-of-the-art unsuper-
vised and supervised baselines, as well
as providing up to a 1.4 improvement in
BLEU score in Chinese-to-English trans-
lation experiments.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999675275862069">
In the last decade, the field of statistical machine
translation has shifted from generating sentences
word by word to systems that recycle whole frag-
ments of training examples, expressed as transla-
tion rules. This general paradigm was first pur-
sued using contiguous phrases (Och et al., 1999;
Koehn et al., 2003), and has since been general-
ized to a wide variety of hierarchical and syntactic
formalisms. The training stage of statistical sys-
tems focuses primarily on discovering translation
rules in parallel corpora.
Most systems discover translation rules via a
two-stage pipeline: a parallel corpus is aligned at
the word level, and then a second procedure ex-
tracts fragment-level rules from word-aligned sen-
tence pairs. This paper offers a model-based alter-
native to phrasal rule extraction, which merges this
two-stage pipeline into a single step. We present a
discriminative model that directly predicts which
set of phrasal translation rules should be extracted
from a sentence pair. Our model predicts extrac-
tion sets: combinatorial objects that include the
set of all overlapping phrasal translation rules con-
sistent with an underlying word-level alignment.
This approach provides additional discriminative
power relative to word aligners because extraction
sets are scored based on the phrasal rules they con-
tain in addition to word-to-word alignment links.
Moreover, the structure of our model directly re-
flects the purpose of alignment models in general,
which is to discover translation rules.
We address several challenges to training and
applying an extraction set model. First, we would
like to leverage existing word-level alignment re-
sources. To do so, we define a deterministic map-
ping from word alignments to extraction sets, in-
spired by existing extraction procedures. In our
mapping, possible alignment links have a precise
interpretation that dictates what phrasal translation
rules can be extracted from a sentence pair. This
mapping allows us to train with existing annotated
data sets and use the predictions from word-level
aligners as features in our extraction set model.
Second, our model solves a structured predic-
tion problem, and the choice of loss function dur-
ing training affects model performance. We opti-
mize for a phrase-level F-measure in order to fo-
cus learning on the task of predicting phrasal rules
rather than word alignment links.
Third, our discriminative approach requires that
we perform inference in the space of extraction
sets. Our model does not factor over disjoint word-
to-word links or minimal phrase pairs, and so ex-
isting inference procedures do not directly apply.
However, we show that the dynamic program for
a block ITG aligner can be augmented to score ex-
traction sets that are indexed by underlying ITG
word alignments (Wu, 1997). We also describe a
</bodyText>
<page confidence="0.867542">
1453
</page>
<note confidence="0.9712255">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1453–1463,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.9957374">
2010年
2月
15日
σ(ei) Type 1: Language-specific function
(�) Type 1: Languagespecific fu
words omitted in the other language
words omtted in the other lan
σ(fj)
Type 2: Role-equivalent pairs that
Type oeequvalet wo
are not lexical equivalents
tha ae lexial e
ove the65%
over the Earth
地球地球
[Earth] [
过
过 Distribution
[go over]
[go ver]
Distribution over
possible link types
possible link
b On February 15 2010
15 20
</figure>
<figureCaption confidence="0.999881">
Figure 1: A word alignment A (shaded grid cells)
</figureCaption>
<bodyText confidence="0.972759352941177">
defines projections σ(ei) and σ(fj), shown as dot-
ted lines for each word in each sentence. The ex-
traction set R3(A) includes all bispans licensed by
these projections, shown as rounded rectangles.
coarse-to-fine inference approach that allows us to
scale our method to long sentences.
Our extraction set model outperforms both un-
supervised and supervised word aligners at pre-
dicting word alignments and extraction sets. We
also demonstrate that extraction sets are useful for
end-to-end machine translation. Our model im-
proves translation quality relative to state-of-the-
art Chinese-to-English baselines across two pub-
licly available systems, providing total BLEU im-
provements of 1.2 in Moses, a phrase-based sys-
tem, and 1.4 in a Joshua, a hierarchical system
(Koehn et al., 2007; Li et al., 2009)
</bodyText>
<sectionHeader confidence="0.991691" genericHeader="method">
2 Extraction Set Models
</sectionHeader>
<bodyText confidence="0.999969666666667">
The input to our model is an unaligned sentence
pair, and the output is an extraction set of phrasal
translation rules. Word-level alignments are gen-
erated as a byproduct of inference. We first spec-
ify the relationship between word alignments and
extraction sets, then define our model.
</bodyText>
<subsectionHeader confidence="0.998649">
2.1 Extraction Sets from Word Alignments
</subsectionHeader>
<bodyText confidence="0.999903454545455">
Rule extraction is a standard concept in machine
translation: word alignment constellations license
particular sets of overlapping rules, from which
subsets are selected according to limits on phrase
length (Koehn et al., 2003), number of gaps (Chi-
ang, 2007), count of internal tree nodes (Galley et
al., 2006), etc. In this paper, we focus on phrasal
rule extraction (i.e., phrase pair extraction), upon
which most other extraction procedures are based.
Given a sentence pair (e, f), phrasal rule extrac-
tion defines a mapping from a set of word-to-word
</bodyText>
<figure confidence="0.842136833333333">
31%
被 [passive marker]
发现 发现 [s
[discover]
w c
was discovered
</figure>
<figureCaption confidence="0.684605">
Figure 2: Examples of two types of possible align-
σ(e)
</figureCaption>
<bodyText confidence="0.746761">
ment links (striped). These types account for 96%
</bodyText>
<equation confidence="0.695027">
2010年
of the possible alignment links in our data set.
alignment links A = {(i, j)} to an extraction set
(f�)
of bispans Rn(A) = {[g, h) &lt;---&gt; [k, `)}, where
5日 月
each bispan links target span [g, h) to source span
[k, `).1 The maximum phase length n ensures that
日
On February 15 2010
max(h − g, ` − k) G n.
</equation>
<bodyText confidence="0.888735">
We candescribe this mapping via word-to-
On Februay 15 2010 PDT
phrase projections, as illustrated in Figure 1. Let
word ei project to the phrasal span σ(ei), where
</bodyText>
<equation confidence="0.999830333333333">
�σ(ei) = min j , max j + 1 (1)
jEJi jEJi
Ji = {j : (i,j) E A}
</equation>
<bodyText confidence="0.9828385">
and likewise each word fj projects to a span of e.
Then, Rn(A) includes a bispan [g, h) &lt;---&gt; [k, `) iff
</bodyText>
<equation confidence="0.9967465">
σ(ei) C [k, `) bi E [g, h)
σ(fj) C [g, h) bj E [k, `)
</equation>
<bodyText confidence="0.9903548">
That is, every word in one of the phrasal spans
must project within the other. This mapping is de-
terministic, and so we can interpret a word-level
alignment A as also specifying the phrasal rules
that should be extracted from a sentence pair.
</bodyText>
<subsectionHeader confidence="0.999114">
2.2 Possible and Null Alignment Links
</subsectionHeader>
<bodyText confidence="0.9996925">
We have not yet accounted for two special cases
in annotated corpora: possible alignments and null
alignments. To analyze these annotations, we con-
sider a particular data set: a hand-aligned portion
</bodyText>
<footnote confidence="0.7115295">
1We use the fencepost indexing scheme used commonly
for parsing. Words are 0-indexed. Spans are inclusive on the
lower bound and exclusive on the upper bound. For example,
the span [0, 2) includes the first two words of a sentence.
</footnote>
<page confidence="0.994615">
1454
</page>
<bodyText confidence="0.999761393939394">
of the NIST MT02 Chinese-to-English test set,
which has been used in previous alignment experi-
ments (Ayan et al., 2005; DeNero and Klein, 2007;
Haghighi et al., 2009).
Possible links account for 22% of all alignment
links in these data, and we found that most of
these links fall into two categories. First, possible
links are used to align function words that have no
equivalent in the other language, but colocate with
aligned content words, such as English determin-
ers. Second, they are used to mark pairs of words
or short phrases that are not lexical equivalents,
but which play equivalent roles in each sentence.
Figure 2 shows examples of these two use cases,
along with their corpus frequencies.2
On the other hand, null alignments are used
sparingly in our annotated data. More than 90%
of words participate in some alignment link. The
unaligned words typically express content in one
sentence that is absent in its translation.
Figure 3 illustrates how we interpret possible
and null links in our projection. Possible links are
typically not included in extraction procedures be-
cause most aligners predict only sure links. How-
ever, we see a natural interpretation for possible
links in rule extraction: they license phrasal rules
that both include and exclude them. We exclude
null alignments from extracted phrases because
they often indicate a mismatch in content.
We achieve these effects by redefining the pro-
jection operator σ. Let A(3) be the subset of A
that are sure links, then let the index set Ji used
for projection σ in Equation 1 be
</bodyText>
<equation confidence="0.952194333333333">
Ji = { {j : (i, j) E A(3)} if ]j : (i, j) E A(3)
{−1, Ifi} if �j : (i, j) E A
{j : (i, j) E A} otherwise
</equation>
<bodyText confidence="0.992403125">
Here, Ji is a set of integers, and σ(ei) for null
aligned ei will be [−1,1fl + 1) by Equation 1.
Of course, the characteristics of our aligned cor-
pus may not hold for other annotated corpora or
other language pairs. However, we hope that the
overall effectiveness of our modeling approach
will influence future annotation efforts to build
corpora that are consistent with this interpretation.
</bodyText>
<subsectionHeader confidence="0.99698">
2.3 A Linear Model of Extraction Sets
</subsectionHeader>
<bodyText confidence="0.99953">
We now define a linear model that scores extrac-
tion sets. We restrict our model to score only co-
</bodyText>
<footnote confidence="0.795446">
2We collected corpus frequencies of possible alignment
link types ourselves on a sample of the hand-aligned data set.
</footnote>
<figure confidence="0.4881835">
σ(e1)
2010年
σ(h)
On February 15 2010 PDT
</figure>
<figureCaption confidence="0.944634">
Figure 3: Possible links constrain the word-to-
</figureCaption>
<bodyText confidence="0.85242605882353">
phrase projection of otherwise unaligned words,
which in turn license overlapping phrases. In this
example, σ(f2) = [1, 2) does not include the
possible link at (1, 0) because of the sure link at
(1, 1), but σ(e1) = [1, 2) does use the possible
link because it would otherwise be unaligned. The
word “PDT” is null aligned, and so its projection
σ(e4) = [−1, 4) extends beyond the bounds of the
sentence, excluding “PDT” from all phrase pairs.
herent extraction sets Rn(A), those that are li-
censed by an underlying word alignment A with
sure alignments A(3) C A. Conditioned on a
sentence pair (e, f) and maximum phrase length
n, we score extraction sets via a feature vec-
tor φ(A(3), Rn(A)) that includes features on sure
links (i, j) E A(3) and features on the bispans in
Rn(A) that link [g, h) in a to [k, `) in f:
</bodyText>
<equation confidence="0.880876">
φ(A(3),Rn(A)) =
</equation>
<bodyText confidence="0.999434823529412">
Because the projection operator Rn(·) is a
deterministic function, we can abbreviate
φ(A(3), Rn(A)) as φ(A) without loss of infor-
mation, although we emphasize that A is a set
of sure and possible alignments, and φ(A) does
not decompose as a sum of vectors on individual
word-level alignment links. Our model is param-
eterized by a weight vector θ, which scores an
extraction set Rn(A) as θ · φ(A).
To further limit the space of extraction sets we
are willing to consider, we restrict A to block
inverse transduction grammar (ITG) alignments,
a space that allows many-to-many alignments
through phrasal terminal productions, but other-
wise enforces at-most-one-to-one phrase match-
ings with ITG reordering patterns (Cherry and Lin,
2007; Zhang et al., 2008). The ITG constraint
</bodyText>
<equation confidence="0.94292675">
2月
15日
E φ�(i, j) + E φb(g, h, k, `)
(i,j)EAW [g,h)q[V)ERn(A)
</equation>
<page confidence="0.951265">
1455
</page>
<figureCaption confidence="0.853052">
Figure 4: Above, we show a representative sub-
</figureCaption>
<bodyText confidence="0.900866222222222">
set of the block alignment patterns that serve as
terminal productions of the ITG that restricts the
output space of our model. These terminal pro-
ductions cover up to n = 3 words in each sentence
and include a mixture of sure (filled) and possible
(striped) word-level alignment links.
is more computationally convenient than arbitrar-
ily ordered phrase matchings (Wu, 1997; DeNero
and Klein, 2008). However, the space of block
ITG alignments is expressive enough to include
the vast majority of patterns observed in hand-
annotated parallel corpora (Haghighi et al., 2009).
In summary, our model scores all Rn(A) for
A ∈ ITG(e, f) where A can include block termi-
nals of size up to n. In our experiments, n = 3.
Unlike previous work, we allow possible align-
ment links to appear in the block terminals, as de-
picted in Figure 4.
</bodyText>
<sectionHeader confidence="0.978514" genericHeader="method">
3 Model Estimation
</sectionHeader>
<bodyText confidence="0.999874166666667">
We estimate the weights θ of our extraction set
model discriminatively using the margin-infused
relaxed algorithm (MIRA) of Crammer and Singer
(2003)—a large-margin, perceptron-style, online
learning algorithm. MIRA has been used suc-
cessfully in MT to estimate both alignment mod-
els (Haghighi et al., 2009) and translation models
(Chiang et al., 2008).
For each training example, MIRA requires that
we find the alignment Am corresponding to the
highest scoring extraction set Rn(Am) under the
current model,
</bodyText>
<equation confidence="0.589301">
Am = arg maxAEITG(e,f)θ · φ(A) (2)
</equation>
<bodyText confidence="0.999826666666667">
Section 4 describes our approach to solving this
search problem for model inference.
MIRA updates away from Rn(Am) and to-
ward a gold extraction set Rn(Ag). Some hand-
annotated alignments are outside of the block ITG
model class. Hence, we update toward the ex-
traction set for a pseudo-gold alignment Ag ∈
ITG(e, f) with minimal distance from the true ref-
erence alignment At.
</bodyText>
<equation confidence="0.953074333333333">
Ag = arg minAEITG(e,f)|A ∪ At − A ∩ At |(3)
Inferencedetails appear in Section 4.3.
σ
</equation>
<bodyText confidence="0.936045">
Given Ag and Am, we update the model param-
eters away from Am and toward Ag.
</bodyText>
<equation confidence="0.934761">
θ ← θ + τ · (φ(Ag) − φ(Am))
</equation>
<bodyText confidence="0.996894285714286">
where τ is the minimal step size that will ensure
On February 15 2010 P
we prefer Ag to Am by a margin greater than
the loss L(Am; Ag), capped at some maximum
update size C to provide regularization. We use
C = 0.01 in experiments. The step size is a closed
form function of the loss and feature vectors: τ =
</bodyText>
<equation confidence="0.993599333333333">
min �
C, L(Am; Ag) − θ · (φ(Ag) − φ(Am))
||φ(Ag) − φ(Am)||22
</equation>
<bodyText confidence="0.9999925">
We train the model for 30 iterations over the
training set, shuffling the order each time, and we
average the weight vectors observed after each it-
eration to estimate our final model.
</bodyText>
<subsectionHeader confidence="0.999846">
3.1 Extraction Set Loss Function
</subsectionHeader>
<bodyText confidence="0.999864">
In order to focus learning on predicting the
right bispans, we use an extraction-level loss
L(Am; Ag): an F-measure of the overlap between
bispans in Rn(Am) and Rn(Ag). This measure
has been proposed previously to evaluate align-
ment systems (Ayan and Dorr, 2006). Based
on preliminary translation results during develop-
ment, we chose bispan F5 as our loss:
</bodyText>
<equation confidence="0.999808">
Pr(Am) = |Rn(Am) ∩ Rn(Ag)|/|Rn(Am)|
Rc(Am) = |Rn(Am) ∩ Rn(Ag)|/|Rn(Ag)|
(1 + 5 2) · Pr(Am) · Rc(Am)
F5 (Am; Ag) = 52 · Pr(Am) + Rc(Am)
L(Am; Ag) = 1 − F5(Am; Ag)
</equation>
<bodyText confidence="0.999881454545455">
F5 favors recall over precision. Previous align-
ment work has shown improvements from adjust-
ing the F-measure parameter (Fraser and Marcu,
2006). In particular, Lacoste-Julien et al. (2006)
also chose a recall-biased objective.
Optimizing for a bispan F-measure penalizes
alignment mistakes in proportion to their rule ex-
traction consequences. That is, adding a word
link that prevents the extraction of many correct
phrasal rules, or which licenses many incorrect
rules, is strongly discouraged by this loss.
</bodyText>
<page confidence="0.955438">
1456
</page>
<subsectionHeader confidence="0.995398">
3.2 Features on Extraction Sets
</subsectionHeader>
<bodyText confidence="0.9999638125">
The discriminative power of our model is driven
by the features on sure word alignment links
φa(i, j) and bispans φb(g, h, k, `). In both cases,
the most important features come from the pre-
dictions of unsupervised models trained on large
parallel corpora, which provide frequency and co-
occurrence information.
To score word-to-word links, we use the poste-
rior predictions of a jointly trained HMM align-
ment model (Liang et al., 2006). The remaining
features include a dictionary feature, an identical
word feature, an absolute position distortion fea-
ture, and features for numbers and punctuation.
To score phrasal translation rules in an extrac-
tion set, we use a mixture of feature types. Ex-
traction set models allow us to incorporate the
same phrasal relative frequency statistics that drive
phrase-based translation performance (Koehn et
al., 2003). To implement these frequency features,
we extract a phrase table from the alignment pre-
dictions of a jointly trained unsupervised HMM
model using Moses (Koehn et al., 2007), and score
bispans using the resulting features. We also in-
clude indicator features on lexical templates for
the 50 most common words in each language, as
in Haghighi et al. (2009). We include indicators
for the number of words and Chinese characters
in rules. One useful indicator feature exploits the
fact that capitalized terms in English tend to align
to Chinese words with three or more characters.
On 1-by-n or n-by-1 phrasal rules, we include in-
dicator features of fertility for common words.3
We also include monolingual phrase features
that expose useful information to the model. For
instance, English bigrams beginning with “the”
are often extractable phrases. English trigrams
with a hyphen as the second word are typically ex-
tractable, meaning that the first and third words
align to consecutive Chinese words. When any
conjugation of the word “to be” is followed by a
verb, indicating passive voice or progressive tense,
the two words tend to align together.
Our feature set also includes bias features on
phrasal rules and links, which control the num-
ber of null-aligned words and number of rules li-
censed. In total, our final model includes 4,249
individual features, dominated by various instanti-
ations of lexical templates.
</bodyText>
<footnote confidence="0.9772705">
3Limiting lexicalized features to common words helps
prevent overfitting.
</footnote>
<bodyText confidence="0.351255">
In the past two years
</bodyText>
<figureCaption confidence="0.994079">
Figure 5: Both possible ITG decompositions of
</figureCaption>
<figure confidence="0.445381">
g h
this example alignment will split one of the two
highlighted bispans across constituents.
k
</figure>
<sectionHeader confidence="0.954354" genericHeader="method">
4 Model Inference
</sectionHeader>
<bodyText confidence="0.9999066">
Equation 2 asks for the highest scoring extraction
set under our model, Rn(Am), which we also re-
quire at test time. Although we have restricted
Am E ITG(e, f), our extraction set model does not
factor over ITG productions, and so the dynamic
</bodyText>
<equation confidence="0.773028333333333">
在
program for a vanilla block ITG will not suffice to
k 2 晩饭
</equation>
<bodyText confidence="0.999709428571429">
find Rn(Am). To see this, consider the extraction
set in Figure 5. An ITG decomposition of the un-
derlying alignment imposes a hierarchical brack-
eting on each sentence, and some bispan in the ex-
traction set for this alignment will cross any such
bracketing. Hence,1the score of some licensed bis-
pan will be non-local to the ITG decomposition.
</bodyText>
<subsectionHeader confidence="0.989151">
4.1 A Dynamic Program for Extraction Sets
</subsectionHeader>
<bodyText confidence="0.990085333333333">
er r l
If we treat the maximum phrase length n as a fixed
constant, then we can define a dynamic program to
search the space of extraction sets. An ITG deriva-
tion for some alignment A decomposes into two
sub-derivations for AL and AR.4 The model score
of A, which scores extraction set Rn(A), decom-
poses over AL and AR, along with any phrasal
bispans licensed by adjoining AL and AR.
</bodyText>
<equation confidence="0.909632">
θ · φ(A) = θ · φ(AL) + θ · φ(AR) + I(AL, AR)
</equation>
<bodyText confidence="0.982603666666667">
where I(AL, AR) is θ · E φ(g, h, k, l) summed
over licensed bispans [g, h) &lt;---&gt; [k, `) that overlap
the boundary between AL and AR.5
</bodyText>
<footnote confidence="0.999178">
4We abuse notation in conflating an alignment ,A with its
derivation. All derivations of the same alignment receive the
same score, and we only compute the max, not the sum.
5We focus on the case of adjoining two aligned bispans.
Our algorithm easily extends to include null alignments, but
we focus on the non-null setting for simplicity.
</footnote>
<figure confidence="0.988863692307692">
过去
�
[past]
[two]
[year]
[in]
年
中
or
1457
g h
k
l
</figure>
<figureCaption confidence="0.747939">
Figure 6: Augmenting the ITG grammar states
with the alignment configuration in an n − 1 deep
</figureCaption>
<bodyText confidence="0.908051416666667">
在
perimeter of the bispan allows us to score all over-
lapping2phrasal rules introduced by adjoining two
bispans. The state must encode whether a sure link
appears in each edge column or row, but the spe-
cific location of edge links is not required.
In order to compute I (AL, AR), we need cer-
tain information about the alignment configura-
tions of AL and AR where they adjoin at a corner.
了
The state must represent (a) the specific alignment
links in the n− 1 deep corner of each A, and (b)
</bodyText>
<subsubsectionHeader confidence="0.625685">
Aftr dinner I slept
</subsubsectionHeader>
<bodyText confidence="0.999958615384615">
whether any sure alignments appear in the rows or
columns extending from those corners.6 With this
information, we can infer the bispans licensed by
adjoining AL and AR, as in Figure 6.
Applying our score recurrence yields a
polynomial-time dynamic program. This dynamic
program is an instance of ITG bitext parsing,
where the grammar uses symbols to encode
the alignment contexts described above. This
context-as-symbol augmentation of the grammar
is similar in character to augmenting symbols with
lexical items to score language models during
hierarchical decoding (Chiang, 2007).
</bodyText>
<subsectionHeader confidence="0.997394">
4.2 Coarse-to-Fine Inference and Pruning
</subsectionHeader>
<bodyText confidence="0.999419272727273">
Exhaustive inference under an ITG requires O(k�)
time in sentence length k, and is prohibitively slow
when there is no sparsity in the grammar. Main-
taining the context necessary to score non-local
bispans further increases running time. That is,
ITG inference is organized around search states
associated with a grammar symbol and a bispan;
augmenting grammar symbols also augments this
state space.
To parse quickly, we prune away search states
using predictions from the more efficient HMM
</bodyText>
<footnote confidence="0.737863333333333">
6The number of configuration states does not depend on
the size of ,A because corners have fixed size, and because the
position of links within rows or columns is not needed.
</footnote>
<bodyText confidence="0.948558692307692">
alignment model (Ney and Vogel, 1996). We dis-
card all states corresponding to bispans that are
incompatible with 3 or more alignment links un-
der an intersected HMM—a proven approach to
pruning the space of ITG alignments (Zhang and
Gildea, 2006; Haghighi et al., 2009). Pruning in
this way reduces the search space dramatically, but
only rarely prohibits correct alignments. The ora-
cle alignment error rate for the block ITG model
class is 1.4%; the oracle alignment error rate for
er]
this pruned subset of ITG is 2.0%.
To take advantage of the sparsity that results
</bodyText>
<equation confidence="0.349306">
ner]
</equation>
<bodyText confidence="0.999185">
from pruning, we use an agenda-based parser that
orders search states from small to large, where we
er]define the size of a bispan as the total number of
words contained within it. For each size, we main-
tain a separate agenda. Only when the agenda for
size k is exhausted does the parser proceed to pro-
cess the agenda for size k + 1.
</bodyText>
<equation confidence="0.613301">
p]
</equation>
<bodyText confidence="0.999637333333333">
We also employ coarse-to-fine search to speed
) up inference (Charniak and Caraballo, 1998). In
the coarse pass, we search over the space of ITG
alignments, but score only features on alignment
links and bispans that are local to terminal blocks.
This simplification eliminates the need to augment
grammar symbols, and so we can exhaustively ex-
plore the (pruned) space. We then compute out-
side scores for bispans under a max-sum semir-
ing (Goodman, 1996). In the fine pass with the
full extraction set model, we impose a maximum
size of 10,000 for each agenda. We order states on
agendas by the sum of their inside score under the
full model and the outside score computed in the
coarse pass, pruning all states not within the fixed
agenda beam size.
Search states that are popped off agendas are
indexed by their corner locations for fast look-
up when constructing new states. For each cor-
ner and size combination, built states are main-
tained in sorted order according to their inside
score. This ordering allows us to stop combin-
ing states early when the results are falling off the
agenda beams. Similar search and beaming strate-
gies appear in many decoders for machine trans-
lation (Huang and Chiang, 2007; Koehn and Had-
dow, 2009; Moore and Quirk, 2007).
</bodyText>
<subsectionHeader confidence="0.999626">
4.3 Finding Pseudo-Gold ITG Alignments
</subsectionHeader>
<bodyText confidence="0.99358">
Equation 3 asks for the block ITG alignment
Ag that is closest to a reference alignment At,
which may not lie in ITG(e,f). We search for
</bodyText>
<page confidence="0.977632">
1458
</page>
<figure confidence="0.961487">
After dinner I slept
</figure>
<figureCaption confidence="0.999136">
Figure 7: A* search for pseudo-gold ITG align-
</figureCaption>
<bodyText confidence="0.928209294117647">
ments uses an admissible heuristic for bispans that
counts the number of gold links outside of [k, E)
but within [g, h). Above, the heuristic is 1, which
is also the minimal number of alignment errors
that an ITG alignment will incur using this bispan.
Ag using A* bitext parsing (Klein and Manning,
2003). Search states, which correspond to bispans
[g, h) &lt;---&gt; [k, E), are scored by the number of errors
within the bispan plus the number of (i, j) E At
such that j E [k, E) but i E� [g, h) (recall errors).
As an admissible heuristic for the future cost of
a bispan [g, h) &lt;---&gt; [k, E), we count the number of
(i, j) E At such that i E [g, h) but j E� [k, E), as
depicted in Figure 7. These links will become re-
call errors eventually. A* search with this heuristic
makes no errors, and the time required to compute
pseudo-gold alignments is negligible.
</bodyText>
<sectionHeader confidence="0.994339" genericHeader="method">
5 Relationship to Previous Work
</sectionHeader>
<bodyText confidence="0.999968388888889">
Our model is certainly not the first alignment ap-
proach to include structures larger than words.
Model-based phrase-to-phrase alignment was pro-
posed early in the history of phrase-based trans-
lation as a method for training translation models
(Marcu and Wong, 2002). A variety of unsuper-
vised models refined this initial work with priors
(DeNero et al., 2008; Blunsom et al., 2009) and
inference constraints (DeNero et al., 2006; Birch
et al., 2006; Cherry and Lin, 2007; Zhang et al.,
2008). These models fundamentally differ from
ours in that they stipulate a segmentation of the
sentence pair into phrases, and only align the min-
imal phrases in that segmentation. Our model
scores the larger overlapping phrases that result
from composing these minimal phrases.
Discriminative alignment is also a well-
explored area. Most work has focused on pre-
dicting word alignments via partial matching in-
ference algorithms (Melamed, 2000; Taskar et al.,
2005; Moore, 2005; Lacoste-Julien et al., 2006).
Work in semi-supervised estimation has also con-
tributed evidence that hand-annotations are useful
for training alignment models (Fraser and Marcu,
2006; Fraser and Marcu, 2007). The ITG gram-
mar formalism, the corresponding word alignment
class, and inference procedures for the class have
also been explored extensively (Wu, 1997; Zhang
and Gildea, 2005; Cherry and Lin, 2007; Zhang
et al., 2008). At the intersection of these lines of
work, discriminative ITG models have also been
proposed, including one-to-one alignment mod-
els (Cherry and Lin, 2006) and block models
(Haghighi et al., 2009). Our model directly ex-
tends this research agenda with first-class possi-
ble links, overlapping phrasal rule features, and an
extraction-level loss function.
K¨a¨ari¨ainen (2009) trains a translation model
discriminatively using features on overlapping
phrase pairs. That work differs from ours in
that it uses fixed word alignments and focuses on
translation model estimation, while we focus on
alignment and translate using standard relative fre-
quency estimators.
Deng and Zhou (2009) present an alignment
combination technique that uses phrasal features.
Our approach differs in two ways. First, their ap-
proach is tightly coupled to the input alignments,
while we perform a full search over the space of
ITG alignments. Also, their approach uses greedy
search, while our search is optimal aside from
pruning and beaming. Despite these differences,
their strong results reinforce our claim that phrase-
level information is useful for alignment.
</bodyText>
<sectionHeader confidence="0.999674" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.936473666666667">
We evaluate our extraction set model by the bis-
pans it predicts, the word alignments it generates,
and the translations generated by two end-to-end
systems. Table 1 compares the five systems de-
scribed below, including three baselines. All su-
pervised aligners were optimized for bispan F5.
Unsupervised Baseline: GIZA++. We trained
GIZA++ (Och and Ney, 2003) using the default
parameters included with the Moses training script
(Koehn et al., 2007). The designated regimen con-
cludes by Viterbi aligning under Model 4 in both
directions. We combined these alignments with
</bodyText>
<figure confidence="0.9990148125">
[after]
[dinner]
[after]
[I]
[sleep]
[past tense]
k =1
l =4
g =0
h =3
在
晩饭
F
我
睡
了
</figure>
<page confidence="0.992314">
1459
</page>
<bodyText confidence="0.993943138888889">
the grow-diag heuristic (Koehn et al., 2003).
Unsupervised Baseline: Joint HMM. We
trained and combined two HMM alignment mod-
els (Ney and Vogel, 1996) using the Berkeley
Aligner.7 We initialized the HMM model pa-
rameters with jointly trained Model 1 param-
eters (Liang et al., 2006), combined word-to-
word posteriors by averaging (soft union), and de-
coded with the competitive thresholding heuristic
of DeNero and Klein (2007), yielding a state-of-
the-art unsupervised baseline.
Supervised Baseline: Block ITG. We discrimi-
natively trained a block ITG aligner with only sure
links, using block terminal productions up to 3
words by 3 words in size. This supervised base-
line is a reimplementation of the MIRA-trained
model of Haghighi et al. (2009). We use the same
features and parser implementation for this model
as we do for our extraction set model to ensure a
clean comparison. To remain within the alignment
class, MIRA updates this model toward a pseudo-
gold alignment with only sure links. This model
does not score any overlapping bispans.
Extraction Set Coarse Pass. We add possible
links to the output of the block ITG model by
adding the mixed terminal block productions de-
scribed in Section 2.3. This model scores over-
lapping phrasal rules contained within terminal
blocks that result from including or excluding pos-
sible links. However, this model does not score
bispans that cross bracketing of ITG derivations.
Full Extraction Set Model. Our full model in-
cludes possible links and features on extraction
sets for phrasal bispans with a maximum size of
3. Model inference is performed using the coarse-
to-fine scheme described in Section 4.2.
</bodyText>
<subsectionHeader confidence="0.996725">
6.1 Data
</subsectionHeader>
<bodyText confidence="0.9993275">
In this paper, we focus exclusively on Chinese-to-
English translation. We performed our discrimi-
native training and alignment evaluations using a
hand-aligned portion of the NIST MT02 test set,
which consists of 150 training and 191 test sen-
tences (Ayan and Dorr, 2006). We trained the
baseline HMM on 11.3 million words of FBIS
newswire data, a comparable dataset to those used
in previous alignment evaluations on our test set
(DeNero and Klein, 2007; Haghighi et al., 2009).
</bodyText>
<footnote confidence="0.835058">
7http://code.google.com/p/berkeleyaligner
</footnote>
<bodyText confidence="0.999630466666667">
Our end-to-end translation experiments were
tuned and evaluated on sentences up to length 40
from the NIST MT04 and MT05 test sets. For
these experiments, we trained on a 22.1 million
word parallel corpus consisting of sentences up to
length 40 of newswire data from the GALE pro-
gram, subsampled from a larger data set to pro-
mote overlap with the tune and test sets. This cor-
pus also includes a bilingual dictionary. To im-
prove performance, we retrained our aligner on a
retokenized version of the hand-annotated data to
match the tokenization of our corpus.8 We trained
a language model with Kneser-Ney smoothing
on 262 million words of newswire using SRILM
(Stolcke, 2002).
</bodyText>
<subsectionHeader confidence="0.999497">
6.2 Word and Phrase Alignment
</subsectionHeader>
<bodyText confidence="0.9999208">
The first panel of Table 1 gives a word-level eval-
uation of all five aligners. We use the alignment
error rate (AER) measure: precision is the frac-
tion of sure links in the system output that are sure
or possible in the reference, and recall is the frac-
tion of sure links in the reference that the system
outputs as sure. For this evaluation, possible links
produced by our extraction set models are ignored.
The full extraction set model performs the best by
a small margin, although it was not tuned for word
alignment.
The second panel gives a phrasal rule-level
evaluation, which measures the degree to which
these aligners matched the extraction sets of hand-
annotated alignments, R3(At).9 To compete
fairly, all models were evaluated on the full ex-
traction sets induced by the word alignments they
predicted. Again, the extraction set model outper-
formed the baselines, particularly on the F5 mea-
sure for which these systems were trained.
Our coarse pass extraction set model performed
nearly as well as the full model. We believe
these models perform similarly for two reasons.
First, most of the information needed to predict
an extraction set can be inferred from word links
and phrasal rules contained within ITG terminal
productions. Second, the coarse-to-fine inference
may be constraining the full phrasal model to pre-
dict similar output to the coarse model. This simi-
larity persists in translation experiments.
</bodyText>
<footnote confidence="0.9987516">
8All alignment results are reported under the annotated
data set’s original tokenization.
9While pseudo-gold approximations to the annotation
were used for training, the evaluation is always performed
relative to the original human annotation.
</footnote>
<page confidence="0.92668">
1460
</page>
<table confidence="0.999361285714286">
Pr Word AER Pr Bispan F1 F5 BLEU Moses
Rc Rc Joshua
Baseline GIZA++ 72.5 71.8 27.8 69.4 45.4 54.9 46.0 33.8 32.6
models Joint HMM 84.0 76.9 19.6 69.5 59.5 64.1 59.9 34.5 33.2
Block ITG 83.4 83.8 16.4 75.8 62.3 68.4 62.8 34.7 33.6
Extraction Coarse Pass 82.2 84.2 16.9 70.0 72.9 71.4 72.8 35.7 34.2
set models Full Model 84.7 84.0 15.6 69.0 74.2 71.6 74.0 35.9 34.4
</table>
<tableCaption confidence="0.728930166666667">
Table 1: Experimental results demonstrate that the full extraction set model outperforms supervised and
unsupervised baselines in evaluations of word alignment quality, extraction set quality, and translation.
In word and bispan evaluations, GIZA++ did not have access to a dictionary while all other methods
did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The
BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate
for parse failures.
</tableCaption>
<subsectionHeader confidence="0.994021">
6.3 Translation Experiments
</subsectionHeader>
<bodyText confidence="0.999977934782609">
We evaluate the alignments predicted by our
model using two publicly available, open-source,
state-of-the-art translation systems. Moses is a
phrase-based system with lexicalized reordering
(Koehn et al., 2007). Joshua (Li et al., 2009) is
an implementation of Hiero (Chiang, 2007) using
a suffix-array-based grammar extraction approach
(Lopez, 2007).
Both of these systems take word alignments as
input, and neither of these systems accepts possi-
ble links in the alignments they consume. To inter-
face with our extraction set models, we produced
three sets of sure-only alignments from our model
predictions: one that omitted possible links, one
that converted all possible links to sure links, and
one that includes each possible link with 0.5 prob-
ability. These three sets were aggregated and rules
were extracted from all three.
The training set we used for MT experiments
is quite heterogenous and noisy compared to our
alignment test sets, and the supervised aligners
did not handle certain sentence pairs in our par-
allel corpus well. In some cases, pruning based
on consistency with the HMM caused parse fail-
ures, which in turn caused training sentences to be
skipped. To account for these issues, we added
counts of phrasal rules extracted from the baseline
HMM to the counts produced by supervised align-
ers.
In Moses, our extraction set model predicts the
set of phrases extracted by the system, and so the
estimation techniques for the alignment model and
translation model both share a common underly-
ing representation: extraction sets. Empirically,
we observe a BLEU score improvement of 1.2
over the best unsupervised baseline and 0.8 over
the block ITG supervised baseline (Papineni et al.,
2002).
In Joshua, hierarchical rule extraction is based
upon phrasal rule extraction, but abstracts away
sub-phrases to create a grammar. Hence, the ex-
traction sets we predict are closely linked to the
representation that this system uses to translate.
The extraction model again outperformed both un-
supervised and supervised baselines, by 1.4 BLEU
and 1.2 BLEU respectively.
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999965727272727">
Our extraction set model serves to coordinate the
alignment and translation model components of a
statistical translation system by unifying their rep-
resentations. Moreover, our model provides an ef-
fective alternative to phrase alignment models that
choose a particular phrase segmentation; instead,
we predict many overlapping phrases, both large
and small, that are mutually consistent. In future
work, we look forward to developing extraction
set models for richer formalisms, including hier-
archical grammars.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99994125">
This project is funded in part by BBN under
DARPA contract HR0011-06-C-0022 and by the
NSF under grant 0643742. We thank the anony-
mous reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.99093" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.390909666666667">
Necip Fazil Ayan and Bonnie J. Dorr. 2006. Going
beyond AER: An extensive analysis of word align-
ments and their impact on MT. In Proceedings of
</bodyText>
<page confidence="0.976167">
1461
</page>
<reference confidence="0.998583872727273">
the Annual Conference of the Association for Com-
putational Linguistics.
Necip Fazil Ayan, Bonnie J. Dorr, and Christof Monz.
2005. Neuralign: combining word alignments us-
ing neural networks. In Proceedings of the Confer-
ence on Human Language Technology and Empiri-
cal Methods in Natural Language Processing.
Alexandra Birch, Chris Callison-Burch, and Miles Os-
borne. 2006. Constraining the phrase-based, joint
probability statistical translation model. In Proceed-
ings of the Conference for the Association for Ma-
chine Translation in the Americas.
Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Os-
borne. 2009. A Gibbs sampler for phrasal syn-
chronous grammar induction. In Proceedings of the
Annual Conference of the Association for Computa-
tional Linguistics.
Eugene Charniak and Sharon Caraballo. 1998. New
figures of merit for best-first probabilistic chart pars-
ing. In Computational Linguistics.
Colin Cherry and Dekang Lin. 2006. Soft syntactic
constraints for word alignment through discrimina-
tive training. In Proceedings of the Annual Confer-
ence of the Association for Computational Linguis-
tics.
Colin Cherry and Dekang Lin. 2007. Inversion trans-
duction grammar for joint phrasal translation mod-
eling. In Proceedings of the Annual Conference of
the North American Chapter of the Association for
Computational Linguistics Workshop on Syntax and
Structure in Statistical Translation.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal of Machine Learning Research, 3:951–991.
John DeNero and Dan Klein. 2007. Tailoring word
alignments to syntactic machine translation. In Pro-
ceedings of the Annual Conference of the Associa-
tion for Computational Linguistics.
John DeNero and Dan Klein. 2008. The complexity of
phrase alignment problems. In Proceedings of the
Annual Conference of the Association for Computa-
tional Linguistics: Short Paper Track.
John DeNero, Dan Gillick, James Zhang, and Dan
Klein. 2006. Why generative phrase models un-
derperform surface heuristics. In Proceedings of the
NAACL Workshop on Statistical Machine Transla-
tion.
John DeNero, Alexandre Bouchard-Cote, and Dan
Klein. 2008. Sampling alignment structure under
a bayesian translation model. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing.
Yonggang Deng and Bowen Zhou. 2009. Optimizing
word alignment combination for phrase table train-
ing. In Proceedings of the Annual Conference of the
Association for Computational Linguistics: Short
Paper Track.
Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
Proceedings of the Annual Conference of the Asso-
ciation for Computational Linguistics.
Alexander Fraser and Daniel Marcu. 2007. Getting
the structure right for word alignment: Leaf. In Pro-
ceedings of the Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Pro-
ceedings of the Annual Conference of the Associa-
tion for Computational Linguistics.
Joshua Goodman. 1996. Parsing algorithms and met-
rics. In Proceedings of the Annual Meeting of the
Association for Computational Linguistics.
Aria Haghighi, John Blitzer, John DeNero, and Dan
Klein. 2009. Better word alignments with super-
vised ITG models. In Proceedings of the Annual
Conference of the Association for Computational
Linguistics.
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Faster decoding with integrated language mod-
els. In Proceedings of the Annual Conference of the
Association for Computational Linguistics.
Matti K¨a¨ari¨ainen. 2009. Sinuhe—statistical machine
translation using a globally trained conditional ex-
ponential family translation model. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.
Dan Klein and Chris Manning. 2003. A* parsing: Fast
exact Viterbi parse selection. In Proceedings of the
Conference of the North American Chapter of the
Association for Computational Linguistics.
Philipp Koehn and Barry Haddow. 2009. Edinburghs
submission to all tracks of the WMT2009 shared
task with reordering and speed improvements to
Moses. In Proceedings of the Workshop on Statis-
tical Machine Translation.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Pro-
ceedings of the Conference of the North American
Chapter of the Association for Computational Lin-
guistics.
</reference>
<page confidence="0.868331">
1462
</page>
<reference confidence="0.999864268292683">
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the Annual Conference of the Associ-
ation for Computational Linguistics: Demonstration
track.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael I. Jordan. 2006. Word alignment via
quadratic assignment. In Proceedings of the Annual
Conference of the North American Chapter of the
Association for Computational Linguistics.
Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Gan-
itkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren
Thornton, Jonathan Weese, and Omar Zaidan. 2009.
Joshua: An open source toolkit for parsing-based
machine translation. In Proceedings of the Work-
shop on Statistical Machine Translation.
Percy Liang, Ben Taskar, and Dan Klein. 2006. Align-
ment by agreement. In Proceedings of the Annual
Conference of the North American Chapter of the
Association for Computational Linguistics.
Adam Lopez. 2007. Hierarchical phrase-based trans-
lation with suffix arrays. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing.
Daniel Marcu and Daniel Wong. 2002. A phrase-
based, joint probability model for statistical machine
translation. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics.
Robert Moore and Chris Quirk. 2007. Faster
beam-search decoding for phrasal statistical ma-
chine translation. In Proceedings of MT Summit XI.
Robert C. Moore. 2005. A discriminative framework
for bilingual word alignment. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing.
Hermann Ney and Stephan Vogel. 1996. HMM-based
word alignment in statistical translation. In Pro-
ceedings of the Conference on Computational lin-
guistics.
Franz Josef Och and Hermann Ney. 2003. A sys-
tematic comparison of various statistical alignment
models. Computational Linguistics, 29:19–51.
Franz Josef Och, Christoph Tillmann, and Hermann
Ney. 1999. Improved alignment models for statisti-
cal machine translation. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In Proceedings of
the Annual Conference of the Association for Com-
putational Linguistics.
Andreas Stolcke. 2002. Srilm an extensible language
modeling toolkit. In Proceedings of the Interna-
tional Conference on Spoken Language Processing.
Ben Taskar, Simon Lacoste-Julien, and Dan Klein.
2005. A discriminative matching approach to word
alignment. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23:377–404.
Hao Zhang and Daniel Gildea. 2005. Stochastic lex-
icalized inversion transduction grammar for align-
ment. In Proceedings of the Annual Conference of
the Association for Computational Linguistics.
Hao Zhang and Daniel Gildea. 2006. Efficient search
for inversion transduction grammar. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.
Hao Zhang, Chris Quirk, Robert C. Moore, and
Daniel Gildea. 2008. Bayesian learning of non-
compositional phrases with synchronous parsing. In
Proceedings of the Annual Conference of the Asso-
ciation for Computational Linguistics.
</reference>
<page confidence="0.922275">
1463
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.960909">
<title confidence="0.999738">Discriminative Modeling of Extraction Sets for Machine Translation</title>
<author confidence="0.998491">DeNero Klein</author>
<affiliation confidence="0.9960105">Computer Science Division University of California, Berkeley</affiliation>
<abstract confidence="0.998578095238095">We present a discriminative model that directly predicts which set of phrasal translation rules should be extracted from a senpair. Our model scores nested collections of all the overlapping phrase pairs consistent with an underlying word alignment. Extraction set models provide two principle advantages over word-factored alignment models. First, we can incorporate features on phrase pairs, in addition to word links. Second, we can optimize for an extraction-based loss function that relates directly to the end task of generating translations. Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>the Annual Conference of the Association for Computational Linguistics.</booktitle>
<marker></marker>
<rawString>the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Necip Fazil Ayan</author>
<author>Bonnie J Dorr</author>
<author>Christof Monz</author>
</authors>
<title>Neuralign: combining word alignments using neural networks.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="7873" citStr="Ayan et al., 2005" startWordPosition="1278" endWordPosition="1281">ed from a sentence pair. 2.2 Possible and Null Alignment Links We have not yet accounted for two special cases in annotated corpora: possible alignments and null alignments. To analyze these annotations, we consider a particular data set: a hand-aligned portion 1We use the fencepost indexing scheme used commonly for parsing. Words are 0-indexed. Spans are inclusive on the lower bound and exclusive on the upper bound. For example, the span [0, 2) includes the first two words of a sentence. 1454 of the NIST MT02 Chinese-to-English test set, which has been used in previous alignment experiments (Ayan et al., 2005; DeNero and Klein, 2007; Haghighi et al., 2009). Possible links account for 22% of all alignment links in these data, and we found that most of these links fall into two categories. First, possible links are used to align function words that have no equivalent in the other language, but colocate with aligned content words, such as English determiners. Second, they are used to mark pairs of words or short phrases that are not lexical equivalents, but which play equivalent roles in each sentence. Figure 2 shows examples of these two use cases, along with their corpus frequencies.2 On the other </context>
</contexts>
<marker>Ayan, Dorr, Monz, 2005</marker>
<rawString>Necip Fazil Ayan, Bonnie J. Dorr, and Christof Monz. 2005. Neuralign: combining word alignments using neural networks. In Proceedings of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Constraining the phrase-based, joint probability statistical translation model.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference for the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="25276" citStr="Birch et al., 2006" startWordPosition="4287" endWordPosition="4290">l errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed</context>
</contexts>
<marker>Birch, Callison-Burch, Osborne, 2006</marker>
<rawString>Alexandra Birch, Chris Callison-Burch, and Miles Osborne. 2006. Constraining the phrase-based, joint probability statistical translation model. In Proceedings of the Conference for the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phil Blunsom</author>
<author>Trevor Cohn</author>
<author>Chris Dyer</author>
<author>Miles Osborne</author>
</authors>
<title>A Gibbs sampler for phrasal synchronous grammar induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="25209" citStr="Blunsom et al., 2009" startWordPosition="4276" endWordPosition="4279">ut j E� [k, E), as depicted in Figure 7. These links will become recall errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et </context>
</contexts>
<marker>Blunsom, Cohn, Dyer, Osborne, 2009</marker>
<rawString>Phil Blunsom, Trevor Cohn, Chris Dyer, and Miles Osborne. 2009. A Gibbs sampler for phrasal synchronous grammar induction. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Sharon Caraballo</author>
</authors>
<title>New figures of merit for best-first probabilistic chart parsing.</title>
<date>1998</date>
<booktitle>In Computational Linguistics.</booktitle>
<contexts>
<context position="22530" citStr="Charniak and Caraballo, 1998" startWordPosition="3800" endWordPosition="3803">s. The oracle alignment error rate for the block ITG model class is 1.4%; the oracle alignment error rate for er] this pruned subset of ITG is 2.0%. To take advantage of the sparsity that results ner] from pruning, we use an agenda-based parser that orders search states from small to large, where we er]define the size of a bispan as the total number of words contained within it. For each size, we maintain a separate agenda. Only when the agenda for size k is exhausted does the parser proceed to process the agenda for size k + 1. p] We also employ coarse-to-fine search to speed ) up inference (Charniak and Caraballo, 1998). In the coarse pass, we search over the space of ITG alignments, but score only features on alignment links and bispans that are local to terminal blocks. This simplification eliminates the need to augment grammar symbols, and so we can exhaustively explore the (pruned) space. We then compute outside scores for bispans under a max-sum semiring (Goodman, 1996). In the fine pass with the full extraction set model, we impose a maximum size of 10,000 for each agenda. We order states on agendas by the sum of their inside score under the full model and the outside score computed in the coarse pass,</context>
</contexts>
<marker>Charniak, Caraballo, 1998</marker>
<rawString>Eugene Charniak and Sharon Caraballo. 1998. New figures of merit for best-first probabilistic chart parsing. In Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26374" citStr="Cherry and Lin, 2006" startWordPosition="4456" endWordPosition="4459">00; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K¨a¨ari¨ainen (2009) trains a translation model discriminatively using features on overlapping phrase pairs. That work differs from ours in that it uses fixed word alignments and focuses on translation model estimation, while we focus on alignment and translate using standard relative frequency estimators. Deng and Zhou (2009) present an alignment combination technique that uses phrasal features. Ou</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Inversion transduction grammar for joint phrasal translation modeling.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics Workshop on Syntax and Structure in Statistical Translation.</booktitle>
<contexts>
<context position="11713" citStr="Cherry and Lin, 2007" startWordPosition="1947" endWordPosition="1950">out loss of information, although we emphasize that A is a set of sure and possible alignments, and φ(A) does not decompose as a sum of vectors on individual word-level alignment links. Our model is parameterized by a weight vector θ, which scores an extraction set Rn(A) as θ · φ(A). To further limit the space of extraction sets we are willing to consider, we restrict A to block inverse transduction grammar (ITG) alignments, a space that allows many-to-many alignments through phrasal terminal productions, but otherwise enforces at-most-one-to-one phrase matchings with ITG reordering patterns (Cherry and Lin, 2007; Zhang et al., 2008). The ITG constraint 2月 15日 E φ�(i, j) + E φb(g, h, k, `) (i,j)EAW [g,h)q[V)ERn(A) 1455 Figure 4: Above, we show a representative subset of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model. These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links. is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is e</context>
<context position="25298" citStr="Cherry and Lin, 2007" startWordPosition="4291" endWordPosition="4294"> A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-an</context>
</contexts>
<marker>Cherry, Lin, 2007</marker>
<rawString>Colin Cherry and Dekang Lin. 2007. Inversion transduction grammar for joint phrasal translation modeling. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics Workshop on Syntax and Structure in Statistical Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="13061" citStr="Chiang et al., 2008" startWordPosition="2174" endWordPosition="2177"> summary, our model scores all Rn(A) for A ∈ ITG(e, f) where A can include block terminals of size up to n. In our experiments, n = 3. Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4. 3 Model Estimation We estimate the weights θ of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Crammer and Singer (2003)—a large-margin, perceptron-style, online learning algorithm. MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al., 2009) and translation models (Chiang et al., 2008). For each training example, MIRA requires that we find the alignment Am corresponding to the highest scoring extraction set Rn(Am) under the current model, Am = arg maxAEITG(e,f)θ · φ(A) (2) Section 4 describes our approach to solving this search problem for model inference. MIRA updates away from Rn(Am) and toward a gold extraction set Rn(Ag). Some handannotated alignments are outside of the block ITG model class. Hence, we update toward the extraction set for a pseudo-gold alignment Ag ∈ ITG(e, f) with minimal distance from the true reference alignment At. Ag = arg minAEITG(e,f)|A ∪ At − A </context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation. Computational Linguistics.</title>
<date>2007</date>
<contexts>
<context position="5883" citStr="Chiang, 2007" startWordPosition="909" endWordPosition="911">9) 2 Extraction Set Models The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules. Word-level alignments are generated as a byproduct of inference. We first specify the relationship between word alignments and extraction sets, then define our model. 2.1 Extraction Sets from Word Alignments Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Chiang, 2007), count of internal tree nodes (Galley et al., 2006), etc. In this paper, we focus on phrasal rule extraction (i.e., phrase pair extraction), upon which most other extraction procedures are based. Given a sentence pair (e, f), phrasal rule extraction defines a mapping from a set of word-to-word 31% 被 [passive marker] 发现 发现 [s [discover] w c was discovered Figure 2: Examples of two types of possible alignσ(e) ment links (striped). These types account for 96% 2010年 of the possible alignment links in our data set. alignment links A = {(i, j)} to an extraction set (f�) of bispans Rn(A) = {[g, h) &lt;</context>
<context position="20819" citStr="Chiang, 2007" startWordPosition="3513" endWordPosition="3514">A, and (b) Aftr dinner I slept whether any sure alignments appear in the rows or columns extending from those corners.6 With this information, we can infer the bispans licensed by adjoining AL and AR, as in Figure 6. Applying our score recurrence yields a polynomial-time dynamic program. This dynamic program is an instance of ITG bitext parsing, where the grammar uses symbols to encode the alignment contexts described above. This context-as-symbol augmentation of the grammar is similar in character to augmenting symbols with lexical items to score language models during hierarchical decoding (Chiang, 2007). 4.2 Coarse-to-Fine Inference and Pruning Exhaustive inference under an ITG requires O(k�) time in sentence length k, and is prohibitively slow when there is no sparsity in the grammar. Maintaining the context necessary to score non-local bispans further increases running time. That is, ITG inference is organized around search states associated with a grammar symbol and a bispan; augmenting grammar symbols also augments this state space. To parse quickly, we prune away search states using predictions from the more efficient HMM 6The number of configuration states does not depend on the size o</context>
<context position="23645" citStr="Chiang, 2007" startWordPosition="3996" endWordPosition="3997">sum of their inside score under the full model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size. Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states. For each corner and size combination, built states are maintained in sorted order according to their inside score. This ordering allows us to stop combining states early when the results are falling off the agenda beams. Similar search and beaming strategies appear in many decoders for machine translation (Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007). 4.3 Finding Pseudo-Gold ITG Alignments Equation 3 asks for the block ITG alignment Ag that is closest to a reference alignment At, which may not lie in ITG(e,f). We search for 1458 After dinner I slept Figure 7: A* search for pseudo-gold ITG alignments uses an admissible heuristic for bispans that counts the number of gold links outside of [k, E) but within [g, h). Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan. Ag using A* bitext parsing (Klein and Manning, 200</context>
<context position="33795" citStr="Chiang, 2007" startWordPosition="5649" endWordPosition="5650"> evaluations, GIZA++ did not have access to a dictionary while all other methods did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate for parse failures. 6.3 Translation Experiments We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems. Moses is a phrase-based system with lexicalized reordering (Koehn et al., 2007). Joshua (Li et al., 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume. To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability. These three sets were aggregated and rules were extracted from all three. The training set we used for MT experiments is qu</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="12859" citStr="Crammer and Singer (2003)" startWordPosition="2144" endWordPosition="2147"> 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in handannotated parallel corpora (Haghighi et al., 2009). In summary, our model scores all Rn(A) for A ∈ ITG(e, f) where A can include block terminals of size up to n. In our experiments, n = 3. Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4. 3 Model Estimation We estimate the weights θ of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Crammer and Singer (2003)—a large-margin, perceptron-style, online learning algorithm. MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al., 2009) and translation models (Chiang et al., 2008). For each training example, MIRA requires that we find the alignment Am corresponding to the highest scoring extraction set Rn(Am) under the current model, Am = arg maxAEITG(e,f)θ · φ(A) (2) Section 4 describes our approach to solving this search problem for model inference. MIRA updates away from Rn(Am) and toward a gold extraction set Rn(Ag). Some handannotated alignments are outside of the b</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailoring word alignments to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7897" citStr="DeNero and Klein, 2007" startWordPosition="1282" endWordPosition="1285">pair. 2.2 Possible and Null Alignment Links We have not yet accounted for two special cases in annotated corpora: possible alignments and null alignments. To analyze these annotations, we consider a particular data set: a hand-aligned portion 1We use the fencepost indexing scheme used commonly for parsing. Words are 0-indexed. Spans are inclusive on the lower bound and exclusive on the upper bound. For example, the span [0, 2) includes the first two words of a sentence. 1454 of the NIST MT02 Chinese-to-English test set, which has been used in previous alignment experiments (Ayan et al., 2005; DeNero and Klein, 2007; Haghighi et al., 2009). Possible links account for 22% of all alignment links in these data, and we found that most of these links fall into two categories. First, possible links are used to align function words that have no equivalent in the other language, but colocate with aligned content words, such as English determiners. Second, they are used to mark pairs of words or short phrases that are not lexical equivalents, but which play equivalent roles in each sentence. Figure 2 shows examples of these two use cases, along with their corpus frequencies.2 On the other hand, null alignments ar</context>
<context position="28455" citStr="DeNero and Klein (2007)" startWordPosition="4784" endWordPosition="4787">nated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with [after] [dinner] [after] [I] [sleep] [past tense] k =1 l =4 g =0 h =3 在 晩饭 F 我 睡 了 1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline. Supervised Baseline: Block ITG. We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size. This supervised baseline is a reimplementation of the MIRA-trained model of Haghighi et al. (2009). We use the same features and parser implementation for this model as we do for our extraction set model to ensure a clean comparison. To remain within the alignment class, MIRA updates this model toward a pseudogold alignment with only sure links. This model does not score any o</context>
<context position="30143" citStr="DeNero and Klein, 2007" startWordPosition="5061" endWordPosition="5064">d features on extraction sets for phrasal bispans with a maximum size of 3. Model inference is performed using the coarseto-fine scheme described in Section 4.2. 6.1 Data In this paper, we focus exclusively on Chinese-toEnglish translation. We performed our discriminative training and alignment evaluations using a hand-aligned portion of the NIST MT02 test set, which consists of 150 training and 191 test sentences (Ayan and Dorr, 2006). We trained the baseline HMM on 11.3 million words of FBIS newswire data, a comparable dataset to those used in previous alignment evaluations on our test set (DeNero and Klein, 2007; Haghighi et al., 2009). 7http://code.google.com/p/berkeleyaligner Our end-to-end translation experiments were tuned and evaluated on sentences up to length 40 from the NIST MT04 and MT05 test sets. For these experiments, we trained on a 22.1 million word parallel corpus consisting of sentences up to length 40 of newswire data from the GALE program, subsampled from a larger data set to promote overlap with the tune and test sets. This corpus also includes a bilingual dictionary. To improve performance, we retrained our aligner on a retokenized version of the hand-annotated data to match the t</context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailoring word alignments to syntactic machine translation. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>The complexity of phrase alignment problems.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics: Short Paper Track.</booktitle>
<contexts>
<context position="12264" citStr="DeNero and Klein, 2008" startWordPosition="2041" endWordPosition="2044">-one phrase matchings with ITG reordering patterns (Cherry and Lin, 2007; Zhang et al., 2008). The ITG constraint 2月 15日 E φ�(i, j) + E φb(g, h, k, `) (i,j)EAW [g,h)q[V)ERn(A) 1455 Figure 4: Above, we show a representative subset of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model. These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links. is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in handannotated parallel corpora (Haghighi et al., 2009). In summary, our model scores all Rn(A) for A ∈ ITG(e, f) where A can include block terminals of size up to n. In our experiments, n = 3. Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4. 3 Model Estimation We estimate the weights θ of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Crammer and Singer (2003)—a la</context>
</contexts>
<marker>DeNero, Klein, 2008</marker>
<rawString>John DeNero and Dan Klein. 2008. The complexity of phrase alignment problems. In Proceedings of the Annual Conference of the Association for Computational Linguistics: Short Paper Track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Gillick</author>
<author>James Zhang</author>
<author>Dan Klein</author>
</authors>
<title>Why generative phrase models underperform surface heuristics.</title>
<date>2006</date>
<booktitle>In Proceedings of the NAACL Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="25256" citStr="DeNero et al., 2006" startWordPosition="4283" endWordPosition="4286">nks will become recall errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation </context>
</contexts>
<marker>DeNero, Gillick, Zhang, Klein, 2006</marker>
<rawString>John DeNero, Dan Gillick, James Zhang, and Dan Klein. 2006. Why generative phrase models underperform surface heuristics. In Proceedings of the NAACL Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Alexandre Bouchard-Cote</author>
<author>Dan Klein</author>
</authors>
<title>Sampling alignment structure under a bayesian translation model.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="25186" citStr="DeNero et al., 2008" startWordPosition="4272" endWordPosition="4275">uch that i E [g, h) but j E� [k, E), as depicted in Figure 7. These links will become recall errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2</context>
</contexts>
<marker>DeNero, Bouchard-Cote, Klein, 2008</marker>
<rawString>John DeNero, Alexandre Bouchard-Cote, and Dan Klein. 2008. Sampling alignment structure under a bayesian translation model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonggang Deng</author>
<author>Bowen Zhou</author>
</authors>
<title>Optimizing word alignment combination for phrase table training.</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics: Short Paper Track.</booktitle>
<contexts>
<context position="26900" citStr="Deng and Zhou (2009)" startWordPosition="4533" endWordPosition="4536">G models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K¨a¨ari¨ainen (2009) trains a translation model discriminatively using features on overlapping phrase pairs. That work differs from ours in that it uses fixed word alignments and focuses on translation model estimation, while we focus on alignment and translate using standard relative frequency estimators. Deng and Zhou (2009) present an alignment combination technique that uses phrasal features. Our approach differs in two ways. First, their approach is tightly coupled to the input alignments, while we perform a full search over the space of ITG alignments. Also, their approach uses greedy search, while our search is optimal aside from pruning and beaming. Despite these differences, their strong results reinforce our claim that phraselevel information is useful for alignment. 6 Experiments We evaluate our extraction set model by the bispans it predicts, the word alignments it generates, and the translations genera</context>
</contexts>
<marker>Deng, Zhou, 2009</marker>
<rawString>Yonggang Deng and Bowen Zhou. 2009. Optimizing word alignment combination for phrase table training. In Proceedings of the Annual Conference of the Association for Computational Linguistics: Short Paper Track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Semisupervised training for statistical word alignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15066" citStr="Fraser and Marcu, 2006" startWordPosition="2538" endWordPosition="2541">g the right bispans, we use an extraction-level loss L(Am; Ag): an F-measure of the overlap between bispans in Rn(Am) and Rn(Ag). This measure has been proposed previously to evaluate alignment systems (Ayan and Dorr, 2006). Based on preliminary translation results during development, we chose bispan F5 as our loss: Pr(Am) = |Rn(Am) ∩ Rn(Ag)|/|Rn(Am)| Rc(Am) = |Rn(Am) ∩ Rn(Ag)|/|Rn(Ag)| (1 + 5 2) · Pr(Am) · Rc(Am) F5 (Am; Ag) = 52 · Pr(Am) + Rc(Am) L(Am; Ag) = 1 − F5(Am; Ag) F5 favors recall over precision. Previous alignment work has shown improvements from adjusting the F-measure parameter (Fraser and Marcu, 2006). In particular, Lacoste-Julien et al. (2006) also chose a recall-biased objective. Optimizing for a bispan F-measure penalizes alignment mistakes in proportion to their rule extraction consequences. That is, adding a word link that prevents the extraction of many correct phrasal rules, or which licenses many incorrect rules, is strongly discouraged by this loss. 1456 3.2 Features on Extraction Sets The discriminative power of our model is driven by the features on sure word alignment links φa(i, j) and bispans φb(g, h, k, `). In both cases, the most important features come from the prediction</context>
<context position="25972" citStr="Fraser and Marcu, 2006" startWordPosition="4393" endWordPosition="4396">ffer from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. </context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2006. Semisupervised training for statistical word alignment. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Getting the structure right for word alignment: Leaf.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="25997" citStr="Fraser and Marcu, 2007" startWordPosition="4397" endWordPosition="4400">hey stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K¨a¨ari¨ainen (2009) trai</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Getting the structure right for word alignment: Leaf. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5935" citStr="Galley et al., 2006" startWordPosition="917" endWordPosition="920">odel is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules. Word-level alignments are generated as a byproduct of inference. We first specify the relationship between word alignments and extraction sets, then define our model. 2.1 Extraction Sets from Word Alignments Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Chiang, 2007), count of internal tree nodes (Galley et al., 2006), etc. In this paper, we focus on phrasal rule extraction (i.e., phrase pair extraction), upon which most other extraction procedures are based. Given a sentence pair (e, f), phrasal rule extraction defines a mapping from a set of word-to-word 31% 被 [passive marker] 发现 发现 [s [discover] w c was discovered Figure 2: Examples of two types of possible alignσ(e) ment links (striped). These types account for 96% 2010年 of the possible alignment links in our data set. alignment links A = {(i, j)} to an extraction set (f�) of bispans Rn(A) = {[g, h) &lt;---&gt; [k, `)}, where 5日 月 each bispan links target sp</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Parsing algorithms and metrics.</title>
<date>1996</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="22892" citStr="Goodman, 1996" startWordPosition="3863" endWordPosition="3864"> it. For each size, we maintain a separate agenda. Only when the agenda for size k is exhausted does the parser proceed to process the agenda for size k + 1. p] We also employ coarse-to-fine search to speed ) up inference (Charniak and Caraballo, 1998). In the coarse pass, we search over the space of ITG alignments, but score only features on alignment links and bispans that are local to terminal blocks. This simplification eliminates the need to augment grammar symbols, and so we can exhaustively explore the (pruned) space. We then compute outside scores for bispans under a max-sum semiring (Goodman, 1996). In the fine pass with the full extraction set model, we impose a maximum size of 10,000 for each agenda. We order states on agendas by the sum of their inside score under the full model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size. Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states. For each corner and size combination, built states are maintained in sorted order according to their inside score. This ordering allows us to stop combining states early when th</context>
</contexts>
<marker>Goodman, 1996</marker>
<rawString>Joshua Goodman. 1996. Parsing algorithms and metrics. In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>John Blitzer</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Better word alignments with supervised ITG models.</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="7921" citStr="Haghighi et al., 2009" startWordPosition="1286" endWordPosition="1289">ull Alignment Links We have not yet accounted for two special cases in annotated corpora: possible alignments and null alignments. To analyze these annotations, we consider a particular data set: a hand-aligned portion 1We use the fencepost indexing scheme used commonly for parsing. Words are 0-indexed. Spans are inclusive on the lower bound and exclusive on the upper bound. For example, the span [0, 2) includes the first two words of a sentence. 1454 of the NIST MT02 Chinese-to-English test set, which has been used in previous alignment experiments (Ayan et al., 2005; DeNero and Klein, 2007; Haghighi et al., 2009). Possible links account for 22% of all alignment links in these data, and we found that most of these links fall into two categories. First, possible links are used to align function words that have no equivalent in the other language, but colocate with aligned content words, such as English determiners. Second, they are used to mark pairs of words or short phrases that are not lexical equivalents, but which play equivalent roles in each sentence. Figure 2 shows examples of these two use cases, along with their corpus frequencies.2 On the other hand, null alignments are used sparingly in our </context>
<context position="12437" citStr="Haghighi et al., 2009" startWordPosition="2068" endWordPosition="2071">) 1455 Figure 4: Above, we show a representative subset of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model. These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links. is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in handannotated parallel corpora (Haghighi et al., 2009). In summary, our model scores all Rn(A) for A ∈ ITG(e, f) where A can include block terminals of size up to n. In our experiments, n = 3. Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4. 3 Model Estimation We estimate the weights θ of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Crammer and Singer (2003)—a large-margin, perceptron-style, online learning algorithm. MIRA has been used successfully in MT to estimate both alignment models (Haghighi et al., 2009) and translation mode</context>
<context position="16676" citStr="Haghighi et al. (2009)" startWordPosition="2793" endWordPosition="2796"> punctuation. To score phrasal translation rules in an extraction set, we use a mixture of feature types. Extraction set models allow us to incorporate the same phrasal relative frequency statistics that drive phrase-based translation performance (Koehn et al., 2003). To implement these frequency features, we extract a phrase table from the alignment predictions of a jointly trained unsupervised HMM model using Moses (Koehn et al., 2007), and score bispans using the resulting features. We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al. (2009). We include indicators for the number of words and Chinese characters in rules. One useful indicator feature exploits the fact that capitalized terms in English tend to align to Chinese words with three or more characters. On 1-by-n or n-by-1 phrasal rules, we include indicator features of fertility for common words.3 We also include monolingual phrase features that expose useful information to the model. For instance, English bigrams beginning with “the” are often extractable phrases. English trigrams with a hyphen as the second word are typically extractable, meaning that the first and thir</context>
<context position="21797" citStr="Haghighi et al., 2009" startWordPosition="3669" endWordPosition="3672">rammar symbol and a bispan; augmenting grammar symbols also augments this state space. To parse quickly, we prune away search states using predictions from the more efficient HMM 6The number of configuration states does not depend on the size of ,A because corners have fixed size, and because the position of links within rows or columns is not needed. alignment model (Ney and Vogel, 1996). We discard all states corresponding to bispans that are incompatible with 3 or more alignment links under an intersected HMM—a proven approach to pruning the space of ITG alignments (Zhang and Gildea, 2006; Haghighi et al., 2009). Pruning in this way reduces the search space dramatically, but only rarely prohibits correct alignments. The oracle alignment error rate for the block ITG model class is 1.4%; the oracle alignment error rate for er] this pruned subset of ITG is 2.0%. To take advantage of the sparsity that results ner] from pruning, we use an agenda-based parser that orders search states from small to large, where we er]define the size of a bispan as the total number of words contained within it. For each size, we maintain a separate agenda. Only when the agenda for size k is exhausted does the parser proceed</context>
<context position="26415" citStr="Haghighi et al., 2009" startWordPosition="4463" endWordPosition="4466">coste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K¨a¨ari¨ainen (2009) trains a translation model discriminatively using features on overlapping phrase pairs. That work differs from ours in that it uses fixed word alignments and focuses on translation model estimation, while we focus on alignment and translate using standard relative frequency estimators. Deng and Zhou (2009) present an alignment combination technique that uses phrasal features. Our approach differs in two ways. First, th</context>
<context position="28774" citStr="Haghighi et al. (2009)" startWordPosition="4835" endWordPosition="4838">t models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline. Supervised Baseline: Block ITG. We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size. This supervised baseline is a reimplementation of the MIRA-trained model of Haghighi et al. (2009). We use the same features and parser implementation for this model as we do for our extraction set model to ensure a clean comparison. To remain within the alignment class, MIRA updates this model toward a pseudogold alignment with only sure links. This model does not score any overlapping bispans. Extraction Set Coarse Pass. We add possible links to the output of the block ITG model by adding the mixed terminal block productions described in Section 2.3. This model scores overlapping phrasal rules contained within terminal blocks that result from including or excluding possible links. Howeve</context>
<context position="30167" citStr="Haghighi et al., 2009" startWordPosition="5065" endWordPosition="5068"> sets for phrasal bispans with a maximum size of 3. Model inference is performed using the coarseto-fine scheme described in Section 4.2. 6.1 Data In this paper, we focus exclusively on Chinese-toEnglish translation. We performed our discriminative training and alignment evaluations using a hand-aligned portion of the NIST MT02 test set, which consists of 150 training and 191 test sentences (Ayan and Dorr, 2006). We trained the baseline HMM on 11.3 million words of FBIS newswire data, a comparable dataset to those used in previous alignment evaluations on our test set (DeNero and Klein, 2007; Haghighi et al., 2009). 7http://code.google.com/p/berkeleyaligner Our end-to-end translation experiments were tuned and evaluated on sentences up to length 40 from the NIST MT04 and MT05 test sets. For these experiments, we trained on a 22.1 million word parallel corpus consisting of sentences up to length 40 of newswire data from the GALE program, subsampled from a larger data set to promote overlap with the tune and test sets. This corpus also includes a bilingual dictionary. To improve performance, we retrained our aligner on a retokenized version of the hand-annotated data to match the tokenization of our corpu</context>
</contexts>
<marker>Haghighi, Blitzer, DeNero, Klein, 2009</marker>
<rawString>Aria Haghighi, John Blitzer, John DeNero, and Dan Klein. 2009. Better word alignments with supervised ITG models. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest rescoring: Faster decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="23645" citStr="Huang and Chiang, 2007" startWordPosition="3994" endWordPosition="3997">as by the sum of their inside score under the full model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size. Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states. For each corner and size combination, built states are maintained in sorted order according to their inside score. This ordering allows us to stop combining states early when the results are falling off the agenda beams. Similar search and beaming strategies appear in many decoders for machine translation (Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007). 4.3 Finding Pseudo-Gold ITG Alignments Equation 3 asks for the block ITG alignment Ag that is closest to a reference alignment At, which may not lie in ITG(e,f). We search for 1458 After dinner I slept Figure 7: A* search for pseudo-gold ITG alignments uses an admissible heuristic for bispans that counts the number of gold links outside of [k, E) but within [g, h). Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan. Ag using A* bitext parsing (Klein and Manning, 200</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest rescoring: Faster decoding with integrated language models. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matti K¨a¨ari¨ainen</author>
</authors>
<title>Sinuhe—statistical machine translation using a globally trained conditional exponential family translation model.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>K¨a¨ari¨ainen, 2009</marker>
<rawString>Matti K¨a¨ari¨ainen. 2009. Sinuhe—statistical machine translation using a globally trained conditional exponential family translation model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Chris Manning</author>
</authors>
<title>A* parsing: Fast exact Viterbi parse selection.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="24247" citStr="Klein and Manning, 2003" startWordPosition="4101" endWordPosition="4104">Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007). 4.3 Finding Pseudo-Gold ITG Alignments Equation 3 asks for the block ITG alignment Ag that is closest to a reference alignment At, which may not lie in ITG(e,f). We search for 1458 After dinner I slept Figure 7: A* search for pseudo-gold ITG alignments uses an admissible heuristic for bispans that counts the number of gold links outside of [k, E) but within [g, h). Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan. Ag using A* bitext parsing (Klein and Manning, 2003). Search states, which correspond to bispans [g, h) &lt;---&gt; [k, E), are scored by the number of errors within the bispan plus the number of (i, j) E At such that j E [k, E) but i E� [g, h) (recall errors). As an admissible heuristic for the future cost of a bispan [g, h) &lt;---&gt; [k, E), we count the number of (i, j) E At such that i E [g, h) but j E� [k, E), as depicted in Figure 7. These links will become recall errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certa</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Chris Manning. 2003. A* parsing: Fast exact Viterbi parse selection. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Barry Haddow</author>
</authors>
<title>Edinburghs submission to all tracks of the WMT2009 shared task with reordering and speed improvements to Moses.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="23669" citStr="Koehn and Haddow, 2009" startWordPosition="3998" endWordPosition="4002">nside score under the full model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size. Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states. For each corner and size combination, built states are maintained in sorted order according to their inside score. This ordering allows us to stop combining states early when the results are falling off the agenda beams. Similar search and beaming strategies appear in many decoders for machine translation (Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007). 4.3 Finding Pseudo-Gold ITG Alignments Equation 3 asks for the block ITG alignment Ag that is closest to a reference alignment At, which may not lie in ITG(e,f). We search for 1458 After dinner I slept Figure 7: A* search for pseudo-gold ITG alignments uses an admissible heuristic for bispans that counts the number of gold links outside of [k, E) but within [g, h). Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan. Ag using A* bitext parsing (Klein and Manning, 2003). Search states, which</context>
</contexts>
<marker>Koehn, Haddow, 2009</marker>
<rawString>Philipp Koehn and Barry Haddow. 2009. Edinburghs submission to all tracks of the WMT2009 shared task with reordering and speed improvements to Moses. In Proceedings of the Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1318" citStr="Koehn et al., 2003" startWordPosition="192" endWordPosition="195"> that relates directly to the end task of generating translations. Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments. 1 Introduction In the last decade, the field of statistical machine translation has shifted from generating sentences word by word to systems that recycle whole fragments of training examples, expressed as translation rules. This general paradigm was first pursued using contiguous phrases (Och et al., 1999; Koehn et al., 2003), and has since been generalized to a wide variety of hierarchical and syntactic formalisms. The training stage of statistical systems focuses primarily on discovering translation rules in parallel corpora. Most systems discover translation rules via a two-stage pipeline: a parallel corpus is aligned at the word level, and then a second procedure extracts fragment-level rules from word-aligned sentence pairs. This paper offers a model-based alternative to phrasal rule extraction, which merges this two-stage pipeline into a single step. We present a discriminative model that directly predicts w</context>
<context position="5852" citStr="Koehn et al., 2003" startWordPosition="902" endWordPosition="905">m (Koehn et al., 2007; Li et al., 2009) 2 Extraction Set Models The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules. Word-level alignments are generated as a byproduct of inference. We first specify the relationship between word alignments and extraction sets, then define our model. 2.1 Extraction Sets from Word Alignments Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Chiang, 2007), count of internal tree nodes (Galley et al., 2006), etc. In this paper, we focus on phrasal rule extraction (i.e., phrase pair extraction), upon which most other extraction procedures are based. Given a sentence pair (e, f), phrasal rule extraction defines a mapping from a set of word-to-word 31% 被 [passive marker] 发现 发现 [s [discover] w c was discovered Figure 2: Examples of two types of possible alignσ(e) ment links (striped). These types account for 96% 2010年 of the possible alignment links in our data set. alignment links A = {(i, j)} to an extraction set (f</context>
<context position="16321" citStr="Koehn et al., 2003" startWordPosition="2734" endWordPosition="2737">large parallel corpora, which provide frequency and cooccurrence information. To score word-to-word links, we use the posterior predictions of a jointly trained HMM alignment model (Liang et al., 2006). The remaining features include a dictionary feature, an identical word feature, an absolute position distortion feature, and features for numbers and punctuation. To score phrasal translation rules in an extraction set, we use a mixture of feature types. Extraction set models allow us to incorporate the same phrasal relative frequency statistics that drive phrase-based translation performance (Koehn et al., 2003). To implement these frequency features, we extract a phrase table from the alignment predictions of a jointly trained unsupervised HMM model using Moses (Koehn et al., 2007), and score bispans using the resulting features. We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al. (2009). We include indicators for the number of words and Chinese characters in rules. One useful indicator feature exploits the fact that capitalized terms in English tend to align to Chinese words with three or more characters. On 1-by-n or n-by-1 p</context>
<context position="28076" citStr="Koehn et al., 2003" startWordPosition="4724" endWordPosition="4727">s it generates, and the translations generated by two end-to-end systems. Table 1 compares the five systems described below, including three baselines. All supervised aligners were optimized for bispan F5. Unsupervised Baseline: GIZA++. We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007). The designated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with [after] [dinner] [after] [I] [sleep] [past tense] k =1 l =4 g =0 h =3 在 晩饭 F 我 睡 了 1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline. Supervised Baseline: Block ITG. We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size. </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics: Demonstration track.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="5254" citStr="Koehn et al., 2007" startWordPosition="808" endWordPosition="811">tions, shown as rounded rectangles. coarse-to-fine inference approach that allows us to scale our method to long sentences. Our extraction set model outperforms both unsupervised and supervised word aligners at predicting word alignments and extraction sets. We also demonstrate that extraction sets are useful for end-to-end machine translation. Our model improves translation quality relative to state-of-theart Chinese-to-English baselines across two publicly available systems, providing total BLEU improvements of 1.2 in Moses, a phrase-based system, and 1.4 in a Joshua, a hierarchical system (Koehn et al., 2007; Li et al., 2009) 2 Extraction Set Models The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules. Word-level alignments are generated as a byproduct of inference. We first specify the relationship between word alignments and extraction sets, then define our model. 2.1 Extraction Sets from Word Alignments Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), </context>
<context position="16495" citStr="Koehn et al., 2007" startWordPosition="2762" endWordPosition="2765"> model (Liang et al., 2006). The remaining features include a dictionary feature, an identical word feature, an absolute position distortion feature, and features for numbers and punctuation. To score phrasal translation rules in an extraction set, we use a mixture of feature types. Extraction set models allow us to incorporate the same phrasal relative frequency statistics that drive phrase-based translation performance (Koehn et al., 2003). To implement these frequency features, we extract a phrase table from the alignment predictions of a jointly trained unsupervised HMM model using Moses (Koehn et al., 2007), and score bispans using the resulting features. We also include indicator features on lexical templates for the 50 most common words in each language, as in Haghighi et al. (2009). We include indicators for the number of words and Chinese characters in rules. One useful indicator feature exploits the fact that capitalized terms in English tend to align to Chinese words with three or more characters. On 1-by-n or n-by-1 phrasal rules, we include indicator features of fertility for common words.3 We also include monolingual phrase features that expose useful information to the model. For insta</context>
<context position="27821" citStr="Koehn et al., 2007" startWordPosition="4676" endWordPosition="4679">mal aside from pruning and beaming. Despite these differences, their strong results reinforce our claim that phraselevel information is useful for alignment. 6 Experiments We evaluate our extraction set model by the bispans it predicts, the word alignments it generates, and the translations generated by two end-to-end systems. Table 1 compares the five systems described below, including three baselines. All supervised aligners were optimized for bispan F5. Unsupervised Baseline: GIZA++. We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007). The designated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with [after] [dinner] [after] [I] [sleep] [past tense] k =1 l =4 g =0 h =3 在 晩饭 F 我 睡 了 1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding he</context>
<context position="33724" citStr="Koehn et al., 2007" startWordPosition="5635" endWordPosition="5638">lignment quality, extraction set quality, and translation. In word and bispan evaluations, GIZA++ did not have access to a dictionary while all other methods did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate for parse failures. 6.3 Translation Experiments We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems. Moses is a phrase-based system with lexicalized reordering (Koehn et al., 2007). Joshua (Li et al., 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume. To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability. These three sets were aggregated and rules were extr</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the Annual Conference of the Association for Computational Linguistics: Demonstration track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Lacoste-Julien</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
<author>Michael I Jordan</author>
</authors>
<title>Word alignment via quadratic assignment.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15111" citStr="Lacoste-Julien et al. (2006)" startWordPosition="2544" endWordPosition="2547">n-level loss L(Am; Ag): an F-measure of the overlap between bispans in Rn(Am) and Rn(Ag). This measure has been proposed previously to evaluate alignment systems (Ayan and Dorr, 2006). Based on preliminary translation results during development, we chose bispan F5 as our loss: Pr(Am) = |Rn(Am) ∩ Rn(Ag)|/|Rn(Am)| Rc(Am) = |Rn(Am) ∩ Rn(Ag)|/|Rn(Ag)| (1 + 5 2) · Pr(Am) · Rc(Am) F5 (Am; Ag) = 52 · Pr(Am) + Rc(Am) L(Am; Ag) = 1 − F5(Am; Ag) F5 favors recall over precision. Previous alignment work has shown improvements from adjusting the F-measure parameter (Fraser and Marcu, 2006). In particular, Lacoste-Julien et al. (2006) also chose a recall-biased objective. Optimizing for a bispan F-measure penalizes alignment mistakes in proportion to their rule extraction consequences. That is, adding a word link that prevents the extraction of many correct phrasal rules, or which licenses many incorrect rules, is strongly discouraged by this loss. 1456 3.2 Features on Extraction Sets The discriminative power of our model is driven by the features on sure word alignment links φa(i, j) and bispans φb(g, h, k, `). In both cases, the most important features come from the predictions of unsupervised models trained on large par</context>
<context position="25819" citStr="Lacoste-Julien et al., 2006" startWordPosition="4372" endWordPosition="4375">nsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Ou</context>
</contexts>
<marker>Lacoste-Julien, Taskar, Klein, Jordan, 2006</marker>
<rawString>Simon Lacoste-Julien, Ben Taskar, Dan Klein, and Michael I. Jordan. 2006. Word alignment via quadratic assignment. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Chris Callison-Burch</author>
<author>Chris Dyer</author>
<author>Juri Ganitkevitch</author>
<author>Sanjeev Khudanpur</author>
<author>Lane Schwartz</author>
<author>Wren Thornton</author>
<author>Jonathan Weese</author>
<author>Omar Zaidan</author>
</authors>
<title>Joshua: An open source toolkit for parsing-based machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="5272" citStr="Li et al., 2009" startWordPosition="812" endWordPosition="815">ded rectangles. coarse-to-fine inference approach that allows us to scale our method to long sentences. Our extraction set model outperforms both unsupervised and supervised word aligners at predicting word alignments and extraction sets. We also demonstrate that extraction sets are useful for end-to-end machine translation. Our model improves translation quality relative to state-of-theart Chinese-to-English baselines across two publicly available systems, providing total BLEU improvements of 1.2 in Moses, a phrase-based system, and 1.4 in a Joshua, a hierarchical system (Koehn et al., 2007; Li et al., 2009) 2 Extraction Set Models The input to our model is an unaligned sentence pair, and the output is an extraction set of phrasal translation rules. Word-level alignments are generated as a byproduct of inference. We first specify the relationship between word alignments and extraction sets, then define our model. 2.1 Extraction Sets from Word Alignments Rule extraction is a standard concept in machine translation: word alignment constellations license particular sets of overlapping rules, from which subsets are selected according to limits on phrase length (Koehn et al., 2003), number of gaps (Ch</context>
<context position="33750" citStr="Li et al., 2009" startWordPosition="5640" endWordPosition="5643">set quality, and translation. In word and bispan evaluations, GIZA++ did not have access to a dictionary while all other methods did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate for parse failures. 6.3 Translation Experiments We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems. Moses is a phrase-based system with lexicalized reordering (Koehn et al., 2007). Joshua (Li et al., 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume. To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability. These three sets were aggregated and rules were extracted from all three. The </context>
</contexts>
<marker>Li, Callison-Burch, Dyer, Ganitkevitch, Khudanpur, Schwartz, Thornton, Weese, Zaidan, 2009</marker>
<rawString>Zhifei Li, Chris Callison-Burch, Chris Dyer, Juri Ganitkevitch, Sanjeev Khudanpur, Lane Schwartz, Wren Thornton, Jonathan Weese, and Omar Zaidan. 2009. Joshua: An open source toolkit for parsing-based machine translation. In Proceedings of the Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15903" citStr="Liang et al., 2006" startWordPosition="2671" endWordPosition="2674">word link that prevents the extraction of many correct phrasal rules, or which licenses many incorrect rules, is strongly discouraged by this loss. 1456 3.2 Features on Extraction Sets The discriminative power of our model is driven by the features on sure word alignment links φa(i, j) and bispans φb(g, h, k, `). In both cases, the most important features come from the predictions of unsupervised models trained on large parallel corpora, which provide frequency and cooccurrence information. To score word-to-word links, we use the posterior predictions of a jointly trained HMM alignment model (Liang et al., 2006). The remaining features include a dictionary feature, an identical word feature, an absolute position distortion feature, and features for numbers and punctuation. To score phrasal translation rules in an extraction set, we use a mixture of feature types. Extraction set models allow us to incorporate the same phrasal relative frequency statistics that drive phrase-based translation performance (Koehn et al., 2003). To implement these frequency features, we extract a phrase table from the alignment predictions of a jointly trained unsupervised HMM model using Moses (Koehn et al., 2007), and sc</context>
<context position="28312" citStr="Liang et al., 2006" startWordPosition="4763" endWordPosition="4766"> We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007). The designated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with [after] [dinner] [after] [I] [sleep] [past tense] k =1 l =4 g =0 h =3 在 晩饭 F 我 睡 了 1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline. Supervised Baseline: Block ITG. We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size. This supervised baseline is a reimplementation of the MIRA-trained model of Haghighi et al. (2009). We use the same features and parser implementation for this model as we do for our extraction set model to ensure a clean comparison. To</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar, and Dan Klein. 2006. Alignment by agreement. In Proceedings of the Annual Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Hierarchical phrase-based translation with suffix arrays.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="33864" citStr="Lopez, 2007" startWordPosition="5657" endWordPosition="5658">er methods did. In the BLEU evaluation, all systems used a bilingual dictionary included in the training corpus. The BLEU evaluation of supervised systems also included rule counts from the Joint HMM to compensate for parse failures. 6.3 Translation Experiments We evaluate the alignments predicted by our model using two publicly available, open-source, state-of-the-art translation systems. Moses is a phrase-based system with lexicalized reordering (Koehn et al., 2007). Joshua (Li et al., 2009) is an implementation of Hiero (Chiang, 2007) using a suffix-array-based grammar extraction approach (Lopez, 2007). Both of these systems take word alignments as input, and neither of these systems accepts possible links in the alignments they consume. To interface with our extraction set models, we produced three sets of sure-only alignments from our model predictions: one that omitted possible links, one that converted all possible links to sure links, and one that includes each possible link with 0.5 probability. These three sets were aggregated and rules were extracted from all three. The training set we used for MT experiments is quite heterogenous and noisy compared to our alignment test sets, and t</context>
</contexts>
<marker>Lopez, 2007</marker>
<rawString>Adam Lopez. 2007. Hierarchical phrase-based translation with suffix arrays. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Daniel Wong</author>
</authors>
<title>A phrasebased, joint probability model for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="25093" citStr="Marcu and Wong, 2002" startWordPosition="4256" endWordPosition="4259">istic for the future cost of a bispan [g, h) &lt;---&gt; [k, E), we count the number of (i, j) E At such that i E [g, h) but j E� [k, E), as depicted in Figure 7. These links will become recall errors eventually. A* search with this heuristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word align</context>
</contexts>
<marker>Marcu, Wong, 2002</marker>
<rawString>Daniel Marcu and Daniel Wong. 2002. A phrasebased, joint probability model for statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Models of translational equivalence among words. Computational Linguistics.</title>
<date>2000</date>
<contexts>
<context position="25755" citStr="Melamed, 2000" startWordPosition="4364" endWordPosition="4365">nitial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Ch</context>
</contexts>
<marker>Melamed, 2000</marker>
<rawString>I. Dan Melamed. 2000. Models of translational equivalence among words. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Moore</author>
<author>Chris Quirk</author>
</authors>
<title>Faster beam-search decoding for phrasal statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of MT Summit XI.</booktitle>
<contexts>
<context position="23693" citStr="Moore and Quirk, 2007" startWordPosition="4003" endWordPosition="4006">ll model and the outside score computed in the coarse pass, pruning all states not within the fixed agenda beam size. Search states that are popped off agendas are indexed by their corner locations for fast lookup when constructing new states. For each corner and size combination, built states are maintained in sorted order according to their inside score. This ordering allows us to stop combining states early when the results are falling off the agenda beams. Similar search and beaming strategies appear in many decoders for machine translation (Huang and Chiang, 2007; Koehn and Haddow, 2009; Moore and Quirk, 2007). 4.3 Finding Pseudo-Gold ITG Alignments Equation 3 asks for the block ITG alignment Ag that is closest to a reference alignment At, which may not lie in ITG(e,f). We search for 1458 After dinner I slept Figure 7: A* search for pseudo-gold ITG alignments uses an admissible heuristic for bispans that counts the number of gold links outside of [k, E) but within [g, h). Above, the heuristic is 1, which is also the minimal number of alignment errors that an ITG alignment will incur using this bispan. Ag using A* bitext parsing (Klein and Manning, 2003). Search states, which correspond to bispans [</context>
</contexts>
<marker>Moore, Quirk, 2007</marker>
<rawString>Robert Moore and Chris Quirk. 2007. Faster beam-search decoding for phrasal statistical machine translation. In Proceedings of MT Summit XI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>A discriminative framework for bilingual word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="25789" citStr="Moore, 2005" startWordPosition="4370" endWordPosition="4371">l., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block mode</context>
</contexts>
<marker>Moore, 2005</marker>
<rawString>Robert C. Moore. 2005. A discriminative framework for bilingual word alignment. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Ney</author>
<author>Stephan Vogel</author>
</authors>
<title>HMM-based word alignment in statistical translation.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Computational linguistics.</booktitle>
<contexts>
<context position="21566" citStr="Ney and Vogel, 1996" startWordPosition="3630" endWordPosition="3633">rohibitively slow when there is no sparsity in the grammar. Maintaining the context necessary to score non-local bispans further increases running time. That is, ITG inference is organized around search states associated with a grammar symbol and a bispan; augmenting grammar symbols also augments this state space. To parse quickly, we prune away search states using predictions from the more efficient HMM 6The number of configuration states does not depend on the size of ,A because corners have fixed size, and because the position of links within rows or columns is not needed. alignment model (Ney and Vogel, 1996). We discard all states corresponding to bispans that are incompatible with 3 or more alignment links under an intersected HMM—a proven approach to pruning the space of ITG alignments (Zhang and Gildea, 2006; Haghighi et al., 2009). Pruning in this way reduces the search space dramatically, but only rarely prohibits correct alignments. The oracle alignment error rate for the block ITG model class is 1.4%; the oracle alignment error rate for er] this pruned subset of ITG is 2.0%. To take advantage of the sparsity that results ner] from pruning, we use an agenda-based parser that orders search s</context>
<context position="28182" citStr="Ney and Vogel, 1996" startWordPosition="4741" endWordPosition="4744">ms described below, including three baselines. All supervised aligners were optimized for bispan F5. Unsupervised Baseline: GIZA++. We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007). The designated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with [after] [dinner] [after] [I] [sleep] [past tense] k =1 l =4 g =0 h =3 在 晩饭 F 我 睡 了 1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-toword posteriors by averaging (soft union), and decoded with the competitive thresholding heuristic of DeNero and Klein (2007), yielding a state-ofthe-art unsupervised baseline. Supervised Baseline: Block ITG. We discriminatively trained a block ITG aligner with only sure links, using block terminal productions up to 3 words by 3 words in size. This supervised baseline is a reimplementation of the MIRA-trained model of Haghighi et al. (2009). We use</context>
</contexts>
<marker>Ney, Vogel, 1996</marker>
<rawString>Hermann Ney and Stephan Vogel. 1996. HMM-based word alignment in statistical translation. In Proceedings of the Conference on Computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<pages>29--19</pages>
<contexts>
<context position="27731" citStr="Och and Ney, 2003" startWordPosition="4662" endWordPosition="4665">pace of ITG alignments. Also, their approach uses greedy search, while our search is optimal aside from pruning and beaming. Despite these differences, their strong results reinforce our claim that phraselevel information is useful for alignment. 6 Experiments We evaluate our extraction set model by the bispans it predicts, the word alignments it generates, and the translations generated by two end-to-end systems. Table 1 compares the five systems described below, including three baselines. All supervised aligners were optimized for bispan F5. Unsupervised Baseline: GIZA++. We trained GIZA++ (Och and Ney, 2003) using the default parameters included with the Moses training script (Koehn et al., 2007). The designated regimen concludes by Viterbi aligning under Model 4 in both directions. We combined these alignments with [after] [dinner] [after] [I] [sleep] [past tense] k =1 l =4 g =0 h =3 在 晩饭 F 我 睡 了 1459 the grow-diag heuristic (Koehn et al., 2003). Unsupervised Baseline: Joint HMM. We trained and combined two HMM alignment models (Ney and Vogel, 1996) using the Berkeley Aligner.7 We initialized the HMM model parameters with jointly trained Model 1 parameters (Liang et al., 2006), combined word-tow</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29:19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Christoph Tillmann</author>
<author>Hermann Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1297" citStr="Och et al., 1999" startWordPosition="188" endWordPosition="191">ased loss function that relates directly to the end task of generating translations. Our model gives improvements in alignment quality relative to state-of-the-art unsupervised and supervised baselines, as well as providing up to a 1.4 improvement in BLEU score in Chinese-to-English translation experiments. 1 Introduction In the last decade, the field of statistical machine translation has shifted from generating sentences word by word to systems that recycle whole fragments of training examples, expressed as translation rules. This general paradigm was first pursued using contiguous phrases (Och et al., 1999; Koehn et al., 2003), and has since been generalized to a wide variety of hierarchical and syntactic formalisms. The training stage of statistical systems focuses primarily on discovering translation rules in parallel corpora. Most systems discover translation rules via a two-stage pipeline: a parallel corpus is aligned at the word level, and then a second procedure extracts fragment-level rules from word-aligned sentence pairs. This paper offers a model-based alternative to phrasal rule extraction, which merges this two-stage pipeline into a single step. We present a discriminative model tha</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>Franz Josef Och, Christoph Tillmann, and Hermann Ney. 1999. Improved alignment models for statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="35223" citStr="Papineni et al., 2002" startWordPosition="5878" endWordPosition="5881">h the HMM caused parse failures, which in turn caused training sentences to be skipped. To account for these issues, we added counts of phrasal rules extracted from the baseline HMM to the counts produced by supervised aligners. In Moses, our extraction set model predicts the set of phrases extracted by the system, and so the estimation techniques for the alignment model and translation model both share a common underlying representation: extraction sets. Empirically, we observe a BLEU score improvement of 1.2 over the best unsupervised baseline and 0.8 over the block ITG supervised baseline (Papineni et al., 2002). In Joshua, hierarchical rule extraction is based upon phrasal rule extraction, but abstracts away sub-phrases to create a grammar. Hence, the extraction sets we predict are closely linked to the representation that this system uses to translate. The extraction model again outperformed both unsupervised and supervised baselines, by 1.4 BLEU and 1.2 BLEU respectively. 7 Conclusion Our extraction set model serves to coordinate the alignment and translation model components of a statistical translation system by unifying their representations. Moreover, our model provides an effective alternativ</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="30885" citStr="Stolcke, 2002" startWordPosition="5182" endWordPosition="5183">ted on sentences up to length 40 from the NIST MT04 and MT05 test sets. For these experiments, we trained on a 22.1 million word parallel corpus consisting of sentences up to length 40 of newswire data from the GALE program, subsampled from a larger data set to promote overlap with the tune and test sets. This corpus also includes a bilingual dictionary. To improve performance, we retrained our aligner on a retokenized version of the hand-annotated data to match the tokenization of our corpus.8 We trained a language model with Kneser-Ney smoothing on 262 million words of newswire using SRILM (Stolcke, 2002). 6.2 Word and Phrase Alignment The first panel of Table 1 gives a word-level evaluation of all five aligners. We use the alignment error rate (AER) measure: precision is the fraction of sure links in the system output that are sure or possible in the reference, and recall is the fraction of sure links in the reference that the system outputs as sure. For this evaluation, possible links produced by our extraction set models are ignored. The full extraction set model performs the best by a small margin, although it was not tuned for word alignment. The second panel gives a phrasal rule-level ev</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Simon Lacoste-Julien</author>
<author>Dan Klein</author>
</authors>
<title>A discriminative matching approach to word alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="25776" citStr="Taskar et al., 2005" startWordPosition="4366" endWordPosition="4369">h priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) a</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>Ben Taskar, Simon Lacoste-Julien, and Dan Klein. 2005. A discriminative matching approach to word alignment. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--377</pages>
<contexts>
<context position="3798" citStr="Wu, 1997" startWordPosition="581" endWordPosition="582">function during training affects model performance. We optimize for a phrase-level F-measure in order to focus learning on the task of predicting phrasal rules rather than word alignment links. Third, our discriminative approach requires that we perform inference in the space of extraction sets. Our model does not factor over disjoint wordto-word links or minimal phrase pairs, and so existing inference procedures do not directly apply. However, we show that the dynamic program for a block ITG aligner can be augmented to score extraction sets that are indexed by underlying ITG word alignments (Wu, 1997). We also describe a 1453 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1453–1463, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics 2010年 2月 15日 σ(ei) Type 1: Language-specific function (�) Type 1: Languagespecific fu words omitted in the other language words omtted in the other lan σ(fj) Type 2: Role-equivalent pairs that Type oeequvalet wo are not lexical equivalents tha ae lexial e ove the65% over the Earth 地球地球 [Earth] [ 过 过 Distribution [go over] [go ver] Distribution over possible link types possible link </context>
<context position="12239" citStr="Wu, 1997" startWordPosition="2039" endWordPosition="2040">ost-one-to-one phrase matchings with ITG reordering patterns (Cherry and Lin, 2007; Zhang et al., 2008). The ITG constraint 2月 15日 E φ�(i, j) + E φb(g, h, k, `) (i,j)EAW [g,h)q[V)ERn(A) 1455 Figure 4: Above, we show a representative subset of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model. These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links. is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is expressive enough to include the vast majority of patterns observed in handannotated parallel corpora (Haghighi et al., 2009). In summary, our model scores all Rn(A) for A ∈ ITG(e, f) where A can include block terminals of size up to n. In our experiments, n = 3. Unlike previous work, we allow possible alignment links to appear in the block terminals, as depicted in Figure 4. 3 Model Estimation We estimate the weights θ of our extraction set model discriminatively using the margin-infused relaxed algorithm (MIRA) of Cramm</context>
<context position="26150" citStr="Wu, 1997" startWordPosition="4422" endWordPosition="4423"> that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K¨a¨ari¨ainen (2009) trains a translation model discriminatively using features on overlapping phrase pairs. That work differs from ours in that it uses fixed word alignments and</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23:377–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
</authors>
<title>Stochastic lexicalized inversion transduction grammar for alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26174" citStr="Zhang and Gildea, 2005" startWordPosition="4424" endWordPosition="4427">lt from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful for training alignment models (Fraser and Marcu, 2006; Fraser and Marcu, 2007). The ITG grammar formalism, the corresponding word alignment class, and inference procedures for the class have also been explored extensively (Wu, 1997; Zhang and Gildea, 2005; Cherry and Lin, 2007; Zhang et al., 2008). At the intersection of these lines of work, discriminative ITG models have also been proposed, including one-to-one alignment models (Cherry and Lin, 2006) and block models (Haghighi et al., 2009). Our model directly extends this research agenda with first-class possible links, overlapping phrasal rule features, and an extraction-level loss function. K¨a¨ari¨ainen (2009) trains a translation model discriminatively using features on overlapping phrase pairs. That work differs from ours in that it uses fixed word alignments and focuses on translation </context>
</contexts>
<marker>Zhang, Gildea, 2005</marker>
<rawString>Hao Zhang and Daniel Gildea. 2005. Stochastic lexicalized inversion transduction grammar for alignment. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
</authors>
<title>Efficient search for inversion transduction grammar.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="21773" citStr="Zhang and Gildea, 2006" startWordPosition="3665" endWordPosition="3668">ates associated with a grammar symbol and a bispan; augmenting grammar symbols also augments this state space. To parse quickly, we prune away search states using predictions from the more efficient HMM 6The number of configuration states does not depend on the size of ,A because corners have fixed size, and because the position of links within rows or columns is not needed. alignment model (Ney and Vogel, 1996). We discard all states corresponding to bispans that are incompatible with 3 or more alignment links under an intersected HMM—a proven approach to pruning the space of ITG alignments (Zhang and Gildea, 2006; Haghighi et al., 2009). Pruning in this way reduces the search space dramatically, but only rarely prohibits correct alignments. The oracle alignment error rate for the block ITG model class is 1.4%; the oracle alignment error rate for er] this pruned subset of ITG is 2.0%. To take advantage of the sparsity that results ner] from pruning, we use an agenda-based parser that orders search states from small to large, where we er]define the size of a bispan as the total number of words contained within it. For each size, we maintain a separate agenda. Only when the agenda for size k is exhausted</context>
</contexts>
<marker>Zhang, Gildea, 2006</marker>
<rawString>Hao Zhang and Daniel Gildea. 2006. Efficient search for inversion transduction grammar. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Chris Quirk</author>
<author>Robert C Moore</author>
<author>Daniel Gildea</author>
</authors>
<title>Bayesian learning of noncompositional phrases with synchronous parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the Annual Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11734" citStr="Zhang et al., 2008" startWordPosition="1951" endWordPosition="1954">n, although we emphasize that A is a set of sure and possible alignments, and φ(A) does not decompose as a sum of vectors on individual word-level alignment links. Our model is parameterized by a weight vector θ, which scores an extraction set Rn(A) as θ · φ(A). To further limit the space of extraction sets we are willing to consider, we restrict A to block inverse transduction grammar (ITG) alignments, a space that allows many-to-many alignments through phrasal terminal productions, but otherwise enforces at-most-one-to-one phrase matchings with ITG reordering patterns (Cherry and Lin, 2007; Zhang et al., 2008). The ITG constraint 2月 15日 E φ�(i, j) + E φb(g, h, k, `) (i,j)EAW [g,h)q[V)ERn(A) 1455 Figure 4: Above, we show a representative subset of the block alignment patterns that serve as terminal productions of the ITG that restricts the output space of our model. These terminal productions cover up to n = 3 words in each sentence and include a mixture of sure (filled) and possible (striped) word-level alignment links. is more computationally convenient than arbitrarily ordered phrase matchings (Wu, 1997; DeNero and Klein, 2008). However, the space of block ITG alignments is expressive enough to i</context>
<context position="25319" citStr="Zhang et al., 2008" startWordPosition="4295" endWordPosition="4298">euristic makes no errors, and the time required to compute pseudo-gold alignments is negligible. 5 Relationship to Previous Work Our model is certainly not the first alignment approach to include structures larger than words. Model-based phrase-to-phrase alignment was proposed early in the history of phrase-based translation as a method for training translation models (Marcu and Wong, 2002). A variety of unsupervised models refined this initial work with priors (DeNero et al., 2008; Blunsom et al., 2009) and inference constraints (DeNero et al., 2006; Birch et al., 2006; Cherry and Lin, 2007; Zhang et al., 2008). These models fundamentally differ from ours in that they stipulate a segmentation of the sentence pair into phrases, and only align the minimal phrases in that segmentation. Our model scores the larger overlapping phrases that result from composing these minimal phrases. Discriminative alignment is also a wellexplored area. Most work has focused on predicting word alignments via partial matching inference algorithms (Melamed, 2000; Taskar et al., 2005; Moore, 2005; Lacoste-Julien et al., 2006). Work in semi-supervised estimation has also contributed evidence that hand-annotations are useful </context>
</contexts>
<marker>Zhang, Quirk, Moore, Gildea, 2008</marker>
<rawString>Hao Zhang, Chris Quirk, Robert C. Moore, and Daniel Gildea. 2008. Bayesian learning of noncompositional phrases with synchronous parsing. In Proceedings of the Annual Conference of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>