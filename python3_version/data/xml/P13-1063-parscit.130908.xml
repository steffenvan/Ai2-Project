<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9982545">
Transfer Learning Based Cross-lingual
Knowledge Extraction for Wikipedia
</title>
<author confidence="0.998423">
Zhigang Wang†, Zhixing Li†, Juanzi Li†, Jie Tang†, and Jeff Z. Pan‡† Tsinghua National Laboratory for Information Science and Technology
</author>
<affiliation confidence="0.968606">
DCST, Tsinghua University, Beijing, China
</affiliation>
<email confidence="0.923423">
{wzhigang,zhxli,ljz,tangjie}@keg.cs.tsinghua.edu.cn
</email>
<affiliation confidence="0.574911">
‡ Department of Computing Science, University of Aberdeen, Aberdeen, UK
</affiliation>
<email confidence="0.995662">
jeff.z.pan@abdn.ac.uk
</email>
<sectionHeader confidence="0.993804" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.992505742857143">
Wikipedia infoboxes are a valuable source
of structured knowledge for global knowl-
edge sharing. However, infobox infor-
mation is very incomplete and imbal-
anced among the Wikipedias in differen-
t languages. It is a promising but chal-
lenging problem to utilize the rich struc-
tured knowledge from a source language
Wikipedia to help complete the missing in-
foboxes for a target language.
In this paper, we formulate the prob-
lem of cross-lingual knowledge extraction
from multilingual Wikipedia sources, and
present a novel framework, called Wiki-
CiKE, to solve this problem. An instance-
based transfer learning method is utilized
to overcome the problems of topic drift
and translation errors. Our experimen-
tal results demonstrate that WikiCiKE out-
performs the monolingual knowledge ex-
traction method and the translation-based
method.
Heino and Pan, 2012) and OWL (Pan and Hor-
rocks, 2006; Pan and Thomas, 2007; Fokoue et
al., 2012), and their reasoning services.
However, most infoboxes in different Wikipedi-
a language versions are missing. Figure 1 shows
the statistics of article numbers and infobox infor-
mation for six major Wikipedias. Only 32.82%
of the articles have infoboxes on average, and the
numbers of infoboxes for these Wikipedias vary
significantly. For instance, the English Wikipedi-
a has 13 times more infoboxes than the Chinese
Wikipedia and 3.5 times more infoboxes than the
second largest Wikipedia of German language.
</bodyText>
<figure confidence="0.997566428571429">
x 106
Article
Infobox
English German French Dutch Spanish Chinese
Number of Instances 4
3.5
3
2.5
2
1.5
1
0.5
0
Languages
</figure>
<figureCaption confidence="0.99881">
Figure 1: Statistics for Six Major Wikipedias.
</figureCaption>
<sectionHeader confidence="0.997794" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962103448276">
In recent years, the automatic knowledge extrac-
tion using Wikipedia has attracted significant re-
search interest in research fields, such as the se-
mantic web. As a valuable source of structured
knowledge, Wikipedia infoboxes have been uti-
lized to build linked open data (Suchanek et al.,
2007; Bollacker et al., 2008; Bizer et al., 2008;
Bizer et al., 2009), support next-generation in-
formation retrieval (Hotho et al., 2006), improve
question answering (Bouma et al., 2008; Fer-
r´andez et al., 2009), and other aspects of data ex-
ploitation (McIlraith et al., 2001; Volkel et al.,
2006; Hogan et al., 2011) using semantic web s-
tandards, such as RDF (Pan and Horrocks, 2007;
To solve this problem, KYLIN has been pro-
posed to extract the missing infoboxes from un-
structured article texts for the English Wikipedi-
a (Wu and Weld, 2007). KYLIN performs
well when sufficient training data are available,
and such techniques as shrinkage and retraining
have been used to increase recall from English
Wikipedia’s long tail of sparse infobox classes
(Weld et al., 2008; Wu et al., 2008). The extraction
performance of KYLIN is limited by the number
of available training samples.
Due to the great imbalance between different
Wikipedia language versions, it is difficult to gath-
er sufficient training data from a single Wikipedia.
Some translation-based cross-lingual knowledge
</bodyText>
<page confidence="0.978644">
641
</page>
<note confidence="0.9143495">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 641–650,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999345666666667">
extraction methods have been proposed (Adar et
al., 2009; Bouma et al., 2009; Adafre and de Rijke,
2006). These methods concentrate on translating
existing infoboxes from a richer source language
version of Wikipedia into the target language. The
recall of new target infoboxes is highly limited
by the number of equivalent cross-lingual arti-
cles and the number of existing source infoboxes.
Take Chinese-English1 Wikipedias as an example:
current translation-based methods only work for
87,603 Chinese Wikipedia articles, 20.43% of the
total 428,777 articles. Hence, the challenge re-
mains: how could we supplement the missing in-
foboxes for the rest 79.57% articles?
On the other hand, the numbers of existing in-
fobox attributes in different languages are high-
ly imbalanced. Table 1 shows the comparison
of the numbers of the articles for the attributes
in template PERSON between English and Chi-
nese Wikipedia. Extracting the missing value for
these attributes, such as awards, weight, influences
and style, inside the single Chinese Wikipedia is
intractable due to the rarity of existing Chinese
attribute-value pairs.
</bodyText>
<table confidence="0.9827906">
Attribute en zh Attribute en zh
name 82,099 1,486 awards 2,310 38
birth date 77,850 1,481 weight 480 12
occupation 66,768 1,279 influences 450 6
nationality 20,048 730 style 127 1
</table>
<tableCaption confidence="0.9762735">
Table 1: The Numbers of Articles in TEMPLATE
PERSON between English(en) and Chinese(zh).
</tableCaption>
<bodyText confidence="0.871399976744186">
In this paper, we have the following hypothesis:
one can use the rich English (auxiliary) informa-
tion to assist the Chinese (target) infobox extrac-
tion. In general, we address the problem of cross-
lingual knowledge extraction by using the imbal-
ance between Wikipedias of different languages.
For each attribute, we aim to learn an extractor to
find the missing value from the unstructured arti-
cle texts in the target Wikipedia by using the rich
information in the source language. Specifically,
we treat this cross-lingual information extraction
task as a transfer learning-based binary classifica-
tion problem.
The contributions of this paper are as follows:
1. We propose a transfer learning-based cross-
lingual knowledge extraction framework
1Chinese-English denotes the task of Chinese Wikipedia
infobox completion using English Wikipedia
called WikiCiKE. The extraction perfor-
mance for the target Wikipedia is improved
by using rich infoboxes and textual informa-
tion in the source language.
2. We propose the TrAdaBoost-based extractor
training method to avoid the problems of top-
ic drift and translation errors of the source
Wikipedia. Meanwhile, some language-
independent features are introduced to make
WikiCiKE as general as possible.
3. Chinese-English experiments for four typ-
ical attributes demonstrate that WikiCiKE
outperforms both the monolingual extrac-
tion method and current translation-based
method. The increases of 12.65% for pre-
cision and 12.47% for recall in the template
named person are achieved when only 30 tar-
get training articles are available.
The rest of this paper is organized as follows.
Section 2 presents some basic concepts, the prob-
lem formalization and the overview of WikiCiKE.
In Section 3, we propose our detailed approaches.
We present our experiments in Section 4. Some re-
lated work is described in Section 5. We conclude
our work and the future work in Section 6.
</bodyText>
<sectionHeader confidence="0.982829" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999724">
In this section, we introduce some basic con-
cepts regarding Wikipedia, formally defining the
key problem of cross-lingual knowledge extrac-
tion and providing an overview of the WikiCiKE
framework.
</bodyText>
<subsectionHeader confidence="0.997282">
2.1 Wiki Knowledge Base and Wiki Article
</subsectionHeader>
<bodyText confidence="0.976458833333333">
We consider each language version of Wikipedia
as a wiki knowledge base, which can be represent-
ed as K = {ai}pi=1, where ai is a disambiguated
article in K and p is the size of K.
Formally we define a wiki article a E K as a
5-tuple a = (title, text, ib, tp, C), where
</bodyText>
<listItem confidence="0.997720333333333">
• title denotes the title of the article a,
• text denotes the unstructured text description
of the article a,
• ib is the infobox associated with a; specif-
ically, ib = {(attri, valuei)}qi=1 represents
the list of attribute-value pairs for the article
</listItem>
<page confidence="0.8095055">
a,
642
</page>
<figureCaption confidence="0.997476">
Figure 2: Simplified Article of “Bill Gates”.
</figureCaption>
<listItem confidence="0.999485">
• tp = {attri}ri=1 is the infobox template as-
sociated with ib, where r is the number of
attributes for one specific template, and
• C denotes the set of categories to which the
article a belongs.
</listItem>
<bodyText confidence="0.995177142857143">
Figure 2 gives an example of these five impor-
tant elements concerning the article named “Bill
Gates”.
In what follows, we will use named subscripts,
such as aBill Gates, or index subscripts, such as ai,
to refer to one particular instance interchangeably.
We will use “name in TEMPLATE PERSON”
to refer to the attribute attrname in the template
tpPERSON. In this cross-lingual task, we use the
source (S) and target (T) languages to denote the
languages of auxiliary and target Wikipedias, re-
spectively. For example, KS indicates the source
wiki knowledge base, and KT denotes the target
wiki knowledge base.
</bodyText>
<subsectionHeader confidence="0.99927">
2.2 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.974013526315789">
Mining new infobox information from unstruc-
tured article texts is actually a multi-template,
multi-slot information extraction problem. In our
task, each template represents an infobox template
and each slot denotes an attribute. In the Wiki-
CiKE framework, for each attribute attrT in an
infobox template tpT, we treat the task of missing
value extraction as a binary classification prob-
lem. It predicts whether a particular word (token)
from the article text is the extraction target (Finn
and Kushmerick, 2004; Lafferty et al., 2001).
Given an attribute attrT and an instance
(word/token) xi, XS = {xi}ni=1 and XT =
{xi}n+m
i=n+1 are the sets of instances (words/tokens)
in the source and the target language respectively.
xi can be represented as a feature vector according
to its context. Usually, we have n ≫ m in our set-
ting, with much more attributes in the source that
those in the target. The function g : X 7→ Y maps
the instance from X = XS ∪ XT to the true la-
bel of Y = {0, 1}, where 1 represents the extrac-
tion target (positive) and 0 denotes the background
information (negative). Because the number of
target instances m is inadequate to train a good
classifier, we combine the source and target in-
stances to construct the training data set as TD =
TDS ∪ TDT, where TDS = {xi, g(xi)}ni=1 and
TDT = {xi, g(xi)}n+m
i=n+1 represent the source
and target training data, respectively.
Given the combined training data set TD, our
objective is to estimate a hypothesis f : X 7→ Y
that minimizes the prediction error on testing data
in the target language. Our idea is to determine the
useful part of TDS to improve the classification
performance in TDT. We view this as a transfer
learning problem.
</bodyText>
<subsectionHeader confidence="0.992945">
2.3 WikiCiKE Framework
</subsectionHeader>
<bodyText confidence="0.998327470588236">
WikiCiKE learns an extractor for a given attribute
attrT in the target Wikipedia. As shown in Fig-
ure 3, WikiCiKE contains four key components:
(1) Automatic Training Data Generation: given
the target attribute attrT and two wiki knowledge
bases KS and KT, WikiCiKE first generates the
training data set TD = TDS ∪ TDT automati-
cally. (2) WikiCiKE Training: WikiCiKE uses
a transfer learning-based classification method to
train the classifier (extractor) f : X 7→ Y by using
TDS ∪ TDT. (3) Template Classification: Wi-
kiCiKE then determines proper candidate articles
which are suitable to generate the missing value of
attrT. (4) WikiCiKE Extraction: given a candi-
date article a, WikiCiKE uses the learned extractor
f to label each word in the text of a, and generate
the extraction result in the end.
</bodyText>
<sectionHeader confidence="0.981815" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.851921">
In this section, we will present the detailed ap-
proaches used in WikiCiKE.
</bodyText>
<page confidence="0.998626">
643
</page>
<figureCaption confidence="0.999398">
Figure 3: WikiCiKE Framework.
</figureCaption>
<subsectionHeader confidence="0.998973">
3.1 Automatic Training Data Generation
</subsectionHeader>
<bodyText confidence="0.999668">
To generate the training data for the target at-
tribute attrT, we first determine the equivalen-
t cross-lingual attribute attrS. Fortunately, some
templates in non-English Wikipedia (e.g. Chinese
Wikipedia) explicitly match their attributes with
their counterparts in English Wikipedia. There-
fore, it is convenient to align the cross-lingual at-
tributes using English Wikipedia as bridge. For
attributes that can not be aligned in this way, cur-
rently we manually align them. The manual align-
ment is worthwhile because thousands of articles
belong to the same template may benefit from it
and at the same time it is not very costly. In Chi-
nese Wikipedia, the top 100 templates have cov-
ered nearly 80% of the articles which have been
assigned a template.
Once the aligned attribute mapping attrT ↔
attrS is obtained, we collect the articles from both
KS and KT containing the corresponding attr.
The collected articles from KS are translated into
the target language. Then, we use a uniform au-
tomatic method, which primarily consists of word
labeling and feature vector generation, to generate
the training data set TD = {(x, g(x))} from these
collected articles.
For each collected article a =
{title, text, ib, tp, C} and its value of attr,
we can automatically label each word x in text
according to whether x and its neighbors are
contained by the value. The text and value are
processed as bags of words {x}text and {x}value.
Then for each xi E {x}text we have:
</bodyText>
<equation confidence="0.9990796">
I 1 xi ∈ {x}value, |{x}value |= 1
1 xi−1, xi ∈ {x}value or xi, xi+1 ∈ {x}value,
|{x}value |&gt; 1
0 otherwise
(1)
</equation>
<bodyText confidence="0.999950571428571">
After the word labeling, each instance
(word/token) is represented as a feature vec-
tor. In this paper, we propose a general feature
space that is suitable for most target languages.
As shown in Table 2, we classify the features
used in WikiCiKE into three categories: format
features, POS tag features and token features.
</bodyText>
<table confidence="0.583651424242424">
Category Feature Example
Format First token of sentence tijWIfn!
feature Hello World!
In first half of sentence tijWIfn!
Hello World!
Starts with two digits 12�1 31 å
31th Dec.
Starts with four digits 19991r a)-,
1999’s summer
Contains a cash sign 10Yor 10$
Contains a percentage 10%
symbol
Stop words J, �t,A
of, the, a, an
Pure number 365
Part of an anchor text FR Q
Movie Director
Begin of an anchor text Rx i c i I lqj
Game Designer
POS tag POS tag of current token
features
POS tags of
previous 5 tokens
POS tags of
next 5 tokens
Token Current token
features
Previous 5 tokens
Next 5 tokens
Is current token
contained by title
Is one of previous 5
tokens contained by title
</table>
<tableCaption confidence="0.952102">
Table 2: Feature Definition.
</tableCaption>
<bodyText confidence="0.999364857142857">
The target training data TDT is directly gener-
ated from articles in the target language Wikipedi-
a. Articles from the source language Wikipedia
are translated into the target language in advance
and then transformed into training data TDS. In
next section, we will discuss how to train an ex-
tractor from TD = TDS U TDT.
</bodyText>
<subsectionHeader confidence="0.998873">
3.2 WikiCiKE Training
</subsectionHeader>
<bodyText confidence="0.999727">
Given the attribute attrT, we want to train a clas-
sifier f : X �-+ Y that can minimize the prediction
</bodyText>
<equation confidence="0.984633">
g(xi) =
</equation>
<page confidence="0.984826">
644
</page>
<bodyText confidence="0.9999536">
error for the testing data in the target language.
Traditional machine learning approaches attempt
to determine f by minimizing some loss function
L on the prediction f(x) for the training instance
x and its real label g(x), which is
</bodyText>
<equation confidence="0.9094935">
f = arg ®in E L(f (x), g(x)) where (x, g(x)) E TDT
(2)
</equation>
<bodyText confidence="0.999927954545455">
In this paper, we use TrAdaBoost (Dai et al.,
2007), which is an instance-based transfer learn-
ing algorithm that was first proposed by Dai to find
ˆf. TrAdaBoost requires that the source training
instances XS and target training instances XT be
drawn from the same feature space. In WikiCiKE,
the source articles are translated into the target
language in advance to satisfy this requirement.
Due to the topic drift problem and translation er-
rors, the joint probability distribution PS(x, g(x))
is not identical to PT (x, g(x)). We must adjust the
source training data TDS so that they fit the dis-
tribution on TDT. TrAdaBoost iteratively updates
the weights of all training instances to optimize the
prediction error. Specifically, the weight-updating
strategy for the source instances is decided by the
loss on the target instances.
For each t = 1 ∼ T iteration, given a weight
vector pt normalized from wt(wt is the weight
vector before normalization), we call a basic clas-
sifier F that can address weighted instances and
then find a hypothesis f that satisfies
</bodyText>
<equation confidence="0.6447775">
� (3)
ˆft = argmin L(pt, f(x), g(x))
f∈ΘF
(x, g(x)) E TDS U TDT
</equation>
<bodyText confidence="0.907668666666667">
Let Et be the prediction error of ˆft at the tth iter-
ation on the target training instances TDT, which
is
</bodyText>
<equation confidence="0.989841">
(wtk x  |ˆft(xk) − yk|) (4)
</equation>
<bodyText confidence="0.945532">
With Et, the weight vector wt is updated by the
function:
</bodyText>
<equation confidence="0.990504">
wt+1 = h(wt, Et) (5)
</equation>
<bodyText confidence="0.956971375">
The weight-updating strategy h is illustrated in
Table 3.
Finally, a final classifier fˆ can be obtained by
combining ˆfT/2 ∼ ˆfT .
TrAdaBoost has a convergence rate of
O(V/ln(n/N)), where n and N are the number
of source samples and number of maximum
iterations respectively.
</bodyText>
<table confidence="0.9220053">
TrAdaBoost AdaBoost
Target + wt wt
samples
− wt x β−1 wt x β−1
t t
Source + wt x β−1 No source training
samples sample available
− wt x β
+: correctly labelled −: miss-labelled
wt: weight of an instance at the tth iteration
</table>
<equation confidence="0.995098">
βt = Et x (1 − Et)
V
β = 1/(1 + 2ln nT)
</equation>
<tableCaption confidence="0.9780915">
Table 3: Weight-updating Strategy of TrAd-
aBoost.
</tableCaption>
<subsectionHeader confidence="0.993876">
3.3 Template Classification
</subsectionHeader>
<bodyText confidence="0.999937117647059">
Before using the learned classifier f to extrac-
t missing infobox value for the target attribute
attrT, we must select the correct articles to be pro-
cessed. For example, the article aNew York is not
a proper article for extracting the missing value of
the attribute attrbirth day.
If a already has an incomplete infobox, it is
clear that the correct tp is the template of its own
infobox ib. For those articles that have no infobox-
es, we use the classical 5-nearest neighbor algo-
rithm to determine their templates (Roussopoulos
et al., 1995) using their category labels, outlinks,
inlinks as features (Wang et al., 2012). Our classi-
fier achieves an average precision of 76.96% with
an average recall of 63.29%, and can be improved
further. In this paper, we concentrate on the Wiki-
CiKE training and extraction components.
</bodyText>
<subsectionHeader confidence="0.946989">
3.4 WikiCiKE Extraction
</subsectionHeader>
<bodyText confidence="0.997950235294118">
Given an article a determined by template classi-
fication, we generate the missing value of attr
from the corresponding text. First, we turn the
text into a word sequence and compute the fea-
ture vector for each word based on the feature
definition in Section 3.1. Next we use f to label
each word, and we get a labeled sequence text&apos; as
text&apos; = {xf(x1)1...xz (i1−1)xz xi)xf(xi+1)i+1...xn(xn)}
where the superscript f(xi) ∈ {0, 1} represents
the positive or negative label by f. After that, we
extract the adjacent positive tokens in text as the
predict value. In particular, the longest positive to-
ken sequence and the one that contains other pos-
itive token sequences are preferred in extraction.
E.g., a positive sequence “comedy movie director”
is preferred to a shorter sequence “movie direc-
tor”.
</bodyText>
<equation confidence="0.993652333333333">
1
En+m t x
k=n+1 wk
Et =
n+mE
k=n+1
</equation>
<page confidence="0.99731">
645
</page>
<sectionHeader confidence="0.999327" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999947875">
In this section, we present our experiments to e-
valuate the effectiveness of WikiCiKE, where we
focus on the Chinese-English case; in other words,
the target language is Chinese and the source lan-
guage is English. It is part of our future work to
try other language pairs which two Wikipedias of
these languages are imbalanced in infobox infor-
mation such as English-Dutch.
</bodyText>
<subsectionHeader confidence="0.934178">
4.1 Experimental Setup
4.1.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.99979865">
Our data sets are from Wikipedia dumps2 generat-
ed on April 3, 2012. For each attribute, we collect
both labeled articles (articles that contain the cor-
responding attribute attr) and unlabeled articles
in Chinese. We split the labeled articles into two
subsets AT and Atest(AT ∩ Atest = ∅), in which
AT is used as target training articles and Atest is
used as the first testing set. For the unlabeled arti-
cles, represented as A′test, we manually label their
infoboxes with their texts and use them as the sec-
ond testing set. For each attribute, we also collect a
set of labeled articles AS in English as the source
training data. Our experiments are performed on
four attributes, which are occupation, nationality,
alma mater in TEMPLATE PERSON, and coun-
try in TEMPLATE FILM. In particular, we extract
values from the first two paragraphs of the texts
because they usually contain most of the valuable
information. The details of data sets on these at-
tributes are given in Table 4.
</bodyText>
<table confidence="0.931455333333333">
Attribute |AS ||AT ||Atest ||A′test|
occupation 1,000 500 779 208
alma mater 1,000 200 215 208
nationality 1,000 300 430 208
country 1,000 500 1,000 −
|A|: the number of articles in A
</table>
<tableCaption confidence="0.995617">
Table 4: Data Sets.
</tableCaption>
<subsubsectionHeader confidence="0.559191">
4.1.2 Comparison Methods
</subsubsectionHeader>
<bodyText confidence="0.99994325">
We compare our WikiCiKE method with two dif-
ferent kinds of methods, the monolingual knowl-
edge extraction method and the translation-based
method. They are implemented as follows:
</bodyText>
<footnote confidence="0.7191268">
1. KE-Mon is the monolingual knowledge ex-
tractor. The difference between WikiCiKE
and KE-Mon is that KE-Mon only uses the
Chinese training data.
2http://dumps.wikimedia.org/
</footnote>
<bodyText confidence="0.862212576923077">
2. KE-Tr is the translation-based extractor. It
obtains the values by two steps: finding their
counterparts (if available) in English using
Wikipedia cross-lingual links and attribute
alignments, and translating them into Chi-
nese.
We conduct two series of evaluation to compare
WikiCiKE with KE-Mon and KE-Tr, respectively.
1. We compare WikiCiKE with KE-Mon on the
first testing data set Atest, where most val-
ues can be found in the articles’ texts in those
labeled articles, in order to demonstrate the
performance improvement by using cross-
lingual knowledge transfer.
2. We compare WikiCiKE with KE-Tr on the
second testing data set A′test, where the
existences of values are not guaranteed in
those randomly selected articles, in order to
demonstrate the better recall of WikiCiKE.
For implementation details, the weighted-SVM
is used as the basic learner f both in WikiCiKE
and KE-Mon (Zhang et al., 2009), and Baidu
Translation API3 is used as the translator both in
WikiCiKE and KE-Tr. The Chinese texts are pre-
processed using ICTCLAS4 for word segmenta-
tion.
</bodyText>
<subsubsectionHeader confidence="0.62487">
4.1.3 Evaluation Metrics
</subsubsectionHeader>
<bodyText confidence="0.999952666666667">
Following Lavelli’s research on evaluation of in-
formation extraction (Lavelli et al., 2008), we per-
form evaluation as follows.
</bodyText>
<listItem confidence="0.989934">
1. We evaluate each attr separately.
2. For each attr, there is exactly one value ex-
tracted.
3. No alternative occurrence of real value is
available.
4. The overlap ratio is used in this paper rather
than “exactly matching” and “containing”.
</listItem>
<bodyText confidence="0.9985958">
Given an extracted value v′ = {w′} and its
corresponding real value v = {w}, two measure-
ments for evaluating the overlap ratio are defined:
recall: the rate of matched tokens w.r.t. the real
value. It can be calculated using
</bodyText>
<equation confidence="0.715731">
R(v′, v) = |v ∩ v′|
</equation>
<footnote confidence="0.998985">
3http://openapi.baidu.com/service
4http://www.ictclas.org/
</footnote>
<page confidence="0.993485">
|v|
646
</page>
<bodyText confidence="0.9963024">
precision: the rate of matched tokens w.r.t. the
extracted value. It can be calculated using
We use the average of these two measures to
evaluate the performance of our extractor as fol-
lows:
</bodyText>
<equation confidence="0.9998195">
R = avg(Ri(v′, v)) ai E Atest
P = avg(Pi(v′, v)) ai E Atest and vi′ =� 0
</equation>
<bodyText confidence="0.999755333333333">
The recall and precision range from 0 to 1 and
are first calculated on a single instance and then
averaged over the testing instances.
</bodyText>
<subsectionHeader confidence="0.998904">
4.2 Comparison with KE-Mon
</subsectionHeader>
<bodyText confidence="0.999587176470588">
In these experiments, WikiCiKE trains extractors
on AS U AT, and KE-Mon trains extractors just
on AT. We incrementally increase the number of
target training articles from 10 to 500 (if available)
to compare WikiCiKE with KE-Mon in different
situations. We use the first testing data set Atest to
evaluate the results.
Figure 4 and Table 5 show the experimental re-
sults on TEMPLATE PERSON and FILM. We can
see that WikiCiKE outperforms KE-Mon on all
three attributions especially when the number of
target training samples is small. Although the re-
call for alma mater and the precision for nation-
ality of WikiCiKE are lower than KE-Mon when
only 10 target training articles are available, Wi-
kiCiKE performs better than KE-Mon if we take
into consideration both precision and recall.
</bodyText>
<figureCaption confidence="0.992473">
Figure 4: Results for TEMPLATE PERSON.
</figureCaption>
<bodyText confidence="0.917687666666667">
Figure 4(d) shows the average improvements
yielded by WikiCiKE w.r.t KE-Mon on TEM-
PLATE PERSON. We can see that WikiCiKE
yields significant improvements when only a few
articles are available in target language and the im-
provements tend to decrease as the number of tar-
get articles is increased. In this case, the articles
in the target language are sufficient to train the ex-
tractors alone.
</bodyText>
<table confidence="0.999327777777778">
# KE-Mon WikiCiKE
P R P R
10 81.1% 63.8% 90.7% 66.3%
30 78.8% 64.5% 87.5% 69.4%
50 80.7% 66.6% 87.7% 72.3%
100 82.8% 68.2% 87.8% 72.1%
200 83.6% 70.5% 87.1% 73.2%
300 85.2% 72.0% 89.1% 76.2%
500 86.2% 73.4% 88.7% 75.6%
</table>
<tableCaption confidence="0.783085">
# Number of the target training articles.
Table 5: Results for country in TEMPLATE
FILM.
</tableCaption>
<subsectionHeader confidence="0.999453">
4.3 Comparison with KE-Tr
</subsectionHeader>
<bodyText confidence="0.999786533333333">
We compare WikiCiKE with KE-Tr on the second
testing data set A′test.
From Table 6 it can be clearly observed that Wi-
kiCiKE significantly outperforms KE-Tr both in
precision and recall. The reasons why the recal-
l of KE-Tr is extremely low are two-fold. First,
because of the limit of cross-lingual links and in-
foboxes in English Wikipedia, only a very smal-
l set of values is found by KE-Tr. Furthermore,
many values obtained using the translator are in-
correct because of translation errors. WikiCiKE
uses translators too, but it has better tolerance to
translation errors because the extracted value is
from the target article texts instead of the output
of translators.
</bodyText>
<table confidence="0.9994108">
Attribute KE-Tr WikiCiKE
P R P R
occupation 27.4% 3.40% 64.8% 26.4%
nationality 66.3% 4.60% 70.0% 55.0%
alma mater 66.7% 0.70% 76.3% 8.20%
</table>
<tableCaption confidence="0.999164">
Table 6: Results of WikiCiKE vs. KE-Tr.
</tableCaption>
<subsectionHeader confidence="0.997125">
4.4 Significance Test
</subsectionHeader>
<bodyText confidence="0.9972508">
We conducted a significance test to demonstrate
that the difference between WikiCiKE and KE-
Mon is significant rather than caused by statistical
errors. As for the comparison between WikiCiKE
and KE-Tr, significant improvements brought by
</bodyText>
<figure confidence="0.9977054">
0.8
1
0.9
0.6
0.8
0.4
0.2
0
10 30 50 100 200 300 500
0.7
P(KE−Mon)
P(WikiCiKE)
R(KE−Mon)
R(WikiCiKE)
0.6
0.5
0.4
10 30 50 100
P(KE−Mon)
P(WikiCiKE)
R(KE−Mon)
R(WikiCiKE)
200
number of target training articles number of target training articles
(a) occupation (b) alma mater
performance gain
number of target training articles number of target training articles
(c) nationality (d) average improvements
10 30 50 100 200 300
percent(%)
20
15
10
5
0
10 30 50 100 200 300 500
P
R
1
0.9
0.8
P(KE−Mon)
P(WikiCiKE)
R(KE−Mon)
R(WikiCiKE)
0.7
0.6
0.5
P(v′, v) = |v fl v′|
|v′|
</figure>
<page confidence="0.990855">
647
</page>
<bodyText confidence="0.998229363636364">
WikiCiKE can be clearly observed from Table 6
so there is no need for further significance test.
In this paper, we use McNemar’s significance test
(Dietterich and Thomas, 1998).
Table 7 shows the results of significance test
calculated for the average on all tested attributes.
When the number of target training articles is less
than 100, the X is much less than 10.83 that cor-
responds to a significance level 0.001. It suggests
that the chance that WikiCiKE is not better than
KE-Mon is less than 0.001.
</bodyText>
<table confidence="0.791389">
# 10 30 50 100 200 300 500
χ 179.5 107.3 51.8 32.8 4.1 4.3 0.3
# Number of the target training articles.
</table>
<tableCaption confidence="0.999582">
Table 7: Results of Significance Test.
</tableCaption>
<subsectionHeader confidence="0.995938">
4.5 Overall Analysis
</subsectionHeader>
<bodyText confidence="0.999873193548387">
As shown in above experiments, we can see that
WikiCiKE outperforms both KE-Mon and KE-Tr.
When only 30 target training samples are avail-
able, WikiCiKE reaches comparable performance
of KE-Mon using 300-500 target training samples.
Among all of the 72 attributes in TEMPLATE
PERSON of Chinese Wikipedia, 39 (54.17%) and
55 (76.39%) attributes have less than 30 and 200
labeled articles respectively. We can see that Wi-
kiCiKE can save considerable human labor when
no sufficient target training samples are available.
We also examined the errors by WikiCiKE and
they can be categorized into three classes. For at-
tribute occupation when 30 target training sam-
ples are used, there are 71 errors. The first cat-
egory is caused by incorrect word segmentation
(40.85%). In Chinese, there is no space between
words so we need to segment them before extrac-
tion. The result of word segmentation directly
decide the performance of extraction so it caus-
es most of the errors. The second category is be-
cause of the incomplete infoboxes (36.62%). In
evaluation of KE-Mon, we directly use the val-
ues in infoboxex as golden values, some of them
are incomplete so the correct predicted values will
be automatically judged as the incorrect in these
cases. The last category is mismatched words
(22.54%). The predicted value does not match the
golden value or a part of it. In the future, we can
improve the performance of WikiCiKE by polish-
ing the word segmentation result.
</bodyText>
<sectionHeader confidence="0.999897" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.987807">
Some approaches of knowledge extraction from
the open Web have been proposed (Wu et al.,
2012; Yates et al., 2007). Here we focus on the
extraction inside Wikipedia.
</bodyText>
<subsectionHeader confidence="0.963221">
5.1 Monolingual Infobox Extraction
</subsectionHeader>
<bodyText confidence="0.999966769230769">
KYLIN is the first system to autonomously ex-
tract the missing infoboxes from the correspond-
ing article texts by using a self-supervised learn-
ing method (Wu and Weld, 2007). KYLIN per-
forms well when enough training data are avail-
able. Such techniques as shrinkage and retraining
are proposed to increase the recall from English
Wikipedia’s long tail of sparse classes (Wu et al.,
2008; Wu and Weld, 2010). Different from Wu’s
research, WikiCiKE is a cross-lingual knowledge
extraction framework, which leverags rich knowl-
edge in the other language to improve extraction
performance in the target Wikipedia.
</bodyText>
<subsectionHeader confidence="0.996162">
5.2 Cross-lingual Infobox Completion
</subsectionHeader>
<bodyText confidence="0.99998995">
Current translation based methods usually con-
tain two steps: cross-lingual attribute alignmen-
t and value translation. The attribute alignmen-
t strategies can be grouped into two categories:
cross-lingual link based methods (Bouma et al.,
2009) and classification based methods (Adar et
al., 2009; Nguyen et al., 2011; Aumueller et al.,
2005; Adafre and de Rijke, 2006; Li et al., 2009).
After the first step, the value in the source lan-
guage is translated into the target language. E.
Adar’s approach gives the overall precision of
54% and recall of 40% (Adar et al., 2009). How-
ever, recall of these methods is limited by the
number of equivalent cross-lingual articles and the
number of infoboxes in the source language. It is
also limited by the quality of the translators. Wi-
kiCiKE attempts to mine the missing infoboxes
directly from the article texts and thus achieves
a higher recall compared with these methods as
shown in Section 4.3.
</bodyText>
<subsectionHeader confidence="0.979476">
5.3 Transfer Learning
</subsectionHeader>
<bodyText confidence="0.999734571428571">
Transfer learning can be grouped into four cate-
gories: instance-transfer, feature-representation-
transfer, parameter-transfer and relational-
knowledge-transfer (Pan and Yang, 2010).
TrAdaBoost, the instance-transfer approach, is
an extension of the AdaBoost algorithm, and
demonstrates better transfer ability than tradition-
</bodyText>
<page confidence="0.99585">
648
</page>
<bodyText confidence="0.9999074">
al learning techniques (Dai et al., 2007). Transfer
learning have been widely studied for classifica-
tion, regression, and cluster problems. However,
few efforts have been spent in the information
extraction tasks with knowledge transfer.
</bodyText>
<sectionHeader confidence="0.988962" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999612176470588">
In this paper we proposed a general cross-lingual
knowledge extraction framework called Wiki-
CiKE, in which extraction performance in the tar-
get Wikipedia is improved by using rich infobox-
es in the source language. The problems of topic
drift and translation error were handled by using
the TrAdaBoost model. Chinese-English exper-
imental results on four typical attributes showed
that WikiCiKE significantly outperforms both the
current translation based methods and the mono-
lingual extraction methods. In theory, WikiCiKE
can be applied to any two wiki knowledge based
of different languages.
We have been considering some future work.
Firstly, more attributes in more infobox templates
should be explored to make our results much
stronger. Secondly, knowledge in a minor lan-
guage may also help improve extraction perfor-
mance for a major language due to the cultural and
religion differences. A bidirectional cross-lingual
extraction approach will also be studied. Last but
not least, we will try to extract multiple attr-value
pairs at the same time for each article.
Furthermore, our work is part of a more ambi-
tious agenda on exploitation of linked data. On the
one hand, being able to extract data and knowl-
edge from multilingual sources such as Wikipedi-
a could help improve the coverage of linked data
for applications. On the other hand, we are also
investigating how to possibly integrate informa-
tion, including subjective information (Sensoy et
al., 2013), from multiple sources, so as to better
support data exploitation in context dependent ap-
plications.
</bodyText>
<sectionHeader confidence="0.96968" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.999916875">
The work is supported by NSFC (No. 61035004),
NSFC-ANR (No. 61261130588), 863 High Tech-
nology Program (2011AA01A207), FP7-288342,
FP7 K-Drive project (286348), the EPSRC WhatIf
project (EP/J014354/1) and THU-NUS NExT Co-
Lab. Besides, we gratefully acknowledge the as-
sistance of Haixun Wang (MSRA) for improving
the paper work.
</bodyText>
<sectionHeader confidence="0.82077" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.962394450980392">
S. Fissaha Adafre and M. de Rijke. 2006. Find-
ing Similar Sentences across Multiple Languages
in Wikipedia. EACL 2006 Workshop on New Text:
Wikis and Blogs and Other Dynamic Text Sources.
Sisay Fissaha Adafre and Maarten de Rijke. 2005.
Discovering Missing Links in Wikipedia. Proceed-
ings of the 3rd International Workshop on Link Dis-
covery.
Eytan Adar, Michael Skinner and Daniel S. Weld.
2009. Information Arbitrage across Multi-lingual
Wikipedia. WSDM’09.
David Aumueller, Hong Hai Do, Sabine Massmann and
Erhard Rahm”. 2005. Schema and ontology match-
ing with COMA++. SIGMOD Conference’05.
Christian Bizer, Jens Lehmann, Georgi Kobilarov,
S¨oren Auer, Christian Becker, Richard Cyganiak
and Sebastian Hellmann. 2009. DBpedia - A crys-
tallization Point for the Web of Data. J. Web Sem..
Christian Bizer, Tom Heath, Kingsley Idehen and Tim
Berners-Lee. 2008. Linked data on the web (L-
DOW2008). WWW’08.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim S-
turge and Jamie Taylor. 2008. Freebase: a Collabo-
ratively Created Graph Database for Structuring Hu-
man Knowledge. SIGMOD’08.
Gosse Bouma, Geert Kloosterman, Jori Mur, Gertjan
Van Noord, Lonneke Van Der Plas and Jorg Tiede-
mann. 2008. Question Answering with Joost at
CLEF 2007. Working Notes for the CLEF 2008
Workshop.
Gosse Bouma, Sergio Duarte and Zahurul Islam.
2009. Cross-lingual Alignment and Completion of
Wikipedia Templates. CLIAWS3 ’09.
Wenyuan Dai, Qiang Yang, Gui-Rong Xue and Yong
Yu. 2007. Boosting for Transfer Learning. ICM-
L’07.
Dietterich and Thomas G. 1998. Approximate Statis-
tical Tests for Comparing Supervised Classification
Learning Algorithms. Neural Comput..
Sergio Ferrandez, Antonio Toral, iscar Ferrandez, An-
tonio Ferrandez and Rafael Mu˜noz. 2009. Exploit-
ing Wikipedia and EuroWordNet to Solve Cross-
Lingual Question Answering. Inf. Sci..
Aidan Finn and Nicholas Kushmerick. 2004. Multi-
level Boundary Classification for Information Ex-
traction. ECML.
Achille Fokoue, Felipe Meneguzzi, Murat Sensoy and
Jeff Z. Pan. 2012. Querying Linked Ontological
Data through Distributed Summarization. Proc. of
the 26th AAAI Conference on Artificial Intelligence
(AAAI2012).
</reference>
<page confidence="0.989351">
649
</page>
<reference confidence="0.999679549450549">
Yoav Freund and Robert E. Schapire. 1997.
A Decision-Theoretic Generalization of On-Line
Learning and an Application to Boosting. J. Com-
put. Syst. Sci..
Norman Heino and Jeff Z. Pan. 2012. RDFS Rea-
soning on Massively Parallel Hardware. Proc. of
the 11th International Semantic Web Conference
(ISWC2012).
Aidan Hogan, Jeff Z. Pan, Axel Polleres and Yuan Ren.
2011. Scalable OWL 2 Reasoning for Linked Data.
Reasoning Web. Semantic Technologies for the Web
ofData.
Andreas Hotho, Robert J¨aschke, Christoph Schmitz
and Gerd Stumme. 2006. Information Retrieval in
Folksonomies: Search and Ranking. ESWC’06.
John D. Lafferty, Andrew McCallum and Fernando
C. N. Pereira. 2001. Conditional Random Fields:
Probabilistic Models for Segmenting and Labeling
Sequence Data. ICML’01.
Alberto Lavelli, MaryElaine Califf, Fabio Ciravegna,
Dayne Freitag, Claudio Giuliano, Nicholas Kush-
merick, Lorenza Romano and Neil Ireson. 2008.
Evaluation of Machine Learning-based Information
Extraction Algorithms: Criticisms and Recommen-
dations. Language Resources and Evaluation.
Juanzi Li, Jie Tang, Yi Li and Qiong Luo. 2009. Ri-
MOM: A Dynamic Multistrategy Ontology Align-
ment Framework. IEEE Trans. Knowl. Data Eng..
Xiao Ling, Gui-Rong Xue, Wenyuan Dai, Yun Jiang,
Qiang Yang and Yong Yu. 2008. Can Chinese We-
b Pages be Classified with English Data Source?.
WWW’08.
Sheila A. McIlraith, Tran Cao Son and Honglei Zeng.
2001. Semantic Web Services. IEEE Intelligent
Systems.
Thanh Hoang Nguyen, Viviane Moreira, Huong N-
guyen, Hoa Nguyen and Juliana Freire. 2011. Mul-
tilingual Schema Matching for Wikipedia Infoboxes.
CoRR.
Jeff Z. Pan and Edward Thomas. 2007. Approximat-
ing OWL-DL Ontologies. 22nd AAAI Conference
on Artificial Intelligence (AAAI-07).
Jeff Z. Pan and Ian Horrocks. 2007. RDFS(FA): Con-
necting RDF(S) and OWL DL. IEEE Transaction
on Knowledge and Data Engineering. 19(2): 192 -
206.
Jeff Z. Pan and Ian Horrocks. 2006. OWL-Eu: Adding
Customised Datatypes into OWL. Journal of Web
Semantics.
Sinno Jialin Pan and Qiang Yang. 2010. A Survey on
Transfer Learning. IEEE Trans. Knowl. Data Eng..
Nick Roussopoulos, Stephen Kelley and Fr´ed´eric Vin-
cent. 1995. Nearest Neighbor Queries. SIGMOD
Conference’95.
Murat Sensoy, Achille Fokoue, Jeff Z. Pan, Timothy
Norman, Yuqing Tang, Nir Oren and Katia Sycara.
2013. Reasoning about Uncertain Information and
Conflict Resolution through Trust Revision. Proc.
ofthe 12th International Conference on Autonomous
Agents and Multiagent Systems (AAMAS2013).
Fabian M. Suchanek, Gjergji Kasneci and Gerhard
Weikum. 2007. Yago: a Core of Semantic Knowl-
edge. WWW’07.
Max Volkel, Markus Krotzsch, Denny Vrandecic,
Heiko Haller and Rudi Studer. 2006. Semantic
Wikipedia. WWW’06.
Zhichun Wang, Juanzi Li, Zhigang Wang and Jie Tang.
2012. Cross-lingual Knowledge Linking across Wi-
ki Knowledge Bases. 21st International World Wide
Web Conference.
Daniel S. Weld, Fei Wu, Eytan Adar, Saleema Amer-
shi, James Fogarty, Raphael Hoffmann, Kayur Pa-
tel and Michael Skinner. 2008. Intelligence in
Wikipedia. AAAI’08.
Fei Wu and Daniel S. Weld. 2007. Autonomously Se-
mantifying Wikipedia. CIKM’07.
Fei Wu and Daniel S. Weld. 2010. Open Information
Extraction Using Wikipedia. ACL’10.
Fei Wu, Raphael Hoffmann and Daniel S. Weld. 2008.
Information Extraction from Wikipedia: Moving
down the Long Tail. KDD’08.
Wentao Wu, Hongsong Li, Haixun Wang and Kenny
Qili Zhu. 2012. Probase: a Probabilistic Taxonomy
for Text Understanding. SIGMOD Conference’12.
Alexander Yates, Michael Cafarella, Michele Banko,
Oren Etzioni, Matthew Broadhead and Stephen
Soderland. 2007. TextRunner: Open Information
Extraction on the Web. NAACL-Demonstrations’07.
Xinfeng Zhang, Xiaozhao Xu, Yiheng Cai and Yaowei
Liu. 2009. A Weighted Hyper-Sphere SVM. IC-
NC(3)’09.
</reference>
<page confidence="0.997966">
650
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.195722">
<title confidence="0.995619">Transfer Learning Based Knowledge Extraction for Wikipedia</title>
<author confidence="0.932414">Zhixing Juanzi Jie</author>
<author confidence="0.932414">Jeff Z National Laboratory for Information Science</author>
<affiliation confidence="0.996134">DCST, Tsinghua University, Beijing,</affiliation>
<address confidence="0.941155">of Computing Science, University of Aberdeen, Aberdeen,</address>
<email confidence="0.999742">jeff.z.pan@abdn.ac.uk</email>
<abstract confidence="0.998396944444444">Wikipedia infoboxes are a valuable source of structured knowledge for global knowledge sharing. However, infobox information is very incomplete and imbalanced among the Wikipedias in different languages. It is a promising but challenging problem to utilize the rich structured knowledge from a source language Wikipedia to help complete the missing infoboxes for a target language. In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called Wiki- CiKE, to solve this problem. An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors. Our experimental results demonstrate that WikiCiKE outperforms the monolingual knowledge extraction method and the translation-based method. Heino and Pan, 2012) and OWL (Pan and Horrocks, 2006; Pan and Thomas, 2007; Fokoue et al., 2012), and their reasoning services. However, most infoboxes in different Wikipedia language versions are missing. Figure 1 shows the statistics of article numbers and infobox information for six major Wikipedias. Only 32.82% of the articles have infoboxes on average, and the numbers of infoboxes for these Wikipedias vary significantly. For instance, the English Wikipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language.</abstract>
<note confidence="0.671932666666667">Article Infobox English German French Dutch Spanish Chinese Number of Instances 4 3.5 3 2.5 2 1.5 1 0.5 0 Languages Figure 1: Statistics for Six Major Wikipedias.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Fissaha Adafre</author>
<author>M de Rijke</author>
</authors>
<title>Finding Similar Sentences across Multiple Languages in Wikipedia.</title>
<date>2006</date>
<booktitle>EACL 2006 Workshop on New Text: Wikis and Blogs and Other Dynamic Text Sources.</booktitle>
<marker>Adafre, de Rijke, 2006</marker>
<rawString>S. Fissaha Adafre and M. de Rijke. 2006. Finding Similar Sentences across Multiple Languages in Wikipedia. EACL 2006 Workshop on New Text: Wikis and Blogs and Other Dynamic Text Sources.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sisay Fissaha Adafre</author>
<author>Maarten de Rijke</author>
</authors>
<title>Discovering Missing Links in Wikipedia.</title>
<date>2005</date>
<booktitle>Proceedings of the 3rd International Workshop on Link Discovery.</booktitle>
<marker>Adafre, de Rijke, 2005</marker>
<rawString>Sisay Fissaha Adafre and Maarten de Rijke. 2005. Discovering Missing Links in Wikipedia. Proceedings of the 3rd International Workshop on Link Discovery.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eytan Adar</author>
<author>Michael Skinner</author>
<author>Daniel S Weld</author>
</authors>
<date>2009</date>
<booktitle>Information Arbitrage across Multi-lingual Wikipedia. WSDM’09.</booktitle>
<contexts>
<context position="3635" citStr="Adar et al., 2009" startWordPosition="551" endWordPosition="554">edia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between different Wikipedia language versions, it is difficult to gather sufficient training data from a single Wikipedia. Some translation-based cross-lingual knowledge 641 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 641–650, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics extraction methods have been proposed (Adar et al., 2009; Bouma et al., 2009; Adafre and de Rijke, 2006). These methods concentrate on translating existing infoboxes from a richer source language version of Wikipedia into the target language. The recall of new target infoboxes is highly limited by the number of equivalent cross-lingual articles and the number of existing source infoboxes. Take Chinese-English1 Wikipedias as an example: current translation-based methods only work for 87,603 Chinese Wikipedia articles, 20.43% of the total 428,777 articles. Hence, the challenge remains: how could we supplement the missing infoboxes for the rest 79.57%</context>
<context position="28909" citStr="Adar et al., 2009" startWordPosition="4804" endWordPosition="4807">nglish Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attribute alignment strategies can be grouped into two categories: cross-lingual link based methods (Bouma et al., 2009) and classification based methods (Adar et al., 2009; Nguyen et al., 2011; Aumueller et al., 2005; Adafre and de Rijke, 2006; Li et al., 2009). After the first step, the value in the source language is translated into the target language. E. Adar’s approach gives the overall precision of 54% and recall of 40% (Adar et al., 2009). However, recall of these methods is limited by the number of equivalent cross-lingual articles and the number of infoboxes in the source language. It is also limited by the quality of the translators. WikiCiKE attempts to mine the missing infoboxes directly from the article texts and thus achieves a higher recall compa</context>
</contexts>
<marker>Adar, Skinner, Weld, 2009</marker>
<rawString>Eytan Adar, Michael Skinner and Daniel S. Weld. 2009. Information Arbitrage across Multi-lingual Wikipedia. WSDM’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Aumueller</author>
<author>Hong Hai Do</author>
<author>Sabine Massmann</author>
<author>Erhard Rahm”</author>
</authors>
<date>2005</date>
<booktitle>Schema and ontology matching with COMA++. SIGMOD Conference’05.</booktitle>
<marker>Aumueller, Do, Massmann, Rahm”, 2005</marker>
<rawString>David Aumueller, Hong Hai Do, Sabine Massmann and Erhard Rahm”. 2005. Schema and ontology matching with COMA++. SIGMOD Conference’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Bizer</author>
<author>Jens Lehmann</author>
<author>Georgi Kobilarov</author>
<author>S¨oren Auer</author>
<author>Christian Becker</author>
<author>Richard Cyganiak</author>
<author>Sebastian Hellmann</author>
</authors>
<title>DBpedia - A crystallization Point for the Web of Data.</title>
<date>2009</date>
<journal>J. Web Sem..</journal>
<contexts>
<context position="2378" citStr="Bizer et al., 2009" startWordPosition="357" endWordPosition="360">3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutch Spanish Chinese Number of Instances 4 3.5 3 2.5 2 1.5 1 0.5 0 Languages Figure 1: Statistics for Six Major Wikipedias. 1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been us</context>
</contexts>
<marker>Bizer, Lehmann, Kobilarov, Auer, Becker, Cyganiak, Hellmann, 2009</marker>
<rawString>Christian Bizer, Jens Lehmann, Georgi Kobilarov, S¨oren Auer, Christian Becker, Richard Cyganiak and Sebastian Hellmann. 2009. DBpedia - A crystallization Point for the Web of Data. J. Web Sem..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Bizer</author>
<author>Tom Heath</author>
<author>Kingsley Idehen</author>
<author>Tim Berners-Lee</author>
</authors>
<date>2008</date>
<note>Linked data on the web (LDOW2008). WWW’08.</note>
<contexts>
<context position="2357" citStr="Bizer et al., 2008" startWordPosition="353" endWordPosition="356">inese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutch Spanish Chinese Number of Instances 4 3.5 3 2.5 2 1.5 1 0.5 0 Languages Figure 1: Statistics for Six Major Wikipedias. 1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and re</context>
</contexts>
<marker>Bizer, Heath, Idehen, Berners-Lee, 2008</marker>
<rawString>Christian Bizer, Tom Heath, Kingsley Idehen and Tim Berners-Lee. 2008. Linked data on the web (LDOW2008). WWW’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a Collaboratively Created Graph Database for Structuring Human Knowledge.</title>
<date>2008</date>
<contexts>
<context position="2337" citStr="Bollacker et al., 2008" startWordPosition="349" endWordPosition="352">re infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutch Spanish Chinese Number of Instances 4 3.5 3 2.5 2 1.5 1 0.5 0 Languages Figure 1: Statistics for Six Major Wikipedias. 1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge and Jamie Taylor. 2008. Freebase: a Collaboratively Created Graph Database for Structuring Human Knowledge. SIGMOD’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>Geert Kloosterman</author>
<author>Jori Mur</author>
</authors>
<title>Gertjan Van Noord, Lonneke Van Der Plas and Jorg Tiedemann.</title>
<date>2008</date>
<journal>Question Answering with Joost at CLEF</journal>
<note>Workshop.</note>
<contexts>
<context position="2494" citStr="Bouma et al., 2008" startWordPosition="373" endWordPosition="376">rench Dutch Spanish Chinese Number of Instances 4 3.5 3 2.5 2 1.5 1 0.5 0 Languages Figure 1: Statistics for Six Major Wikipedias. 1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 20</context>
</contexts>
<marker>Bouma, Kloosterman, Mur, 2008</marker>
<rawString>Gosse Bouma, Geert Kloosterman, Jori Mur, Gertjan Van Noord, Lonneke Van Der Plas and Jorg Tiedemann. 2008. Question Answering with Joost at CLEF 2007. Working Notes for the CLEF 2008 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
<author>Sergio Duarte</author>
<author>Zahurul Islam</author>
</authors>
<title>Cross-lingual Alignment and Completion of Wikipedia Templates.</title>
<date>2009</date>
<pages>3--09</pages>
<contexts>
<context position="3655" citStr="Bouma et al., 2009" startWordPosition="555" endWordPosition="558"> sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between different Wikipedia language versions, it is difficult to gather sufficient training data from a single Wikipedia. Some translation-based cross-lingual knowledge 641 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 641–650, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics extraction methods have been proposed (Adar et al., 2009; Bouma et al., 2009; Adafre and de Rijke, 2006). These methods concentrate on translating existing infoboxes from a richer source language version of Wikipedia into the target language. The recall of new target infoboxes is highly limited by the number of equivalent cross-lingual articles and the number of existing source infoboxes. Take Chinese-English1 Wikipedias as an example: current translation-based methods only work for 87,603 Chinese Wikipedia articles, 20.43% of the total 428,777 articles. Hence, the challenge remains: how could we supplement the missing infoboxes for the rest 79.57% articles? On the ot</context>
<context position="28857" citStr="Bouma et al., 2009" startWordPosition="4796" endWordPosition="4799"> retraining are proposed to increase the recall from English Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attribute alignment strategies can be grouped into two categories: cross-lingual link based methods (Bouma et al., 2009) and classification based methods (Adar et al., 2009; Nguyen et al., 2011; Aumueller et al., 2005; Adafre and de Rijke, 2006; Li et al., 2009). After the first step, the value in the source language is translated into the target language. E. Adar’s approach gives the overall precision of 54% and recall of 40% (Adar et al., 2009). However, recall of these methods is limited by the number of equivalent cross-lingual articles and the number of infoboxes in the source language. It is also limited by the quality of the translators. WikiCiKE attempts to mine the missing infoboxes directly from the a</context>
</contexts>
<marker>Bouma, Duarte, Islam, 2009</marker>
<rawString>Gosse Bouma, Sergio Duarte and Zahurul Islam. 2009. Cross-lingual Alignment and Completion of Wikipedia Templates. CLIAWS3 ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenyuan Dai</author>
</authors>
<title>Qiang Yang, Gui-Rong Xue and Yong Yu.</title>
<date>2007</date>
<marker>Dai, 2007</marker>
<rawString>Wenyuan Dai, Qiang Yang, Gui-Rong Xue and Yong Yu. 2007. Boosting for Transfer Learning. ICML’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietterich</author>
<author>G Thomas</author>
</authors>
<title>Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms.</title>
<date>1998</date>
<journal>Neural Comput..</journal>
<contexts>
<context position="25805" citStr="Dietterich and Thomas, 1998" startWordPosition="4293" endWordPosition="4296">0 100 P(KE−Mon) P(WikiCiKE) R(KE−Mon) R(WikiCiKE) 200 number of target training articles number of target training articles (a) occupation (b) alma mater performance gain number of target training articles number of target training articles (c) nationality (d) average improvements 10 30 50 100 200 300 percent(%) 20 15 10 5 0 10 30 50 100 200 300 500 P R 1 0.9 0.8 P(KE−Mon) P(WikiCiKE) R(KE−Mon) R(WikiCiKE) 0.7 0.6 0.5 P(v′, v) = |v fl v′| |v′| 647 WikiCiKE can be clearly observed from Table 6 so there is no need for further significance test. In this paper, we use McNemar’s significance test (Dietterich and Thomas, 1998). Table 7 shows the results of significance test calculated for the average on all tested attributes. When the number of target training articles is less than 100, the X is much less than 10.83 that corresponds to a significance level 0.001. It suggests that the chance that WikiCiKE is not better than KE-Mon is less than 0.001. # 10 30 50 100 200 300 500 χ 179.5 107.3 51.8 32.8 4.1 4.3 0.3 # Number of the target training articles. Table 7: Results of Significance Test. 4.5 Overall Analysis As shown in above experiments, we can see that WikiCiKE outperforms both KE-Mon and KE-Tr. When only 30 t</context>
</contexts>
<marker>Dietterich, Thomas, 1998</marker>
<rawString>Dietterich and Thomas G. 1998. Approximate Statistical Tests for Comparing Supervised Classification Learning Algorithms. Neural Comput..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Ferrandez</author>
</authors>
<title>Antonio Toral, iscar Ferrandez, Antonio Ferrandez and</title>
<date>2009</date>
<journal>Inf. Sci..</journal>
<marker>Ferrandez, 2009</marker>
<rawString>Sergio Ferrandez, Antonio Toral, iscar Ferrandez, Antonio Ferrandez and Rafael Mu˜noz. 2009. Exploiting Wikipedia and EuroWordNet to Solve CrossLingual Question Answering. Inf. Sci..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aidan Finn</author>
<author>Nicholas Kushmerick</author>
</authors>
<title>Multilevel Boundary Classification for Information Extraction.</title>
<date>2004</date>
<publisher>ECML.</publisher>
<contexts>
<context position="9040" citStr="Finn and Kushmerick, 2004" startWordPosition="1418" endWordPosition="1421"> indicates the source wiki knowledge base, and KT denotes the target wiki knowledge base. 2.2 Problem Formulation Mining new infobox information from unstructured article texts is actually a multi-template, multi-slot information extraction problem. In our task, each template represents an infobox template and each slot denotes an attribute. In the WikiCiKE framework, for each attribute attrT in an infobox template tpT, we treat the task of missing value extraction as a binary classification problem. It predicts whether a particular word (token) from the article text is the extraction target (Finn and Kushmerick, 2004; Lafferty et al., 2001). Given an attribute attrT and an instance (word/token) xi, XS = {xi}ni=1 and XT = {xi}n+m i=n+1 are the sets of instances (words/tokens) in the source and the target language respectively. xi can be represented as a feature vector according to its context. Usually, we have n ≫ m in our setting, with much more attributes in the source that those in the target. The function g : X 7→ Y maps the instance from X = XS ∪ XT to the true label of Y = {0, 1}, where 1 represents the extraction target (positive) and 0 denotes the background information (negative). Because the numb</context>
</contexts>
<marker>Finn, Kushmerick, 2004</marker>
<rawString>Aidan Finn and Nicholas Kushmerick. 2004. Multilevel Boundary Classification for Information Extraction. ECML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Achille Fokoue</author>
<author>Felipe Meneguzzi</author>
<author>Murat Sensoy</author>
<author>Jeff Z Pan</author>
</authors>
<title>Querying Linked Ontological Data through Distributed Summarization.</title>
<date>2012</date>
<booktitle>Proc. of the 26th AAAI Conference on Artificial Intelligence (AAAI2012).</booktitle>
<contexts>
<context position="1330" citStr="Fokoue et al., 2012" startWordPosition="188" endWordPosition="191">nguage Wikipedia to help complete the missing infoboxes for a target language. In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called WikiCiKE, to solve this problem. An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors. Our experimental results demonstrate that WikiCiKE outperforms the monolingual knowledge extraction method and the translation-based method. Heino and Pan, 2012) and OWL (Pan and Horrocks, 2006; Pan and Thomas, 2007; Fokoue et al., 2012), and their reasoning services. However, most infoboxes in different Wikipedia language versions are missing. Figure 1 shows the statistics of article numbers and infobox information for six major Wikipedias. Only 32.82% of the articles have infoboxes on average, and the numbers of infoboxes for these Wikipedias vary significantly. For instance, the English Wikipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutch Spanish Chinese Number of Instances 4 3.5 </context>
</contexts>
<marker>Fokoue, Meneguzzi, Sensoy, Pan, 2012</marker>
<rawString>Achille Fokoue, Felipe Meneguzzi, Murat Sensoy and Jeff Z. Pan. 2012. Querying Linked Ontological Data through Distributed Summarization. Proc. of the 26th AAAI Conference on Artificial Intelligence (AAAI2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Robert E Schapire</author>
</authors>
<title>A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting.</title>
<date>1997</date>
<journal>J. Comput. Syst. Sci..</journal>
<marker>Freund, Schapire, 1997</marker>
<rawString>Yoav Freund and Robert E. Schapire. 1997. A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting. J. Comput. Syst. Sci..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norman Heino</author>
<author>Jeff Z Pan</author>
</authors>
<date>2012</date>
<booktitle>RDFS Reasoning on Massively Parallel Hardware. Proc. of the 11th International Semantic Web Conference (ISWC2012).</booktitle>
<contexts>
<context position="1254" citStr="Heino and Pan, 2012" startWordPosition="173" endWordPosition="176">hallenging problem to utilize the rich structured knowledge from a source language Wikipedia to help complete the missing infoboxes for a target language. In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called WikiCiKE, to solve this problem. An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors. Our experimental results demonstrate that WikiCiKE outperforms the monolingual knowledge extraction method and the translation-based method. Heino and Pan, 2012) and OWL (Pan and Horrocks, 2006; Pan and Thomas, 2007; Fokoue et al., 2012), and their reasoning services. However, most infoboxes in different Wikipedia language versions are missing. Figure 1 shows the statistics of article numbers and infobox information for six major Wikipedias. Only 32.82% of the articles have infoboxes on average, and the numbers of infoboxes for these Wikipedias vary significantly. For instance, the English Wikipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article In</context>
</contexts>
<marker>Heino, Pan, 2012</marker>
<rawString>Norman Heino and Jeff Z. Pan. 2012. RDFS Reasoning on Massively Parallel Hardware. Proc. of the 11th International Semantic Web Conference (ISWC2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aidan Hogan</author>
<author>Jeff Z Pan</author>
<author>Axel Polleres</author>
<author>Yuan Ren</author>
</authors>
<title>Scalable OWL 2 Reasoning for Linked Data. Reasoning Web. Semantic Technologies for the Web ofData.</title>
<date>2011</date>
<contexts>
<context position="2626" citStr="Hogan et al., 2011" startWordPosition="397" endWordPosition="400">1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between </context>
</contexts>
<marker>Hogan, Pan, Polleres, Ren, 2011</marker>
<rawString>Aidan Hogan, Jeff Z. Pan, Axel Polleres and Yuan Ren. 2011. Scalable OWL 2 Reasoning for Linked Data. Reasoning Web. Semantic Technologies for the Web ofData.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Hotho</author>
<author>Robert J¨aschke</author>
<author>Christoph Schmitz</author>
<author>Gerd Stumme</author>
</authors>
<date>2006</date>
<booktitle>Information Retrieval in Folksonomies: Search and Ranking. ESWC’06.</booktitle>
<marker>Hotho, J¨aschke, Schmitz, Stumme, 2006</marker>
<rawString>Andreas Hotho, Robert J¨aschke, Christoph Schmitz and Gerd Stumme. 2006. Information Retrieval in Folksonomies: Search and Ranking. ESWC’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<tech>ICML’01.</tech>
<contexts>
<context position="9064" citStr="Lafferty et al., 2001" startWordPosition="1422" endWordPosition="1425">knowledge base, and KT denotes the target wiki knowledge base. 2.2 Problem Formulation Mining new infobox information from unstructured article texts is actually a multi-template, multi-slot information extraction problem. In our task, each template represents an infobox template and each slot denotes an attribute. In the WikiCiKE framework, for each attribute attrT in an infobox template tpT, we treat the task of missing value extraction as a binary classification problem. It predicts whether a particular word (token) from the article text is the extraction target (Finn and Kushmerick, 2004; Lafferty et al., 2001). Given an attribute attrT and an instance (word/token) xi, XS = {xi}ni=1 and XT = {xi}n+m i=n+1 are the sets of instances (words/tokens) in the source and the target language respectively. xi can be represented as a feature vector according to its context. Usually, we have n ≫ m in our setting, with much more attributes in the source that those in the target. The function g : X 7→ Y maps the instance from X = XS ∪ XT to the true label of Y = {0, 1}, where 1 represents the extraction target (positive) and 0 denotes the background information (negative). Because the number of target instances m</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum and Fernando C. N. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. ICML’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alberto Lavelli</author>
<author>MaryElaine Califf</author>
<author>Fabio Ciravegna</author>
<author>Dayne Freitag</author>
<author>Claudio Giuliano</author>
<author>Nicholas Kushmerick</author>
<author>Lorenza Romano</author>
<author>Neil Ireson</author>
</authors>
<title>Evaluation of Machine Learning-based Information Extraction Algorithms: Criticisms and Recommendations. Language Resources and Evaluation.</title>
<date>2008</date>
<contexts>
<context position="21383" citStr="Lavelli et al., 2008" startWordPosition="3542" endWordPosition="3545">transfer. 2. We compare WikiCiKE with KE-Tr on the second testing data set A′test, where the existences of values are not guaranteed in those randomly selected articles, in order to demonstrate the better recall of WikiCiKE. For implementation details, the weighted-SVM is used as the basic learner f both in WikiCiKE and KE-Mon (Zhang et al., 2009), and Baidu Translation API3 is used as the translator both in WikiCiKE and KE-Tr. The Chinese texts are preprocessed using ICTCLAS4 for word segmentation. 4.1.3 Evaluation Metrics Following Lavelli’s research on evaluation of information extraction (Lavelli et al., 2008), we perform evaluation as follows. 1. We evaluate each attr separately. 2. For each attr, there is exactly one value extracted. 3. No alternative occurrence of real value is available. 4. The overlap ratio is used in this paper rather than “exactly matching” and “containing”. Given an extracted value v′ = {w′} and its corresponding real value v = {w}, two measurements for evaluating the overlap ratio are defined: recall: the rate of matched tokens w.r.t. the real value. It can be calculated using R(v′, v) = |v ∩ v′| 3http://openapi.baidu.com/service 4http://www.ictclas.org/ |v| 646 precision:</context>
</contexts>
<marker>Lavelli, Califf, Ciravegna, Freitag, Giuliano, Kushmerick, Romano, Ireson, 2008</marker>
<rawString>Alberto Lavelli, MaryElaine Califf, Fabio Ciravegna, Dayne Freitag, Claudio Giuliano, Nicholas Kushmerick, Lorenza Romano and Neil Ireson. 2008. Evaluation of Machine Learning-based Information Extraction Algorithms: Criticisms and Recommendations. Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juanzi Li</author>
<author>Jie Tang</author>
<author>Yi Li</author>
<author>Qiong Luo</author>
</authors>
<title>RiMOM: A Dynamic Multistrategy Ontology Alignment Framework.</title>
<date>2009</date>
<journal>IEEE Trans. Knowl. Data Eng..</journal>
<contexts>
<context position="28999" citStr="Li et al., 2009" startWordPosition="4821" endWordPosition="4824">ent from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attribute alignment strategies can be grouped into two categories: cross-lingual link based methods (Bouma et al., 2009) and classification based methods (Adar et al., 2009; Nguyen et al., 2011; Aumueller et al., 2005; Adafre and de Rijke, 2006; Li et al., 2009). After the first step, the value in the source language is translated into the target language. E. Adar’s approach gives the overall precision of 54% and recall of 40% (Adar et al., 2009). However, recall of these methods is limited by the number of equivalent cross-lingual articles and the number of infoboxes in the source language. It is also limited by the quality of the translators. WikiCiKE attempts to mine the missing infoboxes directly from the article texts and thus achieves a higher recall compared with these methods as shown in Section 4.3. 5.3 Transfer Learning Transfer learning ca</context>
</contexts>
<marker>Li, Tang, Li, Luo, 2009</marker>
<rawString>Juanzi Li, Jie Tang, Yi Li and Qiong Luo. 2009. RiMOM: A Dynamic Multistrategy Ontology Alignment Framework. IEEE Trans. Knowl. Data Eng..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Gui-Rong Xue</author>
<author>Wenyuan Dai</author>
<author>Yun Jiang</author>
</authors>
<title>Qiang Yang and Yong Yu.</title>
<date>2008</date>
<marker>Ling, Xue, Dai, Jiang, 2008</marker>
<rawString>Xiao Ling, Gui-Rong Xue, Wenyuan Dai, Yun Jiang, Qiang Yang and Yong Yu. 2008. Can Chinese Web Pages be Classified with English Data Source?. WWW’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheila A McIlraith</author>
</authors>
<title>Tran Cao Son and Honglei Zeng.</title>
<date>2001</date>
<journal>IEEE Intelligent Systems.</journal>
<marker>McIlraith, 2001</marker>
<rawString>Sheila A. McIlraith, Tran Cao Son and Honglei Zeng. 2001. Semantic Web Services. IEEE Intelligent Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thanh Hoang Nguyen</author>
<author>Viviane Moreira</author>
<author>Huong Nguyen</author>
<author>Hoa Nguyen</author>
<author>Juliana Freire</author>
</authors>
<title>Multilingual Schema Matching for Wikipedia Infoboxes.</title>
<date>2011</date>
<publisher>CoRR.</publisher>
<contexts>
<context position="28930" citStr="Nguyen et al., 2011" startWordPosition="4808" endWordPosition="4811">long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attribute alignment strategies can be grouped into two categories: cross-lingual link based methods (Bouma et al., 2009) and classification based methods (Adar et al., 2009; Nguyen et al., 2011; Aumueller et al., 2005; Adafre and de Rijke, 2006; Li et al., 2009). After the first step, the value in the source language is translated into the target language. E. Adar’s approach gives the overall precision of 54% and recall of 40% (Adar et al., 2009). However, recall of these methods is limited by the number of equivalent cross-lingual articles and the number of infoboxes in the source language. It is also limited by the quality of the translators. WikiCiKE attempts to mine the missing infoboxes directly from the article texts and thus achieves a higher recall compared with these method</context>
</contexts>
<marker>Nguyen, Moreira, Nguyen, Nguyen, Freire, 2011</marker>
<rawString>Thanh Hoang Nguyen, Viviane Moreira, Huong Nguyen, Hoa Nguyen and Juliana Freire. 2011. Multilingual Schema Matching for Wikipedia Infoboxes. CoRR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Z Pan</author>
<author>Edward Thomas</author>
</authors>
<date>2007</date>
<booktitle>Approximating OWL-DL Ontologies. 22nd AAAI Conference on Artificial Intelligence (AAAI-07).</booktitle>
<contexts>
<context position="1308" citStr="Pan and Thomas, 2007" startWordPosition="184" endWordPosition="187">ledge from a source language Wikipedia to help complete the missing infoboxes for a target language. In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called WikiCiKE, to solve this problem. An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors. Our experimental results demonstrate that WikiCiKE outperforms the monolingual knowledge extraction method and the translation-based method. Heino and Pan, 2012) and OWL (Pan and Horrocks, 2006; Pan and Thomas, 2007; Fokoue et al., 2012), and their reasoning services. However, most infoboxes in different Wikipedia language versions are missing. Figure 1 shows the statistics of article numbers and infobox information for six major Wikipedias. Only 32.82% of the articles have infoboxes on average, and the numbers of infoboxes for these Wikipedias vary significantly. For instance, the English Wikipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutch Spanish Chinese Numb</context>
</contexts>
<marker>Pan, Thomas, 2007</marker>
<rawString>Jeff Z. Pan and Edward Thomas. 2007. Approximating OWL-DL Ontologies. 22nd AAAI Conference on Artificial Intelligence (AAAI-07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Z Pan</author>
<author>Ian Horrocks</author>
</authors>
<date>2007</date>
<booktitle>RDFS(FA): Connecting RDF(S) and OWL DL. IEEE Transaction on Knowledge and Data Engineering.</booktitle>
<volume>19</volume>
<issue>2</issue>
<pages>192--206</pages>
<contexts>
<context position="2692" citStr="Pan and Horrocks, 2007" startWordPosition="409" endWordPosition="412">ion using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between different Wikipedia language versions, it is difficult to gather s</context>
</contexts>
<marker>Pan, Horrocks, 2007</marker>
<rawString>Jeff Z. Pan and Ian Horrocks. 2007. RDFS(FA): Connecting RDF(S) and OWL DL. IEEE Transaction on Knowledge and Data Engineering. 19(2): 192 -206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Z Pan</author>
<author>Ian Horrocks</author>
</authors>
<title>OWL-Eu: Adding Customised Datatypes into OWL.</title>
<date>2006</date>
<journal>Journal of Web Semantics.</journal>
<contexts>
<context position="1286" citStr="Pan and Horrocks, 2006" startWordPosition="179" endWordPosition="183">the rich structured knowledge from a source language Wikipedia to help complete the missing infoboxes for a target language. In this paper, we formulate the problem of cross-lingual knowledge extraction from multilingual Wikipedia sources, and present a novel framework, called WikiCiKE, to solve this problem. An instancebased transfer learning method is utilized to overcome the problems of topic drift and translation errors. Our experimental results demonstrate that WikiCiKE outperforms the monolingual knowledge extraction method and the translation-based method. Heino and Pan, 2012) and OWL (Pan and Horrocks, 2006; Pan and Thomas, 2007; Fokoue et al., 2012), and their reasoning services. However, most infoboxes in different Wikipedia language versions are missing. Figure 1 shows the statistics of article numbers and infobox information for six major Wikipedias. Only 32.82% of the articles have infoboxes on average, and the numbers of infoboxes for these Wikipedias vary significantly. For instance, the English Wikipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutc</context>
</contexts>
<marker>Pan, Horrocks, 2006</marker>
<rawString>Jeff Z. Pan and Ian Horrocks. 2006. OWL-Eu: Adding Customised Datatypes into OWL. Journal of Web Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sinno Jialin Pan</author>
<author>Qiang Yang</author>
</authors>
<title>A Survey on Transfer Learning.</title>
<date>2010</date>
<journal>IEEE Trans. Knowl. Data Eng..</journal>
<contexts>
<context position="29757" citStr="Pan and Yang, 2010" startWordPosition="4940" endWordPosition="4943">sion of 54% and recall of 40% (Adar et al., 2009). However, recall of these methods is limited by the number of equivalent cross-lingual articles and the number of infoboxes in the source language. It is also limited by the quality of the translators. WikiCiKE attempts to mine the missing infoboxes directly from the article texts and thus achieves a higher recall compared with these methods as shown in Section 4.3. 5.3 Transfer Learning Transfer learning can be grouped into four categories: instance-transfer, feature-representationtransfer, parameter-transfer and relationalknowledge-transfer (Pan and Yang, 2010). TrAdaBoost, the instance-transfer approach, is an extension of the AdaBoost algorithm, and demonstrates better transfer ability than tradition648 al learning techniques (Dai et al., 2007). Transfer learning have been widely studied for classification, regression, and cluster problems. However, few efforts have been spent in the information extraction tasks with knowledge transfer. 6 Conclusion and Future Work In this paper we proposed a general cross-lingual knowledge extraction framework called WikiCiKE, in which extraction performance in the target Wikipedia is improved by using rich infob</context>
</contexts>
<marker>Pan, Yang, 2010</marker>
<rawString>Sinno Jialin Pan and Qiang Yang. 2010. A Survey on Transfer Learning. IEEE Trans. Knowl. Data Eng..</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nick Roussopoulos</author>
<author>Stephen Kelley</author>
<author>Fr´ed´eric Vincent</author>
</authors>
<title>Nearest Neighbor Queries.</title>
<date>1995</date>
<booktitle>SIGMOD Conference’95.</booktitle>
<contexts>
<context position="17068" citStr="Roussopoulos et al., 1995" startWordPosition="2832" endWordPosition="2835"> 2ln nT) Table 3: Weight-updating Strategy of TrAdaBoost. 3.3 Template Classification Before using the learned classifier f to extract missing infobox value for the target attribute attrT, we must select the correct articles to be processed. For example, the article aNew York is not a proper article for extracting the missing value of the attribute attrbirth day. If a already has an incomplete infobox, it is clear that the correct tp is the template of its own infobox ib. For those articles that have no infoboxes, we use the classical 5-nearest neighbor algorithm to determine their templates (Roussopoulos et al., 1995) using their category labels, outlinks, inlinks as features (Wang et al., 2012). Our classifier achieves an average precision of 76.96% with an average recall of 63.29%, and can be improved further. In this paper, we concentrate on the WikiCiKE training and extraction components. 3.4 WikiCiKE Extraction Given an article a determined by template classification, we generate the missing value of attr from the corresponding text. First, we turn the text into a word sequence and compute the feature vector for each word based on the feature definition in Section 3.1. Next we use f to label each word</context>
</contexts>
<marker>Roussopoulos, Kelley, Vincent, 1995</marker>
<rawString>Nick Roussopoulos, Stephen Kelley and Fr´ed´eric Vincent. 1995. Nearest Neighbor Queries. SIGMOD Conference’95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murat Sensoy</author>
<author>Achille Fokoue</author>
<author>Jeff Z Pan</author>
<author>Timothy Norman</author>
</authors>
<title>Yuqing Tang, Nir Oren and Katia Sycara.</title>
<date>2013</date>
<booktitle>Proc. ofthe 12th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2013).</booktitle>
<marker>Sensoy, Fokoue, Pan, Norman, 2013</marker>
<rawString>Murat Sensoy, Achille Fokoue, Jeff Z. Pan, Timothy Norman, Yuqing Tang, Nir Oren and Katia Sycara. 2013. Reasoning about Uncertain Information and Conflict Resolution through Trust Revision. Proc. ofthe 12th International Conference on Autonomous Agents and Multiagent Systems (AAMAS2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: a Core of Semantic Knowledge.</title>
<date>2007</date>
<tech>WWW’07.</tech>
<contexts>
<context position="2313" citStr="Suchanek et al., 2007" startWordPosition="345" endWordPosition="348">kipedia has 13 times more infoboxes than the Chinese Wikipedia and 3.5 times more infoboxes than the second largest Wikipedia of German language. x 106 Article Infobox English German French Dutch Spanish Chinese Number of Instances 4 3.5 3 2.5 2 1.5 1 0.5 0 Languages Figure 1: Statistics for Six Major Wikipedias. 1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are availa</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci and Gerhard Weikum. 2007. Yago: a Core of Semantic Knowledge. WWW’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Volkel</author>
<author>Markus Krotzsch</author>
<author>Denny Vrandecic</author>
<author>Heiko Haller</author>
<author>Rudi Studer</author>
</authors>
<date>2006</date>
<booktitle>Semantic Wikipedia. WWW’06.</booktitle>
<contexts>
<context position="2605" citStr="Volkel et al., 2006" startWordPosition="393" endWordPosition="396">ix Major Wikipedias. 1 Introduction In recent years, the automatic knowledge extraction using Wikipedia has attracted significant research interest in research fields, such as the semantic web. As a valuable source of structured knowledge, Wikipedia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the gre</context>
</contexts>
<marker>Volkel, Krotzsch, Vrandecic, Haller, Studer, 2006</marker>
<rawString>Max Volkel, Markus Krotzsch, Denny Vrandecic, Heiko Haller and Rudi Studer. 2006. Semantic Wikipedia. WWW’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhichun Wang</author>
<author>Juanzi Li</author>
<author>Zhigang Wang</author>
<author>Jie Tang</author>
</authors>
<title>Cross-lingual Knowledge Linking across Wiki Knowledge Bases. 21st International World Wide Web Conference.</title>
<date>2012</date>
<contexts>
<context position="17147" citStr="Wang et al., 2012" startWordPosition="2844" endWordPosition="2847">efore using the learned classifier f to extract missing infobox value for the target attribute attrT, we must select the correct articles to be processed. For example, the article aNew York is not a proper article for extracting the missing value of the attribute attrbirth day. If a already has an incomplete infobox, it is clear that the correct tp is the template of its own infobox ib. For those articles that have no infoboxes, we use the classical 5-nearest neighbor algorithm to determine their templates (Roussopoulos et al., 1995) using their category labels, outlinks, inlinks as features (Wang et al., 2012). Our classifier achieves an average precision of 76.96% with an average recall of 63.29%, and can be improved further. In this paper, we concentrate on the WikiCiKE training and extraction components. 3.4 WikiCiKE Extraction Given an article a determined by template classification, we generate the missing value of attr from the corresponding text. First, we turn the text into a word sequence and compute the feature vector for each word based on the feature definition in Section 3.1. Next we use f to label each word, and we get a labeled sequence text&apos; as text&apos; = {xf(x1)1...xz (i1−1)xz xi)xf(x</context>
</contexts>
<marker>Wang, Li, Wang, Tang, 2012</marker>
<rawString>Zhichun Wang, Juanzi Li, Zhigang Wang and Jie Tang. 2012. Cross-lingual Knowledge Linking across Wiki Knowledge Bases. 21st International World Wide Web Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel S Weld</author>
<author>Fei Wu</author>
<author>Eytan Adar</author>
<author>Saleema Amershi</author>
<author>James Fogarty</author>
<author>Raphael Hoffmann</author>
<author>Kayur Patel</author>
<author>Michael Skinner</author>
</authors>
<date>2008</date>
<note>Intelligence in Wikipedia. AAAI’08.</note>
<contexts>
<context position="3079" citStr="Weld et al., 2008" startWordPosition="472" endWordPosition="475">on answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between different Wikipedia language versions, it is difficult to gather sufficient training data from a single Wikipedia. Some translation-based cross-lingual knowledge 641 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 641–650, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics extraction methods have been proposed (Adar et al., 2009; Bouma et al., 2009; Adafre and de Rijke, 2</context>
</contexts>
<marker>Weld, Wu, Adar, Amershi, Fogarty, Hoffmann, Patel, Skinner, 2008</marker>
<rawString>Daniel S. Weld, Fei Wu, Eytan Adar, Saleema Amershi, James Fogarty, Raphael Hoffmann, Kayur Patel and Michael Skinner. 2008. Intelligence in Wikipedia. AAAI’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Autonomously Semantifying Wikipedia.</title>
<date>2007</date>
<tech>CIKM’07.</tech>
<contexts>
<context position="2851" citStr="Wu and Weld, 2007" startWordPosition="437" endWordPosition="440">ia infoboxes have been utilized to build linked open data (Suchanek et al., 2007; Bollacker et al., 2008; Bizer et al., 2008; Bizer et al., 2009), support next-generation information retrieval (Hotho et al., 2006), improve question answering (Bouma et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between different Wikipedia language versions, it is difficult to gather sufficient training data from a single Wikipedia. Some translation-based cross-lingual knowledge 641 Proceedings of the 51st Annual Meeting of the Association f</context>
<context position="28143" citStr="Wu and Weld, 2007" startWordPosition="4690" endWordPosition="4693">these cases. The last category is mismatched words (22.54%). The predicted value does not match the golden value or a part of it. In the future, we can improve the performance of WikiCiKE by polishing the word segmentation result. 5 Related Work Some approaches of knowledge extraction from the open Web have been proposed (Wu et al., 2012; Yates et al., 2007). Here we focus on the extraction inside Wikipedia. 5.1 Monolingual Infobox Extraction KYLIN is the first system to autonomously extract the missing infoboxes from the corresponding article texts by using a self-supervised learning method (Wu and Weld, 2007). KYLIN performs well when enough training data are available. Such techniques as shrinkage and retraining are proposed to increase the recall from English Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attrib</context>
</contexts>
<marker>Wu, Weld, 2007</marker>
<rawString>Fei Wu and Daniel S. Weld. 2007. Autonomously Semantifying Wikipedia. CIKM’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open Information Extraction Using Wikipedia.</title>
<date>2010</date>
<contexts>
<context position="28375" citStr="Wu and Weld, 2010" startWordPosition="4729" endWordPosition="4732"> Related Work Some approaches of knowledge extraction from the open Web have been proposed (Wu et al., 2012; Yates et al., 2007). Here we focus on the extraction inside Wikipedia. 5.1 Monolingual Infobox Extraction KYLIN is the first system to autonomously extract the missing infoboxes from the corresponding article texts by using a self-supervised learning method (Wu and Weld, 2007). KYLIN performs well when enough training data are available. Such techniques as shrinkage and retraining are proposed to increase the recall from English Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attribute alignment strategies can be grouped into two categories: cross-lingual link based methods (Bouma et al., 2009) and classification based methods (Adar et al., 2009; Nguyen et al., 2011; Aumueller et al., 2005; Adafre and de Rijke</context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S. Weld. 2010. Open Information Extraction Using Wikipedia. ACL’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Raphael Hoffmann</author>
<author>Daniel S Weld</author>
</authors>
<title>Information Extraction from Wikipedia: Moving down the Long Tail.</title>
<date>2008</date>
<contexts>
<context position="3097" citStr="Wu et al., 2008" startWordPosition="476" endWordPosition="479"> et al., 2008; Ferr´andez et al., 2009), and other aspects of data exploitation (McIlraith et al., 2001; Volkel et al., 2006; Hogan et al., 2011) using semantic web standards, such as RDF (Pan and Horrocks, 2007; To solve this problem, KYLIN has been proposed to extract the missing infoboxes from unstructured article texts for the English Wikipedia (Wu and Weld, 2007). KYLIN performs well when sufficient training data are available, and such techniques as shrinkage and retraining have been used to increase recall from English Wikipedia’s long tail of sparse infobox classes (Weld et al., 2008; Wu et al., 2008). The extraction performance of KYLIN is limited by the number of available training samples. Due to the great imbalance between different Wikipedia language versions, it is difficult to gather sufficient training data from a single Wikipedia. Some translation-based cross-lingual knowledge 641 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 641–650, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics extraction methods have been proposed (Adar et al., 2009; Bouma et al., 2009; Adafre and de Rijke, 2006). These method</context>
<context position="28355" citStr="Wu et al., 2008" startWordPosition="4725" endWordPosition="4728">ntation result. 5 Related Work Some approaches of knowledge extraction from the open Web have been proposed (Wu et al., 2012; Yates et al., 2007). Here we focus on the extraction inside Wikipedia. 5.1 Monolingual Infobox Extraction KYLIN is the first system to autonomously extract the missing infoboxes from the corresponding article texts by using a self-supervised learning method (Wu and Weld, 2007). KYLIN performs well when enough training data are available. Such techniques as shrinkage and retraining are proposed to increase the recall from English Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags rich knowledge in the other language to improve extraction performance in the target Wikipedia. 5.2 Cross-lingual Infobox Completion Current translation based methods usually contain two steps: cross-lingual attribute alignment and value translation. The attribute alignment strategies can be grouped into two categories: cross-lingual link based methods (Bouma et al., 2009) and classification based methods (Adar et al., 2009; Nguyen et al., 2011; Aumueller et al., 2005;</context>
</contexts>
<marker>Wu, Hoffmann, Weld, 2008</marker>
<rawString>Fei Wu, Raphael Hoffmann and Daniel S. Weld. 2008. Information Extraction from Wikipedia: Moving down the Long Tail. KDD’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wentao Wu</author>
</authors>
<title>Hongsong Li, Haixun Wang and Kenny Qili Zhu.</title>
<date>2012</date>
<booktitle>SIGMOD Conference’12.</booktitle>
<marker>Wu, 2012</marker>
<rawString>Wentao Wu, Hongsong Li, Haixun Wang and Kenny Qili Zhu. 2012. Probase: a Probabilistic Taxonomy for Text Understanding. SIGMOD Conference’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yates</author>
<author>Michael Cafarella</author>
<author>Michele Banko</author>
<author>Oren Etzioni</author>
<author>Matthew Broadhead</author>
<author>Stephen Soderland</author>
</authors>
<date>2007</date>
<booktitle>TextRunner: Open Information Extraction on the Web. NAACL-Demonstrations’07.</booktitle>
<contexts>
<context position="27885" citStr="Yates et al., 2007" startWordPosition="4649" endWordPosition="4652">e second category is because of the incomplete infoboxes (36.62%). In evaluation of KE-Mon, we directly use the values in infoboxex as golden values, some of them are incomplete so the correct predicted values will be automatically judged as the incorrect in these cases. The last category is mismatched words (22.54%). The predicted value does not match the golden value or a part of it. In the future, we can improve the performance of WikiCiKE by polishing the word segmentation result. 5 Related Work Some approaches of knowledge extraction from the open Web have been proposed (Wu et al., 2012; Yates et al., 2007). Here we focus on the extraction inside Wikipedia. 5.1 Monolingual Infobox Extraction KYLIN is the first system to autonomously extract the missing infoboxes from the corresponding article texts by using a self-supervised learning method (Wu and Weld, 2007). KYLIN performs well when enough training data are available. Such techniques as shrinkage and retraining are proposed to increase the recall from English Wikipedia’s long tail of sparse classes (Wu et al., 2008; Wu and Weld, 2010). Different from Wu’s research, WikiCiKE is a cross-lingual knowledge extraction framework, which leverags ric</context>
</contexts>
<marker>Yates, Cafarella, Banko, Etzioni, Broadhead, Soderland, 2007</marker>
<rawString>Alexander Yates, Michael Cafarella, Michele Banko, Oren Etzioni, Matthew Broadhead and Stephen Soderland. 2007. TextRunner: Open Information Extraction on the Web. NAACL-Demonstrations’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinfeng Zhang</author>
</authors>
<title>Xiaozhao Xu, Yiheng Cai and Yaowei Liu.</title>
<date>2009</date>
<booktitle>SVM. ICNC(3)’09.</booktitle>
<marker>Zhang, 2009</marker>
<rawString>Xinfeng Zhang, Xiaozhao Xu, Yiheng Cai and Yaowei Liu. 2009. A Weighted Hyper-Sphere SVM. ICNC(3)’09.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>