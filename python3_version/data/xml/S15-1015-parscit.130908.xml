<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000019">
<title confidence="0.995253">
Ideological Perspective Detection Using Semantic Features
</title>
<author confidence="0.995191">
Heba Elfardy Mona Diab Chris Callison-Burch
</author>
<affiliation confidence="0.995144">
Columbia University George Washington University University of Pennsylvania
</affiliation>
<address confidence="0.936979">
New York, NY Washington, DC Philadelphia, PA
</address>
<email confidence="0.999758">
heba@cs.columbia.edu mtdiab@gwu.edu ccb@cis.upenn.edu
</email>
<sectionHeader confidence="0.995659" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996779740740741">
In this paper, we propose the use of word sense
disambiguation and latent semantic features to
automatically identify a person’s perspective
from his/her written text. We run an Ama-
zon Mechanical Turk experiment where we
ask Turkers to answer a set of constrained and
open-ended political questions drawn from the
American National Election Studies (ANES).
We then extract the proposed features from
the answers to the open-ended questions and
use them to predict the answer to one of
the constrained questions, namely, their pre-
ferred Presidential Candidate. In addition to
this newly created dataset, we also evaluate
our proposed approach on a second standard
dataset of “Ideological-Debates”. This lat-
ter dataset contains topics from four domains:
Abortion, Creationism, Gun Rights and Gay-
Rights. Experimental results show that us-
ing word sense disambiguation and latent-
semantics, whether separately or combined,
beats the majority and random baselines on the
cross-validation and held-out-test sets for both
the ANES and the four domains of the “Ideo-
logical Debates” datasets. Moreover combin-
ing both feature sets outperforms a stronger
unigram-only classification system.
</bodyText>
<sectionHeader confidence="0.999352" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999982384615385">
With the pervasiveness of social media and online
discussion fora, there has been a significant increase
in documented political and ideological discussions.
Automatically predicting the perspective or stance
of users in such media is a challenging research
problem that has a wide variety of applications in-
cluding recommendation systems, targeted advertis-
ing, political polling, product reviews and even pre-
dicting possible future events. Ideology refers to
the beliefs that influence an individual’s goals, ex-
pectations and views of the world (Van Dijk, 1998;
Ahmed and Xing, 2010). The ideological perspec-
tive of a person is often expressed in his/her choice
of discussed topics. People with opposing per-
spectives will choose to make different topics more
salient. (Entman, 1993).
From a social-science viewpoint, the notion of
“perspective” is related to the concept of “framing”.
Framing involves making some topics (or some as-
pects of the discussed topics) more prominent in or-
der to promote the views and interpretations of the
writer (communicator). The communicator makes
these framing decisions either consciously or uncon-
sciously (Entman, 1993). These decisions are often
expressed in the lexical choice. For example, a per-
son who holds anti-abortion views, is more likely to
use the terms “life” and “kill” whereas a person who
is pro a woman having an option to go for an abor-
tion will often stress on “choice”.
From a computational viewpoint, work on
perspective-detection is closely related to subjectiv-
ity and sentiment analysis. One’s perspective nor-
mally influences his/her sentiment towards different
topics or targets. Conversely identifying the senti-
ment of a person towards multiple targets can serve
as a cue for identifying his/her perspective. The
main difference between perspective and sentiment
is that unlike sentiment that is more transient, per-
spective is often more deeply seated and less likely
</bodyText>
<page confidence="0.968239">
137
</page>
<note confidence="0.953538">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 137–146,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.999367842105263">
to change. Most of the current perspective-detection
work focuses on “Ideological Perspective” by try-
ing to predict a person’s stance on controversial top-
ics such as the Palestinian-Israeli conflict, abortion,
gay-rights, gun-rights, etc.
In this paper, we are interested in identifying the
“Ideological Perspective” of a person using seman-
tic features derived from his/her written text. We use
two different sets of semantic features to train sev-
eral supervised systems that predict different aspects
of a person’s ideological stance toward specific top-
ics.
We explore the use of Word Sense Disambigua-
tion from the high dimensional space and Latent Se-
mantic models from the low dimensional space on
two datasets. We find that explicitly modeling the
lexical and contextual semantics to predict a per-
son’s perspective outperforms a strong-baseline sys-
tem trained on standard unigram features.
</bodyText>
<sectionHeader confidence="0.999748" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999963351351352">
Current computational linguistics research on auto-
matic perspective detection uses both supervised and
unsupervised techniques. The main task handled
by supervised approaches is to perform document
(or post) level perspective (or stance) classification,
whether binary or multiclass labeling. Unsupervised
approaches on the other hand, mainly try to cluster
users in a discussion. One of the early works on
binary perspective identification is that of Lin et al.
(2006) which uses articles from the Bitter-Lemons
website –a website that discusses the Palestinian-
Israeli conflict from each side’s point of view– to
train a system for performing automatic perspective
detection on the sentence and document levels. On
the website, an Israeli editor and a Palestinian edi-
tor, together with invited guests, contribute articles
to the website on a weekly basis. Lin et al. (2006)
use bag-of-words features. They run different ex-
periments where they vary the training and test sets
between: (a) editors’ articles and (b) guests’ arti-
cles. The accuracies of the different experimental
conditions vary between 86% and 99%. As one
might expect the highest accuracy (99%) is that of
the system that is trained and tested on the editors’
articles. For this system, the classifier is not only
capturing the perspective but also the editors’ writ-
ing styles. In Klebanov et al. (2010), the authors
tackle the same problem of binary-perspective de-
tection and experiment with four corpora; Bitter-
Lemons, Bitter-Lemons-International, Partial-Birth-
Abortion and Death-Penalty. They show that using
term-frequencies does not improve over using bi-
nary bag-of-words features and that using only the
best 1-4.9% features is sufficient to achieve high ac-
curacy. They achieve the highest accuracy (97%) on
the Partial-Birth-Abortion dataset and the lowest ac-
curacy (73%) on the Death-Penalty dataset.
Hasan and Ng (2012) also tackle the problem of
binary perspective detection but using Integer Linear
Programming (ILP) to perform joint inference over
the predictions made by a post-stance classifier and
several topic-stance classifiers. The authors use n-
grams, sentence-type and opinion-dependencies as
features to train their classifiers. They collect de-
bate posts discussing Abortion and Gun-Rights and
achieve an Fβ_1 score of 61.1% on the Abortion
dataset and 57.8% on the Gun-Rights dataset. In
Hasan and Ng (2013), they extend their previous
work by incorporating two soft-constraints that treat
the task of post-stance classification as a sequence-
labeling problem and ensure that the topic-stance of
each author is consistent across all posts.
Somasundaran and Wiebe (2010) employ the no-
tion of “arguing” to identify a person’s stance (sup-
porting or opposing) towards a topic. Arguing can
be indicated by using either positive lexical cues
such as “actually” or negative ones such as “cer-
tainly not”. They construct an arguing lexicon and
use it to derive features for their classifier. They ex-
periment with both arguing and sentiment features
on four datasets; Abortion, Creationism, Gun-Rights
and Gay-Rights. They show that combining argu-
ing and sentiment features outperforms a unigram
baseline on Abortion, Gay-Rights and Gun-Rights
datasets while the unigram system performs best on
the Creationism dataset.
A closely related work is that of Al Khatib et al.
(2012). In this work, the authors use a set of Ara-
bic and English Wikipedia articles about Arab and
Israeli public figures to explore the differences in
point of view between the Arabic and English arti-
cles about each figure. They assign a point-of-view
score to each article in each language, and use these
scores to train a classifier to predict the difference in
</bodyText>
<page confidence="0.996739">
138
</page>
<table confidence="0.998008">
PCC Obama Romney Neither
Train 62.9 25.3 11.8
Test 67.6 18.5 13.9
</table>
<tableCaption confidence="0.834312">
Table 1: Class Distribution of Presidential Candi-
date Choice (PCC) in the ANES dataset
</tableCaption>
<bodyText confidence="0.995936666666667">
point of view between each article-pair.
For unsupervised approaches, two of the most re-
cent works are those of Abu-Jbara et al. (2012) and
Dasigi et al. (2012). In Abu-Jbara et al. (2012),
the authors perform subgroup detection by cluster-
ing authors according to their sentiment towards top-
ics, Named-Entities as well as other discussants.
Dasigi et al. (2012) extend the previous work by in-
troducing the notion of implicit attitude which mod-
els the similarity between the topics discussed by a
pair of people. They note that people that share the
same opinion tend to discuss similar topics, thereby
their texts tend to have a high semantic similarity.
By adding implicit attitude, namely by explicitly
modeling latent sentential semantics, they achieve
an Fβ=1 score improvement of 3.83% and 2.12%
on “Wikipedia-Discussions” and “Online-Debates”
datasets, respectively.
Yano et al. (2010) study the linguistic cues for
bias in political blogs. The authors draw sentences
from American political blogs and annotate them for
bias on Amazon Mechanical Turk. They explore
whether the Turkers’ decisions are influenced by
their perspectives, for example whether a self pro-
claimed liberal Turker is more likely to view sen-
tences written by a conservative as biased and vice
versa.
</bodyText>
<sectionHeader confidence="0.99841" genericHeader="method">
3 Datasets
</sectionHeader>
<bodyText confidence="0.981768">
We use two datasets to evaluate our approach.
</bodyText>
<subsectionHeader confidence="0.989914">
3.1 ANES Dataset
</subsectionHeader>
<bodyText confidence="0.999937857142857">
We create this dataset by drawing a set of questions
from the American National Election Studies
(ANES) survey questions.1 ANES conducts various
surveys in order to provide better explanations
and analysis of the outcomes of USA Presidential
elections. While the officially administered ANES
survey contains both constrained multiple choice
</bodyText>
<page confidence="0.418326">
1electionstudies.org/studypages/2010_2012EGSS/2010_2012EGSS
</page>
<table confidence="0.999502333333333">
Pro Against
Abortion 55.3 44.7
Train Creationism 35.8 64.2
Gay-Rights 64 36
Gun-Rights 74 26
Abortion 50.4 49.6
Test Creationism 27.9 72.1
Gay-Rights 63.6 36.4
Gun-Rights 57.5 42.5
</table>
<tableCaption confidence="0.7795205">
Table 2: Class Distribution across the four domains
of the Online Debates Dataset
</tableCaption>
<bodyText confidence="0.998742739130435">
questions and open-ended (free form essay style)
questions, the answers to the open-ended questions,
which are more interesting from an NLP perspec-
tive, are not made publicly available in order to
protect the privacy of respondents. In this work,
we run an Amazon Mechanical Turk annotation
experiment where we ask Amazon Mechanical
Turk annotators (aka Turkers) to answer a large
set of constrained and open-ended questions drawn
from ANES.2 The constrained questions may be
considered a form of self labeling indicating the
respondent/Turker’s background or perspective
on specific issues. All Turkers participating in
the experiment were required to be from the US.
Moreover, we added seven quality-control questions
with a correct (and obvious) answer in order to
identify spam Turkers. All submissions that ren-
dered more than one of these questions wrong were
automatically rejected.
The first set of questions that required constrained
answers, such as multiple choice or binary responses
as true or false can be binned into the following cat-
egories:
</bodyText>
<listItem confidence="0.955325111111111">
• Background Questions: A person’s age, gender,
educational level, income, marital-status, social-
status, how often he/she follows the news, what
news sources he/she follows, etc.;
• Opinion of Political Parties: Democratic and Re-
publican parties and their respective public figure
representatives;
• Opinion on major economic and political prob-
lems facing the USA;
</listItem>
<footnote confidence="0.897971">
2Please contact the authors to obtain the dataset
</footnote>
<page confidence="0.990274">
139
</page>
<bodyText confidence="0.989589166666666">
Q1 I approve of Obama’s and the Democrats’ position on abortion and gay marriage and their tendency to
favor programs that help the poor and working class. They seem more compassionate and more socially
progressive.
Q2 Neither Obama nor the Democrats seems able to get a hold on spending, the deficit or help the economy
and unemployment. They seem to spend too much time criticizing their opponents rather than work toward
viable solutions and seem to distort facts against the other party more.
Q3 I think Mitt Romney and the republicans in general would do a better job at lowering the deficit and stim-
ulating the economy and reducing unemployment. I also agree with their position of less government
involvement in some areas.
Q4 I dislike Mitt Romney’s plans to eliminate funding for Planned Parenthood and the republicans stand on
social issues such as abortion and gay rights, especially gay marriage. I feel Republicans have been taken
over by the religious right and are socially regressive.
</bodyText>
<tableCaption confidence="0.951373">
Table 3: Sample answers provided by one Turker to the first four essay questions in the ANES dataset.
</tableCaption>
<listItem confidence="0.940358">
• Ideology Questions: Importance of religion,
political-party-affiliation, presidential candidate
choice, etc.;
• Opinion on contentious issues: Such as Race
(White, Black, Asian and Hispanic Americans),
same-sex marriage, gun-control, universal health-
care, etc.
</listItem>
<bodyText confidence="0.999494818181818">
The second set of questions ask about a person’s
opinion of certain ideological topics. The responses
are not constrained in any manner.
Since our main objective is to study whether a per-
son’s perspective can be automatically identified us-
ing NLP techniques applied to his/her written text,
we choose to predict the answer to one of the con-
strained ideological questions, “Presidential Candi-
date Choice” (PCC), based on the answers to the fol-
lowing open ended questions: (Table 1 shows the
distribution of PCC in the training and test sets)
</bodyText>
<listItem confidence="0.981658222222222">
• Q1: Is there something that would make you vote
for a Democratic presidential candidate?
• Q2: Is there something that would make you vote
against a Democratic presidential candidate?
• Q3: Is there something that would make you vote
for a Republican presidential candidate?
• Q4: Is there something that would make you vote
against a Republican presidential candidate?
• Q5: If you said there is something you like about
the Democratic Party: What is that?
• Q6: If you said there is something you dislike
about the Democratic Party: What is that?
• Q7: If you said there is something you like about
the Republican Party: What is that?
• Q8: If you said there is something you dislike
about the Republican Party: What is that?
• Q9: What has been the most important issue to
you personally in this election?
• Q10: What has been the second most important
issue to you personally in this election?
• Q11: What do you think is the most important
political problem facing the United States today?
• Q12: What do you think is the second most im-
portant political problem facing the United States
today?
• Q13: What do you think the terrorists were trying
to accomplish by September 11th attacks?
</listItem>
<bodyText confidence="0.99980505">
Table 3 shows the answers provided by a Turker
to the first four of these questions.
In order to simulate user generated content where
people are not providing answers to a predefined set
of questions but are rather discussing current events
or topics, we decide to combine the answers to all of
these questions in one document per Turker and use
this combined resulting document to derive features
(as opposed to deriving features from the answer to
each question separately). In order to reduce am-
biguity, we perform a quasi co-reference resolution
step on pronouns. Prior to combining the answers to
all 13 questions, we perform a “pronoun-rewriting”
step where we replace the sentence initial pronouns
with the topic the question is about. For example, for
Q3, “Is there something that would make you vote
for a Republican presidential candidate?”, and the
answer provided is “They are against voting rights
for illegal immigrants. They want to balance the
budget and find a way to slowly reduce the national
</bodyText>
<page confidence="0.971115">
140
</page>
<table confidence="0.9999755">
Domain Stance Post
Abortion Pro So abortion is okay in areas where more people like it than don’t?
Abortion Against your exact words “But successful abortion carries a 100% rate of risk of death to the child”
no duh, that’s the whole point of abortion, is to KILL THE BABY. well actually that’s
MURDER
Creationism Pro You cant make nothing out of nothing!!!
Creationism Against It is only belief. No one has any real evidence.
Gay-Rights Pro This post is almost insulting in its complete lack of evidence or even a reasoned argument.
Merely dismissing the other side is not an argument
Gay-Rights Against Compared to children with a father and a mother married to each other and getting along
with each other, the answer is yes. Compared to children living in an orphanage, it’s hard
to say.
Gun-Rights Pro An assault weapon ban violates the second amendment
Gun-Rights Against Dude. Are you home all the time? Is this secured? Do you have a lot of fire extinguishers?
</table>
<tableCaption confidence="0.983046">
Table 4: Sample posts from “Ideological Debates” dataset.
</tableCaption>
<table confidence="0.999850142857143">
Train Test
Posts Tokens Token/Post Types Types/Post Posts Tokens Tokens/Post Types Types/Post
ANES 965 437,080 453 14,410 15 108 61,414 569 5,487 51
Abortion 1,036 154,929 150 10,192 10 115 18,299 159 2,734 24
Creationism 1,108 217,262 196 13,466 12 122 10,756 88 2,160 18
Gay-Rights 1,858 312,900 168 16,742 9 206 17,400 84 2,842 14
Gun-Rights 963 146,886 153 10,969 11 106 7,142 67 1,588 15
</table>
<tableCaption confidence="0.984495">
Table 5: Statistics of the training and test sets for both the ANES and the four domains of the Ideological-
Debates datasets.
</tableCaption>
<bodyText confidence="0.728643">
debt.”, we replace “They” with “Republicans”. 4 Approach
</bodyText>
<subsectionHeader confidence="0.986412">
3.2 Ideological Debates Dataset
</subsectionHeader>
<bodyText confidence="0.998217565217391">
This dataset was collected by Somasundaran and
Wiebe (2010) . It contains debate posts from six
domains; (a) Abortion, (b) Creationism, (c) Gay-
Rights, (d) Gun-Rights, (e) Healthcare and (f) Ex-
istence of God. Each domain represents an ideo-
logical topic with two possible perspectives, pro and
against. Similar to the work of (Somasundaran and
Wiebe, 2010), we use the first four domains to eval-
uate our approach. Table 2 shows the class distri-
bution in each of these four domains while table
4 lists some sample posts. It should be noted that
our results are not comparable to those obtained by
(Somasundaran and Wiebe, 2010), since they used a
subset of the posts in each domain and the split was
not publicized.
Table 5 shows the size of the training and test data
in the ANES and Ideological-Debates datasets.
Our goal is to determine whether semantic features
help in identifying a person’s ideological perspec-
tive as determined by his/her answer to the PCC con-
strained question in the “ANES” dataset and his/her
stance towards the ideological-topics discussed in
the “Ideological-Debates” dataset independently.
</bodyText>
<subsectionHeader confidence="0.99111">
4.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999936444444444">
We apply basic preprocessing to the text by separat-
ing punctuation and numbers from words. All punc-
tuation and numbers are then ignored when training
the classifier for all of our systems including the uni-
gram baseline. The intuition behind this is that punc-
tuation and numbers do not capture the perspective
of a person but rather the writing style. Moreover,
by ignoring them, we avoid overfitting the training
data.
</bodyText>
<page confidence="0.996312">
141
</page>
<subsectionHeader confidence="0.991052">
4.2 Word Sense Disambiguation (WSD)
</subsectionHeader>
<bodyText confidence="0.999948818181818">
We use WN-Sense-Relate (Patwardhan et al., 2005)
to perform word sense disambiguation. Sense-
Relate uses WordNet (Miller, 1995) to tag each word
with the part-of-speech and sense-id. The only parts
of speech that are handled by WN-Sense-Relate are
adjectives (a), adverbs (r), verbs (v) and nouns (n).
In addition to the part-of-speech and sense-id, WN-
Sense-Relate also identifies and tags compounds.
The word sense tagging process can be either con-
textual or can rely on the most frequent sense. We
experiment with both variants.
</bodyText>
<subsectionHeader confidence="0.510629">
4.2.1 Contextual WSD (WSD-CXT)
</subsectionHeader>
<bodyText confidence="0.9850365">
In this variant of WSD, in addition to tagging
compounds, we contextually disambiguate each
word and tag it with its sense-id and part-of-speech.
We use the default setting of SenseRelate which
employs a modified version of the Lesk algorithm
(Banerjee and Pedersen, 2002) to perform the
disambiguation. This version of the Lesk algorithm
measures the similarity between the WordNet gloss
of each sense of the target word and those of its
surrounding context words in the text. It then
chooses the sense whose gloss is most similar to the
surrounding words. We use a window of size three
which uses one word before and one word after the
target word.
ex.
“The Democratic Party supports women ’s equality
, including equal pay , access to health care and
other issues .”
</bodyText>
<equation confidence="0.8706264">
becomes:
“the#ND democratic_party#n#1 supports#n#10
women#n#1 ’s#ND equality#n#1 includ-
ing#v#3 equal#a#1 pay#v#1 access#n#2 to#ND
health_care#n#1 and#ND other#a#1 issues#n#7”3
</equation>
<bodyText confidence="0.9613406">
We then use the tagged-words to retrieve the
Synonym-Set (Synset) of this sense of the word us-
ing WN-QueryData (Pedersen et al., 2004). We as-
sign each Synset an ID and whenever any of the
words in the retrieved Synset is seen in the input text,
we replace it with this Synset-ID.
For example, the Synset of “issues#n#7” is iden-
tified as “issue#n#7, consequence#n#1, effect#n#1,
3#ND indicates a non-defined word
outcome#n#2, result#n#1, event#n#4, issue#n#7,
upshot#n#1”. We assign this Synset a unique ID, for
example “Synset-100”, and any occurrence of any
of “issue#n#7, consequence#n#1, effect#n#1, out-
come#n#2, result#n#1, event#n#4, issue#n#7, and
upshot#n#1” is replaced by “Synset-100”.
</bodyText>
<subsectionHeader confidence="0.816886">
4.2.2 Most Frequent Sense WSD (WSD-MFS)
</subsectionHeader>
<bodyText confidence="0.999948857142857">
In this variant of WSD, instead of perform-
ing the disambiguation contextually, we rely on
the most frequent sense. Using this scheme,
“issues” is tagged as “issues#n#1” whose Synset
is “issue#n#1”, while “support” is tagged as
“support#v#1” whose Synset is support#v#1’,
back_up#v#1.
</bodyText>
<subsectionHeader confidence="0.999406">
4.3 Latent Semantics
</subsectionHeader>
<bodyText confidence="0.999858176470588">
The next set of features relies on “Latent Semantics”
which maps text from a high-dimensional space
such as unigrams to a low-dimensional one such as
topics. Most of these models assign a semantic pro-
file to each given sentence (or document) by con-
sidering the observed words and assuming that each
given document has a distribution over “K” top-
ics. We apply (1) Latent Dirichlet Allocation (LDA)
(Blei et al., 2003) as implemented in MALLET
toolkit (McCallum, 2002), and (2) Weighted Tex-
tual Matrix Factorization (WTMF) (Guo and Diab,
2012) to each post. In addition to observed words,
WTMF also models missing ones namely explicitly
modeling what the post is not about. WTMF de-
fines missing words as the whole vocabulary of the
training data minus the ones observed in the given
document.
</bodyText>
<subsectionHeader confidence="0.973047">
4.3.1 Number of Topics
</subsectionHeader>
<bodyText confidence="0.9994507">
We vary the number of topics (K) between 100
and 500 (with a step-size of 100) and use the best
“K” for each dataset. We define the best K, for each
of LDA and WTMF, as the one that yields the best
cross-validation results when combined with uni-
gram features. The best K value for LDA is 400
for PCC and Abortion, 500 for Creationism, 300 for
Gay-Rights and 100 for Gun-Rights. For WTMF,
the best K is 500 for PCC, and Gun-Rights and 100
for Abortion, Creationism and Gay-Rights.
</bodyText>
<page confidence="0.994685">
142
</page>
<table confidence="0.9767875">
PCC Fβ=1 score
Train 74.65
Test 74.81
All 74.69
</table>
<tableCaption confidence="0.836369">
Table 6: Performance of human annotators in pre-
dicting “PCC” of a person from his/her responses to
ANES essay questions.
</tableCaption>
<subsectionHeader confidence="0.942028">
4.3.2 Training Data
</subsectionHeader>
<bodyText confidence="0.999587714285714">
We collected our training data for topic model-
ing from Facebook comments of renowned Amer-
ican politicians such as Joe-Biden, Chris-Christie,
George W. Bush, Michelle-Obama, etc. We trained
LDA and WTMF using a subset of 100,000 com-
ments (corresponding to ~5,000,000 tokens and
~265,000 types.
</bodyText>
<subsectionHeader confidence="0.997295">
4.4 Classifier Training
</subsectionHeader>
<bodyText confidence="0.999935857142857">
Using WEKA toolkit (Hall et al., 2009) and the
derived features, we train Sequential Minimal Op-
timization (SMO) SVM classifiers (Platt, 1998)
for each of “ANES” and the four domains of
“Ideological-Debates” datasets. We use a normal-
ized quadratic kernel, set the parameter C to 100 and
apply a 10-fold cross validation on the training sets.
</bodyText>
<sectionHeader confidence="0.999703" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.999174">
5.1 Baselines
</subsectionHeader>
<bodyText confidence="0.999919">
We compare our approach to three baselines;
</bodyText>
<listItem confidence="0.998001333333333">
• Majority Baseline (MAJ-BL): which assigns all
posts to the most frequent class-label;
• Random Baseline (RAND-BL): which randomly
chooses the class-label;
• Unigram Baseline (UNI-BL): a strong baseline
that uses standard unigram features.
</listItem>
<bodyText confidence="0.9991447">
In addition to these three baselines, we do a
human-evaluation for the ANES dataset in order to
assess the difficulty of the task and in order to get
an upper-bound on how well we can do in predict-
ing PCC. We run an Amazon Mechanical Turk ex-
periment where we ask Turkers to read each post
(constructed by combining the answers to the open-
ended questions of each record) and ask them to
guess the PCC of the person who wrote that text
along with the reason for their answer. We found
</bodyText>
<figureCaption confidence="0.544473">
Figure 1: Fβ=1 score of human judgments in pre-
dicting “PCC” from the answers to the essay ques-
tions in the ANES dataset across different post-sizes
</figureCaption>
<bodyText confidence="0.998707166666667">
that Turkers were able to predict the PCC with an
average Fβ=1 score of ~75% on both the cross-
validation and test-sets. We also found that the task
is particularly difficult for very short (&lt; 100 words)
documents. Table 6 and Figure 1 show the results of
this qualitative assessment.
</bodyText>
<subsectionHeader confidence="0.997767">
5.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999776714285714">
We first evaluate each variant of the proposed fea-
tures separately and then we combine the latent-
semantics features with unigram-features and the
two variants of WSD.
Tables 7 and 8 show the cross-validation results
on the training data and the results on the held-out
test sets respectively.
</bodyText>
<sectionHeader confidence="0.999746" genericHeader="method">
6 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999933">
6.1 Cross Validation Results
</subsectionHeader>
<bodyText confidence="0.999773285714286">
For the cross-validation results, all configurations of
the proposed features outperform the majority and
random baselines. Moreover using WSD-MFS, ei-
ther separately or combined with LDA or WTMF,
outperforms the unigram-baseline. Overall WSD-
MFS performs better than WSD-CXT, except on the
Abortion dataset.
For Latent-Semantics, even though using either
of LDA or WTMF separately, without unigram-
features, does not outperform the unigram baseline,
combining each of them with unigrams outperforms
the unigram-only setup. When combined with uni-
gram or WSD features, WTMF outperforms LDA on
PCC, Creationism and Gun-Rights while LDA out-
</bodyText>
<page confidence="0.996834">
143
</page>
<table confidence="0.999955071428571">
PCC Abortion Creationism Gay-Rights Gun-Rights
MAJ-BL 48.6 39.4 50.2 50 63
RAND-BL 36.7 47.6 50 52.9 52.6
UNI-BL 66.3 63.1 58.7 67.1 72.7
WTMF 62.9 56.9 57.1 57.1 72.6
LDA 62.4 57.4 58.7 63.6 71
Unigram+WTMF 68.8 62.7 62 67.2 75.7
Unigram+LDA 66.6 64.5 60 67.4 72.9
WSD-CXT 65.8 64.8 59.4 69.6 73.8
WSD-MFS 67.5 64 61.1 69.7 75
WSD-CXT + WTMF 68 64.1 61.6 68.1 74.8
WSD-CXT + LDA 65 64.3 59.3 69.1 73.8
WSD-MFS + WTMF 69.2 64.7 62.7 67.6 75.7
WSD-MFS + LDA 67.3 65.1 62.1 69.5 75
</table>
<tableCaption confidence="0.984094">
Table 7: 10-fold cross-validation results (measured in F0=1 score) of using WSD and Latent-Semantics
against the baselines.
</tableCaption>
<table confidence="0.999967714285714">
PCC Abortion Creationism Gay-Rights Gun-Rights
MAJ-BL 54.5 33.8 60.5 49.4 42
RAND-BL 46.6 47.3 54.9 41.9 45.5
UNI-BL 68 54.3 67.1 52.4 48.1
WTMF 69.1 58.1 60.1 49.2 43.7
LDA 60.4 55.3 58.7 58.1 62.4
Unigram+WTMF 68.9 54.2 71.2 56.8 58.7
Unigram+LDA 68 58.9 70.7 56.4 48.1
WSD-CXT 66.8 52.8 66.2 53.4 44.1
WSD-MFS 64.2 54.6 69.8 56.3 46.2
WSD-CXT + WTMF 66.1 52.9 71 55.1 53.7
WSD-CXT + LDA 67.6 57 68.5 55.6 46.2
WSD-MFS + WTMF 71.6 55.7 69.1 56.7 52.7
WSD-MFS + LDA 65.3 62.6 69.6 56.4 44.1
</table>
<tableCaption confidence="0.997257">
Table 8: Held-out test-set results (measured in F0=1 score) of using WSD and Latent-Semantics against the
</tableCaption>
<bodyText confidence="0.919172">
baselines.
performs WTMF on the other two datasets. Com-
bining WSD-MFS with LDA for Abortion and Gay-
Rights and with WTMF for PCC, Creationism and
Gun-Rights yields the best (or close to the best) re-
sults.
</bodyText>
<subsectionHeader confidence="0.996105">
6.2 Held-out Test-Sets Results
</subsectionHeader>
<bodyText confidence="0.999963181818182">
Unlike the cross-validation results, using latent-
semantics features separately improves over the un-
igram baseline for four out of the five datasets and
in some cases adding unigrams to latent-semantics
features actually hurts the performance. This sug-
gests that latent-semantics are less likely to overfit
the training data.
Table 9 shows examples of the posts that were
misclassified by the majority and unigram baselines
and correctly classified by the best semantic model
for each dataset.
</bodyText>
<subsectionHeader confidence="0.985821">
6.3 General Observations
</subsectionHeader>
<bodyText confidence="0.9995495">
We investigated the data to identify the different
challenges faced when trying to identify a person’s
</bodyText>
<page confidence="0.994278">
144
</page>
<table confidence="0.996706307692308">
Domain Stance Post
Abortion Against Yes, all innocent life. But that depends on how you define innocent life.
Creationism Pro There’s a definite difference between micro-evolution and macro-evolution in the sense
that with the moths and the finches, there are minor changes that happen. It’s kind of like
a pendulum. It swings far to the right and to the left, but in the end, it’s right in the center
again, if you understand me correctly.
Gay-Rights Against Not necessarily the question of whether or not same-sex couples’ marriages specifically
are recognized by the government. As for my personal views on the issue I honestly
think the best solution is for the government to simply call all civil unions precisely what
they are: civil unions. Leave it to individuals and churches to determine the definition of
“marriage.”
Gun-Rights Against I agree that gun ownership should be strictly controlled. Put a gun in the hands of a
crackpot and there’s going to be a problem.
</table>
<tableCaption confidence="0.870246">
Table 9: Examples of the posts that were misclassified by the unigram baseline and were correctly classified
by the right semantic model.
</tableCaption>
<bodyText confidence="0.789909">
perspective and found the following:
</bodyText>
<listItem confidence="0.745198">
1. In ANES dataset, due to the structure of the ques-
</listItem>
<bodyText confidence="0.930765153846154">
tions, some Turkers were trying to be objective
which makes it difficult even for a human evalu-
ator to identify the political leaning of the person
who wrote the text. The example in Table 3 illus-
trates such a case where it is not easy to detect the
PCC of the Turker from the provided answers.
2. The use of sarcasm, which can be easily detected
by human evaluators but not by an automated sys-
tem. For example, in Abortion dataset, a partici-
pant who does not oppose abortion wrote “Why
should people use reason and logic to discover
right and wrong when a priest can decide for
them?”
</bodyText>
<listItem confidence="0.776651">
3. Misspelled words such as writing “Romeny” in-
stead of “Romney”
4. In each domain of the Ideological Debates dataset,
</listItem>
<bodyText confidence="0.998828166666667">
the posts were collected from different discus-
sion fora pertaining to the domain of interest.
For example, in the Abortion dataset, posts were
collected from “Can Catholics Vote For Pro-
Choice Politicians”, “Should South Dakota pass
the Abortion Ban”, “Should abortion be legal”
and other fora. For some of the posts, the partici-
pants provided very short answers such as “Once
they take the booth who they vote for is supposed
to be secret.” which makes it almost impossible
to identify their stance without knowing the exact
question the forum posed.
</bodyText>
<sectionHeader confidence="0.999046" genericHeader="method">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999705">
In this paper, we explore the use of semantic fea-
tures to perform automatic detection of ideological-
perspective from written text. Using Word Sense
Disambiguation and Latent Semantics features, we
trained several SVM classifiers that predict differ-
ent aspects of the ideological-perspective of a per-
son. We evaluated the presented approach on two
datasets. The first of which comprises answers to
questions about American politics collected from
an Amazon Mechanical Turk experiment while the
second one consists of four subsets of a standard
dataset, discussing Abortion, Creationism, Gay-
Rights and Gun-Rights. Results show that using the
proposed features outperforms a system that relies
on standard unigram features on all datasets. On the
cross-validation sets, combining word sense disam-
biguation with latent semantics performs best while
on the held-out test sets, the best configuration vari-
ous across the different domains.
We plan to explore other methods for perform-
ing word sense disambiguation in addition to using
semantic-role-labeling and modeling sarcasm.
</bodyText>
<sectionHeader confidence="0.9972" genericHeader="conclusions">
8 Acknowledgment
</sectionHeader>
<bodyText confidence="0.991552">
We thank the three anonymous reviewers for their
useful comments and suggestions.
This research is funded by DARPA DEFT pro-
gram with a subcontract from Columbia University
and a Google Faculty Research Award to Diab.
</bodyText>
<page confidence="0.998547">
145
</page>
<sectionHeader confidence="0.995861" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999934774193549">
Amjad Abu-Jbara, Mona Diab, Pradeep Dasigi, and
Dragomir Radev. 2012. Subgroup detection in ideo-
logical discussions. In Proceedings of the 50th Annual
Meeting of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 399–409. Associa-
tion for Computational Linguistics.
Amr Ahmed and Eric P Xing. 2010. Staying in-
formed: supervised and semi-supervised multi-view
topical analysis of ideological perspective. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1140–
1150. Association for Computational Linguistics.
Khalid Al Khatib, Hinrich SchUtze, and Cathleen Kant-
ner. 2012. Automatic detection of point of view dif-
ferences in wikipedia. In COLING, pages 33–50.
Satanjeev Banerjee and Ted Pedersen. 2002. An adapted
lesk algorithm for word sense disambiguation using
wordnet. In Computational linguistics and intelligent
text processing, pages 136–145. Springer.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. the Journal of ma-
chine Learning research, 3:993–1022.
Pradeep Dasigi, Weiwei Guo, and Mona Diab. 2012.
Genre independent subgroup detection in online dis-
cussion threads: a pilot study of implicit attitude using
latent textual semantics. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics: Short Papers-Volume 2, pages 65–69. As-
sociation for Computational Linguistics.
Robert M Entman. 1993. Framing: Toward clarification
of a fractured paradigm. Journal of communication,
43(4):51–58.
Weiwei Guo and Mona Diab. 2012. Modeling sentences
in the latent space. In Proceedings of the 50th Annual
Meeting of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 864–872. Associa-
tion for Computational Linguistics.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H Witten. 2009.
The weka data mining software: an update. ACM
SIGKDD Explorations Newsletter, 11(1):10–18.
Kazi Saidul Hasan and Vincent Ng. 2012. Predicting
stance in ideological debate with rich linguistic knowl-
edge. In Proceedings of the 24th International Confer-
ence on Computational Linguistics.
Kazi Saidul Hasan and Vincent Ng. 2013. Extra-
linguistic constraints on stance recognition in ideolog-
ical debates. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics.
Association for Computational Linguistics.
Beata Beigman Klebanov, Eyal Beigman, and Daniel
Diermeier. 2010. Vocabulary choice as an indicator
of perspective. In ACL, pages 253–257. Association
for Computational Linguistics.
Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and
Alexander Hauptmann. 2006. Which side are you
on?: identifying perspectives at the document and sen-
tence levels. In Proceedings of the Tenth Conference
on Computational Natural Language Learning, pages
109–116. Association for Computational Linguistics.
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
George A Miller. 1995. Wordnet: a lexical database for
english. Communications of the ACM, 38(11):39–41.
Siddharth Patwardhan, Satanjeev Banerjee, and Ted Ped-
ersen. 2005. Senserelate:: Targetword: a generalized
framework for word sense disambiguation. In Pro-
ceedings of the ACL 2005 on Interactive poster and
demonstration sessions, pages 73–76. Association for
Computational Linguistics.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet:: Similarity: measuring the relat-
edness of concepts. In Demonstration Papers at HLT-
NAACL 2004. Association for Computational Linguis-
tics.
John C. Platt. 1998. Sequential minimal optimization:
A fast algorithm for training support vector machines.
Technical Report MSR-TR-98-14, Microsoft Research.
Swapna Somasundaran and Janyce Wiebe. 2010. Rec-
ognizing stances in ideological online debates. In Pro-
ceedings of the NAACL HLT 2010 Workshop on Com-
putational Approaches to Analysis and Generation of
Emotion in Text, pages 116–124. Association for Com-
putational Linguistics.
Teun A Van Dijk. 1998. Ideology: A multidisciplinary
approach. Sage.
Tae Yano, Philip Resnik, and Noah A Smith. 2010.
Shedding (a thousand points of) light on biased lan-
guage. In Proceedings of the NAACL HLT 2010 Work-
shop on Creating Speech and Language Data with
Amazon’s Mechanical Turk, pages 152–158. Associ-
ation for Computational Linguistics.
</reference>
<page confidence="0.99882">
146
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.948978">
<title confidence="0.999551">Ideological Perspective Detection Using Semantic Features</title>
<author confidence="0.97773">Heba Elfardy Mona Diab Chris Callison-Burch</author>
<affiliation confidence="0.996842">Columbia University George Washington University University of Pennsylvania</affiliation>
<address confidence="0.99059">New York, NY Washington, DC Philadelphia, PA</address>
<email confidence="0.999497">heba@cs.columbia.edumtdiab@gwu.educcb@cis.upenn.edu</email>
<abstract confidence="0.999232464285714">In this paper, we propose the use of word sense disambiguation and latent semantic features to automatically identify a person’s perspective from his/her written text. We run an Amazon Mechanical Turk experiment where we ask Turkers to answer a set of constrained and open-ended political questions drawn from the American National Election Studies (ANES). We then extract the proposed features from the answers to the open-ended questions and use them to predict the answer to one of the constrained questions, namely, their preferred Presidential Candidate. In addition to this newly created dataset, we also evaluate our proposed approach on a second standard dataset of “Ideological-Debates”. This latter dataset contains topics from four domains: Abortion, Creationism, Gun Rights and Gay- Rights. Experimental results show that using word sense disambiguation and latentsemantics, whether separately or combined, beats the majority and random baselines on the cross-validation and held-out-test sets for both the ANES and the four domains of the “Ideological Debates” datasets. Moreover combining both feature sets outperforms a stronger unigram-only classification system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amjad Abu-Jbara</author>
<author>Mona Diab</author>
<author>Pradeep Dasigi</author>
<author>Dragomir Radev</author>
</authors>
<title>Subgroup detection in ideological discussions.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>399--409</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8471" citStr="Abu-Jbara et al. (2012)" startWordPosition="1289" endWordPosition="1292">se a set of Arabic and English Wikipedia articles about Arab and Israeli public figures to explore the differences in point of view between the Arabic and English articles about each figure. They assign a point-of-view score to each article in each language, and use these scores to train a classifier to predict the difference in 138 PCC Obama Romney Neither Train 62.9 25.3 11.8 Test 67.6 18.5 13.9 Table 1: Class Distribution of Presidential Candidate Choice (PCC) in the ANES dataset point of view between each article-pair. For unsupervised approaches, two of the most recent works are those of Abu-Jbara et al. (2012) and Dasigi et al. (2012). In Abu-Jbara et al. (2012), the authors perform subgroup detection by clustering authors according to their sentiment towards topics, Named-Entities as well as other discussants. Dasigi et al. (2012) extend the previous work by introducing the notion of implicit attitude which models the similarity between the topics discussed by a pair of people. They note that people that share the same opinion tend to discuss similar topics, thereby their texts tend to have a high semantic similarity. By adding implicit attitude, namely by explicitly modeling latent sentential sem</context>
</contexts>
<marker>Abu-Jbara, Diab, Dasigi, Radev, 2012</marker>
<rawString>Amjad Abu-Jbara, Mona Diab, Pradeep Dasigi, and Dragomir Radev. 2012. Subgroup detection in ideological discussions. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 399–409. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amr Ahmed</author>
<author>Eric P Xing</author>
</authors>
<title>Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1140--1150</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2063" citStr="Ahmed and Xing, 2010" startWordPosition="293" endWordPosition="296">lassification system. 1 Introduction With the pervasiveness of social media and online discussion fora, there has been a significant increase in documented political and ideological discussions. Automatically predicting the perspective or stance of users in such media is a challenging research problem that has a wide variety of applications including recommendation systems, targeted advertising, political polling, product reviews and even predicting possible future events. Ideology refers to the beliefs that influence an individual’s goals, expectations and views of the world (Van Dijk, 1998; Ahmed and Xing, 2010). The ideological perspective of a person is often expressed in his/her choice of discussed topics. People with opposing perspectives will choose to make different topics more salient. (Entman, 1993). From a social-science viewpoint, the notion of “perspective” is related to the concept of “framing”. Framing involves making some topics (or some aspects of the discussed topics) more prominent in order to promote the views and interpretations of the writer (communicator). The communicator makes these framing decisions either consciously or unconsciously (Entman, 1993). These decisions are often </context>
</contexts>
<marker>Ahmed, Xing, 2010</marker>
<rawString>Amr Ahmed and Eric P Xing. 2010. Staying informed: supervised and semi-supervised multi-view topical analysis of ideological perspective. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1140– 1150. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalid Al Khatib</author>
<author>Hinrich SchUtze</author>
<author>Cathleen Kantner</author>
</authors>
<title>Automatic detection of point of view differences in wikipedia.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<pages>33--50</pages>
<contexts>
<context position="7819" citStr="Khatib et al. (2012)" startWordPosition="1176" endWordPosition="1179">pposing) towards a topic. Arguing can be indicated by using either positive lexical cues such as “actually” or negative ones such as “certainly not”. They construct an arguing lexicon and use it to derive features for their classifier. They experiment with both arguing and sentiment features on four datasets; Abortion, Creationism, Gun-Rights and Gay-Rights. They show that combining arguing and sentiment features outperforms a unigram baseline on Abortion, Gay-Rights and Gun-Rights datasets while the unigram system performs best on the Creationism dataset. A closely related work is that of Al Khatib et al. (2012). In this work, the authors use a set of Arabic and English Wikipedia articles about Arab and Israeli public figures to explore the differences in point of view between the Arabic and English articles about each figure. They assign a point-of-view score to each article in each language, and use these scores to train a classifier to predict the difference in 138 PCC Obama Romney Neither Train 62.9 25.3 11.8 Test 67.6 18.5 13.9 Table 1: Class Distribution of Presidential Candidate Choice (PCC) in the ANES dataset point of view between each article-pair. For unsupervised approaches, two of the mo</context>
</contexts>
<marker>Khatib, SchUtze, Kantner, 2012</marker>
<rawString>Khalid Al Khatib, Hinrich SchUtze, and Cathleen Kantner. 2012. Automatic detection of point of view differences in wikipedia. In COLING, pages 33–50.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>An adapted lesk algorithm for word sense disambiguation using wordnet.</title>
<date>2002</date>
<booktitle>In Computational linguistics and intelligent text processing,</booktitle>
<pages>136--145</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="20006" citStr="Banerjee and Pedersen, 2002" startWordPosition="3152" endWordPosition="3155">h that are handled by WN-Sense-Relate are adjectives (a), adverbs (r), verbs (v) and nouns (n). In addition to the part-of-speech and sense-id, WNSense-Relate also identifies and tags compounds. The word sense tagging process can be either contextual or can rely on the most frequent sense. We experiment with both variants. 4.2.1 Contextual WSD (WSD-CXT) In this variant of WSD, in addition to tagging compounds, we contextually disambiguate each word and tag it with its sense-id and part-of-speech. We use the default setting of SenseRelate which employs a modified version of the Lesk algorithm (Banerjee and Pedersen, 2002) to perform the disambiguation. This version of the Lesk algorithm measures the similarity between the WordNet gloss of each sense of the target word and those of its surrounding context words in the text. It then chooses the sense whose gloss is most similar to the surrounding words. We use a window of size three which uses one word before and one word after the target word. ex. “The Democratic Party supports women ’s equality , including equal pay , access to health care and other issues .” becomes: “the#ND democratic_party#n#1 supports#n#10 women#n#1 ’s#ND equality#n#1 including#v#3 equal#a</context>
</contexts>
<marker>Banerjee, Pedersen, 2002</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2002. An adapted lesk algorithm for word sense disambiguation using wordnet. In Computational linguistics and intelligent text processing, pages 136–145. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="22136" citStr="Blei et al., 2003" startWordPosition="3484" endWordPosition="3487">uent sense. Using this scheme, “issues” is tagged as “issues#n#1” whose Synset is “issue#n#1”, while “support” is tagged as “support#v#1” whose Synset is support#v#1’, back_up#v#1. 4.3 Latent Semantics The next set of features relies on “Latent Semantics” which maps text from a high-dimensional space such as unigrams to a low-dimensional one such as topics. Most of these models assign a semantic profile to each given sentence (or document) by considering the observed words and assuming that each given document has a distribution over “K” topics. We apply (1) Latent Dirichlet Allocation (LDA) (Blei et al., 2003) as implemented in MALLET toolkit (McCallum, 2002), and (2) Weighted Textual Matrix Factorization (WTMF) (Guo and Diab, 2012) to each post. In addition to observed words, WTMF also models missing ones namely explicitly modeling what the post is not about. WTMF defines missing words as the whole vocabulary of the training data minus the ones observed in the given document. 4.3.1 Number of Topics We vary the number of topics (K) between 100 and 500 (with a step-size of 100) and use the best “K” for each dataset. We define the best K, for each of LDA and WTMF, as the one that yields the best cros</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep Dasigi</author>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Genre independent subgroup detection in online discussion threads: a pilot study of implicit attitude using latent textual semantics.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2,</booktitle>
<pages>65--69</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8496" citStr="Dasigi et al. (2012)" startWordPosition="1294" endWordPosition="1297">sh Wikipedia articles about Arab and Israeli public figures to explore the differences in point of view between the Arabic and English articles about each figure. They assign a point-of-view score to each article in each language, and use these scores to train a classifier to predict the difference in 138 PCC Obama Romney Neither Train 62.9 25.3 11.8 Test 67.6 18.5 13.9 Table 1: Class Distribution of Presidential Candidate Choice (PCC) in the ANES dataset point of view between each article-pair. For unsupervised approaches, two of the most recent works are those of Abu-Jbara et al. (2012) and Dasigi et al. (2012). In Abu-Jbara et al. (2012), the authors perform subgroup detection by clustering authors according to their sentiment towards topics, Named-Entities as well as other discussants. Dasigi et al. (2012) extend the previous work by introducing the notion of implicit attitude which models the similarity between the topics discussed by a pair of people. They note that people that share the same opinion tend to discuss similar topics, thereby their texts tend to have a high semantic similarity. By adding implicit attitude, namely by explicitly modeling latent sentential semantics, they achieve an F</context>
</contexts>
<marker>Dasigi, Guo, Diab, 2012</marker>
<rawString>Pradeep Dasigi, Weiwei Guo, and Mona Diab. 2012. Genre independent subgroup detection in online discussion threads: a pilot study of implicit attitude using latent textual semantics. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 65–69. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert M Entman</author>
</authors>
<title>Framing: Toward clarification of a fractured paradigm.</title>
<date>1993</date>
<journal>Journal of communication,</journal>
<volume>43</volume>
<issue>4</issue>
<contexts>
<context position="2262" citStr="Entman, 1993" startWordPosition="326" endWordPosition="327">y predicting the perspective or stance of users in such media is a challenging research problem that has a wide variety of applications including recommendation systems, targeted advertising, political polling, product reviews and even predicting possible future events. Ideology refers to the beliefs that influence an individual’s goals, expectations and views of the world (Van Dijk, 1998; Ahmed and Xing, 2010). The ideological perspective of a person is often expressed in his/her choice of discussed topics. People with opposing perspectives will choose to make different topics more salient. (Entman, 1993). From a social-science viewpoint, the notion of “perspective” is related to the concept of “framing”. Framing involves making some topics (or some aspects of the discussed topics) more prominent in order to promote the views and interpretations of the writer (communicator). The communicator makes these framing decisions either consciously or unconsciously (Entman, 1993). These decisions are often expressed in the lexical choice. For example, a person who holds anti-abortion views, is more likely to use the terms “life” and “kill” whereas a person who is pro a woman having an option to go for </context>
</contexts>
<marker>Entman, 1993</marker>
<rawString>Robert M Entman. 1993. Framing: Toward clarification of a fractured paradigm. Journal of communication, 43(4):51–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Modeling sentences in the latent space.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>864--872</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="22261" citStr="Guo and Diab, 2012" startWordPosition="3503" endWordPosition="3506">“support#v#1” whose Synset is support#v#1’, back_up#v#1. 4.3 Latent Semantics The next set of features relies on “Latent Semantics” which maps text from a high-dimensional space such as unigrams to a low-dimensional one such as topics. Most of these models assign a semantic profile to each given sentence (or document) by considering the observed words and assuming that each given document has a distribution over “K” topics. We apply (1) Latent Dirichlet Allocation (LDA) (Blei et al., 2003) as implemented in MALLET toolkit (McCallum, 2002), and (2) Weighted Textual Matrix Factorization (WTMF) (Guo and Diab, 2012) to each post. In addition to observed words, WTMF also models missing ones namely explicitly modeling what the post is not about. WTMF defines missing words as the whole vocabulary of the training data minus the ones observed in the given document. 4.3.1 Number of Topics We vary the number of topics (K) between 100 and 500 (with a step-size of 100) and use the best “K” for each dataset. We define the best K, for each of LDA and WTMF, as the one that yields the best cross-validation results when combined with unigram features. The best K value for LDA is 400 for PCC and Abortion, 500 for Creat</context>
</contexts>
<marker>Guo, Diab, 2012</marker>
<rawString>Weiwei Guo and Mona Diab. 2012. Modeling sentences in the latent space. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 864–872. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="23562" citStr="Hall et al., 2009" startWordPosition="3728" endWordPosition="3731">PCC, and Gun-Rights and 100 for Abortion, Creationism and Gay-Rights. 142 PCC Fβ=1 score Train 74.65 Test 74.81 All 74.69 Table 6: Performance of human annotators in predicting “PCC” of a person from his/her responses to ANES essay questions. 4.3.2 Training Data We collected our training data for topic modeling from Facebook comments of renowned American politicians such as Joe-Biden, Chris-Christie, George W. Bush, Michelle-Obama, etc. We trained LDA and WTMF using a subset of 100,000 comments (corresponding to ~5,000,000 tokens and ~265,000 types. 4.4 Classifier Training Using WEKA toolkit (Hall et al., 2009) and the derived features, we train Sequential Minimal Optimization (SMO) SVM classifiers (Platt, 1998) for each of “ANES” and the four domains of “Ideological-Debates” datasets. We use a normalized quadratic kernel, set the parameter C to 100 and apply a 10-fold cross validation on the training sets. 5 Experiments 5.1 Baselines We compare our approach to three baselines; • Majority Baseline (MAJ-BL): which assigns all posts to the most frequent class-label; • Random Baseline (RAND-BL): which randomly chooses the class-label; • Unigram Baseline (UNI-BL): a strong baseline that uses standard un</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazi Saidul Hasan</author>
<author>Vincent Ng</author>
</authors>
<title>Predicting stance in ideological debate with rich linguistic knowledge.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="6359" citStr="Hasan and Ng (2012)" startWordPosition="952" endWordPosition="955">only capturing the perspective but also the editors’ writing styles. In Klebanov et al. (2010), the authors tackle the same problem of binary-perspective detection and experiment with four corpora; BitterLemons, Bitter-Lemons-International, Partial-BirthAbortion and Death-Penalty. They show that using term-frequencies does not improve over using binary bag-of-words features and that using only the best 1-4.9% features is sufficient to achieve high accuracy. They achieve the highest accuracy (97%) on the Partial-Birth-Abortion dataset and the lowest accuracy (73%) on the Death-Penalty dataset. Hasan and Ng (2012) also tackle the problem of binary perspective detection but using Integer Linear Programming (ILP) to perform joint inference over the predictions made by a post-stance classifier and several topic-stance classifiers. The authors use ngrams, sentence-type and opinion-dependencies as features to train their classifiers. They collect debate posts discussing Abortion and Gun-Rights and achieve an Fβ_1 score of 61.1% on the Abortion dataset and 57.8% on the Gun-Rights dataset. In Hasan and Ng (2013), they extend their previous work by incorporating two soft-constraints that treat the task of post</context>
</contexts>
<marker>Hasan, Ng, 2012</marker>
<rawString>Kazi Saidul Hasan and Vincent Ng. 2012. Predicting stance in ideological debate with rich linguistic knowledge. In Proceedings of the 24th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazi Saidul Hasan</author>
<author>Vincent Ng</author>
</authors>
<title>Extralinguistic constraints on stance recognition in ideological debates.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6860" citStr="Hasan and Ng (2013)" startWordPosition="1027" endWordPosition="1030"> on the Partial-Birth-Abortion dataset and the lowest accuracy (73%) on the Death-Penalty dataset. Hasan and Ng (2012) also tackle the problem of binary perspective detection but using Integer Linear Programming (ILP) to perform joint inference over the predictions made by a post-stance classifier and several topic-stance classifiers. The authors use ngrams, sentence-type and opinion-dependencies as features to train their classifiers. They collect debate posts discussing Abortion and Gun-Rights and achieve an Fβ_1 score of 61.1% on the Abortion dataset and 57.8% on the Gun-Rights dataset. In Hasan and Ng (2013), they extend their previous work by incorporating two soft-constraints that treat the task of post-stance classification as a sequencelabeling problem and ensure that the topic-stance of each author is consistent across all posts. Somasundaran and Wiebe (2010) employ the notion of “arguing” to identify a person’s stance (supporting or opposing) towards a topic. Arguing can be indicated by using either positive lexical cues such as “actually” or negative ones such as “certainly not”. They construct an arguing lexicon and use it to derive features for their classifier. They experiment with both</context>
</contexts>
<marker>Hasan, Ng, 2013</marker>
<rawString>Kazi Saidul Hasan and Vincent Ng. 2013. Extralinguistic constraints on stance recognition in ideological debates. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beata Beigman Klebanov</author>
<author>Eyal Beigman</author>
<author>Daniel Diermeier</author>
</authors>
<title>Vocabulary choice as an indicator of perspective.</title>
<date>2010</date>
<booktitle>In ACL,</booktitle>
<pages>253--257</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5834" citStr="Klebanov et al. (2010)" startWordPosition="877" endWordPosition="880">nd a Palestinian editor, together with invited guests, contribute articles to the website on a weekly basis. Lin et al. (2006) use bag-of-words features. They run different experiments where they vary the training and test sets between: (a) editors’ articles and (b) guests’ articles. The accuracies of the different experimental conditions vary between 86% and 99%. As one might expect the highest accuracy (99%) is that of the system that is trained and tested on the editors’ articles. For this system, the classifier is not only capturing the perspective but also the editors’ writing styles. In Klebanov et al. (2010), the authors tackle the same problem of binary-perspective detection and experiment with four corpora; BitterLemons, Bitter-Lemons-International, Partial-BirthAbortion and Death-Penalty. They show that using term-frequencies does not improve over using binary bag-of-words features and that using only the best 1-4.9% features is sufficient to achieve high accuracy. They achieve the highest accuracy (97%) on the Partial-Birth-Abortion dataset and the lowest accuracy (73%) on the Death-Penalty dataset. Hasan and Ng (2012) also tackle the problem of binary perspective detection but using Integer </context>
</contexts>
<marker>Klebanov, Beigman, Diermeier, 2010</marker>
<rawString>Beata Beigman Klebanov, Eyal Beigman, and Daniel Diermeier. 2010. Vocabulary choice as an indicator of perspective. In ACL, pages 253–257. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei-Hao Lin</author>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Alexander Hauptmann</author>
</authors>
<title>Which side are you on?: identifying perspectives at the document and sentence levels.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>109--116</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4933" citStr="Lin et al. (2006)" startWordPosition="731" endWordPosition="734">nd contextual semantics to predict a person’s perspective outperforms a strong-baseline system trained on standard unigram features. 2 Related Work Current computational linguistics research on automatic perspective detection uses both supervised and unsupervised techniques. The main task handled by supervised approaches is to perform document (or post) level perspective (or stance) classification, whether binary or multiclass labeling. Unsupervised approaches on the other hand, mainly try to cluster users in a discussion. One of the early works on binary perspective identification is that of Lin et al. (2006) which uses articles from the Bitter-Lemons website –a website that discusses the PalestinianIsraeli conflict from each side’s point of view– to train a system for performing automatic perspective detection on the sentence and document levels. On the website, an Israeli editor and a Palestinian editor, together with invited guests, contribute articles to the website on a weekly basis. Lin et al. (2006) use bag-of-words features. They run different experiments where they vary the training and test sets between: (a) editors’ articles and (b) guests’ articles. The accuracies of the different expe</context>
</contexts>
<marker>Lin, Wilson, Wiebe, Hauptmann, 2006</marker>
<rawString>Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and Alexander Hauptmann. 2006. Which side are you on?: identifying perspectives at the document and sentence levels. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 109–116. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="22186" citStr="McCallum, 2002" startWordPosition="3493" endWordPosition="3494">“issues#n#1” whose Synset is “issue#n#1”, while “support” is tagged as “support#v#1” whose Synset is support#v#1’, back_up#v#1. 4.3 Latent Semantics The next set of features relies on “Latent Semantics” which maps text from a high-dimensional space such as unigrams to a low-dimensional one such as topics. Most of these models assign a semantic profile to each given sentence (or document) by considering the observed words and assuming that each given document has a distribution over “K” topics. We apply (1) Latent Dirichlet Allocation (LDA) (Blei et al., 2003) as implemented in MALLET toolkit (McCallum, 2002), and (2) Weighted Textual Matrix Factorization (WTMF) (Guo and Diab, 2012) to each post. In addition to observed words, WTMF also models missing ones namely explicitly modeling what the post is not about. WTMF defines missing words as the whole vocabulary of the training data minus the ones observed in the given document. 4.3.1 Number of Topics We vary the number of topics (K) between 100 and 500 (with a step-size of 100) and use the best “K” for each dataset. We define the best K, for each of LDA and WTMF, as the one that yields the best cross-validation results when combined with unigram fe</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="19299" citStr="Miller, 1995" startWordPosition="3041" endWordPosition="3042">endently. 4.1 Preprocessing We apply basic preprocessing to the text by separating punctuation and numbers from words. All punctuation and numbers are then ignored when training the classifier for all of our systems including the unigram baseline. The intuition behind this is that punctuation and numbers do not capture the perspective of a person but rather the writing style. Moreover, by ignoring them, we avoid overfitting the training data. 141 4.2 Word Sense Disambiguation (WSD) We use WN-Sense-Relate (Patwardhan et al., 2005) to perform word sense disambiguation. SenseRelate uses WordNet (Miller, 1995) to tag each word with the part-of-speech and sense-id. The only parts of speech that are handled by WN-Sense-Relate are adjectives (a), adverbs (r), verbs (v) and nouns (n). In addition to the part-of-speech and sense-id, WNSense-Relate also identifies and tags compounds. The word sense tagging process can be either contextual or can rely on the most frequent sense. We experiment with both variants. 4.2.1 Contextual WSD (WSD-CXT) In this variant of WSD, in addition to tagging compounds, we contextually disambiguate each word and tag it with its sense-id and part-of-speech. We use the default </context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Senserelate:: Targetword: a generalized framework for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>73--76</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19221" citStr="Patwardhan et al., 2005" startWordPosition="3028" endWordPosition="3031">tance towards the ideological-topics discussed in the “Ideological-Debates” dataset independently. 4.1 Preprocessing We apply basic preprocessing to the text by separating punctuation and numbers from words. All punctuation and numbers are then ignored when training the classifier for all of our systems including the unigram baseline. The intuition behind this is that punctuation and numbers do not capture the perspective of a person but rather the writing style. Moreover, by ignoring them, we avoid overfitting the training data. 141 4.2 Word Sense Disambiguation (WSD) We use WN-Sense-Relate (Patwardhan et al., 2005) to perform word sense disambiguation. SenseRelate uses WordNet (Miller, 1995) to tag each word with the part-of-speech and sense-id. The only parts of speech that are handled by WN-Sense-Relate are adjectives (a), adverbs (r), verbs (v) and nouns (n). In addition to the part-of-speech and sense-id, WNSense-Relate also identifies and tags compounds. The word sense tagging process can be either contextual or can rely on the most frequent sense. We experiment with both variants. 4.2.1 Contextual WSD (WSD-CXT) In this variant of WSD, in addition to tagging compounds, we contextually disambiguate </context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2005</marker>
<rawString>Siddharth Patwardhan, Satanjeev Banerjee, and Ted Pedersen. 2005. Senserelate:: Targetword: a generalized framework for word sense disambiguation. In Proceedings of the ACL 2005 on Interactive poster and demonstration sessions, pages 73–76. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet:: Similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Demonstration Papers at HLTNAACL</booktitle>
<contexts>
<context position="20814" citStr="Pedersen et al., 2004" startWordPosition="3280" endWordPosition="3283"> words in the text. It then chooses the sense whose gloss is most similar to the surrounding words. We use a window of size three which uses one word before and one word after the target word. ex. “The Democratic Party supports women ’s equality , including equal pay , access to health care and other issues .” becomes: “the#ND democratic_party#n#1 supports#n#10 women#n#1 ’s#ND equality#n#1 including#v#3 equal#a#1 pay#v#1 access#n#2 to#ND health_care#n#1 and#ND other#a#1 issues#n#7”3 We then use the tagged-words to retrieve the Synonym-Set (Synset) of this sense of the word using WN-QueryData (Pedersen et al., 2004). We assign each Synset an ID and whenever any of the words in the retrieved Synset is seen in the input text, we replace it with this Synset-ID. For example, the Synset of “issues#n#7” is identified as “issue#n#7, consequence#n#1, effect#n#1, 3#ND indicates a non-defined word outcome#n#2, result#n#1, event#n#4, issue#n#7, upshot#n#1”. We assign this Synset a unique ID, for example “Synset-100”, and any occurrence of any of “issue#n#7, consequence#n#1, effect#n#1, outcome#n#2, result#n#1, event#n#4, issue#n#7, and upshot#n#1” is replaced by “Synset-100”. 4.2.2 Most Frequent Sense WSD (WSD-MFS)</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet:: Similarity: measuring the relatedness of concepts. In Demonstration Papers at HLTNAACL 2004. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Platt</author>
</authors>
<title>Sequential minimal optimization: A fast algorithm for training support vector machines.</title>
<date>1998</date>
<tech>Technical Report MSR-TR-98-14, Microsoft Research.</tech>
<contexts>
<context position="23665" citStr="Platt, 1998" startWordPosition="3745" endWordPosition="3746">81 All 74.69 Table 6: Performance of human annotators in predicting “PCC” of a person from his/her responses to ANES essay questions. 4.3.2 Training Data We collected our training data for topic modeling from Facebook comments of renowned American politicians such as Joe-Biden, Chris-Christie, George W. Bush, Michelle-Obama, etc. We trained LDA and WTMF using a subset of 100,000 comments (corresponding to ~5,000,000 tokens and ~265,000 types. 4.4 Classifier Training Using WEKA toolkit (Hall et al., 2009) and the derived features, we train Sequential Minimal Optimization (SMO) SVM classifiers (Platt, 1998) for each of “ANES” and the four domains of “Ideological-Debates” datasets. We use a normalized quadratic kernel, set the parameter C to 100 and apply a 10-fold cross validation on the training sets. 5 Experiments 5.1 Baselines We compare our approach to three baselines; • Majority Baseline (MAJ-BL): which assigns all posts to the most frequent class-label; • Random Baseline (RAND-BL): which randomly chooses the class-label; • Unigram Baseline (UNI-BL): a strong baseline that uses standard unigram features. In addition to these three baselines, we do a human-evaluation for the ANES dataset in </context>
</contexts>
<marker>Platt, 1998</marker>
<rawString>John C. Platt. 1998. Sequential minimal optimization: A fast algorithm for training support vector machines. Technical Report MSR-TR-98-14, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
</authors>
<title>Recognizing stances in ideological online debates.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<pages>116--124</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7121" citStr="Somasundaran and Wiebe (2010)" startWordPosition="1065" endWordPosition="1068">he predictions made by a post-stance classifier and several topic-stance classifiers. The authors use ngrams, sentence-type and opinion-dependencies as features to train their classifiers. They collect debate posts discussing Abortion and Gun-Rights and achieve an Fβ_1 score of 61.1% on the Abortion dataset and 57.8% on the Gun-Rights dataset. In Hasan and Ng (2013), they extend their previous work by incorporating two soft-constraints that treat the task of post-stance classification as a sequencelabeling problem and ensure that the topic-stance of each author is consistent across all posts. Somasundaran and Wiebe (2010) employ the notion of “arguing” to identify a person’s stance (supporting or opposing) towards a topic. Arguing can be indicated by using either positive lexical cues such as “actually” or negative ones such as “certainly not”. They construct an arguing lexicon and use it to derive features for their classifier. They experiment with both arguing and sentiment features on four datasets; Abortion, Creationism, Gun-Rights and Gay-Rights. They show that combining arguing and sentiment features outperforms a unigram baseline on Abortion, Gay-Rights and Gun-Rights datasets while the unigram system p</context>
<context position="17639" citStr="Somasundaran and Wiebe (2010)" startWordPosition="2769" endWordPosition="2772">pes Types/Post Posts Tokens Tokens/Post Types Types/Post ANES 965 437,080 453 14,410 15 108 61,414 569 5,487 51 Abortion 1,036 154,929 150 10,192 10 115 18,299 159 2,734 24 Creationism 1,108 217,262 196 13,466 12 122 10,756 88 2,160 18 Gay-Rights 1,858 312,900 168 16,742 9 206 17,400 84 2,842 14 Gun-Rights 963 146,886 153 10,969 11 106 7,142 67 1,588 15 Table 5: Statistics of the training and test sets for both the ANES and the four domains of the IdeologicalDebates datasets. debt.”, we replace “They” with “Republicans”. 4 Approach 3.2 Ideological Debates Dataset This dataset was collected by Somasundaran and Wiebe (2010) . It contains debate posts from six domains; (a) Abortion, (b) Creationism, (c) GayRights, (d) Gun-Rights, (e) Healthcare and (f) Existence of God. Each domain represents an ideological topic with two possible perspectives, pro and against. Similar to the work of (Somasundaran and Wiebe, 2010), we use the first four domains to evaluate our approach. Table 2 shows the class distribution in each of these four domains while table 4 lists some sample posts. It should be noted that our results are not comparable to those obtained by (Somasundaran and Wiebe, 2010), since they used a subset of the p</context>
</contexts>
<marker>Somasundaran, Wiebe, 2010</marker>
<rawString>Swapna Somasundaran and Janyce Wiebe. 2010. Recognizing stances in ideological online debates. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 116–124. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teun A Van Dijk</author>
</authors>
<date>1998</date>
<note>Ideology: A multidisciplinary approach. Sage.</note>
<marker>Van Dijk, 1998</marker>
<rawString>Teun A Van Dijk. 1998. Ideology: A multidisciplinary approach. Sage.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tae Yano</author>
<author>Philip Resnik</author>
<author>Noah A Smith</author>
</authors>
<title>Shedding (a thousand points of) light on biased language.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk,</booktitle>
<pages>152--158</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9227" citStr="Yano et al. (2010)" startWordPosition="1406" endWordPosition="1409">timent towards topics, Named-Entities as well as other discussants. Dasigi et al. (2012) extend the previous work by introducing the notion of implicit attitude which models the similarity between the topics discussed by a pair of people. They note that people that share the same opinion tend to discuss similar topics, thereby their texts tend to have a high semantic similarity. By adding implicit attitude, namely by explicitly modeling latent sentential semantics, they achieve an Fβ=1 score improvement of 3.83% and 2.12% on “Wikipedia-Discussions” and “Online-Debates” datasets, respectively. Yano et al. (2010) study the linguistic cues for bias in political blogs. The authors draw sentences from American political blogs and annotate them for bias on Amazon Mechanical Turk. They explore whether the Turkers’ decisions are influenced by their perspectives, for example whether a self proclaimed liberal Turker is more likely to view sentences written by a conservative as biased and vice versa. 3 Datasets We use two datasets to evaluate our approach. 3.1 ANES Dataset We create this dataset by drawing a set of questions from the American National Election Studies (ANES) survey questions.1 ANES conducts va</context>
</contexts>
<marker>Yano, Resnik, Smith, 2010</marker>
<rawString>Tae Yano, Philip Resnik, and Noah A Smith. 2010. Shedding (a thousand points of) light on biased language. In Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk, pages 152–158. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>