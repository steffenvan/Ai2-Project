<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009695">
<title confidence="0.886581">
Dependency Grammar Induction via Bitext Projection Constraints
</title>
<author confidence="0.976424">
Kuzman Ganchev and Jennifer Gillenwater and Ben Taskar
</author>
<affiliation confidence="0.9993325">
Department of Computer and Information Science
University of Pennsylvania, Philadelphia PA, USA
</affiliation>
<email confidence="0.993534">
{kuzman,jengi,taskar}@seas.upenn.edu
</email>
<sectionHeader confidence="0.994705" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999947538461538">
Broad-coverage annotated treebanks nec-
essary to train parsers do not exist for
many resource-poor languages. The wide
availability of parallel text and accurate
parsers in English has opened up the pos-
sibility of grammar induction through par-
tial transfer across bitext. We consider
generative and discriminative models for
dependency grammar induction that use
word-level alignments and a source lan-
guage parser (English) to constrain the
space of possible target trees. Unlike
previous approaches, our framework does
not require full projected parses, allowing
partial, approximate transfer through lin-
ear expectation constraints on the space
of distributions over trees. We consider
several types of constraints that range
from generic dependency conservation to
language-specific annotation rules for aux-
iliary verb analysis. We evaluate our ap-
proach on Bulgarian and Spanish CoNLL
shared task data and show that we con-
sistently outperform unsupervised meth-
ods and can outperform supervised learn-
ing for limited training data.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999777153846154">
For English and a handful of other languages,
there are large, well-annotated corpora with a vari-
ety of linguistic information ranging from named
entity to discourse structure. Unfortunately, for
the vast majority of languages very few linguis-
tic resources are available. This situation is
likely to persist because of the expense of creat-
ing annotated corpora that require linguistic exper-
tise (Abeillé, 2003). On the other hand, parallel
corpora between many resource-poor languages
and resource-rich languages are ample, motivat-
ing recent interest in transferring linguistic re-
sources from one language to another via parallel
text. For example, several early works (Yarowsky
and Ngai, 2001; Yarowsky et al., 2001; Merlo
et al., 2002) demonstrate transfer of shallow pro-
cessing tools such as part-of-speech taggers and
noun-phrase chunkers by using word-level align-
ment models (Brown et al., 1994; Och and Ney,
2000).
Alshawi et al. (2000) and Hwa et al. (2005)
explore transfer of deeper syntactic structure:
dependency grammars. Dependency and con-
stituency grammar formalisms have long coex-
isted and competed in linguistics, especially be-
yond English (Mel’ˇcuk, 1988). Recently, depen-
dency parsing has gained popularity as a simpler,
computationally more efficient alternative to con-
stituency parsing and has spurred several super-
vised learning approaches (Eisner, 1996; Yamada
and Matsumoto, 2003a; Nivre and Nilsson, 2005;
McDonald et al., 2005) as well as unsupervised in-
duction (Klein and Manning, 2004; Smith and Eis-
ner, 2006). Dependency representation has been
used for language modeling, textual entailment
and machine translation (Haghighi et al., 2005;
Chelba et al., 1997; Quirk et al., 2005; Shen et al.,
2008), to name a few tasks.
Dependency grammars are arguably more ro-
bust to transfer since syntactic relations between
aligned words of parallel sentences are better con-
served in translation than phrase structure (Fox,
2002; Hwa et al., 2005). Nevertheless, sev-
eral challenges to accurate training and evalua-
tion from aligned bitext remain: (1) partial word
alignment due to non-literal or distant transla-
tion; (2) errors in word alignments and source lan-
guage parses, (3) grammatical annotation choices
that differ across languages and linguistic theo-
ries (e.g., how to analyze auxiliary verbs, conjunc-
tions).
In this paper, we present a flexible learning
</bodyText>
<page confidence="0.985466">
369
</page>
<note confidence="0.999612">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 369–377,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999756956521739">
framework for transferring dependency grammars
via bitext using the posterior regularization frame-
work (Graça et al., 2008). In particular, we ad-
dress challenges (1) and (2) by avoiding com-
mitment to an entire projected parse tree in the
target language during training. Instead, we ex-
plore formulations of both generative and discrim-
inative probabilistic models where projected syn-
tactic relations are constrained to hold approxi-
mately and only in expectation. Finally, we ad-
dress challenge (3) by introducing a very small
number of language-specific constraints that dis-
ambiguate arbitrary annotation choices.
We evaluate our approach by transferring from
an English parser trained on the Penn treebank to
Bulgarian and Spanish. We evaluate our results
on the Bulgarian and Spanish corpora from the
CoNLL X shared task. We see that our transfer
approach consistently outperforms unsupervised
methods and, given just a few (2 to 7) language-
specific constraints, performs comparably to a su-
pervised parser trained on a very limited corpus
(30 - 140 training sentences).
</bodyText>
<sectionHeader confidence="0.979867" genericHeader="introduction">
2 Approach
</sectionHeader>
<bodyText confidence="0.999861923076923">
At a high level our approach is illustrated in Fig-
ure 1(a). A parallel corpus is word-level aligned
using an alignment toolkit (Graça et al., 2009) and
the source (English) is parsed using a dependency
parser (McDonald et al., 2005). Figure 1(b) shows
an aligned sentence pair example where depen-
dencies are perfectly conserved across the align-
ment. An edge from English parent p to child c is
called conserved if word p aligns to word p&apos; in the
second language, c aligns to c&apos; in the second lan-
guage, and p&apos; is the parent of c&apos;. Note that we are
not restricting ourselves to one-to-one alignments
here; p, c, p&apos;, and c&apos; can all also align to other
words. After filtering to identify well-behaved
sentences and high confidence projected depen-
dencies, we learn a probabilistic parsing model us-
ing the posterior regularization framework (Graça
et al., 2008). We estimate both generative and dis-
criminative models by constraining the posterior
distribution over possible target parses to approxi-
mately respect projected dependencies and other
rules which we describe below. In our experi-
ments we evaluate the learned models on depen-
dency treebanks (Nivre et al., 2007).
Unfortunately the sentence in Figure 1(b) is
highly unusual in its amount of dependency con-
servation. To get a feel for the typical case, we
used off-the-shelf parsers (McDonald et al., 2005)
for English, Spanish and Bulgarian on two bi-
texts (Koehn, 2005; Tiedemann, 2007) and com-
pared several measures of dependency conserva-
tion. For the English-Bulgarian corpus, we ob-
served that 71.9% of the edges we projected were
edges in the corpus, and we projected on average
2.7 edges per sentence (out of 5.3 tokens on aver-
age). For Spanish, we saw conservation of 64.4%
and an average of 5.9 projected edges per sentence
(out of 11.5 tokens on average).
As these numbers illustrate, directly transfer-
ring information one dependency edge at a time
is unfortunately error prone for two reasons. First,
parser and word alignment errors cause much of
the transferred information to be wrong. We deal
with this problem by constraining groups of edges
rather than a single edge. For example, in some
sentence pair we might find 10 edges that have
both end points aligned and can be transferred.
Rather than requiring our target language parse to
contain each of the 10 edges, we require that the
expected number of edges from this set is at least
10q, where q is a strength parameter. This gives
the parser freedom to have some uncertainty about
which edges to include, or alternatively to choose
to exclude some of the transferred edges.
A more serious problem for transferring parse
information across languages are structural differ-
ences and grammar annotation choices between
the two languages. For example dealing with aux-
iliary verbs and reflexive constructions. Hwa et al.
(2005) also note these problems and solve them by
introducing dozens of rules to transform the trans-
ferred parse trees. We discuss these differences
in detail in the experimental section and use our
framework introduce a very small number of rules
to cover the most common structural differences.
</bodyText>
<sectionHeader confidence="0.972837" genericHeader="method">
3 Parsing Models
</sectionHeader>
<bodyText confidence="0.9999079">
We explored two parsing models: a generative
model used by several authors for unsupervised in-
duction and a discriminative model used for fully
supervised training.
The discriminative parser is based on the
edge-factored model and features of the MST-
Parser (McDonald et al., 2005). The parsing
model defines a conditional distribution pg(z I x)
over each projective parse tree z for a particular
sentence x, parameterized by a vector 0. The prob-
</bodyText>
<page confidence="0.998139">
370
</page>
<figureCaption confidence="0.954792333333333">
Figure 1: (a) Overview of our grammar induction approach via bitext: the source (English) is parsed and word-aligned with
target; after filtering, projected dependencies define constraints over target parse tree space, providing weak supervision for
learning a target grammar. (b) An example word-aligned sentence pair with perfectly projected dependencies.
</figureCaption>
<bodyText confidence="0.734071">
ability of any particular parse is
</bodyText>
<equation confidence="0.9669375">
pθ(z  |x) a ri eθ·φ(z,x), (1)
zEz
</equation>
<bodyText confidence="0.999950705882353">
where z is a directed edge contained in the parse
tree z and φ is a feature function. In the fully su-
pervised experiments we run for comparison, pa-
rameter estimation is performed by stochastic gra-
dient ascent on the conditional likelihood func-
tion, similar to maximum entropy models or con-
ditional random fields. One needs to be able to
compute expectations of the features φ(z, x) under
the distribution pθ(z  |x). A version of the inside-
outside algorithm (Lee and Choi, 1997) performs
this computation. Viterbi decoding is done using
Eisner’s algorithm (Eisner, 1996).
We also used a generative model based on de-
pendency model with valence (Klein and Man-
ning, 2004). Under this model, the probability of
a particular parse z and a sentence with part of
speech tags x is given by
</bodyText>
<equation confidence="0.9640508">
pθ(z, x) = proot(r(x)) · (2)
( ri )p—stop(zp, zd, vz) pchild(zp, zd, zc) ·
zEz
( ri )pstop(x, left, vl) pstop(x, right, vr)
xEx
</equation>
<bodyText confidence="0.999523625">
where r(x) is the part of speech tag of the root
of the parse tree z, z is an edge from parent zp
to child zc in direction zd, either left or right, and
vz indicates valency—false if zp has no other chil-
dren further from it in direction zd than zc, true
otherwise. The valencies vr/vl are marked as true
if x has any children on the left/right in z, false
otherwise.
</bodyText>
<sectionHeader confidence="0.980065" genericHeader="method">
4 Posterior Regularization
</sectionHeader>
<bodyText confidence="0.9794758">
Graça et al. (2008) introduce an estimation frame-
work that incorporates side-information into un-
supervised problems in the form of linear con-
straints on posterior expectations. In grammar
transfer, our basic constraint is of the form: the
expected proportion of conserved edges in a sen-
tence pair is at least η (the exact proportion we
used was 0.9, which was determined using un-
labeled data as described in Section 5). Specifi-
cally, let Cx be the set of directed edges projected
from English for a given sentence x, then given
a parse z, the proportion of conserved edges is
f (x, z) = |CX |EzEz 1(z E Cx) and the expected
proportion of conserved edges under distribution
p(z  |x) is
</bodyText>
<equation confidence="0.988698">
1 �
Ep[f(x, z)] = |Cx|
</equation>
<bodyText confidence="0.994688736842105">
The posterior regularization framework (Graça
et al., 2008) was originally defined for gener-
ative unsupervised learning. The standard ob-
jective is to minimize the negative marginal
log-likelihood of the data : E[− log pθ(x)] =
�E[− log Ez pθ(z, x)] over the parameters θ (we
�
use E to denote expectation over the sample sen-
tences x). We typically also add standard regular-
ization term on θ, resulting from a parameter prior
− log p(θ) = R(θ), where p(θ) is Gaussian for the
MST-Parser models and Dirichlet for the valence
model.
To introduce supervision into the model, we de-
fine a set 2x of distributions over the hidden vari-
ables z satisfying the desired posterior constraints
in terms of linear equalities or inequalities on fea-
ture expectations (we use inequalities in this pa-
per):
</bodyText>
<equation confidence="0.990680666666667">
2x = {q(z) : E[f(x, z)] c b}.
p(z  |x).
zECX
</equation>
<page confidence="0.99384">
371
</page>
<table confidence="0.9990475">
Basic Uni-gram Features Basic Bi-gram Features In Between POS Features
xi-word, xi-pos xi-word, xi-pos, xj-word, xj-pos xi-pos, b-pos, xj-pos
xi-word xi-pos, xj-word, xj-pos Surrounding Word POS Features
xi-pos xi-word, xj-word, xj-pos xi-pos, xi-pos+1, xj-pos-1, xj-pos
xj-word, xj-pos xi-word, xi-pos, xj-pos xi-pos-1, xi-pos, xj-pos-1, xj-pos
xj-word xi-word, xi-pos, xj-word xi-pos, xi-pos+1, xj-pos, xj-pos+1
xj-pos xi-word, xj-word xi-pos-1, xi-pos, xj-pos, xj-pos+1
xi-pos, xj-pos
</table>
<tableCaption confidence="0.993371">
Table 1: Features used by the MSTParser. For each edge (i, j), xi-word is the parent word and xj-word is the child word,
analogously for POS tags. The +1 and -1 denote preceeding and following tokens in the sentence, while b denotes tokens
between xi and xj.
</tableCaption>
<bodyText confidence="0.99856975">
In this paper, for example, we use the conserved-
edge-proportion constraint as defined above. The
marginal log-likelihood objective is then modi-
fied with a penalty for deviation from the de-
sired set of distributions, measured by KL-
divergence from the set Qx, KL(Qx||pθ(z|x)) =
minqEQX KL(q(z)||pθ(z|x)). The generative
learning objective is to minimize:
</bodyText>
<equation confidence="0.981301">
E[− log pθ(x)] + R(θ) + �E[KL(Qx||pθ(z  |x))].
</equation>
<bodyText confidence="0.99823475">
For discriminative estimation (Ganchev et al.,
2008), we do not attempt to model the marginal
distribution of x, so we simply have the two regu-
larization terms:
</bodyText>
<equation confidence="0.986267">
R(θ) + �E[KL(Qx||pθ(z  |x))].
</equation>
<bodyText confidence="0.9853068125">
Note that the idea of regularizing moments is re-
lated to generalized expectation criteria algorithm
of Mann and McCallum (2007), as we discuss in
the related work section below. In general, the
objectives above are not convex in θ. To opti-
mize these objectives, we follow an Expectation
Maximization-like scheme. Recall that standard
EM iterates two steps. An E-step computes a prob-
ability distribution over the model’s hidden vari-
ables (posterior probabilities) and an M-step that
updates the model’s parameters based on that dis-
tribution. The posterior-regularized EM algorithm
leaves the M-step unchanged, but involves project-
ing the posteriors onto a constraint set after they
are computed for each sentence x:
arg min KL(q(z) II pθ(z|x))
</bodyText>
<equation confidence="0.8882205">
q (3)
s.t. Eq[f(x, z)] &lt; b,
</equation>
<bodyText confidence="0.999013714285714">
where pθ(z|x) are the posteriors. The new poste-
riors q(z) are used to compute sufficient statistics
for this instance and hence to update the model’s
parameters in the M-step for either the generative
or discriminative setting.
The optimization problem in Equation 3 can be
efficiently solved in its dual formulation:
</bodyText>
<equation confidence="0.510543">
pθ(z  |x) exp {−λTf(x, z)}.
(4)
</equation>
<bodyText confidence="0.999945125">
Given λ, the primal solution is given by: q(z) =
pθ(z  |x) exp{−λTf(x, z)}/Z, where Z is a nor-
malization constant. There is one dual variable per
expectation constraint, and we can optimize them
by projected gradient descent, similar to log-linear
model estimation. The gradient with respect to λ
is given by: b − Eq[f(x, z)], so it involves com-
puting expectations under the distribution q(z).
This remains tractable as long as features factor by
edge, f(x, z) = &amp;;Ez f(x, z), because that en-
sures that q(z) will have the same form as pθ(z |
x). Furthermore, since the constraints are per in-
stance, we can use incremental or online version
of EM (Neal and Hinton, 1998), where we update
parameters θ after posterior-constrained E-step on
each instance x.
</bodyText>
<sectionHeader confidence="0.999542" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999584722222222">
We conducted experiments on two languages:
Bulgarian and Spanish, using each of the pars-
ing models. The Bulgarian experiments transfer a
parser from English to Bulgarian, using the Open-
Subtitles corpus (Tiedemann, 2007). The Span-
ish experiments transfer from English to Spanish
using the Spanish portion of the Europarl corpus
(Koehn, 2005). For both corpora, we performed
word alignments with the open source PostCAT
(Graça et al., 2009) toolkit. We used the Tokyo
tagger (Tsuruoka and Tsujii, 2005) to POS tag
the English tokens, and generated parses using
the first-order model of McDonald et al. (2005)
with projective decoding, trained on sections 2-21
of the Penn treebank with dependencies extracted
using the head rules of Yamada and Matsumoto
(2003b). For Bulgarian we trained the Stanford
POS tagger (Toutanova et al., 2003) on the Bul-
</bodyText>
<figure confidence="0.811392333333333">
arg min �
λ&gt;0 bTλ+log
z
</figure>
<page confidence="0.829375">
372
</page>
<table confidence="0.9955314">
Discriminative model Generative model
Bulgarian Spanish Bulgarian Spanish
no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules
Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3
Post.Reg. 66.9 77.5 78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8
</table>
<tableCaption confidence="0.993065333333333">
Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer
models were trained on 10k sentences of length up to 20, all models tested on CoNLL train sentences of up to 10 words.
Punctuation was stripped at train time.
</tableCaption>
<bodyText confidence="0.999764633333333">
gtreebank corpus from CoNLL X. The Spanish
Europarl data was POS tagged with the FreeLing
language analyzer (Atserias et al., 2006). The dis-
criminative model used the same features as MST-
Parser, summarized in Table 1.
In order to evaluate our method, we a baseline
inspired by Hwa et al. (2005). The baseline con-
structs a full parse tree from the incomplete and
possibly conflicting transferred edges using a sim-
ple random process. We start with no edges and
try to add edges one at a time verifying at each
step that it is possible to complete the tree. We
first try to add the transferred edges in random or-
der, then for each orphan node we try all possible
parents (both in random order). We then use this
full labeling as supervision for a parser. Note that
this baseline is very similar to the first iteration of
our model, since for a large corpus the different
random choices made in different sentences tend
to smooth each other out. We also tried to cre-
ate rules for the adoption of orphans, but the sim-
ple rules we tried added bias and performed worse
than the baseline we report. Table 2 shows at-
tachment accuracy of our method and the baseline
for both language pairs under several conditions.
By attachment accuracy we mean the fraction of
words assigned the correct parent. The experimen-
tal details are described in this section. Link-left
baselines for these corpora are much lower: 33.8%
and 27.9% for Bulgarian and Spanish respectively.
</bodyText>
<subsectionHeader confidence="0.993316">
5.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.999974371428571">
Preliminary experiments showed that our word
alignments were not always appropriate for syn-
tactic transfer, even when they were correct for
translation. For example, the English “bike/V”
could be translated in French as “aller/V en
vélo/N”, where the word “bike” would be aligned
with “vélo”. While this captures some of the se-
mantic shared information in the two languages,
we have no expectation that the noun “vélo”
will have a similar syntactic behavior to the verb
“bike”. To prevent such false transfer, we filter
out alignments between incompatible POS tags. In
both language pairs, filtering out noun-verb align-
ments gave the biggest improvement.
Both corpora also contain sentence fragments,
either because of question responses or frag-
mented speech in movie subtitles or because of
voting announcements and similar formulaic sen-
tences in the parliamentary proceedings. We over-
come this problem by filtering out sentences that
do not have a verb as the English root or for which
the English root is not aligned to a verb in the
target language. For the subtitles corpus we also
remove sentences that end in an ellipsis or con-
tain more than one comma. Finally, following
(Klein and Manning, 2004) we strip out punctu-
ation from the sentences. For the discriminative
model this did not affect results significantly but
improved them slightly in most cases. We found
that the generative model gets confused by punctu-
ation and tends to predict that periods at the end of
sentences are the parents of words in the sentence.
Our basic model uses constraints of the form:
the expected proportion of conserved edges in a
sentence pair is at least q = 90%.1
</bodyText>
<subsectionHeader confidence="0.999777">
5.2 No Language-Specific Rules
</subsectionHeader>
<bodyText confidence="0.94039325">
We call the generic model described above “no-
rules” to distinguish it from the language-specific
constraints we introduce in the sequel. The no
rules columns of Table 2 summarize the perfor-
mance in this basic setting. Discriminative models
outperform the generative models in the majority
of cases. The left panel of Table 3 shows the most
common errors by child POS tag, as well as by
true parent and guessed parent POS tag.
Figure 2 shows that the discriminative model
continues to improve with more transfer-type data
1We chose rl in the following way: we split the unlabeled
parallel text into two portions. We trained a models with dif-
ferent rl on one portion and ran it on the other portion. We
chose the model with the highest fraction of conserved con-
straints on the second portion.
</bodyText>
<page confidence="0.999113">
373
</page>
<figureCaption confidence="0.9998654">
Figure 2: Learning curve of the discriminative no-rules
transfer model on Bulgarian bitext, testing on CoNLL train
sentences of up to 10 words.
Figure 3: A Spanish example where an auxiliary verb dom-
inates the main verb.
</figureCaption>
<bodyText confidence="0.905531">
up to at least 40 thousand sentences.
</bodyText>
<subsectionHeader confidence="0.999606">
5.3 Annotation guidelines and constraints
</subsectionHeader>
<bodyText confidence="0.999925315789474">
Using the straightforward approach outlined
above is a dramatic improvement over the standard
link-left baseline (and the unsupervised generative
model as we discuss below), however it doesn’t
have any information about the annotation guide-
lines used for the testing corpus. For example, the
Bulgarian corpus has an unusual treatment of non-
finite clauses. Figure 4 shows an example. We see
that the “,qa” is the parent of both the verb and its
object, which is different than the treatment in the
English corpus.
We propose to deal with these annotation dis-
similarities by creating very simple rules. For
Spanish, we have three rules. The first rule sets
main verbs to dominate auxiliary verbs. Specifi-
cally, whenever an auxiliary precedes a main verb
the main verb becomes its parent and adopts its
children; if there is only one main verb it becomes
the root of the sentence; main verbs also become
</bodyText>
<figureCaption confidence="0.99735125">
Figure 4: An example where transfer fails because of
different handling of reflexives and nonfinite clauses. The
alignment links provide correct glosses for Bulgarian words.
“Bax” is a past tense marker while “ce” is a reflexive marker.
</figureCaption>
<bodyText confidence="0.999994340425532">
parents of pronouns, adverbs, and common nouns
that directly preceed auxiliary verbs. By adopt-
ing children we mean that we change the parent
of transferred edges to be the adopting node. The
second Spanish rule states that the first element
of an adjective-noun or noun-adjective pair domi-
nates the second; the first element also adopts the
children of the second element. The third and fi-
nal Spanish rule sets all prepositions to be chil-
dren of the first main verb in the sentence, unless
the preposition is a “de” located between two noun
phrases. In this later case, we set the closest noun
in the first of the two noun phrases as the preposi-
tion’s parent.
For Bulgarian the first rule is that “,qa” should
dominate all words until the next verb and adopt
their noun, preposition, particle and adverb chil-
dren. The second rule is that auxiliary verbs
should dominate main verbs and adopt their chil-
dren. We have a list of 12 Bulgarian auxiliary
verbs. The “seven rules” experiments add rules for
5 more words similar to the rule for “,qa”, specif-
ically “zIe”, “JIH”, “KaKB♦”, “He”, “3a”. Table 3
compares the errors for different linguistic rules.
When we train using the “,qa” rule and the rules for
auxiliary verbs, the model learns that main verbs
attach to auxiliary verbs and that “,qa” dominates
its nonfinite clause. This causes an improvement
in the attachment of verbs, and also drastically re-
duces words being attached to verbs instead of par-
ticles. The latter is expected because “,qa” is an-
alyzed as a particle in the Bulgarian POS tagset.
We see an improvement in root/verb confusions
since “,qa” is sometimes errenously attached to a
the following verb rather than being the root of the
sentence.
The rightmost panel of Table 3 shows similar
analysis when we also use the rules for the five
other closed-class words. We see an improvement
in attachments in all categories, but no qualitative
change is visible. The reason for this is probably
that these words are relatively rare, but by encour-
aging the model to add an edge, it also rules out in-
correct edges that would cross it. Consequently we
are seeing improvements not only directly from
the constraints we enforce but also indirectly as
types of edges that tend to get ruled out.
</bodyText>
<subsectionHeader confidence="0.986446">
5.4 Generative parser
</subsectionHeader>
<bodyText confidence="0.9980775">
The generative model we use is a state of the art
model for unsupervised parsing and is our only
</bodyText>
<page confidence="0.997093">
374
</page>
<table confidence="0.993141578947368">
No Rules Two Rules Seven Rules
child POS errors parent POS
acc(%) errors
V 65.2 2237 T/V 2175
N 73.8 1938 V/V 1305
P 58.5 1705 N/V 1112
R 70.3 961 root/V 555
child POS errors parent POS
acc(%) errors
N 78.7 1572 N/V 938
P 70.2 1224 V/V 734
V 84.4 1002 V/N 529
R 79.3 670 N/N 376
child POS errors parent POS
acc(%) errors
N 79.3 1532 N/V 1116
P 75.7 998 V/V 560
R 69.3 993 V/N 507
V 86.2 889 N/N 450
</table>
<tableCaption confidence="0.974187666666667">
Table 3: Top 4 discriminative parser errors by child POS tag and true/guess parent POS tag in the Bulgarian CoNLL train data
of length up to 10. Training with no language-specific rules (left); two rules (center); and seven rules (right). POS meanings:
V verb, N noun, P pronoun, R preposition, T particle. Accuracies are by child or parent truth/guess POS tag.
</tableCaption>
<figure confidence="0.99963464516129">
20 40 60 80 100 120 140
supervised training data size
20 40 60 80 100 120 140
supervised training data size
0.75
0.7
0.65
0.6
20
s
0.75
0.65
0.8
0.7
supervised
no rules
two rules
seven rules
0.8
0.75
0.7
0.65
20
s
0.8
0.75
0.7
0.65
supervised
no rules
three rules
</figure>
<figureCaption confidence="0.9958396">
Figure 5: Comparison to parsers with supervised estimation and transfer. Top: Generative. Bottom: Discriminative. Left:
Bulgarian. Right: Spanish. The transfer models were trained on 10k sentences all of length at most 20, all models tested
on CoNLL train sentences of up to 10 words. The x-axis shows the number of examples used to train the supervised model.
Boxes show first and third quartile, whiskers extend to max and min, with the line passing through the median. Supervised
experiments used 30 random samples from CoNLL train.
</figureCaption>
<bodyText confidence="0.98713188">
fully unsupervised baseline. As smoothing we add
a very small backoff probability of 4.5 x 10−5 to
each learned paramter. Unfortunately, we found
generative model performance was disappointing
overall. The maximum unsupervised accuracy it
achieved on the Bulgarian data is 47.6% with ini-
tialization from Klein and Manning (2004) and
this result is not stable. Changing the initialization
parameters, training sample, or maximum sen-
tence length used for training drastically affected
the results, even for samples with several thousand
sentences. When we use the transferred informa-
tion to constrain the learning, EM stabilizes and
achieves much better performance. Even setting
all parameters equal at the outset does not prevent
the model from learning the dependency structure
of the aligned language. The top panels in Figure 5
show the results in this setting. We see that perfor-
mance is still always below the accuracy achieved
by supervised training on 20 annotated sentences.
However, the improvement in stability makes the
algorithm much more usable. As we shall see be-
low, the discriminative parser performs even better
than the generative model.
u
</bodyText>
<subsectionHeader confidence="0.996353">
5.5 Discriminative parser
</subsectionHeader>
<bodyText confidence="0.956819444444444">
We trained our discriminative parser for 100 iter-
ations of online EM with a Gaussian prior vari-
ance of 100. Results for the discriminative parser
are shown in the bottom panels of Figure 5. The
supervised experiments are given to provide con-
text for the accuracies. For Bulgarian, we see that
without any hints about the annotation guidelines,
the transfer system performs better than an unsu-
%
</bodyText>
<page confidence="0.983934">
375
</page>
<bodyText confidence="0.9998705625">
pervised parser, comparable to a supervised parser
trained on 10 sentences. However, if we spec-
ify just the two rules for “da” and verb conjuga-
tions performance jumps to that of training on 60-
70 fully labeled sentences. If we have just a lit-
tle more prior knowledge about how closed-class
words are handled, performance jumps above 140
fully labeled sentence equivalent.
We observed another desirable property of the
discriminative model. While the generative model
can get confused and perform poorly when the
training data contains very long sentences, the dis-
criminative parser does not appear to have this
drawback. In fact we observed that as the maxi-
mum training sentence length increased, the pars-
ing performance also improved.
</bodyText>
<sectionHeader confidence="0.999967" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999989487804878">
Our work most closely relates to Hwa et al. (2005),
who proposed to learn generative dependency
grammars using Collins’ parser (Collins, 1999) by
constructing full target parses via projected de-
pendencies and completion/transformation rules.
Hwa et al. (2005) found that transferring depen-
dencies directly was not sufficient to get a parser
with reasonable performance, even when both
the source language parses and the word align-
ments are performed by hand. They adjusted for
this by introducing on the order of one or two
dozen language-specific transformation rules to
complete target parses for unaligned words and
to account for diverging annotation rules. Trans-
ferring from English to Spanish in this way, they
achieve 72.1% and transferring to Chinese they
achieve 53.9%.
Our learning method is very closely related to
the work of (Mann and McCallum, 2007; Mann
and McCallum, 2008) who concurrently devel-
oped the idea of using penalties based on pos-
terior expectations of features not necessarily in
the model in order to guide learning. They call
their method generalized expectation constraints
or alternatively expectation regularization. In this
volume (Druck et al., 2009) use this framework
to train a dependency parser based on constraints
stated as corpus-wide expected values of linguis-
tic rules. The rules select a class of edges (e.g.
auxiliary verb to main verb) and require that the
expectation of these be close to some value. The
main difference between this work and theirs is
the source of the information (a linguistic infor-
mant vs. cross-lingual projection). Also, we de-
fine our regularization with respect to inequality
constraints (the model is not penalized for exceed-
ing the required model expectations), while they
require moments to be close to an estimated value.
We suspect that the two learning methods could
perform comparably when they exploit similar in-
formation.
</bodyText>
<sectionHeader confidence="0.998083" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999960666666667">
In this paper, we proposed a novel and effec-
tive learning scheme for transferring dependency
parses across bitext. By enforcing projected de-
pendency constraints approximately and in expec-
tation, our framework allows robust learning from
noisy partially supervised target sentences, instead
of committing to entire parses. We show that dis-
criminative training generally outperforms gener-
ative approaches even in this very weakly super-
vised setting. By adding easily specified language-
specific constraints, our models begin to rival
strong supervised baselines for small amounts of
data. Our framework can handle a wide range of
constraints and we are currently exploring richer
syntactic constraints that involve conservation of
multiple edge constructions as well as constraints
on conservation of surface length of dependen-
cies.
</bodyText>
<sectionHeader confidence="0.99756" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999924571428571">
This work was partially supported by an Integra-
tive Graduate Education and Research Trainee-
ship grant from National Science Foundation
(NSFIGERT 0504487), by ARO MURI SUB-
TLE W911NF-07-1-0216 and by the European
Projects AsIsKnown (FP6-028044) and LTfLL
(FP7-212578).
</bodyText>
<sectionHeader confidence="0.997719" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9976466">
A. Abeill´e. 2003. Treebanks: Building and Using
Parsed Corpora. Springer.
H. Alshawi, S. Bangalore, and S. Douglas. 2000.
Learning dependency translation models as collec-
tions of finite state head transducers. Computational
Linguistics, 26(1).
J. Atserias, B. Casas, E. Comelles, M. Gonz´alez,
L. Padr´o, and M. Padr´o. 2006. Freeling 1.3: Syn-
tactic and semantic services in an open-source nlp
library. In Proc. LREC, Genoa, Italy.
</reference>
<page confidence="0.98833">
376
</page>
<reference confidence="0.99990527">
P. F. Brown, S. Della Pietra, V. J. Della Pietra, and R. L.
Mercer. 1994. The mathematics of statistical ma-
chine translation: Parameter estimation. Computa-
tional Linguistics, 19(2):263–311.
C. Chelba, D. Engle, F. Jelinek, V. Jimenez, S. Khudan-
pur, L. Mangu, H. Printz, E. Ristad, R. Rosenfeld,
A. Stolcke, and D. Wu. 1997. Structure and perfor-
mance of a dependency language model. In Proc.
Eurospeech.
M. Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
G. Druck, G. Mann, and A. McCallum. 2009. Semi-
supervised learning of dependency parsers using
generalized expectation criteria. In Proc. ACL.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: an exploration. In Proc. CoLing.
H. Fox. 2002. Phrasal cohesion and statistical machine
translation. In Proc. EMNLP, pages 304–311.
K. Ganchev, J. Graca, J. Blitzer, and B. Taskar.
2008. Multi-view learning over structured and non-
identical outputs. In Proc. UAI.
J. Grac¸a, K. Ganchev, and B. Taskar. 2008. Expec-
tation maximization and posterior constraints. In
Proc. NIPS.
J. Grac¸a, K. Ganchev, and B. Taskar. 2009. Post-
cat - posterior constrained alignment toolkit. In The
Third Machine Translation Marathon.
A. Haghighi, A. Ng, and C. Manning. 2005. Ro-
bust textual inference via graph matching. In Proc.
EMNLP.
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and
O. Kolak. 2005. Bootstrapping parsers via syntactic
projection across parallel texts. Natural Language
Engineering, 11:11–311.
D. Klein and C. Manning. 2004. Corpus-based induc-
tion of syntactic structure: Models of dependency
and constituency. In Proc. of ACL.
P. Koehn. 2005. Europarl: A parallel corpus for statis-
tical machine translation. In MT Summit.
S. Lee and K. Choi. 1997. Reestimation and best-
first parsing algorithm for probabilistic dependency
grammar. In In WVLC-5, pages 41–55.
G. Mann and A. McCallum. 2007. Simple, robust,
scalable semi-supervised learning via expectation
regularization. In Proc. ICML.
G. Mann and A. McCallum. 2008. Generalized expec-
tation criteria for semi-supervised learning of con-
ditional random fields. In Proc. ACL, pages 870 –
878.
R. McDonald, K. Crammer, and F. Pereira. 2005. On-
line large-margin training of dependency parsers. In
Proc. ACL, pages 91–98.
I. Mel’ˇcuk. 1988. Dependency syntax: theory and
practice. SUNY. inci.
P. Merlo, S. Stevenson, V. Tsang, and G. Allaria. 2002.
A multilingual paradigm for automatic verb classifi-
cation. In Proc. ACL.
R. M. Neal and G. E. Hinton. 1998. A new view of the
EM algorithm that justifies incremental, sparse and
other variants. In M. I. Jordan, editor, Learning in
Graphical Models, pages 355–368. Kluwer.
J. Nivre and J. Nilsson. 2005. Pseudo-projective de-
pendency parsing. In Proc. ACL.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nils-
son, S. Riedel, and D. Yuret. 2007. The CoNLL
2007 shared task on dependency parsing. In Proc.
EMNLP-CoNLL.
F. J. Och and H. Ney. 2000. Improved statistical align-
ment models. In Proc. ACL.
C. Quirk, A. Menezes, and C. Cherry. 2005. De-
pendency treelet translation: syntactically informed
phrasal smt. In Proc. ACL.
L. Shen, J. Xu, and R. Weischedel. 2008. A new
string-to-dependency machine translation algorithm
with a target dependency language model. In Proc.
of ACL.
N. Smith and J. Eisner. 2006. Annealing structural
bias in multilingual weighted grammar induction. In
Proc. ACL.
J. Tiedemann. 2007. Building a multilingual parallel
subtitle corpus. In Proc. CLIN.
K. Toutanova, D. Klein, C. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In Proc. HLT-NAACL.
Y. Tsuruoka and J. Tsujii. 2005. Bidirectional infer-
ence with the easiest-first strategy for tagging se-
quence data. In Proc. HLT/EMNLP.
H. Yamada and Y. Matsumoto. 2003a. Statistical de-
pendency analysis with support vector machines. In
Proc. IWPT, pages 195–206.
H. Yamada and Y. Matsumoto. 2003b. Statistical de-
pendency analysis with support vector machines. In
Proc. IWPT.
D. Yarowsky and G. Ngai. 2001. Inducing multilin-
gual pos taggers and np bracketers via robust pro-
jection across aligned corpora. In Proc. NAACL.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001.
Inducing multilingual text analysis tools via robust
projection across aligned corpora. In Proc. HLT.
</reference>
<page confidence="0.998397">
377
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.518078">
<title confidence="0.998541">Dependency Grammar Induction via Bitext Projection Constraints</title>
<author confidence="0.999099">Ganchev Gillenwater Taskar</author>
<affiliation confidence="0.999982">Department of Computer and Information Science</affiliation>
<address confidence="0.53103">University of Pennsylvania, Philadelphia PA, USA</address>
<abstract confidence="0.999165296296296">Broad-coverage annotated treebanks necessary to train parsers do not exist for many resource-poor languages. The wide availability of parallel text and accurate parsers in English has opened up the possibility of grammar induction through partial transfer across bitext. We consider generative and discriminative models for dependency grammar induction that use word-level alignments and a source language parser (English) to constrain the space of possible target trees. Unlike previous approaches, our framework does not require full projected parses, allowing partial, approximate transfer through linear expectation constraints on the space of distributions over trees. We consider several types of constraints that range from generic dependency conservation to language-specific annotation rules for auxiliary verb analysis. We evaluate our approach on Bulgarian and Spanish CoNLL shared task data and show that we consistently outperform unsupervised methods and can outperform supervised learning for limited training data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeill´e</author>
</authors>
<title>Treebanks: Building and Using Parsed Corpora.</title>
<date>2003</date>
<publisher>Springer.</publisher>
<marker>Abeill´e, 2003</marker>
<rawString>A. Abeill´e. 2003. Treebanks: Building and Using Parsed Corpora. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Alshawi</author>
<author>S Bangalore</author>
<author>S Douglas</author>
</authors>
<title>Learning dependency translation models as collections of finite state head transducers.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<contexts>
<context position="2248" citStr="Alshawi et al. (2000)" startWordPosition="322" endWordPosition="325">e expense of creating annotated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Depe</context>
</contexts>
<marker>Alshawi, Bangalore, Douglas, 2000</marker>
<rawString>H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning dependency translation models as collections of finite state head transducers. Computational Linguistics, 26(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Atserias</author>
<author>B Casas</author>
<author>E Comelles</author>
<author>M Gonz´alez</author>
<author>L Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>Freeling 1.3: Syntactic and semantic services in an open-source nlp library.</title>
<date>2006</date>
<booktitle>In Proc. LREC,</booktitle>
<location>Genoa, Italy.</location>
<marker>Atserias, Casas, Comelles, Gonz´alez, Padr´o, Padr´o, 2006</marker>
<rawString>J. Atserias, B. Casas, E. Comelles, M. Gonz´alez, L. Padr´o, and M. Padr´o. 2006. Freeling 1.3: Syntactic and semantic services in an open-source nlp library. In Proc. LREC, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="2205" citStr="Brown et al., 1994" startWordPosition="314" endWordPosition="317">ation is likely to persist because of the expense of creating annotated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and M</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1994</marker>
<rawString>P. F. Brown, S. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1994. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chelba</author>
<author>D Engle</author>
<author>F Jelinek</author>
<author>V Jimenez</author>
<author>S Khudanpur</author>
<author>L Mangu</author>
<author>H Printz</author>
<author>E Ristad</author>
<author>R Rosenfeld</author>
<author>A Stolcke</author>
<author>D Wu</author>
</authors>
<title>Structure and performance of a dependency language model.</title>
<date>1997</date>
<booktitle>In Proc. Eurospeech.</booktitle>
<contexts>
<context position="2993" citStr="Chelba et al., 1997" startWordPosition="431" endWordPosition="434">r formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2) errors in word alignments and source language parses, (3) grammatical annotation choices that differ across languages and linguistic theories (e.g., h</context>
</contexts>
<marker>Chelba, Engle, Jelinek, Jimenez, Khudanpur, Mangu, Printz, Ristad, Rosenfeld, Stolcke, Wu, 1997</marker>
<rawString>C. Chelba, D. Engle, F. Jelinek, V. Jimenez, S. Khudanpur, L. Mangu, H. Printz, E. Ristad, R. Rosenfeld, A. Stolcke, and D. Wu. 1997. Structure and performance of a dependency language model. In Proc. Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="28259" citStr="Collins, 1999" startWordPosition="4657" endWordPosition="4658">osed-class words are handled, performance jumps above 140 fully labeled sentence equivalent. We observed another desirable property of the discriminative model. While the generative model can get confused and perform poorly when the training data contains very long sentences, the discriminative parser does not appear to have this drawback. In fact we observed that as the maximum training sentence length increased, the parsing performance also improved. 6 Related Work Our work most closely relates to Hwa et al. (2005), who proposed to learn generative dependency grammars using Collins’ parser (Collins, 1999) by constructing full target parses via projected dependencies and completion/transformation rules. Hwa et al. (2005) found that transferring dependencies directly was not sufficient to get a parser with reasonable performance, even when both the source language parses and the word alignments are performed by hand. They adjusted for this by introducing on the order of one or two dozen language-specific transformation rules to complete target parses for unaligned words and to account for diverging annotation rules. Transferring from English to Spanish in this way, they achieve 72.1% and transfe</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>M. Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Druck</author>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Semisupervised learning of dependency parsers using generalized expectation criteria.</title>
<date>2009</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="29301" citStr="Druck et al., 2009" startWordPosition="4816" endWordPosition="4819">les to complete target parses for unaligned words and to account for diverging annotation rules. Transferring from English to Spanish in this way, they achieve 72.1% and transferring to Chinese they achieve 53.9%. Our learning method is very closely related to the work of (Mann and McCallum, 2007; Mann and McCallum, 2008) who concurrently developed the idea of using penalties based on posterior expectations of features not necessarily in the model in order to guide learning. They call their method generalized expectation constraints or alternatively expectation regularization. In this volume (Druck et al., 2009) use this framework to train a dependency parser based on constraints stated as corpus-wide expected values of linguistic rules. The rules select a class of edges (e.g. auxiliary verb to main verb) and require that the expectation of these be close to some value. The main difference between this work and theirs is the source of the information (a linguistic informant vs. cross-lingual projection). Also, we define our regularization with respect to inequality constraints (the model is not penalized for exceeding the required model expectations), while they require moments to be close to an esti</context>
</contexts>
<marker>Druck, Mann, McCallum, 2009</marker>
<rawString>G. Druck, G. Mann, and A. McCallum. 2009. Semisupervised learning of dependency parsers using generalized expectation criteria. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: an exploration.</title>
<date>1996</date>
<booktitle>In Proc. CoLing.</booktitle>
<contexts>
<context position="2680" citStr="Eisner, 1996" startWordPosition="385" endWordPosition="386">shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Neverthe</context>
<context position="9518" citStr="Eisner, 1996" startWordPosition="1491" endWordPosition="1492">ar parse is pθ(z |x) a ri eθ·φ(z,x), (1) zEz where z is a directed edge contained in the parse tree z and φ is a feature function. In the fully supervised experiments we run for comparison, parameter estimation is performed by stochastic gradient ascent on the conditional likelihood function, similar to maximum entropy models or conditional random fields. One needs to be able to compute expectations of the features φ(z, x) under the distribution pθ(z |x). A version of the insideoutside algorithm (Lee and Choi, 1997) performs this computation. Viterbi decoding is done using Eisner’s algorithm (Eisner, 1996). We also used a generative model based on dependency model with valence (Klein and Manning, 2004). Under this model, the probability of a particular parse z and a sentence with part of speech tags x is given by pθ(z, x) = proot(r(x)) · (2) ( ri )p—stop(zp, zd, vz) pchild(zp, zd, zc) · zEz ( ri )pstop(x, left, vl) pstop(x, right, vr) xEx where r(x) is the part of speech tag of the root of the parse tree z, z is an edge from parent zp to child zc in direction zd, either left or right, and vz indicates valency—false if zp has no other children further from it in direction zd than zc, true otherw</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. Eisner. 1996. Three new probabilistic models for dependency parsing: an exploration. In Proc. CoLing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Fox</author>
</authors>
<title>Phrasal cohesion and statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>304--311</pages>
<contexts>
<context position="3251" citStr="Fox, 2002" startWordPosition="475" endWordPosition="476">ised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2) errors in word alignments and source language parses, (3) grammatical annotation choices that differ across languages and linguistic theories (e.g., how to analyze auxiliary verbs, conjunctions). In this paper, we present a flexible learning 369 Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 369–377, Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP framewo</context>
</contexts>
<marker>Fox, 2002</marker>
<rawString>H. Fox. 2002. Phrasal cohesion and statistical machine translation. In Proc. EMNLP, pages 304–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Ganchev</author>
<author>J Graca</author>
<author>J Blitzer</author>
<author>B Taskar</author>
</authors>
<title>Multi-view learning over structured and nonidentical outputs.</title>
<date>2008</date>
<booktitle>In Proc. UAI.</booktitle>
<contexts>
<context position="12992" citStr="Ganchev et al., 2008" startWordPosition="2078" endWordPosition="2081"> and xj-word is the child word, analogously for POS tags. The +1 and -1 denote preceeding and following tokens in the sentence, while b denotes tokens between xi and xj. In this paper, for example, we use the conservededge-proportion constraint as defined above. The marginal log-likelihood objective is then modified with a penalty for deviation from the desired set of distributions, measured by KLdivergence from the set Qx, KL(Qx||pθ(z|x)) = minqEQX KL(q(z)||pθ(z|x)). The generative learning objective is to minimize: E[− log pθ(x)] + R(θ) + �E[KL(Qx||pθ(z |x))]. For discriminative estimation (Ganchev et al., 2008), we do not attempt to model the marginal distribution of x, so we simply have the two regularization terms: R(θ) + �E[KL(Qx||pθ(z |x))]. Note that the idea of regularizing moments is related to generalized expectation criteria algorithm of Mann and McCallum (2007), as we discuss in the related work section below. In general, the objectives above are not convex in θ. To optimize these objectives, we follow an Expectation Maximization-like scheme. Recall that standard EM iterates two steps. An E-step computes a probability distribution over the model’s hidden variables (posterior probabilities)</context>
</contexts>
<marker>Ganchev, Graca, Blitzer, Taskar, 2008</marker>
<rawString>K. Ganchev, J. Graca, J. Blitzer, and B. Taskar. 2008. Multi-view learning over structured and nonidentical outputs. In Proc. UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Grac¸a</author>
<author>K Ganchev</author>
<author>B Taskar</author>
</authors>
<title>Expectation maximization and posterior constraints.</title>
<date>2008</date>
<booktitle>In Proc. NIPS.</booktitle>
<marker>Grac¸a, Ganchev, Taskar, 2008</marker>
<rawString>J. Grac¸a, K. Ganchev, and B. Taskar. 2008. Expectation maximization and posterior constraints. In Proc. NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Grac¸a</author>
<author>K Ganchev</author>
<author>B Taskar</author>
</authors>
<title>Postcat - posterior constrained alignment toolkit.</title>
<date>2009</date>
<booktitle>In The Third Machine Translation Marathon.</booktitle>
<marker>Grac¸a, Ganchev, Taskar, 2009</marker>
<rawString>J. Grac¸a, K. Ganchev, and B. Taskar. 2009. Postcat - posterior constrained alignment toolkit. In The Third Machine Translation Marathon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>A Ng</author>
<author>C Manning</author>
</authors>
<title>Robust textual inference via graph matching.</title>
<date>2005</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="2972" citStr="Haghighi et al., 2005" startWordPosition="427" endWordPosition="430">and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2) errors in word alignments and source language parses, (3) grammatical annotation choices that differ across languages and linguis</context>
</contexts>
<marker>Haghighi, Ng, Manning, 2005</marker>
<rawString>A. Haghighi, A. Ng, and C. Manning. 2005. Robust textual inference via graph matching. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering,</title>
<date>2005</date>
<pages>11--11</pages>
<contexts>
<context position="2270" citStr="Hwa et al. (2005)" startWordPosition="327" endWordPosition="330">tated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation </context>
<context position="7767" citStr="Hwa et al. (2005)" startWordPosition="1209" endWordPosition="1212">d and can be transferred. Rather than requiring our target language parse to contain each of the 10 edges, we require that the expected number of edges from this set is at least 10q, where q is a strength parameter. This gives the parser freedom to have some uncertainty about which edges to include, or alternatively to choose to exclude some of the transferred edges. A more serious problem for transferring parse information across languages are structural differences and grammar annotation choices between the two languages. For example dealing with auxiliary verbs and reflexive constructions. Hwa et al. (2005) also note these problems and solve them by introducing dozens of rules to transform the transferred parse trees. We discuss these differences in detail in the experimental section and use our framework introduce a very small number of rules to cover the most common structural differences. 3 Parsing Models We explored two parsing models: a generative model used by several authors for unsupervised induction and a discriminative model used for fully supervised training. The discriminative parser is based on the edge-factored model and features of the MSTParser (McDonald et al., 2005). The parsin</context>
<context position="16745" citStr="Hwa et al. (2005)" startWordPosition="2702" endWordPosition="2705">78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8 Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer models were trained on 10k sentences of length up to 20, all models tested on CoNLL train sentences of up to 10 words. Punctuation was stripped at train time. gtreebank corpus from CoNLL X. The Spanish Europarl data was POS tagged with the FreeLing language analyzer (Atserias et al., 2006). The discriminative model used the same features as MSTParser, summarized in Table 1. In order to evaluate our method, we a baseline inspired by Hwa et al. (2005). The baseline constructs a full parse tree from the incomplete and possibly conflicting transferred edges using a simple random process. We start with no edges and try to add edges one at a time verifying at each step that it is possible to complete the tree. We first try to add the transferred edges in random order, then for each orphan node we try all possible parents (both in random order). We then use this full labeling as supervision for a parser. Note that this baseline is very similar to the first iteration of our model, since for a large corpus the different random choices made in dif</context>
<context position="28167" citStr="Hwa et al. (2005)" startWordPosition="4643" endWordPosition="4646">g on 60- 70 fully labeled sentences. If we have just a little more prior knowledge about how closed-class words are handled, performance jumps above 140 fully labeled sentence equivalent. We observed another desirable property of the discriminative model. While the generative model can get confused and perform poorly when the training data contains very long sentences, the discriminative parser does not appear to have this drawback. In fact we observed that as the maximum training sentence length increased, the parsing performance also improved. 6 Related Work Our work most closely relates to Hwa et al. (2005), who proposed to learn generative dependency grammars using Collins’ parser (Collins, 1999) by constructing full target parses via projected dependencies and completion/transformation rules. Hwa et al. (2005) found that transferring dependencies directly was not sufficient to get a parser with reasonable performance, even when both the source language parses and the word alignments are performed by hand. They adjusted for this by introducing on the order of one or two dozen language-specific transformation rules to complete target parses for unaligned words and to account for diverging annota</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural Language Engineering, 11:11–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="2817" citStr="Klein and Manning, 2004" startWordPosition="405" endWordPosition="408">t al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or</context>
<context position="9616" citStr="Klein and Manning, 2004" startWordPosition="1506" endWordPosition="1510">e parse tree z and φ is a feature function. In the fully supervised experiments we run for comparison, parameter estimation is performed by stochastic gradient ascent on the conditional likelihood function, similar to maximum entropy models or conditional random fields. One needs to be able to compute expectations of the features φ(z, x) under the distribution pθ(z |x). A version of the insideoutside algorithm (Lee and Choi, 1997) performs this computation. Viterbi decoding is done using Eisner’s algorithm (Eisner, 1996). We also used a generative model based on dependency model with valence (Klein and Manning, 2004). Under this model, the probability of a particular parse z and a sentence with part of speech tags x is given by pθ(z, x) = proot(r(x)) · (2) ( ri )p—stop(zp, zd, vz) pchild(zp, zd, zc) · zEz ( ri )pstop(x, left, vl) pstop(x, right, vr) xEx where r(x) is the part of speech tag of the root of the parse tree z, z is an edge from parent zp to child zc in direction zd, either left or right, and vz indicates valency—false if zp has no other children further from it in direction zd than zc, true otherwise. The valencies vr/vl are marked as true if x has any children on the left/right in z, false ot</context>
<context position="19127" citStr="Klein and Manning, 2004" startWordPosition="3104" endWordPosition="3107">ge pairs, filtering out noun-verb alignments gave the biggest improvement. Both corpora also contain sentence fragments, either because of question responses or fragmented speech in movie subtitles or because of voting announcements and similar formulaic sentences in the parliamentary proceedings. We overcome this problem by filtering out sentences that do not have a verb as the English root or for which the English root is not aligned to a verb in the target language. For the subtitles corpus we also remove sentences that end in an ellipsis or contain more than one comma. Finally, following (Klein and Manning, 2004) we strip out punctuation from the sentences. For the discriminative model this did not affect results significantly but improved them slightly in most cases. We found that the generative model gets confused by punctuation and tends to predict that periods at the end of sentences are the parents of words in the sentence. Our basic model uses constraints of the form: the expected proportion of conserved edges in a sentence pair is at least q = 90%.1 5.2 No Language-Specific Rules We call the generic model described above “norules” to distinguish it from the language-specific constraints we intr</context>
<context position="26111" citStr="Klein and Manning (2004)" startWordPosition="4310" endWordPosition="4313"> on CoNLL train sentences of up to 10 words. The x-axis shows the number of examples used to train the supervised model. Boxes show first and third quartile, whiskers extend to max and min, with the line passing through the median. Supervised experiments used 30 random samples from CoNLL train. fully unsupervised baseline. As smoothing we add a very small backoff probability of 4.5 x 10−5 to each learned paramter. Unfortunately, we found generative model performance was disappointing overall. The maximum unsupervised accuracy it achieved on the Bulgarian data is 47.6% with initialization from Klein and Manning (2004) and this result is not stable. Changing the initialization parameters, training sample, or maximum sentence length used for training drastically affected the results, even for samples with several thousand sentences. When we use the transferred information to constrain the learning, EM stabilizes and achieves much better performance. Even setting all parameters equal at the outset does not prevent the model from learning the dependency structure of the aligned language. The top panels in Figure 5 show the results in this setting. We see that performance is still always below the accuracy achi</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>D. Klein and C. Manning. 2004. Corpus-based induction of syntactic structure: Models of dependency and constituency. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT Summit.</booktitle>
<contexts>
<context position="6346" citStr="Koehn, 2005" startWordPosition="975" endWordPosition="976">regularization framework (Graça et al., 2008). We estimate both generative and discriminative models by constraining the posterior distribution over possible target parses to approximately respect projected dependencies and other rules which we describe below. In our experiments we evaluate the learned models on dependency treebanks (Nivre et al., 2007). Unfortunately the sentence in Figure 1(b) is highly unusual in its amount of dependency conservation. To get a feel for the typical case, we used off-the-shelf parsers (McDonald et al., 2005) for English, Spanish and Bulgarian on two bitexts (Koehn, 2005; Tiedemann, 2007) and compared several measures of dependency conservation. For the English-Bulgarian corpus, we observed that 71.9% of the edges we projected were edges in the corpus, and we projected on average 2.7 edges per sentence (out of 5.3 tokens on average). For Spanish, we saw conservation of 64.4% and an average of 5.9 projected edges per sentence (out of 11.5 tokens on average). As these numbers illustrate, directly transferring information one dependency edge at a time is unfortunately error prone for two reasons. First, parser and word alignment errors cause much of the transfer</context>
<context position="15358" citStr="Koehn, 2005" startWordPosition="2467" endWordPosition="2468"> that q(z) will have the same form as pθ(z | x). Furthermore, since the constraints are per instance, we can use incremental or online version of EM (Neal and Hinton, 1998), where we update parameters θ after posterior-constrained E-step on each instance x. 5 Experiments We conducted experiments on two languages: Bulgarian and Spanish, using each of the parsing models. The Bulgarian experiments transfer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanova et al., 2003) on the Bularg min � λ&gt;0 bTλ+log z 372 Discriminative model Generative model Bulgarian Spanish Bulgarian S</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>P. Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT Summit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lee</author>
<author>K Choi</author>
</authors>
<title>Reestimation and bestfirst parsing algorithm for probabilistic dependency grammar. In</title>
<date>1997</date>
<booktitle>In WVLC-5,</booktitle>
<pages>41--55</pages>
<contexts>
<context position="9426" citStr="Lee and Choi, 1997" startWordPosition="1477" endWordPosition="1480"> example word-aligned sentence pair with perfectly projected dependencies. ability of any particular parse is pθ(z |x) a ri eθ·φ(z,x), (1) zEz where z is a directed edge contained in the parse tree z and φ is a feature function. In the fully supervised experiments we run for comparison, parameter estimation is performed by stochastic gradient ascent on the conditional likelihood function, similar to maximum entropy models or conditional random fields. One needs to be able to compute expectations of the features φ(z, x) under the distribution pθ(z |x). A version of the insideoutside algorithm (Lee and Choi, 1997) performs this computation. Viterbi decoding is done using Eisner’s algorithm (Eisner, 1996). We also used a generative model based on dependency model with valence (Klein and Manning, 2004). Under this model, the probability of a particular parse z and a sentence with part of speech tags x is given by pθ(z, x) = proot(r(x)) · (2) ( ri )p—stop(zp, zd, vz) pchild(zp, zd, zc) · zEz ( ri )pstop(x, left, vl) pstop(x, right, vr) xEx where r(x) is the part of speech tag of the root of the parse tree z, z is an edge from parent zp to child zc in direction zd, either left or right, and vz indicates va</context>
</contexts>
<marker>Lee, Choi, 1997</marker>
<rawString>S. Lee and K. Choi. 1997. Reestimation and bestfirst parsing algorithm for probabilistic dependency grammar. In In WVLC-5, pages 41–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Simple, robust, scalable semi-supervised learning via expectation regularization.</title>
<date>2007</date>
<booktitle>In Proc. ICML.</booktitle>
<contexts>
<context position="13257" citStr="Mann and McCallum (2007)" startWordPosition="2122" endWordPosition="2125"> The marginal log-likelihood objective is then modified with a penalty for deviation from the desired set of distributions, measured by KLdivergence from the set Qx, KL(Qx||pθ(z|x)) = minqEQX KL(q(z)||pθ(z|x)). The generative learning objective is to minimize: E[− log pθ(x)] + R(θ) + �E[KL(Qx||pθ(z |x))]. For discriminative estimation (Ganchev et al., 2008), we do not attempt to model the marginal distribution of x, so we simply have the two regularization terms: R(θ) + �E[KL(Qx||pθ(z |x))]. Note that the idea of regularizing moments is related to generalized expectation criteria algorithm of Mann and McCallum (2007), as we discuss in the related work section below. In general, the objectives above are not convex in θ. To optimize these objectives, we follow an Expectation Maximization-like scheme. Recall that standard EM iterates two steps. An E-step computes a probability distribution over the model’s hidden variables (posterior probabilities) and an M-step that updates the model’s parameters based on that distribution. The posterior-regularized EM algorithm leaves the M-step unchanged, but involves projecting the posteriors onto a constraint set after they are computed for each sentence x: arg min KL(q</context>
<context position="28979" citStr="Mann and McCallum, 2007" startWordPosition="4768" endWordPosition="4771">s. Hwa et al. (2005) found that transferring dependencies directly was not sufficient to get a parser with reasonable performance, even when both the source language parses and the word alignments are performed by hand. They adjusted for this by introducing on the order of one or two dozen language-specific transformation rules to complete target parses for unaligned words and to account for diverging annotation rules. Transferring from English to Spanish in this way, they achieve 72.1% and transferring to Chinese they achieve 53.9%. Our learning method is very closely related to the work of (Mann and McCallum, 2007; Mann and McCallum, 2008) who concurrently developed the idea of using penalties based on posterior expectations of features not necessarily in the model in order to guide learning. They call their method generalized expectation constraints or alternatively expectation regularization. In this volume (Druck et al., 2009) use this framework to train a dependency parser based on constraints stated as corpus-wide expected values of linguistic rules. The rules select a class of edges (e.g. auxiliary verb to main verb) and require that the expectation of these be close to some value. The main diffe</context>
</contexts>
<marker>Mann, McCallum, 2007</marker>
<rawString>G. Mann and A. McCallum. 2007. Simple, robust, scalable semi-supervised learning via expectation regularization. In Proc. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Mann</author>
<author>A McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>870--878</pages>
<contexts>
<context position="29005" citStr="Mann and McCallum, 2008" startWordPosition="4772" endWordPosition="4775">d that transferring dependencies directly was not sufficient to get a parser with reasonable performance, even when both the source language parses and the word alignments are performed by hand. They adjusted for this by introducing on the order of one or two dozen language-specific transformation rules to complete target parses for unaligned words and to account for diverging annotation rules. Transferring from English to Spanish in this way, they achieve 72.1% and transferring to Chinese they achieve 53.9%. Our learning method is very closely related to the work of (Mann and McCallum, 2007; Mann and McCallum, 2008) who concurrently developed the idea of using penalties based on posterior expectations of features not necessarily in the model in order to guide learning. They call their method generalized expectation constraints or alternatively expectation regularization. In this volume (Druck et al., 2009) use this framework to train a dependency parser based on constraints stated as corpus-wide expected values of linguistic rules. The rules select a class of edges (e.g. auxiliary verb to main verb) and require that the expectation of these be close to some value. The main difference between this work an</context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>G. Mann and A. McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Proc. ACL, pages 870 – 878.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>91--98</pages>
<contexts>
<context position="2758" citStr="McDonald et al., 2005" startWordPosition="395" endWordPosition="398">ase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bite</context>
<context position="5157" citStr="McDonald et al., 2005" startWordPosition="775" endWordPosition="778">Penn treebank to Bulgarian and Spanish. We evaluate our results on the Bulgarian and Spanish corpora from the CoNLL X shared task. We see that our transfer approach consistently outperforms unsupervised methods and, given just a few (2 to 7) languagespecific constraints, performs comparably to a supervised parser trained on a very limited corpus (30 - 140 training sentences). 2 Approach At a high level our approach is illustrated in Figure 1(a). A parallel corpus is word-level aligned using an alignment toolkit (Graça et al., 2009) and the source (English) is parsed using a dependency parser (McDonald et al., 2005). Figure 1(b) shows an aligned sentence pair example where dependencies are perfectly conserved across the alignment. An edge from English parent p to child c is called conserved if word p aligns to word p&apos; in the second language, c aligns to c&apos; in the second language, and p&apos; is the parent of c&apos;. Note that we are not restricting ourselves to one-to-one alignments here; p, c, p&apos;, and c&apos; can all also align to other words. After filtering to identify well-behaved sentences and high confidence projected dependencies, we learn a probabilistic parsing model using the posterior regularization framewo</context>
<context position="8355" citStr="McDonald et al., 2005" startWordPosition="1303" endWordPosition="1306">e constructions. Hwa et al. (2005) also note these problems and solve them by introducing dozens of rules to transform the transferred parse trees. We discuss these differences in detail in the experimental section and use our framework introduce a very small number of rules to cover the most common structural differences. 3 Parsing Models We explored two parsing models: a generative model used by several authors for unsupervised induction and a discriminative model used for fully supervised training. The discriminative parser is based on the edge-factored model and features of the MSTParser (McDonald et al., 2005). The parsing model defines a conditional distribution pg(z I x) over each projective parse tree z for a particular sentence x, parameterized by a vector 0. The prob370 Figure 1: (a) Overview of our grammar induction approach via bitext: the source (English) is parsed and word-aligned with target; after filtering, projected dependencies define constraints over target parse tree space, providing weak supervision for learning a target grammar. (b) An example word-aligned sentence pair with perfectly projected dependencies. ability of any particular parse is pθ(z |x) a ri eθ·φ(z,x), (1) zEz where</context>
<context position="15624" citStr="McDonald et al. (2005)" startWordPosition="2509" endWordPosition="2512">. 5 Experiments We conducted experiments on two languages: Bulgarian and Spanish, using each of the parsing models. The Bulgarian experiments transfer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanova et al., 2003) on the Bularg min � λ&gt;0 bTλ+log z 372 Discriminative model Generative model Bulgarian Spanish Bulgarian Spanish no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3 Post.Reg. 66.9 77.5 78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8 Table 2: Comparison between transferring a single tree o</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-margin training of dependency parsers. In Proc. ACL, pages 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mel’ˇcuk</author>
</authors>
<title>Dependency syntax: theory and practice.</title>
<date>1988</date>
<note>SUNY. inci.</note>
<marker>Mel’ˇcuk, 1988</marker>
<rawString>I. Mel’ˇcuk. 1988. Dependency syntax: theory and practice. SUNY. inci.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Merlo</author>
<author>S Stevenson</author>
<author>V Tsang</author>
<author>G Allaria</author>
</authors>
<title>A multilingual paradigm for automatic verb classification.</title>
<date>2002</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2043" citStr="Merlo et al., 2002" startWordPosition="290" endWordPosition="293">ormation ranging from named entity to discourse structure. Unfortunately, for the vast majority of languages very few linguistic resources are available. This situation is likely to persist because of the expense of creating annotated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervi</context>
</contexts>
<marker>Merlo, Stevenson, Tsang, Allaria, 2002</marker>
<rawString>P. Merlo, S. Stevenson, V. Tsang, and G. Allaria. 2002. A multilingual paradigm for automatic verb classification. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Neal</author>
<author>G E Hinton</author>
</authors>
<title>A new view of the EM algorithm that justifies incremental, sparse and other variants.</title>
<date>1998</date>
<booktitle>Learning in Graphical Models,</booktitle>
<pages>355--368</pages>
<editor>In M. I. Jordan, editor,</editor>
<publisher>Kluwer.</publisher>
<contexts>
<context position="14918" citStr="Neal and Hinton, 1998" startWordPosition="2399" endWordPosition="2402"> = pθ(z |x) exp{−λTf(x, z)}/Z, where Z is a normalization constant. There is one dual variable per expectation constraint, and we can optimize them by projected gradient descent, similar to log-linear model estimation. The gradient with respect to λ is given by: b − Eq[f(x, z)], so it involves computing expectations under the distribution q(z). This remains tractable as long as features factor by edge, f(x, z) = &amp;;Ez f(x, z), because that ensures that q(z) will have the same form as pθ(z | x). Furthermore, since the constraints are per instance, we can use incremental or online version of EM (Neal and Hinton, 1998), where we update parameters θ after posterior-constrained E-step on each instance x. 5 Experiments We conducted experiments on two languages: Bulgarian and Spanish, using each of the parsing models. The Bulgarian experiments transfer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005)</context>
</contexts>
<marker>Neal, Hinton, 1998</marker>
<rawString>R. M. Neal and G. E. Hinton. 1998. A new view of the EM algorithm that justifies incremental, sparse and other variants. In M. I. Jordan, editor, Learning in Graphical Models, pages 355–368. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2734" citStr="Nivre and Nilsson, 2005" startWordPosition="391" endWordPosition="394">eech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and eval</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>J. Nivre and J. Nilsson. 2005. Pseudo-projective dependency parsing. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. EMNLP-CoNLL.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proc. EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2225" citStr="Och and Ney, 2000" startWordPosition="318" endWordPosition="321">ersist because of the expense of creating annotated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved statistical alignment models. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Quirk</author>
<author>A Menezes</author>
<author>C Cherry</author>
</authors>
<title>Dependency treelet translation: syntactically informed phrasal smt.</title>
<date>2005</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="3013" citStr="Quirk et al., 2005" startWordPosition="435" endWordPosition="438">g coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2) errors in word alignments and source language parses, (3) grammatical annotation choices that differ across languages and linguistic theories (e.g., how to analyze auxili</context>
</contexts>
<marker>Quirk, Menezes, Cherry, 2005</marker>
<rawString>C. Quirk, A. Menezes, and C. Cherry. 2005. Dependency treelet translation: syntactically informed phrasal smt. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Shen</author>
<author>J Xu</author>
<author>R Weischedel</author>
</authors>
<title>A new string-to-dependency machine translation algorithm with a target dependency language model.</title>
<date>2008</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="3033" citStr="Shen et al., 2008" startWordPosition="439" endWordPosition="442">eted in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2) errors in word alignments and source language parses, (3) grammatical annotation choices that differ across languages and linguistic theories (e.g., how to analyze auxiliary verbs, conjuncti</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>L. Shen, J. Xu, and R. Weischedel. 2008. A new string-to-dependency machine translation algorithm with a target dependency language model. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Smith</author>
<author>J Eisner</author>
</authors>
<title>Annealing structural bias in multilingual weighted grammar induction.</title>
<date>2006</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="2842" citStr="Smith and Eisner, 2006" startWordPosition="409" endWordPosition="413"> 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to accurate training and evaluation from aligned bitext remain: (1) partial word alignment due to non-literal or distant translation; (2)</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>N. Smith and J. Eisner. 2006. Annealing structural bias in multilingual weighted grammar induction. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tiedemann</author>
</authors>
<title>Building a multilingual parallel subtitle corpus.</title>
<date>2007</date>
<booktitle>In Proc. CLIN.</booktitle>
<contexts>
<context position="6364" citStr="Tiedemann, 2007" startWordPosition="977" endWordPosition="978">n framework (Graça et al., 2008). We estimate both generative and discriminative models by constraining the posterior distribution over possible target parses to approximately respect projected dependencies and other rules which we describe below. In our experiments we evaluate the learned models on dependency treebanks (Nivre et al., 2007). Unfortunately the sentence in Figure 1(b) is highly unusual in its amount of dependency conservation. To get a feel for the typical case, we used off-the-shelf parsers (McDonald et al., 2005) for English, Spanish and Bulgarian on two bitexts (Koehn, 2005; Tiedemann, 2007) and compared several measures of dependency conservation. For the English-Bulgarian corpus, we observed that 71.9% of the edges we projected were edges in the corpus, and we projected on average 2.7 edges per sentence (out of 5.3 tokens on average). For Spanish, we saw conservation of 64.4% and an average of 5.9 projected edges per sentence (out of 11.5 tokens on average). As these numbers illustrate, directly transferring information one dependency edge at a time is unfortunately error prone for two reasons. First, parser and word alignment errors cause much of the transferred information to</context>
<context position="15237" citStr="Tiedemann, 2007" startWordPosition="2448" endWordPosition="2449">he distribution q(z). This remains tractable as long as features factor by edge, f(x, z) = &amp;;Ez f(x, z), because that ensures that q(z) will have the same form as pθ(z | x). Furthermore, since the constraints are per instance, we can use incremental or online version of EM (Neal and Hinton, 1998), where we update parameters θ after posterior-constrained E-step on each instance x. 5 Experiments We conducted experiments on two languages: Bulgarian and Spanish, using each of the parsing models. The Bulgarian experiments transfer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanov</context>
</contexts>
<marker>Tiedemann, 2007</marker>
<rawString>J. Tiedemann. 2007. Building a multilingual parallel subtitle corpus. In Proc. CLIN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>Proc. HLT-NAACL.</booktitle>
<contexts>
<context position="15852" citStr="Toutanova et al., 2003" startWordPosition="2544" endWordPosition="2547">n, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanova et al., 2003) on the Bularg min � λ&gt;0 bTλ+log z 372 Discriminative model Generative model Bulgarian Spanish Bulgarian Spanish no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3 Post.Reg. 66.9 77.5 78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8 Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer models were trained on 10k sentences of length up to 20, all models tested on CoNLL train sentences of up to 10 words. Punctuation was stripped at train time. g</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>K. Toutanova, D. Klein, C. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proc. HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<title>Bidirectional inference with the easiest-first strategy for tagging sequence data. In</title>
<date>2005</date>
<booktitle>Proc. HLT/EMNLP.</booktitle>
<contexts>
<context position="15518" citStr="Tsuruoka and Tsujii, 2005" startWordPosition="2491" endWordPosition="2494">EM (Neal and Hinton, 1998), where we update parameters θ after posterior-constrained E-step on each instance x. 5 Experiments We conducted experiments on two languages: Bulgarian and Spanish, using each of the parsing models. The Bulgarian experiments transfer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanova et al., 2003) on the Bularg min � λ&gt;0 bTλ+log z 372 Discriminative model Generative model Bulgarian Spanish Bulgarian Spanish no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3 Post.Reg. </context>
</contexts>
<marker>Tsuruoka, Tsujii, 2005</marker>
<rawString>Y. Tsuruoka and J. Tsujii. 2005. Bidirectional inference with the easiest-first strategy for tagging sequence data. In Proc. HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proc. IWPT,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="2708" citStr="Yamada and Matsumoto, 2003" startWordPosition="387" endWordPosition="390">sing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to </context>
<context position="15775" citStr="Yamada and Matsumoto (2003" startWordPosition="2532" endWordPosition="2535">fer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanova et al., 2003) on the Bularg min � λ&gt;0 bTλ+log z 372 Discriminative model Generative model Bulgarian Spanish Bulgarian Spanish no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3 Post.Reg. 66.9 77.5 78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8 Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer models were trained on 10k sentences of length up to 20, all models tested on CoNLL</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003a. Statistical dependency analysis with support vector machines. In Proc. IWPT, pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Yamada</author>
<author>Y Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proc. IWPT.</booktitle>
<contexts>
<context position="2708" citStr="Yamada and Matsumoto, 2003" startWordPosition="387" endWordPosition="390">sing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has spurred several supervised learning approaches (Eisner, 1996; Yamada and Matsumoto, 2003a; Nivre and Nilsson, 2005; McDonald et al., 2005) as well as unsupervised induction (Klein and Manning, 2004; Smith and Eisner, 2006). Dependency representation has been used for language modeling, textual entailment and machine translation (Haghighi et al., 2005; Chelba et al., 1997; Quirk et al., 2005; Shen et al., 2008), to name a few tasks. Dependency grammars are arguably more robust to transfer since syntactic relations between aligned words of parallel sentences are better conserved in translation than phrase structure (Fox, 2002; Hwa et al., 2005). Nevertheless, several challenges to </context>
<context position="15775" citStr="Yamada and Matsumoto (2003" startWordPosition="2532" endWordPosition="2535">fer a parser from English to Bulgarian, using the OpenSubtitles corpus (Tiedemann, 2007). The Spanish experiments transfer from English to Spanish using the Spanish portion of the Europarl corpus (Koehn, 2005). For both corpora, we performed word alignments with the open source PostCAT (Graça et al., 2009) toolkit. We used the Tokyo tagger (Tsuruoka and Tsujii, 2005) to POS tag the English tokens, and generated parses using the first-order model of McDonald et al. (2005) with projective decoding, trained on sections 2-21 of the Penn treebank with dependencies extracted using the head rules of Yamada and Matsumoto (2003b). For Bulgarian we trained the Stanford POS tagger (Toutanova et al., 2003) on the Bularg min � λ&gt;0 bTλ+log z 372 Discriminative model Generative model Bulgarian Spanish Bulgarian Spanish no rules 2 rules 7 rules no rules 3 rules no rules 2 rules 7 rules no rules 3 rules Baseline 63.8 72.1 72.6 67.6 69.0 66.5 69.1 71.0 68.2 71.3 Post.Reg. 66.9 77.5 78.3 70.6 72.3 67.8 70.7 70.8 69.5 72.8 Table 2: Comparison between transferring a single tree of edges and transferring all possible projected edges. The transfer models were trained on 10k sentences of length up to 20, all models tested on CoNLL</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>H. Yamada and Y. Matsumoto. 2003b. Statistical dependency analysis with support vector machines. In Proc. IWPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
</authors>
<title>Inducing multilingual pos taggers and np bracketers via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proc. NAACL.</booktitle>
<contexts>
<context position="1999" citStr="Yarowsky and Ngai, 2001" startWordPosition="282" endWordPosition="285">notated corpora with a variety of linguistic information ranging from named entity to discourse structure. Unfortunately, for the vast majority of languages very few linguistic resources are available. This situation is likely to persist because of the expense of creating annotated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constitu</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>D. Yarowsky and G. Ngai. 2001. Inducing multilingual pos taggers and np bracketers via robust projection across aligned corpora. In Proc. NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proc. HLT.</booktitle>
<contexts>
<context position="2022" citStr="Yarowsky et al., 2001" startWordPosition="286" endWordPosition="289">riety of linguistic information ranging from named entity to discourse structure. Unfortunately, for the vast majority of languages very few linguistic resources are available. This situation is likely to persist because of the expense of creating annotated corpora that require linguistic expertise (Abeillé, 2003). On the other hand, parallel corpora between many resource-poor languages and resource-rich languages are ample, motivating recent interest in transferring linguistic resources from one language to another via parallel text. For example, several early works (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Merlo et al., 2002) demonstrate transfer of shallow processing tools such as part-of-speech taggers and noun-phrase chunkers by using word-level alignment models (Brown et al., 1994; Och and Ney, 2000). Alshawi et al. (2000) and Hwa et al. (2005) explore transfer of deeper syntactic structure: dependency grammars. Dependency and constituency grammar formalisms have long coexisted and competed in linguistics, especially beyond English (Mel’ˇcuk, 1988). Recently, dependency parsing has gained popularity as a simpler, computationally more efficient alternative to constituency parsing and has sp</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proc. HLT.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>