<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.983904">
Pearl: A Probabilistic Chart Parser*
</title>
<author confidence="0.979577">
David M. Magerman
</author>
<affiliation confidence="0.925262">
CS Departineiit
Stanford University
</affiliation>
<address confidence="0.765244">
Stanford, CA 94305
</address>
<email confidence="0.719486">
inagerniarAcs.stanford.edn
</email>
<author confidence="0.968295">
Mitchell P. Marcus
</author>
<affiliation confidence="0.9684205">
. CIS Department
University of Pennsylvania.
</affiliation>
<address confidence="0.755437">
Philadelphia., PA 19104
</address>
<email confidence="0.915786">
mitchkOlinc.cis.upenn.edu
</email>
<sectionHeader confidence="0.972332" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906291666667">
This paper describes a natural language pars-
ing algorithm for unrestricted text which uses a
probability-based scoring function to select the
&amp;quot;best&amp;quot; parse of a sentence. The parser, Pearl,
is a time-asynchronous bottom-up chart parser
with Earley-type top-down prediction which pur-
sues the highest-scoring theory in the chart, where
the score of a theory represents the extent to which
the context of the sentence predicts that interpre-
tation. This parser differs from previous attempts
at stochastic parsers in that, it uses a richer form of
conditional probabilities based on context to pre-
dict likelihood. Pearl also provides a framework
for incorporating the results of previous work in
part-of-speech assignment, unknown word mod-
els, and other probabilistic inodels of linguistic
features into one parsing tool, interleaving these
techniques instead of using the traditional pipeline
architecture. In preliminary tests, Pearl has been
siiccessful at resolving part-of-speech and word (in
speech processing) ambiguity, determining cate-
gories for unknown words, and selecting correct
parses first using a very loosely fitting covering
grammar.&apos;
</bodyText>
<sectionHeader confidence="0.932193" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.95621725">
All natural language grammars are ambiguous. Even
tightly fitting natural language grammars are ambigu-
ous in some ways. Loosely fitting grammars, which are
necessary for handling the variability and complexity
of unrestricted text and speech, are worse. The stan-
dard technique for dealing with this ambiguity, pruning
This work was partially supported by DARPA grant
No. NO014-85-1i0018, ONR contract No. N00014-89-
C-017I by DARPA and AFOSR jointly under grant No.
AFOSR-90-0066, and by ARO grant No. DAAL 03-89-
(211031 PRI. Special thanks to Carl Weir and Lynette
Hirschman at Unisys for their valued input, guidance and
support.
&apos;The grammar used for our experiments is the string
grammar used in Unisys&apos; PUNDIT natural language un-
derstanding system.
grammars by hand, is painful, time-consuming, and
usually arbitrary. The solution which many people
have proposed is to use stochastic models to train sta-
tistical grammars automatically from a large corpus.
Attempts in applying statistical techniques to nat-
ural language parsing have exhibited varying degrees
of success. These successful and unsuccessful attempts
have suggested to us that:
</bodyText>
<listItem confidence="0.933598818181818">
• Stochastic techniques combined with traditional lin-
guistic theories can (and indeed must) provide a so-
lution to the natural language understanding prob-
lem.
• hi order for stochastic techniques to be effeceive,
they must be applied with restraint (poor estimates
of context are worse than none[7]).
• Interactive, interleaved architectures are preferable
to pipeline architectures in NLU systems, because
they use more of the available information in the
decision-inaking process.
</listItem>
<bodyText confidence="0.999802782608696">
We have constructed a stochastic parser, Pearl, which
is based on these ideas.
The development of the Pearl parser is an effort to
combine the statistical models developed recently into
a single tool which incorporates all of these models into
the decision-making component of a parser. While we
have only attempted to incorporate a few simple sta-
tistical models into this parser, Pearl is structured in
a way which allows any number of syntactic, semantic,
and &apos;other knowledge sources to contribute to parsing
decisions. The current implementation of Pearl uses
Church&apos;s part-of-speech assignment trigram model, a
simple probabilistic unknown word model, and a con-
ditional probability model for grammar rules based on
part-of-speech trigrams and parent rules.
By combining multiple knowledge sources and using
a chart-parsing framework, Pearl attempts to handle
a number of difficult problems. Pearl has the capa-
bility to parse word lattices, an ability which is useful
in recognizing idioms in text processing, as well as in
speech processing. The parser uses probabilistic train-
ing from a corpus to disambiguate between grammati-
cally acceptable structures, such as determining prepo-
</bodyText>
<equation confidence="0.551471">
- 15 -
</equation>
<bodyText confidence="0.999906782608696">
sitional phrase attachment and conjunction scope. Fi-
lially, Pearl maintains a well-formed substring table
within its chart to allow for partial parse retrieval. Par-
tial parses are useful both for error-message generation
and for processing ungrammatical or incomplete sen-
tences.
In preliminary tests, Pearl has shown promising re-
sults in handling part-of-speech assignment, preposi-
tional phrase attachment, and unknown word catego-
rization. Trained on a corpus of 1100 sentences front
the Voyager direction-finding system2 and using the
string grammar from the PtiNEAT Language Under-
standing System, Pearl correctly parsed 35 out of 40 or
88% of sentences selected from Voyager sentences not
used in the training data. We will describe the details
of this experiment later.
In this paper, we will first explain our contribu-
tion to the stochastic models which are used in Pearl:
a context-free grammar with context-sensitive condi-
tional probabilities. Then, we will describe the parser&apos;s
architecture and the parsing algorithm. Finally, we
will give the results of some experiments we performed
using &apos;Pearl which explore its capabilities.
</bodyText>
<subsectionHeader confidence="0.965693">
Using Statistics to Parse
</subsectionHeader>
<bodyText confidence="0.99947075">
Recent work involving context-free and context-
sensitive probabilistic grammars provide little hope for
the success of processing unrestricted text using proba-
bilistic techniques. Works by Chitrao and Grishman[3]
and by Sharman, Jelinek, and Mercer[l 2] exhibit ac-
curacy rates lower than 50% using supervised train-
ing. Supervised training for probabilistic CFCs re-
quires parsed corpora, which is very costly in time and
man-power[2].
In our investigations, we have made two observations
which attempt to explain the lack-luster perfbrniance
of statistical parsing techniques:
</bodyText>
<listItem confidence="0.994763142857143">
• Simple probabilistic CFCs provide general informa-
tion about how likely a construct is going to appear
anywhere in a sample of a language. This average
likelihood is often a poor estimate of probability.
• Parsing algorithms which accumulate probabilities
of parse theories by simply multiplying them over-
penalize infrequent constructs.
</listItem>
<bodyText confidence="0.999654777777778">
Pearl avoids the first pitfall by using a context-
sensitive conditional probability CFO, where context
of a theory is determined by the theories which pre-
dicted it and the part-of-speech sequences in the input
sentence. &apos;lb address the second issue, Pearl scores
each theory by using the geometric mean of the con-
textual conditional probabilities of all of the theories
which have contributed to that theory. This is equiva-
lent to using the sum of the logs of these probabilities.
</bodyText>
<footnote confidence="0.9407405">
2SpeciaI thanks to Victor Zue at MIT for the use of the
speech data from MIT&apos;s Voyager system.
</footnote>
<construct confidence="0.1594425">
CFG with context-sensitive conditional
probabilities
</construct>
<bodyText confidence="0.93305602739726">
In a very large parsed corpus of English text, one
finds that the most frequently occurring noun phrase
structure in the text is a noun phrase containing a
determiner followed by a noun. Simple probabilistic
CFCs dictate that, given this information, &amp;quot;determiner
noun&amp;quot; should be the most likely interpretation of a
noun phrase.
Now, consider only those noun phrases which oc-
cur as subjects of a sentence. In a given corpus, you
might find that pronomis occur just as frequently as
&amp;quot;determiner nones ill the subject position. This type
of information can easily be captured by conditional
probabilities.
Finally, assume that the sentence begins with a pro-
noun followed by a verb. In this case, it is quite clear
that, while you can probably concoct a sentence which
fits this description and does not have a pronoun for
a subjecl„ the first theory which you should pursue is
one which makes this hypothesis.
The context-sensitive conditional probabilities which
Pearl uses Lake into account the immediate parent of
a theory3 and the part-of-speech trigram centered at
the beginning of the theory.
For example, consider the sentence:
My first love was named Pearl.
(no subliminal propaganda intended)
A theory which tries Lo interpret &amp;quot;love&amp;quot; as a verb will
be scored based on the part-of-speech trigram &amp;quot;adjec-
tive verb verb&amp;quot; and the parent theory, probably &amp;quot;S
NP VP.&amp;quot; A theory which interprets &amp;quot;love&amp;quot; as a noun
will be scored based on the trigram &amp;quot;adjective noun
verb.&amp;quot; Although lexical probabilities favor &amp;quot;love&amp;quot; as
a verb, the conditional probabilities will heavily favor
&amp;quot;love&amp;quot; as a noun in this context.4
Using the Geometric Mean of Theory
Scores
According to probability theory, the likelihood of two
independent events occurring at the same time is the
product of their individual probabilities. Previous sta-
tistical parsing techniques apply this definition to the
cooccurrence of two theories in a parse, and claim that
the likelihood of the two theories being correct is the
product of the probabilities of the two theories.
&apos;The parent of a theory is defined as a theory with a
CF rule which contains the left-hand side of the theory.
For instance, if &amp;quot;S NP VP&amp;quot; and &amp;quot;NP —+ det n&amp;quot; are two
grammar rules, the first rule can be a parent of the second,
since the left-hand side of the second &amp;quot;NP&amp;quot; occurs in the
right-hand side of the first rule.
&apos;In fact, the part-of-speech tagging model which is also
used in Pearl will heavily favor &amp;quot;love&amp;quot; as a noun. We ignore
this behavior to demonstrate the benefits of the trigram
condi tiopti 11g.
- 16 -
This application of probability theory ignores two
vital observations about the domain of statistical pars-
ing:
• Two constructs &apos;occurring in the same sentence are
not. necessarily independent, (and frequently are not).
If the in assumption is violated, them the
product of individual probabilities has no meaning
with respect to the joint probability of two events.
• Since statistical parsing sliffers from sparse data,
probability estimates of low freqiiency events will
U sually be inaccurate estimates. Extreme underesti-
mates of the likelihood of low frequency events will
produce misleading joint probability estimates.
From these observations, we have determined that esti-
mating joint. probabilities of theories using individual
probabilities is too difficult with the available data.
We have found that the gemnetric mean of these prob-
ability estimates provides an accurate assessment of a
theory&apos;s viability.
</bodyText>
<subsectionHeader confidence="0.731027">
The Actual Theory Scoring Function
</subsectionHeader>
<bodyText confidence="0.9995135">
In a departure from standard practice, and perhaps
against, better judgment„ we will include a precise
description of the theory scoring function used by
&apos;Pearl. This scoring function tries to solve some of the
problems noted in previous attempts at probabilistic
parsing[31[1
</bodyText>
<listItem confidence="0.995542285714286">
• Theory scores should not depend on the length of
the string which the theory spans.
• Sparse data (zero-frequency events) and even zero-
probability events do occur, and should not result in
zero scoring theories.
• Theory scores should not, discriminate against un-
likely constructs ‘vhen the context. predicts them.
</listItem>
<bodyText confidence="0.9221024">
The raw score of a theory, 0 is calculated by taking
the product. of the conditional probability of that. the-
ory&apos;s C FG rule given the context (where context, is a
imrt-of-siwech trigram and a parent theory&apos;s rule) mid
the score of the trigram:
</bodyText>
<equation confidence="0.991672">
SCraw(0) = P(i-u/e01(popip2), ruleparent)sc(popip2)
</equation>
<bodyText confidence="0.9257544375">
here, the score of a trigram is the product of the
mutual information of the part-of-speech trigram,5
popip2, and the lexical probability of the word at the
location of pi being assigned that part-of-speech p1.6
In the case of ambiguity (part-of-speech ambiguity or
multiple parent theories), the maximum value of this
product, is used. The score of a partial theory or a com-
plete theory is the geometric mean of the raw scores of
all of the theories which are contained in that theory.
mutual information of a part-of-speech trigram,
P01)1 P, is defined to he 1,(11:,(,smi1,1;;Wri), where x is any part-
of-speech. See [4] for further explanation.
&apos;The trigram scoring function actually used by the
pa rser is somewhat more complicated than this.
Theory Length Independence This scoring func-
tion, although heuristic in derivation, • provides a
method for evaluating the value of a theory, regardless
of its length. When a rule is first predicted (Earley-
style), its score is just its raw score, which represents
how much the context predicts it. However, when the
parse process hypothesizes interpretations of the sen-
tence which reinforce this theory, the geometric mean
of all of the raw scores of the rule&apos;s subtree is used,
representing the overall likelihood of the theory given
the context of the sentence.
Low-frequency Events Although some statistical
natural language applications employ backing-off es-
timation technique* 11[51 to handle low-frequency
events, Pearl uses a very simple estimation technique,
reluctantly attributed to Church[7]. This technique
estimates the probability of an event by adding 0.5 to
every frequency count.&apos; Low-scoring theories will be
predicted by the Earley-style parser. And, if no other
hypothesis is suggested, these theories will be pursued.
If a high scoring theory advances a theory with a very
low raw score, the resulting theory&apos;s score will be the
geometric mean of all of the raw scores of theories con-
tained in that, theory, and thus will be much higher
than the low-scoring theory&apos;s score.
Example of Scoring Function As an example of
how the conditional-probability-based scoring function
handles ambiguity, consider the sentence
Fruit flies like a banana.
in the domain of insect studies. Lexical probabilities
should indicate that the word &amp;quot;flies&amp;quot; is more likely to
be a plural noun than an active verb. This information
is incorporated in the trigram scores. However, when
the interpretation
</bodyText>
<equation confidence="0.640523">
S . NP VP
</equation>
<bodyText confidence="0.789408333333333">
is proposed, two possible NPs will be parsed,
NP iimin (fruit)
and
</bodyText>
<equation confidence="0.556176">
NP —+ noun noun (fruit flies).
</equation>
<bodyText confidence="0.929277956521739">
Since this sentence is syntactically ambiguous, if the
first hypothesis is tested first, the parser will interpret
this sentence incorrectly.
However, this will not happen in this domain. Since
&amp;quot;fruit flies&amp;quot; is a common idiom in insect studies, the
score of its trigram, noun noun verb, will be much
greater than the score of the trigram, noun verb verb.
Thus, not only will the lexical probability of the word
&amp;quot;flies/verb&amp;quot; be lower than that of &amp;quot;flies/noun,&amp;quot; but also
the taw score of &amp;quot;NP —+ noun (fruit)&amp;quot; will be lower than
7We are not deliberately avoiding using all probabil-
ity estimation techniques, only those backing-off tech-
niques which use independence assumptions that frequently
provide misleading information when applied to natural
language.
- 17 -
that of &amp;quot;NP --4 noun noun (fruit flies),&amp;quot; because of the
differential between the trigram scores.
So, &amp;quot;NP —4 noun noun&amp;quot; will be used first to advance
the &amp;quot;S . NP VP&amp;quot; rule. Further, even if the parser
advances both NP hypotheses, the &amp;quot;S —4 NP . VP&amp;quot;
rule using &amp;quot;NP —4 noun noun&amp;quot; will have a higher score
than the &amp;quot;S NP . VP&amp;quot; rule using &amp;quot;NP —4 noun.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.905157">
Interleaved Architecture in Pearl
</subsectionHeader>
<bodyText confidence="0.9999846875">
The interleaved architecture implemented in Pearl pro-
vides many advantages over the traditional pipeline
architecture, but it also introduces certain risks. De-
cisions about word and part-of-speech ambiguity can
be delayed until syntactic processing can disambiguate
them. And, using the appropriate score combination
functions, the scoring of ambiguous choices can direct
the parser towards the most likely interpretation effi-
ciently.
I lowever, with these delayed decisions conies a vastly
enlarged search sluice. The effectiveness of the parser
depends on a majority of the theories having very low
scores based on either unlikely syntactic structures or
low scoring input (such as low scores front a speech
recognizer or low lexical probability), hi experiments
we have performed, this has been the case.
</bodyText>
<subsectionHeader confidence="0.942389">
The Parsing Algorithm
</subsectionHeader>
<bodyText confidence="0.999363567567568">
Pearl is a time-asynchronous bottom-up chart parser
with Earley-type top-down prediction. The signifi-
cant, difference between Pearl and non-probabilistic
bottom-up parsers is dud. instead of completely gener-
ating all grammatical interpretations of a word string,
Pearl pursues the N highest-scoring incomplete theo-
ries in the chart at. each pass. However, Pearl parses
wilhoul pruning. Although it. is only advancing the N
highest-scoring incomplete theories, it retains the lower
scoring theories in its agenda. If the higher scoring
theories do not, generate viable alternatives, the lower
scoring theories may be used on subsequent passes.
The parsing algorithm begins with the input word
lattice. An n x a chart, is allocated, where n is the
length of the longest word string in the lattice. Lexical
rules for the input ‘vord lattice are inserted into the
chart. Using Earley-type prediction, a sentence is pre-
dicted at. the beginning of the sentence, and all of the
theories %vine!&apos; are predicted by that initial sentence
are inserted into the chart. These incomplete theo-
ries are scored according to the context-sensitive con-
ditional probabilities and the trigram part-of-speech
model. The incomplete theories are tested in order by
score, until N theories are advanced.&apos; The resulting
advanced theories are scored and predicted for, and
the new incomplete predicted theories are scored and
8 We believe that N depends on the perplexity of the
grammar used, but for the string grammar used for our
experiments we used N=3. For the purposes of training, a
higher N should be used in order to generate more parses.
added to the chart. This process continues until an
complete parse tree is determined, or until the parser
decides, heuristically, that it should not continue. The
heuristics we used for determining that no parse can
be found fir an input, are based on the highest scoring
incomplete theory in the chart, the number of passes
the parser has made, and the size of the chart.
</bodyText>
<subsectionHeader confidence="0.633177">
Pearl&apos;s Capabilities
</subsectionHeader>
<bodyText confidence="0.99528932967033">
Besides using statistical methods to guide the parser
through the parsing search space, &apos;Pearl also performs
other functions which are crucial to robustly processing
unrestricted natural language text and speech.
Handling Unknown Words &apos;Pearl uses a very sim-
ple probabilistic unknown word model to hypothesize
categories for unknown words. When word which is
unknown to the system&apos;s lexicon, the word is assumed
to lw any one of the open class categories. The lexical
probability given a category is the probability of that
category occurring in the training corpus.
Idiom Processing and Lattice Parsing Since the
parsing search space can be simplified by recognizing
idioms, Pearl allows the input string to include idioms
that. span more than one word in the sentence. This is
accomplished by viewing the input sentence as a word
lattice instead of a word string. Since idioms tend to be
unambiguous with respect to part-of-speech, they are
generally favored over processing the individual words
that make up the idiom, since the scores of rules con-
taining the words will tend to be less than I, while
a syntactically appropriate, unambiguous idiom will
have a score of close to 1.
The ability to parse a sentence with multiple word
hypotheses and word boundary hypotheses makes
Pearl very useful in the domain of spoken language
processing. By delaying decisions about word selection
but maintaining scoring information from a speech rec-
ognizer, the parser can use grammatical information in
word selection without slowing the speech recognition
proCess. Because of Pearl&apos;s interleaved architecture,
one could easily incorporate scoring information from
a speech recognizer into the set of scoring functions
used in the parser. Pearl could also provide feedback
to the speech recognizer about the grammaticality of
fragment hypotheses to guide the recognizer&apos;s search.
Partial Parses The main advantage of chart-based
parsing over other parsing algorithms is that the parser
can also recognize well-formed substrings within the
sentence in the course of pursuing a complete parse.
Pearl takes full advantage of this characteristic. Once
Pearl is given the input, sentence, it awaits instructions
as to what type of parse should be attempted for this
input. A standard parser automatically attempts to
produce a sentence (S) spanning the entire input string.
However, if this fails, the semantic interpreter might be
able to derive sonic meaning from the sentence if given
- 18 -
non-overlapping noun, verb, and prepositional phrases.
If a sentence fails to parse, re(plests for partial parses
of the input string can be made by specifying a range
which the parse tree should cover and the category
(NP, VP, etc.).
The ability to produce partial parses allows the sys-
tem to handle multiple sentence inputs. In both speech
and text processing, it. is difficult to know where the
end of a sentence is. For instance, one cannot reli-
ably determine when a speaker terminates a sentence
in free speech. And in text processing, abbreviations
and quoted expressions produce ambiguity about sen-
tence termination. VViten this ambiguity exists, Pearl
can be queried lot partial parse trees for the given in-
put, where the goal category is a sentence. Thus, if
the word string is actually two complete sentences, the
parser can return this information. However, if the
word string is only one sentence, then a complete parse
Lice is returned at, little extra cost..
Trainability One of the major advantages of the
probabilistic parsers is trainability. The conditional
probabilities used by Pearl are estimated by using fre-
quencies front a large corpus of parsed sentences. The
parsed sentemces must be parsed using the grammar
formalism %vhich the &apos;Pearl will use.
Assuming the grammar is not, recursive in an un-
constrained way, the parser can be trained in an unsu-
pervised mode. This is accomplished by running the
parser without. the scoring functions, and generating
amity parse trees for each sentence. Previous work&apos;
has demonstrated that the correct information from
these parse trees will be reinforced, while the incorrect,
substructure will not. Multiple passes of re-training us-
ing frequency data front the previous pass should cause
the frequency tables to converge to a stable state. This
hypothesis has not yet, been tested.&amp;quot;
An alternative to completely unsupervised training
is to take a parsed corpus knr any domain of the same
language using the same grammar, and use the fre-
quency data from that, corpus as the initial training
material for the new corpus. This approach should
serve only to minimize the number of unsupervised
I asses required for the fre(piency data to converge.
</bodyText>
<subsectionHeader confidence="0.894989">
Preliminary Evaluation
</subsectionHeader>
<bodyText confidence="0.899012464285714">
While we have nol, yet, done extensive testing of all of
the capabilities of Pearl, we performed sonic simple
tests to determine if its performance is at, least con-
sistent with the premises upon which it is based. The
test sentences used for this evaluation are not front the
&apos;This is an unpublished result, reportedly due to Fu-
jisaki at IBM Japan.
1° In fact, for certain grammars, the frequency tables may
not converge at all, or they ma.y converge to zero, with
the grammar generating no parses for the entire corpus.
This is a worst-case scenario which we do not anticipate
happening.
training data on which the parser was trained. Using
Pearl&apos;s context-free grammar, these test sentences pro-
duced an average of 64 parses per sentence, with some
sentences producing over 100 parses.
Unknown Word Part-of-speech
Assignment
To determine how Pearl handles unknown words, we
removed five words from the lexicon, i, know, tee, de-
scribe, and station, and tried to parse the 40 sample
sentences using the simple unknown word model pre-
viously described.
lii this test, the pronoun, i, was assigned the cor-
rect part-of-speech 9 of 10 times it occurred in the test
sentences. The nouns, lee and station, were correctly
tagged 4 of 5 Limes. And the verbs, know and describe,
were correctly tagged :I of :3 times.
</bodyText>
<figure confidence="0.391798">
pronoun 904
noun 80%
verb 100%
overall 89%
</figure>
<figureCaption confidence="0.993032">
Figure 1: Performance on Unknown Words in Test Sen-
tences
</figureCaption>
<bodyText confidence="0.96174525">
While this accuracy is expected for unknown words
in isolation, based on the accuracy of the part-of-
speech tagging model, the performance is expected to
degrade for sequences of unknown words.
</bodyText>
<subsectionHeader confidence="0.776558">
Prepositional Phrase Attachment
</subsectionHeader>
<bodyText confidence="0.99131196875">
Accurately determining prepositional phrase attach-
ment in general is a difficult and well-documented
problem. However, based on experience with several
different domains, we have found prepositional phrase
attachment to be a domain-specific phenomenon for
which training can be very lidpful. For instance, in
the,direction-fi tiding domain, from and to prepositional
phoses generally attach to the preceding verb and
not to any noun phrase. This tendency is captured
in the training process for Pearl and is used to guide
the parser to the more likely attachment with respect
to the domain. This does not mean that Pearl will
get the correct parse when the less likely attachment
is correct; in fact, &apos;Pearl will invariably get this case
wrong. However, based on the premise that this is the
less likely, attachment, this will produce more correct
analyses than incorrect. And, using a more sophisti-
cated statistical model, this performance can easily be
improved.
Pearl&apos;s performance on prepositional phrase attach-
ment was very high (54/55 or 98.2% correct). The rea-
son the accuracy rate was so high is that the direction-
finding domain is very consistent in it&apos;s use of individ-
ual prepositions. The accuracy rate is not expected
to be as high in other domains, although it. certainly
- 19 -
should be higher than 50% and we would expect it to
be greater than 75 %, although we have not performed
any rigorous tests on other domains to verify this.
in speech processing. With the exception of word se-
lection, preliminary tests show Pearl performs these
tasks with a high degree of accuracy.
</bodyText>
<table confidence="0.479517">
Preposition from to 011 Overall
Accuracy Rate 92 % 100 % 100 % 98.2 %
</table>
<figureCaption confidence="0.997818">
Figure 2: Accuracy Rate for Prepositional Phrase At-
tachment., by Preposition
</figureCaption>
<subsectionHeader confidence="0.521575">
Overall Parsing Accuracy
</subsectionHeader>
<bodyText confidence="0.999862">
The /10 Lest sentences were parsed by Pearl and the
highest. scoring parse for each sentence was compared
to the correct. parse produced by puNDIT. Of these 40
sentences, Pearl produced parse trees for :18 of them,
and :35 of these parse trees were equivalent to the cor-
rect parse produced by Pundit, for an overall accuracy
rate of 88%.
Many of the Lest sentences were not difficult to parse
for existing parsers, but most had some grammatical
ambiguity which would produce multiple parses. In
fact, on 2 of the 3 sentences which were incorrectly
parsed, &apos;Pearl produced the correct parse as well, but
the correct parse did not have the highest score.
</bodyText>
<subsectionHeader confidence="0.561791">
Future Work
</subsectionHeader>
<bodyText confidence="0.999952642857143">
The &apos;Pearl parser takes advantage of domain-dependent
information to select the most appropriate interpreta-
tion of an input.. However, the statistical measure used
to disambiguate these interpretations is sensitive to
certain attributes of the grammatical formalism used,
as well as to the part-of-speech categories used to la-
bel lexical entries. All of the experiments performed on
Pearl thus far have been using one grammar, one part-
of-speech tag set, and one domain (because of avail-
ability constraints). Future experiments are planned
to evaluate Pearl&apos;s performance on different domains,
as well as on a general corpus of English, and On dif-
ferent grammars, including a grammar derived from a
manually parsed .corpus.
</bodyText>
<sectionHeader confidence="0.957577" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999973538461538">
The probabilistic parser which we have described pro-
vides a platform for exploiting the useful informa-
tion made available by statistical models in a manner
which is consistent with existing grammar formalisms
and parser designs. Pearl can be trained to use any
context-free grammar, accompanied by the appropri-
ate training material. And, the parsing algorithm is
very similar to a. standard bottom-up algorithm, with
the exception of using theory scores to order the search.
More thorough testing is necessary to measure
Pearl&apos;s performance in terms of parsing accuracy, part-
of-speech assignment, unknown word categorization,
idiom processing capabilities, and even word selection
</bodyText>
<sectionHeader confidence="0.996964" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.992638408163265">
[I] Ayuso, D., Bobrow, It., et. al. 1990. Towards Un-
derstanding Text with a Very Large Vocabulary.
In Proceedings of the June 1990 DARPA Speech
and Natural Language Workshop. Hidden Valley,
Pennsylvania.
[2] Brill, E., Magerman, D., Marcus, M., .and San-
torini, 13. 1990. Deducing Linguistic Structure
from the Statistics of Large Corpora. In Proceed-
ings of the Julie 1990 DARPA Speech and Natural
Language Workshop. Hidden Valley, Pennsylva-
nia.
[3] Chitrao, M. and (.1rishinan, It. 1990. Statisti-
cal Parsing of Messages. In Proceedings of the
June 1990 DARPA Speech and Natural Language
Workshop. Hidden Valley, Pennsylvania.
[4] Church, K. 1988. A Stochastic Parts Program
and. Noun Phrase Parser for Unrestricted Text. In
Proceedings of the Second Conference OD Applied
Natural Language Processing. Austin, Texas.
[5] Church, K. and Gale, W. 1990. Enhanced Good-
Turing and Cat-Cal: Two New Methods for Es-
timating Probabilities of English Bigrams. Com-
puters, Speech and Language.
[6] Fano, R. 1961. Transmission of Information. New
York, New York: MIT Press.
[71 Gale, W. A. and Church, K. 1990. Poor Estimates
of Context are Worse than None. In Proceedings
of the June 1990 DARPA Speech and Natural
Language Workshop. Hidden Valley, Pennsylva-
nia.
[8] Hindle, D. 1988. Acquiring a Noun Classification
from Predicate-Argmnent Structures. Bell Labo-
ratories.
[9] Hindle, D. and Rooth, M. 1990. Structural Ambi-
guity and Lexical Relations. In Proceedings of the
June 1990 DARPA Speech and Natural Language
Workshop. Hidden Valley, Pennsylvania.
[10] Jelinek, F. 1985. Self-organizing Language Mod-
eling for Speech Recognition. IBM Report.
[11] Katz, S. M. 1987. Estimation of Probabilities from
Sparse Data for the Language Model Compo-
nent of a Speech Recognizer. IEEE Transactions
on Acoustics, Speech, and Signal Processing, Vol.
ASSP-3.5, No. 3.
[12] Sharman, R. A., Jelinek, F., and Mercer, R. 1990.
In Proceedings of the June 1990 DARPA Speech
and Natural Language Workshop. Hidden Valley,
Pennsylvania.
- 20 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.528368">
<title confidence="0.999733">Pearl: A Probabilistic Chart Parser*</title>
<author confidence="0.999997">David M Magerman</author>
<affiliation confidence="0.984135">CS Departineiit Stanford University</affiliation>
<address confidence="0.999933">Stanford, CA 94305</address>
<email confidence="0.916501">inagerniarAcs.stanford.edn</email>
<author confidence="0.999892">Mitchell P Marcus</author>
<affiliation confidence="0.9990575">Department University of Pennsylvania.</affiliation>
<address confidence="0.996318">Philadelphia., PA 19104</address>
<email confidence="0.999595">mitchkOlinc.cis.upenn.edu</email>
<abstract confidence="0.999508416666667">This paper describes a natural language parsing algorithm for unrestricted text which uses a probability-based scoring function to select the &amp;quot;best&amp;quot; parse of a sentence. The parser, Pearl, is a time-asynchronous bottom-up chart parser with Earley-type top-down prediction which pursues the highest-scoring theory in the chart, where the score of a theory represents the extent to which the context of the sentence predicts that interpretation. This parser differs from previous attempts at stochastic parsers in that, it uses a richer form of conditional probabilities based on context to predict likelihood. Pearl also provides a framework for incorporating the results of previous work in part-of-speech assignment, unknown word models, and other probabilistic inodels of linguistic features into one parsing tool, interleaving these techniques instead of using the traditional pipeline architecture. In preliminary tests, Pearl has been siiccessful at resolving part-of-speech and word (in speech processing) ambiguity, determining categories for unknown words, and selecting correct parses first using a very loosely fitting covering</abstract>
<intro confidence="0.605424">grammar.&apos;</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Ayuso</author>
<author>It Bobrow</author>
</authors>
<title>Towards Understanding Text with a Very Large Vocabulary.</title>
<date>1990</date>
<booktitle>In Proceedings of the</booktitle>
<location>Valley, Pennsylvania.</location>
<marker>[I]</marker>
<rawString>Ayuso, D., Bobrow, It., et. al. 1990. Towards Understanding Text with a Very Large Vocabulary. In Proceedings of the June 1990 DARPA Speech and Natural Language Workshop. Hidden Valley, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
<author>D Magerman</author>
<author>M Marcus</author>
<author>and Santorini</author>
</authors>
<title>Deducing Linguistic Structure from the Statistics of Large Corpora.</title>
<date>1990</date>
<booktitle>In Proceedings of the Julie</booktitle>
<volume>13</volume>
<location>Valley, Pennsylvania.</location>
<contexts>
<context position="5838" citStr="[2]" startWordPosition="865" endWordPosition="865">ecture and the parsing algorithm. Finally, we will give the results of some experiments we performed using &apos;Pearl which explore its capabilities. Using Statistics to Parse Recent work involving context-free and contextsensitive probabilistic grammars provide little hope for the success of processing unrestricted text using probabilistic techniques. Works by Chitrao and Grishman[3] and by Sharman, Jelinek, and Mercer[l 2] exhibit accuracy rates lower than 50% using supervised training. Supervised training for probabilistic CFCs requires parsed corpora, which is very costly in time and man-power[2]. In our investigations, we have made two observations which attempt to explain the lack-luster perfbrniance of statistical parsing techniques: • Simple probabilistic CFCs provide general information about how likely a construct is going to appear anywhere in a sample of a language. This average likelihood is often a poor estimate of probability. • Parsing algorithms which accumulate probabilities of parse theories by simply multiplying them overpenalize infrequent constructs. Pearl avoids the first pitfall by using a contextsensitive conditional probability CFO, where context of a theory is d</context>
</contexts>
<marker>[2]</marker>
<rawString>Brill, E., Magerman, D., Marcus, M., .and Santorini, 13. 1990. Deducing Linguistic Structure from the Statistics of Large Corpora. In Proceedings of the Julie 1990 DARPA Speech and Natural Language Workshop. Hidden Valley, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chitrao</author>
</authors>
<title>Statistical Parsing of Messages.</title>
<date>1990</date>
<booktitle>In Proceedings of the</booktitle>
<location>Valley, Pennsylvania.</location>
<contexts>
<context position="5618" citStr="[3]" startWordPosition="830" endWordPosition="830"> In this paper, we will first explain our contribution to the stochastic models which are used in Pearl: a context-free grammar with context-sensitive conditional probabilities. Then, we will describe the parser&apos;s architecture and the parsing algorithm. Finally, we will give the results of some experiments we performed using &apos;Pearl which explore its capabilities. Using Statistics to Parse Recent work involving context-free and contextsensitive probabilistic grammars provide little hope for the success of processing unrestricted text using probabilistic techniques. Works by Chitrao and Grishman[3] and by Sharman, Jelinek, and Mercer[l 2] exhibit accuracy rates lower than 50% using supervised training. Supervised training for probabilistic CFCs requires parsed corpora, which is very costly in time and man-power[2]. In our investigations, we have made two observations which attempt to explain the lack-luster perfbrniance of statistical parsing techniques: • Simple probabilistic CFCs provide general information about how likely a construct is going to appear anywhere in a sample of a language. This average likelihood is often a poor estimate of probability. • Parsing algorithms which accu</context>
</contexts>
<marker>[3]</marker>
<rawString>Chitrao, M. and (.1rishinan, It. 1990. Statistical Parsing of Messages. In Proceedings of the June 1990 DARPA Speech and Natural Language Workshop. Hidden Valley, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>A Stochastic Parts Program and. Noun Phrase Parser for Unrestricted Text.</title>
<date>1988</date>
<booktitle>In Proceedings of the Second Conference OD Applied Natural Language Processing.</booktitle>
<location>Austin, Texas.</location>
<contexts>
<context position="11962" citStr="[4]" startWordPosition="1855" endWordPosition="1855"> a trigram is the product of the mutual information of the part-of-speech trigram,5 popip2, and the lexical probability of the word at the location of pi being assigned that part-of-speech p1.6 In the case of ambiguity (part-of-speech ambiguity or multiple parent theories), the maximum value of this product, is used. The score of a partial theory or a complete theory is the geometric mean of the raw scores of all of the theories which are contained in that theory. mutual information of a part-of-speech trigram, P01)1 P, is defined to he 1,(11:,(,smi1,1;;Wri), where x is any partof-speech. See [4] for further explanation. &apos;The trigram scoring function actually used by the pa rser is somewhat more complicated than this. Theory Length Independence This scoring function, although heuristic in derivation, • provides a method for evaluating the value of a theory, regardless of its length. When a rule is first predicted (Earleystyle), its score is just its raw score, which represents how much the context predicts it. However, when the parse process hypothesizes interpretations of the sentence which reinforce this theory, the geometric mean of all of the raw scores of the rule&apos;s subtree is us</context>
</contexts>
<marker>[4]</marker>
<rawString>Church, K. 1988. A Stochastic Parts Program and. Noun Phrase Parser for Unrestricted Text. In Proceedings of the Second Conference OD Applied Natural Language Processing. Austin, Texas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
</authors>
<title>Enhanced GoodTuring and Cat-Cal: Two New Methods for Estimating Probabilities of English Bigrams. Computers, Speech and Language.</title>
<date>1990</date>
<marker>[5]</marker>
<rawString>Church, K. and Gale, W. 1990. Enhanced GoodTuring and Cat-Cal: Two New Methods for Estimating Probabilities of English Bigrams. Computers, Speech and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Fano</author>
</authors>
<title>Transmission of Information.</title>
<date>1961</date>
<booktitle>In Proceedings of the</booktitle>
<volume>71</volume>
<publisher>MIT Press.</publisher>
<location>New York, New York:</location>
<marker>[6]</marker>
<rawString>Fano, R. 1961. Transmission of Information. New York, New York: MIT Press. [71 Gale, W. A. and Church, K. 1990. Poor Estimates of Context are Worse than None. In Proceedings of the June 1990 DARPA Speech and Natural Language Workshop. Hidden Valley, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Acquiring a Noun Classification from Predicate-Argmnent Structures. Bell Laboratories.</title>
<date>1988</date>
<marker>[8]</marker>
<rawString>Hindle, D. 1988. Acquiring a Noun Classification from Predicate-Argmnent Structures. Bell Laboratories.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
<author>M Rooth</author>
</authors>
<title>Structural Ambiguity and Lexical Relations.</title>
<date>1990</date>
<booktitle>In Proceedings of the</booktitle>
<location>Valley, Pennsylvania.</location>
<marker>[9]</marker>
<rawString>Hindle, D. and Rooth, M. 1990. Structural Ambiguity and Lexical Relations. In Proceedings of the June 1990 DARPA Speech and Natural Language Workshop. Hidden Valley, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>Self-organizing Language Modeling for Speech Recognition.</title>
<date>1985</date>
<tech>IBM Report.</tech>
<marker>[10]</marker>
<rawString>Jelinek, F. 1985. Self-organizing Language Modeling for Speech Recognition. IBM Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Katz</author>
</authors>
<title>Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer.</title>
<date>1987</date>
<journal>IEEE Transactions on Acoustics, Speech, and Signal Processing,</journal>
<volume>3</volume>
<marker>[11]</marker>
<rawString>Katz, S. M. 1987. Estimation of Probabilities from Sparse Data for the Language Model Component of a Speech Recognizer. IEEE Transactions on Acoustics, Speech, and Signal Processing, Vol. ASSP-3.5, No. 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R A Sharman</author>
<author>F Jelinek</author>
<author>R Mercer</author>
</authors>
<date>1990</date>
<journal>DARPA Speech and Natural Language Workshop. Hidden</journal>
<booktitle>In Proceedings of the</booktitle>
<location>Valley, Pennsylvania. -</location>
<marker>[12]</marker>
<rawString>Sharman, R. A., Jelinek, F., and Mercer, R. 1990. In Proceedings of the June 1990 DARPA Speech and Natural Language Workshop. Hidden Valley, Pennsylvania. - 20 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>