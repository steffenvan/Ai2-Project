<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002138">
<title confidence="0.9990095">
Predicting Unknown Time Arguments
based on Cross-Event Propagation
</title>
<author confidence="0.984423">
Prashant Gupta Heng Ji
</author>
<affiliation confidence="0.8522165">
Indian Institute of Information Computer Science Department, Queens College and
Technology Allahabad the Graduate Center, City University of New York
</affiliation>
<address confidence="0.771924">
Allahabad, India, 211012 New York, NY, 11367, USA
</address>
<email confidence="0.997035">
greatprach@gmail.com hengji@cs.qc.cuny.edu
</email>
<sectionHeader confidence="0.993788" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9990641">
Many events in news articles don’t include
time arguments. This paper describes two
methods, one based on rules and the other
based on statistical learning, to predict the un-
known time argument for an event by the
propagation from its related events. The re-
sults are promising – the rule based approach
was able to correctly predict 74% of the un-
known event time arguments with 70% preci-
sion.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977242424242">
Event time argument detection is important to
many NLP applications such as textual inference
(Baral et al., 2005), multi-document text summa-
rization (e.g. Barzilay e al., 2002), temporal
event linking (e.g. Bethard et al., 2007; Cham-
bers et al., 2007; Ji and Chen, 2009) and template
based question answering (Ahn et al., 2006). It’s
a challenging task in particular because about
half of the event instances don’t include explicit
time arguments. Various methods have been ex-
ploited to identify or infer the implicit time ar-
guments (e.g. Filatova and Hovy, 2001; Mani et
al., 2003; Lapata and Lascarides, 2006; Eidelman,
2008).
Most of the prior work focused on the sen-
tence level by clustering sentences into topics
and ordering sentences on a time line. However,
many sentences in news articles include multiple
events with different time arguments. And it was
not clear how the errors of topic clustering tech-
niques affected the inference scheme. Therefore
it will be valuable to design inference methods
for more fine-grained events.
In addition, in the previous approaches the lin-
guistic evidences such as verb tense were mainly
applied for inferring the exact dates of implicit
time expressions. In this paper we are interested
in those more challenging cases in which an
event mention and all of its coreferential event
mentions do not include any explicit or implicit
time expressions; and therefore its time argument
can only be predicted based on other related e-
vents even if they have different event types.
</bodyText>
<sectionHeader confidence="0.964955" genericHeader="introduction">
2 Terminology and Task
</sectionHeader>
<bodyText confidence="0.919947">
In this paper we will follow the terminology de-
fined in the Automatic Content Extraction
(ACE)1 program:
</bodyText>
<construct confidence="0.7799210625">
entity: an object or a set of objects in one of the
semantic categories of interest: persons, locations,
organizations, facilities, vehicles and weapons.
event: a specific occurrence involving participants.
The 2005 ACE evaluation had 8 types of events,
with 33 subtypes; for the purpose of this paper, we
will treat these simply as 33 distinct event types. In
contrast to ACE event extraction, we exclude ge-
neric, negative, and hypothetical events.
event mention: a phrase or sentence within which
an event is described.
event argument: an entity involved in an event
with some specific role.
event time: an exact date normalized from time ex-
pressions and a role to indicate that an event occurs
before/after/within the date.
</construct>
<bodyText confidence="0.726689">
For any pair of event mentions &lt;EMi, EMj&gt;, if:
</bodyText>
<listItem confidence="0.998912">
• EMi includes a time argument time-arg;
• EMj and its coreferential event mentions
don’t include any time arguments;
</listItem>
<bodyText confidence="0.998727">
The goal of our task is to determine whether
time-arg can be propagated into EMj or not.
</bodyText>
<sectionHeader confidence="0.994752" genericHeader="method">
3 Motivation
</sectionHeader>
<bodyText confidence="0.999887833333333">
The events in a news document may contain a
temporal or locative dimension, typical about an
unfolding situation. Various situations are evolv-
ing, updated, repeated and corrected in different
event mentions. Here later information may
override earlier more tentative or incomplete
</bodyText>
<footnote confidence="0.979896">
1 http://www.nist.gov/speech/tests/ace/
</footnote>
<page confidence="0.960664">
369
</page>
<note confidence="0.92728">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 369–372,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999358846153846">
events. As a result, different events with particu-
lar types tend to occur together frequently, for
example, the chains of “Conflict4Life-Die/Life-
Injure” and “Justice-Convict 4 Justice-Charge-
Indict/Justice-Trial-Hearing” often appear within
one document. To avoid redundancy, the news
writers rarely provide time arguments for all of
these events. Therefore, it’s possible to recover
the time argument of an event by gleaning
knowledge from its related events, especially if
they are involved in a pre-cursor/consequence or
causal relation. We present two examples as fol-
lows.
</bodyText>
<listItem confidence="0.83714">
• Example 1
</listItem>
<bodyText confidence="0.99730125">
For example, we can propagate the time “Sunday
(normalized into “2003-04-06”)” from a “Con-
flict-Attack” EMi to a “Life-Die” EMj because
they both involve “Kurdish/Kurds”:
</bodyText>
<subsectionHeader confidence="0.630942">
[Sentence including EMi]
</subsectionHeader>
<bodyText confidence="0.9961255">
Injured Russian diplomats and a convoy of Amer-
ica&apos;s Kurdish comrades in arms were among unin-
tended victims caught in crossfire and friendly fire
Sunday.
</bodyText>
<subsectionHeader confidence="0.696166">
[Sentence including EMj]
</subsectionHeader>
<bodyText confidence="0.9921775">
Kurds said 18 of their own died in the mistaken
U.S. air strike.
</bodyText>
<listItem confidence="0.814249">
• Example 2
</listItem>
<bodyText confidence="0.999729428571429">
This kind of propagation can also be applied be-
tween two events with similar event types. For
example, in the following we can propagate
“Saturday” from a “Justice-Convict” event to a
“Justice-Sentence” event because they both in-
volve arguments “A state security court/state”
and “newspaper/Monitor”:
</bodyText>
<subsectionHeader confidence="0.634356">
[Sentence including EMi]
</subsectionHeader>
<bodyText confidence="0.998320333333333">
A state security court suspended a newspaper criti-
cal of the government Saturday after convicting it
of publishing religiously inflammatory material.
[Sentence including EMj]
The sentence was the latest in a series of state ac-
tions against the Monitor, the only English lan-
guage daily in Sudan and a leading critic of condi-
tions in the south of the country, where a civil war
has been waged for 20 years.
</bodyText>
<sectionHeader confidence="0.997879" genericHeader="method">
4 Approaches
</sectionHeader>
<bodyText confidence="0.9999636">
Based on these motivations we have developed
two approaches to conduct cross-event propaga-
tion. Section 4.1 below will describe the rule-
based approach and section 4.2 will present the
statistical learning framework respectively.
</bodyText>
<subsectionHeader confidence="0.99892">
4.1 Rule based Prediction
</subsectionHeader>
<bodyText confidence="0.999343714285714">
The easiest solution is to encode rules based on
constraints from event arguments and positions
of two events. We design three types of rules in
this paper.
If EMi has an event type typei and includes an
argument argi with role rolei, while EMj has an
event type typej and includes an argument argj
with role rolej, they are not from two temporally
separate groups of Justice events {Release-Parole,
Appeal, Execute, Extradite, Acquit, Pardon} and
{Arrest-Jail, Trial-Hearing, Charge-Indict, Sue,
Convict, Sentence, Fine}2, and they match one of
the following rules, then we propagate the time
argument between them.
</bodyText>
<listItem confidence="0.9497635">
• Rule1: Same-Sentence Propagation
EMi and EMj are in the same sentence and
only one time expression exists in the sen-
tence; This follows the within-sentence infer-
ence idea in (Lapata and Lascarides, 2006).
• Rule2: Relevant-Type Propagation
argi is coreferential with argj;
typei= “Conflict”, typej= “Life-Die/Life-
Injure”;
rolei=“Target” and rolej=“Victim”, or
rolei=rolej=“Instrument”.
• Rule3: Same-Type Propagation
</listItem>
<bodyText confidence="0.97550975">
argi is coreferential with argj, typei= typej,
rolei= rolej, and they match one of the Time-
Cue event type and argument role combina-
tions in Table 1.
</bodyText>
<table confidence="0.99976725">
Event Typei Argument Rolei
Conflict Target/Attacker/Crime
Justice Defendant/Crime/Plantiff
Life-Die/Life-Injure Victim
Life-Be-Born/Life- Person/Entity
Marry/Life-Divorce
Movement-Transport Destination/Origin
Transaction Buyer/Seller/Giver/
Recipient
Contact Person/Entity
Personnel Person/Entity
Business Organization/Entity
</table>
<tableCaption confidence="0.9313205">
Table 1. Time-Cue Event Types and
Argument Roles
</tableCaption>
<bodyText confidence="0.996309">
The combinations shown in Table 1 above are
those informative arguments that are specific
enough to indicate the event time, thus they are
</bodyText>
<footnote confidence="0.5630355">
2 Statistically there is often a time gap between these
two groups of events.
</footnote>
<page confidence="0.992087">
370
</page>
<bodyText confidence="0.998703666666667">
called “Time-Cue” roles. For example, in a
“Conflict-Attack” event, “Attacker” and “Tar-
get” are more important than “Person” to indi-
cate the event time. The general idea is similar to
extracting the cue phrases for text summarization
(Edmundson, 1969).
</bodyText>
<subsectionHeader confidence="0.993433">
4.2 Statistical Learning based Prediction
</subsectionHeader>
<bodyText confidence="0.9700907">
In addition, we take a more general statistical
approach to capture the cross-event relations and
predict unknown time arguments. We manually
labeled some ACE data and trained a Maximum
Entropy classifier to determine whether to
propagate the time argument of EMi to EMj or
not. The features in this classifier are most de-
rived from the rules in the above section 4.1.
Following Rule 1, we build the following two
features:
</bodyText>
<listItem confidence="0.9804375">
• Feature1: Same-Sentence
F_SameSentence: whether EMi and EMj are
located in the same sentence or not.
• Feature2: Number of Time Arguments
</listItem>
<bodyText confidence="0.993223">
F_TimeNum: if F_SameSentence = true, then
assign the number of time arguments in the
sentence, otherwise assign the feature value as
“Empty”.
For all the Time-Cue argument role pairs in
Rule 2 and Rule 3, we construct a set of features:
</bodyText>
<listItem confidence="0.9023364">
• Feature Set3: Time-Cue Argument Role
Matching
F_CueRoleij: Construct a feature for any pair
of Time-Cue role types Rolei and Rolej in Rule
2 and 3, assign the feature value as follows:
</listItem>
<bodyText confidence="0.999326666666667">
if the argument argi in EMi has a role Rolei
and the argument argj has a role Rolej:
if argi and argj are coreferential then
</bodyText>
<equation confidence="0.815932">
F_CueRoleij = Coreferential,
else F_CueRoleij = Non-Coreferential.
else F_CueRoleij = Empty.
</equation>
<sectionHeader confidence="0.997161" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999884666666667">
In this section we present the results of applying
these two approaches to predict unknown event
time arguments.
</bodyText>
<subsectionHeader confidence="0.983975">
5.1 Data and Answer-Key Annotation
</subsectionHeader>
<bodyText confidence="0.999983941176471">
We used 47 newswire texts from ACE 2005
training corpora to train the Maximum Entropy
classifier, and conduct blind test on a separate set
of 10 ACE 2005 newswire texts. For each docu-
ment we constructed any pair of event mentions
&lt;EMi, EMj&gt; as a candidate sample if EMi in-
cludes a time argument while EMj and its
coreferential event mentions don’t include any
time arguments. We then manually labeled
“Propagate/Not-Propagate” for each sample. The
annotation for both training and test sets took one
human annotator about 10 hours. We asked an-
other annotator to label the 10 test texts sepa-
rately and the inter-annotator agreement is above
95%. There are 485 “Propagate” samples and
617 “Not-Propagate” samples in the training set;
and in total 212 samples in the test set.
</bodyText>
<subsectionHeader confidence="0.999624">
5.2 Overall Performance
</subsectionHeader>
<bodyText confidence="0.989584">
Table 2 presents the overall Precision (P), Recall
(R) and F-Measure (F) of using these two differ-
ent approaches.
</bodyText>
<table confidence="0.994629666666667">
Method P (%) R (%) F(%)
Rule-based 70.40 74.06 72.18
Statistical Learning 72.48 50.94 59.83
</table>
<tableCaption confidence="0.999519">
Table 2. Overall Performance
</tableCaption>
<bodyText confidence="0.9985066">
The results of the rule-based approach are
promising: we are able to correctly predict 74%
of the unknown event time arguments at about
30% error rate. The most common correctly
propagated pairs are:
</bodyText>
<listItem confidence="0.996660333333333">
• From Conflict-Attack to Life-Die/Life-Injure
• From Justice Convict to Justice-Sentence/
Justice-Charge-Indict
• From Movement-Transport to Contact-Meet
• From Justice-Charge-Indict to Justice-
Convict
</listItem>
<subsectionHeader confidence="0.978811">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999981789473684">
From Table 2 we can see that the rule-based ap-
proach achieved 23% higher recall than the sta-
tistical classifier, with only 2% lower precision.
The reason is that we don’t have enough training
data to capture all the evidences from different
Time-cue roles. For instance, for the Example 2
in section 3, Rule 3 is able to predict the time
argument of the “Justice-Sentence” event as
“Saturday (normalized as 2003-05-10)” because
these two events share the coreferential Time-cue
“Defendant” arguments “newspaper” and “Moni-
tor”. However, there is only one positive sample
matching these conditions in the training corpora,
and thus the Maximum Entropy classifier as-
signed a very low confidence score for propaga-
tion. We have also tried to combine these two
approaches in a self-training framework – adding
the results from the propagation rules as addi-
tional training data and re-train the Maximum
</bodyText>
<page confidence="0.99694">
371
</page>
<bodyText confidence="0.988076142857143">
Entropy classifier, but it did not provide further
improvement.
The spurious errors made by the prediction
rules reveal both the shortcomings of ignoring
event reporting order and the restricted matching
on event arguments.
For example, in the following sentences:
[Context Sentence]
American troops stormed a presidential palace and
other key buildings in Baghdad as U.S. tanks rum-
bled into the heart of the battered Iraqi capital on
Monday amid the thunder of gunfire and explo-
sions...
[Sentence including EMj]
At the palace compound, Iraqis shot &lt;instru-
ment&gt;small arms&lt;/instrument&gt; fire from a clock
tower, which the U.S. tanks quickly destroyed.
[Sentence including EMi]
The first one was on Saturday and triggered in-
tense &lt;instrument&gt;gun&lt;/instrument&gt; battles,
which according to some U.S. accounts, left at least
2,000 Iraqi fighters dead.
The time argument “Saturday” was mistakenly
propagated from the “Conflict-Attack” event
“battles” to “shot” because they share the same
Time-cue role “instrument” (“small arms/gun”).
However, the correct time argument for the
“shot” event should be “Monday” as indicated in
the “gunfire/explosions” event in the previous
context sentence. But since the “shot” event
doesn’t share any arguments with “gun-
fire/explosions”, our approach failed to obtain
any evidence for propagating “Monday”. In the
future we plan to incorporate the distance and
event reporting order as additional features and
constraints.
Nevertheless, as Table 2 indicates, the rewards
of using propagation rules outweigh the risks
because it can successfully predict a lot of un-
known time arguments which were not possible
using the traditional time argument extraction
techniques.
</bodyText>
<sectionHeader confidence="0.997033" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9992796">
In this paper we described two approaches to
predict unknown time arguments based on the
inference and propagation between related events.
In the future we shall improve the confidence
estimation of the Maximum Entropy classifier so
that we could incorporate dynamic features from
the high-confidence time arguments which have
already been predicted. We also plan to test the
effectiveness of this system in textual inference,
temporal event linking and event coreference
resolution. We are also interested in extending
these approaches to the setting of cross-
document, so that we can predict more time ar-
guments based on the background knowledge
from related documents.
</bodyText>
<sectionHeader confidence="0.997337" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.7385448">
This material is based upon work supported by
the Defense Advanced Research Projects Agency
under Contract No. HR0011-06-C-0023 via 27-
001022, and the CUNY Research Enhancement
Program and GRTI Program.
</bodyText>
<sectionHeader confidence="0.978769" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999668868421053">
David Ahn, Steven Schockaert, Martine De Cock and
Etienne Kerre. 2006. Supporting Temporal Ques-
tion Answering: Strategies for Offline Data Collec-
tion. Proc. 5th International Workshop on Infer-
ence in Computational Semantics (ICoS-5).
Regina Barzilay, Noemie Elhadad and Kathleen
McKeown. 2002. Inferring Strategies for Sentence
Ordering in Multidocument Summarization. JAIR,
17:35-55.
Chitta Baral, Gregory Gelfond, Michael Gelfond and
Richard B. Scherl. 2005. Proc. AAAI&apos;05 Workshop
on Inference for Textual Question Answering.
Steven Bethard, James H. Martin and Sara Klingen-
stein. 2007. Finding Temporal Structure in Text:
Machine Learning of Syntactic Temporal Relations.
International Journal of Semantic Computing
(IJSC), 1(4), December 2007.
Nathanael Chambers, Shan Wang and Dan Jurafsky.
2007. Classifying Temporal Relations Between
Events. Proc. ACL2007.
H. P. Edmundson. 1969. New Methods in Automatic
Extracting. Journal of the ACM. 16(2):264-285.
Vladimir Eidelman. 2008. Inferring Activity Time in
News through Event Modeling. Proc. ACL-HLT
2008.
Elena Filatova and Eduard Hovy. 2001. Assigning
Time-Stamps to Event-Clauses. Proc. ACL 2001
Workshop on Temporal and Spatial Information
Processing.
Heng Ji and Zheng Chen. 2009. Cross-document
Temporal and Spatial Person Tracking System
Demonstration. Proc. HLT-NAACL 2009.
Mirella Lapata and Alex Lascarides. 2006. Learning
Sentence-internal Temporal Relations. Journal of
Artificial Intelligence Research 27. pp. 85-117.
Inderjeet Mani, Barry Schiffman and Jianping Zhang.
2003. Inferring Temporal Ordering of Events in
News. Proc. HLT-NAACL 2003.
</reference>
<page confidence="0.998347">
372
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.511748">
<title confidence="0.99931">Predicting Unknown Time Arguments based on Cross-Event Propagation</title>
<author confidence="0.994116">Prashant Gupta Heng Ji</author>
<affiliation confidence="0.998423">Indian Institute of Information Computer Science Department, Queens College and</affiliation>
<address confidence="0.8007115">Technology Allahabad the Graduate Center, City University of New York Allahabad, India, 211012 New York, NY, 11367, USA</address>
<email confidence="0.999718">greatprach@gmail.comhengji@cs.qc.cuny.edu</email>
<abstract confidence="0.986407181818182">Many events in news articles don’t include time arguments. This paper describes two methods, one based on rules and the other based on statistical learning, to predict the unknown time argument for an event by the propagation from its related events. The results are promising – the rule based approach was able to correctly predict 74% of the unknown event time arguments with 70% precision.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Ahn</author>
<author>Steven Schockaert</author>
<author>Martine De Cock</author>
<author>Etienne Kerre</author>
</authors>
<title>Supporting Temporal Question Answering: Strategies for Offline Data Collection.</title>
<date>2006</date>
<booktitle>Proc. 5th International Workshop on Inference in Computational Semantics (ICoS-5).</booktitle>
<marker>Ahn, Schockaert, De Cock, Kerre, 2006</marker>
<rawString>David Ahn, Steven Schockaert, Martine De Cock and Etienne Kerre. 2006. Supporting Temporal Question Answering: Strategies for Offline Data Collection. Proc. 5th International Workshop on Inference in Computational Semantics (ICoS-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen McKeown</author>
</authors>
<title>Inferring Strategies for Sentence Ordering in Multidocument Summarization.</title>
<date>2002</date>
<pages>17--35</pages>
<publisher>JAIR,</publisher>
<marker>Barzilay, Elhadad, McKeown, 2002</marker>
<rawString>Regina Barzilay, Noemie Elhadad and Kathleen McKeown. 2002. Inferring Strategies for Sentence Ordering in Multidocument Summarization. JAIR, 17:35-55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chitta Baral</author>
<author>Gregory Gelfond</author>
<author>Michael Gelfond</author>
<author>Richard B Scherl</author>
</authors>
<date>2005</date>
<booktitle>Proc. AAAI&apos;05 Workshop on Inference for Textual Question Answering.</booktitle>
<contexts>
<context position="864" citStr="Baral et al., 2005" startWordPosition="128" endWordPosition="131">abad, India, 211012 New York, NY, 11367, USA greatprach@gmail.com hengji@cs.qc.cuny.edu Abstract Many events in news articles don’t include time arguments. This paper describes two methods, one based on rules and the other based on statistical learning, to predict the unknown time argument for an event by the propagation from its related events. The results are promising – the rule based approach was able to correctly predict 74% of the unknown event time arguments with 70% precision. 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into to</context>
</contexts>
<marker>Baral, Gelfond, Gelfond, Scherl, 2005</marker>
<rawString>Chitta Baral, Gregory Gelfond, Michael Gelfond and Richard B. Scherl. 2005. Proc. AAAI&apos;05 Workshop on Inference for Textual Question Answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
<author>James H Martin</author>
<author>Sara Klingenstein</author>
</authors>
<title>Finding Temporal Structure in Text: Machine Learning of Syntactic Temporal Relations.</title>
<date>2007</date>
<journal>International Journal of Semantic Computing (IJSC),</journal>
<volume>1</volume>
<issue>4</issue>
<contexts>
<context position="978" citStr="Bethard et al., 2007" startWordPosition="145" endWordPosition="148">ews articles don’t include time arguments. This paper describes two methods, one based on rules and the other based on statistical learning, to predict the unknown time argument for an event by the propagation from its related events. The results are promising – the rule based approach was able to correctly predict 74% of the unknown event time arguments with 70% precision. 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with </context>
</contexts>
<marker>Bethard, Martin, Klingenstein, 2007</marker>
<rawString>Steven Bethard, James H. Martin and Sara Klingenstein. 2007. Finding Temporal Structure in Text: Machine Learning of Syntactic Temporal Relations. International Journal of Semantic Computing (IJSC), 1(4), December 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Shan Wang</author>
<author>Dan Jurafsky</author>
</authors>
<title>Classifying Temporal Relations Between Events.</title>
<date>2007</date>
<booktitle>Proc. ACL2007.</booktitle>
<contexts>
<context position="1001" citStr="Chambers et al., 2007" startWordPosition="149" endWordPosition="153">lude time arguments. This paper describes two methods, one based on rules and the other based on statistical learning, to predict the unknown time argument for an event by the propagation from its related events. The results are promising – the rule based approach was able to correctly predict 74% of the unknown event time arguments with 70% precision. 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with different time argument</context>
</contexts>
<marker>Chambers, Wang, Jurafsky, 2007</marker>
<rawString>Nathanael Chambers, Shan Wang and Dan Jurafsky. 2007. Classifying Temporal Relations Between Events. Proc. ACL2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Edmundson</author>
</authors>
<title>New Methods in Automatic Extracting.</title>
<date>1969</date>
<journal>Journal of the ACM.</journal>
<pages>16--2</pages>
<contexts>
<context position="7918" citStr="Edmundson, 1969" startWordPosition="1213" endWordPosition="1214">er/Giver/ Recipient Contact Person/Entity Personnel Person/Entity Business Organization/Entity Table 1. Time-Cue Event Types and Argument Roles The combinations shown in Table 1 above are those informative arguments that are specific enough to indicate the event time, thus they are 2 Statistically there is often a time gap between these two groups of events. 370 called “Time-Cue” roles. For example, in a “Conflict-Attack” event, “Attacker” and “Target” are more important than “Person” to indicate the event time. The general idea is similar to extracting the cue phrases for text summarization (Edmundson, 1969). 4.2 Statistical Learning based Prediction In addition, we take a more general statistical approach to capture the cross-event relations and predict unknown time arguments. We manually labeled some ACE data and trained a Maximum Entropy classifier to determine whether to propagate the time argument of EMi to EMj or not. The features in this classifier are most derived from the rules in the above section 4.1. Following Rule 1, we build the following two features: • Feature1: Same-Sentence F_SameSentence: whether EMi and EMj are located in the same sentence or not. • Feature2: Number of Time Ar</context>
</contexts>
<marker>Edmundson, 1969</marker>
<rawString>H. P. Edmundson. 1969. New Methods in Automatic Extracting. Journal of the ACM. 16(2):264-285.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Eidelman</author>
</authors>
<title>Inferring Activity Time in News through Event Modeling.</title>
<date>2008</date>
<booktitle>Proc. ACL-HLT</booktitle>
<contexts>
<context position="1378" citStr="Eidelman, 2008" startWordPosition="213" endWordPosition="214">gument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with different time arguments. And it was not clear how the errors of topic clustering techniques affected the inference scheme. Therefore it will be valuable to design inference methods for more fine-grained events. In addition, in the previous approaches the linguistic evidences such as verb tense were mainly applied for inferring the exact dates of implicit time expressions. In this paper we are int</context>
</contexts>
<marker>Eidelman, 2008</marker>
<rawString>Vladimir Eidelman. 2008. Inferring Activity Time in News through Event Modeling. Proc. ACL-HLT 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Filatova</author>
<author>Eduard Hovy</author>
</authors>
<title>Assigning Time-Stamps to Event-Clauses.</title>
<date>2001</date>
<booktitle>Proc. ACL 2001 Workshop on Temporal and Spatial Information Processing.</booktitle>
<contexts>
<context position="1313" citStr="Filatova and Hovy, 2001" startWordPosition="201" endWordPosition="204">own event time arguments with 70% precision. 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with different time arguments. And it was not clear how the errors of topic clustering techniques affected the inference scheme. Therefore it will be valuable to design inference methods for more fine-grained events. In addition, in the previous approaches the linguistic evidences such as verb tense were mainly applied for inferring the e</context>
</contexts>
<marker>Filatova, Hovy, 2001</marker>
<rawString>Elena Filatova and Eduard Hovy. 2001. Assigning Time-Stamps to Event-Clauses. Proc. ACL 2001 Workshop on Temporal and Spatial Information Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Zheng Chen</author>
</authors>
<title>Cross-document Temporal and Spatial Person Tracking System Demonstration.</title>
<date>2009</date>
<booktitle>Proc. HLT-NAACL</booktitle>
<contexts>
<context position="1021" citStr="Ji and Chen, 2009" startWordPosition="154" endWordPosition="157">is paper describes two methods, one based on rules and the other based on statistical learning, to predict the unknown time argument for an event by the propagation from its related events. The results are promising – the rule based approach was able to correctly predict 74% of the unknown event time arguments with 70% precision. 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with different time arguments. And it was not cl</context>
</contexts>
<marker>Ji, Chen, 2009</marker>
<rawString>Heng Ji and Zheng Chen. 2009. Cross-document Temporal and Spatial Person Tracking System Demonstration. Proc. HLT-NAACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Learning Sentence-internal Temporal Relations.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research</journal>
<volume>27</volume>
<pages>85--117</pages>
<contexts>
<context position="1361" citStr="Lapata and Lascarides, 2006" startWordPosition="209" endWordPosition="212"> 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with different time arguments. And it was not clear how the errors of topic clustering techniques affected the inference scheme. Therefore it will be valuable to design inference methods for more fine-grained events. In addition, in the previous approaches the linguistic evidences such as verb tense were mainly applied for inferring the exact dates of implicit time expressions. In this</context>
<context position="6708" citStr="Lapata and Lascarides, 2006" startWordPosition="1052" endWordPosition="1055">cludes an argument argi with role rolei, while EMj has an event type typej and includes an argument argj with role rolej, they are not from two temporally separate groups of Justice events {Release-Parole, Appeal, Execute, Extradite, Acquit, Pardon} and {Arrest-Jail, Trial-Hearing, Charge-Indict, Sue, Convict, Sentence, Fine}2, and they match one of the following rules, then we propagate the time argument between them. • Rule1: Same-Sentence Propagation EMi and EMj are in the same sentence and only one time expression exists in the sentence; This follows the within-sentence inference idea in (Lapata and Lascarides, 2006). • Rule2: Relevant-Type Propagation argi is coreferential with argj; typei= “Conflict”, typej= “Life-Die/LifeInjure”; rolei=“Target” and rolej=“Victim”, or rolei=rolej=“Instrument”. • Rule3: Same-Type Propagation argi is coreferential with argj, typei= typej, rolei= rolej, and they match one of the TimeCue event type and argument role combinations in Table 1. Event Typei Argument Rolei Conflict Target/Attacker/Crime Justice Defendant/Crime/Plantiff Life-Die/Life-Injure Victim Life-Be-Born/Life- Person/Entity Marry/Life-Divorce Movement-Transport Destination/Origin Transaction Buyer/Seller/Giv</context>
</contexts>
<marker>Lapata, Lascarides, 2006</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2006. Learning Sentence-internal Temporal Relations. Journal of Artificial Intelligence Research 27. pp. 85-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>Barry Schiffman</author>
<author>Jianping Zhang</author>
</authors>
<title>Inferring Temporal Ordering of Events in News.</title>
<date>2003</date>
<booktitle>Proc. HLT-NAACL</booktitle>
<contexts>
<context position="1332" citStr="Mani et al., 2003" startWordPosition="205" endWordPosition="208">with 70% precision. 1 Introduction Event time argument detection is important to many NLP applications such as textual inference (Baral et al., 2005), multi-document text summarization (e.g. Barzilay e al., 2002), temporal event linking (e.g. Bethard et al., 2007; Chambers et al., 2007; Ji and Chen, 2009) and template based question answering (Ahn et al., 2006). It’s a challenging task in particular because about half of the event instances don’t include explicit time arguments. Various methods have been exploited to identify or infer the implicit time arguments (e.g. Filatova and Hovy, 2001; Mani et al., 2003; Lapata and Lascarides, 2006; Eidelman, 2008). Most of the prior work focused on the sentence level by clustering sentences into topics and ordering sentences on a time line. However, many sentences in news articles include multiple events with different time arguments. And it was not clear how the errors of topic clustering techniques affected the inference scheme. Therefore it will be valuable to design inference methods for more fine-grained events. In addition, in the previous approaches the linguistic evidences such as verb tense were mainly applied for inferring the exact dates of impli</context>
</contexts>
<marker>Mani, Schiffman, Zhang, 2003</marker>
<rawString>Inderjeet Mani, Barry Schiffman and Jianping Zhang. 2003. Inferring Temporal Ordering of Events in News. Proc. HLT-NAACL 2003.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>