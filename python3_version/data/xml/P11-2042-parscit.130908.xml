<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.985008">
Data-oriented Monologue-to-Dialogue Generation
</title>
<author confidence="0.994072">
Paul Piwek
</author>
<affiliation confidence="0.871687666666667">
Centre for Research in Computing
The Open University
Walton Hall, Milton Keynes, UK
</affiliation>
<email confidence="0.992378">
p.piwek@open.ac.uk
</email>
<author confidence="0.929132">
Svetlana Stoyanchev
</author>
<affiliation confidence="0.704288666666667">
Centre for Research in Computing
The Open University
Walton Hall, Milton Keynes, UK
</affiliation>
<email confidence="0.996396">
s.stoyanchev@open.ac.uk
</email>
<sectionHeader confidence="0.993713" genericHeader="abstract">
Abstract
</sectionHeader>
<subsectionHeader confidence="0.553106">
This short paper introduces an implemented
</subsectionHeader>
<figureCaption confidence="0.789072142857143">
and evaluated monolingual Text-to-Text gen-
eration system. The system takes mono-
logue and transforms it to two-participant di-
alogue. After briefly motivating the task
of monologue-to-dialogue generation, we de-
scribe the system and present an evaluation in
terms of fluency and accuracy.
</figureCaption>
<sectionHeader confidence="0.996732" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.994340787878788">
Several empirical studies show that delivering in-
formation in the form of a dialogue, as opposed to
monologue, can be particularly effective for educa-
tion (Craig et al., 2000; Lee et al., 1998) and per-
suasion (Suzuki and Yamada, 2004). Information-
delivering or expository dialogue was already em-
ployed by Plato to communicate his philosophy. It
is used primarily to convey information and possibly
also make an argument; this in contrast with dra-
matic dialogue which focuses on character develop-
ment and narrative.
Expository dialogue lends itself well for presenta-
tion through computer-animated agents (Prendinger
and Ishizuka, 2004). Most information is however
locked up as text in leaflets, books, newspapers,
etc. Automatic generation of dialogue from text in
monologue makes it possible to convert information
into dialogue as and when needed.
This paper describes the first data-oriented
monologue-to-dialogue generation system which re-
lies on the automatic mapping of the discourse
relations underlying monologue to appropriate se-
242
quences of dialogue acts. The approach is data-
oriented in that the mapping rules have been auto-
matically derived from an annotated parallel mono-
logue/dialogue corpus, rather than being hand-
crafted.
The paper proceeds as follows. Section 2 reviews
existing approaches to dialogue generation. Section
3 describes the current approach. We provide an
evaluation in Section 4. Finally, Section 5 describes
our conclusions and plans for further research.
</bodyText>
<sectionHeader confidence="0.999748" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.977448463414634">
For the past decade, generation of information-
delivering dialogues has been approached primarily
as an AI planning task. Andr´e et al. (2000) describe
a system, based on a centralised dialogue planner,
that creates dialogues between a virtual car buyer
and seller from a database; this approach has been
extended by van Deemter et al. (2008). Others have
used (semi-) autonomous agents for dialogue gener-
ation (Cavazza and Charles, 2005; Mateas and Stern,
2005).
More recently, first steps have been taken towards
treating dialogue generation as an instance of Text-
to-Text generation (Rus et al., 2007). In particu-
lar, the T2D system (Piwek et al., 2007) employs
rules that map text annotated with discourse struc-
tures, along the lines of Rhetorical Structure Theory
(Mann and Thompson, 1988), to specific dialogue
sequences. Common to all the approaches discussed
so far has been the manual creation of generation
resources, whether it be mappings from knowledge
representations or discourse to dialogue structure.
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242–247,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
With the creation of the publicly available1 CODA
parallel corpus of monologue and dialogue (Stoy-
anchev and Piwek, 2010a), it has, however, become
possible to adopt a data-oriented approach. This cor-
pus consists of approximately 700 turns of dialogue,
by acclaimed authors such as Mark Twain, that are
aligned with monologue that was written on the ba-
sis of the dialogue, with the specific aim to express
the same information as the dialogue.2 The mono-
logue side has been annotated with discourse rela-
tions, using an adaptation of the annotation guide-
lines of Carlson and Marcu (2001), whereas the di-
alogue side has been marked up with dialogue acts,
using tags inspired by the schemes of Bunt (2000),
Carletta et al. (1997) and Core and Allen (1997).
As we will describe in the next section, our ap-
proach uses the CODA corpus to extract mappings
from monologue to dialogue.
</bodyText>
<sectionHeader confidence="0.995966" genericHeader="method">
3 Monologue-to-Dialogue Generation
Approach
</sectionHeader>
<bodyText confidence="0.985025875">
Our approach is based on five principal steps:
I Discourse parsing: analysis of the input mono-
logue in terms of the underlying discourse rela-
tions.
II Relation conversion: mapping of text annotated
with discourse relations to a sequence of dia-
logue acts, with segments of the input text as-
signed to corresponding dialogue acts.
</bodyText>
<listItem confidence="0.657111875">
III Verbalisation: verbal realisation of dialogue
acts based on the dialogue act type and text of
the corresponding monologue segment.
IV Combination Putting the verbalised dialogues
acts together to create a complete dialogue, and
V Presentation: Rendering of the dialogue (this
can range for simple textual dialogue scripts to
computer-animated spoken dialogue).
</listItem>
<bodyText confidence="0.979832642857143">
1computing.open.ac.uk/coda/data.html
2Consequently, the corpus was not constructed entirely of
pre-existing text; some of the text was authored as part of the
corpus construction. One could therefore argue, as one of the re-
viewers for this paper did, that the approach is not entirely data-
driven, if data-driven is interpreted as ‘generated from unadul-
terated, free text, without any human intervention needed’.
For step I we rely on human annotation or existing
discourse parsers such as DAS (Le and Abeysinghe,
2003) and HILDA (duVerle and Prendinger, 2009).
For the current study, the final step, V, consists sim-
ply of verbatim presentation of the dialogue text.
The focus of the current paper is with steps II and
III (with combination, step IV, beyond the scope of
the current paper). Step II is data-oriented in that
we have extracted mappings from discourse relation
occurrences in the corpus to corresponding dialogue
act sequences, following the approach described in
Piwek and Stoyanchev (2010). Stoyanchev and Pi-
wek (2010b) observed in the CODA corpus a great
variety of Dialogue Act (DA) sequences that could
be used in step II, however in the current version
of the system we selected a representative set of the
most frequent DA sequences for the five most com-
mon discourse relations in the corpus. Table 1 shows
the mapping from text with a discourse relations
to dialogue act sequences (i indicates implemented
mappings).
</bodyText>
<table confidence="0.999279909090909">
DA sequence A C C E M TR
D T R M T
YNQ; Expl i i d
YNQ; Yes; Expl i i i d
Expl; CmplQ; Expl i d
ComplQ; Expl i/t i/t i i c
Expl; YNQ;Yes i d
Expl; Contrad. i d
FactQ; FactA; Expl i c
Expl; Agr; Expl i d
Expl; Fact; Expl t c
</table>
<tableCaption confidence="0.9788314">
Table 1: Mappings from discourse relations (A = Attribu-
tion, CD = Condition, CT = Contrast, ER = Explanation-
Reason, MM = Manner-Means) to dialogue act sequences
(explained below) together with the type of verbalisation
transformation TR being d(irect) or c(omplex).
</tableCaption>
<bodyText confidence="0.99993525">
For comparison, the table also shows the much
less varied mappings implemented by the T2D sys-
tem (indicated with t). Note that the actual mappings
of the T2D system are directly from discourse rela-
tion to dialogue text. The dialogue acts are not ex-
plicitly represented by the system, in contrast with
the current two stage approach which distinguishes
between relation conversion and verbalisation.
</bodyText>
<page confidence="0.921737">
243
</page>
<bodyText confidence="0.8346866">
Verbalisation, step III, takes a dialogue act type 4 Evaluation
and the specification of its semantic content as given We evaluate the output generated with both complex
by the input monologue text. Mapping this to the and direct rules for the relations of Table 1.
appropriate dialogue act requires mappings that vary
in complexity.
For example, Expl(ain) can be generated by sim-
ply copying a monologue segment to dialogue utter-
ance. The dialogue acts Yes and Agreement can be
generated using canned text, such as “That is true”
and “I agree with you”.
</bodyText>
<table confidence="0.845677615384615">
In contrast, ComplQ (Complex Question), FactQ
(Factoid Question), FactA (Factiod Answer) and
YNQ (Yes/No Question) all require syntactic ma-
nipulation. To generate YNQ and FactQ, we use
the CMU Question Generation tool (Heilman and
Smith, 2010) which is based on a combination
of syntactic transformation rules implemented with
tregex (Levy and Andrew, 2006) and statistical
methods. To generate the Compl(ex) Q(uestion) in
the ComplQ;Expl Dialogue Act (DA) sequence, we
use a combination of the CMU tool and lexical trans-
formation rules.3 The GEN example in Table 2 il-
lustrates this: The input monologue has a Manner-
Means relations between the nucleus ‘In September,
Ashland settled the long-simmering dispute’ and the
satellite ‘by agreeing to pay Iran 325 million USD’.
The satellite is copied without alteration to the Ex-
plain dialogue act. The nucleus is processed by ap-
plying the following template-based rule:
Decl ==&gt;. How Yes/No Question(Decl)
In words, the input consisting of a declarative sen-
tence is mapped to a sequence consisting of the word
‘How’ followed by a Yes/No-question (in this case
“Did Ashland settle the long-simmering dispute in
December?’) that is obtained with the CMU QG tool
from the declarative input sentence. A similar ap-
proach is applied for the other relations (Attribution,
Condition and Explanation-Reason) that can lead to
a ComplQ; Expl dialogue act sequence (see Table 1).
Generally, sequences requiring only copying or
canned text are labelled d(irect) in Table 1, whereas
those requiring syntactic transformation are labelled
c(omplex).
4.1 Materials, Judges and Procedure
The input monologues were text excerpts from the
Wall Street Journal as annotated in the RST Dis-
course Treebank4. They consisted of a single sen-
tence with one internal relation, or two sentences
(with no internal relations) connected by a single
</table>
<bodyText confidence="0.904908129032258">
relation. To factor out the quality of the discourse
annotations, we used the gold standard annotations
of the Discourse Treebank and checked these for
correctness, discarding a small number of incorrect
annotations.5 We included text fragments with a
variety of clause length, ordering of nucleus and
satellite, and syntactic structure of clauses. Table 2
shows examples of monologue/dialogue pairs: one
with a generated dialogue and the other from the cor-
pus.
Our study involved a panel of four judges, each
fluent speakers of English (three native) and ex-
perts in Natural Language Generation. We collected
judgements on 53 pairs of monologue and corre-
sponding dialogue. 19 pairs were judged by all four
judges to obtain inter-annotator agreement statistics,
the remainder was parcelled out. 38 pairs consisted
of WSJ monologue and generated dialogue, hence-
forth GEN, and 15 pairs of CODA corpus monologue
and human-authored dialogue, henceforth CORPUS
(instances of generated and corpus dialogue were
randomly interleaved) – see Table 2 for examples.
The two standard evaluation measures for lan-
guage generation, accuracy and fluency (Mellish and
Dale, 1998), were used: a) accuracy: whether a
dialogue (from GEN or CORPUS) preserves the in-
formation of the corresponding monologue (judge-
ment: ‘Yes’ or ‘No’) and b) monologue and dialogue
fluency: how well written a piece of monologue or
dialogue from GEN or CORPUS is. Fluency judge-
ments were on a scale from 1 ‘incomprehensible’ to
</bodyText>
<footnote confidence="0.521301">
5 ‘Comprehensible, grammatically correct and nat-
urally sounding’.
4www.isi.edu/∼marcu/discourse/Corpora.html
5For instance, in our view ‘without wondering’ is incorrectly
connected with the attribution relation to ‘whether she is mov-
ing as gracefully as the scenery.’
3In contrast, the ComplQ in the DA sequence
</footnote>
<table confidence="0.8652563">
Expl;ComplQ;Expl is generated using canned text such as
‘Why?’ or ‘Why is that?’.
244
GEN Monologue
In September, Ashland settled the
long-simmering dispute by agreeing to
pay Iran 325 million USD.
Dialogue (ComplQ; Expl)
A: How did Ashland settle the
long-simmering dispute in December?
</table>
<figure confidence="0.685824333333333">
B: By agreeing to pay Iran 325
million USD.
CORPUS Monologue
If you say “I believe the world is
round”, the “I” is the mind.
Dialogue (FactQ; FactA)
A: If you say “I believe the world is round”,
who is the “I” that is speaking?
B: The mind.
</figure>
<figureCaption confidence="0.990802333333333">
Figure 1: Mean Fluency Rating for Monologues and Dia-
logues (for 15 CORPUS and 38 GEN instances) with 95%
confidence intervals
</figureCaption>
<tableCaption confidence="0.963864">
Table 2: Monologue-Dialogue Instances
</tableCaption>
<sectionHeader confidence="0.695976" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.999944521739131">
Accuracy Three of the four judges marked 90%
of monologue-dialogue pairs as presenting the same
information (with pairwise K of .64, .45 and .31).
One judge interpreted the question differently and
marked only 39% of pairs as containing the same
information. We treated this as an outlier, and ex-
cluded the accuracy data of this judge. For the in-
stances marked by more than one judge, we took the
majority vote. We found that 12 out of 13 instances
(or 92%) of dialogue and monologue pairs from the
CORPUS benchmark sample were judged to contain
the same information. For the GEN monologue-
dialogue pairs, 28 out of 31 (90%) were judged to
contain the same information.
Fluency Although absolute agreement between
judges was low,6 pairwise agreement in terms of
Spearman rank correlation (p) is reasonable (aver-
age: .69, best: .91, worst: .56). For the subset of in-
stances with multiple annotations, we used the data
from the judge with the highest average pair-wise
agreement (p = .86)
The fluency ratings are summarised in Figure 1.
Judges ranked both monologues and dialogues for
</bodyText>
<footnote confidence="0.615457666666667">
6For the four judges, we had an average pairwise r, of .34
with the maximum and minimum values of .52 and .23, respec-
tively.
</footnote>
<bodyText confidence="0.999823555555556">
the GEN sample higher than for the CORPUS sam-
ple (possibly as a result of slightly greater length of
the CORPUS fragments and some use of archaic lan-
guage). However, the drop in fluency, see Figure 2,
from monologue to dialogue is greater for GEN sam-
ple (average: .89 points on the rating scale) than the
CORPUS sample (average: .33) (T-test p&lt;.05), sug-
gesting that there is scope for improving the genera-
tion algorithm.
</bodyText>
<figureCaption confidence="0.680248">
Figure 2: Fluency drop from monologue to correspond-
</figureCaption>
<bodyText confidence="0.8592024">
ing dialogue (for 15 CORPUS and 38 GEN instances). On
the x-axis the fluency drop is marked, starting from no
fluency drop (0) to a fluency drop of 3 (i.e., the dialogue
is rated 3 points less than the monologue on the rating
scale).
</bodyText>
<page confidence="0.97174">
245
</page>
<bodyText confidence="0.872186375">
Direct versus Complex rules We examined the be exploited to improve overall output quality.
difference in fluency drop between direct and com- In future research, we aim to evaluate the accu-
plex rules. Figure 3 shows that the drop in fluency racy and fluency of longer stretches of generated di-
for dialogues generated with complex rules is higher alogue. Additionally, we are currently carrying out
than for the dialogues generated using direct rules a task-related evaluation of monologue versus dia-
(T-test p&lt;.05). This suggests that use of direct rules logue to determine the utility of each.
is more likely to result in high quality dialogue. This Acknowledgements
is encouraging, given that Stoyanchev and Piwek We would like to thank the three anonymous
(2010a) report higher frequencies in professionally reviewers for their helpful comments and sug-
authored dialogues of dialogue acts (YNQ, Expl) that gestions. We are also grateful to our col-
can be dealt with using direct verbalisation (in con- leagues in the Open University’s Natural Lan-
trast with low frequency of, e.g., FactQ). guage Generation group for stimulating discussions
and feedback. The research reported in this pa-
per was carried out as part of the CODA re-
search project (http://computing.open.ac.uk/coda/)
which was funded by the UK’s Engineering and
</bodyText>
<table confidence="0.5655222">
Physical Sciences Research Council under Grant
EP/G020981/1.
References
E. Andr´e, T. Rist, S. van Mulken, M. Klesen, and
S. Baldes. 2000. The automated design of believable
dialogues for animated presentation teams. In Jus-
tine Cassell, Joseph Sullivan, Scott Prevost, and Eliz-
abeth Churchill, editors, Embodied Conversational
Agents, pages 220–255. MIT Press, Cambridge, Mas-
sachusetts.
H. Bunt. 2000. Dialogue pragmatics and context spec-
ification. In H. Bunt and W. Black, editors, Abduc-
tion, Belief and Context in Dialogue: Studies in Com-
putational Pragmatics, volume 1 of Natural Language
Processing, pages 81–150. John Benjamins.
</table>
<figureCaption confidence="0.9725751">
J. Carletta, A. Isard, S. Isard, J. Kowtko, G. Doherty-
Sneddon, and A. Anderson. 1997. The reliability of
a dialogue structure coding scheme. Computational
Linguistics, 23:13–31.
L. Carlson and D. Marcu. 2001. Discourse tagging
reference manual. Technical Report ISI-TR-545, ISI,
September.
M. Cavazza and F. Charles. 2005. Dialogue Gener-
ation in Character-based Interactive Storytelling. In
Proceedings of the AAAI First Annual Artificial Intel-
ligence and Interactive Digital Entertainment Confer-
ence, Marina Del Rey, California, USA.
M. Core and J. Allen. 1997. Coding Dialogs with
the DAMSL Annotation Scheme. In Working Notes:
AAAI Fall Symposium on Communicative Action in
Humans and Machine.
Figure 3: Decrease in Fluency Score from Monologue
to Dialogue comparing Direct (24 samples) and Complex
(14 samples) dialogue generation rules
5 Conclusions and Further Work
</figureCaption>
<bodyText confidence="0.851196176470588">
With information presentation in dialogue form be-
ing particularly suited for education and persua-
sion, the presented system is a step towards mak-
ing information from text automatically available
as dialogue. The system relies on discourse-to-
dialogue structure rules that were automatically ex-
tracted from a parallel monologue/dialogue corpus.
An evaluation against a benchmark sample from the
human-written corpus shows that both accuracy and
fluency of generated dialogues are not worse than
that of human-written dialogues. However, drop in
fluency between input monologue and output dia-
logue is slightly worse for generated dialogues than
for the benchmark sample. We also established a dif-
ference in quality of output generated with complex
versus direct discourse-to-dialogue rules, which can
246
</bodyText>
<reference confidence="0.996735">
S. Craig, B. Gholson, M. Ventura, A. Graesser, and the
Tutoring Research Group. 2000. Overhearing dia-
logues and monologues in virtual tutoring sessions.
International Journal of Artificial Intelligence in Ed-
ucation, 11:242–253.
D. duVerle and H. Prendinger. 2009. A novel discourse
parser based on support vector machines. In Proc 47th
Annual Meeting of the Association for Computational
Linguistics and the 4th Int’l Joint Conf on Natural
Language Processing of the Asian Federation of Nat-
ural Language Processing (ACL-IJCNLP’09), pages
665–673, Singapore, August.
M. Heilman and N. A. Smith. 2010. Good question!
statistical ranking for question generation. In Proc. of
NAACL/HLT, Los Angeles.
Huong T. Le and Geehta Abeysinghe. 2003. A study to
improve the efficiency of a discourse parsing system.
In Proceedings 4th International Conference on Intel-
ligent Text Processing and Computational Linguistics
(CICLing-03), Springer LNCS 2588, pages 101–114.
J. Lee, F. Dinneen, and J. McKendree. 1998. Supporting
student discussions: it isn’t just talk. Education and
Information Technologies, 3:217–229.
R. Levy and G. Andrew. 2006. Tregex and tsurgeon:
tools for querying and manipulating tree data struc-
tures. In 5th International Conference on Language
Resources and Evaluation (LREC 2006)., Genoa, Italy.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243–281.
M. Mateas and A. Stern. 2005. Structuring content in the
faade interactive drama architecture. In Proc. ofArtifi-
cial Intelligence and Interactive Digital Entertainment
(AIIDE), Marina del Rey, Los Angeles, June.
C. Mellish and R. Dale. 1998. Evaluation in the context
of natural language generation. Computer Speech and
Language, 12:349–373.
P. Piwek and S. Stoyanchev. 2010. Generating Exposi-
tory Dialogue from Monologue: Motivation, Corpus
and Preliminary Rules. In Human Language Tech-
nologies: The 2010 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 333–336, Los Angeles, Cali-
fornia, June.
P. Piwek, H. Hernault, H. Prendinger, and M. Ishizuka.
2007. T2D: Generating Dialogues between Virtual
Agents Automatically from Text. In Intelligent Vir-
tual Agents: Proceedings of IVA07, LNAI 4722, pages
161–174. Springer Verlag.
H. Prendinger and M. Ishizuka, editors. 2004. Life-Like
Characters: Tools, Affective Functions, and Applica-
tions. Cognitive Technologies Series. Springer, Berlin.
V. Rus, A. Graesser, A. Stent, M. Walker, and M. White.
2007. Text-to-Text Generation. In R. Dale and
M. White, editors, Shared Tasks and Comparative
Evaluation in Natural Language Generation: Work-
shop Report, Arlington, Virginia.
S. Stoyanchev and P. Piwek. 2010a. Constructing the
CODA corpus. In Procs of LREC 2010, Malta, May.
S. Stoyanchev and P. Piwek. 2010b. Harvesting re-usable
high-level rules for expository dialogue generation. In
6th International Natural Language Generation Con-
ference (INLG 2010), Dublin, Ireland, 7-8, July.
S. V. Suzuki and S. Yamada. 2004. Persuasion through
overheard communication by life-like agents. In Procs
of the 2004 IEEE/WIC/ACM International Conference
on Intelligent Agent Technology, Beijing, September.
K. van Deemter, B. Krenn, P. Piwek, M. Klesen,
M. Schroeder, and S. Baumann. 2008. Fully Gen-
erated Scripted Dialogue for Embodied Agents. Arti-
ficial Intelligence Journal, 172(10):1219–1244.
</reference>
<page confidence="0.997983">
247
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.185964">
<title confidence="0.999259">Data-oriented Monologue-to-Dialogue Generation</title>
<author confidence="0.98341">Paul</author>
<affiliation confidence="0.963863">Centre for Research in</affiliation>
<title confidence="0.689141">The Open</title>
<author confidence="0.912285">Walton Hall</author>
<author confidence="0.912285">Milton Keynes</author>
<email confidence="0.995751">p.piwek@open.ac.uk</email>
<title confidence="0.627660333333333">Svetlana Centre for Research in Computing The Open</title>
<author confidence="0.971698">Walton Hall</author>
<author confidence="0.971698">Milton Keynes</author>
<email confidence="0.998894">s.stoyanchev@open.ac.uk</email>
<abstract confidence="0.997316777777778">This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Craig</author>
<author>B Gholson</author>
<author>M Ventura</author>
<author>A Graesser</author>
</authors>
<title>and the Tutoring Research Group.</title>
<date>2000</date>
<journal>International Journal of Artificial Intelligence in Education,</journal>
<pages>11--242</pages>
<contexts>
<context position="816" citStr="Craig et al., 2000" startWordPosition="111" endWordPosition="114">ch in Computing The Open University Walton Hall, Milton Keynes, UK s.stoyanchev@open.ac.uk Abstract This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy. 1 Introduction Several empirical studies show that delivering information in the form of a dialogue, as opposed to monologue, can be particularly effective for education (Craig et al., 2000; Lee et al., 1998) and persuasion (Suzuki and Yamada, 2004). Informationdelivering or expository dialogue was already employed by Plato to communicate his philosophy. It is used primarily to convey information and possibly also make an argument; this in contrast with dramatic dialogue which focuses on character development and narrative. Expository dialogue lends itself well for presentation through computer-animated agents (Prendinger and Ishizuka, 2004). Most information is however locked up as text in leaflets, books, newspapers, etc. Automatic generation of dialogue from text in monologue</context>
</contexts>
<marker>Craig, Gholson, Ventura, Graesser, 2000</marker>
<rawString>S. Craig, B. Gholson, M. Ventura, A. Graesser, and the Tutoring Research Group. 2000. Overhearing dialogues and monologues in virtual tutoring sessions. International Journal of Artificial Intelligence in Education, 11:242–253.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D duVerle</author>
<author>H Prendinger</author>
</authors>
<title>A novel discourse parser based on support vector machines.</title>
<date>2009</date>
<booktitle>In Proc 47th Annual Meeting of the Association for Computational Linguistics and the 4th Int’l Joint Conf on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP’09),</booktitle>
<pages>665--673</pages>
<location>Singapore,</location>
<contexts>
<context position="5536" citStr="duVerle and Prendinger, 2009" startWordPosition="837" endWordPosition="840">imple textual dialogue scripts to computer-animated spoken dialogue). 1computing.open.ac.uk/coda/data.html 2Consequently, the corpus was not constructed entirely of pre-existing text; some of the text was authored as part of the corpus construction. One could therefore argue, as one of the reviewers for this paper did, that the approach is not entirely datadriven, if data-driven is interpreted as ‘generated from unadulterated, free text, without any human intervention needed’. For step I we rely on human annotation or existing discourse parsers such as DAS (Le and Abeysinghe, 2003) and HILDA (duVerle and Prendinger, 2009). For the current study, the final step, V, consists simply of verbatim presentation of the dialogue text. The focus of the current paper is with steps II and III (with combination, step IV, beyond the scope of the current paper). Step II is data-oriented in that we have extracted mappings from discourse relation occurrences in the corpus to corresponding dialogue act sequences, following the approach described in Piwek and Stoyanchev (2010). Stoyanchev and Piwek (2010b) observed in the CODA corpus a great variety of Dialogue Act (DA) sequences that could be used in step II, however in the cur</context>
</contexts>
<marker>duVerle, Prendinger, 2009</marker>
<rawString>D. duVerle and H. Prendinger. 2009. A novel discourse parser based on support vector machines. In Proc 47th Annual Meeting of the Association for Computational Linguistics and the 4th Int’l Joint Conf on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP’09), pages 665–673, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Heilman</author>
<author>N A Smith</author>
</authors>
<title>Good question! statistical ranking for question generation.</title>
<date>2010</date>
<booktitle>In Proc. of NAACL/HLT,</booktitle>
<location>Los Angeles.</location>
<contexts>
<context position="8105" citStr="Heilman and Smith, 2010" startWordPosition="1278" endWordPosition="1281">the input monologue text. Mapping this to the and direct rules for the relations of Table 1. appropriate dialogue act requires mappings that vary in complexity. For example, Expl(ain) can be generated by simply copying a monologue segment to dialogue utterance. The dialogue acts Yes and Agreement can be generated using canned text, such as “That is true” and “I agree with you”. In contrast, ComplQ (Complex Question), FactQ (Factoid Question), FactA (Factiod Answer) and YNQ (Yes/No Question) all require syntactic manipulation. To generate YNQ and FactQ, we use the CMU Question Generation tool (Heilman and Smith, 2010) which is based on a combination of syntactic transformation rules implemented with tregex (Levy and Andrew, 2006) and statistical methods. To generate the Compl(ex) Q(uestion) in the ComplQ;Expl Dialogue Act (DA) sequence, we use a combination of the CMU tool and lexical transformation rules.3 The GEN example in Table 2 illustrates this: The input monologue has a MannerMeans relations between the nucleus ‘In September, Ashland settled the long-simmering dispute’ and the satellite ‘by agreeing to pay Iran 325 million USD’. The satellite is copied without alteration to the Explain dialogue act.</context>
</contexts>
<marker>Heilman, Smith, 2010</marker>
<rawString>M. Heilman and N. A. Smith. 2010. Good question! statistical ranking for question generation. In Proc. of NAACL/HLT, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huong T Le and Geehta Abeysinghe</author>
</authors>
<title>A study to improve the efficiency of a discourse parsing system.</title>
<date>2003</date>
<booktitle>In Proceedings 4th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-03), Springer LNCS 2588,</booktitle>
<pages>101--114</pages>
<contexts>
<context position="5495" citStr="Abeysinghe, 2003" startWordPosition="833" endWordPosition="834">ialogue (this can range for simple textual dialogue scripts to computer-animated spoken dialogue). 1computing.open.ac.uk/coda/data.html 2Consequently, the corpus was not constructed entirely of pre-existing text; some of the text was authored as part of the corpus construction. One could therefore argue, as one of the reviewers for this paper did, that the approach is not entirely datadriven, if data-driven is interpreted as ‘generated from unadulterated, free text, without any human intervention needed’. For step I we rely on human annotation or existing discourse parsers such as DAS (Le and Abeysinghe, 2003) and HILDA (duVerle and Prendinger, 2009). For the current study, the final step, V, consists simply of verbatim presentation of the dialogue text. The focus of the current paper is with steps II and III (with combination, step IV, beyond the scope of the current paper). Step II is data-oriented in that we have extracted mappings from discourse relation occurrences in the corpus to corresponding dialogue act sequences, following the approach described in Piwek and Stoyanchev (2010). Stoyanchev and Piwek (2010b) observed in the CODA corpus a great variety of Dialogue Act (DA) sequences that cou</context>
</contexts>
<marker>Abeysinghe, 2003</marker>
<rawString>Huong T. Le and Geehta Abeysinghe. 2003. A study to improve the efficiency of a discourse parsing system. In Proceedings 4th International Conference on Intelligent Text Processing and Computational Linguistics (CICLing-03), Springer LNCS 2588, pages 101–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lee</author>
<author>F Dinneen</author>
<author>J McKendree</author>
</authors>
<title>Supporting student discussions: it isn’t just talk.</title>
<date>1998</date>
<booktitle>Education and Information Technologies,</booktitle>
<pages>3--217</pages>
<contexts>
<context position="835" citStr="Lee et al., 1998" startWordPosition="115" endWordPosition="118">Open University Walton Hall, Milton Keynes, UK s.stoyanchev@open.ac.uk Abstract This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy. 1 Introduction Several empirical studies show that delivering information in the form of a dialogue, as opposed to monologue, can be particularly effective for education (Craig et al., 2000; Lee et al., 1998) and persuasion (Suzuki and Yamada, 2004). Informationdelivering or expository dialogue was already employed by Plato to communicate his philosophy. It is used primarily to convey information and possibly also make an argument; this in contrast with dramatic dialogue which focuses on character development and narrative. Expository dialogue lends itself well for presentation through computer-animated agents (Prendinger and Ishizuka, 2004). Most information is however locked up as text in leaflets, books, newspapers, etc. Automatic generation of dialogue from text in monologue makes it possible </context>
</contexts>
<marker>Lee, Dinneen, McKendree, 1998</marker>
<rawString>J. Lee, F. Dinneen, and J. McKendree. 1998. Supporting student discussions: it isn’t just talk. Education and Information Technologies, 3:217–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Levy</author>
<author>G Andrew</author>
</authors>
<title>Tregex and tsurgeon: tools for querying and manipulating tree data structures.</title>
<date>2006</date>
<booktitle>In 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<location>Genoa, Italy.</location>
<contexts>
<context position="8219" citStr="Levy and Andrew, 2006" startWordPosition="1295" endWordPosition="1298">t requires mappings that vary in complexity. For example, Expl(ain) can be generated by simply copying a monologue segment to dialogue utterance. The dialogue acts Yes and Agreement can be generated using canned text, such as “That is true” and “I agree with you”. In contrast, ComplQ (Complex Question), FactQ (Factoid Question), FactA (Factiod Answer) and YNQ (Yes/No Question) all require syntactic manipulation. To generate YNQ and FactQ, we use the CMU Question Generation tool (Heilman and Smith, 2010) which is based on a combination of syntactic transformation rules implemented with tregex (Levy and Andrew, 2006) and statistical methods. To generate the Compl(ex) Q(uestion) in the ComplQ;Expl Dialogue Act (DA) sequence, we use a combination of the CMU tool and lexical transformation rules.3 The GEN example in Table 2 illustrates this: The input monologue has a MannerMeans relations between the nucleus ‘In September, Ashland settled the long-simmering dispute’ and the satellite ‘by agreeing to pay Iran 325 million USD’. The satellite is copied without alteration to the Explain dialogue act. The nucleus is processed by applying the following template-based rule: Decl ==&gt;. How Yes/No Question(Decl) In wo</context>
</contexts>
<marker>Levy, Andrew, 2006</marker>
<rawString>R. Levy and G. Andrew. 2006. Tregex and tsurgeon: tools for querying and manipulating tree data structures. In 5th International Conference on Language Resources and Evaluation (LREC 2006)., Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="2940" citStr="Mann and Thompson, 1988" startWordPosition="436" endWordPosition="439">n a centralised dialogue planner, that creates dialogues between a virtual car buyer and seller from a database; this approach has been extended by van Deemter et al. (2008). Others have used (semi-) autonomous agents for dialogue generation (Cavazza and Charles, 2005; Mateas and Stern, 2005). More recently, first steps have been taken towards treating dialogue generation as an instance of Textto-Text generation (Rus et al., 2007). In particular, the T2D system (Piwek et al., 2007) employs rules that map text annotated with discourse structures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242–247, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics With the creation of the publicly available1 CODA parallel corpus of monologue and dialogue (Stoyanchev and Piwek, 2010a), it has, however, become possible to adopt a data-ori</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mateas</author>
<author>A Stern</author>
</authors>
<title>Structuring content in the faade interactive drama architecture.</title>
<date>2005</date>
<booktitle>In Proc. ofArtificial Intelligence and Interactive Digital Entertainment (AIIDE), Marina</booktitle>
<location>Los Angeles,</location>
<contexts>
<context position="2609" citStr="Mateas and Stern, 2005" startWordPosition="383" endWordPosition="386">escribes the current approach. We provide an evaluation in Section 4. Finally, Section 5 describes our conclusions and plans for further research. 2 Related Work For the past decade, generation of informationdelivering dialogues has been approached primarily as an AI planning task. Andr´e et al. (2000) describe a system, based on a centralised dialogue planner, that creates dialogues between a virtual car buyer and seller from a database; this approach has been extended by van Deemter et al. (2008). Others have used (semi-) autonomous agents for dialogue generation (Cavazza and Charles, 2005; Mateas and Stern, 2005). More recently, first steps have been taken towards treating dialogue generation as an instance of Textto-Text generation (Rus et al., 2007). In particular, the T2D system (Piwek et al., 2007) employs rules that map text annotated with discourse structures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. Proceedings of the 49th Annual Meeting of the</context>
</contexts>
<marker>Mateas, Stern, 2005</marker>
<rawString>M. Mateas and A. Stern. 2005. Structuring content in the faade interactive drama architecture. In Proc. ofArtificial Intelligence and Interactive Digital Entertainment (AIIDE), Marina del Rey, Los Angeles, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Mellish</author>
<author>R Dale</author>
</authors>
<title>Evaluation in the context of natural language generation. Computer Speech and Language,</title>
<date>1998</date>
<pages>12--349</pages>
<contexts>
<context position="10885" citStr="Mellish and Dale, 1998" startWordPosition="1710" endWordPosition="1713">three native) and experts in Natural Language Generation. We collected judgements on 53 pairs of monologue and corresponding dialogue. 19 pairs were judged by all four judges to obtain inter-annotator agreement statistics, the remainder was parcelled out. 38 pairs consisted of WSJ monologue and generated dialogue, henceforth GEN, and 15 pairs of CODA corpus monologue and human-authored dialogue, henceforth CORPUS (instances of generated and corpus dialogue were randomly interleaved) – see Table 2 for examples. The two standard evaluation measures for language generation, accuracy and fluency (Mellish and Dale, 1998), were used: a) accuracy: whether a dialogue (from GEN or CORPUS) preserves the information of the corresponding monologue (judgement: ‘Yes’ or ‘No’) and b) monologue and dialogue fluency: how well written a piece of monologue or dialogue from GEN or CORPUS is. Fluency judgements were on a scale from 1 ‘incomprehensible’ to 5 ‘Comprehensible, grammatically correct and naturally sounding’. 4www.isi.edu/∼marcu/discourse/Corpora.html 5For instance, in our view ‘without wondering’ is incorrectly connected with the attribution relation to ‘whether she is moving as gracefully as the scenery.’ 3In co</context>
</contexts>
<marker>Mellish, Dale, 1998</marker>
<rawString>C. Mellish and R. Dale. 1998. Evaluation in the context of natural language generation. Computer Speech and Language, 12:349–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Piwek</author>
<author>S Stoyanchev</author>
</authors>
<title>Generating Expository Dialogue from Monologue: Motivation, Corpus and Preliminary Rules. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>333--336</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="5981" citStr="Piwek and Stoyanchev (2010)" startWordPosition="909" endWordPosition="912">ut any human intervention needed’. For step I we rely on human annotation or existing discourse parsers such as DAS (Le and Abeysinghe, 2003) and HILDA (duVerle and Prendinger, 2009). For the current study, the final step, V, consists simply of verbatim presentation of the dialogue text. The focus of the current paper is with steps II and III (with combination, step IV, beyond the scope of the current paper). Step II is data-oriented in that we have extracted mappings from discourse relation occurrences in the corpus to corresponding dialogue act sequences, following the approach described in Piwek and Stoyanchev (2010). Stoyanchev and Piwek (2010b) observed in the CODA corpus a great variety of Dialogue Act (DA) sequences that could be used in step II, however in the current version of the system we selected a representative set of the most frequent DA sequences for the five most common discourse relations in the corpus. Table 1 shows the mapping from text with a discourse relations to dialogue act sequences (i indicates implemented mappings). DA sequence A C C E M TR D T R M T YNQ; Expl i i d YNQ; Yes; Expl i i i d Expl; CmplQ; Expl i d ComplQ; Expl i/t i/t i i c Expl; YNQ;Yes i d Expl; Contrad. i d FactQ;</context>
</contexts>
<marker>Piwek, Stoyanchev, 2010</marker>
<rawString>P. Piwek and S. Stoyanchev. 2010. Generating Expository Dialogue from Monologue: Motivation, Corpus and Preliminary Rules. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 333–336, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Piwek</author>
<author>H Hernault</author>
<author>H Prendinger</author>
<author>M Ishizuka</author>
</authors>
<title>T2D: Generating Dialogues between Virtual Agents Automatically from Text.</title>
<date>2007</date>
<booktitle>In Intelligent Virtual Agents: Proceedings of IVA07, LNAI 4722,</booktitle>
<pages>161--174</pages>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="2802" citStr="Piwek et al., 2007" startWordPosition="415" endWordPosition="418">informationdelivering dialogues has been approached primarily as an AI planning task. Andr´e et al. (2000) describe a system, based on a centralised dialogue planner, that creates dialogues between a virtual car buyer and seller from a database; this approach has been extended by van Deemter et al. (2008). Others have used (semi-) autonomous agents for dialogue generation (Cavazza and Charles, 2005; Mateas and Stern, 2005). More recently, first steps have been taken towards treating dialogue generation as an instance of Textto-Text generation (Rus et al., 2007). In particular, the T2D system (Piwek et al., 2007) employs rules that map text annotated with discourse structures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242–247, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics With the creation of the publicly ava</context>
</contexts>
<marker>Piwek, Hernault, Prendinger, Ishizuka, 2007</marker>
<rawString>P. Piwek, H. Hernault, H. Prendinger, and M. Ishizuka. 2007. T2D: Generating Dialogues between Virtual Agents Automatically from Text. In Intelligent Virtual Agents: Proceedings of IVA07, LNAI 4722, pages 161–174. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Prendinger</author>
<author>M Ishizuka</author>
<author>editors</author>
</authors>
<title>Life-Like Characters: Tools, Affective Functions, and Applications. Cognitive Technologies Series.</title>
<date>2004</date>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<marker>Prendinger, Ishizuka, editors, 2004</marker>
<rawString>H. Prendinger and M. Ishizuka, editors. 2004. Life-Like Characters: Tools, Affective Functions, and Applications. Cognitive Technologies Series. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Rus</author>
<author>A Graesser</author>
<author>A Stent</author>
<author>M Walker</author>
<author>M White</author>
</authors>
<title>Text-to-Text Generation. In</title>
<date>2007</date>
<booktitle>Shared Tasks and Comparative Evaluation in Natural Language Generation: Workshop Report,</booktitle>
<editor>R. Dale and M. White, editors,</editor>
<location>Arlington, Virginia.</location>
<contexts>
<context position="2750" citStr="Rus et al., 2007" startWordPosition="405" endWordPosition="408">2 Related Work For the past decade, generation of informationdelivering dialogues has been approached primarily as an AI planning task. Andr´e et al. (2000) describe a system, based on a centralised dialogue planner, that creates dialogues between a virtual car buyer and seller from a database; this approach has been extended by van Deemter et al. (2008). Others have used (semi-) autonomous agents for dialogue generation (Cavazza and Charles, 2005; Mateas and Stern, 2005). More recently, first steps have been taken towards treating dialogue generation as an instance of Textto-Text generation (Rus et al., 2007). In particular, the T2D system (Piwek et al., 2007) employs rules that map text annotated with discourse structures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242–247, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computation</context>
</contexts>
<marker>Rus, Graesser, Stent, Walker, White, 2007</marker>
<rawString>V. Rus, A. Graesser, A. Stent, M. Walker, and M. White. 2007. Text-to-Text Generation. In R. Dale and M. White, editors, Shared Tasks and Comparative Evaluation in Natural Language Generation: Workshop Report, Arlington, Virginia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stoyanchev</author>
<author>P Piwek</author>
</authors>
<title>Constructing the CODA corpus.</title>
<date>2010</date>
<booktitle>In Procs of LREC 2010,</booktitle>
<location>Malta,</location>
<contexts>
<context position="3484" citStr="Stoyanchev and Piwek, 2010" startWordPosition="510" endWordPosition="514">ructures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242–247, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics With the creation of the publicly available1 CODA parallel corpus of monologue and dialogue (Stoyanchev and Piwek, 2010a), it has, however, become possible to adopt a data-oriented approach. This corpus consists of approximately 700 turns of dialogue, by acclaimed authors such as Mark Twain, that are aligned with monologue that was written on the basis of the dialogue, with the specific aim to express the same information as the dialogue.2 The monologue side has been annotated with discourse relations, using an adaptation of the annotation guidelines of Carlson and Marcu (2001), whereas the dialogue side has been marked up with dialogue acts, using tags inspired by the schemes of Bunt (2000), Carletta et al. (</context>
<context position="6009" citStr="Stoyanchev and Piwek (2010" startWordPosition="913" endWordPosition="917">ded’. For step I we rely on human annotation or existing discourse parsers such as DAS (Le and Abeysinghe, 2003) and HILDA (duVerle and Prendinger, 2009). For the current study, the final step, V, consists simply of verbatim presentation of the dialogue text. The focus of the current paper is with steps II and III (with combination, step IV, beyond the scope of the current paper). Step II is data-oriented in that we have extracted mappings from discourse relation occurrences in the corpus to corresponding dialogue act sequences, following the approach described in Piwek and Stoyanchev (2010). Stoyanchev and Piwek (2010b) observed in the CODA corpus a great variety of Dialogue Act (DA) sequences that could be used in step II, however in the current version of the system we selected a representative set of the most frequent DA sequences for the five most common discourse relations in the corpus. Table 1 shows the mapping from text with a discourse relations to dialogue act sequences (i indicates implemented mappings). DA sequence A C C E M TR D T R M T YNQ; Expl i i d YNQ; Yes; Expl i i i d Expl; CmplQ; Expl i d ComplQ; Expl i/t i/t i i c Expl; YNQ;Yes i d Expl; Contrad. i d FactQ; FactA; Expl i c Expl; Agr; </context>
</contexts>
<marker>Stoyanchev, Piwek, 2010</marker>
<rawString>S. Stoyanchev and P. Piwek. 2010a. Constructing the CODA corpus. In Procs of LREC 2010, Malta, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stoyanchev</author>
<author>P Piwek</author>
</authors>
<title>Harvesting re-usable high-level rules for expository dialogue generation.</title>
<date>2010</date>
<booktitle>In 6th International Natural Language Generation Conference (INLG 2010),</booktitle>
<pages>7--8</pages>
<location>Dublin,</location>
<contexts>
<context position="3484" citStr="Stoyanchev and Piwek, 2010" startWordPosition="510" endWordPosition="514">ructures, along the lines of Rhetorical Structure Theory (Mann and Thompson, 1988), to specific dialogue sequences. Common to all the approaches discussed so far has been the manual creation of generation resources, whether it be mappings from knowledge representations or discourse to dialogue structure. Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 242–247, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics With the creation of the publicly available1 CODA parallel corpus of monologue and dialogue (Stoyanchev and Piwek, 2010a), it has, however, become possible to adopt a data-oriented approach. This corpus consists of approximately 700 turns of dialogue, by acclaimed authors such as Mark Twain, that are aligned with monologue that was written on the basis of the dialogue, with the specific aim to express the same information as the dialogue.2 The monologue side has been annotated with discourse relations, using an adaptation of the annotation guidelines of Carlson and Marcu (2001), whereas the dialogue side has been marked up with dialogue acts, using tags inspired by the schemes of Bunt (2000), Carletta et al. (</context>
<context position="6009" citStr="Stoyanchev and Piwek (2010" startWordPosition="913" endWordPosition="917">ded’. For step I we rely on human annotation or existing discourse parsers such as DAS (Le and Abeysinghe, 2003) and HILDA (duVerle and Prendinger, 2009). For the current study, the final step, V, consists simply of verbatim presentation of the dialogue text. The focus of the current paper is with steps II and III (with combination, step IV, beyond the scope of the current paper). Step II is data-oriented in that we have extracted mappings from discourse relation occurrences in the corpus to corresponding dialogue act sequences, following the approach described in Piwek and Stoyanchev (2010). Stoyanchev and Piwek (2010b) observed in the CODA corpus a great variety of Dialogue Act (DA) sequences that could be used in step II, however in the current version of the system we selected a representative set of the most frequent DA sequences for the five most common discourse relations in the corpus. Table 1 shows the mapping from text with a discourse relations to dialogue act sequences (i indicates implemented mappings). DA sequence A C C E M TR D T R M T YNQ; Expl i i d YNQ; Yes; Expl i i i d Expl; CmplQ; Expl i d ComplQ; Expl i/t i/t i i c Expl; YNQ;Yes i d Expl; Contrad. i d FactQ; FactA; Expl i c Expl; Agr; </context>
</contexts>
<marker>Stoyanchev, Piwek, 2010</marker>
<rawString>S. Stoyanchev and P. Piwek. 2010b. Harvesting re-usable high-level rules for expository dialogue generation. In 6th International Natural Language Generation Conference (INLG 2010), Dublin, Ireland, 7-8, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V Suzuki</author>
<author>S Yamada</author>
</authors>
<title>Persuasion through overheard communication by life-like agents.</title>
<date>2004</date>
<booktitle>In Procs of the 2004 IEEE/WIC/ACM International Conference on Intelligent Agent Technology,</booktitle>
<location>Beijing,</location>
<contexts>
<context position="876" citStr="Suzuki and Yamada, 2004" startWordPosition="122" endWordPosition="125">n Keynes, UK s.stoyanchev@open.ac.uk Abstract This short paper introduces an implemented and evaluated monolingual Text-to-Text generation system. The system takes monologue and transforms it to two-participant dialogue. After briefly motivating the task of monologue-to-dialogue generation, we describe the system and present an evaluation in terms of fluency and accuracy. 1 Introduction Several empirical studies show that delivering information in the form of a dialogue, as opposed to monologue, can be particularly effective for education (Craig et al., 2000; Lee et al., 1998) and persuasion (Suzuki and Yamada, 2004). Informationdelivering or expository dialogue was already employed by Plato to communicate his philosophy. It is used primarily to convey information and possibly also make an argument; this in contrast with dramatic dialogue which focuses on character development and narrative. Expository dialogue lends itself well for presentation through computer-animated agents (Prendinger and Ishizuka, 2004). Most information is however locked up as text in leaflets, books, newspapers, etc. Automatic generation of dialogue from text in monologue makes it possible to convert information into dialogue as a</context>
</contexts>
<marker>Suzuki, Yamada, 2004</marker>
<rawString>S. V. Suzuki and S. Yamada. 2004. Persuasion through overheard communication by life-like agents. In Procs of the 2004 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, Beijing, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
<author>B Krenn</author>
<author>P Piwek</author>
<author>M Klesen</author>
<author>M Schroeder</author>
<author>S Baumann</author>
</authors>
<title>Fully Generated Scripted Dialogue for Embodied Agents.</title>
<date>2008</date>
<journal>Artificial Intelligence Journal,</journal>
<volume>172</volume>
<issue>10</issue>
<marker>van Deemter, Krenn, Piwek, Klesen, Schroeder, Baumann, 2008</marker>
<rawString>K. van Deemter, B. Krenn, P. Piwek, M. Klesen, M. Schroeder, and S. Baumann. 2008. Fully Generated Scripted Dialogue for Embodied Agents. Artificial Intelligence Journal, 172(10):1219–1244.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>