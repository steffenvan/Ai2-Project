<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000024">
<title confidence="0.995277">
Integrated Morphological and Syntactic Disambiguation
for Modern Hebrew
</title>
<author confidence="0.869948">
Reut Tsarfaty
</author>
<affiliation confidence="0.827968">
Institute for Logic, Language and Computation, University of Amsterdam
</affiliation>
<address confidence="0.638673">
Plantage Muidergratch 24, 1018 TV Amsterdam, The Netherlands
</address>
<email confidence="0.994233">
rtsarfat@science.uva.nl
</email>
<sectionHeader confidence="0.998562" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999674214285714">
Current parsing models are not immedi-
ately applicable for languages that exhibit
strong interaction between morphology
and syntax, e.g., Modern Hebrew (MH),
Arabic and other Semitic languages. This
work represents a first attempt at model-
ing morphological-syntactic interaction in
a generative probabilistic framework to al-
low for MH parsing. We show that mor-
phological information selected in tandem
with syntactic categories is instrumental
for parsing Semitic languages. We further
show that redundant morphological infor-
mation helps syntactic disambiguation.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991578454545455">
Natural Language Processing is typically viewed
as consisting of different layers,1 each of which is
handled separately. The structure of Semitic lan-
guages poses clear challenges to this traditional
division of labor. Specifically, Semitic languages
demonstrate strong interaction between morpho-
logical and syntactic processing, which limits the
applicability of standard tools for, e.g., parsing.
This work focuses on MH and explores the
ways morphological and syntactic processing in-
teract. Using a morphological analyzer, a part-of-
speech tagger, and a PCFG-based general-purpose
parser, we segment and parse MH sentences based
on a small, annotated corpus. Our integrated
model shows that percolating morphological am-
biguity to the lowest level of non-terminals in the
syntactic parse tree improves parsing accuracy.
1E.g., phonological, morphological, syntactic, semantic
and pragmatic.
Moreover, we show that morphological cues facil-
itate syntactic disambiguation. A particular contri-
bution of this work is to demonstrate that MH sta-
tistical parsing is feasible. Yet, the results obtained
are not comparable to those of, e.g., state-of-the-
art models for English, due to remaining syntactic
ambiguity and limited morphological treatment.
We conjecture that adequate morphological and
syntactic processing of MH should be done in a
unified framework, in which both levels can inter-
act and share information in both directions.
Section 2 presents linguistic data that demon-
strate the strong interaction between morphology
and syntax in MH, thus motivating our choice to
treat both in the same framework. Section 3 sur-
veys previous work and demonstrates again the
unavoidable interaction between the two. Sec-
tion 4.1 puts forward the formal setting of an inte-
grated probabilistic language model, followed by
the evaluation metrics defined for the integrated
task in section 4.2. Sections 4.3 and 4.4 then
describe the experimental setup and preliminary
results for our baseline implementation, and sec-
tion 5 discusses more sophisticated models we in-
tend to investigate.
</bodyText>
<sectionHeader confidence="0.988961" genericHeader="introduction">
2 Linguistic Data
</sectionHeader>
<bodyText confidence="0.999369777777778">
Phrases and sentences in MH, as well as Arabic
and other Semitic languages, have a relatively free
word order.2 In figure 1, for example, two distinct
syntactic structures express the same grammatical
relations. It is typically morphological informa-
tion rather than word order that provides cues for
structural dependencies (e.g., agreement on gen-
der and number in figure 1 reveals the subject-
predicate dependency).
</bodyText>
<footnote confidence="0.87555">
2MH allows for both SV and VS, and in some circum-
stances also VSO, SOV and others.
</footnote>
<page confidence="0.982253">
49
</page>
<note confidence="0.969183">
Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 49–54,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9083805">
Figure 1: Word Order in MH Phrases (marking the
agreement features M(asculine), S(ingular))
</figureCaption>
<figure confidence="0.617111">
S-CNJ
</figure>
<figureCaption confidence="0.6429465">
Figure 2: Syntactic Structures of MH Phrases
(marking word boundaries with ‘ ’)
</figureCaption>
<bodyText confidence="0.99950472">
Furthermore, boundaries of constituents in the
syntactic structure of MH sentences need not co-
incide with word boundaries, as illustrated in fig-
ure 2. A MH word may coincide with a single
constituent, as in ‘ica’3 (go out), it may overlap
with an entire phrase, as in ‘h ild’ (the boy), or it
may span across phrases as in ‘w kf m h bit’ (and
when from the house). Therefore, we conclude
that in order to perform syntactic analysis (pars-
ing) of MH sentences, we must first identify the
morphological constituents that form MH words.
There are (at least) three distinct morphologi-
cal processes in Semitic languages that play a role
in word formation. Derivational morphology is a
non-concatenative process in which verbs, nouns,
and adjectives are derived from (tri-)consonantal
roots plugged into templates of consonant/vowel
skeletons. The word-forms in table 1, for example,
are all derived from the same root, [i][l][d] (child,
birth), plugged into different templates. In addi-
tion, MH has a rich array of agreement features,
such as gender, number and person, expressed in
the word’s inflectional morphology. Verbs, adjec-
tives, determiners and numerals must agree on the
inflectional features with the noun they comple-
</bodyText>
<footnote confidence="0.355445">
3We adopt the transliteration of (Sima’an et al., 2001).
</footnote>
<tableCaption confidence="0.60278125">
Table 1: Derivational Morphology in MH ([..]
mark templates’ slots for consonantal roots, (..)
mark obligatory doubling of roots’ consonants.)
a. ild gdwl b. ildh gdwlh
child.MS big.MS child.FS big.FS
a big boy a big girl
Table 2: Inflectional Morphology in MH (marking
M(asculine)/F(eminine), S(ingular)/P(lural))
</tableCaption>
<bodyText confidence="0.999853558823529">
ment or modify. It can be seen in table 2 that the
suffix h alters the noun ‘ild’ (child) as well as its
modifier ‘gdwl’ (big) to feminine gender. Finally,
particles that are prefixed to the word may serve
different syntactic functions, yet a multiplicity of
them may be concatenated together with the stem
to form a single word. The word ‘wkfmhbit’ in
figure 2, for instance, is formed from a conjunc-
tion w (and), a relativizer kf (when), a preposition
m (from), a definite article h (the) and a noun bit
(house). Identifying such particles is crucial for
analyzing syntactic structures as they reveal struc-
tural dependencies such as subordinate clauses,
adjuncts, and prepositional phrase attachments.
At the same time, MH exhibits a large-scale am-
biguity already at the word level, which means that
there are multiple ways in which a word can be
broken down to its constituent morphemes. This
is further complicated by the fact that most vo-
calization marks (diacritics) are omitted in MH
texts. To illustrate, table 3 lists two segmenta-
tion possibilities, four readings, and five mean-
ings of different morphological analyses for the
word-form ‘fmnh’.4 Yet, the morphological anal-
ysis of a word-form, and in particular its mor-
phological segmentation, cannot be disambiguated
without reference to context, and various morpho-
logical features of syntactically related forms pro-
vide useful hints for morphological disambigua-
tion. Figure 3 shows the correct analyses of the
form ‘fmnh’ in different syntactic contexts. Note
that the correct analyses maintain agreement on
gender and number between the noun and its mod-
ifier. In particular, the analysis ‘that counted’ (b)
</bodyText>
<note confidence="0.37772225">
4A statistical study on a MH corpus has shown that the
average number of possible analyses per word-form was 2.1,
while 55% of the word-forms were morphologically ambigu-
ous (Sima’an et al., 2001).
</note>
<figure confidence="0.999559097560976">
S
S
NP-SBJ
VP
PP
h
the
bit
house
NP-SBJ
D
N
h
the
ild
child.MS
N
ild
child.MS
V
ica
go.out.MS
P
m
from
NP
N
bit
house
PP
NP
D
VP
V
ica
go.out.MS
m
from
P
N
D
h
the
D
h
the
h
the
bit’
house
CC
‘w
and
SBAR
‘h
the
‘ica’
go.out
REL
kf
when
S
P
m
from
PP
NP
D
NP
N
ild’
boy
VP
V
D
N
S
S
...
a. ‘ild’ b. ‘iild’ c. ‘mwld’
[i]e[l]e[d] [i]i[l](l)e[d] mw[][l](l)a[d]
child deliver a child innate
</figure>
<page confidence="0.934927">
50
</page>
<table confidence="0.977292">
‘fmnh’ ‘fmnh’ ‘fmnh’ ‘fmnh’
shmena shamna shimna shimna
fat.FS got-fat.FS put-oil.FS oil-of.FS
fat (adj) got fat (v) put-oil (v) her oil (n)
</table>
<tableCaption confidence="0.963695">
Table 3: Morphological Analyses of the Word-
form ‘fmnh’
</tableCaption>
<figureCaption confidence="0.945212">
Figure 3: Ambiguity Resolution in Different Syn-
tactic Contexts
</figureCaption>
<bodyText confidence="0.999877916666667">
is easily disambiguated, as it is the only one main-
taining agreement with the modified noun.
In light of the above, we would want to con-
clude that syntactic processing must precede mor-
phological analysis; however, this would contra-
dict our previous conclusion. For this reason,
independent morphological and syntactic analyz-
ers for MH will not suffice. We suggest per-
forming morphological and syntactic processing
of MH utterances in a single, integrated, frame-
work, thereby allowing shared information to sup-
port disambiguation in multiple tasks.
</bodyText>
<sectionHeader confidence="0.999982" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.9996467">
As of yet there is no statistical parser for MH.
Parsing models have been developed for different
languages and state-of-the-art results have been
reported for, e.g., English (Collins, 1997; Char-
niak, 2000). However, these models show impov-
erished morphological treatment, and they have
not yet been successfully applied for MH parsing.
(Sima’an et al., 2001) present an attempt to parse
MH sentences based on a small, annotated corpus
by applying a general-purpose Tree-gram model.
However, their work presupposes correct morpho-
logical disambiguation prior to parsing.5
In order to treat morphological phenomena
a few stand-alone morphological analyzers have
been developed for MH.6 Most analyzers consider
words in isolation, and thus propose multiple anal-
yses for each word. Analyzers which also at-
tempt disambiguation require contextual informa-
tion from surrounding word-forms or a shallow
parser (e.g., (Adler and Gabai, 2005)).
</bodyText>
<footnote confidence="0.9995465">
5The same holds for current work on parsing Arabic.
6Available at mila.cs.technion.ac.il.
</footnote>
<figure confidence="0.995592772727273">
a. NP
b. NP
N
CP
Rel
V
ildh.FS
child.FS
fmnh.FS
fat.FS
ild.MS
child.MS
f
that
mnh.MS
counted.MS
A
N
‘f+ mnh’
she + mana
that + counted
that (rel) counted (v)
</figure>
<bodyText confidence="0.997561466666667">
A related research agenda is the development of
part-of-speech taggers for MH and other Semitic
languages. Such taggers need to address the seg-
mentation of words into morphemes to which dis-
tinct morphosyntactic categories can be assigned
(cf. figure 2). It was illustrated for both MH (Bar-
Haim, 2005) and Arabic (Habash and Rambow,
2005) that an integrated approach towards mak-
ing morphological (segmentation) and syntactic
(POS tagging) decisions within the same architec-
ture yields excellent results. The present work fol-
lows up on insights gathered from such studies,
suggesting that an integrated framework is an ade-
quate solution for the apparent circularity in mor-
phological and syntactic processing of MH.
</bodyText>
<sectionHeader confidence="0.9855" genericHeader="method">
4 The Integrated Model
</sectionHeader>
<bodyText confidence="0.9999428">
As a first attempt to model the interaction between
the morphological and the syntactic tasks, we in-
corporate an intermediate level of part-of-speech
(POS) tagging into our model. The key idea is that
POS tags that are assigned to morphological seg-
ments at the word level coincide with the lowest
level of non-terminals in the syntactic parse trees
(cf. (Charniak et al., 1996)). Thus, POS tags can
be used to pass information between the different
tasks yet ensuring agreement between the two.
</bodyText>
<subsectionHeader confidence="0.927739">
4.1 Formal Setting
</subsectionHeader>
<bodyText confidence="0.998465636363636">
Let wm1 be a sequence of words from a fixed vo-
cabulary, sn1 be a sequence of segments of words
from a (different) vocabulary, tn1 a sequence of
morphosyntactic categories from a finite tag-set,
and let 7r be a syntactic parse tree.
We define segmentation as the task of identi-
fying the sequence of morphological constituents
that were concatenated to form a sequence of
words. Formally, we define the task as (1), where
seg(wm1 ) is the set of segmentations resulting
from all possible morphological analyses of wn1 .
</bodyText>
<equation confidence="0.537284">
sn * = argmax P(sn1 |wm1 ) (1)
1
si Eseg(wm) )
</equation>
<bodyText confidence="0.977153">
Syntactic analysis, parsing, identifies the structure
of phrases and sentences. In MH, such tree struc-
tures combine segments of words that serve differ-
ent syntactic functions. We define it formally as
(2), where yield(7r&apos;) is the ordered set of leaves of
a syntactic parse tree 7r&apos;.
</bodyText>
<equation confidence="0.985671">
7r* = argmax P(7r|sn1) (2)
πE1π&apos;:yield(π&apos;)=si }
</equation>
<page confidence="0.992297">
51
</page>
<bodyText confidence="0.998851">
Similarly, we define POS tagging as (3), where
analysis(sn1) is the set of all possible POS tag as-
signments for sn1 .
</bodyText>
<equation confidence="0.96712">
tn * = argmax P(tn1 |sn1) (3)
1
tn1 Eanalyses(sn1 �
</equation>
<bodyText confidence="0.998698666666667">
The task of the integrated model is to find the
most probable segmentation and syntactic parse
tree given a sentence in MH, as in (4).
</bodyText>
<equation confidence="0.9798905">
h7r, sn1 i* = argmax P(7r, sn1 |wm1 ) (4)
(π,sn1 )
</equation>
<bodyText confidence="0.999922571428571">
We reinterpret (4) to distinguish the morphological
and syntactic tasks, conditioning the latter on the
former, yet maximizing for both.
Agreement between the tasks is implemented by
incorporating morphosyntactic categories (POS
tags) that are assigned to morphological segments
and constrain the possible trees, resulting in (7).
</bodyText>
<equation confidence="0.999820666666667">
h7r, tn1 , sn1i* = argmax P(7r, tn1, sn1 |wm1 ) (6)
(n ,n
π,t1 ,s1 )
</equation>
<bodyText confidence="0.99433925">
Finally, we employ the assumption that
P(wm1 |sn1) ≈ 1, since segments can only be
conjoined in a certain order.7 So, instead of (5)
and (7) we end up with (8) and (9), respectively.
</bodyText>
<subsectionHeader confidence="0.987537">
4.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.910735444444445">
The intertwined nature of morphology and syn-
tax in MH poses additional challenges to standard
parsing evaluation metrics. First, note that we can-
not use morphemes as the basic units for com-
parison, as the proposed segmentation need not
coincide with the gold segmentation for a given
sentence. Since words are complex entities that
7Since concatenated particles (conjunctions et al.) appear
in front of the stem, pronominal and inflectional affixes at the
end of the stem, and derivational morphology inside the stem,
there is typically a unique way to restore word boundaries.
can span across phrases (see figure 2), we can-
not use them for comparison either. We propose
to redefine precision and recall by considering the
spans of syntactic categories based on the (space-
free) sequences of characters to which they corre-
spond. Formally, we define syntactic constituents
as hi, A, ji where i, j mark the location of char-
</bodyText>
<equation confidence="0.7763346">
acters. T = {hi, A, ji|A spans from i to j} and
G = {hi, A, ji|A spans from i to j} represent the
test/gold parses, respectively, and we calculate:8
Labeled Precision = #(G ∩ T)l#T (10)
Labeled Recall = #(G ∩ T)l#G (11)
</equation>
<subsectionHeader confidence="0.987806">
4.3 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.99113334375">
Our departure point for the syntactic analysis of
MH is that the basic units for processing are not
words, but morphological segments that are con-
catenated together to form words. Therefore, we
obtain a segment-based probabilistic grammar by
training a Probabilistic Context Free Grammar
(PCFG) on a segmented and annotated MH cor-
pus (Sima’an et al., 2001). Then, we use exist-
ing tools — i.e., a morphological analyzer (Segal,
2000), a part-of-speech tagger (Bar-Haim, 2005),
and a general-purpose parser (Schmid, 2000) — to
find compatible morphological segmentations and
syntactic analyses for unseen sentences.
The Data The data set we use is taken from the
MH treebank which consists of 5001 sentences
from the daily newspaper ‘ha’aretz’ (Sima’an et
al., 2001). We employ the syntactic categories and
POS tag sets developed therein. Our data set in-
cludes 3257 sentences of length greater than 1 and
less than 21. The number of segments per sen-
tence is 60% higher than the number of words per
sentence.9 We conducted 8 experiments in which
the data is split to training and test sets and apply
cross-fold validation to obtain robust averages.
The Models Model I uses the morphological an-
alyzer and the POS tagger to find the most prob-
able segmentation for a given sentence. This is
done by providing the POS tagger with multiple
morphological analyses per word and maximizing
the sum P 1|wm
tn 1 P(tn 1, sn 1 ) (Bar-Haim, 2005, sec-
tion 8.2). Then, the parser is used to find the most
</bodyText>
<footnote confidence="0.8953068">
8Covert definite article errors are counted only at the POS
tags level and discounted at the phrase-level.
9The average number of words per sentence in the com-
plete corpus is 17 while the average number of morphological
segments per sentence is 26.
</footnote>
<table confidence="0.62365825">
= argmax P(7r|tn1 ,sn1, wm1 ) P(tn1 |sn1 , wm P(sn1  |wm)
(π,tn1 ,sn1 )  |{z }  |{z }  |{z }
parsing 1 ) segmentation
tagging (7)
</table>
<equation confidence="0.998603333333333">
h7r, sn1 i* = argmax
(π,sn1 )
P(7r|sn1, wm1 ) P(sn1 |wm1 )
 |{z }  |{z }
parsing
segmentation
(5)
≈ argmax
(π,sn1 )
P(7r|si)
 |{z }
parsing
P(sn1  |wm)
 |{z }
segmentation
P(7r|tn1, sn1) P(tn1 |sn1) P(sn1 |wm1 )
 |{z }  |{z }  |{z }
parsing tagging
≈ argmax
(π,tn1 ,sn1 )
segmentation
</equation>
<page confidence="0.988558">
52
</page>
<bodyText confidence="0.996751481481482">
probable parse tree for the selected sequence of
morphological segments. Formally, this model is
a first approximation of equation (8) using a step-
wise maximization instead of a joint one.10
In Model II we percolate the morphological am-
biguity further, to the lowest level of non-terminals
in the syntactic trees. Here we use the morpholog-
ical analyzer and the POS tagger to find the most
probable segmentation and POS tag assignment
by maximizing the joint probability P(ti, si |wm )
(Bar-Haim, 2005, section 5.2). Then, the parser
is used to parse the tagged segments. Formally,
this model attempts to approximate equation (9).
(Note that here we couple a morphological and
a syntactic decision, as we are looking to max-
imize P(ti, si |w&apos; ) ^ P(ti |si)P(si |w&apos; ) and
constrain the space of trees to those that agree with
the resulting analysis.)11
In both models, smoothing the estimated prob-
abilities is delegated to the relevant subcompo-
nents. Out of vocabulary (OOV) words are treated
by the morphological analyzer, which proposes
all possible segmentations assuming that the stem
is a proper noun. The Tri-gram model used for
POS tagging is smoothed using Good-Turing dis-
counting (see (Bar-Haim, 2005, section 6.1)), and
the parser uses absolute discounting with various
backoff strategies (Schmid, 2000, section 4.4).
The Tag-Sets To examine the usefulness of var-
ious morphological features shared with the pars-
ing task, we alter the set of morphosyntactic cate-
gories to include more fine-grained morphological
distinctions. We use three sets: Set A contains bare
POS categories, Set B identifies also definite nouns
marked for possession, and Set C adds the distinc-
tion between finite and non-finite verb forms.
Evaluation We use seven measures to evaluate
our models’ performance on the integrated task.
10At the cost of incurring indepence assumptions, a step-
wise architecture is computationally cheaper than a joint one
and this is perhaps the simplest end-to-end architecture for
MH parsing imaginable. In the absence of previous MH pars-
ing results, this model is suitable to serve as a baseline against
which we compare more sophisticated models.
11We further developed a third model, Model III, which
is a more faithful approximation, yet computationally afford-
able, of equation (9). There we percolate the ambiguity all the
way through the integrated architecture by means of provid-
ing the parser with the n-best sequences of tagged morpho-
logical segments and selecting the analysis (ir, ti , sl) which
maximizes the production P(ir|ti , sl)P(si , t�1 |w&amp;quot;1 ). How-
ever, we have not yet obtained robust results for this model
prior to the submission of this paper, and therefore we leave
it for future discussion.
</bodyText>
<table confidence="0.889432625">
String Labeled POS tags Segment.
Cover. Prec. / Rec. Prec. / Rec. Prec. / Rec.
Model I-A 99.2% 60.3% / 58.4% 82.4% / 82.6% 94.4% / 94.7 %
Model II-A 95.9% 60.7% / 60.5% 84.5% / 84.8% 91.3% / 91.6%
Model I-B 99.2 % 60.3% / 58.4% 81.6% / 82.3% 94.2% / 95.0%
Model II-B 95.7% 60.7% / 60.5% 82.8% / 83.5% 90.9% / 91.7%
Model I-C 99.2% 60.9% / 59.2% 80.4% / 81.1% 94.2% / 95.1%
Model II-C 95.9% 61.7% / 61.9% 81.6% / 82.3% 91.0% / 91.9%
</table>
<tableCaption confidence="0.99993">
Table 4: Evaluation Metrics, Models I and II
</tableCaption>
<bodyText confidence="0.999780642857143">
First, we present the percentage of sentences for
which the model could propose a pair of corre-
sponding morphological and syntactic analyses.
This measure is referred to as string coverage. To
indicate morphological disambiguation capabili-
ties we report segmentation precision and recall.
To capture tagging and parsing accuracy, we refer
to our redefined Parseval measures and separate
the evaluation of morphosyntactic categories, i.e.,
POS tags precision and recall, and phrase-level
syntactic categories, i.e., labeled precision and re-
call (where root nodes are discarded and empty
trees are counted as zero).12 The labeled cate-
gories are evaluated against the original tag set.
</bodyText>
<subsectionHeader confidence="0.621025">
4.4 Results
</subsectionHeader>
<bodyText confidence="0.999984086956522">
Table 4 shows the evaluation scores for models I-A
to II-C. To the best of our knowledge, these are the
first parsing results for MH assuming no manual
interference for morphological disambiguation.
For all sets, parsing of tagged-segments (Model
II) shows improvement of up to 2% over pars-
ing bare segments’ sequences (Model I). This indi-
cates that morphosyntactic information selected in
tandem with morphological segmentation is more
informative for syntactic analysis than segmenta-
tion alone. We also observe decreasing string cov-
erage for Model II, possibly since disambiguation
based on short context may result in a probable,
yet incorrect, POS tag assignment for which the
parser cannot recover a syntactic analysis. Cor-
rect disambiguation may depend on long-distance
cues, e.g., agreement, so we advocate percolating
the ambiguity further up to the parser.
Comparing the performance for the different tag
sets, parsing accuracy increases for models I-B/C
and II-B/C while POS tagging results decrease.
These results seem to contradict the common wis-
dom that performance on a ‘complex’ task de-
</bodyText>
<footnote confidence="0.812718333333333">
12Since we evaluate the models’ performance on an inte-
grated task, sentences in which one of the subcomponents
failed to propose an analysis counts as zero for all subtasks.
</footnote>
<page confidence="0.998222">
53
</page>
<bodyText confidence="0.9998045">
pends on a ‘simpler’, preceding one; yet, they sup-
port our thesis that morphological information or-
thogonal to syntactic categories facilitates syntac-
tic analysis and improves disambiguation capacity.
</bodyText>
<sectionHeader confidence="0.999674" genericHeader="evaluation">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999746657142857">
Devising a baseline model for morphological and
syntactic processing is of great importance for the
development of a broad-coverage statistical parser
for MH. Here we provide a set of standardized
baseline results for later comparison while con-
solidating the formal and architectural underpin-
ning of an integrated model. However, our results
were obtained using a relatively small set of train-
ing data and a weak (unlexicalized) parser, due to
the size of the corpus and its annotated scheme.13
Training a PCFG on our treebank resulted in a
severely ambiguous grammar, mainly due to high
phrase structure variability.
To compensate for the flat, ambiguous phrase-
structures, in the future we intend to employ prob-
abilistic grammars in which all levels of non-
terminals are augmented with morphological in-
formation percolated up the tree. Furthermore,
the MH treebank annotation scheme features a set
of so-called functional features14 which express
grammatical relations. We propose to learn the
correlation between various morphological mark-
ings and functional features, thereby constraining
the space of syntactic structures to those which ex-
press meaningful predicate-argument structures.
Since our data set is relatively small,15 introduc-
ing orthogonal morphological information to syn-
tactic categories may result in severe data sparse-
ness. In the current architecture, smoothing is
handled separately by each of the subcomponents.
Enriched grammars would allow us to exploit mul-
tiple levels of information in smoothing the esti-
mated probabilities and to redistribute probability
mass to unattested events based on their similarity
to attested events in their integrated representation.
</bodyText>
<sectionHeader confidence="0.999771" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.918720344827586">
Traditional approaches for devising parsing mod-
els, smoothing techniques and evaluation metrics
are not well suited for MH, as they presuppose
13The lack of head marking, for instance, precludes the use
of lexicalized models a` la (Collins, 1997).
14SBJ for subject, OBJ for object, COM for complement,
etc. (Sima’an et al., 2001).
15The size of our treebank is less than 30% of the Arabic
Treebank, and less than 10% of the WSJ Penn Treebank.
separate levels of processing. Different languages
mark regularities in their surface structures in dif-
ferent ways – English encodes regularities in word
order, while MH provides useful hints about gram-
matical relations in its derivational and inflectional
morphology. In the future we intend to develop
more sophisticated models implementing closer
interaction between morphology and syntax, by
means of which we hope to boost parsing accu-
racy and improve morphological disambiguation.
Acknowledgments I would like to thank Khalil
Sima’an for supervising this work, Remko Scha,
Rens Bod and Jelle Zuidema for helpful com-
ments, and Alon Itai, Yoad Winter and Shuly
Wintner for discussion. The Knowledge Cen-
ter for Hebrew Processing provided corpora and
tools, and Roy Bar-Haim provided knowledge and
technical support for which I am grateful. This
work is funded by the Netherlands Organization
for Scientific Research (NWO) grant 017.001.271.
</bodyText>
<sectionHeader confidence="0.999352" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999271862068966">
Meni Adler and Dudi Gabai. 2005. Morphological
Analyzer and Disambiguator for Modern Hebrew.
Knowledge Center for Processing Hebrew.
Roy Bar-Haim. 2005. Part-of-Speech Tagging for He-
brew and Other Semitic Languages. Master’s thesis,
Technion, Haifa, Israel.
Eugene Charniak, Glenn Carroll, John Adcock, An-
thony R. Cassandra, Yoshihiko Gotoh, Jeremy Katz,
Michael L. Littman, and John McCann. 1996. Tag-
gers for Parsers. AI, 85(1-2):45–57.
Eugene Charniak. 2000. A Maximum-Entropy-
Inspired Parser. In Proceedings ofNAACL 2000.
Michael Collins. 1997. Three Generative, Lexicalised
Models for Statistical Parsing. In Proceedings of
ACL-EACL 1997.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphologi-
cal Disambiguation in One Fell Swoop. In Proceed-
ings ofACL 2005.
Helmut Schmid, 2000. LoPar: Design and Implemen-
tation. Institute for Computational Linguistics, Uni-
versity of Stuttgart.
Erel Segal. 2000. A Probabilistic Morphological An-
alyzer for Hebrew Undotted Texts. Master’s thesis,
Computer Science Department, Technion, Isreal.
Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altman,
and Noa Nativ. 2001. Building a Tree-Bank for
Modern Hebrew Text. In Traitement Automatique
des Langues, volume 42, pages 347–380.
</reference>
<page confidence="0.999022">
54
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.610980">
<title confidence="0.958256">Integrated Morphological and Syntactic Disambiguation for Modern Hebrew</title>
<author confidence="0.664634">Reut Tsarfaty</author>
<affiliation confidence="0.947873">Institute for Logic, Language and Computation, University of Amsterdam</affiliation>
<address confidence="0.92066">Plantage Muidergratch 24, 1018 TV Amsterdam, The Netherlands</address>
<email confidence="0.997953">rtsarfat@science.uva.nl</email>
<abstract confidence="0.997955333333333">Current parsing models are not immediately applicable for languages that exhibit strong interaction between morphology and syntax, e.g., Modern Hebrew (MH), Arabic and other Semitic languages. This work represents a first attempt at modeling morphological-syntactic interaction in a generative probabilistic framework to allow for MH parsing. We show that morphological information selected in tandem with syntactic categories is instrumental for parsing Semitic languages. We further show that redundant morphological information helps syntactic disambiguation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Meni Adler</author>
<author>Dudi Gabai</author>
</authors>
<title>Morphological Analyzer and Disambiguator for Modern Hebrew. Knowledge Center for Processing Hebrew.</title>
<date>2005</date>
<contexts>
<context position="9343" citStr="Adler and Gabai, 2005" startWordPosition="1456" endWordPosition="1459">lly applied for MH parsing. (Sima’an et al., 2001) present an attempt to parse MH sentences based on a small, annotated corpus by applying a general-purpose Tree-gram model. However, their work presupposes correct morphological disambiguation prior to parsing.5 In order to treat morphological phenomena a few stand-alone morphological analyzers have been developed for MH.6 Most analyzers consider words in isolation, and thus propose multiple analyses for each word. Analyzers which also attempt disambiguation require contextual information from surrounding word-forms or a shallow parser (e.g., (Adler and Gabai, 2005)). 5The same holds for current work on parsing Arabic. 6Available at mila.cs.technion.ac.il. a. NP b. NP N CP Rel V ildh.FS child.FS fmnh.FS fat.FS ild.MS child.MS f that mnh.MS counted.MS A N ‘f+ mnh’ she + mana that + counted that (rel) counted (v) A related research agenda is the development of part-of-speech taggers for MH and other Semitic languages. Such taggers need to address the segmentation of words into morphemes to which distinct morphosyntactic categories can be assigned (cf. figure 2). It was illustrated for both MH (BarHaim, 2005) and Arabic (Habash and Rambow, 2005) that an int</context>
</contexts>
<marker>Adler, Gabai, 2005</marker>
<rawString>Meni Adler and Dudi Gabai. 2005. Morphological Analyzer and Disambiguator for Modern Hebrew. Knowledge Center for Processing Hebrew.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Bar-Haim</author>
</authors>
<title>Part-of-Speech Tagging for Hebrew and Other Semitic Languages. Master’s thesis,</title>
<date>2005</date>
<location>Technion, Haifa,</location>
<contexts>
<context position="14342" citStr="Bar-Haim, 2005" startWordPosition="2300" endWordPosition="2301">/gold parses, respectively, and we calculate:8 Labeled Precision = #(G ∩ T)l#T (10) Labeled Recall = #(G ∩ T)l#G (11) 4.3 Experimental Setup Our departure point for the syntactic analysis of MH is that the basic units for processing are not words, but morphological segments that are concatenated together to form words. Therefore, we obtain a segment-based probabilistic grammar by training a Probabilistic Context Free Grammar (PCFG) on a segmented and annotated MH corpus (Sima’an et al., 2001). Then, we use existing tools — i.e., a morphological analyzer (Segal, 2000), a part-of-speech tagger (Bar-Haim, 2005), and a general-purpose parser (Schmid, 2000) — to find compatible morphological segmentations and syntactic analyses for unseen sentences. The Data The data set we use is taken from the MH treebank which consists of 5001 sentences from the daily newspaper ‘ha’aretz’ (Sima’an et al., 2001). We employ the syntactic categories and POS tag sets developed therein. Our data set includes 3257 sentences of length greater than 1 and less than 21. The number of segments per sentence is 60% higher than the number of words per sentence.9 We conducted 8 experiments in which the data is split to training a</context>
<context position="16510" citStr="Bar-Haim, 2005" startWordPosition="2683" endWordPosition="2684"> P(7r|tn1, sn1) P(tn1 |sn1) P(sn1 |wm1 ) |{z } |{z } |{z } parsing tagging ≈ argmax (π,tn1 ,sn1 ) segmentation 52 probable parse tree for the selected sequence of morphological segments. Formally, this model is a first approximation of equation (8) using a stepwise maximization instead of a joint one.10 In Model II we percolate the morphological ambiguity further, to the lowest level of non-terminals in the syntactic trees. Here we use the morphological analyzer and the POS tagger to find the most probable segmentation and POS tag assignment by maximizing the joint probability P(ti, si |wm ) (Bar-Haim, 2005, section 5.2). Then, the parser is used to parse the tagged segments. Formally, this model attempts to approximate equation (9). (Note that here we couple a morphological and a syntactic decision, as we are looking to maximize P(ti, si |w&apos; ) ^ P(ti |si)P(si |w&apos; ) and constrain the space of trees to those that agree with the resulting analysis.)11 In both models, smoothing the estimated probabilities is delegated to the relevant subcomponents. Out of vocabulary (OOV) words are treated by the morphological analyzer, which proposes all possible segmentations assuming that the stem is a proper no</context>
</contexts>
<marker>Bar-Haim, 2005</marker>
<rawString>Roy Bar-Haim. 2005. Part-of-Speech Tagging for Hebrew and Other Semitic Languages. Master’s thesis, Technion, Haifa, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Glenn Carroll</author>
<author>John Adcock</author>
<author>Anthony R Cassandra</author>
<author>Yoshihiko Gotoh</author>
<author>Jeremy Katz</author>
<author>Michael L Littman</author>
<author>John McCann</author>
</authors>
<title>Taggers for Parsers.</title>
<date>1996</date>
<pages>85--1</pages>
<publisher>AI,</publisher>
<contexts>
<context position="10707" citStr="Charniak et al., 1996" startWordPosition="1678" endWordPosition="1681">nt results. The present work follows up on insights gathered from such studies, suggesting that an integrated framework is an adequate solution for the apparent circularity in morphological and syntactic processing of MH. 4 The Integrated Model As a first attempt to model the interaction between the morphological and the syntactic tasks, we incorporate an intermediate level of part-of-speech (POS) tagging into our model. The key idea is that POS tags that are assigned to morphological segments at the word level coincide with the lowest level of non-terminals in the syntactic parse trees (cf. (Charniak et al., 1996)). Thus, POS tags can be used to pass information between the different tasks yet ensuring agreement between the two. 4.1 Formal Setting Let wm1 be a sequence of words from a fixed vocabulary, sn1 be a sequence of segments of words from a (different) vocabulary, tn1 a sequence of morphosyntactic categories from a finite tag-set, and let 7r be a syntactic parse tree. We define segmentation as the task of identifying the sequence of morphological constituents that were concatenated to form a sequence of words. Formally, we define the task as (1), where seg(wm1 ) is the set of segmentations resul</context>
</contexts>
<marker>Charniak, Carroll, Adcock, Cassandra, Gotoh, Katz, Littman, McCann, 1996</marker>
<rawString>Eugene Charniak, Glenn Carroll, John Adcock, Anthony R. Cassandra, Yoshihiko Gotoh, Jeremy Katz, Michael L. Littman, and John McCann. 1996. Taggers for Parsers. AI, 85(1-2):45–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A Maximum-EntropyInspired Parser.</title>
<date>2000</date>
<booktitle>In Proceedings ofNAACL</booktitle>
<contexts>
<context position="8618" citStr="Charniak, 2000" startWordPosition="1351" endWordPosition="1353">ic processing must precede morphological analysis; however, this would contradict our previous conclusion. For this reason, independent morphological and syntactic analyzers for MH will not suffice. We suggest performing morphological and syntactic processing of MH utterances in a single, integrated, framework, thereby allowing shared information to support disambiguation in multiple tasks. 3 Related Work As of yet there is no statistical parser for MH. Parsing models have been developed for different languages and state-of-the-art results have been reported for, e.g., English (Collins, 1997; Charniak, 2000). However, these models show impoverished morphological treatment, and they have not yet been successfully applied for MH parsing. (Sima’an et al., 2001) present an attempt to parse MH sentences based on a small, annotated corpus by applying a general-purpose Tree-gram model. However, their work presupposes correct morphological disambiguation prior to parsing.5 In order to treat morphological phenomena a few stand-alone morphological analyzers have been developed for MH.6 Most analyzers consider words in isolation, and thus propose multiple analyses for each word. Analyzers which also attempt</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A Maximum-EntropyInspired Parser. In Proceedings ofNAACL 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three Generative, Lexicalised Models for Statistical Parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL-EACL</booktitle>
<contexts>
<context position="8601" citStr="Collins, 1997" startWordPosition="1349" endWordPosition="1350">de that syntactic processing must precede morphological analysis; however, this would contradict our previous conclusion. For this reason, independent morphological and syntactic analyzers for MH will not suffice. We suggest performing morphological and syntactic processing of MH utterances in a single, integrated, framework, thereby allowing shared information to support disambiguation in multiple tasks. 3 Related Work As of yet there is no statistical parser for MH. Parsing models have been developed for different languages and state-of-the-art results have been reported for, e.g., English (Collins, 1997; Charniak, 2000). However, these models show impoverished morphological treatment, and they have not yet been successfully applied for MH parsing. (Sima’an et al., 2001) present an attempt to parse MH sentences based on a small, annotated corpus by applying a general-purpose Tree-gram model. However, their work presupposes correct morphological disambiguation prior to parsing.5 In order to treat morphological phenomena a few stand-alone morphological analyzers have been developed for MH.6 Most analyzers consider words in isolation, and thus propose multiple analyses for each word. Analyzers w</context>
<context position="23349" citStr="Collins, 1997" startWordPosition="3763" endWordPosition="3764">rseness. In the current architecture, smoothing is handled separately by each of the subcomponents. Enriched grammars would allow us to exploit multiple levels of information in smoothing the estimated probabilities and to redistribute probability mass to unattested events based on their similarity to attested events in their integrated representation. 6 Conclusion Traditional approaches for devising parsing models, smoothing techniques and evaluation metrics are not well suited for MH, as they presuppose 13The lack of head marking, for instance, precludes the use of lexicalized models a` la (Collins, 1997). 14SBJ for subject, OBJ for object, COM for complement, etc. (Sima’an et al., 2001). 15The size of our treebank is less than 30% of the Arabic Treebank, and less than 10% of the WSJ Penn Treebank. separate levels of processing. Different languages mark regularities in their surface structures in different ways – English encodes regularities in word order, while MH provides useful hints about grammatical relations in its derivational and inflectional morphology. In the future we intend to develop more sophisticated models implementing closer interaction between morphology and syntax, by means </context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three Generative, Lexicalised Models for Statistical Parsing. In Proceedings of ACL-EACL 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="9931" citStr="Habash and Rambow, 2005" startWordPosition="1555" endWordPosition="1558">arser (e.g., (Adler and Gabai, 2005)). 5The same holds for current work on parsing Arabic. 6Available at mila.cs.technion.ac.il. a. NP b. NP N CP Rel V ildh.FS child.FS fmnh.FS fat.FS ild.MS child.MS f that mnh.MS counted.MS A N ‘f+ mnh’ she + mana that + counted that (rel) counted (v) A related research agenda is the development of part-of-speech taggers for MH and other Semitic languages. Such taggers need to address the segmentation of words into morphemes to which distinct morphosyntactic categories can be assigned (cf. figure 2). It was illustrated for both MH (BarHaim, 2005) and Arabic (Habash and Rambow, 2005) that an integrated approach towards making morphological (segmentation) and syntactic (POS tagging) decisions within the same architecture yields excellent results. The present work follows up on insights gathered from such studies, suggesting that an integrated framework is an adequate solution for the apparent circularity in morphological and syntactic processing of MH. 4 The Integrated Model As a first attempt to model the interaction between the morphological and the syntactic tasks, we incorporate an intermediate level of part-of-speech (POS) tagging into our model. The key idea is that </context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings ofACL 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>LoPar: Design and Implementation.</title>
<date>2000</date>
<institution>Institute for Computational Linguistics, University of Stuttgart.</institution>
<contexts>
<context position="14387" citStr="Schmid, 2000" startWordPosition="2306" endWordPosition="2307">Labeled Precision = #(G ∩ T)l#T (10) Labeled Recall = #(G ∩ T)l#G (11) 4.3 Experimental Setup Our departure point for the syntactic analysis of MH is that the basic units for processing are not words, but morphological segments that are concatenated together to form words. Therefore, we obtain a segment-based probabilistic grammar by training a Probabilistic Context Free Grammar (PCFG) on a segmented and annotated MH corpus (Sima’an et al., 2001). Then, we use existing tools — i.e., a morphological analyzer (Segal, 2000), a part-of-speech tagger (Bar-Haim, 2005), and a general-purpose parser (Schmid, 2000) — to find compatible morphological segmentations and syntactic analyses for unseen sentences. The Data The data set we use is taken from the MH treebank which consists of 5001 sentences from the daily newspaper ‘ha’aretz’ (Sima’an et al., 2001). We employ the syntactic categories and POS tag sets developed therein. Our data set includes 3257 sentences of length greater than 1 and less than 21. The number of segments per sentence is 60% higher than the number of words per sentence.9 We conducted 8 experiments in which the data is split to training and test sets and apply cross-fold validation </context>
<context position="17319" citStr="Schmid, 2000" startWordPosition="2813" endWordPosition="2814"> as we are looking to maximize P(ti, si |w&apos; ) ^ P(ti |si)P(si |w&apos; ) and constrain the space of trees to those that agree with the resulting analysis.)11 In both models, smoothing the estimated probabilities is delegated to the relevant subcomponents. Out of vocabulary (OOV) words are treated by the morphological analyzer, which proposes all possible segmentations assuming that the stem is a proper noun. The Tri-gram model used for POS tagging is smoothed using Good-Turing discounting (see (Bar-Haim, 2005, section 6.1)), and the parser uses absolute discounting with various backoff strategies (Schmid, 2000, section 4.4). The Tag-Sets To examine the usefulness of various morphological features shared with the parsing task, we alter the set of morphosyntactic categories to include more fine-grained morphological distinctions. We use three sets: Set A contains bare POS categories, Set B identifies also definite nouns marked for possession, and Set C adds the distinction between finite and non-finite verb forms. Evaluation We use seven measures to evaluate our models’ performance on the integrated task. 10At the cost of incurring indepence assumptions, a stepwise architecture is computationally che</context>
</contexts>
<marker>Schmid, 2000</marker>
<rawString>Helmut Schmid, 2000. LoPar: Design and Implementation. Institute for Computational Linguistics, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erel Segal</author>
</authors>
<title>A Probabilistic Morphological Analyzer for Hebrew Undotted Texts.</title>
<date>2000</date>
<tech>Master’s thesis,</tech>
<institution>Computer Science Department, Technion, Isreal.</institution>
<contexts>
<context position="14300" citStr="Segal, 2000" startWordPosition="2295" endWordPosition="2296">A spans from i to j} represent the test/gold parses, respectively, and we calculate:8 Labeled Precision = #(G ∩ T)l#T (10) Labeled Recall = #(G ∩ T)l#G (11) 4.3 Experimental Setup Our departure point for the syntactic analysis of MH is that the basic units for processing are not words, but morphological segments that are concatenated together to form words. Therefore, we obtain a segment-based probabilistic grammar by training a Probabilistic Context Free Grammar (PCFG) on a segmented and annotated MH corpus (Sima’an et al., 2001). Then, we use existing tools — i.e., a morphological analyzer (Segal, 2000), a part-of-speech tagger (Bar-Haim, 2005), and a general-purpose parser (Schmid, 2000) — to find compatible morphological segmentations and syntactic analyses for unseen sentences. The Data The data set we use is taken from the MH treebank which consists of 5001 sentences from the daily newspaper ‘ha’aretz’ (Sima’an et al., 2001). We employ the syntactic categories and POS tag sets developed therein. Our data set includes 3257 sentences of length greater than 1 and less than 21. The number of segments per sentence is 60% higher than the number of words per sentence.9 We conducted 8 experiment</context>
</contexts>
<marker>Segal, 2000</marker>
<rawString>Erel Segal. 2000. A Probabilistic Morphological Analyzer for Hebrew Undotted Texts. Master’s thesis, Computer Science Department, Technion, Isreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalil Sima’an</author>
<author>Alon Itai</author>
<author>Yoad Winter</author>
<author>Alon Altman</author>
<author>Noa Nativ</author>
</authors>
<title>Building a Tree-Bank for Modern Hebrew Text.</title>
<date>2001</date>
<booktitle>In Traitement Automatique des Langues,</booktitle>
<volume>42</volume>
<pages>347--380</pages>
<marker>Sima’an, Itai, Winter, Altman, Nativ, 2001</marker>
<rawString>Khalil Sima’an, Alon Itai, Yoad Winter, Alon Altman, and Noa Nativ. 2001. Building a Tree-Bank for Modern Hebrew Text. In Traitement Automatique des Langues, volume 42, pages 347–380.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>