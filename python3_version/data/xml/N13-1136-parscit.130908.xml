<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.973131">
Towards Coherent Multi-Document Summarization
</title>
<author confidence="0.997349">
Janara Christensen, Mausam, Stephen Soderland, Oren Etzioni
</author>
<affiliation confidence="0.996939">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.757902">
Seattle, WA 98195, USA
</address>
<email confidence="0.999739">
{janara,mausam,soderlan,etzioni}@cs.washington.edu
</email>
<sectionHeader confidence="0.998606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999940894736842">
This paper presents G-FLOW, a novel system
for coherent extractive multi-document sum-
marization (MDS).1 Where previous work on
MDS considered sentence selection and or-
dering separately, G-FLOW introduces a joint
model for selection and ordering that balances
coherence and salience. G-FLOW’s core rep-
resentation is a graph that approximates the
discourse relations across sentences based on
indicators including discourse cues, deverbal
nouns, co-reference, and more. This graph en-
ables G-FLOW to estimate the coherence of a
candidate summary.
We evaluate G-FLOW on Mechanical Turk,
and find that it generates dramatically bet-
ter summaries than an extractive summarizer
based on a pipeline of state-of-the-art sentence
selection and reordering components, under-
scoring the value of our joint model.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951166666667">
The goal of multi-document summarization (MDS)
is to produce high quality summaries of collections
of related documents. Most previous work in ex-
tractive MDS has studied the problems of sentence
selection (e.g., (Radev, 2004; Haghighi and Vander-
wende, 2009)) and sentence ordering (e.g., (Lapata,
2003; Barzilay and Lapata, 2008)) separately, but
we believe that a joint model is necessary to produce
coherent summaries. The intuition is simple: if the
sentences in a summary are first selected—without
regard to coherence—then a satisfactory ordering of
the selected sentences may not exist.
</bodyText>
<footnote confidence="0.915778">
1System and data at http://knowitall.cs.washington.edu/gflow/
</footnote>
<page confidence="0.835185">
1163
</page>
<figureCaption confidence="0.9081854">
Figure 1: An example of a discourse graph covering a
bombing and its aftermath, indicating the source docu-
ment for each node. A coherent summary should begin
with the bombing and then describe the reactions. Sen-
tences are abbreviated for compactness.
</figureCaption>
<bodyText confidence="0.99992925">
An extractive summary is a subset of the sen-
tences in the input documents, ordered in some
way.2 Of course, most possible summaries are in-
coherent. Now, consider a directed graph where the
nodes are sentences in the collection, and each edge
represents a pairwise ordering constraint necessary
for a coherent summary (see Figure 1 for a sample
graph). By definition, any coherent summary must
obey the constraints in this graph.
Previous work has constructed similar graphs au-
tomatically for single document summarization and
manually for MDS (see Section 2). Our system,
G-FLOW extends this research in two important
ways. First, it tackles automatic graph construction
for MDS, which requires novel methods for identi-
fying inter-document edges (Section 3). It uses this
</bodyText>
<footnote confidence="0.799118">
2We focus exclusively on extractive summaries, so we drop
the word “extractive” henceforth.
</footnote>
<figure confidence="0.956572583333334">
doc2: Hamas
claims respon-
sibility
doc1: Bomb-
ing in
Jerusalem
doc1: Anger
from Israelis
doc5: Pales-
tinians con-
demn attack
doc1: Suspen-
sion of peace
accord due to
bombing
doc5: Pales-
tinians urge
peace accord
doc4: Mubarak
urges peace
accord
doc3: Clinton
urges peace
accord
</figure>
<note confidence="0.912565571428572">
Proceedings of NAACL-HLT 2013, pages 1163–1173,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
State-of-the-art MDS system G-FLOW
• The attack took place Tuesday near Cailaco in East Timor, a • In a decision welcomed as a landmark by Portugal, European Union
former Portuguese colony, according to a statement issued by the leaders Saturday backed calls for a referendum to decide the fate of East
pro-independence Christian Democratic Union of East Timor. Timor, the former Portuguese colony occupied by Indonesia since 1975.
• The United Nations does not recognize Indonesian claims to East • Indonesia invaded East Timor in 1975 and annexed it the following
Timor. year.
• Bhichai Rattakul, deputy prime minister and president of the • Thailand won host rights for the quadrennial games in 1995, but
Bangkok Asian Games Organizing Committee, asked the Foreign setbacks in preparations led officials of the Olympic Council of Asia late
Ministry to urge the Saudi government to reconsider withdrawing last year to threaten to move the games to another country.
its 105-strong team. • Thailand showed its nearly complete facilities for the Asian Games to
• The games will be a success. a tough jury Thursday - the heads of the organizing committees from the
43 nations competing in the December event.
</note>
<tableCaption confidence="0.9634855">
Table 1: Pairs of sentences produced by a pipeline of a state-of-the-art sentence extractor (Lin and Bilmes, 2011) and
sentence orderer (Li et al., 2011a), and by G-FLOW.
</tableCaption>
<bodyText confidence="0.9999414">
graph to estimate coherence of a candidate summary.
Second, G-FLOW introduces a novel methodology
for joint sentence selection and ordering (Section 4).
It casts MDS as a constraint optimization problem
where salience and coherence are soft constraints,
and redundancy and summary length are hard con-
straints. Because this optimization problem is NP-
hard, G-FLOW uses local search to approximate it.
We report on a Mechanical Turk evaluation that
directly compares G-FLOW to state-of-the-art MDS
systems. Using DUC’04 as our test set, we com-
pare G-FLOW against a combination of an extractive
summarization system with state-of-the-art ROUGE
scores (Lin and Bilmes, 2011) followed by a state-
of-the-art sentence reordering scheme (Li et al.,
2011a). We also compare G-FLOW to a combina-
tion of an extractive system with state-of-the-art co-
herence scores (Nobata and Sekine, 2004) followed
by the reordering system. In both cases participants
substantially preferred G-FLOW. Participants chose
G-FLOW 54% of the time when compared to Lin,
and chose Lin’s system 22% of the time. When com-
pared to Nobata, participants chose G-FLOW 60%
of the time, and chose Nobata only 20% of the time.
The remainder of the cases were judged equivalent.
A further analysis shows that G-FLOW’s sum-
maries are judged superior along several dimensions
suggested in the DUC’04 evaluation (including co-
herence, repetitive text, and referents). A compar-
ison against manually written, gold standard sum-
maries, reveals that while the gold standard sum-
maries are preferred in direct comparisons, G-FLOW
has nearly equivalent scores on almost all dimen-
sions suggested in the DUC’04 evaluation.
The paper makes the following contributions:
</bodyText>
<listItem confidence="0.981799083333333">
• We present G-FLOW, a novel MDS system that
jointly solves the sentence selection and order-
ing problems to produce coherent summaries.
• G-FLOW automatically constructs a domain-
independent graph of ordering constraints over
sentences in a document collection, based on
syntactic cues and redundancy across docu-
ments. This graph is the backbone for estimat-
ing the coherence of a summary.
• We perform human evaluation on blind test
sets and find that G-FLOW dramatically outper-
forms state-of-the-art MDS systems.
</listItem>
<sectionHeader confidence="0.999489" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998623666666667">
Most existing research in multi-document summa-
rization (MDS) focuses on sentence selection for in-
creasing coverage and does not consider coherence
of the summary (Section 2.1). Although coherence
has been used in ordering of summary sentences
(Section 2.2), this work is limited by the quality of
summary sentences given as input. In contrast, G-
FLOW incorporates coherence in both selection and
ordering of summary sentences.
G-FLOW can be seen as an instance of discourse-
driven summarization (Section 2.3). There is prior
work in this area, but primarily for summarization of
single documents. There is some preliminary work
on the use of manually-created discourse models in
MDS. Our approach is fully automated.
</bodyText>
<subsectionHeader confidence="0.999198">
2.1 Subset Selection in MDS
</subsectionHeader>
<bodyText confidence="0.999445166666666">
Most extractive summarization research aims to in-
crease the coverage of concepts and entities while
reducing redundancy. Approaches include the use of
maximum marginal relevance (Carbonell and Gold-
stein, 1998), centroid-based summarization (Sag-
gion and Gaizauskas, 2004; Radev et al., 2004), cov-
</bodyText>
<page confidence="0.99248">
1164
</page>
<bodyText confidence="0.999935">
ering weighted scores of concepts (Takamura and
Okumura, 2009; Qazvinian et al., 2010), formula-
tion as minimum dominating set problem (Shen and
Li, 2010), and use of submodularity in sentence se-
lection (Lin and Bilmes, 2011). Graph centrality has
also been used to estimate the salience of a sentence
(Erkan and Radev, 2004). Approaches to content
analysis include generative topic models (Haghighi
and Vanderwende, 2009; Celikyilmaz and Hakkani-
Tur, 2010; Li et al., 2011b), and discriminative mod-
els (Aker et al., 2010).
These approaches do not consider coherence as
one of the desiderata in sentence selection. More-
over, they do not attempt to organize the selected
sentences into an intelligible summary. They are
often evaluted by ROUGE (Lin, 2004), which is
coherence-insensitive. In practice, these approaches
often result in incoherent summaries.
</bodyText>
<subsectionHeader confidence="0.999598">
2.2 Sentence Reordering
</subsectionHeader>
<bodyText confidence="0.99996819047619">
A parallel thread of research has investigated taking
a set of summary sentences as input and reordering
them to make the summary fluent. Various algo-
rithms use some combination of topic-relatedness,
chronology, precedence, succession, and entity co-
herence for reordering sentences (Barzilay et al.,
2001; Okazaki et al., 2004; Barzilay and Lapata,
2008; Bollegala et al., 2010). Recent work has also
used event-based models (Zhang et al., 2010) and
context analysis (Li et al., 2011a).
The hypothesis in this research is that a pipelined
combination of subset selection and reordering will
produce high-quality summaries. Unfortunately,
this is not true in practice, because sentences are se-
lected primarily for coverage without regard to co-
herence. This methodology often leads to an inad-
vertent selection of a set of disconnected sentences,
which cannot be put together in a coherent sum-
mary, irrespective of how the succeeding algorithm
reorders them. In our evaluation, reordering had lim-
ited impact on the quality of the summaries.
</bodyText>
<subsectionHeader confidence="0.999723">
2.3 Coherence Models and Summarization
</subsectionHeader>
<bodyText confidence="0.996720023809524">
Research on discourse analysis of documents pro-
vides a basis for modeling coherence in a docu-
ment. Several theories have been developed for
modeling discourse, e.g., Centering Theory, Rhetor-
ical Structure Theory (RST), Penn Discourse Tree-
Bank (Grosz and Sidner, 1986; Mann and Thomp-
son, 1988; Wolf and Gibson, 2005; Prasad et al.,
2008). Numerous discourse-guided summariza-
tion algorithms have been developed (Marcu, 1997;
Mani, 2001; Taboada and Mann, 2006; Barzilay and
Elhadad, 1997; Louis et al., 2010). However, these
approaches have been applied to single document
summarization and not to MDS.
Discourse models have seen some application to
summary generation in MDS, for example, using a
detailed semantic representation of the source texts
(McKeown and Radev, 1995; Radev and McKe-
own, 1998). A multi-document extension of RST
is Cross-document Structure Theory (CST), which
has been applied to MDS (Zhang et al., 2002; Jorge
and Pardo, 2010). However, these systems require
a stronger input, such as a manual CST-annotation
of the set of documents. Our work can be seen as
an instance of summarization based on lightweight
CST. However, a key difference is that our proposed
algorithm is completely automated and does not re-
quire any additional human annotation. Addition-
ally, while incorporating coherence into selection,
this work does not attempt to order the sentences
coherently, while our approach performs joint selec-
tion and ordering.
Discourse models have also been used for evalu-
ating summary quality (Barzilay and Lapata, 2008;
Louis and Nenkova, 2009; Pitler et al., 2010). Fi-
nally, there is work on generating coherent sum-
maries in specific domains, such as scientific articles
(Saggion and Lapalme, 2002; Abu-Jbara and Radev,
2011) using domain-specific cues like citations. In
contrast, our work generates summaries without any
domain-specific knowledge. Other research has fo-
cused on identifying coherent threads of documents
rather than sentences (Shahaf and Guestrin, 2010).
</bodyText>
<sectionHeader confidence="0.984241" genericHeader="method">
3 Discourse Graph
</sectionHeader>
<bodyText confidence="0.999992777777778">
As described in Section 1, our goal is to identify
pairwise ordering constraints over a set of input sen-
tences. These constraints specify a multi-document
discourse graph, which is used by G-FLOW to eval-
uate the coherence of a candidate summary.
In this graph G, each vertex is a sentence and an
edge from sz to sj indicates that sj can be placed
right after sz in a coherent summary. In other words,
the two share a discourse relationship. In the fol-
</bodyText>
<page confidence="0.955128">
1165
</page>
<bodyText confidence="0.990488666666667">
lowing three sentences (from possibly different doc-
uments) there should be an edge from s1 to s2, but
not between s3 and the other sentences:
</bodyText>
<equation confidence="0.633198">
s1 Militants attacked a market in Jerusalem.
s2 Arafat condemned the bombing.
</equation>
<bodyText confidence="0.9684733125">
s3 The Wye River Accord was signed in Oct.
Discourse theories have proposed a variety of re-
lationships between sentences such as background
and interpretation. RST has 17 such relations (Mann
and Thompson, 1988) and PDTB has 16 (Prasad et
al., 2008). While we seek to identify pairs of sen-
tences that have a relationship, we do not attempt to
label the edges with the exact relation.
We use textual cues from the discourse literature
in combination with the redundancy inherent in re-
lated documents to generate edges. Because this
methodology is noisy, the graph used by G-FLOW is
an approximation, which we refer to as an approx-
imate discourse graph (ADG). We first describe the
construction of this graph, and then discuss the use
of the graph for summary generation (Section 4).
</bodyText>
<subsectionHeader confidence="0.997935">
3.1 Deverbal Noun Reference
</subsectionHeader>
<bodyText confidence="0.9999889375">
Often, the main description of an event is mentioned
in a verbal phrase and subsequent references use
deverbal nouns (nominalization of verbs) (e.g., ‘at-
tacked’ and ‘the attack’). In this example, the noun
is derivationally related to the verb, but that is not al-
ways the case. For example, ‘bombing’ in s2 above
refers to ‘attacked’ in s1.
We identify verb-noun pairs with this relationship
as follows. First, we locate a set of candidate pairs
from WordNet: for each verb v, we determine po-
tential noun references n using a path length of up to
two in WordNet (moving from verb to noun is pos-
sible via WordNet’s ‘derivationally related’ links).
This set captures verb-noun pairs such as (‘to at-
tack’, ‘bombing’), but also includes generic pairs
such as (‘to act’, ‘attack’). To filter such errors
we score the candidate references. Our goal is to
emphasize common pairs and to deemphasize pairs
with common verbs or verbs that map to many
nouns. To this end, we score pairs by (c/p) * (c/q),
where c is the number of times the pair (v, n) ap-
pears in adjacent sentences, p is the number of times
the verb appears, and q is the number of times that
v appears with a different noun. We generate these
statistics over a background corpus of 60,000 arti-
cles from the New York Times and Reuters, and
filter out candidate pairs scoring below a threshold
identified over a small training set.
We construct edges in the ADG between pairs of
sentences containing these verb to noun mappings.
To our knowledge, we are the first to use deverbal
nouns for summarization.
</bodyText>
<subsectionHeader confidence="0.995317">
3.2 Event/Entity Continuation
</subsectionHeader>
<bodyText confidence="0.999953666666667">
Our second indicator is related to lexical chains
(Barzilay and Lapata, 2008). We add an edge in
the ADG from a sentence sz to sj if they contain
the same event or entity and the timestamp of sz is
less than or equal to the timestamp of sj (timestamps
generated with (Chang and Manning, 2012)).
</bodyText>
<subsectionHeader confidence="0.997873">
3.3 Discourse Markers
</subsectionHeader>
<bodyText confidence="0.9994686">
We use 36 explicit discourse markers (e.g., ‘but’,
‘however’, ‘moreover’) to identify edges between
two adjacent sentences of a document (Marcu and
Echihabi, 2002). This indicator lets us learn an edge
from s4 to s5 below:
</bodyText>
<listItem confidence="0.2357775">
s4 Arafat condemned the bombing.
s5 However, Netanyahu suspended peace talks.
</listItem>
<subsectionHeader confidence="0.930401">
3.4 Inferred Edges
</subsectionHeader>
<bodyText confidence="0.936126529411765">
We exploit the redundancy of information in MDS
documents to infer edges to related sentences. An
edge (s, s&apos;&apos;) can be inferred if there is an existing
edge (s, s&apos;) and s&apos; and s&apos;&apos; express similar informa-
tion. As an example, the edge (s6, s7) can be in-
ferred based on edge (s4, s5):
s6 Arafat condemned the attack.
s7 Netanyahu has suspended the talks.
To infer edges we need an algorithm to identify
sentences expressing similar information. To iden-
tify these pairs, we extract Open Information Extrac-
tion (Banko et al., 2007) relational tuples for each
sentence, and we mark any pair of sentences with
an equivalent relational tuple as redundant (see Sec-
tion 4.3). The inferred edges allow us to propagate
within-document discourse information to sentences
from other documents.
</bodyText>
<subsectionHeader confidence="0.91777">
3.5 Co-referent Mentions
</subsectionHeader>
<bodyText confidence="0.999965">
A sentence sj will not be clearly understood in iso-
lation and may need another sentence sz in its con-
text, if sj has a general reference (e.g., ‘the presi-
</bodyText>
<page confidence="0.960165">
1166
</page>
<bodyText confidence="0.806089428571429">
dent’) pointing to a specific entity or event in si (e.g.,
‘President Bill Clinton’). We construct edges based
on coreference mentions, as predicted by Stanford’s
coreference system (Lee et al., 2011). We are able
to identify syntactic edge (s8, s9):
s8 Pres. Clinton expressed sympathy for Israel.
s9 He said the attack should not derail the deal.
</bodyText>
<subsectionHeader confidence="0.9945">
3.6 Edge Weights
</subsectionHeader>
<bodyText confidence="0.999996083333333">
We weight each edge in the ADG by adding the
number of distinct indicators used to construct that
edge – if sentences s and s&apos; have an edge because
of a discourse marker and a deverbal reference, the
edge weight wG(s, s&apos;) will be two. We also include
negative edges in the ADG. wG(s, s&apos;) is negative if
s&apos; contains a deverbal noun reference, a discourse
marker, or a co-reference mention that is not fulfilled
by s. For example, if s&apos; contains a discourse marker,
and s is neither the sentence directly preceding s&apos;
and there is no inferred discourse link between s and
s&apos;, then we will add a negative edge wG(s, s&apos;).
</bodyText>
<subsectionHeader confidence="0.99085">
3.7 Preliminary Graph Evaluation
</subsectionHeader>
<bodyText confidence="0.999947769230769">
We evaluated the quality of the ADG used by G-
FLOW, which is important not only for its use in
MDS, but also because the ADG may be used for
other applications like topic tracking and decompos-
ing an event into sub-events. One author randomly
chose 750 edges and labeled an edge correct if the
pair of sentences did have a discourse relationship
between them and incorrect otherwise. 62% of the
edges accurately reflected a discourse relationship.
Our ADG has on average 31 edges per sentence for
a dataset in which each document cluster has on av-
erage 253 sentences. This evaluation includes only
the positive edges.
</bodyText>
<sectionHeader confidence="0.992508" genericHeader="method">
4 Summary Generation
</sectionHeader>
<bodyText confidence="0.999537625">
We denote a candidate summary X to be a sequence
of sentences (x1, x2,... , x|X|�. G-FLOW’s summa-
rization algorithm searches through the space of or-
dered summaries and scores each candidate sum-
mary along the dimensions of coherence (Section
4.1), salience (Section 4.2) and redundancy (Section
4.3). G-FLOW returns the summary that maximizes
a joint objective function (Section 4.4).
</bodyText>
<table confidence="0.9997269">
weight feature
-0.037 position in document
0.033 from first three sentences
-0.035 number of people mentions
0.111 contains money
0.038 sentence length &gt; 20
0.137 length of sentence
0.109 #sentences verbs appear in (any form)
0.349 #sentences common nouns appear in
0.355 #sentences proper nouns appear in
</table>
<tableCaption confidence="0.97637">
Table 2: Linear regression features for salience.
</tableCaption>
<subsectionHeader confidence="0.964859">
4.1 Coherence
</subsectionHeader>
<bodyText confidence="0.9983974">
G-FLOW estimates coherence of a candidate sum-
mary via the ADG. We define coherence as the sum
of edge weights between successive summary sen-
tences. For disconnected sentence pairs, the edge
weight is zero.
</bodyText>
<equation confidence="0.998986">
Coh(X) = � wG+(xi, xi+1) + AwG−(xi, xi+1)
i=1..JXJ−1
</equation>
<bodyText confidence="0.9963755">
wG+ represents positive edges and wG_ represents
negative edge weights. λ is a tradeoff coefficient for
positive and negative weights, which is tuned using
the methodology described in Section 4.4.
</bodyText>
<subsectionHeader confidence="0.962083">
4.2 Salience
</subsectionHeader>
<bodyText confidence="0.970277444444445">
Salience is the inherent value of each sentence to
the documents. We compute salience of a summary
(Sal(X)) as the sum of the saliences of individual
sentences (Ei Sal(xi)).
To estimate salience of a sentence, G-FLOW uses
a linear regression classifier trained on ROUGE
scores over the DUC’03 dataset. The classifier uses
surface features designed to identify sentences that
cover important concepts. The complete list of fea-
tures and learned weights is in Table 2. The clas-
sifier finds a sentence more salient if it mentions
nouns or verbs that are present in more sentences
across the documents. The highest ranked features
are the last three – number of other sentences that
mention a noun or a verb in the given sentence. We
use the same procedure as in deverbal nouns for de-
tecting verb mentions that appear as nouns in other
sentences (Section 3.1).
</bodyText>
<subsectionHeader confidence="0.97991">
4.3 Redundancy
</subsectionHeader>
<bodyText confidence="0.9997602">
We also wish to avoid redundancy. G-FLOW first
processes each sentence with a state-of-the-art Open
Information extractor OLLIE (Mausam et al., 2012),
which converts a sentence into its component re-
lational tuples of the form (arg1, relational phrase,
</bodyText>
<page confidence="0.976962">
1167
</page>
<bodyText confidence="0.951968368421053">
arg2).3 For example, it finds (Militants, bombed, a
marketplace) as a tuple from sentence s12.
Two sentences will express redundant information
if they both contain the same or synonymous com-
ponent fact(s). Unfortunately, detecting synonymy
even at relational tuple level is very hard. G-FLOW
approximates this synonymy by considering two re-
lational tuples synonymous if the relation phrases
contain verbs that are synonyms of each other, have
at least one synonymous argument, and are times-
tamped within a day of each other. Because the in-
put documents cover related events, these relatively
weak rules provide good performance. The same
algorithm is used for inferring edges for the ADG
(Section 3.4). This algorithm can detect that the fol-
lowing sentences express redundant information:
s12 Militants bombed a marketplace in Jerusalem.
s13 He alerted Arafat after assailants attacked the
busy streets of Mahane Yehuda.
</bodyText>
<subsectionHeader confidence="0.993654">
4.4 Objective Function
</subsectionHeader>
<bodyText confidence="0.9999094">
The objective function needs to balance coherence,
salience and redundancy and also honor the given
budget, i.e., maximum summary length B. G-FLOW
treats redundancy and budget as hard constraints and
coherence and salience as soft. Coherence is neces-
sarily soft as the graph is approximate. While previ-
ous MDS systems specifically maximized coverage,
in preliminary experiments on a development set, we
found that adding a coverage term did not improve
G-FLOW’s performance. We optimize:
</bodyText>
<equation confidence="0.9936465">
maximize: F(x) °= Sal(X) + aCoh(X) − ,3|X|
�
s.t. i_1��|X |len(xi) &lt; B
f/xi, xj E X : redundant(xi, xj) = 0
</equation>
<bodyText confidence="0.999788727272727">
Here len refers to the sentence length. We add |X|
term (the number of sentences in the summary) to
avoid picking many short sentences, which may in-
crease coherence and salience scores at the cost of
overall summary quality.
The parameters α, Q and A (see Section 4.1) are
tuned automatically using a grid search over a de-
velopment set as follows. We manually generate ex-
tractive summaries for each document cluster in our
development set (DUC’03) and choose the parame-
ter setting that minimizes |F(XG-FLOW) − F(X*)|
</bodyText>
<footnote confidence="0.953068">
3Available from http://ollie.cs.washington.edu
</footnote>
<bodyText confidence="0.998914307692308">
summed over all document clusters. F is the objec-
tive function, XG-FLOW is the summary produced by
G-FLOW and X* is the manual summary.
This constraint optimization problem is NP hard,
which can be shown by using a reduction of the
longest path problem. For this reason, G-FLOW uses
local search to reach an approximation of the opti-
mum. G-FLOW employs stochastic hill climbing
with random restarts as the base search algorithm.
At each step, the search either adds a sentence, re-
moves a sentence, replaces a sentence by another, or
reorders a pair of sentences. The initial summary for
random restarts is constructed as follows. We first
pick the highest salience sentence with no incoming
negative edges as the first sentence. The following
sentences are probabilistically added one at a time
based on the summary score up to that sentence. The
initial summary is complete when there are no possi-
ble sentences left to fit within the budget. Intuitively,
this heuristic chooses a good starting point by se-
lecting a first sentence that does not rely on context
and subsequent sentences that build a high scoring
summary. As with all local search algorithms, this
algorithm is highly scalable and can easily apply to
large collections of related documents, but does not
guarantee global optima.
</bodyText>
<sectionHeader confidence="0.999706" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999994285714286">
Because summaries are intended for human con-
sumption we focused on human evaluations. We
hired workers on Amazon Mechanical Turk (AMT)
to evaluate the summaries. Our evaluation addresses
the following questions: (1) how do G-FLOW sum-
maries compare against the state-of-the-art in MDS
(Section 5.2)? (2) what is G-FLOW’s performance
along important summarization dimensions such as
coherence and redundancy (Section 5.3)? (3) how
does G-FLOW perform on coverage as measured
by ROUGE (Section 5.3.1)? (4) how much do the
components of G-FLOW’s objective function con-
tribute to performance (Section 5.4)? (5) how do G-
FLOW’s summaries compare to human summaries?
</bodyText>
<subsectionHeader confidence="0.996113">
5.1 Data and Systems
</subsectionHeader>
<bodyText confidence="0.9998625">
We evaluated the systems on the Task 2 DUC’04
multi-document summarization dataset. This dataset
consists of 50 clusters of related documents, each of
which contains 10 documents. Each cluster of doc-
</bodyText>
<page confidence="0.986643">
1168
</page>
<bodyText confidence="0.999823518518518">
uments also includes four gold standard summaries
used for evaluation. As in the DUC’04 competition,
we allowed 665 bytes for each summary including
spaces and punctuation. We used DUC’03 as our
development set, which contains 30 document clus-
ters, again with approximately 10 documents each.
We compared G-FLOW against four systems. The
first is a recent MDS extractive summarizer, which
we choose for its state-of-the-art ROUGE scores
(Lin and Bilmes, 2011).4 The second is a pipeline
of Lin’s system followed by a reimplementation of
a state-of-the-art sentence reordering system (Li et
al., 2011a). We refer to these systems as LIN and
LIN-LI, respectively. This second baseline allows
us to quantify the advantage of using coherence as a
factor in both sentence extraction and ordering.
We also compare against the system that had the
highest coherence ratings at DUC’04 (Nobata and
Sekine, 2004), which we refer to as NOBATA. As
this system did not preform sentence ordering on its
output, we also compare against a pipeline of No-
bata’s system and the sentence reordering system.
We refer to this system as NOBATA-LI.
Lastly, to evaluate how well the system performs
against human generated summaries, we compare
against the gold standard summaries provided by
DUC.
</bodyText>
<subsectionHeader confidence="0.996311">
5.2 Overall Summary Quality
</subsectionHeader>
<bodyText confidence="0.98686436">
Following (Haghighi and Vanderwende, 2009) and
(Celikyilmaz and Hakkani-Tur, 2010), to compare
overall summary quality, we asked AMT workers
to compare two candidate system summaries. The
workers first read a gold standard summary, fol-
lowed by the two system summaries, and were then
asked to choose the better summary from the pair.
The system summaries were shown in a random or-
der to remove any bias.
To ensure that workers provided high quality data
we added two quality checks. First, we restricted
to workers who have an overall approval rating of
over 95% on AMT. Second, we asked the workers
to briefly describe the main events of the summary.
We manually filtered out work where this descrip-
tion was incorrect.
4We thank Lin and Bilmes for providing us with their code.
Unfortunately, we were unable to obtain other recent MDS sys-
tems from their authors.
Six workers compared each pair of summaries.
We recorded the scores for each cluster, and report
three numbers: the percentages of clusters where a
system is more often preferred over the other and the
percentage where the two systems are tied. G-FLOW
is preferred almost three times as often as LIN:
</bodyText>
<equation confidence="0.3637215">
G-FLOW Indifferent LIN
56% 24% 20%
</equation>
<bodyText confidence="0.981665">
Next, we compared G-FLOW and LIN-LI. Sen-
tence reordering improves performance, but G-
FLOW is still overwhelmingly preferred:
</bodyText>
<sectionHeader confidence="0.897569" genericHeader="method">
G-FLOW Indifferent LIN-LI
</sectionHeader>
<bodyText confidence="0.983418863636363">
54% 24% 22%
These results suggest that incorporating coher-
ence in sentence extraction adds significant value to
a summarization system. In these experiments, LIN
and LIN-LI are preferred in some cases. We an-
alyzed those summaries more carefully, and found
that occasionally, G-FLOW will sacrifice a small
amount of coverage for coherence, resulting in lower
performance in those cases (see Section 5.3.1).
We also compared LIN and LIN-LI, and found
that reordering does not improve performance by
much.
LIN-LI Indifferent LIN
32% 38% 30%
While the scores presented above represent com-
parisons between G-FLOW and a summarization
system with state-of-the-art ROUGE scores, we
also compared against a summarization system with
state-of-the-art coherence scores – the system with
the highest coherence scores from DUC’04, (No-
bata and Sekine, 2004). We found that G-FLOW was
again preferred:
</bodyText>
<sectionHeader confidence="0.756158" genericHeader="method">
G-FLOW Indifferent NOBATA
</sectionHeader>
<bodyText confidence="0.860465666666667">
68% 10% 22%
Adding in sentence ordering again improved the
scores for the comparison system somewhat:
</bodyText>
<sectionHeader confidence="0.94412" genericHeader="method">
G-FLOW Indifferent NOBATA-LI
</sectionHeader>
<bodyText confidence="0.932398571428572">
60% 20% 20%
While these scores show a significant improve-
ment over previous sytems, they do not convey how
well G-FLOW compares to the gold standard – man-
ually generated summaries. As a final experiment,
we compared G-FLOW and a second, manually gen-
erated summary:
</bodyText>
<page confidence="0.989876">
1169
</page>
<figure confidence="0.26297">
G-FLOW Indifferent Gold
14% 18% 68%
</figure>
<bodyText confidence="0.9996595">
While we were pleased that in 32% of the cases,
Turkers either preferred G-FLOW or were indiffer-
ent, there is clearly a lot of room for improvement
despite the gains reported over previous sytems.
</bodyText>
<subsectionHeader confidence="0.998453">
5.3 Comparison along Summary Dimensions
</subsectionHeader>
<bodyText confidence="0.999889105263158">
A high quality summary needs to be good along sev-
eral dimensions. We asked AMT workers to rate
summaries using the quality questions enumerated
in DUC’04 evaluation scheme.5 These questions
concern: (1) coherence, (2) useless, confusing, or
repetitive text, (3) redundancy, (4) nouns, pronouns,
and personal names that are not well-specified (5)
entities rementioned in an overly explicit way, (6)
ungrammatical sentences, and (7) formatting errors.
We evaluated G-FLOW LIN-LI and NOBATA-LI
against the gold standard summaries, using the same
AMT scheme as in the previous section. To assess
automated performance with respect to the standards
set by human summaries, we also evaluated a (dif-
ferent) gold standard summary for each document
cluster, using the same Mechanical Turk scheme as
in the previous section. The 50 summaries produced
by each system were evaluated by four workers. The
results are shown in Figure 2.
G-FLOW was rated significantly better than LIN-
LI in all categories except ‘Redundancy’ and signif-
icant better than NOBATA-LI on ‘Coherence’ and
‘Referents’. The ratings for ‘Coherence’, ‘Refer-
ents’, and ‘OverlyExplicit’ are not surprising given
G-FLOW’s focus on coherence. The results for
‘UselessText’ may also be due to G-FLOW’s focus
on coherence which ideally prevents it from getting
off topic. Lastly, G-FLOW may perform better on
‘Grammatical’ and ‘Formatting’ because it tends to
choose longer sentences than other systems, which
are less likely to be sentence segmentation errors.
There may also be some bleeding from one dimen-
sion to the other – if a worker likes one summary she
may score it highly for many dimensions.
Finally, somewhat surprisingly, we find G-
FLOW’s performance to be nearly that of human
summaries. G-FLOW is rated statistically signifi-
cantly lower than the gold summaries on only ‘Re-
</bodyText>
<footnote confidence="0.958767">
5http://duc.nist.gov/duc2004/quality.questions.txt
</footnote>
<table confidence="0.999835571428571">
System R F
NOBATA 30.44 34.36
Best system in DUC-04 38.28 37.94
Takamura and Okumura (2009) 38.50 -
LIN 39.35 38.90
G-FLOW 37.33 37.43
Gold Standard Summaries 40.03 40.03
</table>
<tableCaption confidence="0.995385333333333">
Table 3: ROUGE-1 recall and F-measure results (%) on
DUC-04. Some values are missing because not all sys-
tems reported both F-measure and recall.
</tableCaption>
<bodyText confidence="0.999742">
dundancy’. Given the results from the previous sec-
tion, G-FLOW is likely performing worse on cate-
gories not conveyed in these scores, such as Cover-
age, which we examine next.
</bodyText>
<subsubsectionHeader confidence="0.738857">
5.3.1 Coverage Evaluation using ROUGE
</subsubsectionHeader>
<bodyText confidence="0.999882966666667">
Most recent research has focused on the ROUGE
evaluation, and thus implicitly on coverage of in-
formation in a summary. To estimate the coverage
of G-FLOW, we compared the systems on ROUGE
(Lin, 2004). We calculated ROUGE-1 scores for
G-FLOW, LIN, and NOBATA.6 As sentence order-
ing does not matter for ROUGE, we do not include
LIN-LI or NOBATA-LI in this evaluation. Because
our algorithm does not explicitly maximize coverage
while LIN does, we expected G-FLOW to perform
slightly worse than LIN.
The ROUGE-1 scores for G-FLOW, LIN, NO-
BATA and other recent MDS systems are listed in Ta-
ble 3. We also include the ROUGE-1 scores for the
gold summaries (compared to the other gold sum-
maries). G-FLOW has slightly lower scores than
LIN and the gold standard summaries, but much
higher scores than NOBATA. G-FLOW only scores
significantly lower than LIN and the gold standard
summaries.
We can conclude that good summaries have both
the characteristics listed in the quality dimensions,
and good coverage. The gold standard summaries
outperform G-FLOW on both ROUGE scores and
the quality dimension scores, and therefore, out-
perform G-FLOW on overall comparison. How-
ever, G-FLOW is preferred to LIN-LI in addition to
NOBATA-LI indicating that its quality scores out-
weigh its ROUGE scores in that comparison. An
improvement to G-FLOW may focus on increasing
</bodyText>
<footnote confidence="0.982157">
6ROUGE version 1.5.5 with options: -a -c 95 -b 665 -m -n
4 -w 1.2
</footnote>
<page confidence="0.979763">
1170
</page>
<figure confidence="0.9971204">
0 1 2 3 4 Gold
G−Flow
Nobata−Li
Lin−Li
Coherence UselessText Redundancy Referents OverlyExplicit Grammatical Formatting
</figure>
<figureCaption confidence="0.990249333333333">
Figure 2: Ratings for the systems. 0 is the lowest possible score and 4 is the highest possible score. G-FLOW is rated
significantly higher than LIN-LI on all categories, except for ‘Redundancy’, and significantly higher than NOBATA-LI
on ‘Coherence’ and ‘Referents’. G-FLOW is only significantly lower than the gold standard on ‘Redundancy’.
</figureCaption>
<bodyText confidence="0.9897005">
coverage while retaining strengths such as coher-
ence.
</bodyText>
<subsectionHeader confidence="0.996812">
5.4 Ablation Experiments
</subsectionHeader>
<bodyText confidence="0.9998586">
In this ablation study, we evaluated the contribution
of the main components of G-FLOW – coherence
and salience. The details of the experiments are the
same as in the experiment described in Section 5.2.
We first measured the importance of coherence in
summary generation. This system G-FLOW-SAL is
identical to the full system except that it does not
include the coherence term in the objective function
(see Section 4.4). The results show that coherence is
very important to G-FLOW’s performance:
</bodyText>
<sectionHeader confidence="0.97801" genericHeader="method">
G-FLOW Indifferent G-FLOW-SAL
</sectionHeader>
<bodyText confidence="0.96646525">
54% 26% 20%
Similarly, we evaluated the contribution of
salience. This system G-FLOW-COH does not in-
clude the salience term in the objective function:
</bodyText>
<sectionHeader confidence="0.965786" genericHeader="method">
G-FLOW Indifferent G-FLOW-COH
</sectionHeader>
<bodyText confidence="0.878370333333333">
60% 20% 20%
Without salience, the system produces readable,
but highly irrelevant summaries.
</bodyText>
<subsectionHeader confidence="0.998707">
5.5 Agreement of Expert &amp; AMT Workers
</subsectionHeader>
<bodyText confidence="0.999977263157895">
Because summary evaluation is a relatively complex
task, we compared AMT workers’ annotations with
expert annotations from DUC’04. We randomly
selected ten summaries from each of the seven
DUC’04 annotators, and asked four Turk workers
to annotate them on the DUC’04 quality questions.
For each DUC’04 annotator, we selected all pairs
of summaries where one summary was judged more
than one point better than the other summary. We
compared whether the workers (voting as in Sec-
tion 5.2) likewise judged that summary better than
the second summary. We found that the annotations
agreed in 75% of cases. When we looked only at
pairs more than two points different, the agreement
was 80%. Thus, given the subjective nature of the
task, we feel reasonably confident that the AMT an-
notations are informative, and that the dramatic pref-
erence of G-FLOW over the baseline systems is due
to a substantial improvement in its summaries.
</bodyText>
<sectionHeader confidence="0.99943" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999977291666667">
In this paper, we present G-FLOW, a multi-
document summarization system aimed at generat-
ing coherent summaries. While previous MDS sys-
tems have focused primarily on salience and cov-
erage but not coherence, G-FLOW generates an or-
dered summary by jointly optimizing coherence and
salience. G-FLOW estimates coherence by using
an approximate discourse graph, where each node
is a sentence from the input documents and each
edge represents a discourse relationship between
two sentences. Manual evaluations demonstrate that
G-FLOW generates substantially better summaries
than a pipeline of state-of-the-art sentence selec-
tion and reordering components. ROUGE scores,
which measure summary coverage, show that G-
FLOW sacrifices a small amount of coverage for
overall readability and coherence. Comparisons to
gold standard summaries show that G-FLOW must
improve in coverage to equal the quality of manu-
ally written summaries. We believe this research has
applications to other areas of summarization such as
update summarization and query based summariza-
tion, and we are interested in investigating these top-
ics in future work.
</bodyText>
<page confidence="0.991257">
1171
</page>
<sectionHeader confidence="0.998474" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999282380952381">
We thank Luke Zettlemoyer, Lucy Vanderwende, Hal
Daume III, Pushpak Bhattacharyya, Chris Quirk, Erik
Frey, Tony Fader, Michael Schmitz, Alan Ritter, Melissa
Winstanley, and the three anonymous reviewers for help-
ful conversations and feedback on earlier drafts. We also
thank Lin and Bilmes for providing us with the code for
their system. This research was supported in part by NSF
grant IIS-0803481, ONR grant N00014-11-1-0294, and
DARPA contract FA8750-13-2-0019, and carried out at
the University of Washington’s Turing Center. This pa-
per was also supported in part by the Intelligence Ad-
vanced Research Projects Activity (IARPA) via Air Force
Research Laboratory (AFRL) contract number FA8650-
10-C-7058. The U.S. Government is authorized to repro-
duce and distribute reprints for Governmental purposes
notwithstanding any copyright annotation thereon. The
views and conclusions contained herein are those of the
authors and should not be interpreted as necessarily rep-
resenting the official policies or endorsements, either ex-
pressed or implied, of IARPA, AFRL, or the U.S. Gov-
ernment.
</bodyText>
<sectionHeader confidence="0.998207" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998411548780488">
Amjad Abu-Jbara and Dragomir R. Radev. 2011. Coher-
ent citation-based summarization of scientific papers.
In Proceedings of ACL 2011, pages 500–509.
Ahmet Aker, Trevor Cohn, and Robert Gaizauskas. 2010.
Multi-document summarization using A * search and
discriminative training. In Proceedings of EMNLP
2010.
Michele Banko, Michael Cafarella, Stephen Soderland,
Matt Broadhead, and Oren Etzioni. 2007. Open in-
formation extraction from the web. In Proceedings of
IJCAI2007, pages 68–74.
Regina Barzilay and Michael Elhadad. 1997. Using lex-
ical chains for text summarization. In Proceedings of
the ACL Workshop on Intelligent Scalable Text Sum-
marization, pages 10–17.
Regina Barzilay and Mirella Lapata. 2008. Modeling
local coherence: An entity-based approach. Computa-
tional Linguistics, 34(1):1–34.
Regina Barzilay, Noemie Elhadad, and Kathleen R McK-
eown. 2001. Sentence ordering in multidocument
summarization. In Proceedings of HLT 2001, pages
1–7.
Danushka Bollegala, Naoaki Okazaki, and Mitsuru
Ishizuka. 2010. A bottom-up approach to sentence
ordering for multi-document summarization. Informa-
tion Process Management, 46(1):89–109.
Jaime Carbonell and Jade Goldstein. 1998. The use of
MMR, diversity-based reranking for reordering docu-
ments and producing summaries. In Proceedings of
SIGIR 1998, pages 335–336.
Asli Celikyilmaz and Dilek Hakkani-Tur. 2010. A hy-
brid hierarchical model for multi-document summa-
rization. In Proceedings ofACL 2010, pages 815–824.
Angel Chang and Christopher Manning. 2012. SU-
TIME: A library for recognizing and normalizing time
expressions. In Proceedings of LREC 2012.
Gunes Erkan and Dragomir R Radev. 2004. LexRank:
Graph-based centrality as salience in text summa-
rization. Journal of Artificial Intelligence Research,
22(1):457–479.
Barbara Grosz and Candace Sidner. 1986. Attention,
intentions, and the structure of discourse. Computa-
tional Linguistics, 12(3):175–204.
Aria Haghighi and Lucy Vanderwende. 2009. Explor-
ing content models for multi-document summariza-
tion. Proceedings of NAACL 2009, pages 362–370.
Maria Lucia Castro Jorge and Thiago Alexan-
dre Salgueiro Pardo. 2010. Multi-Document
Summarization: Content Selection based on CST
Model (Cross-document Structure Theory). Ph.D.
thesis, N´ucleo Interinstitucional de Ling¨u´ıstica
Computacional (NILC).
Mirella Lapata. 2003. Probabilistic text structuring: Ex-
periments with sentence ordering. In Proceedings of
ACL 2003, pages 545–552.
Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael
Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011.
Stanford’s multi-pass sieve coreference resolution sys-
tem at the CoNLL-2011 shared task. In CoNLL 2011
Shared Task.
Peifeng Li, Guangxi Deng, and Qiaoming Zhu. 2011a.
Using context inference to improve sentence ordering
for multi-document summarization. In Proceedings of
IJCNLP 2011, pages 1055–1061.
Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011b.
Generating aspect-oriented multi-document summa-
rization with event-aspect model. In Proceedings of
EMNLP 2011, pages 1137–1146.
Hui Lin and Jeff Bilmes. 2011. A class of submodular
functions for document summarization. In Proceed-
ings of ACL 2011, pages 510–520.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Text Summarization
Branches Out: Proceedings of the ACL-04 Workshop,
pages 74–81.
Annie Louis and Ani Nenkova. 2009. Automatic sum-
mary evaluation without using human models. In Pro-
ceedings of EMNLP 2009, pages 306–314.
Annie Louis, Aravind Joshi, Rashmi Prasad, and Ani
Nenkova. 2010. Using entity features to classify im-
plicit discourse relations. In Proceedings of SIGDIAL
2010, pages 59–62.
</reference>
<page confidence="0.886693">
1172
</page>
<reference confidence="0.999944632911392">
Inderjeet Mani. 2001. Automatic Summarization. John
Benjamins Publishing Co, Amsterdam/Philadelphia.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243–281.
Daniel Marcu and Abdessamad Echihabi. 2002. An
unsupervised approach to recognizing discourse rela-
tions. In Proceedings of ACL 2002, pages 368–375.
Daniel Marcu. 1997. From discourse structures to text
summaries. In Proceedings of the ACL Workshop on
Intelligent Scalable Text Summarization, pages 82–88.
Mausam, Michael Schmitz, Robert Bart, Stephen Soder-
land, and Oren Etzioni. 2012. Open language learning
for information extraction. In Proceedings of EMNLP
2012, pages 523–534.
Kathleen McKeown and Dragomir Radev. 1995. Gen-
erating summaries of multiple news articles. In Pro-
ceedings of SIGIR 1995, pages 74–82.
Chikashi Nobata and Satoshi Sekine. 2004. Crl/nyu
summarization system at duc-2004. In Proceedings of
DUC 2004.
Naoaki Okazaki, Yutaka Matsuo, and Mitsuru Ishizuka.
2004. Improving chronological sentence ordering by
precedence relation. In Proceedings of COLING 2004,
pages 750–756.
Emily Pitler, Annie Louis, and Ani Nenkova. 2010.
Automatic evaluation of linguistic quality in multi-
document summarization. In Proceedings of ACL
2010, pages 544–554.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse TreeBank 2.0.
In Proceedings of LREC 2008.
Vahed Qazvinian, Dragomir R. Radev, and Arzucan
¨Ozg¨ur. 2010. Citation summarization through
keyphrase extraction. In Proceedings of COLING
2010, pages 895–903.
Dragomir R. Radev and Kathleen R. McKeown. 1998.
Generating natural language summaries from mul-
tiple on-line sources. Computational Linguistics,
24(3):469–500.
Dragomir R. Radev, Hongyan Jing, Malgorzata Stys, and
Daniel Tam. 2004. Centroid-based summarization
of multiple documents. Information Processing and
Management, 40(6):919–938.
Dragomir R. Radev. 2004. LexRank: Graph-based lexi-
cal centrality as salience in text summarization. Jour-
nal ofArtificial Intelligence Research, 22(1):457–479.
Horacio Saggion and Robert Gaizauskas. 2004. Multi-
document summarization by cluster/profile relevance
and redundancy removal. In Proceedings of DUC
2004.
Horacio Saggion and Guy Lapalme. 2002. Generating
indicative-informative summaries with sumUM. Com-
putational Linguistics, 28(4):497–526.
Dafna Shahaf and Carlos Guestrin. 2010. Connecting the
dots between news articles. In Proceedings of KDD
2010, pages 623–632.
Chao Shen and Tao Li. 2010. Multi-document summa-
rization via the minimum dominating set. In Proceed-
ings of Coling 2010, pages 984–992.
Maite Taboada and William C. Mann. 2006. Applica-
tions of rhetorical structure theory. Discourse Studies,
8(4):567–588.
Hiroya Takamura and Manabu Okumura. 2009. Text
summarization model based on maximum coverage
problem and its variant. In Proceedings ofEACL 2009,
pages 781–789.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: A corpus-based study. Compu-
tational Linguistics, 31(2):249–288.
Zhu Zhang, Sasha Blair-Goldensohn, and Dragomir R.
Radev. 2002. Towards CST-enhanced summarization.
In Proceedings of AAAI 2002, pages 439–445.
Renxian Zhang, Li Wenjie, and Lu Qin. 2010. Sen-
tence ordering with event-enriched semantics and two-
layered clustering for multi-document news summa-
rization. In Proceedings of COLING 2010, pages
1489–1497.
</reference>
<page confidence="0.988135">
1173
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.985918">
<title confidence="0.999942">Towards Coherent Multi-Document Summarization</title>
<author confidence="0.998589">Janara Christensen</author>
<author confidence="0.998589">Stephen Soderland Mausam</author>
<author confidence="0.998589">Oren</author>
<affiliation confidence="0.9998305">Computer Science &amp; University of</affiliation>
<address confidence="0.999545">Seattle, WA 98195,</address>
<abstract confidence="0.99939545">paper presents a novel system for coherent extractive multi-document sum- Where previous work on MDS considered sentence selection and orseparately, a joint model for selection and ordering that balances and salience. core representation is a graph that approximates the discourse relations across sentences based on indicators including discourse cues, deverbal nouns, co-reference, and more. This graph enestimate the coherence of a candidate summary. evaluate Mechanical Turk, and find that it generates dramatically better summaries than an extractive summarizer based on a pipeline of state-of-the-art sentence selection and reordering components, underscoring the value of our joint model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amjad Abu-Jbara</author>
<author>Dragomir R Radev</author>
</authors>
<title>Coherent citation-based summarization of scientific papers.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL 2011,</booktitle>
<pages>500--509</pages>
<contexts>
<context position="11601" citStr="Abu-Jbara and Radev, 2011" startWordPosition="1773" endWordPosition="1776">ght CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzilay and Lapata, 2008; Louis and Nenkova, 2009; Pitler et al., 2010). Finally, there is work on generating coherent summaries in specific domains, such as scientific articles (Saggion and Lapalme, 2002; Abu-Jbara and Radev, 2011) using domain-specific cues like citations. In contrast, our work generates summaries without any domain-specific knowledge. Other research has focused on identifying coherent threads of documents rather than sentences (Shahaf and Guestrin, 2010). 3 Discourse Graph As described in Section 1, our goal is to identify pairwise ordering constraints over a set of input sentences. These constraints specify a multi-document discourse graph, which is used by G-FLOW to evaluate the coherence of a candidate summary. In this graph G, each vertex is a sentence and an edge from sz to sj indicates that sj c</context>
</contexts>
<marker>Abu-Jbara, Radev, 2011</marker>
<rawString>Amjad Abu-Jbara and Dragomir R. Radev. 2011. Coherent citation-based summarization of scientific papers. In Proceedings of ACL 2011, pages 500–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ahmet Aker</author>
<author>Trevor Cohn</author>
<author>Robert Gaizauskas</author>
</authors>
<title>Multi-document summarization using A * search and discriminative training.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="8412" citStr="Aker et al., 2010" startWordPosition="1282" endWordPosition="1285">, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and en</context>
</contexts>
<marker>Aker, Cohn, Gaizauskas, 2010</marker>
<rawString>Ahmet Aker, Trevor Cohn, and Robert Gaizauskas. 2010. Multi-document summarization using A * search and discriminative training. In Proceedings of EMNLP 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of IJCAI2007,</booktitle>
<pages>68--74</pages>
<contexts>
<context position="16106" citStr="Banko et al., 2007" startWordPosition="2544" endWordPosition="2547">rafat condemned the bombing. s5 However, Netanyahu suspended peace talks. 3.4 Inferred Edges We exploit the redundancy of information in MDS documents to infer edges to related sentences. An edge (s, s&apos;&apos;) can be inferred if there is an existing edge (s, s&apos;) and s&apos; and s&apos;&apos; express similar information. As an example, the edge (s6, s7) can be inferred based on edge (s4, s5): s6 Arafat condemned the attack. s7 Netanyahu has suspended the talks. To infer edges we need an algorithm to identify sentences expressing similar information. To identify these pairs, we extract Open Information Extraction (Banko et al., 2007) relational tuples for each sentence, and we mark any pair of sentences with an equivalent relational tuple as redundant (see Section 4.3). The inferred edges allow us to propagate within-document discourse information to sentences from other documents. 3.5 Co-referent Mentions A sentence sj will not be clearly understood in isolation and may need another sentence sz in its context, if sj has a general reference (e.g., ‘the presi1166 dent’) pointing to a specific entity or event in si (e.g., ‘President Bill Clinton’). We construct edges based on coreference mentions, as predicted by Stanford’s</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael Cafarella, Stephen Soderland, Matt Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In Proceedings of IJCAI2007, pages 68–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Michael Elhadad</author>
</authors>
<title>Using lexical chains for text summarization.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization,</booktitle>
<pages>10--17</pages>
<contexts>
<context position="10332" citStr="Barzilay and Elhadad, 1997" startWordPosition="1574" endWordPosition="1577">ithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an </context>
</contexts>
<marker>Barzilay, Elhadad, 1997</marker>
<rawString>Regina Barzilay and Michael Elhadad. 1997. Using lexical chains for text summarization. In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization, pages 10–17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Mirella Lapata</author>
</authors>
<title>Modeling local coherence: An entity-based approach.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="1388" citStr="Barzilay and Lapata, 2008" startWordPosition="187" endWordPosition="190">ce of a candidate summary. We evaluate G-FLOW on Mechanical Turk, and find that it generates dramatically better summaries than an extractive summarizer based on a pipeline of state-of-the-art sentence selection and reordering components, underscoring the value of our joint model. 1 Introduction The goal of multi-document summarization (MDS) is to produce high quality summaries of collections of related documents. Most previous work in extractive MDS has studied the problems of sentence selection (e.g., (Radev, 2004; Haghighi and Vanderwende, 2009)) and sentence ordering (e.g., (Lapata, 2003; Barzilay and Lapata, 2008)) separately, but we believe that a joint model is necessary to produce coherent summaries. The intuition is simple: if the sentences in a summary are first selected—without regard to coherence—then a satisfactory ordering of the selected sentences may not exist. 1System and data at http://knowitall.cs.washington.edu/gflow/ 1163 Figure 1: An example of a discourse graph covering a bombing and its aftermath, indicating the source document for each node. A coherent summary should begin with the bombing and then describe the reactions. Sentences are abbreviated for compactness. An extractive summ</context>
<context position="9123" citStr="Barzilay and Lapata, 2008" startWordPosition="1387" endWordPosition="1390">ction. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and entity coherence for reordering sentences (Barzilay et al., 2001; Okazaki et al., 2004; Barzilay and Lapata, 2008; Bollegala et al., 2010). Recent work has also used event-based models (Zhang et al., 2010) and context analysis (Li et al., 2011a). The hypothesis in this research is that a pipelined combination of subset selection and reordering will produce high-quality summaries. Unfortunately, this is not true in practice, because sentences are selected primarily for coverage without regard to coherence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders the</context>
<context position="11393" citStr="Barzilay and Lapata, 2008" startWordPosition="1740" endWordPosition="1743"> 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summarization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzilay and Lapata, 2008; Louis and Nenkova, 2009; Pitler et al., 2010). Finally, there is work on generating coherent summaries in specific domains, such as scientific articles (Saggion and Lapalme, 2002; Abu-Jbara and Radev, 2011) using domain-specific cues like citations. In contrast, our work generates summaries without any domain-specific knowledge. Other research has focused on identifying coherent threads of documents rather than sentences (Shahaf and Guestrin, 2010). 3 Discourse Graph As described in Section 1, our goal is to identify pairwise ordering constraints over a set of input sentences. These constrai</context>
<context position="15020" citStr="Barzilay and Lapata, 2008" startWordPosition="2355" endWordPosition="2358">appears in adjacent sentences, p is the number of times the verb appears, and q is the number of times that v appears with a different noun. We generate these statistics over a background corpus of 60,000 articles from the New York Times and Reuters, and filter out candidate pairs scoring below a threshold identified over a small training set. We construct edges in the ADG between pairs of sentences containing these verb to noun mappings. To our knowledge, we are the first to use deverbal nouns for summarization. 3.2 Event/Entity Continuation Our second indicator is related to lexical chains (Barzilay and Lapata, 2008). We add an edge in the ADG from a sentence sz to sj if they contain the same event or entity and the timestamp of sz is less than or equal to the timestamp of sj (timestamps generated with (Chang and Manning, 2012)). 3.3 Discourse Markers We use 36 explicit discourse markers (e.g., ‘but’, ‘however’, ‘moreover’) to identify edges between two adjacent sentences of a document (Marcu and Echihabi, 2002). This indicator lets us learn an edge from s4 to s5 below: s4 Arafat condemned the bombing. s5 However, Netanyahu suspended peace talks. 3.4 Inferred Edges We exploit the redundancy of information</context>
</contexts>
<marker>Barzilay, Lapata, 2008</marker>
<rawString>Regina Barzilay and Mirella Lapata. 2008. Modeling local coherence: An entity-based approach. Computational Linguistics, 34(1):1–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Sentence ordering in multidocument summarization.</title>
<date>2001</date>
<booktitle>In Proceedings of HLT</booktitle>
<pages>1--7</pages>
<contexts>
<context position="9074" citStr="Barzilay et al., 2001" startWordPosition="1379" endWordPosition="1382">nce as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and entity coherence for reordering sentences (Barzilay et al., 2001; Okazaki et al., 2004; Barzilay and Lapata, 2008; Bollegala et al., 2010). Recent work has also used event-based models (Zhang et al., 2010) and context analysis (Li et al., 2011a). The hypothesis in this research is that a pipelined combination of subset selection and reordering will produce high-quality summaries. Unfortunately, this is not true in practice, because sentences are selected primarily for coverage without regard to coherence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespec</context>
</contexts>
<marker>Barzilay, Elhadad, McKeown, 2001</marker>
<rawString>Regina Barzilay, Noemie Elhadad, and Kathleen R McKeown. 2001. Sentence ordering in multidocument summarization. In Proceedings of HLT 2001, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danushka Bollegala</author>
<author>Naoaki Okazaki</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>A bottom-up approach to sentence ordering for multi-document summarization.</title>
<date>2010</date>
<journal>Information Process Management,</journal>
<volume>46</volume>
<issue>1</issue>
<contexts>
<context position="9148" citStr="Bollegala et al., 2010" startWordPosition="1391" endWordPosition="1394">t attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and entity coherence for reordering sentences (Barzilay et al., 2001; Okazaki et al., 2004; Barzilay and Lapata, 2008; Bollegala et al., 2010). Recent work has also used event-based models (Zhang et al., 2010) and context analysis (Li et al., 2011a). The hypothesis in this research is that a pipelined combination of subset selection and reordering will produce high-quality summaries. Unfortunately, this is not true in practice, because sentences are selected primarily for coverage without regard to coherence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reo</context>
</contexts>
<marker>Bollegala, Okazaki, Ishizuka, 2010</marker>
<rawString>Danushka Bollegala, Naoaki Okazaki, and Mitsuru Ishizuka. 2010. A bottom-up approach to sentence ordering for multi-document summarization. Information Process Management, 46(1):89–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of MMR, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of SIGIR</booktitle>
<pages>335--336</pages>
<contexts>
<context position="7801" citStr="Carbonell and Goldstein, 1998" startWordPosition="1186" endWordPosition="1190">s input. In contrast, GFLOW incorporates coherence in both selection and ordering of summary sentences. G-FLOW can be seen as an instance of discoursedriven summarization (Section 2.3). There is prior work in this area, but primarily for summarization of single documents. There is some preliminary work on the use of manually-created discourse models in MDS. Our approach is fully automated. 2.1 Subset Selection in MDS Most extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of SIGIR 1998, pages 335–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-Tur</author>
</authors>
<title>A hybrid hierarchical model for multi-document summarization.</title>
<date>2010</date>
<booktitle>In Proceedings ofACL 2010,</booktitle>
<pages>815--824</pages>
<contexts>
<context position="26229" citStr="Celikyilmaz and Hakkani-Tur, 2010" startWordPosition="4184" endWordPosition="4187">r in both sentence extraction and ordering. We also compare against the system that had the highest coherence ratings at DUC’04 (Nobata and Sekine, 2004), which we refer to as NOBATA. As this system did not preform sentence ordering on its output, we also compare against a pipeline of Nobata’s system and the sentence reordering system. We refer to this system as NOBATA-LI. Lastly, to evaluate how well the system performs against human generated summaries, we compare against the gold standard summaries provided by DUC. 5.2 Overall Summary Quality Following (Haghighi and Vanderwende, 2009) and (Celikyilmaz and Hakkani-Tur, 2010), to compare overall summary quality, we asked AMT workers to compare two candidate system summaries. The workers first read a gold standard summary, followed by the two system summaries, and were then asked to choose the better summary from the pair. The system summaries were shown in a random order to remove any bias. To ensure that workers provided high quality data we added two quality checks. First, we restricted to workers who have an overall approval rating of over 95% on AMT. Second, we asked the workers to briefly describe the main events of the summary. We manually filtered out work </context>
</contexts>
<marker>Celikyilmaz, Hakkani-Tur, 2010</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-Tur. 2010. A hybrid hierarchical model for multi-document summarization. In Proceedings ofACL 2010, pages 815–824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel Chang</author>
<author>Christopher Manning</author>
</authors>
<title>SUTIME: A library for recognizing and normalizing time expressions.</title>
<date>2012</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="15235" citStr="Chang and Manning, 2012" startWordPosition="2398" endWordPosition="2401">m the New York Times and Reuters, and filter out candidate pairs scoring below a threshold identified over a small training set. We construct edges in the ADG between pairs of sentences containing these verb to noun mappings. To our knowledge, we are the first to use deverbal nouns for summarization. 3.2 Event/Entity Continuation Our second indicator is related to lexical chains (Barzilay and Lapata, 2008). We add an edge in the ADG from a sentence sz to sj if they contain the same event or entity and the timestamp of sz is less than or equal to the timestamp of sj (timestamps generated with (Chang and Manning, 2012)). 3.3 Discourse Markers We use 36 explicit discourse markers (e.g., ‘but’, ‘however’, ‘moreover’) to identify edges between two adjacent sentences of a document (Marcu and Echihabi, 2002). This indicator lets us learn an edge from s4 to s5 below: s4 Arafat condemned the bombing. s5 However, Netanyahu suspended peace talks. 3.4 Inferred Edges We exploit the redundancy of information in MDS documents to infer edges to related sentences. An edge (s, s&apos;&apos;) can be inferred if there is an existing edge (s, s&apos;) and s&apos; and s&apos;&apos; express similar information. As an example, the edge (s6, s7) can be inferr</context>
</contexts>
<marker>Chang, Manning, 2012</marker>
<rawString>Angel Chang and Christopher Manning. 2012. SUTIME: A library for recognizing and normalizing time expressions. In Proceedings of LREC 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="8216" citStr="Erkan and Radev, 2004" startWordPosition="1253" endWordPosition="1256">st extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>Gunes Erkan and Dragomir R Radev. 2004. LexRank: Graph-based centrality as salience in text summarization. Journal of Artificial Intelligence Research, 22(1):457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Candace Sidner</author>
</authors>
<title>Attention, intentions, and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="10113" citStr="Grosz and Sidner, 1986" startWordPosition="1541" endWordPosition="1544"> without regard to coherence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure The</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara Grosz and Candace Sidner. 1986. Attention, intentions, and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Lucy Vanderwende</author>
</authors>
<title>Exploring content models for multi-document summarization.</title>
<date>2009</date>
<booktitle>Proceedings of NAACL</booktitle>
<pages>362--370</pages>
<contexts>
<context position="1316" citStr="Haghighi and Vanderwende, 2009" startWordPosition="176" endWordPosition="180">ns, co-reference, and more. This graph enables G-FLOW to estimate the coherence of a candidate summary. We evaluate G-FLOW on Mechanical Turk, and find that it generates dramatically better summaries than an extractive summarizer based on a pipeline of state-of-the-art sentence selection and reordering components, underscoring the value of our joint model. 1 Introduction The goal of multi-document summarization (MDS) is to produce high quality summaries of collections of related documents. Most previous work in extractive MDS has studied the problems of sentence selection (e.g., (Radev, 2004; Haghighi and Vanderwende, 2009)) and sentence ordering (e.g., (Lapata, 2003; Barzilay and Lapata, 2008)) separately, but we believe that a joint model is necessary to produce coherent summaries. The intuition is simple: if the sentences in a summary are first selected—without regard to coherence—then a satisfactory ordering of the selected sentences may not exist. 1System and data at http://knowitall.cs.washington.edu/gflow/ 1163 Figure 1: An example of a discourse graph covering a bombing and its aftermath, indicating the source document for each node. A coherent summary should begin with the bombing and then describe the </context>
<context position="8312" citStr="Haghighi and Vanderwende, 2009" startWordPosition="1265" endWordPosition="1268">ies while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Vari</context>
<context position="26189" citStr="Haghighi and Vanderwende, 2009" startWordPosition="4179" endWordPosition="4182">vantage of using coherence as a factor in both sentence extraction and ordering. We also compare against the system that had the highest coherence ratings at DUC’04 (Nobata and Sekine, 2004), which we refer to as NOBATA. As this system did not preform sentence ordering on its output, we also compare against a pipeline of Nobata’s system and the sentence reordering system. We refer to this system as NOBATA-LI. Lastly, to evaluate how well the system performs against human generated summaries, we compare against the gold standard summaries provided by DUC. 5.2 Overall Summary Quality Following (Haghighi and Vanderwende, 2009) and (Celikyilmaz and Hakkani-Tur, 2010), to compare overall summary quality, we asked AMT workers to compare two candidate system summaries. The workers first read a gold standard summary, followed by the two system summaries, and were then asked to choose the better summary from the pair. The system summaries were shown in a random order to remove any bias. To ensure that workers provided high quality data we added two quality checks. First, we restricted to workers who have an overall approval rating of over 95% on AMT. Second, we asked the workers to briefly describe the main events of the</context>
</contexts>
<marker>Haghighi, Vanderwende, 2009</marker>
<rawString>Aria Haghighi and Lucy Vanderwende. 2009. Exploring content models for multi-document summarization. Proceedings of NAACL 2009, pages 362–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lucia</author>
</authors>
<title>Castro Jorge and Thiago Alexandre Salgueiro Pardo.</title>
<date>2010</date>
<booktitle>CST Model (Cross-document Structure Theory). Ph.D. thesis, N´ucleo Interinstitucional de Ling¨u´ıstica Computacional (NILC).</booktitle>
<marker>Lucia, 2010</marker>
<rawString>Maria Lucia Castro Jorge and Thiago Alexandre Salgueiro Pardo. 2010. Multi-Document Summarization: Content Selection based on CST Model (Cross-document Structure Theory). Ph.D. thesis, N´ucleo Interinstitucional de Ling¨u´ıstica Computacional (NILC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>545--552</pages>
<contexts>
<context position="1360" citStr="Lapata, 2003" startWordPosition="185" endWordPosition="186">te the coherence of a candidate summary. We evaluate G-FLOW on Mechanical Turk, and find that it generates dramatically better summaries than an extractive summarizer based on a pipeline of state-of-the-art sentence selection and reordering components, underscoring the value of our joint model. 1 Introduction The goal of multi-document summarization (MDS) is to produce high quality summaries of collections of related documents. Most previous work in extractive MDS has studied the problems of sentence selection (e.g., (Radev, 2004; Haghighi and Vanderwende, 2009)) and sentence ordering (e.g., (Lapata, 2003; Barzilay and Lapata, 2008)) separately, but we believe that a joint model is necessary to produce coherent summaries. The intuition is simple: if the sentences in a summary are first selected—without regard to coherence—then a satisfactory ordering of the selected sentences may not exist. 1System and data at http://knowitall.cs.washington.edu/gflow/ 1163 Figure 1: An example of a discourse graph covering a bombing and its aftermath, indicating the source document for each node. A coherent summary should begin with the bombing and then describe the reactions. Sentences are abbreviated for com</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Mirella Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of ACL 2003, pages 545–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task.</title>
<date>2011</date>
<booktitle>In CoNLL</booktitle>
<note>Shared Task.</note>
<contexts>
<context position="16744" citStr="Lee et al., 2011" startWordPosition="2647" endWordPosition="2650">r each sentence, and we mark any pair of sentences with an equivalent relational tuple as redundant (see Section 4.3). The inferred edges allow us to propagate within-document discourse information to sentences from other documents. 3.5 Co-referent Mentions A sentence sj will not be clearly understood in isolation and may need another sentence sz in its context, if sj has a general reference (e.g., ‘the presi1166 dent’) pointing to a specific entity or event in si (e.g., ‘President Bill Clinton’). We construct edges based on coreference mentions, as predicted by Stanford’s coreference system (Lee et al., 2011). We are able to identify syntactic edge (s8, s9): s8 Pres. Clinton expressed sympathy for Israel. s9 He said the attack should not derail the deal. 3.6 Edge Weights We weight each edge in the ADG by adding the number of distinct indicators used to construct that edge – if sentences s and s&apos; have an edge because of a discourse marker and a deverbal reference, the edge weight wG(s, s&apos;) will be two. We also include negative edges in the ADG. wG(s, s&apos;) is negative if s&apos; contains a deverbal noun reference, a discourse marker, or a co-reference mention that is not fulfilled by s. For example, if s&apos;</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. 2011. Stanford’s multi-pass sieve coreference resolution system at the CoNLL-2011 shared task. In CoNLL 2011 Shared Task.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peifeng Li</author>
<author>Guangxi Deng</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Using context inference to improve sentence ordering for multi-document summarization.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP 2011,</booktitle>
<pages>1055--1061</pages>
<contexts>
<context position="4596" citStr="Li et al., 2011" startWordPosition="692" endWordPosition="695">ttee, asked the Foreign setbacks in preparations led officials of the Olympic Council of Asia late Ministry to urge the Saudi government to reconsider withdrawing last year to threaten to move the games to another country. its 105-strong team. • Thailand showed its nearly complete facilities for the Asian Games to • The games will be a success. a tough jury Thursday - the heads of the organizing committees from the 43 nations competing in the December event. Table 1: Pairs of sentences produced by a pipeline of a state-of-the-art sentence extractor (Lin and Bilmes, 2011) and sentence orderer (Li et al., 2011a), and by G-FLOW. graph to estimate coherence of a candidate summary. Second, G-FLOW introduces a novel methodology for joint sentence selection and ordering (Section 4). It casts MDS as a constraint optimization problem where salience and coherence are soft constraints, and redundancy and summary length are hard constraints. Because this optimization problem is NPhard, G-FLOW uses local search to approximate it. We report on a Mechanical Turk evaluation that directly compares G-FLOW to state-of-the-art MDS systems. Using DUC’04 as our test set, we compare G-FLOW against a combination of an e</context>
<context position="8363" citStr="Li et al., 2011" startWordPosition="1274" endWordPosition="1277">um marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relate</context>
<context position="25446" citStr="Li et al., 2011" startWordPosition="4060" endWordPosition="4063">ster of doc1168 uments also includes four gold standard summaries used for evaluation. As in the DUC’04 competition, we allowed 665 bytes for each summary including spaces and punctuation. We used DUC’03 as our development set, which contains 30 document clusters, again with approximately 10 documents each. We compared G-FLOW against four systems. The first is a recent MDS extractive summarizer, which we choose for its state-of-the-art ROUGE scores (Lin and Bilmes, 2011).4 The second is a pipeline of Lin’s system followed by a reimplementation of a state-of-the-art sentence reordering system (Li et al., 2011a). We refer to these systems as LIN and LIN-LI, respectively. This second baseline allows us to quantify the advantage of using coherence as a factor in both sentence extraction and ordering. We also compare against the system that had the highest coherence ratings at DUC’04 (Nobata and Sekine, 2004), which we refer to as NOBATA. As this system did not preform sentence ordering on its output, we also compare against a pipeline of Nobata’s system and the sentence reordering system. We refer to this system as NOBATA-LI. Lastly, to evaluate how well the system performs against human generated su</context>
</contexts>
<marker>Li, Deng, Zhu, 2011</marker>
<rawString>Peifeng Li, Guangxi Deng, and Qiaoming Zhu. 2011a. Using context inference to improve sentence ordering for multi-document summarization. In Proceedings of IJCNLP 2011, pages 1055–1061.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Li</author>
<author>Yinglin Wang</author>
<author>Wei Gao</author>
<author>Jing Jiang</author>
</authors>
<title>Generating aspect-oriented multi-document summarization with event-aspect model.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP 2011,</booktitle>
<pages>1137--1146</pages>
<contexts>
<context position="4596" citStr="Li et al., 2011" startWordPosition="692" endWordPosition="695">ttee, asked the Foreign setbacks in preparations led officials of the Olympic Council of Asia late Ministry to urge the Saudi government to reconsider withdrawing last year to threaten to move the games to another country. its 105-strong team. • Thailand showed its nearly complete facilities for the Asian Games to • The games will be a success. a tough jury Thursday - the heads of the organizing committees from the 43 nations competing in the December event. Table 1: Pairs of sentences produced by a pipeline of a state-of-the-art sentence extractor (Lin and Bilmes, 2011) and sentence orderer (Li et al., 2011a), and by G-FLOW. graph to estimate coherence of a candidate summary. Second, G-FLOW introduces a novel methodology for joint sentence selection and ordering (Section 4). It casts MDS as a constraint optimization problem where salience and coherence are soft constraints, and redundancy and summary length are hard constraints. Because this optimization problem is NPhard, G-FLOW uses local search to approximate it. We report on a Mechanical Turk evaluation that directly compares G-FLOW to state-of-the-art MDS systems. Using DUC’04 as our test set, we compare G-FLOW against a combination of an e</context>
<context position="8363" citStr="Li et al., 2011" startWordPosition="1274" endWordPosition="1277">um marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relate</context>
<context position="25446" citStr="Li et al., 2011" startWordPosition="4060" endWordPosition="4063">ster of doc1168 uments also includes four gold standard summaries used for evaluation. As in the DUC’04 competition, we allowed 665 bytes for each summary including spaces and punctuation. We used DUC’03 as our development set, which contains 30 document clusters, again with approximately 10 documents each. We compared G-FLOW against four systems. The first is a recent MDS extractive summarizer, which we choose for its state-of-the-art ROUGE scores (Lin and Bilmes, 2011).4 The second is a pipeline of Lin’s system followed by a reimplementation of a state-of-the-art sentence reordering system (Li et al., 2011a). We refer to these systems as LIN and LIN-LI, respectively. This second baseline allows us to quantify the advantage of using coherence as a factor in both sentence extraction and ordering. We also compare against the system that had the highest coherence ratings at DUC’04 (Nobata and Sekine, 2004), which we refer to as NOBATA. As this system did not preform sentence ordering on its output, we also compare against a pipeline of Nobata’s system and the sentence reordering system. We refer to this system as NOBATA-LI. Lastly, to evaluate how well the system performs against human generated su</context>
</contexts>
<marker>Li, Wang, Gao, Jiang, 2011</marker>
<rawString>Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011b. Generating aspect-oriented multi-document summarization with event-aspect model. In Proceedings of EMNLP 2011, pages 1137–1146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Lin</author>
<author>Jeff Bilmes</author>
</authors>
<title>A class of submodular functions for document summarization.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL 2011,</booktitle>
<pages>510--520</pages>
<contexts>
<context position="4558" citStr="Lin and Bilmes, 2011" startWordPosition="685" endWordPosition="688">95, but Bangkok Asian Games Organizing Committee, asked the Foreign setbacks in preparations led officials of the Olympic Council of Asia late Ministry to urge the Saudi government to reconsider withdrawing last year to threaten to move the games to another country. its 105-strong team. • Thailand showed its nearly complete facilities for the Asian Games to • The games will be a success. a tough jury Thursday - the heads of the organizing committees from the 43 nations competing in the December event. Table 1: Pairs of sentences produced by a pipeline of a state-of-the-art sentence extractor (Lin and Bilmes, 2011) and sentence orderer (Li et al., 2011a), and by G-FLOW. graph to estimate coherence of a candidate summary. Second, G-FLOW introduces a novel methodology for joint sentence selection and ordering (Section 4). It casts MDS as a constraint optimization problem where salience and coherence are soft constraints, and redundancy and summary length are hard constraints. Because this optimization problem is NPhard, G-FLOW uses local search to approximate it. We report on a Mechanical Turk evaluation that directly compares G-FLOW to state-of-the-art MDS systems. Using DUC’04 as our test set, we compar</context>
<context position="8116" citStr="Lin and Bilmes, 2011" startWordPosition="1236" endWordPosition="1239">ly-created discourse models in MDS. Our approach is fully automated. 2.1 Subset Selection in MDS Most extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often re</context>
<context position="25306" citStr="Lin and Bilmes, 2011" startWordPosition="4038" endWordPosition="4041">’04 multi-document summarization dataset. This dataset consists of 50 clusters of related documents, each of which contains 10 documents. Each cluster of doc1168 uments also includes four gold standard summaries used for evaluation. As in the DUC’04 competition, we allowed 665 bytes for each summary including spaces and punctuation. We used DUC’03 as our development set, which contains 30 document clusters, again with approximately 10 documents each. We compared G-FLOW against four systems. The first is a recent MDS extractive summarizer, which we choose for its state-of-the-art ROUGE scores (Lin and Bilmes, 2011).4 The second is a pipeline of Lin’s system followed by a reimplementation of a state-of-the-art sentence reordering system (Li et al., 2011a). We refer to these systems as LIN and LIN-LI, respectively. This second baseline allows us to quantify the advantage of using coherence as a factor in both sentence extraction and ordering. We also compare against the system that had the highest coherence ratings at DUC’04 (Nobata and Sekine, 2004), which we refer to as NOBATA. As this system did not preform sentence ordering on its output, we also compare against a pipeline of Nobata’s system and the s</context>
</contexts>
<marker>Lin, Bilmes, 2011</marker>
<rawString>Hui Lin and Jeff Bilmes. 2011. A class of submodular functions for document summarization. In Proceedings of ACL 2011, pages 510–520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop,</booktitle>
<pages>74--81</pages>
<contexts>
<context position="8644" citStr="Lin, 2004" startWordPosition="1321" endWordPosition="1322">d Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and entity coherence for reordering sentences (Barzilay et al., 2001; Okazaki et al., 2004; Barzilay and Lapata, 2008; Bollegala et al., 2010). Recent work has also used event-based models (Zhang et al., 2010) and context analysis (Li et </context>
<context position="31701" citStr="Lin, 2004" startWordPosition="5058" endWordPosition="5059">FLOW 37.33 37.43 Gold Standard Summaries 40.03 40.03 Table 3: ROUGE-1 recall and F-measure results (%) on DUC-04. Some values are missing because not all systems reported both F-measure and recall. dundancy’. Given the results from the previous section, G-FLOW is likely performing worse on categories not conveyed in these scores, such as Coverage, which we examine next. 5.3.1 Coverage Evaluation using ROUGE Most recent research has focused on the ROUGE evaluation, and thus implicitly on coverage of information in a summary. To estimate the coverage of G-FLOW, we compared the systems on ROUGE (Lin, 2004). We calculated ROUGE-1 scores for G-FLOW, LIN, and NOBATA.6 As sentence ordering does not matter for ROUGE, we do not include LIN-LI or NOBATA-LI in this evaluation. Because our algorithm does not explicitly maximize coverage while LIN does, we expected G-FLOW to perform slightly worse than LIN. The ROUGE-1 scores for G-FLOW, LIN, NOBATA and other recent MDS systems are listed in Table 3. We also include the ROUGE-1 scores for the gold summaries (compared to the other gold summaries). G-FLOW has slightly lower scores than LIN and the gold standard summaries, but much higher scores than NOBATA</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Text Summarization Branches Out: Proceedings of the ACL-04 Workshop, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>Automatic summary evaluation without using human models.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>306--314</pages>
<contexts>
<context position="11418" citStr="Louis and Nenkova, 2009" startWordPosition="1744" endWordPosition="1747">0). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summarization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzilay and Lapata, 2008; Louis and Nenkova, 2009; Pitler et al., 2010). Finally, there is work on generating coherent summaries in specific domains, such as scientific articles (Saggion and Lapalme, 2002; Abu-Jbara and Radev, 2011) using domain-specific cues like citations. In contrast, our work generates summaries without any domain-specific knowledge. Other research has focused on identifying coherent threads of documents rather than sentences (Shahaf and Guestrin, 2010). 3 Discourse Graph As described in Section 1, our goal is to identify pairwise ordering constraints over a set of input sentences. These constraints specify a multi-docum</context>
</contexts>
<marker>Louis, Nenkova, 2009</marker>
<rawString>Annie Louis and Ani Nenkova. 2009. Automatic summary evaluation without using human models. In Proceedings of EMNLP 2009, pages 306–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Aravind Joshi</author>
<author>Rashmi Prasad</author>
<author>Ani Nenkova</author>
</authors>
<title>Using entity features to classify implicit discourse relations.</title>
<date>2010</date>
<booktitle>In Proceedings of SIGDIAL</booktitle>
<pages>59--62</pages>
<contexts>
<context position="10353" citStr="Louis et al., 2010" startWordPosition="1578" endWordPosition="1581">valuation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summariza</context>
</contexts>
<marker>Louis, Joshi, Prasad, Nenkova, 2010</marker>
<rawString>Annie Louis, Aravind Joshi, Rashmi Prasad, and Ani Nenkova. 2010. Using entity features to classify implicit discourse relations. In Proceedings of SIGDIAL 2010, pages 59–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
</authors>
<title>Automatic Summarization.</title>
<date>2001</date>
<publisher>John Benjamins Publishing Co, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="10280" citStr="Mani, 2001" startWordPosition="1568" endWordPosition="1569">spective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation </context>
</contexts>
<marker>Mani, 2001</marker>
<rawString>Inderjeet Mani. 2001. Automatic Summarization. John Benjamins Publishing Co, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="10138" citStr="Mann and Thompson, 1988" startWordPosition="1545" endWordPosition="1549">ence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been</context>
<context position="12754" citStr="Mann and Thompson, 1988" startWordPosition="1963" endWordPosition="1966">each vertex is a sentence and an edge from sz to sj indicates that sj can be placed right after sz in a coherent summary. In other words, the two share a discourse relationship. In the fol1165 lowing three sentences (from possibly different documents) there should be an edge from s1 to s2, but not between s3 and the other sentences: s1 Militants attacked a market in Jerusalem. s2 Arafat condemned the bombing. s3 The Wye River Accord was signed in Oct. Discourse theories have proposed a variety of relationships between sentences such as background and interpretation. RST has 17 such relations (Mann and Thompson, 1988) and PDTB has 16 (Prasad et al., 2008). While we seek to identify pairs of sentences that have a relationship, we do not attempt to label the edges with the exact relation. We use textual cues from the discourse literature in combination with the redundancy inherent in related documents to generate edges. Because this methodology is noisy, the graph used by G-FLOW is an approximation, which we refer to as an approximate discourse graph (ADG). We first describe the construction of this graph, and then discuss the use of the graph for summary generation (Section 4). 3.1 Deverbal Noun Reference O</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Abdessamad Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>368--375</pages>
<contexts>
<context position="15423" citStr="Marcu and Echihabi, 2002" startWordPosition="2425" endWordPosition="2428">ontaining these verb to noun mappings. To our knowledge, we are the first to use deverbal nouns for summarization. 3.2 Event/Entity Continuation Our second indicator is related to lexical chains (Barzilay and Lapata, 2008). We add an edge in the ADG from a sentence sz to sj if they contain the same event or entity and the timestamp of sz is less than or equal to the timestamp of sj (timestamps generated with (Chang and Manning, 2012)). 3.3 Discourse Markers We use 36 explicit discourse markers (e.g., ‘but’, ‘however’, ‘moreover’) to identify edges between two adjacent sentences of a document (Marcu and Echihabi, 2002). This indicator lets us learn an edge from s4 to s5 below: s4 Arafat condemned the bombing. s5 However, Netanyahu suspended peace talks. 3.4 Inferred Edges We exploit the redundancy of information in MDS documents to infer edges to related sentences. An edge (s, s&apos;&apos;) can be inferred if there is an existing edge (s, s&apos;) and s&apos; and s&apos;&apos; express similar information. As an example, the edge (s6, s7) can be inferred based on edge (s4, s5): s6 Arafat condemned the attack. s7 Netanyahu has suspended the talks. To infer edges we need an algorithm to identify sentences expressing similar information. T</context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>Daniel Marcu and Abdessamad Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of ACL 2002, pages 368–375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>From discourse structures to text summaries.</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization,</booktitle>
<pages>82--88</pages>
<contexts>
<context position="10268" citStr="Marcu, 1997" startWordPosition="1566" endWordPosition="1567">summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. From discourse structures to text summaries. In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization, pages 82–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schmitz Mausam</author>
<author>Robert Bart</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Open language learning for information extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP 2012,</booktitle>
<pages>523--534</pages>
<contexts>
<context position="20442" citStr="Mausam et al., 2012" startWordPosition="3264" endWordPosition="3267"> The complete list of features and learned weights is in Table 2. The classifier finds a sentence more salient if it mentions nouns or verbs that are present in more sentences across the documents. The highest ranked features are the last three – number of other sentences that mention a noun or a verb in the given sentence. We use the same procedure as in deverbal nouns for detecting verb mentions that appear as nouns in other sentences (Section 3.1). 4.3 Redundancy We also wish to avoid redundancy. G-FLOW first processes each sentence with a state-of-the-art Open Information extractor OLLIE (Mausam et al., 2012), which converts a sentence into its component relational tuples of the form (arg1, relational phrase, 1167 arg2).3 For example, it finds (Militants, bombed, a marketplace) as a tuple from sentence s12. Two sentences will express redundant information if they both contain the same or synonymous component fact(s). Unfortunately, detecting synonymy even at relational tuple level is very hard. G-FLOW approximates this synonymy by considering two relational tuples synonymous if the relation phrases contain verbs that are synonyms of each other, have at least one synonymous argument, and are timest</context>
</contexts>
<marker>Mausam, Bart, Soderland, Etzioni, 2012</marker>
<rawString>Mausam, Michael Schmitz, Robert Bart, Stephen Soderland, and Oren Etzioni. 2012. Open language learning for information extraction. In Proceedings of EMNLP 2012, pages 523–534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
<author>Dragomir Radev</author>
</authors>
<title>Generating summaries of multiple news articles.</title>
<date>1995</date>
<booktitle>In Proceedings of SIGIR</booktitle>
<pages>74--82</pages>
<contexts>
<context position="10620" citStr="McKeown and Radev, 1995" startWordPosition="1618" endWordPosition="1621">iscourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summarization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the s</context>
</contexts>
<marker>McKeown, Radev, 1995</marker>
<rawString>Kathleen McKeown and Dragomir Radev. 1995. Generating summaries of multiple news articles. In Proceedings of SIGIR 1995, pages 74–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikashi Nobata</author>
<author>Satoshi Sekine</author>
</authors>
<title>Crl/nyu summarization system at duc-2004.</title>
<date>2004</date>
<booktitle>In Proceedings of DUC</booktitle>
<contexts>
<context position="5490" citStr="Nobata and Sekine, 2004" startWordPosition="829" endWordPosition="832">s, and redundancy and summary length are hard constraints. Because this optimization problem is NPhard, G-FLOW uses local search to approximate it. We report on a Mechanical Turk evaluation that directly compares G-FLOW to state-of-the-art MDS systems. Using DUC’04 as our test set, we compare G-FLOW against a combination of an extractive summarization system with state-of-the-art ROUGE scores (Lin and Bilmes, 2011) followed by a stateof-the-art sentence reordering scheme (Li et al., 2011a). We also compare G-FLOW to a combination of an extractive system with state-of-the-art coherence scores (Nobata and Sekine, 2004) followed by the reordering system. In both cases participants substantially preferred G-FLOW. Participants chose G-FLOW 54% of the time when compared to Lin, and chose Lin’s system 22% of the time. When compared to Nobata, participants chose G-FLOW 60% of the time, and chose Nobata only 20% of the time. The remainder of the cases were judged equivalent. A further analysis shows that G-FLOW’s summaries are judged superior along several dimensions suggested in the DUC’04 evaluation (including coherence, repetitive text, and referents). A comparison against manually written, gold standard summar</context>
<context position="25748" citStr="Nobata and Sekine, 2004" startWordPosition="4109" endWordPosition="4112">documents each. We compared G-FLOW against four systems. The first is a recent MDS extractive summarizer, which we choose for its state-of-the-art ROUGE scores (Lin and Bilmes, 2011).4 The second is a pipeline of Lin’s system followed by a reimplementation of a state-of-the-art sentence reordering system (Li et al., 2011a). We refer to these systems as LIN and LIN-LI, respectively. This second baseline allows us to quantify the advantage of using coherence as a factor in both sentence extraction and ordering. We also compare against the system that had the highest coherence ratings at DUC’04 (Nobata and Sekine, 2004), which we refer to as NOBATA. As this system did not preform sentence ordering on its output, we also compare against a pipeline of Nobata’s system and the sentence reordering system. We refer to this system as NOBATA-LI. Lastly, to evaluate how well the system performs against human generated summaries, we compare against the gold standard summaries provided by DUC. 5.2 Overall Summary Quality Following (Haghighi and Vanderwende, 2009) and (Celikyilmaz and Hakkani-Tur, 2010), to compare overall summary quality, we asked AMT workers to compare two candidate system summaries. The workers first</context>
<context position="28340" citStr="Nobata and Sekine, 2004" startWordPosition="4524" endWordPosition="4528"> summaries more carefully, and found that occasionally, G-FLOW will sacrifice a small amount of coverage for coherence, resulting in lower performance in those cases (see Section 5.3.1). We also compared LIN and LIN-LI, and found that reordering does not improve performance by much. LIN-LI Indifferent LIN 32% 38% 30% While the scores presented above represent comparisons between G-FLOW and a summarization system with state-of-the-art ROUGE scores, we also compared against a summarization system with state-of-the-art coherence scores – the system with the highest coherence scores from DUC’04, (Nobata and Sekine, 2004). We found that G-FLOW was again preferred: G-FLOW Indifferent NOBATA 68% 10% 22% Adding in sentence ordering again improved the scores for the comparison system somewhat: G-FLOW Indifferent NOBATA-LI 60% 20% 20% While these scores show a significant improvement over previous sytems, they do not convey how well G-FLOW compares to the gold standard – manually generated summaries. As a final experiment, we compared G-FLOW and a second, manually generated summary: 1169 G-FLOW Indifferent Gold 14% 18% 68% While we were pleased that in 32% of the cases, Turkers either preferred G-FLOW or were indif</context>
</contexts>
<marker>Nobata, Sekine, 2004</marker>
<rawString>Chikashi Nobata and Satoshi Sekine. 2004. Crl/nyu summarization system at duc-2004. In Proceedings of DUC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
<author>Yutaka Matsuo</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Improving chronological sentence ordering by precedence relation.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>750--756</pages>
<contexts>
<context position="9096" citStr="Okazaki et al., 2004" startWordPosition="1383" endWordPosition="1386">erata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and entity coherence for reordering sentences (Barzilay et al., 2001; Okazaki et al., 2004; Barzilay and Lapata, 2008; Bollegala et al., 2010). Recent work has also used event-based models (Zhang et al., 2010) and context analysis (Li et al., 2011a). The hypothesis in this research is that a pipelined combination of subset selection and reordering will produce high-quality summaries. Unfortunately, this is not true in practice, because sentences are selected primarily for coverage without regard to coherence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succee</context>
</contexts>
<marker>Okazaki, Matsuo, Ishizuka, 2004</marker>
<rawString>Naoaki Okazaki, Yutaka Matsuo, and Mitsuru Ishizuka. 2004. Improving chronological sentence ordering by precedence relation. In Proceedings of COLING 2004, pages 750–756.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>Automatic evaluation of linguistic quality in multidocument summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL</booktitle>
<pages>544--554</pages>
<contexts>
<context position="11440" citStr="Pitler et al., 2010" startWordPosition="1748" endWordPosition="1751">s require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summarization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzilay and Lapata, 2008; Louis and Nenkova, 2009; Pitler et al., 2010). Finally, there is work on generating coherent summaries in specific domains, such as scientific articles (Saggion and Lapalme, 2002; Abu-Jbara and Radev, 2011) using domain-specific cues like citations. In contrast, our work generates summaries without any domain-specific knowledge. Other research has focused on identifying coherent threads of documents rather than sentences (Shahaf and Guestrin, 2010). 3 Discourse Graph As described in Section 1, our goal is to identify pairwise ordering constraints over a set of input sentences. These constraints specify a multi-document discourse graph, w</context>
</contexts>
<marker>Pitler, Louis, Nenkova, 2010</marker>
<rawString>Emily Pitler, Annie Louis, and Ani Nenkova. 2010. Automatic evaluation of linguistic quality in multidocument summarization. In Proceedings of ACL 2010, pages 544–554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The Penn Discourse TreeBank 2.0.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="10183" citStr="Prasad et al., 2008" startWordPosition="1554" endWordPosition="1557">tent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge an</context>
<context position="12792" citStr="Prasad et al., 2008" startWordPosition="1971" endWordPosition="1974"> sz to sj indicates that sj can be placed right after sz in a coherent summary. In other words, the two share a discourse relationship. In the fol1165 lowing three sentences (from possibly different documents) there should be an edge from s1 to s2, but not between s3 and the other sentences: s1 Militants attacked a market in Jerusalem. s2 Arafat condemned the bombing. s3 The Wye River Accord was signed in Oct. Discourse theories have proposed a variety of relationships between sentences such as background and interpretation. RST has 17 such relations (Mann and Thompson, 1988) and PDTB has 16 (Prasad et al., 2008). While we seek to identify pairs of sentences that have a relationship, we do not attempt to label the edges with the exact relation. We use textual cues from the discourse literature in combination with the redundancy inherent in related documents to generate edges. Because this methodology is noisy, the graph used by G-FLOW is an approximation, which we refer to as an approximate discourse graph (ADG). We first describe the construction of this graph, and then discuss the use of the graph for summary generation (Section 4). 3.1 Deverbal Noun Reference Often, the main description of an event</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse TreeBank 2.0. In Proceedings of LREC 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vahed Qazvinian</author>
<author>Dragomir R Radev</author>
<author>Arzucan ¨Ozg¨ur</author>
</authors>
<title>Citation summarization through keyphrase extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>895--903</pages>
<marker>Qazvinian, Radev, ¨Ozg¨ur, 2010</marker>
<rawString>Vahed Qazvinian, Dragomir R. Radev, and Arzucan ¨Ozg¨ur. 2010. Citation summarization through keyphrase extraction. In Proceedings of COLING 2010, pages 895–903.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Generating natural language summaries from multiple on-line sources.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>3</issue>
<contexts>
<context position="10646" citStr="Radev and McKeown, 1998" startWordPosition="1622" endWordPosition="1626"> Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summarization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while</context>
</contexts>
<marker>Radev, McKeown, 1998</marker>
<rawString>Dragomir R. Radev and Kathleen R. McKeown. 1998. Generating natural language summaries from multiple on-line sources. Computational Linguistics, 24(3):469–500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Hongyan Jing</author>
<author>Malgorzata Stys</author>
<author>Daniel Tam</author>
</authors>
<title>Centroid-based summarization of multiple documents.</title>
<date>2004</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>40</volume>
<issue>6</issue>
<contexts>
<context position="7882" citStr="Radev et al., 2004" startWordPosition="1198" endWordPosition="1201"> sentences. G-FLOW can be seen as an instance of discoursedriven summarization (Section 2.3). There is prior work in this area, but primarily for summarization of single documents. There is some preliminary work on the use of manually-created discourse models in MDS. Our approach is fully automated. 2.1 Subset Selection in MDS Most extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata </context>
</contexts>
<marker>Radev, Jing, Stys, Tam, 2004</marker>
<rawString>Dragomir R. Radev, Hongyan Jing, Malgorzata Stys, and Daniel Tam. 2004. Centroid-based summarization of multiple documents. Information Processing and Management, 40(6):919–938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="1283" citStr="Radev, 2004" startWordPosition="174" endWordPosition="175"> deverbal nouns, co-reference, and more. This graph enables G-FLOW to estimate the coherence of a candidate summary. We evaluate G-FLOW on Mechanical Turk, and find that it generates dramatically better summaries than an extractive summarizer based on a pipeline of state-of-the-art sentence selection and reordering components, underscoring the value of our joint model. 1 Introduction The goal of multi-document summarization (MDS) is to produce high quality summaries of collections of related documents. Most previous work in extractive MDS has studied the problems of sentence selection (e.g., (Radev, 2004; Haghighi and Vanderwende, 2009)) and sentence ordering (e.g., (Lapata, 2003; Barzilay and Lapata, 2008)) separately, but we believe that a joint model is necessary to produce coherent summaries. The intuition is simple: if the sentences in a summary are first selected—without regard to coherence—then a satisfactory ordering of the selected sentences may not exist. 1System and data at http://knowitall.cs.washington.edu/gflow/ 1163 Figure 1: An example of a discourse graph covering a bombing and its aftermath, indicating the source document for each node. A coherent summary should begin with t</context>
<context position="8216" citStr="Radev, 2004" startWordPosition="1255" endWordPosition="1256">ive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated</context>
</contexts>
<marker>Radev, 2004</marker>
<rawString>Dragomir R. Radev. 2004. LexRank: Graph-based lexical centrality as salience in text summarization. Journal ofArtificial Intelligence Research, 22(1):457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
<author>Robert Gaizauskas</author>
</authors>
<title>Multidocument summarization by cluster/profile relevance and redundancy removal.</title>
<date>2004</date>
<booktitle>In Proceedings of DUC</booktitle>
<contexts>
<context position="7861" citStr="Saggion and Gaizauskas, 2004" startWordPosition="1193" endWordPosition="1197">ection and ordering of summary sentences. G-FLOW can be seen as an instance of discoursedriven summarization (Section 2.3). There is prior work in this area, but primarily for summarization of single documents. There is some preliminary work on the use of manually-created discourse models in MDS. Our approach is fully automated. 2.1 Subset Selection in MDS Most extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as o</context>
</contexts>
<marker>Saggion, Gaizauskas, 2004</marker>
<rawString>Horacio Saggion and Robert Gaizauskas. 2004. Multidocument summarization by cluster/profile relevance and redundancy removal. In Proceedings of DUC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
<author>Guy Lapalme</author>
</authors>
<title>Generating indicative-informative summaries with sumUM.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>4</issue>
<contexts>
<context position="11573" citStr="Saggion and Lapalme, 2002" startWordPosition="1769" endWordPosition="1772">arization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzilay and Lapata, 2008; Louis and Nenkova, 2009; Pitler et al., 2010). Finally, there is work on generating coherent summaries in specific domains, such as scientific articles (Saggion and Lapalme, 2002; Abu-Jbara and Radev, 2011) using domain-specific cues like citations. In contrast, our work generates summaries without any domain-specific knowledge. Other research has focused on identifying coherent threads of documents rather than sentences (Shahaf and Guestrin, 2010). 3 Discourse Graph As described in Section 1, our goal is to identify pairwise ordering constraints over a set of input sentences. These constraints specify a multi-document discourse graph, which is used by G-FLOW to evaluate the coherence of a candidate summary. In this graph G, each vertex is a sentence and an edge from </context>
</contexts>
<marker>Saggion, Lapalme, 2002</marker>
<rawString>Horacio Saggion and Guy Lapalme. 2002. Generating indicative-informative summaries with sumUM. Computational Linguistics, 28(4):497–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dafna Shahaf</author>
<author>Carlos Guestrin</author>
</authors>
<title>Connecting the dots between news articles.</title>
<date>2010</date>
<booktitle>In Proceedings of KDD</booktitle>
<pages>623--632</pages>
<contexts>
<context position="11847" citStr="Shahaf and Guestrin, 2010" startWordPosition="1806" endWordPosition="1809">ntences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzilay and Lapata, 2008; Louis and Nenkova, 2009; Pitler et al., 2010). Finally, there is work on generating coherent summaries in specific domains, such as scientific articles (Saggion and Lapalme, 2002; Abu-Jbara and Radev, 2011) using domain-specific cues like citations. In contrast, our work generates summaries without any domain-specific knowledge. Other research has focused on identifying coherent threads of documents rather than sentences (Shahaf and Guestrin, 2010). 3 Discourse Graph As described in Section 1, our goal is to identify pairwise ordering constraints over a set of input sentences. These constraints specify a multi-document discourse graph, which is used by G-FLOW to evaluate the coherence of a candidate summary. In this graph G, each vertex is a sentence and an edge from sz to sj indicates that sj can be placed right after sz in a coherent summary. In other words, the two share a discourse relationship. In the fol1165 lowing three sentences (from possibly different documents) there should be an edge from s1 to s2, but not between s3 and the</context>
</contexts>
<marker>Shahaf, Guestrin, 2010</marker>
<rawString>Dafna Shahaf and Carlos Guestrin. 2010. Connecting the dots between news articles. In Proceedings of KDD 2010, pages 623–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chao Shen</author>
<author>Tao Li</author>
</authors>
<title>Multi-document summarization via the minimum dominating set.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>984--992</pages>
<contexts>
<context position="8045" citStr="Shen and Li, 2010" startWordPosition="1224" endWordPosition="1227">ingle documents. There is some preliminary work on the use of manually-created discourse models in MDS. Our approach is fully automated. 2.1 Subset Selection in MDS Most extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the selected sentences into an intelligible summary. They are often evaluted by ROUGE (Lin, 2004),</context>
</contexts>
<marker>Shen, Li, 2010</marker>
<rawString>Chao Shen and Tao Li. 2010. Multi-document summarization via the minimum dominating set. In Proceedings of Coling 2010, pages 984–992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>William C Mann</author>
</authors>
<date>2006</date>
<booktitle>Applications of rhetorical structure theory. Discourse Studies,</booktitle>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="10304" citStr="Taboada and Mann, 2006" startWordPosition="1570" endWordPosition="1573">how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents.</context>
</contexts>
<marker>Taboada, Mann, 2006</marker>
<rawString>Maite Taboada and William C. Mann. 2006. Applications of rhetorical structure theory. Discourse Studies, 8(4):567–588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
</authors>
<title>Text summarization model based on maximum coverage problem and its variant.</title>
<date>2009</date>
<booktitle>In Proceedings ofEACL 2009,</booktitle>
<pages>781--789</pages>
<contexts>
<context position="7953" citStr="Takamura and Okumura, 2009" startWordPosition="1209" endWordPosition="1212"> summarization (Section 2.3). There is prior work in this area, but primarily for summarization of single documents. There is some preliminary work on the use of manually-created discourse models in MDS. Our approach is fully automated. 2.1 Subset Selection in MDS Most extractive summarization research aims to increase the coverage of concepts and entities while reducing redundancy. Approaches include the use of maximum marginal relevance (Carbonell and Goldstein, 1998), centroid-based summarization (Saggion and Gaizauskas, 2004; Radev et al., 2004), cov1164 ering weighted scores of concepts (Takamura and Okumura, 2009; Qazvinian et al., 2010), formulation as minimum dominating set problem (Shen and Li, 2010), and use of submodularity in sentence selection (Lin and Bilmes, 2011). Graph centrality has also been used to estimate the salience of a sentence (Erkan and Radev, 2004). Approaches to content analysis include generative topic models (Haghighi and Vanderwende, 2009; Celikyilmaz and HakkaniTur, 2010; Li et al., 2011b), and discriminative models (Aker et al., 2010). These approaches do not consider coherence as one of the desiderata in sentence selection. Moreover, they do not attempt to organize the se</context>
<context position="31064" citStr="Takamura and Okumura (2009)" startWordPosition="4950" endWordPosition="4953">tter on ‘Grammatical’ and ‘Formatting’ because it tends to choose longer sentences than other systems, which are less likely to be sentence segmentation errors. There may also be some bleeding from one dimension to the other – if a worker likes one summary she may score it highly for many dimensions. Finally, somewhat surprisingly, we find GFLOW’s performance to be nearly that of human summaries. G-FLOW is rated statistically significantly lower than the gold summaries on only ‘Re5http://duc.nist.gov/duc2004/quality.questions.txt System R F NOBATA 30.44 34.36 Best system in DUC-04 38.28 37.94 Takamura and Okumura (2009) 38.50 - LIN 39.35 38.90 G-FLOW 37.33 37.43 Gold Standard Summaries 40.03 40.03 Table 3: ROUGE-1 recall and F-measure results (%) on DUC-04. Some values are missing because not all systems reported both F-measure and recall. dundancy’. Given the results from the previous section, G-FLOW is likely performing worse on categories not conveyed in these scores, such as Coverage, which we examine next. 5.3.1 Coverage Evaluation using ROUGE Most recent research has focused on the ROUGE evaluation, and thus implicitly on coverage of information in a summary. To estimate the coverage of G-FLOW, we comp</context>
</contexts>
<marker>Takamura, Okumura, 2009</marker>
<rawString>Hiroya Takamura and Manabu Okumura. 2009. Text summarization model based on maximum coverage problem and its variant. In Proceedings ofEACL 2009, pages 781–789.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
</authors>
<title>Representing discourse coherence: A corpus-based study.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="10161" citStr="Wolf and Gibson, 2005" startWordPosition="1550" endWordPosition="1553">ten leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coherence Models and Summarization Research on discourse analysis of documents provides a basis for modeling coherence in a document. Several theories have been developed for modeling discourse, e.g., Centering Theory, Rhetorical Structure Theory (RST), Penn Discourse TreeBank (Grosz and Sidner, 1986; Mann and Thompson, 1988; Wolf and Gibson, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang </context>
</contexts>
<marker>Wolf, Gibson, 2005</marker>
<rawString>Florian Wolf and Edward Gibson. 2005. Representing discourse coherence: A corpus-based study. Computational Linguistics, 31(2):249–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhu Zhang</author>
<author>Sasha Blair-Goldensohn</author>
<author>Dragomir R Radev</author>
</authors>
<title>Towards CST-enhanced summarization.</title>
<date>2002</date>
<booktitle>In Proceedings of AAAI</booktitle>
<pages>439--445</pages>
<contexts>
<context position="10773" citStr="Zhang et al., 2002" startWordPosition="1643" endWordPosition="1646">, 2005; Prasad et al., 2008). Numerous discourse-guided summarization algorithms have been developed (Marcu, 1997; Mani, 2001; Taboada and Mann, 2006; Barzilay and Elhadad, 1997; Louis et al., 2010). However, these approaches have been applied to single document summarization and not to MDS. Discourse models have seen some application to summary generation in MDS, for example, using a detailed semantic representation of the source texts (McKeown and Radev, 1995; Radev and McKeown, 1998). A multi-document extension of RST is Cross-document Structure Theory (CST), which has been applied to MDS (Zhang et al., 2002; Jorge and Pardo, 2010). However, these systems require a stronger input, such as a manual CST-annotation of the set of documents. Our work can be seen as an instance of summarization based on lightweight CST. However, a key difference is that our proposed algorithm is completely automated and does not require any additional human annotation. Additionally, while incorporating coherence into selection, this work does not attempt to order the sentences coherently, while our approach performs joint selection and ordering. Discourse models have also been used for evaluating summary quality (Barzi</context>
</contexts>
<marker>Zhang, Blair-Goldensohn, Radev, 2002</marker>
<rawString>Zhu Zhang, Sasha Blair-Goldensohn, and Dragomir R. Radev. 2002. Towards CST-enhanced summarization. In Proceedings of AAAI 2002, pages 439–445.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renxian Zhang</author>
<author>Li Wenjie</author>
<author>Lu Qin</author>
</authors>
<title>Sentence ordering with event-enriched semantics and twolayered clustering for multi-document news summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>1489--1497</pages>
<contexts>
<context position="9215" citStr="Zhang et al., 2010" startWordPosition="1402" endWordPosition="1405">ry. They are often evaluted by ROUGE (Lin, 2004), which is coherence-insensitive. In practice, these approaches often result in incoherent summaries. 2.2 Sentence Reordering A parallel thread of research has investigated taking a set of summary sentences as input and reordering them to make the summary fluent. Various algorithms use some combination of topic-relatedness, chronology, precedence, succession, and entity coherence for reordering sentences (Barzilay et al., 2001; Okazaki et al., 2004; Barzilay and Lapata, 2008; Bollegala et al., 2010). Recent work has also used event-based models (Zhang et al., 2010) and context analysis (Li et al., 2011a). The hypothesis in this research is that a pipelined combination of subset selection and reordering will produce high-quality summaries. Unfortunately, this is not true in practice, because sentences are selected primarily for coverage without regard to coherence. This methodology often leads to an inadvertent selection of a set of disconnected sentences, which cannot be put together in a coherent summary, irrespective of how the succeeding algorithm reorders them. In our evaluation, reordering had limited impact on the quality of the summaries. 2.3 Coh</context>
</contexts>
<marker>Zhang, Wenjie, Qin, 2010</marker>
<rawString>Renxian Zhang, Li Wenjie, and Lu Qin. 2010. Sentence ordering with event-enriched semantics and twolayered clustering for multi-document news summarization. In Proceedings of COLING 2010, pages 1489–1497.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>