<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.320583">
Aanerien Journal of Computational Linguistics Microfiche 3
</title>
<author confidence="0.326656">
NATURAL SEMANTICS IN ARTIFICIAL INTELLIGENCE
</author>
<affiliation confidence="0.622102333333333">
Jaime R. Carbonell and, Arlan M. Collins
Bolt Beranek and Newman Inc.
Cambridge, Massachusetts
</affiliation>
<footnote confidence="0.460758">
©1974 by the Association for Computational Linguistics
</footnote>
<page confidence="0.807332">
2
</page>
<sectionHeader confidence="0.694401" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.998318074074074">
This paper discusses human semantic knowledge and processing
in terms of the SCHOLAR system. In one major section we discuss
the imprecision, the incompleteness, the open-endedness, and the
uncertainty of people&apos;s knowledge. In the other major section we
discuss strategies people use to make different types of deductive,
negative, and functional inferences, and the way uncertainties
combine in these inferences.
Impreeision can occur either in memory or in communication.
SCHOLAR can have precise values or fuzzy values stored, and its
procedures can, to some extent, deal with fuzzy questions when
precise values are stored, and with precise queltions when fuzzy
values are stored. Embedding allows information to be specified
in the data base to any level of detail or precision. But SCHOLAR
only communicates the most important information on any topic (as
measured by importance tags), unless more information is requested.
It should also be possible by using importance tags to adjust what
information SCHOLAR communicates, in accord with the sophistication
and interests of the listener.
Inference strategies that are appropriate when the complete
set of object attributes, or values, is known (i.e., in a closed
world) do not apply when knowledge is incomplete (i.e., in an
open world). There are a variety of uncertain inferences that
people use to circumvent the holes in their knowledge, which are
being programmed in SCHOLAR.
There is a set of transitive relations -- superordinate,
superpart, simil&amp;rity, proximity, subordinate, and subpart relations
-- that people frequently u c to make deductive inferences.
</bodyText>
<page confidence="0.762576">
3
</page>
<bodyText confidence="0.96434690625">
Currently SCHOLAR only handles superordinate inferences (e.g.,
the Llanos has a rainy seccon because it is a savanna) and super-
part inferences (e.g., the language in Rio is PortUguese because
Rio is pat of Brazil). Deductive inferences can be more or less
certain (similarity inforances are like suparordinate inferences,
but less certain) and can have restrictions on their u e (only
certain attributes transfer on superpart).
When knowledge is incomplete, it is not safe to assume that
something is not true just because it is not stored. Thus an in-
ference is necessary to decide when to say &amp;quot;No&amp;quot; and when to say
&amp;quot;I don&apos;t know.&amp;quot; There is a complicated set of strategies in
SCHOLAR to find various kinds of contradictions that people use
to say &amp;quot;No.&amp;quot; If a contradiction cannot be found, another negative
inference, called the &amp;quot;lack-of-knowledge&amp;quot; inference, is tried.
When enough is known about an object, it is possible to conclude
that something is not true ..ut that object on the grounds that
if it were true, it would be stored.
Another class of uncertain inference E depends on ill-defined
knowledge of functional dete inants, e.g., that climate depends
on latitude and altitude. Different ways that people use functional
knowledge involve functional calculations (e.g., if a place has a
particular latitude, it probably has a particular climate), func-
tional analogies (e.g., if a place is like another place in latitude
and altitude, it probably has the s e cli .te), and to nn-wer Why
questions (e.g., a place has a particular climte because of its
latitude and altitude).
Different inferences can combine in different way3. So tin
one strategy may call another strategy to find an answer. When
different inferences independently reach the s e or different con-
clusions, they combine to increase or decre3se certainty. The pro-
gramming of uncertain infurcaces is necesrary to make computers a
clever and as fuzzy-thinking Llr; p ple.
</bodyText>
<sectionHeader confidence="0.57845" genericHeader="keywords">
TABLE OF CONTENTS
</sectionHeader>
<table confidence="0.904514647058824">
1 IntrOd1JCt1O11.000000000000000 e0000000000000000000000•00m00o 5
2 The Scholar System as an Environment to Study Natural
Semantics. . .. 0 0 . •P9000 000000000000000000000000000000000 0 . 6
3. Natural Semantic Information.. 00000000000 OOOOOOOOOOOO *0.11
3.1 00000000000000000 000000000 all
Imprecision or Fuzziness.
3.2 Incompleteness, Embedding, and Relevancy.. 0.00..... .12
3.3 The Reference Problem and Context.„... .............. .13
304 Closed versus Open Worlds... .0.0.....0...00.0.00.0. .15
3.5 The True-False Dichotomy and Quantification. .17
4. Natural Inferences0 0. 0 . 0 0 0 0 0 0 0 00000000000000000000000000 ,18
4.1 Deductive Inferences. 0000000000000 00000000000000 . 0 019
4.2 Negative In 00000000000000000000000000 0000 022
4.3 Functional In 0..00000.0000000.0 00000 00000 0.25
404 Inductive Inferences00000 00000000000000000000000000 028
405 Combining Inferences and Accumulating Uncertainty...29
Conclusions..... 0000000000 0 000.....0.000000.0000....000 0 030
</table>
<page confidence="0.817655">
1\.cknOW1edgMents00000000000000000000000000000000000000000030
70 References0000000000000000000000000000000000000000000000032
</page>
<figure confidence="0.5006175">
4
5
</figure>
<sectionHeader confidence="0.764947" genericHeader="introduction">
1. Introduction
</sectionHeader>
<subsectionHeader confidence="0.995752">
In this paper we will discuss how to represent and process
</subsectionHeader>
<bodyText confidence="0.99967675">
information in a computer in way that are natural to people.
This does not mean doing away completely with representations and
procedures which computers have traditionally used, but adding
new representations and procedures which they have not used.
</bodyText>
<subsectionHeader confidence="0.715459">
People often store and communicate imprecise, incomplete,
</subsectionHeader>
<bodyText confidence="0.999834166666667">
and unquantified information; they often assert truth or falsity
in relative terms; and they seldom seem to use rigorous logic in
their inferential processes. Because of these conditions, people
seem to have an almost infinite information processing capacity,
with inference making and problem solving abilities more refined
and far more flexible than any existing computer progr
</bodyText>
<subsectionHeader confidence="0.742738">
How an we study these human capabilities in ord r to make
</subsectionHeader>
<bodyText confidence="0.984651722222222">
our machines show similar performance? A combination of
approaches is perhaps best. Observation of people&apos;s behavior,
introspection, some experimentation, protocol analysis, and
synthesis of computer programs cin all be valuable techniques. A
recent paper (Collins, Warnock and Pas fiume6) discusses a tech-
nique for combining protocol analysis with program synthesis as
applied to tutorial dialogues. The synthesis directs what to
alyze, and the strategies observed in the analyrda are evaluated
by synthesis, in a kind of feedback loop We have been using
the SCHOLAR system in this way as a vehicle for experimentation
with natural semantics.
Before we discuss some of the major problems in natural
semantics, we will briefly describe the SCHOLAR system, since it
is the environment for our research. A word of caution though:
we are only trying to develop some insights, without attempting
to be exhaustive. More questions will be raised than Answers
provided. There are many observable things people do that we do
not know how to simulate.
</bodyText>
<sectionHeader confidence="0.802613" genericHeader="method">
2 The Scholar System as an Environment _to Study Natural
</sectionHeader>
<subsectionHeader confidence="0.542703">
Semantics
</subsectionHeader>
<bodyText confidence="0.9381561">
In this section we will discuss, very briefly, some pertinent
spects of SCHO mixed-initiative instructional system. More
detailed discussio s are provided in Carbonell2&apos;3&apos;4 and Warnock
d Collins14. Several data bases currently exist: one
out the ge graphy of South America, another about the ARPA
net rk, d a third about a text-editing system called NLS.
SCHOLAR s knowledge about any subject tter is in the form of a
st tic se antic network of facts, concepts, and procedur s. This
is a modified and extended network a la Quilli 12 and has a rich
intern 1 structure with a well-d ined syntax.
</bodyText>
<subsectionHeader confidence="0.830224">
Dialogue with SCHOLAR talus place in a subset of English that
</subsectionHeader>
<bodyText confidence="0.977559545454545">
is limited mainly by SCHOLAR&apos;s currently primitive syntactic
capabilities. In tutorial fashion, the system uses its semantic
notork to generate the material it presents, the questions it
asks, and the corrections it makes. At any time SCHOLAR accepts
questions and requests from the student, and generates responses
based on its semantic network, making calculations and inferences
of different types that it has been progca fled to handle. The
dialogue is unanticipated, and is dependent on the student&apos;s
responses, questions, and requests. Figure 1 pretents a sample
protocol of an interaction with SCHOLAR; the person types after
the asterisk and returns control to the system with a second
asterisk.
Figure 2 shows some excerpts of SCHOLAR&apos;s se ntic network.
Properties, none of which are obligatory, can have as values
(single words usually English words defined elsewhere in the
network) numbers, different types of lists, and other properties.
Attributes are usually English words, but there is a set of
special attributes for important relations, like SUPERC (for
superconcept or superordinate, e.g., Li is a city and a capital),
SUPER? (for superpart, e.g., Lima is a part of Peru and South
America), SUPERA (for superattribute„ e.g., fertile refers to soil
and soil refer to topography), APPLIED/TO (color applies to things,
</bodyText>
<page confidence="0.86782">
8
</page>
<sectionHeader confidence="0.98061468" genericHeader="method">
WHAT IS THE LANGUAGE OF ARGENTINA?
*PROBABLY SPANISH*
VERY GOOD.
APPROXIMATELY WHAT IS THE AREA OF ARGENTINA?
*TELL ME SOMETHING ABOUT PERU*
PERU IS A COUNTRY.
IT IS IN WESTERN SOUTH AMERICA.
IT IS ON THE COAST OF THE PACIFIC.
THE CAPITAL IS LIMA.
THE MOUNTAINS ARE NUMEROUS.
THE REGIONS ARE THE AMAZON IUNGLE, THE ATACAMA DESERT, AND
THE ANDES.
NOW YOU CAN EITHER ANSWER MY QUESTION OR ASK A NEW ONE.
*THE AREA OF ARGENTINA IS 10100,000 SQUARE MILES*.
APPROXIMATELY TRUE, BUT A MORE EXACT VALUE 18 1,200,000.
THE EASTERN BORDERING COUNTRY OF PERU IS ---
*CHILD*
NO.
THE SOUTHERN BORDERING COUNTRY OF PERU IS CHILE. THE EASTERN
BORDERING COUNT &apos;Y OF PERU IS BRAZIL.
ERE IS PERU?
*WHAT IS THE MOST IMPORTANT DIFFERENCE BETWEEN PERU AND PARAGUAY?*
THE PRIMARY DIFFERENCE IS:
PERU IS IN WESTERN SOUTH AMERICA.
BUT PARAGUAY IS IN CENTRAL SOUTH AMERICA.
</sectionHeader>
<figureCaption confidence="0.6890705">
Figure l. A Sample Dialogue tween SCHOLAR and a Student.
(Student inputs are enclosed by a terisks.)
</figureCaption>
<table confidence="0.872234909090909">
CAPITAL
SUPERC (I 0) CITY
PLACE (I 0)
OF (I 0) GOVERNMENT
APPLIED/TO (I 4) COUNMY STATE
EXAMPLES (I 2) (SEOR BUENOS/AIRES LIMA MONTEVIDEO
BRASILIA GEORGETOWN CARACAS BOGOTA QUITO
SANTIAGO ASUNCION LA/PAZ WASHINGTON)
FERTILE
CONTRA (I 0) BARREN
SUPERA (I 0) SOIL
PERU
SUPERC (I 0) COUNTRY
SUPERC (I 1 B) SOUTH/AMERICA
LOCATION (I 0)
IN (I 0)
SOUTH/AMERICA (I 0) WESTERN
ON (I 0)
COAST (I 0)
OF (I 0) PACIFIC
LATITUDE (I 4)
RANGE (I 0) -18 0
</table>
<equation confidence="0.9617705">
LONGITUDE (1 5)
RANGE (1 0) -82 -68
BORDERING/COUNTRIES (I 1)
NORTHERN (I 1) (SL COLOMBIA ECUADOR)
EASTERN (I 1) BRAZIL
SOUTHEASTERN (I 1) BOLIVIA
SOUTHERN (I 2) CHILE
CAPITAL (I 1) LIMA
CITIES (I 2)
PRINCIPAL (I 0) ($L LIMA CALLAO AREQUIPA TRUJILLO
</equation>
<figure confidence="0.250201571428571">
CHICLAYO CUZCO)
LIMA
SUPERC (I 0) CITY CAPITAL
SUPERC (I 1 B) PERU SOUTH/AMERICA
LOCATION (I 0)
IN (I 0) PERU
9
</figure>
<figureCaption confidence="0.992671">
Figure 2. Four Partial Entries from SCHOLAR&apos;s Georgraphy Dalt
</figureCaption>
<figure confidence="0.4165725">
Base.
10
</figure>
<bodyText confidence="0.97911804">
nnd c(71pital to countrien and states), CONTRA (for contradittion,e.g.
barren contradicts fertile and democracy contradicts dictatorship),
case-structure attributes like agent and fnstrument (see Fillmore),
and various others.
The entry for location under Peru in Figure 2 illustrates an
important aspect of SCHOLAR&apos;s semantic network called embedding.
Under the attribute location there is the value South America
plus everal subattribut ng which is bordering countries.
But under bordering countrios there are subattributes like northern
and eastern, some of which have several values. Embedding
describes the ability to go down as deep as necessary to describe
a property in n.re or les de il.
In the dat b se ther re al :10 tags, such as the (1 0) after
loc tion ad the (I 1) after bordering countries. These tags are
called importance or isrelevanqt tag
fror 0 to 6. The low -r the tag, the
(1-tags), and they vary
n. re important the piece of
info tion 1, Th tags add up as you go down through 1 er
edded ley Oflr of rhe ways SCHOLAR user I-tags is to
decide what relevant to say at any given ti
Ir the rest of this paper, we will discuss how we are using
SCHOLAR to cope with so e of the probl in tural scAantics.
However, there ar still m ny thral mantics problems w have
not touched.
</bodyText>
<subsectionHeader confidence="0.918999">
30 Natural Semantic Information
</subsectionHeader>
<bodyText confidence="0.950764">
In this section we discuss some aspects of natural semantic
information and its relation to artificial intelligence.
</bodyText>
<subsectionHeader confidence="0.999921">
3.1 Imprecision or Fuzziness
</subsectionHeader>
<bodyText confidence="0.998161875">
Imprecise language is an essential characteristic of human
unication. As Lyons10 says, &amp;quot;Far from being a defect as
some philosophers have suggested, referential &apos;impreciseness&apos;...
kes language a more efficient means of communication.&amp;quot; Talking
about a tall person or a blue-green object does not require
precise specification of height or spectral characteristics. The
imprecision may occur either in communication or storage. If we
say that a colleague receives a large salary, we may or may not
know the figure.
SCHOLAR currently stores areas and populations in numerical
form, but it can respond to the fuzzy question &amp;quot;Is Montevideo
large?&amp;quot; with a pertinent an er like: &amp;quot;It is not one of the
largest cities in South America, but it is the largest city in
Uruguay.&amp;quot; Here SCHOLAR has found t superparts, South America
and Uruguay, and then compared Montevideo to other cities in each
with 4espect to population.
</bodyText>
<page confidence="0.779313">
11
</page>
<bodyText confidence="0.9881595">
However, it is more co n for people to ctore values
recise or &apos;fuzzy&apos;, what Zadeh19 calls &apos;linguistic&apos;
</bodyText>
<footnote confidence="0.382747333333333">
III!
that are
variables. This is the case with values like &apos;large&apos;, &apos;red&apos;, &apos;hot&apos;,
</footnote>
<page confidence="0.537256">
12
</page>
<bodyText confidence="0.796561666666667">
&apos;rich&apos;, etc. It seems to us that one must be able to store
either precise values or fuzzy values interchangeably. (In fact,
SCHOLAR has fuzzy values as well as precise values stored, e.g.,
that the Brazilian Highlands has a large population.) Further-
more, the procedures that act upon these values must be flexible
enough to deal with either.
</bodyText>
<subsectionHeader confidence="0.999147">
3.2 Incompleteness/ Embedding, and Relevancy
</subsectionHeader>
<bodyText confidence="0.906965866666667">
Imprecise statements are often motivated by incomplete
specification. Since all specifications can be refined, they
are essentially incomplete. We store what is necessary, and if
we store more, we only co unicate what is pertinent. SCHOLAR
does thi through its I-tags. If it is asked &amp;quot;Tell me about
Peru,&amp;quot; it only gives a few salient facts.
Further specification can be added by refining existing
v lues. For ex ple, instead of &apos;blue&apos; we can have &apos;Navy blue&apos;,
or &apos;quite dark Navy blue&apos;, etc. Further specification can also
be added by giving new properties with attributes som hat
orthogonal to previous ones. ex. pie of this is &apos;tall
ver us °tall, heavy n wearing glasses&apos;. Properties can be
specified to any level of detL il by e edding, an inherent quality
Li.S
of SCHOLAR-type antic networks.
</bodyText>
<page confidence="0.613515">
13
</page>
<subsectionHeader confidence="0.987067">
1.3 The Reference Problem and Context
</subsectionHeader>
<bodyText confidence="0.9995465">
Somewhat related to incompleteness and relevancy is the
eference problem (see Olson11). R3forring to a colleague,
my &apos;define&apos; him as the father of Jack and Jill, or the author of
that paper on self-referential stat tents, or the tall thin fell
path glasme . We decide on c,oLla specification depending on the
ontext, including our assumptions about the paroon we are talking
to. People usually specify only to the degree that is needed.
In this sense, every partial specification is a &apos;definition&apos;.
The problem of context pervades natural semantics.
Definitions and specifications, anaphoric references, what and
how to answer, all depend on context. Furthermore, there usually
co-exist a range of contexts from overall context to short-te
running contexts. For example, at a given time, SCHOLAR may
have the contexts South America, Argentina and Buenos Aires, each
with some dynamically adjustable life. What is relevarit at any
given time depends on this contextual hierarchy.
A start toward making references specific to the listener
is possible in a SCHOLAR-type syst by using I-tags (see Collins,
Warnock, and Passafiume6). The likelihood that another person
will know about any concept is roughly proportional to the
importance of the concept, as acured by the /-tzigu, with
respect to the overall context. Thurafore, it is possible to
</bodyText>
<page confidence="0.377399">
14
</page>
<bodyText confidence="0.993074391304348">
esti te .the sophistication of a person based On the level of tags
Df the concepts he mentions in his conversation. This estimate
then can influence the description one uses in referring to So
concept. For example, to an unsophisticated listener one might
refer to the &amp;quot;capital of Argentina&amp;quot; rather than &amp;quot;Buenos Aires,&amp;quot;
because the I-tags for the concepts &amp;quot;capital&amp;quot; and &amp;quot;Argentina&amp;quot; are
lo r than those for &amp;quot;Buenos Aires,&amp;quot; as measured from a context
such as geography.
In the future we want to have adjustable contexts in SCHOLAR,
that it can talk about the ARPA network, say, &amp;quot;from a communi-
tions point of view&amp;quot; to one person and &amp;quot;from a progr ing point
of vi w&amp;quot; to another person. What this entails is a temporary
alteration of the r lative values of I-tags throughout the
s antic n twork. Th- concepts that are referred to under the
concept &amp;quot;corr ication&amp;quot; (such as message capacity# bit-rate, etc.)
should be temporarily increased in importance wherever they occur
in data base, for th person interested in communication. A
corresponding change must be de for the person intereoted in
progr i g or ry other concept or set of concepts0 This kind
of s nsitivity to the interests and background of the porson, and
the kind of se itivity (d scribed above) to the sophistication
of the person y be the two major lement in the w y people
t what they say to the listener.
</bodyText>
<sectionHeader confidence="0.307584" genericHeader="method">
15
</sectionHeader>
<subsectionHeader confidence="0.964384">
3.4 2111TAMEME2Mn_int
</subsectionHeader>
<bodyText confidence="0.806887295454546">
In some realms of discourse such as an airline reservations
system (foods17), a blocks world (Winograd15), or a lunar rocks
catalogue (Woods, Kaplan, land Nash-Webbur18), there is a closed
set of objects, attributes, and values to deal with. H ever,
in most real world domains such as those faced by SIR (Raphaella),
TLC (Quillian12) or SCHOLAR (Carbone112), there are open sets of
objects, attributes, and values. It turns out that the procedur s
and even the rules of inference that can be applied are different
in closed and open worlds.
The distinction between closed and open oets is one of
exhaustiveness and not one of size. For ex m.le, the set of
states (e.g., Iowa), which i a closed set for w.t people,
probably larger than the set of cattle breeds (e.g., Holstein),
which is an open set. However, cpen sets t d to be lhrger ml
general than closed sets.
The distinction is important in a variety of way. For
example, if there are no basaltic rocks ntored in a closed dat,J
base, then it makes sense to say &amp;quot;No&amp;quot; to the question &amp;quot;&apos;Were any
basaltic rocks brought back?&amp;quot; But if no &apos;.lcanoes are atored
for the U. S., it does not follow that the answer should be &amp;quot;No&amp;quot;
to the question &amp;quot;Are there any volcanoes in the U. S.?&amp;quot; A more
appropriate answer is &amp;quot;I don&apos;t know. ° Furthermore, it L.17.-Aes
sense to ask what the ouallest block in a scene is or the r k
with lam t umin concentration, but it mks no sense to a k 16
fl
what is the iallest city in Brazil or the least famous lawyer
in the U. S. It uld be an appropriate strategy for deciding
how many flights from Boston to Chicago are nonstop, to consider
each flight d count how many make 0 stops. But it .u1d not
be an appropriate strategy to consider each per .n stored in a
limited data base (such as hurnn have), in order to an=ar the
quection &amp;quot;How many people in the U. S. are over 30 years old?&amp;quot;
Within open worlds there are closed sets, so that a question like
&amp;quot;Hon many tatc are on the Pacific?&amp;quot; makes sense whereas &amp;quot;How
any cities are on the Pacific?&amp;quot; does not. SCHOLAR dOils with
this by di tingui hing e&apos;:hzustive sets from non-exhaustive sets.
We will discuss in Section 4 how SCHOLAR begins to doal with
open orld santici, Th eu enti 1 point her is that the well-
defined p cedures that are appropriato for a clocad world simply
do not carry ovc.):.: to open rld. Unfortunately, 13t of h n
k wledge is open-end d, and so people have complex trategie:.&gt; for
dealing with uncertainty nd facing p bla,m.,; such ao how to apply
new attributes or values to objectstal-el:e they haven&apos;t applied in
the past.
</bodyText>
<sectionHeader confidence="0.28687" genericHeader="method">
17
</sectionHeader>
<subsectionHeader confidence="0.943033">
3.5 The Tuue-False Dichot y and Quantification
</subsectionHeader>
<bodyText confidence="0.958315222222222">
The t.-valued logic that underlies the propositional
calculus and related approachco to inference cannot encompcss
natural saztics. The trouble arises beccuoe truth varies in
degree, in time, in range, in certainty, and in point of view of
the observer, when it is applied to rncil-world objects. re All
briefly examine some of the implications of the multivalued nature
oP truth for natural saaantics,
oiic logic us(A7 quantification to distinguish bet,ecn
the universal and the particular, e.g., between &amp;quot;All men are
</bodyText>
<listItem confidence="0.682249">
• rtal&amp;quot; and &amp;quot;Some men have rts.&amp;quot; But there is no allowance
</listItem>
<bodyText confidence="0.854177846153846">
de for the degreec of truth as between say &amp;quot;Some have warts&amp;quot;
and &amp;quot;Some men hav ears,&amp;quot; even though only a fraction have w-krts
and almotit all have ears. P ple will infer that Newton had ears
(given no information to the contrary a 7.7ith Van Gogh), but will
not infer that Newton h3d warts. The inference in the fol:Lor
case treat the particular like the universal, because all&apos;o t
all men have ear3. The re generally tr c statement is, the
I •
re certainty people cosign to such an inference. Thrn just are
not y universal truths to be found out in the cold, cruel rld,
and so people m-ko tho bo t of it.
Degree of truth ries not only with respect to fuzzy
variables (see Section 3.1) d q ntification, but also in other
</bodyText>
<page confidence="0.371779">
18
</page>
<bodyText confidence="0.993665736842105">
respects. The sky is blue, but not all the time. The yellow of
a le 4,11 is less variable than the yellow of corn, which sometimes
bordors on white. Boston is cold in the winter, but it is not so
cold from the point of view of an tskill• Nixon told us that he
didn&apos;t know about the cover-up of Wntergate, but one is only
rlre or less cc! in that he didn&apos;t know. !That these examples are
designed to show is that people are uncertain about the truth of
any propo ition for a variety of reasons. Sometimes people seem
to merge all the iny sources of uncertainty together, but
someticas they c n distinguish different aspects of their
certainty with respect to a single proposition.
SCHOLAR does not now have y means for representing
cert ..nty, but the natural way to add such information is in
tags st red along with the I-tg . Just an with I-tags, U-tags
car apply at 11 I4edded levels of the data base. Because we
have st rted on progr certain inferences (discussed below),
it has beco e desirable repre ent the underlying uncertainty
in th data base 11, in order to eval te how certain any
inference y be.
</bodyText>
<sectionHeader confidence="0.978645" genericHeader="method">
4. Natural Ihferences
</sectionHeader>
<bodyText confidence="0.967841315789474">
We cllify h L&apos;oEM ntic infrncs into four jor type
deductiv, negative, fnnctional, and inductive inforonco,J. The
various type Lice discussed in somewhat gre ter detail in Collins
19
and Quillian7 And Collins, Carbonell, and Warnock5. We do
not argue that these describe all the inferential strategies that
people use, but only one of the -jor varieties. The different
strategies described are being implamanted as subroutines in
SCHOLAR. Mile we think that people have a large set of such
strategies, the n er is probably less than one hundred.
Itt •
Therefore, despite the inelegance of such an approach, we do not
regard it as an endless task to encompasc the bag of inferential
tricks a person uses.
In Figure 3 we havo included excerpts from tape-recorded
dialogues betwen human tutors and students to illustrate so
of the more complic ted strategies people uno, and the &apos;.ys they
combine together. we will discuss examples individually
below.
</bodyText>
<subsectionHeader confidence="0.988858">
4.1 Deductive Inferences
</subsectionHeader>
<bodyText confidence="0.996376714285714">
There are several trznoitive relations that 1:..ople use
frequently to infer that a property of one thing may be a property
of the other. These include superordinate, superpart, similarity,
proximity, 8: ..rdi te, and subpart relations.
Of tho above types SCHOLAR now handles only superordinate
and supnrpart infcrences, which are the most co n. For example,
if asked &amp;quot;Does the Llanoc h(Ar rainy season?&amp;quot;, SCHOLi&apos;lll will
</bodyText>
<figure confidence="0.982277962962963">
20
(T) There is some jungle in here (points to Venezuela) but
this breaks into a savanna around the Orinoco.
(S) Oh right, that is where they grow the coffee up there?
(T) I don&apos;t think that the savanna is used for graving
coffee. The trouble is the savanna has a rainy season
and 91ou can&apos;t count on rain in general. But I don&apos;t
know. This area around Sao Paulo is coffee region, and
it is sort of getting into the savanna region there.
(S) Are there any other areas where oil is found other than
Venezuela?
(T) Not particularly. T ere is -ome oil offshore there but
in general oil comes from Venezuela. Venezuela is the
only one that&apos;s making any money in oil:
OP.C.91.52.=.122WIMMICIA.90.
(S) Is the Chaco the cattle country? I know the cattle
country is dorm there.
(T) I think it&apos;s more sheep country. It like western Texas
o in som sense I guess it&apos;s cattle country.
4.11d,==ILCOW.COM=10,2.4:11E....
(T) And the northern part of Argentina has a large sort of
reoi-arid plain that extends into Paraguay. And that&apos;s
a plains area that is relatively unpopulated.
(S) Why?
(T) Because its pretty dry.
Figur 3 Tutor-Student Dialogue Excerpts
21
</figure>
<figureCaption confidence="0.830037692307692">
first look under Llanos and failing to find the information
there, will look under Llanosl SUPERC (for superordinate), which
is savanna, and its SUPERP (for superpart), which is Venezuela
and Colombia. A rainy season is a property of savannas and so
the superordinate inference provides the answer. The superpart
inference is less general because it is restricted to certain
attributes such as climate, language, and topography. One would
not want to conclude that the capital of Massachusetts is
Washington, D. C., just because Massachusetts is part of the
United S ates. Because most properties of a superordinate or
superpart are only generally true, and hot universally true,
exceptions must be stored to preclude an incorrect inference
(Raphael&amp;quot;).
</figureCaption>
<bodyText confidence="0.999411909090909">
Similarity and proximity inferences parallel the superordinate
and superpart inferences, but they carry less certainty. An
ample of a person using a proximity inference is shown in the
latter part of the tutor&apos;s response in Example 1 of Figure 3.
The tutor first said that a savanna could not be used for growing
coffee, but then he backed off this conclusion because of the
proximity of the large Brazilian savanna to the coffee-growing
region there. To illustrate a similarity inference: if one
knows a wallaby is like a kangaroo, only amaller, then one will
infer that a wallaby probably has a pouch. We plan to add
similarity information to SCHOLAR in the near future, because it
</bodyText>
<page confidence="0.533485">
22
</page>
<bodyText confidence="0.999556142857143">
will also be useful in making functional analogies which are
discussed below, The tecently added map facility (Warnock and
Collins14) which ties together visual and semantic representations,
makes proximity inferences possible, but they are still a way off.
Subordinate and subpart inferences follow a somewhat different
pattern from the others discussed. If asked whether South America
produces any oil, a person will answer &amp;quot;Yes&amp;quot; because Venezuela,
which is part of South America, produces oil. But one does not
want to conclude that South America is hot because the Amazon
jungle is. We haven&apos;t worked out the details of the restrictions
on these inferences as yet.
There are other transitive relations that are used to :.ke
deductive inferenc s but they are not as prevalent as the ones
outlined here.
</bodyText>
<subsectionHeader confidence="0.939609">
4,2 Negative Inferences
</subsectionHeader>
<bodyText confidence="0.999840142857143">
Negativ info ration, such as the fact that men do not have
wheels, is not usually stored but rather inferred. In a closed
world this presents no problem; it is reasonable to assu that
if pomething is not stored, then it is not true. In fact, early
versions of SCHOLAR say &amp;quot;No&amp;quot; if asked &amp;quot;Is oil a product of Brazil?&amp;quot;
just becilArle oil isn&apos;t stored for Brazil. But in the real .r1d,
the fact that so thing is not stored does not necer-;Fial:ily mean
</bodyText>
<page confidence="0.64733">
23
</page>
<bodyText confidence="0.998140956521739">
that it is not true. People seem to have complex strategies for
dectding when to say &amp;quot;No&amp;quot; and when to say &amp;quot;I don&apos;t know.&amp;quot; We
have recently been implementing these in SCHOLAR.
One kind of negative inference now in SCHOLAR is a simple
contradiction procedure. It relies on contradictory values
stored with various concepts: for example, barren contradicts
fertile, and democracy contradicts dictatorship. Suppose
SCHOLAR is asked &amp;quot;Is the Pampas barren?&amp;quot; It would find the soil
of the P pas is fertile, and since fertile contradicts barren,
it would say &amp;quot;No. The soil of the Pampas is fertile.&amp;quot;
There is an important class of contradictions that are not
subsumed under the procedure above. For example, consider the
question &amp;quot;Is Buenos Aires a city in Brazil?&amp;quot; The fact that
Bueno Aires is not among the cities of Brazil is no reason to
say &amp;quot;No,&amp;quot; because there are cities in Brazil, such as Cor
which are not stored. But there are three facts that ether
II ke a contradiction possible: (1) Buenos Aires is located in
Argentina, (2) cities only have one location, and (3) Argentina
and Brazil are mutually exclusive. We can illustrate the
necessity for conditions (2) and (3): (2) even though Portuguese
is the language of Portugal, it is also the language of Brazil
(i.e., language can have .re than one location); (3) even though
Sao Paulo is in South America, it is alco in Brazil (i.e., South
</bodyText>
<listItem confidence="0.494489">
•
</listItem>
<page confidence="0.717405">
24
</page>
<bodyText confidence="0.998685636363636">
America and Brazil are not mutually exclusive). Making an
incorrect negative inference about cities with More than one
location (e.g., Kansas City) or different cities with the same
name (Rome, New York, and Rome, Italy) is precluded by storing
both locations specifically, just as with deductive inferences.
The strategy we have rked out and implemented to find different
contradictions of this kind is fairly complex.
Failure to find a contradiction leads to another kind of
negative inference people use which call the lack-of-knowledge
inference (Collins, Carbonell and Warnock5). Ex le 2 of
Figure 3 shows the tutor using this strategy. The baci of the
tutor&apos;s inference is this: since he knows as much about other
South Aterican countries as he knows about Venezuela, it is a
plausible but uncertain inference that if other countries produced
oilf h would know about it. (Hid conclusion was at lea ;t
somewhat wrong, because there are in fact several other countries
in South America that produce oil, though for those countries oil
is not nearly so important as it is for Venezuela.)
Sach a strategy is currently being implemented in SCHOLAR in
the following way: If asked a question like &amp;quot;Is oil a product of
Uruguay?&amp;quot; where no oil is stored, SCHOL can look for oil under
similar objects (e.g., Venezuela or Brazil) or objects with the
</bodyText>
<note confidence="0.618122">
e SUPERC and SUPERP. If SCHOLAR finds oil stored with
</note>
<page confidence="0.770922">
25
</page>
<bodyText confidence="0.997474846153846">
Venezuela (say with an I-tag of 3) and if it has enough
information stored about Uruguay (up to an I-tag of 8, say)
to know about oil if it were at all important, then it can infer
that Uruguay probably has no oil. The degree of certainty
exprevsed in the an er should depend on the difference in I-tags
between the depth of what it knows about Uruguay and the level at
which oil is stored with similar objects. If SCHOLAR can find no
kailar objects that have the property in question, as with &amp;quot;Is
sand a product of Uruguay?&amp;quot; the appropriate anscler is something
like &amp;quot;I don&apos;t know whether sand is a product of any country in
South America.&amp;quot; The lack-of-knowledge inference is based on the
assumption that one&apos;s knowledge is fairly consistent for similar
objects.
</bodyText>
<subsectionHeader confidence="0.478539">
403 Functional Inferencos
</subsectionHeader>
<bodyText confidence="0.969135967741936">
Functional inferences are co n in the dialogues CYQ collected
I I I •
(Ccllins, Warnock, and Passafiume6). Examples 1, 3, and 4 in
Figure 3 illuztrate the three different ways tie have s n people
use functional knowledge: in qua i rcalculations, in analogies,
and in an er to &amp;quot;why&amp;quot; quactions,
26
Functional knowledge, which includes knowledge about func-
tional determinants and their interactions, is learned, just
is factual knowledge, and therefore is stored in SCHOLAR&apos;s data
base under concepts such as climate or agricultural products. We
would argue that the representation of functional knowledge
should be in a form that different procedures can use. One
problem is to find a way to represent such knowledge in SCHOLAR
so that it can be more or less precise, and still be accessible
to different subroutines that infer answers to questions or that
describe the functional relation to students.
Functional calculations can be used in both a positive and
negative way. One simple positive function now in SCHOLAR
calculates the climate of a place if the information is not
stored. Based on the major functional determinants of climate,
which are 1 titud d altitude, SCHOLAR will infer whether the
cli te is tropical, sub-tropical, t liperate, or cold/polar. A
negative use of calculation based on the agricultural products
t ction is shown in the first part of the tutor&apos;s answer in
E ple l. The functional determinants of agricultural products
include th clikaLte, soil, and rainfall. The tutor picked the
lack of rain aL ba:Ji3 for a tentative &amp;quot;No.* Negative calcula-
tions do not require as precise knowledge as positive calculations.
They often only require that one or two of the functional
determinants have an inappropriate value.
</bodyText>
<page confidence="0.564252">
27
</page>
<bodyText confidence="0.99993575">
Like functional calculations, functional analogies can be
lositive or negative. Example 3 shows the tutor making a positive
functional analogy, again with the agricultural products function.
rhere he thought of a region, western Texas, that matched the
Maco in terms of climate and rainfall, the functional determin-
ants of cattle raising. Since he knew that western Texas une
cattle country he inferred that the Chaco might be as well. A
negative functional analogy might have occurred if the student
had asked whether the Chaco produced rubber. Since the Amazon
jungle and Indonesia produce rubber, the tutor could have said
&apos;No&amp;quot; on the basis of the mismatch between the Chaco and tho
regions, with respect to climate and rainfall.
A positive and negative analogy subroutine has been
implemented in SCHOLAR. It is a fallback strategy to be used
if there is not enough info fl .tion stored to calculate the
functional relationship. For a functional analogy it is only
necessary to know the functionally relevant attributes and their
relative importance. Then SCHOLAR looks to see if it knows any
similar objects where the property in question is in f ct stored.
It tries to find a match or a mismatch by comparing the gi
object and the similar object with respect to their values on
the functionally relevant attributes. People frequently use
such analogical reasoning, probably because of the ill-defined
nature of their knowledge about functional relations.
</bodyText>
<page confidence="0.304551">
28
</page>
<bodyText confidence="0.998972">
The last example in Figure 3 shoOs the use of a functional
relation to answer a &amp;quot;Why&amp;quot; question. The population density of
a place depends on an indefinite set of functional determinants:
climate, soil, and rainfall are m jor ones but distance from the
sea, the par9.cular continent, presence of valuable minerals, all
contribute in different ways. The tutor picked one determinant
that had a value inappruriate for a large population density
and gave that as a reason. By contrast a geographer could
probably write a whole treatise on why the Chaco has a low
population density. What we aspire for SCHOLAR to do is what the
tutor did, that is, to pick one or two of the majtar determinants
with appropriate values and give those as a reason.
</bodyText>
<sectionHeader confidence="0.365521" genericHeader="method">
404 Inductive Inferences
</sectionHeader>
<bodyText confidence="0.996588666666667">
ntior inductive inference herr only because they are
a major class of h &apos;Ian inference. We have not yet tried to
progr them in SCHOLAR since they occur stly in storing
r ther than retrieving inform tion. The generaliz.tion and dis-
crimination processes underlying induction have been discussed
in de.il elsewhere (Beck r1; Winston16; Collins and Quillian7).
</bodyText>
<page confidence="0.617705">
29
</page>
<subsectionHeader confidence="0.973642">
4.5 CoMbinin9 Inferences and Accumulating Uncertainty
</subsectionHeader>
<bodyText confidence="0.995511913043478">
The inferential proceicsos described can combine in a variety
of ways. For instance, contradictions can combine with deductive
inferences. SCHOLAR will answer a question like &amp;quot;Is the Atlantic
orange?&amp;quot; with &amp;quot;No, it is blue,&amp;quot; becauoe it finds blue i,e7 tored
with the SUPERC, ocean. Also one functional inferonco m3y call
another. If the agricultural products function needs a value for
the climate of some region, it could call the cli te function to
compute it.
A more important way that inferences combine dhows up 01.2.11
different strategies reach independent conclusions about the oLlio
question. A good example is Example 1 in Figure 3. The
negative functional inference, with an implicit lack-of-knowledge
inference, first led to a tentative &amp;quot;No&amp;quot; ansuer, but then a
proximity inference produced a possible &amp;quot;Yes&amp;quot; answer, and so the
tutor backed off his earlier &amp;quot;No.&amp;quot; When several inferences coApine
to yield the same conclusion, they increase the certainty of th
answer, and when they produce opposite conclusions, they decreioc
the certainty.
There are a number of sources of uncertainty in inferential
procedures. Uncertainty can derive from the size of the diffuroace
between I-tags in the lack-of-knowledge inference, it can darive
from the degree of match or mi match in a functional analogy, it
can derive from the degree of predictiveme,Ls of the function ;l
</bodyText>
<page confidence="0.56288">
30
</page>
<bodyText confidence="0.999108285714286">
determinants, and as we discuasal earlier, it can derive from the
degree of certainty about the into tion stored. These sources
of uncertainty iy be combined to produce an overall uncertainty
(r7e for e:,unple Xling9). This ovorcll uncertainty is important
so that long, tenuous chains of roaaoning are not pursued to their
pointless end, and so that the dcgree of uncertainty in the an 77er
can be iadicated to the student.
</bodyText>
<sectionHeader confidence="0.867587" genericHeader="conclusions">
50 Conclusions
</sectionHeader>
<bodyText confidence="0.999174">
What we have tried to show in this paper is the fuzzy, ill-
d fi2 d, uncal:tain nature of much of huun knowledge and thinking.
We int SCHOLAR to be just as fuzzy-thinking as ye are.
</bodyText>
<sectionHeader confidence="0.992932" genericHeader="acknowledgments">
6. Acknowledgments
</sectionHeader>
<bodyText confidence="0.9331035">
This paper was started by Jai R. Carbonell who died
suddenly 1ebruary 2, 1973. I have completed it as best I could
following his outline. I w nt to thank Eleanor H. Warnock who
helped me with the editing and D niel G. Bobrow and s Quillian
wh have contributed rny ides to our work. The progra ing of
variouL urbroUtines described in the paper was done by Nelleke
Aiello, Jaime G. Carbonell, Susan M. Graesser, Mark L. Miller,
Joseph J. Passafiume, and Eleanor H. Warnock, Allan M. Collins.
</bodyText>
<page confidence="0.677032">
31
</page>
<note confidence="0.428945">
This research was supported in part by the Office of Naval
</note>
<sectionHeader confidence="0.603369" genericHeader="references">
Research, Information Systems, under Contract No. NO0014-70-C-0264,
</sectionHeader>
<reference confidence="0.9774705">
and also in part by the Office of Naval Research, Per nnel and
Training, under Contract No. NO0014-71-C-0228, and by the Air
Force Systems Command, Electronic Syst Division, under
Contract No. F19628-72-C-0163.
32
7. References
1. J. D. Becker, &amp;quot;A Model for the Encoding of Expericztial
Information,&amp;quot; in R. Schank &amp; K. Colby (ads.), Computer
Models of Thought and Language, Freeman, San Francisco
(1973).
2. J. R. Carbonell, &amp;quot;Mixed-Iniatiative Man-Computer
Instructional Dialogues.&amp;quot; Ph.D. Thesis, M.I.T., Dept. of
Electrical Engineering (June 1970).
30 J. R. Carbonell, &amp;quot;A. I. in C.A.I.: An Artificial-Intelligence
Approach to Computer-Assisted Instruction&amp;quot; IEEE Trans. on
Man-Machine Syste Vol. MMS-11, No. 4 (December 1970).
4. J. R. Carbonell, &amp;quot;Artificial Intelligence and Large
Inter ctive Man-Computer Syste Proceedings of 1971 IEEE
Syste si M nd Cybernetics Conference, Anaheim, California
(October 1971).
5. A. Coll!su.,„ J. R. Carbonell, and E. H. Warnock, &amp;quot;Semantic
Inferential Processing by Computer&amp;quot; in J. Rose (Ed.) Advances
in Cybernetics and Systems, Gordon &amp; Breach, London (1974).
A. M. Collins, E. H. Warnock, and J. J. Passafiume, &amp;quot;Analysis
and Synthesis of Tutorial Dialogue in G. Bower (Ed.). The
Psychology of Learning and Motivation, Vol. 91 Academic Press
New York, (1975).
33
7, A. M. Collins and D R, Ouiltian, &amp;quot;How to Make a Language
User&amp;quot; in E. Tulving and W. Donaldson (Eds.) Organization of
Memory, Academic Press, New York (1972),
0. C. Fillmore, &amp;quot;The Cc.e for Case&amp;quot; in Bach and Harms (Eds.),
Universals in Linguistic Theory. Holt, Rinehart, and
Winston, N. Y. (1968).
9. R. Kling, &amp;quot;FUZZY PLANNER: Computing Inexactness in a
Procedural Problem Solving Language.&amp;quot; University of
Wisconsin Technical Report No. 168 (February 1973).
10. J. Lyons, Introduction to Theoretical Linguistics,
Cambridge University Press, Cambridge, England (1968).
D. R. Olson, &amp;quot;Language and Thought: AspectS of a Cognitive
Theory of Semantics&amp;quot; Psych. Review, Vol. 77, No. 4 (July 1970).
12. M. R. Quillian, &amp;quot;The Teachable Language Comprehender: A
Simulation Program and Theory of Language&amp;quot; CACM, Vol. 12,
No. 8 (August 1969).
13. B. Raphael, &amp;quot;SIR: A Computer Program for Semantic Information
Retrieval&amp;quot; in M. L. Minsky (Ed.) Semantic Information Process-
ingi M.I.T. Press, Cambridge, Mass. (1968).
14. E. H. Warnock and A. M. Collins, &amp;quot;Semantic Networks&amp;quot; Bolt
Beranek and Newman Inc. Report No. 2833 (May 1974).
34
15. T. Winograd, Understanding Natural Language,
Academic Press, New York. (1972).
16. P. H. Winston, &amp;quot;Learning Structural Descriptions from
Examples,&amp;quot; Project MAC TR-76, M.I.T. (September 1970).
17. W. A. Woods, &amp;quot;Semantics for a Question-Answering
System,&amp;quot; Aiken Computation Laboratory, Report No. NSF-19,
Harvard University (August 1967).
18. Wt A. Woods, R. M. Kaplan, and B. Nash-Webber, &amp;quot;The Lunar
Sciences Natural Language Information System,&amp;quot; Bolt Beranek
and Nern Inc., Report No. 2378 (June&apos;1972).
19. L. A. Zadeh, &amp;quot;Outlining of a New Approach to the Analysis of
Complex Systems and Decision Processes&amp;quot; IEEE Trans. on
Systems, Man, and Cybernetics, Vol. SMC-3, No. 1 (January
1973).
</reference>
<figure confidence="0.938725">
1
(
-, _ ■ - .,----,
</figure>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9845165">of Computational Linguistics 3 NATURAL SEMANTICS IN ARTIFICIAL INTELLIGENCE</title>
<author confidence="0.999982">Jaime R Carbonell and</author>
<author confidence="0.999982">Arlan M Collins</author>
<affiliation confidence="0.993634">Bolt Beranek and Newman Inc.</affiliation>
<address confidence="0.969488">Cambridge, Massachusetts</address>
<note confidence="0.6374175">1974 by the Association for Computational Linguistics 2</note>
<abstract confidence="0.995088870967742">This paper discusses human semantic knowledge and processing in terms of the SCHOLAR system. In one major section we discuss the imprecision, the incompleteness, the open-endedness, and the uncertainty of people&apos;s knowledge. In the other major section we discuss strategies people use to make different types of deductive, negative, and functional inferences, and the way uncertainties combine in these inferences. Impreeision can occur either in memory or in communication. SCHOLAR can have precise values or fuzzy values stored, and its procedures can, to some extent, deal with fuzzy questions when precise values are stored, and with precise queltions when fuzzy values are stored. Embedding allows information to be specified in the data base to any level of detail or precision. But SCHOLAR only communicates the most important information on any topic (as measured by importance tags), unless more information is requested. It should also be possible by using importance tags to adjust what communicates, in accord with the sophistication and interests of the listener. Inference strategies that are appropriate when the complete set of object attributes, or values, is known (i.e., in a closed do when knowledge is incomplete (i.e., in open world). There are a variety of uncertain inferences that people use to circumvent the holes in their knowledge, which are programmed There is a set of transitive relations -superordinate, superpart, simil&amp;rity, proximity, subordinate, and subpart relations -that people frequently u c to make deductive inferences. 3 Currently SCHOLAR only handles superordinate inferences (e.g., the Llanos has a rainy seccon because it is a savanna) and superinferences language in Rio is PortUguese because Rio is pat of Brazil). Deductive inferences can be more or less certain (similarity inforances are like suparordinate inferences, but less certain) and can have restrictions on their u e (only certain attributes transfer on superpart). When knowledge is incomplete, it is not safe to assume that is not just because is stored. Thus an inference is necessary to decide when to say &amp;quot;No&amp;quot; and when to say &amp;quot;I don&apos;t know.&amp;quot; There is a complicated set of strategies in to find kinds of that people use to say &amp;quot;No.&amp;quot; If a contradiction cannot be found, another negative inference, called the &amp;quot;lack-of-knowledge&amp;quot; inference, is tried. When enough is known about an object, it is possible to conclude that something is not true ..ut that object on the grounds that if it were true, it would be stored. Another class of uncertain inference E depends on ill-defined knowledge of functional dete inants, e.g., that climate depends latitude and altitude. Different ways that people use involve calculations (e.g., if a place has a latitude, it probably has particular climate), funcanalogies a place is like another place in latitude and altitude, it probably has the s e cli .te), and to nn-wer Why questions (e.g., a place has a particular climte because of its latitude and altitude). inferences can in different way3. So tin strategy may call another strategy find an answer. When different inferences independently reach the s e or different conthey combine to increase decre3se certainty. The proof uncertain infurcaces is necesrary to computers and as fuzzy-thinking p e0000000000000000000000•00m00o 5</abstract>
<note confidence="0.637734153846154">2 The Scholar System as an Environment to Study Natural . .. 0 0 . 000000000000000000000000000000000 0 6 Natural Semantic Information.. OOOOOOOOOOOO 3.1 000000000 Imprecision or Fuzziness. 3.2 Incompleteness, Embedding, and Relevancy.. 0.00..... .12 3.3 The Reference Problem and Context.„... .............. .13 304 Closed versus Open Worlds... .0.0.....0...00.0.00.0. .15 3.5 The True-False Dichotomy and Quantification. .17 0. 0 . 0 0 0 0 0 0 0 ,18 4.1 Inferences. 00000000000000 0 019 4.2 In 0000 022 4.3 Functional In 0..00000.0000000.0 00000 00000 0.25</note>
<address confidence="0.607957">404 Inferences00000 405 Combining Inferences and Accumulating Uncertainty...29 000.....0.000000.0000....000 0 030 References0000000000000000000000000000000000000000000000032 4</address>
<abstract confidence="0.982252898550725">5 In this paper we will discuss how to represent and process information in a computer in way that are natural to people. This does not mean doing away completely with representations and procedures which computers have traditionally used, but adding new representations and procedures which they have not used. People often store and communicate imprecise, incomplete, unquantified information; they falsity in relative terms; and they seldom seem to use rigorous logic in their inferential processes. Because of these conditions, people have an almost infinite information with inference making and problem solving abilities more refined far more flexible any computer progr How an we study these human capabilities in ord r to make our machines show similar performance? A combination of approaches is perhaps best. Observation of people&apos;s behavior, introspection, some experimentation, protocol analysis, and synthesis of computer programs cin all be valuable techniques. A paper (Collins, Warnock and Pas discusses a techfor protocol analysis program synthesis as to tutorial dialogues. The synthesis what to alyze, and the strategies observed in the analyrda are evaluated in a kind of feedback loop We using the SCHOLAR system in this way as a vehicle for experimentation with natural semantics. Before we discuss some of the major problems in natural semantics, we will briefly describe the SCHOLAR system, since it is the environment for our research. A word of caution though: we are only trying to develop some insights, without attempting to be exhaustive. More questions will be raised than Answers provided. There are many observable things people do that we do not know how to simulate. Scholar as an Environment _to Study Natural Semantics In this section we will discuss, very briefly, some pertinent spects of SCHO mixed-initiative instructional system. More discussio s are provided in and Warnock Several data bases currently exist: one out the ge graphy of South America, another about the ARPA net rk, d a third about a text-editing system called NLS. s knowledge about tter is in the form of a st tic se antic network of facts, concepts, and procedur s. This a modified and extended network a la Quilli 12and has a rich intern 1 structure with a well-d ined syntax. Dialogue with SCHOLAR talus place in a subset of English that is limited mainly by SCHOLAR&apos;s currently primitive syntactic capabilities. In tutorial fashion, the system uses its semantic to generate the material it the it asks, and the corrections it makes. At any time SCHOLAR accepts questions and requests from the student, and generates responses based on its semantic network, making calculations and inferences different types that it has been progca handle. The dialogue is unanticipated, and is dependent on the student&apos;s responses, questions, and requests. Figure 1 pretents a sample of an interaction with person types after the asterisk and returns control to the system with a second asterisk. Figure 2 shows some excerpts of SCHOLAR&apos;s se ntic network. Properties, none of which are obligatory, can have as values (single words usually English words defined elsewhere in the network) numbers, different types of lists, and other properties. Attributes are usually English words, but there is a set of special attributes for important relations, like SUPERC (for or superordinate, e.g., Li a city and a (for superpart, is a part of Peru and South America), SUPERA (for superattribute„ e.g., fertile refers to soil and soil refer to topography), APPLIED/TO (color applies to things, 8 WHAT IS THE LANGUAGE OF ARGENTINA?</abstract>
<author confidence="0.425262">PROBABLY SPANISH</author>
<affiliation confidence="0.89647175">VERY GOOD. APPROXIMATELY WHAT IS THE AREA OF ARGENTINA? *TELL ME SOMETHING ABOUT PERU* PERU IS A COUNTRY. IT IS IN WESTERN SOUTH AMERICA. IT IS ON THE COAST OF THE PACIFIC. THE CAPITAL IS LIMA. THE MOUNTAINS ARE NUMEROUS.</affiliation>
<note confidence="0.6608996">THE REGIONS ARE THE AMAZON IUNGLE, THE ATACAMA DESERT, AND THE ANDES. NOW YOU CAN EITHER ANSWER MY QUESTION OR ASK A NEW ONE. AREA OF ARGENTINA IS SQUARE MILES*. APPROXIMATELY TRUE, BUT A MORE EXACT VALUE 18 1,200,000.</note>
<title confidence="0.520561">THE EASTERN BORDERING COUNTRY OF PERU IS --- *CHILD*</title>
<author confidence="0.567784">NO</author>
<affiliation confidence="0.945129428571428">THE SOUTHERN BORDERING COUNTRY OF PERU IS CHILE. THE EASTERN BORDERING COUNT &apos;Y OF PERU IS BRAZIL. ERE IS PERU? *WHAT IS THE MOST IMPORTANT DIFFERENCE BETWEEN PERU AND PARAGUAY?* PRIMARY DIFFERENCE PERU IS IN WESTERN SOUTH AMERICA. BUT PARAGUAY IS IN CENTRAL SOUTH AMERICA.</affiliation>
<note confidence="0.919405714285714">Figure l. A Sample Dialogue tween SCHOLAR and a Student. (Student inputs are enclosed by a terisks.) CAPITAL SUPERC (I 0) CITY PLACE (I 0) OF (I 0) GOVERNMENT APPLIED/TO (I 4) COUNMY STATE</note>
<address confidence="0.486476333333333">EXAMPLES (I 2) (SEOR BUENOS/AIRES LIMA MONTEVIDEO BRASILIA GEORGETOWN CARACAS BOGOTA QUITO SANTIAGO ASUNCION LA/PAZ WASHINGTON)</address>
<email confidence="0.635388">FERTILE</email>
<note confidence="0.887424818181818">CONTRA (I 0) BARREN SUPERA (I 0) SOIL PERU (I SUPERC (I 1 B) SOUTH/AMERICA LOCATION (I 0) IN (I 0) SOUTH/AMERICA (I 0) WESTERN ON (I 0) COAST (I 0) OF (I 0) PACIFIC LATITUDE (I 4) RANGE (I 0) -18 0 LONGITUDE (1 5) RANGE (1 0) -82 -68 BORDERING/COUNTRIES (I 1) NORTHERN (I 1) (SL COLOMBIA ECUADOR) EASTERN (I 1) BRAZIL SOUTHEASTERN (I 1) BOLIVIA SOUTHERN (I 2) CHILE CAPITAL (I 1) LIMA CITIES (I 2)</note>
<affiliation confidence="0.568197">PRINCIPAL (I 0) ($L LIMA CALLAO AREQUIPA TRUJILLO CHICLAYO CUZCO) LIMA</affiliation>
<address confidence="0.590136">SUPERC (I 0) CITY CAPITAL</address>
<note confidence="0.806426142857143">SUPERC (I 1 B) PERU SOUTH/AMERICA LOCATION (I 0) IN (I 0) PERU 9 Figure 2. Four Partial Entries from SCHOLAR&apos;s Georgraphy Dalt Base. 10</note>
<abstract confidence="0.997698579268292">countrien and states), CONTRA (for contradittion,e.g. contradicts fertile contradicts dictatorship), attributes like agent and Fillmore), and various others. The entry for location under Peru in Figure 2 illustrates an aspect of SCHOLAR&apos;s semantic Under the attribute location there is the value South America plus everal subattribut ng which is bordering countries. But under bordering countrios there are subattributes like northern and eastern, some of which have several values. Embedding describes the ability to go down as deep as necessary to describe a property in n.re or les de il. the dat b se ther re :10 such as the (1 0) after loc tion ad the (I 1) after bordering countries. These tags are importanceor isrelevanqttag 0 to 6. The the tag, the (1-tags), and they vary important the piece of info tion 1, Th tags add up as you go down through 1 er of user I-tags is to decide what relevant to say at any given ti rest of this paper, we will discuss how we are using SCHOLAR to cope with so e of the probl in tural However, there ar still m ny thral mantics problems w have not touched. Semantic Information In this section we discuss some aspects of natural semantic information and its relation to artificial intelligence. or Fuzziness Imprecise language is an essential characteristic of human As &amp;quot;Far from being a defect as some philosophers have suggested, referential &apos;impreciseness&apos;... kes language a more efficient means of communication.&amp;quot; Talking a tall person or blue-green object does not require specification of height or spectral characteristics. imprecision may occur either in communication or storage. If we say that a colleague receives a large salary, we may or may not know the figure. SCHOLAR currently stores areas and populations in numerical form, but it can respond to the fuzzy question &amp;quot;Is Montevideo large?&amp;quot; with a pertinent an er like: &amp;quot;It is not one of the largest cities in South America, but it is the largest city in Uruguay.&amp;quot; Here SCHOLAR has found t superparts, South America and Uruguay, and then compared Montevideo to other cities in each with 4espect to population. 11 it is more co n for people to or &apos;fuzzy&apos;, what &apos;linguistic&apos; III! that are variables. This is the case with values like &apos;large&apos;, &apos;red&apos;, &apos;hot&apos;, 12 &apos;rich&apos;, etc. It seems to us that one must be able to store either precise values or fuzzy values interchangeably. (In fact, SCHOLAR has fuzzy values as well as precise values stored, e.g., the Brazilian Highlands has a large population.) Furthermore, the procedures that act upon these values must be flexible enough to deal with either. Embedding, and Relevancy Imprecise statements are often motivated by incomplete specification. Since all specifications can be refined, they are essentially incomplete. We store what is necessary, and if we store more, we only co unicate what is pertinent. SCHOLAR does thi through its I-tags. If it is asked &amp;quot;Tell me about Peru,&amp;quot; it only gives a few salient facts. Further specification can be added by refining existing For ex ple, instead of &apos;blue&apos; we can have &apos;Navy blue&apos;, or &apos;quite dark Navy blue&apos;, etc. Further specification can also be added by giving new properties with attributes som hat orthogonal to previous ones. ex. pie of this is &apos;tall us °tall, glasses&apos;. Properties can be specified to any level of detL il by e edding, an inherent quality of SCHOLAR-type antic networks. 13 The Problem and Context Somewhat related to incompleteness and relevancy is the problem (see R3forring to a colleague, my &apos;define&apos; him as the father of Jack and Jill, or the author of that paper on self-referential stat tents, or the tall thin fell path glasme . We decide on c,oLla specification depending on the ontext, including our assumptions about the paroon we are talking People usually specify only to the is In this sense, every partial specification is a &apos;definition&apos;. The problem of context pervades natural semantics. Definitions and specifications, anaphoric references, what and how to answer, all depend on context. Furthermore, there usually a range of contexts from overall to short-te running contexts. For example, at a given time, SCHOLAR may have the contexts South America, Argentina and Buenos Aires, each dynamically adjustable life. What is relevarit at any given time depends on this contextual hierarchy. A start toward making references specific to the listener is possible in a SCHOLAR-type syst by using I-tags (see Collins, and The likelihood that another person will know about any concept is roughly proportional to the importance of the concept, as acured by the /-tzigu, with to the context. it is possible to 14 te .the sophistication of a person based level of tags concepts he mentions in his conversation. This estimate then can influence the description one uses in referring to So concept. For example, to an unsophisticated listener one might refer to the &amp;quot;capital of Argentina&amp;quot; rather than &amp;quot;Buenos Aires,&amp;quot; because the I-tags for the concepts &amp;quot;capital&amp;quot; and &amp;quot;Argentina&amp;quot; are lo r than those for &amp;quot;Buenos Aires,&amp;quot; as measured from a context such as geography. the future we want to have adjustable contexts SCHOLAR, that it can talk about the ARPA network, say, &amp;quot;from a communitions point of view&amp;quot; to one person and &amp;quot;from a progr ing point of vi w&amp;quot; to another person. What this entails is a temporary alteration of the r lative values of I-tags throughout the s antic n twork. Thconcepts that are referred to under the &amp;quot;corr ication&amp;quot; (such as message bit-rate, etc.) should be temporarily increased in importance wherever they occur in data base, for th person interested in communication. corresponding change must be de for the person intereoted in i g or concept or set of concepts0 This kind of s nsitivity to the interests and background of the porson, and the kind of se itivity (d scribed above) to the sophistication of the person y be the two major lement in the w y people t what they say to the listener. 15 2111TAMEME2Mn_int In some realms of discourse such as an airline reservations a blocks world or a lunar rocks (Woods, Kaplan, land there is a closed set of objects, attributes, and values to deal with. H ever, most real world domains those faced by SIR or SCHOLAR there are open sets of objects, attributes, and values. It turns out that the procedur s and even the rules of inference that can be applied are different in closed and open worlds. The distinction between closed and open oets is one of exhaustiveness and not one of size. For ex m.le, the set of states (e.g., Iowa), which i a closed set for w.t people, probably larger than the set of cattle breeds (e.g., Holstein), is an open set. However, cpen sets t d to be lhrger general than closed sets. The distinction is important in a variety of way. For example, if there are no basaltic rocks ntored in a closed dat,J base, then it makes sense to say &amp;quot;No&amp;quot; to the question &amp;quot;&apos;Were any basaltic rocks brought back?&amp;quot; But if no &apos;.lcanoes are atored for the U. S., it does not follow that the answer should be &amp;quot;No&amp;quot; the question &amp;quot;Are volcanoes in the U. S.?&amp;quot; A more answer is &amp;quot;I don&apos;t know. ° Furthermore, it sense to ask what the ouallest block in a scene is or the r k with lam t umin concentration, but it mks no sense to a k 16 fl what is the iallest city in Brazil or the least famous lawyer the U. S. It uld be an appropriate strategy deciding how many flights from Boston to Chicago are nonstop, to consider each flight d count how many make 0 stops. But it .u1d not be an appropriate strategy to consider each per .n stored in a data base (such as hurnn have), in order to the quection &amp;quot;How many people in the U. S. are over 30 years old?&amp;quot; Within open worlds there are closed sets, so that a question like many on the Pacific?&amp;quot; makes sense whereas &amp;quot;How any cities are on the Pacific?&amp;quot; does not. SCHOLAR dOils with this by di tingui hing e&apos;:hzustive sets from non-exhaustive sets. We will discuss in Section 4 how SCHOLAR begins to doal with orld Th 1 point is that the welldefined p cedures that are appropriato for a clocad world simply not carry ovc.):.: to open rld. Unfortunately, 13t h k wledge is open-end d, and so people have complex trategie:.&gt; for with uncertainty nd facing p such to apply new attributes or values to objectstal-el:e they haven&apos;t applied in the past. 17 Tuue-False Dichot y and Quantification The t.-valued logic that underlies the propositional calculus and related approachco to inference cannot encompcss saztics. The trouble arises truth varies in degree, in time, in range, in certainty, and in point of view of the observer, when it is applied to rncil-world objects. re All briefly examine some of the implications of the multivalued nature oP truth for natural saaantics, logic us(A7 quantification to distinguish the universal and the particular, e.g., between &amp;quot;All men are and &amp;quot;Some men have rts.&amp;quot; But there is no allowance the degreec of truth as between say &amp;quot;Some have warts&amp;quot; &amp;quot;Some hav ears,&amp;quot; even though only a fraction have and almotit all have ears. P ple will infer that Newton had ears information to the contrary a Van Gogh), but will infer that Newton The inference in the fol:Lor treat the particular like the universal, because t men ear3. The re generally tr c statement is, the re certainty people cosign to such an inference. Thrn just are not y universal truths to be found out in the cold, cruel rld, so people m-ko bo of it. Degree of truth ries not only with respect to fuzzy variables (see Section 3.1) d q ntification, but also in other 18 respects. The sky is blue, but not all the time. The yellow of le is less variable than the yellow of corn, which sometimes bordors on white. Boston is cold in the winter, but it is not so cold from the point of view of an tskill• Nixon told us that didn&apos;t know about the cover-up of Wntergate, but one is only or less cc! in that he !That these examples are designed to show is that people are uncertain about the truth of any propo ition for a variety of reasons. Sometimes people seem merge all the inysources of uncertainty together, but someticas they c n distinguish different aspects of their certainty with respect to a single proposition. SCHOLAR does not now have y means for representing cert ..nty, but the natural way to add such information is in tags st red along with the I-tg . Just an with I-tags, U-tags car apply at 11 I4edded levels of the data base. Because we have st rted on progr inferences below), it has beco e desirable repre ent the underlying uncertainty data base 11, in order to eval te how certain inference y be. Ihferences cllify h infrncs into four jor deductiv, negative, fnnctional, and inductive inforonco,J. The various type Lice discussed in somewhat gre ter detail in Collins 19 And Collins, Carbonell, and We do not argue that these describe all the inferential strategies that people use, but only one of the -jor varieties. The different strategies described are being implamanted as subroutines in SCHOLAR. Mile we think that people have a large set of such strategies, the n er is probably less than one hundred. Itt • Therefore, despite the inelegance of such an approach, we do not regard it as an endless task to encompasc the bag of inferential tricks a person uses. In Figure 3 we havo included excerpts from tape-recorded dialogues betwen human tutors and students to illustrate so of the more complic ted strategies people uno, and the &apos;.ys they we will discuss examples individually below. Inferences are trznoitive relations that 1:..ople use to infer a property of one thing may be a of the other. These include superordinate, superpart, similarity, 8: ..rdi te, and relations. Of tho above types SCHOLAR now handles only superordinate supnrpart infcrences, which are most n. For if asked &amp;quot;Does the Llanoc h(Ar rainy season?&amp;quot;, SCHOLi&apos;lll will 20 (T) There is some jungle in here (points to Venezuela) but this breaks into a savanna around the Orinoco. (S) Oh right, that is where they grow the coffee up there? (T) I don&apos;t think that the savanna is used for graving coffee. The trouble is the savanna has a rainy season and 91ou can&apos;t count on rain in general. But I don&apos;t know. This area around Sao Paulo is coffee region, and it is sort of getting into the savanna region there. (S) Are there any other areas where oil is found other than Venezuela? (T) Not particularly. T ere is -ome oil offshore there but in general oil comes from Venezuela. Venezuela is the only one that&apos;s making any money in oil: (S) Is the Chaco the cattle country? I know the cattle country is dorm there. (T) I think it&apos;s more sheep country. It like western Texas o in som sense I guess it&apos;s cattle country. (T) And the northern part of Argentina has a large sort of reoi-arid plain that extends into Paraguay. And that&apos;s a plains area that is relatively unpopulated. (S) Why? (T) Because its pretty dry. Figur 3 Tutor-Student Dialogue Excerpts 21 look under Llanos failing find the information there, will look under Llanosl SUPERC (for superordinate), which is savanna, and its SUPERP (for superpart), which is Venezuela and Colombia. A rainy season is a property of savannas and so superordinate answer. The superpart is less general because it is restricted certain attributes such as climate, language, and topography. One would not want to conclude that the capital of Massachusetts is Washington, D. C., just because Massachusetts is part of the S ates. Because most properties a superordinate or are only generally true, and true, exceptions must be stored to preclude an incorrect inference Similarity and proximity inferences parallel the superordinate and superpart inferences, but they carry less certainty. An ample of a person using a proximity inference is shown in the latter part of the tutor&apos;s response in Example 1 of Figure 3. The tutor first said that a savanna could not be used for growing coffee, but then he backed off this conclusion because of the of the large Brazilian the coffee-growing there. To illustrate a similarity inference: if a wallaby is like a kangaroo, then one will infer that a wallaby probably has a pouch. We plan to add similarity information to SCHOLAR in the near future, because it 22 will also be useful in making functional analogies which are discussed below, The tecently added map facility (Warnock and which ties together visual and semantic representations, makes proximity inferences possible, but they are still a way off. Subordinate and subpart inferences follow a somewhat different pattern from the others discussed. If asked whether South America produces any oil, a person will answer &amp;quot;Yes&amp;quot; because Venezuela, which is part of South America, produces oil. But one does not want to conclude that South America is hot because the Amazon jungle is. We haven&apos;t worked out the details of the restrictions on these inferences as yet. There are other transitive relations that are used to :.ke deductive inferenc s but they are not as prevalent as the ones outlined here. Inferences Negativ info ration, such as the fact that men do not have wheels, is not usually stored but rather inferred. In a closed world this presents no problem; it is reasonable to assu that if pomething is not stored, then it is not true. In fact, early versions of SCHOLAR say &amp;quot;No&amp;quot; if asked &amp;quot;Is oil a product of Brazil?&amp;quot; just becilArle oil isn&apos;t stored for Brazil. But in the real .r1d, the fact that so thing is not stored does not necer-;Fial:ily mean 23 that it is not true. People seem to have complex strategies for dectding when to say &amp;quot;No&amp;quot; and when to say &amp;quot;I don&apos;t know.&amp;quot; We have recently been implementing these in SCHOLAR. One kind of negative inference now in SCHOLAR is a simple contradiction procedure. It relies on contradictory values stored with various concepts: for example, barren contradicts fertile, and democracy contradicts dictatorship. Suppose SCHOLAR is asked &amp;quot;Is the Pampas barren?&amp;quot; It would find the soil of the P pas is fertile, and since fertile contradicts barren, it would say &amp;quot;No. The soil of the Pampas is fertile.&amp;quot; There is an important class of contradictions that are not subsumed under the procedure above. For example, consider the question &amp;quot;Is Buenos Aires a city in Brazil?&amp;quot; The fact that Bueno Aires is not among the cities of Brazil is no reason to say &amp;quot;No,&amp;quot; because there are cities in Brazil, such as Cor which are not stored. But there are three facts that ether a contradiction possible: (1) Buenos Aires is located in (2) cities have location, (3) Argentina Brazil are mutually exclusive. can illustrate the for (2) (3): (2) even though Portuguese language of it is also the language of Brazil language can have .re than one location); (3) Sao Paulo is in South America, it is alco in Brazil (i.e., South • 24 America and Brazil are not mutually exclusive). Making an incorrect negative inference about cities with More than one location (e.g., Kansas City) or different cities with the same name (Rome, New York, and Rome, Italy) is precluded by storing both locations specifically, just as with deductive inferences. The strategy we have rked out and implemented to find different contradictions of this kind is fairly complex. Failure to find a contradiction leads to another kind of negative inference people use which call the (Collins, Carbonell and Ex le 2 of Figure 3 shows the tutor using this strategy. The baci of the inference is he knows as much about other Aterican as he knows about Venezuela, it is a plausible but uncertain inference that if other countries produced h would know about it. was at lea ;t wrong, because there are in fact several other in South America that produce oil, though for those countries oil is not nearly so important as it is for Venezuela.) a strategy is currently being implemented in SCHOLAR the following way: If asked a question like &amp;quot;Is oil a product of Uruguay?&amp;quot; where no oil is stored, SCHOL can look for oil under similar objects (e.g., Venezuela or Brazil) or objects with the e SUPERC and SUPERP. If SCHOLAR finds oil stored with 25 Venezuela (say with an I-tag of 3) and if it has enough information stored about Uruguay (up to an I-tag of 8, say) know about oil it were at all important, then it can infer that Uruguay probably has no oil. The degree of certainty exprevsed in the an er should depend on the difference in I-tags the depth of what it knows Uruguay and level at which oil is stored with similar objects. If SCHOLAR can find no kailar objects that have the property in question, as with &amp;quot;Is a of Uruguay?&amp;quot; the appropriate is something like &amp;quot;I don&apos;t know whether sand is a product of any country in South America.&amp;quot; The lack-of-knowledge inference is based on the assumption that one&apos;s knowledge is fairly consistent for similar objects. Inferencos Functional inferences are co in the dialogues I • Warnock, and Examples 1, 3, and Figure 3 illuztrate the three different ways tie have s n people functional knowledge: in qua i rcalculations, and in an er to &amp;quot;why&amp;quot; quactions, 26 Functional knowledge, which includes knowledge about functional determinants and their interactions, is learned, just is factual knowledge, and therefore is stored in SCHOLAR&apos;s data base under concepts such as climate or agricultural products. We would argue that the representation of functional knowledge should be in a form that different procedures can use. One is to find a represent such knowledge in SCHOLAR that it can more less precise, and still be accessible to different subroutines that infer answers to questions or that describe the functional relation to students. Functional calculations can be used in both a positive and negative way. One simple positive function now in SCHOLAR calculates the climate of a place if the information is not stored. Based on the major functional determinants of climate, are d altitude, SCHOLAR will infer whether te is tropical, sub-tropical, t liperate, or cold/polar. of calculation on the agricultural products t ction is shown in the first part of the tutor&apos;s answer in l. The functional determinants of agricultural products th soil, rainfall. The tutor picked the of rain ba:Ji3 for a tentative &amp;quot;No.* Negative calculado require as precise knowledge as positive calculations. They often only require that one or two of the functional determinants have an inappropriate value. 27 Like functional calculations, functional analogies can be lositive or negative. Example 3 shows the tutor making a positive functional analogy, again with the agricultural products function. rhere he thought of a region, western Texas, that matched the Maco in terms of climate and rainfall, the functional determinof cattle raising. Since he knew that western Texas cattle country he inferred that the Chaco might be as well. A negative functional analogy might have occurred if the student had asked whether the Chaco produced rubber. Since the Amazon jungle and Indonesia produce rubber, the tutor could have said &apos;No&amp;quot; on the basis of the mismatch between the Chaco and tho regions, with respect to climate and rainfall. A positive and negative analogy subroutine has been implemented in SCHOLAR. It is a fallback strategy to be used if there is not enough info fl .tion stored to calculate the functional relationship. For a functional analogy it is only necessary to know the functionally relevant attributes and their relative importance. Then SCHOLAR looks to see if it knows any similar objects where the property in question is in f ct stored. It tries to find a match or a mismatch by comparing the gi object and the similar object with respect to their values on the functionally relevant attributes. People frequently use such analogical reasoning, probably because of the ill-defined nature of their knowledge about functional relations. 28 The last example in Figure 3 shoOs the use of a functional relation to answer a &amp;quot;Why&amp;quot; question. The population density of a place depends on an indefinite set of functional determinants: climate, soil, and rainfall are m jor ones but distance from the sea, the par9.cular continent, presence of valuable minerals, all contribute in different ways. The tutor picked one determinant that had a value inappruriate for a large population density and gave that as a reason. By contrast a geographer could probably write a whole treatise on why the Chaco has a low population density. What we aspire for SCHOLAR to do is what the did, that is, to pick one or two of the with appropriate values and give those as a reason. InductiveInferences inductive inference herr only because they are a major class of h &apos;Ian inference. We have not yet tried to progr them in SCHOLAR since they occur stly in storing r ther than retrieving inform tion. The generaliz.tion and disprocesses induction been discussed de.il elsewhere (Beck and 29 and Accumulating Uncertainty The inferential proceicsos described can combine in a variety of ways. For instance, contradictions can combine with deductive inferences. SCHOLAR will answer a question like &amp;quot;Is the Atlantic with &amp;quot;No, it is blue,&amp;quot; becauoe it finds blue the SUPERC, ocean. Also one functional inferonco another. If the agricultural products function needs a value for the climate of some region, it could call the cli te function to compute it. more important way that inferences combine dhows up different strategies reach independent conclusions about the oLlio question. A good example is Example 1 in Figure 3. The functional inference, an implicit lack-of-knowledge inference, first led to a tentative &amp;quot;No&amp;quot; ansuer, but then a proximity inference produced a possible &amp;quot;Yes&amp;quot; answer, and so the backed off his earlier &amp;quot;No.&amp;quot; When inferences coApine yield the same conclusion, they increase the certainty of th and they produce opposite conclusions, they the certainty. There are a number of sources of uncertainty in inferential Uncertainty can from the size of the diffuroace in the inference, it can darive from the degree of match or mi match in a functional analogy, it derive from the degree of of the function ;l 30 determinants, and as we discuasal earlier, it can derive from the degree of certainty about the into tion stored. These sources of uncertainty iy be combined to produce an overall uncertainty for e:,unple This ovorcll uncertainty is important so that long, tenuous chains of roaaoning are not pursued to their pointless end, and so that the dcgree of uncertainty in the an 77er can be iadicated to the student. What we have tried to show in this paper is the fuzzy, illd fi2 d, uncal:tain nature of much of huun knowledge and thinking. int SCHOLAR to be as are. paper was by Jai R. Carbonell who died 2, 1973. I have completed it as best I could following his outline. I w nt to thank Eleanor H. Warnock who helped me with the editing and D niel G. Bobrow and s wh have contributed rny ides to our work. The progra ing of variouL urbroUtines described in the paper was done by Nelleke</abstract>
<author confidence="0.891759">Jaime Susan M Graesser</author>
<author confidence="0.891759">Mark L Miller</author>
<note confidence="0.937340605633803">Passafiume, and Eleanor H. Warnock, Allan M. Collins. 31 This research was supported in part by the Office of Naval Research, Information Systems, under Contract No. NO0014-70-C-0264, and also in part by the Office of Naval Research, Per nnel and Training, under Contract No. NO0014-71-C-0228, and by the Air Force Systems Command, Electronic Syst Division, under Contract No. F19628-72-C-0163. 32 7. References 1. J. D. Becker, &amp;quot;A Model for the Encoding of Expericztial in R. Schank &amp; K. Colby of Thought and Language,Freeman, San Francisco (1973). 2. J. R. Carbonell, &amp;quot;Mixed-Iniatiative Man-Computer Instructional Dialogues.&amp;quot; Ph.D. Thesis, M.I.T., Dept. of Electrical Engineering (June 1970). R. Carbonell, &amp;quot;A. I. in C.A.I.: An Artificial-Intelligence to Computer-Assisted Instruction&amp;quot; Trans. on Syste Vol. MMS-11, No. 4 (December 1970). J. Carbonell, &amp;quot;Artificial Intelligence and Large ctive Man-Computer Syste of 1971 IEEE M nd Cybernetics Conference, Anaheim, California (October 1971). A. Carbonell, and E. H. Warnock, &amp;quot;Semantic Processing by Computer&amp;quot; in J. Rose (Ed.) Cybernetics and Systems,Gordon &amp; Breach, London (1974). M. Collins, Warnock, and Passafiume, &amp;quot;Analysis and Synthesis of Tutorial Dialogue in G. Bower (Ed.). The of Learning and Vol. Academic Press New York, (1975). 33 7, A. M. Collins and D R, Ouiltian, to Make a Language in E. Tulving and Donaldson (Eds.) of Memory,Academic Press, New York (1972), 0. C. Fillmore, &amp;quot;The Cc.e for Case&amp;quot; in Bach and Harms (Eds.), in Linguistic Theory.Holt, Rinehart, and Winston, N. Y. (1968). R. Kling, PLANNER: Computing Inexactness in a Problem University of Wisconsin Technical Report No. 168 (February 1973). J. to Theoretical Cambridge University Press, Cambridge, England (1968). D. R. Olson, &amp;quot;Language and Thought: AspectS of a Cognitive of Semantics&amp;quot; Review,Vol. 77, No. 4 (July 1970). 12. M. R. Quillian, &amp;quot;The Teachable Language Comprehender: A Program and Theory of CACM, Vol. 12, No. 8 (August 1969). 13. B. Raphael, &amp;quot;SIR: A Computer Program for Semantic Information in M. L. Minsky (Ed.) InformationProcessingi M.I.T. Press, Cambridge, Mass. (1968). 14. E. H. Warnock and A. M. Collins, &amp;quot;Semantic Networks&amp;quot; Bolt Beranek and Newman Inc. Report No. 2833 (May 1974). 34 T. Winograd, Natural Language, Academic Press, New York. (1972). 16. P. H. Winston, &amp;quot;Learning Structural Descriptions from Examples,&amp;quot; Project MAC TR-76, M.I.T. (September 1970). 17. W. A. Woods, &amp;quot;Semantics for a Question-Answering System,&amp;quot; Aiken Computation Laboratory, Report No. NSF-19, Harvard University (August 1967). 18. A. Woods, R. M. Kaplan, and B. Nash-Webber, &amp;quot;The Lunar Sciences Natural Language Information System,&amp;quot; Bolt Beranek NernInc., Report No. 2378 (June&apos;1972). L. Zadeh, &amp;quot;Outlining of a New Approach to the Analysis of Systems and Decision Processes&amp;quot; Trans. on Man, and Cybernetics,Vol. SMC-3, No. 1 (January 1973). 1 ( -, _ ■ - .,----,</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>and also in part by the Office of Naval Research, Per nnel and Training,</title>
<booktitle>under Contract No. NO0014-71-C-0228, and by the Air Force Systems Command, Electronic Syst Division, under Contract No.</booktitle>
<pages>19628--72</pages>
<marker></marker>
<rawString> and also in part by the Office of Naval Research, Per nnel and Training, under Contract No. NO0014-71-C-0228, and by the Air Force Systems Command, Electronic Syst Division, under Contract No. F19628-72-C-0163.</rawString>
</citation>
<citation valid="false">
<institution>References</institution>
<marker>7.</marker>
<rawString>References</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Becker</author>
</authors>
<title>A Model for the Encoding of Expericztial Information,&amp;quot;</title>
<date>1973</date>
<booktitle>in R. Schank &amp; K. Colby (ads.), Computer Models of Thought and Language,</booktitle>
<location>Freeman, San Francisco</location>
<contexts>
<context position="28554" citStr="(1)" startWordPosition="4740" endWordPosition="4740">dicts dictatorship. Suppose SCHOLAR is asked &amp;quot;Is the Pampas barren?&amp;quot; It would find the soil of the P pas is fertile, and since fertile contradicts barren, it would say &amp;quot;No. The soil of the Pampas is fertile.&amp;quot; There is an important class of contradictions that are not subsumed under the procedure above. For example, consider the question &amp;quot;Is Buenos Aires a city in Brazil?&amp;quot; The fact that Bueno Aires is not among the cities of Brazil is no reason to say &amp;quot;No,&amp;quot; because there are cities in Brazil, such as Cor which are not stored. But there are three facts that ether II ke a contradiction possible: (1) Buenos Aires is located in Argentina, (2) cities only have one location, and (3) Argentina and Brazil are mutually exclusive. We can illustrate the necessity for conditions (2) and (3): (2) even though Portuguese is the language of Portugal, it is also the language of Brazil (i.e., language can have .re than one location); (3) even though Sao Paulo is in South America, it is alco in Brazil (i.e., South • 24 America and Brazil are not mutually exclusive). Making an incorrect negative inference about cities with More than one location (e.g., Kansas City) or different cities with the same name (</context>
</contexts>
<marker>1.</marker>
<rawString>J. D. Becker, &amp;quot;A Model for the Encoding of Expericztial Information,&amp;quot; in R. Schank &amp; K. Colby (ads.), Computer Models of Thought and Language, Freeman, San Francisco (1973).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Carbonell</author>
</authors>
<title>Mixed-Iniatiative Man-Computer Instructional Dialogues.&amp;quot;</title>
<date>1970</date>
<journal>IEEE Trans. on Man-Machine Syste</journal>
<tech>Ph.D. Thesis,</tech>
<volume>30</volume>
<institution>M.I.T., Dept. of Electrical Engineering</institution>
<contexts>
<context position="28596" citStr="(2)" startWordPosition="4747" endWordPosition="4747">ed &amp;quot;Is the Pampas barren?&amp;quot; It would find the soil of the P pas is fertile, and since fertile contradicts barren, it would say &amp;quot;No. The soil of the Pampas is fertile.&amp;quot; There is an important class of contradictions that are not subsumed under the procedure above. For example, consider the question &amp;quot;Is Buenos Aires a city in Brazil?&amp;quot; The fact that Bueno Aires is not among the cities of Brazil is no reason to say &amp;quot;No,&amp;quot; because there are cities in Brazil, such as Cor which are not stored. But there are three facts that ether II ke a contradiction possible: (1) Buenos Aires is located in Argentina, (2) cities only have one location, and (3) Argentina and Brazil are mutually exclusive. We can illustrate the necessity for conditions (2) and (3): (2) even though Portuguese is the language of Portugal, it is also the language of Brazil (i.e., language can have .re than one location); (3) even though Sao Paulo is in South America, it is alco in Brazil (i.e., South • 24 America and Brazil are not mutually exclusive). Making an incorrect negative inference about cities with More than one location (e.g., Kansas City) or different cities with the same name (Rome, New York, and Rome, Italy) is preclu</context>
</contexts>
<marker>2.</marker>
<rawString>J. R. Carbonell, &amp;quot;Mixed-Iniatiative Man-Computer Instructional Dialogues.&amp;quot; Ph.D. Thesis, M.I.T., Dept. of Electrical Engineering (June 1970). 30 J. R. Carbonell, &amp;quot;A. I. in C.A.I.: An Artificial-Intelligence Approach to Computer-Assisted Instruction&amp;quot; IEEE Trans. on Man-Machine Syste Vol. MMS-11, No. 4 (December 1970).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Carbonell</author>
</authors>
<title>Artificial Intelligence and Large Inter ctive Man-Computer Syste</title>
<date>1971</date>
<booktitle>Proceedings of 1971 IEEE Syste si M nd Cybernetics Conference,</booktitle>
<location>Anaheim, California</location>
<marker>4.</marker>
<rawString>J. R. Carbonell, &amp;quot;Artificial Intelligence and Large Inter ctive Man-Computer Syste Proceedings of 1971 IEEE Syste si M nd Cybernetics Conference, Anaheim, California (October 1971).</rawString>
</citation>
<citation valid="false">
<authors>
<author>J R Carbonell</author>
<author>E H Warnock</author>
</authors>
<title>Semantic Inferential Processing by Computer&amp;quot; in J. Rose (Ed.) Advances in Cybernetics and Systems,</title>
<date>1974</date>
<booktitle>in G. Bower (Ed.). The Psychology of Learning and Motivation,</booktitle>
<volume>91</volume>
<publisher>Gordon &amp; Breach,</publisher>
<location>London</location>
<note>7,</note>
<marker>5.</marker>
<rawString>A. Coll!su.,„ J. R. Carbonell, and E. H. Warnock, &amp;quot;Semantic Inferential Processing by Computer&amp;quot; in J. Rose (Ed.) Advances in Cybernetics and Systems, Gordon &amp; Breach, London (1974). A. M. Collins, E. H. Warnock, and J. J. Passafiume, &amp;quot;Analysis and Synthesis of Tutorial Dialogue in G. Bower (Ed.). The Psychology of Learning and Motivation, Vol. 91 Academic Press New York, (1975). 7, A. M. Collins and D R, Ouiltian, &amp;quot;How to Make a Language User&amp;quot; in E. Tulving and W. Donaldson (Eds.) Organization of Memory, Academic Press, New York (1972),</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fillmore</author>
</authors>
<title>The Cc.e for Case&amp;quot; in Bach and Harms (Eds.), Universals in Linguistic Theory.</title>
<date>1968</date>
<location>Holt, Rinehart, and</location>
<marker>0.</marker>
<rawString>C. Fillmore, &amp;quot;The Cc.e for Case&amp;quot; in Bach and Harms (Eds.), Universals in Linguistic Theory. Holt, Rinehart, and Winston, N. Y. (1968).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kling</author>
</authors>
<title>FUZZY PLANNER: Computing Inexactness in a Procedural Problem Solving Language.&amp;quot;</title>
<date>1973</date>
<tech>Technical Report No. 168</tech>
<institution>University of Wisconsin</institution>
<marker>9.</marker>
<rawString>R. Kling, &amp;quot;FUZZY PLANNER: Computing Inexactness in a Procedural Problem Solving Language.&amp;quot; University of Wisconsin Technical Report No. 168 (February 1973).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lyons</author>
</authors>
<title>Introduction to Theoretical Linguistics,</title>
<date>1968</date>
<journal>Psych. Review,</journal>
<volume>77</volume>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, England</location>
<marker>10.</marker>
<rawString>J. Lyons, Introduction to Theoretical Linguistics, Cambridge University Press, Cambridge, England (1968). D. R. Olson, &amp;quot;Language and Thought: AspectS of a Cognitive Theory of Semantics&amp;quot; Psych. Review, Vol. 77, No. 4 (July 1970).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Quillian</author>
</authors>
<title>The Teachable Language Comprehender: A Simulation Program and Theory of Language&amp;quot;</title>
<date>1969</date>
<journal>CACM,</journal>
<volume>12</volume>
<marker>12.</marker>
<rawString>M. R. Quillian, &amp;quot;The Teachable Language Comprehender: A Simulation Program and Theory of Language&amp;quot; CACM, Vol. 12, No. 8 (August 1969).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Raphael</author>
</authors>
<title>SIR: A Computer Program for Semantic Information Retrieval&amp;quot;</title>
<date>1968</date>
<booktitle>in M. L. Minsky (Ed.) Semantic Information Processingi</booktitle>
<publisher>M.I.T. Press,</publisher>
<location>Cambridge, Mass.</location>
<marker>13.</marker>
<rawString>B. Raphael, &amp;quot;SIR: A Computer Program for Semantic Information Retrieval&amp;quot; in M. L. Minsky (Ed.) Semantic Information Processingi M.I.T. Press, Cambridge, Mass. (1968).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Warnock</author>
<author>A M Collins</author>
</authors>
<title>Semantic Networks&amp;quot; Bolt Beranek and Newman Inc.</title>
<date>1974</date>
<tech>Report No. 2833</tech>
<marker>14.</marker>
<rawString>E. H. Warnock and A. M. Collins, &amp;quot;Semantic Networks&amp;quot; Bolt Beranek and Newman Inc. Report No. 2833 (May 1974).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Understanding Natural Language,</title>
<date>1972</date>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<marker>15.</marker>
<rawString>T. Winograd, Understanding Natural Language, Academic Press, New York. (1972).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P H Winston</author>
</authors>
<title>Learning Structural Descriptions from Examples,&amp;quot;</title>
<date>1970</date>
<booktitle>Project MAC TR-76,</booktitle>
<location>M.I.T.</location>
<marker>16.</marker>
<rawString>P. H. Winston, &amp;quot;Learning Structural Descriptions from Examples,&amp;quot; Project MAC TR-76, M.I.T. (September 1970).</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Woods</author>
</authors>
<title>Semantics for a Question-Answering System,&amp;quot; Aiken Computation Laboratory,</title>
<date>1967</date>
<tech>Report No. NSF-19,</tech>
<institution>Harvard University</institution>
<marker>17.</marker>
<rawString>W. A. Woods, &amp;quot;Semantics for a Question-Answering System,&amp;quot; Aiken Computation Laboratory, Report No. NSF-19, Harvard University (August 1967).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Wt A Woods</author>
<author>R M Kaplan</author>
<author>B Nash-Webber</author>
</authors>
<title>The Lunar Sciences Natural Language Information System,&amp;quot; Bolt Beranek and Nern Inc.,</title>
<tech>Report No. 2378 (June&apos;1972).</tech>
<marker>18.</marker>
<rawString>Wt A. Woods, R. M. Kaplan, and B. Nash-Webber, &amp;quot;The Lunar Sciences Natural Language Information System,&amp;quot; Bolt Beranek and Nern Inc., Report No. 2378 (June&apos;1972).</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Zadeh</author>
</authors>
<title>Outlining of a New Approach to the Analysis of Complex Systems and Decision Processes&amp;quot;</title>
<date>1973</date>
<journal>IEEE Trans. on Systems, Man, and Cybernetics,</journal>
<volume>3</volume>
<marker>19.</marker>
<rawString>L. A. Zadeh, &amp;quot;Outlining of a New Approach to the Analysis of Complex Systems and Decision Processes&amp;quot; IEEE Trans. on Systems, Man, and Cybernetics, Vol. SMC-3, No. 1 (January 1973).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>