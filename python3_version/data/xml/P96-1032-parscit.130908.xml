<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.980109">
Efficient Tabular LR Parsing
</title>
<author confidence="0.98813">
Mark-Jan Nederhof
</author>
<affiliation confidence="0.995544">
Faculty of Arts
University of Groningen
</affiliation>
<address confidence="0.756744333333333">
P.O. Box 716
9700 AS Groningen
The Netherlands
</address>
<email confidence="0.669669">
markjaallet.rug.n1
</email>
<note confidence="0.686474">
Giorgio Satta
Dipartimento di Elettronica ed Informatica
Universita di Padova
</note>
<address confidence="0.61106">
via Gradenigo, 6/A
1-35131 Padova
Italy
</address>
<email confidence="0.794794">
sattadei.unipd.it
</email>
<sectionHeader confidence="0.96654" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999192363636364">
We give a new treatment of tabular LR
parsing, which is an alternative to Tomita&apos;s
generalized LR algorithm. The advantage
is twofold. Firstly, our treatment is con-
ceptually more attractive because it uses
simpler concepts, such as grammar trans-
formations and standard tabulation tech-
niques also know as chart parsing. Second-
ly, the static and dynamic complexity of
parsing, both in space and time, is signifi-
cantly reduced.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999498738461539">
The efficiency of LR(k) parsing techniques (Sippu
and Soisalon-Soininen, 1990) is very attractive from
the perspective of natural language processing ap-
plications. This has stimulated the computational
linguistics community to develop extensions of these
techniques to general context-free grammar parsing.
The best-known example is generalized LR pars-
ing, also known as Tomita&apos;s algorithm, described by
Tomita (1986) and further investigated by, for ex-
ample, Tomita (1991) and Nederhof (1994a). Des-
pite appearances, the graph-structured stacks used
to describe Tomita&apos;s algorithm differ very little from
parse tables, or in other words, generalized LR pars-
ing is one of the so called tabular parsing algorithms,
among which also the CYK algorithm (Harrison,
1978) and Earley&apos;s algorithm (Earley, 1970) can be
found. (Tabular parsing is also known as chart pars-
ing.)
In this paper we investigate the extension of LR
parsing to general context-free grammars from a
more general viewpoint: tabular algorithms can of-
ten be described by the composition of two construc-
tions. One example is given by Lang (1974) and
Billot and Lang (1989): the construction of push-
down automata from grammars and the simulation
of these automata by means of tabulation yield dif-
ferent tabular algorithms for different such construc-
tions. Another example, on which our presentation
is based, was first suggested by Leermakers (1989):
a grammar is first transformed and then a standard
tabular algorithm along with some filtering condi-
tion is applied using the transformed grammar. In
our case, the transformation and the subsequent ap-
plication of the tabular algorithm result in a new
form of tabular LR parsing.
Our method is more efficient than Tomita&apos;s algo-
rithm in two respects. First, reduce operations are
implemented in an efficient way, by splitting them in-
to several, more primitive, operations (a similar idea
has been proposed by Kipps (1991) for Tomita&apos;s al-
gorithm). Second, several paths in the computation
that must be simulated separately by Tomita&apos;s algo-
rithm are collapsed into a single computation path,
using state minimization techniques. Experiments
on practical grammars have indicated that there is
a significant gain in efficiency, with regard to both
space and time requirements.
Our grammar transformation produces a so called
cover for the input grammar, which together with
the filtering condition fully captures the specifica-
tion of the method, abstracting away from algorith-
mic details such as data structures and control flow.
Since this cover can be easily precomputed, imple-
menting our LR parser simply amounts to running
the standard tabular algorithm. This is very attrac-
tive from an application-oriented perspective, since
many actual systems for natural language processing
are based on these kinds of parsing algorithm.
The remainder of this paper is organized as fol-
lows. In Section 2 some preliminaries are discussed.
We review the notion of LR automaton in Section,3
and introduce the notion of 2LR automaton in Sec-
tion 4. Then we specify our tabular LR method in
Section 5, and provide an analysis of the algorithm
in Section 6. Finally, some empirical results are giv-
</bodyText>
<page confidence="0.996312">
239
</page>
<bodyText confidence="0.955031">
en in Section 7, and further discussion of our method
is provided in Section 8.
</bodyText>
<sectionHeader confidence="0.98611" genericHeader="introduction">
2 Definitions
</sectionHeader>
<bodyText confidence="0.978508507042253">
Throughout this paper we use standard formal lan-
guage notation. We assume that the reader is famil-
iar with context-free grammar parsing theory (Har-
rison, 1978).
A context-free grammar (CFG) is a 4-tuple G
(E, N, P, S), where E and N are two finite disjoint
sets of terminal and nonterminal symbols, respec-
tively, S E N is the start symbol, and P is a finite
set of rules. Each rule has the form A a with
A E N and a E V*, where V denotes N U E. The
size of G, written I GI, is defined as E(A_,,,,,)Ep I Aa I;
by I a I we mean the length of a string of symbols a.
We generally use symbols A, B, C, . . . to range
over N, symbols a, b, c, . . . to range over E, symbols
X ,Y, Z to range over V, symbols a, /3,7, . to range
over V*, and symbols v, w, x, . . . to range over E*.
We write c to denote the empty string.
A CFG is said to be in binary form if a E
{c} U VU N2 for all of its rules A --+ a. (The binary
form does not limit the (weak) generative capaci-
ty of context-free grammars (Harrison, 1978).) For
technical reasons, we sometimes use the augment-
ed grammar associated with G, defined as Gt =
(Et, Nt pt St), where St, D and &lt;I are fresh sym-
bols, Et = E Nt = N U {St} and
pt = p u {St DS&lt;}.
A pushdown automaton (PDA) is a 5-tuple A =
qfin), where E , Q and T are finite sets
of input symbols, stack symbols and transitions, re-
spectively; q2n E Q is the initial stack symbol and
qfin E Q is the final stack symbol.1 Each transition
has the form 61 62, where 61,62 E Q*, 1 &lt; 1611,
&lt; 1,521 &lt; 2, and z = c or z = a. We generally use
symbols q, r, s, . . . to range over Q, and the symbol
6 to range over Q*.
Consider a fixed input string v E E. . A config-
uration of the automaton is a pair (6, w) consisting
of a stack 6 E Q* and the remaining input w, which
is a suffix of the input string v. The rightmost sym-
bol of 6 represents the top of the stack. The initial
configuration has the form (q,n, v), where the stack
is formed by the initial stack symbol. The final con-
figuration has the form (qin qfin, c), where the stack
is formed by the final stack symbol stacked upon the
initial stack symbol.
&apos;We dispense with the notion of state, traditionally
incorporated in the definition of PDA. This does not
affect the power of these devices, since states can be
encoded within stack symbols and transitions.
The application of a transition bi 62 is de-
scribed as follows. If the top-most symbols of the
stack are bi, then these symbols may be replaced by
62, provided that either z = c, or z = a and a is the
first symbol of the remaining input. Furthermore, if
z = a then a is removed from the remaining input.
Formally, for a fixed PDA A we define the bina-
ry relation F on configurations as the least relation
satisfying (661, w) (662, w) if there is a transition
61 IL, 62, and (661, atv) (662, w) if there is a tran-
sition 61 62. The recognition of a certain input v
is obtained if starting from the initial configuration
for that input we can reach the final configuration
by repeated application of transitions, or, formally,
if (q2„, v) (qn, qfin, c), where F* denotes the re-
flexive and transitive closure of F.
By a computation of a PDA we mean a sequence
(q, v) (Si, wi) F (6,w), n &gt; 0. A PDA is
called deterministic if for all possible configurations
at most one transition is applicable. A PDA is said
to be in binary form if, for all transitions 61 124 62,
we have 16i1 &lt;2.
</bodyText>
<sectionHeader confidence="0.98342" genericHeader="method">
3 LR automata
</sectionHeader>
<bodyText confidence="0.9995775">
Let G = (E , N, P, S) be a CFG. We recall the no-
tion of LR automaton, which is a particular kind
of PDA. We make use of the augmented grammar
Gt = (Et , Nt pt st) introduced in Section 2.
Let ./LR = {A a • f3 I (A cei3) E Pt}.
We introduce the function closure from 2hR to 2/LR
and the function got() from 2ILR X V to 2/LR. For
any q C /LB, closure(q) is the smallest set such that
</bodyText>
<listItem confidence="0.553418333333333">
(i) q C closure(q); and
(ii) (B a • A13) E closure(q) and (A —&gt; 7) E Pt
together imply (A • 7) E closure(q).
</listItem>
<bodyText confidence="0.72662">
We then define
</bodyText>
<equation confidence="0.999069">
goto(q, X) =
{A aX • # I (A a • X3) E closure(q)}
</equation>
<bodyText confidence="0.9934315">
We construct a finite set RLR as the smallest collec-
tion of sets satisfying the conditions:
</bodyText>
<listItem confidence="0.996056333333333">
(i) {St L&gt; • S4} E RLR; and
(ii) for every q E R.LR and X E V, we have
goto(q, X) E RLR, provided goto(q, X) 0 0.
</listItem>
<bodyText confidence="0.487249">
Two elements from RLR deserve special attention:
qtn = {St D. • Si}, and qfin, which is defined to
be the unique set in R.LR containing (St DS • &lt;0;
in other words, qfin = goto(q,n, S).
</bodyText>
<page confidence="0.978515">
240
</page>
<bodyText confidence="0.486646333333333">
For A E N, an A-redex is a string qoq02 • qm,
m&gt; 0, of elements from Rut, satisfying the follow-
ing conditions:
</bodyText>
<equation confidence="0.886963181818182">
(i) (A --4 a .) E closure(qm), for some a
Xi X2 • • X,i; and
(ii) goto(qk_i, Xk) = qk, for 1 &lt; k &lt; m.
Note that in such an A-redex, (A —+ • Xi X2 • • Xm)
E closure(qo), and (A Xi. • • • Xk • Xk+1 • • • Xm)
E qk, for 0 &lt; k &lt; m.
The LR automaton associated with G is now in-
troduced.
Definition 1 ALR = (E, Q1,114 TLR, gin, qfin), where
QLR = RLR, qm = {St —+ t&gt; • S.(1}, qfin
goto(q, S), and TLR contains:
</equation>
<listItem confidence="0.8621655">
(i) q q q&apos; , for every a E L&apos; and q, q&apos; E Rut such
that q&apos; = goto(q, a);
(ii) q6 1-S4 q q&apos;, for every A E N A-redex q6, and
q&apos; E RLR such that q&apos; = goto(q, A).
</listItem>
<bodyText confidence="0.98878">
Transitions in (i) above are called shift, transitions
in (ii) are called reduce.
</bodyText>
<sectionHeader confidence="0.996035" genericHeader="method">
4 2LR Automata
</sectionHeader>
<bodyText confidence="0.999250428571428">
The automata ALR defined in the previous section
are deterministic only for a subset of the CFGs,
called the LR(0) grammars (Sippu and Soisalon-
Soininen, 1990), and behave nondeterministical-
ly in the general case. When designing tabular
methods that simulate nondeterministic computa-
tions of ALR, two main difficulties are encountered:
</bodyText>
<listItem confidence="0.96991775">
• A reduce transition in ALR is an elementary op-
eration that removes from the stack a number
of elements bounded by the size of the underly-
ing grammar. Consequently, the time require-
ment of tabular simulation of ALR computa-
tions can be onerous, for reasons pointed out
by Sheil (1976) and Kipps (1991).
• The set &apos;R.LR can be exponential in the size of
the grammar (Johnson, 1991). If in such a case
the computations of ALR touch upon each state,
then time and space requirements of tabular
simulation are obviously onerous.
</listItem>
<bodyText confidence="0.9890623">
The first issue above is solved here by re-
casting ALR in binary form. This is done
by considering each reduce transition as a se-
quence of &amp;quot;pop&amp;quot; operations which affect at most
two stack symbols at a time. (See also
Lang (1974), Villemonte de la Clergerie (1993) and
Nederhof (1994a), and for LR parsing specifically
Kipps (1991) and Leermakers (1992b).) The follow-
ing definition introduces this new kind of automaton.
Definition 2 Aia = (E, QLR, TLR, qm, qfin), where
</bodyText>
<listItem confidence="0.9350891">
QLR = RLR U /1,R) Qin = {St • S4}, qfin =
goto(qm,S) and TiAt contains:
(i) q2+ q q&apos; , for every a E Z and q, q&apos; E RLR such
that q&apos; = goto(q, a);
(ii) q q (A .), for every q E RLR and (A
a.) E closure(q);
(iii) q (A —4 aX • 1(3) I-14 (A —4 a • X)3), for every
q E 7ZLn and (A —4- aX • )3) E q;
(iv) q (A --4 • a) q q&apos;, for every q,q&apos; E RLR and
(A —4 a) E Pt such that q&apos; = goto(q, A).
</listItem>
<bodyText confidence="0.999701730769231">
Transitions in (i) above are again called shift, tran-
sitions in (ii) are called initiate, those in (iii) are
called gathering, and transitions in (iv) are called
goto. The role of a reduce step in ALR is taken over
in Aim by an initiate step, a number of gathering
steps, and a goto step. Observe that these steps in-
volve the new stack symbols (A —+ a • E 1.1,R
that are distinguishable from possible stack symbols
{A a • PI E RLR-
We now turn to the second above-mentioned prob-
lem, regarding the size of set RLR. The problem
is in part solved here as follows. The number of
states in 12,LR is considerably reduced by identify-
ing two states if they become identical after items
A —4 a • )3 from /La have been simplified to only
the suffix of the right-hand side This is rem-
iniscent of techniques of state minimization for fi-
nite automata (Booth, 1967), as they have been ap-
plied before to LR parsing, e.g., by Pager (1970) and
Nederhof and Sarbo (1993).
Let GI be the augmented grammar associated
with a CFG G, and let /21,R = {/3 I (A afi) E
Pl. We define variants of the closure and goto func-
tions from the previous section as follows. For any
set q C /2LR, closure1(q) is the smallest collection of
sets such that
</bodyText>
<listItem confidence="0.979405333333333">
(i) q c closure&apos;(q); and
(ii) (AP) E closure&apos; (q) and (A 7) E PI together
imply (7) E closure&apos; (q).
</listItem>
<bodyText confidence="0.967136">
Also, we define
</bodyText>
<equation confidence="0.521521">
goto1(q, X) = {fl I (XP) E closure&apos; (q)}.
</equation>
<bodyText confidence="0.999305">
We now construct a finite set R2LR as the smallest
set satisfying the conditions:
</bodyText>
<page confidence="0.975928">
241
</page>
<listItem confidence="0.910731">
(i) {S•i} E 7Z2Ln,; and
(ii) for every q E ??-2LR and X E V, we have
goto1(q, X) E Te2LR) provided goto&apos;(q, X) 0 0.
</listItem>
<bodyText confidence="0.9506555">
As stack symbols, we take the elements from /2LR
and a subset of elements from (V x R2LR):
</bodyText>
<equation confidence="0.974181">
Q2LR = {(X, q) I 3V[goto&apos; (9,1 , X) = q]} U-T2LR
</equation>
<bodyText confidence="0.958515444444445">
In a stack symbol of the form (X, q), the X serves
to record the grammar symbol that has been recog-
nized last, cf. the symbols that formerly were found
immediately before the dots.
The 2LR automaton associated with G can now
be introduced.
Definition 3 A2LR = (0, Q2LR, T2LR, q,efin),
where Q2LR is as defined above, q&apos;in = (t&apos;, {S.1}),
g&apos;fin = (S, goto&apos;({S&lt;},S)), and T2LR contains:
</bodyText>
<equation confidence="0.994783555555556">
(i) (X ,q) 111,. (X ,q) (a, q1), for every a E 0 and
(X, q), (a, q&apos;) E Q2LR such that g&apos; = goto&apos;(q, a);
(ii) (X, q) 4 (X, q) (c), for every (X, q) E Q2LR
such that c E closure&apos; (q);
(iii) (X, q) (/3) 4 (X/3), for every (X, q) E Q2LR
and # E q;
(iv) (X, q) (a) 4 (X ,q) (A, q&apos;), for every (X, q),
(A,g1) E Q2LR and (A a) E Pt such that
q&apos; = goto1(q, A).
</equation>
<bodyText confidence="0.999792363636363">
Note that in the case of a reduce/reduce conflict
with two grammar rules sharing some suffix in the
right-hand side, the gathering steps of A2LR will
treat both rules simultaneously, until the parts of
the right-hand sides are reached where the two rules
differ. (See Leermakers (1992a) for a similar sharing
of computation for common suffixes.)
An interesting fact is that the automaton A2LR is
very similar to the automaton ALR constructed for
a grammar transformed by the transformation
given by Nederhof and Satta (1994).2
</bodyText>
<sectionHeader confidence="0.99101" genericHeader="method">
5 The algorithm
</sectionHeader>
<bodyText confidence="0.998951939393939">
This section presents a tabular LR parser, which is
the main result of this paper. The parser is derived
from the 2LR automata introduced in the previous
section. Following the general approach presented
by Leermakers (1989), we simulate computations of
2For the earliest mention of this transformation, we
have encountered pointers to Schauerte (1973). Regret-
tably, we have as yet not been able to get hold of a copy
of this paper.
these devices using a tabular method, a grammar
transformation and a filtering function.
We make use of a tabular parsing algorithm which
is basically an asynchronous version of the CYK al-
gorithm, as presented by Harrison (1978), extended
to productions of the forms A —4 B and A —4 c
and with a left-to-right filtering condition. The al-
gorithm uses a parse table consisting in a 0-indexed
square array U. The indices represent positions in
the input string. We define Ili to be Uk&lt;i Uk,i,
Computation of the entries of U is moderated by
a filtering process. This process makes use of a
function pred from 2N to 2N, specific to a certain
context-free grammar. We have a certain nontermi-
nal Ainit which is initially inserted in U0,0 in order
to start the recognition process.
We are now ready to give a formal specification of
the tabular algorithm.
Algorithm 1 Let G = (0, N, P, S) be a CFG in
binary form, let pred be a function from 2N to 2N,
let Auto be the distinguished element from N, and
let v = al a2 • • • an E 0* be an input string. We
compute the least (n +1) x (n +1) table U such that
Amit E U0,0 and
</bodyText>
<listItem confidence="0.86904675">
(i) A E
if (A ai) E P, A E pred(Ui _1);
(ii) A E Ujj
if (A —4 e) EP,A E pred(Uj);
(iii) A E
if B E Ui,k, C E Ukj, (A —+ BC) E P, A E
pred(Ui);
(iv) A E
</listItem>
<bodyText confidence="0.76248775">
if B E , (A—+ B) E P, A E pred(Ui).
The string has been accepted when S E UO, .
We now specify a grammar transformation, based
on the definition of Ana.
Definition 4 Let A2LR = (0) Q2LR) T2LR) glin) Vfin)
be the 2LR automaton associated with a CFG G.
The 2LR cover associated with G is the CFG
C2LR(G) = (0, Q2LR, P2LR3 efin), where the rules in
</bodyText>
<figure confidence="0.172494454545455">
P2LR
(i) (a, q&apos;) a,
for every (X, q) 142+ (X, q) (a, q&apos;) E T2LR;
(ii) (e) e)
for every (X ,q)i-f-* (X, q) (c) E T2LR;
(iii) (X/3) (X, q) (0),
for every (X, q) (#) 4 (X/3) E T2LR;
are given by:
242
(iv) (A, g&apos;) (a),
for every (X, q) (a)11+ (X, q) (A, q&apos;) E T2LR•
</figure>
<bodyText confidence="0.9953448">
Observe that there is a direct, one-to-one correspon-
dence between transitions of A2LR and productions
of C2LR(G)•
The accompanying function pred is defined as fol-
lows (q, q&apos;, q&amp;quot; range over the stack elements):
</bodyText>
<equation confidence="0.938249666666667">
pred(r) = {q I q&apos; q&amp;quot; 4 q E T2L}t} U
{ q q&apos; E 7, q&apos; q&apos; q E T21.,n} U
{q I q&apos; E r, q&apos; q&amp;quot; q E T2LR}.
</equation>
<bodyText confidence="0.999937904761905">
The above definition implies that only the tabular
equivalents of the shift, initiate and goto transitions
are subject to actual filtering; the simulation of the
gathering transitions does not depend on elements
in T.
Finally, the distinguished nonterminal from the
cover used to initialize the table is q:n. Thus we
start with (c&gt;, {S&lt;1}) E Uo,o,
The 2LR cover introduces spurious ambiguity:
where some grammar G would allow a certain num-
ber of parses to be found for a certain input, the
grammar C2LR(G) in general allows more parses.
This problem is in part solved by the filtering func-
tion pred . The remaining spurious ambiguity is
avoided by a particular way of constructing the parse
trees, described in what follows.
After Algorithm 1 has recognized a given in-
put, the set of all parse trees can be computed as
tree(efin, 0, n) where the function tree, which deter-
mines sets of either parse trees or lists of parse trees
for entries in U, is recursively defined by:
</bodyText>
<listItem confidence="0.985685642857143">
(i) tree((a, q&apos;), i, j) is the set {a}. This set contains
a single parse tree consisting of a single node
labelled a.
(ii) tree(E, i, i) is the set {e}. This set consists of an
empty list of trees.
(iii) tree(X , j) is the union of the sets
where i &lt; k &lt; j, (0) E Uk,i, and there is at
least one (X, q) E Uidc and (X/3) --+ (X, q) (0)
in C2Ln(G), for some q. For each such k, select
one such q. We define &apos;T(kxp),i = ft • ts t E
tree((X , q), i,k) A is E iree(fl ,k, j)} . Each t • is
is a list of trees, with head t and tail is.
(iv) tree((A, q&apos;), i, j) is the union of the sets
7A,q,),i,j, where (a) E Uji is such that
</listItem>
<bodyText confidence="0.92397796">
(A, q&apos;) (a) in C2Ln(G). We define
{glue(A, is) I is E tree(a, j)} . The function
glue constructs a tree from a fresh root node
labelled A and the trees in list is as immediate
subtrees.
We emphasize that in the third clause above, one
should not consider more than one q for given k in
order to prevent spurious ambiguity. (In fact, for
fixed X, i, k and for different q such that (X, q) E
Uidc, tree((X , q), i, k) yields the exact same set of
trees.) With this proviso, the degree of ambiguity,
i.e. the number of parses found by the algorithm for
any input, is reduced to exactly that of the source
grammar.
A practical implementation would construct the
parse trees on-the-fly, attaching them to the table
entries, allowing packing and sharing of subtrees (cf.
the literature on parse forests (Tomita, 1986; Bil-
lot and Lang, 1989)). Our algorithm actually only
needs one (packed) subtree for several (X, q) E Ui,k
with fixed X,i,k but different q. The resulting
parse forests would then be optimally compact, con-
trary to some other LR-based tabular algorithms, as
pointed out by Rekers (1992), Nederhof (1993) and
Nederhof (1994b).
</bodyText>
<sectionHeader confidence="0.683907" genericHeader="method">
6 Analysis of the algorithm
</sectionHeader>
<bodyText confidence="0.963773107142857">
In this section, we investigate how the steps per-
formed by Algorithm 1 (applied to the 2LR cover)
relate to those performed by A2LR, for the same in-
put.
We define a subrelation WI- of 1-+ as: (6, uw)
(bb&apos; , w) if and only if (6, uw) = (15, zi z2 • • • zmw)
(661, z2 • zmw) . . . (66m w) =*- (6.5&apos;, w), for
some m &gt; 1, where 16k I &gt; 0 for all k, 1 &lt; k &lt; m.
Informally, we have (6, uw) (66&apos;, w) if configura-
tion (66&apos;, w) can be reached from (6, uw) without the
bottom-most part 6 of the intermediate stacks being
affected by any of the transitions; furthermore, at
least one element is pushed on top of 6.
The following characterization relates the automa-
ton A2LR and Algorithm 1 applied to the 2LR cover.
Symbol q E Q2LR is eventually added to Uji if and
only if for some 8:
(q, a1 ... an) 1-* (6, ai+i .a) WI- (6q, ai +1
In words, q is found in entry Ujj if and only if, at
input position j, the automaton would push some
element q on top of some lower-part of the stack b
that remains unaffected while the input from i to j
is being read.
The above characterization, whose proof is not re-
ported here, is the justification for calling the result-
ing algorithm tabular LR parsing. In particular, for
a grammar for which A2LR is deterministic, i.e. for
an LR(0) grammar, the number of steps performed
</bodyText>
<page confidence="0.996659">
243
</page>
<bodyText confidence="0.94071736">
by Ana and the number of steps performed by the
above algorithm are exactly the same. In the case of
grammars which are not LR(0), the tabular LR algo-
rithm is more efficient than for example a backtrack
realisation of Azi.,R•
For determining the order of the time complex-
ity of our algorithm, we look at the most expen-
sive step, which is the computation of an element
(X0) E Ui,j from two elements (X, q) E Eli,k and
(j3) E Uk,j, through (X , q) (#) (X13) E T2LR. In
a straightforward realisation of the algorithm, this
step can be applied 0(1 T2LR I • I V 13) times (once for
each i, k, j and each transition), each step taking a
constant amount of time. We conclude that the time
complexity of our algorithm is 0(1 T2LB, I • I V 13).
As far as space requirements are concerned, each
set or Ui contains at most 10 I
, 2LR elements.
(One may assume an auxiliary table storing each IA.)
This results in a space complexity 0(1 Q2LR I I v 12).
The entries in the table represent single stack ele-
ments, as opposed to pairs of stack elements follow-
ing Lang (1974) and Leermakers (1989). This has
been investigated before by Nederhof (1994a, p. 25)
and Villemonte de la Clergerie (1993, p. 155).
</bodyText>
<sectionHeader confidence="0.966948" genericHeader="method">
7 Empirical results
</sectionHeader>
<bodyText confidence="0.999655703703704">
We have performed some experiments with Algo-
rithm 1 applied to A2LR and ALR, for 4 practical
context-free grammars. For ALR a cover was used
analogous to the one in Definition 4; the filtering
function remains the same.
The first grammar generates a subset of the pro-
gramming language ALGOL 68 (van Wijngaarden
and others, 1975). The second and third grammars
generate a fragment of Dutch, and are referred to as
the CORRie grammar (Vosse, 1994) and the Deltra
grammar (Schoorl and Belder, 1990), respectively.
These grammars were stripped of their arguments
in order to convert them into context-free grammars.
The fourth grammar, referred to as the Alvey gram-
mar (Carroll, 1993), generates a fragment of English
and was automatically generated from a unification-
based grammar.
The test sentences have been obtained by au-
tomatic generation from the grammars, using the
Grammar Workbench (Nederhof and Koster, 1992),
which uses a random generator to select rules; there-
fore these sentences do not necessarily represent in-
put typical of the applications for which the gram-
mars were written. Table 1 summarizes the test ma-
terial.
Our implementation is merely a prototype, which
means that absolute duration of the parsing process
</bodyText>
<table confidence="0.9787968">
G = (E , N, P, S) IG1 I NI IPI 111&apos;1
ALGOL 68 783 167 330 13.7
CORRie 1141 203 424 12.3
Deltra 1929 281 703 10.8
Alvey 5072 265 1484 10.7
</table>
<tableCaption confidence="0.7225265">
Table 1: The test material: the four grammars and
some of their dimensions, and the average length of
the test sentences (20 sentences of various length for
each grammar).
</tableCaption>
<table confidence="0.999344333333334">
ALR A2LR
G space time space time
ALGOL 68 327 375 234 343
CORRie 7548 28028 5131 22414
Deltra 11772 94824 6526 70333
Alvey 599 1147 354 747
</table>
<tableCaption confidence="0.869716">
Table 2: Dynamic requirements: average space and
time per sentence.
</tableCaption>
<bodyText confidence="0.996330172413793">
is little indicative of the actual efficiency of more
sophisticated implementations. Therefore, our mea-
surements have been restricted to implementation-
independent quantities, viz, the number of elements
stored in the parse table and the number of elemen-
tary steps performed by the algorithm. In a practical
implementation, such quantities will strongly influ-
ence the space and time complexity, although they
do not represent the only determining factors. Fur-
thermore, all optimizations of the time and space
efficiency have been left out of consideration.
Table 2 presents the costs of parsing the test sen-
tences. The first and third columns give the number
of entries stored in table U, the second and fourth
columns give the number of elementary steps that
were performed.
An elementary step consists of the derivation of
one element in %R or Q2LR. from one or two other
elements. The elements that are used in the filter-
ing process are counted individually. We give an
example for the case of AR. Suppose we derive an
element q&apos; E Uij from an element (A • a) E Uj,
warranted by two elements qi , q2 E U, qi q2,
through pred, in the presence of qi (A • a) 12.4
qi q&apos; E TLR and 0 (A • a) 4 q2 q&apos; E TL,R. . We
then count Iwo parsing steps, one for q1 and one for
q2.
Table 2 shows that there is a significant gain in
space and time efficiency when moving from Aia to
</bodyText>
<page confidence="0.992947">
244
</page>
<table confidence="0.997842142857143">
ALR A2LR
G IR-LFti iQi.,ai MAI R2LR. IQ I I 1
I I , _ 2LR. _ ,T2LR.
ALGOL 68 434 1,217 13,844 109 724 12,387
CORRie 600 1,741 22,129 185 821 15,569
Deltra 856 2,785 54,932 260 1,089 37,510
Alvey 3,712 8,784 1,862,492 753 3,065 537,852
</table>
<tableCaption confidence="0.999363">
Table 3: Static requirements.
</tableCaption>
<bodyText confidence="0.9598258125">
A2LR.
Apart from the dynamic costs of parsing, we have
also measured some quantities relevant to the con-
struction and storage of the two types of tabular LR
parser. These data are given in Table 3.
We see that the number of states is strongly re-
duced with regard to traditional LR parsing. In the
case of the Alvey grammar, moving from &apos;Rut&apos; to
ITZ2LRI amounts to a reduction to 20.3 %. Whereas
time- and space-efficient computation of 1ZLR for this
grammar is a serious problem, computation of R2LR
will not be difficult on any modern computer. Al-
so significant is the reduction from ITLRI to IT2LRI,
especially for the larger grammars. These quanti-
ties correlate with the amount of storage needed for
naive representation of the respective automata.
</bodyText>
<sectionHeader confidence="0.999582" genericHeader="discussions">
8 Discussion
</sectionHeader>
<bodyText confidence="0.9716545">
Our treatment of tabular LR parsing has two impor-
tant advantages over the one by Tomita:
• It is conceptually simpler, because we make use
of simple concepts such as a grammar trans-
formation and the well-understood CYK al-
gorithm, instead of a complicated mechanism
working on graph-structured stacks.
• Our algorithm requires fewer Lit states. This
leads to faster parser generation, to smaller
parsers, and to reduced time and space com-
plexity of parsing itself.
The conceptual simplicity of our formulation of
tabular LR parsing allows comparison with other
tabular parsing techniques, such as Earley&apos;s algo-
rithm (Earley, 1970) and tabular left-corner pars-
ing (Nederhof, 1993), based on implementation-
independent criteria. This is in contrast to experi-
ments reported before (e.g. by Shann (1991)), which
treated tabular 1,it parsing differently from the other
techniques.
The reduced time and space complexities reported
in the previous section pertain to the tabular real-
isation of two parsing techniques, expressed by the
automata ALR and A2LR. The tabular realisation
of the former automata is very close to a variant of
Tomita&apos;s algorithm by Kipps (1991). The objective
of our experiments was to show that the automata
A2LR provide a better basis than ALR for tabular LR
parsing with regard to space and time complexity.
Parsing algorithms that are not based on the
Lit technique have however been left out of con-
sideration, and so were techniques for unification
grammars and techniques incorporating finite-state
processes.3
Theoretical considerations (Leermakers, 1989;
Schabes, 1991; Nederhof, 1994b) have suggested that
for natural language parsing, LR-based techniques
may not necessarily be superior to other parsing
techniques, although convincing empirical data to
this effect has never been shown. This issue is dif-
ficult to resolve because so much of the relative ef-
ficiency of the different parsing techniques depends
on particular grammars and particular input, as well
as on particular implementations of the techniques.
We hope the conceptual framework presented in this
paper may at least partly alleviate this problem.
</bodyText>
<sectionHeader confidence="0.997364" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9285471875">
The first author is supported by the Dutch Organiza-
tion for Scientific Research (NWO), under grant 305-
00-802. Part of the present research was done while
the second author was visiting the Center for Lan-
guage and Speech Processing, Johns Hopkins Uni-
versity, Baltimore, MD.
We received kind help from John Carroll, Job
Honig, Kees Koster, Theo Vosse and Hans de
Vreught in finding the grammars mentioned in this
paper. Generous help with locating relevant litera-
ture was provided by Anton Nijholt, Rockford Ross,
and Arnd RuBmann.
&apos;As remarked before by Nederhof (1993), the algo-
rithms by Schabes (1991) and Leermakers (1989) are not
really related to LR parsing, although some notation
used in these papers suggests otherwise.
</bodyText>
<page confidence="0.997748">
245
</page>
<sectionHeader confidence="0.988928" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99884623655914">
Billot, S. and B. Lang. 1989. The structure of
shared forests in ambiguous parsing. In 27th An-
nual Meeting of the ACL, pages 143-151.
Booth, T.L. 1967. Sequential Machines and Au-
tomata Theory. Wiley, New York.
Carroll, J.A. 1993. Practical unification-based pars-
ing of natural language. Technical Report No.
314, University of Cambridge, Computer Labora-
tory, England. PhD thesis.
Earley, J. 1970. An efficient context-free parsing al-
gorithm. Communications of the ACM, 13(2):94-
102.
Harrison, M.A. 1978. Introduction to Formal Lan-
guage Theory. Addison-Wesley.
Johnson, M. 1991. The computational complexi-
ty of GLR parsing. In Tomita (1991), chapter 3,
pages 35-42.
Kipps, J.R. 1991. GLR parsing in time 0(n3). In
Tomita (1991), chapter 4, pages 43-59.
Lang, B. 1974. Deterministic techniques for ef-
ficient non-deterministic parsers. In Automata,
Languages and Programming, 2nd Colloquium,
LNCS 14, pages 255-269, Saarbriicken. Springer-
Verlag.
Leermakers, R. 1989. How to cover a grammar. In
27th Annual Meeting of the ACL, pages 135-142.
Leermakers, R. 1992a. A recursive ascent Earley
parser. Information Processing Letters, 41(2):87-
91.
Leermakers, R. 1992b. Recursive ascent parsing:
from Earley to Marcus. Theoretical Computer
Science, 104:299-312.
Nederhof, M.J. 1993. Generalized left-corner pars-
ing. In Sixth Conference of the European Chapter
of the ACL, pages 305-314.
Nederhof, M.J. 1994a. Linguistic Parsing and Pro-
gram Transformations. Ph.D. thesis, University
of Nijmegen.
Nederhof, M.J. 1994b. An optimal tabular parsing
algorithm. In 32nd Annual Meeting of the ACL,
pages 117-124.
Nederhof, M.J. and K. Koster. 1992. A customized
grammar workbench. In J. Aarts, P. de Haan,
and N. Oostdijk, editors, English Language Cor-
pora: Design, Analysis and Exploitation, Papers
from the thirteenth International Conference on
English Language Research on Computerized Cor-
pora, pages 163-179, Nijmegen. Rodopi.
Nederhof, M.J. and J.J. Sarbo. 1993. Increasing
the applicability of LR parsing. In Third Interna-
tional Workshop on Parsing Technologies, pages
187-201.
Nederhof, M.J. and G. Satta. 1994. An extended
theory of head-driven parsing. In 32nd Annual
Meeting of the ACL, pages 210-217.
Pager, D. 1970. A solution to an open problem by
Knuth. Information and Control, 17:462-473.
Rekers, J. 1992. Parser Generation for Interactive
Environments. Ph.D. thesis, University of Am-
sterdam.
Schabes, Y. 1991. Polynomial time and space shift-
reduce parsing of arbitrary context-free gram-
mars. In 29th Annual Meeting of the ACL, pages
106-113.
Schauerte, It. 1973. Transformationen von
LR(k)-grammatiken. Diplomarbeit, Universitat
GOttingen, Abteilung Informatik.
Schoorl, J.J. and S. Belder. 1990. Computation-
al linguistics at Delft: A status report. Report
WTM/TT 90-09, Delft University of Technology,
Applied Linguistics Unit.
Shann, P. 1991. Experiments with GLR and chart
parsing. In Tomita (1991), chapter 2, pages 17-
34.
Sheil, B.A. 1976. Observations on context-free pars-
ing. Statistical Methods in Linguistics, pages 71-
109.
Sippu, S. and E. Soisalon-Soininen. 1990. Pars-
ing Theory, Vol. II: LR(k) and LL(k) Parsing.
Springer-Verlag.
Tomita, M. 1986. Efficient Parsing for Natural Lan-
guage. Kluwer Academic Publishers.
Tomita, M., editor. 1991. Generalized LR Parsing.
Kluwer Academic Publishers.
van Wijngaarden, A. et al. 1975. Revised report on
the algorithmic language ALGOL 68. Acta Infor-
matica, 5:1-236.
Villemonte de la Clergerie, E. 1993. Automates a
Piles et Programmation Dynamique - DyALog:
Une application a la Programmaiion en Logique.
Ph.D. thesis, Universite Paris VII.
Vosse, T.G. 1994. The Word Connection. Ph.D.
thesis, University of Leiden.
</reference>
<page confidence="0.998728">
246
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.376053">
<title confidence="0.999916">Efficient Tabular LR Parsing</title>
<author confidence="0.963186">Mark-Jan Nederhof</author>
<affiliation confidence="0.99894">Faculty of Arts University of Groningen</affiliation>
<address confidence="0.978942666666667">716 9700 AS Groningen The Netherlands</address>
<email confidence="0.463827">markjaallet.rug.n1</email>
<author confidence="0.997794">Giorgio Satta</author>
<affiliation confidence="0.9988155">Dipartimento di Elettronica ed Informatica Universita di Padova</affiliation>
<address confidence="0.990611666666667">via Gradenigo, 6/A 1-35131 Padova Italy</address>
<email confidence="0.998894">sattadei.unipd.it</email>
<abstract confidence="0.991846083333333">We give a new treatment of tabular LR parsing, which is an alternative to Tomita&apos;s generalized LR algorithm. The advantage is twofold. Firstly, our treatment is conceptually more attractive because it uses simpler concepts, such as grammar transformations and standard tabulation techalso know as parsing. Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Billot</author>
<author>B Lang</author>
</authors>
<title>The structure of shared forests in ambiguous parsing.</title>
<date>1989</date>
<booktitle>In 27th Annual Meeting of the ACL,</booktitle>
<pages>143--151</pages>
<contexts>
<context position="1871" citStr="Billot and Lang (1989)" startWordPosition="278" endWordPosition="281">nces, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given by Lang (1974) and Billot and Lang (1989): the construction of pushdown automata from grammars and the simulation of these automata by means of tabulation yield different tabular algorithms for different such constructions. Another example, on which our presentation is based, was first suggested by Leermakers (1989): a grammar is first transformed and then a standard tabular algorithm along with some filtering condition is applied using the transformed grammar. In our case, the transformation and the subsequent application of the tabular algorithm result in a new form of tabular LR parsing. Our method is more efficient than Tomita&apos;s </context>
<context position="18902" citStr="Billot and Lang, 1989" startWordPosition="3612" endWordPosition="3616">hird clause above, one should not consider more than one q for given k in order to prevent spurious ambiguity. (In fact, for fixed X, i, k and for different q such that (X, q) E Uidc, tree((X , q), i, k) yields the exact same set of trees.) With this proviso, the degree of ambiguity, i.e. the number of parses found by the algorithm for any input, is reduced to exactly that of the source grammar. A practical implementation would construct the parse trees on-the-fly, attaching them to the table entries, allowing packing and sharing of subtrees (cf. the literature on parse forests (Tomita, 1986; Billot and Lang, 1989)). Our algorithm actually only needs one (packed) subtree for several (X, q) E Ui,k with fixed X,i,k but different q. The resulting parse forests would then be optimally compact, contrary to some other LR-based tabular algorithms, as pointed out by Rekers (1992), Nederhof (1993) and Nederhof (1994b). 6 Analysis of the algorithm In this section, we investigate how the steps performed by Algorithm 1 (applied to the 2LR cover) relate to those performed by A2LR, for the same input. We define a subrelation WI- of 1-+ as: (6, uw) (bb&apos; , w) if and only if (6, uw) = (15, zi z2 • • • zmw) (661, z2 • zm</context>
</contexts>
<marker>Billot, Lang, 1989</marker>
<rawString>Billot, S. and B. Lang. 1989. The structure of shared forests in ambiguous parsing. In 27th Annual Meeting of the ACL, pages 143-151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T L Booth</author>
</authors>
<title>Sequential Machines and Automata Theory.</title>
<date>1967</date>
<publisher>Wiley,</publisher>
<location>New York.</location>
<contexts>
<context position="11712" citStr="Booth, 1967" startWordPosition="2205" endWordPosition="2206">step, a number of gathering steps, and a goto step. Observe that these steps involve the new stack symbols (A —+ a • E 1.1,R that are distinguishable from possible stack symbols {A a • PI E RLRWe now turn to the second above-mentioned problem, regarding the size of set RLR. The problem is in part solved here as follows. The number of states in 12,LR is considerably reduced by identifying two states if they become identical after items A —4 a • )3 from /La have been simplified to only the suffix of the right-hand side This is reminiscent of techniques of state minimization for finite automata (Booth, 1967), as they have been applied before to LR parsing, e.g., by Pager (1970) and Nederhof and Sarbo (1993). Let GI be the augmented grammar associated with a CFG G, and let /21,R = {/3 I (A afi) E Pl. We define variants of the closure and goto functions from the previous section as follows. For any set q C /2LR, closure1(q) is the smallest collection of sets such that (i) q c closure&apos;(q); and (ii) (AP) E closure&apos; (q) and (A 7) E PI together imply (7) E closure&apos; (q). Also, we define goto1(q, X) = {fl I (XP) E closure&apos; (q)}. We now construct a finite set R2LR as the smallest set satisfying the condit</context>
</contexts>
<marker>Booth, 1967</marker>
<rawString>Booth, T.L. 1967. Sequential Machines and Automata Theory. Wiley, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Carroll</author>
</authors>
<title>Practical unification-based parsing of natural language.</title>
<date>1993</date>
<tech>Technical Report No. 314,</tech>
<institution>University of Cambridge, Computer Laboratory, England.</institution>
<contexts>
<context position="22424" citStr="Carroll, 1993" startWordPosition="4272" endWordPosition="4273">R and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (Schoorl and Belder, 1990), respectively. These grammars were stripped of their arguments in order to convert them into context-free grammars. The fourth grammar, referred to as the Alvey grammar (Carroll, 1993), generates a fragment of English and was automatically generated from a unificationbased grammar. The test sentences have been obtained by automatic generation from the grammars, using the Grammar Workbench (Nederhof and Koster, 1992), which uses a random generator to select rules; therefore these sentences do not necessarily represent input typical of the applications for which the grammars were written. Table 1 summarizes the test material. Our implementation is merely a prototype, which means that absolute duration of the parsing process G = (E , N, P, S) IG1 I NI IPI 111&apos;1 ALGOL 68 783 16</context>
</contexts>
<marker>Carroll, 1993</marker>
<rawString>Carroll, J.A. 1993. Practical unification-based parsing of natural language. Technical Report No. 314, University of Cambridge, Computer Laboratory, England. PhD thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<pages>13--2</pages>
<contexts>
<context position="1540" citStr="Earley, 1970" startWordPosition="223" endWordPosition="224">omputational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given by Lang (1974) and Billot and Lang (1989): the construction of pushdown automata from grammars and the simulation of these automata by means of tabulation yield different tabular algorithms for different such constructions. Another example, on which our presentation is based, was first suggested by Leermakers</context>
<context position="26520" citStr="Earley, 1970" startWordPosition="4990" endWordPosition="4991"> tabular LR parsing has two important advantages over the one by Tomita: • It is conceptually simpler, because we make use of simple concepts such as a grammar transformation and the well-understood CYK algorithm, instead of a complicated mechanism working on graph-structured stacks. • Our algorithm requires fewer Lit states. This leads to faster parser generation, to smaller parsers, and to reduced time and space complexity of parsing itself. The conceptual simplicity of our formulation of tabular LR parsing allows comparison with other tabular parsing techniques, such as Earley&apos;s algorithm (Earley, 1970) and tabular left-corner parsing (Nederhof, 1993), based on implementationindependent criteria. This is in contrast to experiments reported before (e.g. by Shann (1991)), which treated tabular 1,it parsing differently from the other techniques. The reduced time and space complexities reported in the previous section pertain to the tabular realisation of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Earley, J. 1970. An efficient context-free parsing algorithm. Communications of the ACM, 13(2):94-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A Harrison</author>
</authors>
<title>Introduction to Formal Language Theory.</title>
<date>1978</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="1502" citStr="Harrison, 1978" startWordPosition="218" endWordPosition="219"> applications. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given by Lang (1974) and Billot and Lang (1989): the construction of pushdown automata from grammars and the simulation of these automata by means of tabulation yield different tabular algorithms for different such constructions. Another example, on which our presentation is ba</context>
<context position="4182" citStr="Harrison, 1978" startWordPosition="649" endWordPosition="651">ithm. The remainder of this paper is organized as follows. In Section 2 some preliminaries are discussed. We review the notion of LR automaton in Section,3 and introduce the notion of 2LR automaton in Section 4. Then we specify our tabular LR method in Section 5, and provide an analysis of the algorithm in Section 6. Finally, some empirical results are giv239 en in Section 7, and further discussion of our method is provided in Section 8. 2 Definitions Throughout this paper we use standard formal language notation. We assume that the reader is familiar with context-free grammar parsing theory (Harrison, 1978). A context-free grammar (CFG) is a 4-tuple G (E, N, P, S), where E and N are two finite disjoint sets of terminal and nonterminal symbols, respectively, S E N is the start symbol, and P is a finite set of rules. Each rule has the form A a with A E N and a E V*, where V denotes N U E. The size of G, written I GI, is defined as E(A_,,,,,)Ep I Aa I; by I a I we mean the length of a string of symbols a. We generally use symbols A, B, C, . . . to range over N, symbols a, b, c, . . . to range over E, symbols X ,Y, Z to range over V, symbols a, /3,7, . to range over V*, and symbols v, w, x, . . . to</context>
<context position="14519" citStr="Harrison (1978)" startWordPosition="2734" endWordPosition="2735">ch is the main result of this paper. The parser is derived from the 2LR automata introduced in the previous section. Following the general approach presented by Leermakers (1989), we simulate computations of 2For the earliest mention of this transformation, we have encountered pointers to Schauerte (1973). Regrettably, we have as yet not been able to get hold of a copy of this paper. these devices using a tabular method, a grammar transformation and a filtering function. We make use of a tabular parsing algorithm which is basically an asynchronous version of the CYK algorithm, as presented by Harrison (1978), extended to productions of the forms A —4 B and A —4 c and with a left-to-right filtering condition. The algorithm uses a parse table consisting in a 0-indexed square array U. The indices represent positions in the input string. We define Ili to be Uk&lt;i Uk,i, Computation of the entries of U is moderated by a filtering process. This process makes use of a function pred from 2N to 2N, specific to a certain context-free grammar. We have a certain nonterminal Ainit which is initially inserted in U0,0 in order to start the recognition process. We are now ready to give a formal specification of th</context>
</contexts>
<marker>Harrison, 1978</marker>
<rawString>Harrison, M.A. 1978. Introduction to Formal Language Theory. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Johnson</author>
</authors>
<title>The computational complexity of GLR parsing.</title>
<date>1991</date>
<booktitle>In Tomita</booktitle>
<pages>35--42</pages>
<contexts>
<context position="9865" citStr="Johnson, 1991" startWordPosition="1837" endWordPosition="1838">led the LR(0) grammars (Sippu and SoisalonSoininen, 1990), and behave nondeterministically in the general case. When designing tabular methods that simulate nondeterministic computations of ALR, two main difficulties are encountered: • A reduce transition in ALR is an elementary operation that removes from the stack a number of elements bounded by the size of the underlying grammar. Consequently, the time requirement of tabular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definition introduces this new kind of automaton. Definition 2 Aia = (E, QLR, TLR, qm, </context>
</contexts>
<marker>Johnson, 1991</marker>
<rawString>Johnson, M. 1991. The computational complexity of GLR parsing. In Tomita (1991), chapter 3, pages 35-42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Kipps</author>
</authors>
<title>GLR parsing in time 0(n3). In Tomita</title>
<date>1991</date>
<pages>43--59</pages>
<note>chapter 4,</note>
<contexts>
<context position="2668" citStr="Kipps (1991)" startWordPosition="407" endWordPosition="408">other example, on which our presentation is based, was first suggested by Leermakers (1989): a grammar is first transformed and then a standard tabular algorithm along with some filtering condition is applied using the transformed grammar. In our case, the transformation and the subsequent application of the tabular algorithm result in a new form of tabular LR parsing. Our method is more efficient than Tomita&apos;s algorithm in two respects. First, reduce operations are implemented in an efficient way, by splitting them into several, more primitive, operations (a similar idea has been proposed by Kipps (1991) for Tomita&apos;s algorithm). Second, several paths in the computation that must be simulated separately by Tomita&apos;s algorithm are collapsed into a single computation path, using state minimization techniques. Experiments on practical grammars have indicated that there is a significant gain in efficiency, with regard to both space and time requirements. Our grammar transformation produces a so called cover for the input grammar, which together with the filtering condition fully captures the specification of the method, abstracting away from algorithmic details such as data structures and control f</context>
<context position="9786" citStr="Kipps (1991)" startWordPosition="1822" endWordPosition="1823"> in the previous section are deterministic only for a subset of the CFGs, called the LR(0) grammars (Sippu and SoisalonSoininen, 1990), and behave nondeterministically in the general case. When designing tabular methods that simulate nondeterministic computations of ALR, two main difficulties are encountered: • A reduce transition in ALR is an elementary operation that removes from the stack a number of elements bounded by the size of the underlying grammar. Consequently, the time requirement of tabular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definiti</context>
<context position="27051" citStr="Kipps (1991)" startWordPosition="5072" endWordPosition="5073"> with other tabular parsing techniques, such as Earley&apos;s algorithm (Earley, 1970) and tabular left-corner parsing (Nederhof, 1993), based on implementationindependent criteria. This is in contrast to experiments reported before (e.g. by Shann (1991)), which treated tabular 1,it parsing differently from the other techniques. The reduced time and space complexities reported in the previous section pertain to the tabular realisation of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have however been left out of consideration, and so were techniques for unification grammars and techniques incorporating finite-state processes.3 Theoretical considerations (Leermakers, 1989; Schabes, 1991; Nederhof, 1994b) have suggested that for natural language parsing, LR-based techniques may not necessarily be superior to other parsing techniques, although convincin</context>
</contexts>
<marker>Kipps, 1991</marker>
<rawString>Kipps, J.R. 1991. GLR parsing in time 0(n3). In Tomita (1991), chapter 4, pages 43-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lang</author>
</authors>
<title>Deterministic techniques for efficient non-deterministic parsers.</title>
<date>1974</date>
<booktitle>In Automata, Languages and Programming, 2nd Colloquium, LNCS 14,</booktitle>
<pages>255--269</pages>
<publisher>Saarbriicken. SpringerVerlag.</publisher>
<contexts>
<context position="1844" citStr="Lang (1974)" startWordPosition="275" endWordPosition="276"> Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given by Lang (1974) and Billot and Lang (1989): the construction of pushdown automata from grammars and the simulation of these automata by means of tabulation yield different tabular algorithms for different such constructions. Another example, on which our presentation is based, was first suggested by Leermakers (1989): a grammar is first transformed and then a standard tabular algorithm along with some filtering condition is applied using the transformed grammar. In our case, the transformation and the subsequent application of the tabular algorithm result in a new form of tabular LR parsing. Our method is mo</context>
<context position="10236" citStr="Lang (1974)" startWordPosition="1904" endWordPosition="1905">ng grammar. Consequently, the time requirement of tabular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definition introduces this new kind of automaton. Definition 2 Aia = (E, QLR, TLR, qm, qfin), where QLR = RLR U /1,R) Qin = {St • S4}, qfin = goto(qm,S) and TiAt contains: (i) q2+ q q&apos; , for every a E Z and q, q&apos; E RLR such that q&apos; = goto(q, a); (ii) q q (A .), for every q E RLR and (A a.) E closure(q); (iii) q (A —4 aX • 1(3) I-14 (A —4 a • X)3), for every q E 7ZLn and (A —4- aX • )3) E q; (iv) q (A --4 • a) q q&apos;, for every q,q&apos; E RLR and (A —4 a) E Pt </context>
<context position="21592" citStr="Lang (1974)" startWordPosition="4136" endWordPosition="4137">#) (X13) E T2LR. In a straightforward realisation of the algorithm, this step can be applied 0(1 T2LR I • I V 13) times (once for each i, k, j and each transition), each step taking a constant amount of time. We conclude that the time complexity of our algorithm is 0(1 T2LB, I • I V 13). As far as space requirements are concerned, each set or Ui contains at most 10 I , 2LR elements. (One may assume an auxiliary table storing each IA.) This results in a space complexity 0(1 Q2LR I I v 12). The entries in the table represent single stack elements, as opposed to pairs of stack elements following Lang (1974) and Leermakers (1989). This has been investigated before by Nederhof (1994a, p. 25) and Villemonte de la Clergerie (1993, p. 155). 7 Empirical results We have performed some experiments with Algorithm 1 applied to A2LR and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) an</context>
</contexts>
<marker>Lang, 1974</marker>
<rawString>Lang, B. 1974. Deterministic techniques for efficient non-deterministic parsers. In Automata, Languages and Programming, 2nd Colloquium, LNCS 14, pages 255-269, Saarbriicken. SpringerVerlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>How to cover a grammar.</title>
<date>1989</date>
<booktitle>In 27th Annual Meeting of the ACL,</booktitle>
<pages>135--142</pages>
<contexts>
<context position="2147" citStr="Leermakers (1989)" startWordPosition="322" endWordPosition="323">ley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given by Lang (1974) and Billot and Lang (1989): the construction of pushdown automata from grammars and the simulation of these automata by means of tabulation yield different tabular algorithms for different such constructions. Another example, on which our presentation is based, was first suggested by Leermakers (1989): a grammar is first transformed and then a standard tabular algorithm along with some filtering condition is applied using the transformed grammar. In our case, the transformation and the subsequent application of the tabular algorithm result in a new form of tabular LR parsing. Our method is more efficient than Tomita&apos;s algorithm in two respects. First, reduce operations are implemented in an efficient way, by splitting them into several, more primitive, operations (a similar idea has been proposed by Kipps (1991) for Tomita&apos;s algorithm). Second, several paths in the computation that must be</context>
<context position="14082" citStr="Leermakers (1989)" startWordPosition="2661" endWordPosition="2662">treat both rules simultaneously, until the parts of the right-hand sides are reached where the two rules differ. (See Leermakers (1992a) for a similar sharing of computation for common suffixes.) An interesting fact is that the automaton A2LR is very similar to the automaton ALR constructed for a grammar transformed by the transformation given by Nederhof and Satta (1994).2 5 The algorithm This section presents a tabular LR parser, which is the main result of this paper. The parser is derived from the 2LR automata introduced in the previous section. Following the general approach presented by Leermakers (1989), we simulate computations of 2For the earliest mention of this transformation, we have encountered pointers to Schauerte (1973). Regrettably, we have as yet not been able to get hold of a copy of this paper. these devices using a tabular method, a grammar transformation and a filtering function. We make use of a tabular parsing algorithm which is basically an asynchronous version of the CYK algorithm, as presented by Harrison (1978), extended to productions of the forms A —4 B and A —4 c and with a left-to-right filtering condition. The algorithm uses a parse table consisting in a 0-indexed s</context>
<context position="21614" citStr="Leermakers (1989)" startWordPosition="4139" endWordPosition="4140"> In a straightforward realisation of the algorithm, this step can be applied 0(1 T2LR I • I V 13) times (once for each i, k, j and each transition), each step taking a constant amount of time. We conclude that the time complexity of our algorithm is 0(1 T2LB, I • I V 13). As far as space requirements are concerned, each set or Ui contains at most 10 I , 2LR elements. (One may assume an auxiliary table storing each IA.) This results in a space complexity 0(1 Q2LR I I v 12). The entries in the table represent single stack elements, as opposed to pairs of stack elements following Lang (1974) and Leermakers (1989). This has been investigated before by Nederhof (1994a, p. 25) and Villemonte de la Clergerie (1993, p. 155). 7 Empirical results We have performed some experiments with Algorithm 1 applied to A2LR and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (</context>
<context position="27468" citStr="Leermakers, 1989" startWordPosition="5135" endWordPosition="5136"> tabular realisation of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have however been left out of consideration, and so were techniques for unification grammars and techniques incorporating finite-state processes.3 Theoretical considerations (Leermakers, 1989; Schabes, 1991; Nederhof, 1994b) have suggested that for natural language parsing, LR-based techniques may not necessarily be superior to other parsing techniques, although convincing empirical data to this effect has never been shown. This issue is difficult to resolve because so much of the relative efficiency of the different parsing techniques depends on particular grammars and particular input, as well as on particular implementations of the techniques. We hope the conceptual framework presented in this paper may at least partly alleviate this problem. Acknowledgements The first author i</context>
</contexts>
<marker>Leermakers, 1989</marker>
<rawString>Leermakers, R. 1989. How to cover a grammar. In 27th Annual Meeting of the ACL, pages 135-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>A recursive ascent Earley parser.</title>
<date>1992</date>
<journal>Information Processing Letters,</journal>
<pages>41--2</pages>
<contexts>
<context position="10359" citStr="Leermakers (1992" startWordPosition="1922" endWordPosition="1923">ointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definition introduces this new kind of automaton. Definition 2 Aia = (E, QLR, TLR, qm, qfin), where QLR = RLR U /1,R) Qin = {St • S4}, qfin = goto(qm,S) and TiAt contains: (i) q2+ q q&apos; , for every a E Z and q, q&apos; E RLR such that q&apos; = goto(q, a); (ii) q q (A .), for every q E RLR and (A a.) E closure(q); (iii) q (A —4 aX • 1(3) I-14 (A —4 a • X)3), for every q E 7ZLn and (A —4- aX • )3) E q; (iv) q (A --4 • a) q q&apos;, for every q,q&apos; E RLR and (A —4 a) E Pt such that q&apos; = goto(q, A). Transitions in (i) above are again called shift, transitions in (ii) are called initiate, those </context>
<context position="13599" citStr="Leermakers (1992" startWordPosition="2584" endWordPosition="2585">q) (a, q1), for every a E 0 and (X, q), (a, q&apos;) E Q2LR such that g&apos; = goto&apos;(q, a); (ii) (X, q) 4 (X, q) (c), for every (X, q) E Q2LR such that c E closure&apos; (q); (iii) (X, q) (/3) 4 (X/3), for every (X, q) E Q2LR and # E q; (iv) (X, q) (a) 4 (X ,q) (A, q&apos;), for every (X, q), (A,g1) E Q2LR and (A a) E Pt such that q&apos; = goto1(q, A). Note that in the case of a reduce/reduce conflict with two grammar rules sharing some suffix in the right-hand side, the gathering steps of A2LR will treat both rules simultaneously, until the parts of the right-hand sides are reached where the two rules differ. (See Leermakers (1992a) for a similar sharing of computation for common suffixes.) An interesting fact is that the automaton A2LR is very similar to the automaton ALR constructed for a grammar transformed by the transformation given by Nederhof and Satta (1994).2 5 The algorithm This section presents a tabular LR parser, which is the main result of this paper. The parser is derived from the 2LR automata introduced in the previous section. Following the general approach presented by Leermakers (1989), we simulate computations of 2For the earliest mention of this transformation, we have encountered pointers to Schau</context>
</contexts>
<marker>Leermakers, 1992</marker>
<rawString>Leermakers, R. 1992a. A recursive ascent Earley parser. Information Processing Letters, 41(2):87-91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Leermakers</author>
</authors>
<title>Recursive ascent parsing: from Earley to Marcus. Theoretical Computer Science,</title>
<date>1992</date>
<pages>104--299</pages>
<contexts>
<context position="10359" citStr="Leermakers (1992" startWordPosition="1922" endWordPosition="1923">ointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definition introduces this new kind of automaton. Definition 2 Aia = (E, QLR, TLR, qm, qfin), where QLR = RLR U /1,R) Qin = {St • S4}, qfin = goto(qm,S) and TiAt contains: (i) q2+ q q&apos; , for every a E Z and q, q&apos; E RLR such that q&apos; = goto(q, a); (ii) q q (A .), for every q E RLR and (A a.) E closure(q); (iii) q (A —4 aX • 1(3) I-14 (A —4 a • X)3), for every q E 7ZLn and (A —4- aX • )3) E q; (iv) q (A --4 • a) q q&apos;, for every q,q&apos; E RLR and (A —4 a) E Pt such that q&apos; = goto(q, A). Transitions in (i) above are again called shift, transitions in (ii) are called initiate, those </context>
<context position="13599" citStr="Leermakers (1992" startWordPosition="2584" endWordPosition="2585">q) (a, q1), for every a E 0 and (X, q), (a, q&apos;) E Q2LR such that g&apos; = goto&apos;(q, a); (ii) (X, q) 4 (X, q) (c), for every (X, q) E Q2LR such that c E closure&apos; (q); (iii) (X, q) (/3) 4 (X/3), for every (X, q) E Q2LR and # E q; (iv) (X, q) (a) 4 (X ,q) (A, q&apos;), for every (X, q), (A,g1) E Q2LR and (A a) E Pt such that q&apos; = goto1(q, A). Note that in the case of a reduce/reduce conflict with two grammar rules sharing some suffix in the right-hand side, the gathering steps of A2LR will treat both rules simultaneously, until the parts of the right-hand sides are reached where the two rules differ. (See Leermakers (1992a) for a similar sharing of computation for common suffixes.) An interesting fact is that the automaton A2LR is very similar to the automaton ALR constructed for a grammar transformed by the transformation given by Nederhof and Satta (1994).2 5 The algorithm This section presents a tabular LR parser, which is the main result of this paper. The parser is derived from the 2LR automata introduced in the previous section. Following the general approach presented by Leermakers (1989), we simulate computations of 2For the earliest mention of this transformation, we have encountered pointers to Schau</context>
</contexts>
<marker>Leermakers, 1992</marker>
<rawString>Leermakers, R. 1992b. Recursive ascent parsing: from Earley to Marcus. Theoretical Computer Science, 104:299-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
</authors>
<title>Generalized left-corner parsing.</title>
<date>1993</date>
<booktitle>In Sixth Conference of the European Chapter of the ACL,</booktitle>
<pages>305--314</pages>
<contexts>
<context position="19181" citStr="Nederhof (1993)" startWordPosition="3660" endWordPosition="3661">.e. the number of parses found by the algorithm for any input, is reduced to exactly that of the source grammar. A practical implementation would construct the parse trees on-the-fly, attaching them to the table entries, allowing packing and sharing of subtrees (cf. the literature on parse forests (Tomita, 1986; Billot and Lang, 1989)). Our algorithm actually only needs one (packed) subtree for several (X, q) E Ui,k with fixed X,i,k but different q. The resulting parse forests would then be optimally compact, contrary to some other LR-based tabular algorithms, as pointed out by Rekers (1992), Nederhof (1993) and Nederhof (1994b). 6 Analysis of the algorithm In this section, we investigate how the steps performed by Algorithm 1 (applied to the 2LR cover) relate to those performed by A2LR, for the same input. We define a subrelation WI- of 1-+ as: (6, uw) (bb&apos; , w) if and only if (6, uw) = (15, zi z2 • • • zmw) (661, z2 • zmw) . . . (66m w) =*- (6.5&apos;, w), for some m &gt; 1, where 16k I &gt; 0 for all k, 1 &lt; k &lt; m. Informally, we have (6, uw) (66&apos;, w) if configuration (66&apos;, w) can be reached from (6, uw) without the bottom-most part 6 of the intermediate stacks being affected by any of the transitions; fu</context>
<context position="26569" citStr="Nederhof, 1993" startWordPosition="4997" endWordPosition="4998">s over the one by Tomita: • It is conceptually simpler, because we make use of simple concepts such as a grammar transformation and the well-understood CYK algorithm, instead of a complicated mechanism working on graph-structured stacks. • Our algorithm requires fewer Lit states. This leads to faster parser generation, to smaller parsers, and to reduced time and space complexity of parsing itself. The conceptual simplicity of our formulation of tabular LR parsing allows comparison with other tabular parsing techniques, such as Earley&apos;s algorithm (Earley, 1970) and tabular left-corner parsing (Nederhof, 1993), based on implementationindependent criteria. This is in contrast to experiments reported before (e.g. by Shann (1991)), which treated tabular 1,it parsing differently from the other techniques. The reduced time and space complexities reported in the previous section pertain to the tabular realisation of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR p</context>
</contexts>
<marker>Nederhof, 1993</marker>
<rawString>Nederhof, M.J. 1993. Generalized left-corner parsing. In Sixth Conference of the European Chapter of the ACL, pages 305-314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
</authors>
<title>Linguistic Parsing and Program Transformations.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Nijmegen.</institution>
<contexts>
<context position="1230" citStr="Nederhof (1994" startWordPosition="176" endWordPosition="177"> Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) is very attractive from the perspective of natural language processing applications. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given </context>
<context position="10290" citStr="Nederhof (1994" startWordPosition="1912" endWordPosition="1913">abular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definition introduces this new kind of automaton. Definition 2 Aia = (E, QLR, TLR, qm, qfin), where QLR = RLR U /1,R) Qin = {St • S4}, qfin = goto(qm,S) and TiAt contains: (i) q2+ q q&apos; , for every a E Z and q, q&apos; E RLR such that q&apos; = goto(q, a); (ii) q q (A .), for every q E RLR and (A a.) E closure(q); (iii) q (A —4 aX • 1(3) I-14 (A —4 a • X)3), for every q E 7ZLn and (A —4- aX • )3) E q; (iv) q (A --4 • a) q q&apos;, for every q,q&apos; E RLR and (A —4 a) E Pt such that q&apos; = goto(q, A). Transitions in (i) above ar</context>
<context position="19200" citStr="Nederhof (1994" startWordPosition="3663" endWordPosition="3664">rses found by the algorithm for any input, is reduced to exactly that of the source grammar. A practical implementation would construct the parse trees on-the-fly, attaching them to the table entries, allowing packing and sharing of subtrees (cf. the literature on parse forests (Tomita, 1986; Billot and Lang, 1989)). Our algorithm actually only needs one (packed) subtree for several (X, q) E Ui,k with fixed X,i,k but different q. The resulting parse forests would then be optimally compact, contrary to some other LR-based tabular algorithms, as pointed out by Rekers (1992), Nederhof (1993) and Nederhof (1994b). 6 Analysis of the algorithm In this section, we investigate how the steps performed by Algorithm 1 (applied to the 2LR cover) relate to those performed by A2LR, for the same input. We define a subrelation WI- of 1-+ as: (6, uw) (bb&apos; , w) if and only if (6, uw) = (15, zi z2 • • • zmw) (661, z2 • zmw) . . . (66m w) =*- (6.5&apos;, w), for some m &gt; 1, where 16k I &gt; 0 for all k, 1 &lt; k &lt; m. Informally, we have (6, uw) (66&apos;, w) if configuration (66&apos;, w) can be reached from (6, uw) without the bottom-most part 6 of the intermediate stacks being affected by any of the transitions; furthermore, at least</context>
<context position="21667" citStr="Nederhof (1994" startWordPosition="4147" endWordPosition="4148"> step can be applied 0(1 T2LR I • I V 13) times (once for each i, k, j and each transition), each step taking a constant amount of time. We conclude that the time complexity of our algorithm is 0(1 T2LB, I • I V 13). As far as space requirements are concerned, each set or Ui contains at most 10 I , 2LR elements. (One may assume an auxiliary table storing each IA.) This results in a space complexity 0(1 Q2LR I I v 12). The entries in the table represent single stack elements, as opposed to pairs of stack elements following Lang (1974) and Leermakers (1989). This has been investigated before by Nederhof (1994a, p. 25) and Villemonte de la Clergerie (1993, p. 155). 7 Empirical results We have performed some experiments with Algorithm 1 applied to A2LR and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (Schoorl and Belder, 1990), respectively. These gramma</context>
<context position="27499" citStr="Nederhof, 1994" startWordPosition="5139" endWordPosition="5140">ng techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have however been left out of consideration, and so were techniques for unification grammars and techniques incorporating finite-state processes.3 Theoretical considerations (Leermakers, 1989; Schabes, 1991; Nederhof, 1994b) have suggested that for natural language parsing, LR-based techniques may not necessarily be superior to other parsing techniques, although convincing empirical data to this effect has never been shown. This issue is difficult to resolve because so much of the relative efficiency of the different parsing techniques depends on particular grammars and particular input, as well as on particular implementations of the techniques. We hope the conceptual framework presented in this paper may at least partly alleviate this problem. Acknowledgements The first author is supported by the Dutch Organi</context>
</contexts>
<marker>Nederhof, 1994</marker>
<rawString>Nederhof, M.J. 1994a. Linguistic Parsing and Program Transformations. Ph.D. thesis, University of Nijmegen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
</authors>
<title>An optimal tabular parsing algorithm.</title>
<date>1994</date>
<booktitle>In 32nd Annual Meeting of the ACL,</booktitle>
<pages>117--124</pages>
<contexts>
<context position="1230" citStr="Nederhof (1994" startWordPosition="176" endWordPosition="177"> Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) is very attractive from the perspective of natural language processing applications. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. One example is given </context>
<context position="10290" citStr="Nederhof (1994" startWordPosition="1912" endWordPosition="1913">abular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definition introduces this new kind of automaton. Definition 2 Aia = (E, QLR, TLR, qm, qfin), where QLR = RLR U /1,R) Qin = {St • S4}, qfin = goto(qm,S) and TiAt contains: (i) q2+ q q&apos; , for every a E Z and q, q&apos; E RLR such that q&apos; = goto(q, a); (ii) q q (A .), for every q E RLR and (A a.) E closure(q); (iii) q (A —4 aX • 1(3) I-14 (A —4 a • X)3), for every q E 7ZLn and (A —4- aX • )3) E q; (iv) q (A --4 • a) q q&apos;, for every q,q&apos; E RLR and (A —4 a) E Pt such that q&apos; = goto(q, A). Transitions in (i) above ar</context>
<context position="19200" citStr="Nederhof (1994" startWordPosition="3663" endWordPosition="3664">rses found by the algorithm for any input, is reduced to exactly that of the source grammar. A practical implementation would construct the parse trees on-the-fly, attaching them to the table entries, allowing packing and sharing of subtrees (cf. the literature on parse forests (Tomita, 1986; Billot and Lang, 1989)). Our algorithm actually only needs one (packed) subtree for several (X, q) E Ui,k with fixed X,i,k but different q. The resulting parse forests would then be optimally compact, contrary to some other LR-based tabular algorithms, as pointed out by Rekers (1992), Nederhof (1993) and Nederhof (1994b). 6 Analysis of the algorithm In this section, we investigate how the steps performed by Algorithm 1 (applied to the 2LR cover) relate to those performed by A2LR, for the same input. We define a subrelation WI- of 1-+ as: (6, uw) (bb&apos; , w) if and only if (6, uw) = (15, zi z2 • • • zmw) (661, z2 • zmw) . . . (66m w) =*- (6.5&apos;, w), for some m &gt; 1, where 16k I &gt; 0 for all k, 1 &lt; k &lt; m. Informally, we have (6, uw) (66&apos;, w) if configuration (66&apos;, w) can be reached from (6, uw) without the bottom-most part 6 of the intermediate stacks being affected by any of the transitions; furthermore, at least</context>
<context position="21667" citStr="Nederhof (1994" startWordPosition="4147" endWordPosition="4148"> step can be applied 0(1 T2LR I • I V 13) times (once for each i, k, j and each transition), each step taking a constant amount of time. We conclude that the time complexity of our algorithm is 0(1 T2LB, I • I V 13). As far as space requirements are concerned, each set or Ui contains at most 10 I , 2LR elements. (One may assume an auxiliary table storing each IA.) This results in a space complexity 0(1 Q2LR I I v 12). The entries in the table represent single stack elements, as opposed to pairs of stack elements following Lang (1974) and Leermakers (1989). This has been investigated before by Nederhof (1994a, p. 25) and Villemonte de la Clergerie (1993, p. 155). 7 Empirical results We have performed some experiments with Algorithm 1 applied to A2LR and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (Schoorl and Belder, 1990), respectively. These gramma</context>
<context position="27499" citStr="Nederhof, 1994" startWordPosition="5139" endWordPosition="5140">ng techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have however been left out of consideration, and so were techniques for unification grammars and techniques incorporating finite-state processes.3 Theoretical considerations (Leermakers, 1989; Schabes, 1991; Nederhof, 1994b) have suggested that for natural language parsing, LR-based techniques may not necessarily be superior to other parsing techniques, although convincing empirical data to this effect has never been shown. This issue is difficult to resolve because so much of the relative efficiency of the different parsing techniques depends on particular grammars and particular input, as well as on particular implementations of the techniques. We hope the conceptual framework presented in this paper may at least partly alleviate this problem. Acknowledgements The first author is supported by the Dutch Organi</context>
</contexts>
<marker>Nederhof, 1994</marker>
<rawString>Nederhof, M.J. 1994b. An optimal tabular parsing algorithm. In 32nd Annual Meeting of the ACL, pages 117-124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
<author>K Koster</author>
</authors>
<title>A customized grammar workbench. In</title>
<date>1992</date>
<booktitle>English Language Corpora: Design, Analysis and Exploitation, Papers from the thirteenth International Conference on English Language Research on Computerized Corpora,</booktitle>
<pages>163--179</pages>
<editor>J. Aarts, P. de Haan, and N. Oostdijk, editors,</editor>
<location>Nijmegen. Rodopi.</location>
<contexts>
<context position="22659" citStr="Nederhof and Koster, 1992" startWordPosition="4305" endWordPosition="4308">L 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (Schoorl and Belder, 1990), respectively. These grammars were stripped of their arguments in order to convert them into context-free grammars. The fourth grammar, referred to as the Alvey grammar (Carroll, 1993), generates a fragment of English and was automatically generated from a unificationbased grammar. The test sentences have been obtained by automatic generation from the grammars, using the Grammar Workbench (Nederhof and Koster, 1992), which uses a random generator to select rules; therefore these sentences do not necessarily represent input typical of the applications for which the grammars were written. Table 1 summarizes the test material. Our implementation is merely a prototype, which means that absolute duration of the parsing process G = (E , N, P, S) IG1 I NI IPI 111&apos;1 ALGOL 68 783 167 330 13.7 CORRie 1141 203 424 12.3 Deltra 1929 281 703 10.8 Alvey 5072 265 1484 10.7 Table 1: The test material: the four grammars and some of their dimensions, and the average length of the test sentences (20 sentences of various len</context>
</contexts>
<marker>Nederhof, Koster, 1992</marker>
<rawString>Nederhof, M.J. and K. Koster. 1992. A customized grammar workbench. In J. Aarts, P. de Haan, and N. Oostdijk, editors, English Language Corpora: Design, Analysis and Exploitation, Papers from the thirteenth International Conference on English Language Research on Computerized Corpora, pages 163-179, Nijmegen. Rodopi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
<author>J J Sarbo</author>
</authors>
<title>Increasing the applicability of LR parsing.</title>
<date>1993</date>
<booktitle>In Third International Workshop on Parsing Technologies,</booktitle>
<pages>187--201</pages>
<contexts>
<context position="11813" citStr="Nederhof and Sarbo (1993)" startWordPosition="2222" endWordPosition="2225"> new stack symbols (A —+ a • E 1.1,R that are distinguishable from possible stack symbols {A a • PI E RLRWe now turn to the second above-mentioned problem, regarding the size of set RLR. The problem is in part solved here as follows. The number of states in 12,LR is considerably reduced by identifying two states if they become identical after items A —4 a • )3 from /La have been simplified to only the suffix of the right-hand side This is reminiscent of techniques of state minimization for finite automata (Booth, 1967), as they have been applied before to LR parsing, e.g., by Pager (1970) and Nederhof and Sarbo (1993). Let GI be the augmented grammar associated with a CFG G, and let /21,R = {/3 I (A afi) E Pl. We define variants of the closure and goto functions from the previous section as follows. For any set q C /2LR, closure1(q) is the smallest collection of sets such that (i) q c closure&apos;(q); and (ii) (AP) E closure&apos; (q) and (A 7) E PI together imply (7) E closure&apos; (q). Also, we define goto1(q, X) = {fl I (XP) E closure&apos; (q)}. We now construct a finite set R2LR as the smallest set satisfying the conditions: 241 (i) {S•i} E 7Z2Ln,; and (ii) for every q E ??-2LR and X E V, we have goto1(q, X) E Te2LR) p</context>
</contexts>
<marker>Nederhof, Sarbo, 1993</marker>
<rawString>Nederhof, M.J. and J.J. Sarbo. 1993. Increasing the applicability of LR parsing. In Third International Workshop on Parsing Technologies, pages 187-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Nederhof</author>
<author>G Satta</author>
</authors>
<title>An extended theory of head-driven parsing.</title>
<date>1994</date>
<booktitle>In 32nd Annual Meeting of the ACL,</booktitle>
<pages>210--217</pages>
<contexts>
<context position="13839" citStr="Nederhof and Satta (1994)" startWordPosition="2620" endWordPosition="2623"> q) (a) 4 (X ,q) (A, q&apos;), for every (X, q), (A,g1) E Q2LR and (A a) E Pt such that q&apos; = goto1(q, A). Note that in the case of a reduce/reduce conflict with two grammar rules sharing some suffix in the right-hand side, the gathering steps of A2LR will treat both rules simultaneously, until the parts of the right-hand sides are reached where the two rules differ. (See Leermakers (1992a) for a similar sharing of computation for common suffixes.) An interesting fact is that the automaton A2LR is very similar to the automaton ALR constructed for a grammar transformed by the transformation given by Nederhof and Satta (1994).2 5 The algorithm This section presents a tabular LR parser, which is the main result of this paper. The parser is derived from the 2LR automata introduced in the previous section. Following the general approach presented by Leermakers (1989), we simulate computations of 2For the earliest mention of this transformation, we have encountered pointers to Schauerte (1973). Regrettably, we have as yet not been able to get hold of a copy of this paper. these devices using a tabular method, a grammar transformation and a filtering function. We make use of a tabular parsing algorithm which is basical</context>
</contexts>
<marker>Nederhof, Satta, 1994</marker>
<rawString>Nederhof, M.J. and G. Satta. 1994. An extended theory of head-driven parsing. In 32nd Annual Meeting of the ACL, pages 210-217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pager</author>
</authors>
<title>A solution to an open problem by Knuth. Information and Control,</title>
<date>1970</date>
<pages>17--462</pages>
<contexts>
<context position="11783" citStr="Pager (1970)" startWordPosition="2219" endWordPosition="2220">steps involve the new stack symbols (A —+ a • E 1.1,R that are distinguishable from possible stack symbols {A a • PI E RLRWe now turn to the second above-mentioned problem, regarding the size of set RLR. The problem is in part solved here as follows. The number of states in 12,LR is considerably reduced by identifying two states if they become identical after items A —4 a • )3 from /La have been simplified to only the suffix of the right-hand side This is reminiscent of techniques of state minimization for finite automata (Booth, 1967), as they have been applied before to LR parsing, e.g., by Pager (1970) and Nederhof and Sarbo (1993). Let GI be the augmented grammar associated with a CFG G, and let /21,R = {/3 I (A afi) E Pl. We define variants of the closure and goto functions from the previous section as follows. For any set q C /2LR, closure1(q) is the smallest collection of sets such that (i) q c closure&apos;(q); and (ii) (AP) E closure&apos; (q) and (A 7) E PI together imply (7) E closure&apos; (q). Also, we define goto1(q, X) = {fl I (XP) E closure&apos; (q)}. We now construct a finite set R2LR as the smallest set satisfying the conditions: 241 (i) {S•i} E 7Z2Ln,; and (ii) for every q E ??-2LR and X E V, </context>
</contexts>
<marker>Pager, 1970</marker>
<rawString>Pager, D. 1970. A solution to an open problem by Knuth. Information and Control, 17:462-473.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rekers</author>
</authors>
<title>Parser Generation for Interactive Environments.</title>
<date>1992</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="19164" citStr="Rekers (1992)" startWordPosition="3658" endWordPosition="3659">of ambiguity, i.e. the number of parses found by the algorithm for any input, is reduced to exactly that of the source grammar. A practical implementation would construct the parse trees on-the-fly, attaching them to the table entries, allowing packing and sharing of subtrees (cf. the literature on parse forests (Tomita, 1986; Billot and Lang, 1989)). Our algorithm actually only needs one (packed) subtree for several (X, q) E Ui,k with fixed X,i,k but different q. The resulting parse forests would then be optimally compact, contrary to some other LR-based tabular algorithms, as pointed out by Rekers (1992), Nederhof (1993) and Nederhof (1994b). 6 Analysis of the algorithm In this section, we investigate how the steps performed by Algorithm 1 (applied to the 2LR cover) relate to those performed by A2LR, for the same input. We define a subrelation WI- of 1-+ as: (6, uw) (bb&apos; , w) if and only if (6, uw) = (15, zi z2 • • • zmw) (661, z2 • zmw) . . . (66m w) =*- (6.5&apos;, w), for some m &gt; 1, where 16k I &gt; 0 for all k, 1 &lt; k &lt; m. Informally, we have (6, uw) (66&apos;, w) if configuration (66&apos;, w) can be reached from (6, uw) without the bottom-most part 6 of the intermediate stacks being affected by any of th</context>
</contexts>
<marker>Rekers, 1992</marker>
<rawString>Rekers, J. 1992. Parser Generation for Interactive Environments. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
</authors>
<title>Polynomial time and space shiftreduce parsing of arbitrary context-free grammars.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the ACL,</booktitle>
<pages>106--113</pages>
<contexts>
<context position="27483" citStr="Schabes, 1991" startWordPosition="5137" endWordPosition="5138">on of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have however been left out of consideration, and so were techniques for unification grammars and techniques incorporating finite-state processes.3 Theoretical considerations (Leermakers, 1989; Schabes, 1991; Nederhof, 1994b) have suggested that for natural language parsing, LR-based techniques may not necessarily be superior to other parsing techniques, although convincing empirical data to this effect has never been shown. This issue is difficult to resolve because so much of the relative efficiency of the different parsing techniques depends on particular grammars and particular input, as well as on particular implementations of the techniques. We hope the conceptual framework presented in this paper may at least partly alleviate this problem. Acknowledgements The first author is supported by </context>
</contexts>
<marker>Schabes, 1991</marker>
<rawString>Schabes, Y. 1991. Polynomial time and space shiftreduce parsing of arbitrary context-free grammars. In 29th Annual Meeting of the ACL, pages 106-113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>It Schauerte</author>
</authors>
<title>Transformationen von LR(k)-grammatiken.</title>
<date>1973</date>
<journal>Diplomarbeit, Universitat GOttingen, Abteilung Informatik.</journal>
<contexts>
<context position="14210" citStr="Schauerte (1973)" startWordPosition="2679" endWordPosition="2680">(1992a) for a similar sharing of computation for common suffixes.) An interesting fact is that the automaton A2LR is very similar to the automaton ALR constructed for a grammar transformed by the transformation given by Nederhof and Satta (1994).2 5 The algorithm This section presents a tabular LR parser, which is the main result of this paper. The parser is derived from the 2LR automata introduced in the previous section. Following the general approach presented by Leermakers (1989), we simulate computations of 2For the earliest mention of this transformation, we have encountered pointers to Schauerte (1973). Regrettably, we have as yet not been able to get hold of a copy of this paper. these devices using a tabular method, a grammar transformation and a filtering function. We make use of a tabular parsing algorithm which is basically an asynchronous version of the CYK algorithm, as presented by Harrison (1978), extended to productions of the forms A —4 B and A —4 c and with a left-to-right filtering condition. The algorithm uses a parse table consisting in a 0-indexed square array U. The indices represent positions in the input string. We define Ili to be Uk&lt;i Uk,i, Computation of the entries of</context>
</contexts>
<marker>Schauerte, 1973</marker>
<rawString>Schauerte, It. 1973. Transformationen von LR(k)-grammatiken. Diplomarbeit, Universitat GOttingen, Abteilung Informatik.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Schoorl</author>
<author>S Belder</author>
</authors>
<title>Computational linguistics at Delft: A status report.</title>
<date>1990</date>
<tech>Report WTM/TT 90-09,</tech>
<institution>Delft University of Technology, Applied Linguistics Unit.</institution>
<contexts>
<context position="22239" citStr="Schoorl and Belder, 1990" startWordPosition="4242" endWordPosition="4245">. This has been investigated before by Nederhof (1994a, p. 25) and Villemonte de la Clergerie (1993, p. 155). 7 Empirical results We have performed some experiments with Algorithm 1 applied to A2LR and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (Schoorl and Belder, 1990), respectively. These grammars were stripped of their arguments in order to convert them into context-free grammars. The fourth grammar, referred to as the Alvey grammar (Carroll, 1993), generates a fragment of English and was automatically generated from a unificationbased grammar. The test sentences have been obtained by automatic generation from the grammars, using the Grammar Workbench (Nederhof and Koster, 1992), which uses a random generator to select rules; therefore these sentences do not necessarily represent input typical of the applications for which the grammars were written. Table</context>
</contexts>
<marker>Schoorl, Belder, 1990</marker>
<rawString>Schoorl, J.J. and S. Belder. 1990. Computational linguistics at Delft: A status report. Report WTM/TT 90-09, Delft University of Technology, Applied Linguistics Unit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Shann</author>
</authors>
<title>Experiments with GLR and chart parsing.</title>
<date>1991</date>
<booktitle>In Tomita</booktitle>
<pages>17--34</pages>
<note>chapter 2,</note>
<contexts>
<context position="26688" citStr="Shann (1991)" startWordPosition="5015" endWordPosition="5016">ation and the well-understood CYK algorithm, instead of a complicated mechanism working on graph-structured stacks. • Our algorithm requires fewer Lit states. This leads to faster parser generation, to smaller parsers, and to reduced time and space complexity of parsing itself. The conceptual simplicity of our formulation of tabular LR parsing allows comparison with other tabular parsing techniques, such as Earley&apos;s algorithm (Earley, 1970) and tabular left-corner parsing (Nederhof, 1993), based on implementationindependent criteria. This is in contrast to experiments reported before (e.g. by Shann (1991)), which treated tabular 1,it parsing differently from the other techniques. The reduced time and space complexities reported in the previous section pertain to the tabular realisation of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have howeve</context>
</contexts>
<marker>Shann, 1991</marker>
<rawString>Shann, P. 1991. Experiments with GLR and chart parsing. In Tomita (1991), chapter 2, pages 17-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B A Sheil</author>
</authors>
<title>Observations on context-free parsing. Statistical Methods in Linguistics,</title>
<date>1976</date>
<pages>71--109</pages>
<contexts>
<context position="9769" citStr="Sheil (1976)" startWordPosition="1819" endWordPosition="1820">omata ALR defined in the previous section are deterministic only for a subset of the CFGs, called the LR(0) grammars (Sippu and SoisalonSoininen, 1990), and behave nondeterministically in the general case. When designing tabular methods that simulate nondeterministic computations of ALR, two main difficulties are encountered: • A reduce transition in ALR is an elementary operation that removes from the stack a number of elements bounded by the size of the underlying grammar. Consequently, the time requirement of tabular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The f</context>
</contexts>
<marker>Sheil, 1976</marker>
<rawString>Sheil, B.A. 1976. Observations on context-free parsing. Statistical Methods in Linguistics, pages 71-109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sippu</author>
<author>E Soisalon-Soininen</author>
</authors>
<title>Parsing Theory, Vol. II: LR(k) and LL(k) Parsing.</title>
<date>1990</date>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="816" citStr="Sippu and Soisalon-Soininen, 1990" startWordPosition="115" endWordPosition="118"> Elettronica ed Informatica Universita di Padova via Gradenigo, 6/A 1-35131 Padova Italy sattadei.unipd.it Abstract We give a new treatment of tabular LR parsing, which is an alternative to Tomita&apos;s generalized LR algorithm. The advantage is twofold. Firstly, our treatment is conceptually more attractive because it uses simpler concepts, such as grammar transformations and standard tabulation techniques also know as chart parsing. Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) is very attractive from the perspective of natural language processing applications. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so </context>
</contexts>
<marker>Sippu, Soisalon-Soininen, 1990</marker>
<rawString>Sippu, S. and E. Soisalon-Soininen. 1990. Parsing Theory, Vol. II: LR(k) and LL(k) Parsing. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Tomita</author>
</authors>
<title>Efficient Parsing for Natural Language.</title>
<date>1986</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1155" citStr="Tomita (1986)" startWordPosition="164" endWordPosition="165">sformations and standard tabulation techniques also know as chart parsing. Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) is very attractive from the perspective of natural language processing applications. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often </context>
<context position="18878" citStr="Tomita, 1986" startWordPosition="3610" endWordPosition="3611"> that in the third clause above, one should not consider more than one q for given k in order to prevent spurious ambiguity. (In fact, for fixed X, i, k and for different q such that (X, q) E Uidc, tree((X , q), i, k) yields the exact same set of trees.) With this proviso, the degree of ambiguity, i.e. the number of parses found by the algorithm for any input, is reduced to exactly that of the source grammar. A practical implementation would construct the parse trees on-the-fly, attaching them to the table entries, allowing packing and sharing of subtrees (cf. the literature on parse forests (Tomita, 1986; Billot and Lang, 1989)). Our algorithm actually only needs one (packed) subtree for several (X, q) E Ui,k with fixed X,i,k but different q. The resulting parse forests would then be optimally compact, contrary to some other LR-based tabular algorithms, as pointed out by Rekers (1992), Nederhof (1993) and Nederhof (1994b). 6 Analysis of the algorithm In this section, we investigate how the steps performed by Algorithm 1 (applied to the 2LR cover) relate to those performed by A2LR, for the same input. We define a subrelation WI- of 1-+ as: (6, uw) (bb&apos; , w) if and only if (6, uw) = (15, zi z2 </context>
</contexts>
<marker>Tomita, 1986</marker>
<rawString>Tomita, M. 1986. Efficient Parsing for Natural Language. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<date>1991</date>
<booktitle>Generalized LR Parsing.</booktitle>
<editor>Tomita, M., editor.</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1211" citStr="(1991)" startWordPosition="174" endWordPosition="174">rt parsing. Secondly, the static and dynamic complexity of parsing, both in space and time, is significantly reduced. 1 Introduction The efficiency of LR(k) parsing techniques (Sippu and Soisalon-Soininen, 1990) is very attractive from the perspective of natural language processing applications. This has stimulated the computational linguistics community to develop extensions of these techniques to general context-free grammar parsing. The best-known example is generalized LR parsing, also known as Tomita&apos;s algorithm, described by Tomita (1986) and further investigated by, for example, Tomita (1991) and Nederhof (1994a). Despite appearances, the graph-structured stacks used to describe Tomita&apos;s algorithm differ very little from parse tables, or in other words, generalized LR parsing is one of the so called tabular parsing algorithms, among which also the CYK algorithm (Harrison, 1978) and Earley&apos;s algorithm (Earley, 1970) can be found. (Tabular parsing is also known as chart parsing.) In this paper we investigate the extension of LR parsing to general context-free grammars from a more general viewpoint: tabular algorithms can often be described by the composition of two constructions. On</context>
<context position="2668" citStr="(1991)" startWordPosition="408" endWordPosition="408">example, on which our presentation is based, was first suggested by Leermakers (1989): a grammar is first transformed and then a standard tabular algorithm along with some filtering condition is applied using the transformed grammar. In our case, the transformation and the subsequent application of the tabular algorithm result in a new form of tabular LR parsing. Our method is more efficient than Tomita&apos;s algorithm in two respects. First, reduce operations are implemented in an efficient way, by splitting them into several, more primitive, operations (a similar idea has been proposed by Kipps (1991) for Tomita&apos;s algorithm). Second, several paths in the computation that must be simulated separately by Tomita&apos;s algorithm are collapsed into a single computation path, using state minimization techniques. Experiments on practical grammars have indicated that there is a significant gain in efficiency, with regard to both space and time requirements. Our grammar transformation produces a so called cover for the input grammar, which together with the filtering condition fully captures the specification of the method, abstracting away from algorithmic details such as data structures and control f</context>
<context position="9786" citStr="(1991)" startWordPosition="1823" endWordPosition="1823">e previous section are deterministic only for a subset of the CFGs, called the LR(0) grammars (Sippu and SoisalonSoininen, 1990), and behave nondeterministically in the general case. When designing tabular methods that simulate nondeterministic computations of ALR, two main difficulties are encountered: • A reduce transition in ALR is an elementary operation that removes from the stack a number of elements bounded by the size of the underlying grammar. Consequently, the time requirement of tabular simulation of ALR computations can be onerous, for reasons pointed out by Sheil (1976) and Kipps (1991). • The set &apos;R.LR can be exponential in the size of the grammar (Johnson, 1991). If in such a case the computations of ALR touch upon each state, then time and space requirements of tabular simulation are obviously onerous. The first issue above is solved here by recasting ALR in binary form. This is done by considering each reduce transition as a sequence of &amp;quot;pop&amp;quot; operations which affect at most two stack symbols at a time. (See also Lang (1974), Villemonte de la Clergerie (1993) and Nederhof (1994a), and for LR parsing specifically Kipps (1991) and Leermakers (1992b).) The following definiti</context>
<context position="26688" citStr="(1991)" startWordPosition="5016" endWordPosition="5016">and the well-understood CYK algorithm, instead of a complicated mechanism working on graph-structured stacks. • Our algorithm requires fewer Lit states. This leads to faster parser generation, to smaller parsers, and to reduced time and space complexity of parsing itself. The conceptual simplicity of our formulation of tabular LR parsing allows comparison with other tabular parsing techniques, such as Earley&apos;s algorithm (Earley, 1970) and tabular left-corner parsing (Nederhof, 1993), based on implementationindependent criteria. This is in contrast to experiments reported before (e.g. by Shann (1991)), which treated tabular 1,it parsing differently from the other techniques. The reduced time and space complexities reported in the previous section pertain to the tabular realisation of two parsing techniques, expressed by the automata ALR and A2LR. The tabular realisation of the former automata is very close to a variant of Tomita&apos;s algorithm by Kipps (1991). The objective of our experiments was to show that the automata A2LR provide a better basis than ALR for tabular LR parsing with regard to space and time complexity. Parsing algorithms that are not based on the Lit technique have howeve</context>
</contexts>
<marker>1991</marker>
<rawString>Tomita, M., editor. 1991. Generalized LR Parsing. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A van Wijngaarden</author>
</authors>
<title>Revised report on the algorithmic language ALGOL 68. Acta Informatica,</title>
<date>1975</date>
<pages>5--1</pages>
<marker>van Wijngaarden, 1975</marker>
<rawString>van Wijngaarden, A. et al. 1975. Revised report on the algorithmic language ALGOL 68. Acta Informatica, 5:1-236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Villemonte de la Clergerie</author>
<author>E</author>
</authors>
<title>Automates a Piles et Programmation Dynamique - DyALog: Une application a la Programmaiion en Logique.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Universite Paris VII.</institution>
<marker>Clergerie, E, 1993</marker>
<rawString>Villemonte de la Clergerie, E. 1993. Automates a Piles et Programmation Dynamique - DyALog: Une application a la Programmaiion en Logique. Ph.D. thesis, Universite Paris VII.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T G Vosse</author>
</authors>
<title>The Word Connection.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Leiden.</institution>
<contexts>
<context position="22189" citStr="Vosse, 1994" startWordPosition="4236" endWordPosition="4237">ing Lang (1974) and Leermakers (1989). This has been investigated before by Nederhof (1994a, p. 25) and Villemonte de la Clergerie (1993, p. 155). 7 Empirical results We have performed some experiments with Algorithm 1 applied to A2LR and ALR, for 4 practical context-free grammars. For ALR a cover was used analogous to the one in Definition 4; the filtering function remains the same. The first grammar generates a subset of the programming language ALGOL 68 (van Wijngaarden and others, 1975). The second and third grammars generate a fragment of Dutch, and are referred to as the CORRie grammar (Vosse, 1994) and the Deltra grammar (Schoorl and Belder, 1990), respectively. These grammars were stripped of their arguments in order to convert them into context-free grammars. The fourth grammar, referred to as the Alvey grammar (Carroll, 1993), generates a fragment of English and was automatically generated from a unificationbased grammar. The test sentences have been obtained by automatic generation from the grammars, using the Grammar Workbench (Nederhof and Koster, 1992), which uses a random generator to select rules; therefore these sentences do not necessarily represent input typical of the appli</context>
</contexts>
<marker>Vosse, 1994</marker>
<rawString>Vosse, T.G. 1994. The Word Connection. Ph.D. thesis, University of Leiden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>