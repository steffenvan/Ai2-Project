<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000089">
<title confidence="0.978408">
Aligning words using matrix factorisation
</title>
<author confidence="0.928502">
Cyril Goutte, Kenji Yamada and Eric Gaussier
</author>
<affiliation confidence="0.852106">
Xerox Research Centre Europe
</affiliation>
<address confidence="0.6383405">
6, chemin de Maupertuis
F-38240 Meylan, France
</address>
<email confidence="0.993606">
Cyril.Goutte,Kenji.Yamada,Eric.Gaussier@xrce.xerox.com
</email>
<sectionHeader confidence="0.99728" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999722230769231">
Aligning words from sentences which are mutual
translations is an important problem in different set-
tings, such as bilingual terminology extraction, Ma-
chine Translation, or projection of linguistic fea-
tures. Here, we view word alignment as matrix fac-
torisation. In order to produce proper alignments,
we show that factors must satisfy a number of con-
straints such as orthogonality. We then propose an
algorithm for orthogonal non-negative matrix fac-
torisation, based on a probabilistic model of the
alignment data, and apply it to word alignment. This
is illustrated on a French-English alignment task
from the Hansard.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992441642857143">
Aligning words from mutually translated sentences
in two different languages is an important and dif-
ficult problem. It is important because a word-
aligned corpus is typically used as a first step in or-
der to identify phrases or templates in phrase-based
Machine Translation (Och et al., 1999), (Tillmann
and Xia, 2003), (Koehn et al., 2003, sec. 3), or
for projecting linguistic annotation across languages
(Yarowsky et al., 2001). Obtaining a word-aligned
corpus usually involves training a word-based trans-
lation models (Brown et al., 1993) in each directions
and combining the resulting alignments.
Besides processing time, important issues are
completeness and propriety of the resulting align-
ment, and the ability to reliably identify general N-
to-M alignments. In the following section, we in-
troduce the problem of aligning words from a cor-
pus that is already aligned at the sentence level. We
show how this problem may be phrased in terms
of matrix factorisation. We then identify a number
of constraints on word alignment, show that these
constraints entail that word alignment is equivalent
to orthogonal non-negative matrix factorisation, and
we give a novel algorithm that solves this problem.
This is illustrated using data from the shared tasks
of the 2003 HLT-NAACL Workshop on Building
the licence fee does not increase
le droit de permis ne augmente pas
</bodyText>
<figureCaption confidence="0.998531">
Figure 1: 1-1, M-1, 1-N and M-N alignments.
</figureCaption>
<bodyText confidence="0.992969">
and Using Parallel Texts (Mihalcea and Pedersen,
2003).
</bodyText>
<sectionHeader confidence="0.977671" genericHeader="introduction">
2 Word alignments
</sectionHeader>
<bodyText confidence="0.988984172413793">
We address the following problem: Given a source
sentence f = fi ... fi ... fI and a target sentence
e = el ... ej ... eJ, we wish to find words fi and ej
on either side which are aligned, ie in mutual corre-
spondence. Note that words may be aligned without
being directly “dictionary translations”. In order to
have proper alignments, we want to enforce the fol-
lowing constraints:
Coverage: Every word on either side must be
aligned to at least one word on the other side
(Possibly taking “null” words into account).
Transitive closure: If fi is aligned to ej and et, any
fk aligned to et must also de aligned to ej.
Under these constraints, there are only 4 types
of alignments: 1-1, 1-N, M-1 and M-N (fig. 1).
Although the first three are particular cases where
N=1 and/or M=1, the distinction is relevant, because
most word-based translation models (eg IBM mod-
els (Brown et al., 1993)) can typically not accom-
modate general M-N alignments.
We formalise this using the notion of cepts: a
cept is a central pivot through which a subset of e-
words is aligned to a subset of f-words. General
M-N alignments then correspond to M-1-N align-
ments from e-words, to a cept, to f-words (fig. 2).
Cepts naturally guarantee transitive closure as long
as each word is connected to a single cept. In ad-
dition, coverage is ensured by imposing that each
the licence fee does not increase
</bodyText>
<equation confidence="0.735516">
(1) (2) (3)(4)
</equation>
<bodyText confidence="0.495833">
le droit de permis ne augmente pas
</bodyText>
<figureCaption confidence="0.991923">
Figure 2: Same as figure 1, using cepts (1)-(4).
</figureCaption>
<bodyText confidence="0.888704705882353">
cepts
Mots francais Mots francais cepts
English words
English words
where without loss of generality, we introduce a di-
agonal K x K scaling matrix 5 which may give
different weights to the different cepts. As factors
F and E contain only positive elements, this is an
instance of non-negative matrix factorisation, aka
NMF (Lee and Seung, 1999). Because NMF de-
composes a matrix into additive, positive compo-
nents, it naturally yields a sparse representation.
In addition, the propriety constraint imposes that
words are aligned to exactly one cept, ie each row
of E and F has exactly one non-zero component, a
property we call extreme sparsity. With the notation
F = [Fik], this means that:
</bodyText>
<equation confidence="0.37017">
bi, bk =� l, Fik.Fil = 0
</equation>
<figureCaption confidence="0.9216335">
Figure 3: Matrix factorisation of the example from
fig. 1, 2. Black squares represent alignments.
word is connected to a cept. A unique constraint
therefore guarantees proper alignments:
</figureCaption>
<bodyText confidence="0.9981605">
Propriety: Each word is associated to exactly one
cept, and each cept is associated to at least one
word on each side.
Note that our use of cepts differs slightly from that
of (Brown et al., 1993, sec.3), inasmuch cepts may
not overlap, according to our definition.
The motivation for our work is that better word
alignments will lead to better translation mod-
els. For example, we may extract better chunks
for phrase-based translation models. In addition,
proper alignments ensure that cept-based phrases
will cover the entire source and target sentences.
</bodyText>
<sectionHeader confidence="0.99092" genericHeader="method">
3 Matrix factorisation
</sectionHeader>
<bodyText confidence="0.999732529411765">
Alignments between source and target words may
be represented by a I x J alignment matrix A =
[aij], such that aij &gt; 0 if fi is aligned with ej and
aij = 0 otherwise. Similarly, given K cepts, words
to cepts alignments may be represented by a I x
K matrix F and a J x K matrix E, with positive
elements indicating alignments. It is easy to see that
matrix A = F x ET then represents the resulting
word-to-word alignment (fig. 3).
Let us now assume that we start from a I xJ ma-
trix M = [mij], which we call the translation ma-
trix, such that mij &gt; 0 measures the strength of the
association between fi and ej (large values mean
close association). This may be estimated using a
translation table, a count (eg from a N-best list), etc.
Finding a suitable alignment matrix A corresponds
to finding factors F and E such that:
</bodyText>
<equation confidence="0.963201">
MPz�Fx5xET (1)
</equation>
<bodyText confidence="0.999955571428571">
As line i contains a single non-zero element, either
Fik or Fil must be 0. An immediate consequence is
that &amp; Fik.Fil = 0: columns of F are orthogonal,
that is F is an orthogonal matrix (and similarly, E
is orthogonal). Finding the best alignment starting
from M therefore reduces to performing a decom-
position into orthogonal non-negative factors.
</bodyText>
<sectionHeader confidence="0.844956" genericHeader="method">
4 An algorithm for Orthogonal
</sectionHeader>
<subsectionHeader confidence="0.694449">
Non-negative Matrix Factorisation
</subsectionHeader>
<bodyText confidence="0.999238272727273">
Standard NMF algorithms (Lee and Seung, 2001)
do not impose orthogonality between factors. We
propose to perform the Orthogonal Non-negative
Matrix Factorisation (ONMF) in two stages: We
first factorise M using Probabilistic Latent Seman-
tic Analysis, aka PLSA (Hofmann, 1999), then we
orthogonalise factors using a Maximum A Poste-
riori (MAP) assignment of words to cepts. PLSA
models a joint probability P(f, e) as a mixture
of conditionally independent multinomial distribu-
tions:
</bodyText>
<equation confidence="0.995012666666667">
� P(c)P(f|c)P(e|c) (2)
P (f, e) =
c
</equation>
<bodyText confidence="0.988669785714286">
With F = [P(f|c)], E = [P(e|c)] and 5 =
diag(P(c)), this is exactly eq. 1. Note also that
despite the additional matrix 5, if we set E =
[P(e, c)], then P(f|e) would factor as F x ET, the
original NMF formulation). All factors in eq. 2
are (conditional) probabilities, and therefore posi-
tive, so PLSA also implements NMF.
The parameters are learned from a matrix M =
[mij] of (fi, ej) counts, by maximising the like-
lihood using the iterative re-estimation formula of
the Expectation-Maximisation algorithm (Dempster
et al., 1977), cf. fig. 4. Convergence is guaran-
teed, leading to a non-negative factorisation of M.
The second step of our algorithm is to orthogonalise
</bodyText>
<equation confidence="0.998890111111111">
P(c)P(fi|c)P(ej|c)
E-step: P(c|fi, ej) = (3)
cP(c)P(fi|c)P(ej |c)
M-step: P(c) = 1N mijP(c|fi, ej) (4)
ij
M-step: P(fi|c)   mijP(c|fi, ej) (5)
j
M-step: P(ej|c)   mijP(c|fi, ej) (6)
i
</equation>
<figureCaption confidence="0.9884265">
Figure 4: The EM algorithm iterates these E and
M-steps until convergence.
</figureCaption>
<bodyText confidence="0.99733275">
the resulting factors. Each source word fi is as-
signed the most probable cept, ie cept c for which
P(c|fi)  P(c)P(fi|c) is maximal. Factor F is
therefore set to:
</bodyText>
<equation confidence="0.925038">
 1 if k = argmaxc P(c|fi)
Fik  (7)
0 otherwise
</equation>
<bodyText confidence="0.999922444444444">
where proportionality ensures that column of F sum
to 1, so that F stays a conditional probability ma-
trix. We proceed similarly for target words ej to
orthogonalise E. Thanks to the MAP assignment,
each line of F and E contains exactly one non-zero
element. We saw earlier that this is equivalent to
having orthogonal factors. The result is therefore an
orthogonal, non-negative factorisation of the origi-
nal translation matrix M.
</bodyText>
<subsectionHeader confidence="0.999094">
4.1 Number of cepts
</subsectionHeader>
<bodyText confidence="0.999943444444444">
In general, the number of cepts is unknown and
must be estimated. This corresponds to choos-
ing the number of components in PLSA, a classi-
cal model selection problem. The likelihood may
not be used as it always increases as components
are added. A standard approach to optimise the
complexity of a mixture model is to maximise the
likelihood, penalised by a term that increases with
model complexity, such as AIC (Akaike, 1974) or
BIC (Schwartz, 1978). BIC asymptotically chooses
the correct model size (for complete models), while
AIC always overestimates the number of compo-
nents, but usually yields good predictive perfor-
mance. As the largest possible number of cepts is
min(I, J), and the smallest is 1 (all fi aligned to
all ej), we estimate the optimal number of cepts
by maximising AIC or BIC between these two ex-
tremes.
</bodyText>
<subsectionHeader confidence="0.99883">
4.2 Dealing with null alignments
</subsectionHeader>
<bodyText confidence="0.999934428571429">
Alignment to a “null” word may be a feature of the
underlying statistical model (eg IBM models), or it
may be introduced to accommodate words which
have a low association measure with all other words.
Using PLSA, we can deal with null alignments in a
principled way by introducing a null word on each
side (fo and eo), and two null cepts (“f-null” and
“e-null”) with a 1-1 alignment to the correspond-
ing null word, to ensure that null alignments will
only be 1-N or M-1. This constraint is easily im-
plemented using proper initial conditions in EM.
Denoting the null cepts as cf and ce, 1-1 align-
ments between null cepts and the corresponding null
words impose the conditions:
</bodyText>
<listItem confidence="0.862491">
1. P(f0|cf) = 1 and i = 0, P(fi|cf) = 0;
2. P(e0|ce) = 1 and j = 0, P(ej|ce) = 0.
</listItem>
<bodyText confidence="0.999958714285714">
Stepping through the E-step and M-step equations
(3–6), we see that these conditions are preserved by
each EM iteration. In order to deal with null align-
ments, the model is therefore augmented with two
null cepts, for which the probabilities are initialised
according to the above conditions. As these are pre-
served through EM, we maintain proper 1-N and M-
1 alignments to the null words. The main difference
between null cepts and the other cepts is that we
relax the propriety constraint and do not force null
cepts to be aligned to at least one word on either
side. This is because in many cases, all words from
a sentence can be aligned to non-null words, and do
not require any null alignments.
</bodyText>
<subsectionHeader confidence="0.999894">
4.3 Modelling noise
</subsectionHeader>
<bodyText confidence="0.999913875">
Most elements of M usually have a non-zero asso-
ciation measure. This means that for proper align-
ments, which give zero probability to alignments
outside identified blocks, actual observations have
exactly 0 probability, ie the log-likelihood of param-
eters corresponding to proper alignments is unde-
fined. We therefore refine the model, adding a noise
component indexed by c = 0:
</bodyText>
<equation confidence="0.997728666666667">
P(f, e) =  P(c)P(f|c)P(e|c)
c&gt;0
+P(c = 0)P(f, e|c = 0)
</equation>
<bodyText confidence="0.9626894">
The simplest choice for the noise component is a
uniform distribution, P(f, e|c = 0)  1. E-step
and M-steps in eqs. (3–6) are unchanged for c &gt; 0,
and the E-step equation for c = 0 is easily adapted:
P(c=0|f, e)  P(c=0)P(f, e|c=0).
</bodyText>
<sectionHeader confidence="0.99871" genericHeader="method">
5 Example
</sectionHeader>
<bodyText confidence="0.999933267857143">
We first illustrate the factorisation process on a
simple example. We use the data provided for
the French-English shared task of the 2003 HLT-
NAACL Workshop on Building and Using Par-
allel Texts (Mihalcea and Pedersen, 2003). The
data is from the Canadian Hansard, and reference
alignments were originally produced by Franz Och
and Hermann Ney (Och and Ney, 2000). Using
the entire corpus (20 million words), we trained
English—*French and French—*English IBM4 mod-
els using GIZA++. For all sentences from the trial
and test set (37 and 447 sentences), we generated up
to 100 best alignments for each sentence and in each
direction. For each pair of source and target words
(fZ, ej), the association measure mZj is simply the
number of times these words were aligned together
in the two N-best lists, leading to a count between 0
(never aligned) and 200 (always aligned).
We focus on sentence 1023, from the trial set.
Figure 5 shows the reference alignments together
with the generated counts. There is a background
“noise” count of 3 to 5 (small dots) and the largest
counts are around 145-150. The N-best counts seem
to give a good idea of the alignments, although
clearly there is no chance that our factorisation al-
gorithm will recover the alignment of the two in-
stances of ’de’ to ’need’, as there is no evidence for
it in the data. The ambiguity that the factorisation
will have to address, and that is not easily resolved
using, eg, thresholding, is whether ’ont’ should be
aligned to ’They’ or to ’need’.
The N-best count matrix serves as the transla-
tion matrix. We estimate PLSA parameters for
K = 1... 6, and find out that AIC and BIC reach
their maximum for K = 6. We therefore select 6
cepts for this sentence, and produce the alignment
matrices shown on figure 6. Note that the order
of the cepts is arbitrary (here the first cept corre-
spond ’et’ — ’and’), except for the null cepts which
are fixed. There is a fixed 1-1 correspondence be-
tween these null cepts and the corresponding null
words on each side, and only the French words ’de’
are mapped to a null cept. Finally, the estimated
noise level is P(c = 0) = 0.00053. The ambigu-
ity associated with aligning ’ont’ has been resolved
through cepts 4 and 5. In our resulting model,
P(c=4|’ont’) Pz� 0.40 while P(c=6|’ont’) Pz� 0.54:
The MAP assignment forces ’ont’ to be aligned to
cept 5 only, and therefore to ’need’.
Note that although the count for (need,ont) is
slightly larger than the count for (they,ont) (cf. fig.
5), this is not a trivial result. The model was able to
resolve the fact that they and need had to be aligned
to 2 different cepts, rather than eg a larger cept
corresponding to a 2-4 alignment, and to produce
proper alignments through the use of these cepts.
</bodyText>
<sectionHeader confidence="0.999596" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9994569375">
In order to perform a more systematic evaluation of
the use of matrix factorisation for aligning words,
we tested this technique on the full trial and test data
from the 2003 HLT-NAACL Workshop. Note that
the reference data has both “Sure” and “Probable”
alignments, with about 77% of all alignments in the
latter category. On the other hand, our system pro-
poses only one type of alignment. The evaluation
is done using the performance measures described
in (Mihalcea and Pedersen, 2003): precision, recall
and F-score on the probable and sure alignments, as
well as the Alignment Error Rate (AER), which in
our case is a weighted average of the recall on the
sure alignments and the precision on the probable.
Given an alignment A and gold standards 9S and
9P (for sure and probable alignments, respectively):
</bodyText>
<equation confidence="0.986091444444445">
PT = |A n 9T |(8)
|A|
RT = |A n 9T |(9)
|9T|
2|A n 9T |(10)
|9T |+ |A|
where T is either S or P, and:
AER = 1 − |9S|RS + |A|PP (11)
|9S |+ |A|
</equation>
<bodyText confidence="0.999839416666667">
Using these measures, we first evaluate the per-
formance on the trial set (37 sentences): as we
produce only one type of alignment and evaluate
against “Sure” and “Probable”, we observe, as ex-
pected, that the recall is very good on sure align-
ments, but precision relatively poor, with the re-
verse situation on the probable alignments (table 1).
This is because we generate an intermediate number
of alignments. There are 338 sure and 1446 prob-
able alignments (for 721 French and 661 English
words) in the reference trial data, and we produce
707 (AIC) or 766 (BIC) alignments with ONMF.
Most of them are at least probably correct, as at-
tested by PP, but only about half of them are in the
“Sure” subset, yielding a low value of PS. Sim-
ilarly, because “Probable” alignments were gener-
ated as the union of alignments produced by two
annotators, they sometimes lead to very large M-
N alignments, which produce on average 2.5 to 2.7
alignments per word. By contrast ONMF produces
less than 1.2 alignments per word, hence the low
value of RP. As the AER is a weighted average of
RS and PP, the resulting AER are relatively low for
our method.
</bodyText>
<figure confidence="0.999261717948718">
FT = 2PTRT
PT+RT
Reference alignments N−best counts
.
loisirs
de
et
jouets
de
besoin
ont
enfants
les
NULL
.
loisirs
de
et
jouets
de
besoin
ont
enfants
les
NULL
NULL
they
need
toys
and
nment
�Jtnment
NULL
they
need
toys
and
.
.
</figure>
<figureCaption confidence="0.9302605">
Figure 5: Left: reference alignments, large squares are sure, medium squares are probable; Right: accumu-
lated counts from IBM4 N-best lists, bigger squares are larger counts.
</figureCaption>
<figure confidence="0.9609438125">
er ne
t r e
e
e
f−to−cept alignment Resulting alignment
.
loisirs
de
et
jouets
de
besoin
ont
enfants
les
NULL
</figure>
<table confidence="0.828494333333333">
Method PS RS FS PP RP FP AER
ONMF + AIC 45.26% 94.67% 61.24% 86.56% 34.30% 49.14% 10.81%
ONMF + BIC 42.69% 96.75% 59.24% 83.42% 35.82% 50.12% 12.50%
</table>
<tableCaption confidence="0.9709105">
Table 1: Performance on the 37 trial sentences for orthogonal non-negative matrix factorisation (ONMF)
using the AIC and BIC criterion for choosing the number of cepts, discounting null alignments.
</tableCaption>
<figure confidence="0.930088">
cept1
cept2
cept3
cept4
cept5
cept6
−null
−null
n e
</figure>
<figureCaption confidence="0.883257">
Figure 6: Resulting word-to-cept and word-to-word alignments for sentence 1023.
</figureCaption>
<figure confidence="0.885841628571429">
×
e−null
f−null
cept1
cept2
cept3
cept4
cept5
cept6
e−to−cept alignment
NULL
they
need
toys
and
nnment
.
enfants
loisirs
besoin
jouets
NULL
ont
les
de
et
de
.
NULL
they
need
toys
and
nment
.
</figure>
<bodyText confidence="0.999646611111111">
We also compared the performance on the 447
test sentences to 1/ the intersection of the align-
ments produced by the top IBM4 alignments in ei-
ther directions, and 2/ the best systems from (Mi-
halcea and Pedersen, 2003). On limited resources,
Ralign.EF.1 (Simard and Langlais, 2003) produced
the best F-score, as well as the best AER when
NULL alignments were taken into account, while
XRCE.Nolem.EF.3 (Dejean et al., 2003) produced
the best AER when NULL alignments were dis-
counted. Tables 2 and 3 show that ONMF improves
on several of these results. In particular, we get bet-
ter recall and F-score on the probable alignments
(and even a better precision than Ralign.EF.1 in ta-
ble 2). On the other hand, the performance, and in
particular the precision, on sure alignments is dis-
mal. We attribute this at least partly to a key dif-
ference between our model and the reference data:
</bodyText>
<table confidence="0.998559166666667">
Method PS RS FS PP RP FP AER
ONMF + AIC 49.86% 95.12% 65.42% 84.63% 37.39% 51.87% 11.76%
ONMF + BIC 46.50% 96.01% 62.65% 80.92% 38.69% 52.35% 14.16%
IBM4 intersection 71.46% 90.04% 79.68% 97.66% 28.44% 44.12% 5.71%
HLT-03 best F 72.54% 80.61% 76.36% 77.56% 38.19% 51.18% 18.50%
HLT-03 best AER 55.43% 93.81% 69.68% 90.09% 35.30% 50.72% 8.53%
</table>
<tableCaption confidence="0.997445">
Table 2: Performance on the 447 English-French test sentences, discounting NULL alignments, for orthog-
</tableCaption>
<bodyText confidence="0.991778868852459">
onal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number of
cepts. HLT-03 best F is Ralign.EF.1 and best AER is XRCE.Nolem.EF.3 (Mihalcea and Pedersen, 2003).
our model enforces coverage and makes sure that
all words are aligned, while the “Sure” reference
alignments have no such constraints and actually
have a very bad coverage. Indeed, less than half the
words in the test set have a “Sure” alignment, which
means that a method which ensures that all words
are aligned will at best have a sub 50% precision. In
addition, many reference “Probable” alignments are
not proper alignments in the sense defined above.
Note that the IBM4 intersection has a bias similar
to the sure reference alignments, and performs very
well in FS, PP and especially in AER, even though
it produces very incomplete alignments. This points
to a particular problem with the AER in the context
of our study. In fact, a system that outputs exactly
the set of sure alignments achieves a perfect AER of
0, even though it aligns only about 23% of words,
clearly an unacceptable drawback in many applica-
tions. We think that this issue may be addressed
in two different ways. One time-consuming possi-
bility would be to post-edit the reference alignment
to ensure coverage and proper alignments. An-
other possibility would be to use the probabilistic
model to mimic the reference data and generate both
“Sure” and “Probable” alignments using eg thresh-
olds on the estimated alignment probabilities. This
approach may lead to better performance according
to our metrics, but it is not obvious that the pro-
duced alignments will be more reasonable or even
useful in a practical application.
We also tested our approach on the Romanian-
English task of the same workshop, cf. table 4.
The ’HLT-03 best’ is our earlier work (Dejean et
al., 2003), simply based on IBM4 alignment us-
ing an additional lexicon extracted from the corpus.
Slightly better results have been published since
(Barbu, 2004), using additional linguistic process-
ing, but those were not presented at the workshop.
Note that the reference alignments for Romanian-
English contain only “Sure” alignments, and there-
fore we only report the performance on those. In ad-
dition, AER = 1−FS in this setting. Table 4 shows
that the matrix factorisation approach does not offer
any quantitative improvements over these results. A
gain of up to 10 points in recall does not offset a
large decrease in precision. As a consequence, the
AER for ONMF+AIC is about 10% higher than in
our earlier work. This seems mainly due to the fact
that the ’HLT-03 best’ produces alignments for only
about 80% of the words, while our technique en-
sure coverage and therefore aligns all words. These
results suggest that remaining 20% seem particu-
larly problematic. These quantitative results are
disappointing given the sofistication of the method.
It should be noted, however, that ONMF provides
the qualitative advantage of producing proper align-
ments, and in particular ensures coverage. This may
be useful in some contexts, eg training a phrase-
based translation system.
</bodyText>
<sectionHeader confidence="0.999954" genericHeader="method">
7 Discussion
</sectionHeader>
<subsectionHeader confidence="0.999772">
7.1 Model selection and stability
</subsectionHeader>
<bodyText confidence="0.999965647058824">
Like all mixture models, PLSA is subject to lo-
cal minima. Although using a few random restarts
seems to yield good performance, the results on
difficult-to-align sentences may still be sensitive to
initial conditions. A standard technique to stabilise
the EM solution is to use deterministic annealing or
tempered EM (Rose et al., 1990). As a side effect,
deterministic annealing actually makes model se-
lection easier. At low temperature, all components
are identical, and they differentiate as the temper-
ature increases, until the final temperature, where
we recover the standard EM algorithm. By keep-
ing track of the component differentiations, we may
consider multiple effective numbers of components
in one pass, therefore alleviating the need for costly
multiple EM runs with different cept numbers and
multiple restarts.
</bodyText>
<subsectionHeader confidence="0.932959">
7.2 Other association measures
</subsectionHeader>
<bodyText confidence="0.9972375">
ONMF is only a tool to factor the original trans-
lation matrix M, containing measures of associa-
tions between fz and ej. The quality of the re-
sulting alignment greatly depends on the way M is
</bodyText>
<table confidence="0.9980274">
Method PS RS FS PP RP FP AER
ONMF + AIC 42.88% 95.12% 59.11% 75.17% 37.20% 49.77% 18.63%
ONMF + BIC 40.17% 96.01% 56.65% 72.20% 38.49% 50.21% 20.78%
IBM4 intersection 56.39% 90.04% 69.35% 81.14% 28.90% 42.62% 15.43%
HLT-03 best 72.54% 80.61% 76.36% 77.56% 36.79% 49.91% 18.50%
</table>
<tableCaption confidence="0.928563666666667">
Table 3: Performance on the 447 English-French test sentences, taking NULL alignments into account, for
orthogonal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the
number of cepts. HLT-03 best is Ralign.EF.1 (Mihalcea and Pedersen, 2003).
</tableCaption>
<table confidence="0.9991986">
no NULL alignments with NULL alignments
Method PS RS FS AER PS RS FS AER
ONMF + AIC 70.34% 65.54% 67.85% 32.15% 62.65% 62.10% 62.38% 37.62%
ONMF + BIC 55.88% 67.70% 61.23% 38.77% 51.78% 64.07% 57.27% 42.73%
HLT-03 best 82.65% 62.44% 71.14% 28.86% 82.65% 54.11% 65.40% 34.60%
</table>
<tableCaption confidence="0.996211">
Table 4: Performance on the 248 Romanian-English test sentences (only sure alignments), for orthogonal
</tableCaption>
<bodyText confidence="0.96550252631579">
non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number of
cepts. HLT-03 best is XRCE.Nolem (Mihalcea and Pedersen, 2003).
filled. In our experiments we used counts from N-
best alignments obtained from IBM model 4. This
is mainly used as a proof of concept: other strate-
gies, such as weighting the alignments according to
their probability or rank in the N-best list would be
natural extensions. In addition, we are currently in-
vestigating the use of translation and distortion ta-
bles obtained from IBM model 2 to estimate M at
a lower cost. Ultimately, it would be interesting
to obtain association measures mzj in a fully non-
parametric way, using corpus statistics rather than
translation models, which themselves perform some
kind of alignment. We have investigated the use
of co-occurrence counts or mutual information be-
tween words, but this has so far not proved success-
ful, mostly because common words, such as func-
tion words, tend to dominate these measures.
</bodyText>
<subsectionHeader confidence="0.974344">
7.3 M-1-0 alignments
</subsectionHeader>
<bodyText confidence="0.999993769230769">
In our model, cepts ensure that resulting alignments
are proper. There is however one situation in which
improper alignments may be produced: If the MAP
assigns f-words but no e-words to a cept (because
e-words have more probable cepts), we may pro-
duce “orphan” cepts, which are aligned to words
only on one side. One way to deal with this situa-
tion is simply to remove cepts which display this be-
haviour. Orphaned words may then be re-assigned
to the remaining cepts, either directly or after re-
training PLSA on the remaining cepts (this is guar-
anteed to converge as there is an obvious solution
for K = 1).
</bodyText>
<subsectionHeader confidence="0.987638">
7.4 Independence between sentences
</subsectionHeader>
<bodyText confidence="0.999996304347826">
One natural comment on our factorisation scheme is
that cepts should not be independent between sen-
tences. However it is easy to show that the fac-
torisation is optimally done on a sentence per sen-
tence basis. Indeed, what we factorise is the associ-
ation measures mzj. For a sentence-aligned corpus,
the association measure between source and tar-
get words from two different sentence pairs should
be exactly 0 because words should not be aligned
across sentences. Therefore, the larger translation
matrix (calculated on the entire corpus) is block
diagonal, with non-zero association measures only
in blocks corresponding to aligned sentence. As
blocks on the diagonal are mutually orthogonal, the
optimal global orthogonal factorisation is identi-
cal to the block-based (ie sentence-based) factori-
sation. Any corpus-induced dependency between
alignments from different sentences must therefore
be built in the association measure mzj, and can-
not be handled by the factorisation method. Note
that this is the case in our experiments, as model 4
alignments rely on parameters obtained on the en-
tire corpus.
</bodyText>
<sectionHeader confidence="0.999433" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999829785714286">
In this paper, we view word alignment as 1/ estimat-
ing the association between source and target words,
and 2/ factorising the resulting association measure
into orthogonal, non-negative factors. For solving
the latter problem, we propose an algorithm for
ONMF, which guarantees both proper alignments
and good coverage. Experiments carried out on the
Hansard give encouraging results, in the sense that
we improve in several ways over state-of-the-art re-
sults, despite a clear bias in the reference align-
ments. Further investigations are required to ap-
ply this technique on different association measures,
and to measure the influence that ONMF may have,
eg on a phrase-based Machine Translation system.
</bodyText>
<sectionHeader confidence="0.997962" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99996525">
We acknowledge the Machine Learning group at
XRCE for discussions related to the topic of word
alignment. We would like to thank the three anony-
mous reviewers for their comments.
</bodyText>
<sectionHeader confidence="0.999287" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998702232142857">
H. Akaike. 1974. A new look at the statistical
model identification. IEEE Tr. Automatic Con-
trol, 19(6):716–723.
A.-M. Barbu. 2004. Simple linguistic methods for
improving a word alignment algorithm. In Le
poids des mots — Proc. JADT04, pages 88–98.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra,
and R. L. Mercer. 1993. The mathematics of
statistical machine translation: Parameter estima-
tion. Computational linguistics, 19:263–312.
H. Dejean, E. Gaussier, C. Goutte, and K. Yamada.
2003. Reducing parameter space for word align-
ment. In HLT-NAACL 2003 Workshop: Building
and Using Parallel Texts, pages 23–26.
A. P. Dempster, N. M. Laird, and D. B. Ru-
bin. 1977. Maximum likelihood from incom-
plete data via the EM algorithm. J. Royal Sta-
tistical Society, Series B, 39(1):1–38.
T. Hofmann. 1999. Probabilistic latent semantic
analysis. In Uncertainty in Artificial Intelligence,
pages 289–296.
P. Koehn, F. Och, and D. Marcu. 2003. Statistical
phrase-based translation. In Proc. HLT-NAACL
2003.
D. D. Lee and H. S. Seung. 1999. Learning the
parts of objects by non-negative matrix factoriza-
tion. Nature, 401:788–791.
D. D. Lee and H. S. Seung. 2001. Algorithms for
non-negative matrix factorization. In NIPS*13,
pages 556–562.
R. Mihalcea and T. Pedersen. 2003. An evalua-
tion exercise for word alignment. In HLT-NAACL
2003 Workshop: Building and Using Parallel
Texts, pages 1–10.
F. Och and H. Ney. 2000. A comparison of align-
ment models for statistical machine translation.
In Proc. COLING’00, pages 1086–1090.
F. Och, C. Tillmann, and H. Ney. 1999. Improved
alignment models for statistical machine transla-
tion. In Proc. EMNLP, pages 20–28.
K. Rose, E. Gurewitz, and G. Fox. 1990. A deter-
ministic annealing approach to clustering. Pat-
tern Recognition Letters, 11(11):589–594.
G. Schwartz. 1978. Estimating the dimension of a
model. The Annals of Statistics, 6(2):461–464.
M. Simard and P. Langlais. 2003. Statistical
translation alignment with compositionality con-
straints. In HLT-NAACL 2003 Workshop: Build-
ing and Using Parallel Texts, pages 19–22.
C. Tillmann and F. Xia. 2003. A phrase-based uni-
gram model for statistical machine translation. In
Proc. HLT-NAACL 2003.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001.
Inducing multilingual text analysis tools via ro-
bust projection across aligned corpora. In Proc.
HLT 2001.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.432344">
<title confidence="0.997828">Aligning words using matrix factorisation</title>
<author confidence="0.992209">Cyril Goutte</author>
<author confidence="0.992209">Kenji Yamada</author>
<author confidence="0.992209">Eric Gaussier</author>
<affiliation confidence="0.837583">Xerox Research Centre Europe</affiliation>
<address confidence="0.6673305">6, chemin de Maupertuis F-38240 Meylan, France</address>
<email confidence="0.987733">Cyril.Goutte,Kenji.Yamada,Eric.Gaussier@xrce.xerox.com</email>
<abstract confidence="0.997680357142857">Aligning words from sentences which are mutual translations is an important problem in different settings, such as bilingual terminology extraction, Machine Translation, or projection of linguistic features. Here, we view word alignment as matrix factorisation. In order to produce proper alignments, we show that factors must satisfy a number of constraints such as orthogonality. We then propose an algorithm for orthogonal non-negative matrix factorisation, based on a probabilistic model of the alignment data, and apply it to word alignment. This is illustrated on a French-English alignment task from the Hansard.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Akaike</author>
</authors>
<title>A new look at the statistical model identification.</title>
<date>1974</date>
<journal>IEEE Tr. Automatic Control,</journal>
<volume>19</volume>
<issue>6</issue>
<contexts>
<context position="9091" citStr="Akaike, 1974" startWordPosition="1526" endWordPosition="1527"> earlier that this is equivalent to having orthogonal factors. The result is therefore an orthogonal, non-negative factorisation of the original translation matrix M. 4.1 Number of cepts In general, the number of cepts is unknown and must be estimated. This corresponds to choosing the number of components in PLSA, a classical model selection problem. The likelihood may not be used as it always increases as components are added. A standard approach to optimise the complexity of a mixture model is to maximise the likelihood, penalised by a term that increases with model complexity, such as AIC (Akaike, 1974) or BIC (Schwartz, 1978). BIC asymptotically chooses the correct model size (for complete models), while AIC always overestimates the number of components, but usually yields good predictive performance. As the largest possible number of cepts is min(I, J), and the smallest is 1 (all fi aligned to all ej), we estimate the optimal number of cepts by maximising AIC or BIC between these two extremes. 4.2 Dealing with null alignments Alignment to a “null” word may be a feature of the underlying statistical model (eg IBM models), or it may be introduced to accommodate words which have a low associa</context>
</contexts>
<marker>Akaike, 1974</marker>
<rawString>H. Akaike. 1974. A new look at the statistical model identification. IEEE Tr. Automatic Control, 19(6):716–723.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-M Barbu</author>
</authors>
<title>Simple linguistic methods for improving a word alignment algorithm.</title>
<date>2004</date>
<booktitle>In Le poids des mots — Proc. JADT04,</booktitle>
<pages>88--98</pages>
<contexts>
<context position="21050" citStr="Barbu, 2004" startWordPosition="3615" endWordPosition="3616">nce data and generate both “Sure” and “Probable” alignments using eg thresholds on the estimated alignment probabilities. This approach may lead to better performance according to our metrics, but it is not obvious that the produced alignments will be more reasonable or even useful in a practical application. We also tested our approach on the RomanianEnglish task of the same workshop, cf. table 4. The ’HLT-03 best’ is our earlier work (Dejean et al., 2003), simply based on IBM4 alignment using an additional lexicon extracted from the corpus. Slightly better results have been published since (Barbu, 2004), using additional linguistic processing, but those were not presented at the workshop. Note that the reference alignments for RomanianEnglish contain only “Sure” alignments, and therefore we only report the performance on those. In addition, AER = 1−FS in this setting. Table 4 shows that the matrix factorisation approach does not offer any quantitative improvements over these results. A gain of up to 10 points in recall does not offset a large decrease in precision. As a consequence, the AER for ONMF+AIC is about 10% higher than in our earlier work. This seems mainly due to the fact that the </context>
</contexts>
<marker>Barbu, 2004</marker>
<rawString>A.-M. Barbu. 2004. Simple linguistic methods for improving a word alignment algorithm. In Le poids des mots — Proc. JADT04, pages 88–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation. Computational linguistics,</title>
<date>1993</date>
<pages>19--263</pages>
<contexts>
<context position="1403" citStr="Brown et al., 1993" startWordPosition="204" endWordPosition="207">lustrated on a French-English alignment task from the Hansard. 1 Introduction Aligning words from mutually translated sentences in two different languages is an important and difficult problem. It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al., 1999), (Tillmann and Xia, 2003), (Koehn et al., 2003, sec. 3), or for projecting linguistic annotation across languages (Yarowsky et al., 2001). Obtaining a word-aligned corpus usually involves training a word-based translation models (Brown et al., 1993) in each directions and combining the resulting alignments. Besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general Nto-M alignments. In the following section, we introduce the problem of aligning words from a corpus that is already aligned at the sentence level. We show how this problem may be phrased in terms of matrix factorisation. We then identify a number of constraints on word alignment, show that these constraints entail that word alignment is equivalent to orthogonal non-negative matrix factorisa</context>
<context position="3235" citStr="Brown et al., 1993" startWordPosition="517" endWordPosition="520">tly “dictionary translations”. In order to have proper alignments, we want to enforce the following constraints: Coverage: Every word on either side must be aligned to at least one word on the other side (Possibly taking “null” words into account). Transitive closure: If fi is aligned to ej and et, any fk aligned to et must also de aligned to ej. Under these constraints, there are only 4 types of alignments: 1-1, 1-N, M-1 and M-N (fig. 1). Although the first three are particular cases where N=1 and/or M=1, the distinction is relevant, because most word-based translation models (eg IBM models (Brown et al., 1993)) can typically not accommodate general M-N alignments. We formalise this using the notion of cepts: a cept is a central pivot through which a subset of ewords is aligned to a subset of f-words. General M-N alignments then correspond to M-1-N alignments from e-words, to a cept, to f-words (fig. 2). Cepts naturally guarantee transitive closure as long as each word is connected to a single cept. In addition, coverage is ensured by imposing that each the licence fee does not increase (1) (2) (3)(4) le droit de permis ne augmente pas Figure 2: Same as figure 1, using cepts (1)-(4). cepts Mots fran</context>
<context position="4918" citStr="Brown et al., 1993" startWordPosition="810" endWordPosition="813">riety constraint imposes that words are aligned to exactly one cept, ie each row of E and F has exactly one non-zero component, a property we call extreme sparsity. With the notation F = [Fik], this means that: bi, bk =� l, Fik.Fil = 0 Figure 3: Matrix factorisation of the example from fig. 1, 2. Black squares represent alignments. word is connected to a cept. A unique constraint therefore guarantees proper alignments: Propriety: Each word is associated to exactly one cept, and each cept is associated to at least one word on each side. Note that our use of cepts differs slightly from that of (Brown et al., 1993, sec.3), inasmuch cepts may not overlap, according to our definition. The motivation for our work is that better word alignments will lead to better translation models. For example, we may extract better chunks for phrase-based translation models. In addition, proper alignments ensure that cept-based phrases will cover the entire source and target sentences. 3 Matrix factorisation Alignments between source and target words may be represented by a I x J alignment matrix A = [aij], such that aij &gt; 0 if fi is aligned with ej and aij = 0 otherwise. Similarly, given K cepts, words to cepts alignme</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational linguistics, 19:263–312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dejean</author>
<author>E Gaussier</author>
<author>C Goutte</author>
<author>K Yamada</author>
</authors>
<title>Reducing parameter space for word alignment.</title>
<date>2003</date>
<booktitle>In HLT-NAACL</booktitle>
<pages>23--26</pages>
<contexts>
<context position="18144" citStr="Dejean et al., 2003" startWordPosition="3127" endWordPosition="3130">ce 1023. × e−null f−null cept1 cept2 cept3 cept4 cept5 cept6 e−to−cept alignment NULL they need toys and nnment . enfants loisirs besoin jouets NULL ont les de et de . NULL they need toys and nment . We also compared the performance on the 447 test sentences to 1/ the intersection of the alignments produced by the top IBM4 alignments in either directions, and 2/ the best systems from (Mihalcea and Pedersen, 2003). On limited resources, Ralign.EF.1 (Simard and Langlais, 2003) produced the best F-score, as well as the best AER when NULL alignments were taken into account, while XRCE.Nolem.EF.3 (Dejean et al., 2003) produced the best AER when NULL alignments were discounted. Tables 2 and 3 show that ONMF improves on several of these results. In particular, we get better recall and F-score on the probable alignments (and even a better precision than Ralign.EF.1 in table 2). On the other hand, the performance, and in particular the precision, on sure alignments is dismal. We attribute this at least partly to a key difference between our model and the reference data: Method PS RS FS PP RP FP AER ONMF + AIC 49.86% 95.12% 65.42% 84.63% 37.39% 51.87% 11.76% ONMF + BIC 46.50% 96.01% 62.65% 80.92% 38.69% 52.35% </context>
<context position="20899" citStr="Dejean et al., 2003" startWordPosition="3590" endWordPosition="3593"> to post-edit the reference alignment to ensure coverage and proper alignments. Another possibility would be to use the probabilistic model to mimic the reference data and generate both “Sure” and “Probable” alignments using eg thresholds on the estimated alignment probabilities. This approach may lead to better performance according to our metrics, but it is not obvious that the produced alignments will be more reasonable or even useful in a practical application. We also tested our approach on the RomanianEnglish task of the same workshop, cf. table 4. The ’HLT-03 best’ is our earlier work (Dejean et al., 2003), simply based on IBM4 alignment using an additional lexicon extracted from the corpus. Slightly better results have been published since (Barbu, 2004), using additional linguistic processing, but those were not presented at the workshop. Note that the reference alignments for RomanianEnglish contain only “Sure” alignments, and therefore we only report the performance on those. In addition, AER = 1−FS in this setting. Table 4 shows that the matrix factorisation approach does not offer any quantitative improvements over these results. A gain of up to 10 points in recall does not offset a large </context>
</contexts>
<marker>Dejean, Gaussier, Goutte, Yamada, 2003</marker>
<rawString>H. Dejean, E. Gaussier, C. Goutte, and K. Yamada. 2003. Reducing parameter space for word alignment. In HLT-NAACL 2003 Workshop: Building and Using Parallel Texts, pages 23–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the EM algorithm.</title>
<date>1977</date>
<journal>J. Royal Statistical Society, Series B,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="7598" citStr="Dempster et al., 1977" startWordPosition="1267" endWordPosition="1270"> of conditionally independent multinomial distributions: � P(c)P(f|c)P(e|c) (2) P (f, e) = c With F = [P(f|c)], E = [P(e|c)] and 5 = diag(P(c)), this is exactly eq. 1. Note also that despite the additional matrix 5, if we set E = [P(e, c)], then P(f|e) would factor as F x ET, the original NMF formulation). All factors in eq. 2 are (conditional) probabilities, and therefore positive, so PLSA also implements NMF. The parameters are learned from a matrix M = [mij] of (fi, ej) counts, by maximising the likelihood using the iterative re-estimation formula of the Expectation-Maximisation algorithm (Dempster et al., 1977), cf. fig. 4. Convergence is guaranteed, leading to a non-negative factorisation of M. The second step of our algorithm is to orthogonalise P(c)P(fi|c)P(ej|c) E-step: P(c|fi, ej) = (3) cP(c)P(fi|c)P(ej |c) M-step: P(c) = 1N mijP(c|fi, ej) (4) ij M-step: P(fi|c)   mijP(c|fi, ej) (5) j M-step: P(ej|c)   mijP(c|fi, ej) (6) i Figure 4: The EM algorithm iterates these E and M-steps until convergence. the resulting factors. Each source word fi is assigned the most probable cept, ie cept c for which P(c|fi)  P(c)P(fi|c) is maximal. Factor F is therefore set to:  1 if k = argmaxc P(c|fi) Fik  </context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum likelihood from incomplete data via the EM algorithm. J. Royal Statistical Society, Series B, 39(1):1–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic analysis.</title>
<date>1999</date>
<booktitle>In Uncertainty in Artificial Intelligence,</booktitle>
<pages>289--296</pages>
<contexts>
<context position="6827" citStr="Hofmann, 1999" startWordPosition="1137" endWordPosition="1138"> An immediate consequence is that &amp; Fik.Fil = 0: columns of F are orthogonal, that is F is an orthogonal matrix (and similarly, E is orthogonal). Finding the best alignment starting from M therefore reduces to performing a decomposition into orthogonal non-negative factors. 4 An algorithm for Orthogonal Non-negative Matrix Factorisation Standard NMF algorithms (Lee and Seung, 2001) do not impose orthogonality between factors. We propose to perform the Orthogonal Non-negative Matrix Factorisation (ONMF) in two stages: We first factorise M using Probabilistic Latent Semantic Analysis, aka PLSA (Hofmann, 1999), then we orthogonalise factors using a Maximum A Posteriori (MAP) assignment of words to cepts. PLSA models a joint probability P(f, e) as a mixture of conditionally independent multinomial distributions: � P(c)P(f|c)P(e|c) (2) P (f, e) = c With F = [P(f|c)], E = [P(e|c)] and 5 = diag(P(c)), this is exactly eq. 1. Note also that despite the additional matrix 5, if we set E = [P(e, c)], then P(f|e) would factor as F x ET, the original NMF formulation). All factors in eq. 2 are (conditional) probabilities, and therefore positive, so PLSA also implements NMF. The parameters are learned from a ma</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>T. Hofmann. 1999. Probabilistic latent semantic analysis. In Uncertainty in Artificial Intelligence, pages 289–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. HLT-NAACL</booktitle>
<contexts>
<context position="1200" citStr="Koehn et al., 2003" startWordPosition="175" endWordPosition="178">nts such as orthogonality. We then propose an algorithm for orthogonal non-negative matrix factorisation, based on a probabilistic model of the alignment data, and apply it to word alignment. This is illustrated on a French-English alignment task from the Hansard. 1 Introduction Aligning words from mutually translated sentences in two different languages is an important and difficult problem. It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al., 1999), (Tillmann and Xia, 2003), (Koehn et al., 2003, sec. 3), or for projecting linguistic annotation across languages (Yarowsky et al., 2001). Obtaining a word-aligned corpus usually involves training a word-based translation models (Brown et al., 1993) in each directions and combining the resulting alignments. Besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general Nto-M alignments. In the following section, we introduce the problem of aligning words from a corpus that is already aligned at the sentence level. We show how this problem may be phrased in </context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. Och, and D. Marcu. 2003. Statistical phrase-based translation. In Proc. HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lee</author>
<author>H S Seung</author>
</authors>
<title>Learning the parts of objects by non-negative matrix factorization.</title>
<date>1999</date>
<journal>Nature,</journal>
<pages>401--788</pages>
<contexts>
<context position="4164" citStr="Lee and Seung, 1999" startWordPosition="680" endWordPosition="683">urally guarantee transitive closure as long as each word is connected to a single cept. In addition, coverage is ensured by imposing that each the licence fee does not increase (1) (2) (3)(4) le droit de permis ne augmente pas Figure 2: Same as figure 1, using cepts (1)-(4). cepts Mots francais Mots francais cepts English words English words where without loss of generality, we introduce a diagonal K x K scaling matrix 5 which may give different weights to the different cepts. As factors F and E contain only positive elements, this is an instance of non-negative matrix factorisation, aka NMF (Lee and Seung, 1999). Because NMF decomposes a matrix into additive, positive components, it naturally yields a sparse representation. In addition, the propriety constraint imposes that words are aligned to exactly one cept, ie each row of E and F has exactly one non-zero component, a property we call extreme sparsity. With the notation F = [Fik], this means that: bi, bk =� l, Fik.Fil = 0 Figure 3: Matrix factorisation of the example from fig. 1, 2. Black squares represent alignments. word is connected to a cept. A unique constraint therefore guarantees proper alignments: Propriety: Each word is associated to exa</context>
</contexts>
<marker>Lee, Seung, 1999</marker>
<rawString>D. D. Lee and H. S. Seung. 1999. Learning the parts of objects by non-negative matrix factorization. Nature, 401:788–791.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lee</author>
<author>H S Seung</author>
</authors>
<title>Algorithms for non-negative matrix factorization.</title>
<date>2001</date>
<booktitle>In NIPS*13,</booktitle>
<pages>556--562</pages>
<contexts>
<context position="6597" citStr="Lee and Seung, 2001" startWordPosition="1102" endWordPosition="1105">a translation table, a count (eg from a N-best list), etc. Finding a suitable alignment matrix A corresponds to finding factors F and E such that: MPz�Fx5xET (1) As line i contains a single non-zero element, either Fik or Fil must be 0. An immediate consequence is that &amp; Fik.Fil = 0: columns of F are orthogonal, that is F is an orthogonal matrix (and similarly, E is orthogonal). Finding the best alignment starting from M therefore reduces to performing a decomposition into orthogonal non-negative factors. 4 An algorithm for Orthogonal Non-negative Matrix Factorisation Standard NMF algorithms (Lee and Seung, 2001) do not impose orthogonality between factors. We propose to perform the Orthogonal Non-negative Matrix Factorisation (ONMF) in two stages: We first factorise M using Probabilistic Latent Semantic Analysis, aka PLSA (Hofmann, 1999), then we orthogonalise factors using a Maximum A Posteriori (MAP) assignment of words to cepts. PLSA models a joint probability P(f, e) as a mixture of conditionally independent multinomial distributions: � P(c)P(f|c)P(e|c) (2) P (f, e) = c With F = [P(f|c)], E = [P(e|c)] and 5 = diag(P(c)), this is exactly eq. 1. Note also that despite the additional matrix 5, if we</context>
</contexts>
<marker>Lee, Seung, 2001</marker>
<rawString>D. D. Lee and H. S. Seung. 2001. Algorithms for non-negative matrix factorization. In NIPS*13, pages 556–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>T Pedersen</author>
</authors>
<title>An evaluation exercise for word alignment.</title>
<date>2003</date>
<booktitle>In HLT-NAACL</booktitle>
<pages>1--10</pages>
<contexts>
<context position="2328" citStr="Mihalcea and Pedersen, 2003" startWordPosition="353" endWordPosition="356"> a corpus that is already aligned at the sentence level. We show how this problem may be phrased in terms of matrix factorisation. We then identify a number of constraints on word alignment, show that these constraints entail that word alignment is equivalent to orthogonal non-negative matrix factorisation, and we give a novel algorithm that solves this problem. This is illustrated using data from the shared tasks of the 2003 HLT-NAACL Workshop on Building the licence fee does not increase le droit de permis ne augmente pas Figure 1: 1-1, M-1, 1-N and M-N alignments. and Using Parallel Texts (Mihalcea and Pedersen, 2003). 2 Word alignments We address the following problem: Given a source sentence f = fi ... fi ... fI and a target sentence e = el ... ej ... eJ, we wish to find words fi and ej on either side which are aligned, ie in mutual correspondence. Note that words may be aligned without being directly “dictionary translations”. In order to have proper alignments, we want to enforce the following constraints: Coverage: Every word on either side must be aligned to at least one word on the other side (Possibly taking “null” words into account). Transitive closure: If fi is aligned to ej and et, any fk align</context>
<context position="11914" citStr="Mihalcea and Pedersen, 2003" startWordPosition="2022" endWordPosition="2025">roper alignments is undefined. We therefore refine the model, adding a noise component indexed by c = 0: P(f, e) =  P(c)P(f|c)P(e|c) c&gt;0 +P(c = 0)P(f, e|c = 0) The simplest choice for the noise component is a uniform distribution, P(f, e|c = 0)  1. E-step and M-steps in eqs. (3–6) are unchanged for c &gt; 0, and the E-step equation for c = 0 is easily adapted: P(c=0|f, e)  P(c=0)P(f, e|c=0). 5 Example We first illustrate the factorisation process on a simple example. We use the data provided for the French-English shared task of the 2003 HLTNAACL Workshop on Building and Using Parallel Texts (Mihalcea and Pedersen, 2003). The data is from the Canadian Hansard, and reference alignments were originally produced by Franz Och and Hermann Ney (Och and Ney, 2000). Using the entire corpus (20 million words), we trained English—*French and French—*English IBM4 models using GIZA++. For all sentences from the trial and test set (37 and 447 sentences), we generated up to 100 best alignments for each sentence and in each direction. For each pair of source and target words (fZ, ej), the association measure mZj is simply the number of times these words were aligned together in the two N-best lists, leading to a count betwe</context>
<context position="14939" citStr="Mihalcea and Pedersen, 2003" startWordPosition="2554" endWordPosition="2557">ather than eg a larger cept corresponding to a 2-4 alignment, and to produce proper alignments through the use of these cepts. 6 Experiments In order to perform a more systematic evaluation of the use of matrix factorisation for aligning words, we tested this technique on the full trial and test data from the 2003 HLT-NAACL Workshop. Note that the reference data has both “Sure” and “Probable” alignments, with about 77% of all alignments in the latter category. On the other hand, our system proposes only one type of alignment. The evaluation is done using the performance measures described in (Mihalcea and Pedersen, 2003): precision, recall and F-score on the probable and sure alignments, as well as the Alignment Error Rate (AER), which in our case is a weighted average of the recall on the sure alignments and the precision on the probable. Given an alignment A and gold standards 9S and 9P (for sure and probable alignments, respectively): PT = |A n 9T |(8) |A| RT = |A n 9T |(9) |9T| 2|A n 9T |(10) |9T |+ |A| where T is either S or P, and: AER = 1 − |9S|RS + |A|PP (11) |9S |+ |A| Using these measures, we first evaluate the performance on the trial set (37 sentences): as we produce only one type of alignment and</context>
<context position="17940" citStr="Mihalcea and Pedersen, 2003" startWordPosition="3095" endWordPosition="3099">the AIC and BIC criterion for choosing the number of cepts, discounting null alignments. cept1 cept2 cept3 cept4 cept5 cept6 −null −null n e Figure 6: Resulting word-to-cept and word-to-word alignments for sentence 1023. × e−null f−null cept1 cept2 cept3 cept4 cept5 cept6 e−to−cept alignment NULL they need toys and nnment . enfants loisirs besoin jouets NULL ont les de et de . NULL they need toys and nment . We also compared the performance on the 447 test sentences to 1/ the intersection of the alignments produced by the top IBM4 alignments in either directions, and 2/ the best systems from (Mihalcea and Pedersen, 2003). On limited resources, Ralign.EF.1 (Simard and Langlais, 2003) produced the best F-score, as well as the best AER when NULL alignments were taken into account, while XRCE.Nolem.EF.3 (Dejean et al., 2003) produced the best AER when NULL alignments were discounted. Tables 2 and 3 show that ONMF improves on several of these results. In particular, we get better recall and F-score on the probable alignments (and even a better precision than Ralign.EF.1 in table 2). On the other hand, the performance, and in particular the precision, on sure alignments is dismal. We attribute this at least partly </context>
<context position="19248" citStr="Mihalcea and Pedersen, 2003" startWordPosition="3311" endWordPosition="3314"> RP FP AER ONMF + AIC 49.86% 95.12% 65.42% 84.63% 37.39% 51.87% 11.76% ONMF + BIC 46.50% 96.01% 62.65% 80.92% 38.69% 52.35% 14.16% IBM4 intersection 71.46% 90.04% 79.68% 97.66% 28.44% 44.12% 5.71% HLT-03 best F 72.54% 80.61% 76.36% 77.56% 38.19% 51.18% 18.50% HLT-03 best AER 55.43% 93.81% 69.68% 90.09% 35.30% 50.72% 8.53% Table 2: Performance on the 447 English-French test sentences, discounting NULL alignments, for orthogonal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number of cepts. HLT-03 best F is Ralign.EF.1 and best AER is XRCE.Nolem.EF.3 (Mihalcea and Pedersen, 2003). our model enforces coverage and makes sure that all words are aligned, while the “Sure” reference alignments have no such constraints and actually have a very bad coverage. Indeed, less than half the words in the test set have a “Sure” alignment, which means that a method which ensures that all words are aligned will at best have a sub 50% precision. In addition, many reference “Probable” alignments are not proper alignments in the sense defined above. Note that the IBM4 intersection has a bias similar to the sure reference alignments, and performs very well in FS, PP and especially in AER, </context>
<context position="23817" citStr="Mihalcea and Pedersen, 2003" startWordPosition="4054" endWordPosition="4057">. The quality of the resulting alignment greatly depends on the way M is Method PS RS FS PP RP FP AER ONMF + AIC 42.88% 95.12% 59.11% 75.17% 37.20% 49.77% 18.63% ONMF + BIC 40.17% 96.01% 56.65% 72.20% 38.49% 50.21% 20.78% IBM4 intersection 56.39% 90.04% 69.35% 81.14% 28.90% 42.62% 15.43% HLT-03 best 72.54% 80.61% 76.36% 77.56% 36.79% 49.91% 18.50% Table 3: Performance on the 447 English-French test sentences, taking NULL alignments into account, for orthogonal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number of cepts. HLT-03 best is Ralign.EF.1 (Mihalcea and Pedersen, 2003). no NULL alignments with NULL alignments Method PS RS FS AER PS RS FS AER ONMF + AIC 70.34% 65.54% 67.85% 32.15% 62.65% 62.10% 62.38% 37.62% ONMF + BIC 55.88% 67.70% 61.23% 38.77% 51.78% 64.07% 57.27% 42.73% HLT-03 best 82.65% 62.44% 71.14% 28.86% 82.65% 54.11% 65.40% 34.60% Table 4: Performance on the 248 Romanian-English test sentences (only sure alignments), for orthogonal non-negative matrix factorisation (ONMF) using the AIC and BIC criterion for choosing the number of cepts. HLT-03 best is XRCE.Nolem (Mihalcea and Pedersen, 2003). filled. In our experiments we used counts from Nbest ali</context>
</contexts>
<marker>Mihalcea, Pedersen, 2003</marker>
<rawString>R. Mihalcea and T. Pedersen. 2003. An evaluation exercise for word alignment. In HLT-NAACL 2003 Workshop: Building and Using Parallel Texts, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
<author>H Ney</author>
</authors>
<title>A comparison of alignment models for statistical machine translation.</title>
<date>2000</date>
<booktitle>In Proc. COLING’00,</booktitle>
<pages>1086--1090</pages>
<contexts>
<context position="12053" citStr="Och and Ney, 2000" startWordPosition="2045" endWordPosition="2048">f, e|c = 0) The simplest choice for the noise component is a uniform distribution, P(f, e|c = 0)  1. E-step and M-steps in eqs. (3–6) are unchanged for c &gt; 0, and the E-step equation for c = 0 is easily adapted: P(c=0|f, e)  P(c=0)P(f, e|c=0). 5 Example We first illustrate the factorisation process on a simple example. We use the data provided for the French-English shared task of the 2003 HLTNAACL Workshop on Building and Using Parallel Texts (Mihalcea and Pedersen, 2003). The data is from the Canadian Hansard, and reference alignments were originally produced by Franz Och and Hermann Ney (Och and Ney, 2000). Using the entire corpus (20 million words), we trained English—*French and French—*English IBM4 models using GIZA++. For all sentences from the trial and test set (37 and 447 sentences), we generated up to 100 best alignments for each sentence and in each direction. For each pair of source and target words (fZ, ej), the association measure mZj is simply the number of times these words were aligned together in the two N-best lists, leading to a count between 0 (never aligned) and 200 (always aligned). We focus on sentence 1023, from the trial set. Figure 5 shows the reference alignments toget</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. Och and H. Ney. 2000. A comparison of alignment models for statistical machine translation. In Proc. COLING’00, pages 1086–1090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Och</author>
<author>C Tillmann</author>
<author>H Ney</author>
</authors>
<title>Improved alignment models for statistical machine translation.</title>
<date>1999</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>20--28</pages>
<contexts>
<context position="1153" citStr="Och et al., 1999" startWordPosition="167" endWordPosition="170">that factors must satisfy a number of constraints such as orthogonality. We then propose an algorithm for orthogonal non-negative matrix factorisation, based on a probabilistic model of the alignment data, and apply it to word alignment. This is illustrated on a French-English alignment task from the Hansard. 1 Introduction Aligning words from mutually translated sentences in two different languages is an important and difficult problem. It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al., 1999), (Tillmann and Xia, 2003), (Koehn et al., 2003, sec. 3), or for projecting linguistic annotation across languages (Yarowsky et al., 2001). Obtaining a word-aligned corpus usually involves training a word-based translation models (Brown et al., 1993) in each directions and combining the resulting alignments. Besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general Nto-M alignments. In the following section, we introduce the problem of aligning words from a corpus that is already aligned at the sentence lev</context>
</contexts>
<marker>Och, Tillmann, Ney, 1999</marker>
<rawString>F. Och, C. Tillmann, and H. Ney. 1999. Improved alignment models for statistical machine translation. In Proc. EMNLP, pages 20–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Rose</author>
<author>E Gurewitz</author>
<author>G Fox</author>
</authors>
<title>A deterministic annealing approach to clustering.</title>
<date>1990</date>
<journal>Pattern Recognition Letters,</journal>
<volume>11</volume>
<issue>11</issue>
<contexts>
<context position="22549" citStr="Rose et al., 1990" startWordPosition="3855" endWordPosition="3858">e method. It should be noted, however, that ONMF provides the qualitative advantage of producing proper alignments, and in particular ensures coverage. This may be useful in some contexts, eg training a phrasebased translation system. 7 Discussion 7.1 Model selection and stability Like all mixture models, PLSA is subject to local minima. Although using a few random restarts seems to yield good performance, the results on difficult-to-align sentences may still be sensitive to initial conditions. A standard technique to stabilise the EM solution is to use deterministic annealing or tempered EM (Rose et al., 1990). As a side effect, deterministic annealing actually makes model selection easier. At low temperature, all components are identical, and they differentiate as the temperature increases, until the final temperature, where we recover the standard EM algorithm. By keeping track of the component differentiations, we may consider multiple effective numbers of components in one pass, therefore alleviating the need for costly multiple EM runs with different cept numbers and multiple restarts. 7.2 Other association measures ONMF is only a tool to factor the original translation matrix M, containing me</context>
</contexts>
<marker>Rose, Gurewitz, Fox, 1990</marker>
<rawString>K. Rose, E. Gurewitz, and G. Fox. 1990. A deterministic annealing approach to clustering. Pattern Recognition Letters, 11(11):589–594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Schwartz</author>
</authors>
<title>Estimating the dimension of a model.</title>
<date>1978</date>
<journal>The Annals of Statistics,</journal>
<volume>6</volume>
<issue>2</issue>
<contexts>
<context position="9115" citStr="Schwartz, 1978" startWordPosition="1530" endWordPosition="1531">equivalent to having orthogonal factors. The result is therefore an orthogonal, non-negative factorisation of the original translation matrix M. 4.1 Number of cepts In general, the number of cepts is unknown and must be estimated. This corresponds to choosing the number of components in PLSA, a classical model selection problem. The likelihood may not be used as it always increases as components are added. A standard approach to optimise the complexity of a mixture model is to maximise the likelihood, penalised by a term that increases with model complexity, such as AIC (Akaike, 1974) or BIC (Schwartz, 1978). BIC asymptotically chooses the correct model size (for complete models), while AIC always overestimates the number of components, but usually yields good predictive performance. As the largest possible number of cepts is min(I, J), and the smallest is 1 (all fi aligned to all ej), we estimate the optimal number of cepts by maximising AIC or BIC between these two extremes. 4.2 Dealing with null alignments Alignment to a “null” word may be a feature of the underlying statistical model (eg IBM models), or it may be introduced to accommodate words which have a low association measure with all ot</context>
</contexts>
<marker>Schwartz, 1978</marker>
<rawString>G. Schwartz. 1978. Estimating the dimension of a model. The Annals of Statistics, 6(2):461–464.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>P Langlais</author>
</authors>
<title>Statistical translation alignment with compositionality constraints.</title>
<date>2003</date>
<booktitle>In HLT-NAACL</booktitle>
<pages>pages</pages>
<contexts>
<context position="18003" citStr="Simard and Langlais, 2003" startWordPosition="3104" endWordPosition="3107">unting null alignments. cept1 cept2 cept3 cept4 cept5 cept6 −null −null n e Figure 6: Resulting word-to-cept and word-to-word alignments for sentence 1023. × e−null f−null cept1 cept2 cept3 cept4 cept5 cept6 e−to−cept alignment NULL they need toys and nnment . enfants loisirs besoin jouets NULL ont les de et de . NULL they need toys and nment . We also compared the performance on the 447 test sentences to 1/ the intersection of the alignments produced by the top IBM4 alignments in either directions, and 2/ the best systems from (Mihalcea and Pedersen, 2003). On limited resources, Ralign.EF.1 (Simard and Langlais, 2003) produced the best F-score, as well as the best AER when NULL alignments were taken into account, while XRCE.Nolem.EF.3 (Dejean et al., 2003) produced the best AER when NULL alignments were discounted. Tables 2 and 3 show that ONMF improves on several of these results. In particular, we get better recall and F-score on the probable alignments (and even a better precision than Ralign.EF.1 in table 2). On the other hand, the performance, and in particular the precision, on sure alignments is dismal. We attribute this at least partly to a key difference between our model and the reference data: M</context>
</contexts>
<marker>Simard, Langlais, 2003</marker>
<rawString>M. Simard and P. Langlais. 2003. Statistical translation alignment with compositionality constraints. In HLT-NAACL 2003 Workshop: Building and Using Parallel Texts, pages 19–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Tillmann</author>
<author>F Xia</author>
</authors>
<title>A phrase-based unigram model for statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. HLT-NAACL</booktitle>
<contexts>
<context position="1179" citStr="Tillmann and Xia, 2003" startWordPosition="171" endWordPosition="174">tisfy a number of constraints such as orthogonality. We then propose an algorithm for orthogonal non-negative matrix factorisation, based on a probabilistic model of the alignment data, and apply it to word alignment. This is illustrated on a French-English alignment task from the Hansard. 1 Introduction Aligning words from mutually translated sentences in two different languages is an important and difficult problem. It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al., 1999), (Tillmann and Xia, 2003), (Koehn et al., 2003, sec. 3), or for projecting linguistic annotation across languages (Yarowsky et al., 2001). Obtaining a word-aligned corpus usually involves training a word-based translation models (Brown et al., 1993) in each directions and combining the resulting alignments. Besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general Nto-M alignments. In the following section, we introduce the problem of aligning words from a corpus that is already aligned at the sentence level. We show how this probl</context>
</contexts>
<marker>Tillmann, Xia, 2003</marker>
<rawString>C. Tillmann and F. Xia. 2003. A phrase-based unigram model for statistical machine translation. In Proc. HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora. In</title>
<date>2001</date>
<booktitle>Proc. HLT</booktitle>
<contexts>
<context position="1291" citStr="Yarowsky et al., 2001" startWordPosition="188" endWordPosition="191">rix factorisation, based on a probabilistic model of the alignment data, and apply it to word alignment. This is illustrated on a French-English alignment task from the Hansard. 1 Introduction Aligning words from mutually translated sentences in two different languages is an important and difficult problem. It is important because a wordaligned corpus is typically used as a first step in order to identify phrases or templates in phrase-based Machine Translation (Och et al., 1999), (Tillmann and Xia, 2003), (Koehn et al., 2003, sec. 3), or for projecting linguistic annotation across languages (Yarowsky et al., 2001). Obtaining a word-aligned corpus usually involves training a word-based translation models (Brown et al., 1993) in each directions and combining the resulting alignments. Besides processing time, important issues are completeness and propriety of the resulting alignment, and the ability to reliably identify general Nto-M alignments. In the following section, we introduce the problem of aligning words from a corpus that is already aligned at the sentence level. We show how this problem may be phrased in terms of matrix factorisation. We then identify a number of constraints on word alignment, </context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proc. HLT 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>