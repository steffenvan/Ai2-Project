<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000028">
<title confidence="0.9972485">
Multilingual Document Clustering: an Heuristic Approach Based on
Cognate Named Entities
</title>
<author confidence="0.980041">
Soto Montalvo Raquel Martinez Arantza Casillas Victor Fresno
</author>
<affiliation confidence="0.953896">
GAVAB Group NLP&amp;IR Group Dpt. EE GAVAB Group
</affiliation>
<address confidence="0.62052">
URJC UNED UPV-EHU URJC
</address>
<email confidence="0.973723">
soto.montalvo@urjc.es raquel@lsi.uned.es arantza.casillas@ehu.es victor.fresno@urjc.es
</email>
<sectionHeader confidence="0.99268" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902136363636">
This paper presents an approach for Mul-
tilingual Document Clustering in compa-
rable corpora. The algorithm is of heuris-
tic nature and it uses as unique evidence
for clustering the identification of cognate
named entities between both sides of the
comparable corpora. One of the main ad-
vantages of this approach is that it does
not depend on bilingual or multilingual re-
sources. However, it depends on the pos-
sibility of identifying cognate named enti-
ties between the languages used in the cor-
pus. An additional advantage of the ap-
proach is that it does not need any infor-
mation about the right number of clusters;
the algorithm calculates it. We have tested
this approach with a comparable corpus
of news written in English and Spanish.
In addition, we have compared the results
with a system which translates selected
document features. The obtained results
are encouraging.
</bodyText>
<sectionHeader confidence="0.999123" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99962158">
Multilingual Document Clustering (MDC) in-
volves dividing a set of n documents, written in
different languages, into a specified number k of
clusters, so the documents that are similar to other
documents are in the same cluster. Meanwhile
a multilingual cluster is composed of documents
written in different languages, a monolingual clus-
ter is composed of documents written in one lan-
guage.
MDC has many applications. The increasing
amount of documents written in different lan-
guages that are available electronically, leads to
develop applications to manage that amount of
information for filtering, retrieving and grouping
multilingual documents. MDC tools can make
easier tasks such as Cross-Lingual Information
Retrieval, the training of parameters in statistics
based machine translation, or the alignment of par-
allel and non parallel corpora, among others.
MDC systems have developed different solu-
tions to group related documents. The strate-
gies employed can be classified in two main
groups: the ones which use translation technolo-
gies, and the ones that transform the document into
a language-independent representation.
One of the crucial issues regarding the methods
based on document or features translation is the
correctness of the proper translation. Bilingual re-
sources usually suggest more than one sense for
a source word and it is not a trivial task to select
the appropriate one. Although word-sense disam-
biguation methods can be applied, these are not
free of errors. On the other hand, methods based
on language-independent representation also have
limitations. For instance, those based on thesaurus
depend on the thesaurus scope. Numbers or dates
identification can be appropriate for some types
of clustering and documents; however, for other
types of documents or clustering it could not be so
relevant and even it could be a source of noise.
In this work we dealt with MDC and we pro-
posed an approach based only on cognate Named
Entities (NE) identification. We have tested this
approach with a comparable corpus of news writ-
ten in English and Spanish, obtaining encouraging
results. One of the main advantages of this ap-
proach is that it does not depend on multilingual
resources such as dictionaries, machine translation
systems, thesaurus or gazetteers. In addition, no
information about the right number of clusters has
</bodyText>
<page confidence="0.915098">
1145
</page>
<note confidence="0.519555">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1145–1152,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999902263157895">
to be provided to the algorithm. It only depends on
the possibility of identifying cognate named enti-
ties between the languages involved in the corpus.
It could be particularly appropriate for news cor-
pus, where named entities play an important role.
In order to compare the results of our approach
with other based on features translation, we also
dealt with this one, as baseline approach. The sys-
tem uses EuroWordNet (Vossen, 1998) to trans-
late the features. We tried different features cate-
gories and combinations of them in order to deter-
mine which ones lead to improve MDC results in
this approach.
In the following section we relate previous work
in the field. In Section 3 we present our approach
for MDC. Section 4 describes the system we com-
pare our approach with, as well as the experiments
and the results. Finally, Section 5 summarizes the
conclusions and the future work.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999936283950617">
MDC is normally applied with parallel (Silva et.
al., 2004) or comparable corpus (Chen and Lin,
2000), (Rauber et. al., 2001), (Lawrence, 2003),
(Steinberger et. al., 2002), (Mathieu et. al, 2004),
(Pouliquen et. al., 2004). In the case of the com-
parable corpora, the documents usually are news
articles.
Considering the approaches based on transla-
tion technology, two different strategies are em-
ployed: (1) translate the whole document to an an-
chor language, and (2) translate some features of
the document to an anchor language.
With regard to the first approach, some authors
use machine translation systems, whereas others
translate the document word by word consulting
a bilingual dictionary. In (Lawrence, 2003), the
author presents several experiments for clustering
a Russian-English multilingual corpus; several of
these experiments are based on using a machine
translation system. Columbia’s Newsblaster sys-
tem (Kirk et al., 2004) clusters news into events,
it categorizes events into broad topic and summa-
rizes multiple articles on each event. In the clus-
tering process non-English documents are trans-
lated using simple dictionary lookup techniques
for translating Japanese and Russian documents,
and the Systran translation system for the other
languages used in the system.
When the solution involves translating only
some features, first it is necessary to select these
features (usually entities, verbs, nouns) and then
translate them with a bilingual dictionary or/and
consulting a parallel corpus.
In (Mathieu et. al, 2004) before the cluster-
ing process, the authors perform a linguistic anal-
ysis which extracts lemmas and recognizes named
entities (location, organization, person, time ex-
pression, numeric expression, product or event);
then, the documents are represented by a set of
terms (keywords or named entity types). In addi-
tion, they use document frequency to select rele-
vant features among the extracted terms. Finally,
the solution uses bilingual dictionaries to translate
the selected features. In (Rauber et. al., 2001)
the authors present a methodology in which docu-
ments are parsed to extract features: all the words
which appear in n documents except the stop-
words. Then, standard machine translation tech-
niques are used to create a monolingual corpus.
After the translation process the documents are au-
tomatically organized into separate clusters using
an un-supervised neural network.
Some approaches first carry out an independent
clustering in each language, that is a monolingual
clustering, and then they find relations among the
obtained clusters generating the multilingual clus-
ters. Others solutions start with a multilingual
clustering to look for relations between the doc-
uments of all the involved languages. This is the
case of (Chen and Lin, 2000), where the authors
propose an architecture of multilingual news sum-
marizer which includes monolingual and multilin-
gual clustering; the multilingual clustering takes
input from the monolingual clusters. The authors
select different type of features depending on the
clustering: for the monolingual clustering they use
only named entities, for the multilingual clustering
they extract verbs besides named entities.
The strategies that use language-independent
representation try to normalize or standardize the
document contents in a language-neutral way; for
example: (1) by mapping text contents to an inde-
pendent knowledge representation, or (2) by rec-
ognizing language independent text features inside
the documents. Both approaches can be employed
isolated or combined.
The first approach involves the use of exist-
ing multilingual linguistic resources, such as the-
saurus, to create a text representation consisting of
a set of thesaurus items. Normally, in a multilin-
gual thesaurus, elements in different languages are
</bodyText>
<page confidence="0.960119">
1146
</page>
<bodyText confidence="0.999981837209302">
related via language-independent items. So, two
documents written in different languages can be
considered similar if they have similar representa-
tion according to the thesaurus. In some cases, it
is necessary to use the thesaurus in combination
with a machine learning method for mapping cor-
rectly documents onto thesaurus. In (Steinberger
et. al., 2002) the authors present an approach to
calculate the semantic similarity by representing
the document contents in a language independent
way, using the descriptor terms of the multilingual
thesaurus Eurovoc.
The second approach, recognition of language
independent text features, involves the recognition
of elements such as: dates, numbers, and named
entities. In others works, for instance (Silva
et. al., 2004), the authors present a method
based on Relevant Expressions (RE). The RE are
multilingual lexical units of any length automat-
ically extracted from the documents using the
LiPXtractor extractor, a language independent
statistics-based tool. The RE are used as base
features to obtain a reduced set of new features
for the multilingual clustering, but the clusters
obtained are monolingual.
Others works combine recognition of indepen-
dent text features (numbers, dates, names, cog-
nates) with mapping text contents to a thesaurus.
In (Pouliquen et. al., 2004) the cross-lingual
news cluster similarity is based on a linear com-
bination of three types of input: (a) cognates, (b)
automatically detected references of geographical
place names, and (c) the results of a mapping
process onto a multilingual classification system
which maps documents onto the multilingual the-
saurus Eurovoc. In (Steinberger et. al., 2004) it
is proposed to extract language-independent text
features using gazetteers and regular expressions
besides thesaurus and classification systems.
None of the revised works use as unique evi-
dence for multilingual clustering the identification
of cognate named entities between both sides of
the comparable corpora.
</bodyText>
<sectionHeader confidence="0.922243" genericHeader="method">
3 MDC by Cognate NE Identification
</sectionHeader>
<bodyText confidence="0.999974333333333">
We propose an approach for MDC based only
on cognate NE identification. The NEs cate-
gories that we take into account are: PERSON,
ORGANIZATION, LOCATION, and MISCEL-
LANY. Other numerical categories such as DATE,
TIME or NUMBER are not considered because
we think they are less relevant regarding the con-
tent of the document. In addition, they can lead to
group documents with few content in common.
The process has two main phases: (1) cognate
NE identification and (2) clustering. Both phases
are described in detail in the following sections.
</bodyText>
<subsectionHeader confidence="0.984693">
3.1 Cognate NE identification
</subsectionHeader>
<bodyText confidence="0.865066">
This phase consists of three steps:
</bodyText>
<listItem confidence="0.931399">
1. Detection and classification of the NEs in
each side of the corpus.
2. Identification of cognates between the NEs of
both sides of the comparable corpus.
3. To work out a statistic of the number of docu-
ments that share cognates of the different NE
categories.
</listItem>
<bodyText confidence="0.999451857142857">
Regarding the first step, it is carried out in each
side of the corpus separately. In our case we used
a corpus with morphosyntactical annotations and
the NEs identified and classified with the FreeLing
tool (Carreras et al., 2004).
In order to identify the cognates between NEs 4
steps are carried out:
</bodyText>
<listItem confidence="0.836309833333333">
• Obtaining two list of NEs, one for each lan-
guage.
• Identification of entity mentions in each lan-
guage. For instance, “Ernesto Zedillo”,
“Zedillo”, “Sr. Zedillo” will be considered
as the same entity after this step since they
</listItem>
<bodyText confidence="0.9356275">
refer to the same person. This step is only
applied to entities of PERSON category. The
identification of NE mentions, as well as cog-
nate NE, is based on the use of the Leven-
shtein edit-distance function (LD). This mea-
sure is obtained by finding the cheapest way
to transform one string into another. Trans-
formations are the one-step operations of in-
sertion, deletion and substitution. The result
is an integer value that is normalized by the
length of the longest string. In addition, con-
straints regarding the number of words that
the NEs are made up, as well as the order of
the words are applied.
</bodyText>
<listItem confidence="0.999332">
• Identification of cognates between the NEs
of both sides of the comparable corpus. It
is also based on the LD. In addition, also
</listItem>
<page confidence="0.986083">
1147
</page>
<bodyText confidence="0.999294333333333">
constraints regarding the number and the or-
der of the words are applied. First, we tried
cognate identification only between NEs of
the same category (PERSON with PERSON,
... ) or between any category and MISCEL-
LANY (PERSON with MISCELLANY,...).
Next, with the rest of NEs that have not been
considered as cognate, a next step is applied
without the constraint of being to the same
category or MISCELLANY. As result of this
step a list of corresponding bilingual cog-
nates is obtained.
</bodyText>
<listItem confidence="0.6275285">
• The same procedure carried out for obtaining
bilingual cognates is used to obtain two more
lists of cognates, one per language, between
the NEs of the same language.
</listItem>
<bodyText confidence="0.996475833333333">
Finally, a statistic of the number of documents
that share cognates of the different NE categories
is worked out. This information can be used by the
algorithm (or the user) to select the NE category
used as constraint in the clustering steps 1(a) and
2(b).
</bodyText>
<subsectionHeader confidence="0.998916">
3.2 Clustering
</subsectionHeader>
<bodyText confidence="0.9992988">
The algorithm for clustering multilingual docu-
ments based on cognate NEs is of heuristic nature.
It consists of 3 main phases: (1) first clusters cre-
ation, (2) addition of remaining documents to ex-
isting clusters, and (3) final cluster adjustment.
</bodyText>
<listItem confidence="0.9897156">
1. First clusters creation. This phase consists of
2 steps.
(a) First, documents in different languages
that have more cognates in common
than a threshold are grouped into the
same cluster. In addition, at least one of
the cognates has to be of a specific cate-
gory (PERSON, LOCATION or ORGA-
NIZATION), and the number of men-
tions has to be similar; a threshold de-
termines the similarity degree. After
this step some documents are assigned
to clusters while the others are free (with
no cluster assigned).
(b) Next, it is tried to assign each free docu-
</listItem>
<bodyText confidence="0.884289339622642">
ment to an existing cluster. This is pos-
sible if there is a document in the cluster
that has more cognates in common with
the free document than a threshold, with
no constraints regarding the NE cate-
gory. If it is not possible, a new clus-
ter is created. This step can also have as
result free documents.
At this point the number of clusters created is
fixed for the next phase.
2. Addition of the rest of the documents to ex-
isting clusters. This phase is carried out in 2
steps.
(a) A document is added to a cluster that
contains a document which has more
cognates in common than a threshold.
(b) Until now, the cognate NEs have been
compared between both sides of the cor-
pus, that is a bilingual comparison. In
this step, the NEs of a language are com-
pared with those of the same language.
This can be described like a monolin-
gual comparison step. The aim is to
group similar documents of the same
language if the bilingual comparison
steps have not been successful. As in
the other cases, a document is added to
a cluster with at least a document of the
same language which has more cognates
in common than a threshold. In addi-
tion, at least one of the cognates have to
be of a specific category (PERSON, LO-
CATION or ORGANIZATION).
3. Final cluster adjustment. Finally, if there are
still free documents, each one is assigned to
the cluster with more cognates in common,
without constraints or threshold. Nonethe-
less, if free documents are left because they
do not have any cognates in common with
those assigned to the existing clusters, new
clusters can be created.
Most of the thresholds can be customized in or-
der to permit and make the experiments easier. In
addition, the parameters customization allows the
adaptation to different type of corpus or content.
For example, in steps 1(a) and 2(b) we enforce at
least on match in a specific NE category. This pa-
rameter can be customized in order to guide the
grouping towards some type of NE. In Section 4.5
the exact values we used are described.
Our approach is an heuristic method that fol-
lowing an agglomerative approach and in an it-
erative way, decides the number of clusters and
</bodyText>
<page confidence="0.984775">
1148
</page>
<bodyText confidence="0.9996165">
locates each document in a cluster; everything is
based in cognate NEs identification. The final
number of clusters depends on the threshold val-
ues.
</bodyText>
<sectionHeader confidence="0.99765" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999891">
We wanted not only determine whether our ap-
proach was successful for MDC or not, but we also
wanted to compare its results with other approach
based on feature translation. That is why we try
MDC by selecting and translating the features of
the documents.
In this Section, first the MCD by feature transla-
tion is described; next, the corpus, the experiments
and the results are presented.
</bodyText>
<subsectionHeader confidence="0.985359">
4.1 MDC by Feature Translation
</subsectionHeader>
<bodyText confidence="0.8618685625">
In this approach we emphasize the feature selec-
tion based on NEs identification and the grammat-
ical category of the words. The selection of fea-
tures we applied is based on previous work (Casil-
las et. al, 2004), in which several document rep-
resentations are tested in order to study which of
them lead to better monolingual clustering results.
We used this MDC approach as baseline method.
The approach we implemented consists of the
following steps:
1. Selection of features (NE, noun, verb, adjec-
tive, ...) and its context (the whole document
or the first paragraph). Normally, the journal-
ist style includes the heart of the news in the
first paragraph; taking this into account we
have experimented with the whole document
and only with the first paragraph.
2. Translation of the features by using Eu-
roWordNet 1.0. We translate English into
Spanish. When more than one sense for a
single word is provided, we disambiguate by
selecting one sense if it appears in the Span-
ish corpus. Since we work with a comparable
corpus, we expect that the correct translation
of a word appears in it.
3. In order to generate the document represen-
tation we use the TF-IDF function to weight
the features.
4. Use of an clustering algorithm. Particu-
larly, we used a partitioning algorithm of the
CLUTO (Karypis, 2002) library for cluster-
ing.
</bodyText>
<subsectionHeader confidence="0.987206">
4.2 Corpus
</subsectionHeader>
<bodyText confidence="0.999973333333333">
A Comparable Corpus is a collection of simi-
lar texts in different languages or in different va-
rieties of a language. In this work we com-
piled a collection of news written in Spanish and
English belonging to the same period of time.
The news are categorized and come from the
news agency EFE compiled by HERMES project
(http://nlp.uned.es/hermes/index.html). That col-
lection can be considered like a comparable cor-
pus. We have used three subset of that collection.
The first subset, call S1, consists on 65 news, 32
in Spanish and 33 in English; we used it in order
to train the threshold values. The second one, S2,
is composed of 79 Spanish news and 70 English
news, that is 149 news. The third subset, S3, con-
tains 179 news: 93 in Spanish and 86 in English.
In order to test the MDC results we carried out a
manual clustering with each subset. Three persons
read every document and grouped them consider-
ing the content of each one. They judged inde-
pendently and only the identical resultant clusters
were selected. The human clustering solution is
composed of 12 clusters for subset S1, 26 clus-
ters for subset S2, and 33 clusters for S3. All the
clusters are multilingual in the three subsets.
In the experimentation process of our approach
the first subset, S1, was used to train the parame-
ters and threshold values; with the second one and
the third one the best parameters values were ap-
plied.
</bodyText>
<subsectionHeader confidence="0.997401">
4.3 Evaluation metric
</subsectionHeader>
<bodyText confidence="0.9999935">
The quality of the experimentation results are de-
termined by means of an external evaluation mea-
sure, the F-measure (van Rijsbergen, 1974). This
measure compares the human solution with the
system one. The F-measure combines the preci-
sion and recall measures:
</bodyText>
<equation confidence="0.997932333333333">
_ 2 x Recall(i, j) x Precision(i, j)
F(i, j) (Precision(i, j) + Recall(i, j)) ,
(1)
</equation>
<bodyText confidence="0.953479142857143">
where Recall(i, j) = nij
ni , P recision(i, j) = nij
nj ,
nij is the number of members of cluster human so-
lution i in cluster j, nj is the number of members
of cluster j and ni is the number of members of
cluster human solution i. For all the clusters:
</bodyText>
<equation confidence="0.8162365">
max{F(i)} (2)
The closer to 1 the F-measure value the better.
F =�
i
ni
n
</equation>
<page confidence="0.980229">
1149
</page>
<subsectionHeader confidence="0.9701965">
4.4 Experiments and Results with MDC by
Feature Translation
</subsectionHeader>
<bodyText confidence="0.999962533333333">
After trying with features of different grammatical
categories and combinations of them, Table 1 and
Table 2 only show the best results of the experi-
ments.
The first column of both tables indicates the
features used in clustering: NOM (nouns), VER
(verbs), ADJ (adjectives), ALL (all the lemmas),
NE (named entities), and 1&amp;quot;&apos; PAR (those of the
first paragraph of the previous categories). The
second column is the F-measure, and the third one
indicates the number of multilingual clusters ob-
tained. Note that the number of total clusters of
each subset is provided to the clustering algorithm.
As can be seen in the tables, the results depend on
the features selected.
</bodyText>
<subsectionHeader confidence="0.9183785">
4.5 Experiments and Results with MDC by
Cognate NE
</subsectionHeader>
<bodyText confidence="0.785857347826087">
The threshold for the LD in order to determine
whether two NEs are cognate or not is 0.2, except
for entities of ORGANIZATION and LOCATION
categories which is 0.3 when they have more than
one word.
Regarding the thresholds of the clustering phase
(Section 3.2), after training the thresholds with the
collection S1 of 65 news articles we have con-
cluded:
• The first step in the clustering phase, 1(a),
performs a good first grouping with thresh-
old relatively high; in this case 6 or 7. That
is, documents in different languages that have
more cognates in common than 6 or 7 are
grouped into the same cluster. In addition,
at least one of the cognates have to be of an
specific category, and the difference between
the number of mentions have to be equal or
less than 2. Of course, these threshold are ap-
plied after checking that there are documents
that meet the requirements. If they do not,
thresholds are reduced. This first step creates
multilingual clusters with high cohesiveness.
</bodyText>
<listItem confidence="0.983263142857143">
• Steps 1(b) and 2(a) lead to good results with
small threshold values: 1 or 2. They are de-
signed to give priority to the addition of doc-
uments to existing clusters. In fact, only step
1(b) can create new clusters.
• Step 2(b) tries to group similar documents of
the same language when the bilingual com-
</listItem>
<bodyText confidence="0.999092608695652">
parison steps could not be able to deal with
them. This step leads to good results with a
threshold value similar to 1(a) step, and with
the same NE category.
On the other hand, regarding the NE category
enforce on match in steps 1(a) and 2(b), we tried
with the two NE categories of cognates shared by
the most number of documents. Particularly, with
S2 and S3 corpus the NE categories of the cog-
nates shared by the most number of documents
was LOCATION followed by PERSON. We ex-
perimented with both categories.
Table 3 and Table 4 show the results of the ap-
plication of the cognate NE approach to subsets
S2 and S3 respectively. The first column of both
tables indicates the thresholds for each step of the
algorithm. Second and third columns show the re-
sults by selecting PERSON category as NE cat-
egory to be shared by at least a cognate in steps
1(a) and 2(b); whereas fourth and fifth columns are
calculated with LOCATION NE category. The re-
sults are quite similar but slightly better with LO-
CATION category, that is the cognate NE category
shared by the most number of documents. Al-
though none of the results got the exact number of
clusters, it is remarkable that the resulting values
are close to the right ones. In fact, no information
about the right number of cluster is provided to the
algorithm.
If we compare the performance of the two ap-
proaches (Table 3 with Table 1 and Table 4 with
Table 2) our approach obtains better results. With
the subset S3 the results of the F-measure of both
approaches are more similar than with the subset
S2, but the F-measure values of our approach are
still slightly better.
To sum up, our approach obtains slightly bet-
ter results that the one based on feature translation
with the same corpora. In addition, the number of
multilingual clusters is closer to the reference so-
lution. We think that it is remarkable that our ap-
proach reaches results that can be comparable with
those obtained by means of features translation.
We will have to test the algorithm with different
corpora (with some monolingual clusters, differ-
ent languages) in order to confirm its performance.
</bodyText>
<sectionHeader confidence="0.998744" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.9936955">
We have presented a novel approach for Multilin-
gual Document Clustering based only on cognate
</bodyText>
<page confidence="0.958962">
1150
</page>
<table confidence="0.9996072">
Selected Features F-measure Multilin. Clus./Total
NOM, VER 0.8533 21/26
NOM, ADJ 0.8405 21/26
ALL 0.8209 21/26
NE 0.8117 19/26
NOM, VER, ADJ 0.7984 20/26
NOM, VER, ADJ, 1rst PAR 0.7570 21/26
NOM, ADJ, 1rst PAR 0.7515 22/26
ALL, 1rst PAR 0.7473 19/26
NOM, VER, 1rst PAR 0.7371 20/26
</table>
<tableCaption confidence="0.990996">
Table 1: MDC results with the feature translation approach and subset S2
</tableCaption>
<table confidence="0.9995627">
Selected Features F-measure Multilin. Clus. /Total
NOM, ADJ 0.8291 26/33
ALL 0.8126 27/33
NOM, VER 0.8028 26/33
NE 0.8015 23/33
NOM, VER, ADJ 0.7917 25/33
NOM, ADJ, 1rst PAR 0.7520 28/33
NOM, VER, ADJ, 1rst PAR 0.7484 26/33
ALL, 1rst PAR 0.7288 26/33
NOM, VER, 1rst PAR 0.7200 24/33
</table>
<tableCaption confidence="0.913309">
Table 2: MDC results with the feature translation approach and subset S3
</tableCaption>
<table confidence="0.781316">
Thresholds 1(a), 2(b) match on PERSON 1(a), 2(b) match on LOCATION
Steps Results Clusters Results Clusters
1(a) 1(b) 2(a) 2(b) F-measure Multil./Calc./Total F-measure Multil./Calc./Total
</table>
<figure confidence="0.985551375">
6 2 1 5 0.9097 24/24/26 0.9097 24/24/26
6 2 1 6 0.8961 24/24/26 0.8961 24/24/26
6 2 1 7 0.8955 24/24/26 0.8955 24/24/26
6 2 2 5 0.8861 24/24/26 0.8913 24/24/26
7 2 1 5 0.8859 24/24/26 0.8913 24/24/26
6 2 2 4 0.8785 24/24/26 0.8899 24/24/26
6 2 2 6 0.8773 24/24/26 0.8833 24/24/26
6 2 2 7 0.8773 24/24/26 0.8708 24/24/26
</figure>
<tableCaption confidence="0.926202">
Table 3: MDC results with the cognate NE approach and S2 subset
</tableCaption>
<table confidence="0.61485325">
Thresholds 1(a), 2(b) match on PERSON 1(a), 2(b) match on LOCATION
Steps Results Clusters Results Clusters
1(a) 1(b) 2(a) 2(b) F-measure Multil./Calc./Total F-measure Multil./Calc./Total
7 2 1 5 0.8587 30/30/33 0.8621 30/30/33
</table>
<figure confidence="0.992342714285714">
6 2 1 5 0.8552 30/30/33 0.8552 30/30/33
6 2 1 6 0.8482 30/30/33 0.8483 30/30/33
6 2 1 7 0.8471 30/30/33 0.8470 30/30/33
6 2 2 5 0.8354 30/30/33 0.8393 30/30/33
6 2 2 6 0.8353 30/30/33 0.8474 30/30/33
6 2 2 4 0.8323 30/30/33 0.8474 30/30/33
6 2 2 7 0.8213 30/30/33 0.8134 30/30/33
</figure>
<tableCaption confidence="0.988133">
Table 4: MDC results with the cognate NE approach and S3 subset
</tableCaption>
<page confidence="0.990862">
1151
</page>
<bodyText confidence="0.999975137931035">
named entities identification. One of the main ad-
vantages of this approach is that it does not depend
on multilingual resources such as dictionaries, ma-
chine translation systems, thesaurus or gazetteers.
The only requirement to fulfill is that the lan-
guages involved in the corpus have to permit the
possibility of identifying cognate named entities.
Another advantage of the approach is that it does
not need any information about the right number
of clusters. In fact, the algorithm calculates it by
using the threshold values of the algorithm.
We have tested this approach with a comparable
corpus of news written in English and Spanish, ob-
taining encouraging results. We think that this ap-
proach could be particularly appropriate for news
articles corpus, where named entities play an im-
portant role. Even more, when there is no previous
evidence of the right number of clusters. In addi-
tion, we have compared our approach with other
based on feature translation, resulting that our ap-
proach presents a slightly better performance.
Future work will include the compilation of
more corpora, the incorporation of machine learn-
ing techniques in order to obtain the thresholds
more appropriate for different type of corpus. In
addition, we will study if changing the order of
the bilingual and monolingual comparison steps
the performance varies significantly for different
type of corpus.
</bodyText>
<sectionHeader confidence="0.996004" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999953">
We wish to thank the anonymous reviewers for
their helpful and instructive comments. This work
has been partially supported by MCyT TIN2005-
08943-C02-02.
</bodyText>
<sectionHeader confidence="0.999277" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999646855072464">
Benoit Mathieu, Romanic Besancon and Christian
Fluhr. 2004. “Multilingual document clusters dis-
covery”. RIAO’2004, p. 1-10.
Arantza Casillas, M. Teresa Gonz´alez de Lena and
Raquel Martinez. 2004. “Sampling and Feature
Selection in a Genetic Algorithm for Document
Clustering”. Computational Linguistics and Intel-
ligent Text Processing, CICLing’04. Lecture Notes
in Computer Science, Springer-Verlag, p. 601-612.
Hsin-Hsi Chen and Chuan-Jie Lin. 2000. “A Multilin-
gual News Summarizer”. Proceedings of 18th Inter-
national Conference on Computational Linguistics,
p. 159-165.
Xavier Carreras, I. Chao, Lluis Padr´o and M.
Padr´o 2004 “An Open-Source Suite of Lan-
guage Analyzers”. Proceedings of the 4th In-
ternational Conference on Language Resources
and Evaluation (LREC’04). Lisbon, Portugal.
http://garraf.epsevg.upc.es/freeling/.
Karypis G. 2002. “ CLUTO: A Clustering Toolkit”.
Technical Report: 02-017. University of Minnesota,
Department of Computer Science, Minneapolis, MN
55455.
David Kirk Evans, Judith L. Klavans and Kathleen
McKeown. 2004. “Columbian Newsblaster: Multi-
lingual News Summarization on the Web”. Proceed-
ings of the Human Language Technology Confer-
ence and the North American Chapter of the Asso-
ciation for Computational Linguistics Annual Meet-
ing, HLT-NAACL’2004.
Lawrence J. Leftin. 2003. “Newsblaster Russian-
English Clustering Performance Analysis”.
Columbia computer science Technical Reports.
Bruno Pouliquen, Ralf Steinberger, Camelia Ignat,
Emilia Ksper and Irina Temikova. 2004. “Multi-
lingual and cross-lineal news topic tracking”. Pro-
ceedings of the 20t International Conference on
computational Linguistics, p. 23-27.
Andreas Rauber, Michael Dittenbach and Dieter Merkl.
2001. “Towards Automatic Content-Based Organi-
zation of Multilingual Digital Libraries: An English,
French, and German View of the Russian Infor-
mation Agency Novosti News”. Third All-Russian
Conference Digital Libraries: Advanced Methods
and Technologies, Digital Collections Petrozavodsk,
RCDI’2001.
van Rijsbergen, C.J. 1974. “Foundations of evalua-
tion”. Journal of Documentation, 30 (1974), p. 365-
373.
Joaquin Silva, J. Mexia, Carlos Coelho and Gabriel
Lopes. 2004. ”A Statistical Approach for Multi-
lingual Document Clustering and Topic Extraction
form Clusters”. Pliska Studia Mathematica Bulgar-
ica, v.16,p. 207-228.
Ralf Steinberger, Bruno Pouliquen, and Johan Scheer.
2002. “Cross-Lingual Document Similarity Cal-
culation Using the Multilingual Thesaurus EU-
ROVOC”. Computational Linguistics and Intelli-
gent Text Processing, CICling’02. Lecture Notes in
Computer Science, Springer-Verlag, p. 415-424.
Ralf Steinberger, Bruno Pouliquen, and Camelia Ignat.
2004. “Exploiting multilingual nomenclatures and
language-independent text features as an interlingua
for cross-lingual text analysis applications”. Slove-
nian Language Technology Conference. Information
Society, SLTC 2004.
Vossen, P. 1998. “Introduction to EuroWordNet”.
Computers and the Humanities Special Issue on Eu-
roWordNet.
</reference>
<page confidence="0.99544">
1152
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.356265">
<title confidence="0.9989205">Multilingual Document Clustering: an Heuristic Approach Based on Cognate Named Entities</title>
<author confidence="0.994071">Soto Montalvo Raquel Martinez Arantza Casillas Victor Fresno</author>
<affiliation confidence="0.9829455">GAVAB Group NLP&amp;IR Group Dpt. EE GAVAB Group URJC UNED UPV-EHU URJC</affiliation>
<abstract confidence="0.973757125">soto.montalvo@urjc.es raquel@lsi.uned.es arantza.casillas@ehu.es victor.fresno@urjc.es Abstract This paper presents an approach for Multilingual Document Clustering in comparable corpora. The algorithm is of heuristic nature and it uses as unique evidence for clustering the identification of cognate named entities between both sides of the comparable corpora. One of the main advantages of this approach is that it does not depend on bilingual or multilingual resources. However, it depends on the possibility of identifying cognate named entities between the languages used in the corpus. An additional advantage of the approach is that it does not need any information about the right number of clusters; the algorithm calculates it. We have tested this approach with a comparable corpus of news written in English and Spanish. In addition, we have compared the results with a system which translates selected document features. The obtained results are encouraging.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Benoit Mathieu</author>
<author>Romanic Besancon</author>
<author>Christian Fluhr</author>
</authors>
<date>2004</date>
<booktitle>Multilingual document clusters discovery”. RIAO’2004,</booktitle>
<pages>1--10</pages>
<marker>Mathieu, Besancon, Fluhr, 2004</marker>
<rawString>Benoit Mathieu, Romanic Besancon and Christian Fluhr. 2004. “Multilingual document clusters discovery”. RIAO’2004, p. 1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arantza Casillas</author>
<author>M Teresa Gonz´alez de Lena</author>
<author>Raquel Martinez</author>
</authors>
<title>Sampling and Feature Selection in a Genetic Algorithm for Document Clustering”.</title>
<date>2004</date>
<booktitle>Computational Linguistics and Intelligent Text Processing, CICLing’04. Lecture Notes in Computer Science,</booktitle>
<pages>601--612</pages>
<publisher>Springer-Verlag,</publisher>
<marker>Casillas, de Lena, Martinez, 2004</marker>
<rawString>Arantza Casillas, M. Teresa Gonz´alez de Lena and Raquel Martinez. 2004. “Sampling and Feature Selection in a Genetic Algorithm for Document Clustering”. Computational Linguistics and Intelligent Text Processing, CICLing’04. Lecture Notes in Computer Science, Springer-Verlag, p. 601-612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hsin-Hsi Chen</author>
<author>Chuan-Jie Lin</author>
</authors>
<title>A Multilingual News Summarizer”.</title>
<date>2000</date>
<booktitle>Proceedings of 18th International Conference on Computational Linguistics,</booktitle>
<pages>159--165</pages>
<contexts>
<context position="4759" citStr="Chen and Lin, 2000" startWordPosition="746" endWordPosition="749">pproach. The system uses EuroWordNet (Vossen, 1998) to translate the features. We tried different features categories and combinations of them in order to determine which ones lead to improve MDC results in this approach. In the following section we relate previous work in the field. In Section 3 we present our approach for MDC. Section 4 describes the system we compare our approach with, as well as the experiments and the results. Finally, Section 5 summarizes the conclusions and the future work. 2 Related Work MDC is normally applied with parallel (Silva et. al., 2004) or comparable corpus (Chen and Lin, 2000), (Rauber et. al., 2001), (Lawrence, 2003), (Steinberger et. al., 2002), (Mathieu et. al, 2004), (Pouliquen et. al., 2004). In the case of the comparable corpora, the documents usually are news articles. Considering the approaches based on translation technology, two different strategies are employed: (1) translate the whole document to an anchor language, and (2) translate some features of the document to an anchor language. With regard to the first approach, some authors use machine translation systems, whereas others translate the document word by word consulting a bilingual dictionary. In </context>
<context position="7453" citStr="Chen and Lin, 2000" startWordPosition="1155" endWordPosition="1158">s except the stopwords. Then, standard machine translation techniques are used to create a monolingual corpus. After the translation process the documents are automatically organized into separate clusters using an un-supervised neural network. Some approaches first carry out an independent clustering in each language, that is a monolingual clustering, and then they find relations among the obtained clusters generating the multilingual clusters. Others solutions start with a multilingual clustering to look for relations between the documents of all the involved languages. This is the case of (Chen and Lin, 2000), where the authors propose an architecture of multilingual news summarizer which includes monolingual and multilingual clustering; the multilingual clustering takes input from the monolingual clusters. The authors select different type of features depending on the clustering: for the monolingual clustering they use only named entities, for the multilingual clustering they extract verbs besides named entities. The strategies that use language-independent representation try to normalize or standardize the document contents in a language-neutral way; for example: (1) by mapping text contents to </context>
</contexts>
<marker>Chen, Lin, 2000</marker>
<rawString>Hsin-Hsi Chen and Chuan-Jie Lin. 2000. “A Multilingual News Summarizer”. Proceedings of 18th International Conference on Computational Linguistics, p. 159-165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>I Chao</author>
<author>Lluis Padr´o</author>
<author>M Padr´o</author>
</authors>
<title>An Open-Source Suite of Language Analyzers”.</title>
<date>2004</date>
<booktitle>Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC’04).</booktitle>
<location>Lisbon, Portugal. http://garraf.epsevg.upc.es/freeling/.</location>
<marker>Carreras, Chao, Padr´o, Padr´o, 2004</marker>
<rawString>Xavier Carreras, I. Chao, Lluis Padr´o and M. Padr´o 2004 “An Open-Source Suite of Language Analyzers”. Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC’04). Lisbon, Portugal. http://garraf.epsevg.upc.es/freeling/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Karypis</author>
</authors>
<title>CLUTO: A Clustering Toolkit”.</title>
<date>2002</date>
<tech>Technical Report: 02-017.</tech>
<pages>55455</pages>
<institution>University of Minnesota, Department of Computer Science,</institution>
<location>Minneapolis, MN</location>
<contexts>
<context position="18406" citStr="Karypis, 2002" startWordPosition="2983" endWordPosition="2984"> experimented with the whole document and only with the first paragraph. 2. Translation of the features by using EuroWordNet 1.0. We translate English into Spanish. When more than one sense for a single word is provided, we disambiguate by selecting one sense if it appears in the Spanish corpus. Since we work with a comparable corpus, we expect that the correct translation of a word appears in it. 3. In order to generate the document representation we use the TF-IDF function to weight the features. 4. Use of an clustering algorithm. Particularly, we used a partitioning algorithm of the CLUTO (Karypis, 2002) library for clustering. 4.2 Corpus A Comparable Corpus is a collection of similar texts in different languages or in different varieties of a language. In this work we compiled a collection of news written in Spanish and English belonging to the same period of time. The news are categorized and come from the news agency EFE compiled by HERMES project (http://nlp.uned.es/hermes/index.html). That collection can be considered like a comparable corpus. We have used three subset of that collection. The first subset, call S1, consists on 65 news, 32 in Spanish and 33 in English; we used it in order</context>
</contexts>
<marker>Karypis, 2002</marker>
<rawString>Karypis G. 2002. “ CLUTO: A Clustering Toolkit”. Technical Report: 02-017. University of Minnesota, Department of Computer Science, Minneapolis, MN 55455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Kirk Evans</author>
<author>Judith L Klavans</author>
<author>Kathleen McKeown</author>
</authors>
<title>Columbian Newsblaster: Multilingual News Summarization on the Web”.</title>
<date>2004</date>
<booktitle>Proceedings of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting, HLT-NAACL’2004.</booktitle>
<marker>Evans, Klavans, McKeown, 2004</marker>
<rawString>David Kirk Evans, Judith L. Klavans and Kathleen McKeown. 2004. “Columbian Newsblaster: Multilingual News Summarization on the Web”. Proceedings of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting, HLT-NAACL’2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence J Leftin</author>
</authors>
<title>Newsblaster RussianEnglish Clustering Performance Analysis”. Columbia computer science</title>
<date>2003</date>
<tech>Technical Reports.</tech>
<marker>Leftin, 2003</marker>
<rawString>Lawrence J. Leftin. 2003. “Newsblaster RussianEnglish Clustering Performance Analysis”. Columbia computer science Technical Reports.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Pouliquen</author>
<author>Ralf Steinberger</author>
</authors>
<title>Camelia Ignat, Emilia Ksper and Irina Temikova.</title>
<date>2004</date>
<booktitle>Proceedings of the 20t International Conference on computational Linguistics,</booktitle>
<pages>23--27</pages>
<marker>Pouliquen, Steinberger, 2004</marker>
<rawString>Bruno Pouliquen, Ralf Steinberger, Camelia Ignat, Emilia Ksper and Irina Temikova. 2004. “Multilingual and cross-lineal news topic tracking”. Proceedings of the 20t International Conference on computational Linguistics, p. 23-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Rauber</author>
<author>Michael Dittenbach</author>
<author>Dieter Merkl</author>
</authors>
<title>Towards Automatic Content-Based Organization of Multilingual Digital Libraries: An English, French, and German View of the Russian Information Agency Novosti News”.</title>
<date>2001</date>
<booktitle>Third All-Russian Conference Digital Libraries: Advanced Methods and Technologies, Digital Collections Petrozavodsk, RCDI’2001.</booktitle>
<marker>Rauber, Dittenbach, Merkl, 2001</marker>
<rawString>Andreas Rauber, Michael Dittenbach and Dieter Merkl. 2001. “Towards Automatic Content-Based Organization of Multilingual Digital Libraries: An English, French, and German View of the Russian Information Agency Novosti News”. Third All-Russian Conference Digital Libraries: Advanced Methods and Technologies, Digital Collections Petrozavodsk, RCDI’2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J van Rijsbergen</author>
</authors>
<title>Foundations of evaluation”.</title>
<date>1974</date>
<journal>Journal of Documentation,</journal>
<volume>30</volume>
<pages>365--373</pages>
<marker>van Rijsbergen, 1974</marker>
<rawString>van Rijsbergen, C.J. 1974. “Foundations of evaluation”. Journal of Documentation, 30 (1974), p. 365-373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joaquin Silva</author>
<author>J Mexia</author>
<author>Carlos Coelho</author>
<author>Gabriel Lopes</author>
</authors>
<title>A Statistical Approach for Multilingual Document Clustering and Topic Extraction form Clusters”. Pliska Studia Mathematica Bulgarica,</title>
<date>2004</date>
<volume>16</volume>
<pages>207--228</pages>
<marker>Silva, Mexia, Coelho, Lopes, 2004</marker>
<rawString>Joaquin Silva, J. Mexia, Carlos Coelho and Gabriel Lopes. 2004. ”A Statistical Approach for Multilingual Document Clustering and Topic Extraction form Clusters”. Pliska Studia Mathematica Bulgarica, v.16,p. 207-228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Johan Scheer</author>
</authors>
<title>Cross-Lingual Document Similarity Calculation Using the Multilingual Thesaurus EUROVOC”.</title>
<date>2002</date>
<booktitle>Computational Linguistics and Intelligent Text Processing, CICling’02. Lecture Notes in Computer Science,</booktitle>
<pages>415--424</pages>
<publisher>Springer-Verlag,</publisher>
<marker>Steinberger, Pouliquen, Scheer, 2002</marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, and Johan Scheer. 2002. “Cross-Lingual Document Similarity Calculation Using the Multilingual Thesaurus EUROVOC”. Computational Linguistics and Intelligent Text Processing, CICling’02. Lecture Notes in Computer Science, Springer-Verlag, p. 415-424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Camelia Ignat</author>
</authors>
<title>Exploiting multilingual nomenclatures and language-independent text features as an interlingua for cross-lingual text analysis applications”. Slovenian Language Technology Conference. Information Society,</title>
<date>2004</date>
<location>SLTC</location>
<marker>Steinberger, Pouliquen, Ignat, 2004</marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, and Camelia Ignat. 2004. “Exploiting multilingual nomenclatures and language-independent text features as an interlingua for cross-lingual text analysis applications”. Slovenian Language Technology Conference. Information Society, SLTC 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<date>1998</date>
<booktitle>Introduction to EuroWordNet”. Computers and the Humanities Special Issue on EuroWordNet.</booktitle>
<contexts>
<context position="4191" citStr="Vossen, 1998" startWordPosition="649" endWordPosition="650">1st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1145–1152, Sydney, July 2006. c�2006 Association for Computational Linguistics to be provided to the algorithm. It only depends on the possibility of identifying cognate named entities between the languages involved in the corpus. It could be particularly appropriate for news corpus, where named entities play an important role. In order to compare the results of our approach with other based on features translation, we also dealt with this one, as baseline approach. The system uses EuroWordNet (Vossen, 1998) to translate the features. We tried different features categories and combinations of them in order to determine which ones lead to improve MDC results in this approach. In the following section we relate previous work in the field. In Section 3 we present our approach for MDC. Section 4 describes the system we compare our approach with, as well as the experiments and the results. Finally, Section 5 summarizes the conclusions and the future work. 2 Related Work MDC is normally applied with parallel (Silva et. al., 2004) or comparable corpus (Chen and Lin, 2000), (Rauber et. al., 2001), (Lawre</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Vossen, P. 1998. “Introduction to EuroWordNet”. Computers and the Humanities Special Issue on EuroWordNet.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>