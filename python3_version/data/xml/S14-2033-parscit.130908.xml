<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013340">
<title confidence="0.982165">
Coooolll: A Deep Learning System for Twitter Sentiment Classification∗
</title>
<author confidence="0.99643">
Duyu Tang†, Furu Wei$, Bing Qin†, Ting Liu†, Ming Zhou$
</author>
<affiliation confidence="0.843998666666667">
†Research Center for Social Computing and Information Retrieval
Harbin Institute of Technology, China
$Microsoft Research, Beijing, China
</affiliation>
<email confidence="0.957818">
{dytang, qinb, tliu}@ir.hit.edu.cn
{fuwei, mingzhou}@microsoft.com
</email>
<sectionHeader confidence="0.993835" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902090909091">
In this paper, we develop a deep learn-
ing system for message-level Twitter sen-
timent classification. Among the 45 sub-
mitted systems including the SemEval
2013 participants, our system (Coooolll)
is ranked 2nd on the Twitter2014 test set
of SemEval 2014 Task 9. Coooolll is
built in a supervised learning framework
by concatenating the sentiment-specific
word embedding (SSWE) features with
the state-of-the-art hand-crafted features.
We develop a neural network with hybrid
loss function 1 to learn SSWE, which en-
codes the sentiment information of tweets
in the continuous representation of words.
To obtain large-scale training corpora, we
train SSWE from 10M tweets collected by
positive and negative emoticons, without
any manual annotation. Our system can
be easily re-implemented with the publicly
available sentiment-specific word embed-
ding.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999484875">
Twitter sentiment classification aims to classify
the sentiment polarity of a tweet as positive, nega-
tive or neutral (Jiang et al., 2011; Hu et al., 2013;
Dong et al., 2014). The majority of existing ap-
proaches follow Pang et al. (2002) and employ ma-
chine learning algorithms to build classifiers from
tweets with manually annotated sentiment polar-
ity. Under this direction, most studies focus on
</bodyText>
<footnote confidence="0.988598875">
∗ This work was partly done when the first author was
visiting Microsoft Research.
1This is one of the three sentiment-specific word embed-
ding learning algorithms proposed in Tang et al. (2014).
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.99982835">
designing effective features to obtain better clas-
sification performance (Pang and Lee, 2008; Liu,
2012; Feldman, 2013). For example, Mohammad
et al. (2013) implement diverse sentiment lexicons
and a variety of hand-crafted features. To leverage
massive tweets containing positive and negative e-
moticons for automatically feature learning, Tang
et al. (2014) propose to learn sentiment-specific
word embedding and Kalchbrenner et al. (2014)
model sentence representation with Dynamic Con-
volutional Neural Network.
In this paper, we develop a deep learning sys-
tem for Twitter sentiment classification. First-
ly, we learn sentiment-specific word embedding
(SSWE) (Tang et al., 2014), which encodes the
sentiment information of text into the continuous
representation of words (Mikolov et al., 2013; Sun
et al., 2014). Afterwards, we concatenate the SS-
WE features with the state-of-the-art hand-crafted
features (Mohammad et al., 2013), and build the
sentiment classifier with the benchmark dataset
from SemEval 2013 (Nakov et al., 2013). To
learn SSWE, we develop a tailored neural net-
work, which incorporates the supervision from
sentiment polarity of tweets in the hybrid loss
function. We learn SSWE from tweets, lever-
aging massive tweets with emoticons as distant-
supervised corpora without any manual annota-
tions.
We evaluate the deep learning system on the
test set of Twitter Sentiment Analysis Track in Se-
mEval 2014 2. Our system (Coooolll) is ranked
2nd on the Twitter2014 test set, along with the
SemEval 2013 participants owning larger train-
ing data than us. The performance of only us-
ing SSWE as features is comparable to the state-
of-the-art hand-crafted features (detailed in Ta-
ble 3), which verifies the effectiveness of the
sentiment-specific word embedding. We release
the sentiment-specific word embedding learned
</bodyText>
<footnote confidence="0.983224">
2http://alt.qcri.org/semeval2014/task9/
</footnote>
<page confidence="0.862064">
208
</page>
<note confidence="0.833671">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 208–212,
Dublin, Ireland, August 23-24, 2014.
</note>
<figureCaption confidence="0.8840565">
Figure 1: Our deep learning system (Coooolll) for
Twitter sentiment classification.
</figureCaption>
<bodyText confidence="0.976793666666667">
from 10 million tweets, which can be easily used
to re-implement our system and adopted off-the-
shell in other sentiment analysis tasks.
</bodyText>
<sectionHeader confidence="0.988952" genericHeader="method">
2 A Deep Learning System
</sectionHeader>
<bodyText confidence="0.99992725">
In this section, we present the details of our deep
learning system for Twitter sentiment classifica-
tion. As illustrated in Figure 1, Coooolll is a su-
pervised learning method that builds the sentimen-
t classifier from tweets with manually annotated
sentiment polarity. In our system, the feature rep-
resentation of tweet is composed of two parts, the
sentiment-specific word embedding features (SS-
WE features) and the state-of-the-art hand-crafted
features (STATE features). In the following parts,
we introduce the SSWE features and STATE fea-
tures, respectively.
</bodyText>
<subsectionHeader confidence="0.982298">
2.1 SSWE Features
</subsectionHeader>
<bodyText confidence="0.9999568125">
In this part, we first describe the neural network
for learning sentiment-specific word embedding.
Then, we generate the SSWE features of a tweet
from the embedding of words it contains.
Our neural network is an extension of the tra-
ditional C&amp;W model (Collobert et al., 2011), as
illustrated in Figure 2. Unlike C&amp;W model that
learns word embedding by only modeling syntac-
tic contexts of words, we develop SSWE., which
captures the sentiment information of sentences as
well as the syntactic contexts of words. Given an
original (or corrupted) ngram and the sentiment
polarity of a sentence as the input, SSWEu predict-
s a two-dimensional vector for each input ngram.
The two scalars (fu0 , fu1 ) stand for language model
score and sentiment score of the input ngram, re-
</bodyText>
<figureCaption confidence="0.832373">
Figure 2: Our neural network (SSWEu) for learn-
ing sentiment-specific word embedding.
</figureCaption>
<bodyText confidence="0.9975355">
spectively. The training objectives of SSWEu are
that (1) the original ngram should obtain a high-
er language model score fu0 (t) than the corrupted
ngram fu0 (tr), and (2) the sentiment score of orig-
inal ngram fu1 (t) should be more consistent with
the gold polarity annotation of sentence than cor-
rupted ngram fu1 (tr). The loss function of SSWEu
is the linear combination of two hinge losses,
</bodyText>
<equation confidence="0.999897">
lossu(t, tr) = α · losscw(t, tr)+ (1)
(1 − α) · lossus (t, tr)
</equation>
<bodyText confidence="0.999113285714286">
where where t is the original ngram, tr is the cor-
rupted ngram which is generated from t with mid-
dle word replaced by a randomly selected one,
losscw(t, tr) is the syntactic loss as given in E-
quation 2, lossus(t, tr) is the sentiment loss as
described in Equation 3. The hyper-parameter α
weighs the two parts.
</bodyText>
<equation confidence="0.9074415">
losscw(t, tr) = max(0, 1 − fcw(t) + fcw(tr))
(2)
</equation>
<bodyText confidence="0.999701142857143">
where Ss(t) is an indicator function reflecting the
sentiment polarity of a sentence, whose value is 1
if the sentiment polarity of tweet t is positive and
-1 if t’s polarity is negative. We train sentiment-
specific word embedding from 10M tweets col-
lected with positive and negative emoticons (Hu
et al., 2013). The details of training phase are de-
scribed in Tang et al. (2014).
After finish learning SSWE, we explore min,
average and max convolutional layers (Collobert
et al., 2011; Socher et al., 2011; Mitchell and Lap-
ata, 2010), to obtain the tweet representation. The
result is the concatenation of vectors derived from
different convolutional layers.
</bodyText>
<figure confidence="0.986722657142857">
Feature
Representation
Sentiment
Classifier
Learning
Algorithm
Training
Data
Massive
Tweets
dimension N
dimension 1
dimension 2
elongated
all-cap
emoticon
....
...
N+1
N+2
...
N+K
....
N
2
1
Embedding
Learning
SSWE
Feature
STATE
Feature
so cooooL :D
syntactic
sentiment
</figure>
<equation confidence="0.638922">
lossus(t, tr) = max(0,1 − Ss(t)fu1 (t)
+ Ss(t)fu1 (tr) ) (3)
</equation>
<page confidence="0.985954">
209
</page>
<subsectionHeader confidence="0.971083">
2.2 STATE Features
</subsectionHeader>
<bodyText confidence="0.99532825">
We re-implement the state-of-the-art hand-crafted
features (Mohammad et al., 2013) for Twitter sen-
timent classification. The STATE features are de-
scribed below.
</bodyText>
<listItem confidence="0.998862541666667">
• All-Caps. The number of words with all char-
acters in upper case.
• Emoticons. We use the presence of positive
(or negative) emoticons and whether the last
unit of a segmentation is emoticon 3.
• Elongated Units. The number of elongated
words (with one character repeated more than
two times), such as gooood.
• Sentiment Lexicon. We utilize several senti-
ment lexicons 4 to generate features. We ex-
plore the number of sentiment words, the s-
core of last sentiment words, the total senti-
ment score and the maximal sentiment score
for each lexicon.
• Negation. The number of individual nega-
tions 5 within a tweet.
• Punctuation. The number of contiguous se-
quences of dot, question mark and exclama-
tion mark.
• Cluster. The presence of words from each
of the 1,000 clusters from the Twitter NLP
tool (Gimpel et al., 2011).
• Ngrams. The presence of word ngrams (1-4)
and character ngrams (3-5).
</listItem>
<sectionHeader confidence="0.99905" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9999404">
We evaluate our deep learning system by applying
it for Twitter sentiment classification within a su-
pervised learning framework. We conduct exper-
iments on both positive/negative/neutral and posi-
tive/negative classification of tweets.
</bodyText>
<footnote confidence="0.857642">
3We use the positive and negative emoticons from Sen-
tiStrength, available at http://sentistrength.wlv.ac.uk/.
4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), N-
RC Emotion (Mohammad and Turney, 2013), NRC Hashtag
and Sentiment140Lexicon (Mohammad et al., 2013).
5http://sentiment.christopherpotts.net/lingstruc.html
</footnote>
<subsectionHeader confidence="0.974847">
3.1 Dataset and Setting
</subsectionHeader>
<bodyText confidence="0.998915733333333">
We train the Twitter sentiment classifier on the
benchmark dataset in SemEval 2013 (Nakov et
al., 2013). The training and development sets were
completely in full to task participants of SemEval
2013. However, we were unable to download al-
l the training and development sets because some
tweets were deleted or not available due to modi-
fied authorization status. The distribution of our
dataset is given in Table 1. We train sentimen-
t classifiers with LibLinear (Fan et al., 2008) on
the training set and dev set, and tune parameter
−c, −wi of SVM on the test set of SemEval 2013.
In both experiment settings, the evaluation met-
ric is the macro-F1 of positive and negative class-
es (Nakov et al., 2013).
</bodyText>
<table confidence="0.99945975">
Positive Negative Neutral Total
Train 2,642 994 3,436 7,072
Dev 408 219 493 1,120
Test 1,570 601 1,639 3,810
</table>
<tableCaption confidence="0.897685">
Table 1: Statistics of our SemEval 2013 Twitter
sentiment classification dataset.
</tableCaption>
<bodyText confidence="0.9907375">
The test sets of SemEval 2014 is directly pro-
vided to the participants, which is composed of
five parts. The statistic of test sets in SemEval
2014 is given in Table 2.
</bodyText>
<table confidence="0.999755333333333">
Positive Negative Neutral Total
T1 427 304 411 1,142
T2 492 394 1,207 2,093
T3 1,572 601 1,640 3,813
T4 982 202 669 1,939
T5 33 40 13 86
</table>
<tableCaption confidence="0.995516">
Table 2: Statistics of SemEval 2014 Twitter senti-
ment classification test set. T1 is LiveJournal2014,
</tableCaption>
<equation confidence="0.5692015">
T2 is SMS2013, T3 is Twitter2013, T4 is Twit-
ter2014, T5 is Twitter2014Sarcasm.
</equation>
<subsectionHeader confidence="0.948963">
3.2 Results and Analysis
</subsectionHeader>
<bodyText confidence="0.999694111111111">
The experiment results of different methods
on positive/negative/neutral and positive/negative
Twitter sentiment classification are listed in Ta-
ble 3. The meanings of T1∼T5 in each column are
described in Table 2. SSWE means the approach
that only utilizes the sentiment-specific word em-
bedding as features for Twitter sentiment classi-
fication. In STATE, we only utilize the existing
features (Mohammad et al., 2013) for building the
</bodyText>
<page confidence="0.99775">
210
</page>
<table confidence="0.99967825">
Method Positive/Negative/Neutral Positive/Negative
T1 T2 T3 T4 T5 T1 T2 T3 T4 T5
SSWE 70.49 64.29 68.69 66.86 50.00 84.51 85.19 85.06 86.14 62.02
Coooolll 72.90 67.68 70.40 70.14 46.66 86.46 85.32 86.01 87.61 56.55
STATE 71.48 65.43 66.18 67.07 44.89 83.96 82.82 84.39 86.16 58.27
W2V 55.19 52.98 52.33 50.58 49.63 68.87 71.89 74.50 71.52 61.60
Top 74.84 70.28 72.12 70.96 58.16 - - - - - - - - - -
Average 63.52 55.63 59.78 60.41 45.44 - - - - - - - - - -
</table>
<tableCaption confidence="0.938543333333333">
Table 3: Macro-F1 of positive and negative classes in positive/negative/neutral and positive/negative
Twitter sentiment classification on the test sets (T1-T5, detailed in Table 2) of SemEval 2014. The
performances of Coooolll on the Twitter-relevant test sets are bold.
</tableCaption>
<bodyText confidence="0.9994173125">
sentiment classifier. In Coooolll, we use the con-
catenation of SSWE features and STATE features.
In W2V, we only use the word embedding learned
from word2vec6 as features. Top and Average are
the top and average performance of the 45 team-
s of SemEval 2014, including the SemEval 2013
participants who owns larger training data.
On positive/negative/neutral classification of
tweets as listed in Table 3 (left table), we find
that the learned sentiment-specific word embed-
ding features (SSWE) performs comparable with
the state-of-the-art hand-crafted features (STATE),
especially on the Twitter-relevant test sets (T3
and T4) 7. After feature combination, Coooolll
yields 4.22% and 3.07% improvement by macro-
F1 on T3 and T4,which verifies the effective-
ness of SSWE by learning discriminate features
from massive data for Twitter sentiment classifi-
cation. From the 45 teams, Coooolll gets the Rank
5/2/3/2 on T1-T4 respectively, along with the Se-
mEval 2013 participants owning larger training
data. We also comparing SSWE with the context-
based word embedding (W2V), which don’t cap-
ture the sentiment supervision of tweets. We find
that W2V is not effective enough for Twitter sen-
timent classification as there is a big gap between
W2V and SSWE on T1-T4. The reason is that W2V
does not capture the sentiment information of text,
which is crucial for sentiment analysis tasks and
effectively leveraged for learning the sentiment-
specific word embedding.
We also conduct experiments on the posi-
</bodyText>
<footnote confidence="0.989509571428572">
6We utilize the Skip-gram model. The embedding is
trained from the 10M tweets collected by positive and neg-
ative emoticons, as same as the training data of SSWE.
7The result of STATE on T3 is different from the results
reported in Mohammad et al. (2013) and Tang et al. (2014)
because we have different training data with the former and
different -wi of SVM with the latter.
</footnote>
<bodyText confidence="0.9998374">
tive/negative classification of tweets. The reason
is that the sentiment-specific word embedding is
learned from the positive/negative supervision of
tweets through emoticons, which is tailored for
positive/negative classification of tweets. From
Table 3 (right table), we find that the performance
of positive/negative Twitter classification is con-
sistent with the performance of 3-class classifica-
tion. SSWE performs comparable to STATE on T3
and T4, and yields better performance (1.62% and
1.45% improvements on T3 and T4, respectively)
through feature combination. SSWE outperform-
s W2V by large margins (more than 10%) on T3
and T4, which further verifies the effectiveness of
sentiment-specific word embedding.
</bodyText>
<sectionHeader confidence="0.996537" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999814">
We develop a deep learning system (Coooolll) for
message-level Twitter sentiment classification in
this paper. The feature representation of Cooool-
ll is composed of two parts, a state-of-the-art
hand-crafted features and the sentiment-specific
word embedding (SSWE) features. The SSWE
is learned from 10M tweets collected by posi-
tive and negative emoticons, without any manu-
al annotation. The effectiveness of Coooolll has
been verified in both positive/negative/neutral and
positive/negative classification of tweets. Among
45 systems of SemEval 2014 Task 9 subtask(b),
Coooolll yields Rank 2 on the Twitter2014 test set,
along with the SemEval 2013 participants owning
larger training data.
</bodyText>
<sectionHeader confidence="0.998285" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.95797675">
We thank Li Dong for helpful discussions. This
work was partly supported by National Natu-
ral Science Foundation of China (No.61133012,
No.61273321, No.61300113).
</bodyText>
<page confidence="0.997772">
211
</page>
<sectionHeader confidence="0.989697" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999714458333334">
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.
Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming
Zhou, and Ke Xu. 2014. Adaptive recursive neural
network for target-dependent twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 49–54.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classification. The Journal of
Machine Learning Research, 9:1871–1874.
Ronen Feldman. 2013. Techniques and application-
s for sentiment analysis. Communications of the
ACM, 56(4):82–89.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: Annotation, features, and experiments.
In Proceedings of the Annual Meeting of the Associ-
ation for Computational Linguistics, pages 42–47.
Ming Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 168–177.
Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu.
2013. Unsupervised sentiment analysis with emo-
tional signals. In Proceedings of the International
World Wide Web Conference, pages 607–618.
Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and
Tiejun Zhao. 2011. Target-dependent twitter sen-
timent classification. The Proceeding of Annual
Meeting of the Association for Computational Lin-
guistics, 1:151–160.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A convolutional neural network for
modelling sentences. In Proceedings of the 52nd
Annual Meeting of the Association for Computation-
al Linguistics, pages 655–665.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word rep-
resentations in vector space. arXiv preprint arX-
iv:1301.3781.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1429.
Saif M Mohammad and Peter D Turney. 2013. Crowd-
sourcing a word–emotion association lexicon. Com-
putational Intelligence, 29(3):436–465.
Saif M Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. Nrc-canada: Building the state-of-
the-art in sentiment analysis of tweets. Proceedings
of the International Workshop on Semantic Evalua-
tion, pages 321–327.
Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva,
Veselin Stoyanov, Alan Ritter, and Theresa Wilson.
2013. Semeval-2013 task 2: Sentiment analysis in
twitter. In Proceedings of the International Work-
shop on Semantic Evaluation, volume 13, pages
312–320.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 79–86.
Richard Socher, Eric H Huang, Jeffrey Pennington,
Andrew Y Ng, and Christopher D Manning. 2011.
Dynamic pooling and unfolding recursive autoen-
coders for paraphrase detection. The Conference
on Neural Information Processing Systems, 24:801–
809.
Yaming Sun, Lei Lin, Duyu Tang, Nan Yang, Zhenzhou
Ji, and Xiaolong Wang. 2014. Radical-enhanced
chinese character embedding. arXiv preprint arX-
iv:1404.4714.
Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting
Liu, and Bing Qin. 2014. Learning sentiment-
specific word embedding for twitter sentiment clas-
sification. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguistic-
s, pages 1555–1565.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing, pages 347–354.
</reference>
<page confidence="0.998492">
212
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.813064">
<title confidence="0.999213">A Deep Learning System for Twitter Sentiment</title>
<author confidence="0.978099">Furu Bing Ting Ming</author>
<affiliation confidence="0.999344">Center for Social Computing and Information Harbin Institute of Technology,</affiliation>
<address confidence="0.981581">Research, Beijing,</address>
<email confidence="0.992808">qinb,</email>
<abstract confidence="0.992783173913043">In this paper, we develop a deep learning system for message-level Twitter sentiment classification. Among the 45 submitted systems including the SemEval participants, our system is ranked 2nd on the Twitter2014 test set of SemEval 2014 Task 9. Coooolll is built in a supervised learning framework by concatenating the sentiment-specific embedding features with the state-of-the-art hand-crafted features. We develop a neural network with hybrid function 1to learn SSWE, which encodes the sentiment information of tweets in the continuous representation of words. To obtain large-scale training corpora, we train SSWE from 10M tweets collected by positive and negative emoticons, without any manual annotation. Our system can be easily re-implemented with the publicly available sentiment-specific word embedding.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="5116" citStr="Collobert et al., 2011" startWordPosition="758" endWordPosition="761">ually annotated sentiment polarity. In our system, the feature representation of tweet is composed of two parts, the sentiment-specific word embedding features (SSWE features) and the state-of-the-art hand-crafted features (STATE features). In the following parts, we introduce the SSWE features and STATE features, respectively. 2.1 SSWE Features In this part, we first describe the neural network for learning sentiment-specific word embedding. Then, we generate the SSWE features of a tweet from the embedding of words it contains. Our neural network is an extension of the traditional C&amp;W model (Collobert et al., 2011), as illustrated in Figure 2. Unlike C&amp;W model that learns word embedding by only modeling syntactic contexts of words, we develop SSWE., which captures the sentiment information of sentences as well as the syntactic contexts of words. Given an original (or corrupted) ngram and the sentiment polarity of a sentence as the input, SSWEu predicts a two-dimensional vector for each input ngram. The two scalars (fu0 , fu1 ) stand for language model score and sentiment score of the input ngram, reFigure 2: Our neural network (SSWEu) for learning sentiment-specific word embedding. spectively. The train</context>
<context position="6996" citStr="Collobert et al., 2011" startWordPosition="1088" endWordPosition="1091">he sentiment loss as described in Equation 3. The hyper-parameter α weighs the two parts. losscw(t, tr) = max(0, 1 − fcw(t) + fcw(tr)) (2) where Ss(t) is an indicator function reflecting the sentiment polarity of a sentence, whose value is 1 if the sentiment polarity of tweet t is positive and -1 if t’s polarity is negative. We train sentimentspecific word embedding from 10M tweets collected with positive and negative emoticons (Hu et al., 2013). The details of training phase are described in Tang et al. (2014). After finish learning SSWE, we explore min, average and max convolutional layers (Collobert et al., 2011; Socher et al., 2011; Mitchell and Lapata, 2010), to obtain the tweet representation. The result is the concatenation of vectors derived from different convolutional layers. Feature Representation Sentiment Classifier Learning Algorithm Training Data Massive Tweets dimension N dimension 1 dimension 2 elongated all-cap emoticon .... ... N+1 N+2 ... N+K .... N 2 1 Embedding Learning SSWE Feature STATE Feature so cooooL :D syntactic sentiment lossus(t, tr) = max(0,1 − Ss(t)fu1 (t) + Ss(t)fu1 (tr) ) (3) 209 2.2 STATE Features We re-implement the state-of-the-art hand-crafted features (Mohammad et</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Dong</author>
<author>Furu Wei</author>
<author>Chuanqi Tan</author>
<author>Duyu Tang</author>
<author>Ming Zhou</author>
<author>Ke Xu</author>
</authors>
<title>Adaptive recursive neural network for target-dependent twitter sentiment classification.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="1377" citStr="Dong et al., 2014" startWordPosition="196" endWordPosition="199">afted features. We develop a neural network with hybrid loss function 1 to learn SSWE, which encodes the sentiment information of tweets in the continuous representation of words. To obtain large-scale training corpora, we train SSWE from 10M tweets collected by positive and negative emoticons, without any manual annotation. Our system can be easily re-implemented with the publicly available sentiment-specific word embedding. 1 Introduction Twitter sentiment classification aims to classify the sentiment polarity of a tweet as positive, negative or neutral (Jiang et al., 2011; Hu et al., 2013; Dong et al., 2014). The majority of existing approaches follow Pang et al. (2002) and employ machine learning algorithms to build classifiers from tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creati</context>
</contexts>
<marker>Dong, Wei, Tan, Tang, Zhou, Xu, 2014</marker>
<rawString>Li Dong, Furu Wei, Chuanqi Tan, Duyu Tang, Ming Zhou, and Ke Xu. 2014. Adaptive recursive neural network for target-dependent twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="9648" citStr="Fan et al., 2008" startWordPosition="1505" endWordPosition="1508">C Hashtag and Sentiment140Lexicon (Mohammad et al., 2013). 5http://sentiment.christopherpotts.net/lingstruc.html 3.1 Dataset and Setting We train the Twitter sentiment classifier on the benchmark dataset in SemEval 2013 (Nakov et al., 2013). The training and development sets were completely in full to task participants of SemEval 2013. However, we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status. The distribution of our dataset is given in Table 1. We train sentiment classifiers with LibLinear (Fan et al., 2008) on the training set and dev set, and tune parameter −c, −wi of SVM on the test set of SemEval 2013. In both experiment settings, the evaluation metric is the macro-F1 of positive and negative classes (Nakov et al., 2013). Positive Negative Neutral Total Train 2,642 994 3,436 7,072 Dev 408 219 493 1,120 Test 1,570 601 1,639 3,810 Table 1: Statistics of our SemEval 2013 Twitter sentiment classification dataset. The test sets of SemEval 2014 is directly provided to the participants, which is composed of five parts. The statistic of test sets in SemEval 2014 is given in Table 2. Positive Negative</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. The Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and applications for sentiment analysis.</title>
<date>2013</date>
<journal>Communications of the ACM,</journal>
<volume>56</volume>
<issue>4</issue>
<contexts>
<context position="2127" citStr="Feldman, 2013" startWordPosition="309" endWordPosition="310">with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to obtain better classification performance (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). For example, Mohammad et al. (2013) implement diverse sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sentiment informatio</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and applications for sentiment analysis. Communications of the ACM, 56(4):82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: Annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>42--47</pages>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: Annotation, features, and experiments. In Proceedings of the Annual Meeting of the Association for Computational Linguistics, pages 42–47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="8958" citStr="Hu and Liu, 2004" startWordPosition="1400" endWordPosition="1403">uences of dot, question mark and exclamation mark. • Cluster. The presence of words from each of the 1,000 clusters from the Twitter NLP tool (Gimpel et al., 2011). • Ngrams. The presence of word ngrams (1-4) and character ngrams (3-5). 3 Experiments We evaluate our deep learning system by applying it for Twitter sentiment classification within a supervised learning framework. We conduct experiments on both positive/negative/neutral and positive/negative classification of tweets. 3We use the positive and negative emoticons from SentiStrength, available at http://sentistrength.wlv.ac.uk/. 4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion (Mohammad and Turney, 2013), NRC Hashtag and Sentiment140Lexicon (Mohammad et al., 2013). 5http://sentiment.christopherpotts.net/lingstruc.html 3.1 Dataset and Setting We train the Twitter sentiment classifier on the benchmark dataset in SemEval 2013 (Nakov et al., 2013). The training and development sets were completely in full to task participants of SemEval 2013. However, we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status. The distribution of our dat</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Ming Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xia Hu</author>
<author>Jiliang Tang</author>
<author>Huiji Gao</author>
<author>Huan Liu</author>
</authors>
<title>Unsupervised sentiment analysis with emotional signals.</title>
<date>2013</date>
<booktitle>In Proceedings of the International World Wide Web Conference,</booktitle>
<pages>607--618</pages>
<contexts>
<context position="1357" citStr="Hu et al., 2013" startWordPosition="192" endWordPosition="195">f-the-art hand-crafted features. We develop a neural network with hybrid loss function 1 to learn SSWE, which encodes the sentiment information of tweets in the continuous representation of words. To obtain large-scale training corpora, we train SSWE from 10M tweets collected by positive and negative emoticons, without any manual annotation. Our system can be easily re-implemented with the publicly available sentiment-specific word embedding. 1 Introduction Twitter sentiment classification aims to classify the sentiment polarity of a tweet as positive, negative or neutral (Jiang et al., 2011; Hu et al., 2013; Dong et al., 2014). The majority of existing approaches follow Pang et al. (2002) and employ machine learning algorithms to build classifiers from tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence de</context>
<context position="6823" citStr="Hu et al., 2013" startWordPosition="1059" endWordPosition="1062">ed ngram which is generated from t with middle word replaced by a randomly selected one, losscw(t, tr) is the syntactic loss as given in Equation 2, lossus(t, tr) is the sentiment loss as described in Equation 3. The hyper-parameter α weighs the two parts. losscw(t, tr) = max(0, 1 − fcw(t) + fcw(tr)) (2) where Ss(t) is an indicator function reflecting the sentiment polarity of a sentence, whose value is 1 if the sentiment polarity of tweet t is positive and -1 if t’s polarity is negative. We train sentimentspecific word embedding from 10M tweets collected with positive and negative emoticons (Hu et al., 2013). The details of training phase are described in Tang et al. (2014). After finish learning SSWE, we explore min, average and max convolutional layers (Collobert et al., 2011; Socher et al., 2011; Mitchell and Lapata, 2010), to obtain the tweet representation. The result is the concatenation of vectors derived from different convolutional layers. Feature Representation Sentiment Classifier Learning Algorithm Training Data Massive Tweets dimension N dimension 1 dimension 2 elongated all-cap emoticon .... ... N+1 N+2 ... N+K .... N 2 1 Embedding Learning SSWE Feature STATE Feature so cooooL :D sy</context>
</contexts>
<marker>Hu, Tang, Gao, Liu, 2013</marker>
<rawString>Xia Hu, Jiliang Tang, Huiji Gao, and Huan Liu. 2013. Unsupervised sentiment analysis with emotional signals. In Proceedings of the International World Wide Web Conference, pages 607–618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>The Proceeding of Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1--151</pages>
<contexts>
<context position="1340" citStr="Jiang et al., 2011" startWordPosition="188" endWordPosition="191">res with the state-of-the-art hand-crafted features. We develop a neural network with hybrid loss function 1 to learn SSWE, which encodes the sentiment information of tweets in the continuous representation of words. To obtain large-scale training corpora, we train SSWE from 10M tweets collected by positive and negative emoticons, without any manual annotation. Our system can be easily re-implemented with the publicly available sentiment-specific word embedding. 1 Introduction Twitter sentiment classification aims to classify the sentiment polarity of a tweet as positive, negative or neutral (Jiang et al., 2011; Hu et al., 2013; Dong et al., 2014). The majority of existing approaches follow Pang et al. (2002) and employ machine learning algorithms to build classifiers from tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organ</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, Xiaohua Liu, and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. The Proceeding of Annual Meeting of the Association for Computational Linguistics, 1:151–160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A convolutional neural network for modelling sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>655--665</pages>
<contexts>
<context position="2448" citStr="Kalchbrenner et al. (2014)" startWordPosition="352" endWordPosition="355">r a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to obtain better classification performance (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). For example, Mohammad et al. (2013) implement diverse sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sentiment information of text into the continuous representation of words (Mikolov et al., 2013; Sun et al., 2014). Afterwards, we concatenate the SSWE features with the state-of-the-art hand-crafted features (Mohammad et al., 2013), and build the sentiment classifier with the benchmark dataset from SemEval 2013 (Nakov et al., 2013). To le</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 655–665.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="2111" citStr="Liu, 2012" startWordPosition="307" endWordPosition="308">rom tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to obtain better classification performance (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). For example, Mohammad et al. (2013) implement diverse sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sent</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</title>
<date>2013</date>
<contexts>
<context position="2802" citStr="Mikolov et al., 2013" startWordPosition="404" endWordPosition="407"> sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sentiment information of text into the continuous representation of words (Mikolov et al., 2013; Sun et al., 2014). Afterwards, we concatenate the SSWE features with the state-of-the-art hand-crafted features (Mohammad et al., 2013), and build the sentiment classifier with the benchmark dataset from SemEval 2013 (Nakov et al., 2013). To learn SSWE, we develop a tailored neural network, which incorporates the supervision from sentiment polarity of tweets in the hybrid loss function. We learn SSWE from tweets, leveraging massive tweets with emoticons as distantsupervised corpora without any manual annotations. We evaluate the deep learning system on the test set of Twitter Sentiment Analy</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="7045" citStr="Mitchell and Lapata, 2010" startWordPosition="1096" endWordPosition="1100"> The hyper-parameter α weighs the two parts. losscw(t, tr) = max(0, 1 − fcw(t) + fcw(tr)) (2) where Ss(t) is an indicator function reflecting the sentiment polarity of a sentence, whose value is 1 if the sentiment polarity of tweet t is positive and -1 if t’s polarity is negative. We train sentimentspecific word embedding from 10M tweets collected with positive and negative emoticons (Hu et al., 2013). The details of training phase are described in Tang et al. (2014). After finish learning SSWE, we explore min, average and max convolutional layers (Collobert et al., 2011; Socher et al., 2011; Mitchell and Lapata, 2010), to obtain the tweet representation. The result is the concatenation of vectors derived from different convolutional layers. Feature Representation Sentiment Classifier Learning Algorithm Training Data Massive Tweets dimension N dimension 1 dimension 2 elongated all-cap emoticon .... ... N+1 N+2 ... N+K .... N 2 1 Embedding Learning SSWE Feature STATE Feature so cooooL :D syntactic sentiment lossus(t, tr) = max(0,1 − Ss(t)fu1 (t) + Ss(t)fu1 (tr) ) (3) 209 2.2 STATE Features We re-implement the state-of-the-art hand-crafted features (Mohammad et al., 2013) for Twitter sentiment classification.</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing a word–emotion association lexicon.</title>
<date>2013</date>
<journal>Computational Intelligence,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="9027" citStr="Mohammad and Turney, 2013" startWordPosition="1412" endWordPosition="1415">. The presence of words from each of the 1,000 clusters from the Twitter NLP tool (Gimpel et al., 2011). • Ngrams. The presence of word ngrams (1-4) and character ngrams (3-5). 3 Experiments We evaluate our deep learning system by applying it for Twitter sentiment classification within a supervised learning framework. We conduct experiments on both positive/negative/neutral and positive/negative classification of tweets. 3We use the positive and negative emoticons from SentiStrength, available at http://sentistrength.wlv.ac.uk/. 4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion (Mohammad and Turney, 2013), NRC Hashtag and Sentiment140Lexicon (Mohammad et al., 2013). 5http://sentiment.christopherpotts.net/lingstruc.html 3.1 Dataset and Setting We train the Twitter sentiment classifier on the benchmark dataset in SemEval 2013 (Nakov et al., 2013). The training and development sets were completely in full to task participants of SemEval 2013. However, we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status. The distribution of our dataset is given in Table 1. We train sentiment classifiers with LibLine</context>
</contexts>
<marker>Mohammad, Turney, 2013</marker>
<rawString>Saif M Mohammad and Peter D Turney. 2013. Crowdsourcing a word–emotion association lexicon. Computational Intelligence, 29(3):436–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Nrc-canada: Building the state-ofthe-art in sentiment analysis of tweets.</title>
<date>2013</date>
<booktitle>Proceedings of the International Workshop on Semantic Evaluation,</booktitle>
<pages>321--327</pages>
<contexts>
<context position="2164" citStr="Mohammad et al. (2013)" startWordPosition="313" endWordPosition="316">ment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to obtain better classification performance (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). For example, Mohammad et al. (2013) implement diverse sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sentiment information of text into the continuous represe</context>
<context position="7607" citStr="Mohammad et al., 2013" startWordPosition="1180" endWordPosition="1183">t al., 2011; Socher et al., 2011; Mitchell and Lapata, 2010), to obtain the tweet representation. The result is the concatenation of vectors derived from different convolutional layers. Feature Representation Sentiment Classifier Learning Algorithm Training Data Massive Tweets dimension N dimension 1 dimension 2 elongated all-cap emoticon .... ... N+1 N+2 ... N+K .... N 2 1 Embedding Learning SSWE Feature STATE Feature so cooooL :D syntactic sentiment lossus(t, tr) = max(0,1 − Ss(t)fu1 (t) + Ss(t)fu1 (tr) ) (3) 209 2.2 STATE Features We re-implement the state-of-the-art hand-crafted features (Mohammad et al., 2013) for Twitter sentiment classification. The STATE features are described below. • All-Caps. The number of words with all characters in upper case. • Emoticons. We use the presence of positive (or negative) emoticons and whether the last unit of a segmentation is emoticon 3. • Elongated Units. The number of elongated words (with one character repeated more than two times), such as gooood. • Sentiment Lexicon. We utilize several sentiment lexicons 4 to generate features. We explore the number of sentiment words, the score of last sentiment words, the total sentiment score and the maximal sentimen</context>
<context position="9088" citStr="Mohammad et al., 2013" startWordPosition="1420" endWordPosition="1423">Twitter NLP tool (Gimpel et al., 2011). • Ngrams. The presence of word ngrams (1-4) and character ngrams (3-5). 3 Experiments We evaluate our deep learning system by applying it for Twitter sentiment classification within a supervised learning framework. We conduct experiments on both positive/negative/neutral and positive/negative classification of tweets. 3We use the positive and negative emoticons from SentiStrength, available at http://sentistrength.wlv.ac.uk/. 4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion (Mohammad and Turney, 2013), NRC Hashtag and Sentiment140Lexicon (Mohammad et al., 2013). 5http://sentiment.christopherpotts.net/lingstruc.html 3.1 Dataset and Setting We train the Twitter sentiment classifier on the benchmark dataset in SemEval 2013 (Nakov et al., 2013). The training and development sets were completely in full to task participants of SemEval 2013. However, we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status. The distribution of our dataset is given in Table 1. We train sentiment classifiers with LibLinear (Fan et al., 2008) on the training set and dev set, and tu</context>
<context position="10990" citStr="Mohammad et al., 2013" startWordPosition="1732" endWordPosition="1735">Table 2: Statistics of SemEval 2014 Twitter sentiment classification test set. T1 is LiveJournal2014, T2 is SMS2013, T3 is Twitter2013, T4 is Twitter2014, T5 is Twitter2014Sarcasm. 3.2 Results and Analysis The experiment results of different methods on positive/negative/neutral and positive/negative Twitter sentiment classification are listed in Table 3. The meanings of T1∼T5 in each column are described in Table 2. SSWE means the approach that only utilizes the sentiment-specific word embedding as features for Twitter sentiment classification. In STATE, we only utilize the existing features (Mohammad et al., 2013) for building the 210 Method Positive/Negative/Neutral Positive/Negative T1 T2 T3 T4 T5 T1 T2 T3 T4 T5 SSWE 70.49 64.29 68.69 66.86 50.00 84.51 85.19 85.06 86.14 62.02 Coooolll 72.90 67.68 70.40 70.14 46.66 86.46 85.32 86.01 87.61 56.55 STATE 71.48 65.43 66.18 67.07 44.89 83.96 82.82 84.39 86.16 58.27 W2V 55.19 52.98 52.33 50.58 49.63 68.87 71.89 74.50 71.52 61.60 Top 74.84 70.28 72.12 70.96 58.16 - - - - - - - - - - Average 63.52 55.63 59.78 60.41 45.44 - - - - - - - - - - Table 3: Macro-F1 of positive and negative classes in positive/negative/neutral and positive/negative Twitter sentiment c</context>
<context position="13483" citStr="Mohammad et al. (2013)" startWordPosition="2143" endWordPosition="2146"> We find that W2V is not effective enough for Twitter sentiment classification as there is a big gap between W2V and SSWE on T1-T4. The reason is that W2V does not capture the sentiment information of text, which is crucial for sentiment analysis tasks and effectively leveraged for learning the sentimentspecific word embedding. We also conduct experiments on the posi6We utilize the Skip-gram model. The embedding is trained from the 10M tweets collected by positive and negative emoticons, as same as the training data of SSWE. 7The result of STATE on T3 is different from the results reported in Mohammad et al. (2013) and Tang et al. (2014) because we have different training data with the former and different -wi of SVM with the latter. tive/negative classification of tweets. The reason is that the sentiment-specific word embedding is learned from the positive/negative supervision of tweets through emoticons, which is tailored for positive/negative classification of tweets. From Table 3 (right table), we find that the performance of positive/negative Twitter classification is consistent with the performance of 3-class classification. SSWE performs comparable to STATE on T3 and T4, and yields better perform</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif M Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. Nrc-canada: Building the state-ofthe-art in sentiment analysis of tweets. Proceedings of the International Workshop on Semantic Evaluation, pages 321–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Sara Rosenthal</author>
<author>Zornitsa Kozareva</author>
<author>Veselin Stoyanov</author>
<author>Alan Ritter</author>
<author>Theresa Wilson</author>
</authors>
<title>Semeval-2013 task 2: Sentiment analysis in twitter.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation,</booktitle>
<volume>13</volume>
<pages>312--320</pages>
<contexts>
<context position="3041" citStr="Nakov et al., 2013" startWordPosition="440" endWordPosition="443">Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sentiment information of text into the continuous representation of words (Mikolov et al., 2013; Sun et al., 2014). Afterwards, we concatenate the SSWE features with the state-of-the-art hand-crafted features (Mohammad et al., 2013), and build the sentiment classifier with the benchmark dataset from SemEval 2013 (Nakov et al., 2013). To learn SSWE, we develop a tailored neural network, which incorporates the supervision from sentiment polarity of tweets in the hybrid loss function. We learn SSWE from tweets, leveraging massive tweets with emoticons as distantsupervised corpora without any manual annotations. We evaluate the deep learning system on the test set of Twitter Sentiment Analysis Track in SemEval 2014 2. Our system (Coooolll) is ranked 2nd on the Twitter2014 test set, along with the SemEval 2013 participants owning larger training data than us. The performance of only using SSWE as features is comparable to the</context>
<context position="9271" citStr="Nakov et al., 2013" startWordPosition="1442" endWordPosition="1445">ter sentiment classification within a supervised learning framework. We conduct experiments on both positive/negative/neutral and positive/negative classification of tweets. 3We use the positive and negative emoticons from SentiStrength, available at http://sentistrength.wlv.ac.uk/. 4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion (Mohammad and Turney, 2013), NRC Hashtag and Sentiment140Lexicon (Mohammad et al., 2013). 5http://sentiment.christopherpotts.net/lingstruc.html 3.1 Dataset and Setting We train the Twitter sentiment classifier on the benchmark dataset in SemEval 2013 (Nakov et al., 2013). The training and development sets were completely in full to task participants of SemEval 2013. However, we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status. The distribution of our dataset is given in Table 1. We train sentiment classifiers with LibLinear (Fan et al., 2008) on the training set and dev set, and tune parameter −c, −wi of SVM on the test set of SemEval 2013. In both experiment settings, the evaluation metric is the macro-F1 of positive and negative classes (Nakov et al., 2013). </context>
</contexts>
<marker>Nakov, Rosenthal, Kozareva, Stoyanov, Ritter, Wilson, 2013</marker>
<rawString>Preslav Nakov, Sara Rosenthal, Zornitsa Kozareva, Veselin Stoyanov, Alan Ritter, and Theresa Wilson. 2013. Semeval-2013 task 2: Sentiment analysis in twitter. In Proceedings of the International Workshop on Semantic Evaluation, volume 13, pages 312–320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="2100" citStr="Pang and Lee, 2008" startWordPosition="303" endWordPosition="306"> build classifiers from tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to obtain better classification performance (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). For example, Mohammad et al. (2013) implement diverse sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encod</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>79--86</pages>
<contexts>
<context position="1440" citStr="Pang et al. (2002)" startWordPosition="207" endWordPosition="210">nction 1 to learn SSWE, which encodes the sentiment information of tweets in the continuous representation of words. To obtain large-scale training corpora, we train SSWE from 10M tweets collected by positive and negative emoticons, without any manual annotation. Our system can be easily re-implemented with the publicly available sentiment-specific word embedding. 1 Introduction Twitter sentiment classification aims to classify the sentiment polarity of a tweet as positive, negative or neutral (Jiang et al., 2011; Hu et al., 2013; Dong et al., 2014). The majority of existing approaches follow Pang et al. (2002) and employ machine learning algorithms to build classifiers from tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to </context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 79–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Eric H Huang</author>
<author>Jeffrey Pennington</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Dynamic pooling and unfolding recursive autoencoders for paraphrase detection.</title>
<date>2011</date>
<booktitle>The Conference on Neural Information Processing Systems,</booktitle>
<pages>24--801</pages>
<contexts>
<context position="7017" citStr="Socher et al., 2011" startWordPosition="1092" endWordPosition="1095">cribed in Equation 3. The hyper-parameter α weighs the two parts. losscw(t, tr) = max(0, 1 − fcw(t) + fcw(tr)) (2) where Ss(t) is an indicator function reflecting the sentiment polarity of a sentence, whose value is 1 if the sentiment polarity of tweet t is positive and -1 if t’s polarity is negative. We train sentimentspecific word embedding from 10M tweets collected with positive and negative emoticons (Hu et al., 2013). The details of training phase are described in Tang et al. (2014). After finish learning SSWE, we explore min, average and max convolutional layers (Collobert et al., 2011; Socher et al., 2011; Mitchell and Lapata, 2010), to obtain the tweet representation. The result is the concatenation of vectors derived from different convolutional layers. Feature Representation Sentiment Classifier Learning Algorithm Training Data Massive Tweets dimension N dimension 1 dimension 2 elongated all-cap emoticon .... ... N+1 N+2 ... N+K .... N 2 1 Embedding Learning SSWE Feature STATE Feature so cooooL :D syntactic sentiment lossus(t, tr) = max(0,1 − Ss(t)fu1 (t) + Ss(t)fu1 (tr) ) (3) 209 2.2 STATE Features We re-implement the state-of-the-art hand-crafted features (Mohammad et al., 2013) for Twitt</context>
</contexts>
<marker>Socher, Huang, Pennington, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Eric H Huang, Jeffrey Pennington, Andrew Y Ng, and Christopher D Manning. 2011. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. The Conference on Neural Information Processing Systems, 24:801– 809.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaming Sun</author>
<author>Lei Lin</author>
<author>Duyu Tang</author>
<author>Nan Yang</author>
<author>Zhenzhou Ji</author>
<author>Xiaolong Wang</author>
</authors>
<title>Radical-enhanced chinese character embedding. arXiv preprint arXiv:1404.4714.</title>
<date>2014</date>
<contexts>
<context position="2821" citStr="Sun et al., 2014" startWordPosition="408" endWordPosition="411">d a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-specific word embedding and Kalchbrenner et al. (2014) model sentence representation with Dynamic Convolutional Neural Network. In this paper, we develop a deep learning system for Twitter sentiment classification. Firstly, we learn sentiment-specific word embedding (SSWE) (Tang et al., 2014), which encodes the sentiment information of text into the continuous representation of words (Mikolov et al., 2013; Sun et al., 2014). Afterwards, we concatenate the SSWE features with the state-of-the-art hand-crafted features (Mohammad et al., 2013), and build the sentiment classifier with the benchmark dataset from SemEval 2013 (Nakov et al., 2013). To learn SSWE, we develop a tailored neural network, which incorporates the supervision from sentiment polarity of tweets in the hybrid loss function. We learn SSWE from tweets, leveraging massive tweets with emoticons as distantsupervised corpora without any manual annotations. We evaluate the deep learning system on the test set of Twitter Sentiment Analysis Track in SemEva</context>
</contexts>
<marker>Sun, Lin, Tang, Yang, Ji, Wang, 2014</marker>
<rawString>Yaming Sun, Lei Lin, Duyu Tang, Nan Yang, Zhenzhou Ji, and Xiaolong Wang. 2014. Radical-enhanced chinese character embedding. arXiv preprint arXiv:1404.4714.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duyu Tang</author>
<author>Furu Wei</author>
<author>Nan Yang</author>
<author>Ming Zhou</author>
<author>Ting Liu</author>
<author>Bing Qin</author>
</authors>
<title>Learning sentimentspecific word embedding for twitter sentiment classification.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1555--1565</pages>
<contexts>
<context position="1794" citStr="Tang et al. (2014)" startWordPosition="263" endWordPosition="266">d embedding. 1 Introduction Twitter sentiment classification aims to classify the sentiment polarity of a tweet as positive, negative or neutral (Jiang et al., 2011; Hu et al., 2013; Dong et al., 2014). The majority of existing approaches follow Pang et al. (2002) and employ machine learning algorithms to build classifiers from tweets with manually annotated sentiment polarity. Under this direction, most studies focus on ∗ This work was partly done when the first author was visiting Microsoft Research. 1This is one of the three sentiment-specific word embedding learning algorithms proposed in Tang et al. (2014). This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/ designing effective features to obtain better classification performance (Pang and Lee, 2008; Liu, 2012; Feldman, 2013). For example, Mohammad et al. (2013) implement diverse sentiment lexicons and a variety of hand-crafted features. To leverage massive tweets containing positive and negative emoticons for automatically feature learning, Tang et al. (2014) propose to learn sentiment-</context>
<context position="6890" citStr="Tang et al. (2014)" startWordPosition="1072" endWordPosition="1075"> randomly selected one, losscw(t, tr) is the syntactic loss as given in Equation 2, lossus(t, tr) is the sentiment loss as described in Equation 3. The hyper-parameter α weighs the two parts. losscw(t, tr) = max(0, 1 − fcw(t) + fcw(tr)) (2) where Ss(t) is an indicator function reflecting the sentiment polarity of a sentence, whose value is 1 if the sentiment polarity of tweet t is positive and -1 if t’s polarity is negative. We train sentimentspecific word embedding from 10M tweets collected with positive and negative emoticons (Hu et al., 2013). The details of training phase are described in Tang et al. (2014). After finish learning SSWE, we explore min, average and max convolutional layers (Collobert et al., 2011; Socher et al., 2011; Mitchell and Lapata, 2010), to obtain the tweet representation. The result is the concatenation of vectors derived from different convolutional layers. Feature Representation Sentiment Classifier Learning Algorithm Training Data Massive Tweets dimension N dimension 1 dimension 2 elongated all-cap emoticon .... ... N+1 N+2 ... N+K .... N 2 1 Embedding Learning SSWE Feature STATE Feature so cooooL :D syntactic sentiment lossus(t, tr) = max(0,1 − Ss(t)fu1 (t) + Ss(t)fu1</context>
<context position="13506" citStr="Tang et al. (2014)" startWordPosition="2148" endWordPosition="2151">fective enough for Twitter sentiment classification as there is a big gap between W2V and SSWE on T1-T4. The reason is that W2V does not capture the sentiment information of text, which is crucial for sentiment analysis tasks and effectively leveraged for learning the sentimentspecific word embedding. We also conduct experiments on the posi6We utilize the Skip-gram model. The embedding is trained from the 10M tweets collected by positive and negative emoticons, as same as the training data of SSWE. 7The result of STATE on T3 is different from the results reported in Mohammad et al. (2013) and Tang et al. (2014) because we have different training data with the former and different -wi of SVM with the latter. tive/negative classification of tweets. The reason is that the sentiment-specific word embedding is learned from the positive/negative supervision of tweets through emoticons, which is tailored for positive/negative classification of tweets. From Table 3 (right table), we find that the performance of positive/negative Twitter classification is consistent with the performance of 3-class classification. SSWE performs comparable to STATE on T3 and T4, and yields better performance (1.62% and 1.45% i</context>
</contexts>
<marker>Tang, Wei, Yang, Zhou, Liu, Qin, 2014</marker>
<rawString>Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014. Learning sentimentspecific word embedding for twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1555–1565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="8986" citStr="Wilson et al., 2005" startWordPosition="1405" endWordPosition="1408">ark and exclamation mark. • Cluster. The presence of words from each of the 1,000 clusters from the Twitter NLP tool (Gimpel et al., 2011). • Ngrams. The presence of word ngrams (1-4) and character ngrams (3-5). 3 Experiments We evaluate our deep learning system by applying it for Twitter sentiment classification within a supervised learning framework. We conduct experiments on both positive/negative/neutral and positive/negative classification of tweets. 3We use the positive and negative emoticons from SentiStrength, available at http://sentistrength.wlv.ac.uk/. 4HL (Hu and Liu, 2004), MPQA (Wilson et al., 2005), NRC Emotion (Mohammad and Turney, 2013), NRC Hashtag and Sentiment140Lexicon (Mohammad et al., 2013). 5http://sentiment.christopherpotts.net/lingstruc.html 3.1 Dataset and Setting We train the Twitter sentiment classifier on the benchmark dataset in SemEval 2013 (Nakov et al., 2013). The training and development sets were completely in full to task participants of SemEval 2013. However, we were unable to download all the training and development sets because some tweets were deleted or not available due to modified authorization status. The distribution of our dataset is given in Table 1. We</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 347–354.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>