<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000193">
<title confidence="0.997185">
Recognizing Stances in Online Debates
</title>
<author confidence="0.994267">
Swapna Somasundaran
</author>
<affiliation confidence="0.99804">
Dept. of Computer Science
University of Pittsburgh
</affiliation>
<address confidence="0.505122">
Pittsburgh, PA 15260
</address>
<email confidence="0.997948">
swapna@cs.pitt.edu
</email>
<author confidence="0.988037">
Janyce Wiebe
</author>
<affiliation confidence="0.9978435">
Dept. of Computer Science
University of Pittsburgh
</affiliation>
<address confidence="0.50531">
Pittsburgh, PA 15260
</address>
<email confidence="0.998609">
wiebe@cs.pitt.edu
</email>
<sectionHeader confidence="0.993894" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999877928571429">
This paper presents an unsupervised opin-
ion analysis method for debate-side clas-
sification, i.e., recognizing which stance a
person is taking in an online debate. In
order to handle the complexities of this
genre, we mine the web to learn associa-
tions that are indicative of opinion stances
in debates. We combine this knowledge
with discourse information, and formu-
late the debate side classification task as
an Integer Linear Programming problem.
Our results show that our method is sub-
stantially better than challenging baseline
methods.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999974584615385">
This paper presents a method for debate-side clas-
sification, i.e., recognizing which stance a per-
son is taking in an online debate posting. In on-
line debate forums, people debate issues, express
their preferences, and argue why their viewpoint is
right. In addition to expressing positive sentiments
about one’s preference, a key strategy is also to
express negative sentiments about the other side.
For example, in the debate “which mobile phone is
better: iPhone or Blackberry,” a participant on the
iPhone side may explicitly assert and rationalize
why the iPhone is better, and, alternatively, also ar-
gue why the Blackberry is worse. Thus, to recog-
nize stances, we need to consider not only which
opinions are positive and negative, but also what
the opinions are about (their targets).
Participants directly express their opinions,
such as “The iPhone is cool,” but, more often, they
mention associated aspects. Some aspects are par-
ticular to one topic (e.g., Active-X is part of IE
but not Firefox), and so distinguish between them.
But even an aspect the topics share may distin-
guish between them, because people who are pos-
itive toward one topic may value that aspect more.
For example, both the iPhone and Blackberry have
keyboards, but we observed in our corpus that pos-
itive opinions about the keyboard are associated
with the pro Blackberry stance. Thus, we need to
find distinguishing aspects, which the topics may
or may not share.
Complicating the picture further, participants
may concede positive aspects of the opposing is-
sue or topic, without coming out in favor of it,
and they may concede negative aspects of the is-
sue or topic they support. For example, in the fol-
lowing sentence, the speaker says positive things
about the iPhone, even though he does not pre-
fer it: “Yes, the iPhone may be cool to take it out
and play with and show off, but past that, it offers
nothing.” Thus, we need to consider discourse re-
lations to sort out which sentiments in fact reveal
the writer’s stance, and which are merely conces-
sions.
Many opinion mining approaches find negative
and positive words in a document, and aggregate
their counts to determine the final document po-
larity, ignoring the targets of the opinions. Some
work in product review mining finds aspects of a
central topic, and summarizes opinions with re-
spect to these aspects. However, they do not find
distinguishing factors associated with a preference
for a stance. Finally, while other opinion anal-
ysis systems have considered discourse informa-
tion, they have not distinguished between conces-
sionary and non-concessionary opinions when de-
termining the overall stance of a document.
This work proposes an unsupervised opinion
analysis method to address the challenges de-
scribed above. First, for each debate side, we mine
the web for opinion-target pairs that are associated
with a preference for that side. This information
is employed, in conjunction with discourse infor-
mation, in an Integer Linear Programming (ILP)
framework. This framework combines the individ-
ual pieces of information to arrive at debate-side
</bodyText>
<page confidence="0.980345">
226
</page>
<note confidence="0.9996115">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 226–234,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.996795428571429">
classifications of posts in online debates.
The remainder of this paper is organized as fol-
lows. We introduce our debate genre in Section 2
and describe our method in Section 3. We present
the experiments in Section 4 and analyze the re-
sults in Section 5. Related work is in Section 6,
and the conclusions are in Section 7.
</bodyText>
<sectionHeader confidence="0.966387" genericHeader="introduction">
2 The Debate Genre
</sectionHeader>
<bodyText confidence="0.98400535">
In this section, we describe our debate data,
and elaborate on characteristic ways of express-
ing opinions in this genre. For our current
work, we use the online debates from the website
http://www.convinceme.net.1
In this work, we deal only with dual-sided,
dual-topic debates about named entities, for ex-
ample iPhone vs. Blackberry, where topics =
iPhone, topic2 =Blackberry, sides = pro-iPhone,
and side2=pro-Blackberry.
Our test data consists of posts of 4 debates:
Windows vs. Mac, Firefox vs. Internet Explorer,
Firefox vs. Opera, and Sony Ps3 vs. Nintendo
Wii. The iPhone vs. Blackberry debate and two
other debates, were used as development data.
Given below are examples of debate posts. Post
1 is taken from the iPhone vs. Blackberry debate,
Post 2 is from the Firefox vs. Internet Explorer
debate, and Post 3 is from the Windows vs. Mac
debate:
</bodyText>
<listItem confidence="0.992514428571429">
(1) While the iPhone may appeal to younger
generations and the BB to older, there is no
way it is geared towards a less rich popula-
tion. In fact it’s exactly the opposite. It’s a
gimmick. The initial purchase may be half
the price, but when all is said and done you
pay at least $200 more for the 3g.
(2) In-line spell check...helps me with big
words like onomatopoeia
(3) Apples are nice computers with an excep-
tional interface. Vista will close the gap on
the interface some but Apple still has the
prettiest, most pleasing interface and most
likely will for the next several years.
</listItem>
<subsectionHeader confidence="0.970675">
2.1 Observations
</subsectionHeader>
<bodyText confidence="0.999184">
As described in Section 1, the debate genre poses
significant challenges to opinion analysis. This
</bodyText>
<footnote confidence="0.990114333333333">
1http://www.forandagainst.com and
http://www.createdebate.com are other similar debating
websites.
</footnote>
<bodyText confidence="0.993886208333333">
subsection elaborates upon some of the complexi-
ties.
Multiple polarities to argue for a side. Debate
participants, in advocating their choice, switch
back and forth between their opinions towards the
sides. This makes it difficult for approaches that
use only positive and negative word counts to de-
cide which side the post is on. Posts 1 and 3 illus-
trate this phenomenon.
Sentiments towards both sides (topics) within a
single post. The above phenomenon gives rise
to an additional problem: often, conflicting sides
(and topics) are addressed within the same post,
sometimes within the same sentence. The second
sentence of Post 3 illustrates this, as it has opinions
about both Windows and Mac.
Differentiating aspects and personal prefer-
ences. People seldom repeatedly mention the
topic/side; they show their evaluations indirectly,
by evaluating aspects of each topic/side. Differen-
tiating aspects determine the debate-post’s side.
Some aspects are unique to one side/topic or the
other, e.g., “3g” in Example 1 and “inline spell
check” in Example 2. However, the debates are
about topics that belong to the same domain and
which therefore share many aspects. Hence, a
purely ontological approach of finding “has-a” and
“is-a” relations, or an approach looking only for
product specifications, would not be sufficient for
finding differentiating features.
When the two topics do share an aspect (e.g., a
keyboard in the iPhone vs. Blackberry debate), the
writer may perceive it to be more positive for one
than the other. And, if the writer values that as-
pect, it will influence his or her overall stance. For
example, many people prefer the Blackberry key-
board over the iPhone keyboard; people to whom
phone keyboards are important are more likely to
prefer the Blackberry.
Concessions. While debating, participants often
refer to and acknowledge the viewpoints of the op-
posing side. However, they do not endorse this ri-
val opinion. Uniform treatment of all opinions in
a post would obviously cause errors in such cases.
The first sentence of Example 1 is an instance of
this phenomenon. The participant concedes that
the iPhone appeals to young consumers, but this
positive opinion is opposite to his overall stance.
</bodyText>
<page confidence="0.996617">
227
</page>
<table confidence="0.998096">
DIRECT OBJECT Rule: dobj(opinion, target)
In words: The target is the direct object of the opinion
Example: I loveopinion1 Firefoxtarget1 and defendedopinion2 ittarget2
NOMINAL SUBJECT Rule: nsubj(opinion, target)
In words: The target is the subject of the opinion
Example: IEtarget breaksopinion with everything.
ADJECTIVAL MODIFIER Rule: amod(target, opinion)
In words: The opinion is an adjectival modifier of the target
Example: The annoyingopinion popuptarget
PREPOSITIONAL OBJECT Rule: if prep(target1,IN) =:&gt;. pobj(IN, target2)
In words: The prepositional object of a known target is also a target of the same opinion
Example: The annoyingopinion popuptarget1 in IEtarget2 (“popup” and “IE” are targets of “annoying”)
RECURSIVE MODIFIERS Rule: if conj(adj2, opinionadj1) =:&gt;. amod(target, adj2)
In words: If the opinion is an adjective (adj1) and it is conjoined with another adjective (adj2),
then the opinion is tied to what adj2 modifies
Example: It is a powerfulopinion(adj1) and easyopinion(adj2) applicationtarget
(“powerful” is attached to the target “application” via the adjective “easy”)
</table>
<tableCaption confidence="0.999849">
Table 1: Examples of syntactic rules for finding targets of opinions
</tableCaption>
<sectionHeader confidence="0.986019" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999997285714286">
We propose an unsupervised approach to classify-
ing the stance of a post in a dual-topic debate. For
this, we first use a web corpus to learn preferences
that are likely to be associated with a side. These
learned preferences are then employed in conjunc-
tion with discourse constraints to identify the side
for a given post.
</bodyText>
<subsectionHeader confidence="0.991577">
3.1 Finding Opinions and Pairing them with
Targets
</subsectionHeader>
<bodyText confidence="0.999983590909091">
We need to find opinions and pair them with tar-
gets, both to mine the web for general preferences
and to classify the stance of a debate post. We use
straightforward methods, as these tasks are not the
focus of this paper.
To find opinions, we look up words in a sub-
jectivity lexicon: all instances of those words are
treated as opinions. An opinion is assigned the
prior polarity that is listed for that word in the lex-
icon, except that, if the prior polarity is positive or
negative, and the instance is modified by a nega-
tion word (e.g., “not”), then the polarity of that in-
stance is reversed. We use the subjectivity lexicon
of (Wilson et al., 2005),2 which contains approxi-
mately 8000 words which may be used to express
opinions. Each entry consists of a subjective word,
its prior polarity (positive (+), negative (−), neu-
tral (*)), morphological information, and part of
speech information.
To pair opinions with targets, we built a rule-
based system based on dependency parse informa-
tion. The dependency parses are obtained using
</bodyText>
<footnote confidence="0.974913">
2Available at http://www.cs.pitt.edu/mpqa.
</footnote>
<bodyText confidence="0.999143823529412">
the Stanford parser.3 We developed the syntactic
rules on separate data that is not used elsewhere in
this paper. Table 1 illustrates some of these rules.
Note that the rules are constructed (and explained
in Table 1) with respect to the grammatical relation
notations of the Stanford parser. As illustrated in
the table, it is possible for an opinion to have more
than one target. In such cases, the single opin-
ion results in multiple opinion-target pairs, one for
each target.
Once these opinion-target pairs are created, we
mask the identity of the opinion word, replacing
the word with its polarity. Thus, the opinion-
target pair is converted to a polarity-target pair.
For instance, “pleasing-interface” is converted to
interface+. This abstraction is essential for han-
dling the sparseness of the data.
</bodyText>
<subsectionHeader confidence="0.962082">
3.2 Learning aspects and preferences from
the web
</subsectionHeader>
<bodyText confidence="0.999910642857143">
We observed in our development data that people
highlight the aspects of topics that are the bases
for their stances, both positive opinions toward as-
pects of the preferred topic, and negative opinions
toward aspects of the dispreferred one. Thus, we
decided to mine the web for aspects associated
with a side in the debate, and then use that infor-
mation to recognize the stances expressed in indi-
vidual posts.
Previous work mined web data for aspects as-
sociated with topics (Hu and Liu, 2004; Popescu
et al., 2005). In our work, we search for aspects
associated with a topic, but particularized to po-
larity. Not all aspects associated with a topic are
</bodyText>
<footnote confidence="0.927022">
3http://nlp.stanford.edu/software/lex-parser.shtml.
</footnote>
<page confidence="0.98669">
228
</page>
<table confidence="0.987118090909091">
term-&apos; side, (pro -iPhone) side2 (pro -blackberry)
P(iPhone+�term-&apos;) P(blackberry−�term-&apos;) P(iPhone−�term-&apos;) P(blackberry+�term-&apos;)
storm+ 0.227 0.068 0.022 0.613
storm− 0.062 0.843 0.06 0.03
phone+ 0.333 0.176 0.137 0.313
e-mail+ 0 0.333 0.166 0.5
ipod+ 0.5 0 0.33 0
battery− 0 0 0.666 0.333
network− 0.333 0 0.666 0
keyboard+ 0.09 0.12 0 0.718
keyboard− 0.25 0.25 0.125 0.375
</table>
<tableCaption confidence="0.999514">
Table 2: Probabilities learned from the web corpus (iPhone vs. blackberry debate)
</tableCaption>
<bodyText confidence="0.999978021276596">
discriminative with respect to stance; we hypoth-
esized that, by including polarity, we would be
more likely to find useful associations. An aspect
may be associated with both of the debate top-
ics, but not, by itself, be discriminative between
stances toward the topics. However, opinions to-
ward that aspect might discriminate between them.
Thus, the basic unit in our web mining process is
a polarity-target pair. Polarity-target pairs which
explicitly mention one of the topics are used to an-
chor the mining process. Opinions about relevant
aspects are gathered from the surrounding context.
For each debate, we downloaded weblogs and
forums that talk about the main topics (corre-
sponding to the sides) of that debate. For ex-
ample, for the iPhone vs. Blackberry debate,
we search the web for pages containing “iPhone”
and “Blackberry.” We used the Yahoo search API
and imposed the search restriction that the pages
should contain both topics in the http URL. This
ensured that we downloaded relevant pages. An
average of 3000 documents were downloaded per
debate.
We apply the method described in Section
3.1 to the downloaded web pages. That is,
we find all instances of words in the lexicon,
extract their targets, and mask the words with
their polarities, yielding polarity-target pairs. For
example, suppose the sentence “The interface
is pleasing” is in the corpus. The system
extracts the pair “pleasing-interface,” which is
masked to “positive-interface,” which we notate
as interface+. If the target in a polarity-target
pair happens to be one of the topics, we select the
polarity-target pairs in its vicinity for further pro-
cessing (the rest are discarded). The intuition be-
hind this is that, if someone expresses an opinion
about a topic, he or she is likely to follow it up
with reasons for that opinion. The sentiments in
the surrounding context thus reveal factors that in-
fluence the preference or dislike towards the topic.
We define the vicinity as the same sentence plus
the following 5 sentences.
Each unique target word targeti in the web cor-
pus, i.e., each word used as the target of an opin-
ion one or more times, is processed to generate the
following conditional probabilities.
</bodyText>
<subsectionHeader confidence="0.468184">
P(topicq j|targetp i ) =
</subsectionHeader>
<bodyText confidence="0.9972327">
where p = {+,− ,* } and q = {+,− ,* } denote the
polarities of the target and the topic, respectively;
j = {1, 2}; and i = {1...M}, where M is the
number of unique targets in the corpus. For exam-
ple, P(Mac+|interface+) is the probability that
“interface” is the target of a positive opinion that is
in the vicinity of a positive opinion toward “Mac.”
Table 2 lists some of the probabilities learned
by this approach. (Note that the neutral cases are
not shown.)
</bodyText>
<subsectionHeader confidence="0.825319">
3.2.1 Interpreting the learned probabilities
</subsectionHeader>
<bodyText confidence="0.999682705882353">
Table 2 contains examples of the learned proba-
bilities. These probabilities align with what we
qualitatively found in our development data. For
example, the opinions towards “Storm” essen-
tially follow the opinions towards “Blackberry;”
that is, positive opinions toward “Storm” are usu-
ally found in the vicinity of positive opinions to-
ward “Blackberry,” and negative opinions toward
“Storm” are usually found in the vicinity of neg-
ative opinions toward “Blackberry” (for example,
in the row for storm+, P(blackberry+|storm+)
is much higher than the other probabilities). Thus,
an opinion expressed about “Storm” is usually the
opinion one has toward “Blackberry.” This is ex-
pected, as Storm is a type of Blackberry. A similar
example is ipod+, which follows the opinion to-
ward the iPhone. This is interesting because an
</bodyText>
<equation confidence="0.627266333333333">
#(topicqj, targetpi )
#targetp i
(1)
</equation>
<page confidence="0.987891">
229
</page>
<bodyText confidence="0.999971730769231">
iPod is not a phone; the association is due to pref-
erence for the brand. In contrast, the probability
distribution for “phone” does not show a prefer-
ence for any one side, even though both iPhone
and Blackberry are phones. This indicates that
opinions towards phones in general will not be
able to distinguish between the debate sides.
Another interesting case is illustrated by the
probabilities for “e-mail.” People who like e-mail
capability are more likely to praise the Blackberry,
or even criticize the iPhone — they would thus be-
long to the pro-Blackberry camp.
While we noted earlier that positive evaluations
of keyboards are associated with positive evalua-
tions of the Blackberry (by far the highest prob-
ability in that row), negative evaluations of key-
boards, are, however, not a strong discriminating
factor.
For the other entries in the table, we see that
criticisms of batteries and the phone network are
more associated with negative sentiments towards
the iPhones.
The possibility of these various cases motivates
our approach, in which opinions and their polar-
ities are considered when searching for associa-
tions between debate topics and their aspects.
</bodyText>
<subsectionHeader confidence="0.984715">
3.3 Debate-side classification
</subsectionHeader>
<bodyText confidence="0.9999889">
Once we have the probabilities collected from the
web, we can build our classifier to classify the de-
bate posts.
Here again, we use the process described in Sec-
tion 3.1 to extract polarity-target pairs for each
opinion expressed in the post. Let N be the num-
ber of instances of polarity-target pairs in the post.
For each instance Ij (j = {1...N}), we look up
the learned probabilities of Section 3.2 to create
two scores, wj and uj:
</bodyText>
<equation confidence="0.9999605">
wj = P(topic+1 |target�� ) + P(topic−2 |targeti&apos;� ) (2)
uj = P(topic−1 |target�� ) + P(topic+2 |targeti&apos;� ) (3)
</equation>
<bodyText confidence="0.997768125">
where target� � is the polarity-target type of which
Ij is an instance.
Score wj corresponds to side1 and uj corre-
sponds to side2. A point to note is that, if a tar-
get word is repeated, and it occurs in different
polarity-target instances, it is counted as a sepa-
rate instance each time — that is, here we account
for tokens, not types. Via Equations 2 and 3, we
interpret the observed polarity-target instance Ij in
terms of debate sides.
We formulate the problem of finding the over-
all side of the post as an Integer Linear Program-
ming (ILP) problem. The side that maximizes the
overall side-score for the post, given all the N in-
stances Ij, is chosen by maximizing the objective
function
</bodyText>
<table confidence="0.701359444444444">
N
E (wjxj + ujyj)
j=1
subject to the following constraints
xj ∈ {0,1}, ∀j
yj ∈ {0, 1}, ∀j
xj + yj = 1, ∀j
xj − xj_1 = 0, j ∈ {2..N}
yj − yj_1 = 0, j ∈ {2..N}
</table>
<bodyText confidence="0.8163178">
Equations 5 and 6 implement binary constraints.
Equation 7 enforces the constraint that each Ij can
belong to exactly one side. Finally, Equations 8
and 9 ensure that a single side is chosen for the
entire post.
</bodyText>
<subsectionHeader confidence="0.978404">
3.4 Accounting for concession
</subsectionHeader>
<bodyText confidence="0.999966037037037">
As described in Section 2, debate participants of-
ten acknowledge the opinions held by the oppos-
ing side. We recognize such discourse constructs
using the Penn Discourse Treebank (Prasad et al.,
2007) list of discourse connectives. In particu-
lar, we use the list of connectives from the Con-
cession and Contra-expectation category. Exam-
ples of connectives in these categories are “while,”
“nonetheless,” “however,” and “even if.” We use
approximations to finding the arguments to the
discourse connectives (ARG1 and ARG2 in Penn
Discourse Treebank terms). If the connective is
mid-sentence, the part of the sentence prior to
the connective is considered conceded, and the
part that follows the connective is considered non-
conceded. An example is the second sentence of
Example 3. If, on the other hand, the connective
is sentence-initial, the sentence is split at the first
comma that occurs mid sentence. The first part is
considered conceded, and the second part is con-
sidered non-conceded. An example is the first sen-
tence of Example 1.
The opinions occurring in the conceded part are
interpreted in reverse. That is, the weights corre-
sponding to the sides wj and uj are interchanged
in equation 4. Thus, conceded opinions are effec-
tively made to count towards the opposing side.
</bodyText>
<page confidence="0.995349">
230
</page>
<sectionHeader confidence="0.999192" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999887857142857">
On http://www.convinceme.net, the html page for
each debate contains side information for each
post (side1 is blue in color and side2 is green).
This gives us automatically labeled data for our
evaluations. For each of the 4 debates in our test
set, we use posts with at least 5 sentences for eval-
uation.
</bodyText>
<subsectionHeader confidence="0.992626">
4.1 Baselines
</subsectionHeader>
<bodyText confidence="0.9999946875">
We implemented two baselines: the OpTopic sys-
tem that uses topic information only, and the
OpPMI system that uses topic as well as related
word (noun) information. All systems use the
same lexicon, as well as exactly the same pro-
cesses for opinion finding and opinion-target pair-
ing.
The OpTopic system This system considers
only explicit mentions of the topic for the opin-
ion analysis. Thus, for this system, the step
of opinion-target pairing only finds all topic+1 ,
topic= , topic+2 , topic2 instances in the post
(where, for example, an instance of topic+1 is a
positive opinion whose target is explicitly topic1).
The polarity-topic pairs are counted for each de-
bate side according to the following equations.
</bodyText>
<equation confidence="0.9999695">
score(side1) = #topic+1 + #topic2 (10)
score(side2) = #topici + #topic+2 (11)
</equation>
<bodyText confidence="0.995254470588235">
The post is assigned the side with the higher score.
The OpPMI system This system finds opinion-
target pairs for not only the topics, but also for the
words in the debate that are significantly related to
either of the topics.
We find semantic relatedness of each noun in
the post with the two main topics of the debate
by calculating the Pointwise Mutual Information
(PMI) between the term and each topic over the
entire web corpus. We use the API provided by the
Measures of Semantic Relatedness (MSR)4 engine
for this purpose. The MSR engine issues Google
queries to retrieve documents and finds the PMI
between any two given words. Table 3 lists PMIs
between the topics and the words from Table 2.
Each noun k is assigned to the topic with the
higher PMI score. That is, if
</bodyText>
<equation confidence="0.82232525">
PMI(topic1,k) &gt; PMI(topic2,k) mak= topic1
and if
4http://cwl-projects.cogsci.rpi.edu/msr/
PMI(topic2,k) &gt; PMI(topic1,k) =k= topic2
</equation>
<bodyText confidence="0.999653">
Next, the polarity-target pairs are found for the
post, as before, and Equations 10 and 11 are used
to assign a side to the post as in the OpTopic
system, except that here, related nouns are also
counted as instances of their associated topics.
</bodyText>
<table confidence="0.997689">
word iPhone blackberry
storm 0.923 0.941
phone 0.908 0.885
e-mail 0.522 0.623
ipod 0.909 0.976
battery 0.974 0.927
network 0.658 0.961
keyboard 0.961 0.983
</table>
<tableCaption confidence="0.999722">
Table 3: PMI of words with the topics
</tableCaption>
<sectionHeader confidence="0.843998" genericHeader="method">
4.2 Results
</sectionHeader>
<equation confidence="0.498119">
Performance is measured using the follow-
ing metrics: Accuracy ( #Correct
#Total posts), Precision
( #Correct) Recall ( #Correct ) and F-measure
(#guessed , #relevant
2*Precision*Recall
(Precision+Recall)).
</equation>
<bodyText confidence="0.994157296296296">
In our task, it is desirable to make a pre-
diction for all the posts; hence #relevant =
#Total posts. This results in Recall and Accu-
racy being the same. However, all of the systems
do not classify a post if the post does not con-
tain the information it needs. Thus, #guessed &lt;
#Total posts, and Precision is not the same as
Accuracy.
Table 4 reports the performance of four systems
on the test data: the two baselines, our method
using the preferences learned from the web cor-
pus (OpPr) and the method additionally using dis-
course information to reverse conceded opinions.
The OpTopic has low recall. This is expected,
because it relies only on opinions explicitly toward
the topics.
The OpPMI has better recall than OpTopic;
however, the precision drops for some debates. We
believe this is due to the addition of noise. This re-
sult suggests that not all terms that are relevant to
a topic are useful for determining the debate side.
Finally, both of the OpPr systems are better than
both baselines in Accuracy as well as F-measure
for all four debates.
The accuracy of the full OpPr system improves,
on average, by 35 percentage points over the Op-
Topic system, and by 20 percentage points over the
</bodyText>
<page confidence="0.993586">
231
</page>
<bodyText confidence="0.9994618">
OpPMI system. The F-measure improves, on aver-
age, by 25 percentage points over the OpTopic sys-
tem, and by 17 percentage points over the OpPMI
system. Note that in 3 out of 4 of the debates, the
full system is able to make a guess for all of the
posts (hence, the metrics all have the same values).
In three of the four debates, the system us-
ing concession handling described in Section 3.4
outperforms the system without it, providing evi-
dence that our treatment of concessions is effec-
tive. On average, there is a 3 percentage point
improvement in Accuracy, 5 percentage point im-
provement in Precision and 5 percentage point im-
provement in F-measure due to the added conces-
sion information.
</bodyText>
<table confidence="0.999873545454545">
OpTopic OpPMI OpPr OpPr
+ Disc
Firefox Vs Internet explorer (62 posts)
Acc 33.87 53.23 64.52 66.13
Prec 67.74 60.0 64.52 66.13
Rec 33.87 53.23 64.52 66.13
F1 45.16 56.41 64.52 66.13
Windows vs. Mac (15 posts)
Acc 13.33 46.67 66.67 66.67
Prec 40.0 53.85 66.67 66.67
Rec 13.33 46.67 66.67 66.67
F1 20.0 50.00 66.67 66.67
SonyPs3 vs. Wii (36 posts)
Acc 33.33 33.33 56.25 61.11
Prec 80.0 46.15 56.25 68.75
Rec 33.33 33.33 50.0 61.11
F1 47.06 38.71 52.94 64.71
Opera vs. Firefox (4 posts)
Acc 25.0 50.0 75.0 100.0
Prec 33.33 100 75.0 100.0
Rec 25.0 50 75.0 100.0
F1 28.57 66.67 75.0 100.0
</table>
<tableCaption confidence="0.8656275">
Table 4: Performance of the systems on the test
data
</tableCaption>
<sectionHeader confidence="0.997958" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999969837209302">
In this section, we discuss the results from the pre-
vious section and describe the sources of errors.
As reported in the previous section, the OpPr
system outperforms both the OpTopic and the
OpPMI systems. In order to analyze why OpPr
outperforms OpPMI, we need to compare Tables
2 and 3. Table 2 reports the conditional proba-
bilities learned from the web corpus for polarity-
target pairs used in OpPr, and Table 3 reports the
PMI of these same targets with the debate topics
used in OpPMI. First, we observe that the PMI
numbers are intuitive, in that all the words, ex-
cept for “e-mail,” show a high PMI relatedness to
both topics. All of them are indeed semantically
related to the domain. Additionally, we see that
some conclusions of the OpPMI system are simi-
lar to those of the OpPr system, for example, that
“Storm” is more closely related to the Blackberry
than the iPhone.
However, notice two cases: the PMI values
for “phone” and “e-mail” are intuitive, but they
may cause errors in debate analysis. Because the
iPhone and the Blackberry are both phones, the
word “phone” does not have any distinguishing
power in debates. On the other hand, the PMI
measure of “e-mail” suggests that it is not closely
related to the debate topics, though it is, in fact, a
desirable feature for smart phone users, even more
so with Blackberry users. The PMI measure does
not reflect this.
The “network” aspect shows a comparatively
greater relatedness to the blackberry than to the
iPhone. Thus, OpPMI uses it as a proxy for
the Blackberry. This may be erroneous, how-
ever, because negative opinions towards “net-
work” are more indicative of negative opinions to-
wards iPhones, a fact revealed by Table 2.
In general, even if the OpPMI system knows
what topic the given word is more related to, it
still does not know what the opinion towards that
word means in the debate scenario. The OpPr sys-
tem, on the other hand, is able to map it to a debate
side.
</bodyText>
<subsectionHeader confidence="0.826432">
5.1 Errors
</subsectionHeader>
<bodyText confidence="0.999927384615385">
False lexicon hits. The lexicon is word based,
but, as shown by (Wiebe and Mihalcea, 2006; Su
and Markert, 2008), many subjective words have
both objective and subjective senses. Thus, one
major source of errors is a false hit of a word in
the lexicon.
Opinion-target pairing. The syntactic rule-
based opinion-target pairing system is a large
source of errors in the OpPr as well as the base-
line systems. Product review mining work has ex-
plored finding opinions with respect to, or in con-
junction with, aspects (Hu and Liu, 2004; Popescu
et al., 2005); however, in our work, we need to find
</bodyText>
<page confidence="0.978087">
232
</page>
<bodyText confidence="0.99997592">
information in the other direction – that is, given
the opinion, what is the opinion about. Stoyanov
and Cardie (2008) work on opinion co-reference;
however, we need to identify the specific target.
Pragmatic opinions. Some of the errors are due
to the fact that the opinions expressed in the post
are pragmatic. This becomes a problem especially
when the debate post is small, and we have few
other lexical clues in the post. The following post
is an example:
(4) The blackberry is something like $150 and
the iPhone is $500. I don’t think it’s worth
it. You could buy a iPod separate and have
a boatload of extra money left over.
In this example, the participant mentions the
difference in the prices in the first sentence. This
sentence implies a negative opinion towards the
iPhone. However, recognizing this would require
a system to have extensive world knowledge. In
the second sentence, the lexicon does hit the word
“worth,” and, using syntactic rules, we can deter-
mine it is negated. However, the opinion-target
pairing system only tells us that the opinion is tied
to the “it.” A co-reference system would be needed
to tie the “it” to “iPhone” in the first sentence.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999984680851064">
Several researchers have worked on similar tasks.
Kim and Hovy (2007) predict the results of an
election by analyzing forums discussing the elec-
tions. Theirs is a supervised bag-of-words sys-
tem using unigrams, bigrams, and trigrams as fea-
tures. In contrast, our approach is unsupervised,
and exploits different types of information. Bansal
et al. (2008) predict the vote from congressional
floor debates using agreement/disagreement fea-
tures. We do not model inter-personal exchanges;
instead, we model factors that influence stance
taking. Lin at al (2006) identify opposing perspec-
tives. Though apparently related at the task level,
perspectives as they define them are not the same
as opinions. Their approach does not involve any
opinion analysis. Fujii and Ishikawa (2006) also
work with arguments. However, their focus is on
argument visualization rather than on recognizing
stances.
Other researchers have also mined data to learn
associations among products and features. In
their work on mining opinions in comparative sen-
tences, Ganapathibhotla and Liu (2008) look for
user preferences for one product’s features over
another’s. We do not exploit comparative con-
structs, but rather probabilistic associations. Thus,
our approach and theirs are complementary. A
number of works in product review mining (Hu
and Liu, 2004; Popescu et al., 2005; Kobayashi et
al., 2005; Bloom et al., 2007) automatically find
features of the reviewed products. However, our
approach is novel in that it learns and exploits as-
sociations among opinion/polarity, topics, and as-
pects.
Several researchers have recognized the im-
portant role discourse plays in opinion analysis
(Polanyi and Zaenen, 2005; Snyder and Barzilay,
2007; Somasundaran et al., 2008; Asher et al.,
2008; Sadamitsu et al., 2008). However, previous
work did not account for concessions in determin-
ing whether an opinion supports one side or the
other.
More sophisticated approaches to identifying
opinions and recognizing their contextual polar-
ity have been published (e.g., (Wilson et al., 2005;
Ikeda et al., 2008; Sadamitsu et al., 2008)). Those
components are not the focus of our work.
</bodyText>
<sectionHeader confidence="0.999209" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.9999619375">
This paper addresses challenges faced by opinion
analysis in the debate genre. In our method, fac-
tors that influence the choice of a debate side are
learned by mining a web corpus for opinions. This
knowledge is exploited in an unsupervised method
for classifying the side taken by a post, which also
accounts for concessionary opinions.
Our results corroborate our hypothesis that find-
ing relations between aspects associated with a
topic, but particularized to polarity, is more effec-
tive than finding relations between topics and as-
pects alone. The system that implements this in-
formation, mined from the web, outperforms the
web PMI-based baseline. Our hypothesis that ad-
dressing concessionary opinions is useful is also
corroborated by improved performance.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999790166666667">
This research was supported in part by the
Department of Homeland Security under grant
N000140710152. We would also like to thank
Vladislav D. Veksler for help with the MSR en-
gine, and the anonymous reviewers for their help-
ful comments.
</bodyText>
<page confidence="0.997575">
233
</page>
<sectionHeader confidence="0.995874" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999961552083333">
Nicholas Asher, Farah Benamara, and Yvette Yannick
Mathieu. 2008. Distilling opinion in discourse:
A preliminary study. In Coling 2008: Companion
volume: Posters and Demonstrations, pages 5–8,
Manchester, UK, August.
Mohit Bansal, Claire Cardie, and Lillian Lee. 2008.
The power of negative thinking: Exploiting label
disagreement in the min-cut classification frame-
work. In Proceedings of COLING: Companion vol-
ume: Posters.
Kenneth Bloom, Navendu Garg, and Shlomo Argamon.
2007. Extracting appraisal expressions. In HLT-
NAACL 2007, pages 308–315, Rochester, NY.
Atsushi Fujii and Tetsuya Ishikawa. 2006. A sys-
tem for summarizing and visualizing arguments in
subjective documents: Toward supporting decision
making. In Proceedings of the Workshop on Senti-
ment and Subjectivity in Text, pages 15–22, Sydney,
Australia, July. Association for Computational Lin-
guistics.
Murthy Ganapathibhotla and Bing Liu. 2008. Mining
opinions in comparative sentences. In Proceedings
of the 22nd International Conference on Compu-
tational Linguistics (Coling 2008), pages 241–248,
Manchester, UK, August.
Minqing Hu and Bing Liu. 2004. Mining opinion fea-
tures in customer reviews. In AAAI-2004.
Daisuke Ikeda, Hiroya Takamura, Lev-Arie Ratinov,
and Manabu Okumura. 2008. Learning to shift
the polarity of words for sentiment classification. In
Proceedings of the Third International Joint Confer-
ence on Natural Language Processing (IJCNLP).
Soo-Min Kim and Eduard Hovy. 2007. Crystal: An-
alyzing predictive opinions on the web. In Pro-
ceedings of the 2007 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning (EMNLP-
CoNLL), pages 1056–1064.
Nozomi Kobayashi, Ryu Iida, Kentaro Inui, and Yuji
Matsumoto. 2005. Opinion extraction using a
learning-based anaphora resolution technique. In
Proceedings of the 2nd International Joint Confer-
ence on Natural Language Processing (IJCNLP-05),
poster, pages 175–180.
Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and
Alexander Hauptmann. 2006. Which side are you
on? Identifying perspectives at the document and
sentence levels. In Proceedings of the 10th Con-
ference on Computational Natural Language Learn-
ing (CoNLL-2006), pages 109–116, New York, New
York.
Livia Polanyi and Annie Zaenen. 2005. Contextual
valence shifters. In Computing Attitude and Affect
in Text. Springer.
Ana-Maria Popescu, Bao Nguyen, and Oren Et-
zioni. 2005. OPINE: Extracting product fea-
tures and opinions from reviews. In Proceedings
of HLT/EMNLP 2005 Interactive Demonstrations,
pages 32–33, Vancouver, British Columbia, Canada,
October. Association for Computational Linguistics.
R. Prasad, E. Miltsakaki, N. Dinesh, A. Lee, A. Joshi,
L. Robaldo, and B. Webber, 2007. PDTB 2.0 Anno-
tation Manual.
Kugatsu Sadamitsu, Satoshi Sekine, and Mikio Ya-
mamoto. 2008. Sentiment analysis based on
probabilistic models using inter-sentence informa-
tion. In European Language Resources Associa-
tion (ELRA), editor, Proceedings of the Sixth In-
ternational Language Resources and Evaluation
(LREC’08), Marrakech, Morocco, May.
Benjamin Snyder and Regina Barzilay. 2007. Multiple
aspect ranking using the good grief algorithm. In
Proceedings ofNAACL-2007.
Swapna Somasundaran, Janyce Wiebe, and Josef Rup-
penhofer. 2008. Discourse level opinion interpre-
tation. In Proceedings of the 22nd International
Conference on Computational Linguistics (Coling
2008), pages 801–808, Manchester, UK, August.
Veselin Stoyanov and Claire Cardie. 2008. Topic
identification for fine-grained opinion analysis. In
Proceedings of the 22nd International Conference
on Computational Linguistics (Coling 2008), pages
817–824, Manchester, UK, August. Coling 2008 Or-
ganizing Committee.
Fangzhong Su and Katja Markert. 2008. From
word to sense: a case study of subjectivity recogni-
tion. In Proceedings of the 22nd International Con-
ference on Computational Linguistics (COLING-
2008), Manchester, UK, August.
Janyce Wiebe and Rada Mihalcea. 2006. Word sense
and subjectivity. In Proceedings of COLING-ACL
2006.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In HLT-EMNLP, pages
347–354, Vancouver, Canada.
</reference>
<page confidence="0.99838">
234
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.752144">
<title confidence="0.999946">Recognizing Stances in Online Debates</title>
<author confidence="0.997801">Swapna Somasundaran</author>
<affiliation confidence="0.9999775">Dept. of Computer Science University of Pittsburgh</affiliation>
<address confidence="0.999383">Pittsburgh, PA 15260</address>
<email confidence="0.937681">swapna@cs.pitt.edu</email>
<author confidence="0.968151">Janyce Wiebe</author>
<affiliation confidence="0.9999795">Dept. of Computer Science University of Pittsburgh</affiliation>
<address confidence="0.999271">Pittsburgh, PA 15260</address>
<email confidence="0.86324">wiebe@cs.pitt.edu</email>
<abstract confidence="0.9973478">This paper presents an unsupervised opinanalysis method for clasi.e., recognizing which stance a person is taking in an online debate. In order to handle the complexities of this genre, we mine the web to learn associations that are indicative of opinion stances in debates. We combine this knowledge with discourse information, and formulate the debate side classification task as an Integer Linear Programming problem. Our results show that our method is substantially better than challenging baseline methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Farah Benamara</author>
<author>Yvette Yannick Mathieu</author>
</authors>
<title>Distilling opinion in discourse: A preliminary study.</title>
<date>2008</date>
<booktitle>In Coling 2008: Companion volume: Posters and Demonstrations,</booktitle>
<pages>5--8</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="31417" citStr="Asher et al., 2008" startWordPosition="5209" endWordPosition="5212">o not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choice of a debate side are learned by mining a web corpus for opinions. This </context>
</contexts>
<marker>Asher, Benamara, Mathieu, 2008</marker>
<rawString>Nicholas Asher, Farah Benamara, and Yvette Yannick Mathieu. 2008. Distilling opinion in discourse: A preliminary study. In Coling 2008: Companion volume: Posters and Demonstrations, pages 5–8, Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohit Bansal</author>
<author>Claire Cardie</author>
<author>Lillian Lee</author>
</authors>
<title>The power of negative thinking: Exploiting label disagreement in the min-cut classification framework.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING: Companion volume: Posters.</booktitle>
<contexts>
<context position="30009" citStr="Bansal et al. (2008)" startWordPosition="4996" endWordPosition="4999">worth,” and, using syntactic rules, we can determine it is negated. However, the opinion-target pairing system only tells us that the opinion is tied to the “it.” A co-reference system would be needed to tie the “it” to “iPhone” in the first sentence. 6 Related Work Several researchers have worked on similar tasks. Kim and Hovy (2007) predict the results of an election by analyzing forums discussing the elections. Theirs is a supervised bag-of-words system using unigrams, bigrams, and trigrams as features. In contrast, our approach is unsupervised, and exploits different types of information. Bansal et al. (2008) predict the vote from congressional floor debates using agreement/disagreement features. We do not model inter-personal exchanges; instead, we model factors that influence stance taking. Lin at al (2006) identify opposing perspectives. Though apparently related at the task level, perspectives as they define them are not the same as opinions. Their approach does not involve any opinion analysis. Fujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations am</context>
</contexts>
<marker>Bansal, Cardie, Lee, 2008</marker>
<rawString>Mohit Bansal, Claire Cardie, and Lillian Lee. 2008. The power of negative thinking: Exploiting label disagreement in the min-cut classification framework. In Proceedings of COLING: Companion volume: Posters.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Bloom</author>
<author>Navendu Garg</author>
<author>Shlomo Argamon</author>
</authors>
<title>Extracting appraisal expressions.</title>
<date>2007</date>
<booktitle>In HLTNAACL 2007,</booktitle>
<pages>308--315</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="31052" citStr="Bloom et al., 2007" startWordPosition="5154" endWordPosition="5157"> also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations among products and features. In their work on mining opinions in comparative sentences, Ganapathibhotla and Liu (2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual </context>
</contexts>
<marker>Bloom, Garg, Argamon, 2007</marker>
<rawString>Kenneth Bloom, Navendu Garg, and Shlomo Argamon. 2007. Extracting appraisal expressions. In HLTNAACL 2007, pages 308–315, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Tetsuya Ishikawa</author>
</authors>
<title>A system for summarizing and visualizing arguments in subjective documents: Toward supporting decision making.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Sentiment and Subjectivity in Text,</booktitle>
<pages>15--22</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="30433" citStr="Fujii and Ishikawa (2006)" startWordPosition="5059" endWordPosition="5062">heirs is a supervised bag-of-words system using unigrams, bigrams, and trigrams as features. In contrast, our approach is unsupervised, and exploits different types of information. Bansal et al. (2008) predict the vote from congressional floor debates using agreement/disagreement features. We do not model inter-personal exchanges; instead, we model factors that influence stance taking. Lin at al (2006) identify opposing perspectives. Though apparently related at the task level, perspectives as they define them are not the same as opinions. Their approach does not involve any opinion analysis. Fujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations among products and features. In their work on mining opinions in comparative sentences, Ganapathibhotla and Liu (2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; </context>
</contexts>
<marker>Fujii, Ishikawa, 2006</marker>
<rawString>Atsushi Fujii and Tetsuya Ishikawa. 2006. A system for summarizing and visualizing arguments in subjective documents: Toward supporting decision making. In Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 15–22, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murthy Ganapathibhotla</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinions in comparative sentences.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>241--248</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="30725" citStr="Ganapathibhotla and Liu (2008)" startWordPosition="5102" endWordPosition="5105">es. We do not model inter-personal exchanges; instead, we model factors that influence stance taking. Lin at al (2006) identify opposing perspectives. Though apparently related at the task level, perspectives as they define them are not the same as opinions. Their approach does not involve any opinion analysis. Fujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations among products and features. In their work on mining opinions in comparative sentences, Ganapathibhotla and Liu (2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polany</context>
</contexts>
<marker>Ganapathibhotla, Liu, 2008</marker>
<rawString>Murthy Ganapathibhotla and Bing Liu. 2008. Mining opinions in comparative sentences. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 241–248, Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinion features in customer reviews.</title>
<date>2004</date>
<booktitle>In AAAI-2004.</booktitle>
<contexts>
<context position="12282" citStr="Hu and Liu, 2004" startWordPosition="1981" endWordPosition="1984">+. This abstraction is essential for handling the sparseness of the data. 3.2 Learning aspects and preferences from the web We observed in our development data that people highlight the aspects of topics that are the bases for their stances, both positive opinions toward aspects of the preferred topic, and negative opinions toward aspects of the dispreferred one. Thus, we decided to mine the web for aspects associated with a side in the debate, and then use that information to recognize the stances expressed in individual posts. Previous work mined web data for aspects associated with topics (Hu and Liu, 2004; Popescu et al., 2005). In our work, we search for aspects associated with a topic, but particularized to polarity. Not all aspects associated with a topic are 3http://nlp.stanford.edu/software/lex-parser.shtml. 228 term-&apos; side, (pro -iPhone) side2 (pro -blackberry) P(iPhone+�term-&apos;) P(blackberry−�term-&apos;) P(iPhone−�term-&apos;) P(blackberry+�term-&apos;) storm+ 0.227 0.068 0.022 0.613 storm− 0.062 0.843 0.06 0.03 phone+ 0.333 0.176 0.137 0.313 e-mail+ 0 0.333 0.166 0.5 ipod+ 0.5 0 0.33 0 battery− 0 0 0.666 0.333 network− 0.333 0 0.666 0 keyboard+ 0.09 0.12 0 0.718 keyboard− 0.25 0.25 0.125 0.375 Table </context>
<context position="28396" citStr="Hu and Liu, 2004" startWordPosition="4723" endWordPosition="4726">ario. The OpPr system, on the other hand, is able to map it to a debate side. 5.1 Errors False lexicon hits. The lexicon is word based, but, as shown by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), many subjective words have both objective and subjective senses. Thus, one major source of errors is a false hit of a word in the lexicon. Opinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in the OpPr as well as the baseline systems. Product review mining work has explored finding opinions with respect to, or in conjunction with, aspects (Hu and Liu, 2004; Popescu et al., 2005); however, in our work, we need to find 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008) work on opinion co-reference; however, we need to identify the specific target. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have few other lexical clues in the post. The following post is an example: (4) The blackberry is something like $150 and the iPhone is $500. I don’</context>
<context position="30985" citStr="Hu and Liu, 2004" startWordPosition="5142" endWordPosition="5145">does not involve any opinion analysis. Fujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations among products and features. In their work on mining opinions in comparative sentences, Ganapathibhotla and Liu (2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated a</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining opinion features in customer reviews. In AAAI-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Ikeda</author>
<author>Hiroya Takamura</author>
<author>Lev-Arie Ratinov</author>
<author>Manabu Okumura</author>
</authors>
<title>Learning to shift the polarity of words for sentiment classification.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third International Joint Conference on Natural Language Processing (IJCNLP).</booktitle>
<contexts>
<context position="31728" citStr="Ikeda et al., 2008" startWordPosition="5257" endWordPosition="5260">ever, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choice of a debate side are learned by mining a web corpus for opinions. This knowledge is exploited in an unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions. Our results corroborate our hypothesis that finding relations between aspects associated with a topic, but particularized to polarity, is more effective than finding relati</context>
</contexts>
<marker>Ikeda, Takamura, Ratinov, Okumura, 2008</marker>
<rawString>Daisuke Ikeda, Hiroya Takamura, Lev-Arie Ratinov, and Manabu Okumura. 2008. Learning to shift the polarity of words for sentiment classification. In Proceedings of the Third International Joint Conference on Natural Language Processing (IJCNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Crystal: Analyzing predictive opinions on the web.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>1056--1064</pages>
<contexts>
<context position="29725" citStr="Kim and Hovy (2007)" startWordPosition="4952" endWordPosition="4955">mple, the participant mentions the difference in the prices in the first sentence. This sentence implies a negative opinion towards the iPhone. However, recognizing this would require a system to have extensive world knowledge. In the second sentence, the lexicon does hit the word “worth,” and, using syntactic rules, we can determine it is negated. However, the opinion-target pairing system only tells us that the opinion is tied to the “it.” A co-reference system would be needed to tie the “it” to “iPhone” in the first sentence. 6 Related Work Several researchers have worked on similar tasks. Kim and Hovy (2007) predict the results of an election by analyzing forums discussing the elections. Theirs is a supervised bag-of-words system using unigrams, bigrams, and trigrams as features. In contrast, our approach is unsupervised, and exploits different types of information. Bansal et al. (2008) predict the vote from congressional floor debates using agreement/disagreement features. We do not model inter-personal exchanges; instead, we model factors that influence stance taking. Lin at al (2006) identify opposing perspectives. Though apparently related at the task level, perspectives as they define them a</context>
</contexts>
<marker>Kim, Hovy, 2007</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2007. Crystal: Analyzing predictive opinions on the web. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 1056–1064.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Ryu Iida</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Opinion extraction using a learning-based anaphora resolution technique.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05),</booktitle>
<pages>175--180</pages>
<contexts>
<context position="31031" citStr="Kobayashi et al., 2005" startWordPosition="5150" endWordPosition="5153">ujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations among products and features. In their work on mining opinions in comparative sentences, Ganapathibhotla and Liu (2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recogniz</context>
</contexts>
<marker>Kobayashi, Iida, Inui, Matsumoto, 2005</marker>
<rawString>Nozomi Kobayashi, Ryu Iida, Kentaro Inui, and Yuji Matsumoto. 2005. Opinion extraction using a learning-based anaphora resolution technique. In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP-05), poster, pages 175–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei-Hao Lin</author>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Alexander Hauptmann</author>
</authors>
<title>Which side are you on? Identifying perspectives at the document and sentence levels.</title>
<date>2006</date>
<booktitle>In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-2006),</booktitle>
<pages>109--116</pages>
<location>New York, New York.</location>
<marker>Lin, Wilson, Wiebe, Hauptmann, 2006</marker>
<rawString>Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and Alexander Hauptmann. 2006. Which side are you on? Identifying perspectives at the document and sentence levels. In Proceedings of the 10th Conference on Computational Natural Language Learning (CoNLL-2006), pages 109–116, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Annie Zaenen</author>
</authors>
<title>Contextual valence shifters.</title>
<date>2005</date>
<booktitle>In Computing Attitude and Affect in Text.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="31343" citStr="Polanyi and Zaenen, 2005" startWordPosition="5197" endWordPosition="5200">(2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choi</context>
</contexts>
<marker>Polanyi, Zaenen, 2005</marker>
<rawString>Livia Polanyi and Annie Zaenen. 2005. Contextual valence shifters. In Computing Attitude and Affect in Text. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Bao Nguyen</author>
<author>Oren Etzioni</author>
</authors>
<title>OPINE: Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP 2005 Interactive Demonstrations,</booktitle>
<pages>32--33</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="12305" citStr="Popescu et al., 2005" startWordPosition="1985" endWordPosition="1988">n is essential for handling the sparseness of the data. 3.2 Learning aspects and preferences from the web We observed in our development data that people highlight the aspects of topics that are the bases for their stances, both positive opinions toward aspects of the preferred topic, and negative opinions toward aspects of the dispreferred one. Thus, we decided to mine the web for aspects associated with a side in the debate, and then use that information to recognize the stances expressed in individual posts. Previous work mined web data for aspects associated with topics (Hu and Liu, 2004; Popescu et al., 2005). In our work, we search for aspects associated with a topic, but particularized to polarity. Not all aspects associated with a topic are 3http://nlp.stanford.edu/software/lex-parser.shtml. 228 term-&apos; side, (pro -iPhone) side2 (pro -blackberry) P(iPhone+�term-&apos;) P(blackberry−�term-&apos;) P(iPhone−�term-&apos;) P(blackberry+�term-&apos;) storm+ 0.227 0.068 0.022 0.613 storm− 0.062 0.843 0.06 0.03 phone+ 0.333 0.176 0.137 0.313 e-mail+ 0 0.333 0.166 0.5 ipod+ 0.5 0 0.33 0 battery− 0 0 0.666 0.333 network− 0.333 0 0.666 0 keyboard+ 0.09 0.12 0 0.718 keyboard− 0.25 0.25 0.125 0.375 Table 2: Probabilities learne</context>
<context position="28419" citStr="Popescu et al., 2005" startWordPosition="4727" endWordPosition="4730">tem, on the other hand, is able to map it to a debate side. 5.1 Errors False lexicon hits. The lexicon is word based, but, as shown by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), many subjective words have both objective and subjective senses. Thus, one major source of errors is a false hit of a word in the lexicon. Opinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in the OpPr as well as the baseline systems. Product review mining work has explored finding opinions with respect to, or in conjunction with, aspects (Hu and Liu, 2004; Popescu et al., 2005); however, in our work, we need to find 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008) work on opinion co-reference; however, we need to identify the specific target. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have few other lexical clues in the post. The following post is an example: (4) The blackberry is something like $150 and the iPhone is $500. I don’t think it’s worth it. </context>
<context position="31007" citStr="Popescu et al., 2005" startWordPosition="5146" endWordPosition="5149">ny opinion analysis. Fujii and Ishikawa (2006) also work with arguments. However, their focus is on argument visualization rather than on recognizing stances. Other researchers have also mined data to learn associations among products and features. In their work on mining opinions in comparative sentences, Ganapathibhotla and Liu (2008) look for user preferences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifyi</context>
</contexts>
<marker>Popescu, Nguyen, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu, Bao Nguyen, and Oren Etzioni. 2005. OPINE: Extracting product features and opinions from reviews. In Proceedings of HLT/EMNLP 2005 Interactive Demonstrations, pages 32–33, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Prasad</author>
<author>E Miltsakaki</author>
<author>N Dinesh</author>
<author>A Lee</author>
<author>A Joshi</author>
<author>L Robaldo</author>
<author>B Webber</author>
</authors>
<date>2007</date>
<journal>PDTB 2.0 Annotation Manual.</journal>
<contexts>
<context position="19590" citStr="Prasad et al., 2007" startWordPosition="3206" endWordPosition="3209">e objective function N E (wjxj + ujyj) j=1 subject to the following constraints xj ∈ {0,1}, ∀j yj ∈ {0, 1}, ∀j xj + yj = 1, ∀j xj − xj_1 = 0, j ∈ {2..N} yj − yj_1 = 0, j ∈ {2..N} Equations 5 and 6 implement binary constraints. Equation 7 enforces the constraint that each Ij can belong to exactly one side. Finally, Equations 8 and 9 ensure that a single side is chosen for the entire post. 3.4 Accounting for concession As described in Section 2, debate participants often acknowledge the opinions held by the opposing side. We recognize such discourse constructs using the Penn Discourse Treebank (Prasad et al., 2007) list of discourse connectives. In particular, we use the list of connectives from the Concession and Contra-expectation category. Examples of connectives in these categories are “while,” “nonetheless,” “however,” and “even if.” We use approximations to finding the arguments to the discourse connectives (ARG1 and ARG2 in Penn Discourse Treebank terms). If the connective is mid-sentence, the part of the sentence prior to the connective is considered conceded, and the part that follows the connective is considered nonconceded. An example is the second sentence of Example 3. If, on the other hand</context>
</contexts>
<marker>Prasad, Miltsakaki, Dinesh, Lee, Joshi, Robaldo, Webber, 2007</marker>
<rawString>R. Prasad, E. Miltsakaki, N. Dinesh, A. Lee, A. Joshi, L. Robaldo, and B. Webber, 2007. PDTB 2.0 Annotation Manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kugatsu Sadamitsu</author>
<author>Satoshi Sekine</author>
<author>Mikio Yamamoto</author>
</authors>
<title>Sentiment analysis based on probabilistic models using inter-sentence information.</title>
<date>2008</date>
<booktitle>In European Language Resources Association (ELRA), editor, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<location>Marrakech, Morocco,</location>
<contexts>
<context position="31442" citStr="Sadamitsu et al., 2008" startWordPosition="5213" endWordPosition="5216">ative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choice of a debate side are learned by mining a web corpus for opinions. This knowledge is exploited in</context>
</contexts>
<marker>Sadamitsu, Sekine, Yamamoto, 2008</marker>
<rawString>Kugatsu Sadamitsu, Satoshi Sekine, and Mikio Yamamoto. 2008. Sentiment analysis based on probabilistic models using inter-sentence information. In European Language Resources Association (ELRA), editor, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Regina Barzilay</author>
</authors>
<title>Multiple aspect ranking using the good grief algorithm.</title>
<date>2007</date>
<booktitle>In Proceedings ofNAACL-2007.</booktitle>
<contexts>
<context position="31370" citStr="Snyder and Barzilay, 2007" startWordPosition="5201" endWordPosition="5204">rences for one product’s features over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choice of a debate side are lea</context>
</contexts>
<marker>Snyder, Barzilay, 2007</marker>
<rawString>Benjamin Snyder and Regina Barzilay. 2007. Multiple aspect ranking using the good grief algorithm. In Proceedings ofNAACL-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
<author>Josef Ruppenhofer</author>
</authors>
<title>Discourse level opinion interpretation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>801--808</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="31397" citStr="Somasundaran et al., 2008" startWordPosition="5205" endWordPosition="5208">atures over another’s. We do not exploit comparative constructs, but rather probabilistic associations. Thus, our approach and theirs are complementary. A number of works in product review mining (Hu and Liu, 2004; Popescu et al., 2005; Kobayashi et al., 2005; Bloom et al., 2007) automatically find features of the reviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choice of a debate side are learned by mining a web corpus</context>
</contexts>
<marker>Somasundaran, Wiebe, Ruppenhofer, 2008</marker>
<rawString>Swapna Somasundaran, Janyce Wiebe, and Josef Ruppenhofer. 2008. Discourse level opinion interpretation. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 801–808, Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Claire Cardie</author>
</authors>
<title>Topic identification for fine-grained opinion analysis.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>817--824</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="28581" citStr="Stoyanov and Cardie (2008)" startWordPosition="4756" endWordPosition="4759">006; Su and Markert, 2008), many subjective words have both objective and subjective senses. Thus, one major source of errors is a false hit of a word in the lexicon. Opinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in the OpPr as well as the baseline systems. Product review mining work has explored finding opinions with respect to, or in conjunction with, aspects (Hu and Liu, 2004; Popescu et al., 2005); however, in our work, we need to find 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008) work on opinion co-reference; however, we need to identify the specific target. Pragmatic opinions. Some of the errors are due to the fact that the opinions expressed in the post are pragmatic. This becomes a problem especially when the debate post is small, and we have few other lexical clues in the post. The following post is an example: (4) The blackberry is something like $150 and the iPhone is $500. I don’t think it’s worth it. You could buy a iPod separate and have a boatload of extra money left over. In this example, the participant mentions the difference in the prices in the first se</context>
</contexts>
<marker>Stoyanov, Cardie, 2008</marker>
<rawString>Veselin Stoyanov and Claire Cardie. 2008. Topic identification for fine-grained opinion analysis. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 817–824, Manchester, UK, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangzhong Su</author>
<author>Katja Markert</author>
</authors>
<title>From word to sense: a case study of subjectivity recognition.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING2008),</booktitle>
<location>Manchester, UK,</location>
<contexts>
<context position="27981" citStr="Su and Markert, 2008" startWordPosition="4651" endWordPosition="4654"> the blackberry than to the iPhone. Thus, OpPMI uses it as a proxy for the Blackberry. This may be erroneous, however, because negative opinions towards “network” are more indicative of negative opinions towards iPhones, a fact revealed by Table 2. In general, even if the OpPMI system knows what topic the given word is more related to, it still does not know what the opinion towards that word means in the debate scenario. The OpPr system, on the other hand, is able to map it to a debate side. 5.1 Errors False lexicon hits. The lexicon is word based, but, as shown by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), many subjective words have both objective and subjective senses. Thus, one major source of errors is a false hit of a word in the lexicon. Opinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in the OpPr as well as the baseline systems. Product review mining work has explored finding opinions with respect to, or in conjunction with, aspects (Hu and Liu, 2004; Popescu et al., 2005); however, in our work, we need to find 232 information in the other direction – that is, given the opinion, what is the opinion about. Stoyanov and Cardie (2008)</context>
</contexts>
<marker>Su, Markert, 2008</marker>
<rawString>Fangzhong Su and Katja Markert. 2008. From word to sense: a case study of subjectivity recognition. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING2008), Manchester, UK, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Rada Mihalcea</author>
</authors>
<title>Word sense and subjectivity.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL</booktitle>
<contexts>
<context position="27958" citStr="Wiebe and Mihalcea, 2006" startWordPosition="4647" endWordPosition="4650">ely greater relatedness to the blackberry than to the iPhone. Thus, OpPMI uses it as a proxy for the Blackberry. This may be erroneous, however, because negative opinions towards “network” are more indicative of negative opinions towards iPhones, a fact revealed by Table 2. In general, even if the OpPMI system knows what topic the given word is more related to, it still does not know what the opinion towards that word means in the debate scenario. The OpPr system, on the other hand, is able to map it to a debate side. 5.1 Errors False lexicon hits. The lexicon is word based, but, as shown by (Wiebe and Mihalcea, 2006; Su and Markert, 2008), many subjective words have both objective and subjective senses. Thus, one major source of errors is a false hit of a word in the lexicon. Opinion-target pairing. The syntactic rulebased opinion-target pairing system is a large source of errors in the OpPr as well as the baseline systems. Product review mining work has explored finding opinions with respect to, or in conjunction with, aspects (Hu and Liu, 2004; Popescu et al., 2005); however, in our work, we need to find 232 information in the other direction – that is, given the opinion, what is the opinion about. Sto</context>
</contexts>
<marker>Wiebe, Mihalcea, 2006</marker>
<rawString>Janyce Wiebe and Rada Mihalcea. 2006. Word sense and subjectivity. In Proceedings of COLING-ACL 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT-EMNLP,</booktitle>
<pages>347--354</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="10506" citStr="Wilson et al., 2005" startWordPosition="1694" endWordPosition="1697"> them with targets, both to mine the web for general preferences and to classify the stance of a debate post. We use straightforward methods, as these tasks are not the focus of this paper. To find opinions, we look up words in a subjectivity lexicon: all instances of those words are treated as opinions. An opinion is assigned the prior polarity that is listed for that word in the lexicon, except that, if the prior polarity is positive or negative, and the instance is modified by a negation word (e.g., “not”), then the polarity of that instance is reversed. We use the subjectivity lexicon of (Wilson et al., 2005),2 which contains approximately 8000 words which may be used to express opinions. Each entry consists of a subjective word, its prior polarity (positive (+), negative (−), neutral (*)), morphological information, and part of speech information. To pair opinions with targets, we built a rulebased system based on dependency parse information. The dependency parses are obtained using 2Available at http://www.cs.pitt.edu/mpqa. the Stanford parser.3 We developed the syntactic rules on separate data that is not used elsewhere in this paper. Table 1 illustrates some of these rules. Note that the rule</context>
<context position="31708" citStr="Wilson et al., 2005" startWordPosition="5253" endWordPosition="5256">eviewed products. However, our approach is novel in that it learns and exploits associations among opinion/polarity, topics, and aspects. Several researchers have recognized the important role discourse plays in opinion analysis (Polanyi and Zaenen, 2005; Snyder and Barzilay, 2007; Somasundaran et al., 2008; Asher et al., 2008; Sadamitsu et al., 2008). However, previous work did not account for concessions in determining whether an opinion supports one side or the other. More sophisticated approaches to identifying opinions and recognizing their contextual polarity have been published (e.g., (Wilson et al., 2005; Ikeda et al., 2008; Sadamitsu et al., 2008)). Those components are not the focus of our work. 7 Conclusions This paper addresses challenges faced by opinion analysis in the debate genre. In our method, factors that influence the choice of a debate side are learned by mining a web corpus for opinions. This knowledge is exploited in an unsupervised method for classifying the side taken by a post, which also accounts for concessionary opinions. Our results corroborate our hypothesis that finding relations between aspects associated with a topic, but particularized to polarity, is more effective</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In HLT-EMNLP, pages 347–354, Vancouver, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>