<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002155">
<title confidence="0.997351">
Better Binarization for the CKY Parsing
</title>
<author confidence="0.994299">
Xinying Songt * Shilin Ding§ * Chin-Yew Lin$
</author>
<affiliation confidence="0.996041666666667">
tMOE-MS Key Laboratory of NLP and Speech, Harbin Institute of Technology, Harbin, China
§Department of Statistics, University of Wisconsin-Madison, Madison, USA
$Microsoft Research Asia, Beijing, China
</affiliation>
<email confidence="0.994026">
xysong@mtlab.hit.edu.cn dingsl@gmail.com cyl@microsoft.com
</email>
<sectionHeader confidence="0.998576" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999558294117647">
We present a study on how grammar binariza-
tion empirically affects the efficiency of the
CKY parsing. We argue that binarizations af-
fect parsing efficiency primarily by affecting
the number of incomplete constituents gener-
ated, and the effectiveness of binarization also
depends on the nature of the input. We pro-
pose a novel binarization method utilizing rich
information learnt from training corpus. Ex-
perimental results not only show that differ-
ent binarizations have great impacts on pars-
ing efficiency, but also confirm that our learnt
binarization outperforms other existing meth-
ods. Furthermore we show that it is feasible to
combine existing parsing speed-up techniques
with our binarization to achieve even better
performance.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998759">
Binarization, which transforms an n-ary grammar
into an equivalent binary grammar, is essential for
achieving an O(n3) time complexity in the context-
free grammar parsing. O(n3) tabular parsing al-
gorithms, such as the CKY algorithm (Kasami,
1965; Younger, 1967), the GHR parser (Graham
et al., 1980), the Earley algorithm (Earley, 1970) and
the chart parsing algorithm (Kay, 1980; Klein and
Manning, 2001) all convert their grammars into bi-
nary branching forms, either explicitly or implicitly
(Charniak et al., 1998).
In fact, the number of all possible binarizations
of a production with n + 1 symbols on its right
&apos;This work was done when Xinying Song and Shilin Ding
were visiting students at Microsoft Research Asia.
hand side is known to be the nth Catalan Number
Cn = n1 1 ( \2n) . All binarizations lead to the same
parsing accuracy, but maybe different parsing effi-
ciency, i.e. parsing speed. We are interested in in-
vestigating whether and how binarizations will af-
fect the efficiency of the CKY parsing.
Do different binarizations lead to different pars-
ing efficiency? Figure 1 gives an example to help
answer this question. Figure 1(a) illustrates the cor-
rect parse of the phrase “get the bag and go”. We
assume that NP —* NP CC NP is in the original
grammar. The symbols enclosed in square brackets
in the figure are intermediate symbols.
</bodyText>
<figureCaption confidence="0.996335">
Figure 1: Parsing with left and right binarization.
</figureCaption>
<bodyText confidence="0.999068923076923">
If a left binarized grammar is used, see Fig-
ure 1(b), an extra constituent [NP CC] spanning
“the bag and” will be produced. Because rule
[NP CC] —* NP CC is in the left binarized gram-
mar and there is an NP over “the bag” and a CC
over the right adjacent “and”. Having this con-
stituent is unnecessary, because it lacks an NP to
the right to complete the production. However, if a
right binarization is used, as shown in Figure 1(c),
such unnecessary constituent can be avoided.
One observation from this example is that differ-
ent binarizations affect constituent generation, thus
affect parsing efficiency. Another observation is that
</bodyText>
<figure confidence="0.997898304347826">
VP VP
the
bag
the
bag
VP
[VP CC]
[CC VP]
NP?
VP VP
VP [NP CC] VP
VP VP
NP?
VB NP CC VB
get DT NN and go
the bag
(a) final parse
VB NP CC VB
get DT NN and go
(b) with left
VB NP CC VB
get DT NN and go
(c) with right
</figure>
<page confidence="0.959091">
167
</page>
<note confidence="0.9615655">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 167–176,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.99992628">
for rules like X → Y CC Y , it is more suitable to
binarize them in a right branching way. This can
be seen as a linguistic nature: for “and”, usually
the right neighbouring word can indicate the correct
parse. A good binarization should reflect such ligu-
istic nature.
In this paper, we aim to study the effect of bina-
rization on the efficiency of the CKY parsing. To our
knowledge, this is the first work on this problem.
We propose the problem to find the optimal bina-
rization in terms of parsing efficiency (Section 3).
We argue that binarizations affect parsing efficiency
primarily by affecting the number of incomplete
constituents generated, and the effectiveness of bi-
narization also depends on the nature of the input
(Section 4). Therefore we propose a novel binariza-
tion method utilizing rich information learnt from
training corpus (Section 5). Experimental results
show that our binarization outperforms other exist-
ing methods (Section 7.2).
Since binarization is usually a preprocessing step
before parsing, we argue that better performance can
be achieved by combining other parsing speed-up
techniques with our binarization (Section 6). We
conduct experiments to confirm this (Section 7.3).
</bodyText>
<sectionHeader confidence="0.981887" genericHeader="introduction">
2 Binarization
</sectionHeader>
<bodyText confidence="0.9850579">
In this paper we assume that the original gram-
mar, perhaps after preprocessing, contains no &amp;
productions or useless symbols. However, we allow
the existence of unary productions, since we adopt
an extended version of the CKY algorithm which
can handle the unary productions. Moreover we do
not distinguish nonterminals and terminals explic-
itly. We treat them as symbols. What we focus on is
the procedure of binarization.
Definition 1. A binarization is a function 7r, map-
ping an n-ary grammar G to an equivalent binary
grammar G&apos;. We say that G&apos; is a binarized grammar
of G, denoted as 7r(G).
Two grammars are equivalent if they define the
same probability distribution over strings (Charniak
et al., 1998).
We use the most widely used left binarization
(Aho and Ullman, 1972) to show the procedure of
binarization, as illustrated in Table 1, where p and q
are the probabilities of the productions.
</bodyText>
<table confidence="0.90049825">
Original grammar Left binarized grammar
Y → ABC: p [A B] → AB : 1.0
Z → AB D : q Y → [AB]C:p
Z → [AB]D:q
</table>
<tableCaption confidence="0.998099">
Table 1: Left binarization
</tableCaption>
<bodyText confidence="0.982979318181818">
In the binarized grammar, symbols of form [A B]
are new (also called intermediate) nonterminals.
Left binarization always selects the left most pair of
symbols and combines them to form an intermedi-
ate nonterminal. This procedure is repeated until all
productions are binary.
In this paper, we assume that all binarizations fol-
low the fashion above, except that the choice of pair
of symbols for combination can be arbitrary. Next
we show three other known binarizations.
Right binarization is almost the same with left
binarization, except that it always selects the right
most pair, instead of left, to combine.
Head binarization always binarizes from the head
outward (Klein and Manning, 2003b). Please refer
to Charniak et al. (2006) for more details.
Compact binarization (Schmid, 2004) tries to
minimize the size of the binarized grammar. It leads
to a compact grammar. We therefore call it compact
binarization. It is done via a greedy approach: it al-
ways selects the pair that occurs most on the right
hand sides of rules to combine.
</bodyText>
<sectionHeader confidence="0.968204" genericHeader="method">
3 The optimal binarization
</sectionHeader>
<bodyText confidence="0.9976446">
The optimal binarization should help CKY parsing
to achieve its best efficiency. We formalize the idea
as follows:
Definition 2. The optimal binarization is 7r*, for a
given n-ary grammar G and a test corpus C:
</bodyText>
<equation confidence="0.997133">
T(7r(G),C) (1)
</equation>
<bodyText confidence="0.999953333333333">
where T(7r(G), C) is the running time for CKY to
parse corpus C, using the binarized grammar 7r(G).
It is hard to find the optimal binarization directly
from Definition 2. We next give an empirical anal-
ysis of the running time of the CKY algorithm and
simplify the problem by introducing assumptions.
</bodyText>
<subsectionHeader confidence="0.999863">
3.1 Analysis of CKY parsing efficiency
</subsectionHeader>
<bodyText confidence="0.9959225">
It is known that the complexity of the CKY algo-
rithm is O(n3L). The constant L depends on the bi-
</bodyText>
<equation confidence="0.943491">
7r* = arg min
7r
</equation>
<page confidence="0.979859">
168
</page>
<bodyText confidence="0.784765176470588">
narized grammar in use. Therefore binarization will
affect L. Our goal is to find a good binarization that
makes parsing more efficient.
It is also known that in the inner most loop of
CKY as shown in Algorithm 1, the for-statement in
Line 1 can be implemented in several different meth-
ods. The choice will affect the efficiency of CKY.
We present here four possible methods:
M1 Enumerate all rules X → Y Z, and check if Y is in
left span and Z in right span.
M2 For each Y in left span, enumerate all rules X →
Y Z, and check if Z is in right span.
M3 For each Z in right span, enumerate all rules X →
Y Z, and check if Y is in left span.
M4 Enumerate each Y in left span and Z in right span1,
check if there are any rules X → Y Z.
Algorithm 1 The inner most loop of CKY
</bodyText>
<listItem confidence="0.992259">
1: for X → Y Z, Y in left span and Z in right span
2: Add X to parent span
</listItem>
<subsectionHeader confidence="0.999691">
3.2 Model assumption
</subsectionHeader>
<bodyText confidence="0.998647275862069">
We have shown that both binarization and the for-
statement implementation in the inner most loop of
CKY will affect the parsing speed.
About the for-statement implementations, no pre-
vious study has addressed which one is superior.
The actual choice may affect our study on binariza-
tion. If using M1, since it enumerates all rules in
the grammar, the optimal binarization will be the
one with minimal number of rules, i.e. minimal bi-
narized grammar size. However, M1 is usually not
preferred in practice (Goodman, 1997). For other
methods, it is hard to tell which binarization is op-
timal theoretically. In this paper, for simplicity rea-
sons we do not consider the effect of for-statement
implementations on the optimal binarization.
On the other hand, it is well known that reduc-
ing the number of constituents produced in parsing
can greatly improve CKY parsing efficiency. That
is how most thresholding systems (Goodman, 1997;
Tsuruoka and Tsujii, 2004; Charniak et al., 2006)
speed up CKY parsing. Apparently, the number of
1Note that we should skip Y (Z) if it never appears as the
first (second) symbol on the right hand side of any rule.
constituents produced in parsing is not affected by
for-statement implementations.
Therefore we assume that the running time of
CKY is primarily determined by the number of con-
stituents generated in parsing. We simplify the opti-
mal binarization to be:
</bodyText>
<equation confidence="0.961029">
7r* ≈ arg min E(7r(G), C) (2)
7r
</equation>
<bodyText confidence="0.999962">
where E(7r(G), C) is the number of constituents
generated when CKY parsing C with 7r(G).
We next discuss how binarizations affect the num-
ber of constituents generated in parsing, and present
our algorithm for finding a good binarization.
</bodyText>
<sectionHeader confidence="0.977419" genericHeader="method">
4 How binarizations affect constituents
</sectionHeader>
<bodyText confidence="0.997846">
Throughout this section and the next, we will use an
example to help illustrate the idea. The grammar is:
</bodyText>
<equation confidence="0.985486">
X → A B C D
Y → A B C
C → C D
Z → A B C E
W → F C D E
</equation>
<bodyText confidence="0.999905">
The input sentence is 0A1B2C3D4E5, where the
subscripts are used to indicate the positions of spans.
For example, [1, 3] stands for B C. The final parse2
is shown in Figure 2. Symbols surrounded by dashed
circles are fictitious, which do not actually exist in
the parse.
</bodyText>
<equation confidence="0.995684">
Y:[0,4] Z:[0,5]
Y:[0,3] X:[0,4] C:[2,4] W
F
A:[0,1] B:[1,2] C:[2,3] D:[3,4] E:[4,5]
</equation>
<figureCaption confidence="0.997127">
Figure 2: Parse of the sentence A B C D E
</figureCaption>
<subsectionHeader confidence="0.994126">
4.1 Complete and incomplete constituents
</subsectionHeader>
<bodyText confidence="0.9988155">
In the procedure of CKY parsing, there are two kinds
of constituents generated: complete and incomplete.
Complete constituents (henceforth CCs) are those
composed by the original grammar symbols and
</bodyText>
<footnote confidence="0.951671">
2More precisely, it is more than a parse tree for it contains
all symbols recognized in parsing.
</footnote>
<page confidence="0.997852">
169
</page>
<bodyText confidence="0.999912090909091">
spans. For example in Figure 2, X:[0, 4], Y :[0, 3]
and Y:[0, 4] are all CCs.
Incomplete constituents (henceforth ICs) are
those labeled by intermediate symbols. Figure 2
does not show them directly, but we can still read the
possible ones. For example, if the binarized gram-
mar in use contains an intermediate symbol [A B C],
then there will be two related ICs [A B C]:[0, 3] and
[A B C]:[0, 4] (the latter is due to C:[2, 4]) produced
in parsing. ICs represent the intermediate steps to
recognize and complete CCs.
</bodyText>
<subsectionHeader confidence="0.999346">
4.2 Impact on complete constituents
</subsectionHeader>
<bodyText confidence="0.999862214285714">
Binarizations do not affect whether a CC will be pro-
duced. If there is a CC in the parse, whatever bi-
narization we use, it will be produced. The differ-
ence merely lies on what intermediate ICs are used.
Therefore given a grammar and an input sentence,
no matter what binarization is used, the CKY pars-
ing will generate the same set of CCs.
For example in Figure 2 there is a CC X :[0, 4],
which is associated with rule X -* A B C D. No
matter what binarization we use, this CC will be rec-
ognized eventually. For example if using left bina-
rization, we will get [A B]:[0, 2], [A B C]:[0, 3] and
finally X:[0, 4]; if using right binarization, we will
get [C D]:[2, 4], [B C D]:[1, 4] and again X:[0, 4].
</bodyText>
<subsectionHeader confidence="0.999474">
4.3 Impact on incomplete constituents
</subsectionHeader>
<bodyText confidence="0.999957424242424">
Binarizations do affect the generation of ICs, be-
cause they generate different intermediate symbols.
We discuss the impact on two aspects:
Shared IC. Some ICs can be used to generate
multiple CCs in parsing. We call them shared. If a
binarization can lead to more shared ICs, then over-
all there will be fewer ICs needed in parsing.
For example, in Figure 2, if we use left binariza-
tion, then [A B]:[0, 2] can be shared to generate both
X:[0, 4] and Y :[0, 3], in which we can save one IC
overall. However, if right binarization is used, there
will be no common ICs to share in the generation
steps of X:[0, 4] and Y :[0, 3], and overall there are
one more IC generated.
Failed IC. For a CC, if it can be recognized even-
tually by applying an original rule of length k, what-
ever binarization to use, we will have to generate the
same number of k − 2 ICs before we can complete
the CC. However, if the CC cannot be fully recog-
nized but only partially recognized, then the number
of ICs needed will be quite different.
For example, in Figure 2, the rule W -* F C D E
can be only partially recognized over [2, 5], so it can-
not generate the corresponding CC. Right binariza-
tion needs two ICs ([D E]:[3, 5] and [C D E]:[2, 5])
to find that the CC cannot be recognized, while left
binarization needs none.
As mentioned earlier, ICs are auxiliary means to
generate CCs. If an IC cannot help generate any
CCs, it is totally useless and even harmful. We call
such an IC failed, otherwise it is successful. There-
fore, if a binarization can help generate fewer failed
ICs then parsing would be more efficient.
</bodyText>
<subsectionHeader confidence="0.976701">
4.4 Binarization and the nature of the input
</subsectionHeader>
<bodyText confidence="0.999990260869565">
Now we show that the impact of binarization also
depends on the actual input. When the input
changes, the impact may also change.
For example, in the previous example about the
rule W -* F C D E in Figure 2, we believe that
left binarization is better based on the observation
that there are more snippets of [C D E] in the in-
put which lack for F to the left. If there are more
snippets of [F C D] in the input lacking for E to the
right, then right binarization would be better.
The discussion above confirms such a view: the
effect of binarization depends on the nature of the
input language, and a good binarization should re-
flect this nature. This accords with our intuition. So
we use training corpus to learn a good binarization.
And we verify the effectiveness of the learnt bina-
rization using a test corpus with the same nature.
In summary, binarizations affect the efficiency of
parsing primarily by affecting the number of ICs
generated, where more shared and fewer failed ICs
will help lead to higher efficiency. Meanwhile, the
effectiveness of binarization also depends on the na-
ture of its input language.
</bodyText>
<sectionHeader confidence="0.969932" genericHeader="method">
5 Towards a good binarization
</sectionHeader>
<bodyText confidence="0.9996895">
Based on the analysis in the previous section, we
employ a greedy approach to find a good binariza-
tion. We use training corpus to compute metrics
for every possible intermediate symbol. We use this
information to greedily select the best pair to com-
bine.
</bodyText>
<page confidence="0.981754">
170
</page>
<subsectionHeader confidence="0.876896">
5.1 Algorithm
</subsectionHeader>
<bodyText confidence="0.7494125">
Given the original grammar G and training corpus
C, for every sentence in C, we firstly obtain the final
parse (like Figure 2). For every possible intermedi-
ate symbol, i.e. every ngram of the original symbols,
denoted by w, we compute the following two met-
rics:
</bodyText>
<listItem confidence="0.994194666666667">
1. How many ICs labeled by w can be generated
in the final parse, denoted by num(w) (number
of related ICs).
2. How many CCs can be generated via ICs la-
beled by w, denoted by ctr(w) (contribution of
related ICs).
</listItem>
<bodyText confidence="0.997381">
For example in Figure 2, for a possible inter-
mediate symbol [A B C], there are two related ICs
([A B C] : [0, 3] and [A B C] : [0, 4]) in the parse,
so we have num([AB C]) = 2. Meanwhile, four
CCs (Y :[0, 3], X:[0, 4], Y :[0, 4] and Z:[0, 5]) can
be generated from the two related ICs. Therefore
ctr([A B C]) = 4. We list the two metrics for every
ngram in Figure 2 in Table 2. We will discuss how
to compute these two metrics in Section 5.2.
</bodyText>
<table confidence="0.998377571428571">
w num ctr w num ctr
[A B] 1 4 [B C E] 1 1
[AB C] 2 4 [C D] 1 2
[A B C D] 1 1 [C D E] 1 0
[A B C E] 1 1 [C E] 1 1
[B C] 2 4 [D E] 1 0
[B C D] 1 1
</table>
<tableCaption confidence="0.999432">
Table 2: Metrics of every ngram
</tableCaption>
<bodyText confidence="0.999968181818182">
The two metrics indicate the goodness of a possi-
ble intermediate symbol w: num(w) indicates how
many ICs labeled by w are likely to be generated in
parsing; while ctr(w) represents how much w can
contribute to the generation of CCs. If ctr(w) is
larger, the corresponding ICs are more likely to be
shared. If ctr is zero, those ICs are surely failed.
Therefore the smaller num(w) is and the larger
ctr(w) is, the better w would be.
Combining num and ctr, we define a utility func-
tion for each ngram w in the original grammar:
</bodyText>
<equation confidence="0.997402">
utility(w) = f(num(w), ctr(w)) (3)
</equation>
<bodyText confidence="0.906792">
where f is a ranking function, satisfying that f(x, y)
is larger when x is smaller and y is larger. We will
discuss more details about it in Section 5.3.
Using utility as the ranking function, we sort all
pairs of symbols and choose the best to combine.
The formal algorithm is as follows:
S1 For every symbol pair of (v1, v2) (where v1 and
v2 can be original symbols or intermediate symbols
generated in previous rounds), let w1 and w2 be the
ngrams of original symbols represented by v1 and
v2, respectively. Let w = w1w2 be the ngram rep-
resented by the symbol pair. Compute utility(w).
S2 Select the ngram w with the highest utility(w), let
it be w∗ (in case of a tie, select the one with a
smaller num). Let the corresponding symbol pair
be (v∗1, v∗2).
S3 Add a new intermediate symbol v∗, and replace all
the occurrences of (v∗1, v∗2) on the right hand sides
of rules with v∗.
</bodyText>
<figure confidence="0.340093666666667">
S4 Add a new rule v∗ —* v∗1v∗2 : 1.0.
S5 Repeat S1 — S4, until there are no rules with more
than two symbols on the right hand side.
</figure>
<subsectionHeader confidence="0.997022">
5.2 Metrics computing
</subsectionHeader>
<bodyText confidence="0.999592944444445">
In this section, we discuss how to compute num and
ctr in details.
Computing ctr is straightforward. First we get
final parses like in Figure 2 for training sentences.
From a final parse, we traverse along every parent
node and enumerate every subsequence of its child
nodes. For example in Figure 2, from the parent
node of X : [0, 4], we can enumerate the follow-
ing: [A B]:[0, 2], [A B C]:[0, 3], [A B C D]:[0, 4],
[B C]:[1, 3], [B C D]:[1, 4], [C D]:[2,4]. We add 1 to
all the ctr of these ngrams, respectively.
To compute num, we resort to the same idea
of dynamic programming as in CKY. We perform
a normal left binarization except that we add all
ngrams in the original grammar G as intermediate
symbols into the binarized grammar G&apos;. For exam-
ple, for the rule of S —* A B C : p, the constructed
grammar is as follows:
</bodyText>
<construct confidence="0.804663">
[AB] —* A B : 1.0
S —* [AB] C : p
[B C] —* B C : 1.0
</construct>
<bodyText confidence="0.744496">
Using the constructed G&apos;, we employ a normal
CKY parsing on the training corpus and compute
</bodyText>
<page confidence="0.996807">
171
</page>
<bodyText confidence="0.999774333333333">
how many constituents are produced for each ngram.
The result is num. Suppose the length of the train-
ing sentence is n, the original grammar G has N
symbols, and the maximum length of rules is k,
then the complexity of this method can be written
as O(Nkn3).
</bodyText>
<subsectionHeader confidence="0.998474">
5.3 Ranking function
</subsectionHeader>
<bodyText confidence="0.999946333333333">
We discuss the details of the ranking function f used
to compute the utility of each ngram w. We come
up with two forms for f: linear and log-linear
</bodyText>
<listItem confidence="0.9983675">
1. linear: f(x, y) = −A1x + A2y
2. log-linear3: f(x, y) = −A1 log(x) + A2 log(y)
</listItem>
<bodyText confidence="0.9713065">
where A1 and A2 are non-negative weights subject to
A1 + A2 = 14.
We will use development set to determine which
form is better and to learn the best weight settings.
</bodyText>
<sectionHeader confidence="0.908772" genericHeader="method">
6 Combination with other techniques
</sectionHeader>
<bodyText confidence="0.999968043478261">
Binarization usually plays a role of preprocessing in
the procedure of parsing. Grammars are binarized
before they are fed into the stage of parsing. There
are many known works on speeding up the CKY
parsing. So we can expect that if we replace the
part of binarization by a better one while keeping
the subsequent parsing unchanged, the parsing will
be more efficient. We will conduct experiment to
confirm this idea in the next section.
We would like to make more discussions be-
fore we advance to the experiments. The first is
about parsing accuracy in combining binarization
with other parsing speed-up techniques. Binariza-
tion itself does not affect parsing accuracy. When
combined with exact inference algorithms, like the
iterative CKY (Tsuruoka and Tsujii, 2004), the ac-
curacy will be the same. However, if combined with
other inexact pruning techniques like beam-pruning
(Goodman, 1997) or coarse-to-fine parsing (Char-
niak et al., 2006), binarization may interact with
those pruning methods in a complicated way to af-
fect parsing accuracy. This is due to different bina-
rizations generate different sets of intermediate sym-
</bodyText>
<footnote confidence="0.99147325">
3For log-linear form, if num(w) = 0 (and consequently
ctr(w) = 0), we set f(num(w), ctr(w)) = 0; if num(w) &gt;
0 but ctr(w) = 0, we set f(num(w), ctr(w)) = −oo.
4Since f is used for ranking, the magnitude is not important.
</footnote>
<bodyText confidence="0.999958548387097">
bols. With the same complete constituents, one bi-
narization might derive incomplete constitutes that
could be pruned while another binarization may not.
This would affect the accuracy. We do not address
this interaction on in this paper, but leave it to the
future work. In Section 7.3 we will use the iterative
CKY for testing.
In addition, we believe there exist some speed-up
techniques which are incompatible with our bina-
rization. One such example may be the top-down
left-corner filtering (Graham et al., 1980; Moore,
2000), which seems to be only applicable to the pro-
cess of left binarization. A detailed investigation on
this problem will be left to the future work.
The last issue is how our binarization performs
on a lexicalized parser, like Collins (1997). Our in-
tuition is that we cannot apply our binarization to
Collins (1997). The key fact in lexicalized parsers
is that we cannot explicitly write down all rules
and compute their probabilities precisely, due to the
great number of rules and the severe data sparsity
problem. Therefore in Collins (1997) grammar rules
are already factorized into a set of probabilities.
In order to capture the dependency relationship be-
tween lexcial heads Collins (1997) breaks down the
rules from head outwards, which prevents us from
factorizing them in other ways. Therefore our bina-
rization cannot apply to the lexicalized parser. How-
ever, there are state-of-the-art unlexicalized parsers
(Klein and Manning, 2003b; Petrov et al., 2006), to
which we believe our binarization can be applied.
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="method">
7 Experiments
</sectionHeader>
<bodyText confidence="0.999977166666667">
We conducted two experiments on Penn Treebank II
corpus (Marcus et al., 1994). The first is to com-
pare the effects of different binarizations on parsing
and the second is to test the feasibility to combine
our work with iterative CKY parsing (Tsuruoka and
Tsujii, 2004) to achieve even better efficiency.
</bodyText>
<subsectionHeader confidence="0.975249">
7.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.999817833333333">
Following conventions, we learnt the grammar from
Wall Street Journal (WSJ) section 2 to 21 and mod-
ified it by discarding all functional tags and empty
nodes. The parser obtained this way is a pure un-
lexicalized context-free parser with the raw treebank
grammar. Its accuracy turns out to be 72.46% in
</bodyText>
<page confidence="0.99577">
172
</page>
<bodyText confidence="0.99995870967742">
terms of F1 measure, quite the same as 72.62% as
stated in Klein and Manning (2003b). We adopt this
parser in our experiment not only because of sim-
plicity but also because we focus on parsing effi-
ciency.
For all sentences with no more than 40 words in
section 22, we use the first 10% as the development
set, and the last 90% as the test set. There are 158
and 1,420 sentences in development set and test set,
respectively. We use the whole 2,416 sentences in
section 23 as the training set.
We use the development set to determine the bet-
ter form of the ranking function f as well as to
tune its weights. Both metrics of num and dr
are normalized before use. Since there is only one
free variable in A1 and A2, we can just enumerate
0 &lt; A1 &lt; 1, and set A2 = 1 — A1. The increasing
step is firstly set to 0.05 for the approximate loca-
tion of the optimal weight, then set to 0.001 to learn
more precisely around the optimal.
We find that the optimal is 5,773,088 (constituents
produced in parsing development set) with A1 =
0.014 for linear form, while for log-linear form the
optimal is 5,905,292 with A1 = 0.691. Therefore we
determine that the better form for the ranking func-
tion is linear with A1 = 0.014 and A2 = 0.986.
The size of each binarized grammar used in the
experiment is shown in Table 3. “Original” refers
to the raw treebank grammar. “Ours” refers to the
learnt binarized grammar by our approach. For the
rest please refer to Section 2.
</bodyText>
<table confidence="0.999538428571428">
# of Symbols # of Rules
Original 72 14,971
Right 10,654 25,553
Left 12,944 27,843
Head 11,798 26,697
Compact 3,644 18,543
Ours 8,407 23,306
</table>
<tableCaption confidence="0.999885">
Table 3: Grammar size of different binarizations
</tableCaption>
<bodyText confidence="0.998893727272727">
We also tested whether the size of the training set
would have significant effect. We use the first 10%,
20%, · · · , up to 100% of section 23 as the training
set, respectively, and parse the development set. We
find that all sizes examined have a similar impact,
since the numbers of constituents produced are all
around 5,780,000. It means the training corpus does
not have to be very large.
The entire experiments are conducted on a server
with an Intel Xeon 2.33 GHz processor and 8 GB
memory.
</bodyText>
<subsectionHeader confidence="0.9878605">
7.2 Experiment 1: compare among
binarizations
</subsectionHeader>
<bodyText confidence="0.9999632">
In this part, we use CKY to parse the entire test set
and evaluate the efficiency of different binarizations.
The for-statement implementation of the inner
most loop of CKY will affect the parsing time
though it won’t affect the number of constituents
produced as discussed in Section 3.2. The best im-
plementations may be different for different bina-
rized grammars. We examine M1—M4, testing their
parsing time on the development set. Results show
that for right binarization the best method is M3,
while for the rest the best is M2. We use the best
method for each binarized grammar when compar-
ing the parsing time in Experiment 1.
Table 4 reports the total number of constituents
and total time required for parsing the entire test set.
It shows that different binarizations have great im-
pacts on the efficiency of CKY. With our binariza-
tion, the number of constituents produced is nearly
20% of that required by right binarization and nearly
25% of that by the widely-used left binarization. As
for the parsing time, CKY with our binarization is
about 2.5 times as fast as with right binarization and
about 1.75 times as fast as with left binarization.
This illustrates that our binarization can significantly
improve the efficiency of the CKY parsing.
</bodyText>
<table confidence="0.999601666666667">
Binarization Constituents Time (s)
Right 241,924,229 5,747
Left 193,238,759 3,474
Head 166,425,179 3,837
Compact 94,257,478 2,302
Ours 52,206,466 2,182
</table>
<tableCaption confidence="0.999914">
Table 4: Performance on test set
</tableCaption>
<bodyText confidence="0.996064">
Figure 3 reports the detailed number of complete
constituents, successful incomplete constituents and
failed incomplete constituents produced in parsing.
The result proves that our binarization can signifi-
cantly reduce the number of failed incomplete con-
stituents, by a factor of 10 in contrast with left bi-
narization. Meanwhile, the number of successful in-
</bodyText>
<page confidence="0.99671">
173
</page>
<bodyText confidence="0.5585725">
complete constituents is also reduced by a factor of
2 compared to left binarization.
</bodyText>
<figure confidence="0.8854885">
Right Left Head Compact Ours
Binarizations
</figure>
<figureCaption confidence="0.999717">
Figure 3: Comparison on various constituents
</figureCaption>
<bodyText confidence="0.99996648">
Another interesting observation is that parsing
with a smaller grammar does not always yield a
higher efficiency. Our binarized grammar is more
than twice the size of compact binarization, but ours
is more efficient. It proves that parsing efficiency is
related to both the size of grammar in use as well as
the number of constituents produced.
In Section 1, we used an example of “get the
bag and go” to illustrate that for rules like X —*
Y CC Y , right binarization is more suitable. We
also investigated the corresponding linguistic nature
that the word to the right of “and” is more likely to
indicate the true relationship represented by “and”.
We argued that a better binarization can reflect such
linguistic nature of the input language. To our sur-
prise, our learnt binarization indeed captures this lin-
guistic insight, by binarizing NP —* NP CC NP
from right to left.
Finally, we would like to acknowledge the limi-
tation of our assumption made in Section 3.2. Ta-
ble 4 shows that the parsing time of CKY is not
always monotonic increasing with the number of
constituents produced. Head binarization produces
fewer constituents than left binarization but con-
sumes more parsing time.
</bodyText>
<subsectionHeader confidence="0.98868">
7.3 Experiment 2: combine with iterative CKY
</subsectionHeader>
<bodyText confidence="0.999887387096774">
In this part, we test the performance of combining
our binarization with the iterative CKY (Tsuruoka
and Tsujii, 2004) (henceforth T&amp;T) algorithm.
Iterative CKY is a procedure of multiple passes
of normal CKY: in each pass, it uses a threshold to
prune bad constituents; if it cannot find a successful
parse in one pass, it will relax the threshold and start
another; this procedure is repeated until a successful
parse is returned. T&amp;T used left binarization. We
re-implement their experiments and combine itera-
tive CKY with our binarization. Note that iterative
CKY is an exact inference algorithm that guarantees
to return the optimal parse. As discussed in Sec-
tion 6, the parsing accuracy is not changed in this
experiment.
T&amp;T used a held-out set to learn the best step of
threshold decrease. They reported that the best step
was 11 (in log-probability). We found that the best
step was indeed 11 for left binarization; for our bina-
rizaiton, the best step was 17. T&amp;T used M4 as the
for-statement implementation of CKY. In this part,
we follow the same method.
The result is shown in Table 5. We can see that
iterative CKY can achieve better performance by us-
ing a better binarization. We also see that the reduc-
tion by binarization with pruning is less significant
than without pruning. It seems that the pruning itself
in iterative CKY can counteract the reduction effect
of binarization to some extent. Still the best per-
formance is archieved by combining iterative CKY
with a better binarization.
</bodyText>
<table confidence="0.999213111111111">
CKY + Binarization Constituents Time (s)
Tsuruoka and Tsujii (2004)
CKY + Left 45,406,084 1,164
Iterative CKY + Left 17,520,427 613
Reimplement
CKY + Left 52,128,941 932
CKY + Ours 14,892,203 571
Iterative CKY + Left 23,267,594 377
Iterative CKY + Ours 10,966,272 314
</table>
<tableCaption confidence="0.999927">
Table 5: Combining with iterative CKY parsing
</tableCaption>
<sectionHeader confidence="0.999868" genericHeader="method">
8 Related work
</sectionHeader>
<bodyText confidence="0.9989007">
Almost all work on parsing starts from a binarized
grammar. Usually binarization plays a role of pre-
processing. Left binarization is widely used (Aho
and Ullman, 1972; Charniak et al., 1998; Tsuruoka
and Tsujii, 2004) while right binarization is rarely
used in the literature. Compact binarization was in-
troduced in Schmid (2004), based on the intuition
that a more compact grammar will help acheive a
highly efficient CKY parser, though from our exper-
iment it is not always true.
</bodyText>
<figure confidence="0.997581615384615">
6.0e+07
4.0e+07
2.0e+07
8.0e+07
0.0e+00
1.8e+08
1.6e+08
1.4e+08
1.2e+08
1.0e+08
complete
successful incomplete
failed incomplete
</figure>
<page confidence="0.994544">
174
</page>
<bodyText confidence="0.999992205128205">
We define the fashion of binarizations in Sec-
tion 2, where we encode an intermediate symbol us-
ing the ngrams of original symbols (content) it de-
rives. This encoding is known as the Inside-Trie (I-
Trie) in Klein and Manning (2003a), in which they
also mentioned another encoding called Outside-
Trie (O-Trie). O-Trie encodes an intermediate sym-
bol using the its parent and the symbols surrounding
it in the original rule (context). Klein and Manning
(2003a) claimed that O-Trie is superior for calculat-
ing estimates for A* parsing. We plan to investigate
binarization defined by O-Trie in the future.
Both I-Trie and O-Trie are equivalent encodings,
resulting in equivalent grammars, because they both
encode using the complete content or context infor-
mation of an intermediate symbol. If we use part of
the information to encode, for example just parent in
O-Trie case, the encoding will be non-equivalent.
Proper non-equivalent encodings are used to gen-
eralize the grammar and prevent the binarized gram-
mar becoming too specific (Charniak et al., 2006). It
is equipped with head binarization to help improve
parsing accuracy, following the traditional linguistic
insight that phrases are organized around the head
(Collins, 1997; Klein and Manning, 2003b). In con-
trast, we focus our attention on parsing efficiency
not accuracy in this paper.
Binarization also attracts attention in the syntax-
based models for machine translation, where trans-
lation can be modeled as a parsing problem and bi-
narization is essential for efficient parsing (Zhang
et al., 2006; Huang, 2007).
Wang et al. (2007) employs binarization to de-
compose syntax trees to acquire more re-usable
translation rules in order to improve translation ac-
curacy. Their binarization is restricted to be a mix-
ture of left and right binarization. This constraint
may decrease the power of binarization when ap-
plied to speeding up parsing in our problem.
</bodyText>
<sectionHeader confidence="0.993659" genericHeader="conclusions">
9 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999985966666667">
We have studied the impact of grammar binarization
on parsing efficiency and presented a novel bina-
rization which utilizes rich information learnt from
training corpus. Experiments not only showed that
our learnt binarization outperforms other existing
ones in terms of parsing efficiency, but also demon-
strated the feasibility to combine our binarization
with known parsing speed-up techniques to achieve
even better performance.
An advantage of our approach to finding a good
binarization would be that the training corpus does
not need to be parsed sentences. Only POS tagged
sentences will suffice for training. This will save the
effort to adapt the model to a new domain.
Our approach is based on the assumption that the
efficiency of CKY parsing is primarily determined
by the number of constituents produced. This is a
fairly sound one, but not always true, as shown in
Section 7.2. One future work will be relaxing the
assumption and finding a better appraoch.
Another future work will be to apply our work to
chart parsing. It is known that binarization is also
essential for an O(n3) complexity of chart parsing,
where dotted rules are used to binarize the grammar
implicitly from left. As shown in Charniak et al.
(1998), we can binarize explicitly and use intermedi-
ate symbols to replace dotted rules in chart parsing.
Therefore chart parsing can use multiple binariza-
tions. We expect that a better binarization will also
help improve the efficiency of chart parsing.
</bodyText>
<sectionHeader confidence="0.998195" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999655">
We thank the anonymous reviwers for their pertinent
comments, Yoshimasa Tsuruoka for the detailed ex-
planations on his referred paper, Yunbo Cao, Shu-
jian Huang, Zhenxing Wang, John Blitzer and Liang
Huang for their valuable suggestions in preparing
the paper.
</bodyText>
<sectionHeader confidence="0.999422" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996829230769231">
Aho, A. V. and Ullman, J. D. (1972). The theory
of parsing, translation, and compiling. Prentice-
Hall, Inc., Upper Saddle River, NJ, USA.
Charniak, E., Goldwater, S., and Johnson, M.
(1998). Edge-based best-first chart parsing. In
Proceedings of the Six Workshop on Very Large
Corpora, pages 127–133.
Charniak, E., Johnson, M., Elsner, M., Austerweil,
J., Ellis, D., Haxton, I., Hill, C., Shrivaths, R.,
Moore, J., Pozar, M., and Vu, T. (2006). Multi-
level coarse-to-fine pcfg parsing. In HLT-NAACL.
Collins, M. (1997). Three generative, lexicalised
models for statistical parsing. In ACL.
</reference>
<page confidence="0.984609">
175
</page>
<reference confidence="0.99906275">
Earley, J. (1970). An efficient context-free parsing
algorithm. Commun. ACM, 13(2):94–102.
Goodman, J. (1997). Global thresholding and
multiple-pass parsing. In EMNLP.
Graham, S. L., Harrison, M. A., and Ruzzo, W. L.
(1980). An improved context-free recognizer.
ACM Trans. Program. Lang. Syst., 2(3):415–462.
Huang, L. (2007). Binarization, synchronous bina-
rization, and target-side binarization. In Proceed-
ings of SSST, NAACL-HLT 2007 / AMTA Work-
shop on Syntax and Structure in Statistical Trans-
lation, pages 33–40, Rochester, New York. Asso-
ciation for Computational Linguistics.
Kasami, T. (1965). An efficient recognition and
syntax analysis algorithm for context-free lan-
guages. Technical Report AFCRL-65-758, Air
Force Cambridge Research Laboratory, Bedford,
Massachusetts.
Kay, M. (1980). Algorithm schemata and data struc-
tures in syntactic processing. Technical Report
CSL80-12, Xerox PARC, Palo Alto, CA.
Klein, D. and Manning, C. D. (2001). Parsing and
hypergraphs. In IWPT.
Klein, D. and Manning, C. D. (2003a). A* parsing:
Fast exact viterbi parse selection. In HLT-NAACL.
Klein, D. and Manning, C. D. (2003b). Accurate
unlexicalized parsing. In ACL.
Marcus, M. P., Kim, G., Marcinkiewicz, M. A.,
MacIntyre, R., Bies, A., Ferguson, M., Katz, K.,
and Schasberger, B. (1994). The penn treebank:
Annotating predicate argument structure. In HLT-
NAACL.
Moore, R. C. (2000). Improved left-corner chart
parsing for large context-free grammars. In IWPT.
Petrov, S., Barrett, L., Thibaux, R., and Klein, D.
(2006). Learning accurate, compact, and inter-
pretable tree annotation. In ACL.
Schmid, H. (2004). Efficient parsing of highly am-
biguous context-free grammars with bit vectors.
In COLING.
Tsuruoka, Y. and Tsujii, J. (2004). Iterative cky pars-
ing for probabilistic context-free grammars. In
IJCNLP.
Wang, W., Knight, K., and Marcu, D. (2007). Bina-
rizing syntax trees to improve syntax-based ma-
chine translation accuracy. In EMNLP-CoNLL.
Younger, D. H. (1967). Recognition and parsing of
context-free languages in time n3. Information
and Control, 10(2):189–208.
Zhang, H., Huang, L., Gildea, D., and Knight, K.
(2006). Synchronous binarization for machine
translation. In HLT-NAACL.
</reference>
<page confidence="0.998747">
176
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.683524">
<title confidence="0.997539">Better Binarization for the CKY Parsing</title>
<author confidence="0.945763">Key Laboratory of NLP</author>
<author confidence="0.945763">Harbin Institute of Technology Speech</author>
<author confidence="0.945763">Harbin</author>
<affiliation confidence="0.966476">of Statistics, University of Wisconsin-Madison, Madison,</affiliation>
<address confidence="0.784533">Research Asia, Beijing,</address>
<email confidence="0.99575">xysong@mtlab.hit.edu.cndingsl@gmail.comcyl@microsoft.com</email>
<abstract confidence="0.997099777777778">We present a study on how grammar binarization empirically affects the efficiency of the CKY parsing. We argue that binarizations affect parsing efficiency primarily by affecting the number of incomplete constituents generated, and the effectiveness of binarization also depends on the nature of the input. We propose a novel binarization method utilizing rich information learnt from training corpus. Experimental results not only show that different binarizations have great impacts on parsing efficiency, but also confirm that our learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A V Aho</author>
<author>J D Ullman</author>
</authors>
<title>The theory of parsing, translation, and compiling. PrenticeHall, Inc., Upper Saddle River,</title>
<date>1972</date>
<location>NJ, USA.</location>
<contexts>
<context position="5536" citStr="Aho and Ullman, 1972" startWordPosition="907" endWordPosition="910"> of unary productions, since we adopt an extended version of the CKY algorithm which can handle the unary productions. Moreover we do not distinguish nonterminals and terminals explicitly. We treat them as symbols. What we focus on is the procedure of binarization. Definition 1. A binarization is a function 7r, mapping an n-ary grammar G to an equivalent binary grammar G&apos;. We say that G&apos; is a binarized grammar of G, denoted as 7r(G). Two grammars are equivalent if they define the same probability distribution over strings (Charniak et al., 1998). We use the most widely used left binarization (Aho and Ullman, 1972) to show the procedure of binarization, as illustrated in Table 1, where p and q are the probabilities of the productions. Original grammar Left binarized grammar Y → ABC: p [A B] → AB : 1.0 Z → AB D : q Y → [AB]C:p Z → [AB]D:q Table 1: Left binarization In the binarized grammar, symbols of form [A B] are new (also called intermediate) nonterminals. Left binarization always selects the left most pair of symbols and combines them to form an intermediate nonterminal. This procedure is repeated until all productions are binary. In this paper, we assume that all binarizations follow the fashion ab</context>
<context position="30695" citStr="Aho and Ullman, 1972" startWordPosition="5418" endWordPosition="5421"> binarization to some extent. Still the best performance is archieved by combining iterative CKY with a better binarization. CKY + Binarization Constituents Time (s) Tsuruoka and Tsujii (2004) CKY + Left 45,406,084 1,164 Iterative CKY + Left 17,520,427 613 Reimplement CKY + Left 52,128,941 932 CKY + Ours 14,892,203 571 Iterative CKY + Left 23,267,594 377 Iterative CKY + Ours 10,966,272 314 Table 5: Combining with iterative CKY parsing 8 Related work Almost all work on parsing starts from a binarized grammar. Usually binarization plays a role of preprocessing. Left binarization is widely used (Aho and Ullman, 1972; Charniak et al., 1998; Tsuruoka and Tsujii, 2004) while right binarization is rarely used in the literature. Compact binarization was introduced in Schmid (2004), based on the intuition that a more compact grammar will help acheive a highly efficient CKY parser, though from our experiment it is not always true. 6.0e+07 4.0e+07 2.0e+07 8.0e+07 0.0e+00 1.8e+08 1.6e+08 1.4e+08 1.2e+08 1.0e+08 complete successful incomplete failed incomplete 174 We define the fashion of binarizations in Section 2, where we encode an intermediate symbol using the ngrams of original symbols (content) it derives. T</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Aho, A. V. and Ullman, J. D. (1972). The theory of parsing, translation, and compiling. PrenticeHall, Inc., Upper Saddle River, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>S Goldwater</author>
<author>M Johnson</author>
</authors>
<title>Edge-based best-first chart parsing.</title>
<date>1998</date>
<booktitle>In Proceedings of the Six Workshop on Very Large Corpora,</booktitle>
<pages>127--133</pages>
<contexts>
<context position="1622" citStr="Charniak et al., 1998" startWordPosition="233" endWordPosition="236">ting parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but maybe different parsing efficiency, i.e. parsing speed. We are interested in investigating whether and how binarizations will affect the efficiency of the CKY parsing. Do different binarizations lead to different parsing efficiency? Figure 1 gives an example to help answ</context>
<context position="5466" citStr="Charniak et al., 1998" startWordPosition="895" endWordPosition="898">ns no &amp; productions or useless symbols. However, we allow the existence of unary productions, since we adopt an extended version of the CKY algorithm which can handle the unary productions. Moreover we do not distinguish nonterminals and terminals explicitly. We treat them as symbols. What we focus on is the procedure of binarization. Definition 1. A binarization is a function 7r, mapping an n-ary grammar G to an equivalent binary grammar G&apos;. We say that G&apos; is a binarized grammar of G, denoted as 7r(G). Two grammars are equivalent if they define the same probability distribution over strings (Charniak et al., 1998). We use the most widely used left binarization (Aho and Ullman, 1972) to show the procedure of binarization, as illustrated in Table 1, where p and q are the probabilities of the productions. Original grammar Left binarized grammar Y → ABC: p [A B] → AB : 1.0 Z → AB D : q Y → [AB]C:p Z → [AB]D:q Table 1: Left binarization In the binarized grammar, symbols of form [A B] are new (also called intermediate) nonterminals. Left binarization always selects the left most pair of symbols and combines them to form an intermediate nonterminal. This procedure is repeated until all productions are binary.</context>
<context position="30718" citStr="Charniak et al., 1998" startWordPosition="5422" endWordPosition="5425">extent. Still the best performance is archieved by combining iterative CKY with a better binarization. CKY + Binarization Constituents Time (s) Tsuruoka and Tsujii (2004) CKY + Left 45,406,084 1,164 Iterative CKY + Left 17,520,427 613 Reimplement CKY + Left 52,128,941 932 CKY + Ours 14,892,203 571 Iterative CKY + Left 23,267,594 377 Iterative CKY + Ours 10,966,272 314 Table 5: Combining with iterative CKY parsing 8 Related work Almost all work on parsing starts from a binarized grammar. Usually binarization plays a role of preprocessing. Left binarization is widely used (Aho and Ullman, 1972; Charniak et al., 1998; Tsuruoka and Tsujii, 2004) while right binarization is rarely used in the literature. Compact binarization was introduced in Schmid (2004), based on the intuition that a more compact grammar will help acheive a highly efficient CKY parser, though from our experiment it is not always true. 6.0e+07 4.0e+07 2.0e+07 8.0e+07 0.0e+00 1.8e+08 1.6e+08 1.4e+08 1.2e+08 1.0e+08 complete successful incomplete failed incomplete 174 We define the fashion of binarizations in Section 2, where we encode an intermediate symbol using the ngrams of original symbols (content) it derives. This encoding is known a</context>
</contexts>
<marker>Charniak, Goldwater, Johnson, 1998</marker>
<rawString>Charniak, E., Goldwater, S., and Johnson, M. (1998). Edge-based best-first chart parsing. In Proceedings of the Six Workshop on Very Large Corpora, pages 127–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>M Johnson</author>
<author>M Elsner</author>
<author>J Austerweil</author>
<author>D Ellis</author>
<author>I Haxton</author>
<author>C Hill</author>
<author>R Shrivaths</author>
<author>J Moore</author>
<author>M Pozar</author>
<author>T Vu</author>
</authors>
<title>Multilevel coarse-to-fine pcfg parsing.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="6528" citStr="Charniak et al. (2006)" startWordPosition="1077" endWordPosition="1080">always selects the left most pair of symbols and combines them to form an intermediate nonterminal. This procedure is repeated until all productions are binary. In this paper, we assume that all binarizations follow the fashion above, except that the choice of pair of symbols for combination can be arbitrary. Next we show three other known binarizations. Right binarization is almost the same with left binarization, except that it always selects the right most pair, instead of left, to combine. Head binarization always binarizes from the head outward (Klein and Manning, 2003b). Please refer to Charniak et al. (2006) for more details. Compact binarization (Schmid, 2004) tries to minimize the size of the binarized grammar. It leads to a compact grammar. We therefore call it compact binarization. It is done via a greedy approach: it always selects the pair that occurs most on the right hand sides of rules to combine. 3 The optimal binarization The optimal binarization should help CKY parsing to achieve its best efficiency. We formalize the idea as follows: Definition 2. The optimal binarization is 7r*, for a given n-ary grammar G and a test corpus C: T(7r(G),C) (1) where T(7r(G), C) is the running time for </context>
<context position="9387" citStr="Charniak et al., 2006" startWordPosition="1601" endWordPosition="1604">al binarization will be the one with minimal number of rules, i.e. minimal binarized grammar size. However, M1 is usually not preferred in practice (Goodman, 1997). For other methods, it is hard to tell which binarization is optimal theoretically. In this paper, for simplicity reasons we do not consider the effect of for-statement implementations on the optimal binarization. On the other hand, it is well known that reducing the number of constituents produced in parsing can greatly improve CKY parsing efficiency. That is how most thresholding systems (Goodman, 1997; Tsuruoka and Tsujii, 2004; Charniak et al., 2006) speed up CKY parsing. Apparently, the number of 1Note that we should skip Y (Z) if it never appears as the first (second) symbol on the right hand side of any rule. constituents produced in parsing is not affected by for-statement implementations. Therefore we assume that the running time of CKY is primarily determined by the number of constituents generated in parsing. We simplify the optimal binarization to be: 7r* ≈ arg min E(7r(G), C) (2) 7r where E(7r(G), C) is the number of constituents generated when CKY parsing C with 7r(G). We next discuss how binarizations affect the number of const</context>
<context position="20693" citStr="Charniak et al., 2006" startWordPosition="3722" endWordPosition="3726"> unchanged, the parsing will be more efficient. We will conduct experiment to confirm this idea in the next section. We would like to make more discussions before we advance to the experiments. The first is about parsing accuracy in combining binarization with other parsing speed-up techniques. Binarization itself does not affect parsing accuracy. When combined with exact inference algorithms, like the iterative CKY (Tsuruoka and Tsujii, 2004), the accuracy will be the same. However, if combined with other inexact pruning techniques like beam-pruning (Goodman, 1997) or coarse-to-fine parsing (Charniak et al., 2006), binarization may interact with those pruning methods in a complicated way to affect parsing accuracy. This is due to different binarizations generate different sets of intermediate sym3For log-linear form, if num(w) = 0 (and consequently ctr(w) = 0), we set f(num(w), ctr(w)) = 0; if num(w) &gt; 0 but ctr(w) = 0, we set f(num(w), ctr(w)) = −oo. 4Since f is used for ranking, the magnitude is not important. bols. With the same complete constituents, one binarization might derive incomplete constitutes that could be pruned while another binarization may not. This would affect the accuracy. We do no</context>
<context position="32193" citStr="Charniak et al., 2006" startWordPosition="5656" endWordPosition="5659">Klein and Manning (2003a) claimed that O-Trie is superior for calculating estimates for A* parsing. We plan to investigate binarization defined by O-Trie in the future. Both I-Trie and O-Trie are equivalent encodings, resulting in equivalent grammars, because they both encode using the complete content or context information of an intermediate symbol. If we use part of the information to encode, for example just parent in O-Trie case, the encoding will be non-equivalent. Proper non-equivalent encodings are used to generalize the grammar and prevent the binarized grammar becoming too specific (Charniak et al., 2006). It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b). In contrast, we focus our attention on parsing efficiency not accuracy in this paper. Binarization also attracts attention in the syntaxbased models for machine translation, where translation can be modeled as a parsing problem and binarization is essential for efficient parsing (Zhang et al., 2006; Huang, 2007). Wang et al. (2007) employs binarization to decompose syntax trees to acquire mor</context>
</contexts>
<marker>Charniak, Johnson, Elsner, Austerweil, Ellis, Haxton, Hill, Shrivaths, Moore, Pozar, Vu, 2006</marker>
<rawString>Charniak, E., Johnson, M., Elsner, M., Austerweil, J., Ellis, D., Haxton, I., Hill, C., Shrivaths, R., Moore, J., Pozar, M., and Vu, T. (2006). Multilevel coarse-to-fine pcfg parsing. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="21868" citStr="Collins (1997)" startWordPosition="3924" endWordPosition="3925">his would affect the accuracy. We do not address this interaction on in this paper, but leave it to the future work. In Section 7.3 we will use the iterative CKY for testing. In addition, we believe there exist some speed-up techniques which are incompatible with our binarization. One such example may be the top-down left-corner filtering (Graham et al., 1980; Moore, 2000), which seems to be only applicable to the process of left binarization. A detailed investigation on this problem will be left to the future work. The last issue is how our binarization performs on a lexicalized parser, like Collins (1997). Our intuition is that we cannot apply our binarization to Collins (1997). The key fact in lexicalized parsers is that we cannot explicitly write down all rules and compute their probabilities precisely, due to the great number of rules and the severe data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a set of probabilities. In order to capture the dependency relationship between lexcial heads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways. Therefore our binarization cannot apply to the l</context>
<context position="32369" citStr="Collins, 1997" startWordPosition="5683" endWordPosition="5684">O-Trie are equivalent encodings, resulting in equivalent grammars, because they both encode using the complete content or context information of an intermediate symbol. If we use part of the information to encode, for example just parent in O-Trie case, the encoding will be non-equivalent. Proper non-equivalent encodings are used to generalize the grammar and prevent the binarized grammar becoming too specific (Charniak et al., 2006). It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b). In contrast, we focus our attention on parsing efficiency not accuracy in this paper. Binarization also attracts attention in the syntaxbased models for machine translation, where translation can be modeled as a parsing problem and binarization is essential for efficient parsing (Zhang et al., 2006; Huang, 2007). Wang et al. (2007) employs binarization to decompose syntax trees to acquire more re-usable translation rules in order to improve translation accuracy. Their binarization is restricted to be a mixture of left and right binarization. This constraint may dec</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Collins, M. (1997). Three generative, lexicalised models for statistical parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Commun. ACM,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="1441" citStr="Earley, 1970" startWordPosition="207" endWordPosition="208">eat impacts on parsing efficiency, but also confirm that our learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but maybe different parsing efficiency, i.e. parsing speed. We are interested in investigating</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Earley, J. (1970). An efficient context-free parsing algorithm. Commun. ACM, 13(2):94–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Goodman</author>
</authors>
<title>Global thresholding and multiple-pass parsing.</title>
<date>1997</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="8928" citStr="Goodman, 1997" startWordPosition="1529" endWordPosition="1530"> 1: for X → Y Z, Y in left span and Z in right span 2: Add X to parent span 3.2 Model assumption We have shown that both binarization and the forstatement implementation in the inner most loop of CKY will affect the parsing speed. About the for-statement implementations, no previous study has addressed which one is superior. The actual choice may affect our study on binarization. If using M1, since it enumerates all rules in the grammar, the optimal binarization will be the one with minimal number of rules, i.e. minimal binarized grammar size. However, M1 is usually not preferred in practice (Goodman, 1997). For other methods, it is hard to tell which binarization is optimal theoretically. In this paper, for simplicity reasons we do not consider the effect of for-statement implementations on the optimal binarization. On the other hand, it is well known that reducing the number of constituents produced in parsing can greatly improve CKY parsing efficiency. That is how most thresholding systems (Goodman, 1997; Tsuruoka and Tsujii, 2004; Charniak et al., 2006) speed up CKY parsing. Apparently, the number of 1Note that we should skip Y (Z) if it never appears as the first (second) symbol on the righ</context>
<context position="20643" citStr="Goodman, 1997" startWordPosition="3717" endWordPosition="3718">r one while keeping the subsequent parsing unchanged, the parsing will be more efficient. We will conduct experiment to confirm this idea in the next section. We would like to make more discussions before we advance to the experiments. The first is about parsing accuracy in combining binarization with other parsing speed-up techniques. Binarization itself does not affect parsing accuracy. When combined with exact inference algorithms, like the iterative CKY (Tsuruoka and Tsujii, 2004), the accuracy will be the same. However, if combined with other inexact pruning techniques like beam-pruning (Goodman, 1997) or coarse-to-fine parsing (Charniak et al., 2006), binarization may interact with those pruning methods in a complicated way to affect parsing accuracy. This is due to different binarizations generate different sets of intermediate sym3For log-linear form, if num(w) = 0 (and consequently ctr(w) = 0), we set f(num(w), ctr(w)) = 0; if num(w) &gt; 0 but ctr(w) = 0, we set f(num(w), ctr(w)) = −oo. 4Since f is used for ranking, the magnitude is not important. bols. With the same complete constituents, one binarization might derive incomplete constitutes that could be pruned while another binarization</context>
</contexts>
<marker>Goodman, 1997</marker>
<rawString>Goodman, J. (1997). Global thresholding and multiple-pass parsing. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S L Graham</author>
<author>M A Harrison</author>
<author>W L Ruzzo</author>
</authors>
<title>An improved context-free recognizer.</title>
<date>1980</date>
<journal>ACM Trans. Program. Lang. Syst.,</journal>
<volume>2</volume>
<issue>3</issue>
<contexts>
<context position="1404" citStr="Graham et al., 1980" startWordPosition="200" endWordPosition="203">ly show that different binarizations have great impacts on parsing efficiency, but also confirm that our learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but maybe different parsing efficiency, i.e. parsing spee</context>
<context position="21615" citStr="Graham et al., 1980" startWordPosition="3879" endWordPosition="3882">r(w) = 0, we set f(num(w), ctr(w)) = −oo. 4Since f is used for ranking, the magnitude is not important. bols. With the same complete constituents, one binarization might derive incomplete constitutes that could be pruned while another binarization may not. This would affect the accuracy. We do not address this interaction on in this paper, but leave it to the future work. In Section 7.3 we will use the iterative CKY for testing. In addition, we believe there exist some speed-up techniques which are incompatible with our binarization. One such example may be the top-down left-corner filtering (Graham et al., 1980; Moore, 2000), which seems to be only applicable to the process of left binarization. A detailed investigation on this problem will be left to the future work. The last issue is how our binarization performs on a lexicalized parser, like Collins (1997). Our intuition is that we cannot apply our binarization to Collins (1997). The key fact in lexicalized parsers is that we cannot explicitly write down all rules and compute their probabilities precisely, due to the great number of rules and the severe data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a</context>
</contexts>
<marker>Graham, Harrison, Ruzzo, 1980</marker>
<rawString>Graham, S. L., Harrison, M. A., and Ruzzo, W. L. (1980). An improved context-free recognizer. ACM Trans. Program. Lang. Syst., 2(3):415–462.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
</authors>
<title>Binarization, synchronous binarization, and target-side binarization.</title>
<date>2007</date>
<booktitle>In Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>33--40</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York.</location>
<contexts>
<context position="32711" citStr="Huang, 2007" startWordPosition="5738" endWordPosition="5739">ze the grammar and prevent the binarized grammar becoming too specific (Charniak et al., 2006). It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b). In contrast, we focus our attention on parsing efficiency not accuracy in this paper. Binarization also attracts attention in the syntaxbased models for machine translation, where translation can be modeled as a parsing problem and binarization is essential for efficient parsing (Zhang et al., 2006; Huang, 2007). Wang et al. (2007) employs binarization to decompose syntax trees to acquire more re-usable translation rules in order to improve translation accuracy. Their binarization is restricted to be a mixture of left and right binarization. This constraint may decrease the power of binarization when applied to speeding up parsing in our problem. 9 Conclusions and future work We have studied the impact of grammar binarization on parsing efficiency and presented a novel binarization which utilizes rich information learnt from training corpus. Experiments not only showed that our learnt binarization ou</context>
</contexts>
<marker>Huang, 2007</marker>
<rawString>Huang, L. (2007). Binarization, synchronous binarization, and target-side binarization. In Proceedings of SSST, NAACL-HLT 2007 / AMTA Workshop on Syntax and Structure in Statistical Translation, pages 33–40, Rochester, New York. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kasami</author>
</authors>
<title>An efficient recognition and syntax analysis algorithm for context-free languages.</title>
<date>1965</date>
<tech>Technical Report AFCRL-65-758,</tech>
<institution>Air Force Cambridge Research Laboratory,</institution>
<location>Bedford, Massachusetts.</location>
<contexts>
<context position="1350" citStr="Kasami, 1965" startWordPosition="193" endWordPosition="194">m training corpus. Experimental results not only show that different binarizations have great impacts on parsing efficiency, but also confirm that our learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but</context>
</contexts>
<marker>Kasami, 1965</marker>
<rawString>Kasami, T. (1965). An efficient recognition and syntax analysis algorithm for context-free languages. Technical Report AFCRL-65-758, Air Force Cambridge Research Laboratory, Bedford, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Algorithm schemata and data structures in syntactic processing.</title>
<date>1980</date>
<tech>Technical Report CSL80-12, Xerox PARC,</tech>
<location>Palo Alto, CA.</location>
<contexts>
<context position="1484" citStr="Kay, 1980" startWordPosition="214" endWordPosition="215">firm that our learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but maybe different parsing efficiency, i.e. parsing speed. We are interested in investigating whether and how binarizations will affect </context>
</contexts>
<marker>Kay, 1980</marker>
<rawString>Kay, M. (1980). Algorithm schemata and data structures in syntactic processing. Technical Report CSL80-12, Xerox PARC, Palo Alto, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Parsing and hypergraphs.</title>
<date>2001</date>
<booktitle>In IWPT.</booktitle>
<contexts>
<context position="1510" citStr="Klein and Manning, 2001" startWordPosition="216" endWordPosition="219">ur learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but maybe different parsing efficiency, i.e. parsing speed. We are interested in investigating whether and how binarizations will affect the efficiency of the CKY </context>
</contexts>
<marker>Klein, Manning, 2001</marker>
<rawString>Klein, D. and Manning, C. D. (2001). Parsing and hypergraphs. In IWPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>A* parsing: Fast exact viterbi parse selection.</title>
<date>2003</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="6486" citStr="Klein and Manning, 2003" startWordPosition="1070" endWordPosition="1073">ermediate) nonterminals. Left binarization always selects the left most pair of symbols and combines them to form an intermediate nonterminal. This procedure is repeated until all productions are binary. In this paper, we assume that all binarizations follow the fashion above, except that the choice of pair of symbols for combination can be arbitrary. Next we show three other known binarizations. Right binarization is almost the same with left binarization, except that it always selects the right most pair, instead of left, to combine. Head binarization always binarizes from the head outward (Klein and Manning, 2003b). Please refer to Charniak et al. (2006) for more details. Compact binarization (Schmid, 2004) tries to minimize the size of the binarized grammar. It leads to a compact grammar. We therefore call it compact binarization. It is done via a greedy approach: it always selects the pair that occurs most on the right hand sides of rules to combine. 3 The optimal binarization The optimal binarization should help CKY parsing to achieve its best efficiency. We formalize the idea as follows: Definition 2. The optimal binarization is 7r*, for a given n-ary grammar G and a test corpus C: T(7r(G),C) (1) </context>
<context position="22569" citStr="Klein and Manning, 2003" startWordPosition="4032" endWordPosition="4035">e key fact in lexicalized parsers is that we cannot explicitly write down all rules and compute their probabilities precisely, due to the great number of rules and the severe data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a set of probabilities. In order to capture the dependency relationship between lexcial heads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways. Therefore our binarization cannot apply to the lexicalized parser. However, there are state-of-the-art unlexicalized parsers (Klein and Manning, 2003b; Petrov et al., 2006), to which we believe our binarization can be applied. 7 Experiments We conducted two experiments on Penn Treebank II corpus (Marcus et al., 1994). The first is to compare the effects of different binarizations on parsing and the second is to test the feasibility to combine our work with iterative CKY parsing (Tsuruoka and Tsujii, 2004) to achieve even better efficiency. 7.1 Experimental setup Following conventions, we learnt the grammar from Wall Street Journal (WSJ) section 2 to 21 and modified it by discarding all functional tags and empty nodes. The parser obtained t</context>
<context position="31370" citStr="Klein and Manning (2003" startWordPosition="5527" endWordPosition="5530">while right binarization is rarely used in the literature. Compact binarization was introduced in Schmid (2004), based on the intuition that a more compact grammar will help acheive a highly efficient CKY parser, though from our experiment it is not always true. 6.0e+07 4.0e+07 2.0e+07 8.0e+07 0.0e+00 1.8e+08 1.6e+08 1.4e+08 1.2e+08 1.0e+08 complete successful incomplete failed incomplete 174 We define the fashion of binarizations in Section 2, where we encode an intermediate symbol using the ngrams of original symbols (content) it derives. This encoding is known as the Inside-Trie (ITrie) in Klein and Manning (2003a), in which they also mentioned another encoding called OutsideTrie (O-Trie). O-Trie encodes an intermediate symbol using the its parent and the symbols surrounding it in the original rule (context). Klein and Manning (2003a) claimed that O-Trie is superior for calculating estimates for A* parsing. We plan to investigate binarization defined by O-Trie in the future. Both I-Trie and O-Trie are equivalent encodings, resulting in equivalent grammars, because they both encode using the complete content or context information of an intermediate symbol. If we use part of the information to encode, </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, D. and Manning, C. D. (2003a). A* parsing: Fast exact viterbi parse selection. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="6486" citStr="Klein and Manning, 2003" startWordPosition="1070" endWordPosition="1073">ermediate) nonterminals. Left binarization always selects the left most pair of symbols and combines them to form an intermediate nonterminal. This procedure is repeated until all productions are binary. In this paper, we assume that all binarizations follow the fashion above, except that the choice of pair of symbols for combination can be arbitrary. Next we show three other known binarizations. Right binarization is almost the same with left binarization, except that it always selects the right most pair, instead of left, to combine. Head binarization always binarizes from the head outward (Klein and Manning, 2003b). Please refer to Charniak et al. (2006) for more details. Compact binarization (Schmid, 2004) tries to minimize the size of the binarized grammar. It leads to a compact grammar. We therefore call it compact binarization. It is done via a greedy approach: it always selects the pair that occurs most on the right hand sides of rules to combine. 3 The optimal binarization The optimal binarization should help CKY parsing to achieve its best efficiency. We formalize the idea as follows: Definition 2. The optimal binarization is 7r*, for a given n-ary grammar G and a test corpus C: T(7r(G),C) (1) </context>
<context position="22569" citStr="Klein and Manning, 2003" startWordPosition="4032" endWordPosition="4035">e key fact in lexicalized parsers is that we cannot explicitly write down all rules and compute their probabilities precisely, due to the great number of rules and the severe data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a set of probabilities. In order to capture the dependency relationship between lexcial heads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways. Therefore our binarization cannot apply to the lexicalized parser. However, there are state-of-the-art unlexicalized parsers (Klein and Manning, 2003b; Petrov et al., 2006), to which we believe our binarization can be applied. 7 Experiments We conducted two experiments on Penn Treebank II corpus (Marcus et al., 1994). The first is to compare the effects of different binarizations on parsing and the second is to test the feasibility to combine our work with iterative CKY parsing (Tsuruoka and Tsujii, 2004) to achieve even better efficiency. 7.1 Experimental setup Following conventions, we learnt the grammar from Wall Street Journal (WSJ) section 2 to 21 and modified it by discarding all functional tags and empty nodes. The parser obtained t</context>
<context position="31370" citStr="Klein and Manning (2003" startWordPosition="5527" endWordPosition="5530">while right binarization is rarely used in the literature. Compact binarization was introduced in Schmid (2004), based on the intuition that a more compact grammar will help acheive a highly efficient CKY parser, though from our experiment it is not always true. 6.0e+07 4.0e+07 2.0e+07 8.0e+07 0.0e+00 1.8e+08 1.6e+08 1.4e+08 1.2e+08 1.0e+08 complete successful incomplete failed incomplete 174 We define the fashion of binarizations in Section 2, where we encode an intermediate symbol using the ngrams of original symbols (content) it derives. This encoding is known as the Inside-Trie (ITrie) in Klein and Manning (2003a), in which they also mentioned another encoding called OutsideTrie (O-Trie). O-Trie encodes an intermediate symbol using the its parent and the symbols surrounding it in the original rule (context). Klein and Manning (2003a) claimed that O-Trie is superior for calculating estimates for A* parsing. We plan to investigate binarization defined by O-Trie in the future. Both I-Trie and O-Trie are equivalent encodings, resulting in equivalent grammars, because they both encode using the complete content or context information of an intermediate symbol. If we use part of the information to encode, </context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Klein, D. and Manning, C. D. (2003b). Accurate unlexicalized parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>G Kim</author>
<author>M A Marcinkiewicz</author>
<author>R MacIntyre</author>
<author>A Bies</author>
<author>M Ferguson</author>
<author>K Katz</author>
<author>B Schasberger</author>
</authors>
<title>The penn treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In HLTNAACL.</booktitle>
<contexts>
<context position="22738" citStr="Marcus et al., 1994" startWordPosition="4060" endWordPosition="4063">re data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a set of probabilities. In order to capture the dependency relationship between lexcial heads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways. Therefore our binarization cannot apply to the lexicalized parser. However, there are state-of-the-art unlexicalized parsers (Klein and Manning, 2003b; Petrov et al., 2006), to which we believe our binarization can be applied. 7 Experiments We conducted two experiments on Penn Treebank II corpus (Marcus et al., 1994). The first is to compare the effects of different binarizations on parsing and the second is to test the feasibility to combine our work with iterative CKY parsing (Tsuruoka and Tsujii, 2004) to achieve even better efficiency. 7.1 Experimental setup Following conventions, we learnt the grammar from Wall Street Journal (WSJ) section 2 to 21 and modified it by discarding all functional tags and empty nodes. The parser obtained this way is a pure unlexicalized context-free parser with the raw treebank grammar. Its accuracy turns out to be 72.46% in 172 terms of F1 measure, quite the same as 72.6</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Marcus, M. P., Kim, G., Marcinkiewicz, M. A., MacIntyre, R., Bies, A., Ferguson, M., Katz, K., and Schasberger, B. (1994). The penn treebank: Annotating predicate argument structure. In HLTNAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Improved left-corner chart parsing for large context-free grammars.</title>
<date>2000</date>
<booktitle>In IWPT.</booktitle>
<contexts>
<context position="21629" citStr="Moore, 2000" startWordPosition="3883" endWordPosition="3884">m(w), ctr(w)) = −oo. 4Since f is used for ranking, the magnitude is not important. bols. With the same complete constituents, one binarization might derive incomplete constitutes that could be pruned while another binarization may not. This would affect the accuracy. We do not address this interaction on in this paper, but leave it to the future work. In Section 7.3 we will use the iterative CKY for testing. In addition, we believe there exist some speed-up techniques which are incompatible with our binarization. One such example may be the top-down left-corner filtering (Graham et al., 1980; Moore, 2000), which seems to be only applicable to the process of left binarization. A detailed investigation on this problem will be left to the future work. The last issue is how our binarization performs on a lexicalized parser, like Collins (1997). Our intuition is that we cannot apply our binarization to Collins (1997). The key fact in lexicalized parsers is that we cannot explicitly write down all rules and compute their probabilities precisely, due to the great number of rules and the severe data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a set of probab</context>
</contexts>
<marker>Moore, 2000</marker>
<rawString>Moore, R. C. (2000). Improved left-corner chart parsing for large context-free grammars. In IWPT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>L Barrett</author>
<author>R Thibaux</author>
<author>D Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="22592" citStr="Petrov et al., 2006" startWordPosition="4036" endWordPosition="4039">parsers is that we cannot explicitly write down all rules and compute their probabilities precisely, due to the great number of rules and the severe data sparsity problem. Therefore in Collins (1997) grammar rules are already factorized into a set of probabilities. In order to capture the dependency relationship between lexcial heads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways. Therefore our binarization cannot apply to the lexicalized parser. However, there are state-of-the-art unlexicalized parsers (Klein and Manning, 2003b; Petrov et al., 2006), to which we believe our binarization can be applied. 7 Experiments We conducted two experiments on Penn Treebank II corpus (Marcus et al., 1994). The first is to compare the effects of different binarizations on parsing and the second is to test the feasibility to combine our work with iterative CKY parsing (Tsuruoka and Tsujii, 2004) to achieve even better efficiency. 7.1 Experimental setup Following conventions, we learnt the grammar from Wall Street Journal (WSJ) section 2 to 21 and modified it by discarding all functional tags and empty nodes. The parser obtained this way is a pure unlex</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Petrov, S., Barrett, L., Thibaux, R., and Klein, D. (2006). Learning accurate, compact, and interpretable tree annotation. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Efficient parsing of highly ambiguous context-free grammars with bit vectors.</title>
<date>2004</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="6582" citStr="Schmid, 2004" startWordPosition="1086" endWordPosition="1087">to form an intermediate nonterminal. This procedure is repeated until all productions are binary. In this paper, we assume that all binarizations follow the fashion above, except that the choice of pair of symbols for combination can be arbitrary. Next we show three other known binarizations. Right binarization is almost the same with left binarization, except that it always selects the right most pair, instead of left, to combine. Head binarization always binarizes from the head outward (Klein and Manning, 2003b). Please refer to Charniak et al. (2006) for more details. Compact binarization (Schmid, 2004) tries to minimize the size of the binarized grammar. It leads to a compact grammar. We therefore call it compact binarization. It is done via a greedy approach: it always selects the pair that occurs most on the right hand sides of rules to combine. 3 The optimal binarization The optimal binarization should help CKY parsing to achieve its best efficiency. We formalize the idea as follows: Definition 2. The optimal binarization is 7r*, for a given n-ary grammar G and a test corpus C: T(7r(G),C) (1) where T(7r(G), C) is the running time for CKY to parse corpus C, using the binarized grammar 7r(</context>
<context position="30858" citStr="Schmid (2004)" startWordPosition="5445" endWordPosition="5446">uoka and Tsujii (2004) CKY + Left 45,406,084 1,164 Iterative CKY + Left 17,520,427 613 Reimplement CKY + Left 52,128,941 932 CKY + Ours 14,892,203 571 Iterative CKY + Left 23,267,594 377 Iterative CKY + Ours 10,966,272 314 Table 5: Combining with iterative CKY parsing 8 Related work Almost all work on parsing starts from a binarized grammar. Usually binarization plays a role of preprocessing. Left binarization is widely used (Aho and Ullman, 1972; Charniak et al., 1998; Tsuruoka and Tsujii, 2004) while right binarization is rarely used in the literature. Compact binarization was introduced in Schmid (2004), based on the intuition that a more compact grammar will help acheive a highly efficient CKY parser, though from our experiment it is not always true. 6.0e+07 4.0e+07 2.0e+07 8.0e+07 0.0e+00 1.8e+08 1.6e+08 1.4e+08 1.2e+08 1.0e+08 complete successful incomplete failed incomplete 174 We define the fashion of binarizations in Section 2, where we encode an intermediate symbol using the ngrams of original symbols (content) it derives. This encoding is known as the Inside-Trie (ITrie) in Klein and Manning (2003a), in which they also mentioned another encoding called OutsideTrie (O-Trie). O-Trie en</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Schmid, H. (2004). Efficient parsing of highly ambiguous context-free grammars with bit vectors. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Tsuruoka</author>
<author>J Tsujii</author>
</authors>
<title>Iterative cky parsing for probabilistic context-free grammars.</title>
<date>2004</date>
<booktitle>In IJCNLP.</booktitle>
<contexts>
<context position="9363" citStr="Tsuruoka and Tsujii, 2004" startWordPosition="1597" endWordPosition="1600">s in the grammar, the optimal binarization will be the one with minimal number of rules, i.e. minimal binarized grammar size. However, M1 is usually not preferred in practice (Goodman, 1997). For other methods, it is hard to tell which binarization is optimal theoretically. In this paper, for simplicity reasons we do not consider the effect of for-statement implementations on the optimal binarization. On the other hand, it is well known that reducing the number of constituents produced in parsing can greatly improve CKY parsing efficiency. That is how most thresholding systems (Goodman, 1997; Tsuruoka and Tsujii, 2004; Charniak et al., 2006) speed up CKY parsing. Apparently, the number of 1Note that we should skip Y (Z) if it never appears as the first (second) symbol on the right hand side of any rule. constituents produced in parsing is not affected by for-statement implementations. Therefore we assume that the running time of CKY is primarily determined by the number of constituents generated in parsing. We simplify the optimal binarization to be: 7r* ≈ arg min E(7r(G), C) (2) 7r where E(7r(G), C) is the number of constituents generated when CKY parsing C with 7r(G). We next discuss how binarizations af</context>
<context position="20518" citStr="Tsuruoka and Tsujii, 2004" startWordPosition="3696" endWordPosition="3699">rsing. There are many known works on speeding up the CKY parsing. So we can expect that if we replace the part of binarization by a better one while keeping the subsequent parsing unchanged, the parsing will be more efficient. We will conduct experiment to confirm this idea in the next section. We would like to make more discussions before we advance to the experiments. The first is about parsing accuracy in combining binarization with other parsing speed-up techniques. Binarization itself does not affect parsing accuracy. When combined with exact inference algorithms, like the iterative CKY (Tsuruoka and Tsujii, 2004), the accuracy will be the same. However, if combined with other inexact pruning techniques like beam-pruning (Goodman, 1997) or coarse-to-fine parsing (Charniak et al., 2006), binarization may interact with those pruning methods in a complicated way to affect parsing accuracy. This is due to different binarizations generate different sets of intermediate sym3For log-linear form, if num(w) = 0 (and consequently ctr(w) = 0), we set f(num(w), ctr(w)) = 0; if num(w) &gt; 0 but ctr(w) = 0, we set f(num(w), ctr(w)) = −oo. 4Since f is used for ranking, the magnitude is not important. bols. With the sam</context>
<context position="22930" citStr="Tsuruoka and Tsujii, 2004" startWordPosition="4093" endWordPosition="4096">ads Collins (1997) breaks down the rules from head outwards, which prevents us from factorizing them in other ways. Therefore our binarization cannot apply to the lexicalized parser. However, there are state-of-the-art unlexicalized parsers (Klein and Manning, 2003b; Petrov et al., 2006), to which we believe our binarization can be applied. 7 Experiments We conducted two experiments on Penn Treebank II corpus (Marcus et al., 1994). The first is to compare the effects of different binarizations on parsing and the second is to test the feasibility to combine our work with iterative CKY parsing (Tsuruoka and Tsujii, 2004) to achieve even better efficiency. 7.1 Experimental setup Following conventions, we learnt the grammar from Wall Street Journal (WSJ) section 2 to 21 and modified it by discarding all functional tags and empty nodes. The parser obtained this way is a pure unlexicalized context-free parser with the raw treebank grammar. Its accuracy turns out to be 72.46% in 172 terms of F1 measure, quite the same as 72.62% as stated in Klein and Manning (2003b). We adopt this parser in our experiment not only because of simplicity but also because we focus on parsing efficiency. For all sentences with no more</context>
<context position="28812" citStr="Tsuruoka and Tsujii, 2004" startWordPosition="5102" endWordPosition="5105">he input language. To our surprise, our learnt binarization indeed captures this linguistic insight, by binarizing NP —* NP CC NP from right to left. Finally, we would like to acknowledge the limitation of our assumption made in Section 3.2. Table 4 shows that the parsing time of CKY is not always monotonic increasing with the number of constituents produced. Head binarization produces fewer constituents than left binarization but consumes more parsing time. 7.3 Experiment 2: combine with iterative CKY In this part, we test the performance of combining our binarization with the iterative CKY (Tsuruoka and Tsujii, 2004) (henceforth T&amp;T) algorithm. Iterative CKY is a procedure of multiple passes of normal CKY: in each pass, it uses a threshold to prune bad constituents; if it cannot find a successful parse in one pass, it will relax the threshold and start another; this procedure is repeated until a successful parse is returned. T&amp;T used left binarization. We re-implement their experiments and combine iterative CKY with our binarization. Note that iterative CKY is an exact inference algorithm that guarantees to return the optimal parse. As discussed in Section 6, the parsing accuracy is not changed in this ex</context>
<context position="30267" citStr="Tsuruoka and Tsujii (2004)" startWordPosition="5347" endWordPosition="5350">the best step was 17. T&amp;T used M4 as the for-statement implementation of CKY. In this part, we follow the same method. The result is shown in Table 5. We can see that iterative CKY can achieve better performance by using a better binarization. We also see that the reduction by binarization with pruning is less significant than without pruning. It seems that the pruning itself in iterative CKY can counteract the reduction effect of binarization to some extent. Still the best performance is archieved by combining iterative CKY with a better binarization. CKY + Binarization Constituents Time (s) Tsuruoka and Tsujii (2004) CKY + Left 45,406,084 1,164 Iterative CKY + Left 17,520,427 613 Reimplement CKY + Left 52,128,941 932 CKY + Ours 14,892,203 571 Iterative CKY + Left 23,267,594 377 Iterative CKY + Ours 10,966,272 314 Table 5: Combining with iterative CKY parsing 8 Related work Almost all work on parsing starts from a binarized grammar. Usually binarization plays a role of preprocessing. Left binarization is widely used (Aho and Ullman, 1972; Charniak et al., 1998; Tsuruoka and Tsujii, 2004) while right binarization is rarely used in the literature. Compact binarization was introduced in Schmid (2004), based o</context>
</contexts>
<marker>Tsuruoka, Tsujii, 2004</marker>
<rawString>Tsuruoka, Y. and Tsujii, J. (2004). Iterative cky parsing for probabilistic context-free grammars. In IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wang</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Binarizing syntax trees to improve syntax-based machine translation accuracy.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL.</booktitle>
<contexts>
<context position="32731" citStr="Wang et al. (2007)" startWordPosition="5740" endWordPosition="5743"> and prevent the binarized grammar becoming too specific (Charniak et al., 2006). It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b). In contrast, we focus our attention on parsing efficiency not accuracy in this paper. Binarization also attracts attention in the syntaxbased models for machine translation, where translation can be modeled as a parsing problem and binarization is essential for efficient parsing (Zhang et al., 2006; Huang, 2007). Wang et al. (2007) employs binarization to decompose syntax trees to acquire more re-usable translation rules in order to improve translation accuracy. Their binarization is restricted to be a mixture of left and right binarization. This constraint may decrease the power of binarization when applied to speeding up parsing in our problem. 9 Conclusions and future work We have studied the impact of grammar binarization on parsing efficiency and presented a novel binarization which utilizes rich information learnt from training corpus. Experiments not only showed that our learnt binarization outperforms other exis</context>
</contexts>
<marker>Wang, Knight, Marcu, 2007</marker>
<rawString>Wang, W., Knight, K., and Marcu, D. (2007). Binarizing syntax trees to improve syntax-based machine translation accuracy. In EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Younger</author>
</authors>
<title>Recognition and parsing of context-free languages in time n3.</title>
<date>1967</date>
<journal>Information and Control,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="1366" citStr="Younger, 1967" startWordPosition="195" endWordPosition="196">pus. Experimental results not only show that different binarizations have great impacts on parsing efficiency, but also confirm that our learnt binarization outperforms other existing methods. Furthermore we show that it is feasible to combine existing parsing speed-up techniques with our binarization to achieve even better performance. 1 Introduction Binarization, which transforms an n-ary grammar into an equivalent binary grammar, is essential for achieving an O(n3) time complexity in the contextfree grammar parsing. O(n3) tabular parsing algorithms, such as the CKY algorithm (Kasami, 1965; Younger, 1967), the GHR parser (Graham et al., 1980), the Earley algorithm (Earley, 1970) and the chart parsing algorithm (Kay, 1980; Klein and Manning, 2001) all convert their grammars into binary branching forms, either explicitly or implicitly (Charniak et al., 1998). In fact, the number of all possible binarizations of a production with n + 1 symbols on its right &apos;This work was done when Xinying Song and Shilin Ding were visiting students at Microsoft Research Asia. hand side is known to be the nth Catalan Number Cn = n1 1 ( \2n) . All binarizations lead to the same parsing accuracy, but maybe different</context>
</contexts>
<marker>Younger, 1967</marker>
<rawString>Younger, D. H. (1967). Recognition and parsing of context-free languages in time n3. Information and Control, 10(2):189–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>L Huang</author>
<author>D Gildea</author>
<author>K Knight</author>
</authors>
<title>Synchronous binarization for machine translation.</title>
<date>2006</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="32697" citStr="Zhang et al., 2006" startWordPosition="5734" endWordPosition="5737">are used to generalize the grammar and prevent the binarized grammar becoming too specific (Charniak et al., 2006). It is equipped with head binarization to help improve parsing accuracy, following the traditional linguistic insight that phrases are organized around the head (Collins, 1997; Klein and Manning, 2003b). In contrast, we focus our attention on parsing efficiency not accuracy in this paper. Binarization also attracts attention in the syntaxbased models for machine translation, where translation can be modeled as a parsing problem and binarization is essential for efficient parsing (Zhang et al., 2006; Huang, 2007). Wang et al. (2007) employs binarization to decompose syntax trees to acquire more re-usable translation rules in order to improve translation accuracy. Their binarization is restricted to be a mixture of left and right binarization. This constraint may decrease the power of binarization when applied to speeding up parsing in our problem. 9 Conclusions and future work We have studied the impact of grammar binarization on parsing efficiency and presented a novel binarization which utilizes rich information learnt from training corpus. Experiments not only showed that our learnt b</context>
</contexts>
<marker>Zhang, Huang, Gildea, Knight, 2006</marker>
<rawString>Zhang, H., Huang, L., Gildea, D., and Knight, K. (2006). Synchronous binarization for machine translation. In HLT-NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>