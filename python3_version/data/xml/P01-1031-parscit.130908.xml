<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000160">
<title confidence="0.993876">
Resolving Ellipsis in Clarification
</title>
<author confidence="0.996811">
Jonathan Ginzburg
</author>
<affiliation confidence="0.99228">
Dept of Computer Science
</affiliation>
<note confidence="0.826755">
King’s College, London
The Strand, London WC2R 2LS
UK
</note>
<email confidence="0.925427">
ginzburg@dcs.kcl.ac.uk
</email>
<author confidence="0.991164">
Robin Cooper
</author>
<affiliation confidence="0.9826765">
Dept of Linguistics
G¨oteborg University
</affiliation>
<address confidence="0.834924">
Box 200, 405 30 G¨oteborg,
Sweden
</address>
<email confidence="0.970753">
cooper@ling.gu.se
</email>
<sectionHeader confidence="0.980723" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916117647059">
We offer a computational analysis of
the resolution of ellipsis in certain cases
of dialogue clarification. We show that
this goes beyond standard techniques
used in anaphora and ellipsis resolu-
tion and requires operations on highly
structured, linguistically heterogeneous
representations. We characterize these
operations and the representations on
which they operate. We offer an analy-
sis couched in a version of Head-Driven
Phrase Structure Grammar combined
with a theory of information states (IS)
in dialogue. We sketch an algorithm for
the process of utterance integration in
ISs which leads to grounding or clarifi-
cation.
</bodyText>
<sectionHeader confidence="0.99515" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999462363636364">
Clarification ellipsis (CE), nonsentential ellipti-
cal queries such as (1a(i),(ii)) are commonplace
in human conversation. Two common read-
ings/understandings of CE are exemplified in
(1b,c): the clausal reading is commonly used sim-
ply to confirm the content of a particular subutter-
ance. The main function of the constituent read-
ing is to elicit an alternative description or osten-
sion to the content (referent or predicate etc) in-
tended by the original speaker of the reprised sub-
utterance.
</bodyText>
<listItem confidence="0.983590428571429">
(1) a. A: Did Bo finagle a raise?
B: (i) Bo?/ (ii) finagle?
b. Clausal reading: Are you asking if
BO (of all people) finagled a raise/Bo FI-
NAGLED a raise (of all actions)
c. Constituent reading: Who is
Bo?/What does it mean to finagle?
</listItem>
<bodyText confidence="0.9973871">
The issue of whether CE involves an ambi-
guity or is simply vague is an important one.12
Clearly, pragmatic reasoning plays an important
role in understanding CEs. Some considerations
do, nonetheless, favour the existence of an ambi-
guity. First, the BNC provides numerous exam-
ples of misunderstandings concerning CE inter-
pretation,3 where a speaker intends one reading,
is misunderstood, and clarifies his original inter-
pretation:
</bodyText>
<listItem confidence="0.924617142857143">
(2) a. A:... you always had er er say every foot
he had with a piece of spunyarn in the
wire/B: Spunyarn?/A: Spunyarn, yes/B:
What’s spunyarn?
b. A: Have a laugh and joke with Dick./
B: Dick?/A: Have a laugh and joke with
Dick./B: Who’s Dick?
</listItem>
<note confidence="0.645957933333334">
1An anonymous ACL reviewer proposed to us that all CE
could be analyzed in terms of a single reading along the lines
of “I thought I heard you say Bo, and I don’t know why you
would do so?”.
2Closely related to this issue is the issue of what other
readings/understandings CE exhibits. We defer discussion
of the latter issue to (Purver et al., 2001), which provides a
detailed analysis of the frequency of CEs and their under-
standings among clarification utterances in the British Na-
tional Corpus (BNC).
3This confirms our (non-instrumentally tested) impres-
sion that these understandings are not on the whole disam-
biguated intonationally. All our CE data from the BNC was
found using SCoRE, Matt Purver’s dialogue oriented BNC
search engine (Purver, 2001).
</note>
<bodyText confidence="0.9995569">
More crucially, the clausal and constituent
readings involve distinct syntactic and phonolog-
ical parallelism conditions. The constituent read-
ing seems to actually require phonological iden-
tity. With the resolution associated with clausal
readings, there is no such requirement. How-
ever, partial syntactic parallelism does obtain: an
XP used to clarify an antecedent sub-utterance
must match categorially, though there is no re-
quirement ofphonological identity:
</bodyText>
<listItem confidence="0.99891025">
(3) a. A: I phoned him. B: him? / #he?
b. A: Did he adore the book. B: adore? /
#adored?
c. A: We’re leaving? B: You?
</listItem>
<bodyText confidence="0.995952">
We are used to systems that will confirm the
user’s utterances by repeating part of them. These
presuppose no sophisticated linguistic analysis.
However, it is not usual for a system to be able to
process CEs produced by the user. It would be a
great advantage in negotiative dialogues, where,
for example, the system and the user might be
discussing several options and the system may
make alternative suggestions, for a system to be
able to recognize and interpret a CE. Consider
the following (constructed) dialogue in the route-
planning domain:
</bodyText>
<listItem confidence="0.9981455">
(4) Sys: Would you like to make that trip via
Malvern? User: Malvern?
</listItem>
<bodyText confidence="0.997565666666667">
At this point the system has to consider a num-
ber of possible intepretations for the user’s utter-
ance all of which involve recognizing that this is a
clarification request concerning the system’s last
utterance.
Appropriate responses might be (5a-c); the sys-
tem should definitely not say (5d), as it might if it
does not recognize that the user is trying to clarify
its previous utterance.
</bodyText>
<listItem confidence="0.961283833333333">
(5) a. Yes, Malvern
b. Malvern – M-A-L-V-E-R-N
c. Going via Malvern is the quickest
route
d. So, you would like to make that trip
via Malvern instead of Malvern?
</listItem>
<bodyText confidence="0.980846214285715">
In this paper we examine the interpretation
of CEs. CE is a singularly complex ellip-
sis/anaphoric phenomenon which cannot be han-
dled by standard techniques such as first order
unification (as anaphora often is) or by higher or-
der unification (HOU) on logical forms (see e.g.
(Pulman, 1997)). For a start, in order to cap-
ture the syntactic and phonological parallelism
exemplified in (3), logical forms are simply in-
sufficient. Moreover, although an HOU account
could, given a theory of dialogue that structures
context appropriately, generate the clausal read-
ing, the constituent reading cannot be so gener-
ated. Clark (e.g. (Clark, 1996)) initiated work
on the grounding of an utterance (for computa-
tional and formal work see e.g. (Traum, 1994;
Poesio and Traum, 1997)). However, existing
work, while spelling out in great detail what up-
dates arise in an IS as a result of grounding, do not
offer a characterization of the clarification possi-
bilities spawned by a given utterance. A sketch
of such a characterization is provided in this pa-
per. On the basis of this we offer an analysis
of CE, integrated into a large existing grammar
framework, Head-Driven Phrase Structure Gram-
mar (HPSG) (specifically the version developed
in (Ginzburg and Sag, 2000)). We start by infor-
mally describing the grounding/clarification pro-
cesses and the representations on which they op-
erate. We then provide the requisite background
on HPSG and on the KOS framework (Ginzburg,
1996; Bohlin et al., 1999), in which our analy-
sis of ISs is couched. We sketch an algorithm for
the process of utterance integration which leads to
grounding or clarification. Finally, we formalize
the operations which underpin clarification and
sketch a grammatical analysis of CE.
2 Utterance Representation: grounding
and clarification
We start by offering an informal description of
how an utterancesuch as (6) can get grounded
or spawn a clarification by an addressee B:
</bodyText>
<listItem confidence="0.963875">
(6) A: Did Bo leave?
</listItem>
<bodyText confidence="0.998855922413793">
A is attempting to convey to B her question
whether the property she has referred to with her
utterance of leave holds of the person she has
referred to with the name Bo. B is required to
try and find values for these references. Finding
values is, with an important caveat, a necessary
condition for B to ground A’s utterance, thereby
signalling that its content has been integrated in
B’s IS.4 Modelling this condition for success-
ful grounding provides one obvious constraint on
the representation of utterance types: such a rep-
resentation must involve a function from or-
abstract over a set of certain parameters (the con-
textual parameters) to contents. This much is fa-
miliar already from early work on context depen-
dence by (Montague, 1974) et seq. What hap-
pens when B cannot or is at least uncertain as to
how he should instantiate in his IS a contextual
parameter? In such a case B needs to do at least
the following: (1) perform a partial update of the
existing context with the successfully processed
components of the utterance (2) pose a clarifica-
tion question that involves reference to the sub-
utterance ufrom whichemanates. Since the
original speaker, A, can coherently integrate a
clarification question once she hears it, it follows
that, for a given utterance, there is a predictable
range ofpartial updates + consequent clarifica-
tion questions. These we take to be specified by
a set of coercion operations on utterance repre-
sentations.5 Indeed we assume that a component
of dialogue competence is knowledge of these co-
ercion operations.
CE gives us some indication concerning both
the input and required output of these operations.
One such operation, which we will refer to as
parameter identification, essentially involves as
output a question paraphrasable as what is the in-
tended reference of sub-utterance u?. The par-
tially updated context in which such a clarifica-
tion takes place is such that simply repeating the
segmental phonology of uusing rising intona-
tion enables that question to be expressed. An-
other existent coercion operation is one which we
will refer to as parameter focussing. This in-
volves a (partially updated) context in which the
issue under discussion is a question that arises by
instantiating all contextual parameters except for
and abstracting over. In such a context, one
4The caveat is, of course, that the necessity is goal driven.
Relative to certain goals, one might decide simply to existen-
tially quantify the problematic referent. For this operation on
meanings see (Cooper, 1998). We cannot enter here into a
discussion of how to integrate the view developed here in a
plan based view of understanding, but see (Ginzburg, (forth-
coming)) for this.
5The term coercion operation is inspired by work on ut-
terance representation within a type theoretic framework re-
ported in (Cooper, 1998).
can confirm thatgets the value B suspects it has
by uttering with rising intonation any apparently
co-referential phrase whose syntactic category is
identical to ’s.
From this discussion, it becomes clear that co-
ercion operations (and by extension the ground-
ing process) cannot be defined simply on mean-
ings. Rather, given the syntactic and phonologi-
cal parallelism encoded in clarification contexts,
these operations need to be defined on repre-
sentations that encode in parallel for each sub-
utterance down to the word level phonological,
syntactic, semantic, and contextual information.
With some minor modifications, signs as con-
ceived in HPSG are exactly such a representa-
tional format and, hence, we will use them to de-
fine coercion operations.6 More precisely, given
that an addressee might not be able to come up
with a unique or a complete parse, due to lexi-
cal ignorance or a noisy environment, we need to
utilize some ‘underspecified’ entity (see e.g. (Mil-
ward, 2000)). For simplicity we will use descrip-
tions of signs. An example of the format for signs
we employ is given in (7):7
6We make two minor modifications to the version of
HPSG described in (Ginzburg and Sag, 2000)). First, we re-
vamp the existing treatment of the feature C-INDICES. This
will now encode the entire inventory of contextual parame-
ters of an utterance (proper names, deictic pronouns, indexi-
cals) not merely information about speaker/hearer/utterance-
time, as standardly. Indeed, in principle, relation names
should also be included, since they vary with context and are
subject to clarification as well. Such a step involves a signif-
icant change to how argument roles are handled in existing
HPSG. Hence, we do not make such a move here. This mod-
ification of C-INDICES will allow signs to play a role akin to
the role associated with ‘meanings’, i.e. to function as ab-
stracts with roles that need to be instantiated. The second
modification we make concerns the encoding of phrasal con-
stituency. Standardly, the feature DTRS is used to encode im-
mediate phrasal constituency. To facilitate statement of coer-
cion operations, we need access to all phrasal constituents—
given that a contextual parameter emanating from deeply
embedding constituents are as clarifiable as immediate con-
stituents. We posit a set valued feature CONSTIT(UENT)S
whose value is the set of all constituents immediate or oth-
erwise of a given sign (Cf. the mother-daughter predicates
used in (Gregory and Lappin, 1999).) In fact, having posited
CONSTITS one could eliminate DTRS: this by making the
value of CONSTITS be a set of sets whose first level elements
are the immediate constituents. For current purposes, we
stick with tradition and tolerate the redundancy of both DTRS
and CONSTITS.
7Within the phrasal type system of (Ginzburg and Sag,
2000) root-cl constitutes the ‘start’ symbol of the grammar.
In particular, phrases of this type have as their content an
illocutionary operator embedding the appropriate semantic
</bodyText>
<figure confidence="0.994092142857143">
root-cl
PHON did bo leave
CAT V[+fin]
C-INDICES,,, i,j
ASK-REL
ASKER i
ASKED j
question
PARAMS
leave-rel
PROPSOAAGT
TIME
MSG-ARG
utt-time(),
precede(,), named(bo)()
CTXTBCKGRD
CONSTITS
PHON Did,PHON Bo,
PHON leave,PHON Did Bo leave
(7)
CONT
</figure>
<bodyText confidence="0.9958875">
Before we can explain how these representa-
tions can feature in dialogue reasoning and the
resolution of CE, we need to sketch briefly the
approach to dialogue ellipsis that we assume.
</bodyText>
<sectionHeader confidence="0.902422" genericHeader="method">
3 Contextual evolution and ellipsis
</sectionHeader>
<bodyText confidence="0.981261666666667">
We adopt the situation semantics based theory
of dialogue context developed in the KOS frame-
work (Ginzburg, 1996; Ginzburg, (forthcoming);
Bohlin et al., 1999). The common ground com-
ponent of ISs is assumed to be structured as fol-
lows:8
</bodyText>
<figure confidence="0.66231">
(8) ✠☛FACTS set offacts
LATEST-MOVE (illocutionary) fact
</figure>
<figureCaption confidence="0.424032">
QUD p.o. set of questions
</figureCaption>
<bodyText confidence="0.9994975">
In (Ginzburg and Sag, 2000) this framework is
integrated into HPSG (Pollard and Sag, 1994);
(Ginzburg and Sag, 2000) define two new at-
tributes within the CONTEXT (CTXT) feature
structure: Maximal Question Under Discussion
(MAX-QUD), whose value is of sort question;9
</bodyText>
<tableCaption confidence="0.7134345">
object (an assertion embedding a proposition, a query em-
bedding a question etc.). Here and throughout we omit vari-
ous features (e.g. STORE, SLASH etc that have no bearing on
current issues wherever possible.
8Here FACTS corresponds to the set of commonly ac-
cepted assumptions; QUD(‘questions under discussion’) is
a set consisting of the currently discussable questions, par-
tially ordered by(‘takes conversational precedence’);
LATEST-MOVE represents information about the content
and structure of the most recent accepted illocutionary move.
9Questions are represented as semantic objects compris-
ing a set of parameters—empty for a polar question—and a
</tableCaption>
<bodyText confidence="0.994452652173913">
and Salient Utterance (SAL-UTT), whose value
is a set (singleton or empty) of elements of type
sign. In information structure terms, SAL-UTT
can be thought of as a means of underspecifying
the subsequent focal (sub)utterance or as a poten-
tial parallel element. MAX-QUD corresponds to
the ground of the dialogue at a given point. Since
SAL-UTT is a sign, it enables one to encode syn-
tactic categorial parallelism and, as we will see
below, also phonological parallelism. SAL-UTT
is computed as the (sub)utterance associated with
the role bearing widest scope within MAX-QUD.10
Below, we will show how to extend this account
of parallelism to clarification queries.
To account for elliptical constructions such as
short answers and sluicing, Ginzburg and Sag
posit a phrasal type headed-fragment-phrase (hd-
frag-ph)—a subtype of hd-only-ph—governed by
the constraint in (9). The various fragments ana-
lyzed here will be subtypes of hd-frag-ph or else
will contain such a phrase as a head daughter.11
This constraint coindexes the head daughter
with the SAL-UTT. This will have the effect of
‘unifying in’ the content of the former into a con-
textually provided content. A subtype of hd-frag-
ph relevant to the current paper is (decl-frag-cl)—
also a subtype of decl-cl—used to analyze short
answers:
proposition. This is the feature structure counterpart of the
-abstract .
10For Wh-questions, SAL-UTT is the wh-phrase associated
with the PARAMS set of the question; otherwise, its possible
values are either the empty set or the utterance associated
with the widest scoping quantifier in MAX-QUD.
11In the (Ginzburg and Sag, 2000) version of HPSG infor-
mation about phrases is encoded by cross-classifying them
in a multi-dimensional type hierarchy. Phrases are classi-
fied not only in terms of their phrase structure schema or
X-bar type, but also with respect to a further informational
dimension of CLAUSALITY. Clauses are divided into inter
alia declarative clauses (decl-cl), which denote propositions,
and interrogative clauses (inter-cl) denoting questions. Each
maximal phrasal type inherits from both these dimensions.
This classification allows specification of systematic corre-
lations between clausal construction types and types of se-
mantic content.
</bodyText>
<figure confidence="0.99624125">
(9)
HEAD v
CTXTSAL-UTT
CAT
CONTINDEX
CATHEAD nominal
HD-DTR
CONTINDEX
</figure>
<bodyText confidence="0.999842444444444">
The content of this phrasal type is a proposition:
whereas in most headed clauses the content is en-
tirely (or primarily) derived from the head daugh-
ter, here it is constructed for the most part from
the contextually salient question. This provides
the concerned situation and the nucleus, whereas
if the fragment is (or contains) a quantifier, that
quantifier must outscope any quantifiers already
present in the contextually salient question.
</bodyText>
<sectionHeader confidence="0.8961845" genericHeader="method">
4 Integrating Utterances in Information
States
</sectionHeader>
<bodyText confidence="0.977646">
Before we turn to formalizing the coercion opera-
tions and describing CE, we need to explain how
on our view utterances get integrated in an agent’s
IS. The basic protocol we assume is given in (11)
below.12
</bodyText>
<figure confidence="0.791767">
(11) Utterance processing protocol
For an agent B with IS: if an utteranceis Maximal in
PENDING:
(a) Try to:
</figure>
<listItem confidence="0.971081">
(1) find an assignmentinfor, whereis the (maximal
description available for) the sign associated with
(2) update LATEST-MOVE with:
1. If LATEST-MOVE is grounded, then FACTS:=
FACTS + LATEST-MOVE;
2. LATEST-MOVE :=
(3) React to content(u) according to querying/assertion pro-
tocols.
(4) If successful,is removed from PENDING
(b) Else: Repeat from stage (a) with MAX-QUD
and SAL-UTT obtaining the various values of
</listItem>
<bodyText confidence="0.741732">
coe , where is the sign
associated with LATEST-MOVE and coeis one of the
available coercion operations;
12In this protocol, PENDING is a stack whose elements
are (unintegrated) utterances.
</bodyText>
<listItem confidence="0.9300745">
(c) Else: make an utterance appropriate for a context such
that MAX-QUD and SAL-UTT get values according to the
</listItem>
<bodyText confidence="0.997994375">
specification in coe , where coeis one of the avail-
able coercion operations.
The protocol involves the assumption that an
agent always initially tries to integrate an utter-
ance by assuming it constitutes an adjacency pair
with the existing LATEST-MOVE. If this route
is blocked somehow, because the current utter-
ance cannot be grounded or the putative resolu-
tion leads to incoherence, only then does she try
to repair by assuming the previous utterance is a
clarification generated in accordance with the ex-
isting coercion operations. If that too fails, then,
she herself generates a clarification. Thus, the
prediction made by this protocol is that A will
tend to initially interpret (12(2)) as a response to
her question, not as a clarification:
</bodyText>
<listItem confidence="0.9379265">
(12) A(1): Who do you think is the only per-
son that admires Mary? B(2): Mary?
</listItem>
<sectionHeader confidence="0.574391" genericHeader="method">
5 Sign Coercion and an Analysis of CE
</sectionHeader>
<bodyText confidence="0.984792230769231">
We now turn to formalizing the coercion op-
erations we specified informally in section 2.
The first operation we define is parameter fo-
cussing:
This is to be understood as follows: given an ut-
terance (whose associated sign is one) which sat-
isfies the specification in the LHS of the rule, a CP
may respond with any utterance which satisfies
the specification in the RHS of the rule.13 More
specifically, the input of the rules singles out a
13The fact that both the LHS and the RHS of the rule are
of type root-cl ensures that the rule applies only to signs as-
sociated with complete utterances.
</bodyText>
<figure confidence="0.997911333333333">
✠proposition
SIT
QUANTS
SOA
NUCL
MAX-QUD
PROP
(10)✠ STORE
✠proposition
SIT
CONT
QUANTS order( )
SOA
NUCL
question
PARAMS neset
HD-DTRSTORE set(param)
MAX-QUD
question
PARAMS
PROP
(13) parameter focussing:
✠root-cl
CTXT-INDICES
CONSTITS CONT
CONTENT
question
CONTENTMSG-ARG
PROP
SAL-UTT
</figure>
<bodyText confidence="0.99906976">
contextual parameter, which is the content of an
element of the daughter set of the utterance 2 .
Intuitively,is a parameter whose value is prob-
lematic or lacking. The sub-utterance 2 is speci-
fied to constitute the value of the feature SAL-UTT
associated with the context of the clarification ut-
terance . The descriptive content of is
a question, any question whose open proposition
3 (given in terms of the feature PROP) is identi-
cal to the (uninstantiated) content of the clarified
utterance. MAX-QUD associated with the clarifi-
cation is fully specified as a question whose open
proposition is 3 and whose PARAMS set consists
of the ‘problematic’ parameter.
We can exemplify the effect of parameter fo-
cussing with respect to clarifying an utterance of
(7). The output this yields, when applied to Bo’s
index 1 , is the partial specification in (14). Such
an utterance will have as its MAX-QUD a ques-
tion cqparaphrasable as who, named Bo, are
you asking if t left, whereas its SAL-UTT is the
sub-utterance of Bo. The content is underspeci-
fied:
This (partial) specification allows for clarifica-
tion questions such as the following:
</bodyText>
<listItem confidence="0.994801333333333">
(15) a. Did WHO leave?
b. WHO?
c. BO? (= Are you asking if BO left?)
</listItem>
<bodyText confidence="0.977715863636364">
Given space constraints, we restrict ourselves
to explaining how the clausal CE, (15c), gets ana-
lyzed. This involves direct application of the type
decl-frag-cl discussed above for short answers.
The QUD-maximality of cqallows us to ana-
lyze the fragment as a ‘short answer’ to cq, using
the type bare-decl-cl. And out of the proposition
which emerges courtesy of bare-decl-cl a (polar)
question is constructed using the type dir-is-int-
cl.14
Bo
The second coercion operation we discussed
previously is parameter identification: for a
given problematic contextual parameter its out-
put is a partial specification for a sign whose con-
tent and MAX-QUD involve a question querying
the content of that utterance parameter:
14The phrasal type dir-is-int-cl which constitutes the type
of the mother node in (16) is a type that inter alia enables a
polar question to be built from a head daughter whose con-
tent is propositional. See (Ginzburg and Sag, 2000) for de-
tails.
</bodyText>
<figure confidence="0.993302274509804">
SAL-UTT
MAX-QUD
question
PROP
question
PARAMS
PROPSOA
ASK-REL
ASKER i
ASKED j
MSG-ARG
question
PARAMS
PROPSOA
leave-rel
AGT
TIME
CONTMSG-ARG
(14)
PROP
(16) S
dir-is-int-cl
question
PARAMS
ask-rel
ASKER i
ASKED j
question
PARAMS
PROPSOA
✒
leave-rel
AGT
TIME
CONT
S
CTXT
SAL-UTT
question
MAX-QUDPARAMSINDEX
PROP
CAT
CONTINDEX
decl-frag-cl
CONT
CATNP
CONTINDEX
(17) parameter identification:
✠root-cl
CTXT-INDICES
CONSTITS CONT
</figure>
<bodyText confidence="0.9982956">
To exemplify: when this operation is applied to
(7), it will yield as output the partial specification
in (18):
This specification will allows for clarification
questions such as the following:
</bodyText>
<listItem confidence="0.979683">
(19) a. Who do you mean BO?
b. WHO? (= who is Bo)
c. Bo? (= who is Bo)
</listItem>
<bodyText confidence="0.999946157894737">
We restrict attention to (19c), which is the most
interesting but also tricky example. The tricky
part arises from the fact that in a case such as this,
in contrast to all previous examples, the fragment
does not contribute its conventional content to the
clausal content. Rather, as we suggested earlier,
the semantic function of the fragment is merely
to serve as an anaphoric element to the phono-
logically identical to–be–clarified sub-utterance.
The content derives entirely from MAX-QUD.
Such utterances can still be analyzed as subtypes
of head-frag-ph, though not as decl-frag-cl, the
short-answer/reprise sluice phrasal type we have
been appealing to extensively. Thus, we posit
constit(uent)-clar(ification)-int-cl, a new phrasal
subtype of head-frag-ph and of inter-cl which en-
capsulates the two idiosyncratic facets of such
utterances, namely the phonological parallelism
and the max-qud/content identity:
</bodyText>
<figure confidence="0.990197291666667">
CONTMSG-ARG
PROP
MAX-QUD
SAL-UTT
question
PARAMSINDEX
PROPSOA
PHON bo
CAT NP
CONTINDEX
CTXTBCKGRDnamed(Bo)()
content-rel
SIGN
CONT
(18)
question
(20)CONT
CTXT
MAX-QUD
SAL-UTTPHON
HPHON
Given this, (19c) receives the following analy-
sis:
6 Summary and Future Work
</figure>
<bodyText confidence="0.997709260869565">
In this paper we offered an analysis of the types of
representations needed to analyze CE, the requi-
site operations thereon, and how these update ISs
during grounding and clarification.
Systems which respond appropriately to CEs
in general will need a great deal of background
knowledge. Even choosing among the responses
in (5) might be a pretty knowledge intensive busi-
ness. However, there are some clear strategies
that might be pursued. For example, if Malvern
has been discussed previously in the dialogue and
understood then (5a,b) would not be appropriate
responses. In order to be able to build dialogue
systems that can handle even some restricted as-
pects of CEs we need to understand more about
what the possible interpretations are and this is
what we have attempted to do in this paper. We
are currently working on a system which inte-
grates SHARDS (see (Ginzburg et al., 2001), a
system which processes dialogue ellipses) with
GoDiS (see (Bohlin et al., 1999), a dialogue sys-
tem developed using TRINDIKIT, which makes
use of ISs modelled on those suggested in the KOS
</bodyText>
<figure confidence="0.994983217391304">
constit-repr-int-cl
question
CONT PARAMS
PROP content(,)
MAX-QUD
PHON
CAT NP
PHON
CAT
SAL-UTT
(21)
CTXT
HD-DTR
MAX-QUD
CONTENTMSG-ARG
PROP
SAL-UTT
question
question
PARAMSINDEX
content-rel
PROPSOASIGN
CONT
</figure>
<bodyText confidence="0.9928945">
framework. Our aim in the near future is to in-
corporate simple aspects of negotiative dialogue
including CEs in a GoDiS-like system employing
SHARDS.
</bodyText>
<sectionHeader confidence="0.992138" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999827176470588">
For very useful discussion and comments we
would like to thank Pat Healey, Howard Gre-
gory, Shalom Lappin, Dimitra Kolliakou, David
Milward, Matt Purver and three anonymous ACL
reviewers. We would also like to thank Matt
Purver for help in using SCoRE. Earlier versions
of this work were presented at colloquia at ITRI,
Brighton, Queen Mary and Westfield College,
London, and at the Computer Lab, Cambridge.
The research described here is funded by grant
number R00022269 from the Economic and So-
cial Research Council of the United Kingdom, by
INDI (Information Exchange in Dialogue), Riks-
bankens Jubileumsfond 1997-0134, and by grant
number GR/R04942/01 from the Engineering and
Physical Sciences Research Council of the United
Kingdom.
</bodyText>
<sectionHeader confidence="0.996337" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999208620689655">
Peter Bohlin, Robin Cooper, Elisabet Engdahl, and
Staffan Larsson. 1999. Information states and di-
alogue move engines. Gothenburg Papers in Com-
putational Linguistics.
Herbert Clark. 1996. Using Language. Cambridge
University Press, Cambridge.
Robin Cooper. 1998. Mixing situation theory and
type theory to formalize information states in di-
alogue exchanges. In J. Hulstijn and A. Nijholt,
editors, Proceedings of TwenDial 98, 13th Twente
workshop on Language Technology. Twente Uni-
versity, Twente.
Jonathan Ginzburg and Ivan Sag. 2000. Interrogative
Investigations: the form, meaning and use of En-
glish Interrogatives. Number 123 in CSLI Lecture
Notes. CSLI Publications, Stanford: California.
Jonathan Ginzburg, Howard Gregory, and Shalom
Lappin. 2001. Shards: Fragment resolution in di-
alogue. In H. Bunt, editor, Proceedings of the 1st
International Workshop on Computational Seman-
tics. ITK, Tilburg University, Tilburg.
Jonathan Ginzburg. 1996. Interrogatives: Ques-
tions, facts, and dialogue. In Shalom Lappin, ed-
itor, Handbook of Contemporary Semantic Theory.
Blackwell, Oxford.
Jonathan Ginzburg. forthcoming. Semantics
and Interaction in Dialogue. CSLI Publi-
cations and Cambridge University Press, Stan-
ford: California. Draft chapters available from
http://www.dcs.kcl.ac.uk/staff/ginzburg.
Howard Gregory and Shalom Lappin. 1999. An-
tecedent contained ellipsis in HPSG. In Gert We-
belhuth, Jean Pierre Koenig, and Andreas Kathol,
editors, Lexical and Constructional Aspects ofLin-
guistic Explanation, pages 331–356. CSLI Publica-
tions, Stanford.
David Milward. 2000. Distributing representation for
robust interpretation of dialogue utterances. ACL.
Richard Montague. 1974. Pragmatics. In Rich-
mond Thomason, editor, Formal Philosophy. Yale
UP, New Haven.
Massimo Poesio and David Traum. 1997. Conversa-
tional actions and discourse situations. Computa-
tionalIntelligence, 13:309–347.
Carl Pollard and Ivan Sag. 1994. Head Driven Phrase
Structure Grammar. University of Chicago Press
and CSLI, Chicago.
Stephen Pulman. 1997. Focus and higher order unifi-
cation. Linguistics and Philosophy, 20.
Matthew Purver, Jonathan Ginzburg, and Patrick
Healey. 2001. On the means for clarification in di-
alogue. Technical report, King’s College, London.
Matthew Purver. 2001. Score: Searching a corpus
for regular expressions. Technical report, King’s
College, London.
David Traum. 1994. A Computational Theory
of Grounding in Natural Language Conversations.
Ph.D. thesis, University of Rochester.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.252157">
<title confidence="0.999984">Resolving Ellipsis in Clarification</title>
<author confidence="0.999989">Jonathan Ginzburg</author>
<affiliation confidence="0.923993">Dept of Computer Science King’s College, London</affiliation>
<address confidence="0.6101955">The Strand, London WC2R 2LS UK</address>
<email confidence="0.976904">ginzburg@dcs.kcl.ac.uk</email>
<author confidence="0.999856">Robin Cooper</author>
<affiliation confidence="0.9999705">Dept of Linguistics G¨oteborg University</affiliation>
<address confidence="0.945191">Box 200, 405 30 G¨oteborg, Sweden</address>
<email confidence="0.980217">cooper@ling.gu.se</email>
<abstract confidence="0.986499277777778">We offer a computational analysis of the resolution of ellipsis in certain cases of dialogue clarification. We show that this goes beyond standard techniques used in anaphora and ellipsis resolution and requires operations on highly structured, linguistically heterogeneous representations. We characterize these operations and the representations on which they operate. We offer an analysis couched in a version of Head-Driven Phrase Structure Grammar combined with a theory of information states (IS) in dialogue. We sketch an algorithm for the process of utterance integration in ISs which leads to grounding or clarification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter Bohlin</author>
<author>Robin Cooper</author>
<author>Elisabet Engdahl</author>
<author>Staffan Larsson</author>
</authors>
<title>Information states and dialogue move engines. Gothenburg Papers in Computational Linguistics.</title>
<date>1999</date>
<contexts>
<context position="6308" citStr="Bohlin et al., 1999" startWordPosition="1020" endWordPosition="1023">sult of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg and Sag, 2000)). We start by informally describing the grounding/clarification processes and the representations on which they operate. We then provide the requisite background on HPSG and on the KOS framework (Ginzburg, 1996; Bohlin et al., 1999), in which our analysis of ISs is couched. We sketch an algorithm for the process of utterance integration which leads to grounding or clarification. Finally, we formalize the operations which underpin clarification and sketch a grammatical analysis of CE. 2 Utterance Representation: grounding and clarification We start by offering an informal description of how an utterancesuch as (6) can get grounded or spawn a clarification by an addressee B: (6) A: Did Bo leave? A is attempting to convey to B her question whether the property she has referred to with her utterance of leave holds of the per</context>
<context position="13223" citStr="Bohlin et al., 1999" startWordPosition="2142" endWordPosition="2145">root-cl PHON did bo leave CAT V[+fin] C-INDICES,,, i,j ASK-REL ASKER i ASKED j question PARAMS leave-rel PROPSOAAGT TIME MSG-ARG utt-time(), precede(,), named(bo)() CTXTBCKGRD CONSTITS PHON Did,PHON Bo, PHON leave,PHON Did Bo leave (7) CONT Before we can explain how these representations can feature in dialogue reasoning and the resolution of CE, we need to sketch briefly the approach to dialogue ellipsis that we assume. 3 Contextual evolution and ellipsis We adopt the situation semantics based theory of dialogue context developed in the KOS framework (Ginzburg, 1996; Ginzburg, (forthcoming); Bohlin et al., 1999). The common ground component of ISs is assumed to be structured as follows:8 (8) ✠☛FACTS set offacts LATEST-MOVE (illocutionary) fact QUD p.o. set of questions In (Ginzburg and Sag, 2000) this framework is integrated into HPSG (Pollard and Sag, 1994); (Ginzburg and Sag, 2000) define two new attributes within the CONTEXT (CTXT) feature structure: Maximal Question Under Discussion (MAX-QUD), whose value is of sort question;9 object (an assertion embedding a proposition, a query embedding a question etc.). Here and throughout we omit various features (e.g. STORE, SLASH etc that have no bearing o</context>
<context position="24896" citStr="Bohlin et al., 1999" startWordPosition="3994" endWordPosition="3997">ledge intensive business. However, there are some clear strategies that might be pursued. For example, if Malvern has been discussed previously in the dialogue and understood then (5a,b) would not be appropriate responses. In order to be able to build dialogue systems that can handle even some restricted aspects of CEs we need to understand more about what the possible interpretations are and this is what we have attempted to do in this paper. We are currently working on a system which integrates SHARDS (see (Ginzburg et al., 2001), a system which processes dialogue ellipses) with GoDiS (see (Bohlin et al., 1999), a dialogue system developed using TRINDIKIT, which makes use of ISs modelled on those suggested in the KOS constit-repr-int-cl question CONT PARAMS PROP content(,) MAX-QUD PHON CAT NP PHON CAT SAL-UTT (21) CTXT HD-DTR MAX-QUD CONTENTMSG-ARG PROP SAL-UTT question question PARAMSINDEX content-rel PROPSOASIGN CONT framework. Our aim in the near future is to incorporate simple aspects of negotiative dialogue including CEs in a GoDiS-like system employing SHARDS. Acknowledgements For very useful discussion and comments we would like to thank Pat Healey, Howard Gregory, Shalom Lappin, Dimitra Koll</context>
</contexts>
<marker>Bohlin, Cooper, Engdahl, Larsson, 1999</marker>
<rawString>Peter Bohlin, Robin Cooper, Elisabet Engdahl, and Staffan Larsson. 1999. Information states and dialogue move engines. Gothenburg Papers in Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="5460" citStr="Clark, 1996" startWordPosition="882" endWordPosition="883">the interpretation of CEs. CE is a singularly complex ellipsis/anaphoric phenomenon which cannot be handled by standard techniques such as first order unification (as anaphora often is) or by higher order unification (HOU) on logical forms (see e.g. (Pulman, 1997)). For a start, in order to capture the syntactic and phonological parallelism exemplified in (3), logical forms are simply insufficient. Moreover, although an HOU account could, given a theory of dialogue that structures context appropriately, generate the clausal reading, the constituent reading cannot be so generated. Clark (e.g. (Clark, 1996)) initiated work on the grounding of an utterance (for computational and formal work see e.g. (Traum, 1994; Poesio and Traum, 1997)). However, existing work, while spelling out in great detail what updates arise in an IS as a result of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Herbert Clark. 1996. Using Language. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
</authors>
<title>Mixing situation theory and type theory to formalize information states in dialogue exchanges.</title>
<date>1998</date>
<booktitle>Proceedings of TwenDial 98, 13th Twente workshop on Language Technology.</booktitle>
<editor>In J. Hulstijn and A. Nijholt, editors,</editor>
<institution>Twente University, Twente.</institution>
<contexts>
<context position="9312" citStr="Cooper, 1998" startWordPosition="1516" endWordPosition="1517">ly repeating the segmental phonology of uusing rising intonation enables that question to be expressed. Another existent coercion operation is one which we will refer to as parameter focussing. This involves a (partially updated) context in which the issue under discussion is a question that arises by instantiating all contextual parameters except for and abstracting over. In such a context, one 4The caveat is, of course, that the necessity is goal driven. Relative to certain goals, one might decide simply to existentially quantify the problematic referent. For this operation on meanings see (Cooper, 1998). We cannot enter here into a discussion of how to integrate the view developed here in a plan based view of understanding, but see (Ginzburg, (forthcoming)) for this. 5The term coercion operation is inspired by work on utterance representation within a type theoretic framework reported in (Cooper, 1998). can confirm thatgets the value B suspects it has by uttering with rising intonation any apparently co-referential phrase whose syntactic category is identical to ’s. From this discussion, it becomes clear that coercion operations (and by extension the grounding process) cannot be defined simp</context>
</contexts>
<marker>Cooper, 1998</marker>
<rawString>Robin Cooper. 1998. Mixing situation theory and type theory to formalize information states in dialogue exchanges. In J. Hulstijn and A. Nijholt, editors, Proceedings of TwenDial 98, 13th Twente workshop on Language Technology. Twente University, Twente.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Ginzburg</author>
<author>Ivan Sag</author>
</authors>
<title>Interrogative Investigations: the form, meaning and use of English Interrogatives.</title>
<date>2000</date>
<journal>Number</journal>
<booktitle>in CSLI Lecture Notes.</booktitle>
<volume>123</volume>
<publisher>CSLI Publications,</publisher>
<location>Stanford: California.</location>
<contexts>
<context position="6075" citStr="Ginzburg and Sag, 2000" startWordPosition="983" endWordPosition="986">k, 1996)) initiated work on the grounding of an utterance (for computational and formal work see e.g. (Traum, 1994; Poesio and Traum, 1997)). However, existing work, while spelling out in great detail what updates arise in an IS as a result of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg and Sag, 2000)). We start by informally describing the grounding/clarification processes and the representations on which they operate. We then provide the requisite background on HPSG and on the KOS framework (Ginzburg, 1996; Bohlin et al., 1999), in which our analysis of ISs is couched. We sketch an algorithm for the process of utterance integration which leads to grounding or clarification. Finally, we formalize the operations which underpin clarification and sketch a grammatical analysis of CE. 2 Utterance Representation: grounding and clarification We start by offering an informal description of how an</context>
<context position="10804" citStr="Ginzburg and Sag, 2000" startWordPosition="1761" endWordPosition="1764">d contextual information. With some minor modifications, signs as conceived in HPSG are exactly such a representational format and, hence, we will use them to define coercion operations.6 More precisely, given that an addressee might not be able to come up with a unique or a complete parse, due to lexical ignorance or a noisy environment, we need to utilize some ‘underspecified’ entity (see e.g. (Milward, 2000)). For simplicity we will use descriptions of signs. An example of the format for signs we employ is given in (7):7 6We make two minor modifications to the version of HPSG described in (Ginzburg and Sag, 2000)). First, we revamp the existing treatment of the feature C-INDICES. This will now encode the entire inventory of contextual parameters of an utterance (proper names, deictic pronouns, indexicals) not merely information about speaker/hearer/utterancetime, as standardly. Indeed, in principle, relation names should also be included, since they vary with context and are subject to clarification as well. Such a step involves a significant change to how argument roles are handled in existing HPSG. Hence, we do not make such a move here. This modification of C-INDICES will allow signs to play a role</context>
<context position="12428" citStr="Ginzburg and Sag, 2000" startWordPosition="2022" endWordPosition="2025">emanating from deeply embedding constituents are as clarifiable as immediate constituents. We posit a set valued feature CONSTIT(UENT)S whose value is the set of all constituents immediate or otherwise of a given sign (Cf. the mother-daughter predicates used in (Gregory and Lappin, 1999).) In fact, having posited CONSTITS one could eliminate DTRS: this by making the value of CONSTITS be a set of sets whose first level elements are the immediate constituents. For current purposes, we stick with tradition and tolerate the redundancy of both DTRS and CONSTITS. 7Within the phrasal type system of (Ginzburg and Sag, 2000) root-cl constitutes the ‘start’ symbol of the grammar. In particular, phrases of this type have as their content an illocutionary operator embedding the appropriate semantic root-cl PHON did bo leave CAT V[+fin] C-INDICES,,, i,j ASK-REL ASKER i ASKED j question PARAMS leave-rel PROPSOAAGT TIME MSG-ARG utt-time(), precede(,), named(bo)() CTXTBCKGRD CONSTITS PHON Did,PHON Bo, PHON leave,PHON Did Bo leave (7) CONT Before we can explain how these representations can feature in dialogue reasoning and the resolution of CE, we need to sketch briefly the approach to dialogue ellipsis that we assume. </context>
<context position="15930" citStr="Ginzburg and Sag, 2000" startWordPosition="2562" endWordPosition="2565">onstraint coindexes the head daughter with the SAL-UTT. This will have the effect of ‘unifying in’ the content of the former into a contextually provided content. A subtype of hd-fragph relevant to the current paper is (decl-frag-cl)— also a subtype of decl-cl—used to analyze short answers: proposition. This is the feature structure counterpart of the -abstract . 10For Wh-questions, SAL-UTT is the wh-phrase associated with the PARAMS set of the question; otherwise, its possible values are either the empty set or the utterance associated with the widest scoping quantifier in MAX-QUD. 11In the (Ginzburg and Sag, 2000) version of HPSG information about phrases is encoded by cross-classifying them in a multi-dimensional type hierarchy. Phrases are classified not only in terms of their phrase structure schema or X-bar type, but also with respect to a further informational dimension of CLAUSALITY. Clauses are divided into inter alia declarative clauses (decl-cl), which denote propositions, and interrogative clauses (inter-cl) denoting questions. Each maximal phrasal type inherits from both these dimensions. This classification allows specification of systematic correlations between clausal construction types a</context>
<context position="22042" citStr="Ginzburg and Sag, 2000" startWordPosition="3551" endWordPosition="3554"> proposition which emerges courtesy of bare-decl-cl a (polar) question is constructed using the type dir-is-intcl.14 Bo The second coercion operation we discussed previously is parameter identification: for a given problematic contextual parameter its output is a partial specification for a sign whose content and MAX-QUD involve a question querying the content of that utterance parameter: 14The phrasal type dir-is-int-cl which constitutes the type of the mother node in (16) is a type that inter alia enables a polar question to be built from a head daughter whose content is propositional. See (Ginzburg and Sag, 2000) for details. SAL-UTT MAX-QUD question PROP question PARAMS PROPSOA ASK-REL ASKER i ASKED j MSG-ARG question PARAMS PROPSOA leave-rel AGT TIME CONTMSG-ARG (14) PROP (16) S dir-is-int-cl question PARAMS ask-rel ASKER i ASKED j question PARAMS PROPSOA ✒ leave-rel AGT TIME CONT S CTXT SAL-UTT question MAX-QUDPARAMSINDEX PROP CAT CONTINDEX decl-frag-cl CONT CATNP CONTINDEX (17) parameter identification: ✠root-cl CTXT-INDICES CONSTITS CONT To exemplify: when this operation is applied to (7), it will yield as output the partial specification in (18): This specification will allows for clarification </context>
</contexts>
<marker>Ginzburg, Sag, 2000</marker>
<rawString>Jonathan Ginzburg and Ivan Sag. 2000. Interrogative Investigations: the form, meaning and use of English Interrogatives. Number 123 in CSLI Lecture Notes. CSLI Publications, Stanford: California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Ginzburg</author>
<author>Howard Gregory</author>
<author>Shalom Lappin</author>
</authors>
<title>Shards: Fragment resolution in dialogue. In</title>
<date>2001</date>
<booktitle>Proceedings of the 1st International Workshop on Computational Semantics. ITK,</booktitle>
<editor>H. Bunt, editor,</editor>
<location>Tilburg University, Tilburg.</location>
<contexts>
<context position="24813" citStr="Ginzburg et al., 2001" startWordPosition="3981" endWordPosition="3984">background knowledge. Even choosing among the responses in (5) might be a pretty knowledge intensive business. However, there are some clear strategies that might be pursued. For example, if Malvern has been discussed previously in the dialogue and understood then (5a,b) would not be appropriate responses. In order to be able to build dialogue systems that can handle even some restricted aspects of CEs we need to understand more about what the possible interpretations are and this is what we have attempted to do in this paper. We are currently working on a system which integrates SHARDS (see (Ginzburg et al., 2001), a system which processes dialogue ellipses) with GoDiS (see (Bohlin et al., 1999), a dialogue system developed using TRINDIKIT, which makes use of ISs modelled on those suggested in the KOS constit-repr-int-cl question CONT PARAMS PROP content(,) MAX-QUD PHON CAT NP PHON CAT SAL-UTT (21) CTXT HD-DTR MAX-QUD CONTENTMSG-ARG PROP SAL-UTT question question PARAMSINDEX content-rel PROPSOASIGN CONT framework. Our aim in the near future is to incorporate simple aspects of negotiative dialogue including CEs in a GoDiS-like system employing SHARDS. Acknowledgements For very useful discussion and comm</context>
</contexts>
<marker>Ginzburg, Gregory, Lappin, 2001</marker>
<rawString>Jonathan Ginzburg, Howard Gregory, and Shalom Lappin. 2001. Shards: Fragment resolution in dialogue. In H. Bunt, editor, Proceedings of the 1st International Workshop on Computational Semantics. ITK, Tilburg University, Tilburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Ginzburg</author>
</authors>
<title>Interrogatives: Questions, facts, and dialogue.</title>
<date>1996</date>
<booktitle>Handbook of Contemporary Semantic Theory.</booktitle>
<editor>In Shalom Lappin, editor,</editor>
<publisher>Blackwell,</publisher>
<location>Oxford.</location>
<contexts>
<context position="6286" citStr="Ginzburg, 1996" startWordPosition="1018" endWordPosition="1019">in an IS as a result of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg and Sag, 2000)). We start by informally describing the grounding/clarification processes and the representations on which they operate. We then provide the requisite background on HPSG and on the KOS framework (Ginzburg, 1996; Bohlin et al., 1999), in which our analysis of ISs is couched. We sketch an algorithm for the process of utterance integration which leads to grounding or clarification. Finally, we formalize the operations which underpin clarification and sketch a grammatical analysis of CE. 2 Utterance Representation: grounding and clarification We start by offering an informal description of how an utterancesuch as (6) can get grounded or spawn a clarification by an addressee B: (6) A: Did Bo leave? A is attempting to convey to B her question whether the property she has referred to with her utterance of </context>
<context position="13176" citStr="Ginzburg, 1996" startWordPosition="2138" endWordPosition="2139">rator embedding the appropriate semantic root-cl PHON did bo leave CAT V[+fin] C-INDICES,,, i,j ASK-REL ASKER i ASKED j question PARAMS leave-rel PROPSOAAGT TIME MSG-ARG utt-time(), precede(,), named(bo)() CTXTBCKGRD CONSTITS PHON Did,PHON Bo, PHON leave,PHON Did Bo leave (7) CONT Before we can explain how these representations can feature in dialogue reasoning and the resolution of CE, we need to sketch briefly the approach to dialogue ellipsis that we assume. 3 Contextual evolution and ellipsis We adopt the situation semantics based theory of dialogue context developed in the KOS framework (Ginzburg, 1996; Ginzburg, (forthcoming); Bohlin et al., 1999). The common ground component of ISs is assumed to be structured as follows:8 (8) ✠☛FACTS set offacts LATEST-MOVE (illocutionary) fact QUD p.o. set of questions In (Ginzburg and Sag, 2000) this framework is integrated into HPSG (Pollard and Sag, 1994); (Ginzburg and Sag, 2000) define two new attributes within the CONTEXT (CTXT) feature structure: Maximal Question Under Discussion (MAX-QUD), whose value is of sort question;9 object (an assertion embedding a proposition, a query embedding a question etc.). Here and throughout we omit various feature</context>
</contexts>
<marker>Ginzburg, 1996</marker>
<rawString>Jonathan Ginzburg. 1996. Interrogatives: Questions, facts, and dialogue. In Shalom Lappin, editor, Handbook of Contemporary Semantic Theory. Blackwell, Oxford.</rawString>
</citation>
<citation valid="false">
<authors>
<author>forthcoming</author>
</authors>
<title>Semantics and Interaction in Dialogue.</title>
<publisher>CSLI Publications and Cambridge University Press,</publisher>
<location>Stanford: California.</location>
<note>Draft chapters available from http://www.dcs.kcl.ac.uk/staff/ginzburg.</note>
<marker>forthcoming, </marker>
<rawString>Jonathan Ginzburg. forthcoming. Semantics and Interaction in Dialogue. CSLI Publications and Cambridge University Press, Stanford: California. Draft chapters available from http://www.dcs.kcl.ac.uk/staff/ginzburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Gregory</author>
<author>Shalom Lappin</author>
</authors>
<title>Antecedent contained ellipsis</title>
<date>1999</date>
<booktitle>Lexical and Constructional Aspects ofLinguistic Explanation,</booktitle>
<pages>331--356</pages>
<editor>in HPSG. In Gert Webelhuth, Jean Pierre Koenig, and Andreas Kathol, editors,</editor>
<publisher>CSLI Publications, Stanford.</publisher>
<contexts>
<context position="12093" citStr="Gregory and Lappin, 1999" startWordPosition="1967" endWordPosition="1970">s abstracts with roles that need to be instantiated. The second modification we make concerns the encoding of phrasal constituency. Standardly, the feature DTRS is used to encode immediate phrasal constituency. To facilitate statement of coercion operations, we need access to all phrasal constituents— given that a contextual parameter emanating from deeply embedding constituents are as clarifiable as immediate constituents. We posit a set valued feature CONSTIT(UENT)S whose value is the set of all constituents immediate or otherwise of a given sign (Cf. the mother-daughter predicates used in (Gregory and Lappin, 1999).) In fact, having posited CONSTITS one could eliminate DTRS: this by making the value of CONSTITS be a set of sets whose first level elements are the immediate constituents. For current purposes, we stick with tradition and tolerate the redundancy of both DTRS and CONSTITS. 7Within the phrasal type system of (Ginzburg and Sag, 2000) root-cl constitutes the ‘start’ symbol of the grammar. In particular, phrases of this type have as their content an illocutionary operator embedding the appropriate semantic root-cl PHON did bo leave CAT V[+fin] C-INDICES,,, i,j ASK-REL ASKER i ASKED j question PA</context>
</contexts>
<marker>Gregory, Lappin, 1999</marker>
<rawString>Howard Gregory and Shalom Lappin. 1999. Antecedent contained ellipsis in HPSG. In Gert Webelhuth, Jean Pierre Koenig, and Andreas Kathol, editors, Lexical and Constructional Aspects ofLinguistic Explanation, pages 331–356. CSLI Publications, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milward</author>
</authors>
<title>Distributing representation for robust interpretation of dialogue utterances.</title>
<date>2000</date>
<publisher>ACL.</publisher>
<contexts>
<context position="10595" citStr="Milward, 2000" startWordPosition="1724" endWordPosition="1726">ism encoded in clarification contexts, these operations need to be defined on representations that encode in parallel for each subutterance down to the word level phonological, syntactic, semantic, and contextual information. With some minor modifications, signs as conceived in HPSG are exactly such a representational format and, hence, we will use them to define coercion operations.6 More precisely, given that an addressee might not be able to come up with a unique or a complete parse, due to lexical ignorance or a noisy environment, we need to utilize some ‘underspecified’ entity (see e.g. (Milward, 2000)). For simplicity we will use descriptions of signs. An example of the format for signs we employ is given in (7):7 6We make two minor modifications to the version of HPSG described in (Ginzburg and Sag, 2000)). First, we revamp the existing treatment of the feature C-INDICES. This will now encode the entire inventory of contextual parameters of an utterance (proper names, deictic pronouns, indexicals) not merely information about speaker/hearer/utterancetime, as standardly. Indeed, in principle, relation names should also be included, since they vary with context and are subject to clarificat</context>
</contexts>
<marker>Milward, 2000</marker>
<rawString>David Milward. 2000. Distributing representation for robust interpretation of dialogue utterances. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<date>1974</date>
<editor>Pragmatics. In Richmond Thomason, editor, Formal Philosophy. Yale UP,</editor>
<location>New Haven.</location>
<contexts>
<context position="7522" citStr="Montague, 1974" startWordPosition="1224" endWordPosition="1225">rson she has referred to with the name Bo. B is required to try and find values for these references. Finding values is, with an important caveat, a necessary condition for B to ground A’s utterance, thereby signalling that its content has been integrated in B’s IS.4 Modelling this condition for successful grounding provides one obvious constraint on the representation of utterance types: such a representation must involve a function from orabstract over a set of certain parameters (the contextual parameters) to contents. This much is familiar already from early work on context dependence by (Montague, 1974) et seq. What happens when B cannot or is at least uncertain as to how he should instantiate in his IS a contextual parameter? In such a case B needs to do at least the following: (1) perform a partial update of the existing context with the successfully processed components of the utterance (2) pose a clarification question that involves reference to the subutterance ufrom whichemanates. Since the original speaker, A, can coherently integrate a clarification question once she hears it, it follows that, for a given utterance, there is a predictable range ofpartial updates + consequent clarific</context>
</contexts>
<marker>Montague, 1974</marker>
<rawString>Richard Montague. 1974. Pragmatics. In Richmond Thomason, editor, Formal Philosophy. Yale UP, New Haven.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Massimo Poesio</author>
<author>David Traum</author>
</authors>
<title>Conversational actions and discourse situations.</title>
<date>1997</date>
<journal>ComputationalIntelligence,</journal>
<pages>13--309</pages>
<contexts>
<context position="5591" citStr="Poesio and Traum, 1997" startWordPosition="902" endWordPosition="905">techniques such as first order unification (as anaphora often is) or by higher order unification (HOU) on logical forms (see e.g. (Pulman, 1997)). For a start, in order to capture the syntactic and phonological parallelism exemplified in (3), logical forms are simply insufficient. Moreover, although an HOU account could, given a theory of dialogue that structures context appropriately, generate the clausal reading, the constituent reading cannot be so generated. Clark (e.g. (Clark, 1996)) initiated work on the grounding of an utterance (for computational and formal work see e.g. (Traum, 1994; Poesio and Traum, 1997)). However, existing work, while spelling out in great detail what updates arise in an IS as a result of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg and Sag, 2000)). We start by informally describing the grounding/clarification processes and the representations on which they ope</context>
</contexts>
<marker>Poesio, Traum, 1997</marker>
<rawString>Massimo Poesio and David Traum. 1997. Conversational actions and discourse situations. ComputationalIntelligence, 13:309–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<date>1994</date>
<institution>Head Driven Phrase Structure Grammar. University of Chicago Press and CSLI, Chicago.</institution>
<contexts>
<context position="13474" citStr="Pollard and Sag, 1994" startWordPosition="2184" endWordPosition="2187">e can explain how these representations can feature in dialogue reasoning and the resolution of CE, we need to sketch briefly the approach to dialogue ellipsis that we assume. 3 Contextual evolution and ellipsis We adopt the situation semantics based theory of dialogue context developed in the KOS framework (Ginzburg, 1996; Ginzburg, (forthcoming); Bohlin et al., 1999). The common ground component of ISs is assumed to be structured as follows:8 (8) ✠☛FACTS set offacts LATEST-MOVE (illocutionary) fact QUD p.o. set of questions In (Ginzburg and Sag, 2000) this framework is integrated into HPSG (Pollard and Sag, 1994); (Ginzburg and Sag, 2000) define two new attributes within the CONTEXT (CTXT) feature structure: Maximal Question Under Discussion (MAX-QUD), whose value is of sort question;9 object (an assertion embedding a proposition, a query embedding a question etc.). Here and throughout we omit various features (e.g. STORE, SLASH etc that have no bearing on current issues wherever possible. 8Here FACTS corresponds to the set of commonly accepted assumptions; QUD(‘questions under discussion’) is a set consisting of the currently discussable questions, partially ordered by(‘takes conversational precedenc</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan Sag. 1994. Head Driven Phrase Structure Grammar. University of Chicago Press and CSLI, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Pulman</author>
</authors>
<title>Focus and higher order unification.</title>
<date>1997</date>
<journal>Linguistics and Philosophy,</journal>
<volume>20</volume>
<contexts>
<context position="5112" citStr="Pulman, 1997" startWordPosition="828" endWordPosition="829">onses might be (5a-c); the system should definitely not say (5d), as it might if it does not recognize that the user is trying to clarify its previous utterance. (5) a. Yes, Malvern b. Malvern – M-A-L-V-E-R-N c. Going via Malvern is the quickest route d. So, you would like to make that trip via Malvern instead of Malvern? In this paper we examine the interpretation of CEs. CE is a singularly complex ellipsis/anaphoric phenomenon which cannot be handled by standard techniques such as first order unification (as anaphora often is) or by higher order unification (HOU) on logical forms (see e.g. (Pulman, 1997)). For a start, in order to capture the syntactic and phonological parallelism exemplified in (3), logical forms are simply insufficient. Moreover, although an HOU account could, given a theory of dialogue that structures context appropriately, generate the clausal reading, the constituent reading cannot be so generated. Clark (e.g. (Clark, 1996)) initiated work on the grounding of an utterance (for computational and formal work see e.g. (Traum, 1994; Poesio and Traum, 1997)). However, existing work, while spelling out in great detail what updates arise in an IS as a result of grounding, do no</context>
</contexts>
<marker>Pulman, 1997</marker>
<rawString>Stephen Pulman. 1997. Focus and higher order unification. Linguistics and Philosophy, 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
<author>Jonathan Ginzburg</author>
<author>Patrick Healey</author>
</authors>
<title>On the means for clarification in dialogue.</title>
<date>2001</date>
<tech>Technical report,</tech>
<location>King’s College, London.</location>
<contexts>
<context position="2666" citStr="Purver et al., 2001" startWordPosition="425" endWordPosition="428">s original interpretation: (2) a. A:... you always had er er say every foot he had with a piece of spunyarn in the wire/B: Spunyarn?/A: Spunyarn, yes/B: What’s spunyarn? b. A: Have a laugh and joke with Dick./ B: Dick?/A: Have a laugh and joke with Dick./B: Who’s Dick? 1An anonymous ACL reviewer proposed to us that all CE could be analyzed in terms of a single reading along the lines of “I thought I heard you say Bo, and I don’t know why you would do so?”. 2Closely related to this issue is the issue of what other readings/understandings CE exhibits. We defer discussion of the latter issue to (Purver et al., 2001), which provides a detailed analysis of the frequency of CEs and their understandings among clarification utterances in the British National Corpus (BNC). 3This confirms our (non-instrumentally tested) impression that these understandings are not on the whole disambiguated intonationally. All our CE data from the BNC was found using SCoRE, Matt Purver’s dialogue oriented BNC search engine (Purver, 2001). More crucially, the clausal and constituent readings involve distinct syntactic and phonological parallelism conditions. The constituent reading seems to actually require phonological identity</context>
</contexts>
<marker>Purver, Ginzburg, Healey, 2001</marker>
<rawString>Matthew Purver, Jonathan Ginzburg, and Patrick Healey. 2001. On the means for clarification in dialogue. Technical report, King’s College, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Purver</author>
</authors>
<title>Score: Searching a corpus for regular expressions.</title>
<date>2001</date>
<tech>Technical report,</tech>
<location>King’s College, London.</location>
<contexts>
<context position="3072" citStr="Purver, 2001" startWordPosition="489" endWordPosition="490">say Bo, and I don’t know why you would do so?”. 2Closely related to this issue is the issue of what other readings/understandings CE exhibits. We defer discussion of the latter issue to (Purver et al., 2001), which provides a detailed analysis of the frequency of CEs and their understandings among clarification utterances in the British National Corpus (BNC). 3This confirms our (non-instrumentally tested) impression that these understandings are not on the whole disambiguated intonationally. All our CE data from the BNC was found using SCoRE, Matt Purver’s dialogue oriented BNC search engine (Purver, 2001). More crucially, the clausal and constituent readings involve distinct syntactic and phonological parallelism conditions. The constituent reading seems to actually require phonological identity. With the resolution associated with clausal readings, there is no such requirement. However, partial syntactic parallelism does obtain: an XP used to clarify an antecedent sub-utterance must match categorially, though there is no requirement ofphonological identity: (3) a. A: I phoned him. B: him? / #he? b. A: Did he adore the book. B: adore? / #adored? c. A: We’re leaving? B: You? We are used to syst</context>
</contexts>
<marker>Purver, 2001</marker>
<rawString>Matthew Purver. 2001. Score: Searching a corpus for regular expressions. Technical report, King’s College, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Traum</author>
</authors>
<title>A Computational Theory of Grounding in Natural Language Conversations.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Rochester.</institution>
<contexts>
<context position="5566" citStr="Traum, 1994" startWordPosition="900" endWordPosition="901"> by standard techniques such as first order unification (as anaphora often is) or by higher order unification (HOU) on logical forms (see e.g. (Pulman, 1997)). For a start, in order to capture the syntactic and phonological parallelism exemplified in (3), logical forms are simply insufficient. Moreover, although an HOU account could, given a theory of dialogue that structures context appropriately, generate the clausal reading, the constituent reading cannot be so generated. Clark (e.g. (Clark, 1996)) initiated work on the grounding of an utterance (for computational and formal work see e.g. (Traum, 1994; Poesio and Traum, 1997)). However, existing work, while spelling out in great detail what updates arise in an IS as a result of grounding, do not offer a characterization of the clarification possibilities spawned by a given utterance. A sketch of such a characterization is provided in this paper. On the basis of this we offer an analysis of CE, integrated into a large existing grammar framework, Head-Driven Phrase Structure Grammar (HPSG) (specifically the version developed in (Ginzburg and Sag, 2000)). We start by informally describing the grounding/clarification processes and the represen</context>
</contexts>
<marker>Traum, 1994</marker>
<rawString>David Traum. 1994. A Computational Theory of Grounding in Natural Language Conversations. Ph.D. thesis, University of Rochester.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>