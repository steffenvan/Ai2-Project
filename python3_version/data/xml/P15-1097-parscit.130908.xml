<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.994109">
Structural Representations for Learning Relations between Pairs of Texts
</title>
<author confidence="0.962968">
Simone Filice and Giovanni Da San Martino and Alessandro Moschitti
</author>
<affiliation confidence="0.880827">
ALT, Qatar Computing Research Institute, Hamad Bin Khalifa University
</affiliation>
<email confidence="0.983465">
{sfilice,gmartino,amoschitti}@qf.org.qa
</email>
<sectionHeader confidence="0.997161" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999715181818182">
This paper studies the use of structural
representations for learning relations be-
tween pairs of short texts (e.g., sentences
or paragraphs) of the kind: the second
text answers to, or conveys exactly the
same information of, or is implied by, the
first text. Engineering effective features
that can capture syntactic and semantic re-
lations between the constituents compos-
ing the target text pairs is rather complex.
Thus, we define syntactic and semantic
structures representing the text pairs and
then apply graph and tree kernels to them
for automatically engineering features in
Support Vector Machines. We carry out
an extensive comparative analysis of state-
of-the-art models for this type of relational
learning. Our findings allow for achiev-
ing the highest accuracy in two differ-
ent and important related tasks, i.e., Para-
phrasing Identification and Textual Entail-
ment Recognition.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.967157464285714">
Advanced NLP systems, e.g., IBM Watson system
(Ferrucci et al., 2010), are the result of effective
use of syntactic/semantic information along with
relational learning (RL) methods. This research
area is rather vast including, extraction of syntac-
tic relations, e.g., (Nastase et al., 2013), predicate
relations, e.g., Semantic Role Labeling (Carreras
and M`arquez, 2005) or FrameNet parsing (Gildea
and Jurafsky, 2002) and relation extraction be-
tween named entities, e.g., (Mintz et al., 2009).
Although extremely interesting, the above
methods target relations only between text con-
stituents whereas the final goal of an intelligent
system would be to interpret the semantics of
larger pieces of text, e.g., sentences or para-
graphs. This line of research relates to three
broad fields, namely, Question Answering (QA)
(Voorhees and Tice, 1999), Paraphrasing Identifi-
cation (PI) (Dolan et al., 2004) and Recognition
of Textual Entailments (RTE) (Giampiccolo et al.,
2007). More generally, RL from text can be denied
as follows: given two text fragments, the main
goal is to derive relations between them, e.g., ei-
ther if the second fragment answers the question,
or conveys exactly the same information or is im-
plied by the first text fragment. For example, the
following two sentences:
- License revenue slid 21 percent, however, to
$107.6 million.
- License sales, a key measure of demand, fell 21
percent to $107.6 million.
express exactly the same meaning, whereas the
next one:
- She was transferred again to Navy when the
American Civil War began, 1861.
implies:
- The American Civil War started in 1861.
Automatic learning a model for deriving the re-
lations above is rather complex as any of the text
constituents, e.g., License revenue, a key measure
of demand, in the two sentences plays an important
role. Therefore, a suitable approach should ex-
ploit representations that can structure the two sen-
tences and put their constituents in relation. Since
the dependencies between constituents can be an
exponential number and representing structures in
learning algorithms is rather challenging, auto-
matic feature engineering through kernel methods
(Shawe-Taylor and Cristianini, 2004; Moschitti,
2006) can be a promising direction.
In particular, in (Zanzotto and Moschitti, 2006),
we represented the two evaluating sentences for
the RTE task with syntactic structures and then ap-
plied tree kernels to them. The resulting system
was very accurate but, unfortunately, it could not
scale to large datasets as it is based on a compu-
</bodyText>
<page confidence="0.849481">
1003
</page>
<note confidence="0.972413">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1003–1013,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.99964355">
tationally exponential algorithm. This prevents its
application to PI tasks, which typically require a
large dataset to train the related systems.
In this paper, we carry out an extensive exper-
imentation using different kernels based on trees
and graphs and their combinations with the aim of
assessing the best model for relation learning be-
tween two entire sentences (or even paragraphs).
More in detail, (i) we design many models for RL
combining state-of-the-art tree kernels and graph
kernels and apply them to innovative computa-
tional structures. These innovative combinations
use for the fist time semantic/syntactic tree ker-
nels and graph kernels for the tackled tasks. (ii)
Our kernels provide effective and efficient solu-
tions, which solve the previous scalability problem
and, at the same time, exceed the state of the art
on both RTE and PI. Finally, our study suggests
research directions for designing effective graph
kernels for RL.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999595857142857">
In this paper, we apply kernel methods, which en-
able an efficient comparison of structures in huge,
possibly infinite, feature spaces. While for trees, a
comparison using all possible subtrees is possible,
designing kernel functions for graphs with such
property is an NP-Hard problem (i.e., it shows the
same complexity of the graph isomorphism prob-
lem) (Gartner et al., 2003). Thus most kernels
for graphs only associate specific types of sub-
structures with features, such as paths (Borgwardt
and Kriegel, 2005; Heinonen et al., 2012), walks
(Kashima et al., 2003; Vishwanathan et al., 2006)
and tree structures (Cilia and Moschitti, 2007;
Mah´e and Vert, 2008; Shervashidze et al., 2011;
Da San Martino et al., 2012).
We exploit structural kernels for PI, whose task
is to evaluate whether a given pair of sentences is
in the paraphrase class or not, (see for example
(Dolan et al., 2004)). Paraphrases can be seen as
a restatement of a text in another form that pre-
serves the original meaning. This task has a pri-
mary importance in many other NLP and IR tasks
such as Machine Translation, Plagiarism Detec-
tion and QA. Several approaches have been pro-
posed, e.g., (Socher et al., 2011) apply a recursive
auto encoder with dynamic pooling, and (Madnani
et al., 2012) use eight machine translation metrics
to achieve the state of the art. To our knowledge no
previous model based on kernel methods has been
applied before: with such methods, we outperform
the state of the art in PI.
A description of RTE can be found in (Giampic-
colo et al., 2007): it is defined as a directional
relation extraction between two text fragments,
called text and hypothesis. The implication is sup-
posed to be detectable only based on the text con-
tent. Its applications are in QA, Information Ex-
traction, Summarization and Machine translation.
One of the most performing approaches of RTE 3
was (Iftene and Balahur-Dobrescu, 2007), which
largely relies on external resources (i.e., WordNet,
Wikipedia, acronyms dictionaries) and a base of
knowledge developed ad hoc for the dataset. In
(Zanzotto and Moschitti, 2006), we designed an
interesting but computationally expensive model
using simple syntactic tree kernels. In this pa-
per, we develop models that do not use external
resources but, at the same time, are efficient and
approach the state of the art in RTE.
</bodyText>
<sectionHeader confidence="0.984927" genericHeader="method">
3 Structural kernels
</sectionHeader>
<bodyText confidence="0.9830214">
Kernel Machines carry out learning and classifi-
cation by only relying on the inner product be-
tween instances. This can be efficiently and im-
plicitly computed by kernel functions by exploit-
ing the following dual formulation of the model
(hyperplane): i=1..lyiαiφ(oi) · φ(o) + b = 0,
where yi are the example labels, αi the support
vector coefficients, oi and o are two objects, φ is
a mapping from the objects to feature vectors ~xi
and φ(oi) · φ(o) = K(oi, o) is the kernel func-
tion implicitly defining such mapping. In case
of structural kernels, K maps objects in substruc-
tures, thus determining their size and shape. Given
two structures S1 and S2, our general definition of
structural kernels is the following:
</bodyText>
<equation confidence="0.997117">
K(S1, S2) = � kiso(s1,s2), (1)
s1⊆S1,s2⊆S2,si∈S
</equation>
<bodyText confidence="0.999538818181818">
where si are substructures of Si, S is the set of ad-
missible substructures, and kiso determines if the
two substructures are isomorphic, i.e., it outputs 1
if s1 and s2 are isomorphic and 0 otherwise.
In the following, we also provide a more
computational-oriented definition of structural
kernels to more easily describe those we use in our
work:
Let the set S = {s1, s2, ... , s|S|} be the substruc-
ture space and χi(n) be an indicator function,
equal to 1 if the target si is rooted at node n and
</bodyText>
<page confidence="0.993491">
1004
</page>
<subsectionHeader confidence="0.993656">
3.1 The Partial Tree Kernel (PTK)
</subsectionHeader>
<bodyText confidence="0.984783444444444">
PTK (Moschitti, 2006) generalizes a large class
of tree kernels as it computes one of the most
general tree substructure spaces. Given two trees
S1 and S2, PTK considers any connected subset
of nodes as possible feature of the substructure
space, and counts how many of them are shared
by S1 and S2. Its computation is carried out by
Eq. 2 using the following ΔPTK function:
if the labels of n1 and n2 are different
</bodyText>
<equation confidence="0.917722">
ΔPTK(n1, n2) = 0; else ΔPTK(n1, n2) =
�ΔPTK(cn1(~I1j), cn2(~I2j))
</equation>
<bodyText confidence="0.999748615384615">
where µ, λ E [0, 1] are two decay factors, ~I1 and
~I2 are two sequences of indices, which index sub-
sequences of children u, I~ = (i1, ..., i|u|), in se-
quences of children s, 1 &lt; i1 &lt; ... &lt; ijuj &lt; |s|,
i.e., such that u = si1..sijuj, and d(~I) = i|u |−
i1 + 1 is the distance between the first and last
child. The PTK computational complexity is
O(pρ2jNS1jjNS2j) (Moschitti, 2006), where p is
the largest subsequence of children that we want
to consider and ρ is the maximal outdegree ob-
served in the two trees. However the average run-
ning time tends to be linear for natural language
syntactic trees (Moschitti, 2006).
</bodyText>
<subsectionHeader confidence="0.997695">
3.2 Smoothed Partial Tree Kernel (SPTK)
</subsectionHeader>
<bodyText confidence="0.932720857142857">
Constraining the application of lexical simi-
larity to words embedded in similar structures
provides clear advantages over all-vs-all words
similarity, which tends to semantically di-
verge. Indeed, syntax provides the necessary
restrictions to compute an effective semantic
similarity. SPTK (Croce et al., 2011) gen-
eralizes PTK by enabling node similarity
during substructure matching. More formally,
SPTK is computed by Eq. 2 using the following
ΔSPTK(n1, n2) = P|�|
i,j=1 χi(n1)χj(n2)Σ(si, sj),
where Σ is a similarity between structures1. The
recursive definition of ΔSPTK is the following:
</bodyText>
<listItem confidence="0.495681666666667">
1. if n1 and n2 are leaves ΔSPTK(n1, n2) =
µλσ(n1, n2); /
2. else ΔSPTK(n1, n2) = µσ(n1, n2) ~ I λ2+
</listItem>
<bodyText confidence="0.9993088">
where σ is any similarity between nodes, e.g., be-
tween their lexical labels, and the other variables
are the same of PTK. The worst case complexity
of SPTK is identical to PTK and in practice is
not higher than O(jNS1jjNS2j).
</bodyText>
<subsectionHeader confidence="0.955427">
3.3 Neighborhood Subgraph Pairwise
Distance Kernel (NSPDK)
</subsectionHeader>
<bodyText confidence="0.965120086956522">
When general subgraphs are used as features in a
kernel computation, eq. 1 and 2 become computa-
tionally intractable (Gartner et al., 2003). To solve
this problem, we need to restrict the set of consid-
ered substructures S. (Costa and De Grave, 2010)
defined NSPDK such that the feature space is
only constituted by pairs of subgraphs (substruc-
tures) that are (i) centered in two nodes n1 and n2
such that their distance is not more than D; and
(ii) constituted by all nodes (and their edges) at
an exact distance h from n1 or n2, where the dis-
tance between two nodes is defined as the num-
ber of edges in the shortest path connecting them.
More formally, let G, NG and EG be a graph and
its set of nodes and edges, respectively, the sub-
structure space S = SG(H, D) used by NSPDK
in eqs 2 and 3 is:
{(γh(n), γh(n&apos;)) : 1 &lt; h &lt; H, n, n&apos; E NG,
d(n, n&apos;) &lt; D},
where γh(n) returns the subgraph obtained by ex-
ecuting h steps of a breadth-first visit of G starting
from node n and d(n, n&apos;) is the distance between
two nodes in the graph. Note that (i) any feature
</bodyText>
<footnote confidence="0.900343">
1Note that this generalizes Eq. 3.
</footnote>
<equation confidence="0.912751111111111">
~I1)
�Δσ(cn1(~I1j), cn2(~I2j)) ,
l(
X λd(~I1)+d( ~I2) Y
~I1,~I2,l(~I1)=l(~I2) j=1
equal to 0 otherwise. A structural-kernel function
over S1 and S2 is
K(S1, S2) = X X Δ(n1, n2), (2)
n1ENS1 n2ENS2
</equation>
<bodyText confidence="0.999564">
where NS1 and NS2 are the sets of the S1’s and
S2’s nodes, respectively and
</bodyText>
<equation confidence="0.9987365">
Δ(n1, n2) = X |� |χi(n1)χi(n2). (3)
i=1
</equation>
<bodyText confidence="0.953508888888889">
The latter is equal to the number of common
substructures rooted in the n1 and n2 nodes.
In order to have a similarity score between 0
and 1, a normalization in the kernel space, i.e.,
K(S1,S2) is usually applied. From a
pK(S1,S1)XK(S2,S2)
practical computation viewpoint, it is convenient
to divide structural kernels in two classes of algo-
rithms working either on trees or graphs.
</bodyText>
<equation confidence="0.999180571428571">
� X
µ λ2+
~I1,~I2,l(~I1)=l(~I2)
l( ~I1)
I2) Y
j=1
λd( �I1)+d(
</equation>
<page confidence="0.890882">
1005
</page>
<bodyText confidence="0.999918142857143">
of the space is basically a pair of substructures;
and (ii) there is currently no efficient (implicit) for-
mulation for computing such kernel. In contrast,
when H and D are limited, it is simple to compute
the space SG(H, D) explicitly. In such case, the
complexity of the kernel is given by the substruc-
ture extraction step, which is O(|NG |x hp log p).
</bodyText>
<subsectionHeader confidence="0.982602">
3.4 Kernel Combinations
</subsectionHeader>
<bodyText confidence="0.999891375">
Previous sections have shown three different ker-
nels. Among them, NSPDK is actually an ex-
plicit kernel, where the features are automatically
extracted with a procedure. In NLP, features are
often manually defined by domain experts, who
know the linguistic phenomena involved in the
task. When available, such features are important
as they encode some of the background knowledge
on the task. Therefore, combining different feature
spaces is typically very useful. Fortunately, ker-
nel methods enable an easy integration of different
kernels or feature spaces, i.e., the kernel sum pro-
duces the joint feature space and it is still a valid
kernel. In the next section, we show representa-
tions of text, i.e., structures and features, specific
to PI and RTE.
</bodyText>
<sectionHeader confidence="0.998975" genericHeader="method">
4 Representations for RL from text
</sectionHeader>
<bodyText confidence="0.999995173913044">
The kernels described in the previous section can
be applied to generic trees and graphs. Auto-
matic feature engineering using structural kernels
requires the design of structures for representing
data examples that are specific to the learning task
we want to tackle. In our case, we focus on RL,
which consists in deriving the semantic relation
between two entire pieces of text. We focus on
two well-understood relations, namely, paraphras-
ing and textual implications. The tasks are simply
defined as: given two texts a1 and a2, automati-
cally classify if (i) a1 is a paraphrase of a2 and/or
(ii) a1 implies a2. Although the two tasks are lin-
guistically and conceptually rather different, they
can be modeled in a similar way from a shallow
representation viewpoint. This is exactly the per-
spective we would like to keep for showing the ad-
vantage of using kernel methods. Therefore, in the
following, we define sentence representations that
can be suitably used for both tasks and then we
rely on structural kernels and the adopted learning
algorithm for exploring the substructures relevant
to the different tasks.
</bodyText>
<subsectionHeader confidence="0.99765">
4.1 Tree Representations
</subsectionHeader>
<bodyText confidence="0.999961333333333">
An intuitive understanding of our target tasks
suggests that syntactic information is essential to
achieve high accuracy. Therefore, we consider
the syntactic parse trees of the pair of sentences
involved in the evaluation. For example, Fig. 1
shows the syntactic constituency trees of the
sentences reported in the introduction (these
do not include the green label REL and the
dashed edges). Given two pairs of sentences,
pa = (a1, a2) and pb = (b1, b2), an initial kernel
for learning the tasks, can be the simple tree
kernel sum, e.g., PTK(a1, b1) + PTK(a2, b2)
as was defined in (Moschitti, 2008). This kernel
works in the space of the union of the sets of all
subtrees from the upper and lower trees, e.g.:
</bodyText>
<equation confidence="0.319156">
{[PP [TO [to::t]][NP [QP [$
[$::$]][QP [CD [107.6::c]]]]]], [PP
[TO][NP [QP [$][QP [CD [107]]]]]], [PP
[TO][NP [QP [QP [CD]]]]], [PP [NP [QP
[QP]]]], ...}
a2: {[NP [NP [DT [a::d]] [JJ [key::j]
NN]][PP]], [NP [NP [DT] [JJ NN]][PP]], [NP
[NP [JJ NN]][PP]], [NP [NP [NN]][PP]],
[NP [NP [JJ]][PP]], ... }
</equation>
<bodyText confidence="0.999960952380953">
However, such features cannot capture the rela-
tions between the constituents (or semantic lexical
units) from the two trees. In contrast, these are es-
sential to learn the relation between the two entire
sentences2.
To overcome this problem, in (Zanzotto and
Moschitti, 2006), we proposed the use of place-
holders for RTE: the main idea was to annotate the
matches between the constituents of the two sen-
tences, e.g., 107.6 millions, on both trees. This
way the tree fragments in the generated kernel
space contained an index capturing the correspon-
dences between a1 and a2. The critical drawback
of this approach is that other pairs, e.g., pb, will
have in general different indices, making the rep-
resentation very sparse. Alternatively, we experi-
mented with models that select the best match be-
tween all possible placeholder assignments across
the two pairs. Although we obtained a good im-
provement, such solution required an exponential
computational time and the selection of the max
</bodyText>
<footnote confidence="0.718748">
2Of course assuming that text meaning is compositional.
</footnote>
<page confidence="0.986566">
1006
</page>
<figureCaption confidence="0.942441">
Figure 1: Text representations for PI and RTE: (i) pair of trees, a1 (upper) and a2 (lower), (ii) combined
</figureCaption>
<bodyText confidence="0.850135">
in a graph with dashed edges, and (iii) labelled with the tag REL (in green). The nodes highlighted in
yellow constitute a feature for the NSPDK kernel (h = 1, D = 3) centered at the nodes ADVB and
NP-REL.
</bodyText>
<figure confidence="0.999813205479452">
ROOT
S
VP
NP-REL
NN
revenue::n
JJ-REL
license::j
VBD
NP-REL
slide::v
CD-REL
21::c
NN-REL
percent::n
.
PP
,::,
,
TO NP
to::t QP-REL
.::.
$-REL
QP-REL
, ADVB
,::, RB
however::r
CD-REL
million::c
$::$
ROOT
S
NP
VP
.
JJ-REL
license::j
NP
NNS
sale::n
DT JJ
a::d key::j
,
,::,
NP
NN
demand::n
.::.
QP-REL
CD-REL CD-REL
107.6::c million::c
NP-REL
NP-REL
IN
NN of::i
PP
CD-REL
21::c
NN-REL
percent::n
$::$
measure::n
PP
,
,::,
NP
VBD
fall::v
TO NP
to:t QP-REL
$-REL
CD-REL
107.6::c
</figure>
<bodyText confidence="0.95016715">
assignment made our similarity function a non-
valid kernel.
Thus, for this paper, we prefer to rely on a more
recent solution we proposed for passage reranking
in the QA domain (Severyn and Moschitti, 2012;
Severyn et al., 2013a; Severyn et al., 2013b), and
for Answer Selection (Severyn and Moschitti,
2013). It consists in simply labeling matching
nodes with a special tag, e.g., REL, which
indicates the correspondences between words.
REL is attached to the father and grandfather
nodes of the matching words. Fig. 1 shows
several green REL tags attached to the usual
POS-tag and constituent node labels of the parse
trees. For example, the lemma license is matched
by the two sentences, thus both its father, JJ,
and its grandfather, NP, nodes are marked with
REL. Thanks to such relational labeling the
simple kernel, PTK(a1, b1) + PTK(a2, b2), can
generate relational features from a1, e.g., [NP
</bodyText>
<sectionHeader confidence="0.865675" genericHeader="method">
[NP-REL [JJ-REL] NN]][PP]], [NP [NP-REL
[NN]][PP]], [NP [NP-REL [JJ-REL]][PP]],...
</sectionHeader>
<bodyText confidence="0.999667142857143">
If such features are matched in b1, they provide
the fuzzy information: there should be a match
similar to [NP [NP-REL [JJ-REL]] also between
a2 and b2. This kind of matches establishes a sort
of relational pair features.
It should be noted that we proposed more
complex REL tagging policies for Passage Re-
ranking, exploiting additional resources such as
Linked Open Data or WordNet (Tymoshenko et
al., 2014). Another interesting application of this
RL framework is the Machine Translation Evalua-
tion (Guzm´an et al., 2014). Finally, we used a sim-
ilar model for translating questions to SQL queries
in (Giordani and Moschitti, 2012).
</bodyText>
<subsectionHeader confidence="0.985125">
4.2 Graph Representations
</subsectionHeader>
<bodyText confidence="0.999048625">
The relational tree representation can capture re-
lational features but the use of the same REL
tag for any match between the two trees prevents
to deterministically establish the correspondences
between nodes. For exactly representing such
matches (without incurring in non-valid kernels
or sparsity problems), a graph representation is
needed. If we connect matching nodes (or also
nodes labelled as REL) in Fig. 1 (see dashed
lines), we obtain a relational graph. Substructures
of such graph clearly indicate how constituents,
e.g., NPs, VPs, PPs, from one sentence map into
the other sentence. If such mappings observed
in a pair of paraphrase sentences are matched
in another sentence pair, there may be evidence
that also the second pair contains paraphrase sen-
</bodyText>
<page confidence="0.970807">
1007
</page>
<bodyText confidence="0.993311615384615">
tences.
Unfortunately, the kernel computing the space
of all substructures of a graph (even if only con-
sidering connected nodes) is an intractable prob-
lem as mentioned in Sec. 3.3. Thus, we opt for the
use of NSPDK, which generates specific pairs
of structures. Intuitively, the latter can capture re-
lational features between constituents of the two
trees. Figure 1 shows an example of features gen-
erated by the NSPDK with parameters H =
1, D = 3 (the substructures are highlighted in
yellow), i.e., [ADVB [VP] [RB]], [NP-REL [VP]
[CD-REL] [NN-REL]].
</bodyText>
<subsectionHeader confidence="0.99821">
4.3 Basic Features
</subsectionHeader>
<bodyText confidence="0.9274392">
In addition to structural representations, we also
use typical features for capturing the degrees of
similarity between two sentences. In contrast,
with the previous kernels these similarities are
computed intra-pair, e.g., between a1 and a2. Note
that any similarity measure generates only one fea-
ture. Their description follows:
– Syntactic similarities, which apply the cosine
function to vectors of n-grams (with n = 1, 2, 3, 4)
of word lemmas and part-of-speech tags.
– Kernel similarities, which use PTK or SPTK
applied to the sentences within the pair.
We also used similarity features from the
DKPro of the UKP Lab (B¨ar et al., 2012), tested
in the Semantic Textual Similarity (STS) task:
– Longest common substring measure and Longest
common subsequence measure, which determine
the length of the longest substring shared by two
text segments.
– Running-Karp-Rabin Greedy String Tiling pro-
vides a similarity between two sentences by count-
ing the number of shuffles in their subparts.
– Resnik similarity based on the WordNet hierar-
chy.
– Explicit Semantic Analysis (ESA) similar-
ity (Gabrilovich and Markovitch, 2007) repre-
sents documents as weighted vectors of con-
cepts learned from Wikipedia, WordNet and Wik-
tionary.
– Lexical Substitution (Szarvas et al., 2013):
a supervised word sense disambiguation system
is used to substitute a wide selection of high-
frequency English nouns with generalizations,
then Resnik and ESA features are computed on the
transformed text.
</bodyText>
<subsectionHeader confidence="0.99603">
4.4 Combined representations
</subsectionHeader>
<bodyText confidence="0.9984932">
As mentioned in Sec. 3.4, we can combine ker-
nels for engineering new features. Let K be PTK
or SPTK, given two pairs of sentences pa =
(a1, a2) and pb = (b1, b2), we build the following
kernel combinations for the RTE task:
</bodyText>
<listItem confidence="0.970380454545455">
(i) K+(pa,pb) = K(a1, b1) + K(a2, b2), which
simply sums the similarities between the first
two sentences and the second two sentences
whose implication has to be derived.
(ii) An alternative kernel combines the two
similarity scores above with the product:
K×(pa, pb) = K(a1, b1) · K(a2, b2).
(iii) The symmetry of the PI task requires differ-
ent kernels. The most intuitive applies K
between all member combinations and sum
all contributions: all+K(pa,pb)=K(a1, b1) +
</listItem>
<equation confidence="0.5473326">
K(a2, b2) + K(a1, b2) + K(a2, b1).
(iv) It is also possible to combine pairs of
corresponding kernels with the product:
all× K(pa, pb) = K(a1, b1)K(a2, b2) +
K(a1, b2)K(a2, b1).
</equation>
<bodyText confidence="0.969115588235294">
(v) An alternative kernel selects only the best be-
tween the two products above: MK(pa, pb) =
max(K(a1, b1)K(a2, b2), K(a1, b2)K(a2, b1)).
This is motivated by the observation that
before measuring the similarity between
two pairs, we need to establish which
az is more similar to bj. However, the
max operator causes MK not to be a
valid kernel function, thus we substi-
tute it with a softmax function, which
is a valid kernel, i.e., SMK(pa, pb) = soft-
max(K(a1, b1)K(a2, b2), K(a1, b2)K(a2, b1)),
where softmax(x1, x2) = 1clog(ecx1 + ecx2)
(c=100 was accurate enough).
The linear kernel (LK) over the basic features
(described previously) and/or NSPDK can be of
course added to all the above kernels.
</bodyText>
<sectionHeader confidence="0.999639" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.912601">
5.1 Setup
</subsectionHeader>
<bodyText confidence="0.995368">
MSR Paraphrasing: we used the Microsoft Re-
search Paraphrase Corpus (Dolan et al., 2004) con-
sisting of 4,076 sentence pairs in the training set
and 1,725 sentence pairs in test set, with a distri-
bution of about 66% between positive and negative
</bodyText>
<page confidence="0.955612">
1008
</page>
<table confidence="0.999983727272727">
Vs Test 5 Fold Cross Validation
Kernel Acc (°lo) P R F1 Acc (°lo) P R F1
without REL tagging LK 75.88 0.784 0.881 0.829 75.54 f 0.45 0.786 f 0.009 0.876 f 0.019 0.828 f 0.004
GK 72.81 0.720 0.967 0.825 72.49 f 1.22 0.723 f 0.014 0.957 f 0.011 0.824 f 0.008
SMPTK 72.06 0.722 0.943 0.818 72.04 f 1.08 0.725 f 0.009 0.940 f 0.017 0.819 f 0.009
SMSPTKLSA 72.12 0.722 0.943 0.818 72.56 f 1.10 0.731 f 0.010 0.937 f 0.017 0.821 f 0.009
SMSP T KW 2V 71.88 0.719 0.946 0.817 72.23 f 1.07 0.727 f 0.009 0.938 f 0.017 0.820 f 0.009
all× 71.42 0.718 0.939 0.814 71.57 f 0.86 0.724 f 0.007 0.933 f 0.015 0.815 f 0.008
P T K
all× 72.29 0.725 0.941 0.819 72.06 f 0.62 0.730 f 0.007 0.928 f 0.014 0.817 f 0.006
SP T KLSA
all× 71.59 0.717 0.947 0.816 71.61 f 0.76 0.725 f 0.008 0.931 f 0.013 0.815 f 0.007
SP T KW 2V
all+ 70.78 0.716 0.930 0.809 70.76 f 0.91 0.720 f 0.008 0.924 f 0.017 0.809 f 0.009
P T K
all+ 71.48 0.720 0.934 0.813 71.42 f 0.91 0.727 f 0.008 0.920 f 0.020 0.812 f 0.009
SP T KLSA
all+ KW 2V 70.72 0.714 0.935 0.809 71.19 f 1.22 0.723 f 0.010 0.927 f 0.018 0.812 f 0.011
SP T
MP T K 72.17 0.725 0.935 0.817 72.31 f 0.67 0.731 f 0.007 0.930 f 0.015 0.819 f 0.007
MSPTKLSA 72.00 0.725 0.934 0.816 72.32 f 0.44 0.732 f 0.006 0.927 f 0.014 0.818 f 0.005
MSP T KW 2V 71.71 0.722 0.933 0.814 71.99 f 0.96 0.730 f 0.008 0.926 f 0.016 0.816 f 0.008
with REL tagging GK 75.07 0.752 0.933 0.833 74.69 f 2.52 0.749 f 0.029 0.940 f 0.008 0.834 f 0.018
SMPTK 76.17 0.765 0.927 0.838 75.42 f 0.86 0.771 f 0.007 0.903 f 0.012 0.832 f 0.008
SMSPTKLSA 76.52 0.767 0.929 0.840 75.62 f 0.90 0.772 f 0.007 0.905 f 0.013 0.833 f 0.007
SMSP T KW 2V 76.35 0.766 0.929 0.839 75.64 f 0.77 0.771 f 0.004 0.907 f 0.012 0.833 f 0.007
all× 75.36 0.767 0.905 0.830 74.76 f 0.71 0.769 f 0.006 0.892 f 0.016 0.826 f 0.008
P T K
all× 75.65 0.770 0.903 0.831 74.83 f 0.92 0.771 f 0.009 0.891 f 0.011 0.826 f 0.008
SP T KLSA
all× 75.88 0.772 0.905 0.833 75.26 f 0.81 0.771 f 0.008 0.898 f 0.011 0.830 f 0.008
SP T KW 2V
all+ 74.49 0.762 0.895 0.824 73.99 f 1.04 0.767 f 0.010 0.880 f 0.013 0.820 f 0.009
P T K
all+ 75.07 0.767 0.899 0.827 73.87 f 0.85 0.766 f 0.009 0.880 f 0.010 0.819 f 0.007
SP T KLSA
all+ KW 2V 75.42 0.772 0.894 0.829 74.16 f 0.75 0.768 f 0.008 0.882 f 0.012 0.821 f 0.007
SP T
GK+SMSP T KW 2V 76.70 0.782 0.901 0.837 76.12 f 0.96 0.787 f 0.008 0.885 f 0.015 0.833 f 0.009
LK+GK 78.67 0.802 0.902 0.849 77.85 f 1.00 0.804 f 0.008 0.886 f 0.015 0.843 f 0.009
LK+SMSP T KW 2V 77.74 0.794 0.899 0.843 77.52 f 1.41 0.802 f 0.011 0.885 f 0.016 0.841 f 0.011
LK+GK+SMSP T KW 2V 79.13 0.807 0.901 0.852 78.11 f 0.94 0.811 f 0.005 0.879 f 0.016 0.844 f 0.009
(Socher et al., 2011) 76.8 − − 0.836 − − − −
(Madnani et al., 2012) 77.4 − − 0.841 − − − −
</table>
<tableCaption confidence="0.999954">
Table 1: Results on Paraphrasing Identification
</tableCaption>
<bodyText confidence="0.9985718">
examples. These pairs were extracted from top-
ically similar Web news articles, applying some
heuristics that select potential paraphrases to be
annotated by human experts.
RTE-3. We adopted the RTE-3 dataset (Giampic-
colo et al., 2007), which is composed by 800 text-
hypothesis pairs in both the training and test sets,
collected by human annotators. The distribution
of the examples among the positive and negative
classes is balanced.
</bodyText>
<subsubsectionHeader confidence="0.69791">
5.1.1 Models and Parameterization
</subsubsectionHeader>
<bodyText confidence="0.999891142857143">
We train our classifiers with the C-SVM learning
algorithm (Chang and Lin, 2011) within KeLP3, a
Kernel-based Machine Learning platform that im-
plements tree kernels. In both tasks, we applied
the kernels described in Sec. 4, where the trees are
generated with the Stanford parser4.
SPTK uses a node similarity function
Q(n1, n2) implemented as follows: if n1 and n2
are two identical syntactic nodes Q = 1. If n1
and n2 are two lexical nodes with the same POS
tag, their similarity is evaluated computing the
cosine similarity of their corresponding vectors in
a wordspace. In all the other cases Q = 0. We
generated two different wordspaces. The first is
</bodyText>
<footnote confidence="0.9967425">
3https://github.com/SAG-KeLP
4http://nlp.stanford.edu/software/corenlp.shtml
</footnote>
<bodyText confidence="0.999691181818182">
a co-occurrence LSA embedding as described in
(Croce and Previtali, 2010). The second space is
derived by applying a skip-gram model (Mikolov
et al., 2013) with the word2vec tool5. SPTK
using the LSA will be referred to as SPTKLSA,
while when adopting word2vec it will be indicated
with SPTKW2V. We used default parameters
both for PTK and SPTK whereas we selected
h and D parameters of NSPDK that obtained
the best average accuracy using a 5-fold cross
validation on the training set.
</bodyText>
<subsubsectionHeader confidence="0.911246">
5.1.2 Performance measures
</subsubsectionHeader>
<bodyText confidence="0.999893333333333">
The two considered tasks are binary classification
problems thus we used Accuracy, Precision, Re-
call and F1. The adopted corpora have a prede-
fined split between training and test sets thus we
tested our models according to such settings for
exactly comparing with previous work. Addition-
ally, to better assess our results, we performed a 5-
fold cross validation on the complete datasets. In
case of PI, the same sentence can appear in mul-
tiple pairs thus we distributed the pairs such that
the same sentence can only appear in one fold at a
time.
</bodyText>
<footnote confidence="0.982015">
5https://code.google.com/p/word2vec/
</footnote>
<page confidence="0.93336">
1009
</page>
<table confidence="0.999986647058824">
Vs Test 5 Fold Cross Validation
Kernel Acc (°lo) P R F1 Acc (°lo) P R F1
without REL tagging LK 62 0.608 0.729 0.663 62.94 f 5.68 0.635 f 0.057 0.679 f 0.083 0.652 f 0.049
GK 55.375 0.555 0.651 0.599 55.63 f 1.81 0.564 f 0.022 0.612 f 0.087 0.584 f 0.032
PTK+ 56.13 0.560 0.676 0.612 54.13 f 3.26 0.547 f 0.024 0.637 f 0.051 0.587 f 0.027
SPTK+ 56.88 0.566 0.683 0.619 53.63 f 2.50 0.543 f 0.024 0.622 f 0.060 0.578 f 0.027
LSA
SPTK+ 56.63 0.563 0.683 0.617 54.06 f 2.34 0.546 f 0.022 0.634 f 0.060 0.585 f 0.026
W 2V
PTK× 55.88 0.558 0.671 0.609 52.81 f 1.99 0.535 f 0.025 0.623 f 0.055 0.574 f 0.028
SPTK× 56.25 0.561 0.671 0.611 53.56 f 2.09 0.543 f 0.022 0.616 f 0.065 0.576 f 0.026
LSA
SPTK× 55.25 0.554 0.646 0.597 52.50 f 1.77 0.533 f 0.027 0.619 f 0.071 0.571 f 0.034
W 2V
with REL tagging GK 61.63 0.603 0.734 0.662 59.81 f 3.84 0.599 f 0.037 0.678 f 0.071 0.634 f 0.026
PTK+ 66.00 0.627 0.829 0.714 67.75 f 7.17 0.655 f 0.067 0.817 f 0.038 0.725 f 0.046
SPTK+ 65.38 0.622 0.824 0.709 67.81 f 7.30 0.656 f 0.069 0.816 f 0.036 0.725 f 0.047
LSA
SPTK+ 66.38 0.629 0.837 0.718 68.00 f 7.15 0.658 f 0.068 0.816 f 0.039 0.726 f 0.046
W 2V
PTK× 66.13 0.629 0.827 0.714 67.75 f 7.37 0.658 f 0.071 0.804 f 0.038 0.722 f 0.049
SPTK× 66.00 0.629 0.822 0.712 68.00 f 7.62 0.661 f 0.074 0.808 f 0.039 0.725 f 0.049
LSA
SPTK× 67.00 0.636 0.834 0.722 67.69 f 6.95 0.658 f 0.069 0.804 f 0.040 0.722 f 0.043
W 2V
GK+SPTK× 66.38 0.634 0.815 0.713 66.00 f 6.79 0.648 f 0.069 0.769 f 0.034 0.701 f 0.044
W 2V
LK+GK 62.25 0.609 0.737 0.667 62.06 f 5.49 0.620 f 0.051 0.702 f 0.053 0.656 f 0.036
LK+SPTK× 66.13 0.628 0.829 0.715 68.25 f 7.54 0.663 f 0.076 0.816 f 0.032 0.728 f 0.047
W 2V
LK+GK+SPTK× 66.00 0.633 0.800 0.707 66.31 f 7.35 0.652 f 0.075 0.770 f 0.053 0.703 f 0.052
W 2V
(Zanzotto et al., 2009) 66.75 0.667 − − − − − −
(Iftene and Balahur-Dobrescu, 2007) 69.13 − − − − − − −
</table>
<tableCaption confidence="0.99975">
Table 2: Results on Textual Entailment Recognition
</tableCaption>
<subsectionHeader confidence="0.980893">
5.2 Results on PI
</subsectionHeader>
<bodyText confidence="0.999602404761905">
The results are reported in Table 1. The first col-
umn shows the use of the relational tag REL in
the structures (discussed in Sec. 4.1). The second
column indicates the kernel models described in
sections 3 and 4 as well as the combination of the
best models. Columns 3-6 report Accuracy, Pre-
cision, Recall and F1 derived on the fixed test set,
whereas the remaining columns regard the results
obtained with cross validation. We note that:
First, when REL information is not used in the
structures, the linear kernel (LK) on basic fea-
tures outperforms all the structural kernels, which
all perform similarly. The best structural kernel is
the graph kernel, NSPDK (GK in short). This
is not surprising as without REL, GK is the only
kernel that can express relational features.
Second, SPTK is only slightly better than
PTK. The reason is mainly due to the ap-
proach used for building the dataset: potential
paraphrases are retrieved applying some heuristics
mostly based on the lexical overlap between sen-
tences. Thus, in most cases, the lexical similarity
used in SPTK is not needed as hard matches oc-
cur between the words of the sentences.
Third, when REL is used on the structures, all
kernels reach or outperform the F1 (official mea-
sure of the challenge) of LK. The relational struc-
tures seem to drastically reduce the inconsistent
matching between positive and negative examples,
reflecting in remarkable increasing in Precision. In
particular, SMSPTKLSA achieves the state of the
art6, i.e., 84.1 (Madnani et al., 2012).
Next, combining our best models produces a
significant improvement of the state of the art, e.g.,
LK +GK +SMSPTKW2V outperforms the result
in (Madnani et al., 2012) by 1.7% in accuracy and
1.1 points in F1.
Finally, the cross-validation experiments con-
firm the system behavior observed on the fixed
test set. The Std. Dev. (specified after the ± sign)
shows that in most cases the system differences are
significant.
</bodyText>
<subsectionHeader confidence="0.982699">
5.3 Results on RTE
</subsectionHeader>
<bodyText confidence="0.893596333333333">
We used the same experimental settings performed
for PI to carry out the experiments on RTE. The
results are shown in Table 2 structured in the same
way as the previous table. We note that:
(i) Findings similar to PI are obtained.
(ii) Again the relational structures (using REL)
provide a remarkable improvement in Ac-
curacy (RTE challenge measure), allowing
tree kernels to compete with the state of the
art. This is an impressive result consider-
ing that our models do not use any exter-
nal resource, e.g., as in (Iftene and Balahur-
Dobrescu, 2007).
(iii) This time, SPT K× W improves on PTK by
1 absolute percent point.
</bodyText>
<footnote confidence="0.9672925">
6The performance of the several best systems improved
by our models are nicely summarized at http://aclweb.
org/aclwiki/index.php?title=Paraphrase_
Identification_(State_of_the_art)
</footnote>
<page confidence="0.992243">
1010
</page>
<bodyText confidence="0.999716">
(iv) The kernel combinations are not more effec-
tive than SPTK alone.
Finally, the cross-fold validation experiments con-
firm the fixed-test set results.
</bodyText>
<sectionHeader confidence="0.997367" genericHeader="discussions">
6 Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.998763">
In this paper, we have engineered and studied
several models for relation learning. We utilized
state-of-the-art kernels for structures and created
new ones by combining kernels together. Addi-
tionally, we provide a novel definition of effective
and computationally feasible structural kernels.
Most importantly, we have designed novel com-
putational structures for trees and graphs, which
are for the first time tested in NLP tasks. Our ker-
nels are computationally efficient thus solving one
of the most important problems of previous work.
We empirically tested our kernels on two of the
most representative tasks of RL from text, namely,
PI and RTE. The extensive experimentation us-
ing many kernel models also combined with tradi-
tional feature vector approaches sheds some light
on how engineering effective graph and tree ker-
nels for learning from pairs of entire text frag-
ments. In particular, our best models significantly
outperform the state of the art in PI and the best
kernel model for RTE 3, with Accuracy close to
the one of the best system of RTE 3.
It should be stressed that the design of previous
state-of-the-art models involved the use of several
resources, annotation and heavy manually engi-
neering of specific rules and features: this makes
the portability of such systems on other domains
and tasks extremely difficult. Moreover the un-
availability of the used resources and the opacity
of the used rules have also made such systems very
difficult to replicate.
On the contrary, the models we propose enable
researchers to:
</bodyText>
<listItem confidence="0.837724">
(i) build their system without the use of spe-
cific resources. We use a standard syntactic
parser, and for some models we use well-
known and available corpora for automati-
cally learning similarities with word embed-
ding algorithms; and
</listItem>
<bodyText confidence="0.983848351351351">
(ii) reuse our work for different (similar) tasks
(see paraphrasing) and data.
The simplicity and portability of our system is a
significant contribution to a very complex research
area such as RL from two entire pieces of text.
Our study has indeed shown that our kernel
models, which are very simple to be implemented,
reach the state of the art and can be used with large
datasets.
Furthermore, it should be noted that our mod-
els outperform the best tree kernel approach of the
RTE challenges (Zanzotto and Moschitti, 2006)
and also its extension that we proposed in (Zan-
zotto et al., 2009). These systems are also adapt-
able and easy to replicate, but they are subject to
an exponential computational complexity and can
thus only be used on very small datasets (e.g., they
cannot be applied to the MSR Paraphrase corpus).
In contrast, the model we proposed in this paper
can be used on large datasets, because its kernel
complexity is about linear (on average).
We believe that disseminating these findings
to the research community is very important, as
it will foster research on RL, e.g., on RTE, us-
ing structural kernel methods. Such research has
had a sudden stop as the RTE data in the latest
challenges increased from 800 instances to sev-
eral thousands and no tree kernel model has been
enough accurate to replace our computational ex-
pensive models (Zanzotto et al., 2009).
In the future, it would be interesting defining
graph kernels that can combine more than two sub-
structures. Another possible extension regards the
use of node similarity in graph kernels. Addition-
ally, we would like to test our models on other
RTE challenges and on several QA datasets, which
for space constraints we could not do in this work.
</bodyText>
<sectionHeader confidence="0.998631" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999371166666667">
This research is part of the Interactive sYstems
for Answer Search (IYAS) project, conducted by
the Arabic Language Technologies (ALT) group
at Qatar Computing Research Institute (QCRI)
within the Hamad Bin Khalifa University and
Qatar Foundation.
</bodyText>
<sectionHeader confidence="0.998914" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.979079888888889">
Daniel B¨ar, Chris Biemann, Iryna Gurevych, and
Torsten Zesch. 2012. Ukp: Computing seman-
tic textual similarity by combining multiple content
similarity measures. In Proc. of SemEval ’12. ACL.
Karsten M Borgwardt and Hans-Peter Kriegel. 2005.
Shortest-Path Kernels on Graphs. ICDM, 0:74–81.
Xavier Carreras and Llu´ıs M`arquez. 2005. Introduc-
tion to the conll-2005 shared task: Semantic role la-
beling. In Proc. of CONLL ’05, USA.
</reference>
<page confidence="0.920687">
1011
</page>
<reference confidence="0.998003339622642">
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology,
2:27:1–27:27.
Elisa Cilia and Alessandro Moschitti. 2007. Ad-
vanced tree-based kernels for protein classification.
In AI*IA 2007: Artificial Intelligence and Human-
Oriented Computing, 10th Congress of the Italian
Association for Artificial Intelligence, Rome, Italy,
September 10-13, 2007, Proceedings, pages 218–
229.
Fabrizio Costa and Kurt De Grave. 2010. Fast
neighborhood subgraph pairwise distance kernel. In
ICML, number v.
Danilo Croce and Daniele Previtali. 2010. Mani-
fold learning for the semi-supervised induction of
framenet predicates: An empirical investigation.
Danilo Croce, Alessandro Moschitti, and Roberto
Basili. 2011. Structured lexical similarity via con-
volution kernels on dependency trees. In Proceed-
ings EMNLP.
Giovanni Da San Martino, Nicol`o Navarin, and
Alessandro Sperduti. 2012. A tree-based kernel for
graphs. In Proceedings of the Twelfth SIAM Interna-
tional Conference on Data Mining, Anaheim, Cal-
ifornia, USA, April 26-28, 2012., pages 975–986.
SIAM / Omnipress.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004.
Unsupervised construction of large paraphrase cor-
pora: Exploiting massively parallel news sources. In
Proc. of COLING ’04, Stroudsburg, PA, USA.
David Ferrucci, Eric Brown, Jennifer Chu-Carroll,
James Fan, David Gondek, Aditya A Kalyanpur,
Adam Lally, J William Murdock, Eric Nyberg, John
Prager, et al. 2010. Building watson: An overview
of the deepqa project. AI magazine, 31(3):59–79.
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing semantic relatedness using wikipedia-
based explicit semantic analysis. In Proc. of IJCAI-
07, pages 1606–1611.
Thomas Gartner, P Flach, and S Wrobel. 2003. On
Graph Kernels : Hardness Results and Efficient Al-
ternatives. LNCS, pages 129–143.
Danilo Giampiccolo, Bernardo Magnini, Ido Dagan,
and Bill Dolan. 2007. The third pascal recognizing
textual entailment challenge. In Proc. of the ACL-
PASCAL RTE ’07 Workshop, pages 1–9. ACL.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic
labeling of semantic roles. Computational Linguis-
tics, 28:245–288.
Alessandra Giordani and Alessandro Moschitti. 2012.
Translating questions to sql queries with genera-
tive parsers discriminatively reranked. In COLING
(Posters), pages 401–410.
Francisco Guzm´an, Shafiq Joty, Llu´ıs M`arquez,
Alessandro Moschitti, Preslav Nakov, and Massimo
Nicosia. 2014. Learning to differentiate better from
worse translations. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP), pages 214–220, Doha, Qatar,
October. Association for Computational Linguistics.
M Heinonen, N V¨alim¨aki, V M¨akinen, and J Rousu.
2012. Efficient Path Kernels for Reaction Function
Prediction. Bioinformatics Models, Methods andAl-
gorithms.
Adrian Iftene and Alexandra Balahur-Dobrescu. 2007.
Hypothesis transformation and semantic variability
rules used in recognizing textual entailment. In RTE
Workshop, Prague.
Hisashi Kashima, Koji Tsuda, and Akihiro Inokuchi.
2003. Marginalized kernels between labeled graphs.
In ICML, pages 321–328. AAAI Press.
Nitin Madnani, Joel Tetreault, and Martin Chodorow.
2012. Re-examining machine translation metrics for
paraphrase identification. In Proceedings of NAACL
HLT ’12. ACL.
Pierre Mah´e and Jean-Philippe Vert. 2008. Graph ker-
nels based on tree patterns for molecules. Machine
Learning, 75(1):3–35, October.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
frey Dean. 2013. Efficient estimation of word
representations in vector space. arXiv preprint
arXiv:1301.3781.
Mike Mintz, Steven Bills, Rion Snow, and Daniel Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In ACL-AFNLP.
Alessandro Moschitti. 2006. Efficient convolution ker-
nels for dependency and constituent syntactic trees.
In Proc. of ECML’06, pages 318–329.
Alessandro Moschitti. 2008. Kernel methods, syn-
tax and semantics for relational text categorization.
In Proceedings of the 17th ACM Conference on In-
formation and Knowledge Management, CIKM ’08,
pages 253–262, New York, NY, USA. ACM.
Vivi Nastase, Preslav Nakov, Diarmuid Saghdha, and
Stan Szpakowicz. 2013. Semantic Relations Be-
tween Nominals. Morgan &amp; Claypool Publishers.
Aliaksei Severyn and Alessandro Moschitti. 2012.
Structural relationships for large-scale learning of
answer re-ranking. In SIGIR.
Aliaksei Severyn and Alessandro Moschitti. 2013. Au-
tomatic feature engineering for answer selection and
extraction. In EMNLP, pages 458–467.
Aliaksei Severyn, Massimo Nicosia, and Alessandro
Moschitti. 2013a. Building structures from clas-
sifiers for passage reranking. In Proceedings of
</reference>
<page confidence="0.848901">
1012
</page>
<reference confidence="0.999816795454545">
the 22Nd ACM International Conference on Con-
ference on Information &amp; Knowledge Manage-
ment, CIKM ’13, pages 969–978, New York, NY,
USA. ACM.
Aliaksei Severyn, Massimo Nicosia, and Alessandro
Moschitti. 2013b. Learning adaptable patterns
for passage reranking. Proceedings of the Seven-
teenth Conference on Computational Natural Lan-
guage Learning, pages 75–83.
John Shawe-Taylor and Nello Cristianini. 2004. Ker-
nel Methods for Pattern Analysis. Cambridge Uni-
versity Press, USA.
Nino Shervashidze, Pascal Schweitzer, Erik Jan van
Leeuwen, Kurt Mehlhorn, and Karsten M Borg-
wardt. 2011. Weisfeiler-Lehman Graph Kernels.
JMLR, 12:2539–2561.
Richard Socher, Eric H. Huang, Jeffrey Pennin,
Christopher D Manning, and Andrew Y. Ng. 2011.
Dynamic pooling and unfolding recursive autoen-
coders for paraphrase detection. In NIPS 24.
Gy¨orgy Szarvas, Chris Biemann, and Iryna Gurevych.
2013. Supervised all-words lexical substitution us-
ing delexicalized features. In NAACL.
Kateryna Tymoshenko, Alessandro Moschitti, and Ali-
aksei Severyn. 2014. Encoding semantic resources
in syntactic structures for passage reranking. EACL
2014, page 664.
S. V. N. Vishwanathan, Karsten M Borgwardt, and
Nicol N Schraudolph. 2006. Fast Computation of
Graph Kernels. In NIPS.
E. Voorhees and D. Tice, 1999. The TREC-8 Question
Answering Track Evaluation.
Fabio Massimo Zanzotto and Alessandro Moschitti.
2006. Automatic learning of textual entailments
with cross-pair similarities. In Proceedings of the
21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 401–408,
Sydney, Australia, July. Association for Computa-
tional Linguistics.
Fabio massimo Zanzotto, Marco Pennacchiotti, and
Alessandro Moschitti. 2009. A machine learn-
ing approach to textual entailment recognition. Nat.
Lang. Eng., 15(4):551–582, October.
</reference>
<page confidence="0.979008">
1013
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.154917">
<title confidence="0.998493">Structural Representations for Learning Relations between Pairs of Texts</title>
<author confidence="0.6954505">Filice Da San Martino ALT</author>
<author confidence="0.6954505">Qatar Computing Research Institute</author>
<author confidence="0.6954505">Hamad Bin Khalifa</author>
<abstract confidence="0.989398409090909">This paper studies the use of structural representations for learning relations between pairs of short texts (e.g., sentences or paragraphs) of the kind: the second text answers to, or conveys exactly the same information of, or is implied by, the first text. Engineering effective features that can capture syntactic and semantic relations between the constituents composing the target text pairs is rather complex. Thus, we define syntactic and semantic structures representing the text pairs and then apply graph and tree kernels to them for automatically engineering features in Support Vector Machines. We carry out an extensive comparative analysis of stateof-the-art models for this type of relational learning. Our findings allow for achieving the highest accuracy in two different and important related tasks, i.e., Paraphrasing Identification and Textual Entail-</abstract>
<intro confidence="0.537927">ment Recognition.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel B¨ar</author>
<author>Chris Biemann</author>
<author>Iryna Gurevych</author>
<author>Torsten Zesch</author>
</authors>
<title>Ukp: Computing semantic textual similarity by combining multiple content similarity measures.</title>
<date>2012</date>
<booktitle>In Proc. of SemEval ’12.</booktitle>
<publisher>ACL.</publisher>
<marker>B¨ar, Biemann, Gurevych, Zesch, 2012</marker>
<rawString>Daniel B¨ar, Chris Biemann, Iryna Gurevych, and Torsten Zesch. 2012. Ukp: Computing semantic textual similarity by combining multiple content similarity measures. In Proc. of SemEval ’12. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karsten M Borgwardt</author>
<author>Hans-Peter Kriegel</author>
</authors>
<date>2005</date>
<booktitle>Shortest-Path Kernels on Graphs. ICDM,</booktitle>
<pages>0--74</pages>
<contexts>
<context position="5443" citStr="Borgwardt and Kriegel, 2005" startWordPosition="830" endWordPosition="833">d PI. Finally, our study suggests research directions for designing effective graph kernels for RL. 2 Related Work In this paper, we apply kernel methods, which enable an efficient comparison of structures in huge, possibly infinite, feature spaces. While for trees, a comparison using all possible subtrees is possible, designing kernel functions for graphs with such property is an NP-Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detectio</context>
</contexts>
<marker>Borgwardt, Kriegel, 2005</marker>
<rawString>Karsten M Borgwardt and Hans-Peter Kriegel. 2005. Shortest-Path Kernels on Graphs. ICDM, 0:74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Llu´ıs M`arquez</author>
</authors>
<title>Introduction to the conll-2005 shared task: Semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proc. of CONLL ’05,</booktitle>
<location>USA.</location>
<marker>Carreras, M`arquez, 2005</marker>
<rawString>Xavier Carreras and Llu´ıs M`arquez. 2005. Introduction to the conll-2005 shared task: Semantic role labeling. In Proc. of CONLL ’05, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<contexts>
<context position="27396" citStr="Chang and Lin, 2011" startWordPosition="4653" endWordPosition="4656">77.4 − − 0.841 − − − − Table 1: Results on Paraphrasing Identification examples. These pairs were extracted from topically similar Web news articles, applying some heuristics that select potential paraphrases to be annotated by human experts. RTE-3. We adopted the RTE-3 dataset (Giampiccolo et al., 2007), which is composed by 800 texthypothesis pairs in both the training and test sets, collected by human annotators. The distribution of the examples among the positive and negative classes is balanced. 5.1.1 Models and Parameterization We train our classifiers with the C-SVM learning algorithm (Chang and Lin, 2011) within KeLP3, a Kernel-based Machine Learning platform that implements tree kernels. In both tasks, we applied the kernels described in Sec. 4, where the trees are generated with the Stanford parser4. SPTK uses a node similarity function Q(n1, n2) implemented as follows: if n1 and n2 are two identical syntactic nodes Q = 1. If n1 and n2 are two lexical nodes with the same POS tag, their similarity is evaluated computing the cosine similarity of their corresponding vectors in a wordspace. In all the other cases Q = 0. We generated two different wordspaces. The first is 3https://github.com/SAG-</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisa Cilia</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Advanced tree-based kernels for protein classification.</title>
<date>2007</date>
<booktitle>In AI*IA 2007: Artificial Intelligence and HumanOriented Computing, 10th Congress of the Italian Association for Artificial Intelligence,</booktitle>
<pages>218--229</pages>
<location>Rome, Italy,</location>
<contexts>
<context position="5571" citStr="Cilia and Moschitti, 2007" startWordPosition="850" endWordPosition="853">we apply kernel methods, which enable an efficient comparison of structures in huge, possibly infinite, feature spaces. While for trees, a comparison using all possible subtrees is possible, designing kernel functions for graphs with such property is an NP-Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) apply a recursive auto encoder with dynamic pooling</context>
</contexts>
<marker>Cilia, Moschitti, 2007</marker>
<rawString>Elisa Cilia and Alessandro Moschitti. 2007. Advanced tree-based kernels for protein classification. In AI*IA 2007: Artificial Intelligence and HumanOriented Computing, 10th Congress of the Italian Association for Artificial Intelligence, Rome, Italy, September 10-13, 2007, Proceedings, pages 218– 229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Costa</author>
<author>Kurt De Grave</author>
</authors>
<title>Fast neighborhood subgraph pairwise distance kernel.</title>
<date>2010</date>
<booktitle>In ICML, number v.</booktitle>
<marker>Costa, De Grave, 2010</marker>
<rawString>Fabrizio Costa and Kurt De Grave. 2010. Fast neighborhood subgraph pairwise distance kernel. In ICML, number v.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Daniele Previtali</author>
</authors>
<title>Manifold learning for the semi-supervised induction of framenet predicates: An empirical investigation.</title>
<date>2010</date>
<contexts>
<context position="28122" citStr="Croce and Previtali, 2010" startWordPosition="4765" endWordPosition="4768"> we applied the kernels described in Sec. 4, where the trees are generated with the Stanford parser4. SPTK uses a node similarity function Q(n1, n2) implemented as follows: if n1 and n2 are two identical syntactic nodes Q = 1. If n1 and n2 are two lexical nodes with the same POS tag, their similarity is evaluated computing the cosine similarity of their corresponding vectors in a wordspace. In all the other cases Q = 0. We generated two different wordspaces. The first is 3https://github.com/SAG-KeLP 4http://nlp.stanford.edu/software/corenlp.shtml a co-occurrence LSA embedding as described in (Croce and Previtali, 2010). The second space is derived by applying a skip-gram model (Mikolov et al., 2013) with the word2vec tool5. SPTK using the LSA will be referred to as SPTKLSA, while when adopting word2vec it will be indicated with SPTKW2V. We used default parameters both for PTK and SPTK whereas we selected h and D parameters of NSPDK that obtained the best average accuracy using a 5-fold cross validation on the training set. 5.1.2 Performance measures The two considered tasks are binary classification problems thus we used Accuracy, Precision, Recall and F1. The adopted corpora have a predefined split between</context>
</contexts>
<marker>Croce, Previtali, 2010</marker>
<rawString>Danilo Croce and Daniele Previtali. 2010. Manifold learning for the semi-supervised induction of framenet predicates: An empirical investigation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Croce</author>
<author>Alessandro Moschitti</author>
<author>Roberto Basili</author>
</authors>
<title>Structured lexical similarity via convolution kernels on dependency trees.</title>
<date>2011</date>
<booktitle>In Proceedings EMNLP.</booktitle>
<contexts>
<context position="10050" citStr="Croce et al., 2011" startWordPosition="1623" endWordPosition="1626">2jNS1jjNS2j) (Moschitti, 2006), where p is the largest subsequence of children that we want to consider and ρ is the maximal outdegree observed in the two trees. However the average running time tends to be linear for natural language syntactic trees (Moschitti, 2006). 3.2 Smoothed Partial Tree Kernel (SPTK) Constraining the application of lexical similarity to words embedded in similar structures provides clear advantages over all-vs-all words similarity, which tends to semantically diverge. Indeed, syntax provides the necessary restrictions to compute an effective semantic similarity. SPTK (Croce et al., 2011) generalizes PTK by enabling node similarity during substructure matching. More formally, SPTK is computed by Eq. 2 using the following ΔSPTK(n1, n2) = P|�| i,j=1 χi(n1)χj(n2)Σ(si, sj), where Σ is a similarity between structures1. The recursive definition of ΔSPTK is the following: 1. if n1 and n2 are leaves ΔSPTK(n1, n2) = µλσ(n1, n2); / 2. else ΔSPTK(n1, n2) = µσ(n1, n2) ~ I λ2+ where σ is any similarity between nodes, e.g., between their lexical labels, and the other variables are the same of PTK. The worst case complexity of SPTK is identical to PTK and in practice is not higher than O(jNS</context>
</contexts>
<marker>Croce, Moschitti, Basili, 2011</marker>
<rawString>Danilo Croce, Alessandro Moschitti, and Roberto Basili. 2011. Structured lexical similarity via convolution kernels on dependency trees. In Proceedings EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giovanni Da San Martino</author>
<author>Nicol`o Navarin</author>
<author>Alessandro Sperduti</author>
</authors>
<title>A tree-based kernel for graphs.</title>
<date>2012</date>
<journal>SIAM / Omnipress.</journal>
<booktitle>In Proceedings of the Twelfth SIAM International Conference on Data Mining,</booktitle>
<pages>975--986</pages>
<location>Anaheim, California, USA,</location>
<contexts>
<context position="5650" citStr="Martino et al., 2012" startWordPosition="864" endWordPosition="867">, possibly infinite, feature spaces. While for trees, a comparison using all possible subtrees is possible, designing kernel functions for graphs with such property is an NP-Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) apply a recursive auto encoder with dynamic pooling, and (Madnani et al., 2012) use eight machine translation metrics to achieve t</context>
</contexts>
<marker>Martino, Navarin, Sperduti, 2012</marker>
<rawString>Giovanni Da San Martino, Nicol`o Navarin, and Alessandro Sperduti. 2012. A tree-based kernel for graphs. In Proceedings of the Twelfth SIAM International Conference on Data Mining, Anaheim, California, USA, April 26-28, 2012., pages 975–986. SIAM / Omnipress.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proc. of COLING ’04,</booktitle>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2063" citStr="Dolan et al., 2004" startWordPosition="299" endWordPosition="302">l., 2013), predicate relations, e.g., Semantic Role Labeling (Carreras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the semantics of larger pieces of text, e.g., sentences or paragraphs. This line of research relates to three broad fields, namely, Question Answering (QA) (Voorhees and Tice, 1999), Paraphrasing Identification (PI) (Dolan et al., 2004) and Recognition of Textual Entailments (RTE) (Giampiccolo et al., 2007). More generally, RL from text can be denied as follows: given two text fragments, the main goal is to derive relations between them, e.g., either if the second fragment answers the question, or conveys exactly the same information or is implied by the first text fragment. For example, the following two sentences: - License revenue slid 21 percent, however, to $107.6 million. - License sales, a key measure of demand, fell 21 percent to $107.6 million. express exactly the same meaning, whereas the next one: - She was transf</context>
<context position="5822" citStr="Dolan et al., 2004" startWordPosition="895" endWordPosition="898">Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) apply a recursive auto encoder with dynamic pooling, and (Madnani et al., 2012) use eight machine translation metrics to achieve the state of the art. To our knowledge no previous model based on kernel methods has been applied before: with such methods, we outperform the state of the art in PI. A desc</context>
<context position="23904" citStr="Dolan et al., 2004" startWordPosition="3950" endWordPosition="3953">ring the similarity between two pairs, we need to establish which az is more similar to bj. However, the max operator causes MK not to be a valid kernel function, thus we substitute it with a softmax function, which is a valid kernel, i.e., SMK(pa, pb) = softmax(K(a1, b1)K(a2, b2), K(a1, b2)K(a2, b1)), where softmax(x1, x2) = 1clog(ecx1 + ecx2) (c=100 was accurate enough). The linear kernel (LK) over the basic features (described previously) and/or NSPDK can be of course added to all the above kernels. 5 Experiments 5.1 Setup MSR Paraphrasing: we used the Microsoft Research Paraphrase Corpus (Dolan et al., 2004) consisting of 4,076 sentence pairs in the training set and 1,725 sentence pairs in test set, with a distribution of about 66% between positive and negative 1008 Vs Test 5 Fold Cross Validation Kernel Acc (°lo) P R F1 Acc (°lo) P R F1 without REL tagging LK 75.88 0.784 0.881 0.829 75.54 f 0.45 0.786 f 0.009 0.876 f 0.019 0.828 f 0.004 GK 72.81 0.720 0.967 0.825 72.49 f 1.22 0.723 f 0.014 0.957 f 0.011 0.824 f 0.008 SMPTK 72.06 0.722 0.943 0.818 72.04 f 1.08 0.725 f 0.009 0.940 f 0.017 0.819 f 0.009 SMSPTKLSA 72.12 0.722 0.943 0.818 72.56 f 1.10 0.731 f 0.010 0.937 f 0.017 0.821 f 0.009 SMSP T </context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proc. of COLING ’04, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Ferrucci</author>
<author>Eric Brown</author>
<author>Jennifer Chu-Carroll</author>
<author>James Fan</author>
<author>David Gondek</author>
<author>Aditya A Kalyanpur</author>
<author>Adam Lally</author>
<author>J William Murdock</author>
<author>Eric Nyberg</author>
<author>John Prager</author>
</authors>
<title>Building watson: An overview of the deepqa project.</title>
<date>2010</date>
<journal>AI magazine,</journal>
<volume>31</volume>
<issue>3</issue>
<contexts>
<context position="1232" citStr="Ferrucci et al., 2010" startWordPosition="176" endWordPosition="179">e constituents composing the target text pairs is rather complex. Thus, we define syntactic and semantic structures representing the text pairs and then apply graph and tree kernels to them for automatically engineering features in Support Vector Machines. We carry out an extensive comparative analysis of stateof-the-art models for this type of relational learning. Our findings allow for achieving the highest accuracy in two different and important related tasks, i.e., Paraphrasing Identification and Textual Entailment Recognition. 1 Introduction Advanced NLP systems, e.g., IBM Watson system (Ferrucci et al., 2010), are the result of effective use of syntactic/semantic information along with relational learning (RL) methods. This research area is rather vast including, extraction of syntactic relations, e.g., (Nastase et al., 2013), predicate relations, e.g., Semantic Role Labeling (Carreras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the s</context>
</contexts>
<marker>Ferrucci, Brown, Chu-Carroll, Fan, Gondek, Kalyanpur, Lally, Murdock, Nyberg, Prager, 2010</marker>
<rawString>David Ferrucci, Eric Brown, Jennifer Chu-Carroll, James Fan, David Gondek, Aditya A Kalyanpur, Adam Lally, J William Murdock, Eric Nyberg, John Prager, et al. 2010. Building watson: An overview of the deepqa project. AI magazine, 31(3):59–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipediabased explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In Proc. of IJCAI07,</booktitle>
<pages>1606--1611</pages>
<contexts>
<context position="21839" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="3602" endWordPosition="3605">s, which use PTK or SPTK applied to the sentences within the pair. We also used similarity features from the DKPro of the UKP Lab (B¨ar et al., 2012), tested in the Semantic Textual Similarity (STS) task: – Longest common substring measure and Longest common subsequence measure, which determine the length of the longest substring shared by two text segments. – Running-Karp-Rabin Greedy String Tiling provides a similarity between two sentences by counting the number of shuffles in their subparts. – Resnik similarity based on the WordNet hierarchy. – Explicit Semantic Analysis (ESA) similarity (Gabrilovich and Markovitch, 2007) represents documents as weighted vectors of concepts learned from Wikipedia, WordNet and Wiktionary. – Lexical Substitution (Szarvas et al., 2013): a supervised word sense disambiguation system is used to substitute a wide selection of highfrequency English nouns with generalizations, then Resnik and ESA features are computed on the transformed text. 4.4 Combined representations As mentioned in Sec. 3.4, we can combine kernels for engineering new features. Let K be PTK or SPTK, given two pairs of sentences pa = (a1, a2) and pb = (b1, b2), we build the following kernel combinations for the RTE</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using wikipediabased explicit semantic analysis. In Proc. of IJCAI07, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Gartner</author>
<author>P Flach</author>
<author>S Wrobel</author>
</authors>
<title>On Graph Kernels : Hardness Results and Efficient Alternatives. LNCS,</title>
<date>2003</date>
<pages>129--143</pages>
<contexts>
<context position="5308" citStr="Gartner et al., 2003" startWordPosition="809" endWordPosition="812">ficient solutions, which solve the previous scalability problem and, at the same time, exceed the state of the art on both RTE and PI. Finally, our study suggests research directions for designing effective graph kernels for RL. 2 Related Work In this paper, we apply kernel methods, which enable an efficient comparison of structures in huge, possibly infinite, feature spaces. While for trees, a comparison using all possible subtrees is possible, designing kernel functions for graphs with such property is an NP-Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves t</context>
<context position="10857" citStr="Gartner et al., 2003" startWordPosition="1759" endWordPosition="1762">where Σ is a similarity between structures1. The recursive definition of ΔSPTK is the following: 1. if n1 and n2 are leaves ΔSPTK(n1, n2) = µλσ(n1, n2); / 2. else ΔSPTK(n1, n2) = µσ(n1, n2) ~ I λ2+ where σ is any similarity between nodes, e.g., between their lexical labels, and the other variables are the same of PTK. The worst case complexity of SPTK is identical to PTK and in practice is not higher than O(jNS1jjNS2j). 3.3 Neighborhood Subgraph Pairwise Distance Kernel (NSPDK) When general subgraphs are used as features in a kernel computation, eq. 1 and 2 become computationally intractable (Gartner et al., 2003). To solve this problem, we need to restrict the set of considered substructures S. (Costa and De Grave, 2010) defined NSPDK such that the feature space is only constituted by pairs of subgraphs (substructures) that are (i) centered in two nodes n1 and n2 such that their distance is not more than D; and (ii) constituted by all nodes (and their edges) at an exact distance h from n1 or n2, where the distance between two nodes is defined as the number of edges in the shortest path connecting them. More formally, let G, NG and EG be a graph and its set of nodes and edges, respectively, the substru</context>
</contexts>
<marker>Gartner, Flach, Wrobel, 2003</marker>
<rawString>Thomas Gartner, P Flach, and S Wrobel. 2003. On Graph Kernels : Hardness Results and Efficient Alternatives. LNCS, pages 129–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Giampiccolo</author>
<author>Bernardo Magnini</author>
<author>Ido Dagan</author>
<author>Bill Dolan</author>
</authors>
<title>The third pascal recognizing textual entailment challenge.</title>
<date>2007</date>
<booktitle>In Proc. of the ACLPASCAL RTE ’07 Workshop,</booktitle>
<pages>1--9</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="2135" citStr="Giampiccolo et al., 2007" startWordPosition="309" endWordPosition="312">eras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the semantics of larger pieces of text, e.g., sentences or paragraphs. This line of research relates to three broad fields, namely, Question Answering (QA) (Voorhees and Tice, 1999), Paraphrasing Identification (PI) (Dolan et al., 2004) and Recognition of Textual Entailments (RTE) (Giampiccolo et al., 2007). More generally, RL from text can be denied as follows: given two text fragments, the main goal is to derive relations between them, e.g., either if the second fragment answers the question, or conveys exactly the same information or is implied by the first text fragment. For example, the following two sentences: - License revenue slid 21 percent, however, to $107.6 million. - License sales, a key measure of demand, fell 21 percent to $107.6 million. express exactly the same meaning, whereas the next one: - She was transferred again to Navy when the American Civil War began, 1861. implies: - </context>
<context position="6479" citStr="Giampiccolo et al., 2007" startWordPosition="1011" endWordPosition="1015">restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) apply a recursive auto encoder with dynamic pooling, and (Madnani et al., 2012) use eight machine translation metrics to achieve the state of the art. To our knowledge no previous model based on kernel methods has been applied before: with such methods, we outperform the state of the art in PI. A description of RTE can be found in (Giampiccolo et al., 2007): it is defined as a directional relation extraction between two text fragments, called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Summarization and Machine translation. One of the most performing approaches of RTE 3 was (Iftene and Balahur-Dobrescu, 2007), which largely relies on external resources (i.e., WordNet, Wikipedia, acronyms dictionaries) and a base of knowledge developed ad hoc for the dataset. In (Zanzotto and Moschitti, 2006), we designed an interesting but computationally ex</context>
<context position="27081" citStr="Giampiccolo et al., 2007" startWordPosition="4603" endWordPosition="4607">849 77.85 f 1.00 0.804 f 0.008 0.886 f 0.015 0.843 f 0.009 LK+SMSP T KW 2V 77.74 0.794 0.899 0.843 77.52 f 1.41 0.802 f 0.011 0.885 f 0.016 0.841 f 0.011 LK+GK+SMSP T KW 2V 79.13 0.807 0.901 0.852 78.11 f 0.94 0.811 f 0.005 0.879 f 0.016 0.844 f 0.009 (Socher et al., 2011) 76.8 − − 0.836 − − − − (Madnani et al., 2012) 77.4 − − 0.841 − − − − Table 1: Results on Paraphrasing Identification examples. These pairs were extracted from topically similar Web news articles, applying some heuristics that select potential paraphrases to be annotated by human experts. RTE-3. We adopted the RTE-3 dataset (Giampiccolo et al., 2007), which is composed by 800 texthypothesis pairs in both the training and test sets, collected by human annotators. The distribution of the examples among the positive and negative classes is balanced. 5.1.1 Models and Parameterization We train our classifiers with the C-SVM learning algorithm (Chang and Lin, 2011) within KeLP3, a Kernel-based Machine Learning platform that implements tree kernels. In both tasks, we applied the kernels described in Sec. 4, where the trees are generated with the Stanford parser4. SPTK uses a node similarity function Q(n1, n2) implemented as follows: if n1 and n2</context>
</contexts>
<marker>Giampiccolo, Magnini, Dagan, Dolan, 2007</marker>
<rawString>Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and Bill Dolan. 2007. The third pascal recognizing textual entailment challenge. In Proc. of the ACLPASCAL RTE ’07 Workshop, pages 1–9. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<pages>28--245</pages>
<contexts>
<context position="1582" citStr="Gildea and Jurafsky, 2002" startWordPosition="225" endWordPosition="228"> relational learning. Our findings allow for achieving the highest accuracy in two different and important related tasks, i.e., Paraphrasing Identification and Textual Entailment Recognition. 1 Introduction Advanced NLP systems, e.g., IBM Watson system (Ferrucci et al., 2010), are the result of effective use of syntactic/semantic information along with relational learning (RL) methods. This research area is rather vast including, extraction of syntactic relations, e.g., (Nastase et al., 2013), predicate relations, e.g., Semantic Role Labeling (Carreras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the semantics of larger pieces of text, e.g., sentences or paragraphs. This line of research relates to three broad fields, namely, Question Answering (QA) (Voorhees and Tice, 1999), Paraphrasing Identification (PI) (Dolan et al., 2004) and Recognition of Textual Entailments (RTE) (Giampiccolo et al., 2007). More generally, RL from text can be denied as</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28:245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandra Giordani</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Translating questions to sql queries with generative parsers discriminatively reranked.</title>
<date>2012</date>
<booktitle>In COLING (Posters),</booktitle>
<pages>401--410</pages>
<contexts>
<context position="19344" citStr="Giordani and Moschitti, 2012" startWordPosition="3206" endWordPosition="3209">such features are matched in b1, they provide the fuzzy information: there should be a match similar to [NP [NP-REL [JJ-REL]] also between a2 and b2. This kind of matches establishes a sort of relational pair features. It should be noted that we proposed more complex REL tagging policies for Passage Reranking, exploiting additional resources such as Linked Open Data or WordNet (Tymoshenko et al., 2014). Another interesting application of this RL framework is the Machine Translation Evaluation (Guzm´an et al., 2014). Finally, we used a similar model for translating questions to SQL queries in (Giordani and Moschitti, 2012). 4.2 Graph Representations The relational tree representation can capture relational features but the use of the same REL tag for any match between the two trees prevents to deterministically establish the correspondences between nodes. For exactly representing such matches (without incurring in non-valid kernels or sparsity problems), a graph representation is needed. If we connect matching nodes (or also nodes labelled as REL) in Fig. 1 (see dashed lines), we obtain a relational graph. Substructures of such graph clearly indicate how constituents, e.g., NPs, VPs, PPs, from one sentence map </context>
</contexts>
<marker>Giordani, Moschitti, 2012</marker>
<rawString>Alessandra Giordani and Alessandro Moschitti. 2012. Translating questions to sql queries with generative parsers discriminatively reranked. In COLING (Posters), pages 401–410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francisco Guzm´an</author>
<author>Shafiq Joty</author>
<author>Llu´ıs M`arquez</author>
<author>Alessandro Moschitti</author>
<author>Preslav Nakov</author>
<author>Massimo Nicosia</author>
</authors>
<title>Learning to differentiate better from worse translations.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>214--220</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<marker>Guzm´an, Joty, M`arquez, Moschitti, Nakov, Nicosia, 2014</marker>
<rawString>Francisco Guzm´an, Shafiq Joty, Llu´ıs M`arquez, Alessandro Moschitti, Preslav Nakov, and Massimo Nicosia. 2014. Learning to differentiate better from worse translations. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 214–220, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Heinonen</author>
<author>N V¨alim¨aki</author>
<author>V M¨akinen</author>
<author>J Rousu</author>
</authors>
<title>Efficient Path Kernels for Reaction Function Prediction. Bioinformatics Models, Methods andAlgorithms.</title>
<date>2012</date>
<marker>Heinonen, V¨alim¨aki, M¨akinen, Rousu, 2012</marker>
<rawString>M Heinonen, N V¨alim¨aki, V M¨akinen, and J Rousu. 2012. Efficient Path Kernels for Reaction Function Prediction. Bioinformatics Models, Methods andAlgorithms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrian Iftene</author>
<author>Alexandra Balahur-Dobrescu</author>
</authors>
<title>Hypothesis transformation and semantic variability rules used in recognizing textual entailment.</title>
<date>2007</date>
<booktitle>In RTE Workshop,</booktitle>
<location>Prague.</location>
<contexts>
<context position="6842" citStr="Iftene and Balahur-Dobrescu, 2007" startWordPosition="1069" endWordPosition="1072">t machine translation metrics to achieve the state of the art. To our knowledge no previous model based on kernel methods has been applied before: with such methods, we outperform the state of the art in PI. A description of RTE can be found in (Giampiccolo et al., 2007): it is defined as a directional relation extraction between two text fragments, called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Summarization and Machine translation. One of the most performing approaches of RTE 3 was (Iftene and Balahur-Dobrescu, 2007), which largely relies on external resources (i.e., WordNet, Wikipedia, acronyms dictionaries) and a base of knowledge developed ad hoc for the dataset. In (Zanzotto and Moschitti, 2006), we designed an interesting but computationally expensive model using simple syntactic tree kernels. In this paper, we develop models that do not use external resources but, at the same time, are efficient and approach the state of the art in RTE. 3 Structural kernels Kernel Machines carry out learning and classification by only relying on the inner product between instances. This can be efficiently and implic</context>
<context position="31008" citStr="Iftene and Balahur-Dobrescu, 2007" startWordPosition="5316" endWordPosition="5319">.049 SPTK× 66.00 0.629 0.822 0.712 68.00 f 7.62 0.661 f 0.074 0.808 f 0.039 0.725 f 0.049 LSA SPTK× 67.00 0.636 0.834 0.722 67.69 f 6.95 0.658 f 0.069 0.804 f 0.040 0.722 f 0.043 W 2V GK+SPTK× 66.38 0.634 0.815 0.713 66.00 f 6.79 0.648 f 0.069 0.769 f 0.034 0.701 f 0.044 W 2V LK+GK 62.25 0.609 0.737 0.667 62.06 f 5.49 0.620 f 0.051 0.702 f 0.053 0.656 f 0.036 LK+SPTK× 66.13 0.628 0.829 0.715 68.25 f 7.54 0.663 f 0.076 0.816 f 0.032 0.728 f 0.047 W 2V LK+GK+SPTK× 66.00 0.633 0.800 0.707 66.31 f 7.35 0.652 f 0.075 0.770 f 0.053 0.703 f 0.052 W 2V (Zanzotto et al., 2009) 66.75 0.667 − − − − − − (Iftene and Balahur-Dobrescu, 2007) 69.13 − − − − − − − Table 2: Results on Textual Entailment Recognition 5.2 Results on PI The results are reported in Table 1. The first column shows the use of the relational tag REL in the structures (discussed in Sec. 4.1). The second column indicates the kernel models described in sections 3 and 4 as well as the combination of the best models. Columns 3-6 report Accuracy, Precision, Recall and F1 derived on the fixed test set, whereas the remaining columns regard the results obtained with cross validation. We note that: First, when REL information is not used in the structures, the linear </context>
</contexts>
<marker>Iftene, Balahur-Dobrescu, 2007</marker>
<rawString>Adrian Iftene and Alexandra Balahur-Dobrescu. 2007. Hypothesis transformation and semantic variability rules used in recognizing textual entailment. In RTE Workshop, Prague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hisashi Kashima</author>
<author>Koji Tsuda</author>
<author>Akihiro Inokuchi</author>
</authors>
<title>Marginalized kernels between labeled graphs.</title>
<date>2003</date>
<booktitle>In ICML,</booktitle>
<pages>321--328</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="5496" citStr="Kashima et al., 2003" startWordPosition="839" endWordPosition="842">signing effective graph kernels for RL. 2 Related Work In this paper, we apply kernel methods, which enable an efficient comparison of structures in huge, possibly infinite, feature spaces. While for trees, a comparison using all possible subtrees is possible, designing kernel functions for graphs with such property is an NP-Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g.</context>
</contexts>
<marker>Kashima, Tsuda, Inokuchi, 2003</marker>
<rawString>Hisashi Kashima, Koji Tsuda, and Akihiro Inokuchi. 2003. Marginalized kernels between labeled graphs. In ICML, pages 321–328. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Joel Tetreault</author>
<author>Martin Chodorow</author>
</authors>
<title>Re-examining machine translation metrics for paraphrase identification.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL HLT ’12.</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="6199" citStr="Madnani et al., 2012" startWordPosition="961" endWordPosition="964"> and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) apply a recursive auto encoder with dynamic pooling, and (Madnani et al., 2012) use eight machine translation metrics to achieve the state of the art. To our knowledge no previous model based on kernel methods has been applied before: with such methods, we outperform the state of the art in PI. A description of RTE can be found in (Giampiccolo et al., 2007): it is defined as a directional relation extraction between two text fragments, called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Summarization and Machine translation. One of the most performing approaches of RT</context>
<context position="26775" citStr="Madnani et al., 2012" startWordPosition="4554" endWordPosition="4557">07 0.767 0.899 0.827 73.87 f 0.85 0.766 f 0.009 0.880 f 0.010 0.819 f 0.007 SP T KLSA all+ KW 2V 75.42 0.772 0.894 0.829 74.16 f 0.75 0.768 f 0.008 0.882 f 0.012 0.821 f 0.007 SP T GK+SMSP T KW 2V 76.70 0.782 0.901 0.837 76.12 f 0.96 0.787 f 0.008 0.885 f 0.015 0.833 f 0.009 LK+GK 78.67 0.802 0.902 0.849 77.85 f 1.00 0.804 f 0.008 0.886 f 0.015 0.843 f 0.009 LK+SMSP T KW 2V 77.74 0.794 0.899 0.843 77.52 f 1.41 0.802 f 0.011 0.885 f 0.016 0.841 f 0.011 LK+GK+SMSP T KW 2V 79.13 0.807 0.901 0.852 78.11 f 0.94 0.811 f 0.005 0.879 f 0.016 0.844 f 0.009 (Socher et al., 2011) 76.8 − − 0.836 − − − − (Madnani et al., 2012) 77.4 − − 0.841 − − − − Table 1: Results on Paraphrasing Identification examples. These pairs were extracted from topically similar Web news articles, applying some heuristics that select potential paraphrases to be annotated by human experts. RTE-3. We adopted the RTE-3 dataset (Giampiccolo et al., 2007), which is composed by 800 texthypothesis pairs in both the training and test sets, collected by human annotators. The distribution of the examples among the positive and negative classes is balanced. 5.1.1 Models and Parameterization We train our classifiers with the C-SVM learning algorithm </context>
<context position="32623" citStr="Madnani et al., 2012" startWordPosition="5590" endWordPosition="5593">l paraphrases are retrieved applying some heuristics mostly based on the lexical overlap between sentences. Thus, in most cases, the lexical similarity used in SPTK is not needed as hard matches occur between the words of the sentences. Third, when REL is used on the structures, all kernels reach or outperform the F1 (official measure of the challenge) of LK. The relational structures seem to drastically reduce the inconsistent matching between positive and negative examples, reflecting in remarkable increasing in Precision. In particular, SMSPTKLSA achieves the state of the art6, i.e., 84.1 (Madnani et al., 2012). Next, combining our best models produces a significant improvement of the state of the art, e.g., LK +GK +SMSPTKW2V outperforms the result in (Madnani et al., 2012) by 1.7% in accuracy and 1.1 points in F1. Finally, the cross-validation experiments confirm the system behavior observed on the fixed test set. The Std. Dev. (specified after the ± sign) shows that in most cases the system differences are significant. 5.3 Results on RTE We used the same experimental settings performed for PI to carry out the experiments on RTE. The results are shown in Table 2 structured in the same way as the pr</context>
</contexts>
<marker>Madnani, Tetreault, Chodorow, 2012</marker>
<rawString>Nitin Madnani, Joel Tetreault, and Martin Chodorow. 2012. Re-examining machine translation metrics for paraphrase identification. In Proceedings of NAACL HLT ’12. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Mah´e</author>
<author>Jean-Philippe Vert</author>
</authors>
<title>Graph kernels based on tree patterns for molecules.</title>
<date>2008</date>
<booktitle>Machine Learning,</booktitle>
<volume>75</volume>
<issue>1</issue>
<marker>Mah´e, Vert, 2008</marker>
<rawString>Pierre Mah´e and Jean-Philippe Vert. 2008. Graph kernels based on tree patterns for molecules. Machine Learning, 75(1):3–35, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</title>
<date>2013</date>
<contexts>
<context position="28204" citStr="Mikolov et al., 2013" startWordPosition="4779" endWordPosition="4782">nford parser4. SPTK uses a node similarity function Q(n1, n2) implemented as follows: if n1 and n2 are two identical syntactic nodes Q = 1. If n1 and n2 are two lexical nodes with the same POS tag, their similarity is evaluated computing the cosine similarity of their corresponding vectors in a wordspace. In all the other cases Q = 0. We generated two different wordspaces. The first is 3https://github.com/SAG-KeLP 4http://nlp.stanford.edu/software/corenlp.shtml a co-occurrence LSA embedding as described in (Croce and Previtali, 2010). The second space is derived by applying a skip-gram model (Mikolov et al., 2013) with the word2vec tool5. SPTK using the LSA will be referred to as SPTKLSA, while when adopting word2vec it will be indicated with SPTKW2V. We used default parameters both for PTK and SPTK whereas we selected h and D parameters of NSPDK that obtained the best average accuracy using a 5-fold cross validation on the training set. 5.1.2 Performance measures The two considered tasks are binary classification problems thus we used Accuracy, Precision, Recall and F1. The adopted corpora have a predefined split between training and test sets thus we tested our models according to such settings for e</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In ACL-AFNLP.</booktitle>
<contexts>
<context position="1657" citStr="Mintz et al., 2009" startWordPosition="237" endWordPosition="240"> different and important related tasks, i.e., Paraphrasing Identification and Textual Entailment Recognition. 1 Introduction Advanced NLP systems, e.g., IBM Watson system (Ferrucci et al., 2010), are the result of effective use of syntactic/semantic information along with relational learning (RL) methods. This research area is rather vast including, extraction of syntactic relations, e.g., (Nastase et al., 2013), predicate relations, e.g., Semantic Role Labeling (Carreras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the semantics of larger pieces of text, e.g., sentences or paragraphs. This line of research relates to three broad fields, namely, Question Answering (QA) (Voorhees and Tice, 1999), Paraphrasing Identification (PI) (Dolan et al., 2004) and Recognition of Textual Entailments (RTE) (Giampiccolo et al., 2007). More generally, RL from text can be denied as follows: given two text fragments, the main goal is to derive relations be</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Daniel Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In ACL-AFNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Efficient convolution kernels for dependency and constituent syntactic trees.</title>
<date>2006</date>
<booktitle>In Proc. of ECML’06,</booktitle>
<pages>318--329</pages>
<contexts>
<context position="3372" citStr="Moschitti, 2006" startWordPosition="509" endWordPosition="510">r started in 1861. Automatic learning a model for deriving the relations above is rather complex as any of the text constituents, e.g., License revenue, a key measure of demand, in the two sentences plays an important role. Therefore, a suitable approach should exploit representations that can structure the two sentences and put their constituents in relation. Since the dependencies between constituents can be an exponential number and representing structures in learning algorithms is rather challenging, automatic feature engineering through kernel methods (Shawe-Taylor and Cristianini, 2004; Moschitti, 2006) can be a promising direction. In particular, in (Zanzotto and Moschitti, 2006), we represented the two evaluating sentences for the RTE task with syntactic structures and then applied tree kernels to them. The resulting system was very accurate but, unfortunately, it could not scale to large datasets as it is based on a compu1003 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1003–1013, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics tati</context>
<context position="7028" citStr="Moschitti, 2006" startWordPosition="1098" endWordPosition="1099">PI. A description of RTE can be found in (Giampiccolo et al., 2007): it is defined as a directional relation extraction between two text fragments, called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Summarization and Machine translation. One of the most performing approaches of RTE 3 was (Iftene and Balahur-Dobrescu, 2007), which largely relies on external resources (i.e., WordNet, Wikipedia, acronyms dictionaries) and a base of knowledge developed ad hoc for the dataset. In (Zanzotto and Moschitti, 2006), we designed an interesting but computationally expensive model using simple syntactic tree kernels. In this paper, we develop models that do not use external resources but, at the same time, are efficient and approach the state of the art in RTE. 3 Structural kernels Kernel Machines carry out learning and classification by only relying on the inner product between instances. This can be efficiently and implicitly computed by kernel functions by exploiting the following dual formulation of the model (hyperplane): i=1..lyiαiφ(oi) · φ(o) + b = 0, where yi are the example labels, αi the support </context>
<context position="8620" citStr="Moschitti, 2006" startWordPosition="1376" endWordPosition="1377">llowing: K(S1, S2) = � kiso(s1,s2), (1) s1⊆S1,s2⊆S2,si∈S where si are substructures of Si, S is the set of admissible substructures, and kiso determines if the two substructures are isomorphic, i.e., it outputs 1 if s1 and s2 are isomorphic and 0 otherwise. In the following, we also provide a more computational-oriented definition of structural kernels to more easily describe those we use in our work: Let the set S = {s1, s2, ... , s|S|} be the substructure space and χi(n) be an indicator function, equal to 1 if the target si is rooted at node n and 1004 3.1 The Partial Tree Kernel (PTK) PTK (Moschitti, 2006) generalizes a large class of tree kernels as it computes one of the most general tree substructure spaces. Given two trees S1 and S2, PTK considers any connected subset of nodes as possible feature of the substructure space, and counts how many of them are shared by S1 and S2. Its computation is carried out by Eq. 2 using the following ΔPTK function: if the labels of n1 and n2 are different ΔPTK(n1, n2) = 0; else ΔPTK(n1, n2) = �ΔPTK(cn1(~I1j), cn2(~I2j)) where µ, λ E [0, 1] are two decay factors, ~I1 and ~I2 are two sequences of indices, which index subsequences of children u, I~ = (i1, ...,</context>
<context position="16168" citStr="Moschitti, 2006" startWordPosition="2678" endWordPosition="2679">es from the upper and lower trees, e.g.: {[PP [TO [to::t]][NP [QP [$ [$::$]][QP [CD [107.6::c]]]]]], [PP [TO][NP [QP [$][QP [CD [107]]]]]], [PP [TO][NP [QP [QP [CD]]]]], [PP [NP [QP [QP]]]], ...} a2: {[NP [NP [DT [a::d]] [JJ [key::j] NN]][PP]], [NP [NP [DT] [JJ NN]][PP]], [NP [NP [JJ NN]][PP]], [NP [NP [NN]][PP]], [NP [NP [JJ]][PP]], ... } However, such features cannot capture the relations between the constituents (or semantic lexical units) from the two trees. In contrast, these are essential to learn the relation between the two entire sentences2. To overcome this problem, in (Zanzotto and Moschitti, 2006), we proposed the use of placeholders for RTE: the main idea was to annotate the matches between the constituents of the two sentences, e.g., 107.6 millions, on both trees. This way the tree fragments in the generated kernel space contained an index capturing the correspondences between a1 and a2. The critical drawback of this approach is that other pairs, e.g., pb, will have in general different indices, making the representation very sparse. Alternatively, we experimented with models that select the best match between all possible placeholder assignments across the two pairs. Although we obt</context>
<context position="36351" citStr="Moschitti, 2006" startWordPosition="6198" endWordPosition="6199">lable corpora for automatically learning similarities with word embedding algorithms; and (ii) reuse our work for different (similar) tasks (see paraphrasing) and data. The simplicity and portability of our system is a significant contribution to a very complex research area such as RL from two entire pieces of text. Our study has indeed shown that our kernel models, which are very simple to be implemented, reach the state of the art and can be used with large datasets. Furthermore, it should be noted that our models outperform the best tree kernel approach of the RTE challenges (Zanzotto and Moschitti, 2006) and also its extension that we proposed in (Zanzotto et al., 2009). These systems are also adaptable and easy to replicate, but they are subject to an exponential computational complexity and can thus only be used on very small datasets (e.g., they cannot be applied to the MSR Paraphrase corpus). In contrast, the model we proposed in this paper can be used on large datasets, because its kernel complexity is about linear (on average). We believe that disseminating these findings to the research community is very important, as it will foster research on RL, e.g., on RTE, using structural kernel</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Efficient convolution kernels for dependency and constituent syntactic trees. In Proc. of ECML’06, pages 318–329.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Kernel methods, syntax and semantics for relational text categorization.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM ’08,</booktitle>
<pages>253--262</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="15481" citStr="Moschitti, 2008" startWordPosition="2564" endWordPosition="2565">epresentations An intuitive understanding of our target tasks suggests that syntactic information is essential to achieve high accuracy. Therefore, we consider the syntactic parse trees of the pair of sentences involved in the evaluation. For example, Fig. 1 shows the syntactic constituency trees of the sentences reported in the introduction (these do not include the green label REL and the dashed edges). Given two pairs of sentences, pa = (a1, a2) and pb = (b1, b2), an initial kernel for learning the tasks, can be the simple tree kernel sum, e.g., PTK(a1, b1) + PTK(a2, b2) as was defined in (Moschitti, 2008). This kernel works in the space of the union of the sets of all subtrees from the upper and lower trees, e.g.: {[PP [TO [to::t]][NP [QP [$ [$::$]][QP [CD [107.6::c]]]]]], [PP [TO][NP [QP [$][QP [CD [107]]]]]], [PP [TO][NP [QP [QP [CD]]]]], [PP [NP [QP [QP]]]], ...} a2: {[NP [NP [DT [a::d]] [JJ [key::j] NN]][PP]], [NP [NP [DT] [JJ NN]][PP]], [NP [NP [JJ NN]][PP]], [NP [NP [NN]][PP]], [NP [NP [JJ]][PP]], ... } However, such features cannot capture the relations between the constituents (or semantic lexical units) from the two trees. In contrast, these are essential to learn the relation between</context>
</contexts>
<marker>Moschitti, 2008</marker>
<rawString>Alessandro Moschitti. 2008. Kernel methods, syntax and semantics for relational text categorization. In Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM ’08, pages 253–262, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Preslav Nakov</author>
<author>Diarmuid Saghdha</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Semantic Relations Between Nominals.</title>
<date>2013</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1453" citStr="Nastase et al., 2013" startWordPosition="208" endWordPosition="211">atures in Support Vector Machines. We carry out an extensive comparative analysis of stateof-the-art models for this type of relational learning. Our findings allow for achieving the highest accuracy in two different and important related tasks, i.e., Paraphrasing Identification and Textual Entailment Recognition. 1 Introduction Advanced NLP systems, e.g., IBM Watson system (Ferrucci et al., 2010), are the result of effective use of syntactic/semantic information along with relational learning (RL) methods. This research area is rather vast including, extraction of syntactic relations, e.g., (Nastase et al., 2013), predicate relations, e.g., Semantic Role Labeling (Carreras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the semantics of larger pieces of text, e.g., sentences or paragraphs. This line of research relates to three broad fields, namely, Question Answering (QA) (Voorhees and Tice, 1999), Paraphrasing Identification (PI) (Dolan et </context>
</contexts>
<marker>Nastase, Nakov, Saghdha, Szpakowicz, 2013</marker>
<rawString>Vivi Nastase, Preslav Nakov, Diarmuid Saghdha, and Stan Szpakowicz. 2013. Semantic Relations Between Nominals. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Structural relationships for large-scale learning of answer re-ranking.</title>
<date>2012</date>
<booktitle>In SIGIR.</booktitle>
<contexts>
<context position="17932" citStr="Severyn and Moschitti, 2012" startWordPosition="2980" endWordPosition="2983">D NP-REL slide::v CD-REL 21::c NN-REL percent::n . PP ,::, , TO NP to::t QP-REL .::. $-REL QP-REL , ADVB ,::, RB however::r CD-REL million::c $::$ ROOT S NP VP . JJ-REL license::j NP NNS sale::n DT JJ a::d key::j , ,::, NP NN demand::n .::. QP-REL CD-REL CD-REL 107.6::c million::c NP-REL NP-REL IN NN of::i PP CD-REL 21::c NN-REL percent::n $::$ measure::n PP , ,::, NP VBD fall::v TO NP to:t QP-REL $-REL CD-REL 107.6::c assignment made our similarity function a nonvalid kernel. Thus, for this paper, we prefer to rely on a more recent solution we proposed for passage reranking in the QA domain (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b), and for Answer Selection (Severyn and Moschitti, 2013). It consists in simply labeling matching nodes with a special tag, e.g., REL, which indicates the correspondences between words. REL is attached to the father and grandfather nodes of the matching words. Fig. 1 shows several green REL tags attached to the usual POS-tag and constituent node labels of the parse trees. For example, the lemma license is matched by the two sentences, thus both its father, JJ, and its grandfather, NP, nodes are marked with REL. Thanks to such relational labeling t</context>
</contexts>
<marker>Severyn, Moschitti, 2012</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2012. Structural relationships for large-scale learning of answer re-ranking. In SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Automatic feature engineering for answer selection and extraction.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>458--467</pages>
<contexts>
<context position="18035" citStr="Severyn and Moschitti, 2013" startWordPosition="2996" endWordPosition="2999">VB ,::, RB however::r CD-REL million::c $::$ ROOT S NP VP . JJ-REL license::j NP NNS sale::n DT JJ a::d key::j , ,::, NP NN demand::n .::. QP-REL CD-REL CD-REL 107.6::c million::c NP-REL NP-REL IN NN of::i PP CD-REL 21::c NN-REL percent::n $::$ measure::n PP , ,::, NP VBD fall::v TO NP to:t QP-REL $-REL CD-REL 107.6::c assignment made our similarity function a nonvalid kernel. Thus, for this paper, we prefer to rely on a more recent solution we proposed for passage reranking in the QA domain (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b), and for Answer Selection (Severyn and Moschitti, 2013). It consists in simply labeling matching nodes with a special tag, e.g., REL, which indicates the correspondences between words. REL is attached to the father and grandfather nodes of the matching words. Fig. 1 shows several green REL tags attached to the usual POS-tag and constituent node labels of the parse trees. For example, the lemma license is matched by the two sentences, thus both its father, JJ, and its grandfather, NP, nodes are marked with REL. Thanks to such relational labeling the simple kernel, PTK(a1, b1) + PTK(a2, b2), can generate relational features from a1, e.g., [NP [NP-RE</context>
</contexts>
<marker>Severyn, Moschitti, 2013</marker>
<rawString>Aliaksei Severyn and Alessandro Moschitti. 2013. Automatic feature engineering for answer selection and extraction. In EMNLP, pages 458–467.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Massimo Nicosia</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Building structures from classifiers for passage reranking.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22Nd ACM International Conference on Conference on Information &amp;#38; Knowledge Management, CIKM ’13,</booktitle>
<pages>969--978</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="17954" citStr="Severyn et al., 2013" startWordPosition="2984" endWordPosition="2987">c NN-REL percent::n . PP ,::, , TO NP to::t QP-REL .::. $-REL QP-REL , ADVB ,::, RB however::r CD-REL million::c $::$ ROOT S NP VP . JJ-REL license::j NP NNS sale::n DT JJ a::d key::j , ,::, NP NN demand::n .::. QP-REL CD-REL CD-REL 107.6::c million::c NP-REL NP-REL IN NN of::i PP CD-REL 21::c NN-REL percent::n $::$ measure::n PP , ,::, NP VBD fall::v TO NP to:t QP-REL $-REL CD-REL 107.6::c assignment made our similarity function a nonvalid kernel. Thus, for this paper, we prefer to rely on a more recent solution we proposed for passage reranking in the QA domain (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b), and for Answer Selection (Severyn and Moschitti, 2013). It consists in simply labeling matching nodes with a special tag, e.g., REL, which indicates the correspondences between words. REL is attached to the father and grandfather nodes of the matching words. Fig. 1 shows several green REL tags attached to the usual POS-tag and constituent node labels of the parse trees. For example, the lemma license is matched by the two sentences, thus both its father, JJ, and its grandfather, NP, nodes are marked with REL. Thanks to such relational labeling the simple kernel, PTK(</context>
</contexts>
<marker>Severyn, Nicosia, Moschitti, 2013</marker>
<rawString>Aliaksei Severyn, Massimo Nicosia, and Alessandro Moschitti. 2013a. Building structures from classifiers for passage reranking. In Proceedings of the 22Nd ACM International Conference on Conference on Information &amp;#38; Knowledge Management, CIKM ’13, pages 969–978, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aliaksei Severyn</author>
<author>Massimo Nicosia</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Learning adaptable patterns for passage reranking.</title>
<date>2013</date>
<booktitle>Proceedings of the Seventeenth Conference on Computational Natural Language Learning,</booktitle>
<pages>75--83</pages>
<contexts>
<context position="17954" citStr="Severyn et al., 2013" startWordPosition="2984" endWordPosition="2987">c NN-REL percent::n . PP ,::, , TO NP to::t QP-REL .::. $-REL QP-REL , ADVB ,::, RB however::r CD-REL million::c $::$ ROOT S NP VP . JJ-REL license::j NP NNS sale::n DT JJ a::d key::j , ,::, NP NN demand::n .::. QP-REL CD-REL CD-REL 107.6::c million::c NP-REL NP-REL IN NN of::i PP CD-REL 21::c NN-REL percent::n $::$ measure::n PP , ,::, NP VBD fall::v TO NP to:t QP-REL $-REL CD-REL 107.6::c assignment made our similarity function a nonvalid kernel. Thus, for this paper, we prefer to rely on a more recent solution we proposed for passage reranking in the QA domain (Severyn and Moschitti, 2012; Severyn et al., 2013a; Severyn et al., 2013b), and for Answer Selection (Severyn and Moschitti, 2013). It consists in simply labeling matching nodes with a special tag, e.g., REL, which indicates the correspondences between words. REL is attached to the father and grandfather nodes of the matching words. Fig. 1 shows several green REL tags attached to the usual POS-tag and constituent node labels of the parse trees. For example, the lemma license is matched by the two sentences, thus both its father, JJ, and its grandfather, NP, nodes are marked with REL. Thanks to such relational labeling the simple kernel, PTK(</context>
</contexts>
<marker>Severyn, Nicosia, Moschitti, 2013</marker>
<rawString>Aliaksei Severyn, Massimo Nicosia, and Alessandro Moschitti. 2013b. Learning adaptable patterns for passage reranking. Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 75–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Shawe-Taylor</author>
<author>Nello Cristianini</author>
</authors>
<title>Kernel Methods for Pattern Analysis.</title>
<date>2004</date>
<publisher>Cambridge University Press, USA.</publisher>
<contexts>
<context position="3354" citStr="Shawe-Taylor and Cristianini, 2004" startWordPosition="505" endWordPosition="508">61. implies: - The American Civil War started in 1861. Automatic learning a model for deriving the relations above is rather complex as any of the text constituents, e.g., License revenue, a key measure of demand, in the two sentences plays an important role. Therefore, a suitable approach should exploit representations that can structure the two sentences and put their constituents in relation. Since the dependencies between constituents can be an exponential number and representing structures in learning algorithms is rather challenging, automatic feature engineering through kernel methods (Shawe-Taylor and Cristianini, 2004; Moschitti, 2006) can be a promising direction. In particular, in (Zanzotto and Moschitti, 2006), we represented the two evaluating sentences for the RTE task with syntactic structures and then applied tree kernels to them. The resulting system was very accurate but, unfortunately, it could not scale to large datasets as it is based on a compu1003 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1003–1013, Beijing, China, July 26-31, 2015. c�2015 Association for Computationa</context>
</contexts>
<marker>Shawe-Taylor, Cristianini, 2004</marker>
<rawString>John Shawe-Taylor and Nello Cristianini. 2004. Kernel Methods for Pattern Analysis. Cambridge University Press, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nino Shervashidze</author>
<author>Pascal Schweitzer</author>
<author>Erik Jan van Leeuwen</author>
<author>Kurt Mehlhorn</author>
<author>Karsten M Borgwardt</author>
</authors>
<title>Weisfeiler-Lehman Graph Kernels.</title>
<date>2011</date>
<pages>12--2539</pages>
<publisher>JMLR,</publisher>
<marker>Shervashidze, Schweitzer, van Leeuwen, Mehlhorn, Borgwardt, 2011</marker>
<rawString>Nino Shervashidze, Pascal Schweitzer, Erik Jan van Leeuwen, Kurt Mehlhorn, and Karsten M Borgwardt. 2011. Weisfeiler-Lehman Graph Kernels. JMLR, 12:2539–2561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Eric H Huang</author>
<author>Jeffrey Pennin</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Dynamic pooling and unfolding recursive autoencoders for paraphrase detection.</title>
<date>2011</date>
<journal>In NIPS</journal>
<volume>24</volume>
<contexts>
<context position="6119" citStr="Socher et al., 2011" startWordPosition="948" endWordPosition="951">ishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) apply a recursive auto encoder with dynamic pooling, and (Madnani et al., 2012) use eight machine translation metrics to achieve the state of the art. To our knowledge no previous model based on kernel methods has been applied before: with such methods, we outperform the state of the art in PI. A description of RTE can be found in (Giampiccolo et al., 2007): it is defined as a directional relation extraction between two text fragments, called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Su</context>
<context position="26729" citStr="Socher et al., 2011" startWordPosition="4542" endWordPosition="4545">10 0.880 f 0.013 0.820 f 0.009 P T K all+ 75.07 0.767 0.899 0.827 73.87 f 0.85 0.766 f 0.009 0.880 f 0.010 0.819 f 0.007 SP T KLSA all+ KW 2V 75.42 0.772 0.894 0.829 74.16 f 0.75 0.768 f 0.008 0.882 f 0.012 0.821 f 0.007 SP T GK+SMSP T KW 2V 76.70 0.782 0.901 0.837 76.12 f 0.96 0.787 f 0.008 0.885 f 0.015 0.833 f 0.009 LK+GK 78.67 0.802 0.902 0.849 77.85 f 1.00 0.804 f 0.008 0.886 f 0.015 0.843 f 0.009 LK+SMSP T KW 2V 77.74 0.794 0.899 0.843 77.52 f 1.41 0.802 f 0.011 0.885 f 0.016 0.841 f 0.011 LK+GK+SMSP T KW 2V 79.13 0.807 0.901 0.852 78.11 f 0.94 0.811 f 0.005 0.879 f 0.016 0.844 f 0.009 (Socher et al., 2011) 76.8 − − 0.836 − − − − (Madnani et al., 2012) 77.4 − − 0.841 − − − − Table 1: Results on Paraphrasing Identification examples. These pairs were extracted from topically similar Web news articles, applying some heuristics that select potential paraphrases to be annotated by human experts. RTE-3. We adopted the RTE-3 dataset (Giampiccolo et al., 2007), which is composed by 800 texthypothesis pairs in both the training and test sets, collected by human annotators. The distribution of the examples among the positive and negative classes is balanced. 5.1.1 Models and Parameterization We train our </context>
</contexts>
<marker>Socher, Huang, Pennin, Manning, Ng, 2011</marker>
<rawString>Richard Socher, Eric H. Huang, Jeffrey Pennin, Christopher D Manning, and Andrew Y. Ng. 2011. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In NIPS 24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szarvas</author>
<author>Chris Biemann</author>
<author>Iryna Gurevych</author>
</authors>
<title>Supervised all-words lexical substitution using delexicalized features.</title>
<date>2013</date>
<booktitle>In NAACL.</booktitle>
<contexts>
<context position="21986" citStr="Szarvas et al., 2013" startWordPosition="3625" endWordPosition="3628">n the Semantic Textual Similarity (STS) task: – Longest common substring measure and Longest common subsequence measure, which determine the length of the longest substring shared by two text segments. – Running-Karp-Rabin Greedy String Tiling provides a similarity between two sentences by counting the number of shuffles in their subparts. – Resnik similarity based on the WordNet hierarchy. – Explicit Semantic Analysis (ESA) similarity (Gabrilovich and Markovitch, 2007) represents documents as weighted vectors of concepts learned from Wikipedia, WordNet and Wiktionary. – Lexical Substitution (Szarvas et al., 2013): a supervised word sense disambiguation system is used to substitute a wide selection of highfrequency English nouns with generalizations, then Resnik and ESA features are computed on the transformed text. 4.4 Combined representations As mentioned in Sec. 3.4, we can combine kernels for engineering new features. Let K be PTK or SPTK, given two pairs of sentences pa = (a1, a2) and pb = (b1, b2), we build the following kernel combinations for the RTE task: (i) K+(pa,pb) = K(a1, b1) + K(a2, b2), which simply sums the similarities between the first two sentences and the second two sentences whose</context>
</contexts>
<marker>Szarvas, Biemann, Gurevych, 2013</marker>
<rawString>Gy¨orgy Szarvas, Chris Biemann, and Iryna Gurevych. 2013. Supervised all-words lexical substitution using delexicalized features. In NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kateryna Tymoshenko</author>
<author>Alessandro Moschitti</author>
<author>Aliaksei Severyn</author>
</authors>
<title>Encoding semantic resources in syntactic structures for passage reranking. EACL</title>
<date>2014</date>
<pages>664</pages>
<contexts>
<context position="19120" citStr="Tymoshenko et al., 2014" startWordPosition="3171" endWordPosition="3174">Thanks to such relational labeling the simple kernel, PTK(a1, b1) + PTK(a2, b2), can generate relational features from a1, e.g., [NP [NP-REL [JJ-REL] NN]][PP]], [NP [NP-REL [NN]][PP]], [NP [NP-REL [JJ-REL]][PP]],... If such features are matched in b1, they provide the fuzzy information: there should be a match similar to [NP [NP-REL [JJ-REL]] also between a2 and b2. This kind of matches establishes a sort of relational pair features. It should be noted that we proposed more complex REL tagging policies for Passage Reranking, exploiting additional resources such as Linked Open Data or WordNet (Tymoshenko et al., 2014). Another interesting application of this RL framework is the Machine Translation Evaluation (Guzm´an et al., 2014). Finally, we used a similar model for translating questions to SQL queries in (Giordani and Moschitti, 2012). 4.2 Graph Representations The relational tree representation can capture relational features but the use of the same REL tag for any match between the two trees prevents to deterministically establish the correspondences between nodes. For exactly representing such matches (without incurring in non-valid kernels or sparsity problems), a graph representation is needed. If </context>
</contexts>
<marker>Tymoshenko, Moschitti, Severyn, 2014</marker>
<rawString>Kateryna Tymoshenko, Alessandro Moschitti, and Aliaksei Severyn. 2014. Encoding semantic resources in syntactic structures for passage reranking. EACL 2014, page 664.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V N Vishwanathan</author>
<author>Karsten M Borgwardt</author>
<author>Nicol N Schraudolph</author>
</authors>
<title>Fast Computation of Graph Kernels.</title>
<date>2006</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="5524" citStr="Vishwanathan et al., 2006" startWordPosition="843" endWordPosition="846">h kernels for RL. 2 Related Work In this paper, we apply kernel methods, which enable an efficient comparison of structures in huge, possibly infinite, feature spaces. While for trees, a comparison using all possible subtrees is possible, designing kernel functions for graphs with such property is an NP-Hard problem (i.e., it shows the same complexity of the graph isomorphism problem) (Gartner et al., 2003). Thus most kernels for graphs only associate specific types of substructures with features, such as paths (Borgwardt and Kriegel, 2005; Heinonen et al., 2012), walks (Kashima et al., 2003; Vishwanathan et al., 2006) and tree structures (Cilia and Moschitti, 2007; Mah´e and Vert, 2008; Shervashidze et al., 2011; Da San Martino et al., 2012). We exploit structural kernels for PI, whose task is to evaluate whether a given pair of sentences is in the paraphrase class or not, (see for example (Dolan et al., 2004)). Paraphrases can be seen as a restatement of a text in another form that preserves the original meaning. This task has a primary importance in many other NLP and IR tasks such as Machine Translation, Plagiarism Detection and QA. Several approaches have been proposed, e.g., (Socher et al., 2011) appl</context>
</contexts>
<marker>Vishwanathan, Borgwardt, Schraudolph, 2006</marker>
<rawString>S. V. N. Vishwanathan, Karsten M Borgwardt, and Nicol N Schraudolph. 2006. Fast Computation of Graph Kernels. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Voorhees</author>
<author>D Tice</author>
</authors>
<title>The TREC-8 Question Answering Track Evaluation.</title>
<date>1999</date>
<contexts>
<context position="2008" citStr="Voorhees and Tice, 1999" startWordPosition="291" endWordPosition="294">ding, extraction of syntactic relations, e.g., (Nastase et al., 2013), predicate relations, e.g., Semantic Role Labeling (Carreras and M`arquez, 2005) or FrameNet parsing (Gildea and Jurafsky, 2002) and relation extraction between named entities, e.g., (Mintz et al., 2009). Although extremely interesting, the above methods target relations only between text constituents whereas the final goal of an intelligent system would be to interpret the semantics of larger pieces of text, e.g., sentences or paragraphs. This line of research relates to three broad fields, namely, Question Answering (QA) (Voorhees and Tice, 1999), Paraphrasing Identification (PI) (Dolan et al., 2004) and Recognition of Textual Entailments (RTE) (Giampiccolo et al., 2007). More generally, RL from text can be denied as follows: given two text fragments, the main goal is to derive relations between them, e.g., either if the second fragment answers the question, or conveys exactly the same information or is implied by the first text fragment. For example, the following two sentences: - License revenue slid 21 percent, however, to $107.6 million. - License sales, a key measure of demand, fell 21 percent to $107.6 million. express exactly t</context>
</contexts>
<marker>Voorhees, Tice, 1999</marker>
<rawString>E. Voorhees and D. Tice, 1999. The TREC-8 Question Answering Track Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Massimo Zanzotto</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Automatic learning of textual entailments with cross-pair similarities.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>401--408</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="3451" citStr="Zanzotto and Moschitti, 2006" startWordPosition="519" endWordPosition="522">ations above is rather complex as any of the text constituents, e.g., License revenue, a key measure of demand, in the two sentences plays an important role. Therefore, a suitable approach should exploit representations that can structure the two sentences and put their constituents in relation. Since the dependencies between constituents can be an exponential number and representing structures in learning algorithms is rather challenging, automatic feature engineering through kernel methods (Shawe-Taylor and Cristianini, 2004; Moschitti, 2006) can be a promising direction. In particular, in (Zanzotto and Moschitti, 2006), we represented the two evaluating sentences for the RTE task with syntactic structures and then applied tree kernels to them. The resulting system was very accurate but, unfortunately, it could not scale to large datasets as it is based on a compu1003 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1003–1013, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics tationally exponential algorithm. This prevents its application to PI tasks, which </context>
<context position="7028" citStr="Zanzotto and Moschitti, 2006" startWordPosition="1096" endWordPosition="1099">f the art in PI. A description of RTE can be found in (Giampiccolo et al., 2007): it is defined as a directional relation extraction between two text fragments, called text and hypothesis. The implication is supposed to be detectable only based on the text content. Its applications are in QA, Information Extraction, Summarization and Machine translation. One of the most performing approaches of RTE 3 was (Iftene and Balahur-Dobrescu, 2007), which largely relies on external resources (i.e., WordNet, Wikipedia, acronyms dictionaries) and a base of knowledge developed ad hoc for the dataset. In (Zanzotto and Moschitti, 2006), we designed an interesting but computationally expensive model using simple syntactic tree kernels. In this paper, we develop models that do not use external resources but, at the same time, are efficient and approach the state of the art in RTE. 3 Structural kernels Kernel Machines carry out learning and classification by only relying on the inner product between instances. This can be efficiently and implicitly computed by kernel functions by exploiting the following dual formulation of the model (hyperplane): i=1..lyiαiφ(oi) · φ(o) + b = 0, where yi are the example labels, αi the support </context>
<context position="16168" citStr="Zanzotto and Moschitti, 2006" startWordPosition="2676" endWordPosition="2679">of all subtrees from the upper and lower trees, e.g.: {[PP [TO [to::t]][NP [QP [$ [$::$]][QP [CD [107.6::c]]]]]], [PP [TO][NP [QP [$][QP [CD [107]]]]]], [PP [TO][NP [QP [QP [CD]]]]], [PP [NP [QP [QP]]]], ...} a2: {[NP [NP [DT [a::d]] [JJ [key::j] NN]][PP]], [NP [NP [DT] [JJ NN]][PP]], [NP [NP [JJ NN]][PP]], [NP [NP [NN]][PP]], [NP [NP [JJ]][PP]], ... } However, such features cannot capture the relations between the constituents (or semantic lexical units) from the two trees. In contrast, these are essential to learn the relation between the two entire sentences2. To overcome this problem, in (Zanzotto and Moschitti, 2006), we proposed the use of placeholders for RTE: the main idea was to annotate the matches between the constituents of the two sentences, e.g., 107.6 millions, on both trees. This way the tree fragments in the generated kernel space contained an index capturing the correspondences between a1 and a2. The critical drawback of this approach is that other pairs, e.g., pb, will have in general different indices, making the representation very sparse. Alternatively, we experimented with models that select the best match between all possible placeholder assignments across the two pairs. Although we obt</context>
<context position="36351" citStr="Zanzotto and Moschitti, 2006" startWordPosition="6196" endWordPosition="6199">nown and available corpora for automatically learning similarities with word embedding algorithms; and (ii) reuse our work for different (similar) tasks (see paraphrasing) and data. The simplicity and portability of our system is a significant contribution to a very complex research area such as RL from two entire pieces of text. Our study has indeed shown that our kernel models, which are very simple to be implemented, reach the state of the art and can be used with large datasets. Furthermore, it should be noted that our models outperform the best tree kernel approach of the RTE challenges (Zanzotto and Moschitti, 2006) and also its extension that we proposed in (Zanzotto et al., 2009). These systems are also adaptable and easy to replicate, but they are subject to an exponential computational complexity and can thus only be used on very small datasets (e.g., they cannot be applied to the MSR Paraphrase corpus). In contrast, the model we proposed in this paper can be used on large datasets, because its kernel complexity is about linear (on average). We believe that disseminating these findings to the research community is very important, as it will foster research on RL, e.g., on RTE, using structural kernel</context>
</contexts>
<marker>Zanzotto, Moschitti, 2006</marker>
<rawString>Fabio Massimo Zanzotto and Alessandro Moschitti. 2006. Automatic learning of textual entailments with cross-pair similarities. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 401–408, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio massimo Zanzotto</author>
<author>Marco Pennacchiotti</author>
<author>Alessandro Moschitti</author>
</authors>
<title>A machine learning approach to textual entailment recognition.</title>
<date>2009</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="30948" citStr="Zanzotto et al., 2009" startWordPosition="5304" endWordPosition="5307">.75 f 7.37 0.658 f 0.071 0.804 f 0.038 0.722 f 0.049 SPTK× 66.00 0.629 0.822 0.712 68.00 f 7.62 0.661 f 0.074 0.808 f 0.039 0.725 f 0.049 LSA SPTK× 67.00 0.636 0.834 0.722 67.69 f 6.95 0.658 f 0.069 0.804 f 0.040 0.722 f 0.043 W 2V GK+SPTK× 66.38 0.634 0.815 0.713 66.00 f 6.79 0.648 f 0.069 0.769 f 0.034 0.701 f 0.044 W 2V LK+GK 62.25 0.609 0.737 0.667 62.06 f 5.49 0.620 f 0.051 0.702 f 0.053 0.656 f 0.036 LK+SPTK× 66.13 0.628 0.829 0.715 68.25 f 7.54 0.663 f 0.076 0.816 f 0.032 0.728 f 0.047 W 2V LK+GK+SPTK× 66.00 0.633 0.800 0.707 66.31 f 7.35 0.652 f 0.075 0.770 f 0.053 0.703 f 0.052 W 2V (Zanzotto et al., 2009) 66.75 0.667 − − − − − − (Iftene and Balahur-Dobrescu, 2007) 69.13 − − − − − − − Table 2: Results on Textual Entailment Recognition 5.2 Results on PI The results are reported in Table 1. The first column shows the use of the relational tag REL in the structures (discussed in Sec. 4.1). The second column indicates the kernel models described in sections 3 and 4 as well as the combination of the best models. Columns 3-6 report Accuracy, Precision, Recall and F1 derived on the fixed test set, whereas the remaining columns regard the results obtained with cross validation. We note that: First, whe</context>
<context position="36418" citStr="Zanzotto et al., 2009" startWordPosition="6208" endWordPosition="6212">rd embedding algorithms; and (ii) reuse our work for different (similar) tasks (see paraphrasing) and data. The simplicity and portability of our system is a significant contribution to a very complex research area such as RL from two entire pieces of text. Our study has indeed shown that our kernel models, which are very simple to be implemented, reach the state of the art and can be used with large datasets. Furthermore, it should be noted that our models outperform the best tree kernel approach of the RTE challenges (Zanzotto and Moschitti, 2006) and also its extension that we proposed in (Zanzotto et al., 2009). These systems are also adaptable and easy to replicate, but they are subject to an exponential computational complexity and can thus only be used on very small datasets (e.g., they cannot be applied to the MSR Paraphrase corpus). In contrast, the model we proposed in this paper can be used on large datasets, because its kernel complexity is about linear (on average). We believe that disseminating these findings to the research community is very important, as it will foster research on RL, e.g., on RTE, using structural kernel methods. Such research has had a sudden stop as the RTE data in th</context>
</contexts>
<marker>Zanzotto, Pennacchiotti, Moschitti, 2009</marker>
<rawString>Fabio massimo Zanzotto, Marco Pennacchiotti, and Alessandro Moschitti. 2009. A machine learning approach to textual entailment recognition. Nat. Lang. Eng., 15(4):551–582, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>