<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001591">
<note confidence="0.439111">
Book Reviews Artificial Intelligence Techniques in Language Learning
</note>
<bodyText confidence="0.998109245614035">
and syntax networks is severed, they can no longer con-
strain each other. The result is a comprehension deficit
rather like that of certain agrammatic aphasic patients.
Cottrell&apos;s work in some ways resembles my own (Hirst
and Charniak 1982; Hirst 1987) and that of Waltz and
Pollack (1985). The most important difference is that this
other work tried to mix conventional symbolic approaches
together with connectionist-like spreading activation for
disambiguation. Waltz and Pollack, for example, use a
chart parser to build a network that represents the alterna-
tive parses of the input sentence. Activation is then spread
through the network, causing one of the parses and one
meaning of each ambiguous word to be chosen. My own
work started from the same psycholinguistic data as Cot-
trell&apos;s. However, lexical disambiguation was performed by
a set of parallel cooperating processes, one per word, which
drew on the results of spreading activation in a semantic
network as just one of several sources of knowledge for
disambiguation. Parsing and semantic interpretation were
purely symbolic.
As NLU systems go, Cottrell&apos;s is pretty dinky; it doesn&apos;t
do anything new. What&apos;s different and important about it is
how it does what it does. By using localist connectionist
networks for everything, Cottrell shows the potential of the
approach, and lays a foundation for the development of
non-dinky systems. However, the price paid for this is the
need to reinvent, almost from scratch, everything that
computational linguistics has done in the least 20 years. It
seems a little perverse to be slaving away, for example, on a
connectionist parser for simple sentences like Bob barfed
badly when highly sophisticated parsers and grammars are
already available.
The reply, of course, is that one day the connectionist
systems will outstrip anything that we have now; they&apos;ll be
faster and more elegant, and so natural that all known
principles of parsing and interpretation (and maybe a few
more) will be &amp;quot;emergent properties&amp;quot; of the systems. In
particular, symbolic systems have had great difficulty with
some of the fuzzier aspects of language understanding,
such as trading off conflicting preferences in the interpreta-
tion of an utterance, and such trade-offs are clearly a
strength of connectionism. But while recent research in
connectionist NLU suggests that useful systems may in-
deed be possible, it will remain for quite some time an
article of faith rather than science that such a research
program can be carried through to completion. It is books
like Cottrell&apos;s that help to sustain that faith.
Cottrell is excellent at analyzing the strengths and weak-
nesses of various approaches—his own and those of other
researchers—and his discussions of other research are a
valuable part of the book. It is also nice to see a book in
which the author can so honestly present the good and bad
points of his own work. Cottrell has an easy and breezy
writing style (with a whimsical canine leitmotif) that is
always clear and a pleasure to read. His book is an impres-
sive integration of Al, psycholinguistics, and neurolinguis-
tics, in the best traditions of cognitive science.
</bodyText>
<sectionHeader confidence="0.991508" genericHeader="abstract">
REFERENCES
</sectionHeader>
<reference confidence="0.974575153846154">
Gorfein, David, editor (1989). Resolving semantic ambiguity. NY:
Springer.
Hirst, Graeme (1987). Semantic interpretation and the resolution of
ambiguity. Cambridge: Cambridge University Press.
Hirst, Graeme and Charniak, Eugene (1982). &amp;quot;Word sense and case slot
disambiguation.&amp;quot; In Proceedings of the Second National Conference on
Artificial Intelligence (AAAI-82), Pittsburgh, August 1982, 95-98.
Rumelhart, David and McClelland, James (1986). Parallel distributed
Processing: Explorations in the microstructure of cognition. Cam-
bridge, MA: MIT Press.
Waltz, David and Pollack, Jordan (1985). &amp;quot;Massively parallel parsing: A
strongly interactive model of natural language interpretation.&amp;quot; Cogni-
tive Science, 9(1), 51-74.
</reference>
<footnote confidence="0.50732525">
Graeme Hirst once thought about becoming a connectionist, but
he&apos;s better now, thank you. Hirst&apos;s address is: Department of
Computer Science, University of Toronto, Toronto, Canada
M5S 1A4. E-mail: gh@cs.toronto.edu
</footnote>
<sectionHeader confidence="0.954865" genericHeader="keywords">
ARTIFICIAL INTELLIGENCE TECHNIQUES IN LANGUAGE
LEARNING
</sectionHeader>
<subsectionHeader confidence="0.871947">
Rex W. Last
</subsectionHeader>
<bodyText confidence="0.973620866666667">
(Department of Modern Languages, University of
Dundee)
Chichester, England: Ellis Horwood, 1989, 173 pp.
(Ellis Horwood series in computers and their applications)
Hardbound, ISBN 0-7458-0177-3 and 0-470-21503-8,
$64.95
Reviewed by
Camilla Schwind
Centre National de la Recherche Scientifique
This book is a state-of-the-art review of the techniques of
artificial intelligence in computer-assisted language learn-
ing (CALL). This is an extremely interesting subject,
which has up to now not been treated extensively in Al, nor
more especially in natural language understanding. The
book&apos;s objectives are:
</bodyText>
<listItem confidence="0.98959325">
• to examine the current developmental level of computer-
assisted language learning (from the point of view of the
in formed modern language teacher and researcher);
• to disentangle the present state of the art of artificial
intelligence as it relates to CALL;
• to establish the extent to which artificial intelligence
applications can be applied to the future development of
CALL.
</listItem>
<bodyText confidence="0.998754428571429">
First, a survey of CALL is given, explaining the how and
why cif the evolution of the field up to the present. The next
chapter, entitled &amp;quot;What is AI?&amp;quot; tries to &amp;quot;consider the
whole question of the nature of AI.&amp;quot; The rest of the book is
devoted to the presentation and discussion of several areas
of Al that the author considers relevant to CALL, such as
human/computer interfaces, knowledge representation, and
</bodyText>
<page confidence="0.752344">
242 Computational Linguistics Volume 16, Number 4, December 1990
</page>
<note confidence="0.286459">
Book Reviews Artificial Intelligence Techniques in Language Learning
</note>
<bodyText confidence="0.987872892561984">
expert systems. The book ends by considering possible
practical applications of Alto CALL and by presenting
some relevant and more recent developments in AI-related
CALL.
As pointed out by the author, this book is not written for
AI specialists but for modern language teachers. The moti-
vation to write this book was his observation that CALL
has not made any real advances, because the computer was
approached from an &amp;quot;amateur&amp;quot; viewpoint, lacking solid
theoretical background. He asserts, modestly enough, that
&amp;quot;what I have set out to achieve is to make the first faltering
step towards establishing the ground for possible advance,
as well as alerting the reader to both the difficulties and the
real dangers that may lie ahead&amp;quot; (p. 14). I think that Last&apos;s
analysis of the situation of CALL and his feelings about Al
are correct. But this is perhaps not sufficient to write a book
of 170 pages on AT techniques in language learning. So,
unfortunately, the objectives of the author are not attained.
In the second chapter (&amp;quot;The story so far&amp;quot;), no real
introduction to CALL or to humanities computing is given.
The parts of literary and linguistic computing and machine
translation contain rather unimportant and long explana-
tions on research organization, rather than investigating, as
announced by the chapter, the influence of humanities
computing to CALL. CALL developments are not really
presented in relation to the language analysis base of these
systems, and much space and time is lost on unimportant
environmental and organizational questions. For example,
we learn that many of the computing pioneers in language
and literature are Germanists, and many of them medieval-
ists at that, and why this is so (although no fundamental
reason is revealed). The other two objectives are no better
attained. Last&apos;s view of Al might be summarized in the
following sentence: &amp;quot;My approach has been one of cautious
inquiry in an area of investigation in which almost as much
effort appears to have been expended in the debate between
proponents of radically different perceptions of what Al
can (and in the view of some, ought to be allowed to)
achieve as in producing the actual research work itself&amp;quot; (p.
7). The author seems to me to give a poor evaluation of the
state of AT (and its subject areas), confusing the philosoph-
ical discussion about Al with the science of Al itself.
(Perhaps this discussion is part of AI—I will not debate
this here—but it is clear that it is not identical to Al.) I feel
that this is a very common misunderstanding, which is
perhaps due to the fact that such discussion is much more
exciting than the down-to-earth research work actually
produced by people working in the field. Thus, little is said
in this book about Al techniques (in spite of what might
have been expected from the title) and much about the
conception of the science of Al.
Although I agree with many feelings of the author with
regard to the unfounded promises made by some scientists
in our field, Last proves by many statements that his
discussion of Al is not founded on competence in the
underlying issues (in Al or in computer science). This is
most regrettable in a book about language learning and
teaching, because much could be said of the interest of Al
fields and techniques for CALL. Many of the author&apos;s
considerations appear to me to be wrong, superficial, irrele-
vant, or even ridiculous. For example:
So, non-AI programs, even though they may appear to
display some of the characteristics of &amp;quot;intelligence,&amp;quot; are
essentially deterministic, algorithm-based, and deal with
a closed problem domain which is completely lacking in
ambiguities and deals in black and white issues with no
shades of grey between. (p. 100)
Certainly, non-AI programs are not necessarily determinis-
tic. Moreover, why should nondeterminism be a criterion of
intelligence? One wonders what could be a program that is
not algorithm-based? Or:
AI is still an aspiration rather than an achievement and
should be applied with considerable caution in real
learning situations. (p. 130)
—whatever the first part of this sentence could mean!
But my main complaint about this book is the lack of
relevant material. The author seems to ignore most of the
Al work that is relevant to CALL. Not a single paper on Al
and CALL is cited (to give just two arbitrary examples:
Schuster 1986; Weischedel 1978). NLU is not even men-
tioned as one of the key aspects of Al for future CALL
developments! And the author&apos;s knowledge in this domain
seems to be exhausted by an allusion to ELIZA and
SHRDLU. More specific topics like anaphora resolution or
ambiguities in natural language analysis are addressed
without any allusion to relevant work in Al and NLU (see,
e.g., Hirst 1987; Webber 1980). Most of the highly interest-
ing and CALL-relevant Al subjects are not at all addressed
in this book: representation of (grammatical) knowledge,
natural language understanding, user modelling, discourse
analysis, error analysis. The book includes a discussion of
programming, but does not consider the question of which
programming language is best suited for parsing and error
analysis.
It is also regrettable that we do not learn anything about
the expectations of CALL with respect to Al. This should
have been addressed in Chapter 2 (on human/computer
interfaces) and in Chapter 8 (&amp;quot;From Theory to Practice&amp;quot;).
We might have expected a discussion of problems such as:
How should exercises be presented to students? What
possibilities are there of interaction for the students (com-
puter language, natural language, graphic interfaces, or a
mixture of all three)? Instead, we are given a discussion on
the sizes of chairs and tables! The topic addressed in
Section 8.3, &amp;quot;What kind of project?,&amp;quot; appears essential to
me and merits more than half a page. Much could be said
about the kind of exercises to set for students and how to
conceive them.
On the other hand, some topics addressed in this book do
not relate to CALL. No relation to CALL is shown for the
Computational Linguistics Volume 16, Number 4, December 1990 243
Book Reviews An Introduction to Chinese, Japanese and Korean Computing
Turing machine (the author asserts that it has never been
built!), nonstandard logics, or nonmonotonic reasoning.
The chapter on expert systems does not really explain what
an expert system is, nor how it works, nor how it could be
used by a CALL system. So these topics will be rather
confusing for the nonspecialists.
To conclude, it seems to me that this book will not
contribute to familiarizing language teachers with notions
of computer science and artificial intelligence.
</bodyText>
<sectionHeader confidence="0.960591" genericHeader="method">
REFERENCES
</sectionHeader>
<bodyText confidence="0.927102833333333">
Hirst, Graeme (1987). Semantic interpretation and the resolution of
ambiguity. Cambridge: Cambridge University Press.
Schuster, Ethel (1986). &amp;quot;The role of native grammars in correcting errors
in second language learning.&amp;quot; Computational Intelligence, 2, 93-98.
Webber, Bonnie (1980). A formal approach to discourse anaphora.
Doctoral dissertation, Harvard University. Published: NY: Garland.
Weischedel, Ralph M; Voge, Wilfried M.; and James, Mark (1978). &amp;quot;An
artificial intelligence approach to language teaching.&amp;quot; Artificial Intelli-
gence, 10, 225-240.
Camilla Schwind is a computer scientist at Centre National de la
Recherche Scientifique, working on natural language understand-
ing and nonclassical logics. In the last few years, her research has
concentrated on applying Al results, methods, and techniques to
computer-assisted language learning. She has conceived and im-
plemented a language tutoring system for German. Schwind&apos;s
address is: Groupe intelligence artificielle, Faculte des sciences de
Luminy, Case 901, 163 Avenue de Luminy, 13288 Marseille,
France.
</bodyText>
<sectionHeader confidence="0.9988595" genericHeader="method">
AN INTRODUCTION TO CHINESE, JAPANESE AND
KOREAN COMPUTING
</sectionHeader>
<bodyText confidence="0.936676333333333">
Jack K. T. Huang and Timothy D. Huang
(Ming Chuan College, Taiwan)
Singapore: World Scientific Publishing, 1989, xxi + 437
pp.
(Series in computer science, vol. 12)
Hardbound, ISBN 9971-50-664-5, $78.00
</bodyText>
<figure confidence="0.9799352">
Reviewed by
M. Martin Taylor
Defence and Civil Institute of Environmental Medicine
and
Insup Taylor
</figure>
<subsubsectionHeader confidence="0.540381">
University of Toronto
</subsubsectionHeader>
<bodyText confidence="0.998289859375">
Readers of Computational Linguistics who might have
been led by the title of this book to expect an introduction to
computational problems in the Chinese, Japanese, and
Korean languages will in fact find little of relevance. The
title is misleading: the book is not about Chinese, Japanese,
and Korean computing. It is almost entirely about the
problems of input, coding, and display of Chinese charac-
ters. It has a great deal to say about the nature and history
of Chinese characters, and about the problems of using
them in computation. It ignores the phonetic scripts used in
conjunction with characters in Japan and Korea, and dis-
cusses Chinese characters mainly from the perspective of
Taiwan rather than the People&apos;s Republic of China.
If you want to learn about Chinese characters, or to
develop computer systems for the Chinese market, you
should probably read this book, because it has a lot of
information on the subject. If not, you might like to read
the book for amusement, since rarely does such a personal,
egotistic, chauvinistic, and polemic book see the light of
day. (It is certainly rare for a book author to give himself
&amp;quot;ten thousand thanks&amp;quot; for his own work on a standardiza-
tion committee; and we do not accept the yin-yang—based
symbol of the I Ching as evidence that the Chinese invented
the fundamental theory of computation.)
Chapter 2, &amp;quot;About the Chinese language,&amp;quot; is actually
about Chinese characters rather than the language. This
chapter gives a good account of history, structure, and
sounds of characters, and includes many figures and tables.
Other chapters and several appendices give statistical data
on characters and phonetic symbols. These parts of the
book could be very useful to someone interested in the
details of Chinese character input, coding, and display.
The book is written in a &amp;quot;Chineselized&amp;quot; version of En-
glish (to use a word much favored by the authors). It would
have benefited greatly from a reading by an English-
speaking copyeditor, and a typographer should have been
consulted about the design. The content should also have
been checked more carefully, as illustrated by Rule 3 of the
Dai-E coding method, the complete text of which is: &amp;quot;If the
character is comprised of a container without another
radical, then rule 3 will not apply&amp;quot; (p. 137).
In Chapter 7, the book goes beyond Chinese I/O to
consider Chinese programming languages and operating
systems, though the authors seem to have some misconcep-
tions about what is available to non-Chinese speakers.
&amp;quot;Total control of a given computer system means that the
human users must be able to communicate with the com-
puter system in their human native language without hin-
dera nce [sic]&amp;quot; (p. 253). &amp;quot;Could you imagine English speak-
ing people having to write their programs in another
language? What would the result be?&amp;quot; (p. 254). &amp;quot;It is not
an English operating system, if it cannot communicate with
the user in plain English&amp;quot; (p. 255). Readers of Computa-
tional Linguistics will presumably now step up their re-
search so that they can develop the first English operating
system.
FORTH is the sole programming language that merits
the authors&apos; approval, seemingly because it emulates Chi-
nese philosophy:
The second similarity between Chinese philosophy and
FORTH can be found in the dual functions of the
FORTH interpreter/compiler. The FORTH interpreter
is an interpretive compiler as well as compilative inter-
preter. It is one of two, two of one. This is similar to
</bodyText>
<page confidence="0.90958">
244 Computational Linguistics Volume 16, Number 4, December 1990
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.037520">
<title confidence="0.988596">Book Reviews Artificial Intelligence Techniques in Language Learning</title>
<abstract confidence="0.998879105263158">and syntax networks is severed, they can no longer constrain each other. The result is a comprehension deficit rather like that of certain agrammatic aphasic patients. Cottrell&apos;s work in some ways resembles my own (Hirst and Charniak 1982; Hirst 1987) and that of Waltz and Pollack (1985). The most important difference is that this other work tried to mix conventional symbolic approaches together with connectionist-like spreading activation for disambiguation. Waltz and Pollack, for example, use a chart parser to build a network that represents the alternative parses of the input sentence. Activation is then spread through the network, causing one of the parses and one meaning of each ambiguous word to be chosen. My own started from the same psycholinguistic data as Cottrell&apos;s. However, lexical disambiguation was performed by a set of parallel cooperating processes, one per word, which drew on the results of spreading activation in a semantic network as just one of several sources of knowledge for disambiguation. Parsing and semantic interpretation were purely symbolic. As NLU systems go, Cottrell&apos;s is pretty dinky; it doesn&apos;t do anything new. What&apos;s different and important about it is does what it does. By using localist connectionist networks for everything, Cottrell shows the potential of the approach, and lays a foundation for the development of non-dinky systems. However, the price paid for this is the need to reinvent, almost from scratch, everything that computational linguistics has done in the least 20 years. It seems a little perverse to be slaving away, for example, on a parser for simple sentences like barfed highly sophisticated parsers and grammars are already available. The reply, of course, is that one day the connectionist systems will outstrip anything that we have now; they&apos;ll be faster and more elegant, and so natural that all known principles of parsing and interpretation (and maybe a few more) will be &amp;quot;emergent properties&amp;quot; of the systems. In particular, symbolic systems have had great difficulty with some of the fuzzier aspects of language understanding, as trading off conflicting preferences in the interpretation of an utterance, and such trade-offs are clearly a strength of connectionism. But while recent research in NLU suggests that useful systems may indeed be possible, it will remain for quite some time an article of faith rather than science that such a research program can be carried through to completion. It is books like Cottrell&apos;s that help to sustain that faith. Cottrell is excellent at analyzing the strengths and weaknesses of various approaches—his own and those of other researchers—and his discussions of other research are a valuable part of the book. It is also nice to see a book in which the author can so honestly present the good and bad points of his own work. Cottrell has an easy and breezy writing style (with a whimsical canine leitmotif) that is always clear and a pleasure to read. His book is an impressive integration of Al, psycholinguistics, and neurolinguistics, in the best traditions of cognitive science.</abstract>
<note confidence="0.885359235294118">REFERENCES David, editor (1989). semantic ambiguity. Springer. Graeme (1987). interpretation and the resolution of Cambridge University Press. Hirst, Graeme and Charniak, Eugene (1982). &amp;quot;Word sense and case slot In of the Second National Conference on Intelligence Pittsburgh, August 1982, 95-98. David and McClelland, James (1986). distributed Explorations in the microstructure of cognition. Cam- MA: Waltz, David and Pollack, Jordan (1985). &amp;quot;Massively parallel parsing: A interactive model of natural language interpretation.&amp;quot; Cogni- Science, 51-74. Hirst thought about becoming a connectionist, but he&apos;s better now, thank you. Hirst&apos;s address is: Department of Computer Science, University of Toronto, Toronto, Canada</note>
<email confidence="0.963538">M5S1A4.E-mail:gh@cs.toronto.edu</email>
<title confidence="0.878694">ARTIFICIAL INTELLIGENCE TECHNIQUES IN LANGUAGE LEARNING</title>
<author confidence="0.99971">Rex W Last</author>
<affiliation confidence="0.9038725">(Department of Modern Languages, University of Dundee)</affiliation>
<address confidence="0.883291">Chichester, England: Ellis Horwood, 1989, 173 pp.</address>
<note confidence="0.95076675">(Ellis Horwood series in computers and their applications) Hardbound, ISBN 0-7458-0177-3 and 0-470-21503-8, $64.95 Reviewed by</note>
<author confidence="0.928093">Camilla Schwind</author>
<affiliation confidence="0.874515">Centre National de la Recherche Scientifique</affiliation>
<abstract confidence="0.990497951219513">This book is a state-of-the-art review of the techniques of artificial intelligence in computer-assisted language learning (CALL). This is an extremely interesting subject, which has up to now not been treated extensively in Al, nor more especially in natural language understanding. The book&apos;s objectives are: • to examine the current developmental level of computerassisted language learning (from the point of view of the in formed modern language teacher and researcher); • to disentangle the present state of the art of artificial intelligence as it relates to CALL; • to establish the extent to which artificial intelligence applications can be applied to the future development of CALL. First, a survey of CALL is given, explaining the how and why cif the evolution of the field up to the present. The next chapter, entitled &amp;quot;What is AI?&amp;quot; tries to &amp;quot;consider the whole question of the nature of AI.&amp;quot; The rest of the book is devoted to the presentation and discussion of several areas of Al that the author considers relevant to CALL, such as human/computer interfaces, knowledge representation, and 242 Computational Linguistics Volume 16, Number 4, December 1990 Book Reviews Artificial Intelligence Techniques in Language Learning expert systems. The book ends by considering possible practical applications of Alto CALL and by presenting some relevant and more recent developments in AI-related CALL. As pointed out by the author, this book is not written for AI specialists but for modern language teachers. The motivation to write this book was his observation that CALL has not made any real advances, because the computer was approached from an &amp;quot;amateur&amp;quot; viewpoint, lacking solid theoretical background. He asserts, modestly enough, that &amp;quot;what I have set out to achieve is to make the first faltering step towards establishing the ground for possible advance, as well as alerting the reader to both the difficulties and the real dangers that may lie ahead&amp;quot; (p. 14). I think that Last&apos;s analysis of the situation of CALL and his feelings about Al are correct. But this is perhaps not sufficient to write a book of 170 pages on AT techniques in language learning. So, unfortunately, the objectives of the author are not attained.</abstract>
<intro confidence="0.672504">In the second chapter (&amp;quot;The story so far&amp;quot;), no real</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>Resolving semantic ambiguity.</title>
<date>1989</date>
<editor>Gorfein, David, editor</editor>
<publisher>NY: Springer.</publisher>
<marker>1989</marker>
<rawString>Gorfein, David, editor (1989). Resolving semantic ambiguity. NY: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Semantic interpretation and the resolution of ambiguity. Cambridge:</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<marker>Hirst, 1987</marker>
<rawString>Hirst, Graeme (1987). Semantic interpretation and the resolution of ambiguity. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>Eugene Charniak</author>
</authors>
<title>Word sense and case slot disambiguation.&amp;quot;</title>
<date>1982</date>
<booktitle>In Proceedings of the Second National Conference on Artificial Intelligence (AAAI-82),</booktitle>
<pages>95--98</pages>
<location>Pittsburgh,</location>
<marker>Hirst, Charniak, 1982</marker>
<rawString>Hirst, Graeme and Charniak, Eugene (1982). &amp;quot;Word sense and case slot disambiguation.&amp;quot; In Proceedings of the Second National Conference on Artificial Intelligence (AAAI-82), Pittsburgh, August 1982, 95-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Rumelhart</author>
<author>James McClelland</author>
</authors>
<title>Parallel distributed Processing: Explorations in the microstructure of cognition.</title>
<date>1986</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Rumelhart, McClelland, 1986</marker>
<rawString>Rumelhart, David and McClelland, James (1986). Parallel distributed Processing: Explorations in the microstructure of cognition. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Waltz</author>
<author>Pollack</author>
</authors>
<title>Massively parallel parsing: A strongly interactive model of natural language interpretation.&amp;quot;</title>
<date>1985</date>
<journal>Cognitive Science,</journal>
<volume>9</volume>
<issue>1</issue>
<pages>51--74</pages>
<marker>Waltz, Pollack, 1985</marker>
<rawString>Waltz, David and Pollack, Jordan (1985). &amp;quot;Massively parallel parsing: A strongly interactive model of natural language interpretation.&amp;quot; Cognitive Science, 9(1), 51-74.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>