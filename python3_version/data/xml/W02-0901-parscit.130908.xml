<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.017214">
<note confidence="0.988246666666667">
Unsupervised Lexical Acquisition: Proceedings of the Workshop of the
ACL Special Interest Group on the Lexicon (SIGLEX), Philadelphia,
July 2002, pp. 1-8. Association for Computational Linguistics.
</note>
<bodyText confidence="0.998884666666667">
dictionaries available, and it is very difficult
to obtain lexical resources for other domains.
We concluded that the correct recognition of
probable real words is very important not only
to build a domain-specific dictionary but also
to augment an existing general dictionary.
Based on the analyses of large collections of
documents, we classify out-of-vocabulary words
into the following categories.
</bodyText>
<listItem confidence="0.99916225">
• derived words
• new words
• proper nouns
• non-word strings
</listItem>
<bodyText confidence="0.999991112903226">
We address the problems of the recognition of
real words and of guessing their POS on the
basis of the types of out-of-vocabulary words.
Derived words are morphological variations
of words already known to the lexicon, mostly
by means of affixation, i.e., adding prefixes to
the beginning of words or suffixes to the end,
and by means of compounding, i.e., two or
more words are written as one word (Pickett et
al., 1996). New words mean the words that
can not be produced by the derivation (or word
formation) rules from the existing words of
the language. Many domain-specific technical
terms belong to this category. Proper nouns are
mostly person names and place nouns. We also
consider upper case and non-initial mixed case
words as proper nouns. Non-word strings mean
alphabetic strings together with non-alphabetic
characters such as numeric characters and other
special characters. In this work, we don&apos;t take
into account proper nouns and non-word strings
because they are not valuable to be kept in dic-
tionaries. Thus, in this work, out-of-vocabulary
words are classified into two categories - derived
words and new words.
The overall process for identifying real words
and for producing lexical information is as
follows. First, we remove all proper names and
non-word strings from the document collection.
It is easy to recognize non-word strings and
upper case and non-initial mixed case words.
In addition to the capitalization feature, we
use a precompiled names database (Ravin
et al., 1997) for recognizing person names
and place names. If a word exists in the
database, we consider it as a proper noun.
Second, we look up all the remaining words in
the document collection in a general purpose
English dictionary built by IBM (IBM, 2001)
and collect all the out-of-vocabulary words, i.e.,
words unknown to the dictionary, and their
frequencies in the collection. Third, we discard
words which appear only once in the collection.
Fourth, we check if an out-of-vocabulary word
is comprised of existing words in the dictionary
and/or morphological units such as a prefix
and a suffix. If this process succeeds, possible
parts-of-speech of the word are generated based
on the morphological rules applied to produce
the word. Fifth, if this process fails, we judge
if the word may be a new word on the basis
of entropy of the probability of its character
trigrams and guess its parts-of-speech from its
ending characters.
The rest of this paper is structured as fol-
lows. We present morphological rule-based ap-
proach in section 2 and entropy-based approach
in section 3. In section 4, we show experimen-
tal results and evaluate the performance of the
proposed method. Previous related work is de-
scribed in Section 5. Finally, we describe possi-
ble future improvements in section 6.
</bodyText>
<sectionHeader confidence="0.950218" genericHeader="abstract">
2 Morphological Rule Approach
</sectionHeader>
<bodyText confidence="0.999960838709677">
This approach performs the recognition and
POS guessing processes for out-of-vocabulary
words given that the sub-components of the
words are already known. There are three
types of morphological variations - words with
prefixes, words with suffixes, and compound
words. For words with prefixes or suffixes, we
use pre-collected sets of prefixes and suffixes
for English - currently containing 75 prefixes
and 76 suffixes. For compound words, we try
to divide an out-of-vocabulary word into two
possible existing words.
The process for prefixed words is as follows.
First, the system checks if any of the prefixes
in the prefix list appears at the beginning of
the word. If a word contains a prefix, then the
system chops the prefix off the word and looks
up the remaining part (the root word) in the
dictionary. We set the minimum length of a
root word to two characters. If the dictionary
contains the root word, the out-of-vocabulary
word is regard as a real word, and the word
inherits the lexical information of the root
word. For example, antiasthmatic, autoinjector,
electrocardiography, and hypothyroidism are
discovered by the prefix process.
The processing for suffixes is more compli-
cated. We have a rule set for suffixes, which
describes the pre-conditional POS of a root word
for having a specific suffix and the resulting POS
condition. The suffix rule structure is as follows.
</bodyText>
<equation confidence="0.940033">
[suffix, { precondition-POS —&gt; result-POS }*]
</equation>
<bodyText confidence="0.998616923076923">
For instance, the rule for suffix able is [able,
{VB —&gt; JJ}, {NN —&gt; JJ}]. This means, a verb
or a noun may have suffix able at the end of the
word, and the resulting word&apos;s part-of-speech
is an adjective. If a word contains a suffix,
the system removes the suffix and recovers
the root word. In English, when a suffix is
added to a word, it may change spelling in the
root word. For instance, words ending with
a silent e usually drop the e before a suffix
beginning with a vowel. An example of this
case is browsable. The final e of browse was
dropped as a result of adding able. Thus, after
separating a suffix from the root word, we
recover the original form of the root word by
using linguistic information. If the recovered
root word is found in the dictionary and it has
one of the preconditioned POS, then the word
is regarded as a real word and it has the result
POS of the rule. Some examples of this case are
migraniotts, oxidizability and ventilatory. Some
words, for example, remanufacturability, may
have a prefix and a suffix together. In this case,
the word goes through both processes explained
above.
If a word fails both the prefix processing and
the suffix processing, it is considered for the
compound processing. If a word consists of two
content words which are known to the lexicon,
and their parts-of-speech are one of the prede-
termined combinations, it is considered as a real
word and has the second component&apos;s part-of-
speech. The possible combinations of words are
Noun+Noun, Noun+Participle form of verbs. If
a word is composed of two words but does not
belong to the possible combinations, the word
is discarded. Some examples of the compound
words are eyedrops, photophobia, stereoselectiv-
ity, airbreathing, and doubleblinded
</bodyText>
<sectionHeader confidence="0.993691" genericHeader="categories and subject descriptors">
3 Entropy Approach
</sectionHeader>
<subsectionHeader confidence="0.999731">
3.1 Identification of new words
</subsectionHeader>
<bodyText confidence="0.993633126984127">
Human beings can very successfully guess
whether a word never seen before is a possible
real word or not, even though the word is
not comprised of already known words. We
assume that human beings may conclude that
a word is a possible word of the language,
if the character sequences in the word look
probable, and it is natural to pronounce. We
base the recognition of non-derivational new
words on this assumption. That is, this method
is based on the prediction of a language; how
well can the next letter of a text be predicted
when the preceding n letters are known (see,
Shannon, 1951 for more extensive description
of estimating the entropy and redundancy of a
language).
A word is a cohesive group of letters with
strong internal statistical influences (Shannon,
1951). We regard a string as a possible real
word if every letter in the string is likely to
co-occur with its neighbors. That is, if the
letters in a word have high chances to occur in
their position given the preceding characters
have been seen (i.e., an n-gram model), the
word is regarded as a real word. More formally,
we compute entropy of the probabilities of
n-gram sequences in an out-of-vocabulary word,
and if the entropy value is high, we conclude the
word is a real word. In this work, the neighbors
of a character are defined as the two preceding
characters, i.e., a trigram model.
The probability of a character, c3, given the
two characters preceding it, cl, c2, is estimated
as in Equation 1.
f (cle2)
In this equation, f (cic2c3) denotes the number
of times the sequence of characters {c1, c2, c3}
is observed and f(c1c2) denotes the number
of times the sequence {c1, c2} is observed in
a training corpus. In this work, we produce
training data by generating all the possible
forms (base forms and inflectional forms) of
the words in our dictionary (IBM, 2001). The
training data consist of 81,274 words.
To estimate the trigram probabilities, we add
one leading space and one trailing space to every
word, making a 28 letter alphabet. That is, for
a word w with n characters, Cl c2 • • • cri, we add
a leading space (co), and an trailing space (cn+i)
and generate w = co c1 c2 • • • cn Cn+1. Then,
we produce all the two character sequences,
co cl, • • • , cn cn+i, and the three character
sequences, co Cl c2, • • • , cn—i cn cn+i, and count
their frequencies in the training data. At last,
we compute the probabilities of all the possible
trigrams by using Equation 1 and store them in
a look-up table.
To compute entropy of an out-of-vocabulary
word, w = Cl c2 • • • C. we add a leading space
(co) and a trailing space (cn+i) to the word and
divide it into trigrams and search each trigram
in the look-up table. The entropy of a word w,
H(w), is defined as in Equation 2.
</bodyText>
<equation confidence="0.95474275">
1(w) = —1092 P(cilci—i, Ci-2)
n+1
H(w) = E P( c,I C,-1, c,-2)/(w) (2)
i=2
</equation>
<listItem confidence="0.997403">
• the number of unknown trigrams2 is less
than a threshold value, 01
• the entropy of a word is greater than a
threshold value, 02
</listItem>
<bodyText confidence="0.9977212">
Currently, 01 is set to 2 if the length of a word
is less than or equal to 10 and set to 3 if the
length is greater than 10. 02 is set to 2.3, which
was determined from the average entropy minus
the minimum entropy of the training data.
</bodyText>
<subsectionHeader confidence="0.997927">
3.2 POS guessing for new words
</subsectionHeader>
<bodyText confidence="0.999328933333334">
In addition to identifying probable new words,
this system produces possible parts-of-speech
of the words. We adopt the ending guessing
method described in Mikheev (1997) for this
purpose. We collect the ending guessing rules
from the training data described in section 3.1.
For all the words in the training data, we gen-
erate all possible endings from length 1 up to
length 5, together with the parts-of-speech of
the words. We set the minimum length of the
remaining part to 3. Table 1 shows how ending
guessing rules are generated from our training
data. Throughout this paper, POS tags are rep-
resented by Penn Treebank Tag code (Marcus
and Santorini, 1993).
</bodyText>
<table confidence="0.999595083333333">
word ailments mounting
Ending ments NNS nting NN nting VBG
Rules ents NNS ting NN ting VBG
nts NNS ing NN ing VBG
ts NNS ng NN ng VBG
s NNS g NN g VBG
word abandons primary
Ending ndons VBZ mary NN mary JJ
Rules dons VBZ ary NN ary JJ
ons VBZ ry NN ry JJ
ns VBZ y NN y JJ
s VBZ
</table>
<tableCaption confidence="0.999899">
Table 1: Examples of Ending Guessing Rules
</tableCaption>
<bodyText confidence="0.999890428571429">
All the ending rules and their frequencies are
collected from the training data, and infrequent
rules (frequency = 1) are discarded from the rule
set. The rule set contains 12,387 rules, and the
most frequent 50 rules are as shown in Table 2.
The numbers in parentheses denote the frequen-
cies of the rules.
</bodyText>
<equation confidence="0.998958">
P(c3lci, c2) = f (cle2c3)
(1)
</equation>
<bodyText confidence="0.922929">
If a given word satisfies the following two con-
ditions, it is regarded as a possible real word.
</bodyText>
<footnote confidence="0.707899">
2trigrams which are not shown in the training data
</footnote>
<figure confidence="0.98270984">
500 1000 1500 2000 2500 3000 3500 4000
number of documents
8000
7000
6000
number of OOV
5000
4000
3000
2000
1000
0
90000
80000
70000
frequency of OOV
60000
50000
40000
30000
20000
10000
0
500 1000 1500 2000 2500 3000 3500 4000
number of documents
</figure>
<table confidence="0.7549434">
00V Type Count
Affixation 443
compound 85
new word 2287
Misc. 1372
</table>
<tableCaption confidence="0.843055">
Table 3: Types of out-of-vocabulary words in
the MEDLINE collection
</tableCaption>
<bodyText confidence="0.999802657142857">
real words, and 1,372 words are not real words
(see, Table 4). In order to verify the system&apos;s
judgment, we have conducted two verification
processes. At first, we looked up all out-of-
vocabulary words in a medical dictionary. We
used the on-line version of the Merriam-Webster
medical dictionary4 for this purpose. Then,
for words which do not exist in the medical
dictionary (we assume they are mostly non-
medical words), the human judges (non-domain
experts) decided whether they are probable
English words or not by referencing an on-line
English dictionary5. If an out-of-vocabulary
word appears in one of the two dictionaries, we
regard it as a real word.
We developed a Perl (Wall and Schwartz,
1992) script program to automate the dictio-
nary look-up processes. This program performs
dictionary look-up with a URL and a word
without any human intervention. It accesses a
webpage of the given URL, and performs search
with the given word, and returns the webpage of
the search result. Then, it parses the returned
webpage and decides if a word was found or not.
Table 4 shows the result of this experiment.
The first column (Dictionary Lookup-Yes) de-
notes the number of the words found in one of
the dictionaries, and the second column (Dic-
tionary Lookup-No) denotes the number of the
words which don&apos;t exist in any of the dictionar-
ies. The first row (System Guess-Yes) denotes
the number of the words which the system con-
sidered as real words, and the second row (Sys-
tem Guess-No) is the number of the words which
the system regarded as invalid words.
</bodyText>
<table confidence="0.998891">
Dictionary LookUp SUM
Yes No
System Yes 2341 474 2815
Guess No 579 793 1372
SUM 2920 1267 4187
</table>
<tableCaption confidence="0.999629">
Table 4: Performance of Experiments
</tableCaption>
<bodyText confidence="0.887045">
The performance of this system on the med-
</bodyText>
<equation confidence="0.95497675">
line collection is as follows.
precision = 83.16%
recall = 80.17%
F — measure = 81.64%
</equation>
<bodyText confidence="0.993260888888889">
However, many of the samples that the sys-
tem decided real words but were not found in
the dictionary (System Guess-Yes and Dictio-
nary Lookup-No) are actually real words. This is
because the dictionary used for this experiment
is also limited. Some examples of the words —
mostly biology terminology and drug/treatment
names — are aggregometry, cardiomyocyte, col-
forsin, nondihydropyridine, nylestriol.
</bodyText>
<sectionHeader confidence="0.999444" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.99968695">
There has been a great effort to address this
problem, especially in the areas of POS taggers
and speech recognition. However, different
applications recognize the problem of out-of-
vocabulary words in different perspectives and
have different goals. For POS taggers and
parsers, which rely on lexical (syntactic) infor-
mation about words, the goal is to guess the
most plausible part-of-speech and other lexical
information of an out-of-vocabulary word in
a context. Dermatas and Kokkinakis (1995)
estimated the probability that an unknown
word has a particular POS tag from the
probability distribution of words which occur
only once in the previously seen texts. More
advanced POS guessing methods use leading
and trailing word segments to determine pos-
sible tags for unknown words. Weischedel et
al. (1993) proposed a POS guessing method for
unknown words by using the probability for an
</bodyText>
<footnote confidence="0.999636">
4http://www.intelihealth.com/IH/ihtIH/WSIHWO00/9276/9276.h1W(nown word to be of a particular POS tag,
5http://www.dictionary.com given its capitalization feature and its ending.
</footnote>
<bodyText confidence="0.999968235294118">
Brill (1995) describes a system of rules which
uses both end-guessing and more morphologi-
cally motivated rules. Mikheev (1997) presents
a technique for fully automatic acquisition
of rules which guesses possible POS tags for
unknown words using their starting and ending
segments. For speech recognition systems, an
out-of-vocabulary(00V) word is either a word
unknown to the system vocabulary or a word
that the recognizer fails to recognize. The
goal is to find the closest word (in terms of
sound and meaning) to the 00V word from the
system&apos;s vocabulary.
Character ngram-based statistical approaches
have been used in word-level language process-
ing such as spelling correction (Angell et al.,
1983), word segmentation (Juola et al., 1994),
and language identification (Dunning, 1994).
Angell, Freund and Willett (1983) describe a
method of comparing misspellings with dictio-
nary terms based on the number of trigrams
that the two strings have in common, using
Dice&apos;s similarity coefficient as the measure of
similarity. The misspelled word is replaced by
the word in the dictionary which best matches
the misspelling. Juola, Hall and Boggs (1994)
describes a system which segments full words
into their constituent morphemes based on en-
tropy of the probabilities of trigram sequences.
Dunning (1994) implements a high accuracy
language identification using character n-gram
models and a Bayesian classifier. The perfor-
mance of the n-gram language classifier is eval-
uated using different size of n-grams.
</bodyText>
<sectionHeader confidence="0.999532" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.964869794871795">
We have developed an approach to augmenting
a morphological lexicon with new words such as
newly derived words and domain-specific tech-
nical words through text analysis of document
collections. For morphologically derived words,
we have employed morphological rule-base
methods such as affixations and compound
words. We have also proposed a new technique
to identify non-derivational new words based
on entropy of the probabilities of trigram se-
quences. The probabilities of trigram sequences
are trained on an existing English dictionary.
Some possible improvements and future plans
are as follows.
1. The rules used for compound word process
is over-generalized. For example, all the
combinations of two nouns may not be com-
pound nouns. We anticipate the perfor-
mance will be improved if we incorporate
a corpus statistics-based compound word
processing scheme into the existing method.
2. The performance will be improved if we in-
clude domain-specific prefixes and suffixes
such as amino, branch°, and cardio.
3. We trained our entropy model on a general-
purpose dictionary. However, many med-
ical and biotechnological terms have their
origin in Latin. We expect the perfor-
mance would be better if we train our sys-
tem by using a domain-specific lexicon or a
tagged (specified if a word is correct or not)
domain-specific corpus.
4. We expect it is not difficult to apply this ap-
proach to other languages because this sys-
tem only uses basic morphological rules of a
language and language-independent statis-
tical information. In addition, it does not
require a large amount of annotated train-
ing data.
</bodyText>
<sectionHeader confidence="0.978924" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9996935">
I am grateful to Marco Gruteser for the devel-
opment of the Perl script for the evaluation of
this work. I also thank anonymous reviewers for
their helpful comments.
</bodyText>
<sectionHeader confidence="0.997464" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9145225">
R. Angell, G. Freund, and P. Willett. 1983. Auto-
matic spelling correction using a trigram similar-
ity measure. Information Processing and Manage-
ment, 19(4):255-261.
Eric Brill. 1995. Transformation-based error-driven
learning and natural language processing: A case
</reference>
<bodyText confidence="0.9869628">
study in part of speech tagging. Computational
Linguistics, 21(4):543-565.
Ralph Weischedel, Marie Meeter, Richard Schwartz,
Lance Ramshaw, and Jeff Palmucci. 1993. Cop-
ing with ambiguity and unknown words through
probabilistic models. Computational Linguistics,
(2):359-382.
Evangelos Dermatas and George Kokkinakis. 1995.
Automatic stochastic tagging of natural language
texts. Computational Linguistics, 21(2):137-164.
</bodyText>
<reference confidence="0.989990261904762">
Ted Dunning. 1994. Statistical identification of
language. Technical Report CRL MCCS 94-273i,
New Mexico State University.
Florian Gallwitz, Elmar Noeth, and Heinrich Nie-
mann. 1996. A category based approach for recog-
nition of out-of-vocabulary words. Proceedings
of International Conference on Spoken Language
Processing, 1:228-231.
Timothy J. Hazen and Bazzi Issam. 2001. A com-
parison and combination of methods for oov word
detection and word confidence scoring. Proceed-
ings of ICASSP.
IBM. 2001. Dictionary and linguistic tools.
http://booksryl.raleigh.ibm.com/lingtool.
Patrik Juola, Chris Hall, and Adam Boggs. 1994.
Corpus based morphological segmentation by en-
tropy changes. Proceedings of the 3rd Interna-
tional Conference on the Cognitive Science of Nat-
ural Language Processing.
Mitch Marcus and Marcinkiewicz B. Santorini. 1993.
Building a large annotated corpus of english:
the penn treebank. Computational Linguistics,
19(2):313-330.
Andrei Mikheev. 1997. Automatic rule induction for
unknown word guessing. Computational Linguis-
tics, 23(3):405-423.
Youngja Park, Roy J. Byrd, and Branimir K. Bogu-
raev. 2002. Automatic glossary extraction: Be-
yond terminology identification. IBM Research
Technical Report, RC22421.
Joseph Pickett et al. 1996. The american heritage
book of english usage: A practical and anthori-
tative guide to contemporary english. Houghton
Mifflin Company.
Yael Ravin, Nina Wacholder, and Misook Choi.
1997. Disambiguation of proper names in text.
17th Annual ACM-SIGIR Conference.
Claude E. Shannon. 1951. Prediction and entropy of
printed english. The Bell System Technical Jour-
nal, January:50-64.
Larry Wall and Randal L. Schwartz. 1992. Program-
ming perl. O&apos;Reilly &amp; Associates, Inc.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000002">
<note confidence="0.763145">Unsupervised Lexical Acquisition: Proceedings of the Workshop of the ACL Special Interest Group on the Lexicon (SIGLEX), Philadelphia,</note>
<abstract confidence="0.990228924528301">July 2002, pp. 1-8. Association for Computational Linguistics. dictionaries available, and it is very difficult to obtain lexical resources for other domains. We concluded that the correct recognition of probable real words is very important not only to build a domain-specific dictionary but also to augment an existing general dictionary. Based on the analyses of large collections of documents, we classify out-of-vocabulary words into the following categories. • derived words • new words • proper nouns • non-word strings We address the problems of the recognition of real words and of guessing their POS on the basis of the types of out-of-vocabulary words. Derived words are morphological variations of words already known to the lexicon, mostly by means of affixation, i.e., adding prefixes to the beginning of words or suffixes to the end, and by means of compounding, i.e., two or words are written as one word (Pickett New words mean the words that can not be produced by the derivation (or word formation) rules from the existing words of the language. Many domain-specific technical terms belong to this category. Proper nouns are mostly person names and place nouns. We also consider upper case and non-initial mixed case words as proper nouns. Non-word strings mean alphabetic strings together with non-alphabetic characters such as numeric characters and other special characters. In this work, we don&apos;t take into account proper nouns and non-word strings because they are not valuable to be kept in dictionaries. Thus, in this work, out-of-vocabulary words are classified into two categories derived words and new words. The overall process for identifying real words and for producing lexical information is as follows. First, we remove all proper names and non-word strings from the document collection. It is easy to recognize non-word strings and upper case and non-initial mixed case words. In addition to the capitalization feature, we use a precompiled names database (Ravin et al., 1997) for recognizing person names and place names. If a word exists in the database, we consider it as a proper noun. Second, we look up all the remaining words in the document collection in a general purpose English dictionary built by IBM (IBM, 2001) and collect all the out-of-vocabulary words, i.e., words unknown to the dictionary, and their frequencies in the collection. Third, we discard words which appear only once in the collection. Fourth, we check if an out-of-vocabulary word is comprised of existing words in the dictionary and/or morphological units such as a prefix and a suffix. If this process succeeds, possible parts-of-speech of the word are generated based on the morphological rules applied to produce the word. Fifth, if this process fails, we judge if the word may be a new word on the basis of entropy of the probability of its character trigrams and guess its parts-of-speech from its ending characters. The rest of this paper is structured as follows. We present morphological rule-based approach in section 2 and entropy-based approach in section 3. In section 4, we show experimental results and evaluate the performance of the proposed method. Previous related work is described in Section 5. Finally, we describe possible future improvements in section 6. 2 Morphological Rule Approach This approach performs the recognition and POS guessing processes for out-of-vocabulary words given that the sub-components of the words are already known. There are three types of morphological variations words with prefixes, words with suffixes, and compound words. For words with prefixes or suffixes, we use pre-collected sets of prefixes and suffixes for English currently containing 75 prefixes and 76 suffixes. For compound words, we try to divide an out-of-vocabulary word into two possible existing words. The process for prefixed words is as follows. First, the system checks if any of the prefixes in the prefix list appears at the beginning of the word. If a word contains a prefix, then the system chops the prefix off the word and looks up the remaining part (the root word) in the dictionary. We set the minimum length of a root word to two characters. If the dictionary contains the root word, the out-of-vocabulary word is regard as a real word, and the word inherits the lexical information of the root For example, autoinjector, discovered by the prefix process. The processing for suffixes is more complicated. We have a rule set for suffixes, which describes the pre-conditional POS of a root word for having a specific suffix and the resulting POS condition. The suffix rule structure is as follows. { }*] instance, the rule for suffix is [able, {VB —&gt; JJ}, {NN —&gt; JJ}]. This means, a verb a noun may have suffix the end of the word, and the resulting word&apos;s part-of-speech is an adjective. If a word contains a suffix, the system removes the suffix and recovers the root word. In English, when a suffix is added to a word, it may change spelling in the root word. For instance, words ending with silent drop the a suffix beginning with a vowel. An example of this is final as a result of adding after separating a suffix from the root word, we recover the original form of the root word by using linguistic information. If the recovered root word is found in the dictionary and it has one of the preconditioned POS, then the word is regarded as a real word and it has the result POS of the rule. Some examples of this case are oxidizability for example, have a prefix and a suffix together. In this case, the word goes through both processes explained above. If a word fails both the prefix processing and the suffix processing, it is considered for the compound processing. If a word consists of two content words which are known to the lexicon, and their parts-of-speech are one of the predetermined combinations, it is considered as a real word and has the second component&apos;s part-ofspeech. The possible combinations of words are Noun+Noun, Noun+Participle form of verbs. If a word is composed of two words but does not belong to the possible combinations, the word is discarded. Some examples of the compound are photophobia, stereoselectivairbreathing, 3 Entropy Approach 3.1 Identification of new words Human beings can very successfully guess whether a word never seen before is a possible real word or not, even though the word is not comprised of already known words. We assume that human beings may conclude that a word is a possible word of the language, if the character sequences in the word look probable, and it is natural to pronounce. We base the recognition of non-derivational new words on this assumption. That is, this method is based on the prediction of a language; how well can the next letter of a text be predicted when the preceding n letters are known (see, Shannon, 1951 for more extensive description of estimating the entropy and redundancy of a language). A word is a cohesive group of letters with strong internal statistical influences (Shannon, 1951). We regard a string as a possible real word if every letter in the string is likely to co-occur with its neighbors. That is, if the letters in a word have high chances to occur in their position given the preceding characters have been seen (i.e., an n-gram model), the word is regarded as a real word. More formally, we compute entropy of the probabilities of n-gram sequences in an out-of-vocabulary word, and if the entropy value is high, we conclude the word is a real word. In this work, the neighbors of a character are defined as the two preceding characters, i.e., a trigram model. The probability of a character, c3, given the characters preceding it, c2, is estimated as in Equation 1. this equation, denotes the number times the sequence of characters c2, c3} observed and the number times the sequence c2} is observed in a training corpus. In this work, we produce training data by generating all the possible forms (base forms and inflectional forms) of the words in our dictionary (IBM, 2001). The training data consist of 81,274 words. To estimate the trigram probabilities, we add one leading space and one trailing space to every word, making a 28 letter alphabet. That is, for word w with n characters, Cl c2 • • • we add leading space an trailing space (cn+i) generate w = co c1 c2 • • • cn we produce all the two character sequences, cl, • • • , and the three character Cl c2, • • • , cn—i and count their frequencies in the training data. At last, we compute the probabilities of all the possible trigrams by using Equation 1 and store them in a look-up table. To compute entropy of an out-of-vocabulary word, w = Cl c2 • • • C. we add a leading space and a trailing space to the word and divide it into trigrams and search each trigram in the look-up table. The entropy of a word w, defined as in Equation 2. n+1 E c,-2)/(w) i=2 the number of unknown is less than a threshold value, 01 • the entropy of a word is greater than a threshold value, 02 is set to 2 if the length of a word is less than or equal to 10 and set to 3 if the length is greater than 10. 02 is set to 2.3, which was determined from the average entropy minus the minimum entropy of the training data. 3.2 POS guessing for new words In addition to identifying probable new words, this system produces possible parts-of-speech of the words. We adopt the ending guessing method described in Mikheev (1997) for this purpose. We collect the ending guessing rules from the training data described in section 3.1. For all the words in the training data, we generate all possible endings from length 1 up to length 5, together with the parts-of-speech of the words. We set the minimum length of the remaining part to 3. Table 1 shows how ending guessing rules are generated from our training data. Throughout this paper, POS tags are represented by Penn Treebank Tag code (Marcus and Santorini, 1993). word ailments mounting Ending Rules ments NNS ents NNS nts NNS ts NNS s NNS nting NN nting VBG ting NN ting VBG ing NN ing VBG ng NN ng VBG g NN g VBG word abandons primary Ending Rules ndons VBZ dons VBZ ons VBZ ns VBZ s VBZ mary NN mary JJ ary NN ary JJ ry NN ry JJ y NN y JJ Table 1: Examples of Ending Guessing Rules All the ending rules and their frequencies are collected from the training data, and infrequent rules (frequency = 1) are discarded from the rule set. The rule set contains 12,387 rules, and the most frequent 50 rules are as shown in Table 2. The numbers in parentheses denote the frequencies of the rules. c2) = f (1) If a given word satisfies the following two conditions, it is regarded as a possible real word. which are not shown in the training data 500 1000 1500 2000 2500 3000 3500 4000 number of documents</abstract>
<address confidence="0.909578">8000 7000 6000</address>
<affiliation confidence="0.938846">number of OOV</affiliation>
<address confidence="0.957817222222222">5000 4000 3000 2000 1000 0 90000 80000 70000</address>
<affiliation confidence="0.970999">frequency of OOV</affiliation>
<address confidence="0.915307142857143">60000 50000 40000 30000 20000 10000 0</address>
<phone confidence="0.682925">500 1000 1500 2000 2500 3000 3500 4000</phone>
<abstract confidence="0.945163023255814">number of documents 00V Type Count Affixation 443 compound 85 new word 2287 Misc. 1372 Table 3: Types of out-of-vocabulary words in the MEDLINE collection real words, and 1,372 words are not real words (see, Table 4). In order to verify the system&apos;s judgment, we have conducted two verification processes. At first, we looked up all out-ofvocabulary words in a medical dictionary. We used the on-line version of the Merriam-Webster for this purpose. Then, for words which do not exist in the medical dictionary (we assume they are mostly nonmedical words), the human judges (non-domain experts) decided whether they are probable English words or not by referencing an on-line If an out-of-vocabulary word appears in one of the two dictionaries, we regard it as a real word. We developed a Perl (Wall and Schwartz, 1992) script program to automate the dictionary look-up processes. This program performs dictionary look-up with a URL and a word without any human intervention. It accesses a webpage of the given URL, and performs search with the given word, and returns the webpage of the search result. Then, it parses the returned webpage and decides if a word was found or not. Table 4 shows the result of this experiment. first column Lookup-Yes) denotes the number of the words found in one of dictionaries, and the second column (Dic- Lookup-No) the number of the words which don&apos;t exist in any of the dictionar- The first row Guess-Yes) the number of the words which the system conas real words, and the second row (Sys- Guess-No) the number of the words which the system regarded as invalid words.</abstract>
<title confidence="0.725168">Dictionary LookUp</title>
<author confidence="0.663361">Yes No</author>
<affiliation confidence="0.410012">System Yes 2341 474 2815</affiliation>
<address confidence="0.754375">Guess No 579 793 1372</address>
<phone confidence="0.56836">1267 4187</phone>
<abstract confidence="0.996548887096774">Table 4: Performance of Experiments performance of this system on the medline collection is as follows. = recall = 80.17% — measure = However, many of the samples that the system decided real words but were not found in dictionary Guess-Yes Dictio- Lookup-No) actually real words. This is because the dictionary used for this experiment is also limited. Some examples of the words — mostly biology terminology and drug/treatment — are cardiomyocyte, colforsin, nondihydropyridine, nylestriol. 5 Related Work There has been a great effort to address this problem, especially in the areas of POS taggers and speech recognition. However, applications recognize the problem of out-ofvocabulary words in different perspectives and have different goals. For POS taggers and parsers, which rely on lexical (syntactic) information about words, the goal is to guess the most plausible part-of-speech and other lexical information of an out-of-vocabulary word in a context. Dermatas and Kokkinakis (1995) estimated the probability that an unknown word has a particular POS tag from the probability distribution of words which occur only once in the previously seen texts. More advanced POS guessing methods use leading and trailing word segments to determine possible tags for unknown words. Weischedel et al. (1993) proposed a POS guessing method for unknown words by using the probability for an to be of a particular POS tag, its capitalization feature and its ending. Brill (1995) describes a system of rules which uses both end-guessing and more morphologically motivated rules. Mikheev (1997) presents a technique for fully automatic acquisition of rules which guesses possible POS tags for unknown words using their starting and ending segments. For speech recognition systems, an out-of-vocabulary(00V) word is either a word unknown to the system vocabulary or a word that the recognizer fails to recognize. The goal is to find the closest word (in terms of sound and meaning) to the 00V word from the system&apos;s vocabulary. Character ngram-based statistical approaches have been used in word-level language processing such as spelling correction (Angell et al., 1983), word segmentation (Juola et al., 1994), and language identification (Dunning, 1994). Angell, Freund and Willett (1983) describe a method of comparing misspellings with dictionary terms based on the number of trigrams that the two strings have in common, using Dice&apos;s similarity coefficient as the measure of similarity. The misspelled word is replaced by the word in the dictionary which best matches the misspelling. Juola, Hall and Boggs (1994) describes a system which segments full words into their constituent morphemes based on entropy of the probabilities of trigram sequences. Dunning (1994) implements a high accuracy language identification using character n-gram models and a Bayesian classifier. The performance of the n-gram language classifier is evaluated using different size of n-grams. 6 Conclusions We have developed an approach to augmenting a morphological lexicon with new words such as newly derived words and domain-specific technical words through text analysis of document collections. For morphologically derived words, we have employed morphological rule-base methods such as affixations and compound words. We have also proposed a new technique to identify non-derivational new words based entropy of the probabilities of trigram sequences. The probabilities of trigram sequences are trained on an existing English dictionary. Some possible improvements and future plans are as follows. 1. The rules used for compound word process is over-generalized. For example, all the combinations of two nouns may not be compound nouns. We anticipate the performance will be improved if we incorporate a corpus statistics-based compound word processing scheme into the existing method. 2. The performance will be improved if we include domain-specific prefixes and suffixes as branch°, 3. We trained our entropy model on a generalpurpose dictionary. However, many medical and biotechnological terms have their origin in Latin. We expect the performance would be better if we train our system by using a domain-specific lexicon or a tagged (specified if a word is correct or not) domain-specific corpus. 4. We expect it is not difficult to apply this approach to other languages because this system only uses basic morphological rules of a language and language-independent statistical information. In addition, it does not require a large amount of annotated training data. Acknowledgement grateful to Marco Gruteser for the development of the Perl script for the evaluation of this work. I also thank anonymous reviewers for their helpful comments. References G. Freund, and P. Willett. 1983. Automatic spelling correction using a trigram similarmeasure. Processing and Manage- Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: A case in part of speech tagging.</abstract>
<note confidence="0.488586454545455">Ralph Weischedel, Marie Meeter, Richard Schwartz, Lance Ramshaw, and Jeff Palmucci. 1993. Coping with ambiguity and unknown words through models. Linguistics, (2):359-382. Evangelos Dermatas and George Kokkinakis. 1995. Automatic stochastic tagging of natural language Linguistics, Ted Dunning. 1994. Statistical identification of Report CRL MCCS 94-273i, New Mexico State University.</note>
<author confidence="0.854129">Florian Gallwitz</author>
<author confidence="0.854129">Elmar Noeth</author>
<author confidence="0.854129">Heinrich Nie-</author>
<abstract confidence="0.930496">mann. 1996. A category based approach for recogof out-of-vocabulary words.</abstract>
<title confidence="0.839382">of International Conference on Spoken Language</title>
<author confidence="0.849211">A com-</author>
<abstract confidence="0.567348434782609">parison and combination of methods for oov word and word confidence scoring. Proceedings of ICASSP. IBM. 2001. Dictionary and linguistic tools. http://booksryl.raleigh.ibm.com/lingtool. Patrik Juola, Chris Hall, and Adam Boggs. 1994. Corpus based morphological segmentation by enchanges. of the 3rd International Conference on the Cognitive Science of Natural Language Processing. Mitch Marcus and Marcinkiewicz B. Santorini. 1993. Building a large annotated corpus of english: penn treebank. Linguistics, 19(2):313-330. Andrei Mikheev. 1997. Automatic rule induction for word guessing. Linguis- Youngja Park, Roy J. Byrd, and Branimir K. Boguraev. 2002. Automatic glossary extraction: Beterminology identification. Research Technical Report, RC22421. Pickett al. The american heritage book of english usage: A practical and anthoriguide to contemporary english.</abstract>
<note confidence="0.889566375">Mifflin Company. Yael Ravin, Nina Wacholder, and Misook Choi. 1997. Disambiguation of proper names in text. Annual Conference. Claude E. Shannon. 1951. Prediction and entropy of english. Bell System Technical Jour- Larry Wall and Randal L. Schwartz. 1992. Programperl. &amp; Associates, Inc.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Angell</author>
<author>G Freund</author>
<author>P Willett</author>
</authors>
<title>Automatic spelling correction using a trigram similarity measure.</title>
<date>1983</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>19--4</pages>
<contexts>
<context position="15818" citStr="Angell et al., 1983" startWordPosition="2688" endWordPosition="2691">phologically motivated rules. Mikheev (1997) presents a technique for fully automatic acquisition of rules which guesses possible POS tags for unknown words using their starting and ending segments. For speech recognition systems, an out-of-vocabulary(00V) word is either a word unknown to the system vocabulary or a word that the recognizer fails to recognize. The goal is to find the closest word (in terms of sound and meaning) to the 00V word from the system&apos;s vocabulary. Character ngram-based statistical approaches have been used in word-level language processing such as spelling correction (Angell et al., 1983), word segmentation (Juola et al., 1994), and language identification (Dunning, 1994). Angell, Freund and Willett (1983) describe a method of comparing misspellings with dictionary terms based on the number of trigrams that the two strings have in common, using Dice&apos;s similarity coefficient as the measure of similarity. The misspelled word is replaced by the word in the dictionary which best matches the misspelling. Juola, Hall and Boggs (1994) describes a system which segments full words into their constituent morphemes based on entropy of the probabilities of trigram sequences. Dunning (1994</context>
</contexts>
<marker>Angell, Freund, Willett, 1983</marker>
<rawString>R. Angell, G. Freund, and P. Willett. 1983. Automatic spelling correction using a trigram similarity measure. Information Processing and Management, 19(4):255-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-based error-driven learning and natural language processing: A case</title>
<date>1995</date>
<contexts>
<context position="15128" citStr="Brill (1995)" startWordPosition="2583" endWordPosition="2584">rmatas and Kokkinakis (1995) estimated the probability that an unknown word has a particular POS tag from the probability distribution of words which occur only once in the previously seen texts. More advanced POS guessing methods use leading and trailing word segments to determine possible tags for unknown words. Weischedel et al. (1993) proposed a POS guessing method for unknown words by using the probability for an 4http://www.intelihealth.com/IH/ihtIH/WSIHWO00/9276/9276.h1W(nown word to be of a particular POS tag, 5http://www.dictionary.com given its capitalization feature and its ending. Brill (1995) describes a system of rules which uses both end-guessing and more morphologically motivated rules. Mikheev (1997) presents a technique for fully automatic acquisition of rules which guesses possible POS tags for unknown words using their starting and ending segments. For speech recognition systems, an out-of-vocabulary(00V) word is either a word unknown to the system vocabulary or a word that the recognizer fails to recognize. The goal is to find the closest word (in terms of sound and meaning) to the 00V word from the system&apos;s vocabulary. Character ngram-based statistical approaches have bee</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-based error-driven learning and natural language processing: A case</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Statistical identification of language.</title>
<date>1994</date>
<tech>Technical Report CRL MCCS 94-273i,</tech>
<institution>New Mexico State University.</institution>
<contexts>
<context position="15903" citStr="Dunning, 1994" startWordPosition="2701" endWordPosition="2702">sition of rules which guesses possible POS tags for unknown words using their starting and ending segments. For speech recognition systems, an out-of-vocabulary(00V) word is either a word unknown to the system vocabulary or a word that the recognizer fails to recognize. The goal is to find the closest word (in terms of sound and meaning) to the 00V word from the system&apos;s vocabulary. Character ngram-based statistical approaches have been used in word-level language processing such as spelling correction (Angell et al., 1983), word segmentation (Juola et al., 1994), and language identification (Dunning, 1994). Angell, Freund and Willett (1983) describe a method of comparing misspellings with dictionary terms based on the number of trigrams that the two strings have in common, using Dice&apos;s similarity coefficient as the measure of similarity. The misspelled word is replaced by the word in the dictionary which best matches the misspelling. Juola, Hall and Boggs (1994) describes a system which segments full words into their constituent morphemes based on entropy of the probabilities of trigram sequences. Dunning (1994) implements a high accuracy language identification using character n-gram models an</context>
</contexts>
<marker>Dunning, 1994</marker>
<rawString>Ted Dunning. 1994. Statistical identification of language. Technical Report CRL MCCS 94-273i, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Gallwitz</author>
<author>Elmar Noeth</author>
<author>Heinrich Niemann</author>
</authors>
<title>A category based approach for recognition of out-of-vocabulary words.</title>
<date>1996</date>
<booktitle>Proceedings of International Conference on Spoken Language Processing,</booktitle>
<pages>1--228</pages>
<marker>Gallwitz, Noeth, Niemann, 1996</marker>
<rawString>Florian Gallwitz, Elmar Noeth, and Heinrich Niemann. 1996. A category based approach for recognition of out-of-vocabulary words. Proceedings of International Conference on Spoken Language Processing, 1:228-231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy J Hazen</author>
<author>Bazzi Issam</author>
</authors>
<title>A comparison and combination of methods for oov word detection and word confidence scoring.</title>
<date>2001</date>
<booktitle>Proceedings of ICASSP.</booktitle>
<marker>Hazen, Issam, 2001</marker>
<rawString>Timothy J. Hazen and Bazzi Issam. 2001. A comparison and combination of methods for oov word detection and word confidence scoring. Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IBM</author>
</authors>
<title>Dictionary and linguistic tools.</title>
<date>2001</date>
<note>http://booksryl.raleigh.ibm.com/lingtool.</note>
<contexts>
<context position="2417" citStr="IBM, 2001" startWordPosition="383" endWordPosition="384">process for identifying real words and for producing lexical information is as follows. First, we remove all proper names and non-word strings from the document collection. It is easy to recognize non-word strings and upper case and non-initial mixed case words. In addition to the capitalization feature, we use a precompiled names database (Ravin et al., 1997) for recognizing person names and place names. If a word exists in the database, we consider it as a proper noun. Second, we look up all the remaining words in the document collection in a general purpose English dictionary built by IBM (IBM, 2001) and collect all the out-of-vocabulary words, i.e., words unknown to the dictionary, and their frequencies in the collection. Third, we discard words which appear only once in the collection. Fourth, we check if an out-of-vocabulary word is comprised of existing words in the dictionary and/or morphological units such as a prefix and a suffix. If this process succeeds, possible parts-of-speech of the word are generated based on the morphological rules applied to produce the word. Fifth, if this process fails, we judge if the word may be a new word on the basis of entropy of the probability of i</context>
<context position="8577" citStr="IBM, 2001" startWordPosition="1428" endWordPosition="1429"> is a real word. In this work, the neighbors of a character are defined as the two preceding characters, i.e., a trigram model. The probability of a character, c3, given the two characters preceding it, cl, c2, is estimated as in Equation 1. f (cle2) In this equation, f (cic2c3) denotes the number of times the sequence of characters {c1, c2, c3} is observed and f(c1c2) denotes the number of times the sequence {c1, c2} is observed in a training corpus. In this work, we produce training data by generating all the possible forms (base forms and inflectional forms) of the words in our dictionary (IBM, 2001). The training data consist of 81,274 words. To estimate the trigram probabilities, we add one leading space and one trailing space to every word, making a 28 letter alphabet. That is, for a word w with n characters, Cl c2 • • • cri, we add a leading space (co), and an trailing space (cn+i) and generate w = co c1 c2 • • • cn Cn+1. Then, we produce all the two character sequences, co cl, • • • , cn cn+i, and the three character sequences, co Cl c2, • • • , cn—i cn cn+i, and count their frequencies in the training data. At last, we compute the probabilities of all the possible trigrams by using </context>
</contexts>
<marker>IBM, 2001</marker>
<rawString>IBM. 2001. Dictionary and linguistic tools. http://booksryl.raleigh.ibm.com/lingtool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrik Juola</author>
<author>Chris Hall</author>
<author>Adam Boggs</author>
</authors>
<title>Corpus based morphological segmentation by entropy changes.</title>
<date>1994</date>
<booktitle>Proceedings of the 3rd International Conference on the Cognitive Science of Natural Language Processing.</booktitle>
<contexts>
<context position="15858" citStr="Juola et al., 1994" startWordPosition="2694" endWordPosition="2697">97) presents a technique for fully automatic acquisition of rules which guesses possible POS tags for unknown words using their starting and ending segments. For speech recognition systems, an out-of-vocabulary(00V) word is either a word unknown to the system vocabulary or a word that the recognizer fails to recognize. The goal is to find the closest word (in terms of sound and meaning) to the 00V word from the system&apos;s vocabulary. Character ngram-based statistical approaches have been used in word-level language processing such as spelling correction (Angell et al., 1983), word segmentation (Juola et al., 1994), and language identification (Dunning, 1994). Angell, Freund and Willett (1983) describe a method of comparing misspellings with dictionary terms based on the number of trigrams that the two strings have in common, using Dice&apos;s similarity coefficient as the measure of similarity. The misspelled word is replaced by the word in the dictionary which best matches the misspelling. Juola, Hall and Boggs (1994) describes a system which segments full words into their constituent morphemes based on entropy of the probabilities of trigram sequences. Dunning (1994) implements a high accuracy language id</context>
</contexts>
<marker>Juola, Hall, Boggs, 1994</marker>
<rawString>Patrik Juola, Chris Hall, and Adam Boggs. 1994. Corpus based morphological segmentation by entropy changes. Proceedings of the 3rd International Conference on the Cognitive Science of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitch Marcus</author>
<author>Marcinkiewicz B Santorini</author>
</authors>
<title>Building a large annotated corpus of english: the penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="10626" citStr="Marcus and Santorini, 1993" startWordPosition="1817" endWordPosition="1820">le new words, this system produces possible parts-of-speech of the words. We adopt the ending guessing method described in Mikheev (1997) for this purpose. We collect the ending guessing rules from the training data described in section 3.1. For all the words in the training data, we generate all possible endings from length 1 up to length 5, together with the parts-of-speech of the words. We set the minimum length of the remaining part to 3. Table 1 shows how ending guessing rules are generated from our training data. Throughout this paper, POS tags are represented by Penn Treebank Tag code (Marcus and Santorini, 1993). word ailments mounting Ending ments NNS nting NN nting VBG Rules ents NNS ting NN ting VBG nts NNS ing NN ing VBG ts NNS ng NN ng VBG s NNS g NN g VBG word abandons primary Ending ndons VBZ mary NN mary JJ Rules dons VBZ ary NN ary JJ ons VBZ ry NN ry JJ ns VBZ y NN y JJ s VBZ Table 1: Examples of Ending Guessing Rules All the ending rules and their frequencies are collected from the training data, and infrequent rules (frequency = 1) are discarded from the rule set. The rule set contains 12,387 rules, and the most frequent 50 rules are as shown in Table 2. The numbers in parentheses denote </context>
</contexts>
<marker>Marcus, Santorini, 1993</marker>
<rawString>Mitch Marcus and Marcinkiewicz B. Santorini. 1993. Building a large annotated corpus of english: the penn treebank. Computational Linguistics, 19(2):313-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Mikheev</author>
</authors>
<title>Automatic rule induction for unknown word guessing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--3</pages>
<contexts>
<context position="10136" citStr="Mikheev (1997)" startWordPosition="1733" endWordPosition="1734"> n+1 H(w) = E P( c,I C,-1, c,-2)/(w) (2) i=2 • the number of unknown trigrams2 is less than a threshold value, 01 • the entropy of a word is greater than a threshold value, 02 Currently, 01 is set to 2 if the length of a word is less than or equal to 10 and set to 3 if the length is greater than 10. 02 is set to 2.3, which was determined from the average entropy minus the minimum entropy of the training data. 3.2 POS guessing for new words In addition to identifying probable new words, this system produces possible parts-of-speech of the words. We adopt the ending guessing method described in Mikheev (1997) for this purpose. We collect the ending guessing rules from the training data described in section 3.1. For all the words in the training data, we generate all possible endings from length 1 up to length 5, together with the parts-of-speech of the words. We set the minimum length of the remaining part to 3. Table 1 shows how ending guessing rules are generated from our training data. Throughout this paper, POS tags are represented by Penn Treebank Tag code (Marcus and Santorini, 1993). word ailments mounting Ending ments NNS nting NN nting VBG Rules ents NNS ting NN ting VBG nts NNS ing NN in</context>
<context position="15242" citStr="Mikheev (1997)" startWordPosition="2600" endWordPosition="2601">obability distribution of words which occur only once in the previously seen texts. More advanced POS guessing methods use leading and trailing word segments to determine possible tags for unknown words. Weischedel et al. (1993) proposed a POS guessing method for unknown words by using the probability for an 4http://www.intelihealth.com/IH/ihtIH/WSIHWO00/9276/9276.h1W(nown word to be of a particular POS tag, 5http://www.dictionary.com given its capitalization feature and its ending. Brill (1995) describes a system of rules which uses both end-guessing and more morphologically motivated rules. Mikheev (1997) presents a technique for fully automatic acquisition of rules which guesses possible POS tags for unknown words using their starting and ending segments. For speech recognition systems, an out-of-vocabulary(00V) word is either a word unknown to the system vocabulary or a word that the recognizer fails to recognize. The goal is to find the closest word (in terms of sound and meaning) to the 00V word from the system&apos;s vocabulary. Character ngram-based statistical approaches have been used in word-level language processing such as spelling correction (Angell et al., 1983), word segmentation (Juo</context>
</contexts>
<marker>Mikheev, 1997</marker>
<rawString>Andrei Mikheev. 1997. Automatic rule induction for unknown word guessing. Computational Linguistics, 23(3):405-423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngja Park</author>
<author>Roy J Byrd</author>
<author>Branimir K Boguraev</author>
</authors>
<title>Automatic glossary extraction: Beyond terminology identification.</title>
<date>2002</date>
<journal>IBM Research</journal>
<tech>Technical Report, RC22421.</tech>
<marker>Park, Byrd, Boguraev, 2002</marker>
<rawString>Youngja Park, Roy J. Byrd, and Branimir K. Boguraev. 2002. Automatic glossary extraction: Beyond terminology identification. IBM Research Technical Report, RC22421.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Pickett</author>
</authors>
<title>The american heritage book of english usage: A practical and anthoritative guide to contemporary english.</title>
<date>1996</date>
<publisher>Houghton Mifflin Company.</publisher>
<marker>Pickett, 1996</marker>
<rawString>Joseph Pickett et al. 1996. The american heritage book of english usage: A practical and anthoritative guide to contemporary english. Houghton Mifflin Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yael Ravin</author>
<author>Nina Wacholder</author>
<author>Misook Choi</author>
</authors>
<date>1997</date>
<booktitle>Disambiguation of proper names in text. 17th Annual ACM-SIGIR Conference.</booktitle>
<contexts>
<context position="2169" citStr="Ravin et al., 1997" startWordPosition="337" endWordPosition="340">. In this work, we don&apos;t take into account proper nouns and non-word strings because they are not valuable to be kept in dictionaries. Thus, in this work, out-of-vocabulary words are classified into two categories - derived words and new words. The overall process for identifying real words and for producing lexical information is as follows. First, we remove all proper names and non-word strings from the document collection. It is easy to recognize non-word strings and upper case and non-initial mixed case words. In addition to the capitalization feature, we use a precompiled names database (Ravin et al., 1997) for recognizing person names and place names. If a word exists in the database, we consider it as a proper noun. Second, we look up all the remaining words in the document collection in a general purpose English dictionary built by IBM (IBM, 2001) and collect all the out-of-vocabulary words, i.e., words unknown to the dictionary, and their frequencies in the collection. Third, we discard words which appear only once in the collection. Fourth, we check if an out-of-vocabulary word is comprised of existing words in the dictionary and/or morphological units such as a prefix and a suffix. If this</context>
</contexts>
<marker>Ravin, Wacholder, Choi, 1997</marker>
<rawString>Yael Ravin, Nina Wacholder, and Misook Choi. 1997. Disambiguation of proper names in text. 17th Annual ACM-SIGIR Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claude E Shannon</author>
</authors>
<title>Prediction and entropy of printed english.</title>
<date>1951</date>
<journal>The Bell System Technical Journal,</journal>
<pages>50--64</pages>
<contexts>
<context position="7318" citStr="Shannon, 1951" startWordPosition="1210" endWordPosition="1211">ification of new words Human beings can very successfully guess whether a word never seen before is a possible real word or not, even though the word is not comprised of already known words. We assume that human beings may conclude that a word is a possible word of the language, if the character sequences in the word look probable, and it is natural to pronounce. We base the recognition of non-derivational new words on this assumption. That is, this method is based on the prediction of a language; how well can the next letter of a text be predicted when the preceding n letters are known (see, Shannon, 1951 for more extensive description of estimating the entropy and redundancy of a language). A word is a cohesive group of letters with strong internal statistical influences (Shannon, 1951). We regard a string as a possible real word if every letter in the string is likely to co-occur with its neighbors. That is, if the letters in a word have high chances to occur in their position given the preceding characters have been seen (i.e., an n-gram model), the word is regarded as a real word. More formally, we compute entropy of the probabilities of n-gram sequences in an out-of-vocabulary word, and i</context>
</contexts>
<marker>Shannon, 1951</marker>
<rawString>Claude E. Shannon. 1951. Prediction and entropy of printed english. The Bell System Technical Journal, January:50-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry Wall</author>
<author>Randal L Schwartz</author>
</authors>
<title>Programming perl. O&apos;Reilly &amp;</title>
<date>1992</date>
<publisher>Associates, Inc.</publisher>
<contexts>
<context position="12520" citStr="Wall and Schwartz, 1992" startWordPosition="2162" endWordPosition="2165"> the system&apos;s judgment, we have conducted two verification processes. At first, we looked up all out-ofvocabulary words in a medical dictionary. We used the on-line version of the Merriam-Webster medical dictionary4 for this purpose. Then, for words which do not exist in the medical dictionary (we assume they are mostly nonmedical words), the human judges (non-domain experts) decided whether they are probable English words or not by referencing an on-line English dictionary5. If an out-of-vocabulary word appears in one of the two dictionaries, we regard it as a real word. We developed a Perl (Wall and Schwartz, 1992) script program to automate the dictionary look-up processes. This program performs dictionary look-up with a URL and a word without any human intervention. It accesses a webpage of the given URL, and performs search with the given word, and returns the webpage of the search result. Then, it parses the returned webpage and decides if a word was found or not. Table 4 shows the result of this experiment. The first column (Dictionary Lookup-Yes) denotes the number of the words found in one of the dictionaries, and the second column (Dictionary Lookup-No) denotes the number of the words which don&apos;</context>
</contexts>
<marker>Wall, Schwartz, 1992</marker>
<rawString>Larry Wall and Randal L. Schwartz. 1992. Programming perl. O&apos;Reilly &amp; Associates, Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>