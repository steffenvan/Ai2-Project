<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.020396">
<title confidence="0.931524">
ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation
</title>
<author confidence="0.922576">
Els Lefever1,2, V´eronique Hoste1,2,3 and Martine De Cock2
</author>
<affiliation confidence="0.483101">
1LT3, Language and Translation Technology Team, University College Ghent
Groot-Brittanni¨elaan 45, 9000 Gent, Belgium
2Dept. of Applied Mathematics and Computer Science, Ghent University
</affiliation>
<address confidence="0.513269">
Krijgslaan 281 (S9), 9000 Gent, Belgium
3Dept. of Linguistics, Ghent University
Blandijnberg 2, 9000 Gent, Belgium
</address>
<sectionHeader confidence="0.97548" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999542454545455">
This paper describes a set of exploratory ex-
periments for a multilingual classification-
based approach to Word Sense Disambigua-
tion. Instead of using a predefined monolin-
gual sense-inventory such as WordNet, we use
a language-independent framework where the
word senses are derived automatically from
word alignments on a parallel corpus. We built
five classifiers with English as an input lan-
guage and translations in the five supported
languages (viz. French, Dutch, Italian, Span-
ish and German) as classification output. The
feature vectors incorporate both the more tra-
ditional local context features, as well as bi-
nary bag-of-words features that are extracted
from the aligned translations. Our results
show that the ParaSense multilingual WSD
system shows very competitive results com-
pared to the best systems that were evaluated
on the SemEval-2010 Cross-Lingual Word
Sense Disambiguation task for all five target
languages.
</bodyText>
<sectionHeader confidence="0.999452" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998657375000001">
Word Sense Disambiguation (WSD) is the NLP
task that consists in selecting the correct sense of
a polysemous word in a given context. Most state-
of-the-art WSD systems are supervised classifiers
that are trained on manually sense-tagged corpora,
which are very time-consuming and expensive to
build (Agirre and Edmonds, 2006) . In order to over-
come this acquisition bottleneck (sense-tagged cor-
pora are scarce for languages other than English),
we decided to take a multilingual approach to WSD,
that builds up the sense inventory on the basis of
the Europarl parallel corpus (Koehn, 2005). Using
translations from a parallel corpus implicitly deals
with the granularity problem as finer sense distinc-
tions are only relevant as far as they are lexicalized
in the target translations. It also facilitates the in-
tegration of WSD in multilingual applications such
as multilingual Information Retrieval (IR) or Ma-
chine Translation (MT). Significant improvements
in terms of general MT quality were for the first time
reported by Carpuat and Wu (2007) and Chan et al.
(2007). Both papers describe the integration of a
dedicated WSD module in a Chinese-English statis-
tical machine translation framework and report sta-
tistically significant improvements in terms of stan-
dard MT evaluation metrics.
Several studies have already shown the validity
of using parallel corpora for sense discrimination
(e.g. (Ide et al., 2002)), for bilingual WSD mod-
ules (e.g. (Gale and Church, 1993; Ng et al., 2003;
Diab and Resnik, 2002; Chan and Ng, 2005; Da-
gan and Itai, 1994)) and for WSD systems that use
a combination of existing WordNets with multilin-
gual evidence (Tufis¸ et al., 2004). The research de-
scribed in this paper is novel as it presents a truly
multilingual classification-based approach to WSD
that directly incorporates evidence from four other
languages. To this end, we build further on two
well-known research ideas: (1) the possibility to
use parallel corpora to extract translation labels and
features in an automated way and (2) the assump-
tion that incorporating evidence from multiple lan-
guages into the feature vector will be more infor-
mative than a more restricted set of monolingual or
bilingual features. Furthermore, our WSD system
does not use any information from external lexical
resources such as WordNet (Fellbaum, 1998) or Eu-
roWordNet (Vossen, 1998).
</bodyText>
<page confidence="0.981672">
317
</page>
<note confidence="0.6200665">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 317–322,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.99573952238806">
2 Experimental Setup prepositions. In future work, we will investigate
Starting point of the experiments was the six-lingual other word alignment strategies and measure the im-
sentence-aligned Europarl corpus that was used in pact on the classification scores. The second training
the SemEval-2010 “Cross-Lingual Word Sense Dis- set uses manually verified word alignments as labels
ambiguation” (CLWSD) task (Lefever and Hoste, for the training instances. This second setup is then
2010b). The task is a lexical sample task for twenty to be considered as the upper bound on the current
English ambiguous nouns that consists in assign- experimental setup.
ing a correct translation in the five supported tar- All English sentences were preprocessed
get languages (viz. French, Italian, Spanish, Ger- by means of a memory-based shallow parser
man and Dutch) for an ambiguous focus word in a (MBSP) (Daelemans and van den Bosch, 2005) that
given context. In order to detect the relevant transla- performs tokenization, Part-of-Speech tagging and
tions for each of the twenty ambiguous focus words, text chunking. The preprocessed sentences were
we ran GIZA++ (Och and Ney, 2003) with its de- used as input to build a set of commonly used WSD
fault settings for all focus words. This word align- features related to the English input sentence:
ment output was then considered to be the label for • features related to the focus word itself being
the training instances for the corresponding classi- the word form of the focus word, the lemma,
fier (e.g. the Dutch translation is the label that is used Part-of-Speech and chunk information
to train the Dutch classifier). By considering this • local context features related to a window of
word alignment output as oracle information, we re- three words preceding and following the focus
defined the CLWSD task as a classification task. word containing for each of these words their
To train our five classifiers (English as input lan- full form, lemma, Part-of-Speech and chunk in-
guage and French, German, Dutch, Italian and Span- formation
ish as focus languages), we used the memory-based In addition to these well known monolingual fea-
learning (MBL) algorithm implemented in TIMBL tures, we extracted a set of binary bag-of-words fea-
(Daelemans and Hoste, 2002), which has success- tures from the aligned translation that are not the
fully been deployed in previous WSD classification target language of the classifier (e.g. for the Dutch
tasks (Hoste et al., 2002). We performed heuris- classifier, we extract bag-of-words features from the
tic experiments to define the parameter settings for Italian, Spanish, French and German aligned trans-
the classifier, leading to the selection of the Jef- lations). In order to extract useful content words,
frey Divergence distance metric, Gain Ratio feature we first ran Part-of-Speech tagging and lemmatisa-
weighting and k = 7 as number of nearest neigh- tion by means of the Treetagger (Schmid, 1994) tool.
bours. In future work, we plan to use an optimized Per ambiguous focus word, a list of content words
word-expert approach in which a genetic algorithm (nouns, adjectives, verbs and adverbs) was extracted
performs joint feature selection and parameter op- that occurred in the aligned translations of the En-
timization per ambiguous word (Daelemans et al., glish sentences containing the focus word. One bi-
2003). nary feature per selected content word was then cre-
For our feature vector creation, we combined a set ated per ambiguous word: ‘0’ in case the word does
of English local context features and a set of binary not occur in the aligned translation of this instance,
bag-of-words features that were extracted from the and ‘1’ in case the word does occur in the aligned
aligned translations. translation of the training instance.
2.1 Training Feature Vector Construction 2.2 Test Feature Vector Construction
We created two experimental setups. The first For the creation of the feature vectors for the test in-
training set incorporates the automatically generated stances, we follow a similar strategy as the one we
word alignments as labels. We applied an automatic used for the creation of the training instances. The
post-processing step on these word alignments in or- first part of the feature vector contains the English
der to remove leading and trailing determiners and
318
local context features that were also extracted for
the training instances. For the construction of the
bag-of-words features however, we need to adopt a
different approach as we do not have aligned trans-
lations for the English test instances at our disposal.
We decided to deploy a novel strategy that uses
the Google Translate API1 to automatically gener-
ate a translation for all English test instances in the
five supported languages. Online machine transla-
tions tools have already been used before to create
artificial parallel corpora that were used for NLP
tasks such as for instance Named Entity Recogni-
tion (Shah et al., 2010).
In a next step the automatically generated transla-
tion was preprocessed in the same way as the train-
ing translations (Part-of-Speech-tagged and lemma-
tized). The resulting lemmas were then used to con-
struct the same set of binary bag-of-words features
that were stored for the training instances of the am-
biguous focus word.
</bodyText>
<sectionHeader confidence="0.998269" genericHeader="introduction">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999987590909091">
To evaluate our five classifiers, we used the sense in-
ventory and test set of the SemEval “Cross-Lingual
Word Sense Disambiguation” task. The sense inven-
tory was built up on the basis of the Europarl corpus:
all retrieved translations of a polysemous word were
manually grouped into clusters, which constitute dif-
ferent senses of that given word. The test instances
were selected from the JRC-ACQUIS Multilingual
Parallel Corpus2 and BNC3. To label the test data,
native speakers provided their top three translations
from the predefined clusters of Europarl translations,
in order to assign frequency weights to the set of
gold standard translations. A more detailed descrip-
tion of the construction of the data set can be found
in Lefever and Hoste (2010a).
As evaluation metrics, we used both the SemEval
BEST precision metric from the CLWSD task as
well as a straightforward accuracy measure. The
SemEval metric takes into account the frequency
weights of the gold standard translations: transla-
tions that were picked by different annotators get
a higher weight. For the BEST evaluation, systems
</bodyText>
<footnote confidence="0.999874">
1http://code.google.com/apis/language/
2http://wt.jrc.it/lt/Acquis/
3http://www.natcorp.ox.ac.uk/
</footnote>
<bodyText confidence="0.97061825">
can propose as many guesses as the system believes
are correct, but the resulting score is divided by the
number of guesses. In this way, systems that out-
put a lot of guesses are not favoured. For a more
detailed description of the SemEval scoring scheme,
we refer to McCarthy and Navigli (2007). Follow-
ing variables are used for the SemEval precision for-
mula. Let H be the set of annotators, T the set of test
items and hi the set of responses for an item i ∈ T
for annotator h ∈ H. Let A be the set of items from
T where the system provides at least one answer and
ai : i ∈ A the set of guesses from the system for
item i. For each i, we calculate the multiset union
(Hi) for all hi for all h ∈ H and for each unique
type (res) in Hi that has an associated frequency
(freqres).
</bodyText>
<equation confidence="0.9592765">
(1)
|A|
</equation>
<bodyText confidence="0.9997775">
The second metric we use is a straightforward ac-
curacy measure, that divides the number of correct
answers by the total amount of test instances.
As a baseline, we selected the most frequent lem-
matized translation that resulted from the automated
word alignment (GIZA++). We also compare our
results with the two winning SemEval-2 systems
for the Cross-Lingual Word Sense Disambiguation
task, UvT-WSD (that only participated for Dutch
and Spanish) and T3-COLEUR. The UvT-WSD sys-
tem (van Gompel, 2010), that also uses a k-nearest
neighbor classifier and a variety of local and global
context features, obtained the best scores for Span-
ish and Dutch in the SemEval CLWSD competi-
tion. Although we also use a memory-based learner,
our method is different from this system in the way
the feature vectors are constructed. Next to the
incorporation of similar local context features, we
also include evidence from multiple languages in
our feature vector. For French, Italian and Ger-
man however, the T3-COLEUR system (Guo and
Diab, 2010) outperformed the other systems in the
SemEval competition. This system adopts a differ-
ent approach: during the training phase a monolin-
gual WSD system processes the English input sen-
tence and a word alignment module is used to ex-
tract the aligned translation. The English senses to-
gether with their aligned translations (and probabil-
</bodyText>
<figure confidence="0.748695">
Prec =
Eai:iEA F-
res2ai fre9res
jaij
|Hi|
</figure>
<page confidence="0.995311">
319
</page>
<bodyText confidence="0.999991836065574">
ity scores) are then stored in a word sense transla-
tion table, in which look-ups are performed during
the testing phase. This system also differs from the
Uvt-WSD and ParaSense systems in the sense that
the word senses are derived from WordNet, whereas
the other systems do not use any external resources.
The results for all five classifiers are listed in two
tables. Table 1 gives an overview of the SemEval-
2010 weighted precision scores, whereas Table 2
shows the more straightforward accuracy figures.
Both tables list the scores averaged over all twenty
test words for the baseline (most frequent word
alignment), the best SemEval system (for a given
language) and the two ParaSense setups: one that ex-
clusively uses automatically generated word align-
ments, and one that uses the verified word alignment
labels. For both setups we trained three flavors of
the ParaSense system (1: local context + translation
features, 2: translation features and 3: local context
features).
The classification results show that for both se-
tups all three flavors of the ParaSense system easily
beat the baseline. Moreover, the ParaSense system
clearly outperforms the winning SemEval systems,
except for Spanish where the scores are similar. As
all systems, viz. the two SemEval systems as well
as the three flavors of the ParaSense system, were
trained on the same Europarl data, the scores illus-
trate the potential advantages of using a multilingual
approach. Although we applied a very basic strategy
for the selection of our bag-of-words translation fea-
tures (we did not perform any filtering on the trans-
lations except for Part-of-Speech information), we
observe that for three languages the full feature vec-
tor outperforms the classifier that uses the more tra-
ditional WSD local context features. For Dutch, the
classifier that merely uses translation features even
outperforms the classifier that uses the local context
features. In previous research (Lefever and Hoste,
2011), we showed that the classifier using evidence
from all different languages was constantly better
than the ones using less or no multilingual evidence.
In addition, the scores also degraded relatively to the
number of translation features that was used. As we
used a different set of translation features for the lat-
ter pilot experiments (we only used the translations
of the ambiguous words instead of the full bag-of-
words features we used for the current setup), we
need to confirm this trend with more experiments
using the current feature sets.
Another important observation is that the classifi-
cation scores degrade when using the automatically
generated word alignments, but only to a minor ex-
tent. This clearly shows the viability of our setup.
Further experiments with different word alignment
settings and symmetrisation methods should allow
us to further improve the results with the automat-
ically generated word alignments. Using the non-
validated labels makes the system very flexible and
language-independent, as all steps in the feature vec-
tor creation can be run automatically.
</bodyText>
<sectionHeader confidence="0.999446" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999970625">
We presented preliminary results for a multilingual
classification-based approach to Word Sense Dis-
ambiguation. In addition to the commonly used
monolingual local context features, we also incor-
porate bag-of-word features that are built from the
aligned translations. Although there is still a lot of
room for improvement on the feature base, our re-
sults show that the ParaSense system clearly outper-
forms state-of-the-art systems for all languages, ex-
cept for Spanish where the results are very similar.
As all steps are run automatically, this multilingual
approach could be an answer for the acquisition bot-
tleneck, as long as there are parallel corpora avail-
able for the targeted languages. Although large mul-
tilingual corpora are still rather scarce, we strongly
believe there will be more parallel corpora available
in the near future (large companies and organiza-
tions disposing of large quantities of parallel text,
internet corpora such as the ever growing Wikipedia
corpus, etc.). Another line of research could be the
exploitation of comparable corpora to acquire addi-
tional training data.
In future work, we want to run additional exper-
iments with different classifiers (SVM) and apply
a genetic algorithm to perform joint feature selec-
tion, parameter optimization and instance selection.
We also plan to expand our feature set by including
global context features (content words from the En-
glish sentence) and to examine the relationship be-
tween the performance and the number (and nature)
of languages that is added to the feature vector. In
addition, we will apply semantic analysis tools (such
</bodyText>
<page confidence="0.991758">
320
</page>
<table confidence="0.999255083333333">
French Italian Spanish Dutch German
Baseline 20.71 14.03 18.36 15.69 13.16
T3-COLEUR 21.96 15.55 19.78 10.71 13.79
UvT-WSD 23.42 17.70
Non-verified word alignment labels
ParaSense1 (full feature vector) 24.54 18.03 22.80 18.56 16.88
ParaSense2 (translation features) 23.92 16.77 22.58 17.70 15.98
ParaSense3 (local context features) 24.09 19.89 23.21 17.57 16.55
Verified word alignment labels
ParaSense1 (full feature vector) 24.60 19.64 23.10 18.61 17.41
ParaSense2 (translation features) 24.29 19.15 22.94 18.25 16.90
ParaSense3 (local context features) 24.79 21.31 23.56 17.70 17.54
</table>
<tableCaption confidence="0.986372">
Table 1: SemEval precision scores averaged over all twenty test words
</tableCaption>
<table confidence="0.99982425">
French Italian Spanish Dutch German
Baseline 63.10 47.90 53.70 59.40 52.30
T3-COLEUR 66.88 50.73 59.83 40.01 54.20
UvT-WSD 70.20 64.10
Non-verified word alignment labels
ParaSense1 (full feature vector) 75.20 63.40 68.20 68.10 66.20
ParaSense2 (translation features) 73.20 58.30 67.60 65.90 63.60
ParaSense3 (local context features) 73.50 65.50 69.40 63.90 61.90
Verified word alignment labels
ParaSense1 (full feature vector) 75.70 63.20 68.50 68.20 67.80
ParaSense2 (translation features) 74.70 61.30 68.30 66.80 66.20
ParaSense3 (local context features) 75.20 67.30 70.30 63.30 66.10
</table>
<tableCaption confidence="0.999545">
Table 2: Accuracy percentages averaged over all twenty test words
</tableCaption>
<bodyText confidence="0.999798666666667">
as LSA) on our multilingual bag-of-words sets in
order to detect latent semantic topics in the multi-
lingual feature base. Finally, we want to evaluate
to which extent the integration of our WSD output
helps practical applications such as Machine Trans-
lation or Information Retrieval.
</bodyText>
<sectionHeader confidence="0.986923" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.990359333333333">
We thank the anonymous reviewers for their valu-
able remarks. This research was funded by the Uni-
versity College Research Fund.
</bodyText>
<sectionHeader confidence="0.995708" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99949">
E. Agirre and P. Edmonds, editors. 2006. Word Sense
Disambiguation. Algorithms and Applications. Text,
Speech and Language Technology. Springer, Dor-
drecht.
M. Carpuat and D. Wu. 2007. Improving statistical
machine translation using word sense disambiguation.
In Proceedings of the 2007 Joint Conference on Em-
pirical Methods in Natural Language Processing and
Computational Natural Language Learning (EMNLP-
CoNLL), pages 61–72, Prague, Czech Republic.
Y.S. Chan and H.T. Ng. 2005. Scaling Up Word Sense
Disambiguation via Parallel Texts. In Proceedings of
the 20th National Conference on Artificial Intelligence
(AAAI 2005), pages 1037–1042, Pittsburgh, Pennsyl-
vania, USA.
Y.S. Chan, H.T. Ng, and D. Chiang. 2007. Word sense
disambiguation improves statistical machine transla-
tion. In Proceedings of the 45th Annual Meeting of the
Association of Computational Linguistics, pages 33–
40, Prague, Czech Republic.
W. Daelemans and V. Hoste. 2002. Evaluation of Ma-
chine Learning Methods for Natural Language Pro-
cessing Tasks. In Proceedings of the third Interna-
tional Conference on Language Resources and Eval-
uation (LREC’02), pages 755–760.
W. Daelemans and A. van den Bosch. 2005. Memory-
based Language Processing. Cambridge University
Press.
W. Daelemans, V. Hoste, F. De Meulder, and B. Naudts.
2003. Combined optimization of feature selection and
</reference>
<page confidence="0.992092">
321
</page>
<reference confidence="0.999526204545455">
algorithm parameters in machine learning of language.
Machine Learning, pages 84–95.
I. Dagan and A. Itai. 1994. Word sense disambiguation
using a second language monolingual corpus. Compu-
tational Linguistics, 20(4):563–596.
M. Diab and P. Resnik. 2002. An Unsupervised Method
for Word Sense Tagging Using Parallel Corpora. In
Proceedings of ACL, pages 255–262.
C. Fellbaum. 1998. WordNet: An Electronic Lexical
Database. MIT Press.
W.A. Gale and K.W. Church. 1993. A program for align-
ing sentences in bilingual corpora. Computational
Linguistics, 19(1):75–102.
W. Guo and M. Diab. 2010. COLEPL and COLSLM: An
Unsupervised WSD Approach to Multilingual Lexical
Substitution, Tasks 2 and 3 SemEval 2010. In Pro-
ceedings of the 5th International Workshop on Seman-
tic Evaluation, pages 129–133, Uppsala, Sweden. As-
sociation for Computational Linguistics.
V. Hoste, I. Hendrickx, W. Daelemans, and A. van den
Bosch. 2002. Parameter Optimization for Machine-
Learning of Word Sense Disambiguation. Natural
Language Engineering, Special Issue on Word Sense
Disambiguation Systems, 8:311–325.
N. Ide, T. Erjavec, and D. Tufis¸. 2002. Sense discrimi-
nation with parallel corpora.. In ACL-2002 Workhop
on Word Sense Disambiguation: Recent Successes and
Future Directions, pages 54–60, Philadelphia.
Ph. Koehn. 2005. Europarl: a parallel corpus for statisti-
cal machine translation. In Tenth Machine Translation
Summit, pages 79–86, Phuket, Thailand.
E. Lefever and V. Hoste. 2010a. Construction
of a Benchmark Data Set for Cross-Lingual Word
Sense Disambiguation. In Nicoletta Calzolari, Khalid
Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk,
Stelios Piperidis, and Daniel Tapias, editors, Proceed-
ings of the seventh International Conference on Lan-
guage Resources and Evaluation (LREC’10), Valletta,
Malta, May. European Language Resources Associa-
tion (ELRA).
E. Lefever and V. Hoste. 2010b. SemEval-2010 Task
3: Cross-Lingual Word Sense Disambiguation. In
Proceedings of the 5th International Workshop on Se-
mantic Evaluation, ACL 2010, pages 15–20, Uppsala,
Sweden.
E. Lefever and V. Hoste. 2011. Examining the Validity
of Cross-Lingual Word Sense Disambiguation. In Pro-
ceedings of the Conference on Computational Linguis-
tics and Intelligent Text Processing (CICLing 2011),
Tokyo, Japan.
D. McCarthy and R. Navigli. 2007. SemEval-2007 Task
10: English Lexical Substitution Task. In Proceedings
of the 4th International Workshop on Semantic Eval-
uations (SemEval-2007), pages 48–53, Prague, Czech
Republic.
H.T. Ng, B. Wang, and Y.S. Chan. 2003. Exploiting par-
allel texts for word sense disambiguation: An empiri-
cal study. In 41st Annual Meeting of the Association
for Computational Linguistics (ACL), pages 455–462,
Sapporo, Japan.
F. J. Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
Linguistics, 29(1):19–51.
H. Schmid. 1994. Probabilistic part-of-speech tagging
using decision trees. In Proceedings of the Interna-
tional Conference on new methods in Language Pro-
cessing, Manchester, UK.
R. Shah, B. Lin, A. Gershman, and R. Frederking. 2010.
SYNERGY: A Named Entity Recognition System for
Resource-scarce Languages such as Swahili using On-
line Machine Translation. In Proceedings of the
Second Workshop on African Language Technology
(AFLAT 2010), Valletta, Malt.
D. Tufis¸, R. Ion, and N. Ide. 2004. Fine-Grained
Word Sense Disambiguation Based on Parallel Cor-
pora, Word Alignment, Word Clustering and Aligned
Wordnets. In Proceedings of the 20th International
Conference on Computational Linguistics (COLING
2004), pages 1312–1318, Geneva, Switzerland, Au-
gust. Association for Computational Linguistics.
M. van Gompel. 2010. UvT-WSD1: A Cross-Lingual
Word Sense Disambiguation System. In Proceedings
of the 5th International Workshop on Semantic Evalu-
ation, pages 238–241, Uppsala, Sweden. Association
for Computational Linguistics.
P. Vossen, editor. 1998. EuroWordNet: a multilingual
database with lexical semantic networks. Kluwer Aca-
demic Publishers, Norwell, MA, USA.
</reference>
<page confidence="0.99835">
322
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.201585">
<title confidence="0.999587">ParaSense or How to Use Parallel Corpora for Word Sense Disambiguation</title>
<author confidence="0.528862">V´eronique</author>
<author confidence="0.528862">Martine De</author>
<affiliation confidence="0.562477">Language and Translation Technology Team, University College</affiliation>
<address confidence="0.705853">Groot-Brittanni¨elaan 45, 9000 Gent, of Applied Mathematics and Computer Science, Ghent Krijgslaan 281 (S9), 9000 Gent, of Linguistics, Ghent Blandijnberg 2, 9000 Gent, Belgium</address>
<abstract confidence="0.997524260869565">This paper describes a set of exploratory experiments for a multilingual classificationbased approach to Word Sense Disambiguation. Instead of using a predefined monolingual sense-inventory such as WordNet, we use a language-independent framework where the word senses are derived automatically from word alignments on a parallel corpus. We built five classifiers with English as an input language and translations in the five supported languages (viz. French, Dutch, Italian, Spanish and German) as classification output. The feature vectors incorporate both the more traditional local context features, as well as binary bag-of-words features that are extracted from the aligned translations. Our results show that the ParaSense multilingual WSD system shows very competitive results compared to the best systems that were evaluated on the SemEval-2010 Cross-Lingual Word Sense Disambiguation task for all five target languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>P Edmonds</author>
<author>editors</author>
</authors>
<title>Word Sense Disambiguation. Algorithms and Applications. Text, Speech and Language Technology.</title>
<date>2006</date>
<publisher>Springer,</publisher>
<location>Dordrecht.</location>
<marker>Agirre, Edmonds, editors, 2006</marker>
<rawString>E. Agirre and P. Edmonds, editors. 2006. Word Sense Disambiguation. Algorithms and Applications. Text, Speech and Language Technology. Springer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Carpuat</author>
<author>D Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL),</booktitle>
<pages>61--72</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2432" citStr="Carpuat and Wu (2007)" startWordPosition="362" endWordPosition="365">ther than English), we decided to take a multilingual approach to WSD, that builds up the sense inventory on the basis of the Europarl parallel corpus (Koehn, 2005). Using translations from a parallel corpus implicitly deals with the granularity problem as finer sense distinctions are only relevant as far as they are lexicalized in the target translations. It also facilitates the integration of WSD in multilingual applications such as multilingual Information Retrieval (IR) or Machine Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence </context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>M. Carpuat and D. Wu. 2007. Improving statistical machine translation using word sense disambiguation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLPCoNLL), pages 61–72, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>H T Ng</author>
</authors>
<title>Scaling Up Word Sense Disambiguation via Parallel Texts.</title>
<date>2005</date>
<booktitle>In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI</booktitle>
<pages>1037--1042</pages>
<location>Pittsburgh, Pennsylvania, USA.</location>
<contexts>
<context position="2916" citStr="Chan and Ng, 2005" startWordPosition="440" endWordPosition="443">e Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufis¸ et al., 2004). The research described in this paper is novel as it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. To this end, we build further on two well-known research ideas: (1) the possibility to use parallel corpora to extract translation labels and features in an automated way and (2) the assumption that incorporating evidence from multiple languages into the feature vector will be m</context>
</contexts>
<marker>Chan, Ng, 2005</marker>
<rawString>Y.S. Chan and H.T. Ng. 2005. Scaling Up Word Sense Disambiguation via Parallel Texts. In Proceedings of the 20th National Conference on Artificial Intelligence (AAAI 2005), pages 1037–1042, Pittsburgh, Pennsylvania, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y S Chan</author>
<author>H T Ng</author>
<author>D Chiang</author>
</authors>
<title>Word sense disambiguation improves statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>33--40</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2455" citStr="Chan et al. (2007)" startWordPosition="367" endWordPosition="370">ided to take a multilingual approach to WSD, that builds up the sense inventory on the basis of the Europarl parallel corpus (Koehn, 2005). Using translations from a parallel corpus implicitly deals with the granularity problem as finer sense distinctions are only relevant as far as they are lexicalized in the target translations. It also facilitates the integration of WSD in multilingual applications such as multilingual Information Retrieval (IR) or Machine Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufis¸ et al., 2004). </context>
</contexts>
<marker>Chan, Ng, Chiang, 2007</marker>
<rawString>Y.S. Chan, H.T. Ng, and D. Chiang. 2007. Word sense disambiguation improves statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 33– 40, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>V Hoste</author>
</authors>
<title>Evaluation of Machine Learning Methods for Natural Language Processing Tasks.</title>
<date>2002</date>
<booktitle>In Proceedings of the third International Conference on Language Resources and Evaluation (LREC’02),</booktitle>
<pages>755--760</pages>
<contexts>
<context position="6263" citStr="Daelemans and Hoste, 2002" startWordPosition="966" endWordPosition="970">his • local context features related to a window of word alignment output as oracle information, we re- three words preceding and following the focus defined the CLWSD task as a classification task. word containing for each of these words their To train our five classifiers (English as input lan- full form, lemma, Part-of-Speech and chunk inguage and French, German, Dutch, Italian and Span- formation ish as focus languages), we used the memory-based In addition to these well known monolingual fealearning (MBL) algorithm implemented in TIMBL tures, we extracted a set of binary bag-of-words fea(Daelemans and Hoste, 2002), which has success- tures from the aligned translation that are not the fully been deployed in previous WSD classification target language of the classifier (e.g. for the Dutch tasks (Hoste et al., 2002). We performed heuris- classifier, we extract bag-of-words features from the tic experiments to define the parameter settings for Italian, Spanish, French and German aligned transthe classifier, leading to the selection of the Jef- lations). In order to extract useful content words, frey Divergence distance metric, Gain Ratio feature we first ran Part-of-Speech tagging and lemmatisaweighting a</context>
</contexts>
<marker>Daelemans, Hoste, 2002</marker>
<rawString>W. Daelemans and V. Hoste. 2002. Evaluation of Machine Learning Methods for Natural Language Processing Tasks. In Proceedings of the third International Conference on Language Resources and Evaluation (LREC’02), pages 755–760.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>A van den Bosch</author>
</authors>
<title>Memorybased Language Processing.</title>
<date>2005</date>
<publisher>Cambridge University Press.</publisher>
<marker>Daelemans, van den Bosch, 2005</marker>
<rawString>W. Daelemans and A. van den Bosch. 2005. Memorybased Language Processing. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>V Hoste</author>
<author>F De Meulder</author>
<author>B Naudts</author>
</authors>
<title>Combined optimization of feature selection and algorithm parameters in machine learning of language.</title>
<date>2003</date>
<booktitle>Machine Learning,</booktitle>
<pages>84--95</pages>
<marker>Daelemans, Hoste, De Meulder, Naudts, 2003</marker>
<rawString>W. Daelemans, V. Hoste, F. De Meulder, and B. Naudts. 2003. Combined optimization of feature selection and algorithm parameters in machine learning of language. Machine Learning, pages 84–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dagan</author>
<author>A Itai</author>
</authors>
<title>Word sense disambiguation using a second language monolingual corpus.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="2939" citStr="Dagan and Itai, 1994" startWordPosition="444" endWordPosition="448"> Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufis¸ et al., 2004). The research described in this paper is novel as it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. To this end, we build further on two well-known research ideas: (1) the possibility to use parallel corpora to extract translation labels and features in an automated way and (2) the assumption that incorporating evidence from multiple languages into the feature vector will be more informative than a </context>
</contexts>
<marker>Dagan, Itai, 1994</marker>
<rawString>I. Dagan and A. Itai. 1994. Word sense disambiguation using a second language monolingual corpus. Computational Linguistics, 20(4):563–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Diab</author>
<author>P Resnik</author>
</authors>
<title>An Unsupervised Method for Word Sense Tagging Using Parallel Corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>255--262</pages>
<contexts>
<context position="2897" citStr="Diab and Resnik, 2002" startWordPosition="436" endWordPosition="439">etrieval (IR) or Machine Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufis¸ et al., 2004). The research described in this paper is novel as it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. To this end, we build further on two well-known research ideas: (1) the possibility to use parallel corpora to extract translation labels and features in an automated way and (2) the assumption that incorporating evidence from multiple languages into the featu</context>
</contexts>
<marker>Diab, Resnik, 2002</marker>
<rawString>M. Diab and P. Resnik. 2002. An Unsupervised Method for Word Sense Tagging Using Parallel Corpora. In Proceedings of ACL, pages 255–262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3718" citStr="Fellbaum, 1998" startWordPosition="570" endWordPosition="571"> it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. To this end, we build further on two well-known research ideas: (1) the possibility to use parallel corpora to extract translation labels and features in an automated way and (2) the assumption that incorporating evidence from multiple languages into the feature vector will be more informative than a more restricted set of monolingual or bilingual features. Furthermore, our WSD system does not use any information from external lexical resources such as WordNet (Fellbaum, 1998) or EuroWordNet (Vossen, 1998). 317 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics:shortpapers, pages 317–322, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics 2 Experimental Setup prepositions. In future work, we will investigate Starting point of the experiments was the six-lingual other word alignment strategies and measure the imsentence-aligned Europarl corpus that was used in pact on the classification scores. The second training the SemEval-2010 “Cross-Lingual Word Sense Dis- set uses manually verified word ali</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W A Gale</author>
<author>K W Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="2857" citStr="Gale and Church, 1993" startWordPosition="428" endWordPosition="431">tions such as multilingual Information Retrieval (IR) or Machine Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufis¸ et al., 2004). The research described in this paper is novel as it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. To this end, we build further on two well-known research ideas: (1) the possibility to use parallel corpora to extract translation labels and features in an automated way and (2) the assumption that incorporating evidenc</context>
</contexts>
<marker>Gale, Church, 1993</marker>
<rawString>W.A. Gale and K.W. Church. 1993. A program for aligning sentences in bilingual corpora. Computational Linguistics, 19(1):75–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Guo</author>
<author>M Diab</author>
</authors>
<title>COLEPL and COLSLM: An Unsupervised WSD Approach to Multilingual Lexical Substitution,</title>
<date>2010</date>
<journal>Tasks</journal>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<volume>2</volume>
<pages>129--133</pages>
<institution>Uppsala, Sweden. Association for Computational Linguistics.</institution>
<contexts>
<context position="12327" citStr="Guo and Diab, 2010" startWordPosition="1962" endWordPosition="1965"> participated for Dutch and Spanish) and T3-COLEUR. The UvT-WSD system (van Gompel, 2010), that also uses a k-nearest neighbor classifier and a variety of local and global context features, obtained the best scores for Spanish and Dutch in the SemEval CLWSD competition. Although we also use a memory-based learner, our method is different from this system in the way the feature vectors are constructed. Next to the incorporation of similar local context features, we also include evidence from multiple languages in our feature vector. For French, Italian and German however, the T3-COLEUR system (Guo and Diab, 2010) outperformed the other systems in the SemEval competition. This system adopts a different approach: during the training phase a monolingual WSD system processes the English input sentence and a word alignment module is used to extract the aligned translation. The English senses together with their aligned translations (and probabilPrec = Eai:iEA Fres2ai fre9res jaij |Hi| 319 ity scores) are then stored in a word sense translation table, in which look-ups are performed during the testing phase. This system also differs from the Uvt-WSD and ParaSense systems in the sense that the word senses ar</context>
</contexts>
<marker>Guo, Diab, 2010</marker>
<rawString>W. Guo and M. Diab. 2010. COLEPL and COLSLM: An Unsupervised WSD Approach to Multilingual Lexical Substitution, Tasks 2 and 3 SemEval 2010. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 129–133, Uppsala, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Hoste</author>
<author>I Hendrickx</author>
<author>W Daelemans</author>
<author>A van den Bosch</author>
</authors>
<title>Parameter Optimization for MachineLearning of Word Sense Disambiguation. Natural Language Engineering, Special Issue on Word Sense Disambiguation Systems,</title>
<date>2002</date>
<pages>8--311</pages>
<marker>Hoste, Hendrickx, Daelemans, van den Bosch, 2002</marker>
<rawString>V. Hoste, I. Hendrickx, W. Daelemans, and A. van den Bosch. 2002. Parameter Optimization for MachineLearning of Word Sense Disambiguation. Natural Language Engineering, Special Issue on Word Sense Disambiguation Systems, 8:311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>T Erjavec</author>
<author>D Tufis¸</author>
</authors>
<title>Sense discrimination with parallel corpora..</title>
<date>2002</date>
<booktitle>In ACL-2002 Workhop on Word Sense Disambiguation: Recent Successes and Future Directions,</booktitle>
<pages>54--60</pages>
<location>Philadelphia.</location>
<marker>Ide, Erjavec, Tufis¸, 2002</marker>
<rawString>N. Ide, T. Erjavec, and D. Tufis¸. 2002. Sense discrimination with parallel corpora.. In ACL-2002 Workhop on Word Sense Disambiguation: Recent Successes and Future Directions, pages 54–60, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koehn</author>
</authors>
<title>Europarl: a parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Tenth Machine Translation Summit,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="1975" citStr="Koehn, 2005" startWordPosition="293" endWordPosition="294">nguages. 1 Introduction Word Sense Disambiguation (WSD) is the NLP task that consists in selecting the correct sense of a polysemous word in a given context. Most stateof-the-art WSD systems are supervised classifiers that are trained on manually sense-tagged corpora, which are very time-consuming and expensive to build (Agirre and Edmonds, 2006) . In order to overcome this acquisition bottleneck (sense-tagged corpora are scarce for languages other than English), we decided to take a multilingual approach to WSD, that builds up the sense inventory on the basis of the Europarl parallel corpus (Koehn, 2005). Using translations from a parallel corpus implicitly deals with the granularity problem as finer sense distinctions are only relevant as far as they are lexicalized in the target translations. It also facilitates the integration of WSD in multilingual applications such as multilingual Information Retrieval (IR) or Machine Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation fr</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Ph. Koehn. 2005. Europarl: a parallel corpus for statistical machine translation. In Tenth Machine Translation Summit, pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="false">
<authors>
<author>E Lefever</author>
<author>V Hoste</author>
</authors>
<title>Construction of a Benchmark Data Set for Cross-Lingual Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>Proceedings of the seventh International Conference on Language Resources and Evaluation (LREC’10),</booktitle>
<editor>In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, and Daniel Tapias, editors,</editor>
<location>Valletta, Malta,</location>
<contexts>
<context position="10067" citStr="Lefever and Hoste (2010" startWordPosition="1580" endWordPosition="1583">task. The sense inventory was built up on the basis of the Europarl corpus: all retrieved translations of a polysemous word were manually grouped into clusters, which constitute different senses of that given word. The test instances were selected from the JRC-ACQUIS Multilingual Parallel Corpus2 and BNC3. To label the test data, native speakers provided their top three translations from the predefined clusters of Europarl translations, in order to assign frequency weights to the set of gold standard translations. A more detailed description of the construction of the data set can be found in Lefever and Hoste (2010a). As evaluation metrics, we used both the SemEval BEST precision metric from the CLWSD task as well as a straightforward accuracy measure. The SemEval metric takes into account the frequency weights of the gold standard translations: translations that were picked by different annotators get a higher weight. For the BEST evaluation, systems 1http://code.google.com/apis/language/ 2http://wt.jrc.it/lt/Acquis/ 3http://www.natcorp.ox.ac.uk/ can propose as many guesses as the system believes are correct, but the resulting score is divided by the number of guesses. In this way, systems that output </context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>E. Lefever and V. Hoste. 2010a. Construction of a Benchmark Data Set for Cross-Lingual Word Sense Disambiguation. In Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odijk, Stelios Piperidis, and Daniel Tapias, editors, Proceedings of the seventh International Conference on Language Resources and Evaluation (LREC’10), Valletta, Malta, May. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lefever</author>
<author>V Hoste</author>
</authors>
<title>SemEval-2010 Task 3: Cross-Lingual Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010,</booktitle>
<pages>15--20</pages>
<location>Uppsala,</location>
<contexts>
<context position="10067" citStr="Lefever and Hoste (2010" startWordPosition="1580" endWordPosition="1583">task. The sense inventory was built up on the basis of the Europarl corpus: all retrieved translations of a polysemous word were manually grouped into clusters, which constitute different senses of that given word. The test instances were selected from the JRC-ACQUIS Multilingual Parallel Corpus2 and BNC3. To label the test data, native speakers provided their top three translations from the predefined clusters of Europarl translations, in order to assign frequency weights to the set of gold standard translations. A more detailed description of the construction of the data set can be found in Lefever and Hoste (2010a). As evaluation metrics, we used both the SemEval BEST precision metric from the CLWSD task as well as a straightforward accuracy measure. The SemEval metric takes into account the frequency weights of the gold standard translations: translations that were picked by different annotators get a higher weight. For the BEST evaluation, systems 1http://code.google.com/apis/language/ 2http://wt.jrc.it/lt/Acquis/ 3http://www.natcorp.ox.ac.uk/ can propose as many guesses as the system believes are correct, but the resulting score is divided by the number of guesses. In this way, systems that output </context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>E. Lefever and V. Hoste. 2010b. SemEval-2010 Task 3: Cross-Lingual Word Sense Disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 15–20, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lefever</author>
<author>V Hoste</author>
</authors>
<title>Examining the Validity of Cross-Lingual Word Sense Disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics and Intelligent Text Processing (CICLing 2011),</booktitle>
<location>Tokyo, Japan.</location>
<contexts>
<context position="14677" citStr="Lefever and Hoste, 2011" startWordPosition="2339" endWordPosition="2342">e same Europarl data, the scores illustrate the potential advantages of using a multilingual approach. Although we applied a very basic strategy for the selection of our bag-of-words translation features (we did not perform any filtering on the translations except for Part-of-Speech information), we observe that for three languages the full feature vector outperforms the classifier that uses the more traditional WSD local context features. For Dutch, the classifier that merely uses translation features even outperforms the classifier that uses the local context features. In previous research (Lefever and Hoste, 2011), we showed that the classifier using evidence from all different languages was constantly better than the ones using less or no multilingual evidence. In addition, the scores also degraded relatively to the number of translation features that was used. As we used a different set of translation features for the latter pilot experiments (we only used the translations of the ambiguous words instead of the full bag-ofwords features we used for the current setup), we need to confirm this trend with more experiments using the current feature sets. Another important observation is that the classific</context>
</contexts>
<marker>Lefever, Hoste, 2011</marker>
<rawString>E. Lefever and V. Hoste. 2011. Examining the Validity of Cross-Lingual Word Sense Disambiguation. In Proceedings of the Conference on Computational Linguistics and Intelligent Text Processing (CICLing 2011), Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>R Navigli</author>
</authors>
<title>SemEval-2007 Task 10: English Lexical Substitution Task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>48--53</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="10804" citStr="McCarthy and Navigli (2007)" startWordPosition="1689" endWordPosition="1692">aightforward accuracy measure. The SemEval metric takes into account the frequency weights of the gold standard translations: translations that were picked by different annotators get a higher weight. For the BEST evaluation, systems 1http://code.google.com/apis/language/ 2http://wt.jrc.it/lt/Acquis/ 3http://www.natcorp.ox.ac.uk/ can propose as many guesses as the system believes are correct, but the resulting score is divided by the number of guesses. In this way, systems that output a lot of guesses are not favoured. For a more detailed description of the SemEval scoring scheme, we refer to McCarthy and Navigli (2007). Following variables are used for the SemEval precision formula. Let H be the set of annotators, T the set of test items and hi the set of responses for an item i ∈ T for annotator h ∈ H. Let A be the set of items from T where the system provides at least one answer and ai : i ∈ A the set of guesses from the system for item i. For each i, we calculate the multiset union (Hi) for all hi for all h ∈ H and for each unique type (res) in Hi that has an associated frequency (freqres). (1) |A| The second metric we use is a straightforward accuracy measure, that divides the number of correct answers </context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>D. McCarthy and R. Navigli. 2007. SemEval-2007 Task 10: English Lexical Substitution Task. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 48–53, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>B Wang</author>
<author>Y S Chan</author>
</authors>
<title>Exploiting parallel texts for word sense disambiguation: An empirical study.</title>
<date>2003</date>
<booktitle>In 41st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>455--462</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="2874" citStr="Ng et al., 2003" startWordPosition="432" endWordPosition="435">ual Information Retrieval (IR) or Machine Translation (MT). Significant improvements in terms of general MT quality were for the first time reported by Carpuat and Wu (2007) and Chan et al. (2007). Both papers describe the integration of a dedicated WSD module in a Chinese-English statistical machine translation framework and report statistically significant improvements in terms of standard MT evaluation metrics. Several studies have already shown the validity of using parallel corpora for sense discrimination (e.g. (Ide et al., 2002)), for bilingual WSD modules (e.g. (Gale and Church, 1993; Ng et al., 2003; Diab and Resnik, 2002; Chan and Ng, 2005; Dagan and Itai, 1994)) and for WSD systems that use a combination of existing WordNets with multilingual evidence (Tufis¸ et al., 2004). The research described in this paper is novel as it presents a truly multilingual classification-based approach to WSD that directly incorporates evidence from four other languages. To this end, we build further on two well-known research ideas: (1) the possibility to use parallel corpora to extract translation labels and features in an automated way and (2) the assumption that incorporating evidence from multiple l</context>
</contexts>
<marker>Ng, Wang, Chan, 2003</marker>
<rawString>H.T. Ng, B. Wang, and Y.S. Chan. 2003. Exploiting parallel texts for word sense disambiguation: An empirical study. In 41st Annual Meeting of the Association for Computational Linguistics (ACL), pages 455–462, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="5129" citStr="Och and Ney, 2003" startWordPosition="779" endWordPosition="782">e upper bound on the current English ambiguous nouns that consists in assign- experimental setup. ing a correct translation in the five supported tar- All English sentences were preprocessed get languages (viz. French, Italian, Spanish, Ger- by means of a memory-based shallow parser man and Dutch) for an ambiguous focus word in a (MBSP) (Daelemans and van den Bosch, 2005) that given context. In order to detect the relevant transla- performs tokenization, Part-of-Speech tagging and tions for each of the twenty ambiguous focus words, text chunking. The preprocessed sentences were we ran GIZA++ (Och and Ney, 2003) with its de- used as input to build a set of commonly used WSD fault settings for all focus words. This word align- features related to the English input sentence: ment output was then considered to be the label for • features related to the focus word itself being the training instances for the corresponding classi- the word form of the focus word, the lemma, fier (e.g. the Dutch translation is the label that is used Part-of-Speech and chunk information to train the Dutch classifier). By considering this • local context features related to a window of word alignment output as oracle informat</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J. Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on new methods in Language Processing,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="6946" citStr="Schmid, 1994" startWordPosition="1076" endWordPosition="1077">he fully been deployed in previous WSD classification target language of the classifier (e.g. for the Dutch tasks (Hoste et al., 2002). We performed heuris- classifier, we extract bag-of-words features from the tic experiments to define the parameter settings for Italian, Spanish, French and German aligned transthe classifier, leading to the selection of the Jef- lations). In order to extract useful content words, frey Divergence distance metric, Gain Ratio feature we first ran Part-of-Speech tagging and lemmatisaweighting and k = 7 as number of nearest neigh- tion by means of the Treetagger (Schmid, 1994) tool. bours. In future work, we plan to use an optimized Per ambiguous focus word, a list of content words word-expert approach in which a genetic algorithm (nouns, adjectives, verbs and adverbs) was extracted performs joint feature selection and parameter op- that occurred in the aligned translations of the Entimization per ambiguous word (Daelemans et al., glish sentences containing the focus word. One bi2003). nary feature per selected content word was then creFor our feature vector creation, we combined a set ated per ambiguous word: ‘0’ in case the word does of English local context feat</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>H. Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In Proceedings of the International Conference on new methods in Language Processing, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Shah</author>
<author>B Lin</author>
<author>A Gershman</author>
<author>R Frederking</author>
</authors>
<title>SYNERGY: A Named Entity Recognition System for Resource-scarce Languages such as Swahili using Online Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Second Workshop on African Language Technology (AFLAT 2010),</booktitle>
<location>Valletta, Malt.</location>
<contexts>
<context position="8973" citStr="Shah et al., 2010" startWordPosition="1403" endWordPosition="1406">atures that were also extracted for the training instances. For the construction of the bag-of-words features however, we need to adopt a different approach as we do not have aligned translations for the English test instances at our disposal. We decided to deploy a novel strategy that uses the Google Translate API1 to automatically generate a translation for all English test instances in the five supported languages. Online machine translations tools have already been used before to create artificial parallel corpora that were used for NLP tasks such as for instance Named Entity Recognition (Shah et al., 2010). In a next step the automatically generated translation was preprocessed in the same way as the training translations (Part-of-Speech-tagged and lemmatized). The resulting lemmas were then used to construct the same set of binary bag-of-words features that were stored for the training instances of the ambiguous focus word. 3 Evaluation To evaluate our five classifiers, we used the sense inventory and test set of the SemEval “Cross-Lingual Word Sense Disambiguation” task. The sense inventory was built up on the basis of the Europarl corpus: all retrieved translations of a polysemous word were </context>
</contexts>
<marker>Shah, Lin, Gershman, Frederking, 2010</marker>
<rawString>R. Shah, B. Lin, A. Gershman, and R. Frederking. 2010. SYNERGY: A Named Entity Recognition System for Resource-scarce Languages such as Swahili using Online Machine Translation. In Proceedings of the Second Workshop on African Language Technology (AFLAT 2010), Valletta, Malt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Tufis¸</author>
<author>R Ion</author>
<author>N Ide</author>
</authors>
<title>Fine-Grained Word Sense Disambiguation Based on Parallel Corpora, Word Alignment, Word Clustering and Aligned Wordnets.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>1312--1318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Geneva, Switzerland,</location>
<marker>Tufis¸, Ion, Ide, 2004</marker>
<rawString>D. Tufis¸, R. Ion, and N. Ide. 2004. Fine-Grained Word Sense Disambiguation Based on Parallel Corpora, Word Alignment, Word Clustering and Aligned Wordnets. In Proceedings of the 20th International Conference on Computational Linguistics (COLING 2004), pages 1312–1318, Geneva, Switzerland, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M van Gompel</author>
</authors>
<title>UvT-WSD1: A Cross-Lingual Word Sense Disambiguation System.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>238--241</pages>
<institution>Uppsala, Sweden. Association for Computational Linguistics.</institution>
<marker>van Gompel, 2010</marker>
<rawString>M. van Gompel. 2010. UvT-WSD1: A Cross-Lingual Word Sense Disambiguation System. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 238–241, Uppsala, Sweden. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
<author>editor</author>
</authors>
<title>EuroWordNet: a multilingual database with lexical semantic networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Norwell, MA, USA.</location>
<marker>Vossen, editor, 1998</marker>
<rawString>P. Vossen, editor. 1998. EuroWordNet: a multilingual database with lexical semantic networks. Kluwer Academic Publishers, Norwell, MA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>