<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.153062">
<title confidence="0.998195">
Integrating Discourse Markers into a
Pipelined Natural Language Generation Architecture
</title>
<author confidence="0.825691">
Charles B. Callaway
</author>
<affiliation confidence="0.801244">
ITC-irst, Trento, Italy
</affiliation>
<address confidence="0.893817">
via Sommarive, 18
Povo (Trento), Italy, I-38050
</address>
<email confidence="0.996581">
callaway@itc.it
</email>
<sectionHeader confidence="0.998516" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997819823529412">
Pipelined Natural Language Generation
(NLG) systems have grown increasingly
complex as architectural modules were
added to support language functionali-
ties such as referring expressions, lexical
choice, and revision. This has given rise to
discussions about the relative placement
of these new modules in the overall archi-
tecture. Recent work on another aspect
of multi-paragraph text, discourse mark-
ers, indicates it is time to consider where a
discourse marker insertion algorithm fits
in. We present examples which suggest
that in a pipelined NLG architecture, the
best approach is to strongly tie it to a revi-
sion component. Finally, we evaluate the
approach in a working multi-page system.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993547826087">
Historically, work on NLG architecture has focused
on integrating major disparate architectural modules
such as discourse and sentence planners and sur-
face realizers. More recently, as it was discovered
that these components by themselves did not cre-
ate highly readable prose, new types of architectural
modules were introduced to deal with newly desired
linguistic phenomena such as referring expressions,
lexical choice, revision, and pronominalization.
Adding each new module typically entailed that
an NLG system designer would justify not only the
reason for including the new module (i.e., what lin-
guistic phenomena it produced that had been pre-
viously unattainable) but how it was integrated into
their architecture and why its placement was reason-
ably optimal (cf., (Elhadad et al., 1997), pp. 4–7).
At the same time, (Reiter, 1994) argued that im-
plemented NLG systems were converging toward
a de facto pipelined architecture (Figure 1) with
minimal-to-nonexistent feedback between modules.
Although several NLG architectures were pro-
posed in opposition to such a linear arrangement
(Kantrowitz and Bates, 1992; Cline, 1994), these re-
search projects have not continued while pipelined
architectures are still actively being pursued.
In addition, Reiter concludes that although com-
plete integration of architectural components is the-
oretically a good idea, in practical engineering terms
such a system would be too inefficient to operate and
too complex to actually implement. Significantly,
Reiter states that fully interconnecting every module
would entail constructing N(N — 1) interfaces be-
tween them. As the number of modules rises (i.e., as
the number of large-scale features an NLG engineer
wants to implement rises) the implementation cost
rises exponentially. Moreover, this cost does not in-
clude modifications that are not component specific,
such as multilingualism.
As text planners scale up to produce ever larger
texts, the switch to multi-page prose will introduce
new features, and consequentially the number of
architectural modules will increase. For example,
Mooney’s EEG system (Mooney, 1994), which cre-
ated a full-page description of the Three-Mile Island
nuclear plant disaster, contains components for dis-
course knowledge, discourse organization, rhetori-
</bodyText>
<figureCaption confidence="0.999222">
Figure 1: A Typical Pipelined NLG Architecture
</figureCaption>
<bodyText confidence="0.99963512">
cal relation structuring, sentence planning, and sur-
face realization. Similarly, the STORYBOOK system
(Callaway and Lester, 2002), which generated 2 to
3 pages of narrative prose in the Little Red Riding
Hood fairy tale domain, contained seven separate
components.
This paper examines the interactions of two lin-
guistic phenomena at the paragraph level: revision
(specifically, clause aggregation, migration and de-
motion) and discourse markers. Clause aggregation
involves the syntactic joining of two simple sen-
tences into a more complex sentence. Discourse
markers link two sentences semantically without
necessarily joining them syntactically. Because both
of these phenomena produce changes in the text
at the clause-level, a lack of coordination between
them can produce interference effects.
We thus hypothesize that the architectural mod-
ules corresponding to revision and discourse marker
selection should be tightly coupled. We then first
summarize current work in discourse markers and
revision, provide examples where these phenomena
interfere with each other, describe an implemented
technique for integrating the two, and report on a
preliminary system evaluation.
</bodyText>
<sectionHeader confidence="0.96115" genericHeader="method">
2 Discourse Markers in NLG
</sectionHeader>
<bodyText confidence="0.999059986111111">
Discourse markers, or cue words, are single words
or small phrases which mark specific semantic rela-
tions between adjacent sentences or small groups of
sentences in a text. Typical examples include words
like however, next, and because. Discourse markers
pose a problem for both the parsing and generation
of clauses in a way similar to the problems that re-
ferring expressions pose to noun phrases: changing
the lexicalization of a discourse marker can change
the semantic interpretation of the clauses affected.
Recent work in the analysis of both the distribu-
tion and role of discourse markers has greatly ex-
tended our knowledge over even the most expansive
previous accounts of discourse connectives (Quirk
et al., 1985) from previous decades. For example,
using a large scale corpus analysis and human sub-
jects employing a substitution test over the corpus
sentences containing discourse markers, Knott and
Mellish (1996) distilled a taxonomy of individual
lexical discourse markers and 8 binary-valued fea-
tures that could be used to drive a discourse marker
selection algorithm.
Other work often focuses on particular semantic
categories, such as temporal discourse markers. For
instance, Grote (1998) attempted to create declar-
ative lexicons that contain applicability conditions
and other constraints to aid in the process of dis-
course marker selection. Other theoretical research
consists, for example, of adapting existing grammat-
ical formalisms such as TAGs (Webber and Joshi,
1998) for discourse-level phenomena.
Alternatively, there are several implemented sys-
tems that automatically insert discourse markers into
multi-sentential text. In an early instance, Elhadad
and McKeown (1990) followed Quirk’s pre-existing
non-computational account of discourse connectives
to produce single argumentative discourse markers
inside a functional unification surface realizer (and
thereby postponing lexicalization till the last possi-
ble moment).
More recent approaches have tended to move the
decision time for marker lexicalization higher up the
pipelined architecture. For example, the MOOSE
system (Stede and Umbach, 1998; Grote and Stede,
1999) lexicalized discourse markers at the sentence
planning level by pushing them directly into the
lexicon. Similarly, Power et al. (1999) produce
multiple discourse markers for Patient Information
Leaflets using a constraint-based method applied to
RST trees during sentence planning.
Finally, in the CIRC-SIM intelligent tutoring sys-
tem (Yang et al., 2000) that generates connected di-
alogues for students studying heart ailments, dis-
course marker lexicalization has been pushed all the
way up to the discourse planning level. In this case,
CIRC-SIM lexicalizes discourse markers inside of
the discourse schema templates themselves.
Given that these different implemented discourse
marker insertion algorithms lexicalize their markers
at three distinct places in a pipelined NLG archi-
tecture, it is not clear if lexicalization can occur at
any point without restriction, or if it is in fact tied
to the particular architectural modules that a system
designer chooses to include.
The answer becomes clearer after noting that none
of the implemented discourse marker algorithms de-
scribed above have been incorporated into a com-
prehensive NLG architecture containing additional
significant components such as revision (with the
exception of MOOSE’s lexical choice component,
which Stede considers to be a submodule of the sen-
tence planner).
</bodyText>
<sectionHeader confidence="0.976702" genericHeader="method">
3 Current Implemented Revision Systems
</sectionHeader>
<bodyText confidence="0.999939949367089">
Revision (or clause aggregation) is principally con-
cerned with taking sets of small, single-proposition
sentences and finding ways to combine them into
more fluent, multiple-proposition sentences. Sen-
tences can be combined using a wide range of differ-
ent syntactic forms, such as conjunction with “and”,
making relative clauses with noun phrases common
to both sentences, and introducing ellipsis.
Typically, revision modules arise because of dis-
satisfaction with the quality of text produced by a
simple pipelined NLG system. As noted by Reape
and Mellish (1999), there is a wide variety in re-
vision definitions, objectives, operating level, and
type. Similarly, Dalianis and Hovy (1993) tried to
distinguish between different revision parameters by
having users perform revision thought experiments
and proposing rules in RST form which mimic the
behavior they observed.
While neither of these were implemented revi-
sion systems, there have been several attempts to im-
prove the quality of text from existing NLG systems.
There are two approaches to the architectural posi-
tion of revision systems: those that operate on se-
mantic representations before the sentence planning
level, of which a prototypical example is (Horacek,
2002), and those placed after the sentence planner,
operating on syntactic/linguistic data. Here we treat
mainly the second type, which have typically been
conceived of as “add-on” components to existing
pipelined architectures. An important implication of
this architectural order is that the revision compo-
nents expect to receive lexicalized sentence plans.
Of these systems, Robin’s STREAK system
(Robin, 1994) is the only one that accepts both lex-
icalized and non-lexicalized data. After a sentence
planner produces the required lexicalized informa-
tion that can form a complete and grammatical sen-
tence, STREAK attempts to gradually aggregate that
data. It then proceeds to try to opportunistically in-
clude additional optional information from a data
set of statistics, performing aggregation operations
at various syntactic levels. Because STREAK only
produces single sentences, it does not attempt to add
discourse markers. In addition, there is no a priori
way to determine whether adjacent propositions in
the input will remain adjacent in the final sentence.
The REVISOR system (Callaway and Lester,
1997) takes an entire sentence plan at once and it-
erates through it in paragraph-sized chunks, em-
ploying clause- and phrase-level aggregation and re-
ordering operations before passing a revised sen-
tence plan to the surface realizer. However, at no
point does it add information that previously did not
exist in the sentence plan. The RTPI system (Har-
vey and Carberry, 1998) takes in sets of multiple,
lexicalized sentential plans over a number of medi-
cal diagnoses from different critiquing systems and
produces a single, unified sentence plan which is
both coherent and cohesive.
Like STREAK, Shaw’s CASPER system (Shaw,
1998) produces single sentences from sets of sen-
tences and doesn’t attempt to deal with discourse
markers. CASPER also delays lexicalization when
aggregating by looking at the lexicon twice during
the revision process. This is due mainly to the effi-
ciency costs of the unification procedure. However,
CASPER’s sentence planner essentially uses the first
lexicon lookup to find a “set of lexicalizations” be-
fore eventually selecting a particular one.
An important similarity of these pipelined revi-
sion systems is that they all manipulate lexical-
ized representations at the clause level. Given that
both aggregation and reordering operators may sep-
arate clauses that were previously adjacent upon
leaving the sentence planner, the inclusion of a re-
vision component has important implications for
any upstream architectural module which assumed
that initially adjacent clauses would remain adjacent
throughout the generation process.
</bodyText>
<sectionHeader confidence="0.990151" genericHeader="method">
4 Architectural Implications
</sectionHeader>
<bodyText confidence="0.999969466666667">
The current state of the art in NLG can be described
as small pipelined generation systems that incorpo-
rate some, but not all, of the available pipelined
NLG modules. Specifically, there is no system to-
date which both revises its output and inserts ap-
propriate discourse markers. Additionally, there are
no systems which utilize the latest theoretical work
in discourse markers described in Section 2. But
as NLG systems begin to reach toward multi-page
text, combining both modules into a single architec-
ture will quickly become a necessity if such systems
are to achieve the quality of prose that is routinely
achieved by human authors.
This integration will not come without con-
straints. For instance, discourse marker insertion al-
gorithms assume that sentence plans are static ob-
jects. Thus any change to the static nature of sen-
tence plans will inevitably disrupt them. On the
other hand, revision systems currently do not add in-
formation not specified by the discourse planner, and
do not perform true lexicalization: any new lexemes
not present in the sentence plan are merely delayed
lexicon entry lookups. Finally, because revision is
potentially destructive, the sentence elements that
lead to a particular discourse marker being chosen
may be significantly altered or may not even exist in
a post-revision sentence plan.
These factors lead to two partial order constraints
on a system that both inserts discourse markers and
revises at the clause level after sentence planning:
</bodyText>
<listItem confidence="0.96705">
• Discourse marker lexicalization cannot pre-
cede revision
• Revision cannot precede discourse marker
lexicalization
</listItem>
<bodyText confidence="0.999839428571429">
In the first case, assume that a sentence plan ar-
rives at the revision module with discourse mark-
ers already lexicalized. Then the original discourse
marker may not be appropraite in the revised sen-
tence plan. For example, consider how the applica-
tion of the following revision types requires different
lexicalizations for the initial discourse markers:
</bodyText>
<listItem confidence="0.999114">
• Clause Aggregation: The merging of two
main clauses into one main clause and one sub-
ordinate clause:
</listItem>
<bodyText confidence="0.998492666666667">
John had always liked to ride motorbikes. T
On account of this, his wife passionately hated
motorbikes. ==&gt;
John had always liked to ride motorbikes,
which his wife {* on account of this I thus}
passionately hated.
</bodyText>
<listItem confidence="0.947625">
• Reordering: Two originally adjacent main
clauses no longer have the same fixed position
relative to each other:
</listItem>
<bodyText confidence="0.99962925">
Diesel motors are well known for emitting ex-
cessive pollutants. T Furthermore, diesel is
often transported unsafely. T However, diesel
motors are becoming cleaner. ==&gt;
Diesel motors are well known for emitting ex-
cessive pollutants, {* however I although}
they are becoming cleaner. Furthermore,
diesel is often transported unsafely.
</bodyText>
<listItem confidence="0.895860333333333">
• Clause Demotion: Two main clauses are
merged where one of them no longer has a
clause structure:
</listItem>
<bodyText confidence="0.999421">
The happy man went home. T However, the
man was poor. ==&gt;
The happy {* however I but} poor man went
home.
These examples show that if discourse marker
lexicalization occurs before clause revision, the
changes that the revision module makes can render
those discourse markers undesirable or even gram-
matically incorrect. Furthermore, these effects span
a wide range of potential revision types.
In the second case, assume that a sentence plan is
passed to the revision component, which performs
various revision operations before discourse mark-
ers are considered. In order to insert appropriate dis-
course markers, the insertion algorithm must access
the appropriate rhetorical structure produced by the
discourse planner. However, there is no guarantee
that the revision module has not altered the initial
organization imposed by the discourse planner. In
such a case, the underlying data used for discourse
marker selection may no longer be valid.
For example, consider the following generically
represented discourse plan:
</bodyText>
<listItem confidence="0.9898388">
C1: “John and his friends went to the party.”
[temporal “before” relation, time(C1, C2)]
C2: “John and his friends gathered at the mall.”
[causal relation, cause(C2, C3)]
C3: “John had been grounded.”
</listItem>
<bodyText confidence="0.999124896551724">
One possible revision that preserved the discourse
plan might be:
“Before John and his friends went to the party,
they gathered at the mall since he had been
grounded.”
In this case, the discourse marker algorithm has
selected “before” and “since” as lexicalized dis-
course markers prior to revision. But there are other
possible revisions that would destroy the ordering
established by the discourse plan and make the se-
lected discourse markers unwieldy:
“John, {* since I c} who had been grounded,
gathered with his friends at the mall before go-
ing to the party.”
“{* Since I Because} he had been grounded,
John and his friends gathered at the mall and
{* before I then} went to the party.”
Reordering sentences without updating the dis-
course relations in the discourse plan itself would
result in many wrong or misplaced discourse marker
lexicalizations. Given that discourse markers can-
not be lexicalized before clause revision is enacted,
and that clause revision may alter the original dis-
course plan upon which a later discourse marker in-
sertion algorithm may rely, it follows that the revi-
sion algorithm should update the discourse plan as
it progresses, and the discourse marker insertion al-
gorithm should be responsive to these changes, thus
delaying discourse marker lexicalization.
</bodyText>
<sectionHeader confidence="0.999031" genericHeader="method">
5 Implementation
</sectionHeader>
<bodyText confidence="0.999993147058823">
To demonstrate the application of this problem to
real world discourse, we took the STORYBOOK
(Callaway and Lester, 2001; Callaway and Lester,
2002) NLG system that generates multi-page text
in the form of Little Red Riding Hood stories and
New York Times articles, using a pipelined architec-
ture with a large number of modules such as revision
(Callaway and Lester, 1997). But although it was ca-
pable of inserting discourse markers, it did so in an
ad-hoc way, and required that the document author
notice possible interferences between revision and
discourse marker insertion and hard-wire the docu-
ment representation accordingly.
Upon adding a principled discourse marker selec-
tion algorithm to the system, we soon noticed vari-
ous unwanted interactions between revision and dis-
course markers of the type described in Section 4
above. Thus, in addition to the other constraints al-
ready considered during clause aggregation, we al-
tered the revision module to also take into account
the information available to our discourse marker in-
sertion algorithm (in our case, intention and rhetori-
cal predicates). We were thus able to incorporate the
discourse marker selection algorithm into the revi-
sion module itself.
This is contrary to most NLG systems where dis-
course marker lexicalization is performed as late as
possible using the modified discourse plan leaves af-
ter the revision rules have reorganized all the origi-
nal clauses. In an architecture that doesn’t consider
discourse markers, a generic revision rule without
access to the original discourse plan might appear
like this (where type refers to the main clause syn-
tax, and rhetorical type refers to its intention):
</bodyText>
<equation confidence="0.99149775">
If type(clause1) = &lt;type&gt;
type(clause2) = &lt;type&gt;
subject(clause1) = subject(clause2)
then make-subject-relative-clause(clause1, clause2)
</equation>
<bodyText confidence="0.999789666666667">
But by making available the intentional and
rhetorical information from the discourse plan, our
modified revision rules instead have this form:
</bodyText>
<equation confidence="0.984017285714286">
If rhetorical-type(clause1) = &lt;type&gt;
rhetorical-type(clause2) = &lt;type&gt;
subject(clause1) = subject(clause2)
rhetorical-relation(clause1, clause2) x set-of-features
then make-subject-relative-clause(clause1, clause2)
lexicalize-discourse-marker(clause1, set-of-features)
update-rhetorical-relation(clause1, current-relations)
</equation>
<bodyText confidence="0.999956444444444">
where the function lexicalize-discourse-marker de-
termines the appropriate discourse marker lexical-
ization given a set of features such as those de-
scribed in (Knott and Mellish, 1996) or (Grote and
Stede, 1999), and update-rhetorical-relation causes
the appropriate changes to be made to the running
discourse plan so that future revision rules can take
those alterations into account.
STORYBOOK takes a discourse plan augmented
with appropriate low-level (i.e., unlexicalized, or
conceptual) rhetorical features and produces a sen-
tence plan without discarding rhetorical informa-
tion. It then revises and lexicalizes discourse mark-
ers concurrently before passing the results to the sur-
face realization module for production of the surface
text.
Consider the following sentences in a short text
plan produced by the generation system:
</bodyText>
<listItem confidence="0.968414">
1. “In this case, Mr. Curtis could no longer be
tried for the shooting of his former girlfriend’s
companion.” &lt;agent-action&gt;
[causal relation]
2. “There is a five-year statute of limitations on
that crime.” &lt;existential&gt;
[opposition relation]
3. “There is no statute of limitations in murder
cases.” &lt;existential&gt;
</listItem>
<bodyText confidence="0.999559814814815">
Without revision, a discourse marker insertion al-
gorithm is only capable of adding discourse markers
before or after a clause boundary:
“In this case, Mr. Curtis could no longer be tried
for the shooting of his former girlfriend’s compan-
ion. This is because there is a five-year statute
of limitations on that crime. However, there is no
statute of limitations in murder cases.”
But a revised version with access to the discourse
plan and integrating discourse markers that our sys-
tem generates is:
“In this case, Mr. Curtis could no longer be tried
for the shooting of his former girlfriend’s compan-
ion, because there is a five-year statute of limita-
tions on that crime even though there is no statue of
limitations in murder cases.”
A revision module without access to the discourse
plan and a method for lexicalizing discourse mark-
ers will be unable to generate the second, improved
version. Furthermore, a discourse marker insertion
algorithm that lexicalizes before the revision algo-
rithm begins will not have enough basis to decide
and frequently produce wrong lexicalizations. The
actual implemented rules in our system (which gen-
erate the example above) are consistent with the ab-
stract rule presented earlier.
Revising sentence 1 with 2:
</bodyText>
<equation confidence="0.9759295">
If rhetorical-type(clause1) = agent-action
rhetorical-type(clause2) = existential
rhetorical-relation(clause1, clause2)
x {causation, simple,... }
then make-subordinate-bound-clause(clause2, clause1)
lexicalize-discourse-marker(clause2, {causation, simple})
update-rhetorical-relation(clause1, clause2, agent-action,
existential, causation)
Revising sentence 2 with 3:
If rhetorical-type(clause2) = existential
rhetorical-type(clause3) = existential
rhetorical-relation(clause2, clause3)
x {opposition, simple,... }
then make-subject-relative-clause(clause2, clause3)
lexicalize-discourse-marker(clause1,
{opposition, simple})
update-rhetorical-relation(clause1, clause2, existential,
existential, current-relations)
</equation>
<bodyText confidence="0.999874666666667">
Given these parameters, the discourse markers
will be lexicalized as because and even though
respectively, and the revision component will be
able to combine all three base sentences plus the
discourse markers into the single sentence shown
above.
</bodyText>
<sectionHeader confidence="0.983439" genericHeader="method">
6 Preliminary Evaluation
</sectionHeader>
<bodyText confidence="0.99954675">
Evaluation of multi-paragraph text generation is ex-
ceedingly difficult, as empirically-driven methods
are not sufficiently sophisticated, and subjective hu-
man evaluations that require multiple comparisons
of large quantities of text is both difficult to control
for and time-consuming. Evaluating our approach is
even more difficult in that the interference between
discourse markers and revision is not a highly fre-
</bodyText>
<table confidence="0.9988575">
# Sentences # Revisions # DMs # Co-occurring DM/Rev Separate Integrated
Article 1 112 90 29 14 17 (56.8%) 26 (89.7%)
Article 2 54 93 50 30 24 (48.0%) 45 (90.0%)
Article 3 72 117 46 26 21 (45.7%) 42 (91.3%)
</table>
<tableCaption confidence="0.99996">
Table 1: Interactions between revision and discourse markers
</tableCaption>
<bodyText confidence="0.999982166666667">
quent occurrence in multi-page text. For instance, in
our corpora we found that these interference effects
occurred 23% of the time for revised clauses and
56% of the time with discourse markers. In other
words, almost one of every four clause revisions po-
tentially forces a change in discourse marker lexi-
calizations and one in every two discourse markers
occur near a clause revision boundary.
However, the “penalty” associated with incor-
rectly selecting discourse markers is fairly high lead-
ing to confusing sentences, although there is no cog-
nitive science evidence that states exactly how high
for a typical reader, despite recent work in this direc-
tion (Tree and Schrock, 1999). Furthermore, there is
little agreement on exactly what constitutes a dis-
course marker, especially between the spoken and
written dialogue communities (e.g., many members
of the latter consider “uh” to be a discourse marker).
We thus present an analysis of the frequencies
of various features from three separate New York
Times articles generated by the STORYBOOK sys-
tem. We then describe the results of running our
combined revision and discourse marker module
with the discourse plans used to generate them.
While three NYT articles is not a substantial enough
evaluation in ideal terms, the cost of evaluation in
such a knowledge-intensive undertaking will con-
tinue to be prohibitive until large-scale automatic or
semiautomatic techniques are developed.
The left side of table 1 presents an analysis of the
frequencies of revisions and discourse markers as
found in each of the three NYT articles. In addition,
we have indicated the number of times in our opin-
ion that revisions and discourse markers co-occurred
(i.e., a discourse marker was present at the junction
site of the clauses being aggregated).
The right side of the table indicates the differ-
ence between the accuracy of two different versions
of the system: separate signifies the initial configu-
ration of the STORYBOOK system where discourse
marker insertion and revision were performed as
separate process, while integrated signifies that dis-
course markers were lexicalized during revision as
described in this paper. The difference between
these two numbers thus represents the number of
times per article that the integrated clause aggrega-
tion and discourse marker module was able to im-
prove the resulting text.
</bodyText>
<sectionHeader confidence="0.999466" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999942">
Efficiency and software engineering considerations
dictate that current large-scale NLG systems must
be constructed in a pipeline fashion that minimizes
backtracking and communication between modules.
Yet discourse markers and revision both operate at
the clause level, which leads to the potential of inter-
ference effects if they are not resolved at the same lo-
cation in a pipelined architecture. We have analyzed
recent theoretical and applied work in both discourse
markers and revision, showing that although no pre-
vious NLG system has yet integrated both compo-
nents into a single architecture, an architecture for
multi-paragraph generation which separated the two
into distinct, unlinked modules would not be able
to guarantee that the final text contained appropri-
ately lexicalized discourse markers. Instead, our
combined revision and discourse marker module in
an implemented pipelined NLG system is able to
correctly insert appropriate discourse markers de-
spite changes made by the revision system. A cor-
pus analysis indicated that significant interference
effects between revision and discourse marker lex-
icalization are possible. Future work may show that
similar interference effects are possible as succes-
sive modules are added to pipelined NLG systems.
</bodyText>
<sectionHeader confidence="0.999175" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999726151515151">
Charles B. Callaway and James C. Lester. 1997. Dy-
namically improving explanations: A revision-based
approach to explanation generation. In Proceedings of
the Fifteenth International Joint Conference on Artifi-
cial Intelligence, pages 952–58, Nagoya, Japan.
Charles B. Callaway and James C. Lester. 2001. Nar-
rative prose generation. In Proceedings of the Seven-
teenth International Joint Conference on Artificial In-
telligence, pages 1241–1248, Seattle, WA.
Charles B. Callaway and James C. Lester. 2002.
Narrative prose generation. Artificial Intelligence,
139(2):213–252.
Ben E. Cline. 1994. Knowledge Intensive Natural Lan-
guage Generation with Revision. Ph.D. thesis, Vir-
ginia Polytechnic and State University, Blacksburg,
Virginia.
Hercules Dalianis and Eduard Hovy. 1993. Aggrega-
tion in natural language generation. In Proceedings of
the Fourth European Workshop on Natural Language
Generation, Pisa, Italy.
Michael Elhadad and Kathy McKeown. 1990. Gener-
ating connectives. In COLING ’90: Proceedings of
the Thirteenth International Conference on Computa-
tional Linguistics, pages 97–101, Helsinki, Finland.
Michael Elhadad, Kathleen McKeown, and Jacques
Robin. 1997. Floating constraints in lexical choice.
Computational Linguistics, 23(2):195–240.
Brigitte Grote. 1998. Representing temporal discourse
markers for generation purposes. In Proceedings of
the Discourse Relations and Discourse Markers Work-
shop, pages 22–28, Montr´eal, Canada.
Brigitte Grote and Manfred Stede. 1999. Ontology and
lexical semantics for generating temporal discourse
markers. In Proceedings of the 7th European Work-
shop on Natural Language Generation, Toulouse,
France, May.
Terrence Harvey and Sandra Carberry. 1998. Integrating
text plans for conciseness and coherence. In Proceed-
ings of the 36th Annual Meeting of the Association for
Computational Linguistics, pages 512–518, August.
Helmut Horacek. 2002. Aggregation with strong regu-
larities and alternatives. In Second International Natu-
ral Language Generation Conference, pages 105–112,
Harriman, NY, July.
M. Kantrowitz and J. Bates. 1992. Integrated natural
language generation systems. In R. Dale, E. Hovy,
D. Rosner, and O. Stock, editors, Aspects of Auto-
mated Natural Language Generation, pages 247–262.
Springer-Verlag, Berlin.
Alistair Knott and Chris Mellish. 1996. A data-driven
method for classifying connective phrases. Journal of
Language and Speech, 39.
David J. Mooney. 1994. Generating High-Level Struc-
ture for Extended Explanations. Ph.D. thesis, The
University of Delaware, Newark, Delaware.
Richard Power, Christine Doran, and Donia Scott. 1999.
Generating embedded discourse markers from rhetor-
ical structure. In Proceedings of the Seventh Eu-
ropean Workshop on Natural Language Generation,
Toulouse, France.
R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985.
A Comprehensive Grammar of the English Language.
Longman Publishers.
Mike Reape and Chris Mellish. 1999. Just what is ag-
gregation anyway? In Proceedings of the 7th Eu-
ropean Workshop on Natural Language Generation,
Toulouse, France, May.
Ehud Reiter. 1994. Has a consensus NL generation
architecture appeared, and is it psycholinguistically
plausible? In Proceedings of the Seventh International
Workshop on Natural Language Generation, pages
163–170, Kennebunkport, ME.
Jacques Robin. 1994. Revision-Based Generation of
Natural Language Summaries Providing Historical
Background. Ph.D. thesis, Columbia University, De-
cember.
James Shaw. 1998. Clause aggregation using linguistic
knowledge. In Proceedings of the 9th International
Workshop on Natural Language Generation, pages
138–147, Niagara-on-the-Lake, Canada.
Manfred Stede and Carla Umbach. 1998. DiM-Lex: A
lexicon of discourse markers for text generation and
understanding. In Proceedings of the Joint 36th Meet-
ing of the ACL and the 17th Meeting of COLING,
pages 1238–1242, Montr´eal, Canada, August.
J. E. Fox Tree and J. C. Schrock. 1999. Discourse mark-
ers in spontaneous speech. Journal of Memory and
Language, 27:35–53.
Bonnie Webber and Aravind Joshi. 1998. Anchoring a
lexicalized tree-adjoining grammar for discourse. In
Proceedings of the COLING-ACL ’96 Discourse Rela-
tions and Discourse Markers Workshop, pages 86–92,
Montr´eal, Canada, August.
Feng-Jen Yang, Jung Hee Kim, Michael Glass, and
Martha Evens. 2000. Lexical usage in the tutoring
schemata of Circsim-Tutor: Analysis of variable ref-
erences and discourse markers. In The Fifth Annual
Conference on Human Interaction and Complex Sys-
tems, pages 27–31, Urbana, IL.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.421468">
<title confidence="0.9955785">Integrating Discourse Markers into a Pipelined Natural Language Generation Architecture</title>
<author confidence="0.999171">Charles B Callaway</author>
<address confidence="0.663105">ITC-irst, Trento, Italy via Sommarive, 18 Povo (Trento), Italy, I-38050</address>
<email confidence="0.958229">callaway@itc.it</email>
<abstract confidence="0.999562">Pipelined Natural Language Generation (NLG) systems have grown increasingly complex as architectural modules were added to support language functionalities such as referring expressions, lexical choice, and revision. This has given rise to discussions about the relative placement of these new modules in the overall architecture. Recent work on another aspect of multi-paragraph text, discourse markers, indicates it is time to consider where a discourse marker insertion algorithm fits in. We present examples which suggest that in a pipelined NLG architecture, the best approach is to strongly tie it to a revision component. Finally, we evaluate the approach in a working multi-page system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Dynamically improving explanations: A revision-based approach to explanation generation.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>952--58</pages>
<location>Nagoya, Japan.</location>
<contexts>
<context position="10316" citStr="Callaway and Lester, 1997" startWordPosition="1517" endWordPosition="1520">ter a sentence planner produces the required lexicalized information that can form a complete and grammatical sentence, STREAK attempts to gradually aggregate that data. It then proceeds to try to opportunistically include additional optional information from a data set of statistics, performing aggregation operations at various syntactic levels. Because STREAK only produces single sentences, it does not attempt to add discourse markers. In addition, there is no a priori way to determine whether adjacent propositions in the input will remain adjacent in the final sentence. The REVISOR system (Callaway and Lester, 1997) takes an entire sentence plan at once and iterates through it in paragraph-sized chunks, employing clause- and phrase-level aggregation and reordering operations before passing a revised sentence plan to the surface realizer. However, at no point does it add information that previously did not exist in the sentence plan. The RTPI system (Harvey and Carberry, 1998) takes in sets of multiple, lexicalized sentential plans over a number of medical diagnoses from different critiquing systems and produces a single, unified sentence plan which is both coherent and cohesive. Like STREAK, Shaw’s CASPE</context>
<context position="17623" citStr="Callaway and Lester, 1997" startWordPosition="2670" endWordPosition="2673">rithm may rely, it follows that the revision algorithm should update the discourse plan as it progresses, and the discourse marker insertion algorithm should be responsive to these changes, thus delaying discourse marker lexicalization. 5 Implementation To demonstrate the application of this problem to real world discourse, we took the STORYBOOK (Callaway and Lester, 2001; Callaway and Lester, 2002) NLG system that generates multi-page text in the form of Little Red Riding Hood stories and New York Times articles, using a pipelined architecture with a large number of modules such as revision (Callaway and Lester, 1997). But although it was capable of inserting discourse markers, it did so in an ad-hoc way, and required that the document author notice possible interferences between revision and discourse marker insertion and hard-wire the document representation accordingly. Upon adding a principled discourse marker selection algorithm to the system, we soon noticed various unwanted interactions between revision and discourse markers of the type described in Section 4 above. Thus, in addition to the other constraints already considered during clause aggregation, we altered the revision module to also take in</context>
</contexts>
<marker>Callaway, Lester, 1997</marker>
<rawString>Charles B. Callaway and James C. Lester. 1997. Dynamically improving explanations: A revision-based approach to explanation generation. In Proceedings of the Fifteenth International Joint Conference on Artificial Intelligence, pages 952–58, Nagoya, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Narrative prose generation.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1241--1248</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="17371" citStr="Callaway and Lester, 2001" startWordPosition="2628" endWordPosition="2631">rong or misplaced discourse marker lexicalizations. Given that discourse markers cannot be lexicalized before clause revision is enacted, and that clause revision may alter the original discourse plan upon which a later discourse marker insertion algorithm may rely, it follows that the revision algorithm should update the discourse plan as it progresses, and the discourse marker insertion algorithm should be responsive to these changes, thus delaying discourse marker lexicalization. 5 Implementation To demonstrate the application of this problem to real world discourse, we took the STORYBOOK (Callaway and Lester, 2001; Callaway and Lester, 2002) NLG system that generates multi-page text in the form of Little Red Riding Hood stories and New York Times articles, using a pipelined architecture with a large number of modules such as revision (Callaway and Lester, 1997). But although it was capable of inserting discourse markers, it did so in an ad-hoc way, and required that the document author notice possible interferences between revision and discourse marker insertion and hard-wire the document representation accordingly. Upon adding a principled discourse marker selection algorithm to the system, we soon no</context>
</contexts>
<marker>Callaway, Lester, 2001</marker>
<rawString>Charles B. Callaway and James C. Lester. 2001. Narrative prose generation. In Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence, pages 1241–1248, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles B Callaway</author>
<author>James C Lester</author>
</authors>
<title>Narrative prose generation.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<volume>139</volume>
<issue>2</issue>
<contexts>
<context position="3375" citStr="Callaway and Lester, 2002" startWordPosition="490" endWordPosition="493">e not component specific, such as multilingualism. As text planners scale up to produce ever larger texts, the switch to multi-page prose will introduce new features, and consequentially the number of architectural modules will increase. For example, Mooney’s EEG system (Mooney, 1994), which created a full-page description of the Three-Mile Island nuclear plant disaster, contains components for discourse knowledge, discourse organization, rhetoriFigure 1: A Typical Pipelined NLG Architecture cal relation structuring, sentence planning, and surface realization. Similarly, the STORYBOOK system (Callaway and Lester, 2002), which generated 2 to 3 pages of narrative prose in the Little Red Riding Hood fairy tale domain, contained seven separate components. This paper examines the interactions of two linguistic phenomena at the paragraph level: revision (specifically, clause aggregation, migration and demotion) and discourse markers. Clause aggregation involves the syntactic joining of two simple sentences into a more complex sentence. Discourse markers link two sentences semantically without necessarily joining them syntactically. Because both of these phenomena produce changes in the text at the clause-level, a</context>
<context position="17399" citStr="Callaway and Lester, 2002" startWordPosition="2632" endWordPosition="2635"> marker lexicalizations. Given that discourse markers cannot be lexicalized before clause revision is enacted, and that clause revision may alter the original discourse plan upon which a later discourse marker insertion algorithm may rely, it follows that the revision algorithm should update the discourse plan as it progresses, and the discourse marker insertion algorithm should be responsive to these changes, thus delaying discourse marker lexicalization. 5 Implementation To demonstrate the application of this problem to real world discourse, we took the STORYBOOK (Callaway and Lester, 2001; Callaway and Lester, 2002) NLG system that generates multi-page text in the form of Little Red Riding Hood stories and New York Times articles, using a pipelined architecture with a large number of modules such as revision (Callaway and Lester, 1997). But although it was capable of inserting discourse markers, it did so in an ad-hoc way, and required that the document author notice possible interferences between revision and discourse marker insertion and hard-wire the document representation accordingly. Upon adding a principled discourse marker selection algorithm to the system, we soon noticed various unwanted inter</context>
</contexts>
<marker>Callaway, Lester, 2002</marker>
<rawString>Charles B. Callaway and James C. Lester. 2002. Narrative prose generation. Artificial Intelligence, 139(2):213–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben E Cline</author>
</authors>
<title>Knowledge Intensive Natural Language Generation with Revision.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Virginia Polytechnic and State University,</institution>
<location>Blacksburg, Virginia.</location>
<contexts>
<context position="2047" citStr="Cline, 1994" startWordPosition="300" endWordPosition="301">igner would justify not only the reason for including the new module (i.e., what linguistic phenomena it produced that had been previously unattainable) but how it was integrated into their architecture and why its placement was reasonably optimal (cf., (Elhadad et al., 1997), pp. 4–7). At the same time, (Reiter, 1994) argued that implemented NLG systems were converging toward a de facto pipelined architecture (Figure 1) with minimal-to-nonexistent feedback between modules. Although several NLG architectures were proposed in opposition to such a linear arrangement (Kantrowitz and Bates, 1992; Cline, 1994), these research projects have not continued while pipelined architectures are still actively being pursued. In addition, Reiter concludes that although complete integration of architectural components is theoretically a good idea, in practical engineering terms such a system would be too inefficient to operate and too complex to actually implement. Significantly, Reiter states that fully interconnecting every module would entail constructing N(N — 1) interfaces between them. As the number of modules rises (i.e., as the number of large-scale features an NLG engineer wants to implement rises) t</context>
</contexts>
<marker>Cline, 1994</marker>
<rawString>Ben E. Cline. 1994. Knowledge Intensive Natural Language Generation with Revision. Ph.D. thesis, Virginia Polytechnic and State University, Blacksburg, Virginia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hercules Dalianis</author>
<author>Eduard Hovy</author>
</authors>
<title>Aggregation in natural language generation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fourth European Workshop on Natural Language Generation,</booktitle>
<location>Pisa, Italy.</location>
<contexts>
<context position="8664" citStr="Dalianis and Hovy (1993)" startWordPosition="1269" endWordPosition="1272">aking sets of small, single-proposition sentences and finding ways to combine them into more fluent, multiple-proposition sentences. Sentences can be combined using a wide range of different syntactic forms, such as conjunction with “and”, making relative clauses with noun phrases common to both sentences, and introducing ellipsis. Typically, revision modules arise because of dissatisfaction with the quality of text produced by a simple pipelined NLG system. As noted by Reape and Mellish (1999), there is a wide variety in revision definitions, objectives, operating level, and type. Similarly, Dalianis and Hovy (1993) tried to distinguish between different revision parameters by having users perform revision thought experiments and proposing rules in RST form which mimic the behavior they observed. While neither of these were implemented revision systems, there have been several attempts to improve the quality of text from existing NLG systems. There are two approaches to the architectural position of revision systems: those that operate on semantic representations before the sentence planning level, of which a prototypical example is (Horacek, 2002), and those placed after the sentence planner, operating </context>
</contexts>
<marker>Dalianis, Hovy, 1993</marker>
<rawString>Hercules Dalianis and Eduard Hovy. 1993. Aggregation in natural language generation. In Proceedings of the Fourth European Workshop on Natural Language Generation, Pisa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
<author>Kathy McKeown</author>
</authors>
<title>Generating connectives.</title>
<date>1990</date>
<booktitle>In COLING ’90: Proceedings of the Thirteenth International Conference on Computational Linguistics,</booktitle>
<pages>97--101</pages>
<location>Helsinki, Finland.</location>
<contexts>
<context position="6147" citStr="Elhadad and McKeown (1990)" startWordPosition="901" endWordPosition="904">n algorithm. Other work often focuses on particular semantic categories, such as temporal discourse markers. For instance, Grote (1998) attempted to create declarative lexicons that contain applicability conditions and other constraints to aid in the process of discourse marker selection. Other theoretical research consists, for example, of adapting existing grammatical formalisms such as TAGs (Webber and Joshi, 1998) for discourse-level phenomena. Alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text. In an early instance, Elhadad and McKeown (1990) followed Quirk’s pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside a functional unification surface realizer (and thereby postponing lexicalization till the last possible moment). More recent approaches have tended to move the decision time for marker lexicalization higher up the pipelined architecture. For example, the MOOSE system (Stede and Umbach, 1998; Grote and Stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon. Similarly, Power et al. (1999) produce mu</context>
</contexts>
<marker>Elhadad, McKeown, 1990</marker>
<rawString>Michael Elhadad and Kathy McKeown. 1990. Generating connectives. In COLING ’90: Proceedings of the Thirteenth International Conference on Computational Linguistics, pages 97–101, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
<author>Kathleen McKeown</author>
<author>Jacques Robin</author>
</authors>
<title>Floating constraints in lexical choice.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>2</issue>
<contexts>
<context position="1711" citStr="Elhadad et al., 1997" startWordPosition="249" endWordPosition="252">ently, as it was discovered that these components by themselves did not create highly readable prose, new types of architectural modules were introduced to deal with newly desired linguistic phenomena such as referring expressions, lexical choice, revision, and pronominalization. Adding each new module typically entailed that an NLG system designer would justify not only the reason for including the new module (i.e., what linguistic phenomena it produced that had been previously unattainable) but how it was integrated into their architecture and why its placement was reasonably optimal (cf., (Elhadad et al., 1997), pp. 4–7). At the same time, (Reiter, 1994) argued that implemented NLG systems were converging toward a de facto pipelined architecture (Figure 1) with minimal-to-nonexistent feedback between modules. Although several NLG architectures were proposed in opposition to such a linear arrangement (Kantrowitz and Bates, 1992; Cline, 1994), these research projects have not continued while pipelined architectures are still actively being pursued. In addition, Reiter concludes that although complete integration of architectural components is theoretically a good idea, in practical engineering terms s</context>
</contexts>
<marker>Elhadad, McKeown, Robin, 1997</marker>
<rawString>Michael Elhadad, Kathleen McKeown, and Jacques Robin. 1997. Floating constraints in lexical choice. Computational Linguistics, 23(2):195–240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Grote</author>
</authors>
<title>Representing temporal discourse markers for generation purposes.</title>
<date>1998</date>
<booktitle>In Proceedings of the Discourse Relations and Discourse Markers Workshop,</booktitle>
<pages>22--28</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="5656" citStr="Grote (1998)" startWordPosition="835" endWordPosition="836">s has greatly extended our knowledge over even the most expansive previous accounts of discourse connectives (Quirk et al., 1985) from previous decades. For example, using a large scale corpus analysis and human subjects employing a substitution test over the corpus sentences containing discourse markers, Knott and Mellish (1996) distilled a taxonomy of individual lexical discourse markers and 8 binary-valued features that could be used to drive a discourse marker selection algorithm. Other work often focuses on particular semantic categories, such as temporal discourse markers. For instance, Grote (1998) attempted to create declarative lexicons that contain applicability conditions and other constraints to aid in the process of discourse marker selection. Other theoretical research consists, for example, of adapting existing grammatical formalisms such as TAGs (Webber and Joshi, 1998) for discourse-level phenomena. Alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text. In an early instance, Elhadad and McKeown (1990) followed Quirk’s pre-existing non-computational account of discourse connectives to produce single argumenta</context>
</contexts>
<marker>Grote, 1998</marker>
<rawString>Brigitte Grote. 1998. Representing temporal discourse markers for generation purposes. In Proceedings of the Discourse Relations and Discourse Markers Workshop, pages 22–28, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Grote</author>
<author>Manfred Stede</author>
</authors>
<title>Ontology and lexical semantics for generating temporal discourse markers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th European Workshop on Natural Language Generation,</booktitle>
<location>Toulouse, France,</location>
<contexts>
<context position="6601" citStr="Grote and Stede, 1999" startWordPosition="962" endWordPosition="965">natively, there are several implemented systems that automatically insert discourse markers into multi-sentential text. In an early instance, Elhadad and McKeown (1990) followed Quirk’s pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside a functional unification surface realizer (and thereby postponing lexicalization till the last possible moment). More recent approaches have tended to move the decision time for marker lexicalization higher up the pipelined architecture. For example, the MOOSE system (Stede and Umbach, 1998; Grote and Stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon. Similarly, Power et al. (1999) produce multiple discourse markers for Patient Information Leaflets using a constraint-based method applied to RST trees during sentence planning. Finally, in the CIRC-SIM intelligent tutoring system (Yang et al., 2000) that generates connected dialogues for students studying heart ailments, discourse marker lexicalization has been pushed all the way up to the discourse planning level. In this case, CIRC-SIM lexicalizes discourse markers inside of the discours</context>
<context position="19739" citStr="Grote and Stede, 1999" startWordPosition="2963" endWordPosition="2966">information from the discourse plan, our modified revision rules instead have this form: If rhetorical-type(clause1) = &lt;type&gt; rhetorical-type(clause2) = &lt;type&gt; subject(clause1) = subject(clause2) rhetorical-relation(clause1, clause2) x set-of-features then make-subject-relative-clause(clause1, clause2) lexicalize-discourse-marker(clause1, set-of-features) update-rhetorical-relation(clause1, current-relations) where the function lexicalize-discourse-marker determines the appropriate discourse marker lexicalization given a set of features such as those described in (Knott and Mellish, 1996) or (Grote and Stede, 1999), and update-rhetorical-relation causes the appropriate changes to be made to the running discourse plan so that future revision rules can take those alterations into account. STORYBOOK takes a discourse plan augmented with appropriate low-level (i.e., unlexicalized, or conceptual) rhetorical features and produces a sentence plan without discarding rhetorical information. It then revises and lexicalizes discourse markers concurrently before passing the results to the surface realization module for production of the surface text. Consider the following sentences in a short text plan produced by</context>
</contexts>
<marker>Grote, Stede, 1999</marker>
<rawString>Brigitte Grote and Manfred Stede. 1999. Ontology and lexical semantics for generating temporal discourse markers. In Proceedings of the 7th European Workshop on Natural Language Generation, Toulouse, France, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terrence Harvey</author>
<author>Sandra Carberry</author>
</authors>
<title>Integrating text plans for conciseness and coherence.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>512--518</pages>
<contexts>
<context position="10683" citStr="Harvey and Carberry, 1998" startWordPosition="1577" endWordPosition="1581">y produces single sentences, it does not attempt to add discourse markers. In addition, there is no a priori way to determine whether adjacent propositions in the input will remain adjacent in the final sentence. The REVISOR system (Callaway and Lester, 1997) takes an entire sentence plan at once and iterates through it in paragraph-sized chunks, employing clause- and phrase-level aggregation and reordering operations before passing a revised sentence plan to the surface realizer. However, at no point does it add information that previously did not exist in the sentence plan. The RTPI system (Harvey and Carberry, 1998) takes in sets of multiple, lexicalized sentential plans over a number of medical diagnoses from different critiquing systems and produces a single, unified sentence plan which is both coherent and cohesive. Like STREAK, Shaw’s CASPER system (Shaw, 1998) produces single sentences from sets of sentences and doesn’t attempt to deal with discourse markers. CASPER also delays lexicalization when aggregating by looking at the lexicon twice during the revision process. This is due mainly to the efficiency costs of the unification procedure. However, CASPER’s sentence planner essentially uses the fir</context>
</contexts>
<marker>Harvey, Carberry, 1998</marker>
<rawString>Terrence Harvey and Sandra Carberry. 1998. Integrating text plans for conciseness and coherence. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, pages 512–518, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Horacek</author>
</authors>
<title>Aggregation with strong regularities and alternatives.</title>
<date>2002</date>
<booktitle>In Second International Natural Language Generation Conference,</booktitle>
<pages>105--112</pages>
<location>Harriman, NY,</location>
<contexts>
<context position="9207" citStr="Horacek, 2002" startWordPosition="1354" endWordPosition="1355">ectives, operating level, and type. Similarly, Dalianis and Hovy (1993) tried to distinguish between different revision parameters by having users perform revision thought experiments and proposing rules in RST form which mimic the behavior they observed. While neither of these were implemented revision systems, there have been several attempts to improve the quality of text from existing NLG systems. There are two approaches to the architectural position of revision systems: those that operate on semantic representations before the sentence planning level, of which a prototypical example is (Horacek, 2002), and those placed after the sentence planner, operating on syntactic/linguistic data. Here we treat mainly the second type, which have typically been conceived of as “add-on” components to existing pipelined architectures. An important implication of this architectural order is that the revision components expect to receive lexicalized sentence plans. Of these systems, Robin’s STREAK system (Robin, 1994) is the only one that accepts both lexicalized and non-lexicalized data. After a sentence planner produces the required lexicalized information that can form a complete and grammatical sentenc</context>
</contexts>
<marker>Horacek, 2002</marker>
<rawString>Helmut Horacek. 2002. Aggregation with strong regularities and alternatives. In Second International Natural Language Generation Conference, pages 105–112, Harriman, NY, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kantrowitz</author>
<author>J Bates</author>
</authors>
<title>Integrated natural language generation systems. In</title>
<date>1992</date>
<booktitle>Aspects of Automated Natural Language Generation,</booktitle>
<pages>247--262</pages>
<editor>R. Dale, E. Hovy, D. Rosner, and O. Stock, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin.</location>
<contexts>
<context position="2033" citStr="Kantrowitz and Bates, 1992" startWordPosition="296" endWordPosition="299">ailed that an NLG system designer would justify not only the reason for including the new module (i.e., what linguistic phenomena it produced that had been previously unattainable) but how it was integrated into their architecture and why its placement was reasonably optimal (cf., (Elhadad et al., 1997), pp. 4–7). At the same time, (Reiter, 1994) argued that implemented NLG systems were converging toward a de facto pipelined architecture (Figure 1) with minimal-to-nonexistent feedback between modules. Although several NLG architectures were proposed in opposition to such a linear arrangement (Kantrowitz and Bates, 1992; Cline, 1994), these research projects have not continued while pipelined architectures are still actively being pursued. In addition, Reiter concludes that although complete integration of architectural components is theoretically a good idea, in practical engineering terms such a system would be too inefficient to operate and too complex to actually implement. Significantly, Reiter states that fully interconnecting every module would entail constructing N(N — 1) interfaces between them. As the number of modules rises (i.e., as the number of large-scale features an NLG engineer wants to impl</context>
</contexts>
<marker>Kantrowitz, Bates, 1992</marker>
<rawString>M. Kantrowitz and J. Bates. 1992. Integrated natural language generation systems. In R. Dale, E. Hovy, D. Rosner, and O. Stock, editors, Aspects of Automated Natural Language Generation, pages 247–262. Springer-Verlag, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
<author>Chris Mellish</author>
</authors>
<title>A data-driven method for classifying connective phrases.</title>
<date>1996</date>
<journal>Journal of Language and Speech,</journal>
<volume>39</volume>
<contexts>
<context position="5375" citStr="Knott and Mellish (1996)" startWordPosition="792" endWordPosition="795">tion of clauses in a way similar to the problems that referring expressions pose to noun phrases: changing the lexicalization of a discourse marker can change the semantic interpretation of the clauses affected. Recent work in the analysis of both the distribution and role of discourse markers has greatly extended our knowledge over even the most expansive previous accounts of discourse connectives (Quirk et al., 1985) from previous decades. For example, using a large scale corpus analysis and human subjects employing a substitution test over the corpus sentences containing discourse markers, Knott and Mellish (1996) distilled a taxonomy of individual lexical discourse markers and 8 binary-valued features that could be used to drive a discourse marker selection algorithm. Other work often focuses on particular semantic categories, such as temporal discourse markers. For instance, Grote (1998) attempted to create declarative lexicons that contain applicability conditions and other constraints to aid in the process of discourse marker selection. Other theoretical research consists, for example, of adapting existing grammatical formalisms such as TAGs (Webber and Joshi, 1998) for discourse-level phenomena. A</context>
<context position="19712" citStr="Knott and Mellish, 1996" startWordPosition="2958" endWordPosition="2961">e intentional and rhetorical information from the discourse plan, our modified revision rules instead have this form: If rhetorical-type(clause1) = &lt;type&gt; rhetorical-type(clause2) = &lt;type&gt; subject(clause1) = subject(clause2) rhetorical-relation(clause1, clause2) x set-of-features then make-subject-relative-clause(clause1, clause2) lexicalize-discourse-marker(clause1, set-of-features) update-rhetorical-relation(clause1, current-relations) where the function lexicalize-discourse-marker determines the appropriate discourse marker lexicalization given a set of features such as those described in (Knott and Mellish, 1996) or (Grote and Stede, 1999), and update-rhetorical-relation causes the appropriate changes to be made to the running discourse plan so that future revision rules can take those alterations into account. STORYBOOK takes a discourse plan augmented with appropriate low-level (i.e., unlexicalized, or conceptual) rhetorical features and produces a sentence plan without discarding rhetorical information. It then revises and lexicalizes discourse markers concurrently before passing the results to the surface realization module for production of the surface text. Consider the following sentences in a </context>
</contexts>
<marker>Knott, Mellish, 1996</marker>
<rawString>Alistair Knott and Chris Mellish. 1996. A data-driven method for classifying connective phrases. Journal of Language and Speech, 39.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Mooney</author>
</authors>
<title>Generating High-Level Structure for Extended Explanations.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>The University of Delaware,</institution>
<location>Newark, Delaware.</location>
<contexts>
<context position="3034" citStr="Mooney, 1994" startWordPosition="446" endWordPosition="447">states that fully interconnecting every module would entail constructing N(N — 1) interfaces between them. As the number of modules rises (i.e., as the number of large-scale features an NLG engineer wants to implement rises) the implementation cost rises exponentially. Moreover, this cost does not include modifications that are not component specific, such as multilingualism. As text planners scale up to produce ever larger texts, the switch to multi-page prose will introduce new features, and consequentially the number of architectural modules will increase. For example, Mooney’s EEG system (Mooney, 1994), which created a full-page description of the Three-Mile Island nuclear plant disaster, contains components for discourse knowledge, discourse organization, rhetoriFigure 1: A Typical Pipelined NLG Architecture cal relation structuring, sentence planning, and surface realization. Similarly, the STORYBOOK system (Callaway and Lester, 2002), which generated 2 to 3 pages of narrative prose in the Little Red Riding Hood fairy tale domain, contained seven separate components. This paper examines the interactions of two linguistic phenomena at the paragraph level: revision (specifically, clause agg</context>
</contexts>
<marker>Mooney, 1994</marker>
<rawString>David J. Mooney. 1994. Generating High-Level Structure for Extended Explanations. Ph.D. thesis, The University of Delaware, Newark, Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Power</author>
<author>Christine Doran</author>
<author>Donia Scott</author>
</authors>
<title>Generating embedded discourse markers from rhetorical structure.</title>
<date>1999</date>
<booktitle>In Proceedings of the Seventh European Workshop on Natural Language Generation,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="6736" citStr="Power et al. (1999)" startWordPosition="982" endWordPosition="985">ce, Elhadad and McKeown (1990) followed Quirk’s pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside a functional unification surface realizer (and thereby postponing lexicalization till the last possible moment). More recent approaches have tended to move the decision time for marker lexicalization higher up the pipelined architecture. For example, the MOOSE system (Stede and Umbach, 1998; Grote and Stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon. Similarly, Power et al. (1999) produce multiple discourse markers for Patient Information Leaflets using a constraint-based method applied to RST trees during sentence planning. Finally, in the CIRC-SIM intelligent tutoring system (Yang et al., 2000) that generates connected dialogues for students studying heart ailments, discourse marker lexicalization has been pushed all the way up to the discourse planning level. In this case, CIRC-SIM lexicalizes discourse markers inside of the discourse schema templates themselves. Given that these different implemented discourse marker insertion algorithms lexicalize their markers at</context>
</contexts>
<marker>Power, Doran, Scott, 1999</marker>
<rawString>Richard Power, Christine Doran, and Donia Scott. 1999. Generating embedded discourse markers from rhetorical structure. In Proceedings of the Seventh European Workshop on Natural Language Generation, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quirk</author>
<author>S Greenbaum</author>
<author>G Leech</author>
<author>J Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<publisher>Longman Publishers.</publisher>
<contexts>
<context position="5173" citStr="Quirk et al., 1985" startWordPosition="762" endWordPosition="765">s between adjacent sentences or small groups of sentences in a text. Typical examples include words like however, next, and because. Discourse markers pose a problem for both the parsing and generation of clauses in a way similar to the problems that referring expressions pose to noun phrases: changing the lexicalization of a discourse marker can change the semantic interpretation of the clauses affected. Recent work in the analysis of both the distribution and role of discourse markers has greatly extended our knowledge over even the most expansive previous accounts of discourse connectives (Quirk et al., 1985) from previous decades. For example, using a large scale corpus analysis and human subjects employing a substitution test over the corpus sentences containing discourse markers, Knott and Mellish (1996) distilled a taxonomy of individual lexical discourse markers and 8 binary-valued features that could be used to drive a discourse marker selection algorithm. Other work often focuses on particular semantic categories, such as temporal discourse markers. For instance, Grote (1998) attempted to create declarative lexicons that contain applicability conditions and other constraints to aid in the p</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>R. Quirk, S. Greenbaum, G. Leech, and J. Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Reape</author>
<author>Chris Mellish</author>
</authors>
<title>Just what is aggregation anyway?</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th European Workshop on Natural Language Generation,</booktitle>
<location>Toulouse, France,</location>
<contexts>
<context position="8539" citStr="Reape and Mellish (1999)" startWordPosition="1250" endWordPosition="1253">he sentence planner). 3 Current Implemented Revision Systems Revision (or clause aggregation) is principally concerned with taking sets of small, single-proposition sentences and finding ways to combine them into more fluent, multiple-proposition sentences. Sentences can be combined using a wide range of different syntactic forms, such as conjunction with “and”, making relative clauses with noun phrases common to both sentences, and introducing ellipsis. Typically, revision modules arise because of dissatisfaction with the quality of text produced by a simple pipelined NLG system. As noted by Reape and Mellish (1999), there is a wide variety in revision definitions, objectives, operating level, and type. Similarly, Dalianis and Hovy (1993) tried to distinguish between different revision parameters by having users perform revision thought experiments and proposing rules in RST form which mimic the behavior they observed. While neither of these were implemented revision systems, there have been several attempts to improve the quality of text from existing NLG systems. There are two approaches to the architectural position of revision systems: those that operate on semantic representations before the sentenc</context>
</contexts>
<marker>Reape, Mellish, 1999</marker>
<rawString>Mike Reape and Chris Mellish. 1999. Just what is aggregation anyway? In Proceedings of the 7th European Workshop on Natural Language Generation, Toulouse, France, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Has a consensus NL generation architecture appeared, and is it psycholinguistically plausible?</title>
<date>1994</date>
<booktitle>In Proceedings of the Seventh International Workshop on Natural Language Generation,</booktitle>
<pages>163--170</pages>
<location>Kennebunkport, ME.</location>
<contexts>
<context position="1755" citStr="Reiter, 1994" startWordPosition="259" endWordPosition="260"> themselves did not create highly readable prose, new types of architectural modules were introduced to deal with newly desired linguistic phenomena such as referring expressions, lexical choice, revision, and pronominalization. Adding each new module typically entailed that an NLG system designer would justify not only the reason for including the new module (i.e., what linguistic phenomena it produced that had been previously unattainable) but how it was integrated into their architecture and why its placement was reasonably optimal (cf., (Elhadad et al., 1997), pp. 4–7). At the same time, (Reiter, 1994) argued that implemented NLG systems were converging toward a de facto pipelined architecture (Figure 1) with minimal-to-nonexistent feedback between modules. Although several NLG architectures were proposed in opposition to such a linear arrangement (Kantrowitz and Bates, 1992; Cline, 1994), these research projects have not continued while pipelined architectures are still actively being pursued. In addition, Reiter concludes that although complete integration of architectural components is theoretically a good idea, in practical engineering terms such a system would be too inefficient to ope</context>
</contexts>
<marker>Reiter, 1994</marker>
<rawString>Ehud Reiter. 1994. Has a consensus NL generation architecture appeared, and is it psycholinguistically plausible? In Proceedings of the Seventh International Workshop on Natural Language Generation, pages 163–170, Kennebunkport, ME.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacques Robin</author>
</authors>
<title>Revision-Based Generation of Natural Language Summaries Providing Historical Background.</title>
<date>1994</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University,</institution>
<contexts>
<context position="9615" citStr="Robin, 1994" startWordPosition="1412" endWordPosition="1413"> are two approaches to the architectural position of revision systems: those that operate on semantic representations before the sentence planning level, of which a prototypical example is (Horacek, 2002), and those placed after the sentence planner, operating on syntactic/linguistic data. Here we treat mainly the second type, which have typically been conceived of as “add-on” components to existing pipelined architectures. An important implication of this architectural order is that the revision components expect to receive lexicalized sentence plans. Of these systems, Robin’s STREAK system (Robin, 1994) is the only one that accepts both lexicalized and non-lexicalized data. After a sentence planner produces the required lexicalized information that can form a complete and grammatical sentence, STREAK attempts to gradually aggregate that data. It then proceeds to try to opportunistically include additional optional information from a data set of statistics, performing aggregation operations at various syntactic levels. Because STREAK only produces single sentences, it does not attempt to add discourse markers. In addition, there is no a priori way to determine whether adjacent propositions in</context>
</contexts>
<marker>Robin, 1994</marker>
<rawString>Jacques Robin. 1994. Revision-Based Generation of Natural Language Summaries Providing Historical Background. Ph.D. thesis, Columbia University, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
</authors>
<title>Clause aggregation using linguistic knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th International Workshop on Natural Language Generation,</booktitle>
<pages>138--147</pages>
<location>Niagara-on-the-Lake, Canada.</location>
<contexts>
<context position="10937" citStr="Shaw, 1998" startWordPosition="1619" endWordPosition="1620">entire sentence plan at once and iterates through it in paragraph-sized chunks, employing clause- and phrase-level aggregation and reordering operations before passing a revised sentence plan to the surface realizer. However, at no point does it add information that previously did not exist in the sentence plan. The RTPI system (Harvey and Carberry, 1998) takes in sets of multiple, lexicalized sentential plans over a number of medical diagnoses from different critiquing systems and produces a single, unified sentence plan which is both coherent and cohesive. Like STREAK, Shaw’s CASPER system (Shaw, 1998) produces single sentences from sets of sentences and doesn’t attempt to deal with discourse markers. CASPER also delays lexicalization when aggregating by looking at the lexicon twice during the revision process. This is due mainly to the efficiency costs of the unification procedure. However, CASPER’s sentence planner essentially uses the first lexicon lookup to find a “set of lexicalizations” before eventually selecting a particular one. An important similarity of these pipelined revision systems is that they all manipulate lexicalized representations at the clause level. Given that both ag</context>
</contexts>
<marker>Shaw, 1998</marker>
<rawString>James Shaw. 1998. Clause aggregation using linguistic knowledge. In Proceedings of the 9th International Workshop on Natural Language Generation, pages 138–147, Niagara-on-the-Lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Stede</author>
<author>Carla Umbach</author>
</authors>
<title>DiM-Lex: A lexicon of discourse markers for text generation and understanding.</title>
<date>1998</date>
<booktitle>In Proceedings of the Joint 36th Meeting of the ACL and the 17th Meeting of COLING,</booktitle>
<pages>1238--1242</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="6577" citStr="Stede and Umbach, 1998" startWordPosition="958" endWordPosition="961">e-level phenomena. Alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text. In an early instance, Elhadad and McKeown (1990) followed Quirk’s pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside a functional unification surface realizer (and thereby postponing lexicalization till the last possible moment). More recent approaches have tended to move the decision time for marker lexicalization higher up the pipelined architecture. For example, the MOOSE system (Stede and Umbach, 1998; Grote and Stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon. Similarly, Power et al. (1999) produce multiple discourse markers for Patient Information Leaflets using a constraint-based method applied to RST trees during sentence planning. Finally, in the CIRC-SIM intelligent tutoring system (Yang et al., 2000) that generates connected dialogues for students studying heart ailments, discourse marker lexicalization has been pushed all the way up to the discourse planning level. In this case, CIRC-SIM lexicalizes discourse marker</context>
</contexts>
<marker>Stede, Umbach, 1998</marker>
<rawString>Manfred Stede and Carla Umbach. 1998. DiM-Lex: A lexicon of discourse markers for text generation and understanding. In Proceedings of the Joint 36th Meeting of the ACL and the 17th Meeting of COLING, pages 1238–1242, Montr´eal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E</author>
</authors>
<title>Fox Tree</title>
<date>1999</date>
<journal>Journal of Memory and Language,</journal>
<pages>27--35</pages>
<marker>E, 1999</marker>
<rawString>J. E. Fox Tree and J. C. Schrock. 1999. Discourse markers in spontaneous speech. Journal of Memory and Language, 27:35–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
<author>Aravind Joshi</author>
</authors>
<title>Anchoring a lexicalized tree-adjoining grammar for discourse.</title>
<date>1998</date>
<booktitle>In Proceedings of the COLING-ACL ’96 Discourse Relations and Discourse Markers Workshop,</booktitle>
<pages>86--92</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="5942" citStr="Webber and Joshi, 1998" startWordPosition="875" endWordPosition="878">s containing discourse markers, Knott and Mellish (1996) distilled a taxonomy of individual lexical discourse markers and 8 binary-valued features that could be used to drive a discourse marker selection algorithm. Other work often focuses on particular semantic categories, such as temporal discourse markers. For instance, Grote (1998) attempted to create declarative lexicons that contain applicability conditions and other constraints to aid in the process of discourse marker selection. Other theoretical research consists, for example, of adapting existing grammatical formalisms such as TAGs (Webber and Joshi, 1998) for discourse-level phenomena. Alternatively, there are several implemented systems that automatically insert discourse markers into multi-sentential text. In an early instance, Elhadad and McKeown (1990) followed Quirk’s pre-existing non-computational account of discourse connectives to produce single argumentative discourse markers inside a functional unification surface realizer (and thereby postponing lexicalization till the last possible moment). More recent approaches have tended to move the decision time for marker lexicalization higher up the pipelined architecture. For example, the M</context>
</contexts>
<marker>Webber, Joshi, 1998</marker>
<rawString>Bonnie Webber and Aravind Joshi. 1998. Anchoring a lexicalized tree-adjoining grammar for discourse. In Proceedings of the COLING-ACL ’96 Discourse Relations and Discourse Markers Workshop, pages 86–92, Montr´eal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feng-Jen Yang</author>
<author>Jung Hee Kim</author>
<author>Michael Glass</author>
<author>Martha Evens</author>
</authors>
<title>Lexical usage in the tutoring schemata of Circsim-Tutor: Analysis of variable references and discourse markers.</title>
<date>2000</date>
<booktitle>In The Fifth Annual Conference on Human Interaction and Complex Systems,</booktitle>
<pages>27--31</pages>
<location>Urbana, IL.</location>
<contexts>
<context position="6956" citStr="Yang et al., 2000" startWordPosition="1013" endWordPosition="1016">by postponing lexicalization till the last possible moment). More recent approaches have tended to move the decision time for marker lexicalization higher up the pipelined architecture. For example, the MOOSE system (Stede and Umbach, 1998; Grote and Stede, 1999) lexicalized discourse markers at the sentence planning level by pushing them directly into the lexicon. Similarly, Power et al. (1999) produce multiple discourse markers for Patient Information Leaflets using a constraint-based method applied to RST trees during sentence planning. Finally, in the CIRC-SIM intelligent tutoring system (Yang et al., 2000) that generates connected dialogues for students studying heart ailments, discourse marker lexicalization has been pushed all the way up to the discourse planning level. In this case, CIRC-SIM lexicalizes discourse markers inside of the discourse schema templates themselves. Given that these different implemented discourse marker insertion algorithms lexicalize their markers at three distinct places in a pipelined NLG architecture, it is not clear if lexicalization can occur at any point without restriction, or if it is in fact tied to the particular architectural modules that a system designe</context>
</contexts>
<marker>Yang, Kim, Glass, Evens, 2000</marker>
<rawString>Feng-Jen Yang, Jung Hee Kim, Michael Glass, and Martha Evens. 2000. Lexical usage in the tutoring schemata of Circsim-Tutor: Analysis of variable references and discourse markers. In The Fifth Annual Conference on Human Interaction and Complex Systems, pages 27–31, Urbana, IL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>