<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.983855">
Composing extended top-down tree transducers*
</title>
<author confidence="0.605456">
Aur´elie Lagoutte
</author>
<affiliation confidence="0.494365">
´Ecole normale sup´erieure de Cachan, D´epartement Informatique
</affiliation>
<email confidence="0.877303">
alagoutt@dptinfo.ens-cachan.fr
</email>
<author confidence="0.994337">
Fabienne Braune and Daniel Quernheim and Andreas Maletti
</author>
<affiliation confidence="0.999728">
University of Stuttgart, Institute for Natural Language Processing
</affiliation>
<email confidence="0.970288">
{braunefe,daniel,maletti}@ims.uni-stuttgart.de
</email>
<note confidence="0.615139">
RC
PREL
</note>
<sectionHeader confidence="0.975637" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9979801">
A composition procedure for linear and
nondeleting extended top-down tree trans-
ducers is presented. It is demonstrated that
the new procedure is more widely applica-
ble than the existing methods. In general,
the result of the composition is an extended
top-down tree transducer that is no longer
linear or nondeleting, but in a number of
cases these properties can easily be recov-
ered by a post-processing step.
</bodyText>
<sectionHeader confidence="0.999368" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997838217391305">
Tree-based translation models such as syn-
chronous tree substitution grammars (Eisner,
2003; Shieber, 2004) or multi bottom-up tree
transducers (Lilin, 1978; Engelfriet et al., 2009;
Maletti, 2010; Maletti, 2011) are used for sev-
eral aspects of syntax-based machine transla-
tion (Knight and Graehl, 2005). Here we consider
the extended top-down tree transducer (XTOP),
which was studied in (Arnold and Dauchet,
1982; Knight, 2007; Graehl et al., 2008; Graehl
et al., 2009) and implemented in the toolkit
TIBURON (May and Knight, 2006; May, 2010).
Specifically, we investigate compositions of linear
and nondeleting XTOPs (ln-XTOP). Arnold and
Dauchet (1982) showed that ln-XTOPs compute
a class of transformations that is not closed under
composition, so we cannot compose two arbitrary
ln-XTOPs into a single ln-XTOP. However, we
will show that ln-XTOPs can be composed into a
(not necessarily linear or nondeleting) XTOP. To
illustrate the use of ln-XTOPs in machine transla-
tion, we consider the following English sentence
together with a German reference translation:
</bodyText>
<footnote confidence="0.376992666666667">
* All authors were financially supported by the EMMY
NOETHER project MA/4959/ 1-1 of the German Research
Foundation (DFG).
</footnote>
<figure confidence="0.8588296">
C
that NP VP
C
�� NP VP
VAUX NP VPART
</figure>
<figureCaption confidence="0.999755">
Figure 1: Word drop [top] and reordering [bottom].
</figureCaption>
<bodyText confidence="0.992271275862069">
The newswire reported yesterday that the Serbs have
completed the negotiations.
Gestern [Yesterday] berichtete [reported] die [the]
Nachrichtenagentur [newswire] die [the] Serben
[Serbs] h¨atten [would have] die [the] Verhandlungen
[negotiations] beendet [completed].
The relation between them can be described
(Yamada and Knight, 2001) by three operations:
drop of the relative pronoun, movement of the
participle to end of the clause, and word-to-word
translation. Figure 1 shows the first two oper-
ations, and Figure 2 shows ln-XTOP rules per-
forming them. Let us now informally describe
the execution of an ln-XTOP on the top rule p
of Figure 2. In general, ln-XTOPs process an in-
put tree from the root towards the leaves using
a set of rules and states. The state p in the left-
hand side of p controls the particular operation of
Figure 1 [top]. Once the operation has been per-
formed, control is passed to states pNP and pVP,
which use their own rules to process the remain-
ing input subtree governed by the variable below
them (see Figure 2). In the same fashion, an ln-
XTOP containing the bottom rule of Figure 2 re-
orders the English verbal complex.
In this way we model the word drop by an ln-
XTOP M and reordering by an ln-XTOP N. The
syntactic properties of linearity and nondeletion
yield nice algorithmic properties, and the mod-
</bodyText>
<figure confidence="0.948510666666667">
C
NP VP
H
C
NP VP
VAUX VPART NP
</figure>
<page confidence="0.95634">
808
</page>
<note confidence="0.9983005">
Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 808–817,
Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999189">
Figure 2: XTOP rules for the operations of Figure 1.
</figureCaption>
<bodyText confidence="0.999870052631579">
ular approach is desirable for better design and
parametrization of the translation model (May et
al., 2010). Composition allows us to recombine
those parts into one device modeling the whole
translation. In particular, it gives all parts the
chance to vote at the same time. This is especially
important if pruning is used because it might oth-
erwise exclude candidates that score low in one
part but well in others (May et al., 2010).
Because ln-XTOP is not closed under compo-
sition, the composition of M and N might be out-
side ln-XTOP. These cases have been identified
by Arnold and Dauchet (1982) as infinitely “over-
lapping cuts”, which occur when the right-hand
sides of M and the left-hand sides of N are un-
boundedly overlapping. This can be purely syn-
tactic (for a given ln-XTOP) or semantic (inher-
ent in all ln-XTOPs for a given transformation).
Despite the general impossibility, several strate-
gies have been developed: (i) Extension of the
model (Maletti, 2010; Maletti, 2011), (ii) online
composition (May et al., 2010), and (iii) restric-
tion of the model, which we follow. Composi-
tions of subclasses in which the XTOP N has at
most one input symbol in its left-hand sides have
already been studied in (Engelfriet, 1975; Baker,
1979; Maletti and Vogler, 2010). Such compo-
sitions are implemented in the toolkit TIBURON.
However, there are translation tasks in which the
used XTOPs do not fulfill this requirement. Sup-
pose that we simply want to compose the rules of
Figure 2, The bottom rule does not satisfy the re-
quirement that there is at most one input symbol
in the left-hand side.
We will demonstrate how to compose two lin-
ear and nondeleting XTOPs into a single XTOP,
which might however no longer be linear or non-
deleting. However, when the syntactic form of
</bodyText>
<figureCaption confidence="0.98450125">
Figure 3: Linear normalized tree t E TE(Q(X)) [left]
and t[α]2 [right] withvar(t) = {x1,x2,x3}. The posi-
tions are indicated in t as superscripts. The subtree t|2
is σ(α, q(x2)).
</figureCaption>
<bodyText confidence="0.98630384375">
the composed XTOP has only bounded overlap-
ping cuts, post-processing will get rid of them
and restore an ln-XTOP. In the remaining cases,
in which unbounded overlapping is necessary or
occurs in the syntactic form but would not be nec-
essary, we will compute an XTOP. This is still
an improvement on the existing methods that just
fail. Since general XTOPs are implemented in
TIBURON and the new composition covers (essen-
tially) all cases currently possible, our new com-
position procedure could replace the existing one
in TIBURON. Our approach to composition is the
same as in (Engelfriet, 1975; Baker, 1979; Maletti
and Vogler, 2010): We simply parse the right-
hand sides of the XTOP M with the left-hand
sides of the XTOP N. However, to facilitate this
approach we have to adjust the XTOPs M and N
in two pre-processing steps. In a first step we cut
left-hand sides of rules of N into smaller pieces,
which might introduce non-linearity and deletion
into N. In certain cases, this can also intro-
duce finite look-ahead (Engelfriet, 1977; Graehl
et al., 2009). To compensate, we expand the rules
of M slightly. Section 4 explains those prepa-
rations. Next, we compose the prepared XTOPs
as usual and obtain a single XTOP computing the
composition of the transformations computed by
M and N (see Section 5). Finally, we apply a
post-processing step to expand rules to reobtain
linearity and nondeletion. Clearly, this cannot be
successful in all cases, but often removes the non-
linearity introduced in the pre-processing step.
</bodyText>
<sectionHeader confidence="0.971561" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.993947">
Our trees have labels taken from an alphabet E
of symbols, and in addition, leaves might be
labeled by elements of the countably infinite
</bodyText>
<equation confidence="0.941594212765958">
p
RC
PREL
that
C
y1 y2
pNP
y1
C
pVP
y2
�
qNP
VP
q
C
z1 VP
z2 z3 z4
C
z1
qVP
qVA
z2
z4
qNP
z3
�
δ(�)
σ(2)
α(21) q(22)
x(221)
2
q(1)
x(11)
1
γ(3)
γ(31)
p(311)
x(3111)
3
q
x1
α γ
γ
p
x3
δ
</equation>
<page confidence="0.966099">
809
</page>
<figureCaption confidence="0.989202">
Figure 4: Substitution where θ(x1) = α, θ(x2) = x2,
and θ(x3) = γ(δ(β, β, x2)).
</figureCaption>
<equation confidence="0.9450538">
set X = {x1, x2,... } of formal variables. For-
mally, for every V ⊆ X the set TΣ(V ) of
E-trees with V-leaves is the smallest set such that
V ⊆ TΣ(V ) and σ(t1,...,tk) ∈ TΣ(V ) for all
k ∈ N, σ ∈ E, and t1, ... , tk ∈ TΣ(V ). To avoid
</equation>
<bodyText confidence="0.998192555555555">
excessive universal quantifications, we drop them
if they are obvious from the context.
For each tree t ∈ TΣ(X) we identify nodes by
positions. The root of t has position ε and the po-
sition iw with i ∈ N and w ∈ N* addresses the
position w in the i-th direct subtree at the root.
The set of all positions in t is pos(t). We write
t(w) for the label (taken from E ∪ X) of t at po-
sition w ∈ pos(t). Similarly, we use
</bodyText>
<listItem confidence="0.9979758">
• t|w to address the subtree of t that is rooted
in position w, and
• t[u]w to represent the tree that is ob-
tained from replacing the subtree t|w at w
by u ∈ TΣ(X).
</listItem>
<bodyText confidence="0.8759">
For a given set L ⊆ E ∪ X of labels, we let
</bodyText>
<equation confidence="0.824166">
posL(t) = {w ∈ pos(t)  |t(w) ∈ L}
be the set of all positions whose label belongs
to L. We also write posl(t) instead of posIll(t).
The tree t ∈ TΣ(V ) is linear if |posx(t) |≤ 1 for
every x ∈ X. Moreover,
var(t) = {x ∈ X  |posx(t) =6 ∅}
</equation>
<bodyText confidence="0.983541153846154">
collects all variables that occur in t. If the vari-
ables occur in the order x1, x2,... in a pre-order
traversal of the tree t, then t is normalized. Given
a finite set Q, we write Q(T) with T ⊆ TΣ(X)
for the set {q(t)  |q ∈ Q, t ∈ T}. We will treat
elements of Q(T) as special trees of TΣuQ(X).
The previous notions are illustrated in Figure 3.
A substitution θ is a mapping θ: X → TΣ(X).
When applied to a tree t ∈ TΣ(X), it will return
the tree tθ, which is obtained from t by replacing
all occurrences of x ∈ X (in parallel) by θ(x).
This can be defined recursively by xθ = θ(x) for
all x ∈ X and σ(t1, ... , tk)θ = σ(t1θ, ... , tkθ)
</bodyText>
<figureCaption confidence="0.995185">
Figure 5: Rule and its use in a derivation step.
</figureCaption>
<bodyText confidence="0.999257333333333">
for all σ ∈ E and t1, ... , tk ∈ TΣ(X). The effect
of a substitution is displayed in Figure 4. Two
substitutions θ, θ&apos;: X → TΣ(X) can be com-
posed to form a substitution θθ&apos;: X → TΣ(X)
such that θθ&apos;(x) = θ(x)θ&apos; for every x ∈ X.
Next, we define two notions of compatibility
for trees. Let t, t&apos; ∈ TΣ(X) be two trees. If there
exists a substitution θ such that t&apos; = tθ, then t&apos; is
an instance of t. Note that this relation is not sym-
metric. A unifier θ for t and t&apos; is a substitution θ
such that tθ = t&apos;θ. The unifier θ is a most gen-
eral unifier (short: mgu) for t and t&apos; if for every
unifier θ&apos;&apos; for t and t&apos; there exists a substitution θ&apos;
such that θθ&apos; = θ&apos;&apos;. The set mgu(t, t&apos;) is the set of
all mgus for t and t&apos;. Most general unifiers can be
computed efficiently (Robinson, 1965; Martelli
and Montanari, 1982) and all mgus for t and t&apos;
are equal up to a variable renaming.
</bodyText>
<equation confidence="0.517947666666667">
Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and
t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such
that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Fig-
</equation>
<bodyText confidence="0.917345">
ure 4 illustrates the unification.
</bodyText>
<sectionHeader confidence="0.997839" genericHeader="method">
3 The model
</sectionHeader>
<bodyText confidence="0.999703">
The discussed model in this contribution is an
extension of the classical top-down tree trans-
ducer, which was introduced by Rounds (1970)
and Thatcher (1970). The extended top-down
tree transducer with finite look-ahead or just
XTOPF and its variations were studied in (Arnold
and Dauchet, 1982; Knight and Graehl, 2005;
</bodyText>
<figure confidence="0.998503662337662">
σ
x1 γ
δ
β β x2
σ
α γ
δ
β β x2
θ
7→
σ
θ
H
α x3
t
qS
S
t
S’
⇒
qNP
VP
qV
qNP
t1
t2
t1
t1
t2 t3
qS
S
x1 VP
x2 x3
x2
x1
x1
S’
→
qV
qNP
qNP
810
RC
→
pNP
y1
p
C
y1 y2
qS
S
x1 VP
x2 x3
S’
qS
S’
x2 x1 x3
S
qV
qNP
→
→
qV
x2
x1
qNP
x3
x2
qNP
x1 x3
VP
qNP
PREL
that
C
pVP
y2
</figure>
<figureCaption confidence="0.99969">
Figure 6: Rule [left] and reversed rule [right].
Figure 7: Top rule of Figure 2 reversed.
</figureCaption>
<bodyText confidence="0.9378895">
Knight, 2007; Graehl et al., 2008; Graehl et
al., 2009). Formally, an extended top-down tree
transducer with finite look-ahead (XTOPF) is a
system M = (Q, E, A, I, R, c) where
</bodyText>
<listItem confidence="0.999845375">
• Q is a finite set of states,
• E and A are alphabets of input and output
symbols, respectively,
• I ⊆ Q is a set of initial states,
• R is a finite set of (rewrite) rules of the form
` → r where ` ∈ Q(TE(X)) is linear and
r ∈ To(Q(var(`))), and
• c: R × X → TE(X) assigns a look-ahead
</listItem>
<bodyText confidence="0.989968888888889">
restriction to each rule and variable such that
c(ρ, x) is linear for each ρ ∈ R and x ∈ X.
The XTOPF M is linear (respectively, nondelet-
ing) if r is linear (respectively, var(r) = var(`))
for every rule ` → r ∈ R. It has no look-ahead
(or it is an XTOP) if c(ρ, x) ∈ X for all rules
ρ ∈ R and x ∈ X. In this case, we drop the look-
ahead component c from the description. A rule
` → r ∈ R is consuming (respectively, produc-
ing) if posE(`) =6 ∅ (respectively, poso(r) =6 ∅).
We let Lhs(M) = {l  |∃q, r: q(l) → r ∈ R}.
Let M = (Q, E, A, I, R, c) be an XTOPF. In
order to facilitate composition, we define senten-
tial forms more generally than immediately nec-
essary. Let E0 and A0 be such that E ⊆ E0
and A ⊆ A0. To keep the presentation sim-
ple, we assume that Q ∩ (E0 ∪ A0) = ∅. A
sentential form of M (using E0 and A0) is a
tree of SF(M) = To,(Q(TE�)). For every
ξ, ζ ∈ SF(M), we write ξ ⇒M ζ if there exist a
position w ∈ posQ(ξ), a rule ρ = ` → r ∈ R, and
a substitution θ: X → TES such that θ(x) is an in-
stance of c(ρ, x) for every x ∈ X and ξ = ξ[`θ]w
and ζ = ξ[rθ]w. If the applicable rules are re-
stricted to a certain subset R0 ⊆ R, then we also
write ξ ⇒R, ζ. Figure 5 illustrates a derivation
step. The tree transformation computed by M is
</bodyText>
<equation confidence="0.949297">
τM = {(t, u) ∈ TE × To  |∃q ∈ I : q(t) ⇒∗M u}
</equation>
<bodyText confidence="0.953202470588235">
where ⇒∗M is the reflexive, transitive closure
of ⇒M. It can easily be verified that the definition
of τM is independent of the choice of E0 and A0.
Moreover, it is known (Graehl et al., 2009) that
each XTOPF can be transformed into an equiva-
lent XTOP preserving both linearity and nondele-
tion. However, the notion of XTOPF will be con-
venient in our composition construction. A de-
tailed exposition to XTOPs is presented by Arnold
and Dauchet (1982) and Graehl et al. (2009).
A linear and nondeleting XTOP M with
rules R can easily be reversed to obtain
a linear and nondeleting XTOP M−1 with
rules R−1, which computes the inverse transfor-
mation τM−1 = τ−1M , by reversing all its rules.
A (suitable) rule is reversed by exchanging the
locations of the states. More precisely, given
a rule q(l) → r ∈ R, we obtain the rule
q(r0) → l0 of R−1, where l0 = lθ and r0 is the
unique tree such that there exists a substitution
θ: X → Q(X) with θ(x) ∈ Q({x}) for every
x ∈ X and r = r0θ. Figure 6 displays a rule
and its corresponding reversed rule. The reversed
form of the XTOP rule modeling the insertion op-
eration in Figure 2 is displayed in Figure 7.
Finally, let us formally define composition.
The XTOP M computes the tree transformation
τM ⊆ TE × To. Given another XTOP N that
computes a tree transformation τN ⊆ To × Tr,
we might be interested in the tree transforma-
tion computed by the composition of M and N
(i.e., running M first and then N). Formally, the
composition τM ; τN of the tree transformations
τM and τN is defined by
</bodyText>
<equation confidence="0.984674">
τM ; τN = {(s, u)  |∃t: (s, t) ∈ τM, (t, u) ∈ τN}
</equation>
<bodyText confidence="0.999980666666667">
and we often also use the notion ‘composition’ for
XTOP with the expectation that the composition
of M and N computes exactly τM ; τN.
</bodyText>
<sectionHeader confidence="0.976504" genericHeader="method">
4 Pre-processing
</sectionHeader>
<bodyText confidence="0.998074">
We want to compose two linear and nondelet-
ing XTOPs M = (P, E, A, IM, RM) and
</bodyText>
<page confidence="0.969407">
811
</page>
<figure confidence="0.999596">
LHS(M−1) LHS(N)
C
z1 VP
z2 z3 z4
Rule of M−1 Rule of N
z1 z2
C
y1 y2
→
σ
δ
y1 y2
β σ
p1
y1
q
σ
q2
z2
q1
z1
p
σ
α ←
p2
y2
</figure>
<figureCaption confidence="0.9998295">
Figure 8: Incompatible left-hand sides of Example 3.
Figure 9: Rules used in Example 5.
</figureCaption>
<bodyText confidence="0.979501111111111">
N = (Q, A, F, IN, RN). Before we actually per-
form the composition, we will prepare M and N
in two pre-processing steps. After these two steps,
the composition is very simple. To avoid com-
plications, we assume that (i) all rules of M are
producing and (ii) all rules of N are consuming.
For convenience, we also assume that the XTOPs
M and N only use variables of the disjoint sets
Y ⊆ X and Z ⊆ X, respectively.
</bodyText>
<subsectionHeader confidence="0.945195">
4.1 Compatibility
</subsectionHeader>
<bodyText confidence="0.990300357142857">
In the existing composition results for subclasses
of XTOPs (Engelfriet, 1975; Baker, 1979; Maletti
and Vogler, 2010) the XTOP N has at most one
input symbol in its left-hand sides. This restric-
tion allows us to match rule applications of N to
positions in the right-hand sides of M. Namely,
for each output symbol in a right-hand side of M,
we can select a rule of N that can consume that
output symbol. To achieve a similar decompo-
sition strategy in our more general setup, we in-
troduce a compatibility requirement on right-hand
sides of M and left-hand sides of N. Roughly
speaking, we require that the left-hand sides of N
are small enough to completely process right-
hand sides of M. However, a comparison of
left- and right-hand sides is complicated by the
fact that their shape is different (left-hand sides
have a state at the root, whereas right-hand sides
have states in front of the variables). We avoid
these complications by considering reversed rules
of M. Thus, an original right-hand side of M is
now a left-hand side in the reversed rules and thus
has the right format for a comparison. Recall that
Lhs(N) contains all left-hand sides of the rules
of N, in which the state at the root was removed.
Definition 2. The XTOP N is compatible to M
if θ(Y ) ⊆ X for all unifiers θ ∈ mgu(l1|w, l2)
between a subtree at a A-labeled position
w ∈ poso(l1) in a left-hand side l1 ∈ Lhs(M−1)
and a left-hand side l2 ∈ Lhs(N).
Intuitively, for every A-labeled position w in a
right-hand side r1 of M and any left-hand side l2
of N, we require (ignoring the states) that either
(i) r1|w and l2 are not unifiable or (ii) r1|w is an
instance of l2.
Example 3. The XTOPs for the English-to-
German translation task in the Introduction are
not compatible. This can be observed on the
left-hand side l1 ∈ Lhs(M−1) of Figure 7
and the left-hand side l2 ∈ Lhs(N) of Fig-
ure 2[bottom]. These two left-hand sides are il-
lustrated in Figure 8. Between them there is an
mgu such that θ(Y ) ⊆6 X (e.g., θ(y1) = z1 and
θ(y2) = VP(z2, z3, z4) is such an mgu).
Theorem 4. There exists an XTOPF N&apos; that is
equivalent to N and compatible with M.
Proof. We achieve compatibility by cutting of-
fending rules of the XTOP N into smaller pieces.
Unfortunately, both linearity and nondeletion
of N might be lost in the process. We first let
N&apos; = (Q, A, F, IN, RN, cN) be the XTOPF such
that cN(ρ, x) = x for every ρ ∈ RN and x ∈ X.
If N&apos; is compatible with M, then we are done.
Otherwise, let l1 ∈ Lhs(M−1) be a left-hand side,
q(l2) → r2 ∈ RN be a rule, and w ∈ poso(l1)
be a position such that θ(y) ∈/ X for some
θ ∈ mgu(l1|w, l2) and y ∈ Y . Let v ∈ posy(l1|w)
be the unique position of y in l1|w.
Now we have to distinguish two cases: (i) Ei-
ther var(l2|v) = ∅ and there is no leaf in r2 la-
beled by a symbol from F. In this case, we have
to introduce deletion and look-ahead into N&apos;. We
replace the old rule ρ = q(l2) → r2 by the new
rule ρ&apos; = q(l2[z]v) → r2, where z ∈ X \ var(l2)
is a variable that does not appear in l2. In addition,
we let cN(ρ&apos;, z) = l2|v and cN(ρ&apos;, x) = cN(ρ, x)
for all x ∈ X \ {z}.
(ii) Otherwise, let V ⊆ var(l2|v) be a maximal
set such that there exists a minimal (with respect
to the prefix order) position w&apos; ∈ pos(r2) with
</bodyText>
<page confidence="0.992346">
812
</page>
<figureCaption confidence="0.956891">
Figure 10: Additional rule used in Example 5.
</figureCaption>
<bodyText confidence="0.9004724">
var(r2|w0) ⊆ var(l2|v) and var(r2[β]w0)∩V = ∅,
where β ∈ F is arbitrary. Let z ∈ X \ var(l2) be
a fresh variable, q0 be a new state of N, and
V 0 = var(l2|v) \ V . We replace the rule
ρ = q(l2) → r2 of RN by
</bodyText>
<equation confidence="0.999945">
ρ1 = q(l2[z]v) → trans(r2)[q0(z)]w0
ρ2 = q0(l2|v) → r2|w0 .
</equation>
<bodyText confidence="0.8170095">
The look-ahead for z is trivial and other-
wise we simply copy the old look-ahead, so
</bodyText>
<equation confidence="0.86896225">
cN(ρ1, z) = z and cN(ρ1, x) = cN(ρ, x) for all
x ∈ X \ {z}. Moreover, cN(ρ2,x) = cN(ρ,x)
for all x ∈ X. The mapping ‘trans’ is given for
t = γ(t1, ... , tk) and q00(z00) ∈ Q(Z) by
</equation>
<bodyText confidence="0.976998">
where v0 = posz00(l2|v).
Finally, we collect all newly generated states
of the form hl, q, vi in Ql and for every such
state with l = δ(l1, ... , lk) and v = iw, let
</bodyText>
<equation confidence="0.98740975">
l0 = δ(z1, ... , zk) and
�
q(zi) if w = ε
hl, q, vi(l0) →
</equation>
<bodyText confidence="0.984349230769231">
hli, q, wi(zi) otherwise
be a new rule of N without look-ahead.
Overall, we run the procedure until N0 is com-
patible with M. The procedure eventually ter-
minates since the left-hand sides of the newly
added rules are always smaller than the replaced
rules. Moreover, each step preserves the seman-
tics of N0, which completes the proof.
We note that the look-ahead of N0 after the con-
struction used in the proof of Theorem 4 is either
trivial (i.e., a variable) or a ground tree (i.e., a tree
without variables). Let us illustrate the construc-
tion used in the proof of Theorem 4.
</bodyText>
<figureCaption confidence="0.980726">
Figure 11: Rules replacing the rule in Figure 7.
</figureCaption>
<bodyText confidence="0.998981">
Example 5. Let us consider the rules illustrated
in Figure 9. We might first note that y1 has to
be unified with β. Since β does not contain any
variables and the right-hand side of the rule of N
does not contain any non-variable leaves, we are
in case (i) in the proof of Theorem 4. Conse-
quently, the displayed rule of N is replaced by a
variant, in which β is replaced by a new variable z
with look-ahead β.
Secondly, with this new rule there is an mgu,
in which y2 is mapped to σ(z1, z2). Clearly, we
are now in case (ii). Furthermore, we can select
the set V = {z1, z2} and position w0 = c. Cor-
respondingly, the following two new rules for N
replace the old rule:
</bodyText>
<equation confidence="0.9381505">
q(σ(z, z0)) → q0(z0)
q0(σ(z1, z2)) → σ(q1(z1), q2(z2)) ,
</equation>
<bodyText confidence="0.998557333333333">
where the look-ahead for z remains β.
Figure 10 displays another rule of N. There is
an mgu, in which y2 is mapped to σ(z2, z3). Thus,
we end up in case (ii) again and we can select the
set V = {z2} and position w0 = 2. Thus, we
replace the rule of Figure 10 by the new rules
</bodyText>
<equation confidence="0.997983666666667">
q(σ(z1, z)) → δ(q1(z1), q0(z), q3(z)) (?)
q0(σ(z2,z3)) → q2(z2)
q3(σ(z1,z2)) → q3(z2) ,
</equation>
<bodyText confidence="0.99535425">
where q3 = hσ(z2, z3), q3, 2i.
Let us use the construction in the proof of The-
orem 4 to resolve the incompatibility (see Exam-
ple 3) between the XTOPs presented in the Intro-
duction. Fortunately, the incompatibility can be
resolved easily by cutting the rule of N (see Fig-
ure 7) into the rules of Figure 11. In this example,
linearity and nondeletion are preserved.
</bodyText>
<figure confidence="0.892754347826087">
z1
z2
Another rule of N
q
σ
z1 σ
z2 z3
z3
→
q1
δ
q2
q3
→
q
µ1: C
z1 z
qNP
C
q0
z1 z
q0
VP
</figure>
<equation confidence="0.864660615384615">
z2 z3 z4
µ2 :
z2
z4
z3
qVP
qVA
qNP
→
VP
trans(t) = γ(trans(t1), ... , trans(tk))
trans(q00(z00)) = f hl2|v,q00,v0i(z) if z00 ∈ V 0
q00(z00) otherwise,
</equation>
<page confidence="0.997172">
813
</page>
<subsectionHeader confidence="0.993062">
4.2 Local determinism
</subsectionHeader>
<bodyText confidence="0.991996612903226">
After the first pre-processing step, we have the
original linear and nondeleting XTOP M and
an XTOPF N0 = (Q0, A, F, IN, R0N, cN) that is
equivalent to N and compatible with M. How-
ever, in the first pre-processing step we might
have introduced some non-linear (copying) rules
in N0 (see rule (?) in Example 5), and it is known
that “nondeterminism [in M] followed by copy-
ing [in N0]” is a feature that prevents composition
to work (Engelfriet, 1975; Baker, 1979). How-
ever, our copying is very local and the copies
are only used to project to different subtrees.
Nevertheless, during those projection steps, we
need to make sure that the processing in M pro-
ceeds deterministically. We immediately note that
all but one copy are processed by states of the
form hl, q, vi ∈ Ql. These states basically pro-
cess (part of) the tree l and project (with state q)
to the subtree at position v. It is guaranteed that
each such subtree (indicated by v) is reached only
once. Thus, the copying is “resolved” once the
states of the form hl, q, vi are left. To keep the
presentation simple, we just add expanded rules
to M such that any rule that can produce a part of
a tree l immediately produces the whole tree. A
similar strategy is used to handle the look-ahead
of N0. Any right-hand side of a rule of M that
produces part of a left-hand side of a rule of N0
with look-ahead is expanded to produce the re-
quired look-ahead immediately.
Let L ⊆ TA(Z) be the set of trees l such that
</bodyText>
<listItem confidence="0.8444148">
• hl, q, vi appears as a state of Ql, or
• l = l2θ for some ρ2 = q(l2) → r2 ∈ R0N
of N0 with non-trivial look-ahead (i.e.,
cN(ρ2, z) ∈/ X for some z ∈ X), where
θ(x) = cN(ρ2, x) for every x ∈ X.
</listItem>
<bodyText confidence="0.999594307692308">
To keep the presentation uniform, we assume
that for every l ∈ L, there exists a state of the
form hl, q, vi ∈ Q0. If this is not already the
case, then we can simply add useless states with-
out rules for them. In other words, we assume that
the first case applies to each l ∈ L.
Next, we add two sets of rules to RM, which
will not change the semantics but prove to be use-
ful in the composition construction. First, for
every tree t ∈ L, let Rt contain all the rules
p(l) → r, where p = p(l) → r is a new state
with p ∈ P, minimal normalized tree l ∈ TE(X),
and an instance r ∈ TA(P(X)) of t such that
</bodyText>
<figureCaption confidence="0.9849345">
Figure 12: Useful rules for the composition M&apos; ; N&apos; of
Example 8, where s, s&apos; ∈ {α, β} and ρ ∈ PQ(z2,z3).
</figureCaption>
<bodyText confidence="0.982993357142857">
p(l) ⇒∗M, ξ ⇒M, r for some ξ that is not an
instance of t. In other words, we construct each
rule of Rt by applying existing rules of RM in
sequence to generate a (minimal) right-hand side
that is an instance of t. We thus potentially make
the right-hand sides of M bigger by joining sev-
eral existing rules into a single rule. Note that
this affects neither compatibility nor the seman-
tics. In the second step, we add pure ε-rules
that allow us to change the state to one that we
constructed in the previous step. For every new
state p� = p(l) → r, let base(p) = p. Then
R0M = RM ∪ RL ∪ RE and P0 = P ∪ Ut∈L Pt
where
</bodyText>
<equation confidence="0.98075475">
�RL = Rt and Pt = {`(ε)  |` → r ∈ Rt}
t∈L
RE = {base(�p)(x1) → �p(x1)  |p� ∈ � Pt} .
t∈L
</equation>
<bodyText confidence="0.9955466">
Clearly, this does not change the semantics be-
cause each rule of R0M can be simulated by a
chain of rules of RM. Let us now do a full ex-
ample for the pre-processing step. We consider a
nondeterministic variant of the classical example
by Arnold and Dauchet (1982).
Example 6. Let M = (P, E, E, {p}, RM)
be the linear and nondeleting XTOP such that
P = {p, pa, pa}, E = {δ, σ, α, β, E}, and
RM contains the following rules
</bodyText>
<figure confidence="0.978592456790123">
p(σ(y1,y2)) → σ(ps(y1),p(y2)) (†)
q
p
i
→
δ
→
y1 y2
σ
ps
y1
i
ps
E
s
i
ps
y1
i
ps
s0
y1
q0
ρ
y2
q
ρ
y2
→ E
i
ps
y1
→
q
0
ρs,s, /ρs,s,
δ
y1 y2 y3
y1 y2
y1 y2
→
→
σ
q
ρs
σ
q0
ρs
q
p
y2
i
ps
y1
δ
σ
→
→
y1 y2 y3
y1 y2 y3
q0
ρ0s,s,
δ
q0
ρs,s,
δ
i
ps,
y2
i
pa
y3
i
ps,
y2
q0
ρ
y3
q
ρ
y3
</figure>
<page confidence="0.750909">
814
</page>
<equation confidence="0.740754125">
hq, pi
RC
PREL
that
p(δ(y1, y2, y3)) → σ(ps(y1), σ(ps0(y2),p(y3)))
p(δ(y1, y2, y3)) → σ(ps(y1), σ(ps0(y2),pα(y3)))
ps(s&apos;(y1)) → s(ps(y1))
ps(e) → E
</equation>
<bodyText confidence="0.99958725">
for every s, s&apos; ∈ {α, β}. Similarly, we let
N = (Q, E, E, {q}, RN) be the linear and non-
deleting XTOP such that Q = {q, i} and RN con-
tains the following rules
</bodyText>
<equation confidence="0.998220333333333">
q(σ(z1,z2)) →σ(i(z1),i(z2)) q(σ(z1, σ(z2, z3))) → δ(i(z1), i(z2), q(z3)) (‡)
i(s(z1)) → s(i(z1))
i(c) → E
</equation>
<bodyText confidence="0.9994974">
for all s ∈ {α, β}. It can easily be verified that
M and N meet our requirements. However, N is
not yet compatible with M because an mgu be-
tween rules (†) of M and (‡) of N might map y2
to σ(z2, z3). Thus, we decompose (‡) into
</bodyText>
<equation confidence="0.974695666666667">
q(σ(z1, z)) → δ(i(z1), q(z), q&apos;(z))
q&apos;(σ(z2, z3)) → q(z3)
q(σ(z1,z2)) →i(z1)
</equation>
<bodyText confidence="0.999991555555556">
where q = hσ(z2, z3), i, 1i. This newly obtained
XTOP N&apos; is compatible with M. In addition, we
only have one special tree σ(z2, z3) that occurs in
states of the form hl, q, vi. Thus, we need to com-
pute all minimal derivations whose output trees
are instances of σ(z2, z3). This is again simple
since the first three rule schemes ρs, ρs,s0, and
ρ&apos;s s0 of M create such instances, so we simply
create copies of them:
</bodyText>
<equation confidence="0.999693">
ρs(σ(y1,y2)) → σ(ps(y1),p(y,2))
ρs,s&apos;/(δ/(y1,y2,y3)) → σ(p,„„s(y1),σ(Ps&apos;/(y2),p(y3)))
ρ&apos;s,s&apos;laly1,y2,y3)) → σ(Ps(y1),σ(ps&apos;(y2),pα(y3)))
</equation>
<bodyText confidence="0.988303">
for all s, s&apos; ∈ {α, β}. These are all the rules
of Rσ(z,,z3). In addition, we create the following
rules of RE:
</bodyText>
<equation confidence="0.9983005">
p(x1) → ρs(x1) p(x1) → ρs,s0(x1)
p(x1) → ρ&apos;s,s0(x1)
</equation>
<bodyText confidence="0.98644125">
for all s, s&apos; ∈ {α, β}.
Especially after reading the example it might
seem useless to create the rule copies in Rl [in Ex-
ample 6 for l = σ(z2, z3)]. However, each such
rule has a distinct state at the root of the left-hand
side, which can be used to trigger only this rule.
In this way, the state selects the next rule to apply,
which yields the desired local determinism.
</bodyText>
<equation confidence="0.601671666666667">
C
x1 x2
x1 x2
</equation>
<figureCaption confidence="0.9999025">
Figure 13: Composed rule created from the rule of Fig-
ure 7 and the rules of N&apos; displayed in Figure 11.
</figureCaption>
<sectionHeader confidence="0.997143" genericHeader="evaluation">
5 Composition
</sectionHeader>
<bodyText confidence="0.999991304347826">
Now we are ready for the actual composition. For
space efficiency reasons we reuse the notations
used in Section 4. Moreover, we identify trees of
Tr(Q&apos;(P&apos;(X))) with trees of Tr((Q&apos; × P&apos;)(X)).
In other words, when meeting a subtree q(p(x))
with q ∈ Q&apos;, p ∈ P&apos;, and x ∈ X, then we also
view this equivalently as the tree hq, pi(x), which
could be part of a rule of our composed XTOP.
However, not all combinations of states will be
allowed in our composed XTOP, so some combi-
nations will never yield valid rules.
Generally, we construct a rule of M&apos;;N&apos; by ap-
plying a single rule of M&apos; followed by any num-
ber of pure ε-rules of RE, which can turn states
base(p) into p. Then we apply any number of
rules of N&apos; and try to obtain a sentential form that
has the required shape of a rule of M&apos; ; N&apos;.
Definition 7. Let M&apos; = (P&apos;, E, 0, IM, R&apos;M) and
N&apos; = (Q&apos;, 0, F, IN, R&apos;N) be the XTOPs con-
structed in Section 4, where UlEL Pl ⊆ P&apos; and
UlEL Ql ⊆ Q&apos;. Let Q&apos;&apos; = Q&apos; \ UlEL Ql. We con-
struct the XTOP M&apos;;N&apos; = (S, E, F, IN ×IM, R)
where
</bodyText>
<equation confidence="0.987638">
S = � (Ql × Pl) ∪ (Q&apos;&apos; × P&apos;)
lEL
</equation>
<bodyText confidence="0.994260818181818">
and R contains all normalized rules ` → r (of the
required shape) such that
` ⇒M0 ξ ⇒RE ζ ⇒N0 r
for some ξ, ζ ∈ Tr(Q&apos;(TA(P&apos;(X)))).
The required rule shape is given by the defi-
nition of an XTOP. Most importantly, we must
have that ` ∈ S(TE(X)), which we identify
with a certain subset of Q&apos;(P&apos;(TE(X))), and
r ∈ Tr(S(X)), which similarly corresponds to
a subset of Tr(Q&apos;(P&apos;(X))). The states are sim-
ply combinations of the states of M&apos; and N&apos;, of
</bodyText>
<figure confidence="0.993989409090909">
C
→
hqNP,pNPi
hq&apos;, pVPi
815
σ
→
q
p
y3
→
i
ps
y2
i
ps
y1
q
p
σ
y1 σ
y2 y3
q
p
σ
y1 δ
y2 y3 y4
σ
i
δ
i
ps
ps0
q
i
y1
y2
ps00
y3
q0
ρ0
y4
ρ0
y4
</figure>
<figureCaption confidence="0.999869">
Figure 14: Successfully expanded rule from Exam-
ple 9.
</figureCaption>
<bodyText confidence="0.9998414">
which however the combinations of a state q ∈ Ql
with a state p ∈/ Pl are forbidden. This reflects the
intuition of the previous section. If we entered a
special state of the form hl, q, vi, then we should
use a corresponding state p ∈ Pl of M, which
only has rules producing instances of l. We note
that look-ahead of N0 is checked normally in the
derivation process.
Example 8. Now let us illustrate the composition
on Example 6. Let us start with rule (†) of M.
</bodyText>
<equation confidence="0.99426125">
q(p(σ(x1, x2)))
⇒M0 q(σ(ps(x1),p(x2)))
⇒RE q(σ(ps(x1), ρs0,s00(x2)))
⇒N0 δ(i(ps(x1)),q(ρs0,s00(x2)),q0(ρs0,s00(x2)))
</equation>
<bodyText confidence="0.998519">
is a rule of M0 ; N0 for every s, s0, s00 ∈ {α, β}.
Note if we had not applied the RE-step, then we
would not have obtained a rule of M ; N (be-
cause we would have obtained the state combina-
tion hq, pi instead of hq, ρs0,s00i, and hq, pi is not a
state of M0 ; N0). Let us also construct a rule for
the state combination hq, ρs0,s00i.
</bodyText>
<equation confidence="0.981832">
q(ρs0,s00(δ(x1, x2, x3)))
⇒M0 q(σ(ps0(x1),σ(ps00(x2),p(x3))))
⇒N0 q0(ps0(x1))
Finally, let us construct a rule for the state combi-
nation hq00, ρs0,s00i.
q00(ρs0,s00(δ(x1, x2, x3)))
⇒M0 q(σ(ps0(x1),σ(ps00(x2),p(x3))))
⇒RE q(σ(ps0(x1), σ(ps00(x2), ρs(x3))))
⇒N0 q(σ(ps00(x2),ρs(x3)))
⇒N0 δ(q0(ps00(x1)), q(ρs(x2)), q00(ρs(x2)))
</equation>
<bodyText confidence="0.991463">
for every s ∈ {α, β}.
After having pre-processed the XTOPs in our
introductory example, the devices M and N0 can
be composed into M ; N0. One rule of the com-
posed XTOP is illustrated in Figure 13.
</bodyText>
<figureCaption confidence="0.994042">
Figure 15: Expanded rule that remains copying (see
Example 9).
</figureCaption>
<sectionHeader confidence="0.964075" genericHeader="conclusions">
6 Post-processing
</sectionHeader>
<bodyText confidence="0.967569285714286">
Finally, we will compose rules again in an ef-
fort to restore linearity (and nondeletion). Since
the composition of two linear and nondeleting
XTOPs cannot always be computed by a single
XTOP (Arnold and Dauchet, 1982), this method
can fail to return such an XTOP. The presented
method is not a characterization, which means it
might even fail to return a linear and nondelet-
ing XTOP although an equivalent linear and non-
deleting XTOP exists. However, in a significant
number of examples, the recombination succeeds
to rebuild a linear (and nondeleting) XTOP.
Let M0 ; N0 = (S, E, F, I, R) be the composed
XTOP constructed in Section 5. We simply in-
spect each non-linear rule (i.e., each rule with a
non-linear right-hand side) and expand it by all
rule options at the copied variables. Since the
method is pretty standard and variants have al-
ready been used in the pre-processing steps, we
only illustrate it on the rules of Figure 12.
Example 9. The first (top row, left-most) rule of
Figure 12 is non-linear in the variable y2. Thus,
we expand the calls hq, ρi(y2) and hq0, ρi(y2). If
ρ = ρs for some s ∈ {α, β}, then the next rules
are uniquely determined and we obtain the rule
displayed in Figure 14. Here the expansion was
successful and we could delete the original rule
for ρ = ρs and replace it by the displayed ex-
panded rule. However, if ρ = ρ0s0,s00, then we can
also expand the rule to obtain the rule displayed in
Figure 15. It is still copying and we could repeat
the process of expansion here, but we cannot get
rid of all copying rules using this approach (as ex-
pected since there is no linear XTOP computing
the same tree transformation).
</bodyText>
<page confidence="0.997756">
816
</page>
<sectionHeader confidence="0.998345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999897038461539">
Andr´e Arnold and Max Dauchet. 1982. Morphismes
et bimorphismes d’arbres. Theoretical Computer
Science, 20(1):33–93.
Brenda S. Baker. 1979. Composition of top-down
and bottom-up tree transductions. Information and
Control, 41(2):186–213.
Jason Eisner. 2003. Learning non-isomorphic tree
mappings for machine translation. In Proc. ACL,
pages 205–208. Association for Computational Lin-
guistics.
Joost Engelfriet, Eric Lilin, and Andreas Maletti.
2009. Composition and decomposition of extended
multi bottom-up tree transducers. Acta Informatica,
46(8):561–590.
Joost Engelfriet. 1975. Bottom-up and top-down
tree transformations—A comparison. Mathemati-
cal Systems Theory, 9(3):198–231.
Joost Engelfriet. 1977. Top-down tree transducers
with regular look-ahead. Mathematical Systems
Theory, 10(1):289–303.
Jonathan Graehl, Kevin Knight, and Jonathan May.
2008. Training tree transducers. Computational
Linguistics, 34(3):391–427.
Jonathan Graehl, Mark Hopkins, Kevin Knight, and
Andreas Maletti. 2009. The power of extended top-
down tree transducers. SIAM Journal on Comput-
ing, 39(2):410–430.
Kevin Knight and Jonathan Graehl. 2005. An over-
view of probabilistic tree transducers for natural
language processing. In Proc. CICLing, volume
3406 of LNCS, pages 1–24. Springer.
Kevin Knight. 2007. Capturing practical natural
language transformations. Machine Translation,
21(2):121–133.
Eric Lilin. 1978. Une g´en´eralisation des transduc-
teurs d’´etats finis d’arbres: les S-transducteurs.
Th`ese 3`eme cycle, Universit´e de Lille.
Andreas Maletti and Heiko Vogler. 2010. Composi-
tions of top-down tree transducers with e-rules. In
Proc. FSMNLP, volume 6062 of LNAI, pages 69–
80. Springer.
Andreas Maletti. 2010. Why synchronous tree sub-
stitution grammars? In Proc. HLT-NAACL, pages
876–884. Association for Computational Linguis-
tics.
Andreas Maletti. 2011. An alternative to synchronous
tree substitution grammars. Natural Language En-
gineering, 17(2):221–242.
Alberto Martelli and Ugo Montanari. 1982. An effi-
cient unification algorithm. ACM Transactions on
Programming Languages and Systems, 4(2):258–
282.
Jonathan May and Kevin Knight. 2006. Tiburon: A
weighted tree automata toolkit. In Proc. CIAA, vol-
ume 4094 of LNCS, pages 102–113. Springer.
Jonathan May, Kevin Knight, and Heiko Vogler. 2010.
Efficient inference through cascades of weighted
tree transducers. In Proc. ACL, pages 1058–1066.
Association for Computational Linguistics.
Jonathan May. 2010. Weighted Tree Automata and
Transducers for Syntactic Natural Language Pro-
cessing. Ph.D. thesis, University of Southern Cali-
fornia, Los Angeles.
John Alan Robinson. 1965. A machine-oriented logic
based on the resolution principle. Journal of the
ACM, 12(1):23–41.
William C. Rounds. 1970. Mappings and grammars
on trees. Mathematical Systems Theory, 4(3):257–
287.
Stuart M. Shieber. 2004. Synchronous grammars as
tree transducers. In Proc. TAG+7, pages 88–95.
James W. Thatcher. 1970. Generalized sequential
machine maps. Journal of Computer and System
Sciences, 4(4):339–367.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. In Proc. ACL,
pages 523–530. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.997752">
817
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.051757">
<title confidence="0.6142">extended top-down tree Aur´elie Lagoutte ´Ecole normale sup´erieure de Cachan, D´epartement alagoutt@dptinfo.ens-cachan.fr</title>
<author confidence="0.932886">Braune Quernheim</author>
<affiliation confidence="0.986805">University of Stuttgart, Institute for Natural Language</affiliation>
<email confidence="0.586156333333333">braunefe@ims.uni-stuttgart.deRCPREL</email>
<email confidence="0.586156333333333">daniel@ims.uni-stuttgart.deRCPREL</email>
<email confidence="0.586156333333333">maletti@ims.uni-stuttgart.deRCPREL</email>
<abstract confidence="0.993376727272727">A composition procedure for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andr´e Arnold</author>
<author>Max Dauchet</author>
</authors>
<title>Morphismes et bimorphismes d’arbres.</title>
<date>1982</date>
<journal>Theoretical Computer Science,</journal>
<volume>20</volume>
<issue>1</issue>
<contexts>
<context position="1186" citStr="Arnold and Dauchet, 1982" startWordPosition="161" endWordPosition="164">lt of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or nondeleting) XTOP. To illustrate the use of ln-XTOPs in machine translation, we consider the following English</context>
<context position="4286" citStr="Arnold and Dauchet (1982)" startWordPosition="678" endWordPosition="681">e operations of Figure 1. ular approach is desirable for better design and parametrization of the translation model (May et al., 2010). Composition allows us to recombine those parts into one device modeling the whole translation. In particular, it gives all parts the chance to vote at the same time. This is especially important if pruning is used because it might otherwise exclude candidates that score low in one part but well in others (May et al., 2010). Because ln-XTOP is not closed under composition, the composition of M and N might be outside ln-XTOP. These cases have been identified by Arnold and Dauchet (1982) as infinitely “overlapping cuts”, which occur when the right-hand sides of M and the left-hand sides of N are unboundedly overlapping. This can be purely syntactic (for a given ln-XTOP) or semantic (inherent in all ln-XTOPs for a given transformation). Despite the general impossibility, several strategies have been developed: (i) Extension of the model (Maletti, 2010; Maletti, 2011), (ii) online composition (May et al., 2010), and (iii) restriction of the model, which we follow. Compositions of subclasses in which the XTOP N has at most one input symbol in its left-hand sides have already bee</context>
<context position="10721" citStr="Arnold and Dauchet, 1982" startWordPosition="1922" endWordPosition="1925">ifiers can be computed efficiently (Robinson, 1965; Martelli and Montanari, 1982) and all mgus for t and t&apos; are equal up to a variable renaming. Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Figure 4 illustrates the unification. 3 The model The discussed model in this contribution is an extension of the classical top-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Formally, an extended top-down tree transducer with finite look-ahead (XTOPF) is a system M = (Q, E, A, I, R, c) where • Q is a finite set of states, • E and A ar</context>
<context position="13302" citStr="Arnold and Dauchet (1982)" startWordPosition="2507" endWordPosition="2510">certain subset R0 ⊆ R, then we also write ξ ⇒R, ζ. Figure 5 illustrates a derivation step. The tree transformation computed by M is τM = {(t, u) ∈ TE × To |∃q ∈ I : q(t) ⇒∗M u} where ⇒∗M is the reflexive, transitive closure of ⇒M. It can easily be verified that the definition of τM is independent of the choice of E0 and A0. Moreover, it is known (Graehl et al., 2009) that each XTOPF can be transformed into an equivalent XTOP preserving both linearity and nondeletion. However, the notion of XTOPF will be convenient in our composition construction. A detailed exposition to XTOPs is presented by Arnold and Dauchet (1982) and Graehl et al. (2009). A linear and nondeleting XTOP M with rules R can easily be reversed to obtain a linear and nondeleting XTOP M−1 with rules R−1, which computes the inverse transformation τM−1 = τ−1M , by reversing all its rules. A (suitable) rule is reversed by exchanging the locations of the states. More precisely, given a rule q(l) → r ∈ R, we obtain the rule q(r0) → l0 of R−1, where l0 = lθ and r0 is the unique tree such that there exists a substitution θ: X → Q(X) with θ(x) ∈ Q({x}) for every x ∈ X and r = r0θ. Figure 6 displays a rule and its corresponding reversed rule. The rev</context>
<context position="25030" citStr="Arnold and Dauchet (1982)" startWordPosition="4870" endWordPosition="4873">affects neither compatibility nor the semantics. In the second step, we add pure ε-rules that allow us to change the state to one that we constructed in the previous step. For every new state p� = p(l) → r, let base(p) = p. Then R0M = RM ∪ RL ∪ RE and P0 = P ∪ Ut∈L Pt where �RL = Rt and Pt = {`(ε) |` → r ∈ Rt} t∈L RE = {base(�p)(x1) → �p(x1) |p� ∈ � Pt} . t∈L Clearly, this does not change the semantics because each rule of R0M can be simulated by a chain of rules of RM. Let us now do a full example for the pre-processing step. We consider a nondeterministic variant of the classical example by Arnold and Dauchet (1982). Example 6. Let M = (P, E, E, {p}, RM) be the linear and nondeleting XTOP such that P = {p, pa, pa}, E = {δ, σ, α, β, E}, and RM contains the following rules p(σ(y1,y2)) → σ(ps(y1),p(y2)) (†) q p i → δ → y1 y2 σ ps y1 i ps E s i ps y1 i ps s0 y1 q0 ρ y2 q ρ y2 → E i ps y1 → q 0 ρs,s, /ρs,s, δ y1 y2 y3 y1 y2 y1 y2 → → σ q ρs σ q0 ρs q p y2 i ps y1 δ σ → → y1 y2 y3 y1 y2 y3 q0 ρ0s,s, δ q0 ρs,s, δ i ps, y2 i pa y3 i ps, y2 q0 ρ y3 q ρ y3 814 hq, pi RC PREL that p(δ(y1, y2, y3)) → σ(ps(y1), σ(ps0(y2),p(y3))) p(δ(y1, y2, y3)) → σ(ps(y1), σ(ps0(y2),pα(y3))) ps(s&apos;(y1)) → s(ps(y1)) ps(e) → E for ever</context>
<context position="30844" citStr="Arnold and Dauchet, 1982" startWordPosition="6024" endWordPosition="6027">,σ(ps00(x2),p(x3)))) ⇒RE q(σ(ps0(x1), σ(ps00(x2), ρs(x3)))) ⇒N0 q(σ(ps00(x2),ρs(x3))) ⇒N0 δ(q0(ps00(x1)), q(ρs(x2)), q00(ρs(x2))) for every s ∈ {α, β}. After having pre-processed the XTOPs in our introductory example, the devices M and N0 can be composed into M ; N0. One rule of the composed XTOP is illustrated in Figure 13. Figure 15: Expanded rule that remains copying (see Example 9). 6 Post-processing Finally, we will compose rules again in an effort to restore linearity (and nondeletion). Since the composition of two linear and nondeleting XTOPs cannot always be computed by a single XTOP (Arnold and Dauchet, 1982), this method can fail to return such an XTOP. The presented method is not a characterization, which means it might even fail to return a linear and nondeleting XTOP although an equivalent linear and nondeleting XTOP exists. However, in a significant number of examples, the recombination succeeds to rebuild a linear (and nondeleting) XTOP. Let M0 ; N0 = (S, E, F, I, R) be the composed XTOP constructed in Section 5. We simply inspect each non-linear rule (i.e., each rule with a non-linear right-hand side) and expand it by all rule options at the copied variables. Since the method is pretty stan</context>
</contexts>
<marker>Arnold, Dauchet, 1982</marker>
<rawString>Andr´e Arnold and Max Dauchet. 1982. Morphismes et bimorphismes d’arbres. Theoretical Computer Science, 20(1):33–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brenda S Baker</author>
</authors>
<title>Composition of top-down and bottom-up tree transductions.</title>
<date>1979</date>
<journal>Information and Control,</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="4929" citStr="Baker, 1979" startWordPosition="788" endWordPosition="789">”, which occur when the right-hand sides of M and the left-hand sides of N are unboundedly overlapping. This can be purely syntactic (for a given ln-XTOP) or semantic (inherent in all ln-XTOPs for a given transformation). Despite the general impossibility, several strategies have been developed: (i) Extension of the model (Maletti, 2010; Maletti, 2011), (ii) online composition (May et al., 2010), and (iii) restriction of the model, which we follow. Compositions of subclasses in which the XTOP N has at most one input symbol in its left-hand sides have already been studied in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010). Such compositions are implemented in the toolkit TIBURON. However, there are translation tasks in which the used XTOPs do not fulfill this requirement. Suppose that we simply want to compose the rules of Figure 2, The bottom rule does not satisfy the requirement that there is at most one input symbol in the left-hand side. We will demonstrate how to compose two linear and nondeleting XTOPs into a single XTOP, which might however no longer be linear or nondeleting. However, when the syntactic form of Figure 3: Linear normalized tree t E TE(Q(X)) [left] and t[α]2 [ri</context>
<context position="6248" citStr="Baker, 1979" startWordPosition="1013" endWordPosition="1014">)). the composed XTOP has only bounded overlapping cuts, post-processing will get rid of them and restore an ln-XTOP. In the remaining cases, in which unbounded overlapping is necessary or occurs in the syntactic form but would not be necessary, we will compute an XTOP. This is still an improvement on the existing methods that just fail. Since general XTOPs are implemented in TIBURON and the new composition covers (essentially) all cases currently possible, our new composition procedure could replace the existing one in TIBURON. Our approach to composition is the same as in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010): We simply parse the righthand sides of the XTOP M with the left-hand sides of the XTOP N. However, to facilitate this approach we have to adjust the XTOPs M and N in two pre-processing steps. In a first step we cut left-hand sides of rules of N into smaller pieces, which might introduce non-linearity and deletion into N. In certain cases, this can also introduce finite look-ahead (Engelfriet, 1977; Graehl et al., 2009). To compensate, we expand the rules of M slightly. Section 4 explains those preparations. Next, we compose the prepared XTOPs as usual and obtain a </context>
<context position="15398" citStr="Baker, 1979" startWordPosition="2931" endWordPosition="2932">y2 Figure 8: Incompatible left-hand sides of Example 3. Figure 9: Rules used in Example 5. N = (Q, A, F, IN, RN). Before we actually perform the composition, we will prepare M and N in two pre-processing steps. After these two steps, the composition is very simple. To avoid complications, we assume that (i) all rules of M are producing and (ii) all rules of N are consuming. For convenience, we also assume that the XTOPs M and N only use variables of the disjoint sets Y ⊆ X and Z ⊆ X, respectively. 4.1 Compatibility In the existing composition results for subclasses of XTOPs (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010) the XTOP N has at most one input symbol in its left-hand sides. This restriction allows us to match rule applications of N to positions in the right-hand sides of M. Namely, for each output symbol in a right-hand side of M, we can select a rule of N that can consume that output symbol. To achieve a similar decomposition strategy in our more general setup, we introduce a compatibility requirement on right-hand sides of M and left-hand sides of N. Roughly speaking, we require that the left-hand sides of N are small enough to completely process righthand sides of M. Ho</context>
<context position="22151" citStr="Baker, 1979" startWordPosition="4279" endWordPosition="4280">qVA qNP → VP trans(t) = γ(trans(t1), ... , trans(tk)) trans(q00(z00)) = f hl2|v,q00,v0i(z) if z00 ∈ V 0 q00(z00) otherwise, 813 4.2 Local determinism After the first pre-processing step, we have the original linear and nondeleting XTOP M and an XTOPF N0 = (Q0, A, F, IN, R0N, cN) that is equivalent to N and compatible with M. However, in the first pre-processing step we might have introduced some non-linear (copying) rules in N0 (see rule (?) in Example 5), and it is known that “nondeterminism [in M] followed by copying [in N0]” is a feature that prevents composition to work (Engelfriet, 1975; Baker, 1979). However, our copying is very local and the copies are only used to project to different subtrees. Nevertheless, during those projection steps, we need to make sure that the processing in M proceeds deterministically. We immediately note that all but one copy are processed by states of the form hl, q, vi ∈ Ql. These states basically process (part of) the tree l and project (with state q) to the subtree at position v. It is guaranteed that each such subtree (indicated by v) is reached only once. Thus, the copying is “resolved” once the states of the form hl, q, vi are left. To keep the present</context>
</contexts>
<marker>Baker, 1979</marker>
<rawString>Brenda S. Baker. 1979. Composition of top-down and bottom-up tree transductions. Information and Control, 41(2):186–213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Learning non-isomorphic tree mappings for machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>205--208</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="863" citStr="Eisner, 2003" startWordPosition="114" endWordPosition="115">for Natural Language Processing {braunefe,daniel,maletti}@ims.uni-stuttgart.de RC PREL Abstract A composition procedure for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a cla</context>
</contexts>
<marker>Eisner, 2003</marker>
<rawString>Jason Eisner. 2003. Learning non-isomorphic tree mappings for machine translation. In Proc. ACL, pages 205–208. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
<author>Eric Lilin</author>
<author>Andreas Maletti</author>
</authors>
<title>Composition and decomposition of extended multi bottom-up tree transducers.</title>
<date>2009</date>
<journal>Acta Informatica,</journal>
<volume>46</volume>
<issue>8</issue>
<contexts>
<context position="953" citStr="Engelfriet et al., 2009" startWordPosition="125" endWordPosition="128">RC PREL Abstract A composition procedure for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbit</context>
</contexts>
<marker>Engelfriet, Lilin, Maletti, 2009</marker>
<rawString>Joost Engelfriet, Eric Lilin, and Andreas Maletti. 2009. Composition and decomposition of extended multi bottom-up tree transducers. Acta Informatica, 46(8):561–590.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
</authors>
<title>Bottom-up and top-down tree transformations—A comparison.</title>
<date>1975</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<pages>9--3</pages>
<contexts>
<context position="4916" citStr="Engelfriet, 1975" startWordPosition="786" endWordPosition="787"> “overlapping cuts”, which occur when the right-hand sides of M and the left-hand sides of N are unboundedly overlapping. This can be purely syntactic (for a given ln-XTOP) or semantic (inherent in all ln-XTOPs for a given transformation). Despite the general impossibility, several strategies have been developed: (i) Extension of the model (Maletti, 2010; Maletti, 2011), (ii) online composition (May et al., 2010), and (iii) restriction of the model, which we follow. Compositions of subclasses in which the XTOP N has at most one input symbol in its left-hand sides have already been studied in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010). Such compositions are implemented in the toolkit TIBURON. However, there are translation tasks in which the used XTOPs do not fulfill this requirement. Suppose that we simply want to compose the rules of Figure 2, The bottom rule does not satisfy the requirement that there is at most one input symbol in the left-hand side. We will demonstrate how to compose two linear and nondeleting XTOPs into a single XTOP, which might however no longer be linear or nondeleting. However, when the syntactic form of Figure 3: Linear normalized tree t E TE(Q(X)) [left] </context>
<context position="6235" citStr="Engelfriet, 1975" startWordPosition="1011" endWordPosition="1012">e t|2 is σ(α, q(x2)). the composed XTOP has only bounded overlapping cuts, post-processing will get rid of them and restore an ln-XTOP. In the remaining cases, in which unbounded overlapping is necessary or occurs in the syntactic form but would not be necessary, we will compute an XTOP. This is still an improvement on the existing methods that just fail. Since general XTOPs are implemented in TIBURON and the new composition covers (essentially) all cases currently possible, our new composition procedure could replace the existing one in TIBURON. Our approach to composition is the same as in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010): We simply parse the righthand sides of the XTOP M with the left-hand sides of the XTOP N. However, to facilitate this approach we have to adjust the XTOPs M and N in two pre-processing steps. In a first step we cut left-hand sides of rules of N into smaller pieces, which might introduce non-linearity and deletion into N. In certain cases, this can also introduce finite look-ahead (Engelfriet, 1977; Graehl et al., 2009). To compensate, we expand the rules of M slightly. Section 4 explains those preparations. Next, we compose the prepared XTOPs as usual </context>
<context position="15385" citStr="Engelfriet, 1975" startWordPosition="2929" endWordPosition="2930"> q1 z1 p σ α ← p2 y2 Figure 8: Incompatible left-hand sides of Example 3. Figure 9: Rules used in Example 5. N = (Q, A, F, IN, RN). Before we actually perform the composition, we will prepare M and N in two pre-processing steps. After these two steps, the composition is very simple. To avoid complications, we assume that (i) all rules of M are producing and (ii) all rules of N are consuming. For convenience, we also assume that the XTOPs M and N only use variables of the disjoint sets Y ⊆ X and Z ⊆ X, respectively. 4.1 Compatibility In the existing composition results for subclasses of XTOPs (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010) the XTOP N has at most one input symbol in its left-hand sides. This restriction allows us to match rule applications of N to positions in the right-hand sides of M. Namely, for each output symbol in a right-hand side of M, we can select a rule of N that can consume that output symbol. To achieve a similar decomposition strategy in our more general setup, we introduce a compatibility requirement on right-hand sides of M and left-hand sides of N. Roughly speaking, we require that the left-hand sides of N are small enough to completely process righthand s</context>
<context position="22137" citStr="Engelfriet, 1975" startWordPosition="4277" endWordPosition="4278">µ2 : z2 z4 z3 qVP qVA qNP → VP trans(t) = γ(trans(t1), ... , trans(tk)) trans(q00(z00)) = f hl2|v,q00,v0i(z) if z00 ∈ V 0 q00(z00) otherwise, 813 4.2 Local determinism After the first pre-processing step, we have the original linear and nondeleting XTOP M and an XTOPF N0 = (Q0, A, F, IN, R0N, cN) that is equivalent to N and compatible with M. However, in the first pre-processing step we might have introduced some non-linear (copying) rules in N0 (see rule (?) in Example 5), and it is known that “nondeterminism [in M] followed by copying [in N0]” is a feature that prevents composition to work (Engelfriet, 1975; Baker, 1979). However, our copying is very local and the copies are only used to project to different subtrees. Nevertheless, during those projection steps, we need to make sure that the processing in M proceeds deterministically. We immediately note that all but one copy are processed by states of the form hl, q, vi ∈ Ql. These states basically process (part of) the tree l and project (with state q) to the subtree at position v. It is guaranteed that each such subtree (indicated by v) is reached only once. Thus, the copying is “resolved” once the states of the form hl, q, vi are left. To ke</context>
</contexts>
<marker>Engelfriet, 1975</marker>
<rawString>Joost Engelfriet. 1975. Bottom-up and top-down tree transformations—A comparison. Mathematical Systems Theory, 9(3):198–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
</authors>
<title>Top-down tree transducers with regular look-ahead.</title>
<date>1977</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<pages>10--1</pages>
<contexts>
<context position="6677" citStr="Engelfriet, 1977" startWordPosition="1089" endWordPosition="1090">tially) all cases currently possible, our new composition procedure could replace the existing one in TIBURON. Our approach to composition is the same as in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010): We simply parse the righthand sides of the XTOP M with the left-hand sides of the XTOP N. However, to facilitate this approach we have to adjust the XTOPs M and N in two pre-processing steps. In a first step we cut left-hand sides of rules of N into smaller pieces, which might introduce non-linearity and deletion into N. In certain cases, this can also introduce finite look-ahead (Engelfriet, 1977; Graehl et al., 2009). To compensate, we expand the rules of M slightly. Section 4 explains those preparations. Next, we compose the prepared XTOPs as usual and obtain a single XTOP computing the composition of the transformations computed by M and N (see Section 5). Finally, we apply a post-processing step to expand rules to reobtain linearity and nondeletion. Clearly, this cannot be successful in all cases, but often removes the nonlinearity introduced in the pre-processing step. 2 Preliminaries Our trees have labels taken from an alphabet E of symbols, and in addition, leaves might be labe</context>
</contexts>
<marker>Engelfriet, 1977</marker>
<rawString>Joost Engelfriet. 1977. Top-down tree transducers with regular look-ahead. Mathematical Systems Theory, 10(1):289–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Jonathan May</author>
</authors>
<title>Training tree transducers.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="1221" citStr="Graehl et al., 2008" startWordPosition="167" endWordPosition="170">-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or nondeleting) XTOP. To illustrate the use of ln-XTOPs in machine translation, we consider the following English sentence together with a German re</context>
<context position="11135" citStr="Graehl et al., 2008" startWordPosition="2041" endWordPosition="2044">ransducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Formally, an extended top-down tree transducer with finite look-ahead (XTOPF) is a system M = (Q, E, A, I, R, c) where • Q is a finite set of states, • E and A are alphabets of input and output symbols, respectively, • I ⊆ Q is a set of initial states, • R is a finite set of (rewrite) rules of the form ` → r where ` ∈ Q(TE(X)) is linear and r ∈ To(Q(var(`))), and • c: R × X → TE(X) assigns a look-ahead restriction to each rule and variable such that c(ρ, x) is linear for each ρ ∈ R and x ∈ X. The XTOPF M is linear (respectively, nondeleting) if r is linear (respectively</context>
</contexts>
<marker>Graehl, Knight, May, 2008</marker>
<rawString>Jonathan Graehl, Kevin Knight, and Jonathan May. 2008. Training tree transducers. Computational Linguistics, 34(3):391–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Graehl</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Andreas Maletti</author>
</authors>
<title>The power of extended topdown tree transducers.</title>
<date>2009</date>
<journal>SIAM Journal on Computing,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="1243" citStr="Graehl et al., 2009" startWordPosition="171" endWordPosition="174"> that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or nondeleting) XTOP. To illustrate the use of ln-XTOPs in machine translation, we consider the following English sentence together with a German reference translation: *</context>
<context position="6699" citStr="Graehl et al., 2009" startWordPosition="1091" endWordPosition="1094">currently possible, our new composition procedure could replace the existing one in TIBURON. Our approach to composition is the same as in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010): We simply parse the righthand sides of the XTOP M with the left-hand sides of the XTOP N. However, to facilitate this approach we have to adjust the XTOPs M and N in two pre-processing steps. In a first step we cut left-hand sides of rules of N into smaller pieces, which might introduce non-linearity and deletion into N. In certain cases, this can also introduce finite look-ahead (Engelfriet, 1977; Graehl et al., 2009). To compensate, we expand the rules of M slightly. Section 4 explains those preparations. Next, we compose the prepared XTOPs as usual and obtain a single XTOP computing the composition of the transformations computed by M and N (see Section 5). Finally, we apply a post-processing step to expand rules to reobtain linearity and nondeletion. Clearly, this cannot be successful in all cases, but often removes the nonlinearity introduced in the pre-processing step. 2 Preliminaries Our trees have labels taken from an alphabet E of symbols, and in addition, leaves might be labeled by elements of the</context>
<context position="11157" citStr="Graehl et al., 2009" startWordPosition="2045" endWordPosition="2048">introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Formally, an extended top-down tree transducer with finite look-ahead (XTOPF) is a system M = (Q, E, A, I, R, c) where • Q is a finite set of states, • E and A are alphabets of input and output symbols, respectively, • I ⊆ Q is a set of initial states, • R is a finite set of (rewrite) rules of the form ` → r where ` ∈ Q(TE(X)) is linear and r ∈ To(Q(var(`))), and • c: R × X → TE(X) assigns a look-ahead restriction to each rule and variable such that c(ρ, x) is linear for each ρ ∈ R and x ∈ X. The XTOPF M is linear (respectively, nondeleting) if r is linear (respectively, var(r) = var(`)) for</context>
<context position="13046" citStr="Graehl et al., 2009" startWordPosition="2464" endWordPosition="2467"> ζ ∈ SF(M), we write ξ ⇒M ζ if there exist a position w ∈ posQ(ξ), a rule ρ = ` → r ∈ R, and a substitution θ: X → TES such that θ(x) is an instance of c(ρ, x) for every x ∈ X and ξ = ξ[`θ]w and ζ = ξ[rθ]w. If the applicable rules are restricted to a certain subset R0 ⊆ R, then we also write ξ ⇒R, ζ. Figure 5 illustrates a derivation step. The tree transformation computed by M is τM = {(t, u) ∈ TE × To |∃q ∈ I : q(t) ⇒∗M u} where ⇒∗M is the reflexive, transitive closure of ⇒M. It can easily be verified that the definition of τM is independent of the choice of E0 and A0. Moreover, it is known (Graehl et al., 2009) that each XTOPF can be transformed into an equivalent XTOP preserving both linearity and nondeletion. However, the notion of XTOPF will be convenient in our composition construction. A detailed exposition to XTOPs is presented by Arnold and Dauchet (1982) and Graehl et al. (2009). A linear and nondeleting XTOP M with rules R can easily be reversed to obtain a linear and nondeleting XTOP M−1 with rules R−1, which computes the inverse transformation τM−1 = τ−1M , by reversing all its rules. A (suitable) rule is reversed by exchanging the locations of the states. More precisely, given a rule q(l</context>
</contexts>
<marker>Graehl, Hopkins, Knight, Maletti, 2009</marker>
<rawString>Jonathan Graehl, Mark Hopkins, Kevin Knight, and Andreas Maletti. 2009. The power of extended topdown tree transducers. SIAM Journal on Computing, 39(2):410–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<title>An overview of probabilistic tree transducers for natural language processing.</title>
<date>2005</date>
<booktitle>In Proc. CICLing,</booktitle>
<volume>3406</volume>
<pages>1--24</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1075" citStr="Knight and Graehl, 2005" startWordPosition="144" endWordPosition="147">s demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or</context>
<context position="10746" citStr="Knight and Graehl, 2005" startWordPosition="1926" endWordPosition="1929">iciently (Robinson, 1965; Martelli and Montanari, 1982) and all mgus for t and t&apos; are equal up to a variable renaming. Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Figure 4 illustrates the unification. 3 The model The discussed model in this contribution is an extension of the classical top-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Formally, an extended top-down tree transducer with finite look-ahead (XTOPF) is a system M = (Q, E, A, I, R, c) where • Q is a finite set of states, • E and A are alphabets of input and </context>
</contexts>
<marker>Knight, Graehl, 2005</marker>
<rawString>Kevin Knight and Jonathan Graehl. 2005. An overview of probabilistic tree transducers for natural language processing. In Proc. CICLing, volume 3406 of LNCS, pages 1–24. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Capturing practical natural language transformations.</title>
<date>2007</date>
<journal>Machine Translation,</journal>
<volume>21</volume>
<issue>2</issue>
<contexts>
<context position="1200" citStr="Knight, 2007" startWordPosition="165" endWordPosition="166">n extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or nondeleting) XTOP. To illustrate the use of ln-XTOPs in machine translation, we consider the following English sentence toge</context>
<context position="11114" citStr="Knight, 2007" startWordPosition="2039" endWordPosition="2040">op-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Formally, an extended top-down tree transducer with finite look-ahead (XTOPF) is a system M = (Q, E, A, I, R, c) where • Q is a finite set of states, • E and A are alphabets of input and output symbols, respectively, • I ⊆ Q is a set of initial states, • R is a finite set of (rewrite) rules of the form ` → r where ` ∈ Q(TE(X)) is linear and r ∈ To(Q(var(`))), and • c: R × X → TE(X) assigns a look-ahead restriction to each rule and variable such that c(ρ, x) is linear for each ρ ∈ R and x ∈ X. The XTOPF M is linear (respectively, nondeleting) if r is</context>
</contexts>
<marker>Knight, 2007</marker>
<rawString>Kevin Knight. 2007. Capturing practical natural language transformations. Machine Translation, 21(2):121–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Lilin</author>
</authors>
<title>Une g´en´eralisation des transducteurs d’´etats finis d’arbres: les S-transducteurs. Th`ese 3`eme cycle, Universit´e de Lille.</title>
<date>1978</date>
<contexts>
<context position="928" citStr="Lilin, 1978" startWordPosition="123" endWordPosition="124">stuttgart.de RC PREL Abstract A composition procedure for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we</context>
</contexts>
<marker>Lilin, 1978</marker>
<rawString>Eric Lilin. 1978. Une g´en´eralisation des transducteurs d’´etats finis d’arbres: les S-transducteurs. Th`ese 3`eme cycle, Universit´e de Lille.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
<author>Heiko Vogler</author>
</authors>
<title>Compositions of top-down tree transducers with e-rules.</title>
<date>2010</date>
<booktitle>In Proc. FSMNLP,</booktitle>
<volume>6062</volume>
<pages>69--80</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4956" citStr="Maletti and Vogler, 2010" startWordPosition="790" endWordPosition="793">r when the right-hand sides of M and the left-hand sides of N are unboundedly overlapping. This can be purely syntactic (for a given ln-XTOP) or semantic (inherent in all ln-XTOPs for a given transformation). Despite the general impossibility, several strategies have been developed: (i) Extension of the model (Maletti, 2010; Maletti, 2011), (ii) online composition (May et al., 2010), and (iii) restriction of the model, which we follow. Compositions of subclasses in which the XTOP N has at most one input symbol in its left-hand sides have already been studied in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010). Such compositions are implemented in the toolkit TIBURON. However, there are translation tasks in which the used XTOPs do not fulfill this requirement. Suppose that we simply want to compose the rules of Figure 2, The bottom rule does not satisfy the requirement that there is at most one input symbol in the left-hand side. We will demonstrate how to compose two linear and nondeleting XTOPs into a single XTOP, which might however no longer be linear or nondeleting. However, when the syntactic form of Figure 3: Linear normalized tree t E TE(Q(X)) [left] and t[α]2 [right] withvar(t) = {x1,x2,x3</context>
<context position="6275" citStr="Maletti and Vogler, 2010" startWordPosition="1015" endWordPosition="1018">sed XTOP has only bounded overlapping cuts, post-processing will get rid of them and restore an ln-XTOP. In the remaining cases, in which unbounded overlapping is necessary or occurs in the syntactic form but would not be necessary, we will compute an XTOP. This is still an improvement on the existing methods that just fail. Since general XTOPs are implemented in TIBURON and the new composition covers (essentially) all cases currently possible, our new composition procedure could replace the existing one in TIBURON. Our approach to composition is the same as in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010): We simply parse the righthand sides of the XTOP M with the left-hand sides of the XTOP N. However, to facilitate this approach we have to adjust the XTOPs M and N in two pre-processing steps. In a first step we cut left-hand sides of rules of N into smaller pieces, which might introduce non-linearity and deletion into N. In certain cases, this can also introduce finite look-ahead (Engelfriet, 1977; Graehl et al., 2009). To compensate, we expand the rules of M slightly. Section 4 explains those preparations. Next, we compose the prepared XTOPs as usual and obtain a single XTOP computing the c</context>
<context position="15425" citStr="Maletti and Vogler, 2010" startWordPosition="2933" endWordPosition="2936">Incompatible left-hand sides of Example 3. Figure 9: Rules used in Example 5. N = (Q, A, F, IN, RN). Before we actually perform the composition, we will prepare M and N in two pre-processing steps. After these two steps, the composition is very simple. To avoid complications, we assume that (i) all rules of M are producing and (ii) all rules of N are consuming. For convenience, we also assume that the XTOPs M and N only use variables of the disjoint sets Y ⊆ X and Z ⊆ X, respectively. 4.1 Compatibility In the existing composition results for subclasses of XTOPs (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010) the XTOP N has at most one input symbol in its left-hand sides. This restriction allows us to match rule applications of N to positions in the right-hand sides of M. Namely, for each output symbol in a right-hand side of M, we can select a rule of N that can consume that output symbol. To achieve a similar decomposition strategy in our more general setup, we introduce a compatibility requirement on right-hand sides of M and left-hand sides of N. Roughly speaking, we require that the left-hand sides of N are small enough to completely process righthand sides of M. However, a comparison of left</context>
</contexts>
<marker>Maletti, Vogler, 2010</marker>
<rawString>Andreas Maletti and Heiko Vogler. 2010. Compositions of top-down tree transducers with e-rules. In Proc. FSMNLP, volume 6062 of LNAI, pages 69– 80. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
</authors>
<title>Why synchronous tree substitution grammars?</title>
<date>2010</date>
<booktitle>In Proc. HLT-NAACL,</booktitle>
<pages>876--884</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="968" citStr="Maletti, 2010" startWordPosition="129" endWordPosition="130">ition procedure for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs i</context>
<context position="4656" citStr="Maletti, 2010" startWordPosition="741" endWordPosition="742">de candidates that score low in one part but well in others (May et al., 2010). Because ln-XTOP is not closed under composition, the composition of M and N might be outside ln-XTOP. These cases have been identified by Arnold and Dauchet (1982) as infinitely “overlapping cuts”, which occur when the right-hand sides of M and the left-hand sides of N are unboundedly overlapping. This can be purely syntactic (for a given ln-XTOP) or semantic (inherent in all ln-XTOPs for a given transformation). Despite the general impossibility, several strategies have been developed: (i) Extension of the model (Maletti, 2010; Maletti, 2011), (ii) online composition (May et al., 2010), and (iii) restriction of the model, which we follow. Compositions of subclasses in which the XTOP N has at most one input symbol in its left-hand sides have already been studied in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010). Such compositions are implemented in the toolkit TIBURON. However, there are translation tasks in which the used XTOPs do not fulfill this requirement. Suppose that we simply want to compose the rules of Figure 2, The bottom rule does not satisfy the requirement that there is at most one input sym</context>
</contexts>
<marker>Maletti, 2010</marker>
<rawString>Andreas Maletti. 2010. Why synchronous tree substitution grammars? In Proc. HLT-NAACL, pages 876–884. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Maletti</author>
</authors>
<title>An alternative to synchronous tree substitution grammars.</title>
<date>2011</date>
<journal>Natural Language Engineering,</journal>
<volume>17</volume>
<issue>2</issue>
<contexts>
<context position="984" citStr="Maletti, 2011" startWordPosition="131" endWordPosition="132"> for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-</context>
<context position="4672" citStr="Maletti, 2011" startWordPosition="743" endWordPosition="744">hat score low in one part but well in others (May et al., 2010). Because ln-XTOP is not closed under composition, the composition of M and N might be outside ln-XTOP. These cases have been identified by Arnold and Dauchet (1982) as infinitely “overlapping cuts”, which occur when the right-hand sides of M and the left-hand sides of N are unboundedly overlapping. This can be purely syntactic (for a given ln-XTOP) or semantic (inherent in all ln-XTOPs for a given transformation). Despite the general impossibility, several strategies have been developed: (i) Extension of the model (Maletti, 2010; Maletti, 2011), (ii) online composition (May et al., 2010), and (iii) restriction of the model, which we follow. Compositions of subclasses in which the XTOP N has at most one input symbol in its left-hand sides have already been studied in (Engelfriet, 1975; Baker, 1979; Maletti and Vogler, 2010). Such compositions are implemented in the toolkit TIBURON. However, there are translation tasks in which the used XTOPs do not fulfill this requirement. Suppose that we simply want to compose the rules of Figure 2, The bottom rule does not satisfy the requirement that there is at most one input symbol in the left-</context>
</contexts>
<marker>Maletti, 2011</marker>
<rawString>Andreas Maletti. 2011. An alternative to synchronous tree substitution grammars. Natural Language Engineering, 17(2):221–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alberto Martelli</author>
<author>Ugo Montanari</author>
</authors>
<title>An efficient unification algorithm.</title>
<date>1982</date>
<journal>ACM Transactions on Programming Languages and Systems,</journal>
<volume>4</volume>
<issue>2</issue>
<pages>282</pages>
<contexts>
<context position="10178" citStr="Martelli and Montanari, 1982" startWordPosition="1823" endWordPosition="1826">) such that θθ&apos;(x) = θ(x)θ&apos; for every x ∈ X. Next, we define two notions of compatibility for trees. Let t, t&apos; ∈ TΣ(X) be two trees. If there exists a substitution θ such that t&apos; = tθ, then t&apos; is an instance of t. Note that this relation is not symmetric. A unifier θ for t and t&apos; is a substitution θ such that tθ = t&apos;θ. The unifier θ is a most general unifier (short: mgu) for t and t&apos; if for every unifier θ&apos;&apos; for t and t&apos; there exists a substitution θ&apos; such that θθ&apos; = θ&apos;&apos;. The set mgu(t, t&apos;) is the set of all mgus for t and t&apos;. Most general unifiers can be computed efficiently (Robinson, 1965; Martelli and Montanari, 1982) and all mgus for t and t&apos; are equal up to a variable renaming. Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Figure 4 illustrates the unification. 3 The model The discussed model in this contribution is an extension of the classical top-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2</context>
</contexts>
<marker>Martelli, Montanari, 1982</marker>
<rawString>Alberto Martelli and Ugo Montanari. 1982. An efficient unification algorithm. ACM Transactions on Programming Languages and Systems, 4(2):258– 282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan May</author>
<author>Kevin Knight</author>
</authors>
<title>Tiburon: A weighted tree automata toolkit.</title>
<date>2006</date>
<booktitle>In Proc. CIAA,</booktitle>
<volume>4094</volume>
<pages>102--113</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1304" citStr="May and Knight, 2006" startWordPosition="181" endWordPosition="184">cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or nondeleting) XTOP. To illustrate the use of ln-XTOPs in machine translation, we consider the following English sentence together with a German reference translation: * All authors were financially supported by the EMMY NOETHER p</context>
</contexts>
<marker>May, Knight, 2006</marker>
<rawString>Jonathan May and Kevin Knight. 2006. Tiburon: A weighted tree automata toolkit. In Proc. CIAA, volume 4094 of LNCS, pages 102–113. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan May</author>
<author>Kevin Knight</author>
<author>Heiko Vogler</author>
</authors>
<title>Efficient inference through cascades of weighted tree transducers.</title>
<date>2010</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>1058--1066</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3795" citStr="May et al., 2010" startWordPosition="592" endWordPosition="595">the English verbal complex. In this way we model the word drop by an lnXTOP M and reordering by an ln-XTOP N. The syntactic properties of linearity and nondeletion yield nice algorithmic properties, and the modC NP VP H C NP VP VAUX VPART NP 808 Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 808–817, Avignon, France, April 23 - 27 2012. c�2012 Association for Computational Linguistics Figure 2: XTOP rules for the operations of Figure 1. ular approach is desirable for better design and parametrization of the translation model (May et al., 2010). Composition allows us to recombine those parts into one device modeling the whole translation. In particular, it gives all parts the chance to vote at the same time. This is especially important if pruning is used because it might otherwise exclude candidates that score low in one part but well in others (May et al., 2010). Because ln-XTOP is not closed under composition, the composition of M and N might be outside ln-XTOP. These cases have been identified by Arnold and Dauchet (1982) as infinitely “overlapping cuts”, which occur when the right-hand sides of M and the left-hand sides of N ar</context>
</contexts>
<marker>May, Knight, Vogler, 2010</marker>
<rawString>Jonathan May, Kevin Knight, and Heiko Vogler. 2010. Efficient inference through cascades of weighted tree transducers. In Proc. ACL, pages 1058–1066. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan May</author>
</authors>
<title>Weighted Tree Automata and Transducers for Syntactic Natural Language Processing.</title>
<date>2010</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Southern</institution>
<location>California, Los Angeles.</location>
<contexts>
<context position="1316" citStr="May, 2010" startWordPosition="185" endWordPosition="186"> can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transformations that is not closed under composition, so we cannot compose two arbitrary ln-XTOPs into a single ln-XTOP. However, we will show that ln-XTOPs can be composed into a (not necessarily linear or nondeleting) XTOP. To illustrate the use of ln-XTOPs in machine translation, we consider the following English sentence together with a German reference translation: * All authors were financially supported by the EMMY NOETHER project MA/49</context>
</contexts>
<marker>May, 2010</marker>
<rawString>Jonathan May. 2010. Weighted Tree Automata and Transducers for Syntactic Natural Language Processing. Ph.D. thesis, University of Southern California, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Alan Robinson</author>
</authors>
<title>A machine-oriented logic based on the resolution principle.</title>
<date>1965</date>
<journal>Journal of the ACM,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="10147" citStr="Robinson, 1965" startWordPosition="1821" endWordPosition="1822">on θθ&apos;: X → TΣ(X) such that θθ&apos;(x) = θ(x)θ&apos; for every x ∈ X. Next, we define two notions of compatibility for trees. Let t, t&apos; ∈ TΣ(X) be two trees. If there exists a substitution θ such that t&apos; = tθ, then t&apos; is an instance of t. Note that this relation is not symmetric. A unifier θ for t and t&apos; is a substitution θ such that tθ = t&apos;θ. The unifier θ is a most general unifier (short: mgu) for t and t&apos; if for every unifier θ&apos;&apos; for t and t&apos; there exists a substitution θ&apos; such that θθ&apos; = θ&apos;&apos;. The set mgu(t, t&apos;) is the set of all mgus for t and t&apos;. Most general unifiers can be computed efficiently (Robinson, 1965; Martelli and Montanari, 1982) and all mgus for t and t&apos; are equal up to a variable renaming. Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Figure 4 illustrates the unification. 3 The model The discussed model in this contribution is an extension of the classical top-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005;</context>
</contexts>
<marker>Robinson, 1965</marker>
<rawString>John Alan Robinson. 1965. A machine-oriented logic based on the resolution principle. Journal of the ACM, 12(1):23–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Rounds</author>
</authors>
<title>Mappings and grammars on trees.</title>
<date>1970</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<volume>4</volume>
<issue>3</issue>
<pages>287</pages>
<contexts>
<context position="10564" citStr="Rounds (1970)" startWordPosition="1900" endWordPosition="1901">ifier θ&apos;&apos; for t and t&apos; there exists a substitution θ&apos; such that θθ&apos; = θ&apos;&apos;. The set mgu(t, t&apos;) is the set of all mgus for t and t&apos;. Most general unifiers can be computed efficiently (Robinson, 1965; Martelli and Montanari, 1982) and all mgus for t and t&apos; are equal up to a variable renaming. Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Figure 4 illustrates the unification. 3 The model The discussed model in this contribution is an extension of the classical top-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Forma</context>
</contexts>
<marker>Rounds, 1970</marker>
<rawString>William C. Rounds. 1970. Mappings and grammars on trees. Mathematical Systems Theory, 4(3):257– 287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>Synchronous grammars as tree transducers.</title>
<date>2004</date>
<booktitle>In Proc. TAG+7,</booktitle>
<pages>88--95</pages>
<contexts>
<context position="879" citStr="Shieber, 2004" startWordPosition="116" endWordPosition="117">nguage Processing {braunefe,daniel,maletti}@ims.uni-stuttgart.de RC PREL Abstract A composition procedure for linear and nondeleting extended top-down tree transducers is presented. It is demonstrated that the new procedure is more widely applicable than the existing methods. In general, the result of the composition is an extended top-down tree transducer that is no longer linear or nondeleting, but in a number of cases these properties can easily be recovered by a post-processing step. 1 Introduction Tree-based translation models such as synchronous tree substitution grammars (Eisner, 2003; Shieber, 2004) or multi bottom-up tree transducers (Lilin, 1978; Engelfriet et al., 2009; Maletti, 2010; Maletti, 2011) are used for several aspects of syntax-based machine translation (Knight and Graehl, 2005). Here we consider the extended top-down tree transducer (XTOP), which was studied in (Arnold and Dauchet, 1982; Knight, 2007; Graehl et al., 2008; Graehl et al., 2009) and implemented in the toolkit TIBURON (May and Knight, 2006; May, 2010). Specifically, we investigate compositions of linear and nondeleting XTOPs (ln-XTOP). Arnold and Dauchet (1982) showed that ln-XTOPs compute a class of transforma</context>
</contexts>
<marker>Shieber, 2004</marker>
<rawString>Stuart M. Shieber. 2004. Synchronous grammars as tree transducers. In Proc. TAG+7, pages 88–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Thatcher</author>
</authors>
<title>Generalized sequential machine maps.</title>
<date>1970</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>4</volume>
<issue>4</issue>
<contexts>
<context position="10584" citStr="Thatcher (1970)" startWordPosition="1903" endWordPosition="1904">d t&apos; there exists a substitution θ&apos; such that θθ&apos; = θ&apos;&apos;. The set mgu(t, t&apos;) is the set of all mgus for t and t&apos;. Most general unifiers can be computed efficiently (Robinson, 1965; Martelli and Montanari, 1982) and all mgus for t and t&apos; are equal up to a variable renaming. Example 1. Let t = σ(x1, γ(δ(β, β, x2))) and t&apos; = σ(α, x3). Then mgu(t, t&apos;) contains θ such that θ(x1) = α and θ(x3) = γ(δ(β, β, x2)). Figure 4 illustrates the unification. 3 The model The discussed model in this contribution is an extension of the classical top-down tree transducer, which was introduced by Rounds (1970) and Thatcher (1970). The extended top-down tree transducer with finite look-ahead or just XTOPF and its variations were studied in (Arnold and Dauchet, 1982; Knight and Graehl, 2005; σ x1 γ δ β β x2 σ α γ δ β β x2 θ 7→ σ θ H α x3 t qS S t S’ ⇒ qNP VP qV qNP t1 t2 t1 t1 t2 t3 qS S x1 VP x2 x3 x2 x1 x1 S’ → qV qNP qNP 810 RC → pNP y1 p C y1 y2 qS S x1 VP x2 x3 S’ qS S’ x2 x1 x3 S qV qNP → → qV x2 x1 qNP x3 x2 qNP x1 x3 VP qNP PREL that C pVP y2 Figure 6: Rule [left] and reversed rule [right]. Figure 7: Top rule of Figure 2 reversed. Knight, 2007; Graehl et al., 2008; Graehl et al., 2009). Formally, an extended top</context>
</contexts>
<marker>Thatcher, 1970</marker>
<rawString>James W. Thatcher. 1970. Generalized sequential machine maps. Journal of Computer and System Sciences, 4(4):339–367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntaxbased statistical translation model.</title>
<date>2001</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2390" citStr="Yamada and Knight, 2001" startWordPosition="342" endWordPosition="345">he following English sentence together with a German reference translation: * All authors were financially supported by the EMMY NOETHER project MA/4959/ 1-1 of the German Research Foundation (DFG). C that NP VP C �� NP VP VAUX NP VPART Figure 1: Word drop [top] and reordering [bottom]. The newswire reported yesterday that the Serbs have completed the negotiations. Gestern [Yesterday] berichtete [reported] die [the] Nachrichtenagentur [newswire] die [the] Serben [Serbs] h¨atten [would have] die [the] Verhandlungen [negotiations] beendet [completed]. The relation between them can be described (Yamada and Knight, 2001) by three operations: drop of the relative pronoun, movement of the participle to end of the clause, and word-to-word translation. Figure 1 shows the first two operations, and Figure 2 shows ln-XTOP rules performing them. Let us now informally describe the execution of an ln-XTOP on the top rule p of Figure 2. In general, ln-XTOPs process an input tree from the root towards the leaves using a set of rules and states. The state p in the lefthand side of p controls the particular operation of Figure 1 [top]. Once the operation has been performed, control is passed to states pNP and pVP, which us</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntaxbased statistical translation model. In Proc. ACL, pages 523–530. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>