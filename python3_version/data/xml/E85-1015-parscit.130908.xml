<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<note confidence="0.655275333333333">
LANGUAGE-BASED ENVIRONMENT FOR NATURAL LANGUAGE PARSING
Lehtola, A., Jappinen, H., Nelimarkka, E.
Sitra Foundation (*) and
</note>
<affiliation confidence="0.749209">
Helsinki University of Technology
Helsinki, Finland
</affiliation>
<sectionHeader confidence="0.553709" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999800529411765">
This paper introduces a special
programming environment for the definition
of grammars and for the implementation of
corresponding parsers. In natural
language processing systems it is
advantageous to have linguistic knowledge
and processing mechanisms separated. Our
environment accepts grammars consisting of
binary dependency relations and
grammatical functions. Well-formed
expressions of functions and relations
provide constituent surroundings for
syntactic categories in the form of
two-way automata. These relations,
functions, and automata are described in a
special definition language.
In focusing on high level descriptions a
linguist may ignore computational details
of the parsing process. He writes the
grammar into a DPL-description and a
compiler translates it into efficient
LISP-code. The environment has also a
tracing facility for the parsing process,
grammar-sensitive lexical maintenance
programs, and routines for the interactive
graphic display of parse trees and grammar
definitions. Translator routines are also
available for the transport of compiled
code between various LISP-dialects. The
environment itself exists currently in
INTERLISP and FRANZLISP. This paper
focuses on knowledge engineering issues
and does not enter linguistic
argumentation.
</bodyText>
<sectionHeader confidence="0.995241" genericHeader="introduction">
INTRODUCTION
</sectionHeader>
<bodyText confidence="0.965958709677419">
Our objective has been to build a parser
for Finnish to work as a practical tool in
real production applications. In the
beginning of our work we were faced with
two major problems. First, so far there
was no formal description of the Finnish
grammar. Second difficulty was that
Finnish differs by its structure greatly
from the Indoeuropean languages. Finnish
has relatively free word order and
syntactico-semantic knowledge in a
sentence is often expressed in the
inflections of the words. Therefore
existing parsing methods for Indoeuropean
languages (eg. ATN, DCG, LFG etc.) did
not seem to grasp the idiosyncracies of
Finnish.
The parser system we have developed is
based on functional dependency. Grammar
is specified by a family of two-way finite
automata and by dependency function and
relation definitions. Each automaton
expresses the valid dependency context of
one constituent type. In abstract sense
the working storage of the parser consists
of two constituent stacks and of a
register which holds the current
constituent (Figure 1).
(*) SITRA Foundation
P.O. Box 329, SF-00121 Helsinki,
Finland
</bodyText>
<figure confidence="0.717111777777778">
The left
constituent
stack
The right
constituent
stock
The register of
the current
constituent
</figure>
<figureCaption confidence="0.8396845">
Figure 1. The working storage
of DPL-parsers
</figureCaption>
<figure confidence="0.969351666666667">
LI
L2
L3
R I
R2
R3
</figure>
<page confidence="0.7790805">
98
•
</page>
<figure confidence="0.969573035087719">
FIND REGENT
ON LEFT
BUILD PHRASE
ON RIGHT
*Phrase
Subject
•Phrase Sub ect
C •■ -Nominal
empty left-
hand side
•Phrose
Rduerbial
•Phrase Object
•Phrase
Rduerbial
Main-
Sent?
IJ SO
-Phrase
end of input
•Phrose Subject
•Phrose
Rduerbiol
&apos;Phrase
Adverbial
•Phrose Rduerbial
BUILD PHRASE
ON RIGHT
C C VERBS
START
•Phrase
•Phrose Subject
(
•Phrase Ob &apos;ect
•Phrose Ob edt
-Phrase
3
+Phrase
C &apos;Nominal
?Uflnal
&apos;Nominal
FIND REGENT
ON RIGHT
•Phrase
Rduerbial
&apos;Phrase Ob ect
Notations:
On the left is a state transition
the state node ?X (priority&apos; with priority, conditions for
L the dependent candidate (if not
conds function)
of the automaton /
The question mark otherwised stated) and
indicates the direction
On the left is
connection function indicated.
Double circles are used
</figure>
<figureCaption confidence="0.9479942">
to denote entrees and
eHits of an automaton.
Inside is eHpressed the
manner of operation.
Figure 2. A two—way automaton for Finnish verbs
</figureCaption>
<bodyText confidence="0.987363565217392">
•Phrase Rduerbial
The two stacks hold the right and left
contexts of the current constituent. The
parsing process is always directed by the
expectations of the current constituent.
Dynamic local control is realized by
permitting the automata to activate one
another. The basic decision for the
automaton associated with the current
constituent is to accept or reject a
neighbor via a valid syntactico-semantic
subordinate relation. Acceptance
subordinates the neighbor, and it
disappears from the stack. The structure
an input sentence receives is an annotated
tree of such binary relations.
An automaton for verbs is described in
Figure 2. When a verb becomes the current
constituent for the first time it will
enter the automaton through the START
node. The automaton expects to find a
dependent from the left (?V). If the left
neighbor has the constituent feature
+Phrase, it will be tested first for
Subject and then for Object. When a
function test succeeds, the neighbor will
be subordinated and the verb advances to
the state indicated by arcs. The double
circle states denote entry and exit points
of the automaton.
If completed constituents do not exist as
neighbors, an automaton may defer
decision. In the Figure 2 states labelled
&amp;quot;BUILD PHRASE ON RIGHT&amp;quot; and &amp;quot;FIND REGENT
ON RIGHT&amp;quot; push the verb to the left stack
and pop the right stack for the current
constituent. When the verb is activated
later on, the control flow will continue
from the state expressed in the
deactivation command.
There are two distinct search strategies
involved. If a single parse is
sufficient, the graphs (i.e. the
automata) are searched depth first
following the priority numbering. A full
search is also possible.
</bodyText>
<page confidence="0.992761">
99
</page>
<bodyText confidence="0.993735476923077">
The functions, relations and automata are
expressed in a special conditional
expression formalism DPL (for Dependency
Parser Language). We believe that DPL
might find applications in other
inflectional languages as well.
DPL-DESCRIPTIONS
The main object in DPL is a constituent.
A grammar specification opens with the
structural descriptions of constituents
and the allowed property names and
property values. User may specify simple
properties, features or categories. The
structures of the lexical entries are also
defined at the beginning. The syntax of
these declarations can be seen in Figure
3.
All properties of constituents may be
referred in a uniform manner using their
values straight. The system automatically
takes into account the computational
details associated to property types. For
example, the system is automatically tuned
to notice the inheritance of properties in
their hierarchies. Extensive support to
multidimensional analysis has been one of
the central objectives in the design of
the DPL-formalism. Patterning can be done
in multiple dimensions and the property
set associated to constituents can easily
be extended.
An example of a constituent structure and
its property definitions is given in
Figure 4. The description states first
that each constituent contains Function,
Role, ConstFeat, Prop0fLexeme and
MorphChar. The next two following
definitions further specify ConstFeat and
Prop0fLexeme. In the last part the
definition of a category tree SemCat is
given. This tree has sets of property
values associated with nodes. The
DPL-system automatically takes care of
their inheritances. Thus for a
constituent that belongs to the semantic
category Human the system automatically
associates feature values +Hum, +Anim,
+countable, and +Concr.
The binary grammatical functions and
relations are defined using the syntax in
Figure 5. A DPL-function returns as its
value the binary construct built from the
current constituent (C) and its dependent
candidate (p), Or it returns NIL.
DPL-relations return as their values the
pairs of C and D constituents that have
passed the associated predicate filter.
By choosing operators a user may vary a
predication between simple equality (=)
and equality with ambiguity elimination
(.:.). Operators := and :- denote
replacement and insertion, respectively.
In predicate expressions angle brackets
signal the scope of an implicit
OR-operator and parentheses that of an
</bodyText>
<table confidence="0.971324666666667">
&lt;constituent structure&gt; ::= ( CONSTITUENT: &lt;list of properties&gt;.. )
&lt;subtree of constituent&gt;::= ( SUBTREE: &lt;glue node&gt;
&lt;list of properties&gt; ) 1
( LEXICON-ENTRY: &lt;glue node&gt;
&lt;list of properties&gt; )
&lt;list of properties&gt; ::= ( &lt;list of properties&gt;.. )
( &lt;property name&gt;.. )
&lt;property name&gt; &lt;type name&gt; : &lt;glue node name&gt;
&lt;type name&gt; ::= &lt;unique lisp atom&gt;
&lt;glue node name&gt; ::= &lt;unique lisp atom&gt;
&lt;glue node&gt; ::= &lt;glue node name in upper level&gt;
&lt;property declaration&gt; ::= ( PROPERTY: &lt;type name&gt; &lt;possible values&gt; )
( FEATURE: &lt;type name&gt; &lt;possible values&gt; ) 1
( CATEGORY: &lt;type name&gt; &lt; &lt;node definition&gt;.. &gt; )
&lt;possible values&gt; &lt; &lt;default value&gt; &lt;unique lisp atom&gt;.. &gt;
&lt;default value &gt; ::= NoDefault : &lt;unique lisp atom&gt;
&lt;node definition&gt; ::= ( &lt;node name&gt; &lt;feature set&gt; &lt;father node&gt; )
&lt;node name&gt; ::= &lt;unique lisp atom&gt;
&lt;feature set&gt; ::= ( &lt;feature value&gt; ) 1 &lt;empty&gt;
&lt;father node&gt; / &lt;name of an already defined node&gt; 1 &lt;empty&gt;
&lt;empty&gt;
</table>
<figureCaption confidence="0.9861675">
Figure 3. The syntax of constituent structure
and property definitions
</figureCaption>
<table confidence="0.982155842105263">
100
(CONSTITUENT: (Function Role ConstFeat Prop0fLexeme Morphchar))
(LEXICON-ENTRY: Prop0fLexeme
( (SyntCat SyntFeat)
(SemCat SemFeat)
(FrameCat LexFrame)
AKO ))
(SUBTREE: MorphChar
( Polar Voice Modal Tense Comparison
Number Case PersonN PersonP Clitl Clit2))
(CATEGORY: SemCat
&lt; ( Entity )
( Concrete ( +Concr ) / Entity )
( Animate ( +Anim +Countable ) / Concrete )
( Human ( +Hum ) / Animate )
( Animals / Animate )
( NonAnim / Concrete )
( Matter ( -Countable ) / NonAnim )
( Thing ( +Countable ) / NonAnim ) &gt;
</table>
<figureCaption confidence="0.9965255">
Figure 4. An example of a constituent structure specification
and the definition of an category tree
</figureCaption>
<bodyText confidence="0.99947332">
implicit AND-operator. An arrow triggers
defaults on: the elements of expressions
to the right of an arrow are in the
OR-relation and those to the left of it
are in the AND-relation. Two kinds of
arrows are in use. A simple arrow (-&gt;)
performs all operations on the right and a
double arrow (=&gt;) terminates the execution
at the first successful operation.
In Figure 6 is an example of how one may
define Subject. If the relation RecSubj
holds between the regent and the dependent
candidate the latter will be labelled
Subject and subordinated to the former.
The relational expression RecSubj defines
the property patterns the constituents
should match.
A grammar definition ends with the context
specifications of constituents expressed
as two-way automata. The automata are
described using the notation shown in
somewhat simplified form in Figure 7. An
automaton can refer up to three
constituents to the right or left using
indexed names: Ll, L2, L3, R1, R2 or R3.
</bodyText>
<table confidence="0.9244628">
&lt;function&gt;
&lt;relation&gt;
&lt;operation expr&gt;
&lt;predicate expr&gt;
::= ( FUNCTION: &lt;function name&gt; &lt;operation expr&gt; )
::= ( RELATION: &lt;relation name&gt; &lt;operation expr&gt; )
::= ( &lt;predicate expr&gt;.. &lt;impl&gt; &lt;operation expri.. )
&lt;predicate expr&gt;
&lt;relation name&gt; 1
( DEL &lt;constituent label&gt; )
&lt; &lt;predicate expr&gt; &gt;
( &lt;predicate expr&gt; )
( &lt;constituent pointer&gt; &lt;operator&gt; &lt;value expr&gt;)
-&gt; =&gt;
C 1 D
&lt; • &lt;value expr&gt;.. &gt;
( &lt;value expr&gt;.. )
&lt;value of some property&gt; 1
&apos;&lt;lexeme&gt;
( &lt;property name&gt; &lt;constituent label&gt; )
</table>
<figure confidence="0.9928225">
&lt;impl&gt;
&lt;constituent label&gt;::=
&lt;operator&gt; 3 =
&lt;value expr&gt;
</figure>
<figureCaption confidence="0.999924">
Figure 5. The syntax of DPL-functions and DPL-relations
</figureCaption>
<page confidence="0.874952">
101
</page>
<table confidence="0.997518074074074">
(FUNCTION: Subject
(RELATION: ( RecSubj -&gt; (D := Subject))
RecSubj
((C = Act &lt; Ind Cond Pot leper &gt;) (D = -Sentence +Nominal)
-&gt; ((I) = Nom)
-&gt; (D = PersPron (PersonP C) (PersonN C))
((I) = Noun) (C = 3P) -&gt; ((C = S) (D = SG))
((C = P) (D = PL))))
((D = Part) (C = S 3P)
-&gt; ((C = &apos;OLLA)
=&gt; (C :- +Existence))
((C = -Transitive +Existence))))
Figure 6. A realisation of Subject
&lt;state in autom.&gt;::= ( STATE: &lt;state name&gt; &lt;direction&gt; &lt;state
&lt;direction&gt; LEFT : RIGHT
&lt;state expr&gt; ( &lt;lhs of s. expr&gt; &lt;impl&gt; &lt;state expr&gt;..
&lt;lhs of s. expr&gt; ::= ( &lt;lhs of s. expr&gt; &lt;impl&gt; &lt;state change&gt;
&lt;state change&gt; &lt;function name&gt; I &lt;predicate expr&gt;..
&lt;state change&gt; ::= ( C := &lt;name of next state&gt; )
&lt;sstate ch.&gt; ( FIND-REG-ON &lt;direction&gt; &lt;sstate ch.
&lt;work sp. manip.&gt;::= ( BUILD-PHRASE-ON &lt;direction&gt; &lt;sstate ch.
( PARSED )
&lt;work sp. manip.&gt; &lt;state change&gt;
( C := &lt;name of return state&gt; )
( DEL &lt;constituent label&gt; ) I
( TRANSPOSE &lt;constituent label&gt;
&lt;constituent label&gt; )
</table>
<figureCaption confidence="0.997333">
Figure 7. Simplified syntax of state specifications
</figureCaption>
<figure confidence="0.876197285714286">
•
(STATE: V? RIGHT
((I) = -I-Phrase) -&gt; (Subject -&gt; (C := VS?))
(Object -&gt; (C := V0?))
(Adverbial -&gt; (C := V?))
(T =&gt; (C := ?Winal)))
(U) = -Phrase) -&gt; (BUILD-PHRASE-ON RIGHT (C := V?)))
</figure>
<figureCaption confidence="0.999793">
Figure 8. The expression of V? in Figure 2.
</figureCaption>
<page confidence="0.996962">
102
</page>
<bodyText confidence="0.995480054545455">
The direction of a state (see Figure 2.)
selects the dependent candidate normally
as Ll or Rl. A switch of state takes
place by an assignment in the same way as
linguistic properties are assigned. As an
example the node V? of Figure 2 is
defined formally in Figure 8.
More linguistically oriented
argumentation of the DPL-formalism appears
elsewhere (Nelimarkka, 1984a, and
Nelimarkka, 1984b).
THE ARCHITECTURE OF THE DPL-ENVIRONMENT
The architecture of the DPL-environment is
described schematically in Figure 9. The
main parts are highlighted by heavy lines.
Single arrows represent data transfer;
double arrows indicate the production of
data structures. All modules have been
implemented in LISP. The realisations do
not rely on specifics of underlying
LISP-environments.
The DPL-compiler
A compilation results in executable code
of a parser. The compiler produces highly
optimized code (Lehtola, 1984).
Internally data structures are only partly
dynamic for the reason of fast information
fetch. Ambiguities are expressed locally
to minimize redundant search. The
principle of structure sharing is followed
whenever new data structures are built.
In the manipulation of constituent
structures there exists a special service
routine for each combination of property
and predication types. These routines
take special care of time and memory
consumption. For instance with regard
replacements and insertions the copying
includes physically only the path from the
root of the list structure to the changed
sublist. The logically shared parts will
,be shared also physically. This
stipulation minimizes memory usage.
In the state transition network level the
search is done depth first. To handle
ambiguities DPL-functions and -relations
process all alternative interpretations in
parallel. In fact the alternatives are
stored in the stacks and in the C-register
as trees of alternants.
In the first version of the DPL-compiler
the generation rules were intermixed with
the compiler code. The maintenance of the
compiler grew harder when we experimented
with new computational features. We
</bodyText>
<figure confidence="0.57406">
DPL-description
</figure>
<figureCaption confidence="0.999888">
Figure 9. The architecture of the DPL-environment
</figureCaption>
<figure confidence="0.998627225806452">
compilation
rules for
DPL
metacompiler
,(rule interpreter)
optimizer
optimizing
translator
transformation
rules:
Intert...) Franzt.
transformation
rules:
Men...Kamm:Ha.
lexicon
maintenance
analyzed
input
words
parser
lexicon
parser
parsing
results
information
extraction system
with
graphic output
tmomme)
tracing
facility
</figure>
<page confidence="0.998101">
103
</page>
<bodyText confidence="0.991912387096774">
therefore started to develop a
metacompiler in which compilation is
defined by rules. At moment we are
testing it and soon it will be in everyday
use. The amount of LISP-code has greatly
reduced with the rule based approach, and
we are now planning to install the
DPL-environment into IBM PC.
Our parsers were aimed to be practical
tools in real production applications. It
was hence important to make the produced
programs transferable. As of now we have
a rule-based translator which converts
parsers between LISP dialects. The
translator accepts currently INTERLISP,
FranzLISP and Common Lisp.
Lexicon and its Maintenance
The environment has a special maintenance
program for lexicons. The program uses
video graphics to ease updating and it
performs various checks to guarantee the
consistency of the lexical entries. it
also co-operates with the information
extraction system to help the user in the
selection of properties.
The Tracing Facility
The tracing facility is a convenient tool
for grammar debugging. For example, in
Figure 10 appears the trace of the parsing
of the sentence &amp;quot;Poikani tuli illalla
kentalta heittamasta kiekkoa.&amp;quot; (= &amp;quot;My son
</bodyText>
<figure confidence="0.837655875">
_(T POIKANI TULI ILLALLA KENTALTA HEITTAMASTA KIEKKOA .)
383 conses
.03 seconds
0.0 seconds, garbage collection time
PARSED
_PATH()
=&gt; (POIKA) (TULLA) (ILTA) (KENTTA) (HEITTAA) (KIEKKO) 7N
(POIKA) &lt;= (TULLA) (ILTA) (KENTTA) (HEITTAA) (KIEKKO) N?
</figure>
<listItem confidence="0.951760068965517">
=&gt; (POIKA) (TULLA) (ILTA) (KENTTA) (HEITTAA) (KIEKKO) ?NFinal
(**) (POI(A) (TULLA) (ILTA) (KENTTA) (HEITTAA) (KIEKKO) NIL
(POIKA) =&gt; (TULLA) (ILTA) (KENTTA) (HEITTAA) (KIEKKO) ?V.
=&gt; ((POIKA) TULLA) (ILTA) (KENTTA) (HEITTAA) (KIEKKO) ?VS
((POIKA) TULLA) &lt;= (ILTA) (KENTTA) (HEITTAA) (KIEKKO) VS?
,((POIKA) TULLA) =&gt; (ILTA) (KENTTA) (HEITTAA) (KIEKKO) ?N
((POIKA) TULLA) (ILTA) &lt;= (KENTTA) (HEITTAA) (KIEKKO) N?
((POIKA) TULLA) =&gt; .(ILTA) (KENTTA) (HEITTAA) (KIEKKO) ?NFinal
((POIKA) TULLA) &lt;= (ILTA) (KENTTA) (HEITTAA) (KIEKKO) VS?
((POIKA) TULLA (ILTA)) &lt;= (KENTTA) (HEITTAA) (KIEKKO) VS?
((POIKA) TULLA (ILTA)) =&gt; (KENTT)) (HEITTAA) (KIEKKO) ?N
((POIKA) TULLA (ILTA)) (KENTTA) &lt;= (HEITTAA) (KIEKKO) N?
((POIKA) TULLA (ILTA)) =&gt; (KENTTA) (HEITTAA) (KIEKKO) ?NFinal
((POIKA) TULLA (ILTA)) &lt;= (KENTTA) (HEITTAA) (KIEKKO) VS?
((POIKA) TULLA (ILTA) (KENTTA)) &lt;= (HEITTAA) (KIEKKO) VS?
((POIKA) TULLA (ILTA) (KENTTA)) =&gt; (HEITTAA) (KIEKKO) ?V
((POIKA) TULLA (ILTA) (KENTTA)) (HEITTAA) &lt;= (KIEKKO) V?
((POIKA) TULLA (ILTA) (KENTTA)) (HEITTAA) =&gt; (KIEKKO) ?N
((POIKA) TULLA (ILTA) (KENTTA)) (HEITTAA) (KIEKKO) &lt;= N?
((POIKA) TULLA (ILTA) (KENTTA)) (HEITTAA) =&gt; (KIEKKO) ?NFinal
((POIKA) TULLA (ILTA) (KENTTA)) (HEITTAA) &lt;= (KIEKKO) V?
((POIKA) TULLA (ILTA) (KENTTA)) (HEITTAA (KIEKKO)) &lt;= yo?
((POIKA) TULLA (ILTA) (KENTTA)) =&gt; (HEITTAA (KIEKKO)) ?VFinal
((POIKA) TULLA (ILIA) (KENTTA)) (= (HEITTAA (KIEKKO)) VS?
((POIKA) TULLA (ILTA) (KENTTA) (HEITTAA (KIEKKO))) &lt;= VS?
=&gt; ((POIKA) TULLA (ILTA) (KENTTA) (HEITTAA (KIEKKO))) ?VFinal
((POIKA) TULLA (ILTA) (KENTTA) (HEITTAA (KIEKKO))) &lt;= MainSent?
((POIKA) TULLA (ILIA) (KENTTA) (HEITTAA (KIEKKO))) &lt;= MainSent? OK
DONE
</listItem>
<figureCaption confidence="0.974138">
Figure 10. A trace of parsing process
</figureCaption>
<page confidence="0.997142">
104
</page>
<bodyText confidence="0.996899567567567">
came back in the evening from the stadium
where he had been throwing the discus.&amp;quot;).
Each row represents a state of the parser
before the control enters the state
mentioned on the right-hand column. The
thus-far found constituents are shown by
the parenthesis. An arrow head points
from a dependent candidate (one which is
subjected to dependency tests) towards the
current constituent.
The tracing facility gives also the
consumed CPU-time and two quality
indicators: search efficiency and
connection efficiency. Search efficiency
is 100%, if no useless state transitions
took place in the search. This figure is
meaningless when the system is
parameterized to full search because then
all transitions are tried.
Connection efficiency is the ratio of the
number of connections remaining in a
result to the total number of connections
attempted for it during the search. We
are currently developing other measuring
tools to extract statistical information,
eg. about the frequency distribution of
different constructs. Under development
is also automatic book-keeping of all
sentence input to the system. These will
be divided into two groups: parsed and
not parsed. The first group constitutes
growing test material to ensure monotonic
improvement of grammars: after a non
trivial change is done in the grammar, a
new compiled parser runs all test
sentences and the results are compared to
the previous ones.
</bodyText>
<subsectionHeader confidence="0.492971">
Information Extraction System
</subsectionHeader>
<bodyText confidence="0.999946153846154">
In an actual working situation there may
be thousands of linguistic symbols in the
work space. To make such a complex
manageable, we have implemented an
information system that for a given symbol
pretty-prints all information associated
with it.
The environment has routines for the
graphic display of parsing results. A
user can select information by pointing
with the cursor. The example in Figure 11
demonstrates the use of this facility.
The command SHOW() inquires the results of
</bodyText>
<figure confidence="0.982808205882353">
_SHOW()
(POIKANI) (ILL!) (ILLALLA) (KENTXLTX) ()€ITTXMASTX) (KIEKKOA) START
((POIKA) TULLA (ILTA KENTTX) (NEITTAA (KIEKKO))) !
TUU-A
*
Subject
(Ergative Neutral)
ILTA
Adverbial
TiesPred
KENTTX
Adverbial
Ablative
NEITTXX
Adverbial
Function
Role
ConstFe
Lexeme
SyntCat
SyntFeat
SemCat
SemFeat
FrameCat
FrameFeat
Polar
Voice
Modal
Tense
Comparison
Number
Case
PersonN
PersonP
Clitl
Clit2
KIEKKO
Object
Neutral
ConstFeat is a linguistic feature type.
De4ault values -Phrase
Associated valuess (+Declarative -Declarative +Main -Main +Nominal
-Nominal &apos;Phrase -Phrase +Predicative -Predicative +Relative -Relative
+Sentence -Sentence)
Associated functions2
(ConstFeat/INIT ConstFeat/FN ConstFeat/m ConstFeat/m2m ConstFeat/s-
ConstFeat/2-/C ConstFeat/um ConstFeat/2m/C)
Subject
(Ergative Neutral)
(-Sentence +Phrase +Nominal)
KA
(Nou
(NIL)
(Human)
(NIL)
(NIL)
(NIL)
(Poe)
(NIL)
(NIL)
(NIL)
(Ni1Compar)
(SG)
(Nom)
(S)
(IP)
(NIL)
(NIL)
</figure>
<figureCaption confidence="0.998452">
Figure 11. An example of information extraction utilities
</figureCaption>
<page confidence="0.996194">
105
</page>
<bodyText confidence="0.9997762">
the parsing process described in Figure 10.
The system replies by first printing the
start state and then the found result(s)
in compressed form. The cursor has been
moved on top of this parse and CTRL-G has
been typed. The system now draws the
picture of the tree structure.
Subsequently one of the nodes has been
opened. The properties of the node POIKA
appear pretty-printed. The user has
furthermore asked information about the
property type ConstFeat. All these
operations are general; they do not use
the special features of any particular
terminal.
</bodyText>
<sectionHeader confidence="0.996359" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<bodyText confidence="0.99993836">
The parsing strategy applied for the
DPL-formalism was originally viewed as a
cognitive model. It has proved to result
practical and efficient parsers as well.
Experiments with a non-trivial set of
Finnish sentence structures have been
performed both on DEC-2060 and on
VAX-11/780 systems. The analysis of an
eight word sentence, for instance, takes
between 20 and 600 ms of DEC CPU-time in
the INTERLISP-version depending on whether
one wants only the first or, through
complete search, all parses for
structurally ambiguous sentences. The
MacLISP-version of the parser runs about
20 % faster on the same computer. The
NIL-version (Common Lisp compatible) is
about 5 times slower on VAX. The whole
environment has been transferred also to
FranzLISP on VAX. We have not yet focused
on optimality issues in grammar
descriptions. We believe that by
rearranging the orderings of expectations
in the automata improvement in efficiency
ensues.
</bodyText>
<sectionHeader confidence="0.995964" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999426409090909">
1. Lehtola, A., Compilation and
Implementation of 2-way Tree Automata for
the Parsing of Finnish. M.S. Thesis,
Helsinki University of Technology,
Department of Physics, 1984, 120 p. (in
Finnish)
2. Nelimarkka, E., Jappinen, H. and
Lehtola A., Two-way Finite Automata and
Dependency Theory: A Parsing Method for
Inflectional Free Word Order Languages.
Proc. COLING84/ACL, Stanford, 1984a, pp.
389-392.
3. Nelimarkka, E., Jappinen, H. and
Lehtola A., Parsing an Inflectional Free
Word Order Language with Two-way Finite
Automata. Proc. of the 6th European
Conference on Artificial Intelligence,
Pisa, 1984b, pp. 167-176.
4. Winograd, T., Language as a Cognitive
Process. Volume Syntax,
Addison-Wesley Publishing Company,
Reading, 1983, 640 p.
</reference>
<page confidence="0.99732">
106
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.254735">
<affiliation confidence="0.63829075">LANGUAGE-BASED ENVIRONMENT FOR NATURAL LANGUAGE PARSING Lehtola, A., Jappinen, H., Nelimarkka, E. Sitra Foundation (*) and Helsinki University of Technology</affiliation>
<address confidence="0.998485">Helsinki, Finland</address>
<abstract confidence="0.997709428571429">This paper introduces a special programming environment for the definition of grammars and for the implementation of corresponding parsers. In natural language processing systems it is advantageous to have linguistic knowledge and processing mechanisms separated. Our environment accepts grammars consisting of binary dependency relations and grammatical functions. Well-formed expressions of functions and relations provide constituent surroundings for syntactic categories in the form of two-way automata. These relations, functions, and automata are described in a special definition language. In focusing on high level descriptions a linguist may ignore computational details of the parsing process. He writes the grammar into a DPL-description and a compiler translates it into efficient LISP-code. The environment has also a tracing facility for the parsing process, grammar-sensitive lexical maintenance programs, and routines for the interactive graphic display of parse trees and grammar definitions. Translator routines are also available for the transport of compiled code between various LISP-dialects. The environment itself exists currently in INTERLISP and FRANZLISP. This paper focuses on knowledge engineering issues and does not enter linguistic argumentation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Lehtola</author>
</authors>
<title>Compilation and Implementation of 2-way Tree Automata for the Parsing of Finnish.</title>
<date>1984</date>
<tech>M.S. Thesis,</tech>
<pages>120</pages>
<institution>Helsinki University of Technology, Department of Physics,</institution>
<note>(in Finnish)</note>
<marker>1.</marker>
<rawString>Lehtola, A., Compilation and Implementation of 2-way Tree Automata for the Parsing of Finnish. M.S. Thesis, Helsinki University of Technology, Department of Physics, 1984, 120 p. (in Finnish)</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Nelimarkka</author>
<author>H Jappinen</author>
<author>A Lehtola</author>
</authors>
<title>Two-way Finite Automata and Dependency Theory: A Parsing Method for Inflectional Free Word Order Languages.</title>
<date>1984</date>
<booktitle>Proc. COLING84/ACL,</booktitle>
<pages>389--392</pages>
<location>Stanford,</location>
<marker>2.</marker>
<rawString>Nelimarkka, E., Jappinen, H. and Lehtola A., Two-way Finite Automata and Dependency Theory: A Parsing Method for Inflectional Free Word Order Languages. Proc. COLING84/ACL, Stanford, 1984a, pp. 389-392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Nelimarkka</author>
<author>H Jappinen</author>
<author>A Lehtola</author>
</authors>
<title>Parsing an Inflectional Free Word Order Language with Two-way Finite Automata.</title>
<date>1984</date>
<booktitle>Proc. of the 6th European Conference on Artificial Intelligence,</booktitle>
<pages>167--176</pages>
<location>Pisa,</location>
<marker>3.</marker>
<rawString>Nelimarkka, E., Jappinen, H. and Lehtola A., Parsing an Inflectional Free Word Order Language with Two-way Finite Automata. Proc. of the 6th European Conference on Artificial Intelligence, Pisa, 1984b, pp. 167-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>Language as a Cognitive Process. Volume Syntax,</title>
<date>1983</date>
<pages>640</pages>
<publisher>Addison-Wesley Publishing Company,</publisher>
<location>Reading,</location>
<marker>4.</marker>
<rawString>Winograd, T., Language as a Cognitive Process. Volume Syntax, Addison-Wesley Publishing Company, Reading, 1983, 640 p.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>