<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000172">
<title confidence="0.953748">
Using Bilingual Information for Cross-Language Document
Summarization
</title>
<author confidence="0.997053">
Xiaojun Wan
</author>
<affiliation confidence="0.982016">
Institute of Compute Science and Technology, Peking University, Beijing 100871, China
Key Laboratory of Computational Linguistics (Peking University), MOE, China
</affiliation>
<email confidence="0.996643">
wanxiaojun@icst.pku.edu.cn
</email>
<sectionHeader confidence="0.996566" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999349842105263">
Cross-language document summarization is de-
fined as the task of producing a summary in a
target language (e.g. Chinese) for a set of
documents in a source language (e.g. English).
Existing methods for addressing this task make
use of either the information from the original
documents in the source language or the infor-
mation from the translated documents in the
target language. In this study, we propose to use
the bilingual information from both the source
and translated documents for this task. Two
summarization methods (SimFusion and
CoRank) are proposed to leverage the bilingual
information in the graph-based ranking frame-
work for cross-language summary extraction.
Experimental results on the DUC2001 dataset
with manually translated reference Chinese
summaries show the effectiveness of the pro-
posed methods.
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999915261904762">
Cross-language document summarization is de-
fined as the task of producing a summary in a dif-
ferent target language for a set of documents in a
source language (Wan et al., 2010). In this study,
we focus on English-to-Chinese cross-language
summarization, which aims to produce Chinese
summaries for English document sets. The task is
very useful in the field of multilingual information
access. For example, it is beneficial for most Chi-
nese readers to quickly browse and understand
English news documents or document sets by read-
ing the corresponding Chinese summaries.
A few pilot studies have investigated the task in
recent years and exiting methods make use of ei-
ther the information in the source language or the
information in the target language after using ma-
chine translation. In particular, for the task of Eng-
lish-to-Chinese cross-language summarization, one
method is to directly extract English summary sen-
tences based on English features extracted from the
English documents, and then automatically trans-
late the English summary sentences into Chinese
summary sentences. The other method is to auto-
matically translate the English sentences into Chi-
nese sentences, and then directly extract Chinese
summary sentences based on Chinese features. The
two methods make use of the information from
only one language side.
However, it is not very reliable to use only the
information in one language, because the machine
translation quality is far from satisfactory, and thus
the translated Chinese sentences usually contain
some errors and noises. For example, the English
sentence “Many destroyed power lines are thought
to be uninsured, as are trees and shrubs uprooted
across a wide area.” is automatically translated
into the Chinese sentence “许多破坏电源线被认
为是保险的,因为是连根拔起的树木和灌木,
在广泛的领域。” by using Google Translate1 ,
but the Chinese sentence contains a few translation
errors. Therefore, on the one side, if we rely only
on the English-side information to extract Chinese
</bodyText>
<footnote confidence="0.994638666666667">
1 http://translate.google.com/. Note that the translation service
is updated frequently and the current translation results may be
different from that presented in this paper.
</footnote>
<page confidence="0.864121">
1546
</page>
<note confidence="0.9805645">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 1546–1555,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.9999099375">
summary sentences, we cannot guarantee that the
automatically translated Chinese sentences for sa-
lient English sentences are really salient when
these sentences may contain many translation er-
rors and other noises. On the other side, if we rely
only on the Chinese-side information to extract
Chinese summary sentences, we cannot guarantee
that the selected sentences are really salient be-
cause the features for sentence ranking based on
the incorrectly translated sentences are not very
reliable, either.
In this study, we propose to leverage both the in-
formation in the source language and the informa-
tion in the target language for cross-language
document summarization. In particular, we pro-
pose two graph-based summarization methods
(SimFusion and CoRank) for using both English-
side and Chinese-side information in the task of
English-to-Chinese cross-document summarization.
The SimFusion method linearly fuses the English-
side similarity and the Chinese-side similarity for
measuring Chinese sentence similarity. The
CoRank method adopts a co-ranking algorithm to
simultaneously rank both English sentences and
Chinese sentences by incorporating mutual influ-
ences between them.
We use the DUC2001 dataset with manually
translated reference Chinese summaries for evalua-
tion. Experimental results based on the ROUGE
metrics show the effectiveness of the proposed
methods. Three important conclusions for this task
are summarized below:
</bodyText>
<listItem confidence="0.960954375">
1) The Chinese-side information is more benefi-
cial than the English-side information.
2) The Chinese-side information and the Eng-
lish-side information can complement each
other.
3) The proposed CoRank method is more reli-
able and robust than the proposed SimFusion
method.
</listItem>
<bodyText confidence="0.9998278">
The rest of this paper is organized as follows:
Section 2 introduces related work. In Section 3, we
present our proposed methods. Evaluation results
are shown in Section 4. Lastly, we conclude this
paper in Section 5.
</bodyText>
<sectionHeader confidence="0.999778" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.963133">
2.1 General Document Summarization
</subsectionHeader>
<bodyText confidence="0.999616957446808">
Document summarization methods can be extrac-
tion-based, abstraction-based or hybrid methods.
We focus on extraction-based methods in this
study, and the methods directly extract summary
sentences from a document or document set by
ranking the sentences in the document or document
set.
In the task of single document summarization,
various features have been investigated for ranking
sentences in a document, including term frequency,
sentence position, cue words, stigma words, and
topic signature (Luhn 1969; Lin and Hovy, 2000).
Machine learning techniques have been used for
sentence ranking (Kupiec et al., 1995; Amini and
Gallinari, 2002). Litvak et al. (2010) present a lan-
guage-independent approach for extractive summa-
rization based on the linear optimization of several
sentence ranking measures using a genetic algo-
rithm. In recent years, graph-based methods have
been proposed for sentence ranking (Erkan and
Radev, 2004; Mihalcea and Tarau, 2004). Other
methods include mutual reinforcement principle
(Zha 2002; Wan et al., 2007).
In the task of multi-document summarization,
the centroid-based method (Radev et al., 2004)
ranks the sentences in a document set based on
such features as cluster centroids, position and
TFIDF. Machine Learning techniques have also
been used for feature combining (Wong et al.,
2008). Nenkova and Louis (2008) investigate the
influences of input difficulty on summarization
performance. Pitler et al. (2010) present a system-
atic assessment of several diverse classes of met-
rics designed for automatic evaluation of linguistic
quality of multi-document summaries. Celikyilmaz
and Hakkani-Tur (2010) formulate extractive
summarization as a two-step learning problem by
building a generative model for pattern discovery
and a regression model for inference. Aker et al.
(2010) propose an A* search algorithm to find the
best extractive summary up to a given length, and
they propose a discriminative training algorithm
for directly maximizing the quality of the best
summary. Graph-based methods have also been
used to rank sentences for multi-document summa-
rization (Mihalcea and Tarau, 2005; Wan and
Yang, 2008).
</bodyText>
<page confidence="0.990792">
1547
</page>
<subsectionHeader confidence="0.9682645">
2.2 Cross-Lingual Document Summariza-
tion
</subsectionHeader>
<bodyText confidence="0.999948051282051">
Several pilot studies have investigated the task of
cross-language document summarization. The ex-
isting methods use only the information in either
language side. Two typical translation schemes are
document translation or summary translation. The
document translation scheme first translates the
source documents into the corresponding docu-
ments in the target language, and then extracts
summary sentences based only on the information
on the target side. The summary translation scheme
first extracts summary sentences from the source
documents based only on the information on the
source side, and then translates the summary sen-
tences into the corresponding summary sentences
in the target language.
For example Leuski et al. (2003) use machine
translation for English headline generation for
Hindi documents. Lim et al. (2004) propose to
generate a Japanese summary by using Korean
summarizer. Chalendar et al. (2005) focus on se-
mantic analysis and sentence generation techniques
for cross-language summarization. Orasan and
Chiorean (2008) propose to produce summaries
with the MMR method from Romanian news arti-
cles and then automatically translate the summaries
into English. Cross language query based summa-
rization has been investigated in (Pingali et al.,
2007), where the query and the documents are in
different languages. Wan et al. (2010) adopt the
summary translation scheme for the task of Eng-
lish-to-Chinese cross-language summarization.
They first extract English summary sentences by
using English-side features and the machine trans-
lation quality factor, and then automatically trans-
late the English summary into Chinese summary.
Other related work includes multilingual summari-
zation (Lin et al., 2005; Siddharthan and McKe-
own, 2005), which aims to create summaries from
multiple sources in multiple languages.
</bodyText>
<sectionHeader confidence="0.994308" genericHeader="method">
3 Our Proposed Methods
</sectionHeader>
<bodyText confidence="0.999970166666667">
As mentioned in Section 1, existing methods rely
only on one-side information for sentence ranking,
which is not very reliable. In order to leveraging
both-side information for sentence ranking, we
propose the following two methods to incorporate
the bilingual information in different ways.
</bodyText>
<subsectionHeader confidence="0.998872">
3.1 SimFusion
</subsectionHeader>
<bodyText confidence="0.993654604651163">
This method uses the English-side information for
Chinese sentence ranking in the graph-based
framework. The sentence similarities in the two
languages are fused in the method. In other words,
when we compute the similarity value between two
Chinese sentences, the similarity value between the
corresponding two English sentences is used by
linear fusion. Since sentence similarity evaluation
plays a very important role in the graph-based
ranking algorithm, this method can leverage both-
side information through similarity fusion.
Formally, given the Chinese document set Dcn
translated from an English document set, let
Gcn=(Vcn, Ecn) be an undirected graph to reflect the
relationships between the sentences in the Chinese
document set. Vcn is the set of vertices and each
vertex scni in Vcn represents a Chinese sentence. Ecn
is the set of edges. Each edge ecnij in Ecn is associ-
ated with an affinity weight f(scni, scnj) between sen-
tences scni and scnj (i≠j). The weight is computed by
linearly combining the similarity value simcosine(scni,
scnj) between the Chinese sentences and the simi-
larity value simcosine(seni, senj) between the corre-
sponding English sentences.
f(scn scn)_A•sim (scn scn)+(1−A)•sim (sen sen )
i , j cosine i , j cosine i , j
where senj and seni are the source English sentences
for scnj and scni. λ∈[0, 1] is a parameter to control
the relative contributions of the two similarity val-
ues. The similarity values simcosine(scni, scnj) and
simcosine(seni, senj) are computed by using the stan-
dard cosine measure. The weight for each term is
computed based on the TFIDF formula. For Chi-
nese similarity computation, Chinese word seg-
mentation is performed. Here, we have f(scni,
scnj)=f(scn j, scni) and let f(scni, scni)=0 to avoid self
transition. We use an affinity matrix Mcn to de-
scribe Gcn with each entry corresponding to the
weight of an edge in the graph. Mcn=(Mcnij)|Vcn|×|Vcn|
is defined as Mcnij=f(scni,scnj). Then Mcn is normal-
ized to cn
M ~ to make the sum of each row equal to 1.
Based on matrix cn
</bodyText>
<listItem confidence="0.9006886">
M ~ , the saliency score Info-
Score(scni) for sentence scni can be deduced from
those of all other sentences linked with it and it can
be formulated in a recursive form as in the PageR-
ank algorithm:
</listItem>
<page confidence="0.853654">
1548
</page>
<figure confidence="0.514344">
~InfoScore(s&apos;) =μ InfoScore(s&apos; ) ⋅ M ji + (1− μ)
n
all j i
≠
</figure>
<bodyText confidence="0.999948384615385">
where n is the sentence number, i.e. n= |Vcn|. μ is
the damping factor usually set to 0.85, as in the
PageRank algorithm.
For numerical computation of the saliency
scores, we can iteratively run the above equation
until convergence.
For multi-document summarization, some sen-
tences are highly overlapping with each other, and
thus we apply the same greedy algorithm in Wan et
al. (2006) to penalize the sentences highly overlap-
ping with other highly scored sentences, and fi-
nally the salient and novel Chinese sentences are
directly selected as summary sentences.
</bodyText>
<subsectionHeader confidence="0.998317">
3.2 CoRank
</subsectionHeader>
<bodyText confidence="0.992030859649123">
This method leverages both the English-side in-
formation and the Chinese-side information in a
co-ranking way. The source English sentences and
the translated Chinese sentences are simultane-
ously ranked in a unified graph-based algorithm.
The saliency of each English sentence relies not
only on the English sentences linked with it, but
also on the Chinese sentences linked with it. Simi-
larly, the saliency of each Chinese sentence relies
not only on the Chinese sentences linked with it,
but also on the English sentences linked with it.
More specifically, the proposed method is based on
the following assumptions:
Assumption 1: A Chinese sentence would be
salient if it is heavily linked with other salient Chi-
nese sentences; and an English sentence would be
salient if it is heavily linked with other salient Eng-
lish sentences.
Assumption 2: A Chinese sentence would be
salient if it is heavily linked with salient English
sentences; and an English sentence would be sali-
ent if it is heavily linked with salient Chinese sen-
tences.
The first assumption is similar to PageRank
which makes use of mutual “recommendations”
between the sentences in the same language to rank
sentences. The second assumption is similar to
HITS if the English sentences and the Chinese sen-
tences are considered as authorities and hubs, re-
spectively. In other words, the proposed method
aims to fuse the ideas of PageRank and HITS in a
unified framework. The mutual influences between
the Chinese sentences and the English sentences
are incorporated in the method.
Figure 1 gives the graph representation for the
method. Three kinds of relationships are exploited:
the CN-CN relationships between Chinese sen-
tences, the EN-EN relationships between English
sentences, and the EN-CN relationships between
English sentences and Chinese sentences.
Formally, given an English document set Den and
the translated Chinese document set Dcn, let G=(Ven,
Vcn, Een, Ecn, Eencn) be an undirected graph to reflect
all the three kinds of relationships between the sen-
tences in the two document sets. Ven ={seni  |1&lt;i&lt;n}
is the set of English sentences. Vcn={scni  |1&lt;i&lt;n} is
the set of Chinese sentences. scni is the correspond-
ing Chinese sentence translated from seni. n is the
number of the sentences. Een is the edge set to re-
flect the relationships between the English sen-
tences. Ecn is the edge set to reflect the
relationships between the Chinese sentences. Eencn
is the edge set to reflect the relationships between
the English sentences and the Chinese sentences.
Based on the graph representation, we compute the
following three affinity matrices to reflect the three
kinds of sentence relationships:
</bodyText>
<figure confidence="0.9459325">
Chinese sentences
English Sentences
</figure>
<figureCaption confidence="0.999829">
Figure 1. The three kinds of sentence relationships
</figureCaption>
<bodyText confidence="0.7501294">
1) Mcn=(Mcnij)n×n: This affinity matrix aims to
reflect the relationships between the Chinese sen-
tences. Each entry in the matrix corresponds to the
cosine similarity between the two Chinese sen-
tences.
</bodyText>
<figure confidence="0.945482315789474">
cn cn
simcosine (si , sj ), if i
otherwise
CN-CN
EN-CN
EN-EN
M
ij
0
cn
=
���
��
,
j
1549
~
Then Mcn is normalized to cn
M
</figure>
<bodyText confidence="0.870616">
sum of each row equal to 1.
2) Men=(Meni,j)n×n: This affinity matrix aims to
reflect the relationships between the English sen-
tences. Each entry in the matrix corresponds to the
cosine similarity between the two English sen-
tences.
Then Men is normalized to Men to make the
sum of each row equal to 1.
</bodyText>
<listItem confidence="0.684158">
3) Mencn=(Mencnij) • This affinity matrix aims to
</listItem>
<bodyText confidence="0.969213866666667">
ij nxn•
reflect the relationships between the English sen-
tences and the Chinese sentences. Each entry
Mencnij in the matrix corresponds to the similarity
between the English sentence seni and the Chinese
sentence scnj. It is hard to directly compute the
similarity between the sentences in different lan-
guages. In this study, the similarity value is com-
puted by fusing the following two similarity values:
the cosine similarity between the sentence seni and
the corresponding source English sentence senj for
scnj, and the cosine similarity between the corre-
sponding translated Chinese sentence scni for seni
and the sentence scnj. We use the geometric mean
of the two values as the affinity weight.
</bodyText>
<equation confidence="0.9563782">
cos ( , ) cos ( ,
en en cn
M encn = s s sim
sim × s s
ij ine i j ine i
</equation>
<bodyText confidence="0.997421">
Note that we have Mencnij=Mencnji and
Mencn=(Mencn)T. Then Mencn is normalized to encn
</bodyText>
<equation confidence="0.524409">
M ~
</equation>
<bodyText confidence="0.999678166666667">
to make the sum of each row equal to 1.
We use two column vectors u=[u(scni)]n×1 and v
=[v(senj)]n×1 to denote the saliency scores of the
Chinese sentences and the English sentences, re-
spectively. Based on the three kinds of relation-
ships, we can get the following four assumptions:
</bodyText>
<equation confidence="0.988424333333333">
u (s&apos;) ∝ ∑ j M~cnu (s&apos; )
v(sen) ∝ ∑i iii&apos;v(sien )
v(s&apos;) ∝ ∑R,&amp;quot;cnu (san )
</equation>
<bodyText confidence="0.9998225">
After fusing the above equations, we can obtain
the following iterative forms:
</bodyText>
<equation confidence="0.963459375">
~
u s α M u s β M v s
cn cn cn encn en
( )= ∑ ( )+ ∑j ~ ( )
i j ji j ji j
~ en
= ∑
α M v s β M u s
en encn cn
v s
( ) ( )+ ∑ i ~
en ( )
j i ij i ij i
And the matrix form is:
u = α(Mcn) T u+β(Mencn )T v
v = α(Men )Tv +β(Mencn)T u
</equation>
<bodyText confidence="0.999969722222222">
where α and β specify the relative contributions to
the final saliency scores from the information in
the same language and the information in the other
language and we have α+β=1.
For numerical computation of the saliency
scores, we can iteratively run the two equations
until convergence. Usually the convergence of the
iteration algorithm is achieved when the difference
between the scores computed at two successive
iterations for any sentences and words falls below
a given threshold. In order to guarantee the con-
vergence of the iterative form, u and v are normal-
ized after each iteration.
After we get the saliency scores u for the Chi-
nese sentences, we apply the same greedy algo-
rithm for redundancy removing. Finally, a few
highly ranked sentences are selected as summary
sentences.
</bodyText>
<sectionHeader confidence="0.997532" genericHeader="method">
4 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.963362">
4.1 Evaluation Setup
</subsectionHeader>
<bodyText confidence="0.99955285">
There is no benchmark dataset for English-to-
Chinese cross-language document summarization,
so we built our evaluation dataset based on the
DUC2001 dataset by manually translating the ref-
erence summaries.
DUC2001 provided 30 English document sets
for generic multi-document summarization. The
average document number per document set was
10. The sentences in each article have been sepa-
rated and the sentence information has been stored
into files. Three or two generic reference English
summaries were provided by NIST annotators for
each document set. Three graduate students were
employed to manually translate the reference Eng-
lish summaries into reference Chinese summaries.
Each student manually translated one third of the
reference summaries. It was much easier and more
reliable to provide the reference Chinese summa-
ries by manual translation than by manual summa-
rization.
</bodyText>
<figure confidence="0.9969025">
cos ( , )
en
sim s s , if i≠
ine i en
j
otherwise
en
⎧ ⎪⎨
⎪⎩
j
Mij
0
,
~
cn ∝ M v(s )
encn en
u s i
( )
j
j
ji
∑
to make the
)
cn
j
</figure>
<page confidence="0.957892">
1550
</page>
<table confidence="0.9988635">
ROUGE-2 ROUGE-W ROUGE-L ROUGE-SU4
Average F Average F Average F Average F
Baseline(EN) 0.03723 0.05566 0.13259 0.07177
Baseline(CN) 0.03805 0.05886 0.13871 0.07474
SimFusion 0.04017 0.06117 0.14362 0.07645
CoRank 0.04282 0.06158 0.14521 0.07805
</table>
<tableCaption confidence="0.999934">
Table 1: Comparison Results
</tableCaption>
<bodyText confidence="0.999729214285714">
All the English sentences in the document set
were automatically translated into Chinese sen-
tences by using Google Translate, and the Stanford
Chinese Word Segmenter2 was used for segment-
ing the Chinese documents and summaries into
words. For comparative study, the summary length
was limited to five sentences, i.e. each Chinese
summary consisted of five sentences.
We used the ROUGE-1.5.5 (Lin and Hovy,
2003) toolkit for evaluation, which has been
widely adopted by DUC and TAC for automatic
summarization evaluation. It measured summary
quality by counting overlapping units such as the
n-gram, word sequences and word pairs between
the candidate summary and the reference summary.
We showed three of the ROUGE F-measure scores
in the experimental results: ROUGE-2 (bigram-
based), ROUGE-W (based on weighted longest
common subsequence, weight=1.2), ROUGE-L
(based on longest common subsequences), and
ROUGE-SU4 (based on skip bigram with a maxi-
mum skip distance of 4). Note that the ROUGE
toolkit was performed for Chinese summaries after
using word segmentation.
Two graph-based baselines were used for com-
parison.
Baseline(EN): This baseline adopts the sum-
mary translation scheme, and it relies on the Eng-
lish-side information for English sentence ranking.
The extracted English summary is finally auto-
matically translated into the corresponding Chinese
summary. The same sentence ranking algorithm
with the SimFusion method is adopted, and the
affinity weight is computed based only on the co-
sine similarity between English sentences.
Baseline(CN): This baseline adopts the docu-
ment translation scheme, and it relies on the Chi-
nese-side information for Chinese sentence ranking.
The Chinese summary sentences are directly ex-
tracted from the translated Chinese documents.
The same sentence ranking algorithm with the
SimFusion method is adopted, and the affinity
</bodyText>
<footnote confidence="0.842789">
2 http://nlp.stanford.edu/software/segmenter.shtml
</footnote>
<figureCaption confidence="0.559807">
weight is computed based only on the cosine simi-
larity between Chinese sentences.
</figureCaption>
<bodyText confidence="0.961269">
For our proposed methods, the parameter val-
ues are empirically set as A=0.8 and α=0.5.
</bodyText>
<subsectionHeader confidence="0.738297">
4.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999944297297298">
Table 1 shows the comparison results for our pro-
posed methods and the baseline methods. Seen
from the tables, Baseline(CN) performs better than
Baseline(EN) over all the metrics. The results dem-
onstrate that the Chinese-side information is more
beneficial than the English-side information for
cross-document summarization, because the sum-
mary sentences are finally selected from the Chi-
nese side. Moreover, our proposed two methods
can outperform the two baselines over all the met-
rics. The results demonstrate the effectiveness of
using bilingual information for cross-language
document summarization. It is noteworthy that the
ROUGE scores in the table are not high due to the
following two reasons: 1) The use of machine
translation may introduce many errors and noises
in the peer Chinese summaries; 2) The use of Chi-
nese word segmentation may introduce more
noises and mismatches in the ROUGE evaluation
based on Chinese words.
We can also see that the CoRank method can
outperform the SimFusion method over all metrics.
The results show that the CoRank method is more
suitable for the task by incorporating the bilingual
information into a unified ranking framework.
In order to show the influence of the value of the
combination parameter A on the performance of the
SimFusion method, we present the performance
curves over the four metrics in Figures 2 through 5,
respectively. In the figures, A ranges from 0 to 1,
and A=1 means that SimFusion is the same with
Baseline(CN), and A=0 means that only English-
side information is used for Chinese sentence rank-
ing. We can see that when A is set to a value larger
than 0.5, SimFusion can outperform the two base-
lines over most metrics. The results show that A
can be set in a relatively wide range. Note that
</bodyText>
<page confidence="0.984558">
1551
</page>
<bodyText confidence="0.998621552631579">
A&gt;0.5 means that SimFusion relies more on the
Chinese-side information than on the English-side
information. Therefore, the Chinese-side informa-
tion is more beneficial than the English-side in-
formation.
In order to show the influence of the value of the
combination parameter α on the performance of the
CoRank method, we present the performance
curves over the four metrics in Figures 6 through 9,
respectively. In the figures, α ranges from 0.1 to
0.9, and a larger value means that the information
from the same language side is more relied on, and
a smaller value means that the information from
the other language side is more relied on. We can
see that CoRank can always outperform the two
baselines over all metrics with different value of α.
The results show that α can be set in a very wide
range. We also note that a very large value or a
very small value of α can lower the performance
values. The results demonstrate that CoRank relies
on both the information from the same language
side and the information from the other language
side for sentence ranking. Therefore, both the Chi-
nese-side information and the English-side infor-
mation can complement each other, and they are
beneficial to the final summarization performance.
Comparing Figures 2 through 5 with Figures 6
through 9, we can further see that the CoRank
method is more stable and robust than the Sim-
Fusion method. The CoRank method can outper-
form the SimFusion method with most parameter
settings. The bilingual information can be better
incorporated in the unified ranking framework of
the CoRank method.
Finally, we show one running example for the
document set D59 in the DUC2001 dataset. The
four summaries produced by the four methods are
listed below:
</bodyText>
<equation confidence="0.885414606060606">
Baseline(EN): 周日的崩溃是 24年来第一次乘客在涉及西
北飞机事故中丧生。有乘客和观察员的报告,这架飞机的右翼引
擎也坠毁前失败。在坠机现场联邦航空局官员表示不会揣测关于
崩溃或在飞机上的发动机评论的原因。美国联邦航空局的记录显
示,除了那些涉及的飞机坠毁,与 JT8D 涡轮路段-200 系列发动
机问题的三个共和国在过去四年的航班发生的事件。1988 年 7
月,一个联合国的 DC-10 坠毁的苏城,艾奥瓦州后,发动机在飞
行中发生外,造成 112 人。
Baseline(CN): 第二,在美国历史上最严重的事故是 1987
年 8 月 16 日,坠毁,造成 156 人时,美国西北航空公司飞机上
的底特律都市机场起飞时坠毁。据美国联邦航空管理局的纪录,
麦道公司的 MD-82 飞机在 1985 年和 1986 年紧急降落后,在其两
个引擎之一是失去权力。周日的崩溃是 24 年来第一次乘客在涉
及西北飞机事故中丧生。今年 4 月,国家运输安全委员会敦促美
国联邦航空局后进行一些危险,发动机故障,飞机的一个发动机
的 200 系列 JT8D 安全调查。目前,机组人员发现了一个黑人师
谁说,他可以引导飞机在附近的人们听到了他们的区域。
SimFusion: 第二,在美国历史上最严重的事故是 1987 年 8
月 16 日,坠毁,造成 156 人时,美国西北航空公司飞机上的底
特律都市机场起飞时坠毁。周日的崩溃是 24 年来第一次乘客在
涉及西北飞机事故中丧生。在坠机现场联邦航空局官员表示不会
揣测关于崩溃或在飞机上的发动机评论的原因。有乘客和观察员
的报告,这架飞机的右翼引擎也坠毁前失败。据美国联邦航空管
理局的纪录,麦道公司的 MD-82 飞机在 1985 年和 1986 年紧急降
落后,在其两个引擎之一是失去权力。
CoRank : 周日的崩溃是 24 年来第一次乘客在涉及西北飞
机事故中丧生。第二,在美国历史上最严重的事故是 1987 年 8
月 16 日,坠毁,造成 156 人时,美国西北航空公司飞机上的底
特律都市机场起飞时坠毁。在坠机现场联邦航空局官员表示不会
揣测关于崩溃或在飞机上的发动机评论的原因。最严重的航空事
故不断,在美国是一个在芝加哥的美国航空公司客机 1979 年崩
溃。有乘客和观察员的报告,这架飞机的右翼引擎也坠毁前失
败。
</equation>
<sectionHeader confidence="0.974112" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999963578947369">
In this paper, we propose two methods (SimFusion
and CoRank) to address the cross-language docu-
ment summarization task by leveraging the bilin-
gual information in both the source and target
language sides. Evaluation results demonstrate the
effectiveness of the proposed methods. The Chi-
nese-side information is validated to be more bene-
ficial than the English-side information, and the
CoRank method is more robust than the SimFusion
method.
In future work, we will investigate to use the
machine translation quality factor to further im-
prove the fluency of the Chinese summary, as in
Wan et al. (2010). Though our attempt to use
GIZA++ for evaluating the similarity between
Chinese sentences and English sentences failed, we
will exploit more advanced measures based on sta-
tistical alignment model for cross-language simi-
larity computation.
</bodyText>
<sectionHeader confidence="0.979851" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999871166666667">
This work was supported by NSFC (60873155),
Beijing Nova Program (2008B03) and NCET
(NCET-08-0006). We thank the three students for
translating the reference summaries. We also thank
the anonymous reviewers for their useful com-
ments.
</bodyText>
<page confidence="0.990364">
1552
</page>
<figure confidence="0.999704208333333">
ROUGE-2(F)
0.042
0.038
0.036
0.034
0.032
0.04
0.03
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
λ
SimFusion Baseline(EN) Baseline(CN)
ROUGE-2(F)
0.044
0.043
0.042
0.041
0.039
0.038
0.037
0.036
0.04
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
CoRank Baseline(EN) Baseline(CN)
α
</figure>
<figureCaption confidence="0.998709">
Figure 2. ROUGE-2(F) vs. λ for SimFusion Figure 6. ROUGE-2(F) vs. α for CoRank
</figureCaption>
<figure confidence="0.999884928571429">
ROUGE-W(F)
0.062
0.061
0.059
0.058
0.057
0.056
0.055
0.054
0.053
0.052
0.06
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SimFusion Baseline(EN) Baseline(CN)
λ
ROUGE-W(F)
0.063
0.062
0.061
0.059
0.058
0.057
0.056
0.055
0.06
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
CoRank Baseline(EN) Baseline(CN)
α
</figure>
<figureCaption confidence="0.993653">
Figure 3. ROUGE-W(F) vs. λ for SimFusion Figure 7. ROUGE-W(F) vs. α for CoRank
</figureCaption>
<figure confidence="0.999835482758621">
ROUGE-L(F)
0.145
0.143
0.141
0.139
0.137
0.135
0.133
0.131
0.129
0.127
0.125
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SimFusion Baseline(EN) Baseline(CN)
λ
ROUGE-L(F)
0.148
0.146
0.144
0.142
0.138
0.136
0.134
0.132
0.14
0.13
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
CoRank Baseline(EN) Baseline(CN)
α
</figure>
<figureCaption confidence="0.997676">
Figure 4. ROUGE-L(F) vs. λ for SimFusion Figure 8. ROUGE-L(F) vs. α for CoRank
</figureCaption>
<figure confidence="0.999745461538462">
ROUGE-SU4(F)
0.078
0.076
0.074
0.072
0.068
0.066
0.064
0.07
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
SimFusion Baseline(EN) Baseline(CN)
λ
ROUGE-SU4(F)
0.079
0.078
0.077
0.076
0.075
0.074
0.073
0.072
0.071
0.07
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
CoRank Baseline(EN) Baseline(CN)
α
</figure>
<figureCaption confidence="0.999999">
Figure 5. ROUGE-SU4(F) vs. λ for SimFusion
Figure 5. ROUGE-SU4(F) vs. λ for SimFusion Figure 9. ROUGE-SU4(F) vs. α for CoRank
Figure 9. ROUGE-SU4(F) vs. α for CoRank
</figureCaption>
<page confidence="0.956884">
1553
</page>
<sectionHeader confidence="0.982501" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999680888888889">
A. Aker, T. Cohn, and R. Gaizauskas. 2010. Multi-
document summarization using A* search and
discriminative training. In Proceedings of
EMNLP2010.
M. R. Amini, P. Gallinari. 2002. The Use of Unla-
beled Data to Improve Supervised Learning for
Text Summarization. In Proceedings of
SIGIR2002.
G. de Chalendar, R. Besançon, O. Ferret, G. Gre-
fenstette, and O. Mesnard. 2005. Crosslingual
summarization with thematic extraction, syntac-
tic sentence simplification, and bilingual genera-
tion. In Workshop on Crossing Barriers in Text
Summarization Research, 5th International Con-
ference on Recent Advances in Natural Lan-
guage Processing (RANLP2005).
A. Celikyilmaz and D. Hakkani-Tur. 2010. A hy-
brid hierarchical model for multi-document
summarization. In Proceedings of ACL2010.
G. ErKan, D. R. Radev. LexPageRank. 2004. Pres-
tige in Multi-Document Text Summarization. In
Proceedings of EMNLP2004.
D. Klein and C. D. Manning. 2002. Fast Exact In-
ference with a Factored Model for Natural Lan-
guage Parsing. In Proceedings of NIPS2002.
J. Kupiec, J. Pedersen, F. Chen. 1995. A.Trainable
Document Summarizer. In Proceedings of
SIGIR1995.
A. Leuski, C.-Y. Lin, L. Zhou, U. Germann, F. J.
Och, E. Hovy. 2003. Cross-lingual C*ST*RD:
English access to Hindi information. ACM
Transactions on Asian Language Information
Processing, 2(3): 245-269.
J.-M. Lim, I.-S. Kang, J.-H. Lee. 2004. Multi-
document summarization using cross-language
texts. In Proceedings of NTCIR-4.
C. Y. Lin, E. Hovy. 2000. The Automated Acquisi-
tion of Topic Signatures for Text Summarization.
In Proceedings of the 17th Conference on Com-
putational Linguistics.
C.-Y. Lin and E.H. Hovy. 2003. Automatic
Evaluation of Summaries Using N-gram Co-
occurrence Statistics. In Proceedings of HLT-
NAACL -03.
C.-Y. Lin, L. Zhou, and E. Hovy. 2005. Multilin-
gual summarization evaluation 2005: automatic
evaluation report. In Proceedings of MSE (ACL-
2005 Workshop).
M. Litvak, M. Last, and M. Friedman. 2010. A
new approach to improving multilingual sum-
marization using a genetic algorithm. In Pro-
ceedings of ACL2010.
H. P. Luhn. 1969. The Automatic Creation of lit-
erature Abstracts. IBM Journal of Research and
Development, 2(2).
R. Mihalcea, P. Tarau. 2004. TextRank: Bringing
Order into Texts. In Proceedings of
EMNLP2004.
R. Mihalcea and P. Tarau. 2005. A language inde-
pendent algorithm for single and multiple docu-
ment summarization. In Proceedings of
IJCNLP-05.
A. Nenkova and A. Louis. 2008. Can you summa-
rize this? Identifying correlates of input diffi-
culty for generic multi-document summarization.
In Proceedings of ACL-08:HLT.
A. Nenkova, R. Passonneau, and K. McKeown.
2007. The Pyramid method: incorporating hu-
man content selection variation in summariza-
tion evaluation. ACM Transactions on Speech
and Language Processing (TSLP), 4(2).
C. Orasan, and O. A. Chiorean. 2008. Evaluation
of a Crosslingual Romanian-English Multi-
document Summariser. In Proceedings of 6th
Language Resources and Evaluation Confer-
ence (LREC2008).
P. Pingali, J. Jagarlamudi and V. Varma. 2007.
Experiments in cross language query focused
multi-document summarization. In Workshop on
Cross Lingual Information Access Addressing
the Information Need of Multilingual Societies
in IJCAI2007.
E. Pitler, A. Louis, and A. Nenkova. 2010. Auto-
matic evaluation of linguistic quality in multi-
document summarization. In Proceedings of
ACL2010.
D. R. Radev, H. Y. Jing, M. Stys and D. Tam.
2004. Centroid-based summarization of multiple
documents. Information Processing and Man-
agement, 40: 919-938.
</reference>
<page confidence="0.897793">
1554
</page>
<reference confidence="0.987721296296296">
A. Siddharthan and K. McKeown. 2005. Improv-
ing multilingual summarization: using redun-
dancy in the input to correct MT errors. In
Proceedings of HLT/EMNLP-2005.
X. Wan, H. Li and J. Xiao. 2010. Cross-language
document summarization based on machine
translation quality prediction. In Proceedings of
ACL2010.
X. Wan, J. Yang and J. Xiao. 2006. Using cross-
document random walks for topic-focused
multi-documetn summarization. In Proceedings
of WI2006.
X. Wan and J. Yang. 2008. Multi-document sum-
marization using cluster-based link analysis. In
Proceedings of SIGIR-08.
X. Wan, J. Yang and J. Xiao. 2007. Towards an
Iterative Reinforcement Approach for Simulta-
neous Document Summarization and Keyword
Extraction. In Proceedings of ACL2007.
K.-F. Wong, M. Wu and W. Li. 2008. Extractive
summarization using supervised and semi-
supervised learning. In Proceedings of
COLING-08.
H. Y. Zha. 2002. Generic Summarization and Key-
phrase Extraction Using Mutual Reinforcement
Principle and Sentence Clustering. In Proceed-
ings of SIGIR2002.
</reference>
<page confidence="0.993938">
1555
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.783469">
<title confidence="0.999146">Using Bilingual Information for Cross-Language Summarization</title>
<author confidence="0.997311">Xiaojun Wan</author>
<affiliation confidence="0.937929">Institute of Compute Science and Technology, Peking University, Beijing 100871, China</affiliation>
<address confidence="0.899018">Key Laboratory of Computational Linguistics (Peking University), MOE, China</address>
<email confidence="0.990343">wanxiaojun@icst.pku.edu.cn</email>
<abstract confidence="0.99647755">Cross-language document summarization is defined as the task of producing a summary in a target language (e.g. Chinese) for a set of documents in a source language (e.g. English). Existing methods for addressing this task make use of either the information from the original documents in the source language or the information from the translated documents in the target language. In this study, we propose to use the bilingual information from both the source and translated documents for this task. Two summarization methods (SimFusion and CoRank) are proposed to leverage the bilingual information in the graph-based ranking framework for cross-language summary extraction. Experimental results on the DUC2001 dataset with manually translated reference Chinese summaries show the effectiveness of the proposed methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Aker</author>
<author>T Cohn</author>
<author>R Gaizauskas</author>
</authors>
<title>Multidocument summarization using A* search and discriminative training.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP2010.</booktitle>
<contexts>
<context position="7268" citStr="Aker et al. (2010)" startWordPosition="1071" endWordPosition="1074">cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a discriminative training algorithm for directly maximizing the quality of the best summary. Graph-based methods have also been used to rank sentences for multi-document summarization (Mihalcea and Tarau, 2005; Wan and Yang, 2008). 1547 2.2 Cross-Lingual Document Summarization Several pilot studies have investigated the task of cross-language document summarization. The existing methods use only the information in either language side. Two typical translation schemes are document translat</context>
</contexts>
<marker>Aker, Cohn, Gaizauskas, 2010</marker>
<rawString>A. Aker, T. Cohn, and R. Gaizauskas. 2010. Multidocument summarization using A* search and discriminative training. In Proceedings of EMNLP2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Amini</author>
<author>P Gallinari</author>
</authors>
<title>The Use of Unlabeled Data to Improve Supervised Learning for Text Summarization.</title>
<date>2002</date>
<booktitle>In Proceedings of SIGIR2002.</booktitle>
<contexts>
<context position="6094" citStr="Amini and Gallinari, 2002" startWordPosition="899" endWordPosition="902">tion methods can be extraction-based, abstraction-based or hybrid methods. We focus on extraction-based methods in this study, and the methods directly extract summary sentences from a document or document set by ranking the sentences in the document or document set. In the task of single document summarization, various features have been investigated for ranking sentences in a document, including term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machi</context>
</contexts>
<marker>Amini, Gallinari, 2002</marker>
<rawString>M. R. Amini, P. Gallinari. 2002. The Use of Unlabeled Data to Improve Supervised Learning for Text Summarization. In Proceedings of SIGIR2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G de Chalendar</author>
<author>R Besançon</author>
<author>O Ferret</author>
<author>G Grefenstette</author>
<author>O Mesnard</author>
</authors>
<title>Crosslingual summarization with thematic extraction, syntactic sentence simplification, and bilingual generation.</title>
<date>2005</date>
<booktitle>In Workshop on Crossing Barriers in Text Summarization Research, 5th International Conference on Recent Advances in Natural Language Processing (RANLP2005).</booktitle>
<marker>de Chalendar, Besançon, Ferret, Grefenstette, Mesnard, 2005</marker>
<rawString>G. de Chalendar, R. Besançon, O. Ferret, G. Grefenstette, and O. Mesnard. 2005. Crosslingual summarization with thematic extraction, syntactic sentence simplification, and bilingual generation. In Workshop on Crossing Barriers in Text Summarization Research, 5th International Conference on Recent Advances in Natural Language Processing (RANLP2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Celikyilmaz</author>
<author>D Hakkani-Tur</author>
</authors>
<title>A hybrid hierarchical model for multi-document summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010.</booktitle>
<contexts>
<context position="7092" citStr="Celikyilmaz and Hakkani-Tur (2010)" startWordPosition="1045" endWordPosition="1048">ciple (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a discriminative training algorithm for directly maximizing the quality of the best summary. Graph-based methods have also been used to rank sentences for multi-document summarization (Mihalcea and Tarau, 2005; Wan and Yang, 2008). 1547 2.2 Cross-Lingual Document Summarization Several pilot studies have investigated</context>
</contexts>
<marker>Celikyilmaz, Hakkani-Tur, 2010</marker>
<rawString>A. Celikyilmaz and D. Hakkani-Tur. 2010. A hybrid hierarchical model for multi-document summarization. In Proceedings of ACL2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LexPageRank</author>
</authors>
<title>Prestige in Multi-Document Text Summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP2004.</booktitle>
<marker>LexPageRank, 2004</marker>
<rawString>G. ErKan, D. R. Radev. LexPageRank. 2004. Prestige in Multi-Document Text Summarization. In Proceedings of EMNLP2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C D Manning</author>
</authors>
<title>Fast Exact Inference with a Factored Model for Natural Language Parsing.</title>
<date>2002</date>
<booktitle>In Proceedings of NIPS2002.</booktitle>
<marker>Klein, Manning, 2002</marker>
<rawString>D. Klein and C. D. Manning. 2002. Fast Exact Inference with a Factored Model for Natural Language Parsing. In Proceedings of NIPS2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kupiec</author>
<author>J Pedersen</author>
<author>F Chen</author>
</authors>
<title>A.Trainable Document Summarizer.</title>
<date>1995</date>
<booktitle>In Proceedings of SIGIR1995.</booktitle>
<contexts>
<context position="6066" citStr="Kupiec et al., 1995" startWordPosition="895" endWordPosition="898">on Document summarization methods can be extraction-based, abstraction-based or hybrid methods. We focus on extraction-based methods in this study, and the methods directly extract summary sentences from a document or document set by ranking the sentences in the document or document set. In the task of single document summarization, various features have been investigated for ranking sentences in a document, including term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroid</context>
</contexts>
<marker>Kupiec, Pedersen, Chen, 1995</marker>
<rawString>J. Kupiec, J. Pedersen, F. Chen. 1995. A.Trainable Document Summarizer. In Proceedings of SIGIR1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Leuski</author>
<author>C-Y Lin</author>
<author>L Zhou</author>
<author>U Germann</author>
<author>F J Och</author>
<author>E Hovy</author>
</authors>
<title>Cross-lingual C*ST*RD: English access to Hindi information.</title>
<date>2003</date>
<journal>ACM Transactions on Asian Language Information Processing,</journal>
<volume>2</volume>
<issue>3</issue>
<pages>245--269</pages>
<contexts>
<context position="8388" citStr="Leuski et al. (2003)" startWordPosition="1238" endWordPosition="1241"> only the information in either language side. Two typical translation schemes are document translation or summary translation. The document translation scheme first translates the source documents into the corresponding documents in the target language, and then extracts summary sentences based only on the information on the target side. The summary translation scheme first extracts summary sentences from the source documents based only on the information on the source side, and then translates the summary sentences into the corresponding summary sentences in the target language. For example Leuski et al. (2003) use machine translation for English headline generation for Hindi documents. Lim et al. (2004) propose to generate a Japanese summary by using Korean summarizer. Chalendar et al. (2005) focus on semantic analysis and sentence generation techniques for cross-language summarization. Orasan and Chiorean (2008) propose to produce summaries with the MMR method from Romanian news articles and then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. </context>
</contexts>
<marker>Leuski, Lin, Zhou, Germann, Och, Hovy, 2003</marker>
<rawString>A. Leuski, C.-Y. Lin, L. Zhou, U. Germann, F. J. Och, E. Hovy. 2003. Cross-lingual C*ST*RD: English access to Hindi information. ACM Transactions on Asian Language Information Processing, 2(3): 245-269.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-M Lim</author>
<author>I-S Kang</author>
<author>J-H Lee</author>
</authors>
<title>Multidocument summarization using cross-language texts.</title>
<date>2004</date>
<booktitle>In Proceedings of NTCIR-4.</booktitle>
<contexts>
<context position="8483" citStr="Lim et al. (2004)" startWordPosition="1252" endWordPosition="1255">ation or summary translation. The document translation scheme first translates the source documents into the corresponding documents in the target language, and then extracts summary sentences based only on the information on the target side. The summary translation scheme first extracts summary sentences from the source documents based only on the information on the source side, and then translates the summary sentences into the corresponding summary sentences in the target language. For example Leuski et al. (2003) use machine translation for English headline generation for Hindi documents. Lim et al. (2004) propose to generate a Japanese summary by using Korean summarizer. Chalendar et al. (2005) focus on semantic analysis and sentence generation techniques for cross-language summarization. Orasan and Chiorean (2008) propose to produce summaries with the MMR method from Romanian news articles and then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. Wan et al. (2010) adopt the summary translation scheme for the task of English-to-Chinese cross</context>
</contexts>
<marker>Lim, Kang, Lee, 2004</marker>
<rawString>J.-M. Lim, I.-S. Kang, J.-H. Lee. 2004. Multidocument summarization using cross-language texts. In Proceedings of NTCIR-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Y Lin</author>
<author>E Hovy</author>
</authors>
<title>The Automated Acquisition of Topic Signatures for Text Summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of the 17th Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="5980" citStr="Lin and Hovy, 2000" startWordPosition="882" endWordPosition="885">, we conclude this paper in Section 5. 2 Related Work 2.1 General Document Summarization Document summarization methods can be extraction-based, abstraction-based or hybrid methods. We focus on extraction-based methods in this study, and the methods directly extract summary sentences from a document or document set by ranking the sentences in the document or document set. In the task of single document summarization, various features have been investigated for ranking sentences in a document, including term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., </context>
</contexts>
<marker>Lin, Hovy, 2000</marker>
<rawString>C. Y. Lin, E. Hovy. 2000. The Automated Acquisition of Topic Signatures for Text Summarization. In Proceedings of the 17th Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y Lin</author>
<author>E H Hovy</author>
</authors>
<title>Automatic Evaluation of Summaries Using N-gram Cooccurrence Statistics.</title>
<date>2003</date>
<booktitle>In Proceedings of HLTNAACL -03.</booktitle>
<contexts>
<context position="20196" citStr="Lin and Hovy, 2003" startWordPosition="3223" endWordPosition="3226">verage F Baseline(EN) 0.03723 0.05566 0.13259 0.07177 Baseline(CN) 0.03805 0.05886 0.13871 0.07474 SimFusion 0.04017 0.06117 0.14362 0.07645 CoRank 0.04282 0.06158 0.14521 0.07805 Table 1: Comparison Results All the English sentences in the document set were automatically translated into Chinese sentences by using Google Translate, and the Stanford Chinese Word Segmenter2 was used for segmenting the Chinese documents and summaries into words. For comparative study, the summary length was limited to five sentences, i.e. each Chinese summary consisted of five sentences. We used the ROUGE-1.5.5 (Lin and Hovy, 2003) toolkit for evaluation, which has been widely adopted by DUC and TAC for automatic summarization evaluation. It measured summary quality by counting overlapping units such as the n-gram, word sequences and word pairs between the candidate summary and the reference summary. We showed three of the ROUGE F-measure scores in the experimental results: ROUGE-2 (bigrambased), ROUGE-W (based on weighted longest common subsequence, weight=1.2), ROUGE-L (based on longest common subsequences), and ROUGE-SU4 (based on skip bigram with a maximum skip distance of 4). Note that the ROUGE toolkit was perform</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>C.-Y. Lin and E.H. Hovy. 2003. Automatic Evaluation of Summaries Using N-gram Cooccurrence Statistics. In Proceedings of HLTNAACL -03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C-Y Lin</author>
<author>L Zhou</author>
<author>E Hovy</author>
</authors>
<title>Multilingual summarization evaluation 2005: automatic evaluation report.</title>
<date>2005</date>
<booktitle>In Proceedings of MSE (ACL2005 Workshop).</booktitle>
<contexts>
<context position="9375" citStr="Lin et al., 2005" startWordPosition="1383" endWordPosition="1386">n news articles and then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. Wan et al. (2010) adopt the summary translation scheme for the task of English-to-Chinese cross-language summarization. They first extract English summary sentences by using English-side features and the machine translation quality factor, and then automatically translate the English summary into Chinese summary. Other related work includes multilingual summarization (Lin et al., 2005; Siddharthan and McKeown, 2005), which aims to create summaries from multiple sources in multiple languages. 3 Our Proposed Methods As mentioned in Section 1, existing methods rely only on one-side information for sentence ranking, which is not very reliable. In order to leveraging both-side information for sentence ranking, we propose the following two methods to incorporate the bilingual information in different ways. 3.1 SimFusion This method uses the English-side information for Chinese sentence ranking in the graph-based framework. The sentence similarities in the two languages are fused</context>
</contexts>
<marker>Lin, Zhou, Hovy, 2005</marker>
<rawString>C.-Y. Lin, L. Zhou, and E. Hovy. 2005. Multilingual summarization evaluation 2005: automatic evaluation report. In Proceedings of MSE (ACL2005 Workshop).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Litvak</author>
<author>M Last</author>
<author>M Friedman</author>
</authors>
<title>A new approach to improving multilingual summarization using a genetic algorithm.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010.</booktitle>
<contexts>
<context position="6116" citStr="Litvak et al. (2010)" startWordPosition="903" endWordPosition="906">on-based, abstraction-based or hybrid methods. We focus on extraction-based methods in this study, and the methods directly extract summary sentences from a document or document set by ranking the sentences in the document or document set. In the task of single document summarization, various features have been investigated for ranking sentences in a document, including term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques</context>
</contexts>
<marker>Litvak, Last, Friedman, 2010</marker>
<rawString>M. Litvak, M. Last, and M. Friedman. 2010. A new approach to improving multilingual summarization using a genetic algorithm. In Proceedings of ACL2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Luhn</author>
</authors>
<title>The Automatic Creation of literature Abstracts.</title>
<date>1969</date>
<journal>IBM Journal of Research and Development,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="5959" citStr="Luhn 1969" startWordPosition="880" endWordPosition="881">n 4. Lastly, we conclude this paper in Section 5. 2 Related Work 2.1 General Document Summarization Document summarization methods can be extraction-based, abstraction-based or hybrid methods. We focus on extraction-based methods in this study, and the methods directly extract summary sentences from a document or document set by ranking the sentences in the document or document set. In the task of single document summarization, various features have been investigated for ranking sentences in a document, including term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based m</context>
</contexts>
<marker>Luhn, 1969</marker>
<rawString>H. P. Luhn. 1969. The Automatic Creation of literature Abstracts. IBM Journal of Research and Development, 2(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>TextRank: Bringing Order into Texts.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP2004.</booktitle>
<contexts>
<context position="6409" citStr="Mihalcea and Tarau, 2004" startWordPosition="946" endWordPosition="949">rious features have been investigated for ranking sentences in a document, including term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>R. Mihalcea, P. Tarau. 2004. TextRank: Bringing Order into Texts. In Proceedings of EMNLP2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>P Tarau</author>
</authors>
<title>A language independent algorithm for single and multiple document summarization.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP-05.</booktitle>
<contexts>
<context position="7584" citStr="Mihalcea and Tarau, 2005" startWordPosition="1120" endWordPosition="1123">s of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a discriminative training algorithm for directly maximizing the quality of the best summary. Graph-based methods have also been used to rank sentences for multi-document summarization (Mihalcea and Tarau, 2005; Wan and Yang, 2008). 1547 2.2 Cross-Lingual Document Summarization Several pilot studies have investigated the task of cross-language document summarization. The existing methods use only the information in either language side. Two typical translation schemes are document translation or summary translation. The document translation scheme first translates the source documents into the corresponding documents in the target language, and then extracts summary sentences based only on the information on the target side. The summary translation scheme first extracts summary sentences from the so</context>
</contexts>
<marker>Mihalcea, Tarau, 2005</marker>
<rawString>R. Mihalcea and P. Tarau. 2005. A language independent algorithm for single and multiple document summarization. In Proceedings of IJCNLP-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nenkova</author>
<author>A Louis</author>
</authors>
<title>Can you summarize this? Identifying correlates of input difficulty for generic multi-document summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08:HLT.</booktitle>
<contexts>
<context position="6804" citStr="Nenkova and Louis (2008)" startWordPosition="1006" endWordPosition="1009">ation based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a discriminative training alg</context>
</contexts>
<marker>Nenkova, Louis, 2008</marker>
<rawString>A. Nenkova and A. Louis. 2008. Can you summarize this? Identifying correlates of input difficulty for generic multi-document summarization. In Proceedings of ACL-08:HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Nenkova</author>
<author>R Passonneau</author>
<author>K McKeown</author>
</authors>
<title>The Pyramid method: incorporating human content selection variation in summarization evaluation.</title>
<date>2007</date>
<journal>ACM Transactions on Speech and Language Processing (TSLP),</journal>
<volume>4</volume>
<issue>2</issue>
<marker>Nenkova, Passonneau, McKeown, 2007</marker>
<rawString>A. Nenkova, R. Passonneau, and K. McKeown. 2007. The Pyramid method: incorporating human content selection variation in summarization evaluation. ACM Transactions on Speech and Language Processing (TSLP), 4(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Orasan</author>
<author>O A Chiorean</author>
</authors>
<title>Evaluation of a Crosslingual Romanian-English Multidocument Summariser.</title>
<date>2008</date>
<booktitle>In Proceedings of 6th Language Resources and Evaluation Conference (LREC2008).</booktitle>
<contexts>
<context position="8697" citStr="Orasan and Chiorean (2008)" startWordPosition="1282" endWordPosition="1285">n the information on the target side. The summary translation scheme first extracts summary sentences from the source documents based only on the information on the source side, and then translates the summary sentences into the corresponding summary sentences in the target language. For example Leuski et al. (2003) use machine translation for English headline generation for Hindi documents. Lim et al. (2004) propose to generate a Japanese summary by using Korean summarizer. Chalendar et al. (2005) focus on semantic analysis and sentence generation techniques for cross-language summarization. Orasan and Chiorean (2008) propose to produce summaries with the MMR method from Romanian news articles and then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. Wan et al. (2010) adopt the summary translation scheme for the task of English-to-Chinese cross-language summarization. They first extract English summary sentences by using English-side features and the machine translation quality factor, and then automatically translate the English summary into Chinese sum</context>
</contexts>
<marker>Orasan, Chiorean, 2008</marker>
<rawString>C. Orasan, and O. A. Chiorean. 2008. Evaluation of a Crosslingual Romanian-English Multidocument Summariser. In Proceedings of 6th Language Resources and Evaluation Conference (LREC2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pingali</author>
<author>J Jagarlamudi</author>
<author>V Varma</author>
</authors>
<title>Experiments in cross language query focused multi-document summarization.</title>
<date>2007</date>
<booktitle>In Workshop on Cross Lingual Information Access Addressing the Information Need of Multilingual Societies in IJCAI2007.</booktitle>
<contexts>
<context position="8924" citStr="Pingali et al., 2007" startWordPosition="1317" endWordPosition="1320">responding summary sentences in the target language. For example Leuski et al. (2003) use machine translation for English headline generation for Hindi documents. Lim et al. (2004) propose to generate a Japanese summary by using Korean summarizer. Chalendar et al. (2005) focus on semantic analysis and sentence generation techniques for cross-language summarization. Orasan and Chiorean (2008) propose to produce summaries with the MMR method from Romanian news articles and then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. Wan et al. (2010) adopt the summary translation scheme for the task of English-to-Chinese cross-language summarization. They first extract English summary sentences by using English-side features and the machine translation quality factor, and then automatically translate the English summary into Chinese summary. Other related work includes multilingual summarization (Lin et al., 2005; Siddharthan and McKeown, 2005), which aims to create summaries from multiple sources in multiple languages. 3 Our Proposed Methods As mentioned in </context>
</contexts>
<marker>Pingali, Jagarlamudi, Varma, 2007</marker>
<rawString>P. Pingali, J. Jagarlamudi and V. Varma. 2007. Experiments in cross language query focused multi-document summarization. In Workshop on Cross Lingual Information Access Addressing the Information Need of Multilingual Societies in IJCAI2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pitler</author>
<author>A Louis</author>
<author>A Nenkova</author>
</authors>
<title>Automatic evaluation of linguistic quality in multidocument summarization.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010.</booktitle>
<contexts>
<context position="6902" citStr="Pitler et al. (2010)" startWordPosition="1019" endWordPosition="1022"> In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a discriminative training algorithm for directly maximizing the quality of the best summary. Graph-based methods have also been</context>
</contexts>
<marker>Pitler, Louis, Nenkova, 2010</marker>
<rawString>E. Pitler, A. Louis, and A. Nenkova. 2010. Automatic evaluation of linguistic quality in multidocument summarization. In Proceedings of ACL2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D R Radev</author>
<author>H Y Jing</author>
<author>M Stys</author>
<author>D Tam</author>
</authors>
<title>Centroid-based summarization of multiple documents.</title>
<date>2004</date>
<journal>Information Processing and Management,</journal>
<volume>40</volume>
<pages>919--938</pages>
<contexts>
<context position="6585" citStr="Radev et al., 2004" startWordPosition="971" endWordPosition="974">nd Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative m</context>
</contexts>
<marker>Radev, Jing, Stys, Tam, 2004</marker>
<rawString>D. R. Radev, H. Y. Jing, M. Stys and D. Tam. 2004. Centroid-based summarization of multiple documents. Information Processing and Management, 40: 919-938.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Siddharthan</author>
<author>K McKeown</author>
</authors>
<title>Improving multilingual summarization: using redundancy in the input to correct MT errors.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP-2005.</booktitle>
<contexts>
<context position="9407" citStr="Siddharthan and McKeown, 2005" startWordPosition="1387" endWordPosition="1391">d then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. Wan et al. (2010) adopt the summary translation scheme for the task of English-to-Chinese cross-language summarization. They first extract English summary sentences by using English-side features and the machine translation quality factor, and then automatically translate the English summary into Chinese summary. Other related work includes multilingual summarization (Lin et al., 2005; Siddharthan and McKeown, 2005), which aims to create summaries from multiple sources in multiple languages. 3 Our Proposed Methods As mentioned in Section 1, existing methods rely only on one-side information for sentence ranking, which is not very reliable. In order to leveraging both-side information for sentence ranking, we propose the following two methods to incorporate the bilingual information in different ways. 3.1 SimFusion This method uses the English-side information for Chinese sentence ranking in the graph-based framework. The sentence similarities in the two languages are fused in the method. In other words, </context>
</contexts>
<marker>Siddharthan, McKeown, 2005</marker>
<rawString>A. Siddharthan and K. McKeown. 2005. Improving multilingual summarization: using redundancy in the input to correct MT errors. In Proceedings of HLT/EMNLP-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>H Li</author>
<author>J Xiao</author>
</authors>
<title>Cross-language document summarization based on machine translation quality prediction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL2010.</booktitle>
<contexts>
<context position="1294" citStr="Wan et al., 2010" startWordPosition="186" endWordPosition="189">e propose to use the bilingual information from both the source and translated documents for this task. Two summarization methods (SimFusion and CoRank) are proposed to leverage the bilingual information in the graph-based ranking framework for cross-language summary extraction. Experimental results on the DUC2001 dataset with manually translated reference Chinese summaries show the effectiveness of the proposed methods. 1 Introduction Cross-language document summarization is defined as the task of producing a summary in a different target language for a set of documents in a source language (Wan et al., 2010). In this study, we focus on English-to-Chinese cross-language summarization, which aims to produce Chinese summaries for English document sets. The task is very useful in the field of multilingual information access. For example, it is beneficial for most Chinese readers to quickly browse and understand English news documents or document sets by reading the corresponding Chinese summaries. A few pilot studies have investigated the task in recent years and exiting methods make use of either the information in the source language or the information in the target language after using machine tra</context>
<context position="9005" citStr="Wan et al. (2010)" startWordPosition="1331" endWordPosition="1334"> use machine translation for English headline generation for Hindi documents. Lim et al. (2004) propose to generate a Japanese summary by using Korean summarizer. Chalendar et al. (2005) focus on semantic analysis and sentence generation techniques for cross-language summarization. Orasan and Chiorean (2008) propose to produce summaries with the MMR method from Romanian news articles and then automatically translate the summaries into English. Cross language query based summarization has been investigated in (Pingali et al., 2007), where the query and the documents are in different languages. Wan et al. (2010) adopt the summary translation scheme for the task of English-to-Chinese cross-language summarization. They first extract English summary sentences by using English-side features and the machine translation quality factor, and then automatically translate the English summary into Chinese summary. Other related work includes multilingual summarization (Lin et al., 2005; Siddharthan and McKeown, 2005), which aims to create summaries from multiple sources in multiple languages. 3 Our Proposed Methods As mentioned in Section 1, existing methods rely only on one-side information for sentence rankin</context>
<context position="27034" citStr="Wan et al. (2010)" startWordPosition="4255" endWordPosition="4258">nd Future Work In this paper, we propose two methods (SimFusion and CoRank) to address the cross-language document summarization task by leveraging the bilingual information in both the source and target language sides. Evaluation results demonstrate the effectiveness of the proposed methods. The Chinese-side information is validated to be more beneficial than the English-side information, and the CoRank method is more robust than the SimFusion method. In future work, we will investigate to use the machine translation quality factor to further improve the fluency of the Chinese summary, as in Wan et al. (2010). Though our attempt to use GIZA++ for evaluating the similarity between Chinese sentences and English sentences failed, we will exploit more advanced measures based on statistical alignment model for cross-language similarity computation. Acknowledgments This work was supported by NSFC (60873155), Beijing Nova Program (2008B03) and NCET (NCET-08-0006). We thank the three students for translating the reference summaries. We also thank the anonymous reviewers for their useful comments. 1552 ROUGE-2(F) 0.042 0.038 0.036 0.034 0.032 0.04 0.03 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 λ SimFusion Ba</context>
</contexts>
<marker>Wan, Li, Xiao, 2010</marker>
<rawString>X. Wan, H. Li and J. Xiao. 2010. Cross-language document summarization based on machine translation quality prediction. In Proceedings of ACL2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
<author>J Xiao</author>
</authors>
<title>Using crossdocument random walks for topic-focused multi-documetn summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of WI2006.</booktitle>
<contexts>
<context position="12502" citStr="Wan et al. (2006)" startWordPosition="1900" endWordPosition="1903">e(scni) for sentence scni can be deduced from those of all other sentences linked with it and it can be formulated in a recursive form as in the PageRank algorithm: 1548 ~InfoScore(s&apos;) =μ InfoScore(s&apos; ) ⋅ M ji + (1− μ) n all j i ≠ where n is the sentence number, i.e. n= |Vcn|. μ is the damping factor usually set to 0.85, as in the PageRank algorithm. For numerical computation of the saliency scores, we can iteratively run the above equation until convergence. For multi-document summarization, some sentences are highly overlapping with each other, and thus we apply the same greedy algorithm in Wan et al. (2006) to penalize the sentences highly overlapping with other highly scored sentences, and finally the salient and novel Chinese sentences are directly selected as summary sentences. 3.2 CoRank This method leverages both the English-side information and the Chinese-side information in a co-ranking way. The source English sentences and the translated Chinese sentences are simultaneously ranked in a unified graph-based algorithm. The saliency of each English sentence relies not only on the English sentences linked with it, but also on the Chinese sentences linked with it. Similarly, the saliency of e</context>
</contexts>
<marker>Wan, Yang, Xiao, 2006</marker>
<rawString>X. Wan, J. Yang and J. Xiao. 2006. Using crossdocument random walks for topic-focused multi-documetn summarization. In Proceedings of WI2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
</authors>
<title>Multi-document summarization using cluster-based link analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGIR-08.</booktitle>
<contexts>
<context position="7605" citStr="Wan and Yang, 2008" startWordPosition="1124" endWordPosition="1127">automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a discriminative training algorithm for directly maximizing the quality of the best summary. Graph-based methods have also been used to rank sentences for multi-document summarization (Mihalcea and Tarau, 2005; Wan and Yang, 2008). 1547 2.2 Cross-Lingual Document Summarization Several pilot studies have investigated the task of cross-language document summarization. The existing methods use only the information in either language side. Two typical translation schemes are document translation or summary translation. The document translation scheme first translates the source documents into the corresponding documents in the target language, and then extracts summary sentences based only on the information on the target side. The summary translation scheme first extracts summary sentences from the source documents based </context>
</contexts>
<marker>Wan, Yang, 2008</marker>
<rawString>X. Wan and J. Yang. 2008. Multi-document summarization using cluster-based link analysis. In Proceedings of SIGIR-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wan</author>
<author>J Yang</author>
<author>J Xiao</author>
</authors>
<title>Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL2007.</booktitle>
<contexts>
<context position="6492" citStr="Wan et al., 2007" startWordPosition="958" endWordPosition="961">requency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010)</context>
</contexts>
<marker>Wan, Yang, Xiao, 2007</marker>
<rawString>X. Wan, J. Yang and J. Xiao. 2007. Towards an Iterative Reinforcement Approach for Simultaneous Document Summarization and Keyword Extraction. In Proceedings of ACL2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-F Wong</author>
<author>M Wu</author>
<author>W Li</author>
</authors>
<title>Extractive summarization using supervised and semisupervised learning.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING-08.</booktitle>
<contexts>
<context position="6778" citStr="Wong et al., 2008" startWordPosition="1002" endWordPosition="1005"> extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and Hakkani-Tur (2010) formulate extractive summarization as a two-step learning problem by building a generative model for pattern discovery and a regression model for inference. Aker et al. (2010) propose an A* search algorithm to find the best extractive summary up to a given length, and they propose a d</context>
</contexts>
<marker>Wong, Wu, Li, 2008</marker>
<rawString>K.-F. Wong, M. Wu and W. Li. 2008. Extractive summarization using supervised and semisupervised learning. In Proceedings of COLING-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Y Zha</author>
</authors>
<title>Generic Summarization and Keyphrase Extraction Using Mutual Reinforcement Principle and Sentence Clustering.</title>
<date>2002</date>
<booktitle>In Proceedings of SIGIR2002.</booktitle>
<contexts>
<context position="6473" citStr="Zha 2002" startWordPosition="956" endWordPosition="957">ing term frequency, sentence position, cue words, stigma words, and topic signature (Luhn 1969; Lin and Hovy, 2000). Machine learning techniques have been used for sentence ranking (Kupiec et al., 1995; Amini and Gallinari, 2002). Litvak et al. (2010) present a language-independent approach for extractive summarization based on the linear optimization of several sentence ranking measures using a genetic algorithm. In recent years, graph-based methods have been proposed for sentence ranking (Erkan and Radev, 2004; Mihalcea and Tarau, 2004). Other methods include mutual reinforcement principle (Zha 2002; Wan et al., 2007). In the task of multi-document summarization, the centroid-based method (Radev et al., 2004) ranks the sentences in a document set based on such features as cluster centroids, position and TFIDF. Machine Learning techniques have also been used for feature combining (Wong et al., 2008). Nenkova and Louis (2008) investigate the influences of input difficulty on summarization performance. Pitler et al. (2010) present a systematic assessment of several diverse classes of metrics designed for automatic evaluation of linguistic quality of multi-document summaries. Celikyilmaz and</context>
</contexts>
<marker>Zha, 2002</marker>
<rawString>H. Y. Zha. 2002. Generic Summarization and Keyphrase Extraction Using Mutual Reinforcement Principle and Sentence Clustering. In Proceedings of SIGIR2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>