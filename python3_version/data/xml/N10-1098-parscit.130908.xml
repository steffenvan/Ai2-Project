<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.024947">
<title confidence="0.990657">
Engaging learning groups using Social Interaction Strategies
</title>
<author confidence="0.990143">
Rohit Kumar Carolyn P. Rosé
</author>
<affiliation confidence="0.987925">
Language Technologies Institute
Carnegie Mellon University, Pittsburgh, PA, 15213
</affiliation>
<email confidence="0.997136">
rohitk@cs.cmu.edu cprose@cs.cmu.edu
</email>
<sectionHeader confidence="0.997412" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996618133333333">
Conversational Agents have been shown to be
effective tutors in a wide range of educational
domains. However, these agents are often ig-
nored and abused in collaborative learning
scenarios involving multiple students. In our
work presented here, we design and evaluate
interaction strategies motivated from prior re-
search in small group communication. We
will discuss how such strategies can be im-
plemented in agents. As a first step towards
evaluating agents that can interact socially, we
report results showing that human tutors em-
ploying these strategies are able to cover more
concepts with the students besides being rated
as better integrated, likeable and friendlier.
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99974412195122">
Conversational Agents (CAs) are autonomous in-
terfaces that interact with users via spoken or writ-
ten conversation. One of the applications of CAs is
tutoring. Various research groups have developed
tutoring agents in domains like reading, algebra,
geometry, calculus, physics, computer literacy,
programming, foreign languages, research methods
and thermodynamics. Many of the evaluations
show that CAs can be effective tutors (Arnott et.
al., 2008; Kumar et. al., 2007; Graesser et. al.,
2005).
Most systems that use CAs as tutors have been
built for learning scenarios involving one student.
Evaluation of learning technologies involving stu-
dents working in groups with interactive agents has
shown that learners are helped both by learning as
a group and receiving tutorials from agents (Kumar
et. al., 2007). However, some previous studies
have reported that students learning in groups ig-
nore the tutor’s messages, unlike the case where
students are individually tutored. Groups are more
likely to abuse tutors than individual students.
We reason that the presence of other students in
collaborative learning scenarios causes the agents
to compete for the attention of the students. Since
the agents are not adept at performing social inter-
active behavior, which makes up the bulk of for-
mative communication in a group, they are quickly
pushed to the periphery of the group.
Research on small group communication has
identified twelve interaction categories that are
commonly observed in small groups (Bales, 1950).
These categories are broadly classified into task
and social-emotional categories. Content presented
by most current CAs mostly classifies under the
task categories. In section 2, we will list the con-
versational strategies motivated from the three pos-
itive social-emotional interaction categories.
Thereafter, the implementation and evaluation of a
CA that interleaves these social interaction strate-
gies while executing a task plan will be described.
</bodyText>
<sectionHeader confidence="0.990598" genericHeader="method">
2 Social Interaction Strategies
</sectionHeader>
<bodyText confidence="0.999680928571429">
Balesian methodology (Bales, 1950) identifies
three positive social-emotional interaction catego-
ries: showing solidarity, showing tension release
and agreeing. Participants contribute turns of these
categories to address the problems of re-
integration, tension release and decision respec-
tively. We have mapped these categories to practi-
cally implementable conversational strategies. This
mapping is shown in table 1 ahead.
Each strategy is implemented as an instantiation
of a conversational behavior. Most of the strategies
listed in Table 1 are realized as prompts, triggered
by rules based on agent plan, discourse and context
features. For example, strategy 1e is triggered
</bodyText>
<page confidence="0.977984">
677
</page>
<subsubsectionHeader confidence="0.57635">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 677–680,
</subsubsectionHeader>
<subsectionHeader confidence="0.276441">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999914285714286">
when one or more students in the group are found
to be inactive for over 5 minutes. In this event, the
tutor chooses to raise the status of the inactive stu-
dents by eliciting contributions from them through
a prompt like: Do you have any suggestions Mike?
More implementation details of these strategies
and triggers are discussed in the following section.
</bodyText>
<figure confidence="0.828761111111111">
1. Showing Solidarity
Raises other&apos;s status, gives help, reward
1a. Do Introductions
Introduce and ask names of all participants
1b. Be Protective &amp; Nurturing
Discourage teasing
1c. Give Re-assurance
When student is discontent, asking for help
1d. Complement / Praise
To acknowledge student contributions
1e. Encourage
When group or members are inactive
1f. Conclude Socially
2. Showing Tension Release
Jokes, laughs, shows satisfaction
2a. Expression of feeling better
After periods of tension, work pressure
2b. Be cheerful
2c. Express enthusiasm, elation, satisfaction
On completing significant steps of the task
3. Agreeing
Shows passive acceptance, understands,
concurs, complies
3a. Show attention
To student ideas as encouragement
3b. Show comprehension / approval
To student opinions and orientations
</figure>
<tableCaption confidence="0.988567">
Table 1. Social Interaction Strategies for three
</tableCaption>
<bodyText confidence="0.54771">
social-emotional interaction categories
</bodyText>
<sectionHeader confidence="0.995051" genericHeader="method">
3 WrenchTalker: Implementation
</sectionHeader>
<bodyText confidence="0.9999138">
WrenchTalker is a CA we have built to employ the
social interaction strategies listed in section 2. It
helps teams of engineering students learn and ap-
ply basic concepts of mechanical stress while they
participate in a freshmen lab project to design an
aluminum wrench. Students can interact with this
agent using a text-based chat environment.
The agent is built using the Basilica architecture
(Kumar and Rosé, 2009). Under this architecture,
CAs are modeled as a network of behavioral
components. There are three types of components:
actors (actuators / performers), filters (perceptors /
annotators / cordinators) and memories. Figure 1
below shows a simplified depiction of the
WrenchTalker component network.
</bodyText>
<figureCaption confidence="0.997925">
Figure 1. Component Network of WrenchTalker
</figureCaption>
<bodyText confidence="0.999920769230769">
Three of the actor and filter components
correspond to three observable behaviors of the
tutor, i.e., Introducing (ai, fi), Prompting (ap, fp) and
Tutoring (at, ft). Most of the other filter
components form a sub-network that annotates
turns with applicable semantic categories,
accumulates them to identify inactive students and
generates events that regulate the controllers.
The plan controller (fplan) is responsible for
executing the agent’s interaction plan, which is
comprised of 37 steps. The plan is executed largely
sequentially; however the plan controller can
choose to skip some steps in the interest of time. In
the experiment described in section 5, the same
plan controller is used in all three conditions. The
social controller (fsocial) implements the 12
strategies listed earlier. The strategies are triggered
by rules based on combinations of three
conditions: the last executed plan step, semantic
categories associated with the most recent student
turns and the ratio of tutor turns generated by fsocial
to fplan. The first two conditions attempt to ensure
that social behavior is suitable in the current
conversational context and the third condition
regulates the amount of social behavior by the CA.
The plan and social controllers are connected so
that they regulate each other. For instance, when
the plan controller is working, it blocks fsocial. Upon
completion of the blocking step, fsocial is given
control, which can then choose to perform a
strategy by blocking fplan before it progresses to the
next step. Reflex strategies like 1b are not blocked.
Once the controllers determine a step or a strat-
egy that is to be generated, the actors generate their
turns. For example, strategy 1a is generated by ac-
tor ai after it is triggered by the social controller.
We note that Basilica provides the flexibility to
build complicated pipelines, as demonstrated in
this case by the use of two controllers.
</bodyText>
<page confidence="0.997867">
678
</page>
<sectionHeader confidence="0.999952" genericHeader="method">
4 Related Work
</sectionHeader>
<bodyText confidence="0.99997235">
To contextualize our research with other work on
CAs, we classify agents with the social interaction
strategies listed in Table 1 as social interfaces fol-
lowing the taxonomy proposed by Isbister (2002).
Within this class of CAs, researchers have investi-
gated the technical challenges and effects of con-
versational behavior that are similar in motivation
to the ones we are exploring. Bickmore et. al.
(2009) report that users found agents with autobio-
graphies, i.e., back stories in first person more en-
joyable and they completed more conversations
with such agents. Dybala et. al. (2009) found that
agents equipped with humor were evaluated as
more human-like, funny and likeable. In a multi-
party conversational scenario, Dohsaka et. al.
(2009) found that an agent’s use of emphatic ex-
pressions improved user satisfaction and user rat-
ing of the agent. We note that use of CAs as social
interfaces has been found to have effects on both
performance and perception metrics.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="method">
5 Experimental Design
</sectionHeader>
<bodyText confidence="0.999962212765957">
In order to evaluate the effect of social interaction
strategies listed in Table 1, we designed an expe-
riment with three conditions. In the experimental
condition (Social), students interacted with an
agent that was equipped with our social interaction
strategies, unlike the control condition (Task). In
the third condition, a human tutor was allowed to
intervene while the students interacted with a Task
agent. In all three conditions, students go through
the same task plan. However, the degree of social
performance is varied from minimal (Task) to ideal
(Human). We hypothesize that the human and so-
cial agents will be rated better than the Task agent.
We conducted a between subjects experiment
during a freshmen computer aided engineering lab.
98 students participated in the experiment, which
was held over six sessions spread evenly between
two days. The two days of the experiment were
separated by two weeks. Students were grouped
into teams of three to four individuals. Students
were grouped so that no two members of the same
team sat next to each other during the lab, to en-
sure all communication was recorded. The teams
were distributed between the three conditions.
Each session started with a follow-along tutori-
al of computer-aided analysis where the students
analyzed a wrench they had designed earlier. The
experimental manipulation happened during a col-
laborative design competition after the tutorial.
Students were asked to work as a team to design a
better wrench considering three aspects: ease of
use, cost and safety. Students were instructed to
make three new designs and calculate success
measures of each of the three considerations. They
were also told that a tutor will help them with two
designs so that they are well-prepared to do the
final design. No additional details about the tutor
were given. The students communicated with each
other and with the tutors using ConcertChat, an on-
line environment that provides text-based instant
messaging and workspace sharing facilities.
After spending 30-35 minutes on the design
competition, each student filled out a question-
naire. It was comprised of eighteen questions on a
seven point Likert-scale ranging from Strongly
Disagree (1) to Strongly Agree (7). The questions
were designed to elicit four types of ratings.
</bodyText>
<listItem confidence="0.999957">
• Ratings about the tutor
• Ratings about the other team members
• Ratings about the design task
• Ratings about the team functioning
</listItem>
<bodyText confidence="0.999862333333333">
The questions in the first two classes elicited
perceived liking and integration and checked
whether the students noticed the tutor’s display of
the social interaction strategies. Task related ques-
tions asked about satisfaction, perceived legitimacy
and discussion quality.
</bodyText>
<sectionHeader confidence="0.999897" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.96854925">
Table 2 below shows the mean values for ques-
tionnaire categories apart from ratings about team
members, since there were no significant effects
related to those questions.
</bodyText>
<table confidence="0.998601">
D1 D2 T S H
Integration 3.85 3.94 3.03 3.94 4.77
Liking 3.68 3.63 2.78 3.53 4.73
Friendly 5.13 5.43 4.47 5.56 5.83
T.Releasing 4.49 4.63 3.84 4.61 5.27
Agreeing 4.30 4.45 3.97 4.44 4.73
Satisfaction 4.66 5.77 5.09 4.75 5.97
</table>
<tableCaption confidence="0.9944775">
Table 2. Mean outcomes per condition ((T)ask,(S)ocial,
(H)uman) and per day (Day1, and Day2)
</tableCaption>
<bodyText confidence="0.890201">
The means are highlighted appropriately
(p&lt;0.001, p&lt;0.05, p&lt;0.08) to indicate significant
</bodyText>
<page confidence="0.998431">
679
</page>
<bodyText confidence="0.999749368421053">
differences from Day1 to Day2 and between the
Task condition and each of the other two using a
pairwise Tukey comparison.
First of all, we note that there is a significant
difference in task satisfaction between the two
days. We fine-tuned the timing parameters of the
plan controller after day 1 so that the students had
sufficient time to follow along with each of the
steps. This was particularly useful for the task con-
dition where the steps would be executed rapidly
due to lack of regulation by the social controller.
On the right side of Table 2, we notice that the
human tutors (H) were rated higher on being part
of the team (Integration), being more liked, being
friendlier and keeping the group more socially
comfortable (T.Releasing). On the other hand, the
social tutors (S) were rated to be friendlier and
were only marginally better at being seen as part of
the team.
</bodyText>
<table confidence="0.997722428571429">
Strategy Social Human
Introducing 1a 2.67 3.80
Friendly 1b-1e 5.61 8.10
Concluding 1f 0.97 1.80
T.Releasing 2a-2c 5.81 1.77
Agreeing 3a-3b 1.78 4.90
Sum 16.83 22.17
</table>
<tableCaption confidence="0.999869">
Table 3. Mean counts of social turns by tutor
</tableCaption>
<bodyText confidence="0.999981181818182">
Note that human tutors were restricted to exhi-
bit only social behaviors, which were displayed in
addition to the same task related content given to
students in the other two conditions. Clearly, the
human tutors were better at employing the social
interaction strategies. To further investigate this,
we compare the number of turns corresponding to
the broad categories of strategies in Table 3. Hu-
man tutors performed significantly more (p&lt;0.001)
social turns than the automated tutors in all strate-
gies except showing tension release.
</bodyText>
<sectionHeader confidence="0.999505" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999992428571428">
In order to make CAs that can participate in multi-
party conversational scenarios, the agents must be
able to employ Social Interaction Strategies. Here
we have shown that the human tutors that use these
strategies are better integrated into the group, and
are considered more likeable and friendlier. These
tutors also cover more steps and concepts and take
less time to tutor the concepts, suggesting that the
students are more engaged and responsive to them.
On the other hand, automated tutors that employ
these strategies in our current implementation do
not show significant differences compared to task
tutor.
We note a contrast between the performance of
the human and the automated tutors with respect to
the frequency with which they employ these strat-
egies. Besides the frequent use of these strategies,
we believe human tutors were better at identifying
opportunities for employing these strategies, and
they are able to customize the prompt to better suit
the discourse context.
</bodyText>
<sectionHeader confidence="0.99893" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9853505">
The research was supported by NSF grant number
DUE 837661
</bodyText>
<sectionHeader confidence="0.999209" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999708363636364">
Elizabeth Arnott, Peter Hastings and David Allbritton,
2008, Research Methods Tutor: Evaluation of a di-
alogue-based tutoring system in the classroom, Beha-
vior Research Methods, 40 (3), 694-698
Robert F. Bales, 1950, Interaction process analysis: A
method for the study of small groups, Addison-
Wesley, Cambridge, MA
Timothy Bickmore, Daniel Schulman and Langxuan
Yin, Engagement vs. Deceit: Virtual Humans with
Human Autobiographies, 2009, IVA, Amsterdam
Kohji Dohsaka, Ryoto Asai, Ryichiro Higashinaka, Ya-
suhiro Minami and Eisaku Maeda, Effects of Con-
versational Agents on Human Communication in
Though Evoking Multi-Party dialogues, 2009, 10th
Annual SigDial, London, UK
Pawel Dybala, Michal Ptaszynski, Rafal Rzepka and
Kenji Araki, Humoroids: Conversational Agents that
induce positive emotions with humor, 2009, AAMAS,
Budapest, Hungary
Arthur C. Graesser, Patrick Chipman, Brian C. Haynes,
and Andrew Olney, 2005, AutoTutor: An Intelligent
Tutoring System with Mixed-initiative Dialogue,
IEEE Transactions in Education, 48, 612-618
Katherine Isbister and Patrick Doyle, Design and Evalu-
ation of Embodied Conversational Agents: A Pro-
posed Taxonomy, 2002, AAMAS Workshop:
Embodied Conversational Agents, Bologna, Italy
Rohit Kumar, Carolyn Rosé, Mahesh Joshi, Yi-Chia
Wang, Yue Cui and Allen Robinson, Tutorial Dialo-
gue as Adaptive Collaborative Learning Support,
13th AIED 2007, Los Angeles, California
Rohit Kumar, Carolyn Rosé, Building Conversational
Agents with Basilica, 2009, NAACL, Boulder, CO
</reference>
<page confidence="0.997659">
680
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.788160">
<title confidence="0.999952">Engaging learning groups using Social Interaction Strategies</title>
<author confidence="0.990285">Rohit Kumar Carolyn P Rosé</author>
<affiliation confidence="0.822104">Language Technologies</affiliation>
<address confidence="0.97026">Carnegie Mellon University, Pittsburgh, PA, 15213</address>
<email confidence="0.997968">rohitk@cs.cmu.educprose@cs.cmu.edu</email>
<abstract confidence="0.99820675">Conversational Agents have been shown to be effective tutors in a wide range of educational domains. However, these agents are often ignored and abused in collaborative learning scenarios involving multiple students. In our work presented here, we design and evaluate interaction strategies motivated from prior research in small group communication. We will discuss how such strategies can be implemented in agents. As a first step towards evaluating agents that can interact socially, we report results showing that human tutors employing these strategies are able to cover more concepts with the students besides being rated as better integrated, likeable and friendlier.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Elizabeth Arnott</author>
<author>Peter Hastings</author>
<author>David Allbritton</author>
</authors>
<title>Research Methods Tutor: Evaluation of a dialogue-based tutoring system in the classroom,</title>
<date>2008</date>
<journal>Behavior Research Methods,</journal>
<volume>40</volume>
<issue>3</issue>
<pages>694--698</pages>
<marker>Arnott, Hastings, Allbritton, 2008</marker>
<rawString>Elizabeth Arnott, Peter Hastings and David Allbritton, 2008, Research Methods Tutor: Evaluation of a dialogue-based tutoring system in the classroom, Behavior Research Methods, 40 (3), 694-698</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert F Bales</author>
</authors>
<title>Interaction process analysis: A method for the study of small groups,</title>
<date>1950</date>
<publisher>AddisonWesley,</publisher>
<location>Cambridge, MA</location>
<contexts>
<context position="2425" citStr="Bales, 1950" startWordPosition="360" endWordPosition="361">’s messages, unlike the case where students are individually tutored. Groups are more likely to abuse tutors than individual students. We reason that the presence of other students in collaborative learning scenarios causes the agents to compete for the attention of the students. Since the agents are not adept at performing social interactive behavior, which makes up the bulk of formative communication in a group, they are quickly pushed to the periphery of the group. Research on small group communication has identified twelve interaction categories that are commonly observed in small groups (Bales, 1950). These categories are broadly classified into task and social-emotional categories. Content presented by most current CAs mostly classifies under the task categories. In section 2, we will list the conversational strategies motivated from the three positive social-emotional interaction categories. Thereafter, the implementation and evaluation of a CA that interleaves these social interaction strategies while executing a task plan will be described. 2 Social Interaction Strategies Balesian methodology (Bales, 1950) identifies three positive social-emotional interaction categories: showing soli</context>
</contexts>
<marker>Bales, 1950</marker>
<rawString>Robert F. Bales, 1950, Interaction process analysis: A method for the study of small groups, AddisonWesley, Cambridge, MA</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Bickmore</author>
<author>Daniel Schulman</author>
<author>Langxuan Yin</author>
</authors>
<title>Engagement vs. Deceit: Virtual Humans with Human Autobiographies,</title>
<date>2009</date>
<location>IVA, Amsterdam</location>
<marker>Bickmore, Schulman, Yin, 2009</marker>
<rawString>Timothy Bickmore, Daniel Schulman and Langxuan Yin, Engagement vs. Deceit: Virtual Humans with Human Autobiographies, 2009, IVA, Amsterdam</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kohji Dohsaka</author>
</authors>
<title>Ryoto Asai, Ryichiro Higashinaka, Yasuhiro Minami and Eisaku Maeda,</title>
<booktitle>Effects of Conversational Agents on Human Communication in Though Evoking Multi-Party dialogues, 2009, 10th Annual SigDial,</booktitle>
<location>London, UK</location>
<marker>Dohsaka, </marker>
<rawString>Kohji Dohsaka, Ryoto Asai, Ryichiro Higashinaka, Yasuhiro Minami and Eisaku Maeda, Effects of Conversational Agents on Human Communication in Though Evoking Multi-Party dialogues, 2009, 10th Annual SigDial, London, UK</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pawel Dybala</author>
<author>Michal Ptaszynski</author>
</authors>
<title>Rafal Rzepka and Kenji Araki, Humoroids: Conversational Agents that induce positive emotions with humor,</title>
<date>2009</date>
<location>AAMAS, Budapest, Hungary</location>
<marker>Dybala, Ptaszynski, 2009</marker>
<rawString>Pawel Dybala, Michal Ptaszynski, Rafal Rzepka and Kenji Araki, Humoroids: Conversational Agents that induce positive emotions with humor, 2009, AAMAS, Budapest, Hungary</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur C Graesser</author>
<author>Patrick Chipman</author>
<author>Brian C Haynes</author>
<author>Andrew Olney</author>
</authors>
<title>AutoTutor: An Intelligent Tutoring System with Mixed-initiative Dialogue,</title>
<date>2005</date>
<journal>IEEE Transactions in Education,</journal>
<volume>48</volume>
<pages>612--618</pages>
<marker>Graesser, Chipman, Haynes, Olney, 2005</marker>
<rawString>Arthur C. Graesser, Patrick Chipman, Brian C. Haynes, and Andrew Olney, 2005, AutoTutor: An Intelligent Tutoring System with Mixed-initiative Dialogue, IEEE Transactions in Education, 48, 612-618</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine Isbister</author>
<author>Patrick Doyle</author>
</authors>
<title>Design and Evaluation of Embodied Conversational Agents: A Proposed Taxonomy,</title>
<date>2002</date>
<location>Bologna, Italy</location>
<marker>Isbister, Doyle, 2002</marker>
<rawString>Katherine Isbister and Patrick Doyle, Design and Evaluation of Embodied Conversational Agents: A Proposed Taxonomy, 2002, AAMAS Workshop: Embodied Conversational Agents, Bologna, Italy</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit Kumar</author>
<author>Carolyn Rosé</author>
<author>Mahesh Joshi</author>
<author>Yi-Chia Wang</author>
<author>Yue Cui</author>
<author>Allen Robinson</author>
</authors>
<date>2007</date>
<booktitle>Tutorial Dialogue as Adaptive Collaborative Learning Support, 13th AIED</booktitle>
<location>Los Angeles, California</location>
<marker>Kumar, Rosé, Joshi, Wang, Cui, Robinson, 2007</marker>
<rawString>Rohit Kumar, Carolyn Rosé, Mahesh Joshi, Yi-Chia Wang, Yue Cui and Allen Robinson, Tutorial Dialogue as Adaptive Collaborative Learning Support, 13th AIED 2007, Los Angeles, California</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit Kumar</author>
</authors>
<title>Carolyn Rosé, Building Conversational Agents with Basilica,</title>
<date>2009</date>
<location>NAACL, Boulder, CO</location>
<marker>Kumar, 2009</marker>
<rawString>Rohit Kumar, Carolyn Rosé, Building Conversational Agents with Basilica, 2009, NAACL, Boulder, CO</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>