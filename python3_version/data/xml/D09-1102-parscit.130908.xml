<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.995025">
Global Learning of Noun Phrase Anaphoricity in Coreference Resolu-
tion via Label Propagation
</title>
<author confidence="0.954147">
ZHOU GuoDong KONG Fang
</author>
<affiliation confidence="0.91105">
JiangSu Provincial Key Lab for Computer Information Processing Technology
School of Computer Science and Technology
</affiliation>
<address confidence="0.828386">
Soochow University. Suzhou, China 215006
</address>
<email confidence="0.998994">
Email:{gdzhou,kongfang}@suda.edu.cn
</email>
<sectionHeader confidence="0.993891" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999614238095238">
Knowledge of noun phrase anaphoricity might
be profitably exploited in coreference resolu-
tion to bypass the resolution of non-anaphoric
noun phrases. However, it is surprising to no-
tice that recent attempts to incorporate auto-
matically acquired anaphoricity information
into coreference resolution have been some-
what disappointing. This paper employs a
global learning method in determining the
anaphoricity of noun phrases via a label
propagation algorithm to improve learning-
based coreference resolution. In particular,
two kinds of kernels, i.e. the feature-based
RBF kernel and the convolution tree kernel,
are employed to compute the anaphoricity
similarity between two noun phrases. Experi-
ments on the ACE 2003 corpus demonstrate
the effectiveness of our method in anaphoric-
ity determination of noun phrases and its ap-
plication in learning-based coreference resolu-
tion.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975573770492">
Coreference resolution, the task of determining
which noun phrases (NPs) in a text refer to the
same real-world entity, has long been considered
an important and difficult problem in natural
language processing. Identifying the linguistic
constraints on when two NPs can co-refer re-
mains an active area of research in the commu-
nity. One significant constraint on coreference,
the anaphoricity constraint, specifies that a non-
anaphoric NP cannot be coreferent with any of
its preceding NPs in a given text. Therefore, it is
useful to skip over these non-anaphoric NPs
rather than attempt an unnecessary search for an
antecedent for them, only to end up with inaccu-
rate outcomes. Although many existing machine
learning approaches to coreference resolution
have performed reasonably well without explicit
anaphoricity determination (e.g., Soon et al 2001;
Ng and Cardie 2002b; Strube and Muller 2003;
Yang et al 2003, 2008), anaphoricity determina-
tion has been studied fairly extensively in the
literature, given the potential usefulness of NP
anaphoricity in coreference resolution. One
common approach involves the design of heuris-
tic rules to identify specific types of non-
anaphoric NPs, such as pleonastic pronouns (e.g.
Paice and Husk 1987; Lappin and Leass 1994;
Kennedy and Boguraev 1996; Denber 1998) and
existential definite descriptions (e.g., Vieira and
Poesio 2000). More recently, the problem has
been tackled using statistics-based (e.g., Bean
and Riloff 1999; Bergsma et al 2008) and learn-
ing-based (e.g. Evans 2001; Ng and Cardie
2002a; Ng 2004; Yang et al 2005; Denis and
Balbridge 2007) methods. Although there is em-
pirical evidence (e.g. Ng and Cardie 2002a,
2004) that coreference resolution might be fur-
ther improved with proper anaphoricity informa-
tion, its contribution is still somewhat disap-
pointing and lacks systematic evaluation.
This paper employs a label propagation (LP)
algorithm for global learning of NP anaphoricity.
Given the labeled data and the unlabeled data,
the LP algorithm first represents labeled and
unlabeled instances as vertices in a connected
graph, then propagates the label information
from any vertex to nearby vertices through
weighted edges and finally infers the labels of
unlabeled instances until a global stable stage is
achieved. Here, the labeled data in this paper
include all the NPs in the training texts with the
anaphoricity labeled and the unlabeled data in-
clude all the NPs in a test text with the ana-
phoricity unlabeled. One major advantage of LP-
based anaphoricity determination is that the ana-
phoricity of all the NPs in a text can be deter-
mined together in a global way. Compared with
previous methods, the LP algorithm can effec-
tively capture the natural clustering structure in
both the labeled and unlabeled data to smooth
the labeling function. In particular, two kinds of
</bodyText>
<page confidence="0.967602">
978
</page>
<note confidence="0.9966095">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 978–986,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.999968222222222">
kernels, i.e. the feature-based RBF kernel and
the convolution tree kernel, are employed to
compute the anaphoricity similarity between two
NPs and weigh the edge between them. Experi-
ments on the ACE 2003 corpus show that our
LP-based anaphoricity determination signifi-
cantly outperforms locally-optimized one, which
adopts a classifier (e.g. SVM) to determine the
anaphoricity of NPs in a text individually and
significantly improves the performance of learn-
ing-based coreference resolution. It also shows
that, while feature-based anaphoricity determi-
nation contributes much to pronoun resolution,
its contribution on definite NP resolution can be
ignored. In comparison, it shows that tree ker-
nel-based anaphoricity resolution contributes
significantly to the resolution of both pronouns
and definite NPs due to the inclusion of various
kinds of syntactic structured information.
The rest of this paper is organized as follows.
In Section 2, we review related work in ana-
phoricity determination. Then, the LP algorithm
is introduced in Section 3 while Section 4 de-
scribes different similarity measurements ex-
plored in the LP algorithm. Section 5 shows the
experimental results. Finally, we conclude our
work in Section 6.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999762551282052">
Given its potential usefulness in coreference
resolution, anaphoricity determination has been
studied fairly extensively in the literature and
can be classified into three categories: heuristic
rule-based (e.g. Paice and Husk 1987; Lappin
and Leass 1994; Kennedy and Boguraev 1996;
Denber 1998; Vieira and Poesio 2000), statis-
tics-based (e.g., Bean and Riloff 1999; Cherry
and Bergsma 2005; Bergsma et al 2008) and
learning-based (e.g. Evans 2001; Ng and Cardie
2002a; Ng 2004; Yang et al 2005; Denis and
Balbridge 2007).
For the heuristic rule-based approaches,
Paice and Husk (1987), Lappin and Leass (1994),
Kennedy and Boguraev (1996), Denber (1998),
and Cherry and Bergsma (2005) looked for par-
ticular constructions using certain trigger words
to identify pleonastic pronouns while Vieira and
Poesio (2000) recognized non-anaphoric definite
NPs through the use of syntactic cues and case-
sensitive rules and found that nearly 50% of
definite NPs are non-anaphoric. As a representa-
tive, Lappin and Leass (1994), and Kennedy and
Boguraev (1996) looked for modal adjectives
(e.g. “necessary”) or cognitive verbs (e.g. “It is
thought that ... ”) in a set of patterned construc-
tions.
For the statistics-based approaches, Bean
and Riloff (1999) developed a statistics-based
method for automatically identifying existential
definite NPs which are non-anaphoric. The intui-
tion behind is that many definite NPs are not
anaphoric since their meanings can be under-
stood from general world knowledge. They
found that existential NPs account for 63% of all
definite NPs and 76% of them could be identi-
fied by syntactic or lexical means. Using 1600
MUC-4 terrorism news documents as the train-
ing data, they achieved 87% in precision and
78% in recall at identifying non-anaphoric defi-
nite NPs. Cherry and Bergsma (2005) extended
the work of Lappin and Leass (1994) for large-
scale anaphoricity determination by additionally
detecting non-anaphoric instances of it using
Minipar’s pleonastic category Subj. This is done
by both employing Minipar’s named entity rec-
ognition to identify time expressions, such as “it
was midnight... ”, and providing a number of
other linguistic patterns to match common non-
anaphoric it cases, such as in expressions “darn
it” and don’t overdo it”. Bergsma et al (2008)
proposed a distributional method in detecting
non-anaphoric pronouns by first extracting the
surrounding textual context of the pronoun, then
gathering the distribution of words that occurred
within that context from a large corpus and fi-
nally learning to classify these distributions as
representing either anaphoric and non-anaphoric
pronoun instances. Experiments on the Science
News corpus of It-Bank1 in identifying non-
anaphoric pronoun it show that their distribu-
tional method achieved the performance of
81.4%, 71.0% and 75.8 in precision, recall and
F1-measure, respectively, compared with the
performance of 93.4%, 21.0% and 34.3 in preci-
sion, recall and F1-measure, respectively using
the rule-based approach as described in Lappin
and Leass (1994), and the performance of
66.4%, 49.7% and 56.9 in precision, recall and
F1-measure, respectively using the rule-based
approach as described in Cherry and Bergsma
(2005).
Among the learning-based methods, Evans
(2001) applied a machine learning approach on
identifying the non-anaphoricity of pronoun it.
Ng and Cardie (2002a) employed various do-
main-independent features in identifying ana-
phoric NPs and showed how such information
</bodyText>
<footnote confidence="0.970003">
1 www.cs.ualberta.ca/~bergsma/ItBank/
</footnote>
<page confidence="0.998497">
979
</page>
<bodyText confidence="0.999991163636364">
can be incorporated into a coreference resolution
system. Experiments show that their method im-
proves the performance of coreference resolu-
tion by 2.0 and 2.6 to 65.8 and 64.2 in F1-
measure on the MUC-6 and MUC-7 corpora,
respectively, due to much more gain in precision
compared with the loss in recall. Ng (2004) ex-
amined the representation and optimization is-
sues in computing and using anaphoricity infor-
mation to improve learning-based coreference
resolution systems. He used an anaphoricity
classifier as a filter for coreference resolution.
Evaluation on the ACE 2003 corpus shows that,
compared with a baseline coreference resolution
system of no explicit anaphoricity determination,
their method improves the performance by 2.8,
2.2 and 4.5 to 54.5, 64.0 and 60.8 in F1-measure
(due to the gain in precision) on the NWIRE,
NPAPER and BNEWS domains, respectively,
via careful determination of an anaphoricity
threshold with proper constraint-based represen-
tation and global optimization. However, he did
not look into the contribution of anaphoricity
determination on coreference resolution of dif-
ferent NP types, such as pronoun and definite
NPs. Yang et al (2005) made use of non-
anaphors to create a special class of training in-
stances in the twin-candidate model (Yang et al
2003) and thus equipped it with the non-
anaphoricity determination capability. Experi-
ments show that the proposed method improves
the performance by 2.9 and 1.6 to 67.3 and 67.2
in F1-measure on the MUC-6 and MUC-7 cor-
pora, respectively, due to much more gain in
precision compared with the loss in recall. How-
ever, surprisingly, their experiments also show
that eliminating non-anaphors using an ana-
phoricity determination module in advance
harms the performance. Denis and Balbridge
(2007) employed an integer linear programming
(ILP) formulation for coreference resolution
which models anaphoricity and coreference as a
joint task, such that each local model informs the
other for final assignments. Experiments on the
NWIRE, NPAPER and BNEWS domains of the
ACE 2003 corpus shows that this joint ana-
phoricity-coreference ILP formulation improves
the F1-measure by 0.7-1.0 over the coreference-
only ILP formulation. However, their experi-
ments assume true ACE mentions(i.e. all the
ACE mentions are already known from the an-
notated corpus). Therefore, the actual effect of
this joint anaphoricity-coreference ILP formula-
tion on fully-automatic coreference resolution is
still unclear.
</bodyText>
<sectionHeader confidence="0.986674" genericHeader="method">
3 Label Propagation
</sectionHeader>
<bodyText confidence="0.9964808">
In the LP algorithm (Zhu and Ghahramani 2002),
the natural clustering structure in data is repre-
sented as a connected graph. Given the labeled
data and unlabeled data, the LP algorithm first
represents labeled and unlabeled instances as
vertices in a connected graph, then propagates
the label information from any vertex to nearby
vertices through weighted edges and finally in-
fers the labels of unlabeled instances until a
global stable stage is achieved. Figure 1 presents
the label propagation algorithm.
Assume:
Y : the n * r labeling matrix, where yij represents
the probability of vertex xi (i = 1... n) with
label rj (j = 1... r) ;
</bodyText>
<figure confidence="0.602670142857143">
YL : the top l rows of 0
Y . YL corresponds to the
l labeled instances;
YU: the bottom u rows of 0
Y . YU corresponds to
the u unlabeled instances;
T : a n * n matrix, with tij is the probability
jumping from vertex xi to vertex xj ;
BEGIN (the algorithm)
Initialization:
1) Set the iteration index t = 0 ;
2) Let 0
Y be the initial soft labels attached to
each vertex;
3) Let 0
YL be consistent with the labeling in the
labeled data, where 0
yij= the weight of the
labeled instance if xi has the label rj ;
4) Initialize 0
YU ;
REPEAT
Propagate the labels of any vertex to nearby ver-
tices by
Clamp the labeled data, that is, replace t+ 1
YL
with 0
YL ;
UNTIL Y converges(e.g. tYL+1 converges to 0
YL );
Assign each unlabeled instance with a label: for
xi (l � i ≤ n) , find its label with
arg max yij ;
j
END (the algorithm)
</figure>
<figureCaption confidence="0.999811">
Figure 1: The LP algorithm
</figureCaption>
<bodyText confidence="0.998805833333333">
Here, each vertex corresponds to an instance,
and the edge between any two instances xi and
xj is weighted by wij to measure their similar-
ity. In principle, larger edge weights allow labels
to travel through easier. Thus the closer the in-
stances are, the more likely they have similar
</bodyText>
<equation confidence="0.9932655">
Yt = TYt
+1 ;
</equation>
<page confidence="0.95764">
980
</page>
<bodyText confidence="0.9995915">
labels. The algorithm first calculates the weight
wij using a kernel, then transforms it
</bodyText>
<equation confidence="0.933499">
n
to tij =p(j→&gt;0=wij/∑ wkj , which meas-
k=1
</equation>
<bodyText confidence="0.955751">
ures the probability of propagating a label from
instance xj to instance xi , and finally normal-
</bodyText>
<equation confidence="0.916137">
n
izes tij row by row using tij = tij / tik to maintain
k=1
</equation>
<bodyText confidence="0.999867">
the class probability interpretation of the label-
ing matrix Y .
During the label propagation process, the la-
bel distribution of the labeled data is clamped in
each loop using their initial weights and acts like
forces to push out labels through the unlabeled
data. With this push originating from the labeled
data, the label boundaries will be pushed faster
along edges with larger weights and settle in
gaps along those with lower weights. Ideally, we
can expect that wij across different classes
should be as small as possible and wij within the
same class as big as possible. In this way, label
propagation tends to happen within the same
class. This algorithm has been shown to con-
verge to a unique solution (Zhu and Ghahramani
2002), which can be obtained without iteration
in theory, and the initialization of YU0 (the unla-
beled data) is not important since YU0 does not
affect its estimation. However, proper initializa-
tion of YU0 actually helps the algorithm converge
more rapidly in practice. In this paper, each row
in YU0 , i.e. the label distribution for each test
instance, is initialized to the weighted similarity
of the test instance with the labeled instances.
</bodyText>
<sectionHeader confidence="0.998397" genericHeader="method">
4 Kernel-based Similarity
</sectionHeader>
<bodyText confidence="0.9983646">
The key issue in label propagation is how to
compute the similarity wij between two in-
stances xi and xj . This paper examines two
similarity measures: the feature-based RBF ker-
nel and the convolution tree kernel.
</bodyText>
<table confidence="0.970869235294118">
Feature Type Feature Description
Features IsPronoun 1 if current NP is a pronoun, else 0
related with IsDefiniteNP 1 if current NP is a define NP, else 0
current NP itself IsDemonstrativeNP 1 if current NP is a demonstrative NP, else 0
IsArg0 1 if the semantic role of current NP is Arg0/agent, else 0
IsArg0MainVerb 1 if current NP has the semantic role of Arg0/agent for the
main predicate of the sentence, else 0
IsArgs 0 if current NP has no semantic role, else 1
IsSingularNP 1 if current NP is a singular noun, else 0
IsMaleFemalePronoun 1 if current NP is a male/female personal pronoun, else 0
Features
related with
the local context
surrounding
current NP
StringMatch 1 if there is a full string match between current NP and one
of other phrases in the context, else 0
</table>
<tableCaption confidence="0.8005252">
NameAlias 1 if current NP and one of other phrases in the context is a
name alias or abbreviation of the other, else 0
Appositive 1 if current NP and one of other phrases in the context are
in an appositive structure, else 0
NPNested 1 if current NP is nested in another NP, else 0
NPNesting 1 if current NP nests another NP, else 0
WordSenseAgreement 1 if current NP and one of other phrases in the context agree
in the WordNet sense, else 0
IsFirstNPinSentence 1 if current NP is the first NP of this sentence, else 0
BackwardDistance The distance between current NP and the nearest backward
clause, indicated by coordinating words (e.g. that,which).
ForwardDistance The distance between the nearest forward clause, indicated
by coordinating words (e.g. that, which), and current NP.
Table 1: Features in anaphoricity determination of NPs. Note: the semantic role-related features are derived from
an in-house state-of-the-art semantic role labeling system.
</tableCaption>
<subsectionHeader confidence="0.796113">
4.1 Feature-based Kernel
</subsectionHeader>
<bodyText confidence="0.9997245">
In our feature-based RBF kernel to anaphoricity
determination, an instance is represented by 17
lexical, syntactic and semantic features, as
shown in Table 1, which are specifically de-
signed for distinguishing anaphoric and non-
anaphoric NPs, according to common-sense
knowledge and linguistic intuitions. Since the
local context surrounding an NP plays a critical
role in discriminating whether an NP is ana-
phoric or not, the features in Table 1 can be clas-
sified into two categories: (a) current NP (i.e. the
NP in anaphoricity consideration) itself, e.g.
</bodyText>
<page confidence="0.993453">
981
</page>
<bodyText confidence="0.9865598">
types and semantic roles of current NP; (b) con-
textual information, e.g. whether current NP is
nested in another NP, the distance between cur-
rent NP and a clause structure, indicated by co-
ordinating words (e.g. that, this, which).
</bodyText>
<subsectionHeader confidence="0.978274">
4.2 Tree Kernel
</subsectionHeader>
<bodyText confidence="0.999942425">
Given a NP in anaphoricity determination, a
parse tree represents the local context surround-
ing current NP in a structural way and thus con-
tains much information in determining whether
current NP is anaphoric or not. For example, the
commonly used knowledge for anaphoricity de-
termination, such as the grammatical role of cur-
rent NP or whether current NP is nested in other
NPs, can be directly captured by a parse tree
structure.
Given a parse tree and a NP in consideration,
the problem is how to choose a proper parse tree
structure to cover syntactic structured informa-
tion well in the tree kernel computation. Gener-
ally, the more a parse tree structure includes, the
more syntactic structured information would be
provided, at the expense of more
noisy/unnecessary information. In this paper, we
limit the window size to 5 chunks (either NPs or
non-NPs), including previous two chunks, cur-
rent chunk (i.e. current NP) and following two
chunks, and prune out the substructures outside
the window. Figure 2 shows the full parse tree
for the sentence “Mary said the woman in the
room hit her too”, using the Charniak parser
(Charniak 2001), and the chunk sequence de-
rived from the parse tree using the Perl script2
written by Sabine Buchholz from Tilburg Uni-
versity.
Here, we explore four parse tree structures
in NP anaphoricity determination: the common
tree (CT), the shortest path-enclosed tree (SPT),
the minimum tree (MT) and the dynamically
extended tree (DET), motivated by Yang et al
(2006) and Zhou et al (2008). Following are the
examples of the four parse tree structures, corre-
sponding to the full parse tree and the chunk se-
quence, as shown in Figure 2, with the NP chunk
“(NP (DT the) (NN woman))” in anaphoricity
determination.
</bodyText>
<sectionHeader confidence="0.644811" genericHeader="method">
Common Tree (CT)
</sectionHeader>
<bodyText confidence="0.999980333333333">
As shown in Figure 3(a), CT is the complete
sub-tree rooted by the nearest common ancestor
of the first chunk “(NP (NNP Mary))” and the
</bodyText>
<footnote confidence="0.609042">
2 http://ilk.kub.nl/~sabine/chunklink/
</footnote>
<bodyText confidence="0.9799775">
last chunk “(NP (DT the) (NN room))” of the
five-chunk window.
</bodyText>
<subsectionHeader confidence="0.65563">
Shortest Path-enclosed Tree (SPT)
</subsectionHeader>
<bodyText confidence="0.9986364">
As shown in Figure 3(b), SPT is the smallest
common sub-tree enclosed by the shortest path
between the first chunk “(NP (NNP Mary))” and
the last chunk “(NP (DT the) (NN room))” of the
five-chunk window.
</bodyText>
<figure confidence="0.9980406">
(a) the full parse tree
(NP (NNP Mary)) (VP (VBD said)) (NP-E (DT the)
(NN woman)) (PP (IN in)) (NP (DT the) (NN room))
(VP (VBD hit)) (NP (PRP her)) (ADVP (RB too))
(b) the chunk sequence
</figure>
<figureCaption confidence="0.9968512">
Figure 2: The full parse tree for the sentence “Mary
said the woman in the room hit her too”, using the
Charniak parser, and the corresponding chunk se-
quence derived from it. Here, the label “E” indicates
the NP in consideration.
</figureCaption>
<figure confidence="0.983099">
(a) CT: Common Tree
(b) SPT: Shortest Path-enclosed Tree
</figure>
<page confidence="0.684545">
982
</page>
<figureCaption confidence="0.807829">
(c) MT: Minimum Tree
(d) DET: Dynamically Extended Tree
Figure 3: Examples of parse tree structures.
</figureCaption>
<sectionHeader confidence="0.410294" genericHeader="method">
Minimum Tree (MT)
</sectionHeader>
<bodyText confidence="0.974198571428571">
As shown in Figure 3(c), MT only keeps the root
path from the NP in anaphoricity determination
to the root node of SPT.
Dynamically Extended Tree (DET),
The intuitions behind DET are that the informa-
tion related with antecedent candidates (all the
antecedent candidates compatible3 with current
NP in anaphoricity consideration), predicates4
and right siblings plays a critical role in corefer-
ence resolution. Given a MT, this is done by:
1) Attaching all the compatible antecedent can-
didates and their corresponding paths. As
shown in Figure 3(d), “Mary” is attached
while “the room” is not since the former is
compatible with the NP “the woman” and
the latter is not compatible with the NP “the
woman”. In this way, possible coreference
between current NP and the compatible an-
tecedent candidates can be included in the
parse tree structure. In some sense, this is a
natural extension of the twin-candidate
</bodyText>
<footnote confidence="0.7940025">
3 With matched number, person and gender agreements.
4 For simplicity, only verbal predicates are considered in
this paper. However, this can be extended to nominal predi-
cates with automatic identification of nominal predicates.
</footnote>
<bodyText confidence="0.998833666666667">
learning method proposed in Yang et al
(2003), which explicitly models the compe-
tition between two antecedent candidates.
</bodyText>
<listItem confidence="0.827441105263158">
2) For each node in MT, attaching the path from
the node to the leaf node of the correspond-
ing predicate, if it is predicate-headed, in the
sense that such predicate-related information
is useful in identifying certain kinds of ex-
pressions with non-anaphoric NPs, e.g. the
non-anaphoric it in “darn it”. As shown in
Figure 3(d), “said” and “hit” are attached.
3) Attaching the path to the head word of the
first right sibling if the parent of current NP
is a NP and current NP has one or more right
siblings. Normally, the NP in anaphoricity
consideration, NP-E, in the production of
“NP-&gt;NP-E+PP” introduces a new entity
and thus non-anaphoric.
4) Pruning those nodes (except POS nodes)
with the single in-arc and the single out-arc
and with its syntactic phrase type same as its
child node.
</listItem>
<bodyText confidence="0.999567833333333">
In this paper, the similarity between two
parse trees is measured using a convolution tree
kernel, which counts the number of common
sub-trees as the syntactic structure similarity
between two parse trees. For details, please refer
to Collins and Duffy (2001).
</bodyText>
<sectionHeader confidence="0.99803" genericHeader="method">
5 Experimentation
</sectionHeader>
<bodyText confidence="0.9999386">
We have systematically evaluated the label
propagation algorithm on global learning of NP
anaphoricity determination on the ACE 2003
corpus, and its application in coreference resolu-
tion.
</bodyText>
<subsectionHeader confidence="0.974626">
5.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999697176470588">
The ACE 2003 corpus contains three domains:
newswire (NWIRE), newspaper (NPAPER), and
broadcast news (BNEWS). For each domain,
there exist two data sets, training and devtest,
which are used for training and testing respec-
tively.
As a baseline coreference resolution system,
a raw test text is first preprocessed automati-
cally by a pipeline of NLP components, includ-
ing sentence boundary detection, POS tagging,
named entity recognition and phrase chunking,
and then a training or test instance is formed by
a anaphor and one of its antecedent candidates,
similar to Soon et al (2001). Among them,
named entity recognition, part-of-speech tagging
and noun phrase chunking apply the same Hid-
den Markov Model (HMM)-based engine with
</bodyText>
<page confidence="0.998066">
983
</page>
<bodyText confidence="0.999995088888889">
error-driven learning capability (Zhou and Su,
2000 &amp; 2002). During training, for each anaphor
encountered, a positive instance is created by
pairing the anaphor and its closest antecedent
while a set of negative instances is formed by
pairing the anaphor with each of the non-
coreferential candidates. Based on the training
instances, a binary classifier is generated using a
particular learning algorithm. In this paper, we
use SVMLight developed by Joachims (1998).
During resolution, an anaphor is first paired in
turn with each preceding antecedent candidate to
form a test instance, which is presented to a
classifier. The classifier then returns a confi-
dence value indicating the likelihood that the
candidate is the antecedent. Finally, the candi-
date with the highest confidence value is se-
lected as the antecedent. As a baseline, the NPs
with mismatched number, person and gender
agreements are filtered out. On average, an ana-
phor has ~7 antecedent candidates. In particular,
the test corpus is resolved in document-level, i.e.
one document by one document.
For anaphoricity determination, we report
the performance in Acc+ and Acc-, which meas-
ure the accuracies of identifying anaphoric NPs
and non-anaphoric NPs, respectively. Obviously,
higher Acc+ means that more anaphoric NPs
would be identified correctly, while higher Acc-
means that more non-anaphoric NPs would be
filtered out. For coreference resolution, we re-
port the performance in terms of recall, precision,
and F1-measure using the commonly-used
model theoretic MUC scoring program (Vilain
et al., 1995). For separate scoring of different
NP types, a recognized reference is considered
correct if the reconized antecedent is in the
coreferential chain of the anaphor. To see
whether an improvement is significant, we con-
duct significance testing using paired t-test. In
this paper, ‘&gt;&gt;&gt;’, ‘&gt;&gt;’ and ‘&gt;’ denote p-values
of an improvement smaller than 0.01, in-
between (0.01, 0,05] and bigger than 0.05,
which mean significantly better, moderately
better and slightly better, respectively.
</bodyText>
<subsectionHeader confidence="0.99863">
5.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.999985435483871">
Table 2 shows the performance of LP-based ana-
phoricity determination using the feature-based
RBF kernel. It shows that our method achieves
the accuracies of 74.8/84.4, 76.2/81.3 and
71.8/81.7 on identifying anaphoric/non-
anaphoric NPs in the NWIRE, NPAPER and
BNEWS domains, respectively. This suggests
that our approach can effectively filter out about
82% of non-anaphoric NPs. However, it can
only keep about 74% of anaphoric NPs. Table 2
also shows the performance on different NP
types. Considering the effectiveness of ana-
phoricity determination on indefinite NPs (due
to that most of anaphoric indefinite NPs are in
an appositive structure and thus can be easily
captured by the IsAppositive feature) and that
most of errors in anaphoricity determination on
proper nouns are caused by the named entity
recognition module in the preprocessing), it in-
dicates the difficulty of anaphoricity determina-
tion in filtering out non-anaphoric pronouns and
identifying anaphoric definite NPs. As a com-
parison, Table 2 also shows the performance of
locally-optimized anaphoricity determination
using a classifier (SVM with the feature-based
RBF kernel, as adopted in this paper) to deter-
mine the NPs in a text individually. It shows that
the LP-based method systematically outperforms
(&gt;&gt;&gt;) the SVM-based method. This suggests the
effectiveness of the LP algorithm in global mod-
eling of the natural clustering structure in ana-
phoricity determination.
Table 3 shows the performance of LP-based
anaphoricity determination using the convolu-
tion tree kernel on different parse tree structures.
It shows that while MT performed worst due to
its simple structure, DET outperforms MT(&gt;&gt;&gt;),
SPT(&gt;&gt;&gt;) and CT(&gt;&gt;&gt;) on all the three domains
due to fine inclusion of necessary structural in-
formation, although inclusion of more informa-
tion in both CT and SPT also improves the per-
formance. It again verifies that LP-based ana-
phoricity determination outperforms (&gt;&gt;&gt;)
SVM-based one, using the tree kernel. Table 4
further indicates that all the three kinds of struc-
tural information related with antecedent candi-
dates, predicates and right siblings in DET con-
tribute significantly (&gt;&gt;&gt;). In addition, Table 5
shows the detailed performance of LP-based
anaphoricity determination on different anaphor
types using DET. Compared with the feature-
based RBF kernel as shown in Table 2, it shows
that the convolution tree kernel significantly
outperforms (&gt;&gt;&gt;) the feature-based RBF kernel
in all the three domains, with much contribution
due to performance improvement on both pro-
nouns and definite NPs, although the tree kernel
performs moderately worse than the feature-
based RBF kernel due to the effectiveness of
anaphoricity determination on proper nouns and
indefinite NPs using the IsNameAlias and IsAp-
positive features respectively.
</bodyText>
<page confidence="0.993819">
984
</page>
<table confidence="0.9998937">
Anaphor NWIRE NPAPER BNEWS
Type
Acc+ Acc- Acc+ Acc- Acc+ Acc-
(%) (%) (%) (%) (%) (%)
Pronoun 88.7 56.2 90.2 58.6 87.4 57.8
ProperNoun 72.5 85.2 74.6 80.5 70.6 78.8
DefiniteNP 66.6 83.1 72.1 77.5 65.3 81.5
InDefiniteNP 95.4 93.7 90.5 95.8 87.2 97.3
Overall 74.8 84.4 76.2 81.3 71.8 81.7
Overall(SVM) 71.3 80.2 73.5 79.1 68.4 78.6
</table>
<tableCaption confidence="0.994886">
Table 2: The performance of LP-based anaphoric-
ity determination using the feature-based RBF kernel
</tableCaption>
<table confidence="0.999927916666667">
Parse Tree structure NWIRE NPAPER BNEWS
Scheme ( %) ( %) ( %)
CT Acc+ 72.6 74.3 74.2
Acc- 82.1 80.2 72.3
SPT Acc+ 72.4 74.1 73.8
Acc- 80.8 79.5 72.5
MT Acc+ 71.4 70.5 66.9
Acc- 77.2 75.3 78.2
DET Acc+ 79.2 81.2 76.5
Acc- 87.8 84.5 85.3
Acc+ 76.5 78.9 74.3
DET(SVM) Acc- 82.3 81.6 83.2
</table>
<tableCaption confidence="0.920919333333333">
Table 3: The performance of LP-based anaphoric-
ity determination using the convolution tree kernel on
different parse tree structures
</tableCaption>
<table confidence="0.999936125">
Performance Change NWIRE NPAPER BNEWS
( %) ( %) ( %)
- antecedent Acc+ -4.0 -3.8 -4.3
candidates Acc- -5.2 -5.3 -4.5
-predicate Acc+ -5.2 -4.8 -5.6
Acc- -4.3 -3.5 -4.9
-first right Acc+ -3.6 -4.1 -3.1
sibling Acc- -4.8 -5.2 -4.4
</table>
<tableCaption confidence="0.9217725">
Table 4: The contribution of structural information
in DET
</tableCaption>
<table confidence="0.999959888888889">
Anaphor NWIRE NPAPER BNEWS
Type
A cc+ Acc- Acc+ Acc- Acc+ Acc-
(%) (%) (%) (%) (%) (%)
Pronoun 90.1 75.6 90.7 79.2 89.2 77.5
ProperNoun 71.4 83.5 72.8 78.1 68.3 77.2
DefiniteNP 74.6 89.1 77.3 85.5 75.3 88.7
InDefiniteNP 93.2 92.1 90.2 94.2 89.4 95.5
Overall 79.2 87.8 81.2 84.5 76.5 85.3
</table>
<tableCaption confidence="0.9758535">
Table 5: The performance of LP-based anaphoric-
ity determination using the tree kernel on DET
</tableCaption>
<bodyText confidence="0.999870074074074">
Finally, we evaluate the effect of LP-based
anaphoricity determination on coreference reso-
lution by including it as a preprocessing step to a
baseline coreference resolution system without
explicit anaphoricity determination, which em-
ploys the same set of features, as adopted in the
single-candidate model of Yang et al (2003),
using a SVM-based classifier and the feature-
based RBF kernel. It shows that anaphoricity
determination with the feature-based RBF Ker-
nel much improves (&gt;&gt;&gt;) the performance of
coreference resolution with most of the contribu-
tion due to pronoun resolution while its contri-
bution on definite NPs can be ignored. It indi-
cates the usefulness of anaphoricity determina-
tion in filtering out non-anaphoric pronouns and
the difficulty in identifying anaphoric definite
NPs, using the feature-based RBF kernel. It also
shows that tree kernel-based anaphoricity deter-
mination can not only improve (&gt;&gt;&gt;) the per-
formance on pronoun resolution but also im-
prove (&gt;&gt;&gt;) the performance on definite NP
resolution due to the much better performance of
tree kernel-based anaphoricity determination on
definite NPs. This suggests the necessity of ex-
ploring structural information in identifying
anaphoric definite NPs.
</bodyText>
<table confidence="0.999146636363636">
System NWIRE NPAPER BNEWS
R% P% F R% P% F R% P% F
BaseLine (No Anaphoricity) Pronoun 66.5 61.6 64.0 70.1 64.2 67.0 61.7 63.2 62.4
DefiniteNP 26.9 80.3 40.2 34.5 62.4 44.4 30.5 71.4 42.9
Overall 53.1 67.4 59.4 57.7 67.0 62.1 48.0 65.9 55.5
+Anaphoricity determination Pronoun 64.1 67.9 66.0 67.3 72.4 69.8 59.5 75.7 66.6
with the feature-based RBF kernel DefiniteNP 26.7 80.6 40.3 34.2 62.5 44.3 30.4 71.9 43.1
Overall 50.6 75.4 60.7 54.4 77.1 63.8 45.9 76.9 57.4
+Anaphoricity determination Pronoun 63.5 70.9 67.0 68 74.9 71.3 61.1 77.6 68.3
with the convolution tree kernel DefiniteNP 28.5 82.4 42.1 36.2 65.3 46.1 32.3 73.1 44.2
Overall 51.6 77.2 61.8 55.2 78.6 65.2 47.5 80.3 59.6
</table>
<tableCaption confidence="0.998837">
Table 6: Employment of anaphoricity determination in coreference resolution
</tableCaption>
<sectionHeader confidence="0.998522" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999950444444444">
This paper systematically studies a global learn-
ing method in identifying the anaphoricity of
noun phrases via a label propagation algorithm
and the application of an explicit anaphoricity
determination module in improving learning-
based coreference resolution. In particular, two
kinds of kernels, i.e. the feature-based RBF ker-
nel and the convolution tree kernel, are em-
ployed to compute the anaphoricity similarity
</bodyText>
<page confidence="0.996529">
985
</page>
<bodyText confidence="0.999928375">
between two NPs. Evaluation on the ACE 2003
corpus indicates that LP-based anaphoricity de-
termination using both the kernels much im-
proves the performance of coreference resolu-
tion. It also shows the usefulness of various
structural information, related with antecedent
candidates, predicates and right siblings, in tree
kernel-based anaphoricity determination and in
coreference resolution of both pronouns and
definite NPs.
To our knowledge, this is the first system-
atic exploration of both feature-based and tree
kernel methods in anaphoricity determination
and the application of an explicit anaphoricity
determination module in learning coreference
resolution.
</bodyText>
<sectionHeader confidence="0.988238" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.944279142857143">
This research is supported by Project 60873150
under the National Natural Science Foundation of
China, project 2006AA01Z147 under the “863”
National High-Tech Research and Development of
China, project 200802850006 under the National
Research Foundation for the Doctoral Program of
Higher Education of China.
</bodyText>
<sectionHeader confidence="0.995253" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999934178571429">
Bean D. and Riloff E. (1999). Corpus-based Identifi-
cation of Non-Anaphoric Noun Phrases.
ACL’1999:373-380.
Bergsma S., Lin D.K. and Goebel R. (2008). Distri-
butional Identification of Non-Referential Pro-
nouns. ACL’2008: 10-18.
Charniak E. (2001). Immediate-head Parsing for Lan-
guage Models. ACL’2001: 129-137.
Cherry C. and Bergsma S. (2005). An expectation
maximization approach to pronoun resolution.
CoNLL’2005:88-95.
Collins M. and Duffy N. (2001). Convolution kernels
for natural language. NIPS’2001: 625-632.
Denber M. (1998). Automatic Resolution of Anaph-
ora in English. Technical Report, Eastman Kodak
Co.
Denis P. and Baldridge J. (2007). Joint determination
of anaphoricity and coreference using integer pro-
gramming. NAACL-HLT’2007:236-243.
Evans R. (2001). Applying machine learning toward
an automatic classification of it. Literary and Lin-
guistic Computing, 16(1):45.57.
Joachims T. (1998). Text Categorization with Sup-
port Vector Machine: learning with many relevant
features. ECML-1998: 137-142.
Kennedy C. and Boguraev B. (1996). Anaphora for
everyone: pronominal anaphora resolution without
a parser. COLING’1996: 113-118.
Lappin S. and Leass H.J. (1994). An algorithm for
pronominal anaphora resolution. Computational
Linguistics, 20(4):535.561.
Ng V. and Cardie C. (2002a). Identifying anaphoric
and non-anaphoric noun phrases to improve
coreference resolution. COLING’2002:730-736.
Ng V. and Cardie C. (2002b). Improving machine
learning approaches to coreference resolution.
ACL’2002: 104-111
Ng V. (2004). Learning Noun Phrase Anaphoricity to
Improve Conference Resolution: Issues in Repre-
sentation and Optimization. ACL’2004: 151-158
Paice C.D. and Husk G.D. (1987). Towards the auto-
matic recognition of anaphoric features in English
text: the impersonal pronoun it. Computer Speech
and Language, 2:109-132.
Soon W.M., Ng H.T. and Lim D. (2001). A machine
learning approach to coreference resolution of
noun phrase. Computational Linguistics, 2001,
27(4):521-544.
Strube M. and Muller C. (2003). A machine learning
approach to pronoun resolution in spoken dialogue.
ACL’2003: 168-175
Vieira R. and Poesio M. (2000). An empirically
based system for processing definite descriptions.
Computational Linguistics, 27(4): 539–592.
Vilain M., Burger J., Aberdeen J., Connolly D. and
Hirschman L. (1995). A model theoretic corefer-
ence scoring scheme. MUC-6: 45–52.
Yang X.F., Zhou G.D., Su J. and Chew C.L. (2003).
Coreference Resolution Using Competition Learn-
ing Approach. ACL’2003:177-184
Yang X.F., Su J. and Tan C.L. (2005). A Twin-
Candidate Model of Coreference Resolution with
Non-Anaphor Identification Capability.
IJCNLP’2005:719-730.
Yang X.F., Su J. and Tan C.L. (2006). Kernel-based
pronoun resolution with structured syntactic
knowledge. COLING-ACL’2006: 41-48.
Yang X.F., Su J., Lang J., Tan C.L., Liu T. and Li S.
(2008). An Entity-Mention Model for Coreference
Resolution with Inductive Logic Programming.
ACL’2008: 843-851.
Zhou G.D. and Su. J. (2000). Error-driven HMM-
based chunk tagger with context-dependent lexi-
con. EMNLP-VLC’2000: 71–79
Zhou G.D. and Su J. (2002). Named Entity recogni-
tion using a HMM-based chunk tagger. In
ACL’2002:473–480.
Zhou G.D., Kong F. and Zhu Q.M. (2008). Context-
sensitive convolution tree kernel for pronoun
resolution . IJCNLP’2008:25-31.
Zhu X. and Ghahramani Z. (2002). Learning from
Labeled and Unlabeled Data with Label Propaga-
tion. CMU CALD Technical Report.CMU-CALD-
02-107.
</reference>
<page confidence="0.998464">
986
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.765926">
<title confidence="0.9962175">Global Learning of Noun Phrase Anaphoricity in Coreference Resolution via Label Propagation</title>
<author confidence="0.991087">ZHOU GuoDong KONG</author>
<affiliation confidence="0.991348">JiangSu Provincial Key Lab for Computer Information Processing School of Computer Science and</affiliation>
<address confidence="0.924902">Soochow University. Suzhou, China 215006</address>
<email confidence="0.970578">gdzhou,kongfang}@suda.edu.cn</email>
<abstract confidence="0.994027590909091">Knowledge of noun phrase anaphoricity might be profitably exploited in coreference resolution to bypass the resolution of non-anaphoric noun phrases. However, it is surprising to notice that recent attempts to incorporate automatically acquired anaphoricity information into coreference resolution have been somewhat disappointing. This paper employs a global learning method in determining the anaphoricity of noun phrases via a label propagation algorithm to improve learningbased coreference resolution. In particular, two kinds of kernels, i.e. the feature-based RBF kernel and the convolution tree kernel, are employed to compute the anaphoricity similarity between two noun phrases. Experiments on the ACE 2003 corpus demonstrate the effectiveness of our method in anaphoricity determination of noun phrases and its application in learning-based coreference resolution.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Bean</author>
<author>E Riloff</author>
</authors>
<title>Corpus-based Identification of Non-Anaphoric Noun Phrases.</title>
<date>1999</date>
<pages>1999--373</pages>
<contexts>
<context position="2679" citStr="Bean and Riloff 1999" startWordPosition="389" endWordPosition="392">1; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity. Given the labeled data and the unlabeled data, the LP algorithm first represents labeled and unlabeled instances as verti</context>
<context position="5813" citStr="Bean and Riloff 1999" startWordPosition="875" endWordPosition="878">determination. Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anapho</context>
</contexts>
<marker>Bean, Riloff, 1999</marker>
<rawString>Bean D. and Riloff E. (1999). Corpus-based Identification of Non-Anaphoric Noun Phrases. ACL’1999:373-380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bergsma</author>
<author>D K Lin</author>
<author>R Goebel</author>
</authors>
<date>2008</date>
<booktitle>Distributional Identification of Non-Referential Pronouns. ACL’2008:</booktitle>
<pages>10--18</pages>
<contexts>
<context position="2700" citStr="Bergsma et al 2008" startWordPosition="393" endWordPosition="396">; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity. Given the labeled data and the unlabeled data, the LP algorithm first represents labeled and unlabeled instances as vertices in a connected gr</context>
<context position="5859" citStr="Bergsma et al 2008" startWordPosition="883" endWordPosition="886">uced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative, Lappin and Leass (19</context>
<context position="7737" citStr="Bergsma et al (2008)" startWordPosition="1178" endWordPosition="1181">s as the training data, they achieved 87% in precision and 78% in recall at identifying non-anaphoric definite NPs. Cherry and Bergsma (2005) extended the work of Lappin and Leass (1994) for largescale anaphoricity determination by additionally detecting non-anaphoric instances of it using Minipar’s pleonastic category Subj. This is done by both employing Minipar’s named entity recognition to identify time expressions, such as “it was midnight... ”, and providing a number of other linguistic patterns to match common nonanaphoric it cases, such as in expressions “darn it” and don’t overdo it”. Bergsma et al (2008) proposed a distributional method in detecting non-anaphoric pronouns by first extracting the surrounding textual context of the pronoun, then gathering the distribution of words that occurred within that context from a large corpus and finally learning to classify these distributions as representing either anaphoric and non-anaphoric pronoun instances. Experiments on the Science News corpus of It-Bank1 in identifying nonanaphoric pronoun it show that their distributional method achieved the performance of 81.4%, 71.0% and 75.8 in precision, recall and F1-measure, respectively, compared with t</context>
</contexts>
<marker>Bergsma, Lin, Goebel, 2008</marker>
<rawString>Bergsma S., Lin D.K. and Goebel R. (2008). Distributional Identification of Non-Referential Pronouns. ACL’2008: 10-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Immediate-head Parsing for Language Models.</title>
<date>2001</date>
<volume>2001</volume>
<pages>129--137</pages>
<contexts>
<context position="18674" citStr="Charniak 2001" startWordPosition="2999" endWordPosition="3000">tructure to cover syntactic structured information well in the tree kernel computation. Generally, the more a parse tree structure includes, the more syntactic structured information would be provided, at the expense of more noisy/unnecessary information. In this paper, we limit the window size to 5 chunks (either NPs or non-NPs), including previous two chunks, current chunk (i.e. current NP) and following two chunks, and prune out the substructures outside the window. Figure 2 shows the full parse tree for the sentence “Mary said the woman in the room hit her too”, using the Charniak parser (Charniak 2001), and the chunk sequence derived from the parse tree using the Perl script2 written by Sabine Buchholz from Tilburg University. Here, we explore four parse tree structures in NP anaphoricity determination: the common tree (CT), the shortest path-enclosed tree (SPT), the minimum tree (MT) and the dynamically extended tree (DET), motivated by Yang et al (2006) and Zhou et al (2008). Following are the examples of the four parse tree structures, corresponding to the full parse tree and the chunk sequence, as shown in Figure 2, with the NP chunk “(NP (DT the) (NN woman))” in anaphoricity determinat</context>
</contexts>
<marker>Charniak, 2001</marker>
<rawString>Charniak E. (2001). Immediate-head Parsing for Language Models. ACL’2001: 129-137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Cherry</author>
<author>S Bergsma</author>
</authors>
<title>An expectation maximization approach to pronoun resolution.</title>
<date>2005</date>
<pages>2005--88</pages>
<contexts>
<context position="5838" citStr="Cherry and Bergsma 2005" startWordPosition="879" endWordPosition="882">he LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative,</context>
<context position="7258" citStr="Cherry and Bergsma (2005)" startWordPosition="1103" endWordPosition="1106">or the statistics-based approaches, Bean and Riloff (1999) developed a statistics-based method for automatically identifying existential definite NPs which are non-anaphoric. The intuition behind is that many definite NPs are not anaphoric since their meanings can be understood from general world knowledge. They found that existential NPs account for 63% of all definite NPs and 76% of them could be identified by syntactic or lexical means. Using 1600 MUC-4 terrorism news documents as the training data, they achieved 87% in precision and 78% in recall at identifying non-anaphoric definite NPs. Cherry and Bergsma (2005) extended the work of Lappin and Leass (1994) for largescale anaphoricity determination by additionally detecting non-anaphoric instances of it using Minipar’s pleonastic category Subj. This is done by both employing Minipar’s named entity recognition to identify time expressions, such as “it was midnight... ”, and providing a number of other linguistic patterns to match common nonanaphoric it cases, such as in expressions “darn it” and don’t overdo it”. Bergsma et al (2008) proposed a distributional method in detecting non-anaphoric pronouns by first extracting the surrounding textual context</context>
<context position="8664" citStr="Cherry and Bergsma (2005)" startWordPosition="1313" endWordPosition="1316">either anaphoric and non-anaphoric pronoun instances. Experiments on the Science News corpus of It-Bank1 in identifying nonanaphoric pronoun it show that their distributional method achieved the performance of 81.4%, 71.0% and 75.8 in precision, recall and F1-measure, respectively, compared with the performance of 93.4%, 21.0% and 34.3 in precision, recall and F1-measure, respectively using the rule-based approach as described in Lappin and Leass (1994), and the performance of 66.4%, 49.7% and 56.9 in precision, recall and F1-measure, respectively using the rule-based approach as described in Cherry and Bergsma (2005). Among the learning-based methods, Evans (2001) applied a machine learning approach on identifying the non-anaphoricity of pronoun it. Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information 1 www.cs.ualberta.ca/~bergsma/ItBank/ 979 can be incorporated into a coreference resolution system. Experiments show that their method improves the performance of coreference resolution by 2.0 and 2.6 to 65.8 and 64.2 in F1- measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss</context>
</contexts>
<marker>Cherry, Bergsma, 2005</marker>
<rawString>Cherry C. and Bergsma S. (2005). An expectation maximization approach to pronoun resolution. CoNLL’2005:88-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>Convolution kernels for natural language.</title>
<date>2001</date>
<volume>2001</volume>
<pages>625--632</pages>
<contexts>
<context position="22683" citStr="Collins and Duffy (2001)" startWordPosition="3666" endWordPosition="3669"> the parent of current NP is a NP and current NP has one or more right siblings. Normally, the NP in anaphoricity consideration, NP-E, in the production of “NP-&gt;NP-E+PP” introduces a new entity and thus non-anaphoric. 4) Pruning those nodes (except POS nodes) with the single in-arc and the single out-arc and with its syntactic phrase type same as its child node. In this paper, the similarity between two parse trees is measured using a convolution tree kernel, which counts the number of common sub-trees as the syntactic structure similarity between two parse trees. For details, please refer to Collins and Duffy (2001). 5 Experimentation We have systematically evaluated the label propagation algorithm on global learning of NP anaphoricity determination on the ACE 2003 corpus, and its application in coreference resolution. 5.1 Experimental Setting The ACE 2003 corpus contains three domains: newswire (NWIRE), newspaper (NPAPER), and broadcast news (BNEWS). For each domain, there exist two data sets, training and devtest, which are used for training and testing respectively. As a baseline coreference resolution system, a raw test text is first preprocessed automatically by a pipeline of NLP components, includi</context>
</contexts>
<marker>Collins, Duffy, 2001</marker>
<rawString>Collins M. and Duffy N. (2001). Convolution kernels for natural language. NIPS’2001: 625-632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Denber</author>
</authors>
<title>Automatic Resolution of Anaphora in English.</title>
<date>1998</date>
<tech>Technical Report,</tech>
<institution>Eastman Kodak Co.</institution>
<contexts>
<context position="2514" citStr="Denber 1998" startWordPosition="368" endWordPosition="369">isting machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algori</context>
<context position="5742" citStr="Denber 1998" startWordPosition="866" endWordPosition="867">follows. In Section 2, we review related work in anaphoricity determination. Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and cases</context>
</contexts>
<marker>Denber, 1998</marker>
<rawString>Denber M. (1998). Automatic Resolution of Anaphora in English. Technical Report, Eastman Kodak Co.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>J Baldridge</author>
</authors>
<title>Joint determination of anaphoricity and coreference using integer programming.</title>
<date>2007</date>
<pages>2007--236</pages>
<marker>Denis, Baldridge, 2007</marker>
<rawString>Denis P. and Baldridge J. (2007). Joint determination of anaphoricity and coreference using integer programming. NAACL-HLT’2007:236-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Evans</author>
</authors>
<title>Applying machine learning toward an automatic classification of it.</title>
<date>2001</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>16--1</pages>
<contexts>
<context position="2736" citStr="Evans 2001" startWordPosition="401" endWordPosition="402">08), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity. Given the labeled data and the unlabeled data, the LP algorithm first represents labeled and unlabeled instances as vertices in a connected graph, then propagates the label infor</context>
<context position="5895" citStr="Evans 2001" startWordPosition="890" endWordPosition="891">ifferent similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative, Lappin and Leass (1994), and Kennedy and Boguraev (1996)</context>
<context position="8712" citStr="Evans (2001)" startWordPosition="1321" endWordPosition="1322">ents on the Science News corpus of It-Bank1 in identifying nonanaphoric pronoun it show that their distributional method achieved the performance of 81.4%, 71.0% and 75.8 in precision, recall and F1-measure, respectively, compared with the performance of 93.4%, 21.0% and 34.3 in precision, recall and F1-measure, respectively using the rule-based approach as described in Lappin and Leass (1994), and the performance of 66.4%, 49.7% and 56.9 in precision, recall and F1-measure, respectively using the rule-based approach as described in Cherry and Bergsma (2005). Among the learning-based methods, Evans (2001) applied a machine learning approach on identifying the non-anaphoricity of pronoun it. Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information 1 www.cs.ualberta.ca/~bergsma/ItBank/ 979 can be incorporated into a coreference resolution system. Experiments show that their method improves the performance of coreference resolution by 2.0 and 2.6 to 65.8 and 64.2 in F1- measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss in recall. Ng (2004) examined the representatio</context>
</contexts>
<marker>Evans, 2001</marker>
<rawString>Evans R. (2001). Applying machine learning toward an automatic classification of it. Literary and Linguistic Computing, 16(1):45.57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text Categorization with Support Vector Machine: learning with many relevant features.</title>
<date>1998</date>
<volume>1998</volume>
<pages>137--142</pages>
<contexts>
<context position="24117" citStr="Joachims (1998)" startWordPosition="3887" endWordPosition="3888">Among them, named entity recognition, part-of-speech tagging and noun phrase chunking apply the same Hidden Markov Model (HMM)-based engine with 983 error-driven learning capability (Zhou and Su, 2000 &amp; 2002). During training, for each anaphor encountered, a positive instance is created by pairing the anaphor and its closest antecedent while a set of negative instances is formed by pairing the anaphor with each of the noncoreferential candidates. Based on the training instances, a binary classifier is generated using a particular learning algorithm. In this paper, we use SVMLight developed by Joachims (1998). During resolution, an anaphor is first paired in turn with each preceding antecedent candidate to form a test instance, which is presented to a classifier. The classifier then returns a confidence value indicating the likelihood that the candidate is the antecedent. Finally, the candidate with the highest confidence value is selected as the antecedent. As a baseline, the NPs with mismatched number, person and gender agreements are filtered out. On average, an anaphor has ~7 antecedent candidates. In particular, the test corpus is resolved in document-level, i.e. one document by one document.</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>Joachims T. (1998). Text Categorization with Support Vector Machine: learning with many relevant features. ECML-1998: 137-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Kennedy</author>
<author>B Boguraev</author>
</authors>
<title>Anaphora for everyone: pronominal anaphora resolution without a parser.</title>
<date>1996</date>
<volume>1996</volume>
<pages>113--118</pages>
<contexts>
<context position="2500" citStr="Kennedy and Boguraev 1996" startWordPosition="364" endWordPosition="367"> outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagati</context>
<context position="5729" citStr="Kennedy and Boguraev 1996" startWordPosition="862" endWordPosition="865">this paper is organized as follows. In Section 2, we review related work in anaphoricity determination. Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic c</context>
</contexts>
<marker>Kennedy, Boguraev, 1996</marker>
<rawString>Kennedy C. and Boguraev B. (1996). Anaphora for everyone: pronominal anaphora resolution without a parser. COLING’1996: 113-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lappin</author>
<author>H J Leass</author>
</authors>
<title>An algorithm for pronominal anaphora resolution.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="2473" citStr="Lappin and Leass 1994" startWordPosition="360" endWordPosition="363"> end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This pape</context>
<context position="5702" citStr="Lappin and Leass 1994" startWordPosition="858" endWordPosition="861">formation. The rest of this paper is organized as follows. In Section 2, we review related work in anaphoricity determination. Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs thr</context>
<context position="7303" citStr="Lappin and Leass (1994)" startWordPosition="1111" endWordPosition="1114">loff (1999) developed a statistics-based method for automatically identifying existential definite NPs which are non-anaphoric. The intuition behind is that many definite NPs are not anaphoric since their meanings can be understood from general world knowledge. They found that existential NPs account for 63% of all definite NPs and 76% of them could be identified by syntactic or lexical means. Using 1600 MUC-4 terrorism news documents as the training data, they achieved 87% in precision and 78% in recall at identifying non-anaphoric definite NPs. Cherry and Bergsma (2005) extended the work of Lappin and Leass (1994) for largescale anaphoricity determination by additionally detecting non-anaphoric instances of it using Minipar’s pleonastic category Subj. This is done by both employing Minipar’s named entity recognition to identify time expressions, such as “it was midnight... ”, and providing a number of other linguistic patterns to match common nonanaphoric it cases, such as in expressions “darn it” and don’t overdo it”. Bergsma et al (2008) proposed a distributional method in detecting non-anaphoric pronouns by first extracting the surrounding textual context of the pronoun, then gathering the distribut</context>
</contexts>
<marker>Lappin, Leass, 1994</marker>
<rawString>Lappin S. and Leass H.J. (1994). An algorithm for pronominal anaphora resolution. Computational Linguistics, 20(4):535.561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution.</title>
<date>2002</date>
<pages>2002--730</pages>
<contexts>
<context position="2080" citStr="Ng and Cardie 2002" startWordPosition="299" endWordPosition="302">when two NPs can co-refer remains an active area of research in the community. One significant constraint on coreference, the anaphoricity constraint, specifies that a nonanaphoric NP cannot be coreferent with any of its preceding NPs in a given text. Therefore, it is useful to skip over these non-anaphoric NPs rather than attempt an unnecessary search for an antecedent for them, only to end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999;</context>
<context position="5915" citStr="Ng and Cardie 2002" startWordPosition="892" endWordPosition="895">ilarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative, Lappin and Leass (1994), and Kennedy and Boguraev (1996) looked for modal ad</context>
<context position="8819" citStr="Ng and Cardie (2002" startWordPosition="1335" endWordPosition="1338">istributional method achieved the performance of 81.4%, 71.0% and 75.8 in precision, recall and F1-measure, respectively, compared with the performance of 93.4%, 21.0% and 34.3 in precision, recall and F1-measure, respectively using the rule-based approach as described in Lappin and Leass (1994), and the performance of 66.4%, 49.7% and 56.9 in precision, recall and F1-measure, respectively using the rule-based approach as described in Cherry and Bergsma (2005). Among the learning-based methods, Evans (2001) applied a machine learning approach on identifying the non-anaphoricity of pronoun it. Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information 1 www.cs.ualberta.ca/~bergsma/ItBank/ 979 can be incorporated into a coreference resolution system. Experiments show that their method improves the performance of coreference resolution by 2.0 and 2.6 to 65.8 and 64.2 in F1- measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss in recall. Ng (2004) examined the representation and optimization issues in computing and using anaphoricity information to improve learning-based corefer</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Ng V. and Cardie C. (2002a). Identifying anaphoric and non-anaphoric noun phrases to improve coreference resolution. COLING’2002:730-736.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
<author>C Cardie</author>
</authors>
<title>Improving machine learning approaches to coreference resolution.</title>
<date>2002</date>
<volume>2002</volume>
<pages>104--111</pages>
<contexts>
<context position="2080" citStr="Ng and Cardie 2002" startWordPosition="299" endWordPosition="302">when two NPs can co-refer remains an active area of research in the community. One significant constraint on coreference, the anaphoricity constraint, specifies that a nonanaphoric NP cannot be coreferent with any of its preceding NPs in a given text. Therefore, it is useful to skip over these non-anaphoric NPs rather than attempt an unnecessary search for an antecedent for them, only to end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999;</context>
<context position="5915" citStr="Ng and Cardie 2002" startWordPosition="892" endWordPosition="895">ilarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative, Lappin and Leass (1994), and Kennedy and Boguraev (1996) looked for modal ad</context>
<context position="8819" citStr="Ng and Cardie (2002" startWordPosition="1335" endWordPosition="1338">istributional method achieved the performance of 81.4%, 71.0% and 75.8 in precision, recall and F1-measure, respectively, compared with the performance of 93.4%, 21.0% and 34.3 in precision, recall and F1-measure, respectively using the rule-based approach as described in Lappin and Leass (1994), and the performance of 66.4%, 49.7% and 56.9 in precision, recall and F1-measure, respectively using the rule-based approach as described in Cherry and Bergsma (2005). Among the learning-based methods, Evans (2001) applied a machine learning approach on identifying the non-anaphoricity of pronoun it. Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information 1 www.cs.ualberta.ca/~bergsma/ItBank/ 979 can be incorporated into a coreference resolution system. Experiments show that their method improves the performance of coreference resolution by 2.0 and 2.6 to 65.8 and 64.2 in F1- measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss in recall. Ng (2004) examined the representation and optimization issues in computing and using anaphoricity information to improve learning-based corefer</context>
</contexts>
<marker>Ng, Cardie, 2002</marker>
<rawString>Ng V. and Cardie C. (2002b). Improving machine learning approaches to coreference resolution. ACL’2002: 104-111</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Learning Noun Phrase Anaphoricity to Improve Conference Resolution: Issues in Representation and Optimization.</title>
<date>2004</date>
<volume>2004</volume>
<pages>151--158</pages>
<contexts>
<context position="2766" citStr="Ng 2004" startWordPosition="407" endWordPosition="408">as been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity. Given the labeled data and the unlabeled data, the LP algorithm first represents labeled and unlabeled instances as vertices in a connected graph, then propagates the label information from any vertex to near</context>
<context position="5925" citStr="Ng 2004" startWordPosition="896" endWordPosition="897">explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative, Lappin and Leass (1994), and Kennedy and Boguraev (1996) looked for modal adjectives (</context>
<context position="9285" citStr="Ng (2004)" startWordPosition="1409" endWordPosition="1410">learning-based methods, Evans (2001) applied a machine learning approach on identifying the non-anaphoricity of pronoun it. Ng and Cardie (2002a) employed various domain-independent features in identifying anaphoric NPs and showed how such information 1 www.cs.ualberta.ca/~bergsma/ItBank/ 979 can be incorporated into a coreference resolution system. Experiments show that their method improves the performance of coreference resolution by 2.0 and 2.6 to 65.8 and 64.2 in F1- measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss in recall. Ng (2004) examined the representation and optimization issues in computing and using anaphoricity information to improve learning-based coreference resolution systems. He used an anaphoricity classifier as a filter for coreference resolution. Evaluation on the ACE 2003 corpus shows that, compared with a baseline coreference resolution system of no explicit anaphoricity determination, their method improves the performance by 2.8, 2.2 and 4.5 to 54.5, 64.0 and 60.8 in F1-measure (due to the gain in precision) on the NWIRE, NPAPER and BNEWS domains, respectively, via careful determination of an anaphorici</context>
</contexts>
<marker>Ng, 2004</marker>
<rawString>Ng V. (2004). Learning Noun Phrase Anaphoricity to Improve Conference Resolution: Issues in Representation and Optimization. ACL’2004: 151-158</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Paice</author>
<author>G D Husk</author>
</authors>
<title>Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun it. Computer Speech and Language,</title>
<date>1987</date>
<pages>2--109</pages>
<contexts>
<context position="2450" citStr="Paice and Husk 1987" startWordPosition="356" endWordPosition="359">ent for them, only to end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systemati</context>
<context position="5679" citStr="Paice and Husk 1987" startWordPosition="854" endWordPosition="857">ntactic structured information. The rest of this paper is organized as follows. In Section 2, we review related work in anaphoricity determination. Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-ana</context>
</contexts>
<marker>Paice, Husk, 1987</marker>
<rawString>Paice C.D. and Husk G.D. (1987). Towards the automatic recognition of anaphoric features in English text: the impersonal pronoun it. Computer Speech and Language, 2:109-132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W M Soon</author>
<author>H T Ng</author>
<author>D Lim</author>
</authors>
<title>A machine learning approach to coreference resolution of noun phrase. Computational Linguistics,</title>
<date>2001</date>
<pages>27--4</pages>
<contexts>
<context position="2060" citStr="Soon et al 2001" startWordPosition="295" endWordPosition="298">c constraints on when two NPs can co-refer remains an active area of research in the community. One significant constraint on coreference, the anaphoricity constraint, specifies that a nonanaphoric NP cannot be coreferent with any of its preceding NPs in a given text. Therefore, it is useful to skip over these non-anaphoric NPs rather than attempt an unnecessary search for an antecedent for them, only to end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., B</context>
<context position="23500" citStr="Soon et al (2001)" startWordPosition="3791" endWordPosition="3794">lution. 5.1 Experimental Setting The ACE 2003 corpus contains three domains: newswire (NWIRE), newspaper (NPAPER), and broadcast news (BNEWS). For each domain, there exist two data sets, training and devtest, which are used for training and testing respectively. As a baseline coreference resolution system, a raw test text is first preprocessed automatically by a pipeline of NLP components, including sentence boundary detection, POS tagging, named entity recognition and phrase chunking, and then a training or test instance is formed by a anaphor and one of its antecedent candidates, similar to Soon et al (2001). Among them, named entity recognition, part-of-speech tagging and noun phrase chunking apply the same Hidden Markov Model (HMM)-based engine with 983 error-driven learning capability (Zhou and Su, 2000 &amp; 2002). During training, for each anaphor encountered, a positive instance is created by pairing the anaphor and its closest antecedent while a set of negative instances is formed by pairing the anaphor with each of the noncoreferential candidates. Based on the training instances, a binary classifier is generated using a particular learning algorithm. In this paper, we use SVMLight developed b</context>
</contexts>
<marker>Soon, Ng, Lim, 2001</marker>
<rawString>Soon W.M., Ng H.T. and Lim D. (2001). A machine learning approach to coreference resolution of noun phrase. Computational Linguistics, 2001, 27(4):521-544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>C Muller</author>
</authors>
<title>A machine learning approach to pronoun resolution in spoken dialogue.</title>
<date>2003</date>
<volume>2003</volume>
<pages>168--175</pages>
<contexts>
<context position="2105" citStr="Strube and Muller 2003" startWordPosition="303" endWordPosition="306">efer remains an active area of research in the community. One significant constraint on coreference, the anaphoricity constraint, specifies that a nonanaphoric NP cannot be coreferent with any of its preceding NPs in a given text. Therefore, it is useful to skip over these non-anaphoric NPs rather than attempt an unnecessary search for an antecedent for them, only to end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and </context>
</contexts>
<marker>Strube, Muller, 2003</marker>
<rawString>Strube M. and Muller C. (2003). A machine learning approach to pronoun resolution in spoken dialogue. ACL’2003: 168-175</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Vieira</author>
<author>M Poesio</author>
</authors>
<title>An empirically based system for processing definite descriptions.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>27</volume>
<issue>4</issue>
<pages>539--592</pages>
<contexts>
<context position="2583" citStr="Vieira and Poesio 2000" startWordPosition="375" endWordPosition="378">on have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity. Given the labeled data an</context>
<context position="5767" citStr="Vieira and Poesio 2000" startWordPosition="868" endWordPosition="871">ection 2, we review related work in anaphoricity determination. Then, the LP algorithm is introduced in Section 3 while Section 4 describes different similarity measurements explored in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found </context>
</contexts>
<marker>Vieira, Poesio, 2000</marker>
<rawString>Vieira R. and Poesio M. (2000). An empirically based system for processing definite descriptions. Computational Linguistics, 27(4): 539–592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Vilain</author>
<author>J Burger</author>
<author>J Aberdeen</author>
<author>D Connolly</author>
<author>L Hirschman</author>
</authors>
<title>A model theoretic coreference scoring scheme.</title>
<date>1995</date>
<volume>6</volume>
<pages>45--52</pages>
<contexts>
<context position="25227" citStr="Vilain et al., 1995" startWordPosition="4056" endWordPosition="4059">t candidates. In particular, the test corpus is resolved in document-level, i.e. one document by one document. For anaphoricity determination, we report the performance in Acc+ and Acc-, which measure the accuracies of identifying anaphoric NPs and non-anaphoric NPs, respectively. Obviously, higher Acc+ means that more anaphoric NPs would be identified correctly, while higher Accmeans that more non-anaphoric NPs would be filtered out. For coreference resolution, we report the performance in terms of recall, precision, and F1-measure using the commonly-used model theoretic MUC scoring program (Vilain et al., 1995). For separate scoring of different NP types, a recognized reference is considered correct if the reconized antecedent is in the coreferential chain of the anaphor. To see whether an improvement is significant, we conduct significance testing using paired t-test. In this paper, ‘&gt;&gt;&gt;’, ‘&gt;&gt;’ and ‘&gt;’ denote p-values of an improvement smaller than 0.01, inbetween (0.01, 0,05] and bigger than 0.05, which mean significantly better, moderately better and slightly better, respectively. 5.2 Experimental Results Table 2 shows the performance of LP-based anaphoricity determination using the feature-based</context>
</contexts>
<marker>Vilain, Burger, Aberdeen, Connolly, Hirschman, 1995</marker>
<rawString>Vilain M., Burger J., Aberdeen J., Connolly D. and Hirschman L. (1995). A model theoretic coreference scoring scheme. MUC-6: 45–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X F Yang</author>
<author>G D Zhou</author>
<author>J Su</author>
<author>C L Chew</author>
</authors>
<title>Coreference Resolution Using Competition Learning Approach.</title>
<date>2003</date>
<pages>2003--177</pages>
<contexts>
<context position="2122" citStr="Yang et al 2003" startWordPosition="307" endWordPosition="310">rea of research in the community. One significant constraint on coreference, the anaphoricity constraint, specifies that a nonanaphoric NP cannot be coreferent with any of its preceding NPs in a given text. Therefore, it is useful to skip over these non-anaphoric NPs rather than attempt an unnecessary search for an antecedent for them, only to end up with inaccurate outcomes. Although many existing machine learning approaches to coreference resolution have performed reasonably well without explicit anaphoricity determination (e.g., Soon et al 2001; Ng and Cardie 2002b; Strube and Muller 2003; Yang et al 2003, 2008), anaphoricity determination has been studied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e</context>
<context position="10262" citStr="Yang et al 2003" startWordPosition="1556" endWordPosition="1559">y determination, their method improves the performance by 2.8, 2.2 and 4.5 to 54.5, 64.0 and 60.8 in F1-measure (due to the gain in precision) on the NWIRE, NPAPER and BNEWS domains, respectively, via careful determination of an anaphoricity threshold with proper constraint-based representation and global optimization. However, he did not look into the contribution of anaphoricity determination on coreference resolution of different NP types, such as pronoun and definite NPs. Yang et al (2005) made use of nonanaphors to create a special class of training instances in the twin-candidate model (Yang et al 2003) and thus equipped it with the nonanaphoricity determination capability. Experiments show that the proposed method improves the performance by 2.9 and 1.6 to 67.3 and 67.2 in F1-measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss in recall. However, surprisingly, their experiments also show that eliminating non-anaphors using an anaphoricity determination module in advance harms the performance. Denis and Balbridge (2007) employed an integer linear programming (ILP) formulation for coreference resolution which models anaphoricity and </context>
<context position="21554" citStr="Yang et al (2003)" startWordPosition="3478" endWordPosition="3481">d while “the room” is not since the former is compatible with the NP “the woman” and the latter is not compatible with the NP “the woman”. In this way, possible coreference between current NP and the compatible antecedent candidates can be included in the parse tree structure. In some sense, this is a natural extension of the twin-candidate 3 With matched number, person and gender agreements. 4 For simplicity, only verbal predicates are considered in this paper. However, this can be extended to nominal predicates with automatic identification of nominal predicates. learning method proposed in Yang et al (2003), which explicitly models the competition between two antecedent candidates. 2) For each node in MT, attaching the path from the node to the leaf node of the corresponding predicate, if it is predicate-headed, in the sense that such predicate-related information is useful in identifying certain kinds of expressions with non-anaphoric NPs, e.g. the non-anaphoric it in “darn it”. As shown in Figure 3(d), “said” and “hit” are attached. 3) Attaching the path to the head word of the first right sibling if the parent of current NP is a NP and current NP has one or more right siblings. Normally, the </context>
<context position="30392" citStr="Yang et al (2003)" startWordPosition="4879" endWordPosition="4882">oun 90.1 75.6 90.7 79.2 89.2 77.5 ProperNoun 71.4 83.5 72.8 78.1 68.3 77.2 DefiniteNP 74.6 89.1 77.3 85.5 75.3 88.7 InDefiniteNP 93.2 92.1 90.2 94.2 89.4 95.5 Overall 79.2 87.8 81.2 84.5 76.5 85.3 Table 5: The performance of LP-based anaphoricity determination using the tree kernel on DET Finally, we evaluate the effect of LP-based anaphoricity determination on coreference resolution by including it as a preprocessing step to a baseline coreference resolution system without explicit anaphoricity determination, which employs the same set of features, as adopted in the single-candidate model of Yang et al (2003), using a SVM-based classifier and the featurebased RBF kernel. It shows that anaphoricity determination with the feature-based RBF Kernel much improves (&gt;&gt;&gt;) the performance of coreference resolution with most of the contribution due to pronoun resolution while its contribution on definite NPs can be ignored. It indicates the usefulness of anaphoricity determination in filtering out non-anaphoric pronouns and the difficulty in identifying anaphoric definite NPs, using the feature-based RBF kernel. It also shows that tree kernel-based anaphoricity determination can not only improve (&gt;&gt;&gt;) the p</context>
</contexts>
<marker>Yang, Zhou, Su, Chew, 2003</marker>
<rawString>Yang X.F., Zhou G.D., Su J. and Chew C.L. (2003). Coreference Resolution Using Competition Learning Approach. ACL’2003:177-184</rawString>
</citation>
<citation valid="true">
<authors>
<author>X F Yang</author>
<author>J Su</author>
<author>C L Tan</author>
</authors>
<title>A TwinCandidate Model of Coreference Resolution with Non-Anaphor Identification Capability.</title>
<date>2005</date>
<pages>2005--719</pages>
<contexts>
<context position="2783" citStr="Yang et al 2005" startWordPosition="409" endWordPosition="412">tudied fairly extensively in the literature, given the potential usefulness of NP anaphoricity in coreference resolution. One common approach involves the design of heuristic rules to identify specific types of nonanaphoric NPs, such as pleonastic pronouns (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998) and existential definite descriptions (e.g., Vieira and Poesio 2000). More recently, the problem has been tackled using statistics-based (e.g., Bean and Riloff 1999; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007) methods. Although there is empirical evidence (e.g. Ng and Cardie 2002a, 2004) that coreference resolution might be further improved with proper anaphoricity information, its contribution is still somewhat disappointing and lacks systematic evaluation. This paper employs a label propagation (LP) algorithm for global learning of NP anaphoricity. Given the labeled data and the unlabeled data, the LP algorithm first represents labeled and unlabeled instances as vertices in a connected graph, then propagates the label information from any vertex to nearby vertices throu</context>
<context position="5942" citStr="Yang et al 2005" startWordPosition="898" endWordPosition="901">in the LP algorithm. Section 5 shows the experimental results. Finally, we conclude our work in Section 6. 2 Related Work Given its potential usefulness in coreference resolution, anaphoricity determination has been studied fairly extensively in the literature and can be classified into three categories: heuristic rule-based (e.g. Paice and Husk 1987; Lappin and Leass 1994; Kennedy and Boguraev 1996; Denber 1998; Vieira and Poesio 2000), statistics-based (e.g., Bean and Riloff 1999; Cherry and Bergsma 2005; Bergsma et al 2008) and learning-based (e.g. Evans 2001; Ng and Cardie 2002a; Ng 2004; Yang et al 2005; Denis and Balbridge 2007). For the heuristic rule-based approaches, Paice and Husk (1987), Lappin and Leass (1994), Kennedy and Boguraev (1996), Denber (1998), and Cherry and Bergsma (2005) looked for particular constructions using certain trigger words to identify pleonastic pronouns while Vieira and Poesio (2000) recognized non-anaphoric definite NPs through the use of syntactic cues and casesensitive rules and found that nearly 50% of definite NPs are non-anaphoric. As a representative, Lappin and Leass (1994), and Kennedy and Boguraev (1996) looked for modal adjectives (e.g. “necessary”)</context>
<context position="10144" citStr="Yang et al (2005)" startWordPosition="1534" endWordPosition="1537">on on the ACE 2003 corpus shows that, compared with a baseline coreference resolution system of no explicit anaphoricity determination, their method improves the performance by 2.8, 2.2 and 4.5 to 54.5, 64.0 and 60.8 in F1-measure (due to the gain in precision) on the NWIRE, NPAPER and BNEWS domains, respectively, via careful determination of an anaphoricity threshold with proper constraint-based representation and global optimization. However, he did not look into the contribution of anaphoricity determination on coreference resolution of different NP types, such as pronoun and definite NPs. Yang et al (2005) made use of nonanaphors to create a special class of training instances in the twin-candidate model (Yang et al 2003) and thus equipped it with the nonanaphoricity determination capability. Experiments show that the proposed method improves the performance by 2.9 and 1.6 to 67.3 and 67.2 in F1-measure on the MUC-6 and MUC-7 corpora, respectively, due to much more gain in precision compared with the loss in recall. However, surprisingly, their experiments also show that eliminating non-anaphors using an anaphoricity determination module in advance harms the performance. Denis and Balbridge (20</context>
</contexts>
<marker>Yang, Su, Tan, 2005</marker>
<rawString>Yang X.F., Su J. and Tan C.L. (2005). A TwinCandidate Model of Coreference Resolution with Non-Anaphor Identification Capability. IJCNLP’2005:719-730.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X F Yang</author>
<author>J Su</author>
<author>C L Tan</author>
</authors>
<title>Kernel-based pronoun resolution with structured syntactic knowledge.</title>
<date>2006</date>
<volume>2006</volume>
<pages>41--48</pages>
<contexts>
<context position="19034" citStr="Yang et al (2006)" startWordPosition="3055" endWordPosition="3058">hunks, current chunk (i.e. current NP) and following two chunks, and prune out the substructures outside the window. Figure 2 shows the full parse tree for the sentence “Mary said the woman in the room hit her too”, using the Charniak parser (Charniak 2001), and the chunk sequence derived from the parse tree using the Perl script2 written by Sabine Buchholz from Tilburg University. Here, we explore four parse tree structures in NP anaphoricity determination: the common tree (CT), the shortest path-enclosed tree (SPT), the minimum tree (MT) and the dynamically extended tree (DET), motivated by Yang et al (2006) and Zhou et al (2008). Following are the examples of the four parse tree structures, corresponding to the full parse tree and the chunk sequence, as shown in Figure 2, with the NP chunk “(NP (DT the) (NN woman))” in anaphoricity determination. Common Tree (CT) As shown in Figure 3(a), CT is the complete sub-tree rooted by the nearest common ancestor of the first chunk “(NP (NNP Mary))” and the 2 http://ilk.kub.nl/~sabine/chunklink/ last chunk “(NP (DT the) (NN room))” of the five-chunk window. Shortest Path-enclosed Tree (SPT) As shown in Figure 3(b), SPT is the smallest common sub-tree enclo</context>
</contexts>
<marker>Yang, Su, Tan, 2006</marker>
<rawString>Yang X.F., Su J. and Tan C.L. (2006). Kernel-based pronoun resolution with structured syntactic knowledge. COLING-ACL’2006: 41-48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X F Yang</author>
<author>J Su</author>
<author>J Lang</author>
<author>C L Tan</author>
<author>T Liu</author>
<author>S Li</author>
</authors>
<title>An Entity-Mention Model for Coreference Resolution with Inductive Logic Programming.</title>
<date>2008</date>
<volume>2008</volume>
<pages>843--851</pages>
<marker>Yang, Su, Lang, Tan, Liu, Li, 2008</marker>
<rawString>Yang X.F., Su J., Lang J., Tan C.L., Liu T. and Li S. (2008). An Entity-Mention Model for Coreference Resolution with Inductive Logic Programming. ACL’2008: 843-851.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J</author>
</authors>
<title>Error-driven HMMbased chunk tagger with context-dependent lexicon.</title>
<date>2000</date>
<pages>2000--71</pages>
<marker>J, 2000</marker>
<rawString>Zhou G.D. and Su. J. (2000). Error-driven HMMbased chunk tagger with context-dependent lexicon. EMNLP-VLC’2000: 71–79</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Zhou</author>
<author>J Su</author>
</authors>
<title>Named Entity recognition using a HMM-based chunk tagger.</title>
<date>2002</date>
<booktitle>In ACL’2002:473–480.</booktitle>
<marker>Zhou, Su, 2002</marker>
<rawString>Zhou G.D. and Su J. (2002). Named Entity recognition using a HMM-based chunk tagger. In ACL’2002:473–480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G D Zhou</author>
<author>F Kong</author>
<author>Q M Zhu</author>
</authors>
<title>Contextsensitive convolution tree kernel for pronoun resolution .</title>
<date>2008</date>
<pages>2008--25</pages>
<contexts>
<context position="19056" citStr="Zhou et al (2008)" startWordPosition="3060" endWordPosition="3063">i.e. current NP) and following two chunks, and prune out the substructures outside the window. Figure 2 shows the full parse tree for the sentence “Mary said the woman in the room hit her too”, using the Charniak parser (Charniak 2001), and the chunk sequence derived from the parse tree using the Perl script2 written by Sabine Buchholz from Tilburg University. Here, we explore four parse tree structures in NP anaphoricity determination: the common tree (CT), the shortest path-enclosed tree (SPT), the minimum tree (MT) and the dynamically extended tree (DET), motivated by Yang et al (2006) and Zhou et al (2008). Following are the examples of the four parse tree structures, corresponding to the full parse tree and the chunk sequence, as shown in Figure 2, with the NP chunk “(NP (DT the) (NN woman))” in anaphoricity determination. Common Tree (CT) As shown in Figure 3(a), CT is the complete sub-tree rooted by the nearest common ancestor of the first chunk “(NP (NNP Mary))” and the 2 http://ilk.kub.nl/~sabine/chunklink/ last chunk “(NP (DT the) (NN room))” of the five-chunk window. Shortest Path-enclosed Tree (SPT) As shown in Figure 3(b), SPT is the smallest common sub-tree enclosed by the shortest pa</context>
</contexts>
<marker>Zhou, Kong, Zhu, 2008</marker>
<rawString>Zhou G.D., Kong F. and Zhu Q.M. (2008). Contextsensitive convolution tree kernel for pronoun resolution . IJCNLP’2008:25-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
</authors>
<title>Learning from Labeled and Unlabeled Data with Label Propagation.</title>
<date>2002</date>
<tech>CMU CALD Technical Report.CMU-CALD02-107.</tech>
<contexts>
<context position="11506" citStr="Zhu and Ghahramani 2002" startWordPosition="1743" endWordPosition="1746">nt task, such that each local model informs the other for final assignments. Experiments on the NWIRE, NPAPER and BNEWS domains of the ACE 2003 corpus shows that this joint anaphoricity-coreference ILP formulation improves the F1-measure by 0.7-1.0 over the coreferenceonly ILP formulation. However, their experiments assume true ACE mentions(i.e. all the ACE mentions are already known from the annotated corpus). Therefore, the actual effect of this joint anaphoricity-coreference ILP formulation on fully-automatic coreference resolution is still unclear. 3 Label Propagation In the LP algorithm (Zhu and Ghahramani 2002), the natural clustering structure in data is represented as a connected graph. Given the labeled data and unlabeled data, the LP algorithm first represents labeled and unlabeled instances as vertices in a connected graph, then propagates the label information from any vertex to nearby vertices through weighted edges and finally infers the labels of unlabeled instances until a global stable stage is achieved. Figure 1 presents the label propagation algorithm. Assume: Y : the n * r labeling matrix, where yij represents the probability of vertex xi (i = 1... n) with label rj (j = 1... r) ; YL : </context>
<context position="14282" citStr="Zhu and Ghahramani 2002" startWordPosition="2262" endWordPosition="2265">istribution of the labeled data is clamped in each loop using their initial weights and acts like forces to push out labels through the unlabeled data. With this push originating from the labeled data, the label boundaries will be pushed faster along edges with larger weights and settle in gaps along those with lower weights. Ideally, we can expect that wij across different classes should be as small as possible and wij within the same class as big as possible. In this way, label propagation tends to happen within the same class. This algorithm has been shown to converge to a unique solution (Zhu and Ghahramani 2002), which can be obtained without iteration in theory, and the initialization of YU0 (the unlabeled data) is not important since YU0 does not affect its estimation. However, proper initialization of YU0 actually helps the algorithm converge more rapidly in practice. In this paper, each row in YU0 , i.e. the label distribution for each test instance, is initialized to the weighted similarity of the test instance with the labeled instances. 4 Kernel-based Similarity The key issue in label propagation is how to compute the similarity wij between two instances xi and xj . This paper examines two sim</context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>Zhu X. and Ghahramani Z. (2002). Learning from Labeled and Unlabeled Data with Label Propagation. CMU CALD Technical Report.CMU-CALD02-107.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>