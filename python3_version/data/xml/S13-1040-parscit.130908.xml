<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002557">
<title confidence="0.876137">
Metaphor Identification as Interpretation
</title>
<author confidence="0.989924">
Ekaterina Shutova
</author>
<affiliation confidence="0.997317666666667">
International Computer Science Institute and
Institute for Cognitive and Brain Sciences
University of California, Berkeley
</affiliation>
<email confidence="0.997792">
katia@berkeley.edu
</email>
<sectionHeader confidence="0.997384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999720875">
Automatic metaphor identification and inter-
pretation in text have been traditionally con-
sidered as two separate tasks in natural lan-
guage processing (NLP) and addressed in-
dividually within computational frameworks.
However, cognitive evidence suggests that hu-
mans are likely to perform these two tasks si-
multaneously, as part of a holistic metaphor
comprehension process. We present a novel
method that performs metaphor identification
through its interpretation, being the first one
in NLP to combine the two tasks in one
step. It outperforms the previous approaches
to metaphor identification both in terms of ac-
curacy and coverage, as well as providing an
interpretation for each identified expression.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999394285714286">
Metaphor undoubtedly gives our expression more
vividness, distinction and artistry, however, it is also
an important linguistic tool that has long become
part of our every-day language. Metaphors arise
when one concept or domain is viewed in terms
of the properties of another (Lakoff and Johnson,
1980). Consider the examples in (1) and (2).
</bodyText>
<listItem confidence="0.9955305">
(1) My car drinks gasoline. (Wilks, 1978)
(2) This policy is strangling business.
</listItem>
<bodyText confidence="0.999926738095238">
The car in (1) and business in (2) are viewed as
living beings and thus they can drink or be stran-
gled respectively. The mapping between the car
(the target concept) and living being (the source
concept) is systematic and results in a number of
metaphorical expressions (e.g. “This oil gives your
car a second life”, “this car has is very temperamen-
tal” etc.) Lakoff and Johnson call such generalisa-
tions a source–target domain mapping, or concep-
tual metaphor.
The ubiquity of metaphor in language has been
established in a number of corpus studies (Cameron,
2003; Martin, 2006; Steen et al., 2010; Shutova
and Teufel, 2010) and the role it plays in human
reasoning has been confirmed in psychological ex-
periments (Thibodeau and Boroditsky, 2011). This
makes its automatic processing an important prob-
lem for NLP and its numerous applications (such
as machine translation, information extraction, opin-
ion mining and many others). For example, the
use of the metaphorical verb strangle in (2) reflects
the speaker’s negative opinion regarding the gov-
ernment’s tight business regulations, which would
be an important fact for an opinion mining system
to discover (Narayanan, 1999). Other experiments
(Agerri, 2008) have investigated and confirmed the
role of metaphor interpretation for textual entailment
resolution (RTE).
The problem of metaphor modeling is rapidly
gaining interest within NLP, with a growing number
of approaches exploiting statistical techniques (Ma-
son, 2004; Gedigian et al., 2006; Shutova, 2010;
Shutova et al., 2010; Turney et al., 2011; Shutova
et al., 2012a). Compared to more traditional ap-
proaches based on hand-coded knowledge (Fass,
1991; Martin, 1990; Narayanan, 1997; Narayanan,
1999; Feldman and Narayanan, 2004; Barnden and
Lee, 2002; Agerri et al., 2007), these more recent
methods tend to have a wider coverage, as well as be
more efficient, accurate and robust. However, even
the statistical metaphor processing approaches so far
often focused on a limited domain or a subset of
</bodyText>
<page confidence="0.972632">
276
</page>
<note confidence="0.900825">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference
and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999834515625">
phenomena (Gedigian et al., 2006; Krishnakumaran
and Zhu, 2007), and required training data (Shutova
et al., 2010; Turney et al., 2011), often resulting in
a limited coverage. The metaphor processing task
itself has been most commonly addressed in NLP
as two individual subtasks: metaphor identification
and metaphor interpretation, with the systems focus-
ing only on one of them at a time, or at best comb-
ing the two in a pipeline (Shutova et al., 2012a).
Metaphor identification systems annotate metaphor-
ical language in text, and metaphor interpretation
systems discover literal meanings of the previously
annotated expressions. However, cognitive evidence
suggests that humans are likely to perform identifi-
cation and interpretation simultaneously, as part of
a holistic metaphor comprehension process (Coul-
son, 2008; Utsumi, 2011; Gibbs and Colston, 2012).
In this paper, we also take this stance and present the
first computational method that identifies metaphori-
cal expressions in unrestricted text by means of their
interpretation. Following Shutova (2010), we define
metaphor interpretation as a task of finding a literal
paraphrase for a metaphorically used word and in-
troduce the concept of symmetric reverse paraphras-
ing as a criterion for metaphor identification. The
main assumption behind our method is that the lit-
eral paraphrases of literally-used words should yield
the original phrase when paraphrased in reverse. For
example, when the expression “clean the house” is
paraphrased as “tidy the house”, the reverse para-
phrasing of tidy would generate clean. Our expec-
tation is that such a symmetry in paraphrasing is
indicative of literal use. The metaphorically-used
words are unlikely to exhibit this symmetry prop-
erty when paraphrased in reverse. For example, the
literal paraphrasing of the verb stir in “stir excite-
ment” would yield “provoke excitement”, but the
reverse paraphrasing of provoke would not retrieve
stir, indicating the non-literal use of stir.
We experimentally verify this hypothesis in a set-
ting involving single-word metaphors expressed by
a verb in verb-subject and verb-direct object rela-
tions. We apply the selectional preference-based
metaphor paraphrasing method of Shutova (2010) to
retrieve literal paraphrases of all input verbs and ex-
tend the method to perform metaphor identification.
In summary, our system (1) determines the likeli-
hood of a verb being metaphorical based on its selec-
tional preference strength (Resnik, 1993); (2) identi-
fies a set of literal paraphrases for verbs that may be
used metaphorically using the algorithm of Shutova
(2010); (3) performs reverse paraphrasing of each
of the identified paraphrases, aiming to retrieve the
original expression; and (4) if the original expres-
sion is retrieved then the verb is tagged as literal,
otherwise it is tagged as metaphorical.
We evaluated the performance of the system using
the manually annotated metaphor corpus of Shutova
and Teufel (2010) in precision- and recall-oriented
settings. In addition, we compared its performance
to that of a baseline using selectional preference vi-
olation as an indicator of metaphor, as well as to
two previous metaphor identification approaches of
Shutova et al. (2010) and Turney et al. (2011).
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999951103448276">
One of the first attempts to identify and interpret
metaphorical expressions in text is the met* sys-
tem of Fass (1991), that utilizes hand-coded knowl-
edge and detects non-literalness via selectional pref-
erence violation. In case of a violation, the re-
spective phrase is first tested for being metonymic
using hand-coded patterns (e.g. CONTAINER-FOR-
CONTENT). If this fails, the system searches the
knowledge base for a relevant analogy in order to
discriminate metaphorical relations from anomalous
ones. The system of Krishnakumaran and Zhu
(2007) uses WordNet (the hyponymy relation) and
word bigram counts to predict verbal, nominal and
adjectival metaphors at the sentence level. The au-
thors discriminate between conventional metaphors
(included in WordNet) and novel metaphors. Birke
and Sarkar (2006) present a sentence clustering ap-
proach that employs a set of seed sentences an-
notated for literalness and computes similarity be-
tween the new input sentence and all of the seed sen-
tences. The system then tags the sentence as literal
or metaphorical according to the annotation in the
most similar seeds, attaining an f-score of 53.8%.
The first system to discover source–target domain
mappings automatically is CorMet (Mason, 2004).
It does this by searching for systematic variations
in domain-specific verb selectional preferences. For
example, pour is a characteristic verb in both LAB
and FINANCE domains. In the LAB domain it has
</bodyText>
<page confidence="0.993241">
277
</page>
<bodyText confidence="0.9999604">
a strong preference for liquids and in the FINANCE
domain for money. From this the system infers the
domain mapping FINANCE – LAB and the concept
mapping money – liquid. Gedigian et al. (2006)
trained a maximum entropy classifier to discrimi-
nate between literal and metaphorical use. They
annotated the sentences from PropBank (Kingsbury
and Palmer, 2002) containing the verbs of MOTION
and CURE for metaphoricity. They used PropBank
annotation (arguments and their semantic types) as
features for classification and report an accuracy
of 95.12% (however, against a majority baseline of
92.90%). The metaphor identification system of
Shutova et al. (2010) starts from a small seed set
of metaphorical expressions, learns the analogies in-
volved in their production and extends the set of
analogies by means of verb and noun clustering. As
a result, the system can recognize new metaphorical
expressions in unrestricted text (e.g. from the seed
“stir excitement” it infers that “swallow anger” is
also a metaphor), achieving a precision of 79%.
Turney et al. (2011) classify verbs and adjectives
as literal or metaphorical based on their level of con-
creteness or abstractness in relation to a noun they
appear with. They learn concreteness rankings for
words automatically (starting from a set of exam-
ples) and then search for expressions where a con-
crete adjective or verb is used with an abstract noun
(e.g. “dark humour” is tagged as a metaphor and
“dark hair” is not). They report an accuracy of 73%.
</bodyText>
<sectionHeader confidence="0.998283" genericHeader="method">
3 Method
</sectionHeader>
<subsectionHeader confidence="0.999904">
3.1 Selectional Preference Strength Filtering
</subsectionHeader>
<bodyText confidence="0.999942170731707">
One of the early influential ideas in the field of com-
putational metaphor processing is that metaphor rep-
resents a violation of selectional preferences (SP)
of a word in a given context (Wilks, 1975; Wilks,
1978). However, applied directly as an identifica-
tion criterion, violation of SPs is also indicative of
many other linguistic phenomena (e.g. metonymy),
and not only metaphor, which is problematic. We
modify this view and apply it to measure the poten-
tial of a word to be used metaphorically based on its
selectional preference strength (SPS). The main in-
tuition behind SPS filtering is that not all verbs have
an equal potential of being a metaphor. For example,
verbs such as choose, remember, describe or like do
not have a strong preference for their direct objects
and are equally likely to appear with many argument
classes. If metaphor represents a violation of SPs,
then the verbs with weak SPS are unlikely to be used
metaphorically in any context. For every verb in the
input text, the filter determines their likelihood of
being a metaphor based on their SPS and discards
the weak ones. The SPS filter is context-free, and
the reverse paraphrasing method is then applied in
the next steps to determine if the remaining verbs
are indeed used metaphorically in the given context.
We automatically acquired selectional preference
distributions for verb-subject and verb-direct object
relations from the British National Corpus (BNC)
(Burnard, 2007) that was parsed using the RASP
parser (Briscoe et al., 2006; Andersen et al., 2008).
We applied the noun clustering method of Sun and
Korhonen (2009) to 2000 most frequent nouns in
the BNC to obtain 200 common selectional prefer-
ence classes. To quantify selectional preferences, we
adopted the SPS measure of Resnik (1993). Resnik
defines SPS of a verb as the difference between the
posterior distribution of noun classes in a particular
relation with the verb and their prior distribution in
that syntactic position (regardless of the verb). He
quantifies this difference using the Kullback-Leibler
divergence:
</bodyText>
<equation confidence="0.997708666666667">
SR(v) = D(P(c|v)||P(c)) =
EPc
P(c|v) log P(C|V), (1)
</equation>
<bodyText confidence="0.999147875">
where P(c) is the prior probability of the noun class,
P(c|v) is the posterior probability of the noun class
given the verb and R is the grammatical relation.
We calculated SPS for verb-subject and verb-
direct object grammatical relations. The optimal se-
lectional preference strength thresholds were set ex-
perimentally on a small heldout dataset at 0.30 for
verb-subject and 0.70 for verb-direct object relations
(via qualitative analysis of the data). The system ex-
cludes expressions containing the verbs with prefer-
ence strength below these thresholds from the set of
candidate metaphors. Examples of verbs with weak
direct object SPs include e.g. imagine, avoid, con-
tain, dislike, make, admire, separate, remember and
the strong SPs are exhibited by e.g. sip, hobble, roar,
hoover, slam, skim, drink etc.
</bodyText>
<page confidence="0.982485">
278
</page>
<subsectionHeader confidence="0.999487">
3.2 Literal Paraphrasing
</subsectionHeader>
<bodyText confidence="0.999991047619048">
The verbs that can be used metaphorically ac-
cording to the SPS filter are then paraphrased us-
ing the context-based literal paraphrasing method
of Shutova (2010). While Shutova only used
the method to paraphrase manually annotated
metaphors, we extend and apply the method to para-
phrasing of literally used terms and metaphor identi-
fication, eliminating the need for manual annotation
of metaphorical expressions.
The system takes verbs and their context in the
form of subject and direct-object relations as input.
It generates a list of possible paraphrases of the verb
that can occur in the same context and ranks them
according to their likelihood, as derived from the
corpus. It then identifies shared features of the para-
phrases and the verb using the WordNet (Fellbaum,
1998) hierarchy and removes unrelated concepts. It
then identifies literal paraphrases among the remain-
ing candidates based on the verb’s automatically in-
duced selectional preferences and the properties of
the context.
</bodyText>
<subsectionHeader confidence="0.744704">
3.2.1 Context-based Paraphrase Ranking
</subsectionHeader>
<bodyText confidence="0.999595">
Following Shutova (2010), we compute the like-
lihood L of a particular paraphrase of the verb
v as a joint probability of the paraphrase i co-
occurring with the other lexical items from its con-
</bodyText>
<equation confidence="0.661241">
text w1, ..., wN in syntactic relations r1, ..., rN.
Li = P(i, (w1, r1), (w2, r2), ..., (wN, rN)). (2)
</equation>
<bodyText confidence="0.998774">
Assuming statistical independence between the rela-
tions of the terms in a phrase, we obtain:
</bodyText>
<equation confidence="0.998658333333333">
P(i, (w1, r1), (w2, r2), ..., (wN, rN)) =
(3)
P(i) · P((w1, r1)|i) · ... · P((wN, rN)|i).
</equation>
<bodyText confidence="0.7978495">
The probabilities can be calculated using maxi-
mum likelihood estimation as P(i) = f(i)
</bodyText>
<equation confidence="0.831136">
�k f(ik)
and P(wn, rn|i) = f(wn,rn,i) where f (i) is the
f (i)
</equation>
<bodyText confidence="0.955411571428571">
frequency of the interpretation irrespective of its
arguments, Ek f(ik) is the number of times its
part of speech class is attested in the corpus and
f(wn, rn, i) is the number of times the interpreta-
tion co-occurs with context word wn in relation rn.
By performing appropriate substitutions into (3), we
obtain:
</bodyText>
<equation confidence="0.999433857142857">
P(i, (w1, r1), (w2, r2), ..., (wN, rN)) =
f(i) f(w1, r1, i) f(wN, rN, i)
Ek f(ik) · f(i) · ... · f(i)
1
H�7N
l n=1 f(wn, rn, i)
(f(i))N−1 · Ek f(ik).
</equation>
<bodyText confidence="0.949444444444444">
(4)
This model is then used to rank the candidate sub-
stitutes of the verb v in the fixed context according
to the data. The parameters of the model were esti-
mated from the RASP-parsed BNC using the gram-
matical relations output created by Andersen et al.
(2008). The goal of this model is to emphasize the
paraphrases that match the context of the verb in the
sentence best.
</bodyText>
<subsectionHeader confidence="0.809213">
3.2.2 WordNet Filter
</subsectionHeader>
<bodyText confidence="0.999990619047619">
After obtaining the initial list of possible substi-
tutes for the verb v, the system filters out the terms
whose meanings do not share any common proper-
ties with that of the verb. This overlap of properties
is identified using the hyponymy relation in Word-
Net. Within the initial list of paraphrases, the sys-
tem selects the terms that are hypernyms of the verb
v, or share a common hypernym with it. Follow-
ing Shutova, we restrict the hypernym search to a
depth of three levels in the taxonomy. Table 1 shows
the filtered lists of paraphrases for the expressions
“stir excitement” and “campaign surged”. The goal
of the filter is to discard unrelated paraphrases and
thus ensure the meaning retention during paraphras-
ing. Note, however, that we define meaning reten-
tion broadly, as sharing a set of similar basic prop-
erties. Such a broad definition distinguishes our sys-
tem from other WordNet-based approaches to lexi-
cal substitution (McCarthy and Navigli, 2007) and
allows for a transition from metaphorical to literal
language, while preserving the original meaning.
</bodyText>
<subsectionHeader confidence="0.638108">
3.2.3 SP-based Re-ranking
</subsectionHeader>
<bodyText confidence="0.999954285714286">
The lists of paraphrases which were generated as
described above contain some irrelevant paraphrases
(e.g. “campaign lifted” for “campaign surged”) and
some metaphorically-used paraphrases (e.g. “cam-
paign soared”). However, our aim is to identify lit-
eral paraphrases among the candidates. Shutova’s
method uses selectional preferences of the candi-
</bodyText>
<page confidence="0.992277">
279
</page>
<table confidence="0.995353222222222">
Log-likelihood Paraphrase
Verb-DirectObject
stir excitement:
-14.28 create
-14.84 provoke
-15.53 make
-15.53 elicit
-15.53 arouse
-16.23 stimulate
-16.23 raise
-16.23 excite
-16.23 conjure
Subject-Verb
campaign surge:
-13.01 run
-15.53 improve
-16.23 soar
-16.23 lift
</table>
<tableCaption confidence="0.999973">
Table 1: The list of paraphrases with the initial ranking
</tableCaption>
<bodyText confidence="0.99991735">
dates for this purpose. Candidates used metaphor-
ically are likely to demonstrate semantic preference
for the source domain, e.g. soar would select for
birds or flying devices as its subject rather than cam-
paigns (the target domain), whereas the ones used
literally would have a higher preference for the tar-
get domain. This is yet another modification of
Wilks’ SP violation view of metaphor. Shutova
(2010) has previously shown that selecting the para-
phrases whose preferences the noun in the context
matches best allows to filter out non-literalness, as
well as unrelated terms.
As in case of the SPS filter, we automatically
acquired selectional preference distributions of the
verbs in the paraphrase lists (for verb-subject and
verb-direct object relations) from the RASP-parsed
BNC. In order to quantify how well a particular ar-
gument class fits the verb, we adopted the selectional
association measure proposed by Resnik (1993). Se-
lectional association is defined as follows:
</bodyText>
<equation confidence="0.996364">
1 P (c|v)
AR(v, c) = SR(v)P(c|v) log P (c) , (5)
</equation>
<bodyText confidence="0.999607857142857">
where P(c) is the prior probability of the noun class,
P(c|v) is the posterior probability of the noun class
given the verb and SR is the overall selectional pref-
erence strength of the verb in the grammatical rela-
tion R.
We use selectional association as a measure of
semantic fitness of the paraphrases into the con-
</bodyText>
<table confidence="0.996292555555556">
Association Paraphrase
Verb-DirectObject
stir excitement:
0.0696 provoke
0.0245 elicit
0.0194 arouse
0.0061 conjure
0.0028 create
0.0001 stimulate
� 0 raise
� 0 make
� 0 excite
Subject-Verb
campaign surge:
0.0086 improve
0.0009 run
� 0 soar
� 0 lift
</table>
<tableCaption confidence="0.999922">
Table 2: The list of paraphrases re-ranked using SPs
</tableCaption>
<bodyText confidence="0.999900588235294">
text, which stands for their literalness. The para-
phrases are re-ranked based on their selectional as-
sociation with the noun in the context. The incor-
rect or metaphorical paraphrases are de-emphasized
within this ranking. The new ranking is shown in
Table 2. While the model in 3.2.1 selected the can-
didate paraphrases that match the context better than
all other candidates, the SP model emphasizes the
paraphrases that match this particular context better
than any other context they may appear in. Shutova’s
experiments have shown that the paraphrase in rank
1 (i.e. the verb with which the noun in the context
has the highest selectional association) represents a
literal interpretation in 81% of all cases. Such a level
of accuracy makes Shutova’s method state-of-the-art
in metaphor paraphrasing. We now apply it to the
task of metaphor identification.
</bodyText>
<subsectionHeader confidence="0.997266">
3.3 Reverse Paraphrasing
</subsectionHeader>
<bodyText confidence="0.999991818181818">
At the heart of our approach to metaphor iden-
tification is the concept of reverse paraphrasing.
The main intuition behind it is that when literally-
used words are paraphrased with their literal substi-
tutes, the reverse literal paraphrasing of that substi-
tute should yield the original expression as one of
the candidates. This is, however, not the case for
metaphor, since its literal paraphrase would yield
another literal expression via literal paraphrasing.
We ran the above paraphrasing method on every
verb in the input text and then again on the top
</bodyText>
<page confidence="0.993313">
280
</page>
<table confidence="0.769124086956522">
Original expression Lit. paraphrase Reverse paraphrase
Verb-DirectObject
stir excitement provoke: elicit, arouse,
cause, create,
stimulate, raise,
make
elicit: provoke, arouse,
see, derive, create,
raise, make
buy a dress
get: change, find, buy,
purchase, take, hit,
alter, ...
purchase: get, buy
Subject-Verb
campaign surge improve: change, turn
run: succeed, direct,
continue, lead, last,
win, extend, ...
prisoner escape flee: escape, run
get: drive, go, turn,
transfer, arrive,
bring, come,...
</table>
<tableCaption confidence="0.9920555">
Table 3: The list of top two literal paraphrases and their
reverse paraphrases, as identified by the system
</tableCaption>
<bodyText confidence="0.999953">
two paraphrases it produces. If this process resulted
in retrieving the original expression then the latter
was tagged as literal, otherwise it was tagged as
metaphorical. Some examples of reverse paraphras-
ing results are given in Table 3. One can see from
the table that when the metaphorical verb stir in “stir
excitement” is paraphrased as the literal “provoke”,
the subsequent paraphrasing of “provoke” does not
produce “stir”. In contrast, when the literal expres-
sion “buy a dress” is paraphrased as “purchase”, the
reverse paraphrasing generates “buy” as one of the
candidates, indicating the literalness of the original
expression. The same is true for the metaphorical
surge in “campaign surged” and the literal escape in
“the prisoner escaped”.
</bodyText>
<sectionHeader confidence="0.99424" genericHeader="evaluation">
4 Evaluation and Discussion
</sectionHeader>
<subsectionHeader confidence="0.928813">
4.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999993107142857">
The baseline system is the implementation of the se-
lectional preference violation view of Wilks (1978)
using automatically induced SPs. Such a choice of a
baseline allows us to compare our own modifications
of the SP violation view to the original approach of
Wilks in a computational setting, as well as evaluate
the latter on real-world data. Another motivation be-
hind this choice is that the symmetry of reverse para-
phrasing can be seen as a kind of “normality” test, in
a similar way as the satisfied selectional preferences
are in Wilk’s approach. However, we believe that
the SP-based reverse paraphrasing method captures
significantly more information than SP violations do
and thus compare the performance of the two meth-
ods in an experimental setting.
The baseline SP classes were created as described
above and the preferences were quantified using se-
lectional association as a measure. The baseline sys-
tem then classified the instances where selectional
association of the verb and the noun in the phrase
were below a certain threshold, as metaphorical.
We determined the optimal threshold by qualitative
analysis of the selectional preference distributions of
50 verbs of different frequency and SPS (through the
analysis of literally and metaphorically-used argu-
ments). The threshold was averaged over individual
verbs’ thresholds and equals 0.07 for direct object
relations, and 0.09 for subject relations.
</bodyText>
<subsectionHeader confidence="0.982024">
4.2 Evaluation Corpus
</subsectionHeader>
<bodyText confidence="0.999977052631579">
We evaluated the system and the baseline against the
corpus of Shutova and Teufel (2010), that was man-
ually annotated for metaphorical expressions. The
corpus is a 14,000-word subset of the BNC, with
the texts selected to retain the original balance of
genre in the BNC itself. The corpus contains ex-
tracts from fiction, newspaper text, radio broadcast
(transcribed speech), essays and journal articles on
politics, social science and literature. Shutova and
Teufel (2010) identified 241 metaphorical expres-
sions in the corpus, out of which 164 were verbal
metaphors.
We parsed the corpus using the RASP parser and
extracted subject and direct object relations from its
output. Among the direct object relations there were
310 literal phrases and 79 metaphorical ones; and
among the subject relations 206 were literal and 67
metaphorical. This constitutes a dataset of 662 rela-
tions for the systems to classify.
</bodyText>
<subsectionHeader confidence="0.967308">
4.3 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.9995935">
The system and baseline performance was evaluated
against the corpus in terms of precision and recall.
Precision, P, measures the proportion of metaphor-
ical expressions that were tagged correctly among
</bodyText>
<page confidence="0.994725">
281
</page>
<table confidence="0.9999375">
Relation Bsln P System P Bsln R System R
Verb-DObj 0.20 0.69 0.52 0.63
Verb-Subj 0.13 0.66 0.59 0.70
Average 0.17 0.68 0.55 0.66
</table>
<tableCaption confidence="0.999511">
Table 4: Baseline and system performance by relation
</tableCaption>
<bodyText confidence="0.999957428571429">
the ones that were tagged by the system. Recall,
R, measures the proportion of metaphorical expres-
sions that were identified out of all metaphorical ex-
pressions in the gold standard corpus. The system
P = 0.68 and R = 0.66, whereas the baseline only
attains P = 0.17 and R = 0.55. System perfor-
mance by relation is shown in Table 4. The hu-
man ceiling for this task, according to the annotation
experiments of Shutova and Teufel (2010) approxi-
mates to P = 0.80. Figure 1 shows example sen-
tences with metaphors identified and paraphrased by
the system. Table 5 provides a breakdown of the an-
notated instances into true / false positives and true
/ false negatives. As one can see from the table, the
systems can accurately annotate both metaphorical
and literal expressions, providing a balance between
precision and recall.
The system outperforms the baseline for both
verb-subject and verb-direct object constructions.
Its performance is also close to the previous
metaphor identification systems of Turney et al.
(2011) (accuracy of 0.73) and Shutova et al. (2010)
(precision of 0.79), however, the results are not di-
rectly comparable due to different experimental set-
tings. Our method has a strong advantage over the
system of Shutova et al. (2010) in terms of cover-
age: the latter system heavily relied on manually an-
notated seed metaphors which limited its applicabil-
ity in unrestricted text to the set of topics covered by
the seeds. As opposed to this, our method is domain-
independent and can be applied to any data. Shutova
et al. (2010) have not measured the recall of their
system, however indicated its possible coverage lim-
itations.
In addition, our system produces paraphrases for
the identified metaphorical expressions. Since the
identification is directly dependent on the quality
of literal paraphrasing, the majority of the inter-
pretations the system provided for the identified
metaphors appear to be correct. However, we found
a few instances where, despite the correct initial
paraphrasing, the system was not able to identify
</bodyText>
<table confidence="0.758451214285714">
FYT Gorbachev inherited a Soviet state which was, in
a celebrated Stalinist formulation, national in form but
socialist in content.
Paraphrase: Gorbachev received a Soviet state which
was, in a celebrated Stalinist formulation, national in
form but socialist in content.
CEK The Clinton campaign surged again and he easily
won the Democratic nomination.
Paraphrase: The Clinton campaign improved again and
he easily won the Democratic nomination.
CEK Their views reflect a lack of enthusiasm among
the British people at large for John Major ’s idea of Eu-
ropean unity.
Paraphrase: Their views show a lack of enthusiasm
among the British people at large for John Major ’s idea
of European unity.
J85 [..] the reasons for this superiority are never spelled
out.
Paraphrase [..] the reasons for this superiority are never
specified.
J85 Anyone who has introduced speech act theory to
students will know that these technical terms are not at
all easy to grasp.
Paraphrase: Anyone who has introduced speech act the-
ory to students will know that these technical terms are
not at all easy to understand.
G0N The man’s voice cut in .
Paraphrase: The man’s voice interrupted.
</table>
<figureCaption confidence="0.985262">
Figure 1: Metaphors tagged by the system (in bold) and
their paraphrases
</figureCaption>
<bodyText confidence="0.993217588235294">
the metaphor, usually in case of highly convention-
alized metaphorical expressions. Overall, the most
frequent system errors fall into the following cate-
gories:
Errors due to incorrect parsing: The system failed
to discover some of the metaphorical expressions in
the corpus since their grammatical relations were
missed by the parser. In addition, some of the in-
stances were misclassified, e.g. “pounds paid to
[...]” or “change was greatly accelerated” were la-
beled as subject relations. Overall, the parser missed
9 metaphorical expressions.
Errors due to incorrect paraphrasing: The most
common type of error that leads to false positives is
the incorrect paraphrasing (resulting in a change of
meaning). This makes it nearly impossible for the
system to retrieve the original term. There were also
</bodyText>
<page confidence="0.990981">
282
</page>
<table confidence="0.99859225">
Positives Negatives Total
True 99 464 563
False 47 52 99
Total 146 516
</table>
<tableCaption confidence="0.998574">
Table 5: System tagging statistics
</tableCaption>
<bodyText confidence="0.999387717948718">
cases where the system could not generate any para-
phrase (usually for literal expressions, e.g. “play an
anthem”).
Errors due to metaphorical paraphrasing: Some
of the system errors are due to metaphorical para-
phrasing. For example, the metaphorical expression
“mend marriage” was paraphrased as “repair mar-
riage”, which is also used metaphorically. And re-
pair in return generated mend, when paraphrased in
reverse. Errors of this type have been mainly trig-
gered by the WordNet filter, and the fact that some
metaphorical senses are included in WordNet.
Errors due to metaphor conventionality: a num-
ber of conventional metaphors were missed by the
system, since the original verb was retrieved due to
its conventionality. Such examples include “impose
a decision”, “put the issue forward”, “lead a life”.
Such cases suggest that the system is better suited to
identify more creative, novel metaphors.
Cases of metonymy: a few cases of gen-
eral metonymy were annotated by the system as
metaphorical, e.g. “shout support”, which stands for
“shout the words of support”, and “humiliate a mo-
ment”, that is likely to mean “humiliate the event of
the moment”. However, there were only 4 errors of
this type in the data.
Baseline Errors: The output of the baseline exhib-
ited two main types of error. The first stemmed from
the conventionality of many metaphorical expres-
sions, which resulted in their literal annotation. Con-
ventionality leads to high selectional association for
verbs with their metaphorical arguments, e.g. em-
brace has {view, ideology, conception etc.} class as
its top ranked direct object argument with the selec-
tional association of 0.18. The second type of error
was the system selecting many language anomalies
that violate selectional preferences and tagging these
as metaphors. This resulted in a high number of false
positives.
</bodyText>
<sectionHeader confidence="0.997821" genericHeader="conclusions">
5 Conclusions and Future Directions
</sectionHeader>
<bodyText confidence="0.999955043478261">
Previous research on metaphor addressed a num-
ber of its aspects using both symbolic and statisti-
cal techniques. While some of this work met with
success with respect to precision in metaphor an-
notation, the methods often focused on a limited
domain and needed manually-labeled training data.
Their dependence on manually annotated training
data made the systems hard to scale. As a result,
many of these systems are not directly applicable to
aid real-world NLP due to their limited coverage. In
contrast, our method does not require any manually-
labeled data, which makes it more robust and appli-
cable to a wide range of genres. It is also the first
one to perform accurate metaphor identification and
interpretation in one step, as opposed to the previ-
ous systems focusing on one part of the task only.
It identifies metaphor with a precision of 68% and
a recall of 66%, which is a very encouraging result.
We believe that this work has important implications
for computational modeling of metaphor, and is rel-
evant to a range of other semantic tasks within NLP.
Although we have so far tested our system on
verb-subject and verb-object metaphors only, we be-
lieve that the described identification and paraphras-
ing techniques can be similarly applied to a wider
range of syntactic constructions. Extending the sys-
tem to deal with more parts of speech and types of
phrases (e.g. nominal and adjectival metaphors) is
part of our future work.
Another promising future research avenue is inte-
grating the techniques with unsupervised paraphras-
ing and lexical substitution methods, using e.g. dis-
tributional similarity measures (Pucci et al., 2009;
McCarthy et al., 2010) or vector space models of
word meaning (Erk and Pad´o, 2008; Erk and Pad´o,
2009; De Cao and Basili, 2009; Shutova et al.,
2012b). These methods could fully or partly replace
the WordNet filter in the detection of similar basic
features of the concepts, or add useful information
to it. Fully replacing the WordNet filter by an un-
supervised method would make the system more ro-
bust and more easily portable across domains and
genres. This may also eliminate some of the system
errors that arise from the inconsistent sense annota-
tion and the inclusion of some metaphorical senses
in WordNet.
</bodyText>
<page confidence="0.997713">
283
</page>
<sectionHeader confidence="0.999212" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9986395">
This work was supported by the ICSI MetaNet
project (grant number W911NF-12-C-0022). Many
thanks to Srini Narayanan, Eve Sweetser and Jerry
Feldman for their advice and feedback.
</bodyText>
<sectionHeader confidence="0.998939" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999839572916667">
Rodrigo Agerri, John Barnden, Mark Lee, and Alan
Wallington. 2007. Metaphor, inference and domain-
independent mappings. In Proceedings of RANLP-
2007, pages 17–23, Borovets, Bulgaria.
Rodrigo Agerri. 2008. Metaphor in textual entailment.
In Proceedings of COLING 2008, pages 3–6, Manch-
ester, UK.
Oistein Andersen, Julien Nioche, Ted Briscoe, and John
Carroll. 2008. The BNC parsed with RASP4UIMA.
In Proceedings of LREC 2008, pages 865–869, Mar-
rakech, Morocco.
John Barnden and Mark Lee. 2002. An artificial intel-
ligence approach to metaphor understanding. Theoria
etHistoria Scientiarum, 6(1):399–412.
Julia Birke and Anoop Sarkar. 2006. A clustering ap-
proach for the nearly unsupervised recognition of non-
literal language. In In Proceedings of EACL-06, pages
329–336.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The second release of the rasp system. In Proceed-
ings of the COLING/ACL on Interactive presentation
sessions, pages 77–80.
Lou Burnard. 2007. Reference Guide for the British Na-
tional Corpus (XML Edition).
Lynne Cameron. 2003. Metaphor in Educational Dis-
course. Continuum, London.
Seana Coulson. 2008. Metaphor comprehension and the
brain. In R.W. Gibbs, editor, Metaphor and Thought,
Cambridge. Cambridge University Press.
Diego De Cao and Roberto Basili. 2009. Combining dis-
tributional and paradigmatic information in a lexical
substitution task. In Proceedings of EVALITA work-
shop, 11th Congress of Italian Association for Artifi-
cial Intelligence.
Katrin Erk and Sebastian Pad´o. 2008. A structured
vector space model for word meaning in context. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, pages 897–906,
Waikiki, Hawaii, USA.
Katrin Erk and Sebastian Pad´o. 2009. Paraphrase as-
sessment in structured vector space: exploring param-
eters and datasets. In Proceedings of the Workshop on
Geometrical Models of Natural Language Semantics,
pages 57–65. Association for Computational Linguis-
tics.
Dan Fass. 1991. met*: A method for discriminating
metonymy and metaphor by computer. Computational
Linguistics, 17(1):49–90.
Jerome Feldman and Srini Narayanan. 2004. Embodied
meaning in a neural theory of language. Brain and
Language, 89(2):385–392.
Christiane Fellbaum, editor. 1998. WordNet. An Elec-
tronic Lexical Database (ISBN. 0-262-06197-X). MIT
Press, first edition.
Matt Gedigian, John Bryant, Srini Narayanan, and Bran-
imir Ciric. 2006. Catching metaphors. In In Proceed-
ings of the 3rd Workshop on Scalable Natural Lan-
guage Understanding, pages 41–48, New York.
Raymond W. Gibbs and Herbert L. Colston. 2012. In-
terpreting Figurative Meaning. Cambridge University
Press.
Paul Kingsbury and Martha Palmer. 2002. From
TreeBank to PropBank. In Proceedings of LREC-
2002, pages 1989–1993, Gran Canaria, Canary Is-
lands, Spain.
Saisuresh Krishnakumaran and Xiaojin Zhu. 2007.
Hunting elusive metaphors using lexical resources.
In Proceedings of the Workshop on Computational
Approaches to Figurative Language, pages 13–20,
Rochester, NY.
George Lakoff and Mark Johnson. 1980. Metaphors We
Live By. University of Chicago Press, Chicago.
James Martin. 1990. A Computational Model of
Metaphor Interpretation. Academic Press Profes-
sional, Inc., San Diego, CA, USA.
James Martin. 2006. A corpus-based analysis of con-
text effects on metaphor comprehension. In A. Ste-
fanowitsch and S. T. Gries, editors, Corpus-Based Ap-
proaches to Metaphor and Metonymy, Berlin. Mouton
de Gruyter.
Zachary Mason. 2004. Cormet: a computational,
corpus-based conventional metaphor extraction sys-
tem. Computational Linguistics, 30(1):23–44.
Diana McCarthy and Roberto Navigli. 2007. Semeval-
2007 task 10: English lexical substitution task. In Pro-
ceedings of the 4th workshop on Semantic Evaluations
(SemEval-2007), pages 48–53.
Diana McCarthy, Bill Keller, and Roberto Navigli. 2010.
Getting synonym candidates from raw data in the en-
glish lexical substitution task. In Proceedings of the
14th EURALEX International Congress, Leeuwarden,
The Netherlands.
Srini Narayanan. 1997. Knowledge-based Action Repre-
sentations for Metaphor and Aspect (KARMA). Tech-
nical report, PhD thesis, University of California at
Berkeley.
</reference>
<page confidence="0.97655">
284
</page>
<reference confidence="0.999866596491228">
Srini Narayanan. 1999. Moving right along: A compu-
tational model of metaphoric reasoning about events.
In Proceedings of AAAI 99), pages 121–128, Orlando,
Florida.
Dario Pucci, Marco Baroni, Franco Cutugno, and
Alessandro Lenci. 2009. Unsupervised lexical sub-
stitution with a word space model. In Proceedings of
EVALITA workshop, 11th Congress of Italian Associ-
ation for Artificial Intelligence.
Philip Resnik. 1993. Selection and Information: A
Class-based Approach to Lexical Relationships. Ph.D.
thesis, Philadelphia, PA, USA.
Ekaterina Shutova and Simone Teufel. 2010. Metaphor
corpus annotated for source - target domain map-
pings. In Proceedings of LREC 2010, pages 3255–
3261, Malta.
Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010.
Metaphor identification using verb and noun cluster-
ing. In Proceedings of Coling 2010, pages 1002–1010,
Beijing, China.
Ekaterina Shutova, Simone Teufel, and Anna Korhonen.
2012a. Statistical Metaphor Processing. Computa-
tional Linguistics, 39(2).
Ekaterina Shutova, Tim Van de Cruys, and Anna Korho-
nen. 2012b. Unsupervised metaphor paraphrasing us-
ing a vector space model. In Proceedings of COLING
2012, Mumbai, India.
Ekaterina Shutova. 2010. Automatic metaphor inter-
pretation as a paraphrasing task. In Proceedings of
NAACL 2010, pages 1029–1037, Los Angeles, USA.
Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann,
Anna A. Kaal, Tina Krennmayr, and Trijntje Pasma.
2010. A method for linguistic metaphor identifica-
tion: From MIP to MIPVU. John Benjamins, Ams-
terdam/Philadelphia.
Lin Sun and Anna Korhonen. 2009. Improving
verb clustering with automatically acquired selectional
preferences. In Proceedings of EMNLP 2009, pages
638–647, Singapore, August.
Paul H. Thibodeau and Lera Boroditsky. 2011.
Metaphors we think with: The role of metaphor in rea-
soning. PLoS ONE, 6(2):e16782, 02.
Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai
Cohen. 2011. Literal and metaphorical sense iden-
tification through concrete and abstract context. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing, EMNLP ’11,
pages 680–690, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Akira Utsumi. 2011. Computational exploration of
metaphor comprehension processes using a semantic
space model. Cognitive Science, 35(2):251–296.
Yorick Wilks. 1975. A preferential pattern-seeking se-
mantics for natural language inference. Artificial In-
telligence, 6:53–74.
Yorick Wilks. 1978. Making preferences more active.
Artificial Intelligence, 11(3):197–223.
</reference>
<page confidence="0.998527">
285
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.947443">
<title confidence="0.999563">Metaphor Identification as Interpretation</title>
<author confidence="0.985262">Ekaterina</author>
<affiliation confidence="0.996942">International Computer Science Institute Institute for Cognitive and Brain University of California, Berkeley</affiliation>
<email confidence="0.999804">katia@berkeley.edu</email>
<abstract confidence="0.998256117647059">Automatic metaphor identification and interpretation in text have been traditionally considered as two separate tasks in natural language processing (NLP) and addressed individually within computational frameworks. However, cognitive evidence suggests that humans are likely to perform these two tasks simultaneously, as part of a holistic metaphor comprehension process. We present a novel method that performs metaphor identification through its interpretation, being the first one in NLP to combine the two tasks in one step. It outperforms the previous approaches to metaphor identification both in terms of accuracy and coverage, as well as providing an interpretation for each identified expression.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rodrigo Agerri</author>
<author>John Barnden</author>
<author>Mark Lee</author>
<author>Alan Wallington</author>
</authors>
<title>Metaphor, inference and domainindependent mappings.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP2007,</booktitle>
<pages>17--23</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="3144" citStr="Agerri et al., 2007" startWordPosition="473" endWordPosition="476">anan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and required training data (Shutova et al., 2010; Turney et al., 20</context>
</contexts>
<marker>Agerri, Barnden, Lee, Wallington, 2007</marker>
<rawString>Rodrigo Agerri, John Barnden, Mark Lee, and Alan Wallington. 2007. Metaphor, inference and domainindependent mappings. In Proceedings of RANLP2007, pages 17–23, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodrigo Agerri</author>
</authors>
<title>Metaphor in textual entailment.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<pages>3--6</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="2569" citStr="Agerri, 2008" startWordPosition="390" endWordPosition="391">Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent metho</context>
</contexts>
<marker>Agerri, 2008</marker>
<rawString>Rodrigo Agerri. 2008. Metaphor in textual entailment. In Proceedings of COLING 2008, pages 3–6, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oistein Andersen</author>
<author>Julien Nioche</author>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>The BNC parsed with RASP4UIMA.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC</booktitle>
<pages>865--869</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="11427" citStr="Andersen et al., 2008" startWordPosition="1772" endWordPosition="1775"> be used metaphorically in any context. For every verb in the input text, the filter determines their likelihood of being a metaphor based on their SPS and discards the weak ones. The SPS filter is context-free, and the reverse paraphrasing method is then applied in the next steps to determine if the remaining verbs are indeed used metaphorically in the given context. We automatically acquired selectional preference distributions for verb-subject and verb-direct object relations from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser (Briscoe et al., 2006; Andersen et al., 2008). We applied the noun clustering method of Sun and Korhonen (2009) to 2000 most frequent nouns in the BNC to obtain 200 common selectional preference classes. To quantify selectional preferences, we adopted the SPS measure of Resnik (1993). Resnik defines SPS of a verb as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position (regardless of the verb). He quantifies this difference using the Kullback-Leibler divergence: SR(v) = D(P(c|v)||P(c)) = EPc P(c|v) log P(C|V), (1) where P(c) is the </context>
<context position="15229" citStr="Andersen et al. (2008)" startWordPosition="2408" endWordPosition="2411">rt of speech class is attested in the corpus and f(wn, rn, i) is the number of times the interpretation co-occurs with context word wn in relation rn. By performing appropriate substitutions into (3), we obtain: P(i, (w1, r1), (w2, r2), ..., (wN, rN)) = f(i) f(w1, r1, i) f(wN, rN, i) Ek f(ik) · f(i) · ... · f(i) 1 H�7N l n=1 f(wn, rn, i) (f(i))N−1 · Ek f(ik). (4) This model is then used to rank the candidate substitutes of the verb v in the fixed context according to the data. The parameters of the model were estimated from the RASP-parsed BNC using the grammatical relations output created by Andersen et al. (2008). The goal of this model is to emphasize the paraphrases that match the context of the verb in the sentence best. 3.2.2 WordNet Filter After obtaining the initial list of possible substitutes for the verb v, the system filters out the terms whose meanings do not share any common properties with that of the verb. This overlap of properties is identified using the hyponymy relation in WordNet. Within the initial list of paraphrases, the system selects the terms that are hypernyms of the verb v, or share a common hypernym with it. Following Shutova, we restrict the hypernym search to a depth of t</context>
</contexts>
<marker>Andersen, Nioche, Briscoe, Carroll, 2008</marker>
<rawString>Oistein Andersen, Julien Nioche, Ted Briscoe, and John Carroll. 2008. The BNC parsed with RASP4UIMA. In Proceedings of LREC 2008, pages 865–869, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Barnden</author>
<author>Mark Lee</author>
</authors>
<title>An artificial intelligence approach to metaphor understanding. Theoria etHistoria</title>
<date>2002</date>
<journal>Scientiarum,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="3122" citStr="Barnden and Lee, 2002" startWordPosition="469" endWordPosition="472">stem to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and required training data (Shutova et al., 2</context>
</contexts>
<marker>Barnden, Lee, 2002</marker>
<rawString>John Barnden and Mark Lee. 2002. An artificial intelligence approach to metaphor understanding. Theoria etHistoria Scientiarum, 6(1):399–412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Birke</author>
<author>Anoop Sarkar</author>
</authors>
<title>A clustering approach for the nearly unsupervised recognition of nonliteral language. In</title>
<date>2006</date>
<booktitle>In Proceedings of EACL-06,</booktitle>
<pages>329--336</pages>
<contexts>
<context position="7682" citStr="Birke and Sarkar (2006)" startWordPosition="1165" endWordPosition="1168"> via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation) and word bigram counts to predict verbal, nominal and adjectival metaphors at the sentence level. The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors. Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences. The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The first system to discover source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANC</context>
</contexts>
<marker>Birke, Sarkar, 2006</marker>
<rawString>Julia Birke and Anoop Sarkar. 2006. A clustering approach for the nearly unsupervised recognition of nonliteral language. In In Proceedings of EACL-06, pages 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the rasp system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="11403" citStr="Briscoe et al., 2006" startWordPosition="1768" endWordPosition="1771">ak SPS are unlikely to be used metaphorically in any context. For every verb in the input text, the filter determines their likelihood of being a metaphor based on their SPS and discards the weak ones. The SPS filter is context-free, and the reverse paraphrasing method is then applied in the next steps to determine if the remaining verbs are indeed used metaphorically in the given context. We automatically acquired selectional preference distributions for verb-subject and verb-direct object relations from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser (Briscoe et al., 2006; Andersen et al., 2008). We applied the noun clustering method of Sun and Korhonen (2009) to 2000 most frequent nouns in the BNC to obtain 200 common selectional preference classes. To quantify selectional preferences, we adopted the SPS measure of Resnik (1993). Resnik defines SPS of a verb as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position (regardless of the verb). He quantifies this difference using the Kullback-Leibler divergence: SR(v) = D(P(c|v)||P(c)) = EPc P(c|v) log P(C|V)</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the rasp system. In Proceedings of the COLING/ACL on Interactive presentation sessions, pages 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<date>2007</date>
<booktitle>Reference Guide for the British National Corpus (XML Edition).</booktitle>
<contexts>
<context position="11343" citStr="Burnard, 2007" startWordPosition="1759" endWordPosition="1760"> represents a violation of SPs, then the verbs with weak SPS are unlikely to be used metaphorically in any context. For every verb in the input text, the filter determines their likelihood of being a metaphor based on their SPS and discards the weak ones. The SPS filter is context-free, and the reverse paraphrasing method is then applied in the next steps to determine if the remaining verbs are indeed used metaphorically in the given context. We automatically acquired selectional preference distributions for verb-subject and verb-direct object relations from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser (Briscoe et al., 2006; Andersen et al., 2008). We applied the noun clustering method of Sun and Korhonen (2009) to 2000 most frequent nouns in the BNC to obtain 200 common selectional preference classes. To quantify selectional preferences, we adopted the SPS measure of Resnik (1993). Resnik defines SPS of a verb as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position (regardless of the verb). He quantifies this difference using the Kullback-Leibler</context>
</contexts>
<marker>Burnard, 2007</marker>
<rawString>Lou Burnard. 2007. Reference Guide for the British National Corpus (XML Edition).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cameron</author>
</authors>
<date>2003</date>
<booktitle>Metaphor in Educational Discourse. Continuum,</booktitle>
<location>London.</location>
<contexts>
<context position="1920" citStr="Cameron, 2003" startWordPosition="292" endWordPosition="293">ks, 1978) (2) This policy is strangling business. The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (N</context>
</contexts>
<marker>Cameron, 2003</marker>
<rawString>Lynne Cameron. 2003. Metaphor in Educational Discourse. Continuum, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seana Coulson</author>
</authors>
<title>Metaphor comprehension and the brain.</title>
<date>2008</date>
<editor>In R.W. Gibbs, editor, Metaphor and Thought, Cambridge.</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4431" citStr="Coulson, 2008" startWordPosition="667" endWordPosition="669">tself has been most commonly addressed in NLP as two individual subtasks: metaphor identification and metaphor interpretation, with the systems focusing only on one of them at a time, or at best combing the two in a pipeline (Shutova et al., 2012a). Metaphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence suggests that humans are likely to perform identification and interpretation simultaneously, as part of a holistic metaphor comprehension process (Coulson, 2008; Utsumi, 2011; Gibbs and Colston, 2012). In this paper, we also take this stance and present the first computational method that identifies metaphorical expressions in unrestricted text by means of their interpretation. Following Shutova (2010), we define metaphor interpretation as a task of finding a literal paraphrase for a metaphorically used word and introduce the concept of symmetric reverse paraphrasing as a criterion for metaphor identification. The main assumption behind our method is that the literal paraphrases of literally-used words should yield the original phrase when paraphrase</context>
</contexts>
<marker>Coulson, 2008</marker>
<rawString>Seana Coulson. 2008. Metaphor comprehension and the brain. In R.W. Gibbs, editor, Metaphor and Thought, Cambridge. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diego De Cao</author>
<author>Roberto Basili</author>
</authors>
<title>Combining distributional and paradigmatic information in a lexical substitution task.</title>
<date>2009</date>
<booktitle>In Proceedings of EVALITA workshop, 11th Congress of Italian Association for Artificial Intelligence.</booktitle>
<marker>De Cao, Basili, 2009</marker>
<rawString>Diego De Cao and Roberto Basili. 2009. Combining distributional and paradigmatic information in a lexical substitution task. In Proceedings of EVALITA workshop, 11th Congress of Italian Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>A structured vector space model for word meaning in context.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>897--906</pages>
<location>Waikiki, Hawaii, USA.</location>
<marker>Erk, Pad´o, 2008</marker>
<rawString>Katrin Erk and Sebastian Pad´o. 2008. A structured vector space model for word meaning in context. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 897–906, Waikiki, Hawaii, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Paraphrase assessment in structured vector space: exploring parameters and datasets.</title>
<date>2009</date>
<booktitle>In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics,</booktitle>
<pages>57--65</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Erk, Pad´o, 2009</marker>
<rawString>Katrin Erk and Sebastian Pad´o. 2009. Paraphrase assessment in structured vector space: exploring parameters and datasets. In Proceedings of the Workshop on Geometrical Models of Natural Language Semantics, pages 57–65. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Fass</author>
</authors>
<title>met*: A method for discriminating metonymy and metaphor by computer.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="3022" citStr="Fass, 1991" startWordPosition="457" endWordPosition="458">t’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena </context>
<context position="6995" citStr="Fass (1991)" startWordPosition="1067" endWordPosition="1068">n the verb is tagged as literal, otherwise it is tagged as metaphorical. We evaluated the performance of the system using the manually annotated metaphor corpus of Shutova and Teufel (2010) in precision- and recall-oriented settings. In addition, we compared its performance to that of a baseline using selectional preference violation as an indicator of metaphor, as well as to two previous metaphor identification approaches of Shutova et al. (2010) and Turney et al. (2011). 2 Related Work One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation) and word bigram counts to predict verbal, nominal and adjectival metaphors at the sentence level. The authors discriminate between co</context>
</contexts>
<marker>Fass, 1991</marker>
<rawString>Dan Fass. 1991. met*: A method for discriminating metonymy and metaphor by computer. Computational Linguistics, 17(1):49–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome Feldman</author>
<author>Srini Narayanan</author>
</authors>
<title>Embodied meaning in a neural theory of language.</title>
<date>2004</date>
<journal>Brain and Language,</journal>
<volume>89</volume>
<issue>2</issue>
<contexts>
<context position="3099" citStr="Feldman and Narayanan, 2004" startWordPosition="465" endWordPosition="468">fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and required training </context>
</contexts>
<marker>Feldman, Narayanan, 2004</marker>
<rawString>Jerome Feldman and Srini Narayanan. 2004. Embodied meaning in a neural theory of language. Brain and Language, 89(2):385–392.</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<booktitle>WordNet. An Electronic Lexical Database (ISBN.</booktitle>
<pages>0--262</pages>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<note>first edition.</note>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet. An Electronic Lexical Database (ISBN. 0-262-06197-X). MIT Press, first edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gedigian</author>
<author>John Bryant</author>
<author>Srini Narayanan</author>
<author>Branimir Ciric</author>
</authors>
<title>Catching metaphors. In</title>
<date>2006</date>
<booktitle>In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding,</booktitle>
<pages>41--48</pages>
<location>New York.</location>
<contexts>
<context position="2857" citStr="Gedigian et al., 2006" startWordPosition="429" endWordPosition="432">ation extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: P</context>
<context position="8514" citStr="Gedigian et al. (2006)" startWordPosition="1302" endWordPosition="1305">the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The first system to discover source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANCE domains. In the LAB domain it has 277 a strong preference for liquids and in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity. They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analo</context>
</contexts>
<marker>Gedigian, Bryant, Narayanan, Ciric, 2006</marker>
<rawString>Matt Gedigian, John Bryant, Srini Narayanan, and Branimir Ciric. 2006. Catching metaphors. In In Proceedings of the 3rd Workshop on Scalable Natural Language Understanding, pages 41–48, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond W Gibbs</author>
<author>Herbert L Colston</author>
</authors>
<title>Interpreting Figurative Meaning.</title>
<date>2012</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="4471" citStr="Gibbs and Colston, 2012" startWordPosition="672" endWordPosition="675">addressed in NLP as two individual subtasks: metaphor identification and metaphor interpretation, with the systems focusing only on one of them at a time, or at best combing the two in a pipeline (Shutova et al., 2012a). Metaphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence suggests that humans are likely to perform identification and interpretation simultaneously, as part of a holistic metaphor comprehension process (Coulson, 2008; Utsumi, 2011; Gibbs and Colston, 2012). In this paper, we also take this stance and present the first computational method that identifies metaphorical expressions in unrestricted text by means of their interpretation. Following Shutova (2010), we define metaphor interpretation as a task of finding a literal paraphrase for a metaphorically used word and introduce the concept of symmetric reverse paraphrasing as a criterion for metaphor identification. The main assumption behind our method is that the literal paraphrases of literally-used words should yield the original phrase when paraphrased in reverse. For example, when the expr</context>
</contexts>
<marker>Gibbs, Colston, 2012</marker>
<rawString>Raymond W. Gibbs and Herbert L. Colston. 2012. Interpreting Figurative Meaning. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
</authors>
<title>From TreeBank to PropBank.</title>
<date>2002</date>
<booktitle>In Proceedings of LREC2002,</booktitle>
<pages>1989--1993</pages>
<location>Gran Canaria, Canary Islands,</location>
<contexts>
<context position="8677" citStr="Kingsbury and Palmer, 2002" startWordPosition="1325" endWordPosition="1328">rce–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANCE domains. In the LAB domain it has 277 a strong preference for liquids and in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity. They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering. As a result, the system can recognize new metaphorical expressions in unrestricted text (e.g. from the seed “stir excite</context>
</contexts>
<marker>Kingsbury, Palmer, 2002</marker>
<rawString>Paul Kingsbury and Martha Palmer. 2002. From TreeBank to PropBank. In Proceedings of LREC2002, pages 1989–1993, Gran Canaria, Canary Islands, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saisuresh Krishnakumaran</author>
<author>Xiaojin Zhu</author>
</authors>
<title>Hunting elusive metaphors using lexical resources.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Figurative Language,</booktitle>
<pages>13--20</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="3675" citStr="Krishnakumaran and Zhu, 2007" startWordPosition="553" endWordPosition="556">n, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena (Gedigian et al., 2006; Krishnakumaran and Zhu, 2007), and required training data (Shutova et al., 2010; Turney et al., 2011), often resulting in a limited coverage. The metaphor processing task itself has been most commonly addressed in NLP as two individual subtasks: metaphor identification and metaphor interpretation, with the systems focusing only on one of them at a time, or at best combing the two in a pipeline (Shutova et al., 2012a). Metaphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence sugg</context>
<context position="7424" citStr="Krishnakumaran and Zhu (2007)" startWordPosition="1128" endWordPosition="1131">tion approaches of Shutova et al. (2010) and Turney et al. (2011). 2 Related Work One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation) and word bigram counts to predict verbal, nominal and adjectival metaphors at the sentence level. The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors. Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences. The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The fi</context>
</contexts>
<marker>Krishnakumaran, Zhu, 2007</marker>
<rawString>Saisuresh Krishnakumaran and Xiaojin Zhu. 2007. Hunting elusive metaphors using lexical resources. In Proceedings of the Workshop on Computational Approaches to Figurative Language, pages 13–20, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
<author>Mark Johnson</author>
</authors>
<title>Metaphors We Live By.</title>
<date>1980</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="1235" citStr="Lakoff and Johnson, 1980" startWordPosition="174" endWordPosition="177">hat performs metaphor identification through its interpretation, being the first one in NLP to combine the two tasks in one step. It outperforms the previous approaches to metaphor identification both in terms of accuracy and coverage, as well as providing an interpretation for each identified expression. 1 Introduction Metaphor undoubtedly gives our expression more vividness, distinction and artistry, however, it is also an important linguistic tool that has long become part of our every-day language. Metaphors arise when one concept or domain is viewed in terms of the properties of another (Lakoff and Johnson, 1980). Consider the examples in (1) and (2). (1) My car drinks gasoline. (Wilks, 1978) (2) This policy is strangling business. The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of m</context>
</contexts>
<marker>Lakoff, Johnson, 1980</marker>
<rawString>George Lakoff and Mark Johnson. 1980. Metaphors We Live By. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>A Computational Model of Metaphor Interpretation.</title>
<date>1990</date>
<publisher>Academic Press Professional, Inc.,</publisher>
<location>San Diego, CA, USA.</location>
<contexts>
<context position="3036" citStr="Martin, 1990" startWordPosition="459" endWordPosition="460">siness regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena (Gedigian et a</context>
</contexts>
<marker>Martin, 1990</marker>
<rawString>James Martin. 1990. A Computational Model of Metaphor Interpretation. Academic Press Professional, Inc., San Diego, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>A corpus-based analysis of context effects on metaphor comprehension.</title>
<date>2006</date>
<booktitle>Corpus-Based Approaches to Metaphor and Metonymy,</booktitle>
<editor>In A. Stefanowitsch and S. T. Gries, editors,</editor>
<location>Berlin. Mouton</location>
<note>de Gruyter.</note>
<contexts>
<context position="1934" citStr="Martin, 2006" startWordPosition="294" endWordPosition="295">his policy is strangling business. The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999</context>
</contexts>
<marker>Martin, 2006</marker>
<rawString>James Martin. 2006. A corpus-based analysis of context effects on metaphor comprehension. In A. Stefanowitsch and S. T. Gries, editors, Corpus-Based Approaches to Metaphor and Metonymy, Berlin. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zachary Mason</author>
</authors>
<title>Cormet: a computational, corpus-based conventional metaphor extraction system.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="2834" citStr="Mason, 2004" startWordPosition="426" endWordPosition="428">ation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semant</context>
<context position="8114" citStr="Mason, 2004" startWordPosition="1237" endWordPosition="1238">, nominal and adjectival metaphors at the sentence level. The authors discriminate between conventional metaphors (included in WordNet) and novel metaphors. Birke and Sarkar (2006) present a sentence clustering approach that employs a set of seed sentences annotated for literalness and computes similarity between the new input sentence and all of the seed sentences. The system then tags the sentence as literal or metaphorical according to the annotation in the most similar seeds, attaining an f-score of 53.8%. The first system to discover source–target domain mappings automatically is CorMet (Mason, 2004). It does this by searching for systematic variations in domain-specific verb selectional preferences. For example, pour is a characteristic verb in both LAB and FINANCE domains. In the LAB domain it has 277 a strong preference for liquids and in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and C</context>
</contexts>
<marker>Mason, 2004</marker>
<rawString>Zachary Mason. 2004. Cormet: a computational, corpus-based conventional metaphor extraction system. Computational Linguistics, 30(1):23–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>Semeval2007 task 10: English lexical substitution task.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>48--53</pages>
<contexts>
<context position="16325" citStr="McCarthy and Navigli, 2007" startWordPosition="2594" endWordPosition="2597">are hypernyms of the verb v, or share a common hypernym with it. Following Shutova, we restrict the hypernym search to a depth of three levels in the taxonomy. Table 1 shows the filtered lists of paraphrases for the expressions “stir excitement” and “campaign surged”. The goal of the filter is to discard unrelated paraphrases and thus ensure the meaning retention during paraphrasing. Note, however, that we define meaning retention broadly, as sharing a set of similar basic properties. Such a broad definition distinguishes our system from other WordNet-based approaches to lexical substitution (McCarthy and Navigli, 2007) and allows for a transition from metaphorical to literal language, while preserving the original meaning. 3.2.3 SP-based Re-ranking The lists of paraphrases which were generated as described above contain some irrelevant paraphrases (e.g. “campaign lifted” for “campaign surged”) and some metaphorically-used paraphrases (e.g. “campaign soared”). However, our aim is to identify literal paraphrases among the candidates. Shutova’s method uses selectional preferences of the candi279 Log-likelihood Paraphrase Verb-DirectObject stir excitement: -14.28 create -14.84 provoke -15.53 make -15.53 elicit </context>
</contexts>
<marker>McCarthy, Navigli, 2007</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2007. Semeval2007 task 10: English lexical substitution task. In Proceedings of the 4th workshop on Semantic Evaluations (SemEval-2007), pages 48–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>Roberto Navigli</author>
</authors>
<title>Getting synonym candidates from raw data in the english lexical substitution task.</title>
<date>2010</date>
<booktitle>In Proceedings of the 14th EURALEX International Congress,</booktitle>
<location>Leeuwarden, The Netherlands.</location>
<contexts>
<context position="32146" citStr="McCarthy et al., 2010" startWordPosition="5112" endWordPosition="5115">c tasks within NLP. Although we have so far tested our system on verb-subject and verb-object metaphors only, we believe that the described identification and paraphrasing techniques can be similarly applied to a wider range of syntactic constructions. Extending the system to deal with more parts of speech and types of phrases (e.g. nominal and adjectival metaphors) is part of our future work. Another promising future research avenue is integrating the techniques with unsupervised paraphrasing and lexical substitution methods, using e.g. distributional similarity measures (Pucci et al., 2009; McCarthy et al., 2010) or vector space models of word meaning (Erk and Pad´o, 2008; Erk and Pad´o, 2009; De Cao and Basili, 2009; Shutova et al., 2012b). These methods could fully or partly replace the WordNet filter in the detection of similar basic features of the concepts, or add useful information to it. Fully replacing the WordNet filter by an unsupervised method would make the system more robust and more easily portable across domains and genres. This may also eliminate some of the system errors that arise from the inconsistent sense annotation and the inclusion of some metaphorical senses in WordNet. 283 Ack</context>
</contexts>
<marker>McCarthy, Keller, Navigli, 2010</marker>
<rawString>Diana McCarthy, Bill Keller, and Roberto Navigli. 2010. Getting synonym candidates from raw data in the english lexical substitution task. In Proceedings of the 14th EURALEX International Congress, Leeuwarden, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Knowledge-based Action Representations for Metaphor and Aspect (KARMA).</title>
<date>1997</date>
<tech>Technical report, PhD thesis,</tech>
<institution>University of California at Berkeley.</institution>
<contexts>
<context position="3053" citStr="Narayanan, 1997" startWordPosition="461" endWordPosition="462">ions, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pages 276–285, Atlanta, Georgia, June 13-14, 2013. c�2013 Association for Computational Linguistics phenomena (Gedigian et al., 2006; Krishna</context>
</contexts>
<marker>Narayanan, 1997</marker>
<rawString>Srini Narayanan. 1997. Knowledge-based Action Representations for Metaphor and Aspect (KARMA). Technical report, PhD thesis, University of California at Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srini Narayanan</author>
</authors>
<title>Moving right along: A computational model of metaphoric reasoning about events.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI 99),</booktitle>
<pages>121--128</pages>
<location>Orlando, Florida.</location>
<contexts>
<context position="2535" citStr="Narayanan, 1999" startWordPosition="386" endWordPosition="387">3; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et a</context>
</contexts>
<marker>Narayanan, 1999</marker>
<rawString>Srini Narayanan. 1999. Moving right along: A computational model of metaphoric reasoning about events. In Proceedings of AAAI 99), pages 121–128, Orlando, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dario Pucci</author>
<author>Marco Baroni</author>
<author>Franco Cutugno</author>
<author>Alessandro Lenci</author>
</authors>
<title>Unsupervised lexical substitution with a word space model.</title>
<date>2009</date>
<booktitle>In Proceedings of EVALITA workshop, 11th Congress of Italian Association for Artificial Intelligence.</booktitle>
<contexts>
<context position="32122" citStr="Pucci et al., 2009" startWordPosition="5108" endWordPosition="5111">nge of other semantic tasks within NLP. Although we have so far tested our system on verb-subject and verb-object metaphors only, we believe that the described identification and paraphrasing techniques can be similarly applied to a wider range of syntactic constructions. Extending the system to deal with more parts of speech and types of phrases (e.g. nominal and adjectival metaphors) is part of our future work. Another promising future research avenue is integrating the techniques with unsupervised paraphrasing and lexical substitution methods, using e.g. distributional similarity measures (Pucci et al., 2009; McCarthy et al., 2010) or vector space models of word meaning (Erk and Pad´o, 2008; Erk and Pad´o, 2009; De Cao and Basili, 2009; Shutova et al., 2012b). These methods could fully or partly replace the WordNet filter in the detection of similar basic features of the concepts, or add useful information to it. Fully replacing the WordNet filter by an unsupervised method would make the system more robust and more easily portable across domains and genres. This may also eliminate some of the system errors that arise from the inconsistent sense annotation and the inclusion of some metaphorical se</context>
</contexts>
<marker>Pucci, Baroni, Cutugno, Lenci, 2009</marker>
<rawString>Dario Pucci, Marco Baroni, Franco Cutugno, and Alessandro Lenci. 2009. Unsupervised lexical substitution with a word space model. In Proceedings of EVALITA workshop, 11th Congress of Italian Association for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selection and Information: A Class-based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="6089" citStr="Resnik, 1993" startWordPosition="921" endWordPosition="922">excitement”, but the reverse paraphrasing of provoke would not retrieve stir, indicating the non-literal use of stir. We experimentally verify this hypothesis in a setting involving single-word metaphors expressed by a verb in verb-subject and verb-direct object relations. We apply the selectional preference-based metaphor paraphrasing method of Shutova (2010) to retrieve literal paraphrases of all input verbs and extend the method to perform metaphor identification. In summary, our system (1) determines the likelihood of a verb being metaphorical based on its selectional preference strength (Resnik, 1993); (2) identifies a set of literal paraphrases for verbs that may be used metaphorically using the algorithm of Shutova (2010); (3) performs reverse paraphrasing of each of the identified paraphrases, aiming to retrieve the original expression; and (4) if the original expression is retrieved then the verb is tagged as literal, otherwise it is tagged as metaphorical. We evaluated the performance of the system using the manually annotated metaphor corpus of Shutova and Teufel (2010) in precision- and recall-oriented settings. In addition, we compared its performance to that of a baseline using se</context>
<context position="11666" citStr="Resnik (1993)" startWordPosition="1813" endWordPosition="1814">is then applied in the next steps to determine if the remaining verbs are indeed used metaphorically in the given context. We automatically acquired selectional preference distributions for verb-subject and verb-direct object relations from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser (Briscoe et al., 2006; Andersen et al., 2008). We applied the noun clustering method of Sun and Korhonen (2009) to 2000 most frequent nouns in the BNC to obtain 200 common selectional preference classes. To quantify selectional preferences, we adopted the SPS measure of Resnik (1993). Resnik defines SPS of a verb as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position (regardless of the verb). He quantifies this difference using the Kullback-Leibler divergence: SR(v) = D(P(c|v)||P(c)) = EPc P(c|v) log P(C|V), (1) where P(c) is the prior probability of the noun class, P(c|v) is the posterior probability of the noun class given the verb and R is the grammatical relation. We calculated SPS for verb-subject and verbdirect object grammatical relations. The optimal select</context>
<context position="18069" citStr="Resnik (1993)" startWordPosition="2854" endWordPosition="2855">is is yet another modification of Wilks’ SP violation view of metaphor. Shutova (2010) has previously shown that selecting the paraphrases whose preferences the noun in the context matches best allows to filter out non-literalness, as well as unrelated terms. As in case of the SPS filter, we automatically acquired selectional preference distributions of the verbs in the paraphrase lists (for verb-subject and verb-direct object relations) from the RASP-parsed BNC. In order to quantify how well a particular argument class fits the verb, we adopted the selectional association measure proposed by Resnik (1993). Selectional association is defined as follows: 1 P (c|v) AR(v, c) = SR(v)P(c|v) log P (c) , (5) where P(c) is the prior probability of the noun class, P(c|v) is the posterior probability of the noun class given the verb and SR is the overall selectional preference strength of the verb in the grammatical relation R. We use selectional association as a measure of semantic fitness of the paraphrases into the conAssociation Paraphrase Verb-DirectObject stir excitement: 0.0696 provoke 0.0245 elicit 0.0194 arouse 0.0061 conjure 0.0028 create 0.0001 stimulate � 0 raise � 0 make � 0 excite Subject-V</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Resnik. 1993. Selection and Information: A Class-based Approach to Lexical Relationships. Ph.D. thesis, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
</authors>
<title>Metaphor corpus annotated for source - target domain mappings.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC 2010,</booktitle>
<pages>3255--3261</pages>
<contexts>
<context position="1981" citStr="Shutova and Teufel, 2010" startWordPosition="300" endWordPosition="303"> The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have invest</context>
<context position="6573" citStr="Shutova and Teufel (2010)" startWordPosition="996" endWordPosition="999">In summary, our system (1) determines the likelihood of a verb being metaphorical based on its selectional preference strength (Resnik, 1993); (2) identifies a set of literal paraphrases for verbs that may be used metaphorically using the algorithm of Shutova (2010); (3) performs reverse paraphrasing of each of the identified paraphrases, aiming to retrieve the original expression; and (4) if the original expression is retrieved then the verb is tagged as literal, otherwise it is tagged as metaphorical. We evaluated the performance of the system using the manually annotated metaphor corpus of Shutova and Teufel (2010) in precision- and recall-oriented settings. In addition, we compared its performance to that of a baseline using selectional preference violation as an indicator of metaphor, as well as to two previous metaphor identification approaches of Shutova et al. (2010) and Turney et al. (2011). 2 Related Work One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation. In case of a violation, the respective phrase is first tested for being met</context>
<context position="23161" citStr="Shutova and Teufel (2010)" startWordPosition="3657" endWordPosition="3660">ine system then classified the instances where selectional association of the verb and the noun in the phrase were below a certain threshold, as metaphorical. We determined the optimal threshold by qualitative analysis of the selectional preference distributions of 50 verbs of different frequency and SPS (through the analysis of literally and metaphorically-used arguments). The threshold was averaged over individual verbs’ thresholds and equals 0.07 for direct object relations, and 0.09 for subject relations. 4.2 Evaluation Corpus We evaluated the system and the baseline against the corpus of Shutova and Teufel (2010), that was manually annotated for metaphorical expressions. The corpus is a 14,000-word subset of the BNC, with the texts selected to retain the original balance of genre in the BNC itself. The corpus contains extracts from fiction, newspaper text, radio broadcast (transcribed speech), essays and journal articles on politics, social science and literature. Shutova and Teufel (2010) identified 241 metaphorical expressions in the corpus, out of which 164 were verbal metaphors. We parsed the corpus using the RASP parser and extracted subject and direct object relations from its output. Among the </context>
<context position="24834" citStr="Shutova and Teufel (2010)" startWordPosition="3933" endWordPosition="3936">mong 281 Relation Bsln P System P Bsln R System R Verb-DObj 0.20 0.69 0.52 0.63 Verb-Subj 0.13 0.66 0.59 0.70 Average 0.17 0.68 0.55 0.66 Table 4: Baseline and system performance by relation the ones that were tagged by the system. Recall, R, measures the proportion of metaphorical expressions that were identified out of all metaphorical expressions in the gold standard corpus. The system P = 0.68 and R = 0.66, whereas the baseline only attains P = 0.17 and R = 0.55. System performance by relation is shown in Table 4. The human ceiling for this task, according to the annotation experiments of Shutova and Teufel (2010) approximates to P = 0.80. Figure 1 shows example sentences with metaphors identified and paraphrased by the system. Table 5 provides a breakdown of the annotated instances into true / false positives and true / false negatives. As one can see from the table, the systems can accurately annotate both metaphorical and literal expressions, providing a balance between precision and recall. The system outperforms the baseline for both verb-subject and verb-direct object constructions. Its performance is also close to the previous metaphor identification systems of Turney et al. (2011) (accuracy of </context>
</contexts>
<marker>Shutova, Teufel, 2010</marker>
<rawString>Ekaterina Shutova and Simone Teufel. 2010. Metaphor corpus annotated for source - target domain mappings. In Proceedings of LREC 2010, pages 3255– 3261, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Metaphor identification using verb and noun clustering.</title>
<date>2010</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>1002--1010</pages>
<location>Beijing, China.</location>
<contexts>
<context position="2894" citStr="Shutova et al., 2010" startWordPosition="435" endWordPosition="438">any others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and</context>
<context position="6835" citStr="Shutova et al. (2010)" startWordPosition="1036" endWordPosition="1039">; (3) performs reverse paraphrasing of each of the identified paraphrases, aiming to retrieve the original expression; and (4) if the original expression is retrieved then the verb is tagged as literal, otherwise it is tagged as metaphorical. We evaluated the performance of the system using the manually annotated metaphor corpus of Shutova and Teufel (2010) in precision- and recall-oriented settings. In addition, we compared its performance to that of a baseline using selectional preference violation as an indicator of metaphor, as well as to two previous metaphor identification approaches of Shutova et al. (2010) and Turney et al. (2011). 2 Related Work One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordN</context>
<context position="8977" citStr="Shutova et al. (2010)" startWordPosition="1369" endWordPosition="1372">d in the FINANCE domain for money. From this the system infers the domain mapping FINANCE – LAB and the concept mapping money – liquid. Gedigian et al. (2006) trained a maximum entropy classifier to discriminate between literal and metaphorical use. They annotated the sentences from PropBank (Kingsbury and Palmer, 2002) containing the verbs of MOTION and CURE for metaphoricity. They used PropBank annotation (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering. As a result, the system can recognize new metaphorical expressions in unrestricted text (e.g. from the seed “stir excitement” it infers that “swallow anger” is also a metaphor), achieving a precision of 79%. Turney et al. (2011) classify verbs and adjectives as literal or metaphorical based on their level of concreteness or abstractness in relation to a noun they appear with. They learn concreteness rankings for word</context>
<context position="25465" citStr="Shutova et al. (2010)" startWordPosition="4033" endWordPosition="4036">tes to P = 0.80. Figure 1 shows example sentences with metaphors identified and paraphrased by the system. Table 5 provides a breakdown of the annotated instances into true / false positives and true / false negatives. As one can see from the table, the systems can accurately annotate both metaphorical and literal expressions, providing a balance between precision and recall. The system outperforms the baseline for both verb-subject and verb-direct object constructions. Its performance is also close to the previous metaphor identification systems of Turney et al. (2011) (accuracy of 0.73) and Shutova et al. (2010) (precision of 0.79), however, the results are not directly comparable due to different experimental settings. Our method has a strong advantage over the system of Shutova et al. (2010) in terms of coverage: the latter system heavily relied on manually annotated seed metaphors which limited its applicability in unrestricted text to the set of topics covered by the seeds. As opposed to this, our method is domainindependent and can be applied to any data. Shutova et al. (2010) have not measured the recall of their system, however indicated its possible coverage limitations. In addition, our syst</context>
</contexts>
<marker>Shutova, Sun, Korhonen, 2010</marker>
<rawString>Ekaterina Shutova, Lin Sun, and Anna Korhonen. 2010. Metaphor identification using verb and noun clustering. In Proceedings of Coling 2010, pages 1002–1010, Beijing, China.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ekaterina Shutova</author>
<author>Simone Teufel</author>
<author>Anna Korhonen</author>
</authors>
<booktitle>2012a. Statistical Metaphor Processing. Computational Linguistics,</booktitle>
<volume>39</volume>
<issue>2</issue>
<marker>Shutova, Teufel, Korhonen, </marker>
<rawString>Ekaterina Shutova, Simone Teufel, and Anna Korhonen. 2012a. Statistical Metaphor Processing. Computational Linguistics, 39(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
<author>Tim Van de Cruys</author>
<author>Anna Korhonen</author>
</authors>
<title>Unsupervised metaphor paraphrasing using a vector space model.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<location>Mumbai, India.</location>
<marker>Shutova, Van de Cruys, Korhonen, 2012</marker>
<rawString>Ekaterina Shutova, Tim Van de Cruys, and Anna Korhonen. 2012b. Unsupervised metaphor paraphrasing using a vector space model. In Proceedings of COLING 2012, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Automatic metaphor interpretation as a paraphrasing task.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL 2010,</booktitle>
<pages>1029--1037</pages>
<location>Los Angeles, USA.</location>
<contexts>
<context position="2872" citStr="Shutova, 2010" startWordPosition="433" endWordPosition="434">on mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of t</context>
<context position="4676" citStr="Shutova (2010)" startWordPosition="704" endWordPosition="705">12a). Metaphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence suggests that humans are likely to perform identification and interpretation simultaneously, as part of a holistic metaphor comprehension process (Coulson, 2008; Utsumi, 2011; Gibbs and Colston, 2012). In this paper, we also take this stance and present the first computational method that identifies metaphorical expressions in unrestricted text by means of their interpretation. Following Shutova (2010), we define metaphor interpretation as a task of finding a literal paraphrase for a metaphorically used word and introduce the concept of symmetric reverse paraphrasing as a criterion for metaphor identification. The main assumption behind our method is that the literal paraphrases of literally-used words should yield the original phrase when paraphrased in reverse. For example, when the expression “clean the house” is paraphrased as “tidy the house”, the reverse paraphrasing of tidy would generate clean. Our expectation is that such a symmetry in paraphrasing is indicative of literal use. The</context>
<context position="6214" citStr="Shutova (2010)" startWordPosition="942" endWordPosition="943">erimentally verify this hypothesis in a setting involving single-word metaphors expressed by a verb in verb-subject and verb-direct object relations. We apply the selectional preference-based metaphor paraphrasing method of Shutova (2010) to retrieve literal paraphrases of all input verbs and extend the method to perform metaphor identification. In summary, our system (1) determines the likelihood of a verb being metaphorical based on its selectional preference strength (Resnik, 1993); (2) identifies a set of literal paraphrases for verbs that may be used metaphorically using the algorithm of Shutova (2010); (3) performs reverse paraphrasing of each of the identified paraphrases, aiming to retrieve the original expression; and (4) if the original expression is retrieved then the verb is tagged as literal, otherwise it is tagged as metaphorical. We evaluated the performance of the system using the manually annotated metaphor corpus of Shutova and Teufel (2010) in precision- and recall-oriented settings. In addition, we compared its performance to that of a baseline using selectional preference violation as an indicator of metaphor, as well as to two previous metaphor identification approaches of </context>
<context position="13005" citStr="Shutova (2010)" startWordPosition="2022" endWordPosition="2023"> verb-direct object relations (via qualitative analysis of the data). The system excludes expressions containing the verbs with preference strength below these thresholds from the set of candidate metaphors. Examples of verbs with weak direct object SPs include e.g. imagine, avoid, contain, dislike, make, admire, separate, remember and the strong SPs are exhibited by e.g. sip, hobble, roar, hoover, slam, skim, drink etc. 278 3.2 Literal Paraphrasing The verbs that can be used metaphorically according to the SPS filter are then paraphrased using the context-based literal paraphrasing method of Shutova (2010). While Shutova only used the method to paraphrase manually annotated metaphors, we extend and apply the method to paraphrasing of literally used terms and metaphor identification, eliminating the need for manual annotation of metaphorical expressions. The system takes verbs and their context in the form of subject and direct-object relations as input. It generates a list of possible paraphrases of the verb that can occur in the same context and ranks them according to their likelihood, as derived from the corpus. It then identifies shared features of the paraphrases and the verb using the Wor</context>
<context position="17542" citStr="Shutova (2010)" startWordPosition="2773" endWordPosition="2774">.53 arouse -16.23 stimulate -16.23 raise -16.23 excite -16.23 conjure Subject-Verb campaign surge: -13.01 run -15.53 improve -16.23 soar -16.23 lift Table 1: The list of paraphrases with the initial ranking dates for this purpose. Candidates used metaphorically are likely to demonstrate semantic preference for the source domain, e.g. soar would select for birds or flying devices as its subject rather than campaigns (the target domain), whereas the ones used literally would have a higher preference for the target domain. This is yet another modification of Wilks’ SP violation view of metaphor. Shutova (2010) has previously shown that selecting the paraphrases whose preferences the noun in the context matches best allows to filter out non-literalness, as well as unrelated terms. As in case of the SPS filter, we automatically acquired selectional preference distributions of the verbs in the paraphrase lists (for verb-subject and verb-direct object relations) from the RASP-parsed BNC. In order to quantify how well a particular argument class fits the verb, we adopted the selectional association measure proposed by Resnik (1993). Selectional association is defined as follows: 1 P (c|v) AR(v, c) = SR(</context>
</contexts>
<marker>Shutova, 2010</marker>
<rawString>Ekaterina Shutova. 2010. Automatic metaphor interpretation as a paraphrasing task. In Proceedings of NAACL 2010, pages 1029–1037, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard J Steen</author>
<author>Aletta G Dorst</author>
<author>J Berenike Herrmann</author>
<author>Anna A Kaal</author>
<author>Tina Krennmayr</author>
<author>Trijntje Pasma</author>
</authors>
<title>A method for linguistic metaphor identification: From MIP to MIPVU.</title>
<date>2010</date>
<publisher>John Benjamins, Amsterdam/Philadelphia.</publisher>
<contexts>
<context position="1954" citStr="Steen et al., 2010" startWordPosition="296" endWordPosition="299">strangling business. The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments</context>
</contexts>
<marker>Steen, Dorst, Herrmann, Kaal, Krennmayr, Pasma, 2010</marker>
<rawString>Gerard J. Steen, Aletta G. Dorst, J. Berenike Herrmann, Anna A. Kaal, Tina Krennmayr, and Trijntje Pasma. 2010. A method for linguistic metaphor identification: From MIP to MIPVU. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preferences.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP 2009,</booktitle>
<pages>638--647</pages>
<location>Singapore,</location>
<contexts>
<context position="11493" citStr="Sun and Korhonen (2009)" startWordPosition="1783" endWordPosition="1786">ut text, the filter determines their likelihood of being a metaphor based on their SPS and discards the weak ones. The SPS filter is context-free, and the reverse paraphrasing method is then applied in the next steps to determine if the remaining verbs are indeed used metaphorically in the given context. We automatically acquired selectional preference distributions for verb-subject and verb-direct object relations from the British National Corpus (BNC) (Burnard, 2007) that was parsed using the RASP parser (Briscoe et al., 2006; Andersen et al., 2008). We applied the noun clustering method of Sun and Korhonen (2009) to 2000 most frequent nouns in the BNC to obtain 200 common selectional preference classes. To quantify selectional preferences, we adopted the SPS measure of Resnik (1993). Resnik defines SPS of a verb as the difference between the posterior distribution of noun classes in a particular relation with the verb and their prior distribution in that syntactic position (regardless of the verb). He quantifies this difference using the Kullback-Leibler divergence: SR(v) = D(P(c|v)||P(c)) = EPc P(c|v) log P(C|V), (1) where P(c) is the prior probability of the noun class, P(c|v) is the posterior proba</context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>Lin Sun and Anna Korhonen. 2009. Improving verb clustering with automatically acquired selectional preferences. In Proceedings of EMNLP 2009, pages 638–647, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul H Thibodeau</author>
<author>Lera Boroditsky</author>
</authors>
<title>Metaphors we think with: The role of metaphor in reasoning.</title>
<date>2011</date>
<journal>PLoS ONE,</journal>
<volume>6</volume>
<issue>2</issue>
<pages>02</pages>
<contexts>
<context position="2103" citStr="Thibodeau and Boroditsky, 2011" startWordPosition="319" endWordPosition="322">. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, 2003; Martin, 2006; Steen et al., 2010; Shutova and Teufel, 2010) and the role it plays in human reasoning has been confirmed in psychological experiments (Thibodeau and Boroditsky, 2011). This makes its automatic processing an important problem for NLP and its numerous applications (such as machine translation, information extraction, opinion mining and many others). For example, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor </context>
</contexts>
<marker>Thibodeau, Boroditsky, 2011</marker>
<rawString>Paul H. Thibodeau and Lera Boroditsky. 2011. Metaphors we think with: The role of metaphor in reasoning. PLoS ONE, 6(2):e16782, 02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Yair Neuman</author>
<author>Dan Assaf</author>
<author>Yohai Cohen</author>
</authors>
<title>Literal and metaphorical sense identification through concrete and abstract context.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>680--690</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2915" citStr="Turney et al., 2011" startWordPosition="439" endWordPosition="442">le, the use of the metaphorical verb strangle in (2) reflects the speaker’s negative opinion regarding the government’s tight business regulations, which would be an important fact for an opinion mining system to discover (Narayanan, 1999). Other experiments (Agerri, 2008) have investigated and confirmed the role of metaphor interpretation for textual entailment resolution (RTE). The problem of metaphor modeling is rapidly gaining interest within NLP, with a growing number of approaches exploiting statistical techniques (Mason, 2004; Gedigian et al., 2006; Shutova, 2010; Shutova et al., 2010; Turney et al., 2011; Shutova et al., 2012a). Compared to more traditional approaches based on hand-coded knowledge (Fass, 1991; Martin, 1990; Narayanan, 1997; Narayanan, 1999; Feldman and Narayanan, 2004; Barnden and Lee, 2002; Agerri et al., 2007), these more recent methods tend to have a wider coverage, as well as be more efficient, accurate and robust. However, even the statistical metaphor processing approaches so far often focused on a limited domain or a subset of 276 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 1: Proceedings of the Main Conference and the Shared Task, pag</context>
<context position="6860" citStr="Turney et al. (2011)" startWordPosition="1041" endWordPosition="1044">aphrasing of each of the identified paraphrases, aiming to retrieve the original expression; and (4) if the original expression is retrieved then the verb is tagged as literal, otherwise it is tagged as metaphorical. We evaluated the performance of the system using the manually annotated metaphor corpus of Shutova and Teufel (2010) in precision- and recall-oriented settings. In addition, we compared its performance to that of a baseline using selectional preference violation as an indicator of metaphor, as well as to two previous metaphor identification approaches of Shutova et al. (2010) and Turney et al. (2011). 2 Related Work One of the first attempts to identify and interpret metaphorical expressions in text is the met* system of Fass (1991), that utilizes hand-coded knowledge and detects non-literalness via selectional preference violation. In case of a violation, the respective phrase is first tested for being metonymic using hand-coded patterns (e.g. CONTAINER-FORCONTENT). If this fails, the system searches the knowledge base for a relevant analogy in order to discriminate metaphorical relations from anomalous ones. The system of Krishnakumaran and Zhu (2007) uses WordNet (the hyponymy relation</context>
<context position="9385" citStr="Turney et al. (2011)" startWordPosition="1436" endWordPosition="1439">n (arguments and their semantic types) as features for classification and report an accuracy of 95.12% (however, against a majority baseline of 92.90%). The metaphor identification system of Shutova et al. (2010) starts from a small seed set of metaphorical expressions, learns the analogies involved in their production and extends the set of analogies by means of verb and noun clustering. As a result, the system can recognize new metaphorical expressions in unrestricted text (e.g. from the seed “stir excitement” it infers that “swallow anger” is also a metaphor), achieving a precision of 79%. Turney et al. (2011) classify verbs and adjectives as literal or metaphorical based on their level of concreteness or abstractness in relation to a noun they appear with. They learn concreteness rankings for words automatically (starting from a set of examples) and then search for expressions where a concrete adjective or verb is used with an abstract noun (e.g. “dark humour” is tagged as a metaphor and “dark hair” is not). They report an accuracy of 73%. 3 Method 3.1 Selectional Preference Strength Filtering One of the early influential ideas in the field of computational metaphor processing is that metaphor rep</context>
<context position="25420" citStr="Turney et al. (2011)" startWordPosition="4025" endWordPosition="4028">ments of Shutova and Teufel (2010) approximates to P = 0.80. Figure 1 shows example sentences with metaphors identified and paraphrased by the system. Table 5 provides a breakdown of the annotated instances into true / false positives and true / false negatives. As one can see from the table, the systems can accurately annotate both metaphorical and literal expressions, providing a balance between precision and recall. The system outperforms the baseline for both verb-subject and verb-direct object constructions. Its performance is also close to the previous metaphor identification systems of Turney et al. (2011) (accuracy of 0.73) and Shutova et al. (2010) (precision of 0.79), however, the results are not directly comparable due to different experimental settings. Our method has a strong advantage over the system of Shutova et al. (2010) in terms of coverage: the latter system heavily relied on manually annotated seed metaphors which limited its applicability in unrestricted text to the set of topics covered by the seeds. As opposed to this, our method is domainindependent and can be applied to any data. Shutova et al. (2010) have not measured the recall of their system, however indicated its possibl</context>
</contexts>
<marker>Turney, Neuman, Assaf, Cohen, 2011</marker>
<rawString>Peter D. Turney, Yair Neuman, Dan Assaf, and Yohai Cohen. 2011. Literal and metaphorical sense identification through concrete and abstract context. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 680–690, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akira Utsumi</author>
</authors>
<title>Computational exploration of metaphor comprehension processes using a semantic space model.</title>
<date>2011</date>
<journal>Cognitive Science,</journal>
<volume>35</volume>
<issue>2</issue>
<contexts>
<context position="4445" citStr="Utsumi, 2011" startWordPosition="670" endWordPosition="671">most commonly addressed in NLP as two individual subtasks: metaphor identification and metaphor interpretation, with the systems focusing only on one of them at a time, or at best combing the two in a pipeline (Shutova et al., 2012a). Metaphor identification systems annotate metaphorical language in text, and metaphor interpretation systems discover literal meanings of the previously annotated expressions. However, cognitive evidence suggests that humans are likely to perform identification and interpretation simultaneously, as part of a holistic metaphor comprehension process (Coulson, 2008; Utsumi, 2011; Gibbs and Colston, 2012). In this paper, we also take this stance and present the first computational method that identifies metaphorical expressions in unrestricted text by means of their interpretation. Following Shutova (2010), we define metaphor interpretation as a task of finding a literal paraphrase for a metaphorically used word and introduce the concept of symmetric reverse paraphrasing as a criterion for metaphor identification. The main assumption behind our method is that the literal paraphrases of literally-used words should yield the original phrase when paraphrased in reverse. </context>
</contexts>
<marker>Utsumi, 2011</marker>
<rawString>Akira Utsumi. 2011. Computational exploration of metaphor comprehension processes using a semantic space model. Cognitive Science, 35(2):251–296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>A preferential pattern-seeking semantics for natural language inference.</title>
<date>1975</date>
<journal>Artificial Intelligence,</journal>
<pages>6--53</pages>
<contexts>
<context position="10078" citStr="Wilks, 1975" startWordPosition="1555" endWordPosition="1556">concreteness or abstractness in relation to a noun they appear with. They learn concreteness rankings for words automatically (starting from a set of examples) and then search for expressions where a concrete adjective or verb is used with an abstract noun (e.g. “dark humour” is tagged as a metaphor and “dark hair” is not). They report an accuracy of 73%. 3 Method 3.1 Selectional Preference Strength Filtering One of the early influential ideas in the field of computational metaphor processing is that metaphor represents a violation of selectional preferences (SP) of a word in a given context (Wilks, 1975; Wilks, 1978). However, applied directly as an identification criterion, violation of SPs is also indicative of many other linguistic phenomena (e.g. metonymy), and not only metaphor, which is problematic. We modify this view and apply it to measure the potential of a word to be used metaphorically based on its selectional preference strength (SPS). The main intuition behind SPS filtering is that not all verbs have an equal potential of being a metaphor. For example, verbs such as choose, remember, describe or like do not have a strong preference for their direct objects and are equally likel</context>
</contexts>
<marker>Wilks, 1975</marker>
<rawString>Yorick Wilks. 1975. A preferential pattern-seeking semantics for natural language inference. Artificial Intelligence, 6:53–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yorick Wilks</author>
</authors>
<title>Making preferences more active.</title>
<date>1978</date>
<journal>Artificial Intelligence,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="1316" citStr="Wilks, 1978" startWordPosition="190" endWordPosition="191"> combine the two tasks in one step. It outperforms the previous approaches to metaphor identification both in terms of accuracy and coverage, as well as providing an interpretation for each identified expression. 1 Introduction Metaphor undoubtedly gives our expression more vividness, distinction and artistry, however, it is also an important linguistic tool that has long become part of our every-day language. Metaphors arise when one concept or domain is viewed in terms of the properties of another (Lakoff and Johnson, 1980). Consider the examples in (1) and (2). (1) My car drinks gasoline. (Wilks, 1978) (2) This policy is strangling business. The car in (1) and business in (2) are viewed as living beings and thus they can drink or be strangled respectively. The mapping between the car (the target concept) and living being (the source concept) is systematic and results in a number of metaphorical expressions (e.g. “This oil gives your car a second life”, “this car has is very temperamental” etc.) Lakoff and Johnson call such generalisations a source–target domain mapping, or conceptual metaphor. The ubiquity of metaphor in language has been established in a number of corpus studies (Cameron, </context>
<context position="10092" citStr="Wilks, 1978" startWordPosition="1557" endWordPosition="1558">or abstractness in relation to a noun they appear with. They learn concreteness rankings for words automatically (starting from a set of examples) and then search for expressions where a concrete adjective or verb is used with an abstract noun (e.g. “dark humour” is tagged as a metaphor and “dark hair” is not). They report an accuracy of 73%. 3 Method 3.1 Selectional Preference Strength Filtering One of the early influential ideas in the field of computational metaphor processing is that metaphor represents a violation of selectional preferences (SP) of a word in a given context (Wilks, 1975; Wilks, 1978). However, applied directly as an identification criterion, violation of SPs is also indicative of many other linguistic phenomena (e.g. metonymy), and not only metaphor, which is problematic. We modify this view and apply it to measure the potential of a word to be used metaphorically based on its selectional preference strength (SPS). The main intuition behind SPS filtering is that not all verbs have an equal potential of being a metaphor. For example, verbs such as choose, remember, describe or like do not have a strong preference for their direct objects and are equally likely to appear wi</context>
<context position="21732" citStr="Wilks (1978)" startWordPosition="3435" endWordPosition="3436">phorical verb stir in “stir excitement” is paraphrased as the literal “provoke”, the subsequent paraphrasing of “provoke” does not produce “stir”. In contrast, when the literal expression “buy a dress” is paraphrased as “purchase”, the reverse paraphrasing generates “buy” as one of the candidates, indicating the literalness of the original expression. The same is true for the metaphorical surge in “campaign surged” and the literal escape in “the prisoner escaped”. 4 Evaluation and Discussion 4.1 Baseline The baseline system is the implementation of the selectional preference violation view of Wilks (1978) using automatically induced SPs. Such a choice of a baseline allows us to compare our own modifications of the SP violation view to the original approach of Wilks in a computational setting, as well as evaluate the latter on real-world data. Another motivation behind this choice is that the symmetry of reverse paraphrasing can be seen as a kind of “normality” test, in a similar way as the satisfied selectional preferences are in Wilk’s approach. However, we believe that the SP-based reverse paraphrasing method captures significantly more information than SP violations do and thus compare the </context>
</contexts>
<marker>Wilks, 1978</marker>
<rawString>Yorick Wilks. 1978. Making preferences more active. Artificial Intelligence, 11(3):197–223.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>