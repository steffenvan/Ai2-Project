<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000996">
<title confidence="0.996703">
Predicting Success in Machine Translation
</title>
<author confidence="0.918732">
Alexandra Birch Miles Osborne Philipp Koehn
</author>
<affiliation confidence="0.830164666666667">
a.c.birch-mayne@sms.ed.ac.uk miles@inf.ed.ac.uk pkoehn@inf.ed.ac.uk
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.961414">
10 Crichton Street
Edinburgh, EH8 9AB, UK
</address>
<sectionHeader confidence="0.930638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999781294117647">
The performance of machine translation sys-
tems varies greatly depending on the source
and target languages involved. Determining
the contribution of different characteristics of
language pairs on system performance is key
to knowing what aspects of machine transla-
tion to improve and which are irrelevant. This
paper investigates the effect of different ex-
planatory variables on the performance of a
phrase-based system for 110 European lan-
guage pairs. We show that three factors are
strong predictors of performance in isolation:
the amount of reordering, the morphological
complexity of the target language and the his-
torical relatedness of the two languages. To-
gether, these factors contribute 75% to the
variability of the performance of the system.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948557692308">
Statistical machine translation (SMT) has improved
over the last decade of intensive research, but for
some language pairs, translation quality is still low.
Certain systematic differences between languages
can be used to predict this. Many researchers have
speculated on the reasons why machine translation is
hard. However, there has never been, to our knowl-
edge, an analysis of what the actual contribution of
different aspects of language pairs is to translation
performance. This understanding of where the diffi-
culties lie will allow researchers to know where to
most gainfully direct their efforts to improving the
current models of machine translation.
Many of the challenges of SMT were first out-
lined by Brown et al. (1993). The original IBM
Models were broken down into separate translation
and distortion models, recognizing the importance
of word order differences in modeling translation.
Brown et al. also highlighted the importance of mod-
eling morphology, both for reducing sparse counts
and improving parameter estimation and for the cor-
rect production of translated forms. We see these two
factors, reordering and morphology, as fundamental
to the quality of machine translation output, and we
would like to quantify their impact on system per-
formance.
It is not sufficient, however, to analyze the mor-
phological complexity of the source and target lan-
guages. It is also very important to know how sim-
ilar the morphology is between the two languages,
as two languages which are morphologically com-
plex in very similar ways, could be relatively easy
to translate. Therefore, we also include a measure of
the family relatedness of languages in our analysis.
The impact of these factors on translation is mea-
sured by using linear regression models. We perform
the analysis with data from 110 different language
pairs drawn from the Europarl project (Koehn,
2005). This contains parallel data for the 11 official
language pairs of the European Union, providing a
rich variety of different language characteristics for
our experiments. Many research papers report re-
sults on only one or two languages pairs. By analyz-
ing so many language pairs, we are able to provide
a much wider perspective on the challenges facing
machine translation. This analysis is important as it
provides very strong motivation for further research.
The findings of this paper are as follows: (1) each
of the main effects, reordering, target language com-
plexity and language relatedness, is a highly signif-
icant predictor of translation performance, (2) indi-
vidually these effects account for just over a third of
</bodyText>
<page confidence="0.976913">
745
</page>
<note confidence="0.962077">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 745–754,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.999663333333333">
the variation of the BLEU score, (3) taken together,
they account for 75% of the variation of the BLEU
score, (4) when removing Finnish results as out-
liers, reordering explains the most variation, and fi-
nally (4) the morphological complexity of the source
language is uncorrelated with performance, which
suggests that any difficulties that arise with sparse
counts are insignificant under the experimental con-
ditions outlined in this paper.
</bodyText>
<sectionHeader confidence="0.995613" genericHeader="introduction">
2 Europarl
</sectionHeader>
<bodyText confidence="0.999957315789474">
In order to analyze the influence of different lan-
guage pair characteristics on translation perfor-
mance, we need access to a large variety of compa-
rable parallel corpora. A good data source for this is
the Europarl Corpus (Koehn, 2005). It is a collection
of the proceedings of the European Parliament, dat-
ing back to 1996. Version 3 of the corpus consists of
up to 44 million words for each of the 11 official lan-
guages of the European Union: Danish (da), German
(de), Greek (el), English (en), Spanish (es), Finnish
(fi), French (fr), Italian (it), Dutch (nl), Portuguese
(pt), and Swedish (sv).
In trying to determine the effect of properties of
the languages involved in translation performance,
it is very important that other variables be kept con-
stant. Using Europarl, the size of the training data
for the different language pairs is very similar, and
there are no domain differences as all sentences are
roughly trained on translations of the same data.
</bodyText>
<sectionHeader confidence="0.994713" genericHeader="method">
3 Morphological Complexity
</sectionHeader>
<bodyText confidence="0.940503411764706">
The morphological complexity of the language pairs
involved in translation is widely recognized as one
of the factors influencing translation performance.
However, most statistical translation systems treat
different inflected forms of the same lemma as com-
pletely independent of one another. This can result in
sparse statistics and poorly estimated models. Fur-
thermore, different variations of the lemma may re-
sult in crucial differences in meaning that affect the
quality of the translation.
Work on improving MT systems’ treatment of
morphology has focussed on either reducing word
forms to lemmas to reduce sparsity (Goldwater
and McClosky, 2005; Talbot and Osborne, 2006)
or including morphological information in decod-
en fr it es pt el nl sv da de fi
Language
</bodyText>
<figureCaption confidence="0.99858">
Figure 1. Average vocabulary size for each language.
</figureCaption>
<bodyText confidence="0.999151">
ing (Dyer, 2007).
Although there is a significant amount of research
into improving the treatment of morphology, in this
paper we aim to discover the effect that different lev-
els of morphology have on translation. We measure
the amount of morphological complexity that exists
in both languages and then relate this to translation
performance.
Some languages seem to be intuitively more com-
plex than others, for instance Finnish appears more
complex than English. There is, however, no obvi-
ous way of measuring this complexity. One method
of measuring complexity is by choosing a number
of hand-picked, intuitive properties called complex-
ity indicators (Bickel and Nichols, 2005) and then
to count their occurrences. Examples of morpholog-
ical complexity indicators could be the number of in-
flectional categories or morpheme types in a typical
sentence. This method suffers from the major draw-
back of finding a principled way of choosing which
of the many possible linguistic properties should be
included in the list of indicators.
A simple alternative employed by Koehn (2005)
is to use vocabulary size as a measure of morpho-
logical complexity. Vocabulary size is strongly in-
fluenced by the number of word forms affected by
number, case, tense etc. and it is also affected by the
number of agglutinations in the language. The com-
plexity of the morphology of languages can there-
fore be approached by looking at vocabulary size.
</bodyText>
<figure confidence="0.962621833333333">
500k−
400k−
200k−
100k−
Av. Vocabulary Size
300k−
</figure>
<page confidence="0.995496">
746
</page>
<bodyText confidence="0.99875875">
Figure 1 shows the vocabulary size for all rele-
vant languages. Each language pair has a slightly
different parallel corpus, and so the size of the vo-
cabularies for each language needs to be averaged.
You can see that the size of the Finnish vocabulary is
about six times larger (510,632 words) than the En-
glish vocabulary size (88,880 words). The reason for
the large vocabulary size is that Finnish is character-
ized by a rich inflectional morphology, and it is typo-
logically classified as an agglutinative-fusional lan-
guage. As a result, words are often polymorphemic,
and become remarkably long.
</bodyText>
<sectionHeader confidence="0.993219" genericHeader="method">
4 Language Relatedness
</sectionHeader>
<bodyText confidence="0.999917636363636">
The morphological complexity of each language in
isolation could be misleading. Large differences in
morphology between two languages could be more
relevant to translation performance than a complex
morphology that is very similar in both languages.
Languages which are closely related could share
morphological forms which might be captured rea-
sonably well in translation models. We include a
measure of language relatedness in our analyses to
take this into account.
Comparative linguistics is a field of linguistics
which aims to determine the historical relatedness
of languages. Lexicostatistics, developed by Morris
Swadesh in the 1950s (Swadesh, 1955), is an ap-
proach to comparative linguistics that is appropriate
for our purposes because it results in a quantitative
measure of relatedness by comparing lists of lexical
cognates.
The lexicostatistic percentages are extracted as
follows. First, a list of universal culture-free mean-
ings are generated. Words are then collected for
these meanings for each language under consider-
ation. Lists for particular purposes have been gen-
erated. For example, we use the data from Dyen et
al. (1992) who developed a list of 200 meanings for
84 Indo-European languages. Cognacy decisions are
then made by a trained linguist. For each pair of lists
the cognacy of a form can be positive, negative or in-
determinate. Finally, the lexicostatistic percentage is
calculated. This percentage is related to the propor-
tion of meanings for a particular language pair that
are cognates, i.e. relative to the total without inde-
terminacy. Factors such as borrowing, tradition and
</bodyText>
<table confidence="0.999150111111111">
Language “animal” “black”
French animal noir
Italian animale nero
Spanish animal negro
English animal black
German tier schwarz
Swedish djur svart
Danish dyr sort
Dutch dier zwart
</table>
<tableCaption confidence="0.9610295">
Table 1. An example from the (Dyen et al., 1992) cognate
list.
</tableCaption>
<bodyText confidence="0.994915571428571">
taboo can skew the results.
A portion of the Dyen et al. (1992) data set is
shown in Table 1 as an example. From this data a
trained linguist would calculate the relatedness of
French, Italian and Spanish as 100% because their
words for “animal” and “black” are cognates. The
Romance languages share one cognate with English,
“animal” but not “black”, which means that the lex-
icostatistic percentage here would be 50%, and no
cognates with the rest of the languages, 0%.
We use the Dyen lexicostatistic percentages as our
measure of language relatedness or similarity for all
bidirectional language pairs except for Finnish, for
which there is not data. Finnish is a Finno-Ugric
language and is not part of the Indo-European lan-
guage family and is therefore not included in the
Dyen results. We were not able to recreate the con-
ditions of this study to generate the data for Finnish
- expert linguists with knowledge of all the lan-
guages would be required. Excluding Finnish would
have been a shame as it is an interesting language
to look at, however we took care to confirm which
effects found in this paper still held when exclud-
ing Finnish. Not being part of the Indo-European
languages means that its historical similarity with
our other languages is very low. For example, En-
glish would be more closely related to Hindu than to
Finnish. We therefore assume that Finnish has zero
similarity with the other languages in the set.
Figure 2 shows the symmetric matrix of language
relatedness, where the width of the square is pro-
portional to the value of relatedness. Finnish is the
language which is least related to the other lan-
guages and has a relatedness score of 0%. Spanish-
Portuguese is the most related language pair with a
</bodyText>
<page confidence="0.997237">
747
</page>
<figureCaption confidence="0.9994035">
Figure 2. Language relatedness - the width of the squares
indicates the lexicostatical relatedness.
</figureCaption>
<bodyText confidence="0.9999616875">
tion Edit Rate metric (HTER) (Snover et al., 2006)
which attempts to find the minimum number of hu-
man edits to correct a hypothesis, and admits mov-
ing blocks of words, however our algorithm is auto-
matic and does not consider inserts or deletes.
Before describing the extraction of reorderings we
need to define some concepts. We define a block A
as consisting of a source span, As, which contains
the positions from Asmin to Asmax and is aligned to
a set of target words. The minimum and maximum
positions (Atmin and Atmax) of the aligned target
words mark the block’s target span, At.
A reordering r consists of the two blocks rA and
rB, which are adjacent in the source and where the
relative order of the blocks in the source is reversed
in the target. More formally:
</bodyText>
<figure confidence="0.913117363636364">
de
fi
nl
fr
es
da
pt
el
en
sv
it
</figure>
<equation confidence="0.57822125">
it sv en el pt da es fr nl fi de
= 0.17 = 0.35 = 0.52 = 0.7
= 0.87
rAs C rBs, rAt &gt; rBt, rAsmaa = rBsmin − 1
</equation>
<bodyText confidence="0.9865965">
score of 0.87%.
A measure of family relatedness should improve
our understanding of the relationship between mor-
phological complexity and translation performance.
</bodyText>
<sectionHeader confidence="0.99298" genericHeader="method">
5 Reordering
</sectionHeader>
<bodyText confidence="0.9999372">
Reordering refers to differences in word order that
occur in a parallel corpus and the amount of reorder-
ing affects the performance of a machine translation
system. In order to determine how much it affects
performance, we first need to measure it.
</bodyText>
<subsectionHeader confidence="0.998733">
5.1 Extracting Reorderings
</subsectionHeader>
<bodyText confidence="0.999978577777778">
Reordering is largely driven by syntactic differences
between languages and can involve complex rear-
rangements between nodes in synchronous trees.
Modeling reordering exactly would require a syn-
chronous tree-substitution grammar. This represen-
tation would be sparse and heterogeneous, limiting
its usefulness as a basis for analysis. We make an
important simplifying assumption in order for the
detection and extraction of reordering data to be
tractable and useful. We assume that reordering is
a binary process occurring between two blocks that
are adjacent in the source. This is similar to the
ITG constraint (Wu, 1997), however our reorder-
ings are not dependent on a synchronous grammar
or a derivation which covers the sentences. There are
also similarities with the Human-Targeted Transla-
A consistent block means that between Atmin and
Atmax there are no target word positions aligned
to source words outside of the block’s source span
As. A reordering is consistent if the block projected
from rAsmin to rBsmaa is consistent.
The following algorithm detects reorderings and
determines the dimensions of the blocks involved.
We step through all the source words, and if a word
is reordered in the target with respect to the previ-
ous source word, then a reordering is said to have
occurred. These two words are initially defined as
the blocks A and B. Then the algorithm attempts
to grow block A from this point towards the source
starting position, while the target span of A is greater
than that of block B, and the new block A is consis-
tent. Finally it attempts to grow block B towards the
source end position, while the target span of B is
less than that of A and the new reordering is incon-
sistent.
See Figure 3 for an example of a sentence pair
with two reorderings. Initially a reordering is de-
tected between the Chinese words aligned to “from”
and “late”. The block A is grown from “late” to in-
clude the whole phrase pair “late last night”. Then
the block B is grown from “from” to include “Bei-
jing” and stops because the reordering is then con-
sistent. The next reordering is detected between “ar-
rived in” and “Beijing”. We can see that block A at-
tempts to grow as large a block as possible and block
</bodyText>
<page confidence="0.993118">
748
</page>
<figureCaption confidence="0.999476333333333">
Figure 3. A sentence pair from the test corpus, with its
alignment. Two reorderings are shown with two different
dash styles.
</figureCaption>
<bodyText confidence="0.999923714285714">
B attempts to grow the smallest block possible. The
reorderings thus extracted would be comparable to
those of a right-branching ITG with inversions. This
allows for syntactically plausible embedded reorder-
ings. This algorithm has the worst case complexity
of O(,22 ) when the words in the target occur in the
reverse order to the words in the source.
</bodyText>
<subsectionHeader confidence="0.999846">
5.2 Measuring Reordering
</subsectionHeader>
<bodyText confidence="0.999607571428571">
Our reordering extraction technique allows us to an-
alyze reorderings in corpora according to the dis-
tribution of reordering widths. In order to facilitate
the comparison of different corpora, we combine
statistics about individual reorderings into a sen-
tence level metric which is then averaged over a cor-
pus.
</bodyText>
<equation confidence="0.9812805">
RQuantity = ErER |rAs |+ |rBs|
I
</equation>
<bodyText confidence="0.999787714285714">
where R is the set of reorderings for a sentence, I
is the source sentence length, A and B are the two
blocks involved in the reordering, and |rAs |is the
size or span of block A on the source side. RQuan-
tity is thus the sum of the spans of all the reordering
blocks on the source side, normalized by the length
of the source sentence.
</bodyText>
<table confidence="0.844393">
RQuantity
Europarl, auto align 0.620
WMT06 test, auto align 0.647
WMT06 test, manual align 0.668
</table>
<tableCaption confidence="0.9935505">
Table 2. The reordering quantity for the different reorder-
ing corpora for DE-EN.
</tableCaption>
<subsectionHeader confidence="0.998086">
5.3 Automatic Alignments
</subsectionHeader>
<bodyText confidence="0.99997425">
Reorderings extracted from manually aligned data
can be reliably assumed to be correct. The only
exception to this is that embedded reorderings are
always right branching and these might contradict
syntactic structure. In this paper, however, we use
alignments that are automatically extracted from the
training corpus using GIZA++. Automatic align-
ments could give very different reordering results.
In order to justify using reordering data extracted
from automatic alignments, we must show that they
are similar enough to gold standard alignments to be
useful as a measure of reordering.
</bodyText>
<subsubsectionHeader confidence="0.803539">
5.3.1 Experimental Design
</subsubsectionHeader>
<bodyText confidence="0.999961538461539">
We select the German-English language pair be-
cause it has a reasonably high level of reordering. A
manually aligned German-English corpus was pro-
vided by Chris Callison-Burch and consists of the
first 220 sentences of test data from the 2006 ACL
Workshop on Machine Translation (WMT06) test
set. This test set is from a held out portion of the
Europarl corpus.
The automatic alignments were extracted by ap-
pending the manually aligned sentences on to the
respective Europarl v3 corpora and aligning them
using GIZA++ (Och and Ney, 2003) and the grow-
final-diag algorithm (Koehn et al., 2003).
</bodyText>
<sectionHeader confidence="0.914548" genericHeader="method">
5.3.2 Results
</sectionHeader>
<bodyText confidence="0.9998128">
In order to use automatic alignments to extract re-
ordering statistics, we need to show that reorderings
from automatic alignments are comparable to those
from manual alignments.
We first look at global reordering statistics and
then we look in more detail at the reordering dis-
tribution of the corpora. Table 2 shows the amount
of reordering in the WMT06 test corpora, with both
manual and automatic alignments, and in the auto-
matically aligned Europarl DE-EN parallel corpus.
</bodyText>
<page confidence="0.983171">
749
</page>
<figure confidence="0.842785">
Reordering Width
</figure>
<figureCaption confidence="0.927537333333333">
Figure 4. Average number of reorderings per sentence
mapped against the total width of the reorderings for DE-
EN.
</figureCaption>
<bodyText confidence="0.999885391304348">
We can see that all three corpora show a similar
amount of reordering.
Figure 4 shows that the distribution of reorder-
ings between the three corpora is also very similar.
These results provide evidence to support our use of
automatic reorderings in lieu of manually annotated
alignments. Firstly, they show that our WMT06 test
corpus is very similar to the Europarl data, which
means that any conclusions that we reach using the
WMT06 test corpus will be valid for the Europarl
data. Secondly, they show that the reordering behav-
ior of this corpus is very similar when looking at
automatic vs. manual alignments.
Although differences between the reorderings de-
tected in the manually and automatically aligned
German-English corpora are minor, there we accept
that there could be a language pair whose real re-
ordering amount is very different to the expected
amount given by the automatic alignments. A par-
ticular language pair could have alignments that are
very unsuited to the stochastic assumptions of the
IBM or HMM alignment models. However, manu-
ally aligning 110 language pairs is impractical.
</bodyText>
<subsectionHeader confidence="0.998222">
5.4 Amount of reordering for the matrix
</subsectionHeader>
<bodyText confidence="0.998694">
Extracting the amount of reordering for each of the
110 language pairs in the matrix required a sam-
pling approach. We randomly extracted a subset of
2000 sentences from each of the parallel training
corpora. From this subset we then extracted the av-
</bodyText>
<figureCaption confidence="0.999427">
Figure 5. Reordering amount - the width of the squares
indicates the amount of reordering or RQuantity.
</figureCaption>
<bodyText confidence="0.985320083333333">
erage RQuantity.
In Figure 5 the amount of reordering for each
of the language pairs is proportional to the width
of the relevant square. Note that the matrix is not
quite symmetrical - reordering results differ de-
pending on which language is chosen to measure
the reordering span. The lowest reordering scores
are generally for languages in the same language
group (like Portuguese-Spanish, 0.20, and Danish-
Swedish, 0.24) and the highest for languages from
different groups (like German-French, 0.64, and
Finnish-Spanish, 0.61).
</bodyText>
<subsectionHeader confidence="0.998598">
5.5 Language similarity and reordering
</subsectionHeader>
<bodyText confidence="0.999565">
In this paper we use linear regression models to de-
termine the correlation and significance of various
explanatory variables with the dependent variable,
the BLEU score. Ideally the explanatory variables
involved should be independent of each other, how-
ever the amount of reordering in a parallel corpus
could easily be influenced by family relatedness. We
investigate the correlation between these variables.
Figure 6 shows the plot of the reordering amount
against language similarity. The regression is highly
significant and has an R2 of 0.2347. This means that
reordering is correlated with language similarity and
that 23% of reordering can be explained by language
similarity.
</bodyText>
<table confidence="0.970101380952381">
5 10 15 20
Av. Reorderings per Sentence
0.0 0.2 0.4 0.6 0.8 1.0
ACL Test Manual
ACL Test Automatic
Euromatrix
de
fi
nl
fr
es
da
pt
el
en
sv
it
it sv en el pt da es fr nl fi de
= 0.13 = 0.25 = 0.38 = 0.51 = 0.64
Target Languages
Source Languages
</table>
<page confidence="0.781145">
750
</page>
<figure confidence="0.8951245">
0.2 0.3 0.4 0.5 0.6
Reordering Amount
</figure>
<figureCaption confidence="0.982649">
Figure 6. Reordering compared to language similarity
with regression.
</figureCaption>
<sectionHeader confidence="0.997264" genericHeader="method">
6 Experimental Design
</sectionHeader>
<bodyText confidence="0.999957166666667">
We used the phrase-based model Moses (Koehn et
al., 2007) for the experiments with all the standard
settings, including a lexicalized reordering model,
and a 5-gram language model. Tests were run on
the ACL WSMT 2008 test set (Callison-Burch et al.,
2008).
</bodyText>
<subsectionHeader confidence="0.998822">
6.1 Evaluation of Translation Performance
</subsectionHeader>
<bodyText confidence="0.993792">
We use the BLEU score (Papineni et al., 2002) to
evaluate our systems. While the role of BLEU in
machine translation evaluation is a much discussed
topic, it is generally assumed to be a adequate metric
for comparing systems of the same type.
</bodyText>
<figureCaption confidence="0.8969555">
Figure 7 shows the BLEU score results for the ma-
trix. Comparing this figure to Figure 5 there seems
to be a clear negative correlation between reordering
amount and translation performance.
</figureCaption>
<subsectionHeader confidence="0.998998">
6.2 Regression Analysis
</subsectionHeader>
<bodyText confidence="0.9993751">
We perform multiple linear regression analyses us-
ing measures of morphological complexity, lan-
guage relatedness and reordering amount as our in-
dependent variables. The dependent variable is the
translation performance metric, the BLEU score.
We then use a t-test to determine whether the co-
efficients for the independent variables are reliably
different from zero. We also test how well the model
explains the data using an R2 test. The two-tailed
significance levels of coefficients and R2 are also
</bodyText>
<figureCaption confidence="0.997237">
Figure 7. System performance - the width of the squares
indicates the system performance in terms of the BLEU
score.
</figureCaption>
<table confidence="0.999864">
Explanatory Variable Coefficient
Target Vocab. Size -3.885 ***
Language Similarity 3.274 ***
Reordering Amount -1.883 ***
Target Vocab. Size2 1.017 ***
Language Similarity2 -1.858 **
Interaction: Reord/Sim -1.4536 ***
</table>
<tableCaption confidence="0.989863">
Table 3. The impact of the various explanatory features
on the BLEU score via their coefficients in the minimal ad-
equate model.
</tableCaption>
<bodyText confidence="0.9994165">
given where * means p &lt; 0.05, ** means p &lt; 0.01,
and *** means p &lt; 0.001.
</bodyText>
<sectionHeader confidence="0.999976" genericHeader="evaluation">
7 Results
</sectionHeader>
<subsectionHeader confidence="0.981513">
7.1 Combined Model
</subsectionHeader>
<bodyText confidence="0.999980384615385">
The first question we are interested in answering is
which factors contribute most and how they interact.
We fit a multiple regression model to the data. The
source vocabulary size has no significant effect on
the outcome. All explanatory variable vectors were
normalized to be more comparable.
In Table 3 we can see the relative contribution of
the different features to the model. Source vocabu-
lary size did not contribute significantly to the ex-
planatory power of this multiple regression model
and was therefore not included. The fraction of the
variance explained by the model, or its goodness of
fit, the R2, is 0.750 which means that 75% of the
</bodyText>
<figure confidence="0.998585576923077">
●
●
● ●
● ●
●
●●
● ●
●
● ●
● ● ●
● ● ● ●
● ● ●●●
●
●
●
●
● ● ●●●
●
● ● ●
● ● ● ●●●
●
●
●●●● ●●●● ● ●
● ● ●●
●
●
● ● ●
●
●
●
●
●
●
●
●
de
fi
nl
fr
es
da
pt
el
en
sv
it
it sv en el pt da es fr nl fi de
= 0.08 = 0.16 = 0.24 = 0.32 = 0.4
Target Languages
0.0 0.2 0.4 0.6 0.8
Language Similarity
Source Languages
</figure>
<page confidence="0.994585">
751
</page>
<bodyText confidence="0.999736322580645">
variation in BLEU can be explained by these three
factors. The interaction of reordering amount and
language relatedness is the product of the values of
these two features, and in itself it is an important ex-
planatory feature.
To make sure that our regression is valid, we need
to consider the special case of Finnish. Data points
where Finnish is the target language are outliers.
Finnish has the lowest language similarity with all
other languages, and the largest vocabulary size. It
also has very high amounts of reordering, and the
lowest BLEU scores when it is the target language.
The multiple regression of Table 3 where Finnish as
the source and target language is excluded, shows
that all the effects are still very significant, with the
model’s R2 dropping only slightly to 0.68.
The coefficients of the variables in the multiple
regression model have only limited usefulness as a
measure of the impact of the explanatory variables
in the model. One important factor to consider is that
if the explanatory variables are highly correlated,
then the values of the coefficients are unstable. The
model could attribute more importance to one or the
other variable without changing the overall fit of the
model. This is the problem of multicollinearity. Our
explanatory variables are all correlated, but a large
amount of this correlation can be explained by look-
ing at language pairs with Finnish as the target lan-
guage. Excluding these data points, only language
relatedness and reordering amount are still corre-
lated, see Section 5.5 for more details.
</bodyText>
<subsectionHeader confidence="0.99903">
7.2 Contribution in isolation
</subsectionHeader>
<bodyText confidence="0.999263">
In order to establish the relative contribution of vari-
ables, we isolate their impact on the BLEU score by
modeling them in separate linear regression models.
Figure 8 shows a simple regression model over
the plot of BLEU scores against target vocabulary
size. This figure shows groups of data points with the
same target language in almost vertical lines. Each
language pair has a separate parallel training corpus,
but the target vocabulary size for one language will
be very similar in all of them. The variance in BLEU
amongst the group with the same target language is
then largely explained by the other factors, similarity
and reordering.
Figure 9 shows a simple regression model over the
plot of BLEU scores against source vocabulary size.
</bodyText>
<subsectionHeader confidence="0.580762">
Target Vocabulary Size
</subsectionHeader>
<figureCaption confidence="0.992267">
Figure 8. BLEU score of experiments compared to target
vocabulary size showing regression
</figureCaption>
<bodyText confidence="0.999835">
This regression model shows that in isolation source
vocabulary size is significant (p &lt; 0.05), but that this
is due to the distorting effect of Finnish. Excluding
results that include Finnish, there is no longer any
significant correlation with BLEU. The source mor-
phology might be significant for models trained on
smaller data sets, where model parameters are more
sensitive to sparse counts.
Figure 10 shows the simple regression model over
the plot of BLEU scores against the amount of re-
ordering. This graph shows that with more reorder-
ing, the performance of the translation model re-
duces. Data points with low levels of reordering and
high BLEU scores tend to be language pairs where
both languages are Romance languages. High BLEU
scores with high levels of reordering tend to have
German as the source language and a Romance lan-
guage as the target.
Figure 11 shows the simple regression model over
the plot of BLEU scores against the amount of lan-
guage relatedness. The left hand line of points are
the results involving Finnish. The vertical group of
points just to the right, are results where Greek
is involved. The next set of points are the results
where the translation is between Germanic and Ro-
mance languages. The final cloud to the right are re-
sults where languages are in the same family, either
within the Romance or the Germanic languages.
Table 4 shows the amount of the variance of
BLEU explained by the different models. As these
</bodyText>
<figure confidence="0.999008603448276">
● ●
●
● ●
●
●
●
●
●
●
●
●
     ||
100k 200k 300k 400k 500k
●
●
●●
●
●
●
●
●
●
●●
●
●
●
●●●
●●
●
●
●●
●
●
● ● ●
● ●
●
●
●
●
●
●
●
●● ●
●
●
●
●●
●
●
●
●
●
●●
●
●●
●●●
0.15 0.20 0.25 0.30 0.35 0.40
BLEU
</figure>
<page confidence="0.807585">
752
</page>
<figureCaption confidence="0.9894415">
Figure 9. BLEU score of experiments compared to source
vocabulary size highlighting the Finnish source vocabu-
lary data points. The regression includes Finnish in the
model.
</figureCaption>
<table confidence="0.9999106">
Explanatory Variable R2
Target Vocab. Size 0.388 ***
Reordering Amount 0.384 ***
Language Similarity 0.366 ***
Source Vocab. Size 0.045 *
Excluding Finnish
Target Vocab. Size 0.219 ***
Reordering Amount 0.332 ***
Language Similarity 0.188 ***
Source Vocab. Size 0.007
</table>
<tableCaption confidence="0.9827">
Table 4. Goodness of fit of different simple linear regres-
</tableCaption>
<bodyText confidence="0.839113230769231">
sion models which use just one explanatory variable. The
significance level represents the level of probability that
the regression is appropriate. The second set of results
excludes Finnish in the source and target language.
are simple regression models, with just one explana-
tory variable, multicolinearity is avoided. This table
shows that each of the main effects explains about a
third of the variance of BLEU, which means that they
can be considered to be of equal importance. When
Finnish examples are removed, only reordering re-
tains its power, and target vocabulary and language
similarity reduce in importance and source vocabu-
lary size no longer correlates with performance.
</bodyText>
<sectionHeader confidence="0.991091" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.9999235">
We have broken down the relative impact of the
characteristics of different language pairs on trans-
</bodyText>
<figureCaption confidence="0.970919">
Figure 11. BLEU score of experiments compared to lan-
guage relatedness.
</figureCaption>
<bodyText confidence="0.999323857142857">
lation performance. The analysis done is able to ac-
count for a large percentage (75%) of the variabil-
ity of the performance of the system, which shows
that we have captured the core challenges for the
phrase-based model. We have shown that their im-
pact is about the same, with reordering and target
vocabulary size each contributing about 0.38%.
These conclusions are only strictly relevant to the
model for which this analysis has been performed,
the phrase-based model. However, we suspect that
the conclusions would be similar for most statisti-
cal machine translation models because of their de-
pendence on automatic alignments. This will be the
topic of future work.
</bodyText>
<figure confidence="0.999244527777778">
●
●●
●
●
● ●
●
●
●
●
●
● ●
● ●
●
     ||
100k 200k 300k 400k 500k
Source Vocabulary Size
●
●
●●
●
●
● ●
● ●
●
●
●
●
●
● ●
●
●
●●
●●
●
●●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●●
●
●
●
●
●●●
● ●
●
●
●
●
● ●
● Finnish
● Other
● ●
●●●●
● ● ● ●
●● ●
● ● ● ● ● ●●
0.15 0.20 0.25 0.30 0.35 0.40
BLEU
0.2 0.3 0.4 0.5 0.6
Reordering Amount
</figure>
<figureCaption confidence="0.895752">
Figure 10. BLEU score of experiments compared to
amount of reordering.
</figureCaption>
<figure confidence="0.999864495726495">
0.0 0.2 0.4 0.6 0.8
Language Similarity
0.15 0.20 0.25 0.30 0.35 0.40
BLEU
●
●
●
●
● ●
●
● ●
●
● ●
●
●
●
●
●
● ● ●
● ●
●
●
●
●●
●
●●
●
●
●
●
●
●
●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ● ●
●
●● ● ●●●
●
●
●●● ● ● ● ●●
●
● ● ●
●
● ● ● ●
● ●
● ●
● ●
●
● ●
● ● ● ●
0.15 0.20 0.25 0.30 0.35 0.40
BLEU
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●
●
●
●
● ●●
●
●
● ●
●●
●
● ●
●
●
●
●
●
●●
●
● ● ● ●
● ●
● ●
●●●
●
●
●
●
●
●●
●
●
● ●
● ●
● ● ●
● ● ● ● ●●
</figure>
<page confidence="0.996547">
753
</page>
<sectionHeader confidence="0.99557" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997272">
Balthasar Bickel and Johanna Nichols, 2005. The World
Atlas of Language Structures, chapter Inflectional syn-
thesis of the verb. Oxford University Press.
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of machine translation: Parameter estimation. Compu-
tational Linguistics, 19(2):263–311.
Chris Callison-Burch, Cameron Fordyce, Philipp Koehn,
Christof Monz, and Josh Schroeder. 2008. Further
meta-evaluation of machine translation. In Proceed-
ings of the Third Workshop on Statistical Machine
Translation, pages 70–106, Columbus, Ohio, June. As-
sociation for Computational Linguistics.
Isidore Dyen, Joseph Kruskal, and Paul Black. 1992. An
indoeuropean classification, a lexicostatistical experi-
ment. Transactions of the American Philosophical So-
ciety, 82(5).
Chris Dyer. 2007. The ’noisier channel’: Transla-
tion from morphologically complex languages. In
Proceedings on the Workshop on Statistical Machine
Translation, Prague, Czech Republic.
Sharon Goldwater and David McClosky. 2005. Im-
proving statistical MT through morphological analy-
sis. In Proceedings of Empirical Methods in Natural
Language Processing.
Philipp Koehn, Franz Och, and Daniel Marcu. 2003. Sta-
tistical phrase-based translation. In Proceedings of the
Human Language Technology and North American As-
sociation for Computational Linguistics Conference,
pages 127–133, Edmonton, Canada. Association for
Computational Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin,
and Evan Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proceedings of
the Association for Computational Linguistics Com-
panion Demo and Poster Sessions, pages 177–180,
Prague, Czech Republic. Association for Computa-
tional Linguistics.
Philipp Koehn. 2005. Europarl: A parallel corpus for
statistical machine translation. In Proceedings of MT-
Summit.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):9–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic evalu-
ation of machine translation. In Proceedings of the As-
sociation for Computational Linguistics, pages 311–
318, Philadelphia, USA.
M Snover, B Dorr, R Schwartz, L Micciulla, and
J Makhoul. 2006. A study of translation edit rate with
targeted human annotation. In AMTA.
Morris Swadesh. 1955. Lexicostatistic dating of prehis-
toric ethnic contacts. In Proceedings American Philo-
sophical Society, volume 96, pages 452–463.
David Talbot and Miles Osborne. 2006. Modelling lex-
ical redundancy for machine translation. In Proceed-
ings of the Association of Computational Linguistics,
Sydney, Australia.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
</reference>
<page confidence="0.998883">
754
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.739905">
<title confidence="0.999931">Predicting Success in Machine Translation</title>
<author confidence="0.999858">Alexandra Birch Miles Osborne Philipp Koehn</author>
<email confidence="0.871518">a.c.birch-mayne@sms.ed.ac.ukmiles@inf.ed.ac.uk</email>
<affiliation confidence="0.997739">School of University of</affiliation>
<address confidence="0.924799">10 Crichton Edinburgh, EH8 9AB, UK</address>
<abstract confidence="0.999686555555555">The performance of machine translation systems varies greatly depending on the source and target languages involved. Determining the contribution of different characteristics of language pairs on system performance is key to knowing what aspects of machine translation to improve and which are irrelevant. This paper investigates the effect of different explanatory variables on the performance of a phrase-based system for 110 European language pairs. We show that three factors are strong predictors of performance in isolation: the amount of reordering, the morphological complexity of the target language and the historical relatedness of the two languages. Together, these factors contribute 75% to the variability of the performance of the system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>Atlas of Language Structures, chapter Inflectional synthesis of the verb.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<publisher>Oxford University Press. Peter</publisher>
<contexts>
<context position="1753" citStr="Brown et al. (1993)" startWordPosition="256" endWordPosition="259">ge pairs, translation quality is still low. Certain systematic differences between languages can be used to predict this. Many researchers have speculated on the reasons why machine translation is hard. However, there has never been, to our knowledge, an analysis of what the actual contribution of different aspects of language pairs is to translation performance. This understanding of where the difficulties lie will allow researchers to know where to most gainfully direct their efforts to improving the current models of machine translation. Many of the challenges of SMT were first outlined by Brown et al. (1993). The original IBM Models were broken down into separate translation and distortion models, recognizing the importance of word order differences in modeling translation. Brown et al. also highlighted the importance of modeling morphology, both for reducing sparse counts and improving parameter estimation and for the correct production of translated forms. We see these two factors, reordering and morphology, as fundamental to the quality of machine translation output, and we would like to quantify their impact on system performance. It is not sufficient, however, to analyze the morphological co</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Atlas of Language Structures, chapter Inflectional synthesis of the verb. Oxford University Press. Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Cameron Fordyce</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Josh Schroeder</author>
</authors>
<title>Further meta-evaluation of machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>70--106</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="22043" citStr="Callison-Burch et al., 2008" startWordPosition="3600" endWordPosition="3603">5 20 Av. Reorderings per Sentence 0.0 0.2 0.4 0.6 0.8 1.0 ACL Test Manual ACL Test Automatic Euromatrix de fi nl fr es da pt el en sv it it sv en el pt da es fr nl fi de = 0.13 = 0.25 = 0.38 = 0.51 = 0.64 Target Languages Source Languages 750 0.2 0.3 0.4 0.5 0.6 Reordering Amount Figure 6. Reordering compared to language similarity with regression. 6 Experimental Design We used the phrase-based model Moses (Koehn et al., 2007) for the experiments with all the standard settings, including a lexicalized reordering model, and a 5-gram language model. Tests were run on the ACL WSMT 2008 test set (Callison-Burch et al., 2008). 6.1 Evaluation of Translation Performance We use the BLEU score (Papineni et al., 2002) to evaluate our systems. While the role of BLEU in machine translation evaluation is a much discussed topic, it is generally assumed to be a adequate metric for comparing systems of the same type. Figure 7 shows the BLEU score results for the matrix. Comparing this figure to Figure 5 there seems to be a clear negative correlation between reordering amount and translation performance. 6.2 Regression Analysis We perform multiple linear regression analyses using measures of morphological complexity, language</context>
</contexts>
<marker>Callison-Burch, Fordyce, Koehn, Monz, Schroeder, 2008</marker>
<rawString>Chris Callison-Burch, Cameron Fordyce, Philipp Koehn, Christof Monz, and Josh Schroeder. 2008. Further meta-evaluation of machine translation. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 70–106, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isidore Dyen</author>
<author>Joseph Kruskal</author>
<author>Paul Black</author>
</authors>
<title>An indoeuropean classification, a lexicostatistical experiment.</title>
<date>1992</date>
<journal>Transactions of the American Philosophical Society,</journal>
<volume>82</volume>
<issue>5</issue>
<contexts>
<context position="9314" citStr="Dyen et al. (1992)" startWordPosition="1456" endWordPosition="1459"> to determine the historical relatedness of languages. Lexicostatistics, developed by Morris Swadesh in the 1950s (Swadesh, 1955), is an approach to comparative linguistics that is appropriate for our purposes because it results in a quantitative measure of relatedness by comparing lists of lexical cognates. The lexicostatistic percentages are extracted as follows. First, a list of universal culture-free meanings are generated. Words are then collected for these meanings for each language under consideration. Lists for particular purposes have been generated. For example, we use the data from Dyen et al. (1992) who developed a list of 200 meanings for 84 Indo-European languages. Cognacy decisions are then made by a trained linguist. For each pair of lists the cognacy of a form can be positive, negative or indeterminate. Finally, the lexicostatistic percentage is calculated. This percentage is related to the proportion of meanings for a particular language pair that are cognates, i.e. relative to the total without indeterminacy. Factors such as borrowing, tradition and Language “animal” “black” French animal noir Italian animale nero Spanish animal negro English animal black German tier schwarz Swedi</context>
</contexts>
<marker>Dyen, Kruskal, Black, 1992</marker>
<rawString>Isidore Dyen, Joseph Kruskal, and Paul Black. 1992. An indoeuropean classification, a lexicostatistical experiment. Transactions of the American Philosophical Society, 82(5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
</authors>
<title>The ’noisier channel’: Translation from morphologically complex languages.</title>
<date>2007</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6081" citStr="Dyer, 2007" startWordPosition="945" endWordPosition="946">d forms of the same lemma as completely independent of one another. This can result in sparse statistics and poorly estimated models. Furthermore, different variations of the lemma may result in crucial differences in meaning that affect the quality of the translation. Work on improving MT systems’ treatment of morphology has focussed on either reducing word forms to lemmas to reduce sparsity (Goldwater and McClosky, 2005; Talbot and Osborne, 2006) or including morphological information in decoden fr it es pt el nl sv da de fi Language Figure 1. Average vocabulary size for each language. ing (Dyer, 2007). Although there is a significant amount of research into improving the treatment of morphology, in this paper we aim to discover the effect that different levels of morphology have on translation. We measure the amount of morphological complexity that exists in both languages and then relate this to translation performance. Some languages seem to be intuitively more complex than others, for instance Finnish appears more complex than English. There is, however, no obvious way of measuring this complexity. One method of measuring complexity is by choosing a number of hand-picked, intuitive prop</context>
</contexts>
<marker>Dyer, 2007</marker>
<rawString>Chris Dyer. 2007. The ’noisier channel’: Translation from morphologically complex languages. In Proceedings on the Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>David McClosky</author>
</authors>
<title>Improving statistical MT through morphological analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5895" citStr="Goldwater and McClosky, 2005" startWordPosition="910" endWordPosition="913">lexity of the language pairs involved in translation is widely recognized as one of the factors influencing translation performance. However, most statistical translation systems treat different inflected forms of the same lemma as completely independent of one another. This can result in sparse statistics and poorly estimated models. Furthermore, different variations of the lemma may result in crucial differences in meaning that affect the quality of the translation. Work on improving MT systems’ treatment of morphology has focussed on either reducing word forms to lemmas to reduce sparsity (Goldwater and McClosky, 2005; Talbot and Osborne, 2006) or including morphological information in decoden fr it es pt el nl sv da de fi Language Figure 1. Average vocabulary size for each language. ing (Dyer, 2007). Although there is a significant amount of research into improving the treatment of morphology, in this paper we aim to discover the effect that different levels of morphology have on translation. We measure the amount of morphological complexity that exists in both languages and then relate this to translation performance. Some languages seem to be intuitively more complex than others, for instance Finnish ap</context>
</contexts>
<marker>Goldwater, McClosky, 2005</marker>
<rawString>Sharon Goldwater and David McClosky. 2005. Improving statistical MT through morphological analysis. In Proceedings of Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference,</booktitle>
<pages>127--133</pages>
<publisher>Association for</publisher>
<institution>Computational Linguistics.</institution>
<location>Edmonton, Canada.</location>
<contexts>
<context position="18036" citStr="Koehn et al., 2003" startWordPosition="2943" endWordPosition="2946">g. 5.3.1 Experimental Design We select the German-English language pair because it has a reasonably high level of reordering. A manually aligned German-English corpus was provided by Chris Callison-Burch and consists of the first 220 sentences of test data from the 2006 ACL Workshop on Machine Translation (WMT06) test set. This test set is from a held out portion of the Europarl corpus. The automatic alignments were extracted by appending the manually aligned sentences on to the respective Europarl v3 corpora and aligning them using GIZA++ (Och and Ney, 2003) and the growfinal-diag algorithm (Koehn et al., 2003). 5.3.2 Results In order to use automatic alignments to extract reordering statistics, we need to show that reorderings from automatic alignments are comparable to those from manual alignments. We first look at global reordering statistics and then we look in more detail at the reordering distribution of the corpora. Table 2 shows the amount of reordering in the WMT06 test corpora, with both manual and automatic alignments, and in the automatically aligned Europarl DE-EN parallel corpus. 749 Reordering Width Figure 4. Average number of reorderings per sentence mapped against the total width of</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the Human Language Technology and North American Association for Computational Linguistics Conference, pages 127–133, Edmonton, Canada. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics Companion Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="21845" citStr="Koehn et al., 2007" startWordPosition="3568" endWordPosition="3571">n is highly significant and has an R2 of 0.2347. This means that reordering is correlated with language similarity and that 23% of reordering can be explained by language similarity. 5 10 15 20 Av. Reorderings per Sentence 0.0 0.2 0.4 0.6 0.8 1.0 ACL Test Manual ACL Test Automatic Euromatrix de fi nl fr es da pt el en sv it it sv en el pt da es fr nl fi de = 0.13 = 0.25 = 0.38 = 0.51 = 0.64 Target Languages Source Languages 750 0.2 0.3 0.4 0.5 0.6 Reordering Amount Figure 6. Reordering compared to language similarity with regression. 6 Experimental Design We used the phrase-based model Moses (Koehn et al., 2007) for the experiments with all the standard settings, including a lexicalized reordering model, and a 5-gram language model. Tests were run on the ACL WSMT 2008 test set (Callison-Burch et al., 2008). 6.1 Evaluation of Translation Performance We use the BLEU score (Papineni et al., 2002) to evaluate our systems. While the role of BLEU in machine translation evaluation is a much discussed topic, it is generally assumed to be a adequate metric for comparing systems of the same type. Figure 7 shows the BLEU score results for the matrix. Comparing this figure to Figure 5 there seems to be a clear n</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the Association for Computational Linguistics Companion Demo and Poster Sessions, pages 177–180, Prague, Czech Republic. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MTSummit.</booktitle>
<contexts>
<context position="2897" citStr="Koehn, 2005" startWordPosition="440" endWordPosition="441">ance. It is not sufficient, however, to analyze the morphological complexity of the source and target languages. It is also very important to know how similar the morphology is between the two languages, as two languages which are morphologically complex in very similar ways, could be relatively easy to translate. Therefore, we also include a measure of the family relatedness of languages in our analysis. The impact of these factors on translation is measured by using linear regression models. We perform the analysis with data from 110 different language pairs drawn from the Europarl project (Koehn, 2005). This contains parallel data for the 11 official language pairs of the European Union, providing a rich variety of different language characteristics for our experiments. Many research papers report results on only one or two languages pairs. By analyzing so many language pairs, we are able to provide a much wider perspective on the challenges facing machine translation. This analysis is important as it provides very strong motivation for further research. The findings of this paper are as follows: (1) each of the main effects, reordering, target language complexity and language relatedness, </context>
<context position="4490" citStr="Koehn, 2005" startWordPosition="689" endWordPosition="690"> the variation of the BLEU score, (4) when removing Finnish results as outliers, reordering explains the most variation, and finally (4) the morphological complexity of the source language is uncorrelated with performance, which suggests that any difficulties that arise with sparse counts are insignificant under the experimental conditions outlined in this paper. 2 Europarl In order to analyze the influence of different language pair characteristics on translation performance, we need access to a large variety of comparable parallel corpora. A good data source for this is the Europarl Corpus (Koehn, 2005). It is a collection of the proceedings of the European Parliament, dating back to 1996. Version 3 of the corpus consists of up to 44 million words for each of the 11 official languages of the European Union: Danish (da), German (de), Greek (el), English (en), Spanish (es), Finnish (fi), French (fr), Italian (it), Dutch (nl), Portuguese (pt), and Swedish (sv). In trying to determine the effect of properties of the languages involved in translation performance, it is very important that other variables be kept constant. Using Europarl, the size of the training data for the different language pa</context>
<context position="7141" citStr="Koehn (2005)" startWordPosition="1112" endWordPosition="1113">here is, however, no obvious way of measuring this complexity. One method of measuring complexity is by choosing a number of hand-picked, intuitive properties called complexity indicators (Bickel and Nichols, 2005) and then to count their occurrences. Examples of morphological complexity indicators could be the number of inflectional categories or morpheme types in a typical sentence. This method suffers from the major drawback of finding a principled way of choosing which of the many possible linguistic properties should be included in the list of indicators. A simple alternative employed by Koehn (2005) is to use vocabulary size as a measure of morphological complexity. Vocabulary size is strongly influenced by the number of word forms affected by number, case, tense etc. and it is also affected by the number of agglutinations in the language. The complexity of the morphology of languages can therefore be approached by looking at vocabulary size. 500k− 400k− 200k− 100k− Av. Vocabulary Size 300k− 746 Figure 1 shows the vocabulary size for all relevant languages. Each language pair has a slightly different parallel corpus, and so the size of the vocabularies for each language needs to be avera</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In Proceedings of MTSummit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="17982" citStr="Och and Ney, 2003" startWordPosition="2934" endWordPosition="2937">ard alignments to be useful as a measure of reordering. 5.3.1 Experimental Design We select the German-English language pair because it has a reasonably high level of reordering. A manually aligned German-English corpus was provided by Chris Callison-Burch and consists of the first 220 sentences of test data from the 2006 ACL Workshop on Machine Translation (WMT06) test set. This test set is from a held out portion of the Europarl corpus. The automatic alignments were extracted by appending the manually aligned sentences on to the respective Europarl v3 corpora and aligning them using GIZA++ (Och and Ney, 2003) and the growfinal-diag algorithm (Koehn et al., 2003). 5.3.2 Results In order to use automatic alignments to extract reordering statistics, we need to show that reorderings from automatic alignments are comparable to those from manual alignments. We first look at global reordering statistics and then we look in more detail at the reordering distribution of the corpora. Table 2 shows the amount of reordering in the WMT06 test corpora, with both manual and automatic alignments, and in the automatically aligned Europarl DE-EN parallel corpus. 749 Reordering Width Figure 4. Average number of reor</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):9–51.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-</author>
</authors>
<marker>Papineni, Roukos, Ward, Wei-, </marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, USA.</location>
<marker>Zhu, 2002</marker>
<rawString>Jing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the Association for Computational Linguistics, pages 311– 318, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Snover</author>
<author>B Dorr</author>
<author>R Schwartz</author>
<author>L Micciulla</author>
<author>J Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In AMTA.</booktitle>
<contexts>
<context position="11911" citStr="Snover et al., 2006" startWordPosition="1894" endWordPosition="1897">or example, English would be more closely related to Hindu than to Finnish. We therefore assume that Finnish has zero similarity with the other languages in the set. Figure 2 shows the symmetric matrix of language relatedness, where the width of the square is proportional to the value of relatedness. Finnish is the language which is least related to the other languages and has a relatedness score of 0%. SpanishPortuguese is the most related language pair with a 747 Figure 2. Language relatedness - the width of the squares indicates the lexicostatical relatedness. tion Edit Rate metric (HTER) (Snover et al., 2006) which attempts to find the minimum number of human edits to correct a hypothesis, and admits moving blocks of words, however our algorithm is automatic and does not consider inserts or deletes. Before describing the extraction of reorderings we need to define some concepts. We define a block A as consisting of a source span, As, which contains the positions from Asmin to Asmax and is aligned to a set of target words. The minimum and maximum positions (Atmin and Atmax) of the aligned target words mark the block’s target span, At. A reordering r consists of the two blocks rA and rB, which are a</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>M Snover, B Dorr, R Schwartz, L Micciulla, and J Makhoul. 2006. A study of translation edit rate with targeted human annotation. In AMTA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Morris Swadesh</author>
</authors>
<title>Lexicostatistic dating of prehistoric ethnic contacts.</title>
<date>1955</date>
<booktitle>In Proceedings American Philosophical Society,</booktitle>
<volume>96</volume>
<pages>452--463</pages>
<contexts>
<context position="8825" citStr="Swadesh, 1955" startWordPosition="1381" endWordPosition="1382">e in isolation could be misleading. Large differences in morphology between two languages could be more relevant to translation performance than a complex morphology that is very similar in both languages. Languages which are closely related could share morphological forms which might be captured reasonably well in translation models. We include a measure of language relatedness in our analyses to take this into account. Comparative linguistics is a field of linguistics which aims to determine the historical relatedness of languages. Lexicostatistics, developed by Morris Swadesh in the 1950s (Swadesh, 1955), is an approach to comparative linguistics that is appropriate for our purposes because it results in a quantitative measure of relatedness by comparing lists of lexical cognates. The lexicostatistic percentages are extracted as follows. First, a list of universal culture-free meanings are generated. Words are then collected for these meanings for each language under consideration. Lists for particular purposes have been generated. For example, we use the data from Dyen et al. (1992) who developed a list of 200 meanings for 84 Indo-European languages. Cognacy decisions are then made by a trai</context>
</contexts>
<marker>Swadesh, 1955</marker>
<rawString>Morris Swadesh. 1955. Lexicostatistic dating of prehistoric ethnic contacts. In Proceedings American Philosophical Society, volume 96, pages 452–463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Modelling lexical redundancy for machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Association of Computational Linguistics,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="5922" citStr="Talbot and Osborne, 2006" startWordPosition="914" endWordPosition="917">nvolved in translation is widely recognized as one of the factors influencing translation performance. However, most statistical translation systems treat different inflected forms of the same lemma as completely independent of one another. This can result in sparse statistics and poorly estimated models. Furthermore, different variations of the lemma may result in crucial differences in meaning that affect the quality of the translation. Work on improving MT systems’ treatment of morphology has focussed on either reducing word forms to lemmas to reduce sparsity (Goldwater and McClosky, 2005; Talbot and Osborne, 2006) or including morphological information in decoden fr it es pt el nl sv da de fi Language Figure 1. Average vocabulary size for each language. ing (Dyer, 2007). Although there is a significant amount of research into improving the treatment of morphology, in this paper we aim to discover the effect that different levels of morphology have on translation. We measure the amount of morphological complexity that exists in both languages and then relate this to translation performance. Some languages seem to be intuitively more complex than others, for instance Finnish appears more complex than Eng</context>
</contexts>
<marker>Talbot, Osborne, 2006</marker>
<rawString>David Talbot and Miles Osborne. 2006. Modelling lexical redundancy for machine translation. In Proceedings of the Association of Computational Linguistics, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="13849" citStr="Wu, 1997" startWordPosition="2232" endWordPosition="2233">largely driven by syntactic differences between languages and can involve complex rearrangements between nodes in synchronous trees. Modeling reordering exactly would require a synchronous tree-substitution grammar. This representation would be sparse and heterogeneous, limiting its usefulness as a basis for analysis. We make an important simplifying assumption in order for the detection and extraction of reordering data to be tractable and useful. We assume that reordering is a binary process occurring between two blocks that are adjacent in the source. This is similar to the ITG constraint (Wu, 1997), however our reorderings are not dependent on a synchronous grammar or a derivation which covers the sentences. There are also similarities with the Human-Targeted TranslaA consistent block means that between Atmin and Atmax there are no target word positions aligned to source words outside of the block’s source span As. A reordering is consistent if the block projected from rAsmin to rBsmaa is consistent. The following algorithm detects reorderings and determines the dimensions of the blocks involved. We step through all the source words, and if a word is reordered in the target with respect</context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>