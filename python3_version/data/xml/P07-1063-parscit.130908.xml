<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000195">
<title confidence="0.991896">
PERSONAGE: Personality Generation for Dialogue
</title>
<author confidence="0.996568">
Franc¸ois Mairesse
</author>
<affiliation confidence="0.997644">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.956769">
Sheffield, S1 4DP, United Kingdom
</address>
<email confidence="0.998777">
F.Mairesse@sheffield.ac.uk
</email>
<author confidence="0.990818">
Marilyn Walker
</author>
<affiliation confidence="0.9976305">
Department of Computer Science
University of Sheffield
</affiliation>
<address confidence="0.956899">
Sheffield, S1 4DP, United Kingdom
</address>
<email confidence="0.999083">
M.A.Walker@sheffield.ac.uk
</email>
<sectionHeader confidence="0.993897" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997580952381">
Over the last fifty years, the “Big Five”
model of personality traits has become a
standard in psychology, and research has
systematically documented correlations be-
tween a wide range of linguistic variables
and the Big Five traits. A distinct line of
research has explored methods for automati-
cally generating language that varies along
personality dimensions. We present PER-
SONAGE (PERSONAlity GEnerator), the
first highly parametrizable language gener-
ator for extraversion, an important aspect
of personality. We evaluate two personal-
ity generation methods: (1) direct genera-
tion with particular parameter settings sug-
gested by the psychology literature; and (2)
overgeneration and selection using statistical
models trained from judge’s ratings. Results
show that both methods reliably generate ut-
terances that vary along the extraversion di-
mension, according to human judges.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.954475142857143">
Over the last fifty years, the “Big Five” model of per-
sonality traits has become a standard in psychology
(extraversion, neuroticism, agreeableness, conscien-
tiousness, and openness to experience), and research
has systematically documented correlations between
a wide range of linguistic variables and the Big Five
traits (Mehl et al., 2006; Norman, 1963; Oberlan-
der and Gill, 2006; Pennebaker and King, 1999). A
distinct line of research has explored methods for
automatically generating language that varies along
personality dimensions, targeting applications such
as computer gaming and educational virtual worlds
(Andr´e et al., 2000; Isard et al., 2006; Loyall and
Bates, 1997; Piwek, 2003; Walker et al., 1997) inter
</bodyText>
<page confidence="0.99124">
496
</page>
<bodyText confidence="0.993319285714286">
alia. Other work suggests a clear utility for gener-
ating language manifesting personality (Reeves and
Nass, 1996). However, to date, (1) research in gener-
ation has not systematically exploited the psycholin-
guistic findings; and (2) there has been little evalua-
tion showing that automatic generators can produce
language with recognizable personality variation.
</bodyText>
<listItem confidence="0.311945916666667">
Alt Realization Extra
5 Err... it seems to me that Le Marais isn’t as bad 1.83
as the others.
4 Right, I mean, Le Marais is the only restaurant 2.83
that is any good.
8 Ok, I mean, Le Marais is a quite french, kosher 5.17
and steak house place, you know and the atmo-
sphere isn’t nasty, it has nice atmosphere. It has
friendly service. It seems to me that the service
is nice. It isn’t as bad as the others, is it?
9 Well, it seems to me that I am sure you would 5.83
like Le Marais. It has good food, the food is
</listItem>
<bodyText confidence="0.876529884615385">
sort of rather tasty, the ambience is nice, the at-
mosphere isn’t sort of nasty, it features rather
friendly servers and its price is around 44 dol-
lars.
3 I am sure you would like Le Marais, you know. 6.00
The atmosphere is acceptable, the servers are
nice and it’s a french, kosher and steak house
place. Actually, the food is good, even if its price
is 44 dollars.
10 It seems to me that Le Marais isn’t as bad as 6.17
the others. It’s a french, kosher and steak house
place. It has friendly servers, you know but it’s
somewhat expensive, you know!
2 Basically, actually, I am sure you would like Le 6.17
Marais. It features friendly service and accept-
able atmosphere and it’s a french, kosher and
steak house place. Even if its price is 44 dollars,
it just has really good food, nice food.
Table 1: Recommendations along the extraver-
sion dimension, with the average extraversion rating
from human judges on a scale from 1 to 7. Alt-2 and
3 are from the extravert set, Alt-4 and 5 are from the
introvert set, and others were randomly generated.
Our aim is to produce a highly parameterizable
generator whose outputs vary along personality di-
mensions. We hypothesize that such language can
</bodyText>
<note confidence="0.903127">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 496–503,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.999874444444444">
be generated by varying parameters suggested by
psycholinguistic research. So, we must first map
the psychological findings to parameters of a natural
language generator (NLG). However, this presents
several challenges: (1) The findings result from
studies of genres of language, such as stream-of-
consciousness essays (Pennebaker and King, 1999),
and informal conversations (Mehl et al., 2006), and
thus may not apply to fixed content domains used in
NLG; (2) Most findings are based on self-reports of
personality, but we want to affect observer’s percep-
tions; (3) The findings consist of weak but signifi-
cant correlations, so that individual parameters may
not have a strong enough effect to produce recog-
nizable variation within a single utterance; (4) There
are many possible mappings of the findings to gen-
eration parameters; and (5) It is unclear whether
only specific speech-act types manifest personality
or whether all utterances do.
Thus this paper makes several contributions.
First, Section 2 summarizes the linguistic reflexes of
extraversion, organized by the modules in a standard
NLG system, and propose a mapping from these
findings to NLG parameters. To our knowledge this
is the first attempt to put forward a systematic frame-
work for generating language manifesting personal-
ity. We start with the extraversion dimension be-
cause it is an important personality factor, with many
associated linguistic variables. We believe that our
framework will generalize to the other dimensions
in the Big Five model. Second, Sections 3 and 4
describe the PERSONAGE (PERSONAlity GEner-
ator) generator and its 29 parameters. Table 1 shows
examples generated by PERSONAGE for recom-
mendations in the restaurant domain, along with
human extraversion judgments. Third, Sections 5
and 6 describe experiments evaluating two genera-
tion methods. We first show that (1) the parame-
ters generate utterances that vary significantly on the
extraversion dimension, according to human judg-
ments; and (2) we can train a statistical model that
matches human performance in assigning extraver-
sion ratings to generation outputs produced with ran-
dom parameter settings. Section 7 sums up and dis-
cusses future work.
</bodyText>
<sectionHeader confidence="0.8485785" genericHeader="introduction">
2 Psycholinguistic Findings and
PERSONAGE Parameters
</sectionHeader>
<bodyText confidence="0.999524666666667">
We hypothesize that personality can be made man-
ifest in evaluative speech acts in any dialogue do-
main, i.e. utterances responding to requests to REC-
OMMEND or COMPARE domain entities, such as
restaurants or movies (Isard et al., 2006; Stent et al.,
2004). Thus, we start with the SPaRKy genera-
tor1, which produces evaluative recommendations
and comparisons in the restaurant domain, for a
database of restaurants in New York City. There
are eight attributes for each restaurant: the name and
address, scalar attributes for price, food quality, at-
mosphere, and service and categorical attributes for
neighborhood and type of cuisine. SPaRKy is based
on the standard NLG architecture (Reiter and Dale,
2000), and consists of the following modules:
</bodyText>
<listItem confidence="0.9995275">
1. Content Planning: refine communicative goals, select and
structure content;
2. Sentence planning; choose linguistic resources (lexicon,
syntax) to achieve goals;
3. Realization: use grammar (syntax, morphology) to gen-
erate surface utterances.
</listItem>
<bodyText confidence="0.999948628571429">
Given the NLG architecture, speech-act types,
and domain, the first step then is to summarise psy-
chological findings on extraversion and map them
to this architecture. The column NLG modules of
Table 2 gives the proposed mapping. The first row
specifies findings for the content planning module
and the other rows are aspects of sentence planning.
Realization is achieved with the RealPro surface re-
alizer (Lavoie and Rambow, 1997). An examina-
tion of the introvert and extravert findings in Table 2
highlights the challenges above, i.e. exploiting these
findings in a systematic way within a parameteriz-
able NLG system.
The column Parameter in Table 2 proposes pa-
rameters (explained in Sections 3 and 4) that are ma-
nipulated within each module to realize the findings
in the other columns. Each parameter varies con-
tinuously from 0 to 1, where end points are meant
to produce extreme but plausible output. Given the
challenges above, it is important to note that these
parameters represent hypotheses about how a find-
ing can be mapped into any NLG system. The Intro
and Extra columns at the right hand side of the Pa-
rameter column indicate a range of settings for this
parameter, suggested by the psychological findings,
to produce introverted vs. extraverted language.
SPaRKy produces content plans for restaurant
recommendations and comparisons that are modi-
fied by the parameters. The sample content plan
for a recommendation in Figure 1 corresponds to
the outputs in Table 1. While Table 1 shows that
PERSONAGE’s parameters have various pragmatic
effects, they preserve the meaning at the Gricean in-
tention level (dialogue goal). Each content plan con-
tains a claim (nucleus) about the overall quality of
</bodyText>
<footnote confidence="0.9284325">
1Available for download from
www.dcs.shef.ac.uk/cogsys/sparky.html
</footnote>
<page confidence="0.994395">
497
</page>
<table confidence="0.99991805">
NLG modules Introvert findings Extravert findings Parameter Intro Extra
Content Single topic Many topics VERBOSITY low high
selection Strict selection Think out loud* RESTATEMENTS low high
and Problem talk, Pleasure talk, agreement, REPETITIONS low low
structure dissatisfaction compliment CONTENT POLARITY low high
REPETITIONS POLARITY low high
CLAIM POLARITY low high
CONCESSIONS avg avg
CONCESSIONS POLARITY low high
POLARISATION low high
POSITIVE CONTENT FIRST low high
Syntactic Few self-references Many self-references SELF-REFERENCES low high
templates Elaborated constructions Simple constructions* CLAIM COMPLEXITY high low
selection Many articles Few articles
Aggregation Many words per Few words per RELATIVE CLAUSES high low
Operations sentence/clause sentence/clause WITH CUE WORD high low
Many unfilled pauses Few unfilled pauses CONJUNCTION low high
PERIOD high low
...
Pragmatic Many nouns, adjectives, prepo- Many verbs, adverbs, pronouns SUBJECT IMPLICITNESS low high
transformations sitions (explicit) (implicit) NEGATION INSERTION high low
Many negations Few negations DOWNTONER HEDGES: high low
Many tentative words Few tentative words ·SORT OF, SOMEWHAT, QUITE, RATHER, avg avg
Formal Informal ERR, I THINK THAT, IT SEEMS THAT, IT low high
Realism Exaggeration* SEEMS TO ME THAT, I MEAN low high
No politeness form Positive face redressment* ·AROUND high low
Lower word count Higher word count ·KIND OF, LIKE low high
ACKNOWLEDGMENTS: low high
·YEAH low high
·RIGHT, OK, I SEE, WELL low avg
EMPHASIZER HEDGES: low low
·REALLY, BASICALLY, ACTUALLY, JUST
HAVE, JUST IS, EXCLAMATION
·YOU KNOW
TAG QUESTION INSERTION
HEDGE VARIATION
HEDGE REPETITION
Lexical Rich Poor LEXICON FREQUENCY low high
choice Few positive emotion words Many positive emotion words see polarity parameters
Many negative emotion words Few negative emotion words see polarity parameters
</table>
<tableCaption confidence="0.92905025">
Table 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham
(1990); Mehl et al. (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSON-
AGE’s corresponding generation parameters. Asterisks indicate hypotheses, rather than results. For details
on aggregation parameters, see Section 4.2.
</tableCaption>
<construct confidence="0.542071">
Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3);
JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5);
JUSTIFY (nuc:1, sat:6)
Content: 1. assert(best (Le Marais))
</construct>
<listItem confidence="0.9706754">
2. assert(is (Le Marais, cuisine (French)))
3. assert(has (Le Marais, food-quality (good)))
4. assert(has (Le Marais, service (good)))
5. assert(has (Le Marais, decor (decent)))
6. assert(is (Le Marais, price (44 dollars)))
</listItem>
<figureCaption confidence="0.994605">
Figure 1: A content plan for a recommendation.
</figureCaption>
<bodyText confidence="0.999542">
the selected restaurant(s), supported by a set of satel-
lite content items describing their attributes. See Ta-
ble 1. Claims can be expressed in different ways,
such as RESTAURANT NAME is the best, while
the attribute satellites follow the pattern RESTAU-
RANT NAME has MODIFIER ATTRIBUTE NAME,
as in Le Marais has good food. Recommendations
are characterized by a JUSTIFY rhetorical relation
associating the claim with all other content items,
which are linked together through an INFER relation.
In comparisons, the attributes of multiple restaurants
are compared using a CONTRAST relation. An op-
tional claim about the quality of all restaurants can
also be expressed as the nucleus of an ELABORATE
relation, with the rest of the content plan tree as a
satellite.
</bodyText>
<sectionHeader confidence="0.94309" genericHeader="method">
3 Content Planning
</sectionHeader>
<bodyText confidence="0.99957625">
Content planning selects and structures the content
to be communicated. Table 2 specifies 10 param-
eters hypothesized to affect this process which are
explained below.
Content size: Extraverts are more talkative than
introverts (Furnham, 1990; Pennebaker and King,
1999), although it is not clear whether they actu-
ally produce more content, or are just redundant and
wordy. Thus various parameters relate to the amount
and type of content produced. The VERBOSITY pa-
rameter controls the number of content items se-
lected from the content plan. For example, Alt-5 in
Table 1 is terse, while Alt-2 expresses all the items in
the content plan. The REPETITION parameter adds
an exact repetition: the content item is duplicated
and linked to the original content by a RESTATE
</bodyText>
<page confidence="0.994537">
498
</page>
<bodyText confidence="0.999414962962963">
rhetorical relation. In a similar way, the RESTATE-
MENT parameter adds paraphrases of content items
to the plan, that are obtained from the initial hand-
crafted generation dictionary (see Section 4.1) and
by automatically substituting content words with the
most frequent WordNet synonym (see Section 4.4).
Alt-9 in Table 1 contains restatements for the food
quality and the atmosphere attributes.
Polarity: Extraverts tend to be more positive; in-
troverts are characterized as engaging in more ‘prob-
lem talk’ and expressions of dissatisfaction (Thorne,
1987). To control for polarity, content items are
defined as positive or negative based on the scalar
value of the corresponding attribute. The type of cui-
sine and neighborhood attributes have neutral polar-
ity. There are multiple parameters associated with
polarity. The CONTENT POLARITY parameter con-
trols whether the content is mostly negative (e.g.
X has mediocre food), neutral (e.g. X is a Thai
restaurant), or positive. From the filtered set of
content items, the POLARISATION parameter deter-
mines whether the final content includes items with
extreme scalar values (e.g. X has fantastic staff).
In addition, polarity can also be implied more sub-
tly through rhetorical structure. The CONCESSIONS
parameter controls how negative and positive infor-
mation is presented, i.e. whether two content items
with different polarity are presented objectively, or if
one is foregrounded and the other backgrounded. If
two opposed content items are selected for a con-
cession, a CONCESS rhetorical relation is inserted
between them. While the CONCESSIONS param-
eter captures the tendency to put information into
perspective, the CONCESSION POLARITY parameter
controls whether the positive or the negative content
is concessed, i.e. marked as the satellite of the CON-
CESS relation. The last sentence of Alt-3 in Table 1
illustrates a positive concession, in which the good
food quality is put before the high price.
Content ordering: Although extraverts use more
positive language (Pennebaker and King, 1999;
Thorne, 1987), it is unclear how they position the
positive content within their utterances. Addition-
ally, the position of the claim affects the persuasive-
ness of an argument (Carenini and Moore, 2000):
starting with the claim facilitates the hearer’s under-
standing, while finishing with the claim is more ef-
fective if the hearer disagrees. The POSITIVE CON-
TENT FIRST parameter therefore controls whether
positive content items – including the claim – appear
first or last, and the order in which the content items
are aggregated. However, some operations can still
impose a specific ordering (e.g. BECAUSE cue word
to realize the JUSTIFY relation, see Section 4.2).
</bodyText>
<sectionHeader confidence="0.978219" genericHeader="method">
4 Sentence Planning
</sectionHeader>
<bodyText confidence="0.999973166666667">
Sentence planning chooses the linguistic resources
from the lexicon and the syntactic and discourse
structures to achieve the communicative goals spec-
ified in the input content plan. Table 2 specifies four
sets of findings and parameters for different aspects
of sentence planning discussed below.
</bodyText>
<subsectionHeader confidence="0.998296">
4.1 Syntactic template selection
</subsectionHeader>
<bodyText confidence="0.999142705882353">
PERSONAGE’s input generation dictionary is made
of 27 Deep Syntactic Structures (DSyntS): 9 for
the recommendation claim, 12 for the comparison
claim, and one per attribute. Selecting a DSyntS re-
quires assigning it automatically to a point in a three
dimensional space described below. All parameter
values are normalized over all the DSyntS, so the
DSyntS closest to the target value can be computed.
Syntactic complexity: Furnham (1990) suggests
that introverts produce more complex constructions:
the CLAIM COMPLEXITY parameter controls the
depth of the syntactic structure chosen to represent
the claim, e.g. the claim X is the best is rated as less
complex than X is one of my favorite restaurants.
Self-references: Extraverts make more self-
references than introverts (Pennebaker and King,
1999). The SELF-REFERENCE parameter controls
whether the claim is made in the first person, based
on the speaker’s own experience, or whether the
claim is reported as objective or information ob-
tained elsewhere. The self-reference value is ob-
tained from the syntactic structure by counting the
number of first person pronouns. For example, the
claim of Alt-2 in Table 1, i.e. I am sure you would
like Le Marais, will be rated higher than Le Marais
isn’t as bad as the others in Alt-5.
Polarity: While polarity can be expressed by con-
tent selection and structure, it can also be directly
associated with the DSyntS. The CLAIM POLARITY
parameter determines the DSyntS selected to realize
the claim. DSyntS are manually annotated for po-
larity. For example, Alt-4’s claim in Table 1, i.e. Le
Marais is the only restaurant that is any good, has a
lower polarity than Alt-2.
</bodyText>
<subsectionHeader confidence="0.997005">
4.2 Aggregation operations
</subsectionHeader>
<bodyText confidence="0.999968333333333">
SPaRKy aggregation operations are used (See Stent
et al. (2004)), with additional operations for conces-
sions and restatements. See Table 2. The probabil-
ity of the operations biases the production of com-
plex clauses, periods and formal cue words for in-
troverts, to express their preference for complex syn-
</bodyText>
<page confidence="0.996681">
499
</page>
<bodyText confidence="0.999529818181818">
tactic constructions, long pauses and rich vocabulary
(Furnham, 1990). Thus, the introvert parameters fa-
vor operations such as RELATIVE CLAUSE for the
INFER relation, PERIOD HOWEVER CUE WORD for
CONTRAST, and ALTHOUGH ADVERBIAL CLAUSE
for CONCESS, that we hypothesize to result in more
formal language. Extravert aggregation produces
longer sentences with simpler constructions and in-
formal cue words. Thus extravert utterances tend to
use operations such as a CONJUNCTION to realize
the INFER and RESTATE relations, and the EVEN IF
</bodyText>
<sectionHeader confidence="0.938969" genericHeader="method">
ADVERBIAL CLAUSE for CONCESS relations.
</sectionHeader>
<subsectionHeader confidence="0.999616">
4.3 Pragmatic transformations
</subsectionHeader>
<bodyText confidence="0.999343296875">
This section describes the insertion of markers in the
DSyntS to produce various pragmatic effects.
Hedges: Hedges correlate with introversion (Pen-
nebaker and King, 1999) and affect politeness
(Brown and Levinson, 1987). Thus there are param-
eters for inserting a wide range of hedges, both af-
fective and epistemic, such as kind of, sort of, quite,
rather, somewhat, like, around, err, I think that, it
seems that, it seems to me that, and I mean. Alt-5 in
Table 1 shows hedges err and it seems to me that.
To model extraverts use of more social language,
agreement and backchannel behavior (Dewaele and
Furnham, 1999; Pennebaker and King, 1999), we
use informal acknowledgments such as yeah, right,
ok. Acknowledgments that may affect introversion
are I see, expressing self-reference and cognitive
load, and the well cue word implying reservation
from the speaker (see Alt-9).
To model social connection and emotion we
added mechanisms for inserting emphasizers such as
you know, basically, actually, just have, just is, and
exclamations. Alt-3 in Table 1 shows the insertion
of you know and actually.
Although similar hedges can be grouped together,
each hedge has a unique pragmatic effect. For ex-
ample, you know implies positive-face redressment,
while actually doesn’t. A parameter for each hedge
controls the likelihood of its selection.
To control the general level of hedging, a HEDGE
VARIATION parameter defines how many different
hedges are selected (maximum of 5), while the fre-
quency of an individual hedge is controlled by a
HEDGE REPETITION parameter, up to a maximum
of 2 identical hedges per utterance.
The syntactic structure of hedges are defined as
well as constraints on their insertion point in the ut-
terance’s syntactic structure. Each time a hedge is
selected, it is randomly inserted at one of the inser-
tion points respecting the constraints, until the spec-
ified frequency is reached. For example, a constraint
on the hedge kind of is that it modifies adjectives.
Tag questions: Tag questions are also polite-
ness markers (Brown and Levinson, 1987). They
redress the hearer’s positive face by claiming com-
mon ground. A TAG QUESTION INSERTION param-
eter leads to negating the auxiliary of the verb and
pronominalizing the subject, e.g. X has great food
results in the insertion of doesn’t it?, as in Alt-8.
Negations: Introverts use significantly more
negations (Pennebaker and King, 1999). Although
the content parameters select more negative polarity
content items for introvert utterances, we also ma-
nipulate negations, while keeping the content con-
stant, by converting adjectives to the negative of
their antonyms, e.g. the atmosphere is nice was
transformed to not nasty in Alt-9 in Table 1.
Subject implicitness: Heylighen and Dewaele
(2002) found that extraverts use more implicit lan-
guage than introverts. To control the level of implic-
itness, the SUBJECT IMPLICITNESS parameter deter-
mines whether predicates describing restaurant at-
tributes are expressed with the restaurant in the sub-
ject, or with the attribute itself (e.g., it has goodfood
vs. the food is tasty in Alt-9).
</bodyText>
<subsectionHeader confidence="0.997921">
4.4 Lexical choice
</subsectionHeader>
<bodyText confidence="0.999991461538462">
Introverts use a richer vocabulary (Dewaele and
Furnham, 1999), so the LEXICON FREQUENCY pa-
rameter selects lexical items by their normalized fre-
quency in the British National Corpus. WordNet
synonyms are used to obtain a pool of synonyms, as
well as adjectives extracted from a corpus of restau-
rant reviews for all levels of polarity (e.g. the ad-
jective tasty in Alt-9 is a high polarity modifier of
the food attribute). Synonyms are manually checked
to make sure they are interchangeable. For example,
the content item expressed originally as it has decent
service is transformed to it features friendly service
in Alt-2, and to the servers are nice in Alt-3.
</bodyText>
<sectionHeader confidence="0.984105" genericHeader="method">
5 Experimental Method and Hypotheses
</sectionHeader>
<bodyText confidence="0.999897909090909">
Our primary hypothesis is that language generated
by varying parameters suggested by psycholinguis-
tic research can be recognized as extravert or in-
trovert. To test this hypothesis, three expert judges
evaluated a set of generated utterances as if they had
been uttered by a friend responding in a dialogue to a
request to recommend restaurants. These utterances
had been generated to systematically manipulate ex-
traversion/introversion parameters.
The judges rated each utterance for perceived ex-
traversion, by answering the two questions measur-
</bodyText>
<page confidence="0.982766">
500
</page>
<bodyText confidence="0.9999435">
ing that trait from the Ten-Item Personality Inven-
tory, as this instrument was shown to be psychome-
trically superior to a ‘single item per trait’ question-
naire (Gosling et al., 2003). The answers are aver-
aged to produce an extraversion rating ranging from
1 (highly introvert) to 7 (highly extravert). Because
it was unclear whether the generation parameters in
Table 2 would produce natural sounding utterances,
the judges also evaluated the naturalness of each ut-
terance on the same scale. The judges rated 240 ut-
terances, grouped into 20 sets of 12 utterances gen-
erated from the same content plan. They rated one
randomly ordered set at a time, but viewed all 12
utterances in that set before rating them. The ut-
terances were generated to meet two experimental
goals. First, to test the direct control of the per-
ception of extraversion. 2 introvert utterances and
2 extravert utterances were generated for each con-
tent plan (80 in total) using the parameter values
in Table 2. Multiple outputs were generated with
both parameter settings normally distributed with a
15% standard deviation. Second, 8 utterances for
each content plan (160 in total) were generated with
random parameter values. These random utterances
make it possible to: (1) improve PERSONAGE’s di-
rect output by calibrating its parameters more pre-
cisely; and (2) build a statistical model that selects
utterances matching input personality values after an
overgeneration phase (see Section 6.2). The inter-
rater agreement for extraversion between the judges
over all 240 utterances (average Pearson’s correla-
tion of 0.57) shows that the magnitude of the differ-
ences of perception between judges is almost con-
stant (Q = .037). A low agreement can yield a high
correlation (e.g. if all values differ by a constant
factor), so we also compute the intraclass correla-
tion coefficient r based on a two-way random effect
model. We obtain a r of 0.79, which is significant
at the p &lt; .001 level (reliability of average mea-
sures, identical to Cronbach’s alpha). This is com-
parable to the agreement ofjudgments of personality
in Mehl et al. (2006) (mean r = 0.84).
</bodyText>
<sectionHeader confidence="0.999038" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<subsectionHeader confidence="0.999926">
6.1 Hypothesized parameter settings
</subsectionHeader>
<bodyText confidence="0.985149142857143">
Table 1 provides examples of PERSONAGE’s out-
put and extraversion ratings. To assess whether
PERSONAGE generates language that can be rec-
ognized as introvert and extravert, we did a indepen-
dent sample t-test between the average ratings of the
40 introvert and 40 extravert utterances (parameters
with 15% standard deviation as in Table 2). Table 3
</bodyText>
<table confidence="0.999418">
Rating Introvert Extravert Random
Extraversion 2.96 5.98 5.02
Naturalness 4.93 5.78 4.51
</table>
<tableCaption confidence="0.741641">
Table 3: Average extraversion and naturalness rat-
ings for the utterances generated with introvert, ex-
travert, and random parameters.
</tableCaption>
<bodyText confidence="0.999770444444445">
shows that introvert utterances have an average rat-
ing of 2.96 out of 7 while extravert utterances have
an average rating of 5.98. These ratings are signifi-
cantly different at the p &lt; .001 level (two-tailed).
In addition, if we divide the data into two equal-
width bins around the neutral extravert rating (4 out
of 7), then PERSONAGE’s utterance ratings fall in
the bin predicted by the parameter set 89.2% of the
time. Extravert utterance are also slightly more nat-
ural than the introvert ones (p &lt; .001).
Table 3 also shows that the 160 random parame-
ter utterances produce an average extraversion rating
of 5.02, both significantly higher than the introvert
set and lower than the extravert set (p &lt; .001). In-
terestingly, the random utterances, which may com-
bine linguistic variables associated with both intro-
verts and extraverts, are less natural than the intro-
vert (p = .059) and extravert sets (p &lt; .001).
</bodyText>
<subsectionHeader confidence="0.999685">
6.2 Statistical models evaluation
</subsectionHeader>
<bodyText confidence="0.999600416666667">
We also investigate a second approach: overgener-
ation with random parameter settings, followed by
ranking via a statistical model trained on the judges’
feedback. This approach supports generating utter-
ances for any input extraversion value, as well as de-
termining which parameters affect the judges’ per-
ception.
We model perceived personality ratings (1... 7)
with regression models from the Weka toolbox (Wit-
ten and Frank, 2005). We used the full dataset of
160 averaged ratings for the random parameter utter-
ances. Each utterance was associated with a feature
vector with the generation decisions for each param-
eter in Section 2. To reduce data sparsity, we select
features that correlate significantly with the ratings
(p &lt; .10) with a coefficient higher than 0.1.
Regression models are evaluated using the mean
absolute error and the correlation between the pre-
dicted score and the actual average rating. Table 4
shows the mean absolute error on a scale from 1 to
7 over ten 10-fold cross-validations for the 4 best
regression models: Linear Regression (LR), M5’
model tree (M5), and Support Vector Machines (i.e.
SMOreg) with linear kernels (SMOI) and radial-
</bodyText>
<page confidence="0.993982">
501
</page>
<bodyText confidence="0.999392625">
basis function kernels (SMO,). All models signif-
icantly outperform the baseline (0.83 mean absolute
error, p &lt; .05), but surprisingly the linear model
performs the best with a mean absolute error of 0.65.
The best model produces a correlation coefficient of
0.59 with the judges’ ratings, which is higher than
the correlations between pairs of judges, suggesting
that the model performs as well as a human judge.
</bodyText>
<table confidence="0.999726333333333">
Metric LR M5 SMO1 SMO,
Absolute error 0.65 0.66 0.72 0.70
Correlation 0.59 0.56 0.54 0.57
</table>
<tableCaption confidence="0.814975">
Table 4: Mean absolute regression errors (scale from
1 to 7) and correlation coefficients over ten 10-fold
</tableCaption>
<bodyText confidence="0.982929315789474">
cross-validations, for 4 models: Linear Regression
(LR), M5’ model tree (M5), Support Vector Ma-
chines with linear kernels (SMO1) and radial-basis
function kernels (SMO,). All models significantly
outperform the mean baseline (0.83 error, p &lt; .05).
The M5’ regression tree in Figure 2 assigns a rat-
ing given the features. Verbosity plays the most im-
portant role: utterances with 4 or more content items
are modeled as more extravert. Given a low ver-
bosity, lexical frequency and restatements determine
the extraversion level, e.g. utterances with less than
4 content items and infrequent words are perceived
as very introverted (rating of 2.69 out of 7). For
verbose utterances, the you know hedge indicates
extraversion, as well as concessions, restatements,
self-references, and positive content. Although rel-
atively simple, these models are useful for identify-
ing new personality markers, as well as calibrating
parameters in the direct generation model.
</bodyText>
<sectionHeader confidence="0.995815" genericHeader="conclusions">
7 Discussion and Conclusions
</sectionHeader>
<bodyText confidence="0.9931376875">
We present and evaluate PERSONAGE, a parame-
terizable generator that produces outputs that vary
along the extraversion personality dimension. This
paper makes four contributions:
1. We present a systematic review of psycholinguistic find-
ings, organized by the NLG reference architecture;
2. We propose a mapping from these findings to generation
parameters for each NLG module and a real-time imple-
mentation of a generator using these parameters2. To our
knowledge this is the first attempt to put forward a sys-
tematic framework for generating language that manifests
personality;
3. We present an evaluation experiment showing that we can
control the parameters to produce recognizable linguis-
tic variation along the extraversion personality dimen-
sion. Thus, we show that the weak correlations reported
</bodyText>
<footnote confidence="0.4676565">
2An online demo is available at
www.dcs.shef.ac.uk/cogsys/personage.html
</footnote>
<reference confidence="0.50710375">
in other genres of language, and for self-reports rather
than observers, carry over to the production of single eval-
uative utterances with recognizable personality in a re-
stricted domain;
4. We present the results of a training experiment showing
that given an output, we can train a model that matches
human performance in assigning an extraversion rating to
that output.
</reference>
<bodyText confidence="0.999948173913043">
Some of the challenges discussed in the introduc-
tion remain. We have shown that evaluative utter-
ances in the restaurant domain can manifest person-
ality, but more research is needed on which speech
acts recognisably manifest personality in a restricted
domain. We also showed that the mapping we hy-
pothesised of findings to generation parameters was
effective, but there may be additional parameters
that the psycholinguistic findings could be mapped
to.
Our work was partially inspired by the ICONO-
CLAST and PAULINE parameterizable generators
(Bouayad-Agha et al., 2000; Hovy, 1988), which
vary the style, rather than the personality, of the gen-
erated texts. Walker et al. (1997) describe a gen-
erator intended to affect perceptions of personality,
based on Brown and Levinson’s theory of polite-
ness (Brown and Levinson, 1987), that uses some
of the linguistic constructions implemented here,
such as tag questions and hedges, but it was never
evaluated. Research by Andr´e et al. (2000); Piwek
(2003) uses personality variables to affect the lin-
guistic behaviour of conversational agents, but they
did not systematically manipulate parameters, and
their generators were not evaluated. Reeves and
Nass (1996) demonstrate that manipulations of per-
sonality affect many aspects of user’s perceptions,
but their experiments use handcrafted utterances,
rather than generated utterances. Cassell and Bick-
more (2003) show that extraverts prefer systems uti-
lizing discourse plans that include small talk. Paiva
and Evans’ trainable generator (2005) produces out-
puts that correspond to a set of linguistic variables
measured in a corpus of target texts. Their method
is similar to our statistical method using regression
trees, but provides direct control. The method re-
ported in Mairesse and Walker (2005) for training
individualized sentence planners ranks the outputs
produced by an overgeneration phase, rather than di-
rectly predicting a scalar value, as we do here. The
closest work to ours is probably Isard et al.’s CRAG-
2 system (2006), which overgenerates and ranks us-
ing ngram language models trained on a corpus la-
belled for all Big Five personality dimensions. How-
ever, CRAG-2 has no explicit parameter control, and
it has yet to be evaluated.
</bodyText>
<page confidence="0.985123">
502
</page>
<figure confidence="0.827853">
Verbosity
</figure>
<figureCaption confidence="0.936585">
Figure 2: M5’ regression tree. The output ranges from 1 to 7, where 7 means strongly extravert.
</figureCaption>
<figure confidence="0.998992">
Max BNC Frequency
Hedge: ‘you know’
Max BNC Frequency Restatements
Concessions
Verbosity
&lt;= 3.5
&gt; 3.5
&lt;= 0.5
&gt; 0.5
&lt;= 0.1
&gt; 0.1
&lt;= 4.5 &gt; 4.5
&lt;= 0.5
&gt; 0.02
&lt;= 0.02
&gt; 0.5
&lt;= 0.5
&gt; 0.5
2.69 3.52 Verbosity 4.47
5.93
Self−references Restatements
Content
4.12
Max BNC Frequency
3.74
3.26
4.52
5.00
5.08 5.53
Polarity
&lt;= 0.5
&gt; 0.87
&gt; 0.5 &lt;= 0.5 &gt; 0.5
&lt;= 0.87
&lt;= 0.64 &gt; 0.64
Infer aggregation:
Period
&lt;= 0.5
5.33 Verbosity
&lt;= 5.5
5.85
&gt; 5.5
&gt; 0.5
5.54 5.78
&lt;= 2.5
&gt; 2.5
</figure>
<bodyText confidence="0.999296777777778">
In future work, we hope to directly compare the
direct generation method of Section 6.1 with the
overgenerate and rank method of Section 6.2, and to
use these results to refine PERSONAGE’s parame-
ter settings. We also hope to extend PERSONAGE’s
generation capabilities to other Big Five traits, iden-
tify additional features to improve the model’s per-
formance, and evaluate the effect of personality vari-
ation on user satisfaction in various applications.
</bodyText>
<sectionHeader confidence="0.999259" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998639930555555">
E. Andr´e, T. Rist, S. van Mulken, M. Klesen, and S. Baldes.
2000. The automated design of believable dialogues for
animated presentation teams. In Embodied conversational
agents, p. 220–255. MIT Press, Cambridge, MA.
N. Bouayad-Agha, D. Scott, and R. Power. 2000. Integrating
content and style in documents: a case study of patient in-
formation leaflets. Information Design Journal, 9:161–176.
P. Brown and S. Levinson. 1987. Politeness: Some universals
in language usage. Cambridge University Press.
G. Carenini and J. D. Moore. 2000. A strategy for generating
evaluative arguments. In Proc. of International Conference
on Natural Language Generation, p. 47–54.
J. Cassell and T. Bickmore. 2003. Negotiated collusion: Model-
ing social language and its relationship effects in intelligent
agents. User Modeling and User-Adapted Interaction, 13
(1-2):89–132.
J-M. Dewaele and A. Furnham. 1999. Extraversion: the unloved
variable in applied linguistic research. Language Learning,
49(3):509–544.
A. Furnham. 1990. Language and personality. In Handbook of
Language and Social Psychology. Winley.
S. D. Gosling, P. J. Rentfrow, and W. B. Swann Jr. 2003. A very
brief measure of the big five personality domains. Journal of
Research in Personality, 37:504–528.
F. Heylighen and J-M. Dewaele. 2002. Variation in the con-
textuality of language: an empirical measure. Context in
Context, Foundations of Science, 7(3):293–340.
E. Hovy. 1988. Generating Natural Language under Pragmatic
Constraints. Lawrence Erlbaum Associates.
A. Isard, C. Brockmann, and J. Oberlander. 2006. Individuality
and alignment in generated dialogues. In Proc. ofINLG.
B. Lavoie and O. Rambow. 1997. A fast and portable realizer
for text generation systems. In Proc. ofANLP.
A. Loyall and J. Bates. 1997. Personality-rich believable agents
that use language. In Proc. of the First International Confer-
ence on Autonomous Agents, p. 106–113.
F. Mairesse and M. Walker. 2005. Learning to personalize spo-
ken generation for dialogue systems. In Proc. of the Inter-
speech - Eurospeech, p. 1881–1884.
M. Mehl, S. Gosling, and J. Pennebaker. 2006. Personality in
its natural habitat: Manifestations and implicit folk theories
of personality in daily life. Journal ofPersonality and Social
Psychology, 90:862–877.
W. T. Norman. 1963. Toward an adequate taxonomy of per-
sonality attributes: Replicated factor structure in peer nom-
ination personality rating. Journal of Abnormal and Social
Psychology, 66:574–583.
J. Oberlander and A. Gill. 2006. Language with character: A
stratified corpus comparison of individual differences in e-
mail communication. Discourse Processes, 42:239–270.
D. Paiva and R. Evans. 2005. Empirically-based control of nat-
ural language generation. In Proc. ofACL.
J. W. Pennebaker and L. A. King. 1999. Linguistic styles: Lan-
guage use as an individual difference. Journal ofPersonality
and Social Psychology, 77:1296–1312.
P. Piwek. 2003. A flexible pragmatics-driven language genera-
tor for animated agents. In Proc. ofEACL.
B. Reeves and C. Nass. 1996. The Media Equation. University
of Chicago Press.
E. Reiter and R. Dale. 2000. Building Natural Language Gen-
eration Systems. Cambridge University Press.
A. Stent, R. Prasad, and M. Walker. 2004. Trainable sentence
planning for complex information presentation in spoken di-
alog systems. In Proc. ofACL.
A. Thorne. 1987. The press of personality: A study of conver-
sations between introverts and extraverts. Journal ofPerson-
ality and Social Psychology, 53:718–726.
M. Walker, J. Cahn, and S. Whittaker. 1997. Improvising lin-
guistic style: Social and affective bases for agent personality.
In Proc. of the Conference on Autonomous Agents.
I. H. Witten and E. Frank. 2005. Data Mining: Practical ma-
chine learning tools and techniques. Morgan Kaufmann.
</reference>
<page confidence="0.998765">
503
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.761131">
<title confidence="0.999672">PERSONAGE: Personality Generation for Dialogue</title>
<author confidence="0.80164">Mairesse</author>
<affiliation confidence="0.9998575">Department of Computer Science University of Sheffield</affiliation>
<address confidence="0.999034">Sheffield, S1 4DP, United Kingdom</address>
<email confidence="0.995923">F.Mairesse@sheffield.ac.uk</email>
<author confidence="0.999872">Marilyn Walker</author>
<affiliation confidence="0.999893">Department of Computer Science University of Sheffield</affiliation>
<address confidence="0.999148">Sheffield, S1 4DP, United Kingdom</address>
<email confidence="0.999012">M.A.Walker@sheffield.ac.uk</email>
<abstract confidence="0.998004909090909">Over the last fifty years, the “Big Five” model of personality traits has become a standard in psychology, and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits. A distinct line of research has explored methods for automatically generating language that varies along personality dimensions. We present PER- SONAGE (PERSONAlity GEnerator), the first highly parametrizable language generator for extraversion, an important aspect of personality. We evaluate two personality generation methods: (1) direct generation with particular parameter settings suggested by the psychology literature; and (2) overgeneration and selection using statistical models trained from judge’s ratings. Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>in other genres of language, and for self-reports rather than observers, carry over to the production of single evaluative utterances with recognizable personality in a restricted domain;</title>
<marker></marker>
<rawString>in other genres of language, and for self-reports rather than observers, carry over to the production of single evaluative utterances with recognizable personality in a restricted domain;</rawString>
</citation>
<citation valid="false">
<title>We present the results of a training experiment showing that given an output, we can train a model that matches human performance in assigning an extraversion rating to that output.</title>
<marker></marker>
<rawString>4. We present the results of a training experiment showing that given an output, we can train a model that matches human performance in assigning an extraversion rating to that output.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Andr´e</author>
<author>T Rist</author>
<author>S van Mulken</author>
<author>M Klesen</author>
<author>S Baldes</author>
</authors>
<title>The automated design of believable dialogues for animated presentation teams.</title>
<date>2000</date>
<booktitle>In Embodied conversational agents,</booktitle>
<pages>220--255</pages>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Andr´e, Rist, van Mulken, Klesen, Baldes, 2000</marker>
<rawString>E. Andr´e, T. Rist, S. van Mulken, M. Klesen, and S. Baldes. 2000. The automated design of believable dialogues for animated presentation teams. In Embodied conversational agents, p. 220–255. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bouayad-Agha</author>
<author>D Scott</author>
<author>R Power</author>
</authors>
<title>Integrating content and style in documents: a case study of patient information leaflets.</title>
<date>2000</date>
<journal>Information Design Journal,</journal>
<pages>9--161</pages>
<marker>Bouayad-Agha, Scott, Power, 2000</marker>
<rawString>N. Bouayad-Agha, D. Scott, and R. Power. 2000. Integrating content and style in documents: a case study of patient information leaflets. Information Design Journal, 9:161–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>S Levinson</author>
</authors>
<title>Politeness: Some universals in language usage.</title>
<date>1987</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="19325" citStr="Brown and Levinson, 1987" startWordPosition="2988" endWordPosition="2991">NTRAST, and ALTHOUGH ADVERBIAL CLAUSE for CONCESS, that we hypothesize to result in more formal language. Extravert aggregation produces longer sentences with simpler constructions and informal cue words. Thus extravert utterances tend to use operations such as a CONJUNCTION to realize the INFER and RESTATE relations, and the EVEN IF ADVERBIAL CLAUSE for CONCESS relations. 4.3 Pragmatic transformations This section describes the insertion of markers in the DSyntS to produce various pragmatic effects. Hedges: Hedges correlate with introversion (Pennebaker and King, 1999) and affect politeness (Brown and Levinson, 1987). Thus there are parameters for inserting a wide range of hedges, both affective and epistemic, such as kind of, sort of, quite, rather, somewhat, like, around, err, I think that, it seems that, it seems to me that, and I mean. Alt-5 in Table 1 shows hedges err and it seems to me that. To model extraverts use of more social language, agreement and backchannel behavior (Dewaele and Furnham, 1999; Pennebaker and King, 1999), we use informal acknowledgments such as yeah, right, ok. Acknowledgments that may affect introversion are I see, expressing self-reference and cognitive load, and the well c</context>
<context position="21177" citStr="Brown and Levinson, 1987" startWordPosition="3291" endWordPosition="3294"> are selected (maximum of 5), while the frequency of an individual hedge is controlled by a HEDGE REPETITION parameter, up to a maximum of 2 identical hedges per utterance. The syntactic structure of hedges are defined as well as constraints on their insertion point in the utterance’s syntactic structure. Each time a hedge is selected, it is randomly inserted at one of the insertion points respecting the constraints, until the specified frequency is reached. For example, a constraint on the hedge kind of is that it modifies adjectives. Tag questions: Tag questions are also politeness markers (Brown and Levinson, 1987). They redress the hearer’s positive face by claiming common ground. A TAG QUESTION INSERTION parameter leads to negating the auxiliary of the verb and pronominalizing the subject, e.g. X has great food results in the insertion of doesn’t it?, as in Alt-8. Negations: Introverts use significantly more negations (Pennebaker and King, 1999). Although the content parameters select more negative polarity content items for introvert utterances, we also manipulate negations, while keeping the content constant, by converting adjectives to the negative of their antonyms, e.g. the atmosphere is nice was</context>
</contexts>
<marker>Brown, Levinson, 1987</marker>
<rawString>P. Brown and S. Levinson. 1987. Politeness: Some universals in language usage. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carenini</author>
<author>J D Moore</author>
</authors>
<title>A strategy for generating evaluative arguments.</title>
<date>2000</date>
<booktitle>In Proc. of International Conference on Natural Language Generation,</booktitle>
<pages>47--54</pages>
<contexts>
<context position="15687" citStr="Carenini and Moore, 2000" startWordPosition="2420" endWordPosition="2423">ncy to put information into perspective, the CONCESSION POLARITY parameter controls whether the positive or the negative content is concessed, i.e. marked as the satellite of the CONCESS relation. The last sentence of Alt-3 in Table 1 illustrates a positive concession, in which the good food quality is put before the high price. Content ordering: Although extraverts use more positive language (Pennebaker and King, 1999; Thorne, 1987), it is unclear how they position the positive content within their utterances. Additionally, the position of the claim affects the persuasiveness of an argument (Carenini and Moore, 2000): starting with the claim facilitates the hearer’s understanding, while finishing with the claim is more effective if the hearer disagrees. The POSITIVE CONTENT FIRST parameter therefore controls whether positive content items – including the claim – appear first or last, and the order in which the content items are aggregated. However, some operations can still impose a specific ordering (e.g. BECAUSE cue word to realize the JUSTIFY relation, see Section 4.2). 4 Sentence Planning Sentence planning chooses the linguistic resources from the lexicon and the syntactic and discourse structures to </context>
</contexts>
<marker>Carenini, Moore, 2000</marker>
<rawString>G. Carenini and J. D. Moore. 2000. A strategy for generating evaluative arguments. In Proc. of International Conference on Natural Language Generation, p. 47–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cassell</author>
<author>T Bickmore</author>
</authors>
<title>Negotiated collusion: Modeling social language and its relationship effects in intelligent agents. User Modeling and User-Adapted Interaction,</title>
<date>2003</date>
<volume>13</volume>
<pages>1--2</pages>
<marker>Cassell, Bickmore, 2003</marker>
<rawString>J. Cassell and T. Bickmore. 2003. Negotiated collusion: Modeling social language and its relationship effects in intelligent agents. User Modeling and User-Adapted Interaction, 13 (1-2):89–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-M Dewaele</author>
<author>A Furnham</author>
</authors>
<title>Extraversion: the unloved variable in applied linguistic research.</title>
<date>1999</date>
<journal>Language Learning,</journal>
<volume>49</volume>
<issue>3</issue>
<contexts>
<context position="11183" citStr="Dewaele and Furnham (1999)" startWordPosition="1727" endWordPosition="1730">sitive face redressment* ·AROUND high low Lower word count Higher word count ·KIND OF, LIKE low high ACKNOWLEDGMENTS: low high ·YEAH low high ·RIGHT, OK, I SEE, WELL low avg EMPHASIZER HEDGES: low low ·REALLY, BASICALLY, ACTUALLY, JUST HAVE, JUST IS, EXCLAMATION ·YOU KNOW TAG QUESTION INSERTION HEDGE VARIATION HEDGE REPETITION Lexical Rich Poor LEXICON FREQUENCY low high choice Few positive emotion words Many positive emotion words see polarity parameters Many negative emotion words Few negative emotion words see polarity parameters Table 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham (1990); Mehl et al. (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSONAGE’s corresponding generation parameters. Asterisks indicate hypotheses, rather than results. For details on aggregation parameters, see Section 4.2. Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3); JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5); JUSTIFY (nuc:1, sat:6) Content: 1. assert(best (Le Marais)) 2. assert(is (Le Marais, cuisine (French))) 3. assert(has (Le Marais, food-quality (good))) 4. assert(has (Le Marais, service (good))) 5. assert(has (Le Marais, decor (dec</context>
<context position="19722" citStr="Dewaele and Furnham, 1999" startWordPosition="3060" endWordPosition="3063">rmations This section describes the insertion of markers in the DSyntS to produce various pragmatic effects. Hedges: Hedges correlate with introversion (Pennebaker and King, 1999) and affect politeness (Brown and Levinson, 1987). Thus there are parameters for inserting a wide range of hedges, both affective and epistemic, such as kind of, sort of, quite, rather, somewhat, like, around, err, I think that, it seems that, it seems to me that, and I mean. Alt-5 in Table 1 shows hedges err and it seems to me that. To model extraverts use of more social language, agreement and backchannel behavior (Dewaele and Furnham, 1999; Pennebaker and King, 1999), we use informal acknowledgments such as yeah, right, ok. Acknowledgments that may affect introversion are I see, expressing self-reference and cognitive load, and the well cue word implying reservation from the speaker (see Alt-9). To model social connection and emotion we added mechanisms for inserting emphasizers such as you know, basically, actually, just have, just is, and exclamations. Alt-3 in Table 1 shows the insertion of you know and actually. Although similar hedges can be grouped together, each hedge has a unique pragmatic effect. For example, you know </context>
<context position="22293" citStr="Dewaele and Furnham, 1999" startWordPosition="3465" endWordPosition="3468"> content constant, by converting adjectives to the negative of their antonyms, e.g. the atmosphere is nice was transformed to not nasty in Alt-9 in Table 1. Subject implicitness: Heylighen and Dewaele (2002) found that extraverts use more implicit language than introverts. To control the level of implicitness, the SUBJECT IMPLICITNESS parameter determines whether predicates describing restaurant attributes are expressed with the restaurant in the subject, or with the attribute itself (e.g., it has goodfood vs. the food is tasty in Alt-9). 4.4 Lexical choice Introverts use a richer vocabulary (Dewaele and Furnham, 1999), so the LEXICON FREQUENCY parameter selects lexical items by their normalized frequency in the British National Corpus. WordNet synonyms are used to obtain a pool of synonyms, as well as adjectives extracted from a corpus of restaurant reviews for all levels of polarity (e.g. the adjective tasty in Alt-9 is a high polarity modifier of the food attribute). Synonyms are manually checked to make sure they are interchangeable. For example, the content item expressed originally as it has decent service is transformed to it features friendly service in Alt-2, and to the servers are nice in Alt-3. 5</context>
</contexts>
<marker>Dewaele, Furnham, 1999</marker>
<rawString>J-M. Dewaele and A. Furnham. 1999. Extraversion: the unloved variable in applied linguistic research. Language Learning, 49(3):509–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Furnham</author>
</authors>
<title>Language and personality.</title>
<date>1990</date>
<booktitle>In Handbook of Language and Social Psychology.</booktitle>
<publisher>Winley.</publisher>
<contexts>
<context position="11199" citStr="Furnham (1990)" startWordPosition="1731" endWordPosition="1732">OUND high low Lower word count Higher word count ·KIND OF, LIKE low high ACKNOWLEDGMENTS: low high ·YEAH low high ·RIGHT, OK, I SEE, WELL low avg EMPHASIZER HEDGES: low low ·REALLY, BASICALLY, ACTUALLY, JUST HAVE, JUST IS, EXCLAMATION ·YOU KNOW TAG QUESTION INSERTION HEDGE VARIATION HEDGE REPETITION Lexical Rich Poor LEXICON FREQUENCY low high choice Few positive emotion words Many positive emotion words see polarity parameters Many negative emotion words Few negative emotion words see polarity parameters Table 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham (1990); Mehl et al. (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSONAGE’s corresponding generation parameters. Asterisks indicate hypotheses, rather than results. For details on aggregation parameters, see Section 4.2. Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3); JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5); JUSTIFY (nuc:1, sat:6) Content: 1. assert(best (Le Marais)) 2. assert(is (Le Marais, cuisine (French))) 3. assert(has (Le Marais, food-quality (good))) 4. assert(has (Le Marais, service (good))) 5. assert(has (Le Marais, decor (decent))) 6. assert</context>
<context position="12905" citStr="Furnham, 1990" startWordPosition="1986" endWordPosition="1987">m with all other content items, which are linked together through an INFER relation. In comparisons, the attributes of multiple restaurants are compared using a CONTRAST relation. An optional claim about the quality of all restaurants can also be expressed as the nucleus of an ELABORATE relation, with the rest of the content plan tree as a satellite. 3 Content Planning Content planning selects and structures the content to be communicated. Table 2 specifies 10 parameters hypothesized to affect this process which are explained below. Content size: Extraverts are more talkative than introverts (Furnham, 1990; Pennebaker and King, 1999), although it is not clear whether they actually produce more content, or are just redundant and wordy. Thus various parameters relate to the amount and type of content produced. The VERBOSITY parameter controls the number of content items selected from the content plan. For example, Alt-5 in Table 1 is terse, while Alt-2 expresses all the items in the content plan. The REPETITION parameter adds an exact repetition: the content item is duplicated and linked to the original content by a RESTATE 498 rhetorical relation. In a similar way, the RESTATEMENT parameter adds</context>
<context position="16942" citStr="Furnham (1990)" startWordPosition="2615" endWordPosition="2616"> in the input content plan. Table 2 specifies four sets of findings and parameters for different aspects of sentence planning discussed below. 4.1 Syntactic template selection PERSONAGE’s input generation dictionary is made of 27 Deep Syntactic Structures (DSyntS): 9 for the recommendation claim, 12 for the comparison claim, and one per attribute. Selecting a DSyntS requires assigning it automatically to a point in a three dimensional space described below. All parameter values are normalized over all the DSyntS, so the DSyntS closest to the target value can be computed. Syntactic complexity: Furnham (1990) suggests that introverts produce more complex constructions: the CLAIM COMPLEXITY parameter controls the depth of the syntactic structure chosen to represent the claim, e.g. the claim X is the best is rated as less complex than X is one of my favorite restaurants. Self-references: Extraverts make more selfreferences than introverts (Pennebaker and King, 1999). The SELF-REFERENCE parameter controls whether the claim is made in the first person, based on the speaker’s own experience, or whether the claim is reported as objective or information obtained elsewhere. The self-reference value is obt</context>
<context position="18572" citStr="Furnham, 1990" startWordPosition="2879" endWordPosition="2880">DSyntS selected to realize the claim. DSyntS are manually annotated for polarity. For example, Alt-4’s claim in Table 1, i.e. Le Marais is the only restaurant that is any good, has a lower polarity than Alt-2. 4.2 Aggregation operations SPaRKy aggregation operations are used (See Stent et al. (2004)), with additional operations for concessions and restatements. See Table 2. The probability of the operations biases the production of complex clauses, periods and formal cue words for introverts, to express their preference for complex syn499 tactic constructions, long pauses and rich vocabulary (Furnham, 1990). Thus, the introvert parameters favor operations such as RELATIVE CLAUSE for the INFER relation, PERIOD HOWEVER CUE WORD for CONTRAST, and ALTHOUGH ADVERBIAL CLAUSE for CONCESS, that we hypothesize to result in more formal language. Extravert aggregation produces longer sentences with simpler constructions and informal cue words. Thus extravert utterances tend to use operations such as a CONJUNCTION to realize the INFER and RESTATE relations, and the EVEN IF ADVERBIAL CLAUSE for CONCESS relations. 4.3 Pragmatic transformations This section describes the insertion of markers in the DSyntS to p</context>
</contexts>
<marker>Furnham, 1990</marker>
<rawString>A. Furnham. 1990. Language and personality. In Handbook of Language and Social Psychology. Winley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S D Gosling</author>
<author>P J Rentfrow</author>
<author>W B Swann Jr</author>
</authors>
<title>A very brief measure of the big five personality domains.</title>
<date>2003</date>
<journal>Journal of Research in Personality,</journal>
<pages>37--504</pages>
<contexts>
<context position="23660" citStr="Gosling et al., 2003" startWordPosition="3684" endWordPosition="3687"> can be recognized as extravert or introvert. To test this hypothesis, three expert judges evaluated a set of generated utterances as if they had been uttered by a friend responding in a dialogue to a request to recommend restaurants. These utterances had been generated to systematically manipulate extraversion/introversion parameters. The judges rated each utterance for perceived extraversion, by answering the two questions measur500 ing that trait from the Ten-Item Personality Inventory, as this instrument was shown to be psychometrically superior to a ‘single item per trait’ questionnaire (Gosling et al., 2003). The answers are averaged to produce an extraversion rating ranging from 1 (highly introvert) to 7 (highly extravert). Because it was unclear whether the generation parameters in Table 2 would produce natural sounding utterances, the judges also evaluated the naturalness of each utterance on the same scale. The judges rated 240 utterances, grouped into 20 sets of 12 utterances generated from the same content plan. They rated one randomly ordered set at a time, but viewed all 12 utterances in that set before rating them. The utterances were generated to meet two experimental goals. First, to t</context>
</contexts>
<marker>Gosling, Rentfrow, Jr, 2003</marker>
<rawString>S. D. Gosling, P. J. Rentfrow, and W. B. Swann Jr. 2003. A very brief measure of the big five personality domains. Journal of Research in Personality, 37:504–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Heylighen</author>
<author>J-M Dewaele</author>
</authors>
<title>Variation in the contextuality of language: an empirical measure. Context in Context,</title>
<date>2002</date>
<journal>Foundations of Science,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="21874" citStr="Heylighen and Dewaele (2002)" startWordPosition="3399" endWordPosition="3402">A TAG QUESTION INSERTION parameter leads to negating the auxiliary of the verb and pronominalizing the subject, e.g. X has great food results in the insertion of doesn’t it?, as in Alt-8. Negations: Introverts use significantly more negations (Pennebaker and King, 1999). Although the content parameters select more negative polarity content items for introvert utterances, we also manipulate negations, while keeping the content constant, by converting adjectives to the negative of their antonyms, e.g. the atmosphere is nice was transformed to not nasty in Alt-9 in Table 1. Subject implicitness: Heylighen and Dewaele (2002) found that extraverts use more implicit language than introverts. To control the level of implicitness, the SUBJECT IMPLICITNESS parameter determines whether predicates describing restaurant attributes are expressed with the restaurant in the subject, or with the attribute itself (e.g., it has goodfood vs. the food is tasty in Alt-9). 4.4 Lexical choice Introverts use a richer vocabulary (Dewaele and Furnham, 1999), so the LEXICON FREQUENCY parameter selects lexical items by their normalized frequency in the British National Corpus. WordNet synonyms are used to obtain a pool of synonyms, as w</context>
</contexts>
<marker>Heylighen, Dewaele, 2002</marker>
<rawString>F. Heylighen and J-M. Dewaele. 2002. Variation in the contextuality of language: an empirical measure. Context in Context, Foundations of Science, 7(3):293–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
</authors>
<title>Generating Natural Language under Pragmatic Constraints. Lawrence Erlbaum Associates.</title>
<date>1988</date>
<marker>Hovy, 1988</marker>
<rawString>E. Hovy. 1988. Generating Natural Language under Pragmatic Constraints. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Isard</author>
<author>C Brockmann</author>
<author>J Oberlander</author>
</authors>
<title>Individuality and alignment in generated dialogues.</title>
<date>2006</date>
<booktitle>In Proc. ofINLG.</booktitle>
<contexts>
<context position="1876" citStr="Isard et al., 2006" startWordPosition="258" endWordPosition="261">” model of personality traits has become a standard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little evaluation showing that automatic generators can produce language with recognizable personality variation. Alt Realization Extra 5 Err... it seems to me that Le Marais isn’t as bad 1.83 as the others. 4 Right, I mean, Le Marais is the only restaurant 2.83 that is any good. 8 </context>
<context position="6680" citStr="Isard et al., 2006" startWordPosition="1051" endWordPosition="1054">he parameters generate utterances that vary significantly on the extraversion dimension, according to human judgments; and (2) we can train a statistical model that matches human performance in assigning extraversion ratings to generation outputs produced with random parameter settings. Section 7 sums up and discusses future work. 2 Psycholinguistic Findings and PERSONAGE Parameters We hypothesize that personality can be made manifest in evaluative speech acts in any dialogue domain, i.e. utterances responding to requests to RECOMMEND or COMPARE domain entities, such as restaurants or movies (Isard et al., 2006; Stent et al., 2004). Thus, we start with the SPaRKy generator1, which produces evaluative recommendations and comparisons in the restaurant domain, for a database of restaurants in New York City. There are eight attributes for each restaurant: the name and address, scalar attributes for price, food quality, atmosphere, and service and categorical attributes for neighborhood and type of cuisine. SPaRKy is based on the standard NLG architecture (Reiter and Dale, 2000), and consists of the following modules: 1. Content Planning: refine communicative goals, select and structure content; 2. Sente</context>
</contexts>
<marker>Isard, Brockmann, Oberlander, 2006</marker>
<rawString>A. Isard, C. Brockmann, and J. Oberlander. 2006. Individuality and alignment in generated dialogues. In Proc. ofINLG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Lavoie</author>
<author>O Rambow</author>
</authors>
<title>A fast and portable realizer for text generation systems.</title>
<date>1997</date>
<booktitle>In Proc. ofANLP.</booktitle>
<contexts>
<context position="7870" citStr="Lavoie and Rambow, 1997" startWordPosition="1231" endWordPosition="1234">ct and structure content; 2. Sentence planning; choose linguistic resources (lexicon, syntax) to achieve goals; 3. Realization: use grammar (syntax, morphology) to generate surface utterances. Given the NLG architecture, speech-act types, and domain, the first step then is to summarise psychological findings on extraversion and map them to this architecture. The column NLG modules of Table 2 gives the proposed mapping. The first row specifies findings for the content planning module and the other rows are aspects of sentence planning. Realization is achieved with the RealPro surface realizer (Lavoie and Rambow, 1997). An examination of the introvert and extravert findings in Table 2 highlights the challenges above, i.e. exploiting these findings in a systematic way within a parameterizable NLG system. The column Parameter in Table 2 proposes parameters (explained in Sections 3 and 4) that are manipulated within each module to realize the findings in the other columns. Each parameter varies continuously from 0 to 1, where end points are meant to produce extreme but plausible output. Given the challenges above, it is important to note that these parameters represent hypotheses about how a finding can be map</context>
</contexts>
<marker>Lavoie, Rambow, 1997</marker>
<rawString>B. Lavoie and O. Rambow. 1997. A fast and portable realizer for text generation systems. In Proc. ofANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Loyall</author>
<author>J Bates</author>
</authors>
<title>Personality-rich believable agents that use language.</title>
<date>1997</date>
<booktitle>In Proc. of the First International Conference on Autonomous Agents,</booktitle>
<pages>106--113</pages>
<contexts>
<context position="1900" citStr="Loyall and Bates, 1997" startWordPosition="262" endWordPosition="265">ty traits has become a standard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little evaluation showing that automatic generators can produce language with recognizable personality variation. Alt Realization Extra 5 Err... it seems to me that Le Marais isn’t as bad 1.83 as the others. 4 Right, I mean, Le Marais is the only restaurant 2.83 that is any good. 8 Ok, I mean, Le Marais is</context>
</contexts>
<marker>Loyall, Bates, 1997</marker>
<rawString>A. Loyall and J. Bates. 1997. Personality-rich believable agents that use language. In Proc. of the First International Conference on Autonomous Agents, p. 106–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Mairesse</author>
<author>M Walker</author>
</authors>
<title>Learning to personalize spoken generation for dialogue systems.</title>
<date>2005</date>
<booktitle>In Proc. of the Interspeech - Eurospeech,</booktitle>
<pages>1881--1884</pages>
<marker>Mairesse, Walker, 2005</marker>
<rawString>F. Mairesse and M. Walker. 2005. Learning to personalize spoken generation for dialogue systems. In Proc. of the Interspeech - Eurospeech, p. 1881–1884.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mehl</author>
<author>S Gosling</author>
<author>J Pennebaker</author>
</authors>
<title>Personality in its natural habitat: Manifestations and implicit folk theories of personality in daily life.</title>
<date>2006</date>
<journal>Journal ofPersonality and Social Psychology,</journal>
<pages>90--862</pages>
<contexts>
<context position="1558" citStr="Mehl et al., 2006" startWordPosition="212" endWordPosition="215">uggested by the psychology literature; and (2) overgeneration and selection using statistical models trained from judge’s ratings. Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges. 1 Introduction Over the last fifty years, the “Big Five” model of personality traits has become a standard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguisti</context>
<context position="4590" citStr="Mehl et al., 2006" startWordPosition="723" endWordPosition="726">We hypothesize that such language can Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 496–503, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics be generated by varying parameters suggested by psycholinguistic research. So, we must first map the psychological findings to parameters of a natural language generator (NLG). However, this presents several challenges: (1) The findings result from studies of genres of language, such as stream-ofconsciousness essays (Pennebaker and King, 1999), and informal conversations (Mehl et al., 2006), and thus may not apply to fixed content domains used in NLG; (2) Most findings are based on self-reports of personality, but we want to affect observer’s perceptions; (3) The findings consist of weak but significant correlations, so that individual parameters may not have a strong enough effect to produce recognizable variation within a single utterance; (4) There are many possible mappings of the findings to generation parameters; and (5) It is unclear whether only specific speech-act types manifest personality or whether all utterances do. Thus this paper makes several contributions. First</context>
<context position="11219" citStr="Mehl et al. (2006)" startWordPosition="1733" endWordPosition="1736">wer word count Higher word count ·KIND OF, LIKE low high ACKNOWLEDGMENTS: low high ·YEAH low high ·RIGHT, OK, I SEE, WELL low avg EMPHASIZER HEDGES: low low ·REALLY, BASICALLY, ACTUALLY, JUST HAVE, JUST IS, EXCLAMATION ·YOU KNOW TAG QUESTION INSERTION HEDGE VARIATION HEDGE REPETITION Lexical Rich Poor LEXICON FREQUENCY low high choice Few positive emotion words Many positive emotion words see polarity parameters Many negative emotion words Few negative emotion words see polarity parameters Table 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham (1990); Mehl et al. (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSONAGE’s corresponding generation parameters. Asterisks indicate hypotheses, rather than results. For details on aggregation parameters, see Section 4.2. Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3); JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5); JUSTIFY (nuc:1, sat:6) Content: 1. assert(best (Le Marais)) 2. assert(is (Le Marais, cuisine (French))) 3. assert(has (Le Marais, food-quality (good))) 4. assert(has (Le Marais, service (good))) 5. assert(has (Le Marais, decor (decent))) 6. assert(is (Le Marais, pric</context>
<context position="25584" citStr="Mehl et al. (2006)" startWordPosition="4001" endWordPosition="4004">nt for extraversion between the judges over all 240 utterances (average Pearson’s correlation of 0.57) shows that the magnitude of the differences of perception between judges is almost constant (Q = .037). A low agreement can yield a high correlation (e.g. if all values differ by a constant factor), so we also compute the intraclass correlation coefficient r based on a two-way random effect model. We obtain a r of 0.79, which is significant at the p &lt; .001 level (reliability of average measures, identical to Cronbach’s alpha). This is comparable to the agreement ofjudgments of personality in Mehl et al. (2006) (mean r = 0.84). 6 Experimental Results 6.1 Hypothesized parameter settings Table 1 provides examples of PERSONAGE’s output and extraversion ratings. To assess whether PERSONAGE generates language that can be recognized as introvert and extravert, we did a independent sample t-test between the average ratings of the 40 introvert and 40 extravert utterances (parameters with 15% standard deviation as in Table 2). Table 3 Rating Introvert Extravert Random Extraversion 2.96 5.98 5.02 Naturalness 4.93 5.78 4.51 Table 3: Average extraversion and naturalness ratings for the utterances generated with</context>
</contexts>
<marker>Mehl, Gosling, Pennebaker, 2006</marker>
<rawString>M. Mehl, S. Gosling, and J. Pennebaker. 2006. Personality in its natural habitat: Manifestations and implicit folk theories of personality in daily life. Journal ofPersonality and Social Psychology, 90:862–877.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W T Norman</author>
</authors>
<title>Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating.</title>
<date>1963</date>
<journal>Journal of Abnormal and Social Psychology,</journal>
<pages>66--574</pages>
<contexts>
<context position="1572" citStr="Norman, 1963" startWordPosition="216" endWordPosition="217">chology literature; and (2) overgeneration and selection using statistical models trained from judge’s ratings. Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges. 1 Introduction Over the last fifty years, the “Big Five” model of personality traits has become a standard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; an</context>
</contexts>
<marker>Norman, 1963</marker>
<rawString>W. T. Norman. 1963. Toward an adequate taxonomy of personality attributes: Replicated factor structure in peer nomination personality rating. Journal of Abnormal and Social Psychology, 66:574–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Oberlander</author>
<author>A Gill</author>
</authors>
<title>Language with character: A stratified corpus comparison of individual differences in email communication.</title>
<date>2006</date>
<booktitle>Discourse Processes,</booktitle>
<pages>42--239</pages>
<contexts>
<context position="1599" citStr="Oberlander and Gill, 2006" startWordPosition="218" endWordPosition="222">ture; and (2) overgeneration and selection using statistical models trained from judge’s ratings. Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges. 1 Introduction Over the last fifty years, the “Big Five” model of personality traits has become a standard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little</context>
<context position="11247" citStr="Oberlander and Gill (2006)" startWordPosition="1737" endWordPosition="1740">r word count ·KIND OF, LIKE low high ACKNOWLEDGMENTS: low high ·YEAH low high ·RIGHT, OK, I SEE, WELL low avg EMPHASIZER HEDGES: low low ·REALLY, BASICALLY, ACTUALLY, JUST HAVE, JUST IS, EXCLAMATION ·YOU KNOW TAG QUESTION INSERTION HEDGE VARIATION HEDGE REPETITION Lexical Rich Poor LEXICON FREQUENCY low high choice Few positive emotion words Many positive emotion words see polarity parameters Many negative emotion words Few negative emotion words see polarity parameters Table 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham (1990); Mehl et al. (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSONAGE’s corresponding generation parameters. Asterisks indicate hypotheses, rather than results. For details on aggregation parameters, see Section 4.2. Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3); JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5); JUSTIFY (nuc:1, sat:6) Content: 1. assert(best (Le Marais)) 2. assert(is (Le Marais, cuisine (French))) 3. assert(has (Le Marais, food-quality (good))) 4. assert(has (Le Marais, service (good))) 5. assert(has (Le Marais, decor (decent))) 6. assert(is (Le Marais, price (44 dollars))) Figure 1: A</context>
</contexts>
<marker>Oberlander, Gill, 2006</marker>
<rawString>J. Oberlander and A. Gill. 2006. Language with character: A stratified corpus comparison of individual differences in email communication. Discourse Processes, 42:239–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Paiva</author>
<author>R Evans</author>
</authors>
<title>Empirically-based control of natural language generation.</title>
<date>2005</date>
<booktitle>In Proc. ofACL.</booktitle>
<marker>Paiva, Evans, 2005</marker>
<rawString>D. Paiva and R. Evans. 2005. Empirically-based control of natural language generation. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Pennebaker</author>
<author>L A King</author>
</authors>
<title>Linguistic styles: Language use as an individual difference.</title>
<date>1999</date>
<journal>Journal ofPersonality and Social Psychology,</journal>
<pages>77--1296</pages>
<contexts>
<context position="1627" citStr="Pennebaker and King, 1999" startWordPosition="223" endWordPosition="226">n and selection using statistical models trained from judge’s ratings. Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges. 1 Introduction Over the last fifty years, the “Big Five” model of personality traits has become a standard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little evaluation showing that aut</context>
<context position="4542" citStr="Pennebaker and King, 1999" startWordPosition="716" endWordPosition="719">erator whose outputs vary along personality dimensions. We hypothesize that such language can Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 496–503, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics be generated by varying parameters suggested by psycholinguistic research. So, we must first map the psychological findings to parameters of a natural language generator (NLG). However, this presents several challenges: (1) The findings result from studies of genres of language, such as stream-ofconsciousness essays (Pennebaker and King, 1999), and informal conversations (Mehl et al., 2006), and thus may not apply to fixed content domains used in NLG; (2) Most findings are based on self-reports of personality, but we want to affect observer’s perceptions; (3) The findings consist of weak but significant correlations, so that individual parameters may not have a strong enough effect to produce recognizable variation within a single utterance; (4) There are many possible mappings of the findings to generation parameters; and (5) It is unclear whether only specific speech-act types manifest personality or whether all utterances do. Th</context>
<context position="11275" citStr="Pennebaker and King (1999)" startWordPosition="1741" endWordPosition="1744">low high ACKNOWLEDGMENTS: low high ·YEAH low high ·RIGHT, OK, I SEE, WELL low avg EMPHASIZER HEDGES: low low ·REALLY, BASICALLY, ACTUALLY, JUST HAVE, JUST IS, EXCLAMATION ·YOU KNOW TAG QUESTION INSERTION HEDGE VARIATION HEDGE REPETITION Lexical Rich Poor LEXICON FREQUENCY low high choice Few positive emotion words Many positive emotion words see polarity parameters Many negative emotion words Few negative emotion words see polarity parameters Table 2: Summary of language cues for extraversion, based on Dewaele and Furnham (1999); Furnham (1990); Mehl et al. (2006); Oberlander and Gill (2006); Pennebaker and King (1999), as well as PERSONAGE’s corresponding generation parameters. Asterisks indicate hypotheses, rather than results. For details on aggregation parameters, see Section 4.2. Relations: JUSTIFY (nuc:1, sat:2); JUSTIFY (nuc:1, sat:3); JUSTIFY (nuc:1, sat:4); JUSTIFY (nuc:1, sat:5); JUSTIFY (nuc:1, sat:6) Content: 1. assert(best (Le Marais)) 2. assert(is (Le Marais, cuisine (French))) 3. assert(has (Le Marais, food-quality (good))) 4. assert(has (Le Marais, service (good))) 5. assert(has (Le Marais, decor (decent))) 6. assert(is (Le Marais, price (44 dollars))) Figure 1: A content plan for a recommen</context>
<context position="12933" citStr="Pennebaker and King, 1999" startWordPosition="1988" endWordPosition="1991">r content items, which are linked together through an INFER relation. In comparisons, the attributes of multiple restaurants are compared using a CONTRAST relation. An optional claim about the quality of all restaurants can also be expressed as the nucleus of an ELABORATE relation, with the rest of the content plan tree as a satellite. 3 Content Planning Content planning selects and structures the content to be communicated. Table 2 specifies 10 parameters hypothesized to affect this process which are explained below. Content size: Extraverts are more talkative than introverts (Furnham, 1990; Pennebaker and King, 1999), although it is not clear whether they actually produce more content, or are just redundant and wordy. Thus various parameters relate to the amount and type of content produced. The VERBOSITY parameter controls the number of content items selected from the content plan. For example, Alt-5 in Table 1 is terse, while Alt-2 expresses all the items in the content plan. The REPETITION parameter adds an exact repetition: the content item is duplicated and linked to the original content by a RESTATE 498 rhetorical relation. In a similar way, the RESTATEMENT parameter adds paraphrases of content item</context>
<context position="15484" citStr="Pennebaker and King, 1999" startWordPosition="2388" endWordPosition="2391">grounded and the other backgrounded. If two opposed content items are selected for a concession, a CONCESS rhetorical relation is inserted between them. While the CONCESSIONS parameter captures the tendency to put information into perspective, the CONCESSION POLARITY parameter controls whether the positive or the negative content is concessed, i.e. marked as the satellite of the CONCESS relation. The last sentence of Alt-3 in Table 1 illustrates a positive concession, in which the good food quality is put before the high price. Content ordering: Although extraverts use more positive language (Pennebaker and King, 1999; Thorne, 1987), it is unclear how they position the positive content within their utterances. Additionally, the position of the claim affects the persuasiveness of an argument (Carenini and Moore, 2000): starting with the claim facilitates the hearer’s understanding, while finishing with the claim is more effective if the hearer disagrees. The POSITIVE CONTENT FIRST parameter therefore controls whether positive content items – including the claim – appear first or last, and the order in which the content items are aggregated. However, some operations can still impose a specific ordering (e.g.</context>
<context position="17304" citStr="Pennebaker and King, 1999" startWordPosition="2668" endWordPosition="2671">Selecting a DSyntS requires assigning it automatically to a point in a three dimensional space described below. All parameter values are normalized over all the DSyntS, so the DSyntS closest to the target value can be computed. Syntactic complexity: Furnham (1990) suggests that introverts produce more complex constructions: the CLAIM COMPLEXITY parameter controls the depth of the syntactic structure chosen to represent the claim, e.g. the claim X is the best is rated as less complex than X is one of my favorite restaurants. Self-references: Extraverts make more selfreferences than introverts (Pennebaker and King, 1999). The SELF-REFERENCE parameter controls whether the claim is made in the first person, based on the speaker’s own experience, or whether the claim is reported as objective or information obtained elsewhere. The self-reference value is obtained from the syntactic structure by counting the number of first person pronouns. For example, the claim of Alt-2 in Table 1, i.e. I am sure you would like Le Marais, will be rated higher than Le Marais isn’t as bad as the others in Alt-5. Polarity: While polarity can be expressed by content selection and structure, it can also be directly associated with th</context>
<context position="19276" citStr="Pennebaker and King, 1999" startWordPosition="2980" endWordPosition="2984">the INFER relation, PERIOD HOWEVER CUE WORD for CONTRAST, and ALTHOUGH ADVERBIAL CLAUSE for CONCESS, that we hypothesize to result in more formal language. Extravert aggregation produces longer sentences with simpler constructions and informal cue words. Thus extravert utterances tend to use operations such as a CONJUNCTION to realize the INFER and RESTATE relations, and the EVEN IF ADVERBIAL CLAUSE for CONCESS relations. 4.3 Pragmatic transformations This section describes the insertion of markers in the DSyntS to produce various pragmatic effects. Hedges: Hedges correlate with introversion (Pennebaker and King, 1999) and affect politeness (Brown and Levinson, 1987). Thus there are parameters for inserting a wide range of hedges, both affective and epistemic, such as kind of, sort of, quite, rather, somewhat, like, around, err, I think that, it seems that, it seems to me that, and I mean. Alt-5 in Table 1 shows hedges err and it seems to me that. To model extraverts use of more social language, agreement and backchannel behavior (Dewaele and Furnham, 1999; Pennebaker and King, 1999), we use informal acknowledgments such as yeah, right, ok. Acknowledgments that may affect introversion are I see, expressing </context>
<context position="21516" citStr="Pennebaker and King, 1999" startWordPosition="3345" endWordPosition="3348">it is randomly inserted at one of the insertion points respecting the constraints, until the specified frequency is reached. For example, a constraint on the hedge kind of is that it modifies adjectives. Tag questions: Tag questions are also politeness markers (Brown and Levinson, 1987). They redress the hearer’s positive face by claiming common ground. A TAG QUESTION INSERTION parameter leads to negating the auxiliary of the verb and pronominalizing the subject, e.g. X has great food results in the insertion of doesn’t it?, as in Alt-8. Negations: Introverts use significantly more negations (Pennebaker and King, 1999). Although the content parameters select more negative polarity content items for introvert utterances, we also manipulate negations, while keeping the content constant, by converting adjectives to the negative of their antonyms, e.g. the atmosphere is nice was transformed to not nasty in Alt-9 in Table 1. Subject implicitness: Heylighen and Dewaele (2002) found that extraverts use more implicit language than introverts. To control the level of implicitness, the SUBJECT IMPLICITNESS parameter determines whether predicates describing restaurant attributes are expressed with the restaurant in th</context>
</contexts>
<marker>Pennebaker, King, 1999</marker>
<rawString>J. W. Pennebaker and L. A. King. 1999. Linguistic styles: Language use as an individual difference. Journal ofPersonality and Social Psychology, 77:1296–1312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Piwek</author>
</authors>
<title>A flexible pragmatics-driven language generator for animated agents.</title>
<date>2003</date>
<booktitle>In Proc. ofEACL.</booktitle>
<contexts>
<context position="1913" citStr="Piwek, 2003" startWordPosition="266" endWordPosition="267">tandard in psychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little evaluation showing that automatic generators can produce language with recognizable personality variation. Alt Realization Extra 5 Err... it seems to me that Le Marais isn’t as bad 1.83 as the others. 4 Right, I mean, Le Marais is the only restaurant 2.83 that is any good. 8 Ok, I mean, Le Marais is a quite fren</context>
</contexts>
<marker>Piwek, 2003</marker>
<rawString>P. Piwek. 2003. A flexible pragmatics-driven language generator for animated agents. In Proc. ofEACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Reeves</author>
<author>C Nass</author>
</authors>
<title>The Media Equation.</title>
<date>1996</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="2059" citStr="Reeves and Nass, 1996" startWordPosition="287" endWordPosition="290">matically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little evaluation showing that automatic generators can produce language with recognizable personality variation. Alt Realization Extra 5 Err... it seems to me that Le Marais isn’t as bad 1.83 as the others. 4 Right, I mean, Le Marais is the only restaurant 2.83 that is any good. 8 Ok, I mean, Le Marais is a quite french, kosher 5.17 and steak house place, you know and the atmosphere isn’t nasty, it has nice atmosphere. It has friendly service. It seems to me th</context>
</contexts>
<marker>Reeves, Nass, 1996</marker>
<rawString>B. Reeves and C. Nass. 1996. The Media Equation. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Reiter</author>
<author>R Dale</author>
</authors>
<title>Building Natural Language Generation Systems.</title>
<date>2000</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7152" citStr="Reiter and Dale, 2000" startWordPosition="1124" endWordPosition="1127">any dialogue domain, i.e. utterances responding to requests to RECOMMEND or COMPARE domain entities, such as restaurants or movies (Isard et al., 2006; Stent et al., 2004). Thus, we start with the SPaRKy generator1, which produces evaluative recommendations and comparisons in the restaurant domain, for a database of restaurants in New York City. There are eight attributes for each restaurant: the name and address, scalar attributes for price, food quality, atmosphere, and service and categorical attributes for neighborhood and type of cuisine. SPaRKy is based on the standard NLG architecture (Reiter and Dale, 2000), and consists of the following modules: 1. Content Planning: refine communicative goals, select and structure content; 2. Sentence planning; choose linguistic resources (lexicon, syntax) to achieve goals; 3. Realization: use grammar (syntax, morphology) to generate surface utterances. Given the NLG architecture, speech-act types, and domain, the first step then is to summarise psychological findings on extraversion and map them to this architecture. The column NLG modules of Table 2 gives the proposed mapping. The first row specifies findings for the content planning module and the other rows</context>
</contexts>
<marker>Reiter, Dale, 2000</marker>
<rawString>E. Reiter and R. Dale. 2000. Building Natural Language Generation Systems. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
<author>R Prasad</author>
<author>M Walker</author>
</authors>
<title>Trainable sentence planning for complex information presentation in spoken dialog systems.</title>
<date>2004</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="6701" citStr="Stent et al., 2004" startWordPosition="1055" endWordPosition="1058">te utterances that vary significantly on the extraversion dimension, according to human judgments; and (2) we can train a statistical model that matches human performance in assigning extraversion ratings to generation outputs produced with random parameter settings. Section 7 sums up and discusses future work. 2 Psycholinguistic Findings and PERSONAGE Parameters We hypothesize that personality can be made manifest in evaluative speech acts in any dialogue domain, i.e. utterances responding to requests to RECOMMEND or COMPARE domain entities, such as restaurants or movies (Isard et al., 2006; Stent et al., 2004). Thus, we start with the SPaRKy generator1, which produces evaluative recommendations and comparisons in the restaurant domain, for a database of restaurants in New York City. There are eight attributes for each restaurant: the name and address, scalar attributes for price, food quality, atmosphere, and service and categorical attributes for neighborhood and type of cuisine. SPaRKy is based on the standard NLG architecture (Reiter and Dale, 2000), and consists of the following modules: 1. Content Planning: refine communicative goals, select and structure content; 2. Sentence planning; choose </context>
<context position="18258" citStr="Stent et al. (2004)" startWordPosition="2828" endWordPosition="2831">the claim of Alt-2 in Table 1, i.e. I am sure you would like Le Marais, will be rated higher than Le Marais isn’t as bad as the others in Alt-5. Polarity: While polarity can be expressed by content selection and structure, it can also be directly associated with the DSyntS. The CLAIM POLARITY parameter determines the DSyntS selected to realize the claim. DSyntS are manually annotated for polarity. For example, Alt-4’s claim in Table 1, i.e. Le Marais is the only restaurant that is any good, has a lower polarity than Alt-2. 4.2 Aggregation operations SPaRKy aggregation operations are used (See Stent et al. (2004)), with additional operations for concessions and restatements. See Table 2. The probability of the operations biases the production of complex clauses, periods and formal cue words for introverts, to express their preference for complex syn499 tactic constructions, long pauses and rich vocabulary (Furnham, 1990). Thus, the introvert parameters favor operations such as RELATIVE CLAUSE for the INFER relation, PERIOD HOWEVER CUE WORD for CONTRAST, and ALTHOUGH ADVERBIAL CLAUSE for CONCESS, that we hypothesize to result in more formal language. Extravert aggregation produces longer sentences with</context>
</contexts>
<marker>Stent, Prasad, Walker, 2004</marker>
<rawString>A. Stent, R. Prasad, and M. Walker. 2004. Trainable sentence planning for complex information presentation in spoken dialog systems. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Thorne</author>
</authors>
<title>The press of personality: A study of conversations between introverts and extraverts.</title>
<date>1987</date>
<booktitle>Journal ofPersonality and Social Psychology,</booktitle>
<pages>53--718</pages>
<contexts>
<context position="13992" citStr="Thorne, 1987" startWordPosition="2160" endWordPosition="2161">ated and linked to the original content by a RESTATE 498 rhetorical relation. In a similar way, the RESTATEMENT parameter adds paraphrases of content items to the plan, that are obtained from the initial handcrafted generation dictionary (see Section 4.1) and by automatically substituting content words with the most frequent WordNet synonym (see Section 4.4). Alt-9 in Table 1 contains restatements for the food quality and the atmosphere attributes. Polarity: Extraverts tend to be more positive; introverts are characterized as engaging in more ‘problem talk’ and expressions of dissatisfaction (Thorne, 1987). To control for polarity, content items are defined as positive or negative based on the scalar value of the corresponding attribute. The type of cuisine and neighborhood attributes have neutral polarity. There are multiple parameters associated with polarity. The CONTENT POLARITY parameter controls whether the content is mostly negative (e.g. X has mediocre food), neutral (e.g. X is a Thai restaurant), or positive. From the filtered set of content items, the POLARISATION parameter determines whether the final content includes items with extreme scalar values (e.g. X has fantastic staff). In </context>
<context position="15499" citStr="Thorne, 1987" startWordPosition="2392" endWordPosition="2393">grounded. If two opposed content items are selected for a concession, a CONCESS rhetorical relation is inserted between them. While the CONCESSIONS parameter captures the tendency to put information into perspective, the CONCESSION POLARITY parameter controls whether the positive or the negative content is concessed, i.e. marked as the satellite of the CONCESS relation. The last sentence of Alt-3 in Table 1 illustrates a positive concession, in which the good food quality is put before the high price. Content ordering: Although extraverts use more positive language (Pennebaker and King, 1999; Thorne, 1987), it is unclear how they position the positive content within their utterances. Additionally, the position of the claim affects the persuasiveness of an argument (Carenini and Moore, 2000): starting with the claim facilitates the hearer’s understanding, while finishing with the claim is more effective if the hearer disagrees. The POSITIVE CONTENT FIRST parameter therefore controls whether positive content items – including the claim – appear first or last, and the order in which the content items are aggregated. However, some operations can still impose a specific ordering (e.g. BECAUSE cue wo</context>
</contexts>
<marker>Thorne, 1987</marker>
<rawString>A. Thorne. 1987. The press of personality: A study of conversations between introverts and extraverts. Journal ofPersonality and Social Psychology, 53:718–726.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Walker</author>
<author>J Cahn</author>
<author>S Whittaker</author>
</authors>
<title>Improvising linguistic style: Social and affective bases for agent personality.</title>
<date>1997</date>
<booktitle>In Proc. of the Conference on Autonomous Agents.</booktitle>
<contexts>
<context position="1935" citStr="Walker et al., 1997" startWordPosition="268" endWordPosition="271">ychology (extraversion, neuroticism, agreeableness, conscientiousness, and openness to experience), and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits (Mehl et al., 2006; Norman, 1963; Oberlander and Gill, 2006; Pennebaker and King, 1999). A distinct line of research has explored methods for automatically generating language that varies along personality dimensions, targeting applications such as computer gaming and educational virtual worlds (Andr´e et al., 2000; Isard et al., 2006; Loyall and Bates, 1997; Piwek, 2003; Walker et al., 1997) inter 496 alia. Other work suggests a clear utility for generating language manifesting personality (Reeves and Nass, 1996). However, to date, (1) research in generation has not systematically exploited the psycholinguistic findings; and (2) there has been little evaluation showing that automatic generators can produce language with recognizable personality variation. Alt Realization Extra 5 Err... it seems to me that Le Marais isn’t as bad 1.83 as the others. 4 Right, I mean, Le Marais is the only restaurant 2.83 that is any good. 8 Ok, I mean, Le Marais is a quite french, kosher 5.17 and st</context>
</contexts>
<marker>Walker, Cahn, Whittaker, 1997</marker>
<rawString>M. Walker, J. Cahn, and S. Whittaker. 1997. Improvising linguistic style: Social and affective bases for agent personality. In Proc. of the Conference on Autonomous Agents.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I H Witten</author>
<author>E Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools and techniques.</title>
<date>2005</date>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="27606" citStr="Witten and Frank, 2005" startWordPosition="4325" endWordPosition="4329">may combine linguistic variables associated with both introverts and extraverts, are less natural than the introvert (p = .059) and extravert sets (p &lt; .001). 6.2 Statistical models evaluation We also investigate a second approach: overgeneration with random parameter settings, followed by ranking via a statistical model trained on the judges’ feedback. This approach supports generating utterances for any input extraversion value, as well as determining which parameters affect the judges’ perception. We model perceived personality ratings (1... 7) with regression models from the Weka toolbox (Witten and Frank, 2005). We used the full dataset of 160 averaged ratings for the random parameter utterances. Each utterance was associated with a feature vector with the generation decisions for each parameter in Section 2. To reduce data sparsity, we select features that correlate significantly with the ratings (p &lt; .10) with a coefficient higher than 0.1. Regression models are evaluated using the mean absolute error and the correlation between the predicted score and the actual average rating. Table 4 shows the mean absolute error on a scale from 1 to 7 over ten 10-fold cross-validations for the 4 best regressio</context>
</contexts>
<marker>Witten, Frank, 2005</marker>
<rawString>I. H. Witten and E. Frank. 2005. Data Mining: Practical machine learning tools and techniques. Morgan Kaufmann.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>