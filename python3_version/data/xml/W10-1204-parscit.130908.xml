<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.984925">
A Graph-Based Semi-Supervised Learning for Question Semantic Labeling
</title>
<author confidence="0.978657">
Asli Celikyilmaz Dilek Hakkani-Tur
</author>
<affiliation confidence="0.9981735">
Computer Science Division International Computer Science Institute
University of California, Berkeley Berkeley, CA
</affiliation>
<email confidence="0.996412">
asli@berkeley.edu dilek@icsi.berkeley.edu
</email>
<sectionHeader confidence="0.98479" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999305428571429">
We investigate a graph-based semi-supervised
learning approach for labeling semantic com-
ponents of questions such as topic, focus,
event, etc., for question understanding task.
We focus on graph construction to handle
learning with dense/sparse graphs and present
Relaxed Linear Neighborhoods method, in
which each node is linearly constructed from
varying sizes of its neighbors based on the
density/sparsity of its surrounding. With the
new graph representation, we show perfor-
mance improvements on syntactic and real
datasets, primarily due to the use of unlabeled
data and relaxed graph construction.
</bodyText>
<sectionHeader confidence="0.992514" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.98856305">
One of the important steps in Question Answering
(QA) is question understanding to identify semantic
components of questions. In this paper, we inves-
tigate question understanding based on a machine
learning approach to discover semantic components
(Table 1).
An important issue in information extraction from
text is that one often deals with insufficient la-
beled data and large number of unlabeled data,
which have led to improvements in semi-supervised
learning (SSL) methods, e.g., (Belkin and Niyogi.,
2002b), (Zhou et al., 2004). Recently, graph based
SSL methods have gained interest (Alexandrescu
and Kirchhoff, 2007), (Goldberg and Zhu, 2009).
These methods create graphs whose vertices corre-
spond to labeled and unlabeled data, while the edge
weights encode the similarity between each pair of
data points. Classification is performed using these
graphs by scoring unlabeled points in such a way
27
</bodyText>
<note confidence="0.798314166666667">
Semantic Components &amp; Named-Entitiy Types
topic: ’Jar’ (Begin-Topic); ’Jar’ (In-Topic) ;
’Binks’ (In-Topic)(HUMAN:Individual)
focus: ’ilm’ (Begin-Focus) (DESCRIPTION:Deinition)
action / event: ’introduced’ (Begin-Event)
expected answer-type: ENTITY:creative
</note>
<tableCaption confidence="0.9727005">
Table 1: Question Analysis - Semantic Components of a
sample question from TREC QA task.
</tableCaption>
<bodyText confidence="0.999842391304348">
that instances connected by large weights are given
similar labels. Such methods can perform well when
no parametric information about distribution of data
is available and when data is characterized by an un-
derlying manifold structure.
In this paper, we present a semantic component
labeling module for our QA system using a new
graph-based SSL to benefit from unlabeled ques-
tions. One of the issues affecting the performance
of graph-based methods (Maier and Luxburg, 2008)
is that there is no reliable approach for model se-
lection when there are too few labeled points (Zhou
et al., 2004). Such issues have only recently came
into focus (Wang and Zhang, 2006). This is some-
what surprising because graph construction is a
fundamental step. Rather than proposing yet an-
other learning algorithm, we focus on graph con-
struction for our labeling task, which suffers from
insufficient graph sparsification methods. Such
problems are caused by fixed neighborhood assign-
ments in k-nearest neighbor approaches, treating
sparse and denser regions of data equally or using
improper threshold assumptions in c-neighborhood
</bodyText>
<figure confidence="0.99086025">
What
 |{z }
other
 |{z }
introduced
event
 |Jar Jar Bink
{z
topic
film
 |{z }
focus
</figure>
<note confidence="0.985015">
Proceedings of the NAACL HLT 2010 Workshop on Semantic Search, pages 27–35,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.959694307692308">
graphs, yielding disconnected components or sub- beled questions. Graph-based methods are suitable
graphs or isolated singleton vertices. We propose for labeling tasks because when two lexical units
a Relaxed Linear Neighborhood (RLN) method to in different questions are close in the intrinsic ge-
overcome fixed k or E assumptions. RLN approx- ometry of question forms, their semantic compo-
imates the entire graph by a series of overlapped nents (labels) will be similar to each other. Labels
linear neighborhood patches, where neighborhood vary smoothly along the geodesics, i.e., manifold
JV(xi) of any node xi is captured dynamically based assumption, which plays an essential role in SSL
on the density/sparsity of its surrounding. Moreover, (Belkin et al., 2006).
RLN exploits degree of neighborhood during re- This paper presents a new graph construction to
construction method rather than fixed assignments, improve performance of an important module of QA
which does not get affected by outliers, producing a when labeled data is sparse. We compare our re-
more robust graph, demonstrated in Experiment #1. sults with other graph construction methods. Next,
We present our question semantic component we present the dataset construction for our semantic
model in section 3 with the following contributions: component labeling model before we introduce the
(1) a new graph construction method for SSL, new graph construction and inference for SSL.
which relaxes neighborhood assumptions yielding 3 Semantic Component Labeling
robust graphs as defined in section 5, Each word (token) in a question is associated with
(2) a new inference approach to enable learning a label among a pre-determined list of semantic
from unlabeled data as defined in section 6. tags. A question i is defined as a sequence of in-
The experiments in section 7 yield performance im- put units (words/tokens) xi = (x1i, ..., xTi) E XT
provement in comparison to other labeling methods which are tagged with a sequence of class labels,
on different datasets. Finally we draw conclusions. yi = (y1i, ..., yTi) E YT, semantic components.
2 Related Work on Question Analysis The task is to learn classifier F that, given a new
An important step in question analysis is extracting sequence xnew, predicts a sequence of class labels
semantic components like answer type, focus, event, ynew = F(xnew). Among different semantic com-
etc. The ’answer-type’ is a quantity that a question ponent types presented in previous studies, we give
is seeking. A question ’topic’ usually represents ma- each token a MUC style semantic label from a list of
jor context/constraint of a question (”Jar Jar Binks” 11 labels.
in Table 1). A question ’focus’ (e.g., film) denotes a (1) O: other;
certain aspect (or descriptive feature) of a question (2) BT:begin-topic;
’topic’. To extract topic-focus from questions, (Ha- (3) IT:in-topic
jicova et al., 1993) used rule-based approaches via (4) BF:begin-focus;
dependency parser structures. (Burger, 2006) im- (5) IF:in-focus
plemented parsers and a mixture of rule-based and (6) BE:begin-event;
learning methods to extract different salient features (7) IE:in-event
such as question type, event, entities, etc. (Chai and (8) BCL:begin-clause
Jin, 2004) explored semantic units based on their (9) ICL:in-clause
discourse relations via rule-based systems. (10) BC:begin-complement
In (Duan et al., 2008) a language model is pre- (11) IC:in-complement
sented to extract semantic components from ques- More labels can be appended if necessary. The first
tions. Similarly, (Fan et al., 2008)’s semantic chunk token of a component gets ’begin’ prefix and con-
annotation uses conditional random fields (CRF) secutive words are given ’in’ prefix, e.g., Jar (begin-
(Lafferty et al., 2001) to annotate semantic chunks topic), Jar (in-topic), Binks (in-topic) in Table 1.
of questions in Chinese. Our work aparts from In graph-based SSL methods, a graph is con-
these studies in that we use a graph-based SSL structed !9 = (V, £), where V = X is a vertex set,
method to extract semantic components from unla- £ is an edge set, associated with each edge eij rep-
28
resents a relation between xi and xj. The task is to
assign a label (out of 11 possible labels) to each to-
ken of a question i, xti, t = 1, ..., T, T is the max
number of tokens in a given query. We introduce
a set of nodes for each token (xti), each represent-
ing a binary relation between that token and one of
possible tags (yti). A binary relation represents an
agreement between a given token and assigned label,
so our SSL classifier predicts the probability of true
relation between token and assigned label. Thus,
for each token, we introduce 11 different nodes us-
ing y� E {O,BT,IT,BF,IF,BC,IC,BE,IE,BCL,ICL}.
There will be 11 label probability assignments ob-
tained from each of the 11 corresponding nodes. For
labeled questions, intuitively, only one node per to-
ken is introduced to the graph for known(true) to-
ken/label relations. We find the best question label
sequence via Viterbi algorithm (Forney, 1973).
</bodyText>
<subsectionHeader confidence="0.998961">
3.1 Feature Extraction For Labeling Task
</subsectionHeader>
<bodyText confidence="0.9999895">
The following pre-processing modules are built for
feature extraction prior to graph construction.
</bodyText>
<subsectionHeader confidence="0.908587">
3.1.1 Pre-Processing For Feature Extraction
</subsectionHeader>
<bodyText confidence="0.997637133333333">
Phrase Analysis(PA): Using basic syntactic anal-
ysis (shallow parsing), the PA module re-builds
phrases from linguistic structures such as noun-
phrases (NN), basic prepositional phrases (PP) or
verb groups (VG). Using Stanford dependency
parser (Klein and Manning, 2003), (Marneffe et al.,
2006), which produces 48 different grammatical re-
lations, PA module re-constructs the phrases. For
example for the question in Table 1, dependency
parser generates two relations:
− nn(Binks-3, Jar-1) and nn(Binks-3, Jar-2),
PA reveals ”Jar Jar Binks” as a noun phrase re-
constructing the nn:noun compound modifier. We
also extract part of speech tags of questions via de-
pendency parser to be used for feature extraction.
</bodyText>
<subsectionHeader confidence="0.529554">
Question Dependency Relations (QDR): Using
</subsectionHeader>
<bodyText confidence="0.99975">
shallow semantics, we decode underlying Stanford
dependency trees (Marneffe et al., 2006) that em-
body linguistic relationships such as head-subject
(H-S), head-modifier (complement) (H-M), head-
object (H-O), etc. For example: ”How did Troops
enter the area last Friday?” is chunked as:
</bodyText>
<listItem confidence="0.48796">
− Head (H): enter − Object (O): area
− Subject (S): Troops − Modifier (M): last Friday
</listItem>
<bodyText confidence="0.988620666666667">
Later, the feature functions (FF) are extracted based
on generalized rules such as S and O’s are usually
considered topic/focus, H is usually an event, etc.
</bodyText>
<sectionHeader confidence="0.829317" genericHeader="method">
3.1.2 Features for Token-Label Pairs
</sectionHeader>
<bodyText confidence="0.9996631">
Each node vi in a graph !9 represents a relation of
any token(word) i, xti to its label yti, denoted as a
feature vector xti E ltd. A list of feature functions
are formed to construct multi-dimensional training
examples. We extract mainly first and second order
features to identify token-label relations, as follows:
Lexicon Features (LF): These features are over
words and their labels along with information about
words such as POS tags, etc. A sample first order
lexicon feature, z(yt, x1:T, t):
</bodyText>
<equation confidence="0.990666">
�
1 if yt =(BE/IE) and POSxt=VB
z = 1
0 otherwise ( )
</equation>
<bodyText confidence="0.9996426">
is set to 1, if its assigned label yt is of event type
(BE/IE) and word’s POS tag is VB(verb) (such
token-label assignment would be correct). A simi-
lar feature is set to 1 if a word has ’VB’ as its POS
tag and it is a copula word, so it’s correct label can
only be ”O:other”. Nodes satisfying only this con-
straint and have a relation to ”O” label get the value
of ’1’. Similar binary features are: if the word is a
WH type (query word), if its POS tag is an article, if
its POS tag is NN(P)(noun), IN, etc.
Compound Features (CF): These features ex-
ploit semantic compound information obtained from
our PA and QDR modules, in which noun-phrases
are labeled as focus/topics, or verb-phrases as event.
For instance, if a token is part of a semantic com-
pound, e.g., subject, identified via our QDR mod-
ule, then for any of the 11 nodes generated for this
token, if token-label is other than ’O(Other)’, then
such feature would be 1, and 0 otherwise. Similarly,
if a word is part of a noun-phrase, then a node having
a relation to any of the labels other than ’O/BE/IE’
would be given the value 1, and 0 otherwise We
eliminate inclusion of some nodes with certain la-
bels such as words with ”NN” tags are not usually
considered events.
Probability Feature Functions (PFF): We cal-
culate word unigram and bigram frequencies from
training samples to extract label conditional prob-
abilities given a word, e.g., P(BT—”IBM”), P(O-
BE—”Who founded”). When no match is found in
</bodyText>
<page confidence="0.66564">
29
</page>
<bodyText confidence="0.999839727272727">
unigram and bigram label conditional probability ta-
bles for testing cases, we use unigram and bigram
label probabilities given the POS tag of that word,
e.g., P(BT—NNP), P(O-BE—”WP-VBD”). We ex-
tract 11 different features for each word correspond-
ing to each possible label to form the probability fea-
tures from unigram frequencies, max. of 11X11 fea-
tures for bigram frequencies, where some bigrams
are never seen in training dataset.
Second-Order Features (SOF): Such features
denote relation between a token, tag and tag−1, e.g.,:
</bodyText>
<equation confidence="0.9173668">
�
z
1 if yt_1 =BT, yt =IT and POS.,, =NN
=
0 otherwise
</equation>
<bodyText confidence="0.991624">
(2)
which indicates if previous label is a start of a topic
tag (BT) and current POS tag is NN, then a node
with a relation to label ”In-Topic (IT)” would yield
value ’1’. For any given token, one should introduce
112 different nodes to represent a single property. In
experiments we found that only a limited number of
second order nodes are feasible.
</bodyText>
<sectionHeader confidence="0.94324" genericHeader="method">
4 Graph Construction for SSL
</sectionHeader>
<bodyText confidence="0.997090454545455">
Let XL = {x1, ..., xl} be labeled question tokens
with associated labels YL = {y1, ..., yl}T and XU =
{x1, ..., x,} be unlabeled tokens, X = XL ∪ XU.
A weighted symmetric adjacency matrix W is
formed in two steps with edges E in G where Wij ∈
&lt;nxn, and non-zero elements represent the edge
weight between vi and vj. Firstly, similarity be-
tween each pair of nodes is obtained by a measure
to create a full affinity matrix, A ∈ &lt;nxn, using a
kernel function, Aij = k(xi, xj) as weight measure
(Zhou et al., 2004) wij
</bodyText>
<equation confidence="0.963884">
wij = exp (− kxi − xjk /2σ2) (3)
</equation>
<bodyText confidence="0.999954736842105">
Secondly, based on chosen graph sparsification
method, a sparse affinity matrix is obtained by re-
moving edges that do not convey with neighborhood
assumption. Usually a k-nearest neighbor (kNN) or
E neighbor (EN) methods are used for sparsification.
Graph formation is crucial in graph based SSL
since sparsity ensures that the predicted model re-
mains efficient and robust to noise, e.g., especially
in text processing noise is inevitable. EN graphs pro-
vide weaker performance than the k-nearest neigh-
borhood graphs (Jebara et al., 2009). In addition,
the issue with kNN sparsification of graph is that the
number of neighbors is fixed at the start, which may
cause fault neighborhood assumptions even when
neighbors are far apart. Additionally, kernel simi-
larity functions may not rate edge weights because
they might be useful locally but not quite efficient
when nodes are far apart. Next, we present Relaxed
Linear Neighborhoods to address these issues.
</bodyText>
<sectionHeader confidence="0.990489" genericHeader="method">
5 Relaxed Linear Neighborhoods (RLN)
</sectionHeader>
<bodyText confidence="0.999942285714286">
Instead of measuring pairwise relations (3), we use
neighborhood information to construct G. When
building a sparse affinity matrix, we re-construct
each node using a linear combination of its neigh-
bors, similar to Locally Linear Embedding (Roweis
and Saul, 2000) and Linear Neighborhoods (Wang
and Zhang, 2006), and minimize:
</bodyText>
<equation confidence="0.896977">
min Ei ||xi − Ej:xjEAr(xi) wijxj||2 (4)
</equation>
<bodyText confidence="0.998662">
where N(xi) is neighborhood of xi, and wij is the
degree of contribution of xj to xi. In (4) each node
can be optimally reconstructed using a linear combi-
nation of its neighborhood (Roweis and Saul, 2000).
However, having fixed k neighbors at start of the
algorithm can effect generalization of classifier and
can also cause confusion on different manifolds.
We present novel RLN method to reconstruct
each object (node) by using dynamic neighborhood
information, as opposed to fixed k neighbors of
(Wang and Zhang, 2006). RLN approximates entire
graph by a series of overlapped linear neighborhood
patches, where neighborhood N(xi) of a node xi is
captured dynamically via its neighbor’s density.
Boundary Detection: Instead of finding fixed k
neighbors of each node xi (Wang and Zhang, 2006),
RLN captures boundary of each node B(xi) based
on neighborhood information and pins each node
within this boundary as its neighbors. We define
weight W matrix using a measure like (3) as a first
pass sparsification. We identify neighbors for each
node xi ∈ X and save information in boundary ma-
trix, B. kNN recovers its k neighbors using a simi-
larity function, e.g., a kernel distance function, and
instantiates via:
</bodyText>
<equation confidence="0.949419">
Nxi;k(xj) = 1 1otherwi)eed(xi,xj2) 1 (5)
∈ &lt;nxn:
</equation>
<page confidence="0.483014">
30
</page>
<figureCaption confidence="0.775585">
Figure 1: Neighborhood Boundary. Having same number
of neighbors (n=15), boundaries of x1 and x2 are similar
based on kNN (e.g., k=15), but dissimilar based on EN.
</figureCaption>
<bodyText confidence="0.912962666666667">
31 neighborhood bonds will be formed to re-construct
Similarly, with the EN approach the neighbors are
instantiated when they are at most E far away:
</bodyText>
<equation confidence="0.77517">
N( ) = 5 1 d(xi, xj) &lt; E 1
xi;E x� l 0 otherwise J (6)
</equation>
<bodyText confidence="0.99992875">
Both methods have limitations when sparsity or den-
sity is to concern. For sparse regions, if we restrict
definition to k neighbors, then N(xi) would contain
dissimilar points. Similarly, improper threshold val-
ues could result in disconnected components or sub-
graphs or isolated singleton vertices. E-radius would
not define a graph because not every neighborhood
radius would have the same density (see Fig. 1).
Neighborhoods of two points (x1, x2) are different,
although they contain same number of nodes.
We can use both kNN and ENN approaches to
define the neighborhood between any xi and xj as:
</bodyText>
<equation confidence="0.745562">
X
</equation>
<bodyText confidence="0.986116571428571">
Relaxed Boundary Detection: Adjusting bound-
aries based on a neighborhood radius and density
might cause some problems. Specifically, if dense
regions (clusters) exist and parameters are set large
for sparse datasets, e.g., k and E, then neighborhood
sets would include more (and even noisy) nodes
than necessary
</bodyText>
<equation confidence="0.998516">
nB(xi) = xj=1..n∈
(8)
���IN�i;k,�(xj)=1 o
</equation>
<bodyText confidence="0.9964982">
. Similarly, for low density regions
if parameters are set for dense neighborhoods, weak
via linear neighborhoods. An algorithm that can
handle a wide range of change interval would be
advantageous. It should also include information
provided by neighboring nodes closest to the corre-
sponding node, which can take neighborhood rela-
tion into consideration more sensitively. Thus we
extend neighborhood definition in (7) and (8) ac-
counting for sensitivity of points with varying dis-
</bodyText>
<equation confidence="0.990584461538462">
=max {(1
k (d(xi,
,
Nxi(xj)
−
xj)/dmax))
0}(9)
dmax =
In (10) m is the max. feature vector dimension of
an
qPm (10)
d(xi, xj) = p=1(xip − xjp)2
y xi, k plays a role in determining neighborhood
radius, such that it could be adjusted as follows:
k
= 0
k = dmax/
−
(E/dmax)
⇒
E (11)
X
[0,
={xj=1..n∈
|Nxi(xj)∈
1]} (12)
&amp; xi
j.
j Et3(x
)
� �
w
−P
x
i
xi
xj )wijxj
Pj wij = 1, wij ≥ 0
(7)
</equation>
<bodyText confidence="0.833458">
denotes cardinality of E-neighbors of xi,
and
according to (5). Thus if
there are enough number of nodes in the E vicinity
</bodyText>
<equation confidence="0.834801090909091">
(&gt; k), then the boundary is identified. Otherwise
we use kNN. Boundary set of an
|NE(xi)|
Nxi;k(xj)∈{0,1}
y xi is defined as:
tan
ces to neighbor points based on parameter k &gt; 0:
1
The new boundary set of an
y given xi includes:
B(xi)
</equation>
<bodyText confidence="0.978654">
In the experiments, we tested our RLN approach
(9), 0 &lt;
&lt; 1 for boundary detection, in
comparison to the static neighborhood assignments
where the number of neighbors, k is fixed.
(3) Graph Formation: Instead of measuring pair-
wise relations as in (3), we use neighborhood in-
formation to represent
In an analogical man-
ner to (Roweis and Saul, 2000), (Wang and Zhang,
2006), for graph sparcification, for our Relaxed Lin-
ear Neighborhood, we re-construct each node using
a li
</bodyText>
<equation confidence="0.728334">
Nxi(xj)
G.
near combination of its dynamic neighbors:
min
s.t.
(13)
</equation>
<bodyText confidence="0.958410333333333">
where 0 &lt;
&lt; 1 is the degree of neighbor-
hood to boundary set
and
is degree of con-
tribution of xj to xi, to be predicted. A
= 0
means no edge link. To prevent negative weights,
and satisfy their normalization to unity, we used a
constraint in (13) for RLN.
Edge weights of
are found using above relaxed
</bodyText>
<equation confidence="0.701770111111111">
boundary assumption, an
Nxi(xj)
B(xi)
wij
Nxi(xj)
G
d relaxed neighborhood
1  |NE(xi) |&gt; k
j
Nxi;k(x
) otherwise
Nxi;k,E(xj)
=(
)
d(xi,
maxxi,xjEX
xj)
2
</equation>
<bodyText confidence="0.936189125">
method. A sparse relaxed weight matrix ( W)ij = w)/ D = Z − W. Since f is a function on the man-
wij is formed representing different number of con-
nected edges for every node, which are weighted ac-
cording to their neighborhood density. Since wij is
constructed via linear combination of varying num-
ber of neighbors of each node, W is used as the edge
weights of !9. Next we form a regularization frame-
work in place of label propagation (LP).
</bodyText>
<sectionHeader confidence="0.941884" genericHeader="method">
6 Regularization and Inference
</sectionHeader>
<bodyText confidence="0.9999821">
Given a set of token-label assignments X =
{x1, ..., xl, xl+1, ..., xn}, and binary labels of first l
points, Y = {y1, ..., yl, 0, .., 0}, the goal is to predict
if the label assignment of any token of a given test
question is true or false. Let F denote set of clas-
sifying functions defined on X, and Vf E F a real
value fi to every point xi is assigned. At each it-
eration, any given data point exploits a part of label
information from its neighbors, which is determined
by RLN. Thus, predicted label of a node xi at t+1:
</bodyText>
<equation confidence="0.9885605">
ft+1
i = λyi + (1 − λ) Ej Nxi(xj)wijftj (14)
</equation>
<bodyText confidence="0.99993025">
where xj E Bxi, 0&lt; λ &lt;1 sets a portion of la-
bel information that xi gets from its local neighbors,
ft = (ft1, ft2, ..., ftn) is the prediction label vector at
iteration t and f0 = y. We can re-state (14) as:
</bodyText>
<equation confidence="0.994773">
ft+1 = λyi + (1 − λ)�Wft (15)
</equation>
<bodyText confidence="0.999706142857143">
Each node’s label is updated via (15) until conver-
gence, which might be at t —* oc. In place of LP,
we can develop a regularization framework (Zhou et
al., 2004) to learn f. In graph-based SSL, a function
over a graph is estimated to satisfy two conditions:
(i) close to the observed labels , and (ii) be smooth
on the whole graph via following loss function:
</bodyText>
<equation confidence="0.947270333333333">
arg min 2(f) = Eni=1 (fi − yi)2+ (16)
λ En Ej:xjEt3(xi) φxi(xj) (fi, fj)
i,j=1
</equation>
<bodyText confidence="0.998181">
where φxi(xj) = Nxi(xj)�wij. Setting gradient of
loss function 2(f) to zero, we obtain:
</bodyText>
<equation confidence="0.999088">
∂f2(f) = 2(Y −f)+λ[(Z −-b)+(Z −.b)T]f (17)
</equation>
<bodyText confidence="0.999029428571429">
Relaxed weight matrix W is normalized according
to constraint in (13), so as degree matrix, D =
Ej Wij, and graph Laplacian, i.e., L = (D −
ifold and the graph is discretized form of a manifold
(Belkin and Niyogi, 2002a), f can also be regarded
as the discrete form of f, which is equivalent at the
nodes of graph. So the second term of (16) yields:
</bodyText>
<equation confidence="0.881899">
[(Z −�W)+(Z −�W)T]f Pz� 2Lf Pz� [(Z −�W)]f (18)
</equation>
<bodyText confidence="0.894002">
Hence optimum f* is obtained by new form of
derivative in (17) after replacing (18):
</bodyText>
<equation confidence="0.9977935">
( )−1 Y
f* = (1 − λ) Z − λ W� (19)
</equation>
<bodyText confidence="0.99803425">
Most graph-based SSLs are transductive, i.e., not
easily expendable to new testing points. In (Delal-
leau et al., 2005) an induction scheme is proposed to
classify a new point xTe by
</bodyText>
<equation confidence="0.998719">
�f(xTe) = EiELUU �Wxifi/EiELUU �Wxi (20)
</equation>
<bodyText confidence="0.999924">
Thus, we use induction, where we can, to avoid re-
construction of the graph for new test points.
</bodyText>
<sectionHeader confidence="0.943662" genericHeader="evaluation">
7 Experiments and Discussions
</sectionHeader>
<bodyText confidence="0.973225217391305">
In the next, we evaluate the performance of the pro-
posed RLN in comparison to the other methods on
syntactic and real datasets.
Exp. 1. Graph Construction Performance:
Here we use a similar syntactic data in (Jebara et
al., 2009) shown in Fig.2.a, which contains two
clusters of dissimilar densities and shapes. We
investigate three graph construction methods, lin-
ear k-neighborhoods of (Roweis and Saul, 2000) in
Fig.2.b, b-matching(Jebara et al., 2009) in Fig.2.c
and RLN of this work in Fig.2.d using a dataset of
300 points with binary output values. b-matching
permits a given datum to select k neighboring points
but also ensures that exactly k points selects given
datum as their neighbor.
In each graph construction method Gaussian ker-
nel distance is used. Experiments are run 50 times
where at each fold only 2 labeled samples from op-
posite classes are used to predict the rest. The exper-
iments are repeated for different k, b and E values. In
Fig. 2, average of trials is shown when k, b are 10
and E &gt;0.5. We also used the EN approach but it did
not show any improvement over kNN approach.
</bodyText>
<page confidence="0.783187">
32
</page>
<figureCaption confidence="0.997668">
Figure 2: Graph Construction Experiments. (a) Syntactic data. (b) linear k-neighborhood (c) b-matching (d) RLN.
</figureCaption>
<bodyText confidence="0.999964166666667">
In Fig. 2.d, RLN can separate two classes
more efficiently than the rest. Compared to the b-
matching approach, RLN clearly improves the ro-
bustness. There are more links between clusters in
other graph methods than RLN, which shows that
RLN can separate two classes much efficiently. Also
since dynamic number of edges are constructed with
RLN, unnecessary links are avoided, but for the rest
of the graph methods there are edges between far
away nodes (shown with arrows). In the rest of the
experiments, we use b-matching for benchmark as it
is the closest approach to the proposed RLN.
</bodyText>
<subsectionHeader confidence="0.285247">
Exp. 2. Semantic Component Recognition:
</subsectionHeader>
<bodyText confidence="0.999945434782609">
We demonstrate the performance of the new RLN
with two sets of experiments for sequence labeling
of question recognition task. As a first step in un-
derstanding semantic components of questions, we
asked two annotators to annotate a random subsam-
ple of 4000 TREC factoid and description questions
obtained from tasks of 1999-2006. There are 11
predefined semantic categories (section 3), close to
280K labeled tokens. Annotators are told that each
question must have one topic and zero or one focus
and event, zero or more of the rest of the compo-
nents. Inter-tagger agreement is r. = 0.68, which
denotes a considerable agreement.
We trained models on 3500 random set of ques-
tions and reserved the rest of 500 for testing the per-
formance. We applied pre-processing and feature
selection of section 3 to compile labeled and unla-
beled training and labeled testing datasets. At train-
ing time, we performed manual iterative parameter
optimization based on prediction accuracy to find
the best parameter sets, i.e., k = {3, 5, 10, 20, 50},
E ∈ {0, 1}, distance = {linear, gaussion}.
We use the average loss (L) per sequence (query)
</bodyText>
<table confidence="0.9962206">
other topic focus event rest
# Samples 1997 1142 525 264 217
CRF 0.935 0.903 0.823 0.894 0.198
b-matching 0.871 0.900 0.711 0.847 0.174
RLN 0.911 0.910 0.761 0.834 0.180
</table>
<tableCaption confidence="0.967646666666667">
Table 2: Chunking accuracy on testing data. ’other’=O,
’topic’=BT+IT, ’focus’ = BF+IF, ’event’= ’BE+IE”,
’rest’= rest of the labels, i.e., IE, BC, IC, BCL, ICL.
</tableCaption>
<bodyText confidence="0.980540541666667">
to evaluate the semantic chunking performance:
�N L = N i=1 [Li �j i 1 I ((�yi)j =6 (yi)j) ] (21)
where y� and y are predicted and actual sequence re-
spectively; N is the number of test examples; Li is
the length of ith sequence; I is the 0-1 loss function.
(1) Chunking Performance: Here, we investigate
the accuracy of our models on individual component
prediction. We use CRF, b-matching and our RLN
to learn models from labeled training data and eval-
uate performance on testing dataset. For RLN and
b-matching we use training as labeled and testing as
unlabeled dataset in transductive way to predict to-
ken labels. The testing results are shown in Table 2
for different group of components. The accuracy for
’topic’ and ’focus’ components are relatively high
compared to other components. Most of the errors
on the ’rest’ labels are due to confusion with ’topic’
or ’focus’. On some components, i.e., topic, other,
RLN performed significantly better than b-matching
based on t-test statistics (at 95% confidence). No
statistical significance between CRF and RLN is ob-
served indicating that RLN’s good performance on
individual label scoring, as it shows that RLN can
be used efficiently for sequence labeling.
</bodyText>
<table confidence="0.9107407">
(2) Question Labeling Performance. Having
33
Labeled CRF SSL sCRF b-match RLN
1% 0.240 0.235 0.223 0.233 0.220
5% 0.222 0.218 0.215 0.203 0.189
10% 0.170 0.219 0.186 0.194 0.180
25% 0.173 0.196 0.175 0.174 0.170
50% 0.160 0.158 0.147 0.156 0.158
75% 0.140 0.163 0.138 0.160 0.155
100% 0.120 0.170 0.123 0.155 0.149
</table>
<tableCaption confidence="0.971477666666667">
Table 3: Test Data Average Loss on graph construction
with RLN, b-matching, standard SSL with kNN as well
as CRF, CRF with Self Learning (sCRF).
</tableCaption>
<bodyText confidence="0.999871205882353">
demonstrated that RLN is an alternative method
to the standard sequence learning methods for
the question labeling task, next we evaluate per
sequence (question) performance, rather than in-
dividual label performance using unlabeled data.
Firstly, we randomly select subset of labeled train-
ing dataset, XiL C XL with different sample sizes,
niL = 5% * nL, 10% * nL, 25% * nL, 50% * nL,
75% * nL, 100% * nL, where nL is the size of XL.
Thus, instead of fixing the number of labeled records
and varying the number of unlabeled points, we pro-
pose to fix the percentage of unlabeled points in
training dataset. We hypothetically use unselected
part of the labeled dataset as unlabeled data at each
random selection. We compare the result of RLN to
other graph based methods including standard SSL
(Zhu et al., 2003) using kNN, and b-matching. We
also build a CRF model using the same features
as RLN except the output information, which CRF
learns through probabilistic structure. In addition,
we implemente self training for CRF (sCRF), most
commonly known SSL method, by adding most con-
fident (x, f(x)) unlabeled data back to the data and
repeat the process 10 times. Table 3 reports average
loss of question recognition tasks on testing dataset
using these methods.
When the number of labeled data is small (niL &lt;
25%nL), RLN has better performance compared to
the rest (an average of 7% improvement). The SSL
and sCRF performance is slightly better than CRF at
this stage. As expected, as the percentage of labeled
points in training is increased, the CRF outperforms
the rest of the models. However, observing no sta-
tistical significance between CRF, b-matching and
</bodyText>
<table confidence="0.9909305">
# Unlabeled tokens 25K 50K 75K 100K
Average Loss 0.150 0.146 0.141 0.139
</table>
<tableCaption confidence="0.9345515">
Table 4: Average Loss Results for RLN graph based SSL
as unlabeled tokens is increased.
</tableCaption>
<bodyText confidence="0.998210217391304">
RLN up to 25-50% labeled points indicates RLNs
performance on unlabeled datasets. Thus, for se-
quence labeling, the RLN can be a better alternative
to known sequence labeling methods, when manual
annotation of the entire dataset is not feasible.
Exp. 3. Unlabeled Data Performance: Here
we evaluate the effect of the size of unlabeled data
on the performance of RLN by gradually increas-
ing the size of unlabeled questions. The assump-
tion is that as more unlabeled data is used, the model
would have additional spatial information about to-
ken neighbors that would help to improve its gener-
alization performance. We used the questions from
the Question and Answer pair dataset distributed by
Linguistic Data Consortium for the DARPA GALE
project (LDC catalog number: LDC2008E16). We
compiled 10K questions, consisting of 100K tokens.
Although the error reduction is small (Table 4),
the empirical results indicate that unlabeled data can
have positive effect on the performance of the RLN
method. As we introduce more unlabeled data, the
RLN performance is increased, which indicates that
there is a lot to discover from unlabeled questions.
</bodyText>
<sectionHeader confidence="0.998755" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.9999889375">
In this paper, we presented a graph-based semi-
supervised learning method with a new graph con-
struction. Our new graph construction relaxes the
neighborhood assumptions yielding robust graphs
when the labeled data is sparse, in comparison to
previous methods, which set rigid boundaries. The
new algorithm is particularly appealing to question
semantic component recognition task, namely ques-
tion understanding, in that in this task we usually
deal with very few labeled data and considerably
larger unlabeled data. Experiments on question se-
mantic component recognition show that our semi-
supervised graph-based method can improve perfor-
mance by up to 7-10% compared to well-known se-
quence labeling methods, especially when there are
more unlabeled data than the labeled data.
</bodyText>
<page confidence="0.897038">
34
</page>
<sectionHeader confidence="0.992419" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99985376119403">
A. Alexandrescu and K. Kirchhoff. 2007. Data-driven
graph construction for semi-supervised graph-based
learning in nlp. In Proc. of HLT 2007.
M. Belkin and P. Niyogi. 2002a. Laplacian eigenmaps
and spectral techniques for embedding and clustering.
In Advances in Neural Information Processing Sys-
tems.
M. Belkin and P. Niyogi. 2002b. Using manifold struc-
ture for partially labeled classification. In Proc. of
NIPS 2002.
M. Belkin, P. Niyogi, and V. Sindhwani. 2006. A ge-
ometric framework for learning from examples. In
Journal of Machine Learning Research.
J. D. Burger. 2006. Mitre’s qanda at trec-15. In Proc. of
the TREC-2006.
J.Y. Chai and R. Jin. 2004. Discourse structure for
context question answering. In Proc. of HLT-NAACL
2004.
O. Delalleau, Y. Bengio, and N.L. Roux. 2005. Efficient
non-parametric function induction in semi-supervised
learning. In Proc. of AISTAT-2005.
H. Duan, Cao Y, C.Y. Lin, and Y. Yu. 2008. Searching
questions by identifying question topic and question
focus. In Proc. of ACL-08.
S. Fan, Y. Zhang, W.W.Y. Ng, Xuan Wang, and X. Wang.
2008. Semantic chunk annotation for complex ques-
tions using conditional random field. In Coling 2008:
Proc. of Workshop on Knowledge and Reasoning for
Answering Questions.
GD. Forney. 1973. The viterbi algorithm. In Proc. of
IEEE 61(3), pages 269–278.
A. Goldberg and X. Zhu. 2009. Keepin’ it real: Semi-
supervised learning with realistic tuning. In Proc.
of NAACL-09 Workshop on Semi-Supervised Learning
for NLP.
E. Hajicova, P. Sgall, and H. Skoumalova. 1993. Iden-
tifying topic and focus by an automatic procedure. In
Proc. of the EACL-1993.
T. Jebara, J. Wang, and S.F. Chang. 2009. Graph con-
struction and b-matching for semi-supervised learning.
In Proc. of ICML-09.
Dan Klein and Christopher D. Manning. 2003. Accu-
rate unlexicalized parsing. In Proceedings of the 41st
Meeting of the ACL-2003, pages 423–430.
J.D. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional random fields: Probabilistic models for seg-
menting and labeling sequence data. In Proc. of 18th
International Conf. on Machine Learning (ICML’01).
M. Maier and U.V. Luxburg. 2008. Influence of graph
construction on graph-based clustering measures. In
Proc. of Neural Infor. Proc. Sys. (NIPS 2008).
M.-C.D. Marneffe, B. MacCartney, and C.D. Manning.
2006. Generating typed-dependency parsers from
phrase structure parsers. In In LREC2006.
S.T. Roweis and L.K. Saul. 2000. Nonlinear dimension-
ality reduction by locally embedding. In Science, vol-
ume 290, pages 2323–2326.
F. Wang and C. Zhang. 2006. Label propagation through
linear neighborhoods. In Proc. of the ICML-2006.
Dengyong Zhou, Olivier Bousquet, Thomas N. Lal, Ja-
son Weston, and Bernhard Scholkopf. 2004. Learning
with local and global consistency. Advances in Neural
Information Processing Systems, 16:321–328.
Xiaojin Zhu, John Lafferty, and Zoubin Ghahramani.
2003. Semi-supervised learning: From Gaussian
Fields to Gaussian processes. Technical Report CMU-
CS-03-175, Carnegie Mellon University, Pittsburgh.
</reference>
<page confidence="0.953286">
35
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.825537">
<title confidence="0.999948">A Graph-Based Semi-Supervised Learning for Question Semantic Labeling</title>
<author confidence="0.990064">Asli Celikyilmaz Dilek Hakkani-Tur</author>
<affiliation confidence="0.9344215">Computer Science Division International Computer Science Institute University of California, Berkeley Berkeley, CA</affiliation>
<email confidence="0.998219">asli@berkeley.edudilek@icsi.berkeley.edu</email>
<abstract confidence="0.997417133333333">We investigate a graph-based semi-supervised learning approach for labeling semantic comof questions such as focus, for question understanding task. We focus on graph construction to handle learning with dense/sparse graphs and present Linear Neighborhoods in which each node is linearly constructed from varying sizes of its neighbors based on the density/sparsity of its surrounding. With the new graph representation, we show performance improvements on syntactic and real datasets, primarily due to the use of unlabeled data and relaxed graph construction.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Alexandrescu</author>
<author>K Kirchhoff</author>
</authors>
<title>Data-driven graph construction for semi-supervised graph-based learning in nlp.</title>
<date>2007</date>
<booktitle>In Proc. of HLT</booktitle>
<contexts>
<context position="1515" citStr="Alexandrescu and Kirchhoff, 2007" startWordPosition="207" endWordPosition="210">oduction One of the important steps in Question Answering (QA) is question understanding to identify semantic components of questions. In this paper, we investigate question understanding based on a machine learning approach to discover semantic components (Table 1). An important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (SSL) methods, e.g., (Belkin and Niyogi., 2002b), (Zhou et al., 2004). Recently, graph based SSL methods have gained interest (Alexandrescu and Kirchhoff, 2007), (Goldberg and Zhu, 2009). These methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points. Classification is performed using these graphs by scoring unlabeled points in such a way 27 Semantic Components &amp; Named-Entitiy Types topic: ’Jar’ (Begin-Topic); ’Jar’ (In-Topic) ; ’Binks’ (In-Topic)(HUMAN:Individual) focus: ’ilm’ (Begin-Focus) (DESCRIPTION:Deinition) action / event: ’introduced’ (Begin-Event) expected answer-type: ENTITY:creative Table 1: Question Analysis - Semantic Components of a samp</context>
</contexts>
<marker>Alexandrescu, Kirchhoff, 2007</marker>
<rawString>A. Alexandrescu and K. Kirchhoff. 2007. Data-driven graph construction for semi-supervised graph-based learning in nlp. In Proc. of HLT 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Belkin</author>
<author>P Niyogi</author>
</authors>
<title>Laplacian eigenmaps and spectral techniques for embedding and clustering.</title>
<date>2002</date>
<booktitle>In Advances in Neural Information Processing Systems.</booktitle>
<contexts>
<context position="21837" citStr="Belkin and Niyogi, 2002" startWordPosition="3629" endWordPosition="3632">learn f. In graph-based SSL, a function over a graph is estimated to satisfy two conditions: (i) close to the observed labels , and (ii) be smooth on the whole graph via following loss function: arg min 2(f) = Eni=1 (fi − yi)2+ (16) λ En Ej:xjEt3(xi) φxi(xj) (fi, fj) i,j=1 where φxi(xj) = Nxi(xj)�wij. Setting gradient of loss function 2(f) to zero, we obtain: ∂f2(f) = 2(Y −f)+λ[(Z −-b)+(Z −.b)T]f (17) Relaxed weight matrix W is normalized according to constraint in (13), so as degree matrix, D = Ej Wij, and graph Laplacian, i.e., L = (D − ifold and the graph is discretized form of a manifold (Belkin and Niyogi, 2002a), f can also be regarded as the discrete form of f, which is equivalent at the nodes of graph. So the second term of (16) yields: [(Z −�W)+(Z −�W)T]f Pz� 2Lf Pz� [(Z −�W)]f (18) Hence optimum f* is obtained by new form of derivative in (17) after replacing (18): ( )−1 Y f* = (1 − λ) Z − λ W� (19) Most graph-based SSLs are transductive, i.e., not easily expendable to new testing points. In (Delalleau et al., 2005) an induction scheme is proposed to classify a new point xTe by �f(xTe) = EiELUU �Wxifi/EiELUU �Wxi (20) Thus, we use induction, where we can, to avoid reconstruction of the graph fo</context>
</contexts>
<marker>Belkin, Niyogi, 2002</marker>
<rawString>M. Belkin and P. Niyogi. 2002a. Laplacian eigenmaps and spectral techniques for embedding and clustering. In Advances in Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Belkin</author>
<author>P Niyogi</author>
</authors>
<title>Using manifold structure for partially labeled classification.</title>
<date>2002</date>
<booktitle>In Proc. of NIPS</booktitle>
<contexts>
<context position="21837" citStr="Belkin and Niyogi, 2002" startWordPosition="3629" endWordPosition="3632">learn f. In graph-based SSL, a function over a graph is estimated to satisfy two conditions: (i) close to the observed labels , and (ii) be smooth on the whole graph via following loss function: arg min 2(f) = Eni=1 (fi − yi)2+ (16) λ En Ej:xjEt3(xi) φxi(xj) (fi, fj) i,j=1 where φxi(xj) = Nxi(xj)�wij. Setting gradient of loss function 2(f) to zero, we obtain: ∂f2(f) = 2(Y −f)+λ[(Z −-b)+(Z −.b)T]f (17) Relaxed weight matrix W is normalized according to constraint in (13), so as degree matrix, D = Ej Wij, and graph Laplacian, i.e., L = (D − ifold and the graph is discretized form of a manifold (Belkin and Niyogi, 2002a), f can also be regarded as the discrete form of f, which is equivalent at the nodes of graph. So the second term of (16) yields: [(Z −�W)+(Z −�W)T]f Pz� 2Lf Pz� [(Z −�W)]f (18) Hence optimum f* is obtained by new form of derivative in (17) after replacing (18): ( )−1 Y f* = (1 − λ) Z − λ W� (19) Most graph-based SSLs are transductive, i.e., not easily expendable to new testing points. In (Delalleau et al., 2005) an induction scheme is proposed to classify a new point xTe by �f(xTe) = EiELUU �Wxifi/EiELUU �Wxi (20) Thus, we use induction, where we can, to avoid reconstruction of the graph fo</context>
</contexts>
<marker>Belkin, Niyogi, 2002</marker>
<rawString>M. Belkin and P. Niyogi. 2002b. Using manifold structure for partially labeled classification. In Proc. of NIPS 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Belkin</author>
<author>P Niyogi</author>
<author>V Sindhwani</author>
</authors>
<title>A geometric framework for learning from examples.</title>
<date>2006</date>
<journal>In Journal of Machine Learning Research.</journal>
<contexts>
<context position="4268" citStr="Belkin et al., 2006" startWordPosition="621" endWordPosition="624">e for labeling tasks because when two lexical units a Relaxed Linear Neighborhood (RLN) method to in different questions are close in the intrinsic geovercome fixed k or E assumptions. RLN approx- ometry of question forms, their semantic compoimates the entire graph by a series of overlapped nents (labels) will be similar to each other. Labels linear neighborhood patches, where neighborhood vary smoothly along the geodesics, i.e., manifold JV(xi) of any node xi is captured dynamically based assumption, which plays an essential role in SSL on the density/sparsity of its surrounding. Moreover, (Belkin et al., 2006). RLN exploits degree of neighborhood during re- This paper presents a new graph construction to construction method rather than fixed assignments, improve performance of an important module of QA which does not get affected by outliers, producing a when labeled data is sparse. We compare our remore robust graph, demonstrated in Experiment #1. sults with other graph construction methods. Next, We present our question semantic component we present the dataset construction for our semantic model in section 3 with the following contributions: component labeling model before we introduce the (1) a</context>
</contexts>
<marker>Belkin, Niyogi, Sindhwani, 2006</marker>
<rawString>M. Belkin, P. Niyogi, and V. Sindhwani. 2006. A geometric framework for learning from examples. In Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Burger</author>
</authors>
<title>Mitre’s qanda at trec-15.</title>
<date>2006</date>
<booktitle>In Proc. of the TREC-2006.</booktitle>
<contexts>
<context position="6507" citStr="Burger, 2006" startWordPosition="978" endWordPosition="979">ntic cometc. The ’answer-type’ is a quantity that a question ponent types presented in previous studies, we give is seeking. A question ’topic’ usually represents ma- each token a MUC style semantic label from a list of jor context/constraint of a question (”Jar Jar Binks” 11 labels. in Table 1). A question ’focus’ (e.g., film) denotes a (1) O: other; certain aspect (or descriptive feature) of a question (2) BT:begin-topic; ’topic’. To extract topic-focus from questions, (Ha- (3) IT:in-topic jicova et al., 1993) used rule-based approaches via (4) BF:begin-focus; dependency parser structures. (Burger, 2006) im- (5) IF:in-focus plemented parsers and a mixture of rule-based and (6) BE:begin-event; learning methods to extract different salient features (7) IE:in-event such as question type, event, entities, etc. (Chai and (8) BCL:begin-clause Jin, 2004) explored semantic units based on their (9) ICL:in-clause discourse relations via rule-based systems. (10) BC:begin-complement In (Duan et al., 2008) a language model is pre- (11) IC:in-complement sented to extract semantic components from ques- More labels can be appended if necessary. The first tions. Similarly, (Fan et al., 2008)’s semantic chunk </context>
</contexts>
<marker>Burger, 2006</marker>
<rawString>J. D. Burger. 2006. Mitre’s qanda at trec-15. In Proc. of the TREC-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Y Chai</author>
<author>R Jin</author>
</authors>
<title>Discourse structure for context question answering.</title>
<date>2004</date>
<booktitle>In Proc. of HLT-NAACL</booktitle>
<marker>Chai, Jin, 2004</marker>
<rawString>J.Y. Chai and R. Jin. 2004. Discourse structure for context question answering. In Proc. of HLT-NAACL 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Delalleau</author>
<author>Y Bengio</author>
<author>N L Roux</author>
</authors>
<title>Efficient non-parametric function induction in semi-supervised learning.</title>
<date>2005</date>
<booktitle>In Proc. of AISTAT-2005.</booktitle>
<contexts>
<context position="22255" citStr="Delalleau et al., 2005" startWordPosition="3710" endWordPosition="3714">t matrix W is normalized according to constraint in (13), so as degree matrix, D = Ej Wij, and graph Laplacian, i.e., L = (D − ifold and the graph is discretized form of a manifold (Belkin and Niyogi, 2002a), f can also be regarded as the discrete form of f, which is equivalent at the nodes of graph. So the second term of (16) yields: [(Z −�W)+(Z −�W)T]f Pz� 2Lf Pz� [(Z −�W)]f (18) Hence optimum f* is obtained by new form of derivative in (17) after replacing (18): ( )−1 Y f* = (1 − λ) Z − λ W� (19) Most graph-based SSLs are transductive, i.e., not easily expendable to new testing points. In (Delalleau et al., 2005) an induction scheme is proposed to classify a new point xTe by �f(xTe) = EiELUU �Wxifi/EiELUU �Wxi (20) Thus, we use induction, where we can, to avoid reconstruction of the graph for new test points. 7 Experiments and Discussions In the next, we evaluate the performance of the proposed RLN in comparison to the other methods on syntactic and real datasets. Exp. 1. Graph Construction Performance: Here we use a similar syntactic data in (Jebara et al., 2009) shown in Fig.2.a, which contains two clusters of dissimilar densities and shapes. We investigate three graph construction methods, linear k</context>
</contexts>
<marker>Delalleau, Bengio, Roux, 2005</marker>
<rawString>O. Delalleau, Y. Bengio, and N.L. Roux. 2005. Efficient non-parametric function induction in semi-supervised learning. In Proc. of AISTAT-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Duan</author>
<author>Y Cao</author>
<author>C Y Lin</author>
<author>Y Yu</author>
</authors>
<title>Searching questions by identifying question topic and question focus.</title>
<date>2008</date>
<booktitle>In Proc. of ACL-08.</booktitle>
<contexts>
<context position="6904" citStr="Duan et al., 2008" startWordPosition="1031" endWordPosition="1034">) of a question (2) BT:begin-topic; ’topic’. To extract topic-focus from questions, (Ha- (3) IT:in-topic jicova et al., 1993) used rule-based approaches via (4) BF:begin-focus; dependency parser structures. (Burger, 2006) im- (5) IF:in-focus plemented parsers and a mixture of rule-based and (6) BE:begin-event; learning methods to extract different salient features (7) IE:in-event such as question type, event, entities, etc. (Chai and (8) BCL:begin-clause Jin, 2004) explored semantic units based on their (9) ICL:in-clause discourse relations via rule-based systems. (10) BC:begin-complement In (Duan et al., 2008) a language model is pre- (11) IC:in-complement sented to extract semantic components from ques- More labels can be appended if necessary. The first tions. Similarly, (Fan et al., 2008)’s semantic chunk token of a component gets ’begin’ prefix and conannotation uses conditional random fields (CRF) secutive words are given ’in’ prefix, e.g., Jar (begin(Lafferty et al., 2001) to annotate semantic chunks topic), Jar (in-topic), Binks (in-topic) in Table 1. of questions in Chinese. Our work aparts from In graph-based SSL methods, a graph is conthese studies in that we use a graph-based SSL structe</context>
</contexts>
<marker>Duan, Cao, Lin, Yu, 2008</marker>
<rawString>H. Duan, Cao Y, C.Y. Lin, and Y. Yu. 2008. Searching questions by identifying question topic and question focus. In Proc. of ACL-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Fan</author>
<author>Y Zhang</author>
<author>W W Y Ng</author>
<author>Xuan Wang</author>
<author>X Wang</author>
</authors>
<title>Semantic chunk annotation for complex questions using conditional random field.</title>
<date>2008</date>
<booktitle>In Coling 2008: Proc. of Workshop on Knowledge and Reasoning for Answering Questions.</booktitle>
<contexts>
<context position="7089" citStr="Fan et al., 2008" startWordPosition="1060" endWordPosition="1063">y parser structures. (Burger, 2006) im- (5) IF:in-focus plemented parsers and a mixture of rule-based and (6) BE:begin-event; learning methods to extract different salient features (7) IE:in-event such as question type, event, entities, etc. (Chai and (8) BCL:begin-clause Jin, 2004) explored semantic units based on their (9) ICL:in-clause discourse relations via rule-based systems. (10) BC:begin-complement In (Duan et al., 2008) a language model is pre- (11) IC:in-complement sented to extract semantic components from ques- More labels can be appended if necessary. The first tions. Similarly, (Fan et al., 2008)’s semantic chunk token of a component gets ’begin’ prefix and conannotation uses conditional random fields (CRF) secutive words are given ’in’ prefix, e.g., Jar (begin(Lafferty et al., 2001) to annotate semantic chunks topic), Jar (in-topic), Binks (in-topic) in Table 1. of questions in Chinese. Our work aparts from In graph-based SSL methods, a graph is conthese studies in that we use a graph-based SSL structed !9 = (V, £), where V = X is a vertex set, method to extract semantic components from unla- £ is an edge set, associated with each edge eij rep28 resents a relation between xi and xj. </context>
</contexts>
<marker>Fan, Zhang, Ng, Wang, Wang, 2008</marker>
<rawString>S. Fan, Y. Zhang, W.W.Y. Ng, Xuan Wang, and X. Wang. 2008. Semantic chunk annotation for complex questions using conditional random field. In Coling 2008: Proc. of Workshop on Knowledge and Reasoning for Answering Questions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Forney</author>
</authors>
<title>The viterbi algorithm.</title>
<date>1973</date>
<booktitle>In Proc. of IEEE</booktitle>
<volume>61</volume>
<issue>3</issue>
<pages>269--278</pages>
<contexts>
<context position="8567" citStr="Forney, 1973" startWordPosition="1320" endWordPosition="1321"> one of possible tags (yti). A binary relation represents an agreement between a given token and assigned label, so our SSL classifier predicts the probability of true relation between token and assigned label. Thus, for each token, we introduce 11 different nodes using y� E {O,BT,IT,BF,IF,BC,IC,BE,IE,BCL,ICL}. There will be 11 label probability assignments obtained from each of the 11 corresponding nodes. For labeled questions, intuitively, only one node per token is introduced to the graph for known(true) token/label relations. We find the best question label sequence via Viterbi algorithm (Forney, 1973). 3.1 Feature Extraction For Labeling Task The following pre-processing modules are built for feature extraction prior to graph construction. 3.1.1 Pre-Processing For Feature Extraction Phrase Analysis(PA): Using basic syntactic analysis (shallow parsing), the PA module re-builds phrases from linguistic structures such as nounphrases (NN), basic prepositional phrases (PP) or verb groups (VG). Using Stanford dependency parser (Klein and Manning, 2003), (Marneffe et al., 2006), which produces 48 different grammatical relations, PA module re-constructs the phrases. For example for the question in</context>
</contexts>
<marker>Forney, 1973</marker>
<rawString>GD. Forney. 1973. The viterbi algorithm. In Proc. of IEEE 61(3), pages 269–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Goldberg</author>
<author>X Zhu</author>
</authors>
<title>Keepin’ it real: Semisupervised learning with realistic tuning.</title>
<date>2009</date>
<booktitle>In Proc. of NAACL-09 Workshop on Semi-Supervised Learning for NLP.</booktitle>
<contexts>
<context position="1541" citStr="Goldberg and Zhu, 2009" startWordPosition="211" endWordPosition="214">in Question Answering (QA) is question understanding to identify semantic components of questions. In this paper, we investigate question understanding based on a machine learning approach to discover semantic components (Table 1). An important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (SSL) methods, e.g., (Belkin and Niyogi., 2002b), (Zhou et al., 2004). Recently, graph based SSL methods have gained interest (Alexandrescu and Kirchhoff, 2007), (Goldberg and Zhu, 2009). These methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points. Classification is performed using these graphs by scoring unlabeled points in such a way 27 Semantic Components &amp; Named-Entitiy Types topic: ’Jar’ (Begin-Topic); ’Jar’ (In-Topic) ; ’Binks’ (In-Topic)(HUMAN:Individual) focus: ’ilm’ (Begin-Focus) (DESCRIPTION:Deinition) action / event: ’introduced’ (Begin-Event) expected answer-type: ENTITY:creative Table 1: Question Analysis - Semantic Components of a sample question from TREC QA t</context>
</contexts>
<marker>Goldberg, Zhu, 2009</marker>
<rawString>A. Goldberg and X. Zhu. 2009. Keepin’ it real: Semisupervised learning with realistic tuning. In Proc. of NAACL-09 Workshop on Semi-Supervised Learning for NLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hajicova</author>
<author>P Sgall</author>
<author>H Skoumalova</author>
</authors>
<title>Identifying topic and focus by an automatic procedure.</title>
<date>1993</date>
<booktitle>In Proc. of the EACL-1993.</booktitle>
<marker>Hajicova, Sgall, Skoumalova, 1993</marker>
<rawString>E. Hajicova, P. Sgall, and H. Skoumalova. 1993. Identifying topic and focus by an automatic procedure. In Proc. of the EACL-1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Jebara</author>
<author>J Wang</author>
<author>S F Chang</author>
</authors>
<title>Graph construction and b-matching for semi-supervised learning.</title>
<date>2009</date>
<booktitle>In Proc. of ICML-09.</booktitle>
<contexts>
<context position="14141" citStr="Jebara et al., 2009" startWordPosition="2266" endWordPosition="2269">xi, xj) as weight measure (Zhou et al., 2004) wij wij = exp (− kxi − xjk /2σ2) (3) Secondly, based on chosen graph sparsification method, a sparse affinity matrix is obtained by removing edges that do not convey with neighborhood assumption. Usually a k-nearest neighbor (kNN) or E neighbor (EN) methods are used for sparsification. Graph formation is crucial in graph based SSL since sparsity ensures that the predicted model remains efficient and robust to noise, e.g., especially in text processing noise is inevitable. EN graphs provide weaker performance than the k-nearest neighborhood graphs (Jebara et al., 2009). In addition, the issue with kNN sparsification of graph is that the number of neighbors is fixed at the start, which may cause fault neighborhood assumptions even when neighbors are far apart. Additionally, kernel similarity functions may not rate edge weights because they might be useful locally but not quite efficient when nodes are far apart. Next, we present Relaxed Linear Neighborhoods to address these issues. 5 Relaxed Linear Neighborhoods (RLN) Instead of measuring pairwise relations (3), we use neighborhood information to construct G. When building a sparse affinity matrix, we re-con</context>
<context position="22715" citStr="Jebara et al., 2009" startWordPosition="3791" endWordPosition="3794"> (18): ( )−1 Y f* = (1 − λ) Z − λ W� (19) Most graph-based SSLs are transductive, i.e., not easily expendable to new testing points. In (Delalleau et al., 2005) an induction scheme is proposed to classify a new point xTe by �f(xTe) = EiELUU �Wxifi/EiELUU �Wxi (20) Thus, we use induction, where we can, to avoid reconstruction of the graph for new test points. 7 Experiments and Discussions In the next, we evaluate the performance of the proposed RLN in comparison to the other methods on syntactic and real datasets. Exp. 1. Graph Construction Performance: Here we use a similar syntactic data in (Jebara et al., 2009) shown in Fig.2.a, which contains two clusters of dissimilar densities and shapes. We investigate three graph construction methods, linear k-neighborhoods of (Roweis and Saul, 2000) in Fig.2.b, b-matching(Jebara et al., 2009) in Fig.2.c and RLN of this work in Fig.2.d using a dataset of 300 points with binary output values. b-matching permits a given datum to select k neighboring points but also ensures that exactly k points selects given datum as their neighbor. In each graph construction method Gaussian kernel distance is used. Experiments are run 50 times where at each fold only 2 labeled s</context>
</contexts>
<marker>Jebara, Wang, Chang, 2009</marker>
<rawString>T. Jebara, J. Wang, and S.F. Chang. 2009. Graph construction and b-matching for semi-supervised learning. In Proc. of ICML-09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Meeting of the ACL-2003,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="9021" citStr="Klein and Manning, 2003" startWordPosition="1380" endWordPosition="1383">y, only one node per token is introduced to the graph for known(true) token/label relations. We find the best question label sequence via Viterbi algorithm (Forney, 1973). 3.1 Feature Extraction For Labeling Task The following pre-processing modules are built for feature extraction prior to graph construction. 3.1.1 Pre-Processing For Feature Extraction Phrase Analysis(PA): Using basic syntactic analysis (shallow parsing), the PA module re-builds phrases from linguistic structures such as nounphrases (NN), basic prepositional phrases (PP) or verb groups (VG). Using Stanford dependency parser (Klein and Manning, 2003), (Marneffe et al., 2006), which produces 48 different grammatical relations, PA module re-constructs the phrases. For example for the question in Table 1, dependency parser generates two relations: − nn(Binks-3, Jar-1) and nn(Binks-3, Jar-2), PA reveals ”Jar Jar Binks” as a noun phrase reconstructing the nn:noun compound modifier. We also extract part of speech tags of questions via dependency parser to be used for feature extraction. Question Dependency Relations (QDR): Using shallow semantics, we decode underlying Stanford dependency trees (Marneffe et al., 2006) that embody linguistic rela</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Meeting of the ACL-2003, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proc. of 18th International Conf. on Machine Learning (ICML’01).</booktitle>
<contexts>
<context position="7280" citStr="Lafferty et al., 2001" startWordPosition="1089" endWordPosition="1093">E:in-event such as question type, event, entities, etc. (Chai and (8) BCL:begin-clause Jin, 2004) explored semantic units based on their (9) ICL:in-clause discourse relations via rule-based systems. (10) BC:begin-complement In (Duan et al., 2008) a language model is pre- (11) IC:in-complement sented to extract semantic components from ques- More labels can be appended if necessary. The first tions. Similarly, (Fan et al., 2008)’s semantic chunk token of a component gets ’begin’ prefix and conannotation uses conditional random fields (CRF) secutive words are given ’in’ prefix, e.g., Jar (begin(Lafferty et al., 2001) to annotate semantic chunks topic), Jar (in-topic), Binks (in-topic) in Table 1. of questions in Chinese. Our work aparts from In graph-based SSL methods, a graph is conthese studies in that we use a graph-based SSL structed !9 = (V, £), where V = X is a vertex set, method to extract semantic components from unla- £ is an edge set, associated with each edge eij rep28 resents a relation between xi and xj. The task is to assign a label (out of 11 possible labels) to each token of a question i, xti, t = 1, ..., T, T is the max number of tokens in a given query. We introduce a set of nodes for ea</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J.D. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. of 18th International Conf. on Machine Learning (ICML’01).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Maier</author>
<author>U V Luxburg</author>
</authors>
<title>Influence of graph construction on graph-based clustering measures.</title>
<date>2008</date>
<booktitle>In Proc. of Neural Infor. Proc. Sys. (NIPS</booktitle>
<contexts>
<context position="2621" citStr="Maier and Luxburg, 2008" startWordPosition="367" endWordPosition="370">oduced’ (Begin-Event) expected answer-type: ENTITY:creative Table 1: Question Analysis - Semantic Components of a sample question from TREC QA task. that instances connected by large weights are given similar labels. Such methods can perform well when no parametric information about distribution of data is available and when data is characterized by an underlying manifold structure. In this paper, we present a semantic component labeling module for our QA system using a new graph-based SSL to benefit from unlabeled questions. One of the issues affecting the performance of graph-based methods (Maier and Luxburg, 2008) is that there is no reliable approach for model selection when there are too few labeled points (Zhou et al., 2004). Such issues have only recently came into focus (Wang and Zhang, 2006). This is somewhat surprising because graph construction is a fundamental step. Rather than proposing yet another learning algorithm, we focus on graph construction for our labeling task, which suffers from insufficient graph sparsification methods. Such problems are caused by fixed neighborhood assignments in k-nearest neighbor approaches, treating sparse and denser regions of data equally or using improper t</context>
</contexts>
<marker>Maier, Luxburg, 2008</marker>
<rawString>M. Maier and U.V. Luxburg. 2008. Influence of graph construction on graph-based clustering measures. In Proc. of Neural Infor. Proc. Sys. (NIPS 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C D Marneffe</author>
<author>B MacCartney</author>
<author>C D Manning</author>
</authors>
<title>Generating typed-dependency parsers from phrase structure parsers. In</title>
<date>2006</date>
<booktitle>In LREC2006.</booktitle>
<contexts>
<context position="9046" citStr="Marneffe et al., 2006" startWordPosition="1384" endWordPosition="1387">is introduced to the graph for known(true) token/label relations. We find the best question label sequence via Viterbi algorithm (Forney, 1973). 3.1 Feature Extraction For Labeling Task The following pre-processing modules are built for feature extraction prior to graph construction. 3.1.1 Pre-Processing For Feature Extraction Phrase Analysis(PA): Using basic syntactic analysis (shallow parsing), the PA module re-builds phrases from linguistic structures such as nounphrases (NN), basic prepositional phrases (PP) or verb groups (VG). Using Stanford dependency parser (Klein and Manning, 2003), (Marneffe et al., 2006), which produces 48 different grammatical relations, PA module re-constructs the phrases. For example for the question in Table 1, dependency parser generates two relations: − nn(Binks-3, Jar-1) and nn(Binks-3, Jar-2), PA reveals ”Jar Jar Binks” as a noun phrase reconstructing the nn:noun compound modifier. We also extract part of speech tags of questions via dependency parser to be used for feature extraction. Question Dependency Relations (QDR): Using shallow semantics, we decode underlying Stanford dependency trees (Marneffe et al., 2006) that embody linguistic relationships such as head-su</context>
</contexts>
<marker>Marneffe, MacCartney, Manning, 2006</marker>
<rawString>M.-C.D. Marneffe, B. MacCartney, and C.D. Manning. 2006. Generating typed-dependency parsers from phrase structure parsers. In In LREC2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S T Roweis</author>
<author>L K Saul</author>
</authors>
<title>Nonlinear dimensionality reduction by locally embedding.</title>
<date>2000</date>
<journal>In Science,</journal>
<volume>290</volume>
<pages>2323--2326</pages>
<contexts>
<context position="14862" citStr="Roweis and Saul, 2000" startWordPosition="2378" endWordPosition="2381">at the start, which may cause fault neighborhood assumptions even when neighbors are far apart. Additionally, kernel similarity functions may not rate edge weights because they might be useful locally but not quite efficient when nodes are far apart. Next, we present Relaxed Linear Neighborhoods to address these issues. 5 Relaxed Linear Neighborhoods (RLN) Instead of measuring pairwise relations (3), we use neighborhood information to construct G. When building a sparse affinity matrix, we re-construct each node using a linear combination of its neighbors, similar to Locally Linear Embedding (Roweis and Saul, 2000) and Linear Neighborhoods (Wang and Zhang, 2006), and minimize: min Ei ||xi − Ej:xjEAr(xi) wijxj||2 (4) where N(xi) is neighborhood of xi, and wij is the degree of contribution of xj to xi. In (4) each node can be optimally reconstructed using a linear combination of its neighborhood (Roweis and Saul, 2000). However, having fixed k neighbors at start of the algorithm can effect generalization of classifier and can also cause confusion on different manifolds. We present novel RLN method to reconstruct each object (node) by using dynamic neighborhood information, as opposed to fixed k neighbors </context>
<context position="19124" citStr="Roweis and Saul, 2000" startWordPosition="3111" endWordPosition="3114">nough number of nodes in the E vicinity (&gt; k), then the boundary is identified. Otherwise we use kNN. Boundary set of an |NE(xi)| Nxi;k(xj)∈{0,1} y xi is defined as: tan ces to neighbor points based on parameter k &gt; 0: 1 The new boundary set of an y given xi includes: B(xi) In the experiments, we tested our RLN approach (9), 0 &lt; &lt; 1 for boundary detection, in comparison to the static neighborhood assignments where the number of neighbors, k is fixed. (3) Graph Formation: Instead of measuring pairwise relations as in (3), we use neighborhood information to represent In an analogical manner to (Roweis and Saul, 2000), (Wang and Zhang, 2006), for graph sparcification, for our Relaxed Linear Neighborhood, we re-construct each node using a li Nxi(xj) G. near combination of its dynamic neighbors: min s.t. (13) where 0 &lt; &lt; 1 is the degree of neighborhood to boundary set and is degree of contribution of xj to xi, to be predicted. A = 0 means no edge link. To prevent negative weights, and satisfy their normalization to unity, we used a constraint in (13) for RLN. Edge weights of are found using above relaxed boundary assumption, an Nxi(xj) B(xi) wij Nxi(xj) G d relaxed neighborhood 1 |NE(xi) |&gt; k j Nxi;k(x ) oth</context>
<context position="22896" citStr="Roweis and Saul, 2000" startWordPosition="3817" endWordPosition="3820">e is proposed to classify a new point xTe by �f(xTe) = EiELUU �Wxifi/EiELUU �Wxi (20) Thus, we use induction, where we can, to avoid reconstruction of the graph for new test points. 7 Experiments and Discussions In the next, we evaluate the performance of the proposed RLN in comparison to the other methods on syntactic and real datasets. Exp. 1. Graph Construction Performance: Here we use a similar syntactic data in (Jebara et al., 2009) shown in Fig.2.a, which contains two clusters of dissimilar densities and shapes. We investigate three graph construction methods, linear k-neighborhoods of (Roweis and Saul, 2000) in Fig.2.b, b-matching(Jebara et al., 2009) in Fig.2.c and RLN of this work in Fig.2.d using a dataset of 300 points with binary output values. b-matching permits a given datum to select k neighboring points but also ensures that exactly k points selects given datum as their neighbor. In each graph construction method Gaussian kernel distance is used. Experiments are run 50 times where at each fold only 2 labeled samples from opposite classes are used to predict the rest. The experiments are repeated for different k, b and E values. In Fig. 2, average of trials is shown when k, b are 10 and E</context>
</contexts>
<marker>Roweis, Saul, 2000</marker>
<rawString>S.T. Roweis and L.K. Saul. 2000. Nonlinear dimensionality reduction by locally embedding. In Science, volume 290, pages 2323–2326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wang</author>
<author>C Zhang</author>
</authors>
<title>Label propagation through linear neighborhoods.</title>
<date>2006</date>
<booktitle>In Proc. of the ICML-2006.</booktitle>
<contexts>
<context position="2808" citStr="Wang and Zhang, 2006" startWordPosition="401" endWordPosition="404"> are given similar labels. Such methods can perform well when no parametric information about distribution of data is available and when data is characterized by an underlying manifold structure. In this paper, we present a semantic component labeling module for our QA system using a new graph-based SSL to benefit from unlabeled questions. One of the issues affecting the performance of graph-based methods (Maier and Luxburg, 2008) is that there is no reliable approach for model selection when there are too few labeled points (Zhou et al., 2004). Such issues have only recently came into focus (Wang and Zhang, 2006). This is somewhat surprising because graph construction is a fundamental step. Rather than proposing yet another learning algorithm, we focus on graph construction for our labeling task, which suffers from insufficient graph sparsification methods. Such problems are caused by fixed neighborhood assignments in k-nearest neighbor approaches, treating sparse and denser regions of data equally or using improper threshold assumptions in c-neighborhood What |{z } other |{z } introduced event |Jar Jar Bink {z topic film |{z } focus Proceedings of the NAACL HLT 2010 Workshop on Semantic Search, pages</context>
<context position="14910" citStr="Wang and Zhang, 2006" startWordPosition="2385" endWordPosition="2388">assumptions even when neighbors are far apart. Additionally, kernel similarity functions may not rate edge weights because they might be useful locally but not quite efficient when nodes are far apart. Next, we present Relaxed Linear Neighborhoods to address these issues. 5 Relaxed Linear Neighborhoods (RLN) Instead of measuring pairwise relations (3), we use neighborhood information to construct G. When building a sparse affinity matrix, we re-construct each node using a linear combination of its neighbors, similar to Locally Linear Embedding (Roweis and Saul, 2000) and Linear Neighborhoods (Wang and Zhang, 2006), and minimize: min Ei ||xi − Ej:xjEAr(xi) wijxj||2 (4) where N(xi) is neighborhood of xi, and wij is the degree of contribution of xj to xi. In (4) each node can be optimally reconstructed using a linear combination of its neighborhood (Roweis and Saul, 2000). However, having fixed k neighbors at start of the algorithm can effect generalization of classifier and can also cause confusion on different manifolds. We present novel RLN method to reconstruct each object (node) by using dynamic neighborhood information, as opposed to fixed k neighbors of (Wang and Zhang, 2006). RLN approximates enti</context>
<context position="19148" citStr="Wang and Zhang, 2006" startWordPosition="3115" endWordPosition="3118">the E vicinity (&gt; k), then the boundary is identified. Otherwise we use kNN. Boundary set of an |NE(xi)| Nxi;k(xj)∈{0,1} y xi is defined as: tan ces to neighbor points based on parameter k &gt; 0: 1 The new boundary set of an y given xi includes: B(xi) In the experiments, we tested our RLN approach (9), 0 &lt; &lt; 1 for boundary detection, in comparison to the static neighborhood assignments where the number of neighbors, k is fixed. (3) Graph Formation: Instead of measuring pairwise relations as in (3), we use neighborhood information to represent In an analogical manner to (Roweis and Saul, 2000), (Wang and Zhang, 2006), for graph sparcification, for our Relaxed Linear Neighborhood, we re-construct each node using a li Nxi(xj) G. near combination of its dynamic neighbors: min s.t. (13) where 0 &lt; &lt; 1 is the degree of neighborhood to boundary set and is degree of contribution of xj to xi, to be predicted. A = 0 means no edge link. To prevent negative weights, and satisfy their normalization to unity, we used a constraint in (13) for RLN. Edge weights of are found using above relaxed boundary assumption, an Nxi(xj) B(xi) wij Nxi(xj) G d relaxed neighborhood 1 |NE(xi) |&gt; k j Nxi;k(x ) otherwise Nxi;k,E(xj) =( ) </context>
</contexts>
<marker>Wang, Zhang, 2006</marker>
<rawString>F. Wang and C. Zhang. 2006. Label propagation through linear neighborhoods. In Proc. of the ICML-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dengyong Zhou</author>
<author>Olivier Bousquet</author>
<author>Thomas N Lal</author>
<author>Jason Weston</author>
<author>Bernhard Scholkopf</author>
</authors>
<title>Learning with local and global consistency.</title>
<date>2004</date>
<booktitle>Advances in Neural Information Processing Systems,</booktitle>
<pages>16--321</pages>
<contexts>
<context position="1424" citStr="Zhou et al., 2004" startWordPosition="195" endWordPosition="198">rily due to the use of unlabeled data and relaxed graph construction. 1 Introduction One of the important steps in Question Answering (QA) is question understanding to identify semantic components of questions. In this paper, we investigate question understanding based on a machine learning approach to discover semantic components (Table 1). An important issue in information extraction from text is that one often deals with insufficient labeled data and large number of unlabeled data, which have led to improvements in semi-supervised learning (SSL) methods, e.g., (Belkin and Niyogi., 2002b), (Zhou et al., 2004). Recently, graph based SSL methods have gained interest (Alexandrescu and Kirchhoff, 2007), (Goldberg and Zhu, 2009). These methods create graphs whose vertices correspond to labeled and unlabeled data, while the edge weights encode the similarity between each pair of data points. Classification is performed using these graphs by scoring unlabeled points in such a way 27 Semantic Components &amp; Named-Entitiy Types topic: ’Jar’ (Begin-Topic); ’Jar’ (In-Topic) ; ’Binks’ (In-Topic)(HUMAN:Individual) focus: ’ilm’ (Begin-Focus) (DESCRIPTION:Deinition) action / event: ’introduced’ (Begin-Event) expec</context>
<context position="2737" citStr="Zhou et al., 2004" startWordPosition="389" endWordPosition="392">uestion from TREC QA task. that instances connected by large weights are given similar labels. Such methods can perform well when no parametric information about distribution of data is available and when data is characterized by an underlying manifold structure. In this paper, we present a semantic component labeling module for our QA system using a new graph-based SSL to benefit from unlabeled questions. One of the issues affecting the performance of graph-based methods (Maier and Luxburg, 2008) is that there is no reliable approach for model selection when there are too few labeled points (Zhou et al., 2004). Such issues have only recently came into focus (Wang and Zhang, 2006). This is somewhat surprising because graph construction is a fundamental step. Rather than proposing yet another learning algorithm, we focus on graph construction for our labeling task, which suffers from insufficient graph sparsification methods. Such problems are caused by fixed neighborhood assignments in k-nearest neighbor approaches, treating sparse and denser regions of data equally or using improper threshold assumptions in c-neighborhood What |{z } other |{z } introduced event |Jar Jar Bink {z topic film |{z } foc</context>
<context position="13566" citStr="Zhou et al., 2004" startWordPosition="2172" endWordPosition="2175">iments we found that only a limited number of second order nodes are feasible. 4 Graph Construction for SSL Let XL = {x1, ..., xl} be labeled question tokens with associated labels YL = {y1, ..., yl}T and XU = {x1, ..., x,} be unlabeled tokens, X = XL ∪ XU. A weighted symmetric adjacency matrix W is formed in two steps with edges E in G where Wij ∈ &lt;nxn, and non-zero elements represent the edge weight between vi and vj. Firstly, similarity between each pair of nodes is obtained by a measure to create a full affinity matrix, A ∈ &lt;nxn, using a kernel function, Aij = k(xi, xj) as weight measure (Zhou et al., 2004) wij wij = exp (− kxi − xjk /2σ2) (3) Secondly, based on chosen graph sparsification method, a sparse affinity matrix is obtained by removing edges that do not convey with neighborhood assumption. Usually a k-nearest neighbor (kNN) or E neighbor (EN) methods are used for sparsification. Graph formation is crucial in graph based SSL since sparsity ensures that the predicted model remains efficient and robust to noise, e.g., especially in text processing noise is inevitable. EN graphs provide weaker performance than the k-nearest neighborhood graphs (Jebara et al., 2009). In addition, the issue </context>
<context position="21210" citStr="Zhou et al., 2004" startWordPosition="3515" endWordPosition="3518">gned. At each iteration, any given data point exploits a part of label information from its neighbors, which is determined by RLN. Thus, predicted label of a node xi at t+1: ft+1 i = λyi + (1 − λ) Ej Nxi(xj)wijftj (14) where xj E Bxi, 0&lt; λ &lt;1 sets a portion of label information that xi gets from its local neighbors, ft = (ft1, ft2, ..., ftn) is the prediction label vector at iteration t and f0 = y. We can re-state (14) as: ft+1 = λyi + (1 − λ)�Wft (15) Each node’s label is updated via (15) until convergence, which might be at t —* oc. In place of LP, we can develop a regularization framework (Zhou et al., 2004) to learn f. In graph-based SSL, a function over a graph is estimated to satisfy two conditions: (i) close to the observed labels , and (ii) be smooth on the whole graph via following loss function: arg min 2(f) = Eni=1 (fi − yi)2+ (16) λ En Ej:xjEt3(xi) φxi(xj) (fi, fj) i,j=1 where φxi(xj) = Nxi(xj)�wij. Setting gradient of loss function 2(f) to zero, we obtain: ∂f2(f) = 2(Y −f)+λ[(Z −-b)+(Z −.b)T]f (17) Relaxed weight matrix W is normalized according to constraint in (13), so as degree matrix, D = Ej Wij, and graph Laplacian, i.e., L = (D − ifold and the graph is discretized form of a manifo</context>
</contexts>
<marker>Zhou, Bousquet, Lal, Weston, Scholkopf, 2004</marker>
<rawString>Dengyong Zhou, Olivier Bousquet, Thomas N. Lal, Jason Weston, and Bernhard Scholkopf. 2004. Learning with local and global consistency. Advances in Neural Information Processing Systems, 16:321–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojin Zhu</author>
<author>John Lafferty</author>
<author>Zoubin Ghahramani</author>
</authors>
<title>Semi-supervised learning: From Gaussian Fields to Gaussian processes.</title>
<date>2003</date>
<tech>Technical Report CMUCS-03-175,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh.</location>
<contexts>
<context position="28269" citStr="Zhu et al., 2003" startWordPosition="4732" endWordPosition="4735">dual label performance using unlabeled data. Firstly, we randomly select subset of labeled training dataset, XiL C XL with different sample sizes, niL = 5% * nL, 10% * nL, 25% * nL, 50% * nL, 75% * nL, 100% * nL, where nL is the size of XL. Thus, instead of fixing the number of labeled records and varying the number of unlabeled points, we propose to fix the percentage of unlabeled points in training dataset. We hypothetically use unselected part of the labeled dataset as unlabeled data at each random selection. We compare the result of RLN to other graph based methods including standard SSL (Zhu et al., 2003) using kNN, and b-matching. We also build a CRF model using the same features as RLN except the output information, which CRF learns through probabilistic structure. In addition, we implemente self training for CRF (sCRF), most commonly known SSL method, by adding most confident (x, f(x)) unlabeled data back to the data and repeat the process 10 times. Table 3 reports average loss of question recognition tasks on testing dataset using these methods. When the number of labeled data is small (niL &lt; 25%nL), RLN has better performance compared to the rest (an average of 7% improvement). The SSL an</context>
</contexts>
<marker>Zhu, Lafferty, Ghahramani, 2003</marker>
<rawString>Xiaojin Zhu, John Lafferty, and Zoubin Ghahramani. 2003. Semi-supervised learning: From Gaussian Fields to Gaussian processes. Technical Report CMUCS-03-175, Carnegie Mellon University, Pittsburgh.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>