<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000041">
<title confidence="0.9973065">
Balancing User Effort and Translation Error in Interactive Machine
Translation Via Confidence Measures
</title>
<author confidence="0.712423">
Jes´us Gonz´alez-Rubio
</author>
<note confidence="0.6698105">
Inst. Tec. de Inform´atica
Univ. Polit´ec. de Valencia
</note>
<address confidence="0.6865">
46021 Valencia, Spain
</address>
<email confidence="0.990146">
jegonzalez@iti.upv.es
</email>
<author confidence="0.821514">
Daniel Ortiz-Martinez
</author>
<affiliation confidence="0.5822355">
Dpto. de Sist Inf. y Comp.
Univ. Polit´ec. de Valencia
</affiliation>
<address confidence="0.858107">
46021 Valencia, Spain
</address>
<email confidence="0.99078">
dortiz@dsic.upv.es
</email>
<author confidence="0.839335">
Francisco Casacuberta
</author>
<affiliation confidence="0.5985075">
Dpto. de Sist Inf. y Comp.
Univ. Polit´ec. de Valencia
</affiliation>
<address confidence="0.944179">
46021 Valencia, Spain
</address>
<email confidence="0.998315">
fcn@dsic.upv.es
</email>
<sectionHeader confidence="0.997372" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999901133333333">
This work deals with the application of
confidence measures within an interactive-
predictive machine translation system in
order to reduce human effort. If a small
loss in translation quality can be tolerated
for the sake of efficiency, user effort can
be saved by interactively translating only
those initial translations which the confi-
dence measure classifies as incorrect. We
apply confidence estimation as a way to
achieve a balance between user effort sav-
ings and final translation error. Empiri-
cal results show that our proposal allows
to obtain almost perfect translations while
significantly reducing user effort.
</bodyText>
<sectionHeader confidence="0.999346" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992279">
In Statistical Machine Translation (SMT), the
translation is modelled as a decission process. For
a given source string fJ1 = f1 ... fj ... fJ, we
seek for the target string eI1 =
</bodyText>
<equation confidence="0.849409">
e1 ... ei ... eI
which maximises posterior probability:
Pr(eI1|fJ1 ) . (1)
</equation>
<bodyText confidence="0.999771538461538">
Within the Interactive-predictive Machine
Translation (IMT) framework, a state-of-the-art
SMT system is employed in the following way:
For a given source sentence, the SMT system
fully automatically generates an initial translation.
A human translator checks this translation from
left to right, correcting the first error. The SMT
system then proposes a new extension, taking the
correct prefix ei1 = e1 ... ei into account. These
steps are repeated until the whole input sentence
has been correctly translated. In the resulting
decision rule, we maximise over all possible
extensions eIi+1 of ei 1:
</bodyText>
<equation confidence="0.454669">
�ei+1 =ˆI argmax Pr(eIi+1|ei1, fJ1 ) . (2)
</equation>
<page confidence="0.425875">
I,ei+1
</page>
<bodyText confidence="0.99984025">
An implementation of the IMT famework was
performed in the TransType project (Foster et al.,
1997; Langlais et al., 2002) and further improved
within the TransType2 project (Esteban et al.,
2004; Barrachina et al., 2009).
IMT aims at reducing the effort and increas-
ing the productivity of translators, while preserv-
ing high-quality translation. In this work, we inte-
grate Confidence Measures (CMs) within the IMT
framework to further reduce the user effort. As
will be shown, our proposal allows to balance the
ratio between user effort and final translation error.
</bodyText>
<subsectionHeader confidence="0.99813">
1.1 Confidence Measures
</subsectionHeader>
<bodyText confidence="0.999852176470588">
Confidence estimation have been extensively stud-
ied for speech recognition. Only recently have re-
searchers started to investigate CMs for MT (Gan-
drabur and Foster, 2003; Blatz et al., 2004; Ueffing
and Ney, 2007).
Different TransType-style MT systems use con-
fidence information to improve translation predic-
tion accuracy (Gandrabur and Foster, 2003; Ueff-
ing and Ney, 2005). In this work, we propose a fo-
cus shift in which CMs are used to modify the in-
teraction between the user and the system instead
of modify the IMT translation predictions.
To compute CMs we have to select suitable con-
fidence features and define a binary classifier. Typ-
ically, the classification is carried out depending
on whether the confidence value exceeds a given
threshold or not.
</bodyText>
<sectionHeader confidence="0.966923" genericHeader="method">
2 IMT with Sentence CMs
</sectionHeader>
<bodyText confidence="0.997476875">
In the conventional IMT scenario a human trans-
lator and a SMT system collaborate in order to
obtain the translation the user has in mind. Once
the user has interactively translated the source sen-
tences, the output translations are error-free. We
propose an alternative scenario where not all the
source sentences are interactively translated by the
user. Specifically, only those source sentences
</bodyText>
<equation confidence="0.994071">
�e1 = argmax
ˆI
I,ei
</equation>
<page confidence="0.967215">
173
</page>
<note confidence="0.4998335">
Proceedings of the ACL 2010 Conference Short Papers, pages 173–177,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999977068965517">
whose initial fully automatic translation are incor-
rect, according to some quality criterion, are in-
teractively translated. We propose to use CMs as
the quality criterion to classify those initial trans-
lations.
Our approach implies a modification of the
user-machine interaction protocol. For a given
source sentence, the SMT system generates an ini-
tial translation. Then, if the CM classifies this
translation as correct, we output it as our final
translation. On the contrary, if the initial trans-
lation is classified as incorrect, we perform a con-
ventional IMT procedure, validating correct pre-
fixes and generating new suffixes, until the sen-
tence that the user has in mind is reached.
In our scenario, we allow the final translations
to be different from the ones the user has in mind.
This implies that the output may contain errors.
If a small loss in translation can be tolerated for
the sake of efficiency, user effort can be saved by
interactively translating only those sentences that
the CMs classify as incorrect.
It is worth of notice that our proposal can be
seen as a generalisation of the conventional IMT
approach. Varying the value of the CM classifi-
cation threshold, we can range from a fully auto-
matic SMT system where all sentences are clas-
sified as correct to a conventional IMT system
where all sentences are classified as incorrect.
</bodyText>
<subsectionHeader confidence="0.998746">
2.1 Selecting a CM for IMT
</subsectionHeader>
<bodyText confidence="0.999945">
We compute sentence CMs by combining the
scores given by a word CM based on the IBM
model 1 (Brown et al., 1993), similar to the one
described in (Blatz et al., 2004). We modified this
word CM by replacing the average by the max-
imal lexicon probability, because the average is
dominated by this maximum (Ueffing and Ney,
2005). We choose this word CM because it can be
calculated very fast during search, which is cru-
cial given the time constraints of the IMT sys-
tems. Moreover, its performance is similar to that
of other word CMs as results presented in (Blatz
et al., 2003; Blatz et al., 2004) show. The word
confidence value of word ei, cw(ei), is given by
</bodyText>
<equation confidence="0.9644665">
cw(ei) = max p(eilfj) , (3)
0&lt;j&lt;J
</equation>
<bodyText confidence="0.999639">
where p(eiIfj) is the IBM model 1 lexicon proba-
bility, and f0 is the empty source word.
From this word CM, we compute two sentence
CMs which differ in the way the word confidence
</bodyText>
<table confidence="0.9992208">
Spanish English
Train Sentences 214.5K
Running words 5.8M 5.2M
Vocabulary 97.4K 83.7K
Dev. Sentences 400
Running words 11.5K 10.1K
Perplexity (trigrams) 46.1 59.4
Test Sentences 800
Running words 22.6K 19.9K
Perplexity (trigrams) 45.2 60.8
</table>
<tableCaption confidence="0.839022666666667">
Table 1: Statistics of the Spanish–English EU cor-
pora. K and M denote thousands and millions of
elements respectively.
</tableCaption>
<bodyText confidence="0.88417375">
scores cw(ei) are combined:
MEAN CM (cM(eI1)) is computed as the geo-
metric mean of the confidence scores of the
words in the sentence:
</bodyText>
<equation confidence="0.9990425">
� cM(eI1) = z I cw(ei) . (4)
i=1
</equation>
<bodyText confidence="0.9440476">
RATIO CM (cR(eI1)) is computed as the percent-
age of words classified as correct in the sen-
tence. A word is classified as correct if
its confidence exceeds a word classification
threshold Tw.
</bodyText>
<equation confidence="0.995003">
cR(eI1) = Ilei / cw(ei) &gt; Twjl (5)
I
</equation>
<bodyText confidence="0.999916428571429">
After computing the confidence value, each sen-
tence is classified as either correct or incorrect, de-
pending on whether its confidence value exceeds
or not a sentence clasiffication threshold Ts. If
Ts = 0.0 then all the sentences will be classified
as correct whereas if Ts = 1.0 all the sentences
will be classified as incorrect.
</bodyText>
<sectionHeader confidence="0.999293" genericHeader="method">
3 Experimentation
</sectionHeader>
<bodyText confidence="0.99997975">
The aim of the experimentation was to study the
possibly trade-off between saved user effort and
translation error obtained when using sentence
CMs within the IMT framework.
</bodyText>
<subsectionHeader confidence="0.997972">
3.1 System evaluation
</subsectionHeader>
<bodyText confidence="0.9831245">
In this paper, we report our results as measured
by Word Stroke Ratio (WSR) (Barrachina et al.,
2009). WSR is used in the context of IMT to mea-
sure the effort required by the user to generate her
</bodyText>
<page confidence="0.983588">
174
</page>
<figure confidence="0.999614">
WSR
100
40
20
80
60
0 0
0 0.2 0.4 0.6 0.8 1
WSR IMT-CM
BLEU IMT-CM
WSR IMT
BLEU SMT
40
20
80
60
100
BLEU
WSR
100
40
20
80
60
0 0
0 0.2 0.4 0.6 0.8 1
WSR IMT-CM (iw=0.4)
BLEU IMT-CM (iw=0.4)
WSR IMT
BLEU SMT
40
20
80
60
100
BLEU
Threshold (is)
</figure>
<figureCaption confidence="0.999777">
Figure 1: BLEU translation scores versus WSR
</figureCaption>
<bodyText confidence="0.958029705882353">
for different values of the sentence classification
threshold using the MEAN CM.
translations. WSR is computed as the ratio be-
tween the number of word-strokes a user would
need to achieve the translation she has in mind and
the total number of words in the sentence. In this
context, a word-stroke is interpreted as a single ac-
tion, in which the user types a complete word, and
is assumed to have constant cost.
Additionally, and because our proposal allows
differences between its output and the reference
translation, we will also present translation qual-
ity results in terms of BiLingual Evaluation Un-
derstudy (BLEU) (Papineni et al., 2002). BLEU
computes a geometric mean of the precision of n-
grams multiplied by a factor to penalise short sen-
tences.
</bodyText>
<subsectionHeader confidence="0.994979">
3.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.996895166666667">
Our experiments were carried out on the EU cor-
pora (Barrachina et al., 2009). The EU corpora
were extracted from the Bulletin of the European
Union. The EU corpora is composed of sentences
given in three different language pairs. Here, we
will focus on the Spanish–English part of the EU
corpora. The corpus is divided into training, de-
velopment and test sets. The main figures of the
corpus can be seen in Table 1.
As a first step, be built a SMT system to trans-
late from Spanish into English. This was done
by means of the Thot toolkit (Ortiz et al., 2005),
which is a complete system for building phrase-
based SMT models. This toolkit involves the esti-
mation, from the training set, of different statisti-
cal models, which are in turn combined in a log-
linear fashion by adjusting a weight for each of
them by means of the MERT (Och, 2003) proce-
</bodyText>
<figure confidence="0.473014">
Threshold (is)
</figure>
<figureCaption confidence="0.852113">
Figure 2: BLEU translation scores versus WSR
</figureCaption>
<bodyText confidence="0.969674555555556">
for different values of the sentence classification
threshold using the RATIO CM with r,,, = 0.4.
dure, optimising the BLEU score on the develop-
ment set.
The IMT system which we have implemented
relies on the use of word graphs (Ueffing et al.,
2002) to efficiently compute the suffix for a given
prefix. A word graph has to be generated for each
sentence to be interactively translated. For this
purpose, we used a multi-stack phrase-based de-
coder which will be distributed in the near future
together with the Thot toolkit. We discarded to
use the state-of-the-art Moses toolkit (Koehn et
al., 2007) because preliminary experiments per-
formed with it revealed that the decoder by Ortiz-
Martinez et al. (2005) performs better in terms of
WSR when used to generate word graphs for their
use in IMT (Sanchis-Trilles et al., 2008). More-
over, the performance difference in regular SMT is
negligible. The decoder was set to only consider
monotonic translation, since in real IMT scenar-
ios considering non-monotonic translation leads to
excessive response time for the user.
Finally, the obtained word graphs were used
within the IMT procedure to produce the refer-
ence translations in the test set, measuring WSR
and BLEU.
</bodyText>
<subsectionHeader confidence="0.892687">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.999969875">
We carried out a series of experiments ranging the
value of the sentence classification threshold rs,
between 0.0 (equivalent to a fully automatic SMT
system) and 1.0 (equivalent to a conventional IMT
system), for both the MEAN and RATIO CMs.
For each threshold value, we calculated the effort
of the user in terms of WSR, and the translation
quality of the final output as measured by BLEU.
</bodyText>
<page confidence="0.995398">
175
</page>
<note confidence="0.986869166666667">
src-1 DECLARACI ´ON (No 17) relativa al derecho de acceso a la informaci´on
ref-1 DECLARATION (No 17) on the right of access to information
tra-1 DECLARATION (No 17) on the right of access to information
src-2 Conclusiones del Consejo sobre el comercio electr´onico y los impuestos indirectos.
ref-2 Council conclusions on electronic commerce and indirect taxation.
tra-2 Council conclusions on e-commerce and indirect taxation.
</note>
<tableCaption confidence="0.737283">
src-3 participaci´on de los paises candidatos en los programas comunitarios.
ref-3 participation of the applicant countries in Community programmes.
tra-3 countries’ involvement in Community programmes.
Example 1: Examples of initial fully automatically generated sentences classified as correct by the CMs.
</tableCaption>
<bodyText confidence="0.99755582">
Figure 1 shows WSR (WSR IMT-CM) and
BLEU (BLEU IMT-CM) scores obtained varying
τ3 for the MEAN CM. Additionally, we also show
the BLEU score (BLEU SMT) obtained by a fully
automatic SMT system as translation quality base-
line, and the WSR score (WSR IMT) obtained by
a conventional IMT system as user effort baseline.
This figure shows a continuous transition between
the fully automatic SMT system and the conven-
tional IMT system. This transition occurs when
ranging τ3 between 0.0 and 0.6. This is an unde-
sired effect, since for almost a half of the possible
values for τ3 there is no change in the behaviour
of our proposed IMT system.
The RATIO CM confidence values depend on
a word classification threshold τ,,,. We have car-
ried out experimentation ranging τ,,, between 0.0
and 1.0 and found that this value can be used to
solve the above mentioned undesired effect for
the MEAN CM. Specifically, varying the value of
τ,,, we can stretch the interval in which the tran-
sition between the fully automatic SMT system
and the conventional IMT system is produced, al-
lowing us to obtain smother transitions. Figure 2
shows WSR and BLEU scores for different val-
ues of the sentence classification threshold τ3 us-
ing τ,,, = 0.4. We show results only for this value
of τ,,, due to paper space limitations and because
τ,,, = 0.4 produced the smoothest transition. Ac-
cording to Figure 2, using a sentence classification
threshold value of 0.6 we obtain a WSR reduction
of 20% relative and an almost perfect translation
quality of 87 BLEU points.
It is worth of notice that the final translations
are compared with only one reference, therefore,
the reported translation quality scores are clearly
pessimistic. Better results are expected using a
multi-reference corpus. Example 1 shows the
source sentence (src), the reference translation
(ref) and the final translation (tra) for three of the
initial fully automatically generated translations
that were classified as correct by our CMs, and
thus, were not interactively translated by the user.
The first translation (tra-1) is identical to the corre-
sponding reference translation (ref-1). The second
translation (tra-2) corresponds to a correct trans-
lation of the source sentence (src-2) that is differ-
ent from the corresponding reference (ref-2). Fi-
nally, the third translation (tra-3) is an example of
a slightly incorrect translation.
</bodyText>
<sectionHeader confidence="0.990975" genericHeader="method">
4 Concluding Remarks
</sectionHeader>
<bodyText confidence="0.9999722">
In this paper, we have presented a novel proposal
that introduces sentence CMs into an IMT system
to reduce user effort. Our proposal entails a mod-
ification of the user-machine interaction protocol
that allows to achieve a balance between the user
effort and the final translation error.
We have carried out experimentation using two
different sentence CMs. Varying the value of
the sentence classification threshold, we can range
from a fully automatic SMT system to a conven-
tional IMT system. Empirical results show that
our proposal allows to obtain almost perfect trans-
lations while significantly reducing user effort.
Future research aims at the investigation of im-
proved CMs to be integrated in our IMT system.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998271">
Work supported by the EC (FEDER/FSE) and
the Spanish MEC/MICINN under the MIPRCV
“Consolider Ingenio 2010” program (CSD2007-
00018), the iTransDoc (TIN2006-15694-CO2-01)
and iTrans2 (TIN2009-14511) projects and the
FPU scholarship AP2006-00691. Also supported
by the Spanish MITyC under the erudito.com
(TSI-020110-2009-439) project and by the Gener-
alitat Valenciana under grant Prometeo/2009/014.
</bodyText>
<page confidence="0.998128">
176
</page>
<sectionHeader confidence="0.996361" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999916254237288">
S. Barrachina, O. Bender, F. Casacuberta, J. Civera,
E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Tom´as,
and E. Vidal. 2009. Statistical approaches to
computer-assisted translation. Computational Lin-
guistics, 35(1):3–28.
J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,
C. Goutte, A. Kulesza, A. Sanchis, and N. Ueffing.
2003. Confidence estimation for machine transla-
tion.
J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur,
C. Goutte, A. Kuesza, A. Sanchis, and N. Ueffing.
2004. Confidence estimation for machine transla-
tion. In Proc. COLING, page 315.
P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and
R. L. Mercer. 1993. The Mathematics of Statistical
Machine Translation: Parameter Estimation. Com-
putational Linguistics, 19(2):263–311.
J. Esteban, J. Lorenzo, A. Valderr´abanos, and G. La-
palme. 2004. Transtype2: an innovative computer-
assisted translation system. In Proc. ACL, page 1.
G. Foster, P. Isabelle, and P. Plamondon. 1997. Target-
text mediated interactive machine translation. Ma-
chine Translation, 12:12–175.
S. Gandrabur and G. Foster. 2003. Confidence esti-
mation for text prediction. In Proc. CoNLL, pages
315–321.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: Open source toolkit
for statistical machine translation. In Proc. ACL,
pages 177–180.
P. Langlais, G. Lapalme, and M. Loranger. 2002.
Transtype: Development-evaluation cycles to boost
translator’s productivity. Machine Translation,
15(4):77–98.
F. J. Och. 2003. Minimum error rate training in statis-
tical machine translation. In Proc. ACL, pages 160–
167.
D. Ortiz, I. Garcia-Varea, and F. Casacuberta. 2005.
Thot: a toolkit to train phrase-based statistical trans-
lation models. In Proc. MT Summit, pages 141–148.
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of MT.
In Proc. ACL, pages 311–318.
G. Sanchis-Trilles, D. Ortiz-Martinez, J. Civera,
F. Casacuberta, E. Vidal, and H. Hoang. 2008. Im-
proving interactive machine translation via mouse
actions. In Proc. EMNLP, pages 25–27.
N. Ueffing and H. Ney. 2005. Application of word-
level confidence measures in interactive statistical
machine translation. In Proc. EAMT, pages 262–
270.
N. Ueffing and H. Ney. 2007. Word-level confidence
estimation for machine translation. Comput. Lin-
guist., 33(1):9–40.
N. Ueffing, F.J. Och, and H. Ney. 2002. Generation
of word graphs in statistical machine translation. In
Proc. EMNLP, pages 156–163.
</reference>
<page confidence="0.997727">
177
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.858803">
<title confidence="0.9992945">Balancing User Effort and Translation Error in Interactive Machine Translation Via Confidence Measures</title>
<author confidence="0.999876">Jes´us Gonz´alez-Rubio</author>
<affiliation confidence="0.992582">Inst. Tec. de Inform´atica Univ. Polit´ec. de Valencia</affiliation>
<address confidence="0.999842">46021 Valencia, Spain</address>
<email confidence="0.962298">jegonzalez@iti.upv.es</email>
<author confidence="0.997844">Daniel Ortiz-Martinez</author>
<affiliation confidence="0.9942895">Dpto. de Sist Inf. y Comp. Univ. Polit´ec. de Valencia</affiliation>
<address confidence="0.99984">46021 Valencia, Spain</address>
<email confidence="0.946915">dortiz@dsic.upv.es</email>
<author confidence="0.99656">Francisco Casacuberta</author>
<affiliation confidence="0.9934535">Dpto. de Sist Inf. y Comp. Univ. Polit´ec. de Valencia</affiliation>
<address confidence="0.999739">46021 Valencia, Spain</address>
<email confidence="0.995454">fcn@dsic.upv.es</email>
<abstract confidence="0.9994634375">This work deals with the application of confidence measures within an interactivepredictive machine translation system in order to reduce human effort. If a small loss in translation quality can be tolerated for the sake of efficiency, user effort can be saved by interactively translating only those initial translations which the confidence measure classifies as incorrect. We apply confidence estimation as a way to achieve a balance between user effort savings and final translation error. Empirical results show that our proposal allows to obtain almost perfect translations while significantly reducing user effort.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Barrachina</author>
<author>O Bender</author>
<author>F Casacuberta</author>
<author>J Civera</author>
<author>E Cubel</author>
<author>S Khadivi</author>
<author>A Lagarda</author>
<author>H Ney</author>
<author>J Tom´as</author>
<author>E Vidal</author>
</authors>
<title>Statistical approaches to computer-assisted translation.</title>
<date>2009</date>
<journal>Computational Linguistics,</journal>
<volume>35</volume>
<issue>1</issue>
<marker>Barrachina, Bender, Casacuberta, Civera, Cubel, Khadivi, Lagarda, Ney, Tom´as, Vidal, 2009</marker>
<rawString>S. Barrachina, O. Bender, F. Casacuberta, J. Civera, E. Cubel, S. Khadivi, A. Lagarda, H. Ney, J. Tom´as, and E. Vidal. 2009. Statistical approaches to computer-assisted translation. Computational Linguistics, 35(1):3–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blatz</author>
<author>E Fitzgerald</author>
<author>G Foster</author>
<author>S Gandrabur</author>
<author>C Goutte</author>
<author>A Kulesza</author>
<author>A Sanchis</author>
<author>N Ueffing</author>
</authors>
<title>Confidence estimation for machine translation.</title>
<date>2003</date>
<contexts>
<context position="5915" citStr="Blatz et al., 2003" startWordPosition="948" endWordPosition="951">d as incorrect. 2.1 Selecting a CM for IMT We compute sentence CMs by combining the scores given by a word CM based on the IBM model 1 (Brown et al., 1993), similar to the one described in (Blatz et al., 2004). We modified this word CM by replacing the average by the maximal lexicon probability, because the average is dominated by this maximum (Ueffing and Ney, 2005). We choose this word CM because it can be calculated very fast during search, which is crucial given the time constraints of the IMT systems. Moreover, its performance is similar to that of other word CMs as results presented in (Blatz et al., 2003; Blatz et al., 2004) show. The word confidence value of word ei, cw(ei), is given by cw(ei) = max p(eilfj) , (3) 0&lt;j&lt;J where p(eiIfj) is the IBM model 1 lexicon probability, and f0 is the empty source word. From this word CM, we compute two sentence CMs which differ in the way the word confidence Spanish English Train Sentences 214.5K Running words 5.8M 5.2M Vocabulary 97.4K 83.7K Dev. Sentences 400 Running words 11.5K 10.1K Perplexity (trigrams) 46.1 59.4 Test Sentences 800 Running words 22.6K 19.9K Perplexity (trigrams) 45.2 60.8 Table 1: Statistics of the Spanish–English EU corpora. K and </context>
</contexts>
<marker>Blatz, Fitzgerald, Foster, Gandrabur, Goutte, Kulesza, Sanchis, Ueffing, 2003</marker>
<rawString>J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kulesza, A. Sanchis, and N. Ueffing. 2003. Confidence estimation for machine translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blatz</author>
<author>E Fitzgerald</author>
<author>G Foster</author>
<author>S Gandrabur</author>
<author>C Goutte</author>
<author>A Kuesza</author>
<author>A Sanchis</author>
<author>N Ueffing</author>
</authors>
<title>Confidence estimation for machine translation.</title>
<date>2004</date>
<booktitle>In Proc. COLING,</booktitle>
<pages>315</pages>
<contexts>
<context position="2788" citStr="Blatz et al., 2004" startWordPosition="423" endWordPosition="426">ype2 project (Esteban et al., 2004; Barrachina et al., 2009). IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error. 1.1 Confidence Measures Confidence estimation have been extensively studied for speech recognition. Only recently have researchers started to investigate CMs for MT (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). Different TransType-style MT systems use confidence information to improve translation prediction accuracy (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). In this work, we propose a focus shift in which CMs are used to modify the interaction between the user and the system instead of modify the IMT translation predictions. To compute CMs we have to select suitable confidence features and define a binary classifier. Typically, the classification is carried out depending on whether the confidence value exceeds a given threshold or not. 2 IMT with Sentence CMs In th</context>
<context position="5506" citStr="Blatz et al., 2004" startWordPosition="875" endWordPosition="878">be saved by interactively translating only those sentences that the CMs classify as incorrect. It is worth of notice that our proposal can be seen as a generalisation of the conventional IMT approach. Varying the value of the CM classification threshold, we can range from a fully automatic SMT system where all sentences are classified as correct to a conventional IMT system where all sentences are classified as incorrect. 2.1 Selecting a CM for IMT We compute sentence CMs by combining the scores given by a word CM based on the IBM model 1 (Brown et al., 1993), similar to the one described in (Blatz et al., 2004). We modified this word CM by replacing the average by the maximal lexicon probability, because the average is dominated by this maximum (Ueffing and Ney, 2005). We choose this word CM because it can be calculated very fast during search, which is crucial given the time constraints of the IMT systems. Moreover, its performance is similar to that of other word CMs as results presented in (Blatz et al., 2003; Blatz et al., 2004) show. The word confidence value of word ei, cw(ei), is given by cw(ei) = max p(eilfj) , (3) 0&lt;j&lt;J where p(eiIfj) is the IBM model 1 lexicon probability, and f0 is the em</context>
</contexts>
<marker>Blatz, Fitzgerald, Foster, Gandrabur, Goutte, Kuesza, Sanchis, Ueffing, 2004</marker>
<rawString>J. Blatz, E. Fitzgerald, G. Foster, S. Gandrabur, C. Goutte, A. Kuesza, A. Sanchis, and N. Ueffing. 2004. Confidence estimation for machine translation. In Proc. COLING, page 315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The Mathematics of Statistical Machine Translation: Parameter Estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="5452" citStr="Brown et al., 1993" startWordPosition="865" endWordPosition="868">tolerated for the sake of efficiency, user effort can be saved by interactively translating only those sentences that the CMs classify as incorrect. It is worth of notice that our proposal can be seen as a generalisation of the conventional IMT approach. Varying the value of the CM classification threshold, we can range from a fully automatic SMT system where all sentences are classified as correct to a conventional IMT system where all sentences are classified as incorrect. 2.1 Selecting a CM for IMT We compute sentence CMs by combining the scores given by a word CM based on the IBM model 1 (Brown et al., 1993), similar to the one described in (Blatz et al., 2004). We modified this word CM by replacing the average by the maximal lexicon probability, because the average is dominated by this maximum (Ueffing and Ney, 2005). We choose this word CM because it can be calculated very fast during search, which is crucial given the time constraints of the IMT systems. Moreover, its performance is similar to that of other word CMs as results presented in (Blatz et al., 2003; Blatz et al., 2004) show. The word confidence value of word ei, cw(ei), is given by cw(ei) = max p(eilfj) , (3) 0&lt;j&lt;J where p(eiIfj) is</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, S. A. Della Pietra, V. J. Della Pietra, and R. L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Esteban</author>
<author>J Lorenzo</author>
<author>A Valderr´abanos</author>
<author>G Lapalme</author>
</authors>
<title>Transtype2: an innovative computerassisted translation system.</title>
<date>2004</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>1</pages>
<marker>Esteban, Lorenzo, Valderr´abanos, Lapalme, 2004</marker>
<rawString>J. Esteban, J. Lorenzo, A. Valderr´abanos, and G. Lapalme. 2004. Transtype2: an innovative computerassisted translation system. In Proc. ACL, page 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Foster</author>
<author>P Isabelle</author>
<author>P Plamondon</author>
</authors>
<title>Targettext mediated interactive machine translation.</title>
<date>1997</date>
<booktitle>Machine Translation,</booktitle>
<pages>12--12</pages>
<contexts>
<context position="2107" citStr="Foster et al., 1997" startWordPosition="316" endWordPosition="319"> way: For a given source sentence, the SMT system fully automatically generates an initial translation. A human translator checks this translation from left to right, correcting the first error. The SMT system then proposes a new extension, taking the correct prefix ei1 = e1 ... ei into account. These steps are repeated until the whole input sentence has been correctly translated. In the resulting decision rule, we maximise over all possible extensions eIi+1 of ei 1: �ei+1 =ˆI argmax Pr(eIi+1|ei1, fJ1 ) . (2) I,ei+1 An implementation of the IMT famework was performed in the TransType project (Foster et al., 1997; Langlais et al., 2002) and further improved within the TransType2 project (Esteban et al., 2004; Barrachina et al., 2009). IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error. 1.1 Confidence Measures Confidence estimation have been extensively studied for speech recognition. Only recently have researchers </context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1997</marker>
<rawString>G. Foster, P. Isabelle, and P. Plamondon. 1997. Targettext mediated interactive machine translation. Machine Translation, 12:12–175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gandrabur</author>
<author>G Foster</author>
</authors>
<title>Confidence estimation for text prediction.</title>
<date>2003</date>
<booktitle>In Proc. CoNLL,</booktitle>
<pages>315--321</pages>
<contexts>
<context position="2768" citStr="Gandrabur and Foster, 2003" startWordPosition="418" endWordPosition="422">r improved within the TransType2 project (Esteban et al., 2004; Barrachina et al., 2009). IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error. 1.1 Confidence Measures Confidence estimation have been extensively studied for speech recognition. Only recently have researchers started to investigate CMs for MT (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). Different TransType-style MT systems use confidence information to improve translation prediction accuracy (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). In this work, we propose a focus shift in which CMs are used to modify the interaction between the user and the system instead of modify the IMT translation predictions. To compute CMs we have to select suitable confidence features and define a binary classifier. Typically, the classification is carried out depending on whether the confidence value exceeds a given threshold or not. 2 IMT wit</context>
</contexts>
<marker>Gandrabur, Foster, 2003</marker>
<rawString>S. Gandrabur and G. Foster. 2003. Confidence estimation for text prediction. In Proc. CoNLL, pages 315–321.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="10286" citStr="Koehn et al., 2007" startWordPosition="1723" endWordPosition="1726">scores versus WSR for different values of the sentence classification threshold using the RATIO CM with r,,, = 0.4. dure, optimising the BLEU score on the development set. The IMT system which we have implemented relies on the use of word graphs (Ueffing et al., 2002) to efficiently compute the suffix for a given prefix. A word graph has to be generated for each sentence to be interactively translated. For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit. We discarded to use the state-of-the-art Moses toolkit (Koehn et al., 2007) because preliminary experiments performed with it revealed that the decoder by OrtizMartinez et al. (2005) performs better in terms of WSR when used to generate word graphs for their use in IMT (Sanchis-Trilles et al., 2008). Moreover, the performance difference in regular SMT is negligible. The decoder was set to only consider monotonic translation, since in real IMT scenarios considering non-monotonic translation leads to excessive response time for the user. Finally, the obtained word graphs were used within the IMT procedure to produce the reference translations in the test set, measuring</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ACL, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Langlais</author>
<author>G Lapalme</author>
<author>M Loranger</author>
</authors>
<title>Transtype: Development-evaluation cycles to boost translator’s productivity.</title>
<date>2002</date>
<journal>Machine Translation,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="2131" citStr="Langlais et al., 2002" startWordPosition="320" endWordPosition="323">rce sentence, the SMT system fully automatically generates an initial translation. A human translator checks this translation from left to right, correcting the first error. The SMT system then proposes a new extension, taking the correct prefix ei1 = e1 ... ei into account. These steps are repeated until the whole input sentence has been correctly translated. In the resulting decision rule, we maximise over all possible extensions eIi+1 of ei 1: �ei+1 =ˆI argmax Pr(eIi+1|ei1, fJ1 ) . (2) I,ei+1 An implementation of the IMT famework was performed in the TransType project (Foster et al., 1997; Langlais et al., 2002) and further improved within the TransType2 project (Esteban et al., 2004; Barrachina et al., 2009). IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error. 1.1 Confidence Measures Confidence estimation have been extensively studied for speech recognition. Only recently have researchers started to investigate C</context>
</contexts>
<marker>Langlais, Lapalme, Loranger, 2002</marker>
<rawString>P. Langlais, G. Lapalme, and M. Loranger. 2002. Transtype: Development-evaluation cycles to boost translator’s productivity. Machine Translation, 15(4):77–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="9619" citStr="Och, 2003" startWordPosition="1613" endWordPosition="1614"> Here, we will focus on the Spanish–English part of the EU corpora. The corpus is divided into training, development and test sets. The main figures of the corpus can be seen in Table 1. As a first step, be built a SMT system to translate from Spanish into English. This was done by means of the Thot toolkit (Ortiz et al., 2005), which is a complete system for building phrasebased SMT models. This toolkit involves the estimation, from the training set, of different statistical models, which are in turn combined in a loglinear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) proceThreshold (is) Figure 2: BLEU translation scores versus WSR for different values of the sentence classification threshold using the RATIO CM with r,,, = 0.4. dure, optimising the BLEU score on the development set. The IMT system which we have implemented relies on the use of word graphs (Ueffing et al., 2002) to efficiently compute the suffix for a given prefix. A word graph has to be generated for each sentence to be interactively translated. For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit. We disca</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>F. J. Och. 2003. Minimum error rate training in statistical machine translation. In Proc. ACL, pages 160– 167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ortiz</author>
<author>I Garcia-Varea</author>
<author>F Casacuberta</author>
</authors>
<title>Thot: a toolkit to train phrase-based statistical translation models.</title>
<date>2005</date>
<booktitle>In Proc. MT Summit,</booktitle>
<pages>141--148</pages>
<contexts>
<context position="9338" citStr="Ortiz et al., 2005" startWordPosition="1560" endWordPosition="1563">a factor to penalise short sentences. 3.2 Experimental Setup Our experiments were carried out on the EU corpora (Barrachina et al., 2009). The EU corpora were extracted from the Bulletin of the European Union. The EU corpora is composed of sentences given in three different language pairs. Here, we will focus on the Spanish–English part of the EU corpora. The corpus is divided into training, development and test sets. The main figures of the corpus can be seen in Table 1. As a first step, be built a SMT system to translate from Spanish into English. This was done by means of the Thot toolkit (Ortiz et al., 2005), which is a complete system for building phrasebased SMT models. This toolkit involves the estimation, from the training set, of different statistical models, which are in turn combined in a loglinear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) proceThreshold (is) Figure 2: BLEU translation scores versus WSR for different values of the sentence classification threshold using the RATIO CM with r,,, = 0.4. dure, optimising the BLEU score on the development set. The IMT system which we have implemented relies on the use of word graphs (Ueffing et al., 2002) to</context>
</contexts>
<marker>Ortiz, Garcia-Varea, Casacuberta, 2005</marker>
<rawString>D. Ortiz, I. Garcia-Varea, and F. Casacuberta. 2005. Thot: a toolkit to train phrase-based statistical translation models. In Proc. MT Summit, pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of MT.</title>
<date>2002</date>
<booktitle>In Proc. ACL,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="8645" citStr="Papineni et al., 2002" startWordPosition="1434" endWordPosition="1437">of the sentence classification threshold using the MEAN CM. translations. WSR is computed as the ratio between the number of word-strokes a user would need to achieve the translation she has in mind and the total number of words in the sentence. In this context, a word-stroke is interpreted as a single action, in which the user types a complete word, and is assumed to have constant cost. Additionally, and because our proposal allows differences between its output and the reference translation, we will also present translation quality results in terms of BiLingual Evaluation Understudy (BLEU) (Papineni et al., 2002). BLEU computes a geometric mean of the precision of ngrams multiplied by a factor to penalise short sentences. 3.2 Experimental Setup Our experiments were carried out on the EU corpora (Barrachina et al., 2009). The EU corpora were extracted from the Bulletin of the European Union. The EU corpora is composed of sentences given in three different language pairs. Here, we will focus on the Spanish–English part of the EU corpora. The corpus is divided into training, development and test sets. The main figures of the corpus can be seen in Table 1. As a first step, be built a SMT system to transla</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a method for automatic evaluation of MT. In Proc. ACL, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Sanchis-Trilles</author>
<author>D Ortiz-Martinez</author>
<author>J Civera</author>
<author>F Casacuberta</author>
<author>E Vidal</author>
<author>H Hoang</author>
</authors>
<title>Improving interactive machine translation via mouse actions.</title>
<date>2008</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>25--27</pages>
<contexts>
<context position="10511" citStr="Sanchis-Trilles et al., 2008" startWordPosition="1761" endWordPosition="1764">lies on the use of word graphs (Ueffing et al., 2002) to efficiently compute the suffix for a given prefix. A word graph has to be generated for each sentence to be interactively translated. For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit. We discarded to use the state-of-the-art Moses toolkit (Koehn et al., 2007) because preliminary experiments performed with it revealed that the decoder by OrtizMartinez et al. (2005) performs better in terms of WSR when used to generate word graphs for their use in IMT (Sanchis-Trilles et al., 2008). Moreover, the performance difference in regular SMT is negligible. The decoder was set to only consider monotonic translation, since in real IMT scenarios considering non-monotonic translation leads to excessive response time for the user. Finally, the obtained word graphs were used within the IMT procedure to produce the reference translations in the test set, measuring WSR and BLEU. 3.3 Results We carried out a series of experiments ranging the value of the sentence classification threshold rs, between 0.0 (equivalent to a fully automatic SMT system) and 1.0 (equivalent to a conventional I</context>
</contexts>
<marker>Sanchis-Trilles, Ortiz-Martinez, Civera, Casacuberta, Vidal, Hoang, 2008</marker>
<rawString>G. Sanchis-Trilles, D. Ortiz-Martinez, J. Civera, F. Casacuberta, E. Vidal, and H. Hoang. 2008. Improving interactive machine translation via mouse actions. In Proc. EMNLP, pages 25–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Application of wordlevel confidence measures in interactive statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. EAMT,</booktitle>
<pages>262--270</pages>
<contexts>
<context position="2972" citStr="Ueffing and Ney, 2005" startWordPosition="449" endWordPosition="453">ion. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error. 1.1 Confidence Measures Confidence estimation have been extensively studied for speech recognition. Only recently have researchers started to investigate CMs for MT (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). Different TransType-style MT systems use confidence information to improve translation prediction accuracy (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). In this work, we propose a focus shift in which CMs are used to modify the interaction between the user and the system instead of modify the IMT translation predictions. To compute CMs we have to select suitable confidence features and define a binary classifier. Typically, the classification is carried out depending on whether the confidence value exceeds a given threshold or not. 2 IMT with Sentence CMs In the conventional IMT scenario a human translator and a SMT system collaborate in order to obtain the translation the user has in mind. Once the user has interactively translated the sour</context>
<context position="5666" citStr="Ueffing and Ney, 2005" startWordPosition="902" endWordPosition="905">alisation of the conventional IMT approach. Varying the value of the CM classification threshold, we can range from a fully automatic SMT system where all sentences are classified as correct to a conventional IMT system where all sentences are classified as incorrect. 2.1 Selecting a CM for IMT We compute sentence CMs by combining the scores given by a word CM based on the IBM model 1 (Brown et al., 1993), similar to the one described in (Blatz et al., 2004). We modified this word CM by replacing the average by the maximal lexicon probability, because the average is dominated by this maximum (Ueffing and Ney, 2005). We choose this word CM because it can be calculated very fast during search, which is crucial given the time constraints of the IMT systems. Moreover, its performance is similar to that of other word CMs as results presented in (Blatz et al., 2003; Blatz et al., 2004) show. The word confidence value of word ei, cw(ei), is given by cw(ei) = max p(eilfj) , (3) 0&lt;j&lt;J where p(eiIfj) is the IBM model 1 lexicon probability, and f0 is the empty source word. From this word CM, we compute two sentence CMs which differ in the way the word confidence Spanish English Train Sentences 214.5K Running words</context>
</contexts>
<marker>Ueffing, Ney, 2005</marker>
<rawString>N. Ueffing and H. Ney. 2005. Application of wordlevel confidence measures in interactive statistical machine translation. In Proc. EAMT, pages 262– 270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>H Ney</author>
</authors>
<title>Word-level confidence estimation for machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="2812" citStr="Ueffing and Ney, 2007" startWordPosition="427" endWordPosition="430">n et al., 2004; Barrachina et al., 2009). IMT aims at reducing the effort and increasing the productivity of translators, while preserving high-quality translation. In this work, we integrate Confidence Measures (CMs) within the IMT framework to further reduce the user effort. As will be shown, our proposal allows to balance the ratio between user effort and final translation error. 1.1 Confidence Measures Confidence estimation have been extensively studied for speech recognition. Only recently have researchers started to investigate CMs for MT (Gandrabur and Foster, 2003; Blatz et al., 2004; Ueffing and Ney, 2007). Different TransType-style MT systems use confidence information to improve translation prediction accuracy (Gandrabur and Foster, 2003; Ueffing and Ney, 2005). In this work, we propose a focus shift in which CMs are used to modify the interaction between the user and the system instead of modify the IMT translation predictions. To compute CMs we have to select suitable confidence features and define a binary classifier. Typically, the classification is carried out depending on whether the confidence value exceeds a given threshold or not. 2 IMT with Sentence CMs In the conventional IMT scena</context>
</contexts>
<marker>Ueffing, Ney, 2007</marker>
<rawString>N. Ueffing and H. Ney. 2007. Word-level confidence estimation for machine translation. Comput. Linguist., 33(1):9–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ueffing</author>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Generation of word graphs in statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>156--163</pages>
<contexts>
<context position="9935" citStr="Ueffing et al., 2002" startWordPosition="1665" endWordPosition="1668">kit (Ortiz et al., 2005), which is a complete system for building phrasebased SMT models. This toolkit involves the estimation, from the training set, of different statistical models, which are in turn combined in a loglinear fashion by adjusting a weight for each of them by means of the MERT (Och, 2003) proceThreshold (is) Figure 2: BLEU translation scores versus WSR for different values of the sentence classification threshold using the RATIO CM with r,,, = 0.4. dure, optimising the BLEU score on the development set. The IMT system which we have implemented relies on the use of word graphs (Ueffing et al., 2002) to efficiently compute the suffix for a given prefix. A word graph has to be generated for each sentence to be interactively translated. For this purpose, we used a multi-stack phrase-based decoder which will be distributed in the near future together with the Thot toolkit. We discarded to use the state-of-the-art Moses toolkit (Koehn et al., 2007) because preliminary experiments performed with it revealed that the decoder by OrtizMartinez et al. (2005) performs better in terms of WSR when used to generate word graphs for their use in IMT (Sanchis-Trilles et al., 2008). Moreover, the performa</context>
</contexts>
<marker>Ueffing, Och, Ney, 2002</marker>
<rawString>N. Ueffing, F.J. Och, and H. Ney. 2002. Generation of word graphs in statistical machine translation. In Proc. EMNLP, pages 156–163.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>