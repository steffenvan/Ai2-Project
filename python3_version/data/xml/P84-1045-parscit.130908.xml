<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.352638">
UNDERSTANDING PRAGMATICALLY ILL-FORMED INPUT
</note>
<author confidence="0.486435">
M. Sandra Carberry
</author>
<affiliation confidence="0.850879666666667">
Department of Computer Science
University of Delaware
Newark, Delaware 19711 USA
</affiliation>
<sectionHeader confidence="0.481335" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999926090909091">
An utterance may be syntactically and semant-
ically well-formed yet violate the pragmatic rules
of the world model. This paper presents a
context-based strategy for constructing a coopera-
tive but limited response to pragmatically ill-
formed queries. Suggestion heuristics use a con-
text model of the speaker&apos;s task inferred from the
preceding dialogue to propose revisions to the
speaker&apos;s ill-formed query. Selection heuristics
then evaluate these suggestions based upon seman-
tic and relevance criteria.
</bodyText>
<sectionHeader confidence="0.929664" genericHeader="keywords">
I INTRODUCTION
</sectionHeader>
<bodyText confidence="0.994276038961039">
An utterance may be syntactically and semant-
ically well-formed yet violate the pragmatic rules
of the world model. The system will therefore
view it as &amp;quot;ill-formed&amp;quot; even if a native speaker
finds it perfectly normal. This phenomenon has
been termed &amp;quot;pragmatic overshoot&amp;quot; [Sondheimer and
Weischede1,1980] and may be divided into three
classes:
[1] User-specified relationships that do not
exist in the world model.
EXAMPLE: &amp;quot;Which apartments are for
sale?&amp;quot;
In a real estate model, single apart-
ments are rented, not sold. However apart-
ment buildings, condominiums, townhouses, and
houses are for sale.
[2] User-specified restrictions on the relation-
ships which can never be satisfied, even with
new entries.
EXAMPLE: &amp;quot;Which lower-level English
courses have a maximum enrollment of at
most 25 students?&amp;quot;
In a University world model, it may be
the case that the maximum enrollments of
This material is based upon work supported by the
National Science Foundation under grants 1ST-
8009673 and IST-8311400
lower-level English courses are constrained
to have values larger than 25 but that such
constraints do not apply to the current
enrollments of courses, the maximum enroll-
ments of upper-level English courses, and the
maximum enrollments of latter-level courses in
other departments. The sample utterance is
pragmatically ill-formed since world model
constraints prohibit the restricted relations
specified by the user.
User-specified relationships which result in
a query that is irrelevant to the user&apos;s
underlying task.
EXAMPLE: &amp;quot;What is Dr. Smith&apos;s home
address?&amp;quot;
The home addresses of faculty at a
university may be available. However if a
student wants to obtain special permission to
take a course, a query requesting the
instructor&apos;s home address is inappropriate;
the speaker should request the instructor&apos;s
office address or phone. Although such
utterances do not violate the underlying
domain world model, they are a variation of
pragmatic overshoot in that they violate the
listener&apos;s model of the speaker&apos;s underlying
task.
A cooperative participant uses the informa-
tion exchanged during a dialogue and his knowledge
of the domain to hypothesize the speaker&apos;s goals
and plans for achieving those goals. This context
model of goals and plans provides clues for inter-
preting utterances and formulating cooperative
responses. When pragmatic overshoot occurs, a
human listener can modify the speaker&apos;s ill-formed
query to form a similar query X that is both mean-
ingful and relevant. For example, the query
&amp;quot;What is the area of the special weapons
magazine of the Alamo?&amp;quot;
erroneously presumes that storage locations have
an AREA attribute in the REL database of ships
[Thompson, 1980]; this is an instance of the first
class of pragmatic overshoot. Depending upon the
speaker&apos;s underlying task, a listener might infer
that the speaker wants to know the REMAINING -
CAPACITY, TOTAL-CAPACITY, or perhaps even the
LOCATION (if &amp;quot;area&amp;quot; is interpreted as referring to
&amp;quot;place&amp;quot;) of the Alamo&apos;s Special Weapons Magazine.
In each case, a cooperative participant uses the
preceding dialogue and his knowledge of the
</bodyText>
<page confidence="0.988917">
200
</page>
<bodyText confidence="0.960783405405405">
speaker to formulate a response that might provide
the desired information.
This paper presents a method for handling
this first class of pragmatic overshoot by formu-
lating a modified query X that satisfies the
speaker&apos;s needs. Future research may extend this
technique to handle other pragmatic overshoot
classes.
Our work on pragmatic overshoot processing is
part of an on-going project to develop a robust
natural language interface [Weischedel and Son-
dheimer, 1983]. Mays[1980], Webber and
Mays[1983], and Ramshaw and Weischedel[1984] have
suggested mechanisms for detecting the occurrence
of pragmatic overshoot and identifying its causes.
The main contribution of our work is a context-
based strategy for constructing a cooperative but
limited response to pragmatically ill-formed
queries. This response satisfies the user&apos;s per-
ceived needs, inferred both from the preceding
dialogue and the ill-formed utterance. In partic-
ular,
[1] A context model of the user&apos;s goals and plans
provides expectations about utterances,
expectations that may be used to model the
user&apos;s goals. We use a context mechanism
[Carberry, 1983] to build the speaker&apos;s
underlying task-related plan as the dialogue
progresses and differentiate between local
and global contexts.
[2] Only alternative queries which might
represent the user&apos;s intent or at least
satisfy his needs are considered. QUL
bvPothesis lm that the user&apos;s inferred am,
raoresented hythe context model, mummeetm m
substitution fur the proposition gaming the
pragmatic. pvershoot.
</bodyText>
<sectionHeader confidence="0.883627" genericHeader="introduction">
II KM:LEDGE REPRESENTATION
</sectionHeader>
<bodyText confidence="0.975208">
Our system requires a representation for each
of the following:
</bodyText>
<listItem confidence="0.859572428571429">
[1] the set of domain-dependent plans and goals
[2] the speaker&apos;s plan inferred from the preced-
ing dialogue
[3] the existing relationships among attributes
and entity sets in the underlying world model
[4] the semantic difference of attributes, rela-
tions, entity sets, and functions.
</listItem>
<footnote confidence="0.964716285714286">
Plans are represented using an extended
STRIPS [Fikes and Nilsson, 1971] formalism. A plan
can contain subgoals and actions that have associ-
ated plans. We use a context tree [Carberry,
1983] to represent the speaker&apos;s inferred plan as
constructed from the preceding dialogue. Nodes
within this tree represent goals and actions which
</footnote>
<bodyText confidence="0.961957176470588">
• the speaker has investigated; these nodes are des-
cendants of parent nodes representing higher-level
goals whose associated plans contain these lower-
level actions. The context tree represents the
global context or overall plan inferred for the
speaker. The focused plan is a subtree of the
context tree and represents the local context or
particular aspect of the plan upon which the
speaker&apos;s attention is currently focused. This
focused plan produces the strongest expectations
for future utterances.
An entity-relationship model states the pos-
sible primitive relationships among entity sets.
Our world model includes a generalization hierar-
chy of entity sets, attributes, relations, and
functions and also specifies the types of attri-
butes and the domains of functions.
</bodyText>
<sectionHeader confidence="0.972589" genericHeader="method">
III CONSTRUCTING THE CONTEXT MODEL
</sectionHeader>
<bodyText confidence="0.999768818181818">
The plan construction component is described
in [Carberry, 1983]. It hypothesizes and tracks
the changing task-level goals of a speaker during
the course of a dialogue. Our approach is to
infer a lower-level task-related goal from the
speaker&apos;s explicitly communicated goal, relate it
to potential higher-level plans, and build the
complete plan context as the dialogue progresses.
The context mechanism distinguishes local and glo-
bal contexts and uses these to predict new speaker
goals from the current utterance.
</bodyText>
<sectionHeader confidence="0.907379" genericHeader="method">
IV PRAGMATIC OVERSHOOT PROCESSING
</sectionHeader>
<bodyText confidence="0.987356434782609">
Once pragmatic overshoot has been detected,
the system formulates a revised query QR request-
ing the information needed by the user. Our
hypothesis is that the user&apos;s inferred plan,
represented by the context model, suggests a sub-
stitution for the proposition that caused the
pragmatic overshoot. The system then selects from
amongst these suggestions using the criteria of
relevance to the current dialogue, semantic
difference from the proposition in the user&apos;s
query, and the type of revision operation applied
to this proposition.
A. 3uzgestiou kimpammlimm
The suggestion mechanism examines the current
context model and possible expansions of its con-
stituent goals and actions, proposing substitu-
tions for the proposition causing the pragmatic
overshoot. This erroneous proposition represents
either a non-existent attribute or entity set
relationship or a function applied to an inap-
propriate set of attribute values.
The suggestion mechanism applies two classes
of rules. The first class proposes a simple sub-
</bodyText>
<page confidence="0.989421">
201
</page>
<bodyText confidence="0.999340555555555">
stitution for an attribute, entity set, relation,
or function appearing in the erroneous proposi-
tion. The second class proposes a conjunction of
propositions representing an expanded relationship
path as a substitution for the user-specified
proposition. These two classes of rules may be
used together to propose both an expanded rela-
tionship path &apos;and an attribute or entity set sub-
stitution.
</bodyText>
<sectionHeader confidence="0.921078" genericHeader="method">
1. simp12-5ubstitution Rua&amp;
</sectionHeader>
<bodyText confidence="0.984711577777778">
Suppose a student wants to pursue an indepen-
dent study project; such projects can be directed
by full-time or part-time faculty but not by
faculty who are &amp;quot;extension&amp;quot; or &amp;quot;on sabbatical&amp;quot;.
The student might erroneously enter the query
&amp;quot;What is the classification of Dr. Smith?&amp;quot;
Only students have classification attributes (such
as Arts&amp;Science -1985, Engineering-1987); faculty
have attributes such as rank, status, age, and
title. Pursuing an independent study project
under the direction of Dr. Smith requires that Dr.
Smith&apos;s status be &amp;quot;full-time&amp;quot; or &amp;quot;part-time&amp;quot;. If
the listener knows the student wants to pursue
independent study, then he might infer that the
student needs the value of this status attribute
and answer the revised query
&amp;quot;What is the status of Dr. Smith?&amp;quot;
The suggestion mechanism contains five simple
substitution rules for handling such erroneous
queries. One such rule proposes a substitution
for the user-specified attribute in the erroneous
proposition. Intuitively, a listener anticipates
that the speaker will need to know each entity and
attribute value in the speaker&apos;s plan inferred
from the domain and the preceding dialogue. Sup-
pose this inferred plan contains an attribute ATT1
for a member of ENTITY -SET1, namely ATT1(ENTITY-
SET1,attribute-value), and that the speaker
erroneously requests the value of attribute ATTU
for a member ent1 of ENTITY -SET1. Then a coopera-
tive listener might infer that the value of ATT1
for entity ent1 will satisfy the speaker&apos;s needs,
especially if attributes ATT1 and ATTU are closely
related.
The substitution mechanism searches the
user&apos;s inferred plan and its possible expansions
for propositions whose arguments unify with the
arguments in the erroneous proposition causing the
pragmatic overshoot. The above rule then suggests
substituting the attribute from the plan&apos;s propo-
sition for the attribute specified in the user&apos;s
query. This substitution produces a query
relevant to the current dialogue and may capture
the speaker&apos;s intent or at least satisfy his
needs.
</bodyText>
<sectionHeader confidence="0.405471" genericHeader="method">
2. gm:landed Path Pules
</sectionHeader>
<bodyText confidence="0.9909042">
Suppose a student wants to contact Dr. Smith
to discuss the appropriate background for a new
seminar course. Then the student might enter the
query
&amp;quot;What is Dr. Smith&apos;s phone number?&amp;quot;
Phone numbers are associated with homes, offices,
and departmental offices. Course discussions with
professors may be handled in person or by phone;
contacting a professor by phone requires that the
student dial the phone number of Dr. Smith&apos;s
office. Thus the listener might infer that the
student needs the phone number of the office occu-
pied by Dr. Smith.
The second class of rules handles such &amp;quot;miss-
ing logical joins&amp;quot;. (This is somewhat related to
the philosophical concept of &amp;quot;deferred ostension&amp;quot;
[Quine,1969].) These rules apply when the entity
sets are not directly related by the user-
specified relation RLU --- but there is a path R
in the entity relationship model between the
entity sets. We call this path expansion since by
finding the missing joins between entity sets, we
are constructing an expanded relational path.
Suppose the inferred plan for the speaker
includes a sequence of relations
</bodyText>
<equation confidence="0.933062">
R1(ENTITY-SET1,ENTITY-SETA)
R2(ENTITY-SETA,ENTITY -SETH)
R3(ENTITY-SETB,ENTITY-SET2);
</equation>
<bodyText confidence="0.976030363636364">
then the listener anticipates that the speaker
will need to know those members of ENTITY-SET1
that are related by the composition of relations
111,112,R3 to a member of ENTITY -SET2. If the
speaker erroneously requests those members of
ENTITY-SET1 that are related by R2 (or alterna-
tively R1 or R3) to members of ENTITY-SET2, then
perhaps the speaker really meant the expanded path
R1oR2*R3. The path expansion rules suggest sub-
stituting this expanded path for the user-
specified relation.
We employ a user model to constrain path
expansion. This model represents the speaker&apos;s
beliefs about membership in entity sets. If prag-
matic overshoot occurs because the speaker misused
a relation
R(ENTITY-SET1, ENTITY-SET2)
by specifying an argument that is not a member of
the correct entity set for the relation, then path
expansion is permitted only if the user model
indicates that the speaker may believe the errone-
ous argument is not a member of that entity set.
EXAMPLE: &amp;quot;Which bed is Dr. Brown assigned?&amp;quot;
Suppose beds are assigned to patients in
a hospital model. If Dr. Brown is a doctor
and doctors cannot simultaneously be
patients, then path expansion is permitted if
our user model indicates that the speaker may
recognize that Dr. Brown is not a patient.
In this case, our expanded path expression
may retrieve the beds assigned to patients of
Dr. Brown, if this is suggested by the
inferred task-related plan.
</bodyText>
<page confidence="0.991025">
202
</page>
<bodyText confidence="0.946893785714286">
To limit the components of path expressions
to those relations which can be meaningfully com-
bined in a given context, we make a strong assump-
tion: that the relations comprising the relevant
expansion appear on a single path within the con-
text tree representing the speaker&apos;s inferred
plan. For example, suppose the speaker&apos;s inferred
plan is to take CS105. Expansion of this plan
will contain the two actions
Learn-From-Teacher-In-Class(SPEARER,
section, faculty)
such that Teach(faculty,section)
Obtain-Necessary -Extra-Help(SPEARER,
section, teaching-assistant)
such that Assists(teaching-assistant,section)
The associated plans for these two actions specify
respectively that the speaker attend class at the
time the section meets and that the speaker meet
with the section&apos;s teaching assistant at the time
of his office hours. Now consider the utterance
&amp;quot;When are teaching assistants available?&amp;quot;
A direct relationship between teaching assistants
and time does not exist. The constraint that all
components of a path expression appear on a single
path in the inferred task-related plan prohibits
composing Assists(teaching-assistant,section) and
Meet -Time(section,time) to suggest a reply con-
sisting of the times that the CS105 sections meet.
</bodyText>
<subsectionHeader confidence="0.394872">
B. $electiou EtLimami
</subsectionHeader>
<bodyText confidence="0.990268675675676">
The substitution and path expansion rules
propose substitutions for the erroneous proposi-
tion that caused the pragmatic overshoot. Three
criteria are used to select from the proposed sub-
stitutions the revised query, if any, that is most
likely to satisfy the speaker&apos;s intent in making
the utterance.
First, the relevance of the revised query to
the speaker&apos;s plans and goals is measured by three
factors:
[1] A revised query that interrogates an aspect
of the current focused plan is most relevant
to the current dialogue.
[2] The set of higher level plans whose expan-
sions led to the current focused plan form a
stack of increasingly more general, and
therefore less immediately relevant, active
plans to which the user may return. A
revised query which interrogates an aspect of
an active plan closer to the top of this
stack is more expected than a query which
reverts back to a more general active plan.
[3] Within a given active plan, a revised query
that investigates the single-level expansion
of an action is more expected, and therefore
more relevant, than a revised query that
investigates details at a much deeper level
of expansion.
Second, we can classify the substitution
T--&gt;V which produced the revised query into four
categories, each of which represents a more signi-
ficant, and therefore less preferable, alteration
of the user&apos;s query (Figure 1). Category 1 con-
tains expanded relational paths R1*R211...4Rn such
that the user-specified attribute or relation
appears in the path expression. For example, the
expanded path
</bodyText>
<figure confidence="0.137731428571429">
Treats(Dr.Brown,patient)lIs-Assigned(patient,rocm)
is a Category 1 substitution for the user-
specified proposition
Is-Assigned(Dr.Brown,room)
SUBSTITUTION SUBSTITUTION
CATEGORY TERM T VARIABLE V
1 Expanded relational path User-specified attribute
</figure>
<figureCaption confidence="0.555966866666667">
including the user-specified or relation
attribute or relation User-specified attribute,
2 Attribute, relation, entity relation, entity set, or
set, or function semantically function
similar to that specified
by the user
3 Expanded relational path, User-specified attribute
including an attribute or or relation
relation semantically similar
to that specified by the user
4 Double substitution: entity User-specified entity set
set and relation semantically and relation
similar to a user-specified
entity set and relation
Figure 1. Classification of Query Revision Operations
</figureCaption>
<page confidence="0.996783">
203
</page>
<bodyText confidence="0.988199086956522">
contained in the semantic representation of the
query
&amp;quot;Which bed is Dr. Brawn assigned?&amp;quot;
Category 2 contains simple substitutions that
are semantically similar to the attribute, rela-
tion, entity set, or function specified by the
speaker. An example of Category 2 is the previ-
ously discussed substitution of attribute &amp;quot;status&amp;quot;
for the user specified attribute &amp;quot;classification&amp;quot;
in the query
&amp;quot;What is the classification of Dr. Smith?&amp;quot;
Categories 3 and 4 contain substitutions that
are formed by either a Category 1 path expansion
followed by a Category 2 substitution or by two
Category 2 substitutions.
Third, the semantic difference between the
revised query and the original query is measured
in two ways. First, if the revised query is an
expanded path, we count the number of relations
comprising that path; shorter paths are more
desirable than longer ones. Second, if the
revised query contains an attribute, relation,
function, or entity set substitution, we use a
generalization hierarchy to semantically compare
substitutions with the items for which they are
substituted. Our difference measure is the dis-
tance from the item for which the substitution is
being made to the closest common ancestor of it
and the substituted item; small difference meas-
ures are preferred. In particular, each attri-
bute, relation, function, and entity set ATTRFENT
is assigned to a primitive semantic class:
PRIM-CLASS(ATTRFENT , CLASSA)
Each semantic class is assigned at most one
immediate superclass of which it is a proper sub-
set:
SUPER(CLASSA,CLASSB)
We define function f such that
f(ATTRFENT , 1+1) = CLASS
if PRIM-CLASS(ATTRFENT,CLASSal)
and SUPER(CLASSa1,CLASSa2)
and SUPER(CLASSa2,CLASSa3)
and ...
and SUPER(CLASSai,CLASS)
If a revised query proposes substituting
ATTRFENTnew for ATTRFENTold, then
</bodyText>
<equation confidence="0.648014333333333">
semantiadifference(ATTRFENTnew,ATTRFENTold)
=NIL if there does not exist j,k such that
f(ATTRFENTnew,j)=f(ATTRFENTold,k)
</equation>
<bodyText confidence="0.982904952380952">
=min k such that there exists j such that
f(ATTRFENTnew,j)=f(ATTRFENTold,k)
otherwise
An initial set is constructed consistiDg of
those suggested revised queries that interrogate
an aspect of the current focused plan in the con-
text model. These revised queries are particu-
larly relevant to the current local context of the
dialogue. Members of this set whose difference
measure is small and whose revision operation con-
sists of a path expansion or simple substitution
are considered and the most relevant of these are
selected by measuring the depth within the focused
plan of the component that suggested each revised
query. If none of these revised queries meets a
predetermined acceptance level, the same selection
criteria are applied to a newly constructed set of
revised queries suggested by a higher level active
plan whose expansion led to the current focused
plan, and a less stringent set of selection cri-
teria are applied to the original revised query .
aet. (The revised queries in this new set are not
immediately relevant to the current local dialogue
context but are relevant to the global context.)
As we consider revised queries suggested by higher
level plans in the stack of active plans
representing the global context, the acceptance
level for previously considered queries is
decreased. Thus revised queries which were not
rated highly enough to terminate processing when
first suggested may eventually be accepted after
less relevant aspects of the dialogue have been
investigated. This relaxation and query set
expansion is repeated until either an acceptable
revised query is produced or all potential revised
queries have been considered.
V EXAMPLES
Several examples are provided to illustrate
the suggestion and selection strategies.
[I] Relation or Entity Set Substitution
&amp;quot;Which apartments are for sale?&amp;quot;
In a real-estate model, single apart-
ments are rented, not sold. However apart-
ment buildings, condominiums, townhouses, and
houses are for sale. Thus the speaker&apos;s
utterance contains the erroneous proposition
For-Sale(apartment)
where apartment is a member of entity set
APARTMENT.
If the preceding dialogue indicates that
the speaker is seeking temporary living
arrangements, then expansion of the context
model representing the speaker&apos;s inferred
plan will contain the possible action
Rent(SPEAKER,apartment)
such that For-Rent(apartment)
The substitution rules propose substituting
relation For-Rent from this plan in place of
relation For-Sale in the speaker&apos;s utterance.
On the other hand, if the preceding
dialogue indicates that the speaker
represents a real estate investment trust
interested in expanding its holdings, an
</bodyText>
<page confidence="0.996592">
204
</page>
<bodyText confidence="0.9465452">
expansion of the context model representing
the speaker&apos;s inferred plan will contain the
possible action
Purchase(SPEAKER,apartment -building)
where apartment-building is a member of
entity set APARTMENT-BUILDING. Purchasing an
apartment building necessitates that the
building be for sale or that one convince the
owner to sell it. Thus one expansion of this
Purchase plan includes the precondition
</bodyText>
<subsectionHeader confidence="0.657558">
For-Sale(apartment -building)
</subsectionHeader>
<bodyText confidence="0.931475307692308">
The substitution rules propose substituting
entity set APARTMENT-BUILDING from this plan
for the entity set APARTMENT in the speaker&apos;s
utterance.
[3] Expanded Relational Path
&amp;quot;When does MitChel meet?&amp;quot;
A university model does not contain a
relation MEET between FACULTY and TIMES.
However, faculty teach courses, present sem-
inars, chair committees, etc., and courses,
seminars, and committees meet at scheduled
times. The speaker&apos;s utterance contains the
erroneous proposition
</bodyText>
<subsectionHeader confidence="0.719537">
Meet -Time(Dr.Mitchel,time)
</subsectionHeader>
<bodyText confidence="0.985313428571429">
If the preceding dialogue indicates that
the speaker is considering taking CS105, then
an expansion of the context model represent-
ing the speaker&apos;s inferred plan will contain
the action
Earn-Credit-In-Section(SPEAKER,section)
such that Is-Section-Of(section,CS105)
</bodyText>
<sectionHeader confidence="0.435444" genericHeader="method">
[2] Function Substitution
</sectionHeader>
<bodyText confidence="0.986419180327869">
&amp;quot;What is the average rank of CS faculty?&amp;quot;
The function AVERAGE cannot be applied
to non-numeric elements such as &amp;quot;professor&amp;quot;.
The speaker&apos;s utterance contains the errone-
ous proposition
AVERAOE(rank,fn-value)
such that Department -0f(faculty,CS)
and Rank(faculty,rank)
If the preceding dialogue indicates that the
speaker is evaluating the CS department, then
an expansion of the context model represent-
ing the speaker&apos;s inferred plan will contain
the possible action
Evaluate-Faculty(SPEAKER,CS)
The plan for Evaluate-Faculty contains the
action
Evaluate(SPEAKER,ave-rank)
such that ORDERED-AVE(rank,ave-rank)
and Department -0f(faculty,CS)
and Rank(faculty,rank)
If a domain D of non-numeric elements has an
explicit ordering, then we can associate with
each of the n domain elements an index number
between 0 and n-1 specifying its position in
the sorted domain. The function ORDERED-AVE
appearing in the speaker&apos;s plan operates upon
non-nuneric elements of such domains by cal-
culating the average of the index nunbers
associated with each element instead of
attempting to calculate the average of the
elements themselves. The substitution rules
propose substituting the function ORDERED-AVE
from the speaker&apos;s inferred plan for the
function AVERAGE in the speaker&apos;s utterance.
ORDERED-AVE and AVERAGE are semantically
similar functions so the difference measure
for the resultant revised query will be
small.
Expansion of the plan for Earn-Credit-In-
Section contains the action
Learn-From -Teacher-In-Class(SPEAKER,
section, faculty)
such that Teach(faculty,section)
and the plan for this action contains the
action
Attend-Class(SPEAKER,place,time)
such that Meet-Place(section,place)
and Meet -Time(section,time)
The two relations Teach(Dr.Mitchel,section)
and Meet -Time(section,time) appear on the
same path in the context model. Therefore
the path expansion heuristics suggest the
expanded relational path
Teach(Dr.Mitchel,section)*Meet-Time(section,time)
as a substitution for the relation
Meet-Time(Dr.Mitchel,time)
in the user&apos;s utterance. Only one arc is
added to produce the expanded relational path
and it contains the user-specified relation
Meet-Time, so the difference measure for this
revised query is small.
</bodyText>
<sectionHeader confidence="0.9958" genericHeader="method">
VI RELATED WORK
</sectionHeader>
<bodyText confidence="0.9997546">
Erik Mays[1980] discusses the recognition of
pragmatic overshoot and proposes a response con-
taining a list of those entity sets that are
related by the user-specified relation and a list
of those relations that connect the user-specified
entity sets. However he does not use a model of
whether these possibilities are applicable to the
user&apos;s underlying task. In a large database, such
responses will be too lengthy and include too many
irrelevant alternatives.
</bodyText>
<page confidence="0.995365">
205
</page>
<bodyText confidence="0.965479407407407">
Kaplan[1979], Chang[1978], and Sowa[1976]
have investigated the problem of missing joins
between entity sets. Kaplan proposes using the
shortest relational path connecting the entity
sets; Chang proposes an algorithm based on minimal
spanning trees, using an a priori weigbting of the.
arcs; Sowa uses a conceptual graph (semantic net)
for constructing the expanded relation. None of
these present a model of whether the proposed path
is relevant to the speaker&apos;s intentions.
VII LIMITATIONS AND FUTURE WORK
Pragmatic overshoot processing has been
implemented for a domain consisting of a subset of
the courses, requirements, and policies for stu-
dents at a University. Our system assumes that
the relations comprising a meaningful and relevant
path expansion will appear on a single path within
the context tree representing the speaker&apos;s
inferred plan. This restricts such expansions to
those communicated via the speaker&apos;s underlying
inferred task-related plan. However this plan may
fail to capture some associations, such as between
a person&apos;s Social Security Number and his name.
This problem of producing precisely the set of
path expansions that are meaningful and relevant
must be investigated further. Other areas for
future work include:
</bodyText>
<reference confidence="0.8875194">
[1] Extensions to handle relationships among more
than two entity sets
[2] Extensions to the other classes of pragmatic
overshoot mentioned in the introduction.
[3] Extensions to detect and respond to queries
</reference>
<bodyText confidence="0.86607275">
which exceed the knowledge represented in the
underlying world model. We are currently
assuming that the system can provide the
information needed by the speaker.
</bodyText>
<sectionHeader confidence="0.99859" genericHeader="method">
VIII CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999901083333333">
The main contribution of our work is a
context-based strategy for constructing a coopera-
tive but limited response to pragmatically ill-
formed queries. This response satisfies the
speaker&apos;s perceived needs, inferred both from the
preceding dialogue and the ill-formed utterance.
Our hypothesis is that the speaker&apos;s inferred
task-related plan, represented by the context
model, suggests a substitution for the proposition
causing the pragmatic overshoot and that such
suggestions then must be evaluated on the basis of
relevance and semantic criteria.
</bodyText>
<sectionHeader confidence="0.986623" genericHeader="conclusions">
ACKNOWLELOMENTS
</sectionHeader>
<bodyText confidence="0.9999176">
I would like to thank Ralph Weischedel for
his encouragement and direction in this research
and for his suggestions on the style and content
of this paper and Lance Ramshaw for many helpful
discussions.
</bodyText>
<sectionHeader confidence="0.993282" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.9889688125">
1. Carberry, S., &amp;quot;Tracking User Goals in an
Information-Seeking Environment&amp;quot;, ?roc,. tut.
Conf. On Artificial Intelligence, Washing-
ton, D.C., 1983
2. Chang, C. L., &amp;quot;Finding Missing Joins for
Incomplete Queries in Relational Data Bases&amp;quot;
IBM Res. Lab., RJ2145, San Jose, Ca., 1978
3. Fikes, R. E. and N. J. Nilsson, &amp;quot;STRIPS: A
New Approach to the Application of Theorem
Proving to Problem Solving&amp;quot;, Artificial
IDtelligence 2, 1971
4. Kaplan, S. J., &amp;quot;Cooperative Responses from a
Portable Natural Language Data Base Query
System&amp;quot;, Ph.D. Diss., Univ. of Pennsyl-
vania,1979
5. Mays,E., &amp;quot;Failures in Natural Language Query
Systems: Applications to Data Base Query Sys-
tems&amp;quot;, Proc. at. cont. On Artificial
Intelligence, Stanford, 1980
6. Quine, W. V., &amp;quot;Ontological Relativity&amp;quot; in
Ontological ftelativitv and Other Bssavs ,
Columbia University Press, New York 1969
7. Ramsbaw, L. A. and R. M. Weischedel, &amp;quot;Problem
Localization Strategies for Pragmatic Pro-
cessing in Natural Language Front Ends&amp;quot;,
Proo. QL ath at. Q. qa Computational
Linguistics, 1984
8. Sondheimer, N. K. and R. M. Weischedel, &amp;quot;A
Rule-Based Approach to Ill-Formed Input&amp;quot;,
Proc. 1th Int. Conf. on Computational
Lineuistico, 1980
9. Sowa, J. F., &amp;quot;Conceptual Graphs for a Data
Base Interface&amp;quot;, LM iggrngl of Research and
Development, July 1976
10. Thompson, B. H., &amp;quot;Linguistic Analysis of
Natural Language Communication with Comput -
era&amp;quot;, ?roc I= Int. Conf. on Compute-
tional Linguistics, 1980
11. Webber, B. L. and E. Mays, &amp;quot;Varieties of User
Misconceptions: Detection and Correction&amp;quot;,
Proc. ath Int. Joint Conf. gn Artificial
Intelligence, Karlsruhe, West Germany, August
1 983
12. Weischedel, R. M. and N. K. Sondheimer,
&amp;quot;Meta-Rules as a Basis for Processing Ill-
Formed Input&amp;quot;, (to appear in American Journal
2f Computational Linguistics, Vol. 9, #3,
1983)
</reference>
<page confidence="0.998849">
206
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.938293">
<title confidence="0.999431">UNDERSTANDING PRAGMATICALLY ILL-FORMED INPUT</title>
<author confidence="0.999899">M Sandra Carberry</author>
<affiliation confidence="0.999954">Department of Computer Science University of Delaware</affiliation>
<address confidence="0.99557">Newark, Delaware 19711 USA</address>
<abstract confidence="0.995218583333333">An utterance may be syntactically and semantically well-formed yet violate the pragmatic rules of the world model. This paper presents a context-based strategy for constructing a cooperative but limited response to pragmatically illformed queries. Suggestion heuristics use a context model of the speaker&apos;s task inferred from the preceding dialogue to propose revisions to the speaker&apos;s ill-formed query. Selection heuristics then evaluate these suggestions based upon semantic and relevance criteria.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>[1] Extensions to handle relationships among more than two entity sets [2] Extensions to the other classes of pragmatic overshoot mentioned in the introduction. [3] Extensions to detect and respond to queries</title>
<marker></marker>
<rawString> [1] Extensions to handle relationships among more than two entity sets [2] Extensions to the other classes of pragmatic overshoot mentioned in the introduction. [3] Extensions to detect and respond to queries</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
</authors>
<title>Tracking User Goals in an Information-Seeking Environment&amp;quot;,</title>
<date>1983</date>
<booktitle>roc,. tut. Conf. On Artificial Intelligence,</booktitle>
<location>Washington, D.C.,</location>
<contexts>
<context position="1017" citStr="[1]" startWordPosition="147" endWordPosition="147">euristics use a context model of the speaker&apos;s task inferred from the preceding dialogue to propose revisions to the speaker&apos;s ill-formed query. Selection heuristics then evaluate these suggestions based upon semantic and relevance criteria. I INTRODUCTION An utterance may be syntactically and semantically well-formed yet violate the pragmatic rules of the world model. The system will therefore view it as &amp;quot;ill-formed&amp;quot; even if a native speaker finds it perfectly normal. This phenomenon has been termed &amp;quot;pragmatic overshoot&amp;quot; [Sondheimer and Weischede1,1980] and may be divided into three classes: [1] User-specified relationships that do not exist in the world model. EXAMPLE: &amp;quot;Which apartments are for sale?&amp;quot; In a real estate model, single apartments are rented, not sold. However apartment buildings, condominiums, townhouses, and houses are for sale. [2] User-specified restrictions on the relationships which can never be satisfied, even with new entries. EXAMPLE: &amp;quot;Which lower-level English courses have a maximum enrollment of at most 25 students?&amp;quot; In a University world model, it may be the case that the maximum enrollments of This material is based upon work supported by the National Scienc</context>
<context position="4722" citStr="[1]" startWordPosition="713" endWordPosition="713">ic overshoot processing is part of an on-going project to develop a robust natural language interface [Weischedel and Sondheimer, 1983]. Mays[1980], Webber and Mays[1983], and Ramshaw and Weischedel[1984] have suggested mechanisms for detecting the occurrence of pragmatic overshoot and identifying its causes. The main contribution of our work is a contextbased strategy for constructing a cooperative but limited response to pragmatically ill-formed queries. This response satisfies the user&apos;s perceived needs, inferred both from the preceding dialogue and the ill-formed utterance. In particular, [1] A context model of the user&apos;s goals and plans provides expectations about utterances, expectations that may be used to model the user&apos;s goals. We use a context mechanism [Carberry, 1983] to build the speaker&apos;s underlying task-related plan as the dialogue progresses and differentiate between local and global contexts. [2] Only alternative queries which might represent the user&apos;s intent or at least satisfy his needs are considered. QUL bvPothesis lm that the user&apos;s inferred am, raoresented hythe context model, mummeetm m substitution fur the proposition gaming the pragmatic. pvershoot. II KM:LE</context>
<context position="15161" citStr="[1]" startWordPosition="2311" endWordPosition="2311">-related plan prohibits composing Assists(teaching-assistant,section) and Meet -Time(section,time) to suggest a reply consisting of the times that the CS105 sections meet. B. $electiou EtLimami The substitution and path expansion rules propose substitutions for the erroneous proposition that caused the pragmatic overshoot. Three criteria are used to select from the proposed substitutions the revised query, if any, that is most likely to satisfy the speaker&apos;s intent in making the utterance. First, the relevance of the revised query to the speaker&apos;s plans and goals is measured by three factors: [1] A revised query that interrogates an aspect of the current focused plan is most relevant to the current dialogue. [2] The set of higher level plans whose expansions led to the current focused plan form a stack of increasingly more general, and therefore less immediately relevant, active plans to which the user may return. A revised query which interrogates an aspect of an active plan closer to the top of this stack is more expected than a query which reverts back to a more general active plan. [3] Within a given active plan, a revised query that investigates the single-level expansion of an a</context>
</contexts>
<marker>1.</marker>
<rawString>Carberry, S., &amp;quot;Tracking User Goals in an Information-Seeking Environment&amp;quot;, ?roc,. tut. Conf. On Artificial Intelligence, Washington, D.C., 1983</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Chang</author>
</authors>
<title>Finding Missing Joins for Incomplete Queries in Relational Data Bases&amp;quot;</title>
<date>1978</date>
<booktitle>IBM Res. Lab., RJ2145,</booktitle>
<location>San Jose, Ca.,</location>
<contexts>
<context position="1274" citStr="[2]" startWordPosition="187" endWordPosition="187">An utterance may be syntactically and semantically well-formed yet violate the pragmatic rules of the world model. The system will therefore view it as &amp;quot;ill-formed&amp;quot; even if a native speaker finds it perfectly normal. This phenomenon has been termed &amp;quot;pragmatic overshoot&amp;quot; [Sondheimer and Weischede1,1980] and may be divided into three classes: [1] User-specified relationships that do not exist in the world model. EXAMPLE: &amp;quot;Which apartments are for sale?&amp;quot; In a real estate model, single apartments are rented, not sold. However apartment buildings, condominiums, townhouses, and houses are for sale. [2] User-specified restrictions on the relationships which can never be satisfied, even with new entries. EXAMPLE: &amp;quot;Which lower-level English courses have a maximum enrollment of at most 25 students?&amp;quot; In a University world model, it may be the case that the maximum enrollments of This material is based upon work supported by the National Science Foundation under grants 1ST8009673 and IST-8311400 lower-level English courses are constrained to have values larger than 25 but that such constraints do not apply to the current enrollments of courses, the maximum enrollments of upper-level English cours</context>
<context position="5045" citStr="[2]" startWordPosition="762" endWordPosition="762">tribution of our work is a contextbased strategy for constructing a cooperative but limited response to pragmatically ill-formed queries. This response satisfies the user&apos;s perceived needs, inferred both from the preceding dialogue and the ill-formed utterance. In particular, [1] A context model of the user&apos;s goals and plans provides expectations about utterances, expectations that may be used to model the user&apos;s goals. We use a context mechanism [Carberry, 1983] to build the speaker&apos;s underlying task-related plan as the dialogue progresses and differentiate between local and global contexts. [2] Only alternative queries which might represent the user&apos;s intent or at least satisfy his needs are considered. QUL bvPothesis lm that the user&apos;s inferred am, raoresented hythe context model, mummeetm m substitution fur the proposition gaming the pragmatic. pvershoot. II KM:LEDGE REPRESENTATION Our system requires a representation for each of the following: [1] the set of domain-dependent plans and goals [2] the speaker&apos;s plan inferred from the preceding dialogue [3] the existing relationships among attributes and entity sets in the underlying world model [4] the semantic difference of attribu</context>
<context position="15279" citStr="[2]" startWordPosition="2331" endWordPosition="2331">consisting of the times that the CS105 sections meet. B. $electiou EtLimami The substitution and path expansion rules propose substitutions for the erroneous proposition that caused the pragmatic overshoot. Three criteria are used to select from the proposed substitutions the revised query, if any, that is most likely to satisfy the speaker&apos;s intent in making the utterance. First, the relevance of the revised query to the speaker&apos;s plans and goals is measured by three factors: [1] A revised query that interrogates an aspect of the current focused plan is most relevant to the current dialogue. [2] The set of higher level plans whose expansions led to the current focused plan form a stack of increasingly more general, and therefore less immediately relevant, active plans to which the user may return. A revised query which interrogates an aspect of an active plan closer to the top of this stack is more expected than a query which reverts back to a more general active plan. [3] Within a given active plan, a revised query that investigates the single-level expansion of an action is more expected, and therefore more relevant, than a revised query that investigates details at a much deeper l</context>
<context position="22906" citStr="[2]" startWordPosition="3450" endWordPosition="3450"> Path &amp;quot;When does MitChel meet?&amp;quot; A university model does not contain a relation MEET between FACULTY and TIMES. However, faculty teach courses, present seminars, chair committees, etc., and courses, seminars, and committees meet at scheduled times. The speaker&apos;s utterance contains the erroneous proposition Meet -Time(Dr.Mitchel,time) If the preceding dialogue indicates that the speaker is considering taking CS105, then an expansion of the context model representing the speaker&apos;s inferred plan will contain the action Earn-Credit-In-Section(SPEAKER,section) such that Is-Section-Of(section,CS105) [2] Function Substitution &amp;quot;What is the average rank of CS faculty?&amp;quot; The function AVERAGE cannot be applied to non-numeric elements such as &amp;quot;professor&amp;quot;. The speaker&apos;s utterance contains the erroneous proposition AVERAOE(rank,fn-value) such that Department -0f(faculty,CS) and Rank(faculty,rank) If the preceding dialogue indicates that the speaker is evaluating the CS department, then an expansion of the context model representing the speaker&apos;s inferred plan will contain the possible action Evaluate-Faculty(SPEAKER,CS) The plan for Evaluate-Faculty contains the action Evaluate(SPEAKER,ave-rank) such</context>
</contexts>
<marker>2.</marker>
<rawString>Chang, C. L., &amp;quot;Finding Missing Joins for Incomplete Queries in Relational Data Bases&amp;quot; IBM Res. Lab., RJ2145, San Jose, Ca., 1978</rawString>
</citation>
<citation valid="true">
<authors>
<author>R E Fikes</author>
<author>N J Nilsson</author>
</authors>
<title>STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving&amp;quot;,</title>
<date>1971</date>
<journal>Artificial IDtelligence</journal>
<volume>2</volume>
<contexts>
<context position="5516" citStr="[3]" startWordPosition="833" endWordPosition="833">build the speaker&apos;s underlying task-related plan as the dialogue progresses and differentiate between local and global contexts. [2] Only alternative queries which might represent the user&apos;s intent or at least satisfy his needs are considered. QUL bvPothesis lm that the user&apos;s inferred am, raoresented hythe context model, mummeetm m substitution fur the proposition gaming the pragmatic. pvershoot. II KM:LEDGE REPRESENTATION Our system requires a representation for each of the following: [1] the set of domain-dependent plans and goals [2] the speaker&apos;s plan inferred from the preceding dialogue [3] the existing relationships among attributes and entity sets in the underlying world model [4] the semantic difference of attributes, relations, entity sets, and functions. Plans are represented using an extended STRIPS [Fikes and Nilsson, 1971] formalism. A plan can contain subgoals and actions that have associated plans. We use a context tree [Carberry, 1983] to represent the speaker&apos;s inferred plan as constructed from the preceding dialogue. Nodes within this tree represent goals and actions which • the speaker has investigated; these nodes are descendants of parent nodes representing highe</context>
<context position="15664" citStr="[3]" startWordPosition="2400" endWordPosition="2400">he relevance of the revised query to the speaker&apos;s plans and goals is measured by three factors: [1] A revised query that interrogates an aspect of the current focused plan is most relevant to the current dialogue. [2] The set of higher level plans whose expansions led to the current focused plan form a stack of increasingly more general, and therefore less immediately relevant, active plans to which the user may return. A revised query which interrogates an aspect of an active plan closer to the top of this stack is more expected than a query which reverts back to a more general active plan. [3] Within a given active plan, a revised query that investigates the single-level expansion of an action is more expected, and therefore more relevant, than a revised query that investigates details at a much deeper level of expansion. Second, we can classify the substitution T--&gt;V which produced the revised query into four categories, each of which represents a more significant, and therefore less preferable, alteration of the user&apos;s query (Figure 1). Category 1 contains expanded relational paths R1*R211...4Rn such that the user-specified attribute or relation appears in the path expression. Fo</context>
<context position="22283" citStr="[3]" startWordPosition="3368" endWordPosition="3368">ng its holdings, an 204 expansion of the context model representing the speaker&apos;s inferred plan will contain the possible action Purchase(SPEAKER,apartment -building) where apartment-building is a member of entity set APARTMENT-BUILDING. Purchasing an apartment building necessitates that the building be for sale or that one convince the owner to sell it. Thus one expansion of this Purchase plan includes the precondition For-Sale(apartment -building) The substitution rules propose substituting entity set APARTMENT-BUILDING from this plan for the entity set APARTMENT in the speaker&apos;s utterance. [3] Expanded Relational Path &amp;quot;When does MitChel meet?&amp;quot; A university model does not contain a relation MEET between FACULTY and TIMES. However, faculty teach courses, present seminars, chair committees, etc., and courses, seminars, and committees meet at scheduled times. The speaker&apos;s utterance contains the erroneous proposition Meet -Time(Dr.Mitchel,time) If the preceding dialogue indicates that the speaker is considering taking CS105, then an expansion of the context model representing the speaker&apos;s inferred plan will contain the action Earn-Credit-In-Section(SPEAKER,section) such that Is-Sectio</context>
</contexts>
<marker>3.</marker>
<rawString>Fikes, R. E. and N. J. Nilsson, &amp;quot;STRIPS: A New Approach to the Application of Theorem Proving to Problem Solving&amp;quot;, Artificial IDtelligence 2, 1971</rawString>
</citation>
<citation valid="false">
<authors>
<author>S J Kaplan</author>
</authors>
<title>Cooperative Responses from a Portable Natural Language Data Base Query System&amp;quot;,</title>
<institution>Ph.D. Diss., Univ. of Pennsylvania,1979</institution>
<contexts>
<context position="5610" citStr="[4]" startWordPosition="847" endWordPosition="847">between local and global contexts. [2] Only alternative queries which might represent the user&apos;s intent or at least satisfy his needs are considered. QUL bvPothesis lm that the user&apos;s inferred am, raoresented hythe context model, mummeetm m substitution fur the proposition gaming the pragmatic. pvershoot. II KM:LEDGE REPRESENTATION Our system requires a representation for each of the following: [1] the set of domain-dependent plans and goals [2] the speaker&apos;s plan inferred from the preceding dialogue [3] the existing relationships among attributes and entity sets in the underlying world model [4] the semantic difference of attributes, relations, entity sets, and functions. Plans are represented using an extended STRIPS [Fikes and Nilsson, 1971] formalism. A plan can contain subgoals and actions that have associated plans. We use a context tree [Carberry, 1983] to represent the speaker&apos;s inferred plan as constructed from the preceding dialogue. Nodes within this tree represent goals and actions which • the speaker has investigated; these nodes are descendants of parent nodes representing higher-level goals whose associated plans contain these lowerlevel actions. The context tree repres</context>
</contexts>
<marker>4.</marker>
<rawString>Kaplan, S. J., &amp;quot;Cooperative Responses from a Portable Natural Language Data Base Query System&amp;quot;, Ph.D. Diss., Univ. of Pennsylvania,1979</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mays</author>
</authors>
<title>Failures in Natural Language Query Systems: Applications to Data Base Query Systems&amp;quot;,</title>
<date>1980</date>
<booktitle>Proc. at. cont. On Artificial Intelligence,</booktitle>
<location>Stanford,</location>
<marker>5.</marker>
<rawString>Mays,E., &amp;quot;Failures in Natural Language Query Systems: Applications to Data Base Query Systems&amp;quot;, Proc. at. cont. On Artificial Intelligence, Stanford, 1980</rawString>
</citation>
<citation valid="true">
<authors>
<author>W V Quine</author>
</authors>
<title>Ontological Relativity&amp;quot; in Ontological ftelativitv and Other Bssavs ,</title>
<date>1969</date>
<publisher>Columbia University Press,</publisher>
<location>New York</location>
<marker>6.</marker>
<rawString>Quine, W. V., &amp;quot;Ontological Relativity&amp;quot; in Ontological ftelativitv and Other Bssavs , Columbia University Press, New York 1969</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramsbaw</author>
<author>R M Weischedel</author>
</authors>
<title>Problem Localization Strategies for Pragmatic Processing in Natural Language Front Ends&amp;quot;,</title>
<date>1984</date>
<booktitle>Proo. QL ath at. Q. qa Computational Linguistics,</booktitle>
<marker>7.</marker>
<rawString>Ramsbaw, L. A. and R. M. Weischedel, &amp;quot;Problem Localization Strategies for Pragmatic Processing in Natural Language Front Ends&amp;quot;, Proo. QL ath at. Q. qa Computational Linguistics, 1984</rawString>
</citation>
<citation valid="true">
<authors>
<author>N K Sondheimer</author>
<author>R M Weischedel</author>
</authors>
<title>A Rule-Based Approach to Ill-Formed Input&amp;quot;,</title>
<date>1980</date>
<booktitle>Proc. 1th Int. Conf. on Computational Lineuistico,</booktitle>
<marker>8.</marker>
<rawString>Sondheimer, N. K. and R. M. Weischedel, &amp;quot;A Rule-Based Approach to Ill-Formed Input&amp;quot;, Proc. 1th Int. Conf. on Computational Lineuistico, 1980</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Sowa</author>
</authors>
<title>Conceptual Graphs for a Data Base Interface&amp;quot;,</title>
<date>1976</date>
<booktitle>LM iggrngl of Research and Development,</booktitle>
<marker>9.</marker>
<rawString>Sowa, J. F., &amp;quot;Conceptual Graphs for a Data Base Interface&amp;quot;, LM iggrngl of Research and Development, July 1976</rawString>
</citation>
<citation valid="true">
<authors>
<author>B H Thompson</author>
</authors>
<title>Linguistic Analysis of Natural Language Communication with Comput -era&amp;quot;,</title>
<date>1980</date>
<booktitle>roc I= Int. Conf. on Computetional Linguistics,</booktitle>
<marker>10.</marker>
<rawString>Thompson, B. H., &amp;quot;Linguistic Analysis of Natural Language Communication with Comput -era&amp;quot;, ?roc I= Int. Conf. on Computetional Linguistics, 1980</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Webber</author>
<author>E Mays</author>
</authors>
<title>Varieties of User Misconceptions: Detection and Correction&amp;quot;,</title>
<date></date>
<booktitle>Proc. ath Int. Joint Conf. gn Artificial Intelligence,</booktitle>
<volume>1</volume>
<pages>983</pages>
<location>Karlsruhe, West Germany,</location>
<marker>11.</marker>
<rawString>Webber, B. L. and E. Mays, &amp;quot;Varieties of User Misconceptions: Detection and Correction&amp;quot;, Proc. ath Int. Joint Conf. gn Artificial Intelligence, Karlsruhe, West Germany, August 1 983</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Weischedel</author>
<author>N K Sondheimer</author>
</authors>
<title>Meta-Rules as a Basis for Processing IllFormed Input&amp;quot;,</title>
<date>1983</date>
<journal>American Journal 2f Computational Linguistics,</journal>
<volume>9</volume>
<note>to appear in</note>
<marker>12.</marker>
<rawString>Weischedel, R. M. and N. K. Sondheimer, &amp;quot;Meta-Rules as a Basis for Processing IllFormed Input&amp;quot;, (to appear in American Journal 2f Computational Linguistics, Vol. 9, #3, 1983)</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>