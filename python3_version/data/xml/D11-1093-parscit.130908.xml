<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.999">
Refining the Notions of Depth and Density in WordNet-based
Semantic Similarity Measures
</title>
<author confidence="0.999633">
Tong Wang
</author>
<affiliation confidence="0.9992255">
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.996424">
tong@cs.toronto.edu
</email>
<author confidence="0.995525">
Graeme Hirst
</author>
<affiliation confidence="0.9992115">
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.998371">
gh@cs.toronto.edu
</email>
<sectionHeader confidence="0.995641" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999489">
We re-investigate the rationale for and the ef-
fectiveness of adopting the notions of depth
and density in WordNet-based semantic sim-
ilarity measures. We show that the intuition
for including these notions in WordNet-based
similarity measures does not always stand up
to empirical examination. In particular, the
traditional definitions of depth and density
as ordinal integer values in the hierarchical
structure of WordNet does not always corre-
late with human judgment of lexical semantic
similarity, which imposes strong limitations
on their contribution to an accurate similarity
measure. We thus propose several novel defi-
nitions of depth and density, which yield sig-
nificant improvement in degree of correlation
with similarity. When used in WordNet-based
semantic similarity measures, the new defini-
tions consistently improve performance on a
task of correlating with human judgment.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99928825">
Semantic similarity measures are widely used in
natural language processing for measuring distance
between meanings of words. There are currently
two mainstream approaches to deriving such mea-
sures, i.e., distributional and lexical resource-based
approaches. The former usually explores the co-
occurrence patterns of words in large collections
of texts such as text corpora (Lin, 1998) or the
Web (Turney, 2001). The latter takes advantage of
mostly handcrafted information, such as dictionar-
ies (Chodorow et al., 1985; Kozima and Ito, 1997)
or thesauri (Jarmasz and Szpakowicz, 2003).
</bodyText>
<page confidence="0.829021">
1003
</page>
<bodyText confidence="0.999148352941176">
Another important resource in the latter stream is
semantic taxonomies such as WordNet (Fellbaum,
1998). Despite their high cost of compilation and
limited availability across languages, semantic tax-
onomies have been widely used in similarity mea-
sures, and one of the main reasons behind this is that
the often complex notion of lexical semantic simi-
larity can be approximated with ease by the distance
between words (represented as nodes) in their hier-
archical structures, and this approximation appeals
much to our intuition. Even methods as simple as
“hop counts” between nodes (e.g., that of Rada et al.
1989 on the English WordNet) can take us a long
way. Meanwhile, taxonomy-based methods have
been constantly refined by incorporating various
structural features such as depth (Sussna, 1993; Wu
and Palmer, 1994), density (Sussna, 1993), type of
connection (Hirst and St-Onge, 1998; Sussna, 1993),
word class (sense) frequency estimates (Resnik,
1999), or a combination these features (Jiang and
Conrath, 1997). Most of these algorithms are fairly
self-contained and easy to implement, with off-the-
shelf toolkits such as that of Pedersen et al. (2004).
With the existing literature focusing on carefully
weighting these features to construct a better seman-
tic similarity measure, however, the rationale for
adopting these features in calculating semantic sim-
ilarity remains largely intuitive. To the best of our
knowledge, there is no empirical study directly in-
vestigating the effectiveness of adopting structural
features such as depth and density. This serves as
the major motivation for this study.
The paper is organized as follows. In Section
2 we review the basic rationale for adopting depth
</bodyText>
<note confidence="0.948744">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1003–1011,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.999123">
and density in WordNet-based similarity measures
as well as existing literature on constructing such
measures. In Section 3, we show the limitations of
the current definitions of depth and density as well as
possible explanations for these limitations.1 We then
propose new definitions to avoid such limitations in
Section 4. The effectiveness of the new definitions
is evaluated by applying them in semantic similar-
ity measures in Section 5 and conclusions made in
Section 6.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999954909090909">
The following are the current definitions of depth
and density which we aim at improving. Given a
node/concept c in WordNet, depth refers to the num-
ber of nodes between c and the root of WordNet,
(i.e., the root has depth zero, its hyponyms depth
one, and so on). There are more variations in the
definition of density, but it is usually defined as the
number of edges leaving c (i.e., its number of child
nodes) or leaving its parent node(s) (i.e., its number
of sibling nodes). We choose to use the latter since
it is used by most of the existing literature.
</bodyText>
<subsectionHeader confidence="0.996243">
2.1 The Rationale for Depth and Density
</subsectionHeader>
<bodyText confidence="0.993985368421053">
The rationale for using the notions of depth and den-
sity in WordNet-based semantic similarity measures
is based on the following assumption:
Assumption 1 Everything else being equal, two
nodes are semantically closer if (a) they reside
deeper in the WordNet hierarchy, or (b) they are
more densely connected locally.
This is the working assumption for virtually all
WordNet-based semantic similarity studies using
depth and/or density. For depth, the intuition is
that adjacent nodes deep down the hierarchy are
likely to be conceptually close, since the differen-
tiation is based on finer details (Jiang and Conrath,
1997). Sussna (1993) termed the use of depth as
depth-relative scaling, claiming that “only-siblings
deep in a tree are more closely related than only-
siblings higher in the tree”. Richardson and Smeaton
(1995) gave an hypothetical example illustrating
this “only-siblings” situation, where plant–animal
</bodyText>
<footnote confidence="0.711829333333333">
1Since the works we review in this section have different
definitions of depth and density, we defer our formal definitions
to Section 3.
</footnote>
<bodyText confidence="0.999590375">
are the only two nodes under living things, and
wolfhound–foxhound under hound. They claimed
the reason that the former pair can be regarded as
conceptually farther apart compared to the latter is
related to the difference in depth.
As for the relation between density and similar-
ity, the intuition is that if the overall semantic mass
for a given node is constant (Jiang and Conrath,
1997), then the more neighboring nodes there are in
a locally connected subnetwork, the closer its mem-
bers are to each other. For example, animal, per-
son, and plant are more strongly connected with life
form than aerobe and plankton because the first three
words all have high density in their local network
structures (Richardson and Smeaton, 1995). Note
that the notion of density here is not to be con-
fused with the conceptual density used by Agirre
and Rigau (1996), which is essentially a semantic
similarity measure by itself.
In general, both observations on depth and density
conform to intuition and are supported qualitatively
by several existing studies. The main objective of
this study is to empirically examine the validity of
this assumption.
</bodyText>
<subsectionHeader confidence="0.992052">
2.2 Semantic Similarity Measures Using Depth
and/or Density
</subsectionHeader>
<bodyText confidence="0.9997598">
One of the first examples of using depth and den-
sity in WordNet-based similarity measures is that of
Sussna (1993). The weight on an edge between two
nodes c1 and c2 with relation r in WordNet is given
as:
</bodyText>
<equation confidence="0.980824666666667">
w(c1 →r c2)+w(c2 →r c1)
w(c1,c2) =
2d
</equation>
<bodyText confidence="0.99997975">
where d is the depth of the deeper of the two nodes.
As depth increases, weight decreases and similarity
in turn increases, conforming to Assumption 1. The
edge weight was further defined as
</bodyText>
<equation confidence="0.9970375">
w(c1 →r c2) = maxr −
nr(c1)
</equation>
<bodyText confidence="0.923172666666667">
where nr(X) is “the number of relations of type r
leaving node X”, which is essentially an implicit
form of density, and maxr and minr are the maxi-
mum and minimum of nr, respectively. Note that
this formulation of density contradicts Assumption
maxr − minr
</bodyText>
<page confidence="0.963119">
1004
</page>
<bodyText confidence="0.99396125">
1 since it is proportional to edge weight (left-hand-
side) and thus negatively correlated to similarity.
Wu and Palmer (1994) proposed a concept simi-
larity measure between two concepts c1 and c2 as:
</bodyText>
<equation confidence="0.9976995">
sim(c1,c2) = len(c1,c) + len(c2,c) + 2 · dep(c)
(1)
</equation>
<bodyText confidence="0.9994325">
where c is the lowest common subsumer (LCS) of c1
and c2, and len(·,·) is the number of edges between
two nodes. The rationale is to adjust “hop count”
(the first two terms in the denominator) with the
depth of LCS: similarity between nodes with same-
level LCS is in negative proportion to hop counts,
while given the same hop count, a “deeper” LCS
pulls the similarity score closer to 1.
Jiang and Conrath (1997) proposed a hybrid
method incorporating depth and density information
into an information-content-based model (Resnik,
1999):
</bodyText>
<equation confidence="0.993119333333333">
E¯
den(p)]
× [IC(c) − IC(p)]T(c, p) (2)
</equation>
<bodyText confidence="0.999932454545455">
Here, p and c are parent and child nodes in Word-
Net, dep(·) and den(·) denote the depth and den-
sity of a node, respectively, E¯ is the average density
over the entire network of WordNet, and a and R are
two parameters controlling the contribution of depth
and density values to the similarity score. IC(·) is
the information content of a node based on proba-
bility estimates of word classes from a small sense-
tagged corpus (Resnik, 1999), and T(c, p) is a link-
type factor differentiating different types of relations
between c and p.
</bodyText>
<sectionHeader confidence="0.9439725" genericHeader="method">
3 Limitations on the Current Definitions of
Depth and Density
</sectionHeader>
<bodyText confidence="0.999733142857143">
To what extent do the notions of depth and density
help towards an accurate semantic similarity mea-
sure? Our empirical investigation below suggests
that more often than not, they fail our intuition.
A direct assessment of the effectiveness of us-
ing depth and density is to examine their correla-
tion with similarity. Empirical results in this section
</bodyText>
<figureCaption confidence="0.997959">
Figure 1: Correlation between depth and similarity.
</figureCaption>
<bodyText confidence="0.999995434782609">
are achieved by the following experimental setting.
Depth is defined as the number of edges between the
root of the hierarchy and the lowest common sub-
sumer (LCS) of two nodes under comparison, and
density as the number of siblings of the LCS.2 Sim-
ilarity is measured by human judgment on similar-
ity between word pairs. Commonly used data sets
for such judgments include that of Rubenstein and
Goodenough (1965), Miller and Charles (1991), and
Finkelstein et al. (2001) (denoted RG, MC, and FG,
respectively). RG is a collection of similarity ratings
of 65 word pairs averaged over judgments from 51
human subjects on a scale of 0 to 4 (from least to
most similar). MC is a subset of 30 pairs out of the
RG data set. These pairs were chosen to have evenly
distributed similarity ratings in the original data set,
and similarity judgment was elicited from 38 human
judges with the same instruction as used for RG. FG
is a much larger set consisting of 353 word pairs,
and the rating scale is from 0 to 10. We combine the
RG and FG data sets in order to maximize data size.
Human ratings r on individual sets are normalized to
rn on 0 to 1 scale by the following formula:
</bodyText>
<equation confidence="0.853828333333333">
r − rmin
rn =
rmax − rmin
</equation>
<bodyText confidence="0.915272714285714">
where rmax and rmin are the maximum and minimum
of the original ratings, respectively. Correlation is
evaluated using Spearman’s p.
2We also tried several other variants of these definitions,
e.g., using the maximum or minimum depth of the two nodes
instead of the LCS. With respect to statistical significance tests,
these variants all gave the same results as our primary definition.
</bodyText>
<equation confidence="0.9971295">
2 · dep(c)
w(c, p) =(dep(p) + 1)a
dep(p)
× [R+(1−R)
</equation>
<page confidence="0.621814">
1005
</page>
<bodyText confidence="0.993479414634146">
normal distribution N (8,2). It is visually quite no-
ticeable that the actual quantity denoting how deep a
node resides in WordNet is conflated at depth values
below 5 or above 14. In other words, the distribution
makes it rather inaccurate to say, for instance, that a
node of depth 4 is twice as deep as a node of depth 2.
This might explain the low degree of correlation be-
tween similarity and depth under 5 in Figure 1 (man-
ifested by the long, vertical stripes across the entire
range of similarity scores (0 to 1) for depth 4 and
under), and also how the correlation increases with
depth value. Unfortunately, we do not have enough
data for depth above 14 to draw any conclusion on
this higher end of the depth spectrum.
Secondly, even on the range of depth values with
higher correlation with similarity, there is no defini-
tive sufficient and necessary relation between depth
and similarity (hence the upper triangle instead of
a sloped line or band). Particularly, semantically
more similar words are not necessarily deeper in the
WordNet hierarchy. Data analysis reveals that the
LCS of highly similar words can be quite close to
the hierarchical root. Examples include coast–shore,
which is judged to be very similar by humans (9 on
a scale of 0–10 in both data sets). The latter is a hy-
pernym of the former and thus the LCS of the pair,
yet it is only four levels below the root node entity
(via geological formation, object, and physical en-
tity). Another situation is when the human judges
confused relatedness with similarity, and WordNet
fails to capture the relatedness with its hierarchical
structure of lexical semantics: the pair software–
computer can only be related by the root node en-
tity as their LCS, although the pair is judged quite
“similar” by humans (8.5 on 0 to 10 scale).
The only conclusive claim that can be made here
is that word pairs with deeper LCS’s tend to be more
similar. However, since only word forms (rather
than senses) are available in these psycho-linguistic
experiments, the one similarity rating given by hu-
man judges sometimes fails to cover multiple senses
</bodyText>
<table confidence="0.941984821428572">
for polysemous words. In the pair stock–jaguar of
the FG set, for example, one sense of stock (live-
stock, stock, farm animal: any animals kept for use
or profit) is closely connected to jaguar through a
depth-10 LCS (placental, placental mammal, eu-
therian, eutherian mammal). However, the pair re-
ceived a low similarity rating (0.92 on 0–10), prob-
Figure 2: Histogram of depth of WordNet noun synsets.
3.1 Depth
The distribution of similarity of the combined data
set over depth is plotted in Figure 1. For depth val-
ues under 5, similarity scores are fairly evenly dis-
tributed over depth, showing no statistical signifi-
cance in correlation. For depth 5 and above, the
shape of distribution resembles an upper-triangle,
suggesting that (1) correlation with similarity be-
comes stronger in this range of depth value, and (2)
data points with higher depth values tend to have
higher similarity scores, but the reverse of the claim
does not hold, i.e., word pairs with “shallower” LCS
can also be judged quite similar by humans.
There are many more data points with lower depth
values than with higher depth values in the com-
bined data set. In order to have a fair comparison of
statistical significance tests on the two value ranges
for depth, we randomly sample an equal number
(100) of data points from each value range, and the
correlation coefficient between depth and similarity
</table>
<bodyText confidence="0.754823875">
is averaged over 100 of such samplings. Correla-
tion coefficients for depth value under 5 versus 5 and
above are ρ = 0.0881, p ≈ 0.1 and ρ = 0.3779, p &lt;
0.0001, respectively, showing an apparent difference
in degree of correlation.
Two interesting observations can be made from
these results. Firstly, the notion of depth is relative
to the distribution of number of nodes over depth
value. For example, depth 20 by itself is virtually
meaningless since it might be quite high if the ma-
jority of nodes in WordNet are of depth 10 or less,
or quite low if the majority depth value are 50 or
more. According to the histogram of depth values
in WordNet (Figure 2), the distribution of number of
nodes over depth value approximately conforms to a
1006
</bodyText>
<figureCaption confidence="0.773693">
Figure 3: Correlation between density and similarity.
</figureCaption>
<table confidence="0.98805">
MC RG FG
dep 0.7056*** 0.6909*** 0.3701***
den 0.2268 0.2660* 0.1023
</table>
<tableCaption confidence="0.696814333333333">
Table 1: Correlation between depth/density and similar-
ity on individual data sets. Number of asterisks indicates
different confidence intervals (“*” for p &lt; 0.05, “***” for
</tableCaption>
<bodyText confidence="0.962110833333333">
p &lt; 0.0001).
ably because judges associated the word form stock
with its financial sense, especially when there was
an abundant presence of pairs indicating this particu-
lar sense of the word (e.g., stock–market, company–
stock).
</bodyText>
<subsectionHeader confidence="0.99189">
3.2 Density
</subsectionHeader>
<bodyText confidence="0.999164915254237">
Comparing to depth, density exhibits much lower
correlation with similarity (Figure 3-a and 3-b). We
conducted correlation experiments between density
and similarity with the same setting as for depth and
similarity above. Data points with extremely high
density values (up to over 400) are mostly idiosyn-
cratic to the densely connected regions in WordNet
and are numerically quite harmful. We thus ex-
cluded outliers with density values above 100 in the
experiment.
Evaluation on the combined data set shows no
correlation between density and similarity. To con-
firm the result, we break the experiments down to the
three individual data sets, and the results are listed in
Table 1. The correlation coefficient between density
and similarity ranges from 0.10 to 0.27 There is no
statistical significance of correlation on two of the
three data sets (MC and FG), and the significance
on RG is close to marginal with p = 0.0366.
Data analysis suggests that density values are of-
ten biased by particular fine-grainedness of local
structures in WordNet. Qualitatively, Richardson
and Smeaton (1995) previously observed that “the
irregular densities of links between concepts results
in unexpected conceptual distance measures”. Em-
pirically, on the one hand, more than 90% of Word-
Net nodes have density values less than or equal to
3. This means that for 90% of the LCS’s, there are
only three integer values for density to distinguish
the varying degrees of similarity. In other words,
such a range might be too narrow to have any real
distinguishing power over similarity. On the other
hand, there are outliers with extreme density values
particular to the perhaps overly fine-grained subcat-
egorization of some WordNet concepts, and these
nodes can be LCS’s of word pairs of drastically dif-
ferent similarity. The node person, individual, for
example, can be the LCS of similar pairs such as
man–woman, as well as quite dissimilar ones such
as boy–sage, where the large density value does not
necessarily indicate high degree of similarity.
Another crucial limitation of the definition of den-
sity is the information loss on specificity. In the ex-
isting literature, density is often adopted as a proxy
for the degree of specificity of a concept, i.e., nodes
in densely connected regions in WordNet are taken
to be more specific and thus closer to each other.
This information of a given node should be inher-
ited by its hierarchical descendants, since specificity
should monotonically increase as one descends the
hierarchy. For example, the node piano has a den-
sity value of 15 under the node percussion instru-
ment. However, the density value of its hyponyms
Grand piano, upright piano, and mechanical piano,
is only 3. Due to the particular structure of this sub-
network in WordNet, the grand–upright pair might
be incorrectly regarded as less specific (and thus less
similar) than, say, between piano–gong, both as per-
cussion instruments.
</bodyText>
<sectionHeader confidence="0.996061" genericHeader="method">
4 New Definitions of Depth and Density
</sectionHeader>
<bodyText confidence="0.9988135">
In this section, we formalize new definitions of
depth and density to correct for their current limi-
</bodyText>
<page confidence="0.968369">
1007
</page>
<table confidence="0.9991695">
MC RG FG
depu 0.7201*** 0.6798*** 0.3751***
denu 0.2268 0.2660* 0.1019
deni 0.7338*** 0.6751*** 0.3445***
</table>
<tableCaption confidence="0.993792">
Table 2: Correlation between new definitions of
depth/density and similarity.
</tableCaption>
<table confidence="0.314015">
tations discussed in Section 3.
</table>
<subsectionHeader confidence="0.964722">
4.1 Depth
</subsectionHeader>
<bodyText confidence="0.999913357142857">
The major problem with the current definition of
depth is its failure to take into account the uneven
distribution of number of nodes over the depth value.
As seen in previous examples, the distribution is
rather “flat” on both ends of depth value, which does
not preserve the linearity of using the ordinal values
of depth and thus introduces much inaccuracy.
To avoid this problem, we “re-curve” depth value
to the cumulative distribution. Specifically, if we
take the histogram distribution of depth value in Fig-
ure 2 as a probability density function, our approach
is to project cardinal depth values onto its cumula-
tive distribution function. The new depth is denoted
depu and is defined as:
</bodyText>
<equation confidence="0.948715">
depu(c) = ∑c&apos;cWN |{c&apos; : dep(c&apos;) G dep(c)J|
|WN|
</equation>
<bodyText confidence="0.999737727272727">
Here, dep(·) is the original depth value, and WN is
the set of all nodes in WordNet. The resulting depth
values not only reflect the flat ends, but also preserve
linearity for the depth value range in the middle. In
comparison with Table 1), correlation between depu
and similarity increases over the original depth val-
ues on two of the three data sets (first row in Table
2 and decreases on the RG set. Later, in Section 5,
we show how these marginal improvements translate
into better similarity measures with statistical signif-
icance.
</bodyText>
<subsectionHeader confidence="0.941719">
4.2 Density
</subsectionHeader>
<bodyText confidence="0.998187142857143">
In theory, a procedure analogous to the above cumu-
lative definition can also be applied to density, i.e.,
by projecting the original values onto the cumula-
tive distribution function. However, due to the Zip-
fian nature of density’s histogram distribution (Fig-
ure 4, in contrast to Gaussian for depth in Figure
2), this is essentially to collapse most density values
</bodyText>
<figureCaption confidence="0.997323">
Figure 4: Histogram of density in WordNet.
</figureCaption>
<bodyText confidence="0.999771666666667">
into a very small number of discrete values (which
correspond to the original density of 1 to 3). Ex-
periments show that it does not help in improving
correlation with similarity scores (second row in Ta-
ble 2 for denu): correlation remains the same on MC
and RG, and decreases slightly on FG.
We therefore resort to addressing the issue of in-
formation loss on specificity by inheritance. Intu-
itively, the idea is to ensure that a node be assigned
no less density mass than its parent node(s). In the
“piano” example (Section 3.2), the concept piano is
highly specific due to its large number of siblings
under the parent node percussion instruments. Con-
sequently, the density of its child nodes upright pi-
ano and grand piano should inherit its specificity on
top of their own.
Formally, we redefine density recursively as fol-
lows:
</bodyText>
<equation confidence="0.9999">
deni(r) = 0
∑hchyper(c) deni(h)
deni(c) = |hyper(c) |+den(c)
</equation>
<bodyText confidence="0.999856916666667">
where r is the root of WordNet hierarchy (with no
hypernym), and hyper(·) is the set of hypernyms of a
given concept. The first term is the inheritance part,
normalized over all hypernyms of c in case of mul-
tiple inheritance, and the second term is the original
value of density.
The resulting density values correlate signifi-
cantly better with similarity. As shown in row 3
in Table 2, the correlation coefficients are about
tripled on all three data sets with the new density
definition deni, and the significance of correlation
is greatly improved as well (from non-correlating or
</bodyText>
<page confidence="0.985837">
1008
</page>
<bodyText confidence="0.9820405">
marginally correlating to strongly significantly cor-
relating on all three data sets).
</bodyText>
<subsectionHeader confidence="0.588967">
5 Using the New Definitions in Semantic
Similarity Measures
</subsectionHeader>
<bodyText confidence="0.999863904761905">
In this section, we test the effectiveness of the new
definitions of depth and density by using them in
WordNet-based semantic similarity measures. The
two similarity measures we experiment with are that
of Wu and Palmer (1994) and Jiang and Conrath
(1997). The first one used depth only, and the second
one used both depth and density.
The task is to correlate the similarity measures
with human judgment on similarity between word
pairs. We use the same three data sets as in Section
3. despite the fact that MC is a subset of RG data
set, we include both in order to compare with exist-
ing studies.
Correlation coefficient is calculated using Spear-
man’s p, although results reported by some earlier
studies used parametric tests such as the Pearson
Correlation Coefficient. The reason for our choice
is that the similarity scores of the word pairs in
these data sets do not necessarily conform to nor-
mal distributions. Rather, we are interested in testing
whether the artificial algorithms would give higher
scores to pairs that are regarded closer in meaning
by human judges. A non-parametric test suits better
for this scenario. And this partly explains why our
re-implementations of the models have lower corre-
lation coefficients than in the original studies.
Note that there are other WordNet-based similar-
ity measures using depth and/or density that we opt
to omit for various reasons. Some of them were not
designed for the particular task at hand (e.g., that of
Sussna, 1993, which gives very poor correlation in
this task). Others use depth of the entire WordNet
hierarchy instead of individual nodes as a scaling
factor (e.g., that of Leacock and Chodorow, 1998),
which is unsuitable for illustrating the improvement
brought about by the new depth and density defini-
tions.
Parameterization of the weighting of depth and
density is a common practice to control their indi-
vidual contribution to the final similarity score (e.g.,
a and R in Equation (2)). Jiang and Conrath already
had separate weights in their original study. In or-
</bodyText>
<table confidence="0.83599225">
Best Average
MC RB GR MC RB GR
dep 0.7671 0.7824 0.3773 0.7612 0.7686 0.3660
depu 0.7824 0.7912 0.3946 0.7798 0.7810 0.3787
</table>
<tableCaption confidence="0.931036333333333">
Table 3: Correlation between human judgment and simi-
larity score by Wu and Palmer (1994) using two versions
of depth.
</tableCaption>
<table confidence="0.999507666666667">
MC Best GR MC Average GR
RB RB
0.7875 0.8111 0.3720 0.7689 0.7990 0.3583
0.8009 0.8181 0.3804 0.7885 0.8032 0.3669
0.7882 0.8199 0.3803 0.7863 0.8102 0.3689
0.8065 0.8202 0.3818 0.8189 0.8194 0.3715
</table>
<tableCaption confidence="0.882765333333333">
Table 4: Correlation between human judgment and sim-
ilarity score by Jiang and Conrath (1997) using different
definitions of depth and density.
</tableCaption>
<bodyText confidence="0.615290333333333">
der to parameterize depth used by Wu and Palmer in
their similarity measure, we also modify Equation
(1) as follows:
</bodyText>
<equation confidence="0.9997215">
sim(c1,c2) =
len(c1,c) + len(c2,c) + 2 · depa(c)
</equation>
<bodyText confidence="0.999973125">
where depth is raised to the power of a to vary its
contribution to the similarity score.
For a number of combinations of the weighting
parameters, we report both the best performance
and the averaged performance over all the param-
eter combinations. The latter number is meaningful
in that it is a good indication of numerical stability of
the parameterization. In addition, parameterization
is able to generate multiple correlation coefficients,
on which statistical tests can be run in order to show
the significance of improvement. We use the range
from 0 to 5 with step 1 for a and from 0 to 1 with
step 0.1 for R.
Table 3 and 4 list the experiment results. In both
models, the cumulative definition of depth depu con-
sistently improve the performance of the similarity
measures. In the Jiang and Conrath (1997) model,
where density is applicable, the inheritance-based
definition of density deni also results in better cor-
relation with human judgments. The optimal result
is achieved when combining the new definitions of
depth and density (row 4 in Table 4). For average
performance, the improvement of all the new def-
initions over the original definitions is statistically
</bodyText>
<figure confidence="0.6964786">
dep,den
depu, den
dep,deni
depu,deni
2 · depa(c)
</figure>
<page confidence="0.97198">
1009
</page>
<sectionHeader confidence="0.952262" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998852666666667">
This study was inspired by lectures given by Profes-
sor Gerald Penn of the University of Toronto, and
was financially supported by the Natural Sciences
and Engineering Research Council of Canada.
significant on all three data sets according to paired
t-test.
</bodyText>
<sectionHeader confidence="0.986171" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99993956097561">
This study explored effective uses of depth and/or
density in WordNet-based similarity measures. We
started by examining how well these two structural
features correlate with human judgment on word
pair similarities. This direct comparison showed that
depth correlates with similarity only on certain value
ranges, while density does not correlate with human
judgment at all.
Further investigation revealed that the problem for
depth lies in the simplistic representation as its ordi-
nal integer values. The linearity in this representa-
tion fails to take into account the conflated quantity
of depth in the two extreme ends of the depth spec-
trum. For density, a prominent issue is the informa-
tion loss on specificity of WordNet concepts, which
gives an inaccurate density value that is biased by
the idiosyncratic constructions in densely connected
regions in the hierarchy.
We then proposed new definitions of depth and
density to address these issues. For depth, linear-
ity in different value ranges is realistically reflected
by projecting the depth value to its cumulative dis-
tribution function. The loss of specificity informa-
tion in density, on the other hand, is corrected by
allowing concepts to inherit specificity information
from their parent nodes. The new definitions show
significant improvement in correlation of semantic
similarity given by human judges. In addition, when
used in existing WordNet-based similarity measures,
they consistently improve performance and numeri-
cal stability of the parameterization of the two fea-
tures.
The notions of depth and density pertain to any
hierarchical structure like WordNet, which suggests
various extensions of this work. A natural next step
of the current work is to apply the same idea to se-
mantic taxonomies in languages other than English
with available similarity judgments are also avail-
able. Extrinsic tasks using WordNet-based semantic
similarity can potentially benefit from these refined
notions of depth and density as well.
</bodyText>
<sectionHeader confidence="0.996058" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998199315789474">
Eneko Agirre and German Rigau. Word sense dis-
ambiguation using conceptual density. In Pro-
ceedings of the 16th Conference on Computa-
tional Linguistics, pages 16–22. Association for
Computational Linguistics, 1996.
Martin Chodorow, Roy Byrd, and George Heidorn.
Extracting semantic hierarchies from a large on-
line dictionary. In Proceedings of the 23rd An-
nual Meeting of the Association for Computa-
tional Linguistics, pages 299–304, Chicago, Illi-
nois, USA, 1985.
Christiane Fellbaum. WordNet: An Electronic Lexi-
cal Database. MIT Press, Cambridge, MA, 1998.
Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias,
Ehud Rivlin, Zach Solan, Gadi Wolfman, and Ey-
tan Ruppin. Placing search in context: The con-
cept revisited. In Proceedings of the 10th Inter-
national Conference on World Wide Web, pages
406–414. ACM, 2001.
Graeme Hirst and David St-Onge. Lexical chains
as representations of context for the detection and
correction of malapropisms. In Christiane Fell-
baum, editor, WordNet: An Electronic Lexical
Database, pages 305–332. 1998.
Mario Jarmasz and Stan Szpakowicz. Roget’s the-
saurus and semantic similarity. In Proceedings
of International Conference on Recent Advances
in Natural Language Processing, pages 212–219,
Borovets, Bulgaria, 2003.
Jay Jiang and David Conrath. Semantic similarity
based on corpus statistics and lexical taxonomy.
Proceedings of International Conference on Re-
search in Computational Linguistics, 33, 1997.
Hideki Kozima and Akira Ito. Context-sensitive
measurement of word distance by adaptive scal-
ing of a semantic space. Recent Advances in Nat-
ural Language Processing: Selected Papers from
RANLP, 95:111–124, 1997.
</reference>
<page confidence="0.735164">
1010
</page>
<reference confidence="0.9991486875">
Claudia Leacock and Martin Chodorow. Combin-
ing local context and WordNet similarity for word
sense identification. WordNet: An electronic lexi-
cal database, 49(2):265–283, 1998.
Dekang Lin. Automatic retrieval and clustering of
similar words. In Proceedings of the 17th Interna-
tional Conference on Computational Linguistics,
pages 768–774, Montreal, Canada, 1998.
Goerge Miller and Walter Charles. Contextual cor-
relates of semantic similarity. Language and Cog-
nitive Processes, 6(1):1–28, 1991.
Ted Pedersen, Siddharth Patwardhan, and Jason
Michelizzi. WordNet::Similarity: measuring the
relatedness of concepts. In Demonstration Papers
at Human Language Technologies - North Ameri-
can Chapter of the Association for Computational
Linguistics, pages 38–41. Association for Com-
putational Linguistics, 2004.
Roy Rada, Hafedh Mili, Ellen Bicknell, and Maria
Blettner. Development and application of a metric
on semantic nets. IEEE Transactions on Systems,
Man and Cybernetics, 19(1):17–30, 1989.
Philip Resnik. Semantic similarity in a taxon-
omy: an information-based measure and its ap-
plication to problems of ambiguity in natural lan-
guage. Journal ofArtificial Intelligence Research,
11(11):95–130, 1999.
R. Richardson and A.F. Smeaton. Using WordNet
in a knowledge-based approach to information re-
trieval. In Proceedings of the BCS-IRSG Collo-
quium, Crewe. Citeseer, 1995.
Herbert Rubenstein and John Goodenough. Contex-
tual correlates of synonymy. Communications of
the ACM, 8(10):627–633, 1965.
Michael Sussna. Word sense disambiguation for
free-text indexing using a massive semantic net-
work. In Proceedings of the second international
conference on Information and knowledge man-
agement, pages 67–74. ACM, 1993.
Peter Turney. Mining the web for synonyms: PMI-
IR versus LSA on TOEFL. Proceedings of the
Twelfth European Conference on Machine Learn-
ing, pages 491–502, 2001.
Zhibiao Wu and Martha Palmer. Verb semantics
and lexical selection. In Proceedings of the 32nd
Annual Meeting of the Association for Compu-
tational Linguistics, pages 133–138. Association
for Computational Linguistics, 1994.
</reference>
<page confidence="0.993207">
1011
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.897952">
<title confidence="0.9951505">Refining the Notions of Depth and Density in Semantic Similarity Measures</title>
<author confidence="0.989695">Tong</author>
<affiliation confidence="0.999799">Department of Computer University of</affiliation>
<email confidence="0.998154">tong@cs.toronto.edu</email>
<author confidence="0.92638">Graeme</author>
<affiliation confidence="0.999797">Department of Computer University of</affiliation>
<email confidence="0.999098">gh@cs.toronto.edu</email>
<abstract confidence="0.999619761904762">We re-investigate the rationale for and the effectiveness of adopting the notions of depth and density in WordNet-based semantic similarity measures. We show that the intuition for including these notions in WordNet-based similarity measures does not always stand up to empirical examination. In particular, the traditional definitions of depth and density as ordinal integer values in the hierarchical structure of WordNet does not always correlate with human judgment of lexical semantic similarity, which imposes strong limitations on their contribution to an accurate similarity measure. We thus propose several novel definitions of depth and density, which yield significant improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>German Rigau</author>
</authors>
<title>Word sense disambiguation using conceptual density.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th Conference on Computational Linguistics,</booktitle>
<pages>16--22</pages>
<contexts>
<context position="6667" citStr="Agirre and Rigau (1996)" startWordPosition="1034" endWordPosition="1037">. As for the relation between density and similarity, the intuition is that if the overall semantic mass for a given node is constant (Jiang and Conrath, 1997), then the more neighboring nodes there are in a locally connected subnetwork, the closer its members are to each other. For example, animal, person, and plant are more strongly connected with life form than aerobe and plankton because the first three words all have high density in their local network structures (Richardson and Smeaton, 1995). Note that the notion of density here is not to be confused with the conceptual density used by Agirre and Rigau (1996), which is essentially a semantic similarity measure by itself. In general, both observations on depth and density conform to intuition and are supported qualitatively by several existing studies. The main objective of this study is to empirically examine the validity of this assumption. 2.2 Semantic Similarity Measures Using Depth and/or Density One of the first examples of using depth and density in WordNet-based similarity measures is that of Sussna (1993). The weight on an edge between two nodes c1 and c2 with relation r in WordNet is given as: w(c1 →r c2)+w(c2 →r c1) w(c1,c2) = 2d where d</context>
</contexts>
<marker>Agirre, Rigau, 1996</marker>
<rawString>Eneko Agirre and German Rigau. Word sense disambiguation using conceptual density. In Proceedings of the 16th Conference on Computational Linguistics, pages 16–22. Association for Computational Linguistics, 1996.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Chodorow</author>
<author>Roy Byrd</author>
<author>George Heidorn</author>
</authors>
<title>Extracting semantic hierarchies from a large online dictionary.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>299--304</pages>
<location>Chicago, Illinois, USA,</location>
<contexts>
<context position="1686" citStr="Chodorow et al., 1985" startWordPosition="238" endWordPosition="241">finitions consistently improve performance on a task of correlating with human judgment. 1 Introduction Semantic similarity measures are widely used in natural language processing for measuring distance between meanings of words. There are currently two mainstream approaches to deriving such measures, i.e., distributional and lexical resource-based approaches. The former usually explores the cooccurrence patterns of words in large collections of texts such as text corpora (Lin, 1998) or the Web (Turney, 2001). The latter takes advantage of mostly handcrafted information, such as dictionaries (Chodorow et al., 1985; Kozima and Ito, 1997) or thesauri (Jarmasz and Szpakowicz, 2003). 1003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition.</context>
</contexts>
<marker>Chodorow, Byrd, Heidorn, 1985</marker>
<rawString>Martin Chodorow, Roy Byrd, and George Heidorn. Extracting semantic hierarchies from a large online dictionary. In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, pages 299–304, Chicago, Illinois, USA, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA,</location>
<contexts>
<context position="1862" citStr="Fellbaum, 1998" startWordPosition="266" endWordPosition="267">r measuring distance between meanings of words. There are currently two mainstream approaches to deriving such measures, i.e., distributional and lexical resource-based approaches. The former usually explores the cooccurrence patterns of words in large collections of texts such as text corpora (Lin, 1998) or the Web (Turney, 2001). The latter takes advantage of mostly handcrafted information, such as dictionaries (Chodorow et al., 1985; Kozima and Ito, 1997) or thesauri (Jarmasz and Szpakowicz, 2003). 1003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have bee</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Finkelstein</author>
<author>Evgeniy Gabrilovich</author>
<author>Yossi Matias</author>
<author>Ehud Rivlin</author>
<author>Zach Solan</author>
<author>Gadi Wolfman</author>
<author>Eytan Ruppin</author>
</authors>
<title>Placing search in context: The concept revisited.</title>
<date>2001</date>
<booktitle>In Proceedings of the 10th International Conference on World Wide Web,</booktitle>
<pages>406--414</pages>
<publisher>ACM,</publisher>
<contexts>
<context position="10035" citStr="Finkelstein et al. (2001)" startWordPosition="1608" endWordPosition="1611">ng depth and density is to examine their correlation with similarity. Empirical results in this section Figure 1: Correlation between depth and similarity. are achieved by the following experimental setting. Depth is defined as the number of edges between the root of the hierarchy and the lowest common subsumer (LCS) of two nodes under comparison, and density as the number of siblings of the LCS.2 Similarity is measured by human judgment on similarity between word pairs. Commonly used data sets for such judgments include that of Rubenstein and Goodenough (1965), Miller and Charles (1991), and Finkelstein et al. (2001) (denoted RG, MC, and FG, respectively). RG is a collection of similarity ratings of 65 word pairs averaged over judgments from 51 human subjects on a scale of 0 to 4 (from least to most similar). MC is a subset of 30 pairs out of the RG data set. These pairs were chosen to have evenly distributed similarity ratings in the original data set, and similarity judgment was elicited from 38 human judges with the same instruction as used for RG. FG is a much larger set consisting of 353 word pairs, and the rating scale is from 0 to 10. We combine the RG and FG data sets in order to maximize data siz</context>
</contexts>
<marker>Finkelstein, Gabrilovich, Matias, Rivlin, Solan, Wolfman, Ruppin, 2001</marker>
<rawString>Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. Placing search in context: The concept revisited. In Proceedings of the 10th International Conference on World Wide Web, pages 406–414. ACM, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>David St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms.</title>
<date>1998</date>
<booktitle>In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database,</booktitle>
<pages>305--332</pages>
<contexts>
<context position="2646" citStr="Hirst and St-Onge, 1998" startWordPosition="388" endWordPosition="391">the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully weighting these features to construct a better semantic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitive. To the best of our knowledge, there is no empirical study directly investigating the eff</context>
</contexts>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Graeme Hirst and David St-Onge. Lexical chains as representations of context for the detection and correction of malapropisms. In Christiane Fellbaum, editor, WordNet: An Electronic Lexical Database, pages 305–332. 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mario Jarmasz</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Roget’s thesaurus and semantic similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of International Conference on Recent Advances in Natural Language Processing,</booktitle>
<pages>212--219</pages>
<location>Borovets, Bulgaria,</location>
<contexts>
<context position="1752" citStr="Jarmasz and Szpakowicz, 2003" startWordPosition="248" endWordPosition="251">rrelating with human judgment. 1 Introduction Semantic similarity measures are widely used in natural language processing for measuring distance between meanings of words. There are currently two mainstream approaches to deriving such measures, i.e., distributional and lexical resource-based approaches. The former usually explores the cooccurrence patterns of words in large collections of texts such as text corpora (Lin, 1998) or the Web (Turney, 2001). The latter takes advantage of mostly handcrafted information, such as dictionaries (Chodorow et al., 1985; Kozima and Ito, 1997) or thesauri (Jarmasz and Szpakowicz, 2003). 1003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that </context>
</contexts>
<marker>Jarmasz, Szpakowicz, 2003</marker>
<rawString>Mario Jarmasz and Stan Szpakowicz. Roget’s thesaurus and semantic similarity. In Proceedings of International Conference on Recent Advances in Natural Language Processing, pages 212–219, Borovets, Bulgaria, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Jiang</author>
<author>David Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>Proceedings of International Conference on Research in Computational Linguistics,</booktitle>
<volume>33</volume>
<contexts>
<context position="2775" citStr="Jiang and Conrath, 1997" startWordPosition="406" endWordPosition="409">e distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully weighting these features to construct a better semantic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitive. To the best of our knowledge, there is no empirical study directly investigating the effectiveness of adopting structural features such as depth and density. This serves as the major motivation for this study. The pap</context>
<context position="5377" citStr="Jiang and Conrath, 1997" startWordPosition="823" endWordPosition="826">y The rationale for using the notions of depth and density in WordNet-based semantic similarity measures is based on the following assumption: Assumption 1 Everything else being equal, two nodes are semantically closer if (a) they reside deeper in the WordNet hierarchy, or (b) they are more densely connected locally. This is the working assumption for virtually all WordNet-based semantic similarity studies using depth and/or density. For depth, the intuition is that adjacent nodes deep down the hierarchy are likely to be conceptually close, since the differentiation is based on finer details (Jiang and Conrath, 1997). Sussna (1993) termed the use of depth as depth-relative scaling, claiming that “only-siblings deep in a tree are more closely related than onlysiblings higher in the tree”. Richardson and Smeaton (1995) gave an hypothetical example illustrating this “only-siblings” situation, where plant–animal 1Since the works we review in this section have different definitions of depth and density, we defer our formal definitions to Section 3. are the only two nodes under living things, and wolfhound–foxhound under hound. They claimed the reason that the former pair can be regarded as conceptually farther</context>
<context position="8403" citStr="Jiang and Conrath (1997)" startWordPosition="1336" endWordPosition="1339">ght (left-handside) and thus negatively correlated to similarity. Wu and Palmer (1994) proposed a concept similarity measure between two concepts c1 and c2 as: sim(c1,c2) = len(c1,c) + len(c2,c) + 2 · dep(c) (1) where c is the lowest common subsumer (LCS) of c1 and c2, and len(·,·) is the number of edges between two nodes. The rationale is to adjust “hop count” (the first two terms in the denominator) with the depth of LCS: similarity between nodes with samelevel LCS is in negative proportion to hop counts, while given the same hop count, a “deeper” LCS pulls the similarity score closer to 1. Jiang and Conrath (1997) proposed a hybrid method incorporating depth and density information into an information-content-based model (Resnik, 1999): E¯ den(p)] × [IC(c) − IC(p)]T(c, p) (2) Here, p and c are parent and child nodes in WordNet, dep(·) and den(·) denote the depth and density of a node, respectively, E¯ is the average density over the entire network of WordNet, and a and R are two parameters controlling the contribution of depth and density values to the similarity score. IC(·) is the information content of a node based on probability estimates of word classes from a small sensetagged corpus (Resnik, 199</context>
<context position="22862" citStr="Jiang and Conrath (1997)" startWordPosition="3772" endWordPosition="3775">n row 3 in Table 2, the correlation coefficients are about tripled on all three data sets with the new density definition deni, and the significance of correlation is greatly improved as well (from non-correlating or 1008 marginally correlating to strongly significantly correlating on all three data sets). 5 Using the New Definitions in Semantic Similarity Measures In this section, we test the effectiveness of the new definitions of depth and density by using them in WordNet-based semantic similarity measures. The two similarity measures we experiment with are that of Wu and Palmer (1994) and Jiang and Conrath (1997). The first one used depth only, and the second one used both depth and density. The task is to correlate the similarity measures with human judgment on similarity between word pairs. We use the same three data sets as in Section 3. despite the fact that MC is a subset of RG data set, we include both in order to compare with existing studies. Correlation coefficient is calculated using Spearman’s p, although results reported by some earlier studies used parametric tests such as the Pearson Correlation Coefficient. The reason for our choice is that the similarity scores of the word pairs in the</context>
<context position="25180" citStr="Jiang and Conrath (1997)" startWordPosition="4158" endWordPosition="4161">quation (2)). Jiang and Conrath already had separate weights in their original study. In orBest Average MC RB GR MC RB GR dep 0.7671 0.7824 0.3773 0.7612 0.7686 0.3660 depu 0.7824 0.7912 0.3946 0.7798 0.7810 0.3787 Table 3: Correlation between human judgment and similarity score by Wu and Palmer (1994) using two versions of depth. MC Best GR MC Average GR RB RB 0.7875 0.8111 0.3720 0.7689 0.7990 0.3583 0.8009 0.8181 0.3804 0.7885 0.8032 0.3669 0.7882 0.8199 0.3803 0.7863 0.8102 0.3689 0.8065 0.8202 0.3818 0.8189 0.8194 0.3715 Table 4: Correlation between human judgment and similarity score by Jiang and Conrath (1997) using different definitions of depth and density. der to parameterize depth used by Wu and Palmer in their similarity measure, we also modify Equation (1) as follows: sim(c1,c2) = len(c1,c) + len(c2,c) + 2 · depa(c) where depth is raised to the power of a to vary its contribution to the similarity score. For a number of combinations of the weighting parameters, we report both the best performance and the averaged performance over all the parameter combinations. The latter number is meaningful in that it is a good indication of numerical stability of the parameterization. In addition, paramete</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay Jiang and David Conrath. Semantic similarity based on corpus statistics and lexical taxonomy. Proceedings of International Conference on Research in Computational Linguistics, 33, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hideki Kozima</author>
<author>Akira Ito</author>
</authors>
<title>Context-sensitive measurement of word distance by adaptive scaling of a semantic space.</title>
<date>1997</date>
<booktitle>Recent Advances in Natural Language Processing: Selected Papers from RANLP,</booktitle>
<pages>95--111</pages>
<contexts>
<context position="1709" citStr="Kozima and Ito, 1997" startWordPosition="242" endWordPosition="245">improve performance on a task of correlating with human judgment. 1 Introduction Semantic similarity measures are widely used in natural language processing for measuring distance between meanings of words. There are currently two mainstream approaches to deriving such measures, i.e., distributional and lexical resource-based approaches. The former usually explores the cooccurrence patterns of words in large collections of texts such as text corpora (Lin, 1998) or the Web (Turney, 2001). The latter takes advantage of mostly handcrafted information, such as dictionaries (Chodorow et al., 1985; Kozima and Ito, 1997) or thesauri (Jarmasz and Szpakowicz, 2003). 1003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple</context>
</contexts>
<marker>Kozima, Ito, 1997</marker>
<rawString>Hideki Kozima and Akira Ito. Context-sensitive measurement of word distance by adaptive scaling of a semantic space. Recent Advances in Natural Language Processing: Selected Papers from RANLP, 95:111–124, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudia Leacock</author>
<author>Martin Chodorow</author>
</authors>
<title>Combining local context and WordNet similarity for word sense identification. WordNet: An electronic lexical database,</title>
<date>1998</date>
<volume>49</volume>
<issue>2</issue>
<contexts>
<context position="24279" citStr="Leacock and Chodorow, 1998" startWordPosition="4009" endWordPosition="4012">oser in meaning by human judges. A non-parametric test suits better for this scenario. And this partly explains why our re-implementations of the models have lower correlation coefficients than in the original studies. Note that there are other WordNet-based similarity measures using depth and/or density that we opt to omit for various reasons. Some of them were not designed for the particular task at hand (e.g., that of Sussna, 1993, which gives very poor correlation in this task). Others use depth of the entire WordNet hierarchy instead of individual nodes as a scaling factor (e.g., that of Leacock and Chodorow, 1998), which is unsuitable for illustrating the improvement brought about by the new depth and density definitions. Parameterization of the weighting of depth and density is a common practice to control their individual contribution to the final similarity score (e.g., a and R in Equation (2)). Jiang and Conrath already had separate weights in their original study. In orBest Average MC RB GR MC RB GR dep 0.7671 0.7824 0.3773 0.7612 0.7686 0.3660 depu 0.7824 0.7912 0.3946 0.7798 0.7810 0.3787 Table 3: Correlation between human judgment and similarity score by Wu and Palmer (1994) using two versions </context>
</contexts>
<marker>Leacock, Chodorow, 1998</marker>
<rawString>Claudia Leacock and Martin Chodorow. Combining local context and WordNet similarity for word sense identification. WordNet: An electronic lexical database, 49(2):265–283, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics,</booktitle>
<pages>768--774</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="1553" citStr="Lin, 1998" startWordPosition="219" endWordPosition="220"> improvement in degree of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment. 1 Introduction Semantic similarity measures are widely used in natural language processing for measuring distance between meanings of words. There are currently two mainstream approaches to deriving such measures, i.e., distributional and lexical resource-based approaches. The former usually explores the cooccurrence patterns of words in large collections of texts such as text corpora (Lin, 1998) or the Web (Turney, 2001). The latter takes advantage of mostly handcrafted information, such as dictionaries (Chodorow et al., 1985; Kozima and Ito, 1997) or thesauri (Jarmasz and Szpakowicz, 2003). 1003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the </context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. Automatic retrieval and clustering of similar words. In Proceedings of the 17th International Conference on Computational Linguistics, pages 768–774, Montreal, Canada, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Goerge Miller</author>
<author>Walter Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<journal>Language and Cognitive Processes,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="10004" citStr="Miller and Charles (1991)" startWordPosition="1603" endWordPosition="1606">ent of the effectiveness of using depth and density is to examine their correlation with similarity. Empirical results in this section Figure 1: Correlation between depth and similarity. are achieved by the following experimental setting. Depth is defined as the number of edges between the root of the hierarchy and the lowest common subsumer (LCS) of two nodes under comparison, and density as the number of siblings of the LCS.2 Similarity is measured by human judgment on similarity between word pairs. Commonly used data sets for such judgments include that of Rubenstein and Goodenough (1965), Miller and Charles (1991), and Finkelstein et al. (2001) (denoted RG, MC, and FG, respectively). RG is a collection of similarity ratings of 65 word pairs averaged over judgments from 51 human subjects on a scale of 0 to 4 (from least to most similar). MC is a subset of 30 pairs out of the RG data set. These pairs were chosen to have evenly distributed similarity ratings in the original data set, and similarity judgment was elicited from 38 human judges with the same instruction as used for RG. FG is a much larger set consisting of 353 word pairs, and the rating scale is from 0 to 10. We combine the RG and FG data set</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>Goerge Miller and Walter Charles. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>WordNet::Similarity: measuring the relatedness of concepts. In Demonstration Papers at Human Language Technologies -</title>
<date>2004</date>
<journal>North American Chapter of the Association for Computational Linguistics,</journal>
<pages>38--41</pages>
<contexts>
<context position="2916" citStr="Pedersen et al. (2004)" startWordPosition="429" endWordPosition="432">thods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully weighting these features to construct a better semantic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitive. To the best of our knowledge, there is no empirical study directly investigating the effectiveness of adopting structural features such as depth and density. This serves as the major motivation for this study. The paper is organized as follows. In Section 2 we review the basic rationale for adopting depth Proceedings of the 2011 Conference on Empirical Met</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. WordNet::Similarity: measuring the relatedness of concepts. In Demonstration Papers at Human Language Technologies - North American Chapter of the Association for Computational Linguistics, pages 38–41. Association for Computational Linguistics, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Rada</author>
<author>Hafedh Mili</author>
<author>Ellen Bicknell</author>
<author>Maria Blettner</author>
</authors>
<title>Development and application of a metric on semantic nets.</title>
<date>1989</date>
<journal>IEEE Transactions on Systems, Man and Cybernetics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="2371" citStr="Rada et al. 1989" startWordPosition="347" endWordPosition="350">003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully we</context>
</contexts>
<marker>Rada, Mili, Bicknell, Blettner, 1989</marker>
<rawString>Roy Rada, Hafedh Mili, Ellen Bicknell, and Maria Blettner. Development and application of a metric on semantic nets. IEEE Transactions on Systems, Man and Cybernetics, 19(1):17–30, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Semantic similarity in a taxonomy: an information-based measure and its application to problems of ambiguity in natural language.</title>
<date>1999</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<volume>11</volume>
<issue>11</issue>
<contexts>
<context position="2716" citStr="Resnik, 1999" startWordPosition="399" endWordPosition="400">c similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully weighting these features to construct a better semantic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitive. To the best of our knowledge, there is no empirical study directly investigating the effectiveness of adopting structural features such as depth and density. </context>
<context position="8527" citStr="Resnik, 1999" startWordPosition="1353" endWordPosition="1354">o concepts c1 and c2 as: sim(c1,c2) = len(c1,c) + len(c2,c) + 2 · dep(c) (1) where c is the lowest common subsumer (LCS) of c1 and c2, and len(·,·) is the number of edges between two nodes. The rationale is to adjust “hop count” (the first two terms in the denominator) with the depth of LCS: similarity between nodes with samelevel LCS is in negative proportion to hop counts, while given the same hop count, a “deeper” LCS pulls the similarity score closer to 1. Jiang and Conrath (1997) proposed a hybrid method incorporating depth and density information into an information-content-based model (Resnik, 1999): E¯ den(p)] × [IC(c) − IC(p)]T(c, p) (2) Here, p and c are parent and child nodes in WordNet, dep(·) and den(·) denote the depth and density of a node, respectively, E¯ is the average density over the entire network of WordNet, and a and R are two parameters controlling the contribution of depth and density values to the similarity score. IC(·) is the information content of a node based on probability estimates of word classes from a small sensetagged corpus (Resnik, 1999), and T(c, p) is a linktype factor differentiating different types of relations between c and p. 3 Limitations on the Curr</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. Semantic similarity in a taxonomy: an information-based measure and its application to problems of ambiguity in natural language. Journal ofArtificial Intelligence Research, 11(11):95–130, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Richardson</author>
<author>A F Smeaton</author>
</authors>
<title>Using WordNet in a knowledge-based approach to information retrieval.</title>
<date>1995</date>
<booktitle>In Proceedings of the BCS-IRSG Colloquium,</booktitle>
<location>Crewe. Citeseer,</location>
<contexts>
<context position="5581" citStr="Richardson and Smeaton (1995)" startWordPosition="855" endWordPosition="858">semantically closer if (a) they reside deeper in the WordNet hierarchy, or (b) they are more densely connected locally. This is the working assumption for virtually all WordNet-based semantic similarity studies using depth and/or density. For depth, the intuition is that adjacent nodes deep down the hierarchy are likely to be conceptually close, since the differentiation is based on finer details (Jiang and Conrath, 1997). Sussna (1993) termed the use of depth as depth-relative scaling, claiming that “only-siblings deep in a tree are more closely related than onlysiblings higher in the tree”. Richardson and Smeaton (1995) gave an hypothetical example illustrating this “only-siblings” situation, where plant–animal 1Since the works we review in this section have different definitions of depth and density, we defer our formal definitions to Section 3. are the only two nodes under living things, and wolfhound–foxhound under hound. They claimed the reason that the former pair can be regarded as conceptually farther apart compared to the latter is related to the difference in depth. As for the relation between density and similarity, the intuition is that if the overall semantic mass for a given node is constant (Ji</context>
<context position="17066" citStr="Richardson and Smeaton (1995)" startWordPosition="2810" endWordPosition="2813">. Evaluation on the combined data set shows no correlation between density and similarity. To confirm the result, we break the experiments down to the three individual data sets, and the results are listed in Table 1. The correlation coefficient between density and similarity ranges from 0.10 to 0.27 There is no statistical significance of correlation on two of the three data sets (MC and FG), and the significance on RG is close to marginal with p = 0.0366. Data analysis suggests that density values are often biased by particular fine-grainedness of local structures in WordNet. Qualitatively, Richardson and Smeaton (1995) previously observed that “the irregular densities of links between concepts results in unexpected conceptual distance measures”. Empirically, on the one hand, more than 90% of WordNet nodes have density values less than or equal to 3. This means that for 90% of the LCS’s, there are only three integer values for density to distinguish the varying degrees of similarity. In other words, such a range might be too narrow to have any real distinguishing power over similarity. On the other hand, there are outliers with extreme density values particular to the perhaps overly fine-grained subcategoriz</context>
</contexts>
<marker>Richardson, Smeaton, 1995</marker>
<rawString>R. Richardson and A.F. Smeaton. Using WordNet in a knowledge-based approach to information retrieval. In Proceedings of the BCS-IRSG Colloquium, Crewe. Citeseer, 1995.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert Rubenstein</author>
<author>John Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="9977" citStr="Rubenstein and Goodenough (1965)" startWordPosition="1599" endWordPosition="1602">il our intuition. A direct assessment of the effectiveness of using depth and density is to examine their correlation with similarity. Empirical results in this section Figure 1: Correlation between depth and similarity. are achieved by the following experimental setting. Depth is defined as the number of edges between the root of the hierarchy and the lowest common subsumer (LCS) of two nodes under comparison, and density as the number of siblings of the LCS.2 Similarity is measured by human judgment on similarity between word pairs. Commonly used data sets for such judgments include that of Rubenstein and Goodenough (1965), Miller and Charles (1991), and Finkelstein et al. (2001) (denoted RG, MC, and FG, respectively). RG is a collection of similarity ratings of 65 word pairs averaged over judgments from 51 human subjects on a scale of 0 to 4 (from least to most similar). MC is a subset of 30 pairs out of the RG data set. These pairs were chosen to have evenly distributed similarity ratings in the original data set, and similarity judgment was elicited from 38 human judges with the same instruction as used for RG. FG is a much larger set consisting of 353 word pairs, and the rating scale is from 0 to 10. We com</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>Herbert Rubenstein and John Goodenough. Contextual correlates of synonymy. Communications of the ACM, 8(10):627–633, 1965.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Sussna</author>
</authors>
<title>Word sense disambiguation for free-text indexing using a massive semantic network.</title>
<date>1993</date>
<booktitle>In Proceedings of the second international conference on Information and knowledge management,</booktitle>
<pages>67--74</pages>
<publisher>ACM,</publisher>
<contexts>
<context position="2555" citStr="Sussna, 1993" startWordPosition="376" endWordPosition="377">s, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully weighting these features to construct a better semantic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitiv</context>
<context position="5392" citStr="Sussna (1993)" startWordPosition="827" endWordPosition="828">the notions of depth and density in WordNet-based semantic similarity measures is based on the following assumption: Assumption 1 Everything else being equal, two nodes are semantically closer if (a) they reside deeper in the WordNet hierarchy, or (b) they are more densely connected locally. This is the working assumption for virtually all WordNet-based semantic similarity studies using depth and/or density. For depth, the intuition is that adjacent nodes deep down the hierarchy are likely to be conceptually close, since the differentiation is based on finer details (Jiang and Conrath, 1997). Sussna (1993) termed the use of depth as depth-relative scaling, claiming that “only-siblings deep in a tree are more closely related than onlysiblings higher in the tree”. Richardson and Smeaton (1995) gave an hypothetical example illustrating this “only-siblings” situation, where plant–animal 1Since the works we review in this section have different definitions of depth and density, we defer our formal definitions to Section 3. are the only two nodes under living things, and wolfhound–foxhound under hound. They claimed the reason that the former pair can be regarded as conceptually farther apart compared</context>
<context position="7130" citStr="Sussna (1993)" startWordPosition="1107" endWordPosition="1108">(Richardson and Smeaton, 1995). Note that the notion of density here is not to be confused with the conceptual density used by Agirre and Rigau (1996), which is essentially a semantic similarity measure by itself. In general, both observations on depth and density conform to intuition and are supported qualitatively by several existing studies. The main objective of this study is to empirically examine the validity of this assumption. 2.2 Semantic Similarity Measures Using Depth and/or Density One of the first examples of using depth and density in WordNet-based similarity measures is that of Sussna (1993). The weight on an edge between two nodes c1 and c2 with relation r in WordNet is given as: w(c1 →r c2)+w(c2 →r c1) w(c1,c2) = 2d where d is the depth of the deeper of the two nodes. As depth increases, weight decreases and similarity in turn increases, conforming to Assumption 1. The edge weight was further defined as w(c1 →r c2) = maxr − nr(c1) where nr(X) is “the number of relations of type r leaving node X”, which is essentially an implicit form of density, and maxr and minr are the maximum and minimum of nr, respectively. Note that this formulation of density contradicts Assumption maxr −</context>
<context position="24089" citStr="Sussna, 1993" startWordPosition="3980" endWordPosition="3981"> not necessarily conform to normal distributions. Rather, we are interested in testing whether the artificial algorithms would give higher scores to pairs that are regarded closer in meaning by human judges. A non-parametric test suits better for this scenario. And this partly explains why our re-implementations of the models have lower correlation coefficients than in the original studies. Note that there are other WordNet-based similarity measures using depth and/or density that we opt to omit for various reasons. Some of them were not designed for the particular task at hand (e.g., that of Sussna, 1993, which gives very poor correlation in this task). Others use depth of the entire WordNet hierarchy instead of individual nodes as a scaling factor (e.g., that of Leacock and Chodorow, 1998), which is unsuitable for illustrating the improvement brought about by the new depth and density definitions. Parameterization of the weighting of depth and density is a common practice to control their individual contribution to the final similarity score (e.g., a and R in Equation (2)). Jiang and Conrath already had separate weights in their original study. In orBest Average MC RB GR MC RB GR dep 0.7671 </context>
</contexts>
<marker>Sussna, 1993</marker>
<rawString>Michael Sussna. Word sense disambiguation for free-text indexing using a massive semantic network. In Proceedings of the second international conference on Information and knowledge management, pages 67–74. ACM, 1993.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
</authors>
<title>Mining the web for synonyms: PMIIR versus LSA on TOEFL.</title>
<date>2001</date>
<booktitle>Proceedings of the Twelfth European Conference on Machine Learning,</booktitle>
<pages>491--502</pages>
<contexts>
<context position="1579" citStr="Turney, 2001" startWordPosition="224" endWordPosition="225">of correlation with similarity. When used in WordNet-based semantic similarity measures, the new definitions consistently improve performance on a task of correlating with human judgment. 1 Introduction Semantic similarity measures are widely used in natural language processing for measuring distance between meanings of words. There are currently two mainstream approaches to deriving such measures, i.e., distributional and lexical resource-based approaches. The former usually explores the cooccurrence patterns of words in large collections of texts such as text corpora (Lin, 1998) or the Web (Turney, 2001). The latter takes advantage of mostly handcrafted information, such as dictionaries (Chodorow et al., 1985; Kozima and Ito, 1997) or thesauri (Jarmasz and Szpakowicz, 2003). 1003 Another important resource in the latter stream is semantic taxonomies such as WordNet (Fellbaum, 1998). Despite their high cost of compilation and limited availability across languages, semantic taxonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (re</context>
</contexts>
<marker>Turney, 2001</marker>
<rawString>Peter Turney. Mining the web for synonyms: PMIIR versus LSA on TOEFL. Proceedings of the Twelfth European Conference on Machine Learning, pages 491–502, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhibiao Wu</author>
<author>Martha Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<contexts>
<context position="2577" citStr="Wu and Palmer, 1994" startWordPosition="378" endWordPosition="381">xonomies have been widely used in similarity measures, and one of the main reasons behind this is that the often complex notion of lexical semantic similarity can be approximated with ease by the distance between words (represented as nodes) in their hierarchical structures, and this approximation appeals much to our intuition. Even methods as simple as “hop counts” between nodes (e.g., that of Rada et al. 1989 on the English WordNet) can take us a long way. Meanwhile, taxonomy-based methods have been constantly refined by incorporating various structural features such as depth (Sussna, 1993; Wu and Palmer, 1994), density (Sussna, 1993), type of connection (Hirst and St-Onge, 1998; Sussna, 1993), word class (sense) frequency estimates (Resnik, 1999), or a combination these features (Jiang and Conrath, 1997). Most of these algorithms are fairly self-contained and easy to implement, with off-theshelf toolkits such as that of Pedersen et al. (2004). With the existing literature focusing on carefully weighting these features to construct a better semantic similarity measure, however, the rationale for adopting these features in calculating semantic similarity remains largely intuitive. To the best of our </context>
<context position="7865" citStr="Wu and Palmer (1994)" startWordPosition="1238" endWordPosition="1241"> w(c1,c2) = 2d where d is the depth of the deeper of the two nodes. As depth increases, weight decreases and similarity in turn increases, conforming to Assumption 1. The edge weight was further defined as w(c1 →r c2) = maxr − nr(c1) where nr(X) is “the number of relations of type r leaving node X”, which is essentially an implicit form of density, and maxr and minr are the maximum and minimum of nr, respectively. Note that this formulation of density contradicts Assumption maxr − minr 1004 1 since it is proportional to edge weight (left-handside) and thus negatively correlated to similarity. Wu and Palmer (1994) proposed a concept similarity measure between two concepts c1 and c2 as: sim(c1,c2) = len(c1,c) + len(c2,c) + 2 · dep(c) (1) where c is the lowest common subsumer (LCS) of c1 and c2, and len(·,·) is the number of edges between two nodes. The rationale is to adjust “hop count” (the first two terms in the denominator) with the depth of LCS: similarity between nodes with samelevel LCS is in negative proportion to hop counts, while given the same hop count, a “deeper” LCS pulls the similarity score closer to 1. Jiang and Conrath (1997) proposed a hybrid method incorporating depth and density info</context>
<context position="22833" citStr="Wu and Palmer (1994)" startWordPosition="3767" endWordPosition="3770">th similarity. As shown in row 3 in Table 2, the correlation coefficients are about tripled on all three data sets with the new density definition deni, and the significance of correlation is greatly improved as well (from non-correlating or 1008 marginally correlating to strongly significantly correlating on all three data sets). 5 Using the New Definitions in Semantic Similarity Measures In this section, we test the effectiveness of the new definitions of depth and density by using them in WordNet-based semantic similarity measures. The two similarity measures we experiment with are that of Wu and Palmer (1994) and Jiang and Conrath (1997). The first one used depth only, and the second one used both depth and density. The task is to correlate the similarity measures with human judgment on similarity between word pairs. We use the same three data sets as in Section 3. despite the fact that MC is a subset of RG data set, we include both in order to compare with existing studies. Correlation coefficient is calculated using Spearman’s p, although results reported by some earlier studies used parametric tests such as the Pearson Correlation Coefficient. The reason for our choice is that the similarity sc</context>
<context position="24859" citStr="Wu and Palmer (1994)" startWordPosition="4106" endWordPosition="4109">.g., that of Leacock and Chodorow, 1998), which is unsuitable for illustrating the improvement brought about by the new depth and density definitions. Parameterization of the weighting of depth and density is a common practice to control their individual contribution to the final similarity score (e.g., a and R in Equation (2)). Jiang and Conrath already had separate weights in their original study. In orBest Average MC RB GR MC RB GR dep 0.7671 0.7824 0.3773 0.7612 0.7686 0.3660 depu 0.7824 0.7912 0.3946 0.7798 0.7810 0.3787 Table 3: Correlation between human judgment and similarity score by Wu and Palmer (1994) using two versions of depth. MC Best GR MC Average GR RB RB 0.7875 0.8111 0.3720 0.7689 0.7990 0.3583 0.8009 0.8181 0.3804 0.7885 0.8032 0.3669 0.7882 0.8199 0.3803 0.7863 0.8102 0.3689 0.8065 0.8202 0.3818 0.8189 0.8194 0.3715 Table 4: Correlation between human judgment and similarity score by Jiang and Conrath (1997) using different definitions of depth and density. der to parameterize depth used by Wu and Palmer in their similarity measure, we also modify Equation (1) as follows: sim(c1,c2) = len(c1,c) + len(c2,c) + 2 · depa(c) where depth is raised to the power of a to vary its contributi</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Zhibiao Wu and Martha Palmer. Verb semantics and lexical selection. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pages 133–138. Association for Computational Linguistics, 1994.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>