<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000073">
<title confidence="0.970724">
Learning Sub-Word Units for Open Vocabulary Speech Recognition
</title>
<author confidence="0.999079">
Carolina Parada&apos;, Mark Dredze&apos;, Abhinav Sethy2, and Ariya Rastrow&apos;
</author>
<affiliation confidence="0.9284375">
&apos;Human Language Technology Center of Excellence, Johns Hopkins University
3400 N Charles Street, Baltimore, MD, USA
</affiliation>
<email confidence="0.964336">
carolinap@jhu.edu, mdredze@cs.jhu.edu, ariya@jhu.edu
</email>
<note confidence="0.50429">
2IBM T.J. Watson Research Center, Yorktown Heights, NY, USA
</note>
<email confidence="0.988722">
asethy@us.ibm.com
</email>
<sectionHeader confidence="0.994582" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.940594095238095">
Large vocabulary speech recognition systems
fail to recognize words beyond their vocab-
ulary, many of which are information rich
terms, like named entities or foreign words.
Hybrid word/sub-word systems solve this
problem by adding sub-word units to large vo-
cabulary word based systems; new words can
then be represented by combinations of sub-
word units. Previous work heuristically cre-
ated the sub-word lexicon from phonetic rep-
resentations of text using simple statistics to
select common phone sequences. We pro-
pose a probabilistic model to learn the sub-
word lexicon optimized for a given task. We
consider the task of out of vocabulary (OOV)
word detection, which relies on output from
a hybrid model. A hybrid model with our
learned sub-word lexicon reduces error by
6.3% and 7.6% (absolute) at a 5% false alarm
rate on an English Broadcast News and MIT
Lectures task respectively.
</bodyText>
<sectionHeader confidence="0.998823" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997600090909091">
Most automatic speech recognition systems operate
with a large but limited vocabulary, finding the most
likely words in the vocabulary for the given acoustic
signal. While large vocabulary continuous speech
recognition (LVCSR) systems produce high quality
transcripts, they fail to recognize out of vocabulary
(OOV) words. Unfortunately, OOVs are often infor-
mation rich nouns, such as named entities and for-
eign words, and mis-recognizing them can have a
disproportionate impact on transcript coherence.
Hybrid word/sub-word recognizers can produce a
sequence of sub-word units in place of OOV words.
Ideally, the recognizer outputs a complete word for
in-vocabulary (IV) utterances, and sub-word units
for OOVs. Consider the word “Slobodan”, the given
name of the former president of Serbia. As an un-
common English word, it is unlikely to be in the vo-
cabulary of an English recognizer. While a LVCSR
system would output the closest known words (e.x.
“slow it dawn”), a hybrid system could output a
sequence of multi-phoneme units: s l ow, b ax,
d ae n. The latter is more useful for automatically
recovering the word’s orthographic form, identify-
ing that an OOV was spoken, or improving perfor-
mance of a spoken term detection system with OOV
queries. In fact, hybrid systems have improved OOV
spoken term detection (Mamou et al., 2007; Parada
et al., 2009), achieved better phone error rates, espe-
cially in OOV regions (Rastrow et al., 2009b), and
obtained state-of-the-art performance for OOV de-
tection (Parada et al., 2010).
Hybrid recognizers vary in a number of ways:
sub-word unit type: variable-length phoneme
units (Rastrow et al., 2009a; Bazzi and Glass, 2001)
or joint letter sound sub-words (Bisani and Ney,
2005); unit creation: data-driven or linguistically
motivated (Choueiter, 2009); and how they are in-
corporated in LVCSR systems: hierarchical (Bazzi,
2002) or flat models (Bisani and Ney, 2005).
In this work, we consider how to optimally cre-
ate sub-word units for a hybrid system. These units
are variable-length phoneme sequences, although in
principle our work can be use for other unit types.
Previous methods for creating the sub-word lexi-
</bodyText>
<page confidence="0.945463">
712
</page>
<note confidence="0.9801065">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 712–721,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.99638597368421">
con have relied on simple statistics computed from word lexicon.1 Learning input includes a list of
the phonetic representation of text (Rastrow et al., words to segment taken from raw text, a mapping
2009a). These units typically represent the most fre- between words and classes (side information indi-
quent phoneme sequences in English words. How- cating whether token is IV or OOV), a pronuncia-
ever, it isn’t clear why these units would produce the tion dictionary D, and a letter to sound model (L2S),
best hybrid output. Instead, we introduce a prob- such as the one described in Chen (2003). The cor-
abilistic model for learning the optimal units for a pus W is the list of types (unique words) in the raw
given task. Our model learns a segmentation of a text input. This forces each word to have a unique
text corpus given some side information: a mapping segmentation, shared by all common tokens. Words
between the vocabulary and a label set; learned units are converted into phonetic representations accord-
are predictive of class labels. ing to their most likely dictionary pronunciation;
In this paper, we learn sub-word units optimized non-dictionary words use the L2S model.2
for OOV detection. OOV detection aims to identify
regions in the LVCSR output where OOVs were ut-
tered. Towards this goal, we are interested in select-
ing units such that the recognizer outputs them only
for OOV regions while prefering to output a com-
plete word for in-vocabulary regions. Our approach
yields improvements over state-of-the-art results.
We begin by presenting our log-linear model for
learning sub-word units with a simple but effective
inference procedure. After reviewing existing OOV
detection approaches, we detail how the learned
units are integrated into a hybrid speech recognition
system. We show improvements in OOV detection,
and evaluate impact on phone error rates.
2 Learning Sub-Word Units
Given raw text, our objective is to produce a lexicon
of sub-word units that can be used by a hybrid sys-
tem for open vocabulary speech recognition. Rather
than relying on the text alone, we also utilize side
information: a mapping of words to classes so we
can optimize learning for a specific task.
The provided mapping assigns labels Y to the cor-
pus. We maximize the probability of the observed
labeling sequence Y given the text W: P (Y |W).
We assume there is a latent segmentation S of this
corpus which impacts Y . The complete data likeli-
</bodyText>
<table confidence="0.945190153846154">
hood becomes: P(Y |W) = ES P(Y, S|W) during
training. Since we are maximizing the observed Y ,
segmentation S must discriminate between different
possible labels.
We learn variable-length multi-phone units by
segmenting the phonetic representation of each word
in the corpus. Resulting segments form the sub-
713
2.1 Model
Inspired by the morphological segmentation model
of Poon et al. (2009), we assume P(Y, S|W) is a
log-linear model parameterized by A:
1
</table>
<equation confidence="0.583937">
PA(Y,S|W) = Z(W)uA(Y,S,W) (1)
</equation>
<bodyText confidence="0.995371678571428">
where uA(Y,S,W) defines the score of the pro-
posed segmentation S for words W and labels Y
according to model parameters A. Sub-word units
σ compose S, where each σ is a phone sequence, in-
cluding the full pronunciation for vocabulary words;
the collection of σs form the lexicon. Each unit
σ is present in a segmentation with some context
c = (φl, φr) of the form φlσφr. Features based on
the context and the unit itself parameterize uA.
In addition to scoring a segmentation based on
features, we include two priors inspired by the Min-
imum Description Length (MDL) principle sug-
gested by Poon et al. (2009). The lexicon prior
favors smaller lexicons by placing an exponential
prior with negative weight on the length of the lex-
icon &amp; |σ|, where |σ |is the length of the unit σ
in number of phones. Minimizing the lexicon prior
favors a trivial lexicon of only the phones. The
corpus prior counters this effect, an exponential
prior with negative weight on the number of units
in each word’s segmentation, where |si |is the seg-
mentation length and |wi |is the length of the word
in phones. Learning strikes a balance between the
two priors. Using these definitions, the segmenta-
tion score uA(Y, S, W) is given as:
1Since sub-word units can expand full-words, we refer to
both words and sub-words simply as units.
2The model can also take multiple pronunciations (§3.1).
</bodyText>
<subsectionHeader confidence="0.360252">
slow b ax daen
</subsectionHeader>
<bodyText confidence="0.620696">
(#,#, , b, ax) (l,ow, , d, ae) (b,ax, , #, #)
</bodyText>
<figureCaption confidence="0.9849795">
Figure 1: Units and bigram phone context (in parenthesis)
for an example segmentation of the word “slobodan”.
</figureCaption>
<equation confidence="0.9300084">
X
+
C&apos;,Y
X+ α · |σ|
QES
+ β ·
iEW
X !|si|/|wi |(2)
f,,y(S, Y ) are the co-occurrence counts of the pair
(σ, y) where σ is a unit under segmentation S and y
</equation>
<bodyText confidence="0.896810833333333">
is the label. fc,y(S, Y ) are the co-occurrence counts
for the context c and label y under S. The model
parameters are A = {λIT,y, λc,y : ∀σ, c, y}. The neg-
ative weights for the lexicon (α) and corpus priors
(β) are tuned on development data. The normalizer
Z sums over all possible segmentations and labels:
</bodyText>
<equation confidence="0.99739">
Z(W) = X X uA(Y &apos;, S&apos;, W) (3)
S1 Y 1
</equation>
<bodyText confidence="0.99836325">
Consider the example segmentation for the word
“slobodan” with pronunciation s,l,ow,b,ax,d,ae,n
(Figure 1). The bigram phone context as a four-tuple
appears below each unit; the first two entries corre-
spond to the left context, and last two the right con-
text. The example corpus (Figure 2) demonstrates
how unit features f,,y and context features fc,y are
computed.
</bodyText>
<sectionHeader confidence="0.929968" genericHeader="method">
3 Model Training
</sectionHeader>
<bodyText confidence="0.99436675">
Learning maximizes the log likelihood of the ob-
served labels Y * given the words W:
We use the Expectation-Maximization algorithm,
where the expectation step predicts segmentations S
</bodyText>
<equation confidence="0.892649909090909">
Labeled corpus: president/y = 0 milosevic/y = 1
Segmented corpus: p r eh z ih d ih n t/0 m ih/1 l aa/1
s ax/1 v ih ch/1
Unit-feature:Value p r eh z ih d ih n t/0:1 m ih/1:1
l aa/1:1 s ax/1:1 v ih ch/1:1
Context-feature:Value
(#/0,#/0, ,l/1,aa/1):1,
(m/1,ih/1, ,s/1,ax/1):1,
(l/1,aa/1, ,v/1,ih/1):1,
(s/1,ax/1, ,#/0,#/0):1,
(#/0,#/0, ,#/0,#/0):1
</equation>
<figureCaption confidence="0.9911724">
Figure 2: A small example corpus with segmentations
and corresponding features. The notation m ih/1:1
represents unit/label:feature-value. Overlapping context
features capture rich segmentation regularities associated
with each class.
</figureCaption>
<bodyText confidence="0.99112025">
given the model’s current parameters A (§3.1), and
the maximization step updates these parameters us-
ing gradient ascent. The partial derivatives of the
objective (4) with respect to each parameter λi are:
</bodyText>
<equation confidence="0.9993055">
∂`(Y *|W)
∂λi = ES|Y *,W[fi] − ES,Y |W[fi] (5)
</equation>
<bodyText confidence="0.9998922">
The gradient takes the usual form, where we en-
courage the expected segmentation from the current
model given the correct labels to equal the expected
segmentation and expected labels. The next section
discusses computing these expectations.
</bodyText>
<subsectionHeader confidence="0.96568">
3.1 Inference
</subsectionHeader>
<bodyText confidence="0.99996055">
Inference is challenging since the lexicon prior ren-
ders all word segmentations interdependent. Con-
sider a simple two word corpus: cesar (s,iy,z,er),
and cesium (s,iy,z,iy,ax,m). Numerous segmen-
tations are possible; each word has 2N−1 possible
segmentations, where N is the number of phones in
its pronunciation (i.e., 23 × 25 = 256). However,
if we decide to segment the first word as: {s iy,
z er}, then the segmentation for “cesium”:{s iy,
z iy ax m} will incur a lexicon prior penalty for
including the new segment z iy ax m. If instead
we segment “cesar” as {s iy z, er}, the segmen-
tation {s iy, z iy ax m} incurs double penalty
for the lexicon prior (since we are including two new
units in the lexicon: s iy and z iy ax m). This
dependency requires joint segmentation of the entire
corpus, which is intractable. Hence, we resort to ap-
proximations of the expectations in Eq. (5).
One approach is to use Gibbs Sampling: it-
erating through each word, sampling a new seg-
</bodyText>
<equation confidence="0.9925338">
s l ow b ax d ae n
XuA(Y, S, W) = exp
Q,Y
λQ,YfQ,Y(S,Y )
λ,,Yf.,Y(S, Y )
X
`(Y *|W) = log
S
1 uA(Y *, S, W) (4)
Z(W)
</equation>
<page confidence="0.978961">
714
</page>
<bodyText confidence="0.871204888888889">
mentation conditioned on the segmentation of all
other words. The sampling distribution requires
enumerating all possible segmentations for each
word (2N−1) and computing the conditional prob-
abilities for each segmentation: P(S|Y *, W) =
P(Y *, S|W)/P(Y *|W) (the features are extracted
from the remaining words in the corpus). Using M
sampled segmentations S1, S2,... Sm we compute
ES|Y ∗,W[fi] as follows:
</bodyText>
<equation confidence="0.947121">
1 � ES|Y ∗,W [fi] ^ M fi[Sj]
j
</equation>
<bodyText confidence="0.99988">
Similarly, to compute ES,Y |W we sample a seg-
mentation and a label for each word. We com-
pute the joint probability of P(Y, S|W) for each
segmentation-label pair using Eq. (1). A sampled
segmentation can introduce new units, which may
have higher probability than existing ones.
Using these approximations in Eq. (5), we update
the parameters using gradient ascent:
</bodyText>
<equation confidence="0.637598">
Anew = Aold + ^/V4(Y *|W)
</equation>
<bodyText confidence="0.999717363636364">
where -y &gt; 0 is the learning rate.
To obtain the best segmentation, we use determin-
istic annealing. Sampling operates as usual, except
that the parameters are divided by a value, which
starts large and gradually drops to zero. To make
burn in faster for sampling, the sampler is initialized
with the most likely segmentation from the previous
iteration. To initialize the sampler the first time, we
set all the parameters to zero (only the priors have
non-zero values) and run deterministic annealing to
obtain the first segmentation of the corpus.
</bodyText>
<subsectionHeader confidence="0.999869">
3.2 Efficient Sampling
</subsectionHeader>
<bodyText confidence="0.99692809375">
Sampling a segmentation for the corpus requires
computing the normalization constant (3), which
contains a summation over all possible corpus seg-
mentations. Instead, we approximate this constant
by sampling words independently, keeping fixed all
other segmentations. Still, even sampling a single
word’s segmentation requires enumerating probabil-
ities for all possible segmentations.
We sample a segmentation efficiently using dy-
namic programming. We can represent all possible
segmentations for a word as a finite state machine
(FSM) (Figure 3), where arcs weights arise from
scoring the segmentation’s features. This weight is
the negative log probability of the resulting model
after adding the corresponding features and priors.
However, the lexicon prior poses a problem for
this construction since the penalty incurred by a new
unit in the segmentation depends on whether that
unit is present elsewhere in that segmentation. For
example, consider the segmentation for the word
ANJANI: AA N, JH, AA N, IY. If none of these units
are in the lexicon, this segmentation yields the low-
est prior penalty since it repeats the unit AA N. 3 This
global dependency means paths must encode the full
unit history, making computing forward-backward
probabilities inefficient.
Our solution is to use the Metropolis-Hastings al-
gorithm, which samples from the true distribution
P(Y, S|W) by first sampling a new label and seg-
mentation (y&apos;, s&apos;) from a simpler proposal distribu-
tion Q(Y, S|W). The new assignment (y&apos;, s&apos;) is ac-
cepted with probability:
</bodyText>
<equation confidence="0.99707025">
„ «
1, P (Y 0, S0|W )Q(Y, S|Y 0, S0, W )
α(Y0, S0|Y, S, W)=min
P (Y, S|W)Q(Y 0, S0|Y, S, W)
</equation>
<bodyText confidence="0.999998">
We choose the proposal distribution Q(Y, S|W)
as Eq. (1) omitting the lexicon prior, removing the
challenge for efficient computation. The probability
of accepting a sample becomes:
</bodyText>
<equation confidence="0.9814585">
α(Y 0, S0|Y, S, W)=min1, &amp;quot;:S, |σ|) (6)
„ P,∈S  |σ |/
</equation>
<bodyText confidence="0.981384153846154">
We sample a path from the FSM by running the
forward-backward algorithm, where the backward
computations are carried out explicitly, and the for-
ward pass is done through sampling, i.e. we traverse
the machine only computing forward probabilities
for arcs leaving the sampled state.4 Once we sample
a segmentation (and label) we accept it according to
Eq. (6) or keep the previous segmentation if rejected.
Alg. 1 shows our full sub-word learning proce-
dure, where sampleSL (Alg. 2) samples a segmen-
tation and label sequence for the entire corpus from
P(Y, S|W), and sampleS samples a segmentation
from P(S|Y *, W).
</bodyText>
<footnote confidence="0.99984025">
3Splitting at phone boundaries yields the same lexicon prior
but a higher corpus prior.
4We use OpenFst’s RandGen operation with a costumed arc-
selector (http://www.openfst.org/).
</footnote>
<page confidence="0.993473">
715
</page>
<figure confidence="0.9872435">
AA_N_JH_AA_N
JH_AA_N_IY
</figure>
<figureCaption confidence="0.979364">
Figure 3: FSM representing all segmentations for the word ANJANI with pronunciation: AA,N,JH,AA,N,IY
</figureCaption>
<figure confidence="0.99484137037037">
AA
0 1
AA_N
AA_N_JH
N
AA_N_JH_AA
N_JH
2
N_JH_AA
JH
N_JH_AA_N
JH_AA
3
N_JH_AA_N_IY
JH_AA_N
AA
AA_N
4
AA_N_IY
N
5
IY
6
Algorithm 1 Training
Input: Lexicon L from training text W, Dictionary D,
Mapping M, L2S pronunciations, Annealing temp T.
Initialization:
</figure>
<equation confidence="0.910874875">
Assign label y∗m = M[wm].
S0 = random segmentation for each word in L.
for i = 1 to K do
/* E-Step */
Si = bestSegmentation(T, λi−1, Si−1).
for k = 1 to NumSamples do
(S0k, Y0k) = sampleSL(P(Y, Si|W),Q(Y, Si|W))
9k = sampleS(P(Si|Y ∗, W),Q(Si|Y ∗, W))
end for
/* M-Step */
ES,Y|W [fi] = NumSamples Ek fσ,l [S0k, Y0k]
ES|Y *,W[fσ,l] = NumSamples Ek fσ,l[�Sk,Y ∗]
�
λi = Ai−1 + γ∇L¯λ(Y ∗|W)
end for
S = bestSegmentation(T, λK, S0)
</equation>
<copyright confidence="0.361916">
Output: Lexicon Lo from S
</copyright>
<sectionHeader confidence="0.994631" genericHeader="method">
4 OOV Detection Using Hybrid Models
</sectionHeader>
<bodyText confidence="0.9995882">
To evaluate our model for learning sub-word units,
we consider the task of out-of-vocabulary (OOV)
word detection. OOV detection for ASR output can
be categorized into two broad groups: 1) hybrid
(filler) models: which explicitly model OOVs us-
ing either filler, sub-words, or generic word mod-
els (Bazzi, 2002; Schaaf, 2001; Bisani and Ney,
2005; Klakow et al., 1999; Wang, 2009); and
2) confidence-based approaches: which label un-
reliable regions as OOVs based on different con-
fidence scores, such as acoustic scores, language
models, and lattice scores (Lin et al., 2007; Burget
et al., 2008; Sun et al., 2001; Wessel et al., 2001).
In the next section we detail the OOV detection
approach we employ, which combines hybrid and
</bodyText>
<equation confidence="0.98484325">
Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W))
for m = 1 to M (NumWords) do
(s0 m, y0m) = Sample segmentation/label pair for
word wm according to Q(S, Y |W)
Y 0 = {y1 ... ym−1y0mym+1 ... yM}
S0 = {s1 . . . sm−1s0 msm+1 . . . sM}
�α=min1, C� ES&apos; |σ|
/ IES |σ|
with prob α : ym,k = y0m, sm,k = s0m
with prob (1 − α) : ym,k = ym, sm,k = sm
end for
return (S0k, Y0k) = [(s1,k, y1,k) ... (sM,k, yM,k)]
</equation>
<bodyText confidence="0.97256">
confidence-based models, achieving state-of-the art
performance for this task.
</bodyText>
<subsectionHeader confidence="0.943149">
4.1 OOV Detection Approach
</subsectionHeader>
<bodyText confidence="0.999910454545455">
We use the state-of-the-art OOV detection model of
Parada et al. (2010), a second order CRF with fea-
tures based on the output of a hybrid recognizer.
This detector processes hybrid recognizer output, so
we can evaluate different sub-word unit lexicons for
the hybrid recognizer and measure the change in
OOV detection accuracy.
Our model (§2.1) can be applied to this task by
using a dictionary D to label words as IV (yi = 0 if
wi ∈ D) and OOV (yi = 1 if wi ∈/ D). This results
in a labeled corpus, where the labeling sequence Y
indicates the presence of out-of-vocabulary words
(OOVs). For comparison we evaluate a baseline
method (Rastrow et al., 2009b) for selecting units.
Given a sub-word lexicon, the word and sub-
words are combined to form a hybrid language
model (LM) to be used by the LVCSR system. This
hybrid LM captures dependencies between word and
sub-words. In the LM training data, all OOVs are
represented by the smallest number of sub-words
which corresponds to their pronunciation. Pronun-
ciations for all OOVs are obtained using grapheme
</bodyText>
<equation confidence="0.8770295">
0
λ0 =
</equation>
<page confidence="0.963723">
716
</page>
<figureCaption confidence="0.993332549019608">
to phone models (Chen, 2003). with a 83K word vocabulary. The LVCSR system’s
Since sub-words represent OOVs while building WER on the standard RT04 BN test set was 19.4%.
the hybrid LM, the existence of sub-words in ASR Excluded utterances amount to 100hrs. These were
output indicate an OOV region. A simple solution to divided into 5 hours of training for the OOV detec-
the OOV detection problem would then be reduced tor and 95 hours of test. Note that the OOV detector
to a search for the sub-words in the output of the training set is different from the LVCSR training set.
ASR system. The search can be on the one-best We also use a hybrid LVCSR system, combin-
transcripts, lattices or confusion networks. While ing word and sub-word units obtained from ei-
lattices contain more information, they are harder ther our approach or a state-of-the-art baseline ap-
to process; confusion networks offer a trade-off be- proach (Rastrow et al., 2009a) (§5.2). Our hybrid
tween richness (posterior probabilities are already system’s lexicon has 83K words and 5K or 10K
computed) and compactness (Mangu et al., 1999). sub-words. Note that the word vocabulary is com-
Two effective indications of OOVs are the exis- mon to both systems and only the sub-words are se-
tence of sub-words (Eq. 7) and high entropy in a lected using either approach. The word vocabulary
network region (Eq. 8), both of which are used as used is close to most modern LVCSR system vo-
features in the model of Parada et al. (2010). cabularies for English Broadcast News; the result-
�Sub-word Posterior= p(u|tj) (7) ing OOVs are more challenging but more realistic
QEtj (i.e. mostly named entities and technical terms). The
�Word-Entropy = − p(w|tj) log p(w|tj) (8) 1290 words are OOVs to both the word and hybrid
wEtj systems.
tj is the current bin in the confusion network and In addition we report OOV detection results on a
a is a sub-word in the hybrid dictionary. Improving MIT lectures data set (Glass et al., 2010) consisting
the sub-word unit lexicon, improves the quality of of 3 Hrs from two speakers with a 1.5% OOV rate.
the confusion networks for OOV detection. These were divided into 1 Hr for training the OOV
5 Experimental Setup detector and 2 Hrs for testing. Note that the LVCSR
We used the data set constructed by Can et al. system is trained on Broadcast News data. This out-
(2009) (OOVCORP) for the evaluation of Spoken of-domain test-set help us evaluate the cross-domain
Term Detection of OOVs since it focuses on the performance of the proposed and baseline hybrid
OOV problem. The corpus contains 100 hours of systems. OOVs in this data set correspond mainly to
transcribed Broadcast News English speech. There technical terms in computer science and math. e.g.
are 1290 unique OOVs in the corpus, which were ALGORITHM, DEBUG, COMPILER, LISP.
selected with a minimum of 5 acoustic instances per 5.1 Learning parameters
word and short OOVs inappropriate for STD (less For learning the sub-words we randomly selected
than 4 phones) were explicitly excluded. Example from training 5,000 words which belong to the 83K
OOVs include: NATALIE, PUTIN, QAEDA, vocabulary and 5,000 OOVs6. For development we
HOLLOWAY, COROLLARIES, HYPERLINKED, selected an additional 1,000 IV and 1,000 OOVs.
etc. This resulted in roughly 24K (2%) OOV tokens. This was used to tune our model hyper parameters
For LVCSR, we used the IBM Speech Recogni- (set to a = −1, Q = −20). There is no overlap
tion Toolkit (Soltau et al., 2005)5 to obtain a tran- of OOVs in training, development and test sets. All
script of the audio. Acoustic models were trained feature weights were initialized to zero and had a
on 300 hours of HUB4 data (Fiscus et al., 1998) Gaussian prior with variance a = 100. Each of the
and utterances containing OOV words as marked in words in training and development was converted to
OOVCORP were excluded. The language model was their most-likely pronunciation using the dictionary
trained on 400M words from various text sources
6This was used to obtain the 5K hybrid system. To learn sub-
words for the 10K hybrid system we used 10K in-vocabulary
words and 10K OOVs. All words were randomly selected from
the LM training text.
5The IBM system used speaker adaptive training based on
maximum likelihood with no discriminative training.
717
</figureCaption>
<bodyText confidence="0.997182933333333">
for IV words or the L2S model for OOVs.7
The learning rate was &apos;Yk = �
(k���A)� , where k is
the iteration, A is the stability constant (set to 0.1K),
-y = 0.4, and T = 0.6. We used K = 40 itera-
tions for learning and 200 samples to compute the
expectations in Eq. 5. The sampler was initialized
by sampling for 500 iterations with deterministic an-
nealing for a temperature varying from 10 to 0 at 0.1
intervals. Final segmentations were obtained using
10, 000 samples and the same temperature schedule.
We limit segmentations to those including units of at
most 5 phones to speed sampling with no significant
degradation in performance. We observed improved
performance by dis-allowing whole word units.
</bodyText>
<subsectionHeader confidence="0.993425">
5.2 Baseline Unit Selection
</subsectionHeader>
<bodyText confidence="0.999984222222222">
We used Rastrow et al. (2009a) as our baseline
unit selection method, a data driven approach where
the language model training text is converted into
phones using the dictionary (or a letter-to-sound
model for OOVs), and a N-gram phone LM is es-
timated on this data and pruned using a relative en-
tropy based method. The hybrid lexicon includes
resulting sub-words – ranging from unigrams to 5-
gram phones, and the 83K word lexicon.
</bodyText>
<subsectionHeader confidence="0.970145">
5.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999913384615385">
We obtain confusion networks from both the word
and hybrid LVCSR systems. We align the LVCSR
transcripts with the reference transcripts and tag
each confusion region as either IV or OOV. The
OOV detector classifies each region in the confusion
network as IV/OOV. We report OOV detection accu-
racy using standard detection error tradeoff (DET)
curves (Martin et al., 1997). DET curves measure
tradeoffs between false alarms (x-axis) and misses
(y-axis), and are useful for determining the optimal
operating point for an application; lower curves are
better. Following Parada et al. (2010) we separately
evaluate unobserved OOVs.8
</bodyText>
<footnote confidence="0.9879895">
7In this work we ignore pronunciation variability and sim-
ply consider the most likely pronunciation for each word. It
is straightforward to extend to multiple pronunciations by first
sampling a pronunciation for each word and then sampling a
segmentation for that pronunciation.
8Once an OOV word has been observed in the OOV detector
training data, even if it was not in the LVCSR training data, it is
no longer truly OOV.
</footnote>
<sectionHeader confidence="0.998907" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999971368421053">
We compare the performance of a hybrid sys-
tem with baseline units9 (§5.2) and one with units
learned by our model on OOV detection and phone
error rate. We present results using a hybrid system
with 5k and 10k sub-words.
We evaluate the CRF OOV detector with two dif-
ferent feature sets. The first uses only Word En-
tropy and Sub-word Posterior (Eqs. 7 and 8) (Fig-
ure 4)10. The second (context) uses the extended
context features of Parada et al. (2010) (Figure 5).
Specifically, we include all trigrams obtained from
the best hypothesis of the recognizer (a window of 5
words around current confusion bin). Predictions at
different FA rates are obtained by varying a proba-
bility threshold.
At a 5% FA rate, our system (This Paper 5k) re-
duces the miss OOV rate by 6.3% absolute over the
baseline (Baseline 5k) when evaluating all OOVs.
For unobserved OOVs, it achieves 3.6% absolute
improvement. A larger lexicon (Baseline 10k and
This Paper 10k ) shows similar relative improve-
ments. Note that the features used so far do not nec-
essarily provide an advantage for unobserved ver-
sus observed OOVs, since they ignore the decoded
word/sub-word sequence. In fact, the performance
on un-observed OOVs is better.
OOV detection improvements can be attributed to
increased coverage of OOV regions by the learned
sub-words compared to the baseline. Table 1 shows
the percent of Hits: sub-word units predicted in
OOV regions, and False Alarms: sub-word units
predicted for in-vocabulary words. We can see
that the proposed system increases the Hits by over
8% absolute, while increasing the False Alarms by
0.3%. Interestingly, the average sub-word length
for the proposed units exceeded that of the baseline
units by 0.3 phones (Baseline 5K average length
was 2.92, while that of This Paper 5K was 3.2).
</bodyText>
<footnote confidence="0.995852">
9Our baseline results differ from Parada et al. (2010). When
implementing the lexicon baseline, we discovered that their hy-
brid units were mistakenly derived from text containing test
OOVs. Once excluded, the relative improvements of previous
work remain, but the absolute error rates are higher.
10All real-valued features were normalized and quantized us-
ing the uniform-occupancy partitioning described in White et
al. (2007). We used 50 partitions with a minimum of 100 train-
ing values per partition.
</footnote>
<page confidence="0.988017">
718
</page>
<figure confidence="0.990698193548387">
70
65
60
55
50
45
40
35
300 5 10 15 20
%FA
%Masses
Baseline (5k)
This Paper (5k)
Baseline (10k)
This Paper (10k)
%Masses
45
70
65
60
55
50
300 5 10 15 20
%FA
Baseline (5k)
This Paper (5k)
Baseline (10k)
This Paper (10k)
40
35
(a) (b)
</figure>
<figureCaption confidence="0.997851">
Figure 4: DET curves for OOV detection using baseline hybrid systems for different lexicon size and proposed dis-
criminative hybrid system on OOVCORP data set. Evaluation on un-observed OOVs (a) and all OOVs (b).
</figureCaption>
<figure confidence="0.995961">
70
65
60
%Masses 55
50
45
40
35
300 5 10 15 20
%FA
(a) (b)
</figure>
<figureCaption confidence="0.973977">
Figure 5: Effect of adding context features to baseline and discriminative hybrid systems on OOVCORP data set.
Evaluation on un-observed OOVs (a) and all OOVs (b).
</figureCaption>
<figure confidence="0.998717888888889">
Baseline (10k)
Baseline (10k) + context-features
This Paper (10k)
This Paper (10k) + context-features
%Masses
40
80
70
60
50
30
20
100 5 10 15 20
%FA
Baseline (10k)
Baseline (10k) + context-features
This Paper (10k)
This Paper (10k) + context-features
</figure>
<bodyText confidence="0.998622733333333">
Consistent with previously published results, in-
cluding context achieves large improvement in per-
formance. The proposed hybrid system (This Pa-
per 10k + context-features) still improves over the
baseline (Baseline 10k + context-features), however
the relative gain is reduced. In this case, we ob-
tain larger gains for un-observed OOVs which ben-
efit less from the context clues learned in training.
Lastly, we report OOV detection performance on
MIT Lectures. Both the sub-word lexicon and the
LVCSR models were trained on Broadcast News
data, helping us evaluate the robustness of learned
sub-words across domains. Note that the OOVs
in these domains are quite different: MIT Lec-
tures’ OOVs correspond to technical computer sci-
</bodyText>
<table confidence="0.9992136">
Hybrid System Hits FAs
Baseline (5k) 18.25 1.49
This Paper (5k) 26.78 1.78
Baseline (10k) 24.26 1.82
This Paper (10k) 28.96 1.92
</table>
<tableCaption confidence="0.996671">
Table 1: Coverage of OOV regions by baseline and pro-
posed sub-words in OOVCORP.
</tableCaption>
<bodyText confidence="0.999375263157895">
ence and math terms, while in Broadcast News they
are mainly named-entities.
Figure 6 and 7 show the OOV detection results in
the MIT Lectures data set. For un-observed OOVs,
the proposed system (This Paper 10k) reduces the
miss OOV rate by 7.6% with respect to the base-
line (Baseline 10k) at a 5% FA rate. Similar to
Broadcast News results, we found that the learned
sub-words provide larger coverage of OOV regions
in MIT Lectures domain. These results suggest that
the proposed sub-words are not simply modeling the
training OOVs (named-entities) better than the base-
line sub-words, but also describe better novel unex-
pected words. Furthermore, including context fea-
tures does not seem as helpful. We conjecture that
this is due to the higher WER11 and the less struc-
tured nature of the domain: i.e. ungrammatical sen-
tences, disfluencies, incomplete sentences, making
it more difficult to predict OOVs based on context.
</bodyText>
<footnote confidence="0.820604">
11WER = 32.7% since the LVCSR system was trained on
Broadcast News data as described in Section 5.
</footnote>
<page confidence="0.991808">
719
</page>
<figure confidence="0.996538407407407">
90
80
70
60
50
40
300 5 10 15 20
%FA
%Masses
Baseline (5k)
This Paper (5k)
Baseline (10k)
This Paper (10k)
%Masses
40
90
80
70
60
50
300 5 10 15 20
%FA
Baseline (5k)
This Paper (5k)
Baseline (10k)
This Paper (10k)
(a) (b)
</figure>
<figureCaption confidence="0.9976415">
Figure 6: DET curves for OOV detection using baseline hybrid systems for different lexicon size and proposed dis-
criminative hybrid system on MIT Lectures data set. Evaluation on un-observed OOVs (a) and all OOVs (b).
</figureCaption>
<figure confidence="0.998324666666667">
90
80
70
%Masses 60
50
40
300 5 10 15 20
%FA
(a) (b)
</figure>
<figureCaption confidence="0.973483">
Figure 7: Effect of adding context features to baseline and discriminative hybrid systems on MIT Lectures data set.
Evaluation on un-observed OOVs (a) and all OOVs (b).
</figureCaption>
<figure confidence="0.999360882352941">
Baseline (10k)
Baseline (10k) + context-features
This Paper (10k)
This Paper (10k) + context-features
%Masses
40
90
80
70
60
50
300 5 10 15 20
%FA
Baseline (10k)
Baseline (10k) + context-features
This Paper (10k)
This Paper (10k) + context-features
</figure>
<subsectionHeader confidence="0.969648">
6.1 Improved Phonetic Transcription
</subsectionHeader>
<bodyText confidence="0.999981176470588">
We consider the hybrid lexicon’s impact on Phone
Error Rate (PER) with respect to the reference tran-
scription. The reference phone sequence is obtained
by doing forced alignment of the audio stream to the
reference transcripts using acoustic models. This
provides an alignment of the pronunciation variant
of each word in the reference and the recognizer’s
one-best output. The aligned words are converted to
the phonetic representation using the dictionary.
Table 2 presents PERs for the word and differ-
ent hybrid systems. As previously reported (Ras-
trow et al., 2009b), the hybrid systems achieve bet-
ter PER, specially in OOV regions since they pre-
dict sub-word units for OOVs. Our method achieves
modest improvements in PER compared to the hy-
brid baseline. No statistically significant improve-
ments in PER were observed on MIT Lectures.
</bodyText>
<sectionHeader confidence="0.999224" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999667333333333">
Our probabilistic model learns sub-word units for
hybrid speech recognizers by segmenting a text cor-
pus while exploiting side information. Applying our
</bodyText>
<table confidence="0.998531833333333">
System OOV IV All
Word 1.62 6.42 8.04
Hybrid: Baseline (5k) 1.56 6.44 8.01
Hybrid: Baseline (10k) 1.51 6.41 7.92
Hybrid: This Paper (5k) 1.52 6.42 7.94
Hybrid: This Paper (10k) 1.45 6.39 7.85
</table>
<tableCaption confidence="0.999263">
Table 2: Phone Error Rate for OOVCORP.
</tableCaption>
<bodyText confidence="0.999970545454546">
method to the task of OOV detection, we obtain an
absolute error reduction of 6.3% and 7.6% at a 5%
false alarm rate on an English Broadcast News and
MIT Lectures task respectively, when compared to a
baseline system. Furthermore, we have confirmed
previous work that hybrid systems achieve better
phone accuracy, and our model makes modest im-
provements over a baseline with a similarly sized
sub-word lexicon. We plan to further explore our
new lexicon’s performance for other languages and
tasks, such as OOV spoken term detection.
</bodyText>
<sectionHeader confidence="0.998822" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99997275">
We gratefully acknowledge Bhuvaha Ramabhadran
for many insightful discussions and the anonymous
reviewers for their helpful comments. This work
was funded by a Google PhD Fellowship.
</bodyText>
<page confidence="0.991856">
720
</page>
<sectionHeader confidence="0.993853" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999834186046512">
Issam Bazzi and James Glass. 2001. Learning units
for domain-independent out-of-vocabulary word mod-
eling. In EuroSpeech.
Issam Bazzi. 2002. Modelling out-of-vocabulary words
for robust speech recognition. Ph.D. thesis, Mas-
sachusetts Institute of Technology.
M. Bisani and H. Ney. 2005. Open vocabulary speech
recognition with flat hybrid models. In INTER-
SPEECH.
L. Burget, P. Schwarz, P. Matejka, M. Hannemann,
A. Rastrow, C. White, S. Khudanpur, H. Hermansky,
and J. Cernocky. 2008. Combination of strongly and
weakly constrained recognizers for reliable detection
of OOVS. In ICASSP.
D. Can, E. Cooper, A. Sethy, M. Saraclar, and C. White.
2009. Effect of pronounciations on OOV queries in
spoken term detection. Proceedings of ICASSP.
Stanley F. Chen. 2003. Conditional and joint models
for grapheme-to-phoneme conversion. In Eurospeech,
pages 2033–2036.
G. Choueiter. 2009. Linguistically-motivated sub-
word modeling with applications to speech recogni-
tion. Ph.D. thesis, Massachusetts Institute of Technol-
ogy.
Jonathan Fiscus, John Garofolo, Mark Przybocki,
William Fisher, and David Pallett, 1998. 1997 En-
glish Broadcast News Speech (HUB4). Linguistic
Data Consortium, Philadelphia.
James Glass, Timothy Hazen, Lee Hetherington, and
Chao Wang. 2010. Analysis and processing of lec-
ture audio data: Preliminary investigations. In North
American Chapter of the Association for Computa-
tional Linguistics (NAACL).
Dietrich Klakow, Georg Rose, and Xavier Aubert. 1999.
OOV-detection in large vocabulary system using au-
tomatically defined word-fragments as fillers. In Eu-
rospeech.
Hui Lin, J. Bilmes, D. Vergyri, and K. Kirchhoff. 2007.
OOV detection by joint word/phone lattice alignment.
In ASRU, pages 478–483, Dec.
Jonathan Mamou, Bhuvana Ramabhadran, and Olivier
Siohan. 2007. Vocabulary independent spoken term
detection. In Proceedings of SIGIR.
L. Mangu, E. Brill, and A. Stolcke. 1999. Finding con-
sensus among words. In Eurospeech.
A. Martin, G. Doddington, T. Kamm, M. Ordowski, and
M. Przybocky. 1997. The det curve in assessment of
detection task performance. In Eurospeech.
Carolina Parada, Abhinav Sethy, and Bhuvana Ramab-
hadran. 2009. Query-by-example spoken term detec-
tion for oov terms. In ASRU.
Carolina Parada, Mark Dredze, Denis Filimonov, and
Fred Jelinek. 2010. Contextual information improves
oov detection in speech. In North American Chap-
ter of the Association for Computational Linguistics
(NAACL).
H. Poon, C. Cherry, and K. Toutanova. 2009. Unsu-
pervised morphological segmentation with log-linear
models. In ACL.
Ariya Rastrow, Abhinav Sethy, and Bhuvana Ramab-
hadran. 2009a. A new method for OOV detection
using hybrid word/fragment system. Proceedings of
ICASSP.
Ariya Rastrow, Abhinav Sethy, Bhuvana Ramabhadran,
and Fred Jelinek. 2009b. Towards using hybrid,
word, and fragment units for vocabulary independent
LVCSR systems. INTERSPEECH.
T. Schaaf. 2001. Detection of OOV words using gen-
eralized word models and a semantic class language
model. In Eurospeech.
H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon,
and G. Zweig. 2005. The ibm 2004 conversational
telephony system for rich transcription. In ICASSP.
H. Sun, G. Zhang, f. Zheng, and M. Xu. 2001. Using
word confidence measure for OOV words detection in
a spontaneous spoken dialog system. In Eurospeech.
Stanley Wang. 2009. Using graphone models in au-
tomatic speech recognition. Master’s thesis, Mas-
sachusetts Institute of Technology.
F. Wessel, R. Schluter, K. Macherey, and H. Ney. 2001.
Confidence measures for large vocabulary continuous
speech recognition. IEEE Transactions on Speech and
Audio Processing, 9(3).
Christopher White, Jasha Droppo, Alex Acero, and Ju-
lian Odell. 2007. Maximum entropy confidence esti-
mation for speech recognition. In ICASSP.
</reference>
<page confidence="0.997784">
721
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.771656">
<title confidence="0.999986">Learning Sub-Word Units for Open Vocabulary Speech Recognition</title>
<author confidence="0.983356">Mark Abhinav</author>
<author confidence="0.983356">Ariya</author>
<affiliation confidence="0.91896">Language Technology Center of Excellence, Johns Hopkins</affiliation>
<address confidence="0.989628">3400 N Charles Street, Baltimore, MD,</address>
<email confidence="0.986598">carolinap@jhu.edu,mdredze@cs.jhu.edu,</email>
<author confidence="0.906255">T J Watson Research Center</author>
<author confidence="0.906255">Yorktown Heights</author>
<author confidence="0.906255">NY</author>
<email confidence="0.999575">asethy@us.ibm.com</email>
<abstract confidence="0.997591681818182">Large vocabulary speech recognition systems fail to recognize words beyond their vocabulary, many of which are information rich terms, like named entities or foreign words. Hybrid word/sub-word systems solve this problem by adding sub-word units to large vocabulary word based systems; new words can then be represented by combinations of subword units. Previous work heuristically created the sub-word lexicon from phonetic representations of text using simple statistics to select common phone sequences. We proa probabilistic model to subword lexicon optimized for a given task. We consider the task of out of vocabulary (OOV) word detection, which relies on output from a hybrid model. A hybrid model with our learned sub-word lexicon reduces error by 6.3% and 7.6% (absolute) at a 5% false alarm rate on an English Broadcast News and MIT Lectures task respectively.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Issam Bazzi</author>
<author>James Glass</author>
</authors>
<title>Learning units for domain-independent out-of-vocabulary word modeling.</title>
<date>2001</date>
<booktitle>In EuroSpeech.</booktitle>
<contexts>
<context position="2956" citStr="Bazzi and Glass, 2001" startWordPosition="455" endWordPosition="458"> ae n. The latter is more useful for automatically recovering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme sequences, although in principle our work can be use for other unit types. Previous methods for creating the sub-word lexi712 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 712–721,</context>
</contexts>
<marker>Bazzi, Glass, 2001</marker>
<rawString>Issam Bazzi and James Glass. 2001. Learning units for domain-independent out-of-vocabulary word modeling. In EuroSpeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Issam Bazzi</author>
</authors>
<title>Modelling out-of-vocabulary words for robust speech recognition.</title>
<date>2002</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="3161" citStr="Bazzi, 2002" startWordPosition="486" endWordPosition="487">ybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme sequences, although in principle our work can be use for other unit types. Previous methods for creating the sub-word lexi712 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 712–721, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics con have relied on simple statistics computed from word lexicon.1 Learning input includes a list of the phonetic repres</context>
<context position="16613" citStr="Bazzi, 2002" startWordPosition="2746" endWordPosition="2747">(P(Y, Si|W),Q(Y, Si|W)) 9k = sampleS(P(Si|Y ∗, W),Q(Si|Y ∗, W)) end for /* M-Step */ ES,Y|W [fi] = NumSamples Ek fσ,l [S0k, Y0k] ES|Y *,W[fσ,l] = NumSamples Ek fσ,l[�Sk,Y ∗] � λi = Ai−1 + γ∇L¯λ(Y ∗|W) end for S = bestSegmentation(T, λK, S0) Output: Lexicon Lo from S 4 OOV Detection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 .</context>
</contexts>
<marker>Bazzi, 2002</marker>
<rawString>Issam Bazzi. 2002. Modelling out-of-vocabulary words for robust speech recognition. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Bisani</author>
<author>H Ney</author>
</authors>
<title>Open vocabulary speech recognition with flat hybrid models.</title>
<date>2005</date>
<booktitle>In INTERSPEECH.</booktitle>
<contexts>
<context position="3011" citStr="Bisani and Ney, 2005" startWordPosition="464" endWordPosition="467">ering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme sequences, although in principle our work can be use for other unit types. Previous methods for creating the sub-word lexi712 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 712–721, Portland, Oregon, June 19-24, 2011. c�2011 Association</context>
<context position="16649" citStr="Bisani and Ney, 2005" startWordPosition="2750" endWordPosition="2753">= sampleS(P(Si|Y ∗, W),Q(Si|Y ∗, W)) end for /* M-Step */ ES,Y|W [fi] = NumSamples Ek fσ,l [S0k, Y0k] ES|Y *,W[fσ,l] = NumSamples Ek fσ,l[�Sk,Y ∗] � λi = Ai−1 + γ∇L¯λ(Y ∗|W) end for S = bestSegmentation(T, λK, S0) Output: Lexicon Lo from S 4 OOV Detection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 .</context>
</contexts>
<marker>Bisani, Ney, 2005</marker>
<rawString>M. Bisani and H. Ney. 2005. Open vocabulary speech recognition with flat hybrid models. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Burget</author>
<author>P Schwarz</author>
<author>P Matejka</author>
<author>M Hannemann</author>
<author>A Rastrow</author>
<author>C White</author>
<author>S Khudanpur</author>
<author>H Hermansky</author>
<author>J Cernocky</author>
</authors>
<title>Combination of strongly and weakly constrained recognizers for reliable detection of OOVS.</title>
<date>2008</date>
<booktitle>In ICASSP.</booktitle>
<contexts>
<context position="16897" citStr="Burget et al., 2008" startWordPosition="2790" endWordPosition="2793">ection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� ES&apos; |σ| / IES |σ| with prob α : ym,k = y0m, sm,k = s0m with prob (1 − α) : ym,k = ym, sm,k = sm end for return (S0k, Y0k) = [(s1,k, y1,k) ... (sM,k, yM,k)] confidence-based models, achieving state-of-the art performance for thi</context>
</contexts>
<marker>Burget, Schwarz, Matejka, Hannemann, Rastrow, White, Khudanpur, Hermansky, Cernocky, 2008</marker>
<rawString>L. Burget, P. Schwarz, P. Matejka, M. Hannemann, A. Rastrow, C. White, S. Khudanpur, H. Hermansky, and J. Cernocky. 2008. Combination of strongly and weakly constrained recognizers for reliable detection of OOVS. In ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Can</author>
<author>E Cooper</author>
<author>A Sethy</author>
<author>M Saraclar</author>
<author>C White</author>
</authors>
<title>Effect of pronounciations on OOV queries in spoken term detection.</title>
<date>2009</date>
<booktitle>Proceedings of ICASSP.</booktitle>
<marker>Can, Cooper, Sethy, Saraclar, White, 2009</marker>
<rawString>D. Can, E. Cooper, A. Sethy, M. Saraclar, and C. White. 2009. Effect of pronounciations on OOV queries in spoken term detection. Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
</authors>
<title>Conditional and joint models for grapheme-to-phoneme conversion.</title>
<date>2003</date>
<booktitle>In Eurospeech,</booktitle>
<pages>2033--2036</pages>
<contexts>
<context position="4238" citStr="Chen (2003)" startWordPosition="659" endWordPosition="660">al Linguistics con have relied on simple statistics computed from word lexicon.1 Learning input includes a list of the phonetic representation of text (Rastrow et al., words to segment taken from raw text, a mapping 2009a). These units typically represent the most fre- between words and classes (side information indiquent phoneme sequences in English words. How- cating whether token is IV or OOV), a pronunciaever, it isn’t clear why these units would produce the tion dictionary D, and a letter to sound model (L2S), best hybrid output. Instead, we introduce a prob- such as the one described in Chen (2003). The corabilistic model for learning the optimal units for a pus W is the list of types (unique words) in the raw given task. Our model learns a segmentation of a text input. This forces each word to have a unique text corpus given some side information: a mapping segmentation, shared by all common tokens. Words between the vocabulary and a label set; learned units are converted into phonetic representations accordare predictive of class labels. ing to their most likely dictionary pronunciation; In this paper, we learn sub-word units optimized non-dictionary words use the L2S model.2 for OOV </context>
<context position="18628" citStr="Chen, 2003" startWordPosition="3110" endWordPosition="3111">abeled corpus, where the labeling sequence Y indicates the presence of out-of-vocabulary words (OOVs). For comparison we evaluate a baseline method (Rastrow et al., 2009b) for selecting units. Given a sub-word lexicon, the word and subwords are combined to form a hybrid language model (LM) to be used by the LVCSR system. This hybrid LM captures dependencies between word and sub-words. In the LM training data, all OOVs are represented by the smallest number of sub-words which corresponds to their pronunciation. Pronunciations for all OOVs are obtained using grapheme 0 λ0 = 716 to phone models (Chen, 2003). with a 83K word vocabulary. The LVCSR system’s Since sub-words represent OOVs while building WER on the standard RT04 BN test set was 19.4%. the hybrid LM, the existence of sub-words in ASR Excluded utterances amount to 100hrs. These were output indicate an OOV region. A simple solution to divided into 5 hours of training for the OOV detecthe OOV detection problem would then be reduced tor and 95 hours of test. Note that the OOV detector to a search for the sub-words in the output of the training set is different from the LVCSR training set. ASR system. The search can be on the one-best We a</context>
</contexts>
<marker>Chen, 2003</marker>
<rawString>Stanley F. Chen. 2003. Conditional and joint models for grapheme-to-phoneme conversion. In Eurospeech, pages 2033–2036.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Choueiter</author>
</authors>
<title>Linguistically-motivated subword modeling with applications to speech recognition.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="3085" citStr="Choueiter, 2009" startWordPosition="474" endWordPosition="475">oving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme sequences, although in principle our work can be use for other unit types. Previous methods for creating the sub-word lexi712 Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 712–721, Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics con have relied on simple statistics comput</context>
</contexts>
<marker>Choueiter, 2009</marker>
<rawString>G. Choueiter. 2009. Linguistically-motivated subword modeling with applications to speech recognition. Ph.D. thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Fiscus</author>
<author>John Garofolo</author>
<author>Mark Przybocki</author>
<author>William Fisher</author>
<author>David Pallett</author>
</authors>
<date>1998</date>
<booktitle>English Broadcast News Speech (HUB4). Linguistic Data Consortium,</booktitle>
<location>Philadelphia.</location>
<contexts>
<context position="22311" citStr="Fiscus et al., 1998" startWordPosition="3736" endWordPosition="3739"> the 83K OOVs include: NATALIE, PUTIN, QAEDA, vocabulary and 5,000 OOVs6. For development we HOLLOWAY, COROLLARIES, HYPERLINKED, selected an additional 1,000 IV and 1,000 OOVs. etc. This resulted in roughly 24K (2%) OOV tokens. This was used to tune our model hyper parameters For LVCSR, we used the IBM Speech Recogni- (set to a = −1, Q = −20). There is no overlap tion Toolkit (Soltau et al., 2005)5 to obtain a tran- of OOVs in training, development and test sets. All script of the audio. Acoustic models were trained feature weights were initialized to zero and had a on 300 hours of HUB4 data (Fiscus et al., 1998) Gaussian prior with variance a = 100. Each of the and utterances containing OOV words as marked in words in training and development was converted to OOVCORP were excluded. The language model was their most-likely pronunciation using the dictionary trained on 400M words from various text sources 6This was used to obtain the 5K hybrid system. To learn subwords for the 10K hybrid system we used 10K in-vocabulary words and 10K OOVs. All words were randomly selected from the LM training text. 5The IBM system used speaker adaptive training based on maximum likelihood with no discriminative trainin</context>
</contexts>
<marker>Fiscus, Garofolo, Przybocki, Fisher, Pallett, 1998</marker>
<rawString>Jonathan Fiscus, John Garofolo, Mark Przybocki, William Fisher, and David Pallett, 1998. 1997 English Broadcast News Speech (HUB4). Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Glass</author>
<author>Timothy Hazen</author>
<author>Lee Hetherington</author>
<author>Chao Wang</author>
</authors>
<title>Analysis and processing of lecture audio data: Preliminary investigations.</title>
<date>2010</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="20582" citStr="Glass et al., 2010" startWordPosition="3444" endWordPosition="3447">gion (Eq. 8), both of which are used as used is close to most modern LVCSR system vofeatures in the model of Parada et al. (2010). cabularies for English Broadcast News; the result�Sub-word Posterior= p(u|tj) (7) ing OOVs are more challenging but more realistic QEtj (i.e. mostly named entities and technical terms). The �Word-Entropy = − p(w|tj) log p(w|tj) (8) 1290 words are OOVs to both the word and hybrid wEtj systems. tj is the current bin in the confusion network and In addition we report OOV detection results on a a is a sub-word in the hybrid dictionary. Improving MIT lectures data set (Glass et al., 2010) consisting the sub-word unit lexicon, improves the quality of of 3 Hrs from two speakers with a 1.5% OOV rate. the confusion networks for OOV detection. These were divided into 1 Hr for training the OOV 5 Experimental Setup detector and 2 Hrs for testing. Note that the LVCSR We used the data set constructed by Can et al. system is trained on Broadcast News data. This out(2009) (OOVCORP) for the evaluation of Spoken of-domain test-set help us evaluate the cross-domain Term Detection of OOVs since it focuses on the performance of the proposed and baseline hybrid OOV problem. The corpus contains</context>
</contexts>
<marker>Glass, Hazen, Hetherington, Wang, 2010</marker>
<rawString>James Glass, Timothy Hazen, Lee Hetherington, and Chao Wang. 2010. Analysis and processing of lecture audio data: Preliminary investigations. In North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietrich Klakow</author>
<author>Georg Rose</author>
<author>Xavier Aubert</author>
</authors>
<title>OOV-detection in large vocabulary system using automatically defined word-fragments as fillers.</title>
<date>1999</date>
<booktitle>In Eurospeech.</booktitle>
<contexts>
<context position="16670" citStr="Klakow et al., 1999" startWordPosition="2754" endWordPosition="2757">,Q(Si|Y ∗, W)) end for /* M-Step */ ES,Y|W [fi] = NumSamples Ek fσ,l [S0k, Y0k] ES|Y *,W[fσ,l] = NumSamples Ek fσ,l[�Sk,Y ∗] � λi = Ai−1 + γ∇L¯λ(Y ∗|W) end for S = bestSegmentation(T, λK, S0) Output: Lexicon Lo from S 4 OOV Detection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� </context>
</contexts>
<marker>Klakow, Rose, Aubert, 1999</marker>
<rawString>Dietrich Klakow, Georg Rose, and Xavier Aubert. 1999. OOV-detection in large vocabulary system using automatically defined word-fragments as fillers. In Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Lin</author>
<author>J Bilmes</author>
<author>D Vergyri</author>
<author>K Kirchhoff</author>
</authors>
<title>OOV detection by joint word/phone lattice alignment.</title>
<date>2007</date>
<booktitle>In ASRU,</booktitle>
<pages>478--483</pages>
<contexts>
<context position="16876" citStr="Lin et al., 2007" startWordPosition="2786" endWordPosition="2789">o from S 4 OOV Detection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� ES&apos; |σ| / IES |σ| with prob α : ym,k = y0m, sm,k = s0m with prob (1 − α) : ym,k = ym, sm,k = sm end for return (S0k, Y0k) = [(s1,k, y1,k) ... (sM,k, yM,k)] confidence-based models, achieving state-of-the ar</context>
</contexts>
<marker>Lin, Bilmes, Vergyri, Kirchhoff, 2007</marker>
<rawString>Hui Lin, J. Bilmes, D. Vergyri, and K. Kirchhoff. 2007. OOV detection by joint word/phone lattice alignment. In ASRU, pages 478–483, Dec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Mamou</author>
<author>Bhuvana Ramabhadran</author>
<author>Olivier Siohan</author>
</authors>
<title>Vocabulary independent spoken term detection.</title>
<date>2007</date>
<booktitle>In Proceedings of SIGIR.</booktitle>
<contexts>
<context position="2622" citStr="Mamou et al., 2007" startWordPosition="403" endWordPosition="406">ider the word “Slobodan”, the given name of the former president of Serbia. As an uncommon English word, it is unlikely to be in the vocabulary of an English recognizer. While a LVCSR system would output the closest known words (e.x. “slow it dawn”), a hybrid system could output a sequence of multi-phoneme units: s l ow, b ax, d ae n. The latter is more useful for automatically recovering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we cons</context>
</contexts>
<marker>Mamou, Ramabhadran, Siohan, 2007</marker>
<rawString>Jonathan Mamou, Bhuvana Ramabhadran, and Olivier Siohan. 2007. Vocabulary independent spoken term detection. In Proceedings of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mangu</author>
<author>E Brill</author>
<author>A Stolcke</author>
</authors>
<title>Finding consensus among words.</title>
<date>1999</date>
<booktitle>In Eurospeech.</booktitle>
<contexts>
<context position="19708" citStr="Mangu et al., 1999" startWordPosition="3290" endWordPosition="3293">he sub-words in the output of the training set is different from the LVCSR training set. ASR system. The search can be on the one-best We also use a hybrid LVCSR system, combintranscripts, lattices or confusion networks. While ing word and sub-word units obtained from eilattices contain more information, they are harder ther our approach or a state-of-the-art baseline apto process; confusion networks offer a trade-off be- proach (Rastrow et al., 2009a) (§5.2). Our hybrid tween richness (posterior probabilities are already system’s lexicon has 83K words and 5K or 10K computed) and compactness (Mangu et al., 1999). sub-words. Note that the word vocabulary is comTwo effective indications of OOVs are the exis- mon to both systems and only the sub-words are setence of sub-words (Eq. 7) and high entropy in a lected using either approach. The word vocabulary network region (Eq. 8), both of which are used as used is close to most modern LVCSR system vofeatures in the model of Parada et al. (2010). cabularies for English Broadcast News; the result�Sub-word Posterior= p(u|tj) (7) ing OOVs are more challenging but more realistic QEtj (i.e. mostly named entities and technical terms). The �Word-Entropy = − p(w|tj</context>
</contexts>
<marker>Mangu, Brill, Stolcke, 1999</marker>
<rawString>L. Mangu, E. Brill, and A. Stolcke. 1999. Finding consensus among words. In Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Martin</author>
<author>G Doddington</author>
<author>T Kamm</author>
<author>M Ordowski</author>
<author>M Przybocky</author>
</authors>
<title>The det curve in assessment of detection task performance.</title>
<date>1997</date>
<booktitle>In Eurospeech.</booktitle>
<contexts>
<context position="24467" citStr="Martin et al., 1997" startWordPosition="4099" endWordPosition="4102">nd model for OOVs), and a N-gram phone LM is estimated on this data and pruned using a relative entropy based method. The hybrid lexicon includes resulting sub-words – ranging from unigrams to 5- gram phones, and the 83K word lexicon. 5.3 Evaluation We obtain confusion networks from both the word and hybrid LVCSR systems. We align the LVCSR transcripts with the reference transcripts and tag each confusion region as either IV or OOV. The OOV detector classifies each region in the confusion network as IV/OOV. We report OOV detection accuracy using standard detection error tradeoff (DET) curves (Martin et al., 1997). DET curves measure tradeoffs between false alarms (x-axis) and misses (y-axis), and are useful for determining the optimal operating point for an application; lower curves are better. Following Parada et al. (2010) we separately evaluate unobserved OOVs.8 7In this work we ignore pronunciation variability and simply consider the most likely pronunciation for each word. It is straightforward to extend to multiple pronunciations by first sampling a pronunciation for each word and then sampling a segmentation for that pronunciation. 8Once an OOV word has been observed in the OOV detector trainin</context>
</contexts>
<marker>Martin, Doddington, Kamm, Ordowski, Przybocky, 1997</marker>
<rawString>A. Martin, G. Doddington, T. Kamm, M. Ordowski, and M. Przybocky. 1997. The det curve in assessment of detection task performance. In Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolina Parada</author>
<author>Abhinav Sethy</author>
<author>Bhuvana Ramabhadran</author>
</authors>
<title>Query-by-example spoken term detection for oov terms.</title>
<date>2009</date>
<booktitle>In ASRU.</booktitle>
<contexts>
<context position="2644" citStr="Parada et al., 2009" startWordPosition="407" endWordPosition="410">dan”, the given name of the former president of Serbia. As an uncommon English word, it is unlikely to be in the vocabulary of an English recognizer. While a LVCSR system would output the closest known words (e.x. “slow it dawn”), a hybrid system could output a sequence of multi-phoneme units: s l ow, b ax, d ae n. The latter is more useful for automatically recovering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally </context>
</contexts>
<marker>Parada, Sethy, Ramabhadran, 2009</marker>
<rawString>Carolina Parada, Abhinav Sethy, and Bhuvana Ramabhadran. 2009. Query-by-example spoken term detection for oov terms. In ASRU.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolina Parada</author>
<author>Mark Dredze</author>
<author>Denis Filimonov</author>
<author>Fred Jelinek</author>
</authors>
<title>Contextual information improves oov detection in speech.</title>
<date>2010</date>
<booktitle>In North American Chapter of the Association for Computational Linguistics (NAACL).</booktitle>
<contexts>
<context position="2813" citStr="Parada et al., 2010" startWordPosition="433" endWordPosition="436">m would output the closest known words (e.x. “slow it dawn”), a hybrid system could output a sequence of multi-phoneme units: s l ow, b ax, d ae n. The latter is more useful for automatically recovering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme sequences, although in principle our work can be use for other unit types. Previous me</context>
<context position="17603" citStr="Parada et al. (2010)" startWordPosition="2928" endWordPosition="2931">ion approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� ES&apos; |σ| / IES |σ| with prob α : ym,k = y0m, sm,k = s0m with prob (1 − α) : ym,k = ym, sm,k = sm end for return (S0k, Y0k) = [(s1,k, y1,k) ... (sM,k, yM,k)] confidence-based models, achieving state-of-the art performance for this task. 4.1 OOV Detection Approach We use the state-of-the-art OOV detection model of Parada et al. (2010), a second order CRF with features based on the output of a hybrid recognizer. This detector processes hybrid recognizer output, so we can evaluate different sub-word unit lexicons for the hybrid recognizer and measure the change in OOV detection accuracy. Our model (§2.1) can be applied to this task by using a dictionary D to label words as IV (yi = 0 if wi ∈ D) and OOV (yi = 1 if wi ∈/ D). This results in a labeled corpus, where the labeling sequence Y indicates the presence of out-of-vocabulary words (OOVs). For comparison we evaluate a baseline method (Rastrow et al., 2009b) for selecting </context>
<context position="20092" citStr="Parada et al. (2010)" startWordPosition="3361" endWordPosition="3364">; confusion networks offer a trade-off be- proach (Rastrow et al., 2009a) (§5.2). Our hybrid tween richness (posterior probabilities are already system’s lexicon has 83K words and 5K or 10K computed) and compactness (Mangu et al., 1999). sub-words. Note that the word vocabulary is comTwo effective indications of OOVs are the exis- mon to both systems and only the sub-words are setence of sub-words (Eq. 7) and high entropy in a lected using either approach. The word vocabulary network region (Eq. 8), both of which are used as used is close to most modern LVCSR system vofeatures in the model of Parada et al. (2010). cabularies for English Broadcast News; the result�Sub-word Posterior= p(u|tj) (7) ing OOVs are more challenging but more realistic QEtj (i.e. mostly named entities and technical terms). The �Word-Entropy = − p(w|tj) log p(w|tj) (8) 1290 words are OOVs to both the word and hybrid wEtj systems. tj is the current bin in the confusion network and In addition we report OOV detection results on a a is a sub-word in the hybrid dictionary. Improving MIT lectures data set (Glass et al., 2010) consisting the sub-word unit lexicon, improves the quality of of 3 Hrs from two speakers with a 1.5% OOV rate</context>
<context position="24683" citStr="Parada et al. (2010)" startWordPosition="4131" endWordPosition="4134"> 83K word lexicon. 5.3 Evaluation We obtain confusion networks from both the word and hybrid LVCSR systems. We align the LVCSR transcripts with the reference transcripts and tag each confusion region as either IV or OOV. The OOV detector classifies each region in the confusion network as IV/OOV. We report OOV detection accuracy using standard detection error tradeoff (DET) curves (Martin et al., 1997). DET curves measure tradeoffs between false alarms (x-axis) and misses (y-axis), and are useful for determining the optimal operating point for an application; lower curves are better. Following Parada et al. (2010) we separately evaluate unobserved OOVs.8 7In this work we ignore pronunciation variability and simply consider the most likely pronunciation for each word. It is straightforward to extend to multiple pronunciations by first sampling a pronunciation for each word and then sampling a segmentation for that pronunciation. 8Once an OOV word has been observed in the OOV detector training data, even if it was not in the LVCSR training data, it is no longer truly OOV. 6 Results We compare the performance of a hybrid system with baseline units9 (§5.2) and one with units learned by our model on OOV det</context>
<context position="27006" citStr="Parada et al. (2010)" startWordPosition="4519" endWordPosition="4522">ents can be attributed to increased coverage of OOV regions by the learned sub-words compared to the baseline. Table 1 shows the percent of Hits: sub-word units predicted in OOV regions, and False Alarms: sub-word units predicted for in-vocabulary words. We can see that the proposed system increases the Hits by over 8% absolute, while increasing the False Alarms by 0.3%. Interestingly, the average sub-word length for the proposed units exceeded that of the baseline units by 0.3 phones (Baseline 5K average length was 2.92, while that of This Paper 5K was 3.2). 9Our baseline results differ from Parada et al. (2010). When implementing the lexicon baseline, we discovered that their hybrid units were mistakenly derived from text containing test OOVs. Once excluded, the relative improvements of previous work remain, but the absolute error rates are higher. 10All real-valued features were normalized and quantized using the uniform-occupancy partitioning described in White et al. (2007). We used 50 partitions with a minimum of 100 training values per partition. 718 70 65 60 55 50 45 40 35 300 5 10 15 20 %FA %Masses Baseline (5k) This Paper (5k) Baseline (10k) This Paper (10k) %Masses 45 70 65 60 55 50 300 5 1</context>
</contexts>
<marker>Parada, Dredze, Filimonov, Jelinek, 2010</marker>
<rawString>Carolina Parada, Mark Dredze, Denis Filimonov, and Fred Jelinek. 2010. Contextual information improves oov detection in speech. In North American Chapter of the Association for Computational Linguistics (NAACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Poon</author>
<author>C Cherry</author>
<author>K Toutanova</author>
</authors>
<title>Unsupervised morphological segmentation with log-linear models.</title>
<date>2009</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="6484" citStr="Poon et al. (2009)" startWordPosition="1027" endWordPosition="1030">ng assigns labels Y to the corpus. We maximize the probability of the observed labeling sequence Y given the text W: P (Y |W). We assume there is a latent segmentation S of this corpus which impacts Y . The complete data likelihood becomes: P(Y |W) = ES P(Y, S|W) during training. Since we are maximizing the observed Y , segmentation S must discriminate between different possible labels. We learn variable-length multi-phone units by segmenting the phonetic representation of each word in the corpus. Resulting segments form the sub713 2.1 Model Inspired by the morphological segmentation model of Poon et al. (2009), we assume P(Y, S|W) is a log-linear model parameterized by A: 1 PA(Y,S|W) = Z(W)uA(Y,S,W) (1) where uA(Y,S,W) defines the score of the proposed segmentation S for words W and labels Y according to model parameters A. Sub-word units σ compose S, where each σ is a phone sequence, including the full pronunciation for vocabulary words; the collection of σs form the lexicon. Each unit σ is present in a segmentation with some context c = (φl, φr) of the form φlσφr. Features based on the context and the unit itself parameterize uA. In addition to scoring a segmentation based on features, we include</context>
</contexts>
<marker>Poon, Cherry, Toutanova, 2009</marker>
<rawString>H. Poon, C. Cherry, and K. Toutanova. 2009. Unsupervised morphological segmentation with log-linear models. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariya Rastrow</author>
<author>Abhinav Sethy</author>
<author>Bhuvana Ramabhadran</author>
</authors>
<title>A new method for OOV detection using hybrid word/fragment system.</title>
<date>2009</date>
<booktitle>Proceedings of ICASSP.</booktitle>
<contexts>
<context position="2728" citStr="Rastrow et al., 2009" startWordPosition="421" endWordPosition="424"> it is unlikely to be in the vocabulary of an English recognizer. While a LVCSR system would output the closest known words (e.x. “slow it dawn”), a hybrid system could output a sequence of multi-phoneme units: s l ow, b ax, d ae n. The latter is more useful for automatically recovering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme s</context>
<context position="18186" citStr="Rastrow et al., 2009" startWordPosition="3033" endWordPosition="3036">tection model of Parada et al. (2010), a second order CRF with features based on the output of a hybrid recognizer. This detector processes hybrid recognizer output, so we can evaluate different sub-word unit lexicons for the hybrid recognizer and measure the change in OOV detection accuracy. Our model (§2.1) can be applied to this task by using a dictionary D to label words as IV (yi = 0 if wi ∈ D) and OOV (yi = 1 if wi ∈/ D). This results in a labeled corpus, where the labeling sequence Y indicates the presence of out-of-vocabulary words (OOVs). For comparison we evaluate a baseline method (Rastrow et al., 2009b) for selecting units. Given a sub-word lexicon, the word and subwords are combined to form a hybrid language model (LM) to be used by the LVCSR system. This hybrid LM captures dependencies between word and sub-words. In the LM training data, all OOVs are represented by the smallest number of sub-words which corresponds to their pronunciation. Pronunciations for all OOVs are obtained using grapheme 0 λ0 = 716 to phone models (Chen, 2003). with a 83K word vocabulary. The LVCSR system’s Since sub-words represent OOVs while building WER on the standard RT04 BN test set was 19.4%. the hybrid LM, </context>
<context position="19543" citStr="Rastrow et al., 2009" startWordPosition="3265" endWordPosition="3268">vided into 5 hours of training for the OOV detecthe OOV detection problem would then be reduced tor and 95 hours of test. Note that the OOV detector to a search for the sub-words in the output of the training set is different from the LVCSR training set. ASR system. The search can be on the one-best We also use a hybrid LVCSR system, combintranscripts, lattices or confusion networks. While ing word and sub-word units obtained from eilattices contain more information, they are harder ther our approach or a state-of-the-art baseline apto process; confusion networks offer a trade-off be- proach (Rastrow et al., 2009a) (§5.2). Our hybrid tween richness (posterior probabilities are already system’s lexicon has 83K words and 5K or 10K computed) and compactness (Mangu et al., 1999). sub-words. Note that the word vocabulary is comTwo effective indications of OOVs are the exis- mon to both systems and only the sub-words are setence of sub-words (Eq. 7) and high entropy in a lected using either approach. The word vocabulary network region (Eq. 8), both of which are used as used is close to most modern LVCSR system vofeatures in the model of Parada et al. (2010). cabularies for English Broadcast News; the result</context>
<context position="23678" citStr="Rastrow et al. (2009" startWordPosition="3969" endWordPosition="3972"> to 0.1K), -y = 0.4, and T = 0.6. We used K = 40 iterations for learning and 200 samples to compute the expectations in Eq. 5. The sampler was initialized by sampling for 500 iterations with deterministic annealing for a temperature varying from 10 to 0 at 0.1 intervals. Final segmentations were obtained using 10, 000 samples and the same temperature schedule. We limit segmentations to those including units of at most 5 phones to speed sampling with no significant degradation in performance. We observed improved performance by dis-allowing whole word units. 5.2 Baseline Unit Selection We used Rastrow et al. (2009a) as our baseline unit selection method, a data driven approach where the language model training text is converted into phones using the dictionary (or a letter-to-sound model for OOVs), and a N-gram phone LM is estimated on this data and pruned using a relative entropy based method. The hybrid lexicon includes resulting sub-words – ranging from unigrams to 5- gram phones, and the 83K word lexicon. 5.3 Evaluation We obtain confusion networks from both the word and hybrid LVCSR systems. We align the LVCSR transcripts with the reference transcripts and tag each confusion region as either IV or</context>
<context position="31856" citStr="Rastrow et al., 2009" startWordPosition="5338" endWordPosition="5342">ontext-features 6.1 Improved Phonetic Transcription We consider the hybrid lexicon’s impact on Phone Error Rate (PER) with respect to the reference transcription. The reference phone sequence is obtained by doing forced alignment of the audio stream to the reference transcripts using acoustic models. This provides an alignment of the pronunciation variant of each word in the reference and the recognizer’s one-best output. The aligned words are converted to the phonetic representation using the dictionary. Table 2 presents PERs for the word and different hybrid systems. As previously reported (Rastrow et al., 2009b), the hybrid systems achieve better PER, specially in OOV regions since they predict sub-word units for OOVs. Our method achieves modest improvements in PER compared to the hybrid baseline. No statistically significant improvements in PER were observed on MIT Lectures. 7 Conclusions Our probabilistic model learns sub-word units for hybrid speech recognizers by segmenting a text corpus while exploiting side information. Applying our System OOV IV All Word 1.62 6.42 8.04 Hybrid: Baseline (5k) 1.56 6.44 8.01 Hybrid: Baseline (10k) 1.51 6.41 7.92 Hybrid: This Paper (5k) 1.52 6.42 7.94 Hybrid: Th</context>
</contexts>
<marker>Rastrow, Sethy, Ramabhadran, 2009</marker>
<rawString>Ariya Rastrow, Abhinav Sethy, and Bhuvana Ramabhadran. 2009a. A new method for OOV detection using hybrid word/fragment system. Proceedings of ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ariya Rastrow</author>
<author>Abhinav Sethy</author>
<author>Bhuvana Ramabhadran</author>
<author>Fred Jelinek</author>
</authors>
<title>Towards using hybrid, word, and fragment units for vocabulary independent LVCSR systems.</title>
<date>2009</date>
<publisher>INTERSPEECH.</publisher>
<contexts>
<context position="2728" citStr="Rastrow et al., 2009" startWordPosition="421" endWordPosition="424"> it is unlikely to be in the vocabulary of an English recognizer. While a LVCSR system would output the closest known words (e.x. “slow it dawn”), a hybrid system could output a sequence of multi-phoneme units: s l ow, b ax, d ae n. The latter is more useful for automatically recovering the word’s orthographic form, identifying that an OOV was spoken, or improving performance of a spoken term detection system with OOV queries. In fact, hybrid systems have improved OOV spoken term detection (Mamou et al., 2007; Parada et al., 2009), achieved better phone error rates, especially in OOV regions (Rastrow et al., 2009b), and obtained state-of-the-art performance for OOV detection (Parada et al., 2010). Hybrid recognizers vary in a number of ways: sub-word unit type: variable-length phoneme units (Rastrow et al., 2009a; Bazzi and Glass, 2001) or joint letter sound sub-words (Bisani and Ney, 2005); unit creation: data-driven or linguistically motivated (Choueiter, 2009); and how they are incorporated in LVCSR systems: hierarchical (Bazzi, 2002) or flat models (Bisani and Ney, 2005). In this work, we consider how to optimally create sub-word units for a hybrid system. These units are variable-length phoneme s</context>
<context position="18186" citStr="Rastrow et al., 2009" startWordPosition="3033" endWordPosition="3036">tection model of Parada et al. (2010), a second order CRF with features based on the output of a hybrid recognizer. This detector processes hybrid recognizer output, so we can evaluate different sub-word unit lexicons for the hybrid recognizer and measure the change in OOV detection accuracy. Our model (§2.1) can be applied to this task by using a dictionary D to label words as IV (yi = 0 if wi ∈ D) and OOV (yi = 1 if wi ∈/ D). This results in a labeled corpus, where the labeling sequence Y indicates the presence of out-of-vocabulary words (OOVs). For comparison we evaluate a baseline method (Rastrow et al., 2009b) for selecting units. Given a sub-word lexicon, the word and subwords are combined to form a hybrid language model (LM) to be used by the LVCSR system. This hybrid LM captures dependencies between word and sub-words. In the LM training data, all OOVs are represented by the smallest number of sub-words which corresponds to their pronunciation. Pronunciations for all OOVs are obtained using grapheme 0 λ0 = 716 to phone models (Chen, 2003). with a 83K word vocabulary. The LVCSR system’s Since sub-words represent OOVs while building WER on the standard RT04 BN test set was 19.4%. the hybrid LM, </context>
<context position="19543" citStr="Rastrow et al., 2009" startWordPosition="3265" endWordPosition="3268">vided into 5 hours of training for the OOV detecthe OOV detection problem would then be reduced tor and 95 hours of test. Note that the OOV detector to a search for the sub-words in the output of the training set is different from the LVCSR training set. ASR system. The search can be on the one-best We also use a hybrid LVCSR system, combintranscripts, lattices or confusion networks. While ing word and sub-word units obtained from eilattices contain more information, they are harder ther our approach or a state-of-the-art baseline apto process; confusion networks offer a trade-off be- proach (Rastrow et al., 2009a) (§5.2). Our hybrid tween richness (posterior probabilities are already system’s lexicon has 83K words and 5K or 10K computed) and compactness (Mangu et al., 1999). sub-words. Note that the word vocabulary is comTwo effective indications of OOVs are the exis- mon to both systems and only the sub-words are setence of sub-words (Eq. 7) and high entropy in a lected using either approach. The word vocabulary network region (Eq. 8), both of which are used as used is close to most modern LVCSR system vofeatures in the model of Parada et al. (2010). cabularies for English Broadcast News; the result</context>
<context position="23678" citStr="Rastrow et al. (2009" startWordPosition="3969" endWordPosition="3972"> to 0.1K), -y = 0.4, and T = 0.6. We used K = 40 iterations for learning and 200 samples to compute the expectations in Eq. 5. The sampler was initialized by sampling for 500 iterations with deterministic annealing for a temperature varying from 10 to 0 at 0.1 intervals. Final segmentations were obtained using 10, 000 samples and the same temperature schedule. We limit segmentations to those including units of at most 5 phones to speed sampling with no significant degradation in performance. We observed improved performance by dis-allowing whole word units. 5.2 Baseline Unit Selection We used Rastrow et al. (2009a) as our baseline unit selection method, a data driven approach where the language model training text is converted into phones using the dictionary (or a letter-to-sound model for OOVs), and a N-gram phone LM is estimated on this data and pruned using a relative entropy based method. The hybrid lexicon includes resulting sub-words – ranging from unigrams to 5- gram phones, and the 83K word lexicon. 5.3 Evaluation We obtain confusion networks from both the word and hybrid LVCSR systems. We align the LVCSR transcripts with the reference transcripts and tag each confusion region as either IV or</context>
<context position="31856" citStr="Rastrow et al., 2009" startWordPosition="5338" endWordPosition="5342">ontext-features 6.1 Improved Phonetic Transcription We consider the hybrid lexicon’s impact on Phone Error Rate (PER) with respect to the reference transcription. The reference phone sequence is obtained by doing forced alignment of the audio stream to the reference transcripts using acoustic models. This provides an alignment of the pronunciation variant of each word in the reference and the recognizer’s one-best output. The aligned words are converted to the phonetic representation using the dictionary. Table 2 presents PERs for the word and different hybrid systems. As previously reported (Rastrow et al., 2009b), the hybrid systems achieve better PER, specially in OOV regions since they predict sub-word units for OOVs. Our method achieves modest improvements in PER compared to the hybrid baseline. No statistically significant improvements in PER were observed on MIT Lectures. 7 Conclusions Our probabilistic model learns sub-word units for hybrid speech recognizers by segmenting a text corpus while exploiting side information. Applying our System OOV IV All Word 1.62 6.42 8.04 Hybrid: Baseline (5k) 1.56 6.44 8.01 Hybrid: Baseline (10k) 1.51 6.41 7.92 Hybrid: This Paper (5k) 1.52 6.42 7.94 Hybrid: Th</context>
</contexts>
<marker>Rastrow, Sethy, Ramabhadran, Jelinek, 2009</marker>
<rawString>Ariya Rastrow, Abhinav Sethy, Bhuvana Ramabhadran, and Fred Jelinek. 2009b. Towards using hybrid, word, and fragment units for vocabulary independent LVCSR systems. INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Schaaf</author>
</authors>
<title>Detection of OOV words using generalized word models and a semantic class language model.</title>
<date>2001</date>
<booktitle>In Eurospeech.</booktitle>
<contexts>
<context position="16627" citStr="Schaaf, 2001" startWordPosition="2748" endWordPosition="2749">(Y, Si|W)) 9k = sampleS(P(Si|Y ∗, W),Q(Si|Y ∗, W)) end for /* M-Step */ ES,Y|W [fi] = NumSamples Ek fσ,l [S0k, Y0k] ES|Y *,W[fσ,l] = NumSamples Ek fσ,l[�Sk,Y ∗] � λi = Ai−1 + γ∇L¯λ(Y ∗|W) end for S = bestSegmentation(T, λK, S0) Output: Lexicon Lo from S 4 OOV Detection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s</context>
</contexts>
<marker>Schaaf, 2001</marker>
<rawString>T. Schaaf. 2001. Detection of OOV words using generalized word models and a semantic class language model. In Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Soltau</author>
<author>B Kingsbury</author>
<author>L Mangu</author>
<author>D Povey</author>
<author>G Saon</author>
<author>G Zweig</author>
</authors>
<title>conversational telephony system for rich transcription.</title>
<date>2005</date>
<booktitle>The ibm</booktitle>
<contexts>
<context position="22091" citStr="Soltau et al., 2005" startWordPosition="3696" endWordPosition="3699">ances per 5.1 Learning parameters word and short OOVs inappropriate for STD (less For learning the sub-words we randomly selected than 4 phones) were explicitly excluded. Example from training 5,000 words which belong to the 83K OOVs include: NATALIE, PUTIN, QAEDA, vocabulary and 5,000 OOVs6. For development we HOLLOWAY, COROLLARIES, HYPERLINKED, selected an additional 1,000 IV and 1,000 OOVs. etc. This resulted in roughly 24K (2%) OOV tokens. This was used to tune our model hyper parameters For LVCSR, we used the IBM Speech Recogni- (set to a = −1, Q = −20). There is no overlap tion Toolkit (Soltau et al., 2005)5 to obtain a tran- of OOVs in training, development and test sets. All script of the audio. Acoustic models were trained feature weights were initialized to zero and had a on 300 hours of HUB4 data (Fiscus et al., 1998) Gaussian prior with variance a = 100. Each of the and utterances containing OOV words as marked in words in training and development was converted to OOVCORP were excluded. The language model was their most-likely pronunciation using the dictionary trained on 400M words from various text sources 6This was used to obtain the 5K hybrid system. To learn subwords for the 10K hybri</context>
</contexts>
<marker>Soltau, Kingsbury, Mangu, Povey, Saon, Zweig, 2005</marker>
<rawString>H. Soltau, B. Kingsbury, L. Mangu, D. Povey, G. Saon, and G. Zweig. 2005. The ibm 2004 conversational telephony system for rich transcription. In ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sun</author>
<author>G Zhang</author>
<author>f Zheng</author>
<author>M Xu</author>
</authors>
<title>Using word confidence measure for OOV words detection in a spontaneous spoken dialog system.</title>
<date>2001</date>
<booktitle>In Eurospeech.</booktitle>
<contexts>
<context position="16915" citStr="Sun et al., 2001" startWordPosition="2794" endWordPosition="2797">odels To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� ES&apos; |σ| / IES |σ| with prob α : ym,k = y0m, sm,k = s0m with prob (1 − α) : ym,k = ym, sm,k = sm end for return (S0k, Y0k) = [(s1,k, y1,k) ... (sM,k, yM,k)] confidence-based models, achieving state-of-the art performance for this task. 4.1 OOV De</context>
</contexts>
<marker>Sun, Zhang, Zheng, Xu, 2001</marker>
<rawString>H. Sun, G. Zhang, f. Zheng, and M. Xu. 2001. Using word confidence measure for OOV words detection in a spontaneous spoken dialog system. In Eurospeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Wang</author>
</authors>
<title>Using graphone models in automatic speech recognition. Master’s thesis,</title>
<date>2009</date>
<institution>Massachusetts Institute of Technology.</institution>
<contexts>
<context position="16683" citStr="Wang, 2009" startWordPosition="2758" endWordPosition="2759">r /* M-Step */ ES,Y|W [fi] = NumSamples Ek fσ,l [S0k, Y0k] ES|Y *,W[fσ,l] = NumSamples Ek fσ,l[�Sk,Y ∗] � λi = Ai−1 + γ∇L¯λ(Y ∗|W) end for S = bestSegmentation(T, λK, S0) Output: Lexicon Lo from S 4 OOV Detection Using Hybrid Models To evaluate our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� ES&apos; |σ| / IES</context>
</contexts>
<marker>Wang, 2009</marker>
<rawString>Stanley Wang. 2009. Using graphone models in automatic speech recognition. Master’s thesis, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wessel</author>
<author>R Schluter</author>
<author>K Macherey</author>
<author>H Ney</author>
</authors>
<title>Confidence measures for large vocabulary continuous speech recognition.</title>
<date>2001</date>
<journal>IEEE Transactions on Speech and Audio Processing,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="16937" citStr="Wessel et al., 2001" startWordPosition="2798" endWordPosition="2801">our model for learning sub-word units, we consider the task of out-of-vocabulary (OOV) word detection. OOV detection for ASR output can be categorized into two broad groups: 1) hybrid (filler) models: which explicitly model OOVs using either filler, sub-words, or generic word models (Bazzi, 2002; Schaaf, 2001; Bisani and Ney, 2005; Klakow et al., 1999; Wang, 2009); and 2) confidence-based approaches: which label unreliable regions as OOVs based on different confidence scores, such as acoustic scores, language models, and lattice scores (Lin et al., 2007; Burget et al., 2008; Sun et al., 2001; Wessel et al., 2001). In the next section we detail the OOV detection approach we employ, which combines hybrid and Algorithm 2 sampleSL(P(S,Y |W), Q(S,Y |W)) for m = 1 to M (NumWords) do (s0 m, y0m) = Sample segmentation/label pair for word wm according to Q(S, Y |W) Y 0 = {y1 ... ym−1y0mym+1 ... yM} S0 = {s1 . . . sm−1s0 msm+1 . . . sM} �α=min1, C� ES&apos; |σ| / IES |σ| with prob α : ym,k = y0m, sm,k = s0m with prob (1 − α) : ym,k = ym, sm,k = sm end for return (S0k, Y0k) = [(s1,k, y1,k) ... (sM,k, yM,k)] confidence-based models, achieving state-of-the art performance for this task. 4.1 OOV Detection Approach We us</context>
</contexts>
<marker>Wessel, Schluter, Macherey, Ney, 2001</marker>
<rawString>F. Wessel, R. Schluter, K. Macherey, and H. Ney. 2001. Confidence measures for large vocabulary continuous speech recognition. IEEE Transactions on Speech and Audio Processing, 9(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher White</author>
<author>Jasha Droppo</author>
<author>Alex Acero</author>
<author>Julian Odell</author>
</authors>
<title>Maximum entropy confidence estimation for speech recognition.</title>
<date>2007</date>
<booktitle>In ICASSP.</booktitle>
<contexts>
<context position="27379" citStr="White et al. (2007)" startWordPosition="4573" endWordPosition="4576">Interestingly, the average sub-word length for the proposed units exceeded that of the baseline units by 0.3 phones (Baseline 5K average length was 2.92, while that of This Paper 5K was 3.2). 9Our baseline results differ from Parada et al. (2010). When implementing the lexicon baseline, we discovered that their hybrid units were mistakenly derived from text containing test OOVs. Once excluded, the relative improvements of previous work remain, but the absolute error rates are higher. 10All real-valued features were normalized and quantized using the uniform-occupancy partitioning described in White et al. (2007). We used 50 partitions with a minimum of 100 training values per partition. 718 70 65 60 55 50 45 40 35 300 5 10 15 20 %FA %Masses Baseline (5k) This Paper (5k) Baseline (10k) This Paper (10k) %Masses 45 70 65 60 55 50 300 5 10 15 20 %FA Baseline (5k) This Paper (5k) Baseline (10k) This Paper (10k) 40 35 (a) (b) Figure 4: DET curves for OOV detection using baseline hybrid systems for different lexicon size and proposed discriminative hybrid system on OOVCORP data set. Evaluation on un-observed OOVs (a) and all OOVs (b). 70 65 60 %Masses 55 50 45 40 35 300 5 10 15 20 %FA (a) (b) Figure 5: Effe</context>
</contexts>
<marker>White, Droppo, Acero, Odell, 2007</marker>
<rawString>Christopher White, Jasha Droppo, Alex Acero, and Julian Odell. 2007. Maximum entropy confidence estimation for speech recognition. In ICASSP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>