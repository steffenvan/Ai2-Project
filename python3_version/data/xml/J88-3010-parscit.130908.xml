<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000401">
<sectionHeader confidence="0.8714895" genericHeader="abstract">
ON THE RELATIONSHIP BETWEEN USER MODELS AND
DISCOURSE MODELS
</sectionHeader>
<author confidence="0.962222">
Robin Cohen
</author>
<affiliation confidence="0.97435">
Department of Computer Science
University of Waterloo
</affiliation>
<address confidence="0.510722">
Waterloo, Canada N214 3G1
</address>
<bodyText confidence="0.997897025316456">
The best way to summarize my view of the relationship
between user models and discourse models is that they
are separate, but related to each other. This paper will
show why the two terms have completely distinct
elements, and where the common ground between the
two lies. It is also important to acknowledge at the
outset that the two terms have not been well defined in
the literature.
For the discourse model, I am including everything
that should be derived from an analysis of discourse, to
present a representation for the structure of the dis-
course, useful in subsequent responses. In this sense, I
focus on the interpretation of a discourse from the point
of view of one of the conversants. I essentially include
in the discourse all the components covered by the
model of Grosz and Sidner (1986). For the definition of
the user model, I also ground the discussion in the point
of view of one conversant. The model is thus an analysis
of the other conversant (subsequently referred to as the
speaker). The term user model is especially obscure,
because in the context of this journal it is confined to a
derivation of background knowledge and goals of a user
which influence the language used in the discourse.
(One can use a similar term in the design of graphical
interfaces, for instance).
The discourse model must thus contain the following
key elements: an indication of the structure of the
discourse and an organization of the objects of the real
world mentioned in the discourse (to help anaphora
resolution, for example). As soon as this kind of history
of objects is included (covered in the model of Grosz
and Sidner (1986) by tracking attentional state and the
objects currently in focus), there are elements that are
not specifically attached to the user himself.
The structure of the discourse is essentially provided
in two different ways. Which of the actual utterances of
the discourse group together into logical segments is
covered by the &amp;quot;linguistic structure&amp;quot; of Grosz and
Sidner (1986). Often clue words (such as &amp;quot;but anyway&amp;quot;)
will indicate how to segment the utterances into logical
segments, without concern for how individual utter-
ances within that segment relate. In addition, there is an
indication of the intentional structure. Here, I would
reinterpret slightly the term as used in Grosz and Sidner
(1986) (see Cohen 1986). Intentional structure should
indicate the intentional relations between, again, actual
utterances. For instance, it is important to determine
the cases where the goal underlying an utterance &amp;quot;con-
tributes to the satisfaction of&apos; &apos; the goal underlying
another utterance—e.g., getting the hearer to believe
some proposition p contributes to the satisfaction of
getting the hearer to believe some proposition q (deter-
mined as dominance relations in Grosz and Sidner
(1986). In this sense, my interpretation of the derivation
of intentional structure agrees well with Wahlster&apos;s
appeal for an incremental derivation of the discourse
model).
I believe that the intentional structure is related to,
but not identical with, the plan of the speaker underly-
ing discourse. For one, the plan of the speaker can be
reconstructed at a different level of detail than what is
actually uttered. For an example, see Appendix 1.
This leads me to where I feel the discourse model and
user model relate. The plan of the speaker underlying
discourse is one part of the user model and is related to
the intentional structure of the discourse. But there is
more to the user model as well. There has been a good
deal of work on co-operative responses (e.g., Joshi et al.
(1984)). Van Beek (van Beek and Cohen 1986, van Beek
1986) shows that goals and systemwide preferences of a
user can influence appropriate responses (e.g., prefer-
ring to take numerical analysis courses in a course
advisor domain). It is thus important to include a model
of the user&apos;s goals (beyond an understanding of the goal
underlying each individual utterance, useful for the
reconstruction of the intentional structure). This kind of
Copyright 1988 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided
that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To
copy otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<footnote confidence="0.511741">
0362-613X/ 88 /0100.4403.00
</footnote>
<page confidence="0.940817">
88 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
<bodyText confidence="0.988168776119403">
Robin Cohen On the Relationship Between User Models and Discourse Models
goal is not part of the discourse per se. Other important
components of the user model are background knowl-
edge of the user (e.g., Cohen and Jones (1988) show that
it is important to vary the response to a parent vs. a
teacher in a domain of educational diagnosis; Paris
(1985) shows how the form of response can vary accord-
ing to the level of expertise; Chin (1986) also uses the
level of expertise of the user, together with a labeling of
difficulty of the system&apos;s knowledge, to produce good
responses). Especially if the user is modeled over a
period of time, these &amp;quot;values&amp;quot; can change and must be
monitored.
The bottom line, I feel, is that what is included in the
user model or the discourse model is dependent on what
the system employing these models is being designed
for. (Again, I agree with Wahlster&apos;s perception of the
problem—the discussion of what is in the UM or DM
can be guided by how systems should be designed).
I prefer the point of view of a NLUS, taking the role
of a conversant, analyzing the discourse of the speaker
(using a model of the user as well as an incrementally
built model of the discourse), to be used to eventually
respond. If a representation to facilitate response is
what is needed, it seems clear that both a picture of the
discourse as it proceeded and an understanding of the
person producing the discourse will be important dis-
tinct factors. Understanding the structure enables the
hearer to comprehend the points made by the speaker,
to then evaluate and address a response. Deeper know-
ledge of the speaker will then facilitate constructing a
response that can be well understood (for which the goal
of the hearer in producing the response will succeed).
For an example, see Appendix 2.
I will close with some comments about the terminol-
ogy used by Schuster. I feel that the definition of
discourse model here is too narrow—there is more to a
model of discourse than an indication of the underlying
entities (objects, events). Schuster seems to suggest
that some of the structuring provided in Grosz and
Sidner (1986) is there only to highlight the entities. In
my view, the actual utterances themselves are worth
examining as participating in some structure.
I also find Schuster&apos;s definition for user model—the
information a system has about the user—somewhat
problematic. I think that the user model must concen-
trate on dynamic information, that is, which has some
potential for change. In any case, the information
should be such that different values make for different
analyses ( of the discourse where the user model is
derived). Otherwise, why have a model at all? So if all
the users of a system are male, why record this fact in
the user model for each one? (My views here thus
coincide with Sparck Jones&apos;s claim that a user should be
modeled if there are particular characteristics which set
her apart.)
Finally, relevant to Schuster&apos;s discussion on agent
models and user models (see also Wahlster and Kobsa
1988; Kass and Finin, this issue), I reiterate that the
focus should be on the user as conversant. If the topic
of conversation is another agent, it is useful to know
about this person, in the same sense that it is useful to
know about any topic discussed (e.g., the working of a
nuclear power plant). (Note that the system&apos;s and the
user&apos;s view of the topic may not coincide, and thus this
view of the world may need to be modeled of the user as
well).
</bodyText>
<listItem confidence="0.931968714285714">
1. See that screw
2. The one with the funny top
3. Loosen it with the wrench
4. That black wrench there
5. OK—now you can slip in the pliers
6. And the whole pole comes off
Plan of Speaker:
</listItem>
<bodyText confidence="0.9089185">
The top level goal is get pole off, which succeeds if the following hierarchy of subgoals succeeds:
get pole off
loosen screw with/wrenci-\_,_ slip in pliers
/
identify screw identify wrench
/ X
know chars. of screw know chars. of wrench
Intentional structure of discourse (as in Grosz and Sidner 1986):
</bodyText>
<listItem confidence="0.81191025">
Primary Intentions:
Il: intend H (get pole off);
12: intend H (loosen screw with wrench)
13: intend H (identify screw)
</listItem>
<table confidence="0.51439">
Computational Linguistics, Volume 14, Number 3, September 1988 89
Robin Cohen On the Relationship Between User Models and Discourse Models
Segmentation Structure:
( ( ( 1 2 (ds3) ) 3 4 (ds2) ) 5 6 (dsl) )
</table>
<bodyText confidence="0.909709791666667">
There are three segments: ds3 with 13, ds2 with 12, and dsl with Ii, where 12 DOM 13 and Il DOM 12 (i.e.
13 contributes to the satisfaction of 12, etc.)
There are two main sources of difference between the
plan of the speaker and the intentional structure of
discourse, illustrated by the above example: (i) there
may be no direct match from the utterances to the units
(subgoals) of the plan; here, there is no utterance
corresponding to &amp;quot;identify wrench&amp;quot;, on top of utter-
ance 4, which serves to let the hearer &amp;quot;know charac-
teristics of the wrench&amp;quot;; (ii) the intentions recorded for
the intentional structure may be at a higher level of
detail.
The examples provided in Grosz and Sidner (1986),
for instance, only record those attached to segments of
more than one utterance. There are, indeed, many issues
regarding the relationship of plans and discourse struc-
ture; we will not elaborate further here. Our main point is
that the two terms should be related, but distinct.
Appendix 1. Plans vs. Intentional Structure.
Example:
2. 1. Prime Minister Mulroney is wonderful.
2. He refuses to back off on the free trade plan.
2b. 1. Prime Minister Mulroney is wonderful.
2. For example, he refuses to back off on the free
trade plan.
In Example 2b, the structure of the discourse, indicated
by the connecting phrase &amp;quot;for example&amp;quot;, suggests an
intentional connection between (1) and (2). (One way to
view this discourse is as an argument where the speaker
utters (2) in order to get the hearer to believe (1)). Clue
words alone may provide a basis for the determination
of the segmentation of this small example.
Now, if we also know of the speaker (or derive, on
the basis of the likely intended connection above) that
he is an arch-conservative, we have additional informa-
tion to facilitate response. One such rejoinder might be:
2c. Yes, but won&apos;t this prevent big private compa-
nies from making lots of money?
This rejoinder would not be appropriate for a fiery labor
supporter (e.g., New Democrat, in Canadian politics).
Example 2 is also a case where having a model of the
user&apos;s beliefs (e.g., he&apos;s an arch-conservative stereo-
type) may facilitate derivation of the intended structure
of the discourse, in the absence of clue words. This thus
also argues for inclusion in the user model information
additional to the structure of discourse determined so
far.
Appendix 2. Using Discourse Structure and User Models for Response.
</bodyText>
<sectionHeader confidence="0.995981" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999858166666667">
Chin, D. N. 1986 User Modeling in UC, the UNIX Consultant. In
Proceedings of the Conference on Human Factors in Computing
Systems, Boston, MA: 24-28.
Cohen, R. 1986 An Incremental Model for Discourse Analysis.
Unpublished draft, Department of Computer Science, University
of Waterloo, Canada.
Cohen, R. and Jones, M. 1988 Incorporating User Models into Expert
Systems for Educational Diagnosis. In Kobsa, A. and Wahlster,
W. (eds.), User Models in Dialog Systems. Springer-Verlag,
Berlin—New York.
Grosz, B. and Sidner, C. 1986 Attention, Intentions, and the Structure
of Discourse. In Computational Linguistics 12: 175-204.
Joshi, A.; Webber, B. and Weischedel, R. M. 1984 Living up to
Expectations: Computing Expert Responses. In Proceedings of
the National Conference on Artificial Intelligence, Stanford, CA:
169-175.
Kass, R. and Finin, T. (this issue): Modeling the User in Natural
Language Systems.
Paris, C. L. 1985 Description Strategies for Naive and Expert Users.
In Proceedings of the 23rd Annual Meeting of the Association for
Computational Linguistics, Chicago, IL: 238-246.
van Beek, P. 1986 A Model for User Specific Explanation from Expert
Systems. M. Math, thesis, Technical Report CS-86-42, Depart-
ment of Computer Science, University of Waterloo, Canada.
van Beek, P. and Cohen, R. 1986 Towards User Specific Explanation
Systems. In Proceedings of the 6th Canadian Conference on
Artificial Intelligence, Montreal, Canada: 194-198.
Wahlster, W. and Kobsa, A. 1988 User Models in Dialog Systems. In
Kobsa, A. and Wahlster, W. (eds.), User Models in Dialog
Systems. Springer-Verlag, Berlin—New York.
</reference>
<page confidence="0.968898">
90 Computational Linguistics, Volume 14, Number 3, September 1988
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.011358">
<title confidence="0.9970455">ON THE RELATIONSHIP BETWEEN USER MODELS DISCOURSE MODELS</title>
<author confidence="0.999998">Robin Cohen</author>
<affiliation confidence="0.999941">Department of Computer University of Waterloo</affiliation>
<address confidence="0.945116">Waterloo, Canada N214 3G1</address>
<abstract confidence="0.980122049382716">The best way to summarize my view of the relationship between user models and discourse models is that they are separate, but related to each other. This paper will show why the two terms have completely distinct elements, and where the common ground between the two lies. It is also important to acknowledge at the outset that the two terms have not been well defined in the literature. For the discourse model, I am including everything that should be derived from an analysis of discourse, to present a representation for the structure of the discourse, useful in subsequent responses. In this sense, I focus on the interpretation of a discourse from the point of view of one of the conversants. I essentially include in the discourse all the components covered by the model of Grosz and Sidner (1986). For the definition of the user model, I also ground the discussion in the point of view of one conversant. The model is thus an analysis of the other conversant (subsequently referred to as the speaker). The term user model is especially obscure, because in the context of this journal it is confined to a derivation of background knowledge and goals of a user which influence the language used in the discourse. (One can use a similar term in the design of graphical interfaces, for instance). The discourse model must thus contain the following key elements: an indication of the structure of the discourse and an organization of the objects of the real world mentioned in the discourse (to help anaphora resolution, for example). As soon as this kind of history of objects is included (covered in the model of Grosz and Sidner (1986) by tracking attentional state and the objects currently in focus), there are elements that are not specifically attached to the user himself. The structure of the discourse is essentially provided in two different ways. Which of the actual utterances of the discourse group together into logical segments is covered by the &amp;quot;linguistic structure&amp;quot; of Grosz and Sidner (1986). Often clue words (such as &amp;quot;but anyway&amp;quot;) will indicate how to segment the utterances into logical segments, without concern for how individual utterances within that segment relate. In addition, there is an indication of the intentional structure. Here, I would reinterpret slightly the term as used in Grosz and Sidner (1986) (see Cohen 1986). Intentional structure should indicate the intentional relations between, again, actual utterances. For instance, it is important to determine the cases where the goal underlying an utterance &amp;quot;contributes to the satisfaction of&apos; &apos; the goal underlying another utterance—e.g., getting the hearer to believe proposition to the satisfaction of the hearer to believe some proposition (determined as dominance relations in Grosz and Sidner (1986). In this sense, my interpretation of the derivation of intentional structure agrees well with Wahlster&apos;s appeal for an incremental derivation of the discourse model). I believe that the intentional structure is related to, but not identical with, the plan of the speaker underlying discourse. For one, the plan of the speaker can be reconstructed at a different level of detail than what is actually uttered. For an example, see Appendix 1. This leads me to where I feel the discourse model and user model relate. The plan of the speaker underlying discourse is one part of the user model and is related to the intentional structure of the discourse. But there is more to the user model as well. There has been a good deal of work on co-operative responses (e.g., Joshi et al. (1984)). Van Beek (van Beek and Cohen 1986, van Beek 1986) shows that goals and systemwide preferences of a user can influence appropriate responses (e.g., preferring to take numerical analysis courses in a course advisor domain). It is thus important to include a model of the user&apos;s goals (beyond an understanding of the goal underlying each individual utterance, useful for the reconstruction of the intentional structure). This kind of Copyright 1988 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided the copies are not made for direct commercial advantage and the and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 88 /0100.4403.00 88 Computational Linguistics, Volume 14, Number 3, September 1988 Cohen On the Relationship Models and Discourse Models goal is not part of the discourse per se. Other important components of the user model are background knowledge of the user (e.g., Cohen and Jones (1988) show that it is important to vary the response to a parent vs. a teacher in a domain of educational diagnosis; Paris (1985) shows how the form of response can vary according to the level of expertise; Chin (1986) also uses the level of expertise of the user, together with a labeling of difficulty of the system&apos;s knowledge, to produce good responses). Especially if the user is modeled over a period of time, these &amp;quot;values&amp;quot; can change and must be monitored. The bottom line, I feel, is that what is included in the user model or the discourse model is dependent on what the system employing these models is being designed for. (Again, I agree with Wahlster&apos;s perception of the problem—the discussion of what is in the UM or DM can be guided by how systems should be designed). I prefer the point of view of a NLUS, taking the role of a conversant, analyzing the discourse of the speaker (using a model of the user as well as an incrementally built model of the discourse), to be used to eventually respond. If a representation to facilitate response is what is needed, it seems clear that both a picture of the discourse as it proceeded and an understanding of the person producing the discourse will be important distinct factors. Understanding the structure enables the hearer to comprehend the points made by the speaker, to then evaluate and address a response. Deeper knowledge of the speaker will then facilitate constructing a response that can be well understood (for which the goal of the hearer in producing the response will succeed). For an example, see Appendix 2. I will close with some comments about the terminology used by Schuster. I feel that the definition of discourse model here is too narrow—there is more to a model of discourse than an indication of the underlying entities (objects, events). Schuster seems to suggest that some of the structuring provided in Grosz and Sidner (1986) is there only to highlight the entities. In my view, the actual utterances themselves are worth examining as participating in some structure. also find Schuster&apos;s definition for user information a system has about the user—somewhat problematic. I think that the user model must concentrate on dynamic information, that is, which has some for change. In any the information should be such that different values make for different analyses ( of the discourse where the user model is derived). Otherwise, why have a model at all? So if all the users of a system are male, why record this fact in the user model for each one? (My views here thus coincide with Sparck Jones&apos;s claim that a user should be modeled if there are particular characteristics which set her apart.) Finally, relevant to Schuster&apos;s discussion on agent models and user models (see also Wahlster and Kobsa 1988; Kass and Finin, this issue), I reiterate that the focus should be on the user as conversant. If the topic of conversation is another agent, it is useful to know about this person, in the same sense that it is useful to know about any topic discussed (e.g., the working of a nuclear power plant). (Note that the system&apos;s and the user&apos;s view of the topic may not coincide, and thus this view of the world may need to be modeled of the user as well). 1. See that screw 2. The one with the funny top 3. Loosen it with the wrench 4. That black wrench there 5. OK—now you can slip in the pliers 6. And the whole pole comes off Plan of Speaker: The top level goal is get pole off, which succeeds if the following hierarchy of subgoals succeeds: get pole off screw in pliers / identify screw identify wrench / X know chars. of screw know chars. of</abstract>
<note confidence="0.750273818181818">Intentional structure of discourse (as in Grosz and Sidner 1986): Primary Intentions: Il: intend H (get pole off); 12: intend H (loosen screw with wrench) 13: intend H (identify screw) Computational Linguistics, Volume 14, Number 3, September 1988 89 Robin Cohen On the Relationship Between User Models and Discourse Models Segmentation Structure: ( ( ( 1 2 (ds3) ) 3 4 (ds2) ) 5 6 (dsl) ) There are three segments: ds3 with 13, ds2 with 12, and dsl with Ii, where 12 DOM 13 and Il DOM 12 (i.e. 13 contributes to the satisfaction of 12, etc.)</note>
<abstract confidence="0.993084086956522">There are two main sources of difference between the plan of the speaker and the intentional structure of discourse, illustrated by the above example: (i) there may be no direct match from the utterances to the units (subgoals) of the plan; here, there is no utterance corresponding to &amp;quot;identify wrench&amp;quot;, on top of utterance 4, which serves to let the hearer &amp;quot;know characteristics of the wrench&amp;quot;; (ii) the intentions recorded for the intentional structure may be at a higher level of detail. The examples provided in Grosz and Sidner (1986), for instance, only record those attached to segments of more than one utterance. There are, indeed, many issues regarding the relationship of plans and discourse structure; we will not elaborate further here. Our main point is that the two terms should be related, but distinct. vs. Intentional Structure. Example: 2. 1. Prime Minister Mulroney is wonderful. 2. He refuses to back off on the free trade plan. Minister Mulroney is wonderful. 2. For example, he refuses to back off on the free trade plan. In Example 2b, the structure of the discourse, indicated by the connecting phrase &amp;quot;for example&amp;quot;, suggests an intentional connection between (1) and (2). (One way to view this discourse is as an argument where the speaker (2) in order to get the hearer to believe words alone may provide a basis for the determination of the segmentation of this small example. Now, if we also know of the speaker (or derive, on the basis of the likely intended connection above) that he is an arch-conservative, we have additional information to facilitate response. One such rejoinder might be: Yes, but won&apos;t this prevent big private companies from making lots of money? This rejoinder would not be appropriate for a fiery labor supporter (e.g., New Democrat, in Canadian politics). Example 2 is also a case where having a model of the user&apos;s beliefs (e.g., he&apos;s an arch-conservative stereotype) may facilitate derivation of the intended structure of the discourse, in the absence of clue words. This thus also argues for inclusion in the user model information additional to the structure of discourse determined so far. 2. Discourse Structure and User Models for Response.</abstract>
<note confidence="0.92332396875">REFERENCES D. N. User Modeling in UC, the UNIX Consultant. In Proceedings of the Conference on Human Factors in Computing MA: 24-28. Cohen, R. 1986 An Incremental Model for Discourse Analysis. Unpublished draft, Department of Computer Science, University of Waterloo, Canada. Cohen, R. and Jones, M. 1988 Incorporating User Models into Expert Systems for Educational Diagnosis. In Kobsa, A. and Wahlster, (eds.), Models in Dialog Systems. Berlin—New York. Grosz, B. and Sidner, C. 1986 Attention, Intentions, and the Structure Discourse. In Linguistics 175-204. Joshi, A.; Webber, B. and Weischedel, R. M. 1984 Living up to Computing Expert Responses. In of National Conference on Artificial Intelligence, CA: 169-175. Kass, R. and Finin, T. (this issue): Modeling the User in Natural Language Systems. Paris, C. L. 1985 Description Strategies for Naive and Expert Users. of the 23rd Annual Meeting of the Association for Linguistics, IL: 238-246. van Beek, P. 1986 A Model for User Specific Explanation from Expert Systems. M. Math, thesis, Technical Report CS-86-42, Department of Computer Science, University of Waterloo, Canada. van Beek, P. and Cohen, R. 1986 Towards User Specific Explanation In of the 6th Canadian Conference on Intelligence, Canada: 194-198. Wahlster, W. and Kobsa, A. 1988 User Models in Dialog Systems. In A. and Wahlster, W. (eds.), Models in Dialog Berlin—New York. Linguistics, Volume 14, Number 3, September 1988</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D N Chin</author>
</authors>
<title>User Modeling in UC, the UNIX Consultant.</title>
<date>1986</date>
<booktitle>In Proceedings of the Conference on Human Factors in Computing Systems,</booktitle>
<pages>24--28</pages>
<location>Boston, MA:</location>
<contexts>
<context position="5097" citStr="Chin (1986)" startWordPosition="839" endWordPosition="840">o copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/ 88 /0100.4403.00 88 Computational Linguistics, Volume 14, Number 3, September 1988 Robin Cohen On the Relationship Between User Models and Discourse Models goal is not part of the discourse per se. Other important components of the user model are background knowledge of the user (e.g., Cohen and Jones (1988) show that it is important to vary the response to a parent vs. a teacher in a domain of educational diagnosis; Paris (1985) shows how the form of response can vary according to the level of expertise; Chin (1986) also uses the level of expertise of the user, together with a labeling of difficulty of the system&apos;s knowledge, to produce good responses). Especially if the user is modeled over a period of time, these &amp;quot;values&amp;quot; can change and must be monitored. The bottom line, I feel, is that what is included in the user model or the discourse model is dependent on what the system employing these models is being designed for. (Again, I agree with Wahlster&apos;s perception of the problem—the discussion of what is in the UM or DM can be guided by how systems should be designed). I prefer the point of view of a NL</context>
</contexts>
<marker>Chin, 1986</marker>
<rawString>Chin, D. N. 1986 User Modeling in UC, the UNIX Consultant. In Proceedings of the Conference on Human Factors in Computing Systems, Boston, MA: 24-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cohen</author>
</authors>
<title>An Incremental Model for Discourse Analysis. Unpublished draft,</title>
<date>1986</date>
<institution>Department of Computer Science, University of Waterloo, Canada.</institution>
<contexts>
<context position="2512" citStr="Cohen 1986" startWordPosition="416" endWordPosition="417">ically attached to the user himself. The structure of the discourse is essentially provided in two different ways. Which of the actual utterances of the discourse group together into logical segments is covered by the &amp;quot;linguistic structure&amp;quot; of Grosz and Sidner (1986). Often clue words (such as &amp;quot;but anyway&amp;quot;) will indicate how to segment the utterances into logical segments, without concern for how individual utterances within that segment relate. In addition, there is an indication of the intentional structure. Here, I would reinterpret slightly the term as used in Grosz and Sidner (1986) (see Cohen 1986). Intentional structure should indicate the intentional relations between, again, actual utterances. For instance, it is important to determine the cases where the goal underlying an utterance &amp;quot;contributes to the satisfaction of&apos; &apos; the goal underlying another utterance—e.g., getting the hearer to believe some proposition p contributes to the satisfaction of getting the hearer to believe some proposition q (determined as dominance relations in Grosz and Sidner (1986). In this sense, my interpretation of the derivation of intentional structure agrees well with Wahlster&apos;s appeal for an incrementa</context>
<context position="3802" citStr="Cohen 1986" startWordPosition="628" endWordPosition="629">s related to, but not identical with, the plan of the speaker underlying discourse. For one, the plan of the speaker can be reconstructed at a different level of detail than what is actually uttered. For an example, see Appendix 1. This leads me to where I feel the discourse model and user model relate. The plan of the speaker underlying discourse is one part of the user model and is related to the intentional structure of the discourse. But there is more to the user model as well. There has been a good deal of work on co-operative responses (e.g., Joshi et al. (1984)). Van Beek (van Beek and Cohen 1986, van Beek 1986) shows that goals and systemwide preferences of a user can influence appropriate responses (e.g., preferring to take numerical analysis courses in a course advisor domain). It is thus important to include a model of the user&apos;s goals (beyond an understanding of the goal underlying each individual utterance, useful for the reconstruction of the intentional structure). This kind of Copyright 1988 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advant</context>
</contexts>
<marker>Cohen, 1986</marker>
<rawString>Cohen, R. 1986 An Incremental Model for Discourse Analysis. Unpublished draft, Department of Computer Science, University of Waterloo, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cohen</author>
<author>M Jones</author>
</authors>
<title>Incorporating User Models into Expert Systems for Educational Diagnosis.</title>
<date>1988</date>
<booktitle>User Models in Dialog Systems.</booktitle>
<editor>In Kobsa, A. and Wahlster, W. (eds.),</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin—New York.</location>
<contexts>
<context position="4884" citStr="Cohen and Jones (1988)" startWordPosition="797" endWordPosition="800">s. Permission to copy without fee all or part of this material is granted provided that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/ 88 /0100.4403.00 88 Computational Linguistics, Volume 14, Number 3, September 1988 Robin Cohen On the Relationship Between User Models and Discourse Models goal is not part of the discourse per se. Other important components of the user model are background knowledge of the user (e.g., Cohen and Jones (1988) show that it is important to vary the response to a parent vs. a teacher in a domain of educational diagnosis; Paris (1985) shows how the form of response can vary according to the level of expertise; Chin (1986) also uses the level of expertise of the user, together with a labeling of difficulty of the system&apos;s knowledge, to produce good responses). Especially if the user is modeled over a period of time, these &amp;quot;values&amp;quot; can change and must be monitored. The bottom line, I feel, is that what is included in the user model or the discourse model is dependent on what the system employing these m</context>
</contexts>
<marker>Cohen, Jones, 1988</marker>
<rawString>Cohen, R. and Jones, M. 1988 Incorporating User Models into Expert Systems for Educational Diagnosis. In Kobsa, A. and Wahlster, W. (eds.), User Models in Dialog Systems. Springer-Verlag, Berlin—New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<title>Attention, Intentions, and the Structure of Discourse.</title>
<date>1986</date>
<journal>In Computational Linguistics</journal>
<volume>12</volume>
<pages>175--204</pages>
<contexts>
<context position="957" citStr="Grosz and Sidner (1986)" startWordPosition="157" endWordPosition="160"> terms have completely distinct elements, and where the common ground between the two lies. It is also important to acknowledge at the outset that the two terms have not been well defined in the literature. For the discourse model, I am including everything that should be derived from an analysis of discourse, to present a representation for the structure of the discourse, useful in subsequent responses. In this sense, I focus on the interpretation of a discourse from the point of view of one of the conversants. I essentially include in the discourse all the components covered by the model of Grosz and Sidner (1986). For the definition of the user model, I also ground the discussion in the point of view of one conversant. The model is thus an analysis of the other conversant (subsequently referred to as the speaker). The term user model is especially obscure, because in the context of this journal it is confined to a derivation of background knowledge and goals of a user which influence the language used in the discourse. (One can use a similar term in the design of graphical interfaces, for instance). The discourse model must thus contain the following key elements: an indication of the structure of the</context>
<context position="2495" citStr="Grosz and Sidner (1986)" startWordPosition="411" endWordPosition="414"> elements that are not specifically attached to the user himself. The structure of the discourse is essentially provided in two different ways. Which of the actual utterances of the discourse group together into logical segments is covered by the &amp;quot;linguistic structure&amp;quot; of Grosz and Sidner (1986). Often clue words (such as &amp;quot;but anyway&amp;quot;) will indicate how to segment the utterances into logical segments, without concern for how individual utterances within that segment relate. In addition, there is an indication of the intentional structure. Here, I would reinterpret slightly the term as used in Grosz and Sidner (1986) (see Cohen 1986). Intentional structure should indicate the intentional relations between, again, actual utterances. For instance, it is important to determine the cases where the goal underlying an utterance &amp;quot;contributes to the satisfaction of&apos; &apos; the goal underlying another utterance—e.g., getting the hearer to believe some proposition p contributes to the satisfaction of getting the hearer to believe some proposition q (determined as dominance relations in Grosz and Sidner (1986). In this sense, my interpretation of the derivation of intentional structure agrees well with Wahlster&apos;s appeal </context>
<context position="6794" citStr="Grosz and Sidner (1986)" startWordPosition="1131" endWordPosition="1134">prehend the points made by the speaker, to then evaluate and address a response. Deeper knowledge of the speaker will then facilitate constructing a response that can be well understood (for which the goal of the hearer in producing the response will succeed). For an example, see Appendix 2. I will close with some comments about the terminology used by Schuster. I feel that the definition of discourse model here is too narrow—there is more to a model of discourse than an indication of the underlying entities (objects, events). Schuster seems to suggest that some of the structuring provided in Grosz and Sidner (1986) is there only to highlight the entities. In my view, the actual utterances themselves are worth examining as participating in some structure. I also find Schuster&apos;s definition for user model—the information a system has about the user—somewhat problematic. I think that the user model must concentrate on dynamic information, that is, which has some potential for change. In any case, the information should be such that different values make for different analyses ( of the discourse where the user model is derived). Otherwise, why have a model at all? So if all the users of a system are male, wh</context>
<context position="8642" citStr="Grosz and Sidner 1986" startWordPosition="1460" endWordPosition="1463">s and the user&apos;s view of the topic may not coincide, and thus this view of the world may need to be modeled of the user as well). 1. See that screw 2. The one with the funny top 3. Loosen it with the wrench 4. That black wrench there 5. OK—now you can slip in the pliers 6. And the whole pole comes off Plan of Speaker: The top level goal is get pole off, which succeeds if the following hierarchy of subgoals succeeds: get pole off loosen screw with/wrenci-\_,_ slip in pliers / identify screw identify wrench / X know chars. of screw know chars. of wrench Intentional structure of discourse (as in Grosz and Sidner 1986): Primary Intentions: Il: intend H (get pole off); 12: intend H (loosen screw with wrench) 13: intend H (identify screw) Computational Linguistics, Volume 14, Number 3, September 1988 89 Robin Cohen On the Relationship Between User Models and Discourse Models Segmentation Structure: ( ( ( 1 2 (ds3) ) 3 4 (ds2) ) 5 6 (dsl) ) There are three segments: ds3 with 13, ds2 with 12, and dsl with Ii, where 12 DOM 13 and Il DOM 12 (i.e. 13 contributes to the satisfaction of 12, etc.) There are two main sources of difference between the plan of the speaker and the intentional structure of discourse, illu</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Grosz, B. and Sidner, C. 1986 Attention, Intentions, and the Structure of Discourse. In Computational Linguistics 12: 175-204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Joshi</author>
<author>B Webber</author>
<author>R M Weischedel</author>
</authors>
<title>Living up to Expectations: Computing Expert Responses.</title>
<date>1984</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>169--175</pages>
<location>Stanford, CA:</location>
<contexts>
<context position="3766" citStr="Joshi et al. (1984)" startWordPosition="619" endWordPosition="622">). I believe that the intentional structure is related to, but not identical with, the plan of the speaker underlying discourse. For one, the plan of the speaker can be reconstructed at a different level of detail than what is actually uttered. For an example, see Appendix 1. This leads me to where I feel the discourse model and user model relate. The plan of the speaker underlying discourse is one part of the user model and is related to the intentional structure of the discourse. But there is more to the user model as well. There has been a good deal of work on co-operative responses (e.g., Joshi et al. (1984)). Van Beek (van Beek and Cohen 1986, van Beek 1986) shows that goals and systemwide preferences of a user can influence appropriate responses (e.g., preferring to take numerical analysis courses in a course advisor domain). It is thus important to include a model of the user&apos;s goals (beyond an understanding of the goal underlying each individual utterance, useful for the reconstruction of the intentional structure). This kind of Copyright 1988 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided that the copies are n</context>
</contexts>
<marker>Joshi, Webber, Weischedel, 1984</marker>
<rawString>Joshi, A.; Webber, B. and Weischedel, R. M. 1984 Living up to Expectations: Computing Expert Responses. In Proceedings of the National Conference on Artificial Intelligence, Stanford, CA: 169-175.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R Kass</author>
<author>T Finin</author>
</authors>
<title>(this issue): Modeling the User in Natural Language Systems.</title>
<marker>Kass, Finin, </marker>
<rawString>Kass, R. and Finin, T. (this issue): Modeling the User in Natural Language Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Paris</author>
</authors>
<title>Description Strategies for Naive and Expert Users.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>238--246</pages>
<location>Chicago, IL:</location>
<contexts>
<context position="5008" citStr="Paris (1985)" startWordPosition="822" endWordPosition="823">advantage and the CL reference and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/ 88 /0100.4403.00 88 Computational Linguistics, Volume 14, Number 3, September 1988 Robin Cohen On the Relationship Between User Models and Discourse Models goal is not part of the discourse per se. Other important components of the user model are background knowledge of the user (e.g., Cohen and Jones (1988) show that it is important to vary the response to a parent vs. a teacher in a domain of educational diagnosis; Paris (1985) shows how the form of response can vary according to the level of expertise; Chin (1986) also uses the level of expertise of the user, together with a labeling of difficulty of the system&apos;s knowledge, to produce good responses). Especially if the user is modeled over a period of time, these &amp;quot;values&amp;quot; can change and must be monitored. The bottom line, I feel, is that what is included in the user model or the discourse model is dependent on what the system employing these models is being designed for. (Again, I agree with Wahlster&apos;s perception of the problem—the discussion of what is in the UM o</context>
</contexts>
<marker>Paris, 1985</marker>
<rawString>Paris, C. L. 1985 Description Strategies for Naive and Expert Users. In Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, Chicago, IL: 238-246.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P van Beek</author>
</authors>
<title>A Model for User Specific Explanation from Expert Systems.</title>
<date>1986</date>
<tech>M. Math, thesis, Technical Report CS-86-42,</tech>
<institution>Department of Computer Science, University of Waterloo, Canada.</institution>
<marker>van Beek, 1986</marker>
<rawString>van Beek, P. 1986 A Model for User Specific Explanation from Expert Systems. M. Math, thesis, Technical Report CS-86-42, Department of Computer Science, University of Waterloo, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P van Beek</author>
<author>R Cohen</author>
</authors>
<title>Towards User Specific Explanation Systems.</title>
<date>1986</date>
<booktitle>In Proceedings of the 6th Canadian Conference on Artificial Intelligence,</booktitle>
<location>Montreal, Canada:</location>
<marker>van Beek, Cohen, 1986</marker>
<rawString>van Beek, P. and Cohen, R. 1986 Towards User Specific Explanation Systems. In Proceedings of the 6th Canadian Conference on Artificial Intelligence, Montreal, Canada: 194-198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
<author>A Kobsa</author>
</authors>
<title>User Models in Dialog Systems.</title>
<date>1988</date>
<booktitle>User Models in Dialog Systems.</booktitle>
<editor>In Kobsa, A. and Wahlster, W. (eds.),</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin—New York.</location>
<contexts>
<context position="7700" citStr="Wahlster and Kobsa 1988" startWordPosition="1283" endWordPosition="1286">el must concentrate on dynamic information, that is, which has some potential for change. In any case, the information should be such that different values make for different analyses ( of the discourse where the user model is derived). Otherwise, why have a model at all? So if all the users of a system are male, why record this fact in the user model for each one? (My views here thus coincide with Sparck Jones&apos;s claim that a user should be modeled if there are particular characteristics which set her apart.) Finally, relevant to Schuster&apos;s discussion on agent models and user models (see also Wahlster and Kobsa 1988; Kass and Finin, this issue), I reiterate that the focus should be on the user as conversant. If the topic of conversation is another agent, it is useful to know about this person, in the same sense that it is useful to know about any topic discussed (e.g., the working of a nuclear power plant). (Note that the system&apos;s and the user&apos;s view of the topic may not coincide, and thus this view of the world may need to be modeled of the user as well). 1. See that screw 2. The one with the funny top 3. Loosen it with the wrench 4. That black wrench there 5. OK—now you can slip in the pliers 6. And th</context>
</contexts>
<marker>Wahlster, Kobsa, 1988</marker>
<rawString>Wahlster, W. and Kobsa, A. 1988 User Models in Dialog Systems. In Kobsa, A. and Wahlster, W. (eds.), User Models in Dialog Systems. Springer-Verlag, Berlin—New York.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>