<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000753">
<title confidence="0.9413635">
THE FORMAL CONSEQUENCES OF USING VARIABLES
IN CCG CATEGORIES
</title>
<author confidence="0.996984">
Beryl Hoffman *
</author>
<affiliation confidence="0.998656">
Dept. of Computer and Information Sciences
University of Pennsylvania
</affiliation>
<address confidence="0.774357">
Philadelphia, PA 19104
</address>
<email confidence="0.997817">
(hoffman@linc.cis.upenn.edu)
</email>
<sectionHeader confidence="0.997372" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997371">
Combinatory Categorial Grammars, CCGs, (Steedman
1985) have been shown by Weir and Joshi (1988) to
generate the same class of languages as Tree-Adjoining
Grammars (TAG), Head Grammars (HG), and Linear
Indexed Grammars (LIG). In this paper, I will discuss
the effect of using variables in lexical category assign-
ments in CCGs. It will be shown that using variables
in lexical categories can increase the weak generative
capacity of CCGs beyond the class of grammars listed
above.
</bodyText>
<sectionHeader confidence="0.895404" genericHeader="categories and subject descriptors">
A Formal Definition for CCGs
</sectionHeader>
<bodyText confidence="0.9990752">
In categorial grammars, grammatical entities are of
two types: basic categories and functions. A basic
category such as NP serves as a shorthand for a set of
syntactic and semantic features. A category such as
S\N P is a function representing an intransitive verb;
the function looks for an argument of type NP on
its left and results in the category S. A small set of
combinatory rules serve to combine these categories
while preserving a transparent relation between syntax
and semantics. Application rules allow functions to
combine with their arguments, while composition rules
allow two functions to combine together.
Based on the formal definition of CCGs in
(Weir-Joshi 1988), a CCG, G, is denoted by
(VT, VN, S, f, R), where
</bodyText>
<listItem confidence="0.8859655">
• VT is a finite set of terminals,
• VN is a finite set of nonterminals,
• S is a distinguished member of VN,
• f is a function that maps elements of VT U fej to
finite subsets of C( VN), the set of categories, where,
- VN C C(VN) and
- if ci and c2 E C(VN), then (ci \ c2) and (ci/c2) E
C(VN).
</listItem>
<footnote confidence="0.9895166">
*I would like to thank Mark Steedman, Libby Levison,
Owen Rambow, and the anonymous referees for their valu-
able advice. This work was partially supported by DARPA
N00014-904-1863, ARO DAAL03-89-C-0031, NSF IRI 90-
16592, Ben Franklin 91S.3078C-1.
</footnote>
<listItem confidence="0.976755071428571">
• R is a finite set of combinatory rules where
X ,Y, Z1, . , Zn are variables over the set of cat-
egories C(VN), and the slash variable L can bind
to \ or /. Certain restrictions may be placed on the
possible instantiations of the variables in the rules.
— Forward Application (&gt;):
X/Y Y
— Backward Application (&lt;):
Y X\Y —+ X
— Generalized Forward Composition
(&gt;B(n) or &gt;Bx(n)): For some n &gt; 1,
X/Y .AZ16 ...
— Generalized Backward Composition
(&lt;B(n) or &lt;Bx(n)): For some n&gt; 1,
</listItem>
<bodyText confidence="0.764543">
Y liZik Zn X \Y —&gt; • • • In
The derives relation in a CCG is defined as ac#
</bodyText>
<equation confidence="0.72413225">
ac1c2# if R contains the rule CI c2 c. The language
generated by this grammar is defined as
L(G) = fah ..., I S • • , Cm)
E f(ai), ai E VT U {E},i &lt;i&gt; n}
</equation>
<bodyText confidence="0.8965836">
Under these assumptions, Weir and Joshi (1988) prove
that CCGs are weakly equivalent to TAGs, HGs, and
LIGs. Their conversion of a CCG to a LIG&apos; relies
on the fact that the combinatory rules in the CCG are
linear. To preserve linearity in CCGs, only the category
X in the combinatory rules can be unbounded in size;
the variables Y and Z must be bounded in their possible
instantiations. In other words, only a finite number of
categories can fill the secondary constituent of each
combinatory rule. The secondary constituent is the
second of the pair of categories being combined in the
forward rules and the first of the pair in the backward
rules (e.g. . • • I Zn
Weir and Joshi do not restrict the size of the sec-
ondary constituents in the formal definition of the CCG
rules, but they prove that the following lemma holds of
the grammar.
&apos;Linear Indexed Grammars are a restricted version of
Indexed Grammars in which no rule can copy a stack of
unbounded size to more than one daughter (Gazdar 1985).
</bodyText>
<page confidence="0.988769">
298
</page>
<construct confidence="0.971730333333333">
Lemma: There is a bound (determined by the gram-
mar G) on the number of useful categories that can
match the secondary constituent of a rule.
</construct>
<bodyText confidence="0.999893222222222">
There are an infinite number of derivable cate-
gories in CCGs, however Weir and Joshi show that
the number of components that derivable categories
have is bounded. The components of a category
c = (C011C112- • In Cn ) are its immediate components
co, ..., c, and the components of these immediate com-
ponents. A finite set Dc(G) can be defined that con-
tains all derivable components of every useful category
where a category c is useful if c w for some w in
</bodyText>
<equation confidence="0.9869475">
VT* :
C E Dc (G) if c is a component of c&apos;
</equation>
<bodyText confidence="0.9936">
where c&apos; E f (a) for some a E VT U {e} .
Given that every useful category matching the sec-
ondary constituents Y and Y in the combi-
natory rules has components which are in D (G), the
lemma given above holds.
However, this lemma does not hold if there are
variables in the lexical categories in VT. Variables can
bind a category of any size, and thus useful categories
containing variables do not necessarily have all of their
derivable components in the finite set D (G).
</bodyText>
<subsectionHeader confidence="0.9964985">
The Use of Variables
Linguistic Use
</subsectionHeader>
<bodyText confidence="0.999981428571429">
In CCGs, a type-raising rule can be used in the lexicon
to convert basic elements into functions; for exam-
ple, an NP category can be type-raised to the category
SAS\NP) representing a function looking for an in-
transitive verb on its right. Steedman uses type-raising
of NPs to capture syntactic coordination and extraction
facts. In Steedman&apos;s Dutch grammar (1985), variables
are used in the lexical category for type-raised NPs,
i.e. the variable v in the category v I (v\N P) general-
izes across all possible verbal categories. The use of
variables allows the type-raised NPs in the following
coordinated sentence to easily combine together, us-
ing the forward composition rule, even though they are
arguments of different verbs.
</bodyText>
<figure confidence="0.929639428571429">
(1) ...dat [Jan Piet] en [Cecilia Henk] zag zwemmen.
...that [Jan Piet] and [Cecilia Henk] saw swim.
...that Jan saw Piet and Cecilia saw Henk swim.
Jan Piet
v I (v\N P) 1(v&apos;\N P)
&gt;B (v&apos; --= (v\N P))
v I (v\N P\N P)
</figure>
<subsectionHeader confidence="0.815099">
Formal Power
</subsectionHeader>
<bodyText confidence="0.9963377">
I will show that the use of variables in assigned lexical
categories increases the weak generative capacity of
CCGs. VAR-CCGs, CCGs using variables, can gener-
ate languages that are known not to be Tree-Adjoining
Languages; therefore VAR-CCGs are more powerful
than the weakly equivalent TAG and CCG formalisms.
The following language is known not to be a TAL:
L fanbnednen In &gt;
The following VAR-CCG, G&apos;, generates a language L&apos;
which is very similar to L:
</bodyText>
<equation confidence="0.999843166666667">
f(e) = S,
f (a) = A,
f(b) = v\Al(v\B),
f(c) = v\B 1(v\C),
f(d) = v\C I (v\D),
f(e) = S\DIS.
</equation>
<bodyText confidence="0.998563666666667">
The rules allowed in this grammar are forward and
backward application and forward crossing composi-
tion with n &lt;2. The variable v can bind an arbitrarily
large category in the infinite set of categories C( VN)
defined for the grammar.
In the language generated by this grammar, two
characters of the same type can combine together using
the forward crossing composition rule &gt;Bx(2). The
composition of the types for the character e is shown
below. A string of e&apos;s can be constructed by allowing
the result of this composition to combine with another
e category.
</bodyText>
<equation confidence="0.970254333333333">
S\DIS S\DIS
&gt;Bx(2)
S\D\D/S
</equation>
<bodyText confidence="0.99319625">
The types for the characters b, c, and d can combine
using the same composition rule; these types contain
variables (e.g. v and v&apos; below) which can bind to a
category of unbounded size.
</bodyText>
<equation confidence="0.998704333333333">
v\Al(v\B) v&apos;\AI (e\B)
&gt;Bx(2) (v/ = (v\B))
v\A\AI (v\B\B)
</equation>
<bodyText confidence="0.9861148">
By applying the forward crossing composition rule to
a string of n b&apos;s, we can form the complex category
v \ Ai . . /(v \ Bi . . BO representing this string.
Thus, during the derivation of an bncncinen for
n &gt; 0, the following complex categories are created:
</bodyText>
<equation confidence="0.9766405">
v\AI ...111/(v\BI B1)
v\Bi . . . Bk I (v\Ci • • • Ck)
v\Ci . . . CI(v\Di
s\Di . . Di
</equation>
<bodyText confidence="0.99986125">
Once the complex categories for a string of b&apos;s,
a string of c&apos;s, a string of d&apos;s, and a string of e&apos;s
are constructed, we can link one string of a particu-
lar character to another using the forward application
rule. This rule can only apply to these categories if
i = j, j = k,k = 1, and I = m where in is the num-
ber of A&apos;s generated and i, j, k , 1 are as in the complex
categories listed above. For example,
</bodyText>
<equation confidence="0.705653">
v\CI Ci/(v\Di DJ) s\Di . . . Di
s\CI Ci
&gt; (j = i)
</equation>
<page confidence="0.993161">
299
</page>
<bodyText confidence="0.9999572">
With each succesful forward application, we ensure
that there are equal numbers of two characters: the E&apos;s
are linked to the D&apos;s, the D&apos;s are linked to the C&apos;s,
etc., so that we have the exact same number of all five
characters. In fact, the grammar can be easily extended
to generate a language such asfatila&apos;2/aIn &gt; 0}
for any k.
The language L&apos; generated by G&apos; intersected with
the regular language a* b* c* d* e* gives the language L
above. If we assume that L&apos; is a Tree-Adjoining Lan-
guage (TAL), then L would be a TAL as well since
TALs are closed under intersection with Regular lan-
guages. However, since we know that L is not a TAL,
L&apos; cannot be a TAL either. Thus, G&apos; generates a lan-
guage that TAGs and CCGs cannot.
</bodyText>
<subsectionHeader confidence="0.541774">
Conclusions
</subsectionHeader>
<bodyText confidence="0.999993115384615">
We have seen that using variables in the lexical cat-
egories of a CCG can increase its weak generative
capacity. However, there is some linguistic motivation
for looking at the more powerful formalism of VAR-
CCGs. As argued by Gazdar (1985), this extra power
may be necessary in order to capture coordination in
natural languages. We have seen that type-raised cat-
egories with variables in CCGs can be used to capture
syntactic coordination and extraction facts in Dutch
(Steedman 1985). Further research is needed to decide
whether this linguistic motivation warrants the move
to a more powerful formalism.
Although VAR-CCGs have a greater weak gen-
erative capacity than the class including TAGs, HGs,
CCGs, and LIGs, we conjecture that it is still a mildly
context-sensitive grammar as defined by Joshi (1985).
The language discussed above is a mildly context-
sensitive language since it observes the constant growth
and semilinearity properties. It is an open question
whether VAR-CCGs can generate languages which are
beyond mildly context-sensitive. Note that MC-TAGs,
which are a more powerful extension of TAGs, can also
generate languages like L, and they are known to be
mildly context-sensitive formalisms (Weir 1988). In
future research, we will investigate exactly what the
resulting generative capacity of VAR-CCGs is.
</bodyText>
<subsectionHeader confidence="0.956991">
Future Research on Word Order
</subsectionHeader>
<bodyText confidence="0.9999644">
My current research also involves extending the CCG
formalism to handle free word order languages. By
representing NPs as type-raised categories, we can de-
rive a scrambled sentence in which the NPs do not
occur in the order that the verb specifies:
</bodyText>
<equation confidence="0.672733333333333">
v/(v\NP2) v/(v\NPI) S\NPI\NP2
&gt;8
5\NP2
</equation>
<bodyText confidence="0.992952866666667">
In many free word order languages, an NP can be
scrambled an unbounded distance away from its verb,
i.e. long distance scrambling. If we allow unrestricted
composition rules for any n arguments as well as the
use of variables in type-raised categories in a CCG, a
string of any number of scrambled NPs followed by a
string of verbs can be derived. We first combine any
number of verbs together, using backward composi-
tion, to get a complex verb category looking for all of
the NPs; next, we combine each NPs with this com-
plex verb category. Any type-raised N pi can combine
with the complex verb regardless of the order specified
by the complex verb. The variable in the type-raised
category can bind a verbal category of unbounded size,
e.g. (v = S\N pi\...\N pi_ 1).
</bodyText>
<figure confidence="0.603582">
v I (v\Npi) S\Np1\Np2...\Np1...\Npn
&gt;B x(n)
S\N pi\...\N pi_ i\N pi+1...\N p,,,
</figure>
<bodyText confidence="0.999813272727273">
Although we can capture scrambling by using variables
in type-raised categories, this analysis is not consistent
with incremental processing and cannot account for co-
ordination in scrambled sentences; for instance, in the
first example given above, N P2 and NP1 cannot com-
bine together before combining with the verb. In future
research, I will investigate whether VAR-CCGs is an
adequate linguistic formalism in capturing all aspects
of free word order languages or whether a formalism
such as {}-CCGs (Hoffman 1992), which allows sets
of arguments in function categories, is better suited.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99988704">
[1] Gazdar, G. 1985. Applicability of Indexed Gram-
mars to Natural Languages. Technical Report
CSLI-85-34, Center for Study of Language and In-
formation.
[2] Hoffman, Beryl. 1992. A CCG Approach to Free
Word Order Languages. Proceedings of the 30th
Annual Meeting of ACL, Student Session.
[3] Joshi, A.K., 1985. How much context-sensitivity
is required to provide reasonable structural descrip-
tions: Tree adjoining grammars. in D. Dowty and
L. Karttunen and A. Zwicky, editors, Natural Lan-
guage Parsing: Psycholinguistic, Computational
and Theoretical Perspectives, Cambridge Univer-
sity Press.
[4] Steedman, Mark. 1985. Dependency and Coordi-
nation in the Grammar of Dutch and English. Lan-
guage, 61, 523-568.
[5] Weir, David. 1988. Characterising Mildly Context-
sensitive Grammar Formalisms. Ph.D dissertation.
University of Pennsylvania.
[6] Weir, David and Aravind Joshi. 1988. Combina-
tory Categorial Grammars: Generative Power and
Relationship to Linear Context-Free Rewriting Sys-
tems. Proceedings of the 26th Annual Meeting of
ACL.
</reference>
<page confidence="0.997982">
300
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.018401">
<title confidence="0.9772825">THE FORMAL CONSEQUENCES OF USING VARIABLES IN CCG CATEGORIES</title>
<author confidence="0.999242">Beryl Hoffman</author>
<affiliation confidence="0.9997455">Dept. of Computer and Information Sciences University of Pennsylvania</affiliation>
<address confidence="0.9999">Philadelphia, PA 19104</address>
<email confidence="0.969891">(hoffman@linc.cis.upenn.edu)</email>
<abstract confidence="0.992887155555556">Combinatory Categorial Grammars, CCGs, (Steedman 1985) have been shown by Weir and Joshi (1988) to generate the same class of languages as Tree-Adjoining Grammars (TAG), Head Grammars (HG), and Linear Indexed Grammars (LIG). In this paper, I will discuss the effect of using variables in lexical category assignments in CCGs. It will be shown that using variables in lexical categories can increase the weak generative capacity of CCGs beyond the class of grammars listed above. A Formal Definition for CCGs In categorial grammars, grammatical entities are of types: categories basic category such as NP serves as a shorthand for a set of syntactic and semantic features. A category such as P a function representing an intransitive verb; function looks for an argument of type left and results in the category small set of combinatory rules serve to combine these categories while preserving a transparent relation between syntax and semantics. Application rules allow functions to combine with their arguments, while composition rules allow two functions to combine together. Based on the formal definition of CCGs in 1988), a CCG, denoted by VN, f,R), VT a finite set of terminals, VN a finite set of nonterminals, S a distinguished member of VN, f a function that maps elements of U subsets of VN), set of categories, where, VN C C(VN) if and c2 E \ and (ci/c2) E C(VN). *I would like to thank Mark Steedman, Libby Levison, Owen Rambow, and the anonymous referees for their valuable advice. This work was partially supported by DARPA N00014-904-1863, ARO DAAL03-89-C-0031, NSF IRI 90- 16592, Ben Franklin 91S.3078C-1. R a finite set of combinatory rules where ,Y, Z1, . , are variables over the set of catthe slash variable Lcan bind to \ or /. Certain restrictions may be placed on the possible instantiations of the variables in the rules.</abstract>
<title confidence="0.9502654">Forward Application (&gt;): X/Y Y Application X\Y X — Generalized Forward Composition</title>
<note confidence="0.660347">gt;B(n) or &gt;Bx(n)): For some n &gt; 1, ... Backward Composition (&lt;B(n) or &lt;Bx(n)): For some n&gt; 1,</note>
<abstract confidence="0.984215184834123">X \Y —&gt; • • • In derives relation in a CCG is defined as the rule c. language generated by this grammar is defined as fah ..., I • , E U &lt;i&gt; Under these assumptions, Weir and Joshi (1988) prove that CCGs are weakly equivalent to TAGs, HGs, and LIGs. Their conversion of a CCG to a LIG&apos; relies on the fact that the combinatory rules in the CCG are linear. To preserve linearity in CCGs, only the category X in the combinatory rules can be unbounded in size; the variables Y and Z must be bounded in their possible instantiations. In other words, only a finite number of categories can fill the secondary constituent of each combinatory rule. The secondary constituent is the second of the pair of categories being combined in the forward rules and the first of the pair in the backward rules (e.g. . • • I Zn Weir and Joshi do not restrict the size of the secondary constituents in the formal definition of the CCG rules, but they prove that the following lemma holds of the grammar. &apos;Linear Indexed Grammars are a restricted version of Indexed Grammars in which no rule can copy a stack of unbounded size to more than one daughter (Gazdar 1985). 298 is a bound (determined by the grammar G) on the number of useful categories that can match the secondary constituent of a rule. There are an infinite number of derivable categories in CCGs, however Weir and Joshi show that the number of components that derivable categories have is bounded. The components of a category • Cn its immediate components ..., the components of these immediate com- A finite set Dc(G)can be defined that conall derivable components of every a category w some w in VT* : E Dc (G) a component of c&apos; f (a) for some a VT . that every useful category matching the secconstituents Y and Y in the rules has components which are in (G), lemma given above holds. However, this lemma does not hold if there are in the lexical categories in can bind a category of any size, and thus useful categories containing variables do not necessarily have all of their components in the finite set (G). The Use of Variables Linguistic Use In CCGs, a type-raising rule can be used in the lexicon to convert basic elements into functions; for example, an NP category can be type-raised to the category a function looking for an intransitive verb on its right. Steedman uses type-raising of NPs to capture syntactic coordination and extraction facts. In Steedman&apos;s Dutch grammar (1985), variables are used in the lexical category for type-raised NPs, the variable v in the category I (v\N P) generalizes across all possible verbal categories. The use of variables allows the type-raised NPs in the following coordinated sentence to easily combine together, using the forward composition rule, even though they are arguments of different verbs. (1) ...dat [Jan Piet] en [Cecilia Henk] zag zwemmen. ...that [Jan Piet] and [Cecilia Henk] saw swim. ...that Jan saw Piet and Cecilia saw Henk swim. Jan Piet v I (v\N P) 1(v&apos;\N P) &gt;B (v&apos; --= P)) v I (v\N P\N P) Formal Power show that the use of variables in assigned lexical categories increases the weak generative capacity of CCGs. VAR-CCGs, CCGs using variables, can generate languages that are known not to be Tree-Adjoining Languages; therefore VAR-CCGs are more powerful than the weakly equivalent TAG and CCG formalisms. The following language is known not to be a TAL: Lfanbnednen In &gt; following VAR-CCG, a language is very similar to f(e) = S, f (a) = A, f(b) = v\Al(v\B), f(c) = v\B 1(v\C), f(d) = v\C I (v\D), f(e) = S\DIS. The rules allowed in this grammar are forward and backward application and forward crossing composition with n &lt;2. The variable v can bind an arbitrarily category in the infinite set of categories defined for the grammar. In the language generated by this grammar, two characters of the same type can combine together using the forward crossing composition rule &gt;Bx(2). The of the types for the character shown below. A string of e&apos;s can be constructed by allowing the result of this composition to combine with another e category. S\DIS S\DIS &gt;Bx(2) S\D\D/S The types for the characters b, c, and d can combine using the same composition rule; these types contain variables (e.g. v and v&apos; below) which can bind to a category of unbounded size. v\Al(v\B) v&apos;\AI (e\B) &gt;Bx(2) = (v\B)) v\A\AI (v\B\B) By applying the forward crossing composition rule to a string of n b&apos;s, we can form the complex category \ Ai . . /(v \ . . this string. during the derivation of bncncinen n &gt; 0, the following complex categories are created: ...111/(v\BI v\Bi . . . Bk I (v\Ci • • • Ck) v\Ci . . . CI(v\Di s\Di . . Di Once the complex categories for a string of b&apos;s, a string of c&apos;s, a string of d&apos;s, and a string of e&apos;s are constructed, we can link one string of a particular character to another using the forward application rule. This rule can only apply to these categories if = j, j = = 1, I = m where the numof A&apos;s generated and i, k , 1 are as the complex categories listed above. For example, DJ) . . . Di i) 299 With each succesful forward application, we ensure that there are equal numbers of two characters: the E&apos;s are linked to the D&apos;s, the D&apos;s are linked to the C&apos;s, etc., so that we have the exact same number of all five characters. In fact, the grammar can be easily extended generate a language such &gt; 0} any language by with regular language a* c* d* the language If we assume that a Tree-Adjoining Lan- (TAL), then be a TAL as well since TALs are closed under intersection with Regular lan- However, since we know that not a TAL, be a TAL either. Thus, G&apos; generates a language that TAGs and CCGs cannot. Conclusions We have seen that using variables in the lexical categories of a CCG can increase its weak generative capacity. However, there is some linguistic motivation for looking at the more powerful formalism of VAR- CCGs. As argued by Gazdar (1985), this extra power may be necessary in order to capture coordination in natural languages. We have seen that type-raised categories with variables in CCGs can be used to capture syntactic coordination and extraction facts in Dutch (Steedman 1985). Further research is needed to decide whether this linguistic motivation warrants the move to a more powerful formalism. Although VAR-CCGs have a greater weak generative capacity than the class including TAGs, HGs, CCGs, and LIGs, we conjecture that it is still a mildly context-sensitive grammar as defined by Joshi (1985). The language discussed above is a mildly contextsensitive language since it observes the constant growth and semilinearity properties. It is an open question whether VAR-CCGs can generate languages which are beyond mildly context-sensitive. Note that MC-TAGs, which are a more powerful extension of TAGs, can also languages like they are known to be mildly context-sensitive formalisms (Weir 1988). In future research, we will investigate exactly what the resulting generative capacity of VAR-CCGs is. Future Research on Word Order My current research also involves extending the CCG formalism to handle free word order languages. By representing NPs as type-raised categories, we can derive a scrambled sentence in which the NPs do not occur in the order that the verb specifies: &gt;8 In many free word order languages, an NP can be scrambled an unbounded distance away from its verb, distance scrambling. we allow unrestricted composition rules for any n arguments as well as the use of variables in type-raised categories in a CCG, a string of any number of scrambled NPs followed by a string of verbs can be derived. We first combine any number of verbs together, using backward composition, to get a complex verb category looking for all of the NPs; next, we combine each NPs with this comverb category. Any type-raised pi combine with the complex verb regardless of the order specified by the complex verb. The variable in the type-raised category can bind a verbal category of unbounded size, (v = pi\...\N pi_ I (v\Npi) &gt;B x(n) pi\...\N pi_ i\N p,,, Although we can capture scrambling by using variables in type-raised categories, this analysis is not consistent with incremental processing and cannot account for coordination in scrambled sentences; for instance, in the example given above, P2 NP1 cannot combine together before combining with the verb. In future research, I will investigate whether VAR-CCGs is an adequate linguistic formalism in capturing all aspects of free word order languages or whether a formalism such as {}-CCGs (Hoffman 1992), which allows sets of arguments in function categories, is better suited.</abstract>
<note confidence="0.93206262962963">References Gazdar, G. 1985. of Indexed Gramto Natural Languages. Report CSLI-85-34, Center for Study of Language and Information. [2] Hoffman, Beryl. 1992. A CCG Approach to Free Order Languages. of the 30th Meeting of ACL, Session. [3] Joshi, A.K., 1985. How much context-sensitivity is required to provide reasonable structural descriptions: Tree adjoining grammars. in D. Dowty and Karttunen and A. Zwicky, editors, Language Parsing: Psycholinguistic, Computational Theoretical Perspectives, University Press. [4] Steedman, Mark. 1985. Dependency and Coordiin the Grammar of Dutch and English. Lan- 523-568. Weir, David. 1988. Mildly Context- Grammar Formalisms. dissertation. University of Pennsylvania. [6] Weir, David and Aravind Joshi. 1988. Combinatory Categorial Grammars: Generative Power and Relationship to Linear Context-Free Rewriting Sysof the 26th Annual Meeting of ACL. 300</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>Applicability of Indexed Grammars to Natural Languages.</title>
<date>1985</date>
<tech>Technical Report CSLI-85-34,</tech>
<institution>Center for Study of Language and Information.</institution>
<marker>[1]</marker>
<rawString>Gazdar, G. 1985. Applicability of Indexed Grammars to Natural Languages. Technical Report CSLI-85-34, Center for Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beryl Hoffman</author>
</authors>
<title>A CCG Approach to Free Word Order Languages.</title>
<date>1992</date>
<booktitle>Proceedings of the 30th Annual Meeting of ACL, Student Session.</booktitle>
<marker>[2]</marker>
<rawString>Hoffman, Beryl. 1992. A CCG Approach to Free Word Order Languages. Proceedings of the 30th Annual Meeting of ACL, Student Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>How much context-sensitivity is required to provide reasonable structural descriptions: Tree adjoining grammars.</title>
<date>1985</date>
<booktitle>Natural Language Parsing: Psycholinguistic, Computational and Theoretical Perspectives,</booktitle>
<editor>in D. Dowty and L. Karttunen and A. Zwicky, editors,</editor>
<publisher>Cambridge University Press.</publisher>
<marker>[3]</marker>
<rawString>Joshi, A.K., 1985. How much context-sensitivity is required to provide reasonable structural descriptions: Tree adjoining grammars. in D. Dowty and L. Karttunen and A. Zwicky, editors, Natural Language Parsing: Psycholinguistic, Computational and Theoretical Perspectives, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Dependency and Coordination in the</title>
<date>1985</date>
<journal>Grammar of Dutch and English. Language,</journal>
<volume>61</volume>
<pages>523--568</pages>
<marker>[4]</marker>
<rawString>Steedman, Mark. 1985. Dependency and Coordination in the Grammar of Dutch and English. Language, 61, 523-568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Weir</author>
</authors>
<title>Characterising Mildly Contextsensitive Grammar Formalisms. Ph.D dissertation.</title>
<date>1988</date>
<institution>University of Pennsylvania.</institution>
<marker>[5]</marker>
<rawString>Weir, David. 1988. Characterising Mildly Contextsensitive Grammar Formalisms. Ph.D dissertation. University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Weir</author>
<author>Aravind Joshi</author>
</authors>
<title>Combinatory Categorial Grammars: Generative Power and Relationship to Linear Context-Free Rewriting Systems.</title>
<date>1988</date>
<booktitle>Proceedings of the 26th Annual Meeting of ACL.</booktitle>
<marker>[6]</marker>
<rawString>Weir, David and Aravind Joshi. 1988. Combinatory Categorial Grammars: Generative Power and Relationship to Linear Context-Free Rewriting Systems. Proceedings of the 26th Annual Meeting of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>