<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.991764">
Structured Models for Fine-to-Coarse Sentiment Analysis
</title>
<author confidence="0.980846">
Ryan McDonald* Kerry Hannan Tyler Neylon Mike Wells Jeff Reynar
</author>
<affiliation confidence="0.914261">
Google, Inc.
</affiliation>
<address confidence="0.9770165">
76 Ninth Avenue
New York, NY 10011
</address>
<email confidence="0.993807">
*Contact email: ryanmcd@google.com
</email>
<sectionHeader confidence="0.995551" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999359">
In this paper we investigate a structured
model for jointly classifying the sentiment
of text at varying levels of granularity. Infer-
ence in the model is based on standard se-
quence classification techniques using con-
strained Viterbi to ensure consistent solu-
tions. The primary advantage of such a
model is that it allows classification deci-
sions from one level in the text to influence
decisions at another. Experiments show that
this method can significantly reduce classifi-
cation error relative to models trained in iso-
lation.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.978949833333333">
Extracting sentiment from text is a challenging prob-
lem with applications throughout Natural Language
Processing and Information Retrieval. Previous
work on sentiment analysis has covered a wide range
of tasks, including polarity classification (Pang et
al., 2002; Turney, 2002), opinion extraction (Pang
and Lee, 2004), and opinion source assignment
(Choi et al., 2005; Choi et al., 2006). Furthermore,
these systems have tackled the problem at differ-
ent levels of granularity, from the document level
(Pang et al., 2002), sentence level (Pang and Lee,
2004; Mao and Lebanon, 2006), phrase level (Tur-
ney, 2002; Choi et al., 2005), as well as the speaker
level in debates (Thomas et al., 2006). The abil-
ity to classify sentiment on multiple levels is impor-
tant since different applications have different needs.
For example, a summarization system for product
reviews might require polarity classification at the
sentence or phrase level; a question answering sys-
tem would most likely require the sentiment of para-
graphs; and a system that determines which articles
from an online news source are editorial in nature
would require a document level analysis.
This work focuses on models that jointly classify
sentiment on multiple levels of granularity. Consider
the following example,
This is the first Mp3 player that I have used ... I
thought it sounded great ... After only a few weeks,
it started having trouble with the earphone connec-
tion ... I won’t be buying another.
</bodyText>
<subsectionHeader confidence="0.44818">
Mp3 player review from Amazon.com
</subsectionHeader>
<bodyText confidence="0.999946266666667">
This excerpt expresses an overall negative opinion of
the product being reviewed. However, not all parts
of the review are negative. The first sentence merely
provides some context on the reviewer’s experience
with such devices and the second sentence indicates
that, at least in one regard, the product performed
well. We call the problem of identifying the senti-
ment of the document and of all its subcomponents,
whether at the paragraph, sentence, phrase or word
level, fine-to-coarse sentiment analysis.
The simplest approach to fine-to-coarse sentiment
analysis would be to create a separate system for
each level of granularity. There are, however, obvi-
ous advantages to building a single model that clas-
sifies each level in tandem. Consider the sentence,
</bodyText>
<footnote confidence="0.967453">
My 11 year old daughter has also been using it and
it is a lot harder than it looks.
In isolation, this sentence appears to convey negative
sentiment. However, it is part of a favorable review
</footnote>
<page confidence="0.925377">
432
</page>
<note confidence="0.926954">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 432–439,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.99126693877551">
for a piece of fitness equipment, where hard essen- labeling or chunking, but have also been applied to
tially means good workout. In this domain, hard’s parsing (Taskar et al., 2004; McDonald et al., 2005),
sentiment can only be determined in context (i.e., machine translation (Liang et al., 2006) and summa-
hard to assemble versus a hard workout). If the clas- rization (Daum´e III et al., 2006).
sifier knew the overall sentiment of a document, then Structured models have previously been used for
disambiguating such cases would be easier. sentiment analysis. Choi et al. (2005, 2006) use
Conversely, document level analysis can benefit CRFs to learn a global sequence model to classify
from finer level classification by taking advantage and assign sources to opinions. Mao and Lebanon
of common discourse cues, such as the last sentence (2006) used a sequential CRF regression model to
being a reliable indicator for overall sentiment in re- measure polarity on the sentence level in order to
views. Furthermore, during training, the model will determine the sentiment flow of authors in reviews.
not need to modify its parameters to explain phe- Here we show that fine-to-coarse models of senti-
nomena like the typically positive word great ap- ment can often be reduced to the sequential case.
pearing in a negative text (as is the case above). The Cascaded models for fine-to-coarse sentiment
model can also avoid overfitting to features derived analysis were studied by Pang and Lee (2004). In
from neutral or objective sentences. In fact, it has al- that work an initial model classified each sentence
ready been established that sentence level classifica- as being subjective or objective using a global min-
tion can improve document level analysis (Pang and cut inference algorithm that considered local label-
Lee, 2004). This line of reasoning suggests that a ing consistencies. The top subjective sentences are
cascaded approach would also be insufficient. Valu- then input into a standard document level polarity
able information is passed in both directions, which classifier with improved results. The current work
means any model of fine-to-coarse analysis should differs from that in Pang and Lee through the use of
account for this. a single joint structured model for both sentence and
In Section 2 we describe a simple structured document level analysis.
model that jointly learns and infers sentiment on dif- Many problems in natural language processing
ferent levels of granularity. In particular, we reduce can be improved by learning and/or predicting mul-
the problem of joint sentence and document level tiple outputs jointly. This includes parsing and rela-
analysis to a sequential classification problem us- tion extraction (Miller et al., 2000), entity labeling
ing constrained Viterbi inference. Extensions to the and relation extraction (Roth and Yih, 2004), and
model that move beyond just two-levels of analysis part-of-speech tagging and chunking (Sutton et al.,
are also presented. In Section 3 an empirical eval- 2004). One interesting work on sentiment analysis
uation of the model is given that shows significant is that of Popescu and Etzioni (2005) which attempts
gains in accuracy over both single level classifiers to classify the sentiment of phrases with respect to
and cascaded systems. possible product features. To do this an iterative al-
1.1 Related Work gorithm is used that attempts to globally maximize
The models in this work fall into the broad class of the classification of all phrases while satisfying local
global structured models, which are typically trained consistency constraints.
with structured learning algorithms. Hidden Markov 2 Structured Model
models (Rabiner, 1989) are one of the earliest struc- In this section we present a structured model for
tured learning algorithms, which have recently been fine-to-coarse sentiment analysis. We start by exam-
followed by discriminative learning approaches such ining the simple case with two-levels of granularity
as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the
2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification
perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the fea-
ants (Taskar et al., 2003; Tsochantaridis et al., 2004; ture space and give an algorithm for learning the pa-
McDonald et al., 2005; Daum´e III et al., 2006). rameters based on large-margin structured learning.
These algorithms are usually applied to sequential
433
Extensions to the model are also examined.
</bodyText>
<subsectionHeader confidence="0.980846">
2.1 A Sentence-Document Model
</subsectionHeader>
<bodyText confidence="0.989107022222222">
Let Y(d) be a discrete set of sentiment labels at
the document level and Y(s) be a discrete set of
sentiment labels at the sentence level. As input a
system is given a document containing sentences
s = s1, ... , sn and must produce sentiment labels
for the document, yd E Y(d), and each individ-
ual sentence, ys = ys1, ... , ysn, where ysi E Y(s) V
1 G i G n. Define y = (yd, ys) = (yd, ys1, . ..,ysn)
as the joint labeling of the document and sentences.
For instance, in Pang and Lee (2004), yd would be
the polarity of the document and ysi would indicate
whether sentence si is subjective or objective. The
models presented here are compatible with arbitrary
sets of discrete output labels.
Figure 1 presents a model for jointly classifying
the sentiment of both the sentences and the docu-
ment. In this undirected graphical model, the label
of each sentence is dependent on the labels of its
neighbouring sentences plus the label of the docu-
ment. The label of the document is dependent on
the label of every sentence. Note that the edges
between the input (each sentence) and the output
labels are not solid, indicating that they are given
as input and are not being modeled. The fact that
the sentiment of sentences is dependent not only on
the local sentiment of other sentences, but also the
global document sentiment – and vice versa – al-
lows the model to directly capture the importance
of classification decisions across levels in fine-to-
coarse sentiment analysis. The local dependencies
between sentiment labels on sentences is similar to
the work of Pang and Lee (2004) where soft local
consistency constraints were created between every
sentence in a document and inference was solved us-
ing a min-cut algorithm. However, jointly modeling
the document label and allowing for non-binary la-
bels complicates min-cut style solutions as inference
becomes intractable.
Learning and inference in undirected graphical
models is a well studied problem in machine learn-
ing and NLP. For example, CRFs define the prob-
ability over the labels conditioned on the input us-
ing the property that the joint probability distribu-
tion over the labels factors over clique potentials in
undirected graphical models (Lafferty et al., 2001).
</bodyText>
<figureCaption confidence="0.999339">
Figure 1: Sentence and document level model.
</figureCaption>
<bodyText confidence="0.999795">
In this work we will use structured linear classi-
fiers (Collins, 2002). We denote the score of a la-
beling y for an input s as score(y, s) and define this
score as the sum of scores over each clique,
</bodyText>
<equation confidence="0.870438">
score(y, s) = score((yd, ys), s)
= score((yd, ys 1, ... , ys n), s)
n
= score(y , yi_1, yis , s)
d s
i=2
</equation>
<bodyText confidence="0.994388571428572">
where each clique score is a linear combination of
features and their weights,
score(yd, ysi�1, ysi , s) = w · f(yd, ysi�1, ysi , s) (1)
and f is a high dimensional feature representation
of the clique and w a corresponding weight vector.
Note that s is included in each score since it is given
as input and can always be conditioned on.
In general, inference in undirected graphical mod-
els is intractable. However, for the common case of
sequences (a.k.a. linear-chain models) the Viterbi al-
gorithm can be used (Rabiner, 1989; Lafferty et al.,
2001). Fortunately there is a simple technique that
reduces inference in the above model to sequence
classification with a constrained version of Viterbi.
</bodyText>
<subsectionHeader confidence="0.686647">
2.1.1 Inference as Sequential Labeling
</subsectionHeader>
<bodyText confidence="0.951441">
The inference problem is to find the highest scor-
ing labeling y for an input s, i.e.,
arg max score(y, s)
Y
If the document label yd is fixed, then inference
in the model from Figure 1 reduces to the sequen-
tial case. This is because the search space is only
over the sentence labels ysi , whose graphical struc-
ture forms a chain. Thus the problem of finding the
</bodyText>
<page confidence="0.996131">
434
</page>
<figure confidence="0.633918375">
Input: s = sl, ... , s�
1. y=null
2. for each yd E Y(d)
3. y3 = arg maxys score((yd, y3), s)
4. y, = (yd, y3)
5. if score(y&apos;, s) &gt; score(y, s) or y = null
6. y = y&apos;
7. return y
</figure>
<figureCaption confidence="0.95879">
Figure 2: Inference algorithm for model in Figure 1.
</figureCaption>
<bodyText confidence="0.967228296296296">
The argmax in line 3 can be solved using Viterbi’s
algorithm since yd is fixed.
highest scoring sentiment labels for all sentences,
given a particular document label yd, can be solved
efficiently using Viterbi’s algorithm.
The general inference problem can then be solved
by iterating over each possible yd, finding y8 max-
imizing score((yd, y8), s) and keeping the single
best y = (yd, y8). This algorithm is outlined in Fig-
ure 2 and has a runtime of O(|Y(d)||Y(s)|2n), due
to running Viterbi |Y(d) |times over a label space of
size |Y(s)|. The algorithm can be extended to pro-
duce exact k-best lists. This is achieved by using
k-best Viterbi techniques to return the k-best global
labelings for each document label in line 3. Merging
these sets will produce the final k-best list.
It is possible to view the inference algorithm in
Figure 2 as a constrained Viterbi search since it is
equivalent to flattening the model in Figure 1 to a
sequential model with sentence labels from the set
Y(s) x Y(d). The resulting Viterbi search would
then need to be constrained to ensure consistent
solutions, i.e., the label assignments agree on the
document label over all sentences. If viewed this
way, it is also possible to run a constrained forward-
backward algorithm and learn the parameters for
CRFs as well.
</bodyText>
<subsectionHeader confidence="0.882702">
2.1.2 Feature Space
</subsectionHeader>
<bodyText confidence="0.9902799">
In this section we define the feature representa-
tion for each clique, f(yd, ysi_1, ysi , s). Assume that
each sentence si is represented by a set of binary
predicates P(si). This set can contain any predicate
over the input s, but for the present purposes it will
include all the unigram, bigram and trigrams in
the sentence si conjoined with their part-of-speech
(obtained from an automatic classifier). Back-offs
of each predicate are also included where one or
more word is discarded. For instance, if P(si) con-
tains the predicate a:DT great:JJ product:NN,
then it would also have the predicates
a:DT great:JJ *:NN, a:DT *:JJ product:NN,
*:DT great:JJ product:NN, a:DT *:JJ *:NN, etc.
Each predicate, p, is then conjoined with the label
information to construct a binary feature. For exam-
ple, if the sentence label set is Y(s) = {subj, obj}
and the document set is Y(d) = {pos, neg}, then
the system might contain the following feature,
{ 1 if p E P(si)
</bodyText>
<subsectionHeader confidence="0.481644">
s
</subsectionHeader>
<bodyText confidence="0.967061210526316">
and y! = obj
and ysi = subj
and yd = neg
0 otherwise
Where f(j) is the jth dimension of the feature space.
For each feature, a set of back-off features are in-
cluded that only consider the document label yd, the
current sentence label ysi , the current sentence and
document label ysi and yd, and the current and pre-
vious sentence labels ysi and ysi�1. Note that through
these back-off features the joint models feature set
will subsume the feature set of any individual level
model. Only features observed in the training data
were considered. Depending on the data set, the di-
mension of the feature vector f ranged from 350K to
500K. Though the feature vectors can be sparse, the
feature weights will be learned using large-margin
techniques that are well known to be robust to large
and sparse feature representations.
</bodyText>
<subsectionHeader confidence="0.778827">
2.1.3 Training the Model
</subsectionHeader>
<bodyText confidence="0.9999748125">
Let Y = Y(d) x Y(s)n be the set of all valid
sentence-document labelings for an input s. The
weights, w, are set using the MIRA learning al-
gorithm, which is an inference based online large-
margin learning technique (Crammer and Singer,
2003; McDonald et al., 2005). An advantage of this
algorithm is that it relies only on inference to learn
the weight vector (see Section 2.1.1). MIRA has
been shown to provide state-of-the-art accuracy for
many language processing tasks including parsing,
chunking and entity extraction (McDonald, 2006).
The basic algorithm is outlined in Figure 3. The
algorithm works by considering a single training in-
stance during each iteration. The weight vector w is
updated in line 4 through a quadratic programming
problem. This update modifies the weight vector so
</bodyText>
<equation confidence="0.946234">
f(j)(yd,ysi�1,ysi ,s) =
</equation>
<page confidence="0.979217">
435
</page>
<table confidence="0.782520727272727">
Training data: T = {(yt, st)}Tt�1
1. w(°) = 0; i = 0
2. for n : 1..N
3. fort : 1..T ‚
‚ ‚
4. w(i+1) = arg minw* ‚w* − w(i)‚ ‚
s.t. score(yt, st) − score(y&apos;, s) &gt; L(yt, y&apos;)
relative to w*
`dy&apos; E C C Y, where |C |= k
5. i = i + 1
6. return w(NXT)
</table>
<figureCaption confidence="0.972249333333333">
Figure 3: MIRA learning algorithm.
that the score of the correct labeling is larger than
the score of every labeling in a constraint set C with
</figureCaption>
<bodyText confidence="0.964322352941177">
a margin proportional to the loss. The constraint set
C can be chosen arbitrarily, but it is usually taken to
be the k labelings that have the highest score under
the old weight vector w(z) (McDonald et al., 2005).
In this manner, the learning algorithm can update its
parameters relative to those labelings closest to the
decision boundary. Of all the weight vectors that sat-
isfy these constraints, MIRA chooses the one that is
as close as possible to the previous weight vector in
order to retain information about previous updates.
The loss function L(y, y&apos;) is a positive real val-
ued function and is equal to zero when y = y&apos;. This
function is task specific and is usually the hamming
loss for sequence classification problems (Taskar et
al., 2003). Experiments with different loss functions
for the joint sentence-document model on a develop-
ment data set indicated that the hamming loss over
sentence labels multiplied by the 0-1 loss over doc-
ument labels worked best.
An important modification that was made to the
learning algorithm deals with how the k constraints
are chosen for the optimization. Typically these con-
straints are the k highest scoring labelings under the
current weight vector. However, early experiments
showed that the model quickly learned to discard
any labeling with an incorrect document label for
the instances in the training set. As a result, the con-
straints were dominated by labelings that only dif-
fered over sentence labels. This did not allow the al-
gorithm adequate opportunity to set parameters rel-
ative to incorrect document labeling decisions. To
combat this, k was divided by the number of doc-
ument labels, to get a new value k&apos;. For each doc-
ument label, the k&apos; highest scoring labelings were
</bodyText>
<page confidence="0.652076">
436
</page>
<figureCaption confidence="0.8678655">
Figure 4: An extension to the model from Figure 1
incorporating paragraph level analysis.
extracted. Each of these sets were then combined to
produce the final constraint set. This allowed con-
straints to be equally distributed amongst different
document labels.
Based on performance on the development data
set the number of training iterations was set to N =
5 and the number of constraints to k = 10. Weight
averaging was also employed (Collins, 2002), which
helped improve performance.
2.2 Beyond Two-Level Models
</figureCaption>
<bodyText confidence="0.993441464285714">
To this point, we have focused solely on a model for
two-level fine-to-coarse sentiment analysis not only
for simplicity, but because the experiments in Sec-
tion 3 deal exclusively with this scenario. In this
section, we briefly discuss possible extensions for
more complex situations. For example, longer doc-
uments might benefit from an analysis on the para-
graph level as well as the sentence and document
levels. One possible model for this case is given
in Figure 4, which essentially inserts an additional
layer between the sentence and document level from
the original model. Sentence level analysis is de-
pendent on neighbouring sentences as well as the
paragraph level analysis, and the paragraph anal-
ysis is dependent on each of the sentences within
it, the neighbouring paragraphs, and the document
level analysis. This can be extended to an arbitrary
level of fine-to-coarse sentiment analysis by simply
inserting new layers in this fashion to create more
complex hierarchical models.
The advantage of using hierarchical models of
this form is that they are nested, which keeps in-
ference tractable. Observe that each pair of adja-
cent levels in the model is equivalent to the origi-
nal model from Figure 1. As a result, the scores
of the every label at each node in the graph can
be calculated with a straight-forward bottom-up dy-
namic programming algorithm. Details are omitted
</bodyText>
<table confidence="0.999530833333333">
Sentence Stats Document Stats
Pos Neg Neu Tot Pos Neg Tot
472 443 264 1179 98 80 178
568 635 371 1574 92 97 189
485 464 214 1163 98 89 187
1525 1542 849 3916 288 266 554
</table>
<subsectionHeader confidence="0.95694">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.992982">
Three baseline systems were created,
</bodyText>
<listItem confidence="0.976354">
• Document-Classifier is a classifier that learns
to predict the document label only.
</listItem>
<note confidence="0.4300135">
Car
Fit
Mp3
Tot
</note>
<tableCaption confidence="0.924938">
Table 1: Data statistics for corpus. Pos = positive
polarity, Neg = negative polarity, Neu = no polarity.
</tableCaption>
<bodyText confidence="0.99018925">
for space reasons.
Other models are possible where dependencies
occur across non-neighbouring levels, e.g., by in-
serting edges between the sentence level nodes and
the document level node. In the general case, infer-
ence is exponential in the size of each clique. Both
the models in Figure 1 and Figure 4 have maximum
clique sizes of three.
</bodyText>
<sectionHeader confidence="0.999069" genericHeader="introduction">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996441">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.999526925925926">
To test the model we compiled a corpus of 600 on-
line product reviews from three domains: car seats
for children, fitness equipment, and Mp3 players. Of
the original 600 reviews that were gathered, we dis-
carded duplicate reviews, reviews with insufficient
text, and spam. All reviews were labeled by on-
line customers as having a positive or negative polar-
ity on the document level, i.e., Y(d) _ {pos, neg}.
Each review was then split into sentences and ev-
ery sentence annotated by a single annotator as ei-
ther being positive, negative or neutral, i.e., Y( s) _
{pos, neg, neu}. Data statistics for the corpus are
given in Table 1.
All sentences were annotated based on their con-
text within the document. Sentences were anno-
tated as neutral if they conveyed no sentiment or had
indeterminate sentiment from their context. Many
neutral sentences pertain to the circumstances un-
der which the product was purchased. A common
class of sentences were those containing product
features. These sentences were annotated as having
positive or negative polarity if the context supported
it. This could include punctuation such as excla-
mation points, smiley/frowny faces, question marks,
etc. The supporting evidence could also come from
another sentence, e.g., “I love it. It has 64Mb of
memory and comes with a set of earphones”.
</bodyText>
<listItem confidence="0.873162888888889">
• Sentence-Classifier is a classifier that learns
to predict sentence labels in isolation of one
another, i.e., without consideration for either
the document or neighbouring sentences sen-
timent.
• Sentence-Structured is another sentence clas-
sifier, but this classifier uses a sequential chain
model to learn and classify sentences. The
third baseline is essentially the model from Fig-
</listItem>
<bodyText confidence="0.99746109375">
ure 1 without the top level document node. This
baseline will help to gage the empirical gains of
the different components of the joint structured
model on sentence level classification.
The model described in Section 2 will be called
Joint-Structured. All models use the same ba-
sic predicate space: unigram, bigram, trigram con-
joined with part-of-speech, plus back-offs of these
(see Section 2.1.2 for more). However, due to the
structure of the model and its label space, the feature
space of each might be different, e.g., the document
classifier will only conjoin predicates with the doc-
ument label to create the feature set. All models are
trained using the MIRA learning algorithm.
Results for each model are given in the first four
rows of Table 2. These results were gathered using
10-fold cross validation with one fold for develop-
ment and the other nine folds for evaluation. This
table shows that classifying sentences in isolation
from one another is inferior to accounting for a more
global context. A significant increase in perfor-
mance can be obtained when labeling decisions be-
tween sentences are modeled (Sentence-Structured).
More interestingly, even further gains can be had
when document level decisions are modeled (Joint-
Structured). In many cases, these improvements are
highly statistically significant.
On the document level, performance can also be
improved by incorporating sentence level decisions
– though these improvements are not consistent.
This inconsistency may be a result of the model
overfitting on the small set of training data. We
</bodyText>
<page confidence="0.961697">
437
</page>
<bodyText confidence="0.988068632653061">
suspect this because the document level error rate is a slight improvement in performance suggesting
on the Mp3 training set converges to zero much that an iterative approach might be beneficial. That
more rapidly for the Joint-Structured model than the is, a system could start by classifying documents,
Document-Classifier. This suggests that the Joint- use the document information to classify sentences,
Structured model might be relying too much on use the sentence information to classify documents,
the sentence level sentiment features – in order to and repeat until convergence. However, experiments
minimize its error rate – instead of distributing the showed that this did not improve accuracy over a sin-
weights across all features more evenly. gle iteration and often hurt performance.
One interesting application of sentence level sen- Improvements from the cascaded models are far
timent analysis is summarizing product reviews on less consistent than those given from the joint struc-
retail websites like Amazon.com or review aggrega- ture model. This is because decisions in the cas-
tors like Yelp.com. In this setting the correct polar- caded system are passed to the next layer as the
ity of a document is often known, but we wish to “gold” standard at test time, which results in errors
label sentiment on the sentence or phrase level to from the first classifier propagating to errors in the
aid in generating a cohesive and informative sum- second. This could be improved by passing a lattice
mary. The joint model can be used to classify sen- of possibilities from the first classifier to the second
tences in this setting by constraining inference to the with corresponding confidences. However, solutions
known fixed document label for a review. If this is such as these are really just approximations of the
done, then sentiment accuracy on the sentence level joint structured model that was presented here.
increases substantially from 62.6% to 70.3%. 4 Future Work
Finally we should note that experiments using One important extension to this work is to augment
CRFs to train the structured models and logistic re- the models for partially labeled data. It is realistic
gression to train the local models yielded similar re- to imagine a training set where many examples do
sults to those in Table 2. not have every level of sentiment annotated. For
3.2.1 Cascaded Models example, there are thousands of online product re-
Another approach to fine-to-coarse sentiment views with labeled document sentiment, but a much
analysis is to use a cascaded system. In such a sys- smaller amount where sentences are also labeled.
tem, a sentence level classifier might first be run Work on learning with hidden variables can be used
on the data, and then the results input into a docu- for both CRFs (Quattoni et al., 2004) and for in-
ment level classifier – or vice-versa.&apos; Two cascaded ference based learning algorithms like those used in
systems were built. The first uses the Sentence- this work (Liang et al., 2006).
Structured classifier to classify all the sentences Another area of future work is to empirically in-
from a review, then passes this information to the vestigate the use of these models on longer docu-
document classifier as input. In particular, for ev- ments that require more levels of sentiment anal-
ery predicate in the original document classifier, an ysis than product reviews. In particular, the rela-
additional predicate that specifies the polarity of the tive position of a phrase to a contrastive discourse
sentence in which this predicate occurred was cre- connective or a cue phrase like “in conclusion” or
ated. The second cascaded system uses the docu- “to summarize” may lead to improved performance
ment classifier to determine the global polarity, then since higher level classifications can learn to weigh
passes this information as input into the Sentence- information passed from these lower level compo-
Structured model, constructing predicates in a simi- nents more heavily.
lar manner. 5 Discussion
The results for these two systems can be seen in In this paper we have investigated the use of a global
the last two rows of Table 2. In both cases there structured model that learns to predict sentiment on
different levels of granularity for a text. We de-
&apos;Alternatively, decisions from the sentence classifier can
guide which input is seen by the document level classifier (Pang
and Lee, 2004).
438
</bodyText>
<table confidence="0.920227428571429">
Document-Classifier
Sentence-Classifier
Sentence-Structured
Joint-Structured
Sentence Accuracy Document Accuracy
Car Fit Mp3 Total Car Fit Mp3 Total
- - - - 72.8 80.1 87.2 80.3
54.8 56.8 49.4 53.1 - - - -
60.5 61.4 55.7 58.8 - - - -
63.5* 65.2** 60.1** 62.6** 81.5* 81.9 85.0 82.8
60.5 61.4 55.7 58.8 75.9 80.7 86.1 81.1
59.7 61.0 58.3 59.5 72.8 80.1 87.2 80.3
Cascaded Sentence --+ Document
Cascaded Document --+ Sentence
</table>
<tableCaption confidence="0.907231">
Table 2: Fine-to-coarse sentiment accuracy. Significance calculated using McNemar’s test between top two
performing systems. *Statistically significant p &lt; 0.05. **Statistically significant p &lt; 0.005.
</tableCaption>
<bodyText confidence="0.9992543">
scribed a simple model for sentence-document anal-
ysis and showed that inference in it is tractable. Ex-
periments show that this model obtains higher ac-
curacy than classifiers trained in isolation as well
as cascaded systems that pass information from one
level to another at test time. Furthermore, extensions
to the sentence-document model were discussed and
it was argued that a nested hierarchical structure
would be beneficial since it would allow for efficient
inference algorithms.
</bodyText>
<sectionHeader confidence="0.999046" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999615938461539">
Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. 2005. Identi-
fying sources of opinions with conditional random fields and
extraction patterns. In Proc. HLT/EMNLP.
Y. Choi, E. Breck, and C. Cardie. 2006. Joint extraction of enti-
ties and relations for opinion recognition. In Proc. EMNLP.
M. Collins. 2002. Discriminative training methods for hidden
Markov models: Theory and experiments with perceptron
algorithms. In Proc. EMNLP.
K. Crammer and Y. Singer. 2003. Ultraconservative online
algorithms for multiclass problems. JMLR.
Hal Daum´e III, John Langford, and Daniel Marcu. 2006.
Search-based structured prediction. In Submission.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional
random fields: Probabilistic models for segmenting and la-
beling sequence data. In Proc. ICML.
P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar. 2006. An
end-to-end discriminative approach to machine translation.
In Proc. ACL.
Y. Mao and G. Lebanon. 2006. Isotonic conditional random
fields and local sentiment flow. In Proc. NIPS.
R. McDonald, K. Crammer, and F. Pereira. 2005. Online large-
margin training of dependency parsers. In Proc. ACL.
R. McDonald. 2006. Discriminative Training and Spanning
Tree Algorithms for Dependency Parsing. Ph.D. thesis, Uni-
versity of Pennsylvania.
S. Miller, H. Fox, L.A. Ramshaw, and R.M. Weischedel. 2000.
A novel use of statistical parsing to extract information from
text. In Proc NAACL, pages 226–233.
B. Pang and L. Lee. 2004. A sentimental education: Sen-
timent analysis using subjectivity summarization based on
minimum cuts. In Proc. ACL.
B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up?
Sentiment classification using machine learning techniques.
In EMNLP.
A. Popescu and O. Etzioni. 2005. Extracting product features
and opinions from reviews. In Proc. HLT/EMNLP.
A. Quattoni, M. Collins, and T. Darrell. 2004. Conditional
random fields for object recognition. In Proc. NIPS.
L. R. Rabiner. 1989. A tutorial on hidden Markov models and
selected applications in speech recognition. Proceedings of
the IEEE, 77(2):257–285, February.
D. Roth and W. Yih. 2004. A linear programming formula-
tion for global inference in natural language tasks. In Proc.
CoNLL.
C. Sutton and A. McCallum. 2006. An introduction to con-
ditional random fields for relational learning. In L. Getoor
and B. Taskar, editors, Introduction to Statistical Relational
Learning. MIT Press.
C. Sutton, K. Rohanimanesh, and A. McCallum. 2004. Dy-
namic conditional random fields: Factorized probabilistic
models for labeling and segmenting sequence data. In Proc.
ICML.
B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin
Markov networks. In Proc. NIPS.
B. Taskar, D. Klein, M. Collins, D. Koller, and C. Manning.
2004. Max-margin parsing. In Proc. EMNLP.
M. Thomas, B. Pang, and L. Lee. 2006. Get out the vote:
Determining support or opposition from congressional floor-
debate transcripts. In Proc. EMNLP.
I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. 2004.
Support vector learning for interdependent and structured
output spaces. In Proc. ICML.
P. Turney. 2002. Thumbs up or thumbs down? Sentiment ori-
entation applied to unsupervised classification of reviews. In
EMNLP.
</reference>
<page confidence="0.999261">
439
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.732264">
<title confidence="0.998912">Structured Models for Fine-to-Coarse Sentiment Analysis</title>
<author confidence="0.999857">Kerry Hannan Tyler Neylon Mike Wells Jeff Reynar</author>
<affiliation confidence="0.993817">Google, Inc.</affiliation>
<address confidence="0.9995885">76 Ninth Avenue New York, NY 10011</address>
<email confidence="0.99276"></email>
<abstract confidence="0.981480071428571">In this paper we investigate a structured model for jointly classifying the sentiment of text at varying levels of granularity. Inference in the model is based on standard sequence classification techniques using constrained Viterbi to ensure consistent solutions. The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>C Cardie</author>
<author>E Riloff</author>
<author>S Patwardhan</author>
</authors>
<title>Identifying sources of opinions with conditional random fields and extraction patterns.</title>
<date>2005</date>
<booktitle>In Proc. HLT/EMNLP.</booktitle>
<contexts>
<context position="1125" citStr="Choi et al., 2005" startWordPosition="165" endWordPosition="168"> model is that it allows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation. 1 Introduction Extracting sentiment from text is a challenging problem with applications throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product reviews might require polarity classification at the sentence or phrase level; a question answering system wo</context>
<context position="3993" citStr="Choi et al. (2005" startWordPosition="628" endWordPosition="631">ation for Computational Linguistics for a piece of fitness equipment, where hard essen- labeling or chunking, but have also been applied to tially means good workout. In this domain, hard’s parsing (Taskar et al., 2004; McDonald et al., 2005), sentiment can only be determined in context (i.e., machine translation (Liang et al., 2006) and summahard to assemble versus a hard workout). If the clas- rization (Daum´e III et al., 2006). sifier knew the overall sentiment of a document, then Structured models have previously been used for disambiguating such cases would be easier. sentiment analysis. Choi et al. (2005, 2006) use Conversely, document level analysis can benefit CRFs to learn a global sequence model to classify from finer level classification by taking advantage and assign sources to opinions. Mao and Lebanon of common discourse cues, such as the last sentence (2006) used a sequential CRF regression model to being a reliable indicator for overall sentiment in re- measure polarity on the sentence level in order to views. Furthermore, during training, the model will determine the sentiment flow of authors in reviews. not need to modify its parameters to explain phe- Here we show that fine-to-co</context>
</contexts>
<marker>Choi, Cardie, Riloff, Patwardhan, 2005</marker>
<rawString>Y. Choi, C. Cardie, E. Riloff, and S. Patwardhan. 2005. Identifying sources of opinions with conditional random fields and extraction patterns. In Proc. HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>E Breck</author>
<author>C Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition. In</title>
<date>2006</date>
<booktitle>Proc. EMNLP.</booktitle>
<contexts>
<context position="1145" citStr="Choi et al., 2006" startWordPosition="169" endWordPosition="172">llows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation. 1 Introduction Extracting sentiment from text is a challenging problem with applications throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product reviews might require polarity classification at the sentence or phrase level; a question answering system would most likely requ</context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Y. Choi, E. Breck, and C. Cardie. 2006. Joint extraction of entities and relations for opinion recognition. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="7662" citStr="Collins, 2002" startWordPosition="1199" endWordPosition="1200">s. with structured learning algorithms. Hidden Markov 2 Structured Model models (Rabiner, 1989) are one of the earliest struc- In this section we present a structured model for tured learning algorithms, which have recently been fine-to-coarse sentiment analysis. We start by examfollowed by discriminative learning approaches such ining the simple case with two-levels of granularity as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the 2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the feaants (Taskar et al., 2003; Tsochantaridis et al., 2004; ture space and give an algorithm for learning the paMcDonald et al., 2005; Daum´e III et al., 2006). rameters based on large-margin structured learning. These algorithms are usually applied to sequential 433 Extensions to the model are also examined. 2.1 A Sentence-Document Model Let Y(d) be a discrete set of sentiment labels at the document level and Y(s) be a discrete set of sentiment labels at the sentence level. As input a system is given a document contain</context>
<context position="10418" citStr="Collins, 2002" startWordPosition="1665" endWordPosition="1666">ver, jointly modeling the document label and allowing for non-binary labels complicates min-cut style solutions as inference becomes intractable. Learning and inference in undirected graphical models is a well studied problem in machine learning and NLP. For example, CRFs define the probability over the labels conditioned on the input using the property that the joint probability distribution over the labels factors over clique potentials in undirected graphical models (Lafferty et al., 2001). Figure 1: Sentence and document level model. In this work we will use structured linear classifiers (Collins, 2002). We denote the score of a labeling y for an input s as score(y, s) and define this score as the sum of scores over each clique, score(y, s) = score((yd, ys), s) = score((yd, ys 1, ... , ys n), s) n = score(y , yi_1, yis , s) d s i=2 where each clique score is a linear combination of features and their weights, score(yd, ysi�1, ysi , s) = w · f(yd, ysi�1, ysi , s) (1) and f is a high dimensional feature representation of the clique and w a corresponding weight vector. Note that s is included in each score since it is given as input and can always be conditioned on. In general, inference in und</context>
<context position="18517" citStr="Collins, 2002" startWordPosition="3101" endWordPosition="3102">sions. To combat this, k was divided by the number of document labels, to get a new value k&apos;. For each document label, the k&apos; highest scoring labelings were 436 Figure 4: An extension to the model from Figure 1 incorporating paragraph level analysis. extracted. Each of these sets were then combined to produce the final constraint set. This allowed constraints to be equally distributed amongst different document labels. Based on performance on the development data set the number of training iterations was set to N = 5 and the number of constraints to k = 10. Weight averaging was also employed (Collins, 2002), which helped improve performance. 2.2 Beyond Two-Level Models To this point, we have focused solely on a model for two-level fine-to-coarse sentiment analysis not only for simplicity, but because the experiments in Section 3 deal exclusively with this scenario. In this section, we briefly discuss possible extensions for more complex situations. For example, longer documents might benefit from an analysis on the paragraph level as well as the sentence and document levels. One possible model for this case is given in Figure 4, which essentially inserts an additional layer between the sentence </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>Y Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<publisher>JMLR.</publisher>
<contexts>
<context position="15353" citStr="Crammer and Singer, 2003" startWordPosition="2549" endWordPosition="2552">dividual level model. Only features observed in the training data were considered. Depending on the data set, the dimension of the feature vector f ranged from 350K to 500K. Though the feature vectors can be sparse, the feature weights will be learned using large-margin techniques that are well known to be robust to large and sparse feature representations. 2.1.3 Training the Model Let Y = Y(d) x Y(s)n be the set of all valid sentence-document labelings for an input s. The weights, w, are set using the MIRA learning algorithm, which is an inference based online largemargin learning technique (Crammer and Singer, 2003; McDonald et al., 2005). An advantage of this algorithm is that it relies only on inference to learn the weight vector (see Section 2.1.1). MIRA has been shown to provide state-of-the-art accuracy for many language processing tasks including parsing, chunking and entity extraction (McDonald, 2006). The basic algorithm is outlined in Figure 3. The algorithm works by considering a single training instance during each iteration. The weight vector w is updated in line 4 through a quadratic programming problem. This update modifies the weight vector so f(j)(yd,ysi�1,ysi ,s) = 435 Training data: T </context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>K. Crammer and Y. Singer. 2003. Ultraconservative online algorithms for multiclass problems. JMLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e John Langford</author>
<author>Daniel Marcu</author>
</authors>
<title>Search-based structured prediction. In Submission.</title>
<date>2006</date>
<marker>Langford, Marcu, 2006</marker>
<rawString>Hal Daum´e III, John Langford, and Daniel Marcu. 2006. Search-based structured prediction. In Submission.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In</title>
<date>2001</date>
<booktitle>Proc. ICML.</booktitle>
<contexts>
<context position="10301" citStr="Lafferty et al., 2001" startWordPosition="1644" endWordPosition="1647">stency constraints were created between every sentence in a document and inference was solved using a min-cut algorithm. However, jointly modeling the document label and allowing for non-binary labels complicates min-cut style solutions as inference becomes intractable. Learning and inference in undirected graphical models is a well studied problem in machine learning and NLP. For example, CRFs define the probability over the labels conditioned on the input using the property that the joint probability distribution over the labels factors over clique potentials in undirected graphical models (Lafferty et al., 2001). Figure 1: Sentence and document level model. In this work we will use structured linear classifiers (Collins, 2002). We denote the score of a labeling y for an input s as score(y, s) and define this score as the sum of scores over each clique, score(y, s) = score((yd, ys), s) = score((yd, ys 1, ... , ys n), s) n = score(y , yi_1, yis , s) d s i=2 where each clique score is a linear combination of features and their weights, score(yd, ysi�1, ysi , s) = w · f(yd, ysi�1, ysi , s) (1) and f is a high dimensional feature representation of the clique and w a corresponding weight vector. Note that </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proc. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>A Bouchard-Cote</author>
<author>D Klein</author>
<author>B Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="3711" citStr="Liang et al., 2006" startWordPosition="582" endWordPosition="585">arder than it looks. In isolation, this sentence appears to convey negative sentiment. However, it is part of a favorable review 432 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 432–439, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics for a piece of fitness equipment, where hard essen- labeling or chunking, but have also been applied to tially means good workout. In this domain, hard’s parsing (Taskar et al., 2004; McDonald et al., 2005), sentiment can only be determined in context (i.e., machine translation (Liang et al., 2006) and summahard to assemble versus a hard workout). If the clas- rization (Daum´e III et al., 2006). sifier knew the overall sentiment of a document, then Structured models have previously been used for disambiguating such cases would be easier. sentiment analysis. Choi et al. (2005, 2006) use Conversely, document level analysis can benefit CRFs to learn a global sequence model to classify from finer level classification by taking advantage and assign sources to opinions. Mao and Lebanon of common discourse cues, such as the last sentence (2006) used a sequential CRF regression model to being a</context>
<context position="27066" citStr="Liang et al., 2006" startWordPosition="4497" endWordPosition="4500">re thousands of online product reAnother approach to fine-to-coarse sentiment views with labeled document sentiment, but a much analysis is to use a cascaded system. In such a sys- smaller amount where sentences are also labeled. tem, a sentence level classifier might first be run Work on learning with hidden variables can be used on the data, and then the results input into a docu- for both CRFs (Quattoni et al., 2004) and for inment level classifier – or vice-versa.&apos; Two cascaded ference based learning algorithms like those used in systems were built. The first uses the Sentence- this work (Liang et al., 2006). Structured classifier to classify all the sentences Another area of future work is to empirically infrom a review, then passes this information to the vestigate the use of these models on longer docudocument classifier as input. In particular, for ev- ments that require more levels of sentiment analery predicate in the original document classifier, an ysis than product reviews. In particular, the relaadditional predicate that specifies the polarity of the tive position of a phrase to a contrastive discourse sentence in which this predicate occurred was cre- connective or a cue phrase like “i</context>
</contexts>
<marker>Liang, Bouchard-Cote, Klein, Taskar, 2006</marker>
<rawString>P. Liang, A. Bouchard-Cote, D. Klein, and B. Taskar. 2006. An end-to-end discriminative approach to machine translation. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mao</author>
<author>G Lebanon</author>
</authors>
<title>Isotonic conditional random fields and local sentiment flow.</title>
<date>2006</date>
<booktitle>In Proc. NIPS.</booktitle>
<contexts>
<context position="1338" citStr="Mao and Lebanon, 2006" startWordPosition="200" endWordPosition="203">ls trained in isolation. 1 Introduction Extracting sentiment from text is a challenging problem with applications throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product reviews might require polarity classification at the sentence or phrase level; a question answering system would most likely require the sentiment of paragraphs; and a system that determines which articles from an online news source are editorial in nature would require a document level analysis. This work focuses on mod</context>
</contexts>
<marker>Mao, Lebanon, 2006</marker>
<rawString>Y. Mao and G. Lebanon. 2006. Isotonic conditional random fields and local sentiment flow. In Proc. NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Online largemargin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="3618" citStr="McDonald et al., 2005" startWordPosition="568" endWordPosition="571"> tandem. Consider the sentence, My 11 year old daughter has also been using it and it is a lot harder than it looks. In isolation, this sentence appears to convey negative sentiment. However, it is part of a favorable review 432 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 432–439, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics for a piece of fitness equipment, where hard essen- labeling or chunking, but have also been applied to tially means good workout. In this domain, hard’s parsing (Taskar et al., 2004; McDonald et al., 2005), sentiment can only be determined in context (i.e., machine translation (Liang et al., 2006) and summahard to assemble versus a hard workout). If the clas- rization (Daum´e III et al., 2006). sifier knew the overall sentiment of a document, then Structured models have previously been used for disambiguating such cases would be easier. sentiment analysis. Choi et al. (2005, 2006) use Conversely, document level analysis can benefit CRFs to learn a global sequence model to classify from finer level classification by taking advantage and assign sources to opinions. Mao and Lebanon of common disco</context>
<context position="7870" citStr="McDonald et al., 2005" startWordPosition="1231" endWordPosition="1235">s, which have recently been fine-to-coarse sentiment analysis. We start by examfollowed by discriminative learning approaches such ining the simple case with two-levels of granularity as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the 2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the feaants (Taskar et al., 2003; Tsochantaridis et al., 2004; ture space and give an algorithm for learning the paMcDonald et al., 2005; Daum´e III et al., 2006). rameters based on large-margin structured learning. These algorithms are usually applied to sequential 433 Extensions to the model are also examined. 2.1 A Sentence-Document Model Let Y(d) be a discrete set of sentiment labels at the document level and Y(s) be a discrete set of sentiment labels at the sentence level. As input a system is given a document containing sentences s = s1, ... , sn and must produce sentiment labels for the document, yd E Y(d), and each individual sentence, ys = ys1, ... , ysn, where ysi E Y(s) V 1 G i G n. Define y = (yd, ys) = (yd, ys1, .</context>
<context position="15377" citStr="McDonald et al., 2005" startWordPosition="2553" endWordPosition="2556"> features observed in the training data were considered. Depending on the data set, the dimension of the feature vector f ranged from 350K to 500K. Though the feature vectors can be sparse, the feature weights will be learned using large-margin techniques that are well known to be robust to large and sparse feature representations. 2.1.3 Training the Model Let Y = Y(d) x Y(s)n be the set of all valid sentence-document labelings for an input s. The weights, w, are set using the MIRA learning algorithm, which is an inference based online largemargin learning technique (Crammer and Singer, 2003; McDonald et al., 2005). An advantage of this algorithm is that it relies only on inference to learn the weight vector (see Section 2.1.1). MIRA has been shown to provide state-of-the-art accuracy for many language processing tasks including parsing, chunking and entity extraction (McDonald, 2006). The basic algorithm is outlined in Figure 3. The algorithm works by considering a single training instance during each iteration. The weight vector w is updated in line 4 through a quadratic programming problem. This update modifies the weight vector so f(j)(yd,ysi�1,ysi ,s) = 435 Training data: T = {(yt, st)}Tt�1 1. w(°)</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>R. McDonald, K. Crammer, and F. Pereira. 2005. Online largemargin training of dependency parsers. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
</authors>
<title>Discriminative Training and Spanning Tree Algorithms for Dependency Parsing.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="15652" citStr="McDonald, 2006" startWordPosition="2596" endWordPosition="2597">robust to large and sparse feature representations. 2.1.3 Training the Model Let Y = Y(d) x Y(s)n be the set of all valid sentence-document labelings for an input s. The weights, w, are set using the MIRA learning algorithm, which is an inference based online largemargin learning technique (Crammer and Singer, 2003; McDonald et al., 2005). An advantage of this algorithm is that it relies only on inference to learn the weight vector (see Section 2.1.1). MIRA has been shown to provide state-of-the-art accuracy for many language processing tasks including parsing, chunking and entity extraction (McDonald, 2006). The basic algorithm is outlined in Figure 3. The algorithm works by considering a single training instance during each iteration. The weight vector w is updated in line 4 through a quadratic programming problem. This update modifies the weight vector so f(j)(yd,ysi�1,ysi ,s) = 435 Training data: T = {(yt, st)}Tt�1 1. w(°) = 0; i = 0 2. for n : 1..N 3. fort : 1..T ‚ ‚ ‚ 4. w(i+1) = arg minw* ‚w* − w(i)‚ ‚ s.t. score(yt, st) − score(y&apos;, s) &gt; L(yt, y&apos;) relative to w* `dy&apos; E C C Y, where |C |= k 5. i = i + 1 6. return w(NXT) Figure 3: MIRA learning algorithm. that the score of the correct labeli</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>R. McDonald. 2006. Discriminative Training and Spanning Tree Algorithms for Dependency Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Miller</author>
<author>H Fox</author>
<author>L A Ramshaw</author>
<author>R M Weischedel</author>
</authors>
<title>A novel use of statistical parsing to extract information from text.</title>
<date>2000</date>
<booktitle>In Proc NAACL,</booktitle>
<pages>226--233</pages>
<contexts>
<context position="6182" citStr="Miller et al., 2000" startWordPosition="973" endWordPosition="976">ine-to-coarse analysis should differs from that in Pang and Lee through the use of account for this. a single joint structured model for both sentence and In Section 2 we describe a simple structured document level analysis. model that jointly learns and infers sentiment on dif- Many problems in natural language processing ferent levels of granularity. In particular, we reduce can be improved by learning and/or predicting multhe problem of joint sentence and document level tiple outputs jointly. This includes parsing and relaanalysis to a sequential classification problem us- tion extraction (Miller et al., 2000), entity labeling ing constrained Viterbi inference. Extensions to the and relation extraction (Roth and Yih, 2004), and model that move beyond just two-levels of analysis part-of-speech tagging and chunking (Sutton et al., are also presented. In Section 3 an empirical eval- 2004). One interesting work on sentiment analysis uation of the model is given that shows significant is that of Popescu and Etzioni (2005) which attempts gains in accuracy over both single level classifiers to classify the sentiment of phrases with respect to and cascaded systems. possible product features. To do this an </context>
</contexts>
<marker>Miller, Fox, Ramshaw, Weischedel, 2000</marker>
<rawString>S. Miller, H. Fox, L.A. Ramshaw, and R.M. Weischedel. 2000. A novel use of statistical parsing to extract information from text. In Proc NAACL, pages 226–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="1075" citStr="Pang and Lee, 2004" startWordPosition="157" endWordPosition="160">onsistent solutions. The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation. 1 Introduction Extracting sentiment from text is a challenging problem with applications throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product reviews might require polarity classification at the senten</context>
<context position="4910" citStr="Pang and Lee (2004)" startWordPosition="776" endWordPosition="779">ion model to being a reliable indicator for overall sentiment in re- measure polarity on the sentence level in order to views. Furthermore, during training, the model will determine the sentiment flow of authors in reviews. not need to modify its parameters to explain phe- Here we show that fine-to-coarse models of sentinomena like the typically positive word great ap- ment can often be reduced to the sequential case. pearing in a negative text (as is the case above). The Cascaded models for fine-to-coarse sentiment model can also avoid overfitting to features derived analysis were studied by Pang and Lee (2004). In from neutral or objective sentences. In fact, it has al- that work an initial model classified each sentence ready been established that sentence level classifica- as being subjective or objective using a global mintion can improve document level analysis (Pang and cut inference algorithm that considered local labelLee, 2004). This line of reasoning suggests that a ing consistencies. The top subjective sentences are cascaded approach would also be insufficient. Valu- then input into a standard document level polarity able information is passed in both directions, which classifier with imp</context>
<context position="8568" citStr="Pang and Lee (2004)" startWordPosition="1362" endWordPosition="1365"> These algorithms are usually applied to sequential 433 Extensions to the model are also examined. 2.1 A Sentence-Document Model Let Y(d) be a discrete set of sentiment labels at the document level and Y(s) be a discrete set of sentiment labels at the sentence level. As input a system is given a document containing sentences s = s1, ... , sn and must produce sentiment labels for the document, yd E Y(d), and each individual sentence, ys = ys1, ... , ysn, where ysi E Y(s) V 1 G i G n. Define y = (yd, ys) = (yd, ys1, . ..,ysn) as the joint labeling of the document and sentences. For instance, in Pang and Lee (2004), yd would be the polarity of the document and ysi would indicate whether sentence si is subjective or objective. The models presented here are compatible with arbitrary sets of discrete output labels. Figure 1 presents a model for jointly classifying the sentiment of both the sentences and the document. In this undirected graphical model, the label of each sentence is dependent on the labels of its neighbouring sentences plus the label of the document. The label of the document is dependent on the label of every sentence. Note that the edges between the input (each sentence) and the output la</context>
<context position="28479" citStr="Pang and Lee, 2004" startWordPosition="4727" endWordPosition="4730">ications can learn to weigh passes this information as input into the Sentence- information passed from these lower level compoStructured model, constructing predicates in a simi- nents more heavily. lar manner. 5 Discussion The results for these two systems can be seen in In this paper we have investigated the use of a global the last two rows of Table 2. In both cases there structured model that learns to predict sentiment on different levels of granularity for a text. We de&apos;Alternatively, decisions from the sentence classifier can guide which input is seen by the document level classifier (Pang and Lee, 2004). 438 Document-Classifier Sentence-Classifier Sentence-Structured Joint-Structured Sentence Accuracy Document Accuracy Car Fit Mp3 Total Car Fit Mp3 Total - - - - 72.8 80.1 87.2 80.3 54.8 56.8 49.4 53.1 - - - - 60.5 61.4 55.7 58.8 - - - - 63.5* 65.2** 60.1** 62.6** 81.5* 81.9 85.0 82.8 60.5 61.4 55.7 58.8 75.9 80.7 86.1 81.1 59.7 61.0 58.3 59.5 72.8 80.1 87.2 80.3 Cascaded Sentence --+ Document Cascaded Document --+ Sentence Table 2: Fine-to-coarse sentiment accuracy. Significance calculated using McNemar’s test between top two performing systems. *Statistically significant p &lt; 0.05. **Statist</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>B. Pang and L. Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1019" citStr="Pang et al., 2002" startWordPosition="149" endWordPosition="152">ation techniques using constrained Viterbi to ensure consistent solutions. The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation. 1 Introduction Extracting sentiment from text is a challenging problem with applications throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product rev</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Popescu</author>
<author>O Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proc. HLT/EMNLP.</booktitle>
<contexts>
<context position="6597" citStr="Popescu and Etzioni (2005)" startWordPosition="1037" endWordPosition="1040">nd/or predicting multhe problem of joint sentence and document level tiple outputs jointly. This includes parsing and relaanalysis to a sequential classification problem us- tion extraction (Miller et al., 2000), entity labeling ing constrained Viterbi inference. Extensions to the and relation extraction (Roth and Yih, 2004), and model that move beyond just two-levels of analysis part-of-speech tagging and chunking (Sutton et al., are also presented. In Section 3 an empirical eval- 2004). One interesting work on sentiment analysis uation of the model is given that shows significant is that of Popescu and Etzioni (2005) which attempts gains in accuracy over both single level classifiers to classify the sentiment of phrases with respect to and cascaded systems. possible product features. To do this an iterative al1.1 Related Work gorithm is used that attempts to globally maximize The models in this work fall into the broad class of the classification of all phrases while satisfying local global structured models, which are typically trained consistency constraints. with structured learning algorithms. Hidden Markov 2 Structured Model models (Rabiner, 1989) are one of the earliest struc- In this section we pre</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>A. Popescu and O. Etzioni. 2005. Extracting product features and opinions from reviews. In Proc. HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Quattoni</author>
<author>M Collins</author>
<author>T Darrell</author>
</authors>
<title>Conditional random fields for object recognition. In</title>
<date>2004</date>
<booktitle>Proc. NIPS.</booktitle>
<contexts>
<context position="26870" citStr="Quattoni et al., 2004" startWordPosition="4464" endWordPosition="4467">he local models yielded similar re- to imagine a training set where many examples do sults to those in Table 2. not have every level of sentiment annotated. For 3.2.1 Cascaded Models example, there are thousands of online product reAnother approach to fine-to-coarse sentiment views with labeled document sentiment, but a much analysis is to use a cascaded system. In such a sys- smaller amount where sentences are also labeled. tem, a sentence level classifier might first be run Work on learning with hidden variables can be used on the data, and then the results input into a docu- for both CRFs (Quattoni et al., 2004) and for inment level classifier – or vice-versa.&apos; Two cascaded ference based learning algorithms like those used in systems were built. The first uses the Sentence- this work (Liang et al., 2006). Structured classifier to classify all the sentences Another area of future work is to empirically infrom a review, then passes this information to the vestigate the use of these models on longer docudocument classifier as input. In particular, for ev- ments that require more levels of sentiment analery predicate in the original document classifier, an ysis than product reviews. In particular, the re</context>
</contexts>
<marker>Quattoni, Collins, Darrell, 2004</marker>
<rawString>A. Quattoni, M. Collins, and T. Darrell. 2004. Conditional random fields for object recognition. In Proc. NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L R Rabiner</author>
</authors>
<title>A tutorial on hidden Markov models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<volume>77</volume>
<issue>2</issue>
<contexts>
<context position="7143" citStr="Rabiner, 1989" startWordPosition="1121" endWordPosition="1122">s given that shows significant is that of Popescu and Etzioni (2005) which attempts gains in accuracy over both single level classifiers to classify the sentiment of phrases with respect to and cascaded systems. possible product features. To do this an iterative al1.1 Related Work gorithm is used that attempts to globally maximize The models in this work fall into the broad class of the classification of all phrases while satisfying local global structured models, which are typically trained consistency constraints. with structured learning algorithms. Hidden Markov 2 Structured Model models (Rabiner, 1989) are one of the earliest struc- In this section we present a structured model for tured learning algorithms, which have recently been fine-to-coarse sentiment analysis. We start by examfollowed by discriminative learning approaches such ining the simple case with two-levels of granularity as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the 2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the feaan</context>
<context position="11178" citStr="Rabiner, 1989" startWordPosition="1812" endWordPosition="1813">e((yd, ys), s) = score((yd, ys 1, ... , ys n), s) n = score(y , yi_1, yis , s) d s i=2 where each clique score is a linear combination of features and their weights, score(yd, ysi�1, ysi , s) = w · f(yd, ysi�1, ysi , s) (1) and f is a high dimensional feature representation of the clique and w a corresponding weight vector. Note that s is included in each score since it is given as input and can always be conditioned on. In general, inference in undirected graphical models is intractable. However, for the common case of sequences (a.k.a. linear-chain models) the Viterbi algorithm can be used (Rabiner, 1989; Lafferty et al., 2001). Fortunately there is a simple technique that reduces inference in the above model to sequence classification with a constrained version of Viterbi. 2.1.1 Inference as Sequential Labeling The inference problem is to find the highest scoring labeling y for an input s, i.e., arg max score(y, s) Y If the document label yd is fixed, then inference in the model from Figure 1 reduces to the sequential case. This is because the search space is only over the sentence labels ysi , whose graphical structure forms a chain. Thus the problem of finding the 434 Input: s = sl, ... , </context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L. R. Rabiner. 1989. A tutorial on hidden Markov models and selected applications in speech recognition. Proceedings of the IEEE, 77(2):257–285, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Proc. CoNLL.</booktitle>
<contexts>
<context position="6297" citStr="Roth and Yih, 2004" startWordPosition="989" endWordPosition="992">structured model for both sentence and In Section 2 we describe a simple structured document level analysis. model that jointly learns and infers sentiment on dif- Many problems in natural language processing ferent levels of granularity. In particular, we reduce can be improved by learning and/or predicting multhe problem of joint sentence and document level tiple outputs jointly. This includes parsing and relaanalysis to a sequential classification problem us- tion extraction (Miller et al., 2000), entity labeling ing constrained Viterbi inference. Extensions to the and relation extraction (Roth and Yih, 2004), and model that move beyond just two-levels of analysis part-of-speech tagging and chunking (Sutton et al., are also presented. In Section 3 an empirical eval- 2004). One interesting work on sentiment analysis uation of the model is given that shows significant is that of Popescu and Etzioni (2005) which attempts gains in accuracy over both single level classifiers to classify the sentiment of phrases with respect to and cascaded systems. possible product features. To do this an iterative al1.1 Related Work gorithm is used that attempts to globally maximize The models in this work fall into t</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Proc. CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sutton</author>
<author>A McCallum</author>
</authors>
<title>An introduction to conditional random fields for relational learning.</title>
<date>2006</date>
<editor>In L. Getoor and B. Taskar, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7567" citStr="Sutton and McCallum, 2006" startWordPosition="1185" endWordPosition="1188">phrases while satisfying local global structured models, which are typically trained consistency constraints. with structured learning algorithms. Hidden Markov 2 Structured Model models (Rabiner, 1989) are one of the earliest struc- In this section we present a structured model for tured learning algorithms, which have recently been fine-to-coarse sentiment analysis. We start by examfollowed by discriminative learning approaches such ining the simple case with two-levels of granularity as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the 2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the feaants (Taskar et al., 2003; Tsochantaridis et al., 2004; ture space and give an algorithm for learning the paMcDonald et al., 2005; Daum´e III et al., 2006). rameters based on large-margin structured learning. These algorithms are usually applied to sequential 433 Extensions to the model are also examined. 2.1 A Sentence-Document Model Let Y(d) be a discrete set of sentiment labels at the document level and Y(s) be a discre</context>
</contexts>
<marker>Sutton, McCallum, 2006</marker>
<rawString>C. Sutton and A. McCallum. 2006. An introduction to conditional random fields for relational learning. In L. Getoor and B. Taskar, editors, Introduction to Statistical Relational Learning. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sutton</author>
<author>K Rohanimanesh</author>
<author>A McCallum</author>
</authors>
<title>Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data. In</title>
<date>2004</date>
<booktitle>Proc. ICML.</booktitle>
<marker>Sutton, Rohanimanesh, McCallum, 2004</marker>
<rawString>C. Sutton, K. Rohanimanesh, and A. McCallum. 2004. Dynamic conditional random fields: Factorized probabilistic models for labeling and segmenting sequence data. In Proc. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>C Guestrin</author>
<author>D Koller</author>
</authors>
<title>Max-margin Markov networks.</title>
<date>2003</date>
<booktitle>In Proc. NIPS.</booktitle>
<contexts>
<context position="7766" citStr="Taskar et al., 2003" startWordPosition="1214" endWordPosition="1217"> one of the earliest struc- In this section we present a structured model for tured learning algorithms, which have recently been fine-to-coarse sentiment analysis. We start by examfollowed by discriminative learning approaches such ining the simple case with two-levels of granularity as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the 2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the feaants (Taskar et al., 2003; Tsochantaridis et al., 2004; ture space and give an algorithm for learning the paMcDonald et al., 2005; Daum´e III et al., 2006). rameters based on large-margin structured learning. These algorithms are usually applied to sequential 433 Extensions to the model are also examined. 2.1 A Sentence-Document Model Let Y(d) be a discrete set of sentiment labels at the document level and Y(s) be a discrete set of sentiment labels at the sentence level. As input a system is given a document containing sentences s = s1, ... , sn and must produce sentiment labels for the document, yd E Y(d), and each i</context>
<context position="17077" citStr="Taskar et al., 2003" startWordPosition="2861" endWordPosition="2864">t have the highest score under the old weight vector w(z) (McDonald et al., 2005). In this manner, the learning algorithm can update its parameters relative to those labelings closest to the decision boundary. Of all the weight vectors that satisfy these constraints, MIRA chooses the one that is as close as possible to the previous weight vector in order to retain information about previous updates. The loss function L(y, y&apos;) is a positive real valued function and is equal to zero when y = y&apos;. This function is task specific and is usually the hamming loss for sequence classification problems (Taskar et al., 2003). Experiments with different loss functions for the joint sentence-document model on a development data set indicated that the hamming loss over sentence labels multiplied by the 0-1 loss over document labels worked best. An important modification that was made to the learning algorithm deals with how the k constraints are chosen for the optimization. Typically these constraints are the k highest scoring labelings under the current weight vector. However, early experiments showed that the model quickly learned to discard any labeling with an incorrect document label for the instances in the tr</context>
</contexts>
<marker>Taskar, Guestrin, Koller, 2003</marker>
<rawString>B. Taskar, C. Guestrin, and D. Koller. 2003. Max-margin Markov networks. In Proc. NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Taskar</author>
<author>D Klein</author>
<author>M Collins</author>
<author>D Koller</author>
<author>C Manning</author>
</authors>
<title>Max-margin parsing.</title>
<date>2004</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="3594" citStr="Taskar et al., 2004" startWordPosition="564" endWordPosition="567">ssifies each level in tandem. Consider the sentence, My 11 year old daughter has also been using it and it is a lot harder than it looks. In isolation, this sentence appears to convey negative sentiment. However, it is part of a favorable review 432 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 432–439, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics for a piece of fitness equipment, where hard essen- labeling or chunking, but have also been applied to tially means good workout. In this domain, hard’s parsing (Taskar et al., 2004; McDonald et al., 2005), sentiment can only be determined in context (i.e., machine translation (Liang et al., 2006) and summahard to assemble versus a hard workout). If the clas- rization (Daum´e III et al., 2006). sifier knew the overall sentiment of a document, then Structured models have previously been used for disambiguating such cases would be easier. sentiment analysis. Choi et al. (2005, 2006) use Conversely, document level analysis can benefit CRFs to learn a global sequence model to classify from finer level classification by taking advantage and assign sources to opinions. Mao and</context>
</contexts>
<marker>Taskar, Klein, Collins, Koller, Manning, 2004</marker>
<rawString>B. Taskar, D. Klein, M. Collins, D. Koller, and C. Manning. 2004. Max-margin parsing. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thomas</author>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Get out the vote: Determining support or opposition from congressional floordebate transcripts.</title>
<date>2006</date>
<booktitle>In Proc. EMNLP.</booktitle>
<contexts>
<context position="1449" citStr="Thomas et al., 2006" startWordPosition="221" endWordPosition="224"> throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product reviews might require polarity classification at the sentence or phrase level; a question answering system would most likely require the sentiment of paragraphs; and a system that determines which articles from an online news source are editorial in nature would require a document level analysis. This work focuses on models that jointly classify sentiment on multiple levels of granularity. Consider the following example, This is </context>
</contexts>
<marker>Thomas, Pang, Lee, 2006</marker>
<rawString>M. Thomas, B. Pang, and L. Lee. 2006. Get out the vote: Determining support or opposition from congressional floordebate transcripts. In Proc. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Tsochantaridis</author>
<author>T Hofmann</author>
<author>T Joachims</author>
<author>Y Altun</author>
</authors>
<title>Support vector learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proc. ICML.</booktitle>
<contexts>
<context position="7795" citStr="Tsochantaridis et al., 2004" startWordPosition="1218" endWordPosition="1221">struc- In this section we present a structured model for tured learning algorithms, which have recently been fine-to-coarse sentiment analysis. We start by examfollowed by discriminative learning approaches such ining the simple case with two-levels of granularity as conditional random fields (CRFs) (Lafferty et al., – the sentence and document – and show that the 2001; Sutton and McCallum, 2006), the structured problem can be reduced to sequential classification perceptron (Collins, 2002) and its large-margin vari- with constrained inference. We then discuss the feaants (Taskar et al., 2003; Tsochantaridis et al., 2004; ture space and give an algorithm for learning the paMcDonald et al., 2005; Daum´e III et al., 2006). rameters based on large-margin structured learning. These algorithms are usually applied to sequential 433 Extensions to the model are also examined. 2.1 A Sentence-Document Model Let Y(d) be a discrete set of sentiment labels at the document level and Y(s) be a discrete set of sentiment labels at the sentence level. As input a system is given a document containing sentences s = s1, ... , sn and must produce sentiment labels for the document, yd E Y(d), and each individual sentence, ys = ys1,</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>I. Tsochantaridis, T. Hofmann, T. Joachims, and Y. Altun. 2004. Support vector learning for interdependent and structured output spaces. In Proc. ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Turney</author>
</authors>
<title>Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1034" citStr="Turney, 2002" startWordPosition="153" endWordPosition="154">ing constrained Viterbi to ensure consistent solutions. The primary advantage of such a model is that it allows classification decisions from one level in the text to influence decisions at another. Experiments show that this method can significantly reduce classification error relative to models trained in isolation. 1 Introduction Extracting sentiment from text is a challenging problem with applications throughout Natural Language Processing and Information Retrieval. Previous work on sentiment analysis has covered a wide range of tasks, including polarity classification (Pang et al., 2002; Turney, 2002), opinion extraction (Pang and Lee, 2004), and opinion source assignment (Choi et al., 2005; Choi et al., 2006). Furthermore, these systems have tackled the problem at different levels of granularity, from the document level (Pang et al., 2002), sentence level (Pang and Lee, 2004; Mao and Lebanon, 2006), phrase level (Turney, 2002; Choi et al., 2005), as well as the speaker level in debates (Thomas et al., 2006). The ability to classify sentiment on multiple levels is important since different applications have different needs. For example, a summarization system for product reviews might requ</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>P. Turney. 2002. Thumbs up or thumbs down? Sentiment orientation applied to unsupervised classification of reviews. In EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>