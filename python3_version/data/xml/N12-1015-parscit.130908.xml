<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.996666">
Structured Perceptron with Inexact Search
</title>
<author confidence="0.997483">
Liang Huang Suphan Fayong Yang Guo
</author>
<affiliation confidence="0.996519">
Information Sciences Institute Dept. of Computer Science Bloomberg L.P.
University of Southern California University of Southern California New York, NY
</affiliation>
<email confidence="0.996084">
liang.huang.sh@gmail.com suphan.ying@gmail.com yangg86@gmail.com
</email>
<sectionHeader confidence="0.993884" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998710263157895">
Most existing theory of structured prediction
assumes exact inference, which is often in-
tractable in many practical problems. This
leads to the routine use of approximate infer-
ence such as beam search but there is not much
theory behind it. Based on the structured
perceptron, we propose a general framework
of “violation-fixing” perceptrons for inexact
search with a theoretical guarantee for conver-
gence under new separability conditions. This
framework subsumes and justifies the pop-
ular heuristic “early-update” for perceptron
with beam search (Collins and Roark, 2004).
We also propose several new update meth-
ods within this framework, among which the
“max-violation” method dramatically reduces
training time (by 3 fold as compared to early-
update) on state-of-the-art part-of-speech tag-
ging and incremental parsing systems.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962230769231">
Discriminative structured prediction algorithms
such as conditional random fields (Lafferty et al.,
2001), structured perceptron (Collins, 2002), max-
margin markov networks (Taskar et al., 2003), and
structural SVMs (Tsochantaridis et al., 2005) lead
to state-of-the-art performance on many structured
prediction problems such as part-of-speech tagging,
sequence labeling, and parsing. But despite their
success, there remains a major problem: these learn-
ing algorithms all assume exact inference (over an
exponentially-large search space), which is needed
to ensure their theoretical properties such as conver-
gence. This exactness assumption, however, rarely
holds in practice since exact inference is often in-
tractable in many important problems such as ma-
chine translation (Liang et al., 2006), incremen-
tal parsing (Collins and Roark, 2004; Huang and
Sagae, 2010), and bottom-up parsing (McDonald
and Pereira, 2006; Huang, 2008). This leads to
routine use of approximate inference such as beam
search as evidenced in the above-cited papers, but
the inexactness unfortunately abandons existing the-
oretical guarantees of the learning algorithms, and
besides notable exceptions discussed below and in
Section 7, little is known for theoretical properties
of structured prediction under inexact search.
Among these notable exceptions, many exam-
ine how and which approximations break theoretical
guarantees of existing learning algorithms (Kulesza
and Pereira, 2007; Finley and Joachims, 2008), but
we ask a deeper and practically more useful ques-
tion: can we modify existing learning algorithms to
accommodate the inexactness in inference, so that
the theoretical properties are still maintained?
For the structured perceptron, Collins and Roark
(2004) provides a partial answer: they suggest vari-
ant called “early update” for beam search, which up-
dates on partial hypotheses when the correct solution
falls out of the beam. This method works signif-
icantly better than standard perceptron, and is fol-
lowed by later incremental parsers, for instance in
(Zhang and Clark, 2008; Huang and Sagae, 2010).
However, two problems remain: first, up till now
there has been no theoretical justification for early
update; and secondly, it makes learning extremely
slow as witnessed by the above-cited papers because
it only learns on partial examples and often requires
15–40 iterations to converge while normal percep-
tron converges in 5–10 iterations (Collins, 2002).
We develop a theoretical framework of “violation-
fixing” perceptron that addresses these challenges.
In particular, we make the following contributions:
</bodyText>
<listItem confidence="0.608696">
• We show that, somewhat surprisingly, exact
</listItem>
<page confidence="0.651587333333333">
142
2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 142–151,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</page>
<bodyText confidence="0.999194">
search is not required by perceptron conver-
gence. All we need is that each update involves
a “violation”, i.e., the 1-best sequence has a
higher model score than the correct sequence.
Such an update is considered a “valid update”,
and any perceptron variant that maintains this
is bound to converge. We call these variants
“violation-fixing perceptrons” (Section 3.1).
</bodyText>
<listItem confidence="0.835303333333334">
• This theory explains why standard perceptron
update may fail to work with inexact search,
because violation is no longer guaranteed: the
correct structure might indeed be preferred by
the model, but was pruned during the search
process (Sec. 3.2). Such an update is thus con-
sidered invalid, and experiments show that in-
valid updates lead to bad learning (Sec. 6.2).
• We show that the early update is always valid
and is thus a special case in our framework; this
is the first theoretical justification for early up-
date (Section 4). We also show that (a variant
of) LaSO (Daum´e and Marcu, 2005) is another
special case (Section 7).
• We then propose several other update meth-
ods within this framework (Section 5). Experi-
ments in Section 6 confirm that among them,
the max-violation method can learn equal or
better models with dramatically reduced learn-
ing times (by 3 fold as compared to early
update) on state-of-the-art part-of-speech tag-
ging (Collins, 2002)1 and incremental parsing
(Huang and Sagae, 2010) systems. We also
found strong correlation between search error
and invalid updates, suggesting that the ad-
vantage of valid update methods is more pro-
nounced with harder inference problems.
</listItem>
<bodyText confidence="0.994805">
Our techniques are widely applicable to other str-
cutured prediction problems which require inexact
search like machine translation and protein folding.
</bodyText>
<sectionHeader confidence="0.960594" genericHeader="introduction">
2 Structured Perceptron
</sectionHeader>
<bodyText confidence="0.9400245">
We review the convergence properties of the stan-
dard structured perceptron (Collins, 2002) in our
1Incidentally, we achieve the best POS tagging accuracy to
date (97.35%) on English Treebank by early update (Sec. 6.1).
</bodyText>
<construct confidence="0.4209952">
Algorithm 1 Structured Perceptron (Collins, 2002).
Input: data D = {(x(t), y(t))}t1 and feature map 4)
Output: weight vector w
Let: EXACT(x, w) =� argmax3∈Y(x) w · 4)(x, s)
Let: 04)(x, y, z) �=4)(x, y) −4)(x, z)
</construct>
<listItem confidence="0.971937833333333">
1: repeat
2: for each example (x, y) in D do
3: z ← EXACT(x, w)
4: if z =6 y then
5: w ← w + 04)(x, y, z)
6: until converged
</listItem>
<bodyText confidence="0.74229125">
own notations that will be reused in later sections
for non-exact search. We first define a new concept:
Definition 1. The standard confusion set Cs(D)
for training data D = {(x(t), y(t))}n t=1 is the set of
</bodyText>
<equation confidence="0.873832">
triples (x, y, z) where z is a wrong label for input x:
Cs(D) Δ= {(x, y, z)  |(x, y) ∈ D, z ∈ Y(x) − {y}}.
</equation>
<bodyText confidence="0.914210733333333">
The rest of the theory, including separation and
violation, all builds upon this concept. We call such
a triple 5 = hD, 4), Ci a training scenario, and
in the remainder of this section, we assume C =
Cs(D), though later we will define other confusion
sets to accommodate other update methods.
Definition 2. The training scenario 5 = hD, 4), Ci
is said to be linearly separable (i.e., dataset D is
linearly separable in C by representation 4)) with
margin S &gt; 0 if there exists an oracle vector u
with kuk = 1 such that it can correctly classify
all examples in D (with a gap of at least S), i.e.,
∀(x, y, z) ∈ C, u · 04)(x, y, z) ≥ S. We define
the maximal margin S(5) to be the maximal such
margin over all unit oracle vectors:
</bodyText>
<equation confidence="0.99527">
S(5) Δ = max min
JIu11=1 (x,y,z)∈C
</equation>
<bodyText confidence="0.682669428571429">
Definition 3. A triple (x, y, z) is said to be a vi-
olation in training scenario 5 = hD, 4), Ci with
respect to weight vector w if (x, y, z) ∈ C and
w · 04)(x, y, z) ≤ 0.
Intuitively, this means model w is possible to mis-
label example x (though not necessarily to z) since
y is not its single highest scoring label under w.
</bodyText>
<construct confidence="0.790268">
Lemma 1. Each update triple (x, y, z) in Algo-
rithm 1 (line 5) is a violation in 5 = hD, 4), Cs(D)i.
</construct>
<equation confidence="0.821602333333333">
u · 04)(x, y, z).
143
Proof. z = EXACT(x, w), thus for all z′ E Y(x),
w·4)(x, z) &gt; w·4)(x, z′), i.e., w·A4)(x, y, z) &lt; 0.
On the other hand, z E Y(x) and z =� y, so
(x, y, z) E Cs(D).
</equation>
<bodyText confidence="0.9386419">
This lemma basically says exact search guaran-
tees violation in each update, but as we will see in
the convergence proof, violation itself is more fun-
damental than search exactness.
Definition 4. The diameter R(S) for scenario S =
(D, 4), C) is max(�,y,z)∈CIIA4)(x, y, z)II.
Theorem 1(convergence, Collins). For a separable
training scenario S = (D, 4), Cs(D)) with δ(S) &gt;
0, the perceptron algorithm in Algorithm 1 will make
finite number of updates (before convergence):
</bodyText>
<equation confidence="0.777998">
err(S) &lt; R2(S)/δ2(S).
</equation>
<bodyText confidence="0.77938725">
Proof. Let w(k) be the weight vector before the kth
update; w(0) = 0. Suppose the kth update happens
on the triple (x, y, z). We will bound IIw(k+1)II from
two directions:
</bodyText>
<listItem confidence="0.998752846153846">
1. w(k+1) = w(k) + A4)(x, y, z). Since scenario
S is separable with max margin δ(S), there ex-
ists a unit oracle vector u that achieves this
margin. Dot product both sides with u, we have
u · w(k+1) = u · w(k) + u · A4)(x, y, z)
&gt; u · w(k) + δ(S)
by Lemma 1 that (x, y, z) E Cs(D) and by the
definition of margin. By induction, we have
u · w(k+1) &gt; kδ(S). Since for any two vec-
tors a and b we have IIaIIIIbII &gt; a · b, thus
IIuIIIIw(k+1)II &gt; u · w(k+1) &gt; kδ(S). As u is
a unit vector, we have IIw(k+1)II &gt; kδ(S).
2. On the other hand, since IIa + bII2 = IIaII2 +
</listItem>
<equation confidence="0.9658996">
IIbII2 + 2 a · b for any vectors a and b,we have
IIw(k+1)II2 = IIw(k) + A4)(x, y, z)II2
= IIw(k)II2 + IIA4)(x,y,z)II2
+ 2 w(k) · A4)(x, y, z)
&lt; IIw(k)II2 + R2(S) + 0 .
</equation>
<bodyText confidence="0.726487857142857">
By Lemma 1, the update triple is a violation so
that w(k)·A4)(x, y, z) &lt; 0, and that (x, y, z) E
Cs(D) thus IIA4)(x,y,z)II2 &lt; R2(S) by the
definition of diameter. By induction, we have
IIw(k+1)II2 &lt; kR2(S).
Algorithm 2 Local Violation-Fixing Perceptron.
Input: training scenario S = (D, 4), C)
</bodyText>
<listItem confidence="0.976251833333333">
1: repeat
2: for each example (x, y) in D do
3: (x, y′, z) = FINDVIOLATION(x, y, w)
4: if z =� y then ⊲ (x, y′, z) is a violation
5: w &lt;-- w + A4)(x, y′, z)
6: until converged
</listItem>
<bodyText confidence="0.9514975">
Combining the two bounds, we have k2δ2(S) &lt;
IIw(k+1)II2 &lt; kR2(S), thus k &lt; R2(S)/δ2(S).
</bodyText>
<sectionHeader confidence="0.846616" genericHeader="method">
3 Violation is All We Need
</sectionHeader>
<bodyText confidence="0.999828875">
We now draw the central observation of this work
from part 2 of the above proof: note that exact search
(argmax) is not required in the proof, instead, it
just needs a violation, which is a much weaker con-
dition.2 Exact search is simply used to ensure viola-
tion. In other words, if we can guarantee violation in
each update (which we call “valid update”), it does
not matter whether or how exact the search is.
</bodyText>
<subsectionHeader confidence="0.999172">
3.1 Violation-Fixing Perceptron
</subsectionHeader>
<bodyText confidence="0.991581476190476">
This observation leads us to two generalized vari-
ants of perceptron which we call “violation-fixing
perceptrons”. The local version, Algorithm 2 still
works on one example at a time, and searches for
one violation (if any) in that example to update with.
The global version, Algorithm 3, can update on any
violation in the dataset at any time. We state the fol-
lowing generalized theorem:
Theorem 2. For a separable training scenario S
the perceptrons in Algorithms 2 and 3 both con-
verge with the same update bounds of R2(S)/δ2(S)
as long as the FINDVIOLATION and FINDVIO-
LATIONINDATA functions always return violation
triples if there are any.
Proof. Same as the proof to Theorem 1, except for
replacing Lemma 1 in part 2 by the fact that the up-
date triples are guaranteed to be violations. (Note a
violation triple is by definition in the confusion set,
thus we can still use separation and diameter).
These generic violation-fixing perceptron algo-
rithms can been seen as “interfaces” (or APIs),
</bodyText>
<footnote confidence="0.565003">
2Crammer and Singer (2003) further demonstrates that a
convex combination of violations can also be used for update.
</footnote>
<page confidence="0.989919">
144
</page>
<figure confidence="0.931387684210527">
Algorithm 3 Global Violation-Fixing Perceptron.
Input: training scenario S = hD, Φ, Ci
1: repeat
2: (x, y, z) ← FINDVIOLATIONINDATA(C, w)
3: if x = ǫ then break ⊲ no more violation?
4: w ← w + 0Φ(x, y, z)
5: until converged
data D = {(x, y)}:
x fruit flies fly .
y N N V .
search space: Y(x) = {N} × {N, V} × {N, V} × {.}.
feature map: Φ(x, y) = (#N1N(y), #V1.(y)).
iter label z 0Φ(x, y, z) w·0Φ new w
0 (0,0)
1 NNN. (−1, +1) 0 √ (−1, 1)
2 NVN. (+1, +1) 0 √ (0,2)
3 NNN. (−1, +1) 2 × (−1,3)
4 NVN. (+1, +1) 2 × (0,4)
... infinite loop ...
</figure>
<figureCaption confidence="0.993943333333333">
Figure 1: Example that standard perceptron does not
converge with greedy search on a separable scenario
(e.g. u = (1, 2) can separate D with exact search).
</figureCaption>
<bodyText confidence="0.9999728">
where later sections will supply different implemen-
tations of the FINDVIOLATION and FINDVIOLA-
TIONINDATA subroutines, thus establishing alterna-
tive update methods for inexact search as special
cases in this general framework.
</bodyText>
<subsectionHeader confidence="0.999853">
3.2 Non-Convergence with Inexact Search
</subsectionHeader>
<bodyText confidence="0.999989875">
What if we can not guarantee valid updates? Well,
the convergence proof in Theorems 1 and 2 would
break in part 2. This is exactly why standard struc-
tured perceptron may not work well with inexact
search: with search errors it is no longer possible
to guarantee violation in each update. For example,
an inexact search method explores a (proper) subset
of the search space Y,&apos;(x) C Y(x), and finds a label
</bodyText>
<equation confidence="0.9844515">
z = argmax w · Φ(x, s).
sEY′„(x)
</equation>
<bodyText confidence="0.9805965">
It is possible that the correct label y is outside of
the explored subspace, and yet has a higher score:
</bodyText>
<equation confidence="0.759695875">
AΦ(x, y, z) &gt; 0 but y ∈/ Y,&apos;(x). In this case,
(x, y, z) is not a violation, which breaks the proof.
We show below that this situation actually exists.
Algorithm 4 Greedy Search.
Let: NEXT(x, z) = D {z ◦ a  |a ∈ Y|z|+1(x)} ⊲ set of
possible one-step extensions (successors)
D
BEST(x, z, w) = argmaxz′∈NEXT(x,z) w · Φ(x, z′)
</equation>
<listItem confidence="0.892037666666667">
⊲ best one-step extension based on history
1: function GREEDYSEARCH(x, w)
2: z ← ǫ ⊲ empty sequence
3: for i ∈ 1 ... |x |do
4: z ← BEST(x, z, w)
5: return z
</listItem>
<bodyText confidence="0.967899260869565">
Theorem 3. For a separable training scenario S =
hD, Φ, Cs(D)i, if the argmax in Algorithm 1 is not
exact, the perceptron might not converge.
Proof. See the example in Figure 1.
This situation happens very often in NLP: of-
ten the search space Y(x) is too big either because
it does not factor locally, or because it is still too
big after factorization, which requires some approxi-
mate search. In either case, updating the model w on
a non-violation (i.e., “invalid”) triple (x, y, z) does
not make sense: it is not the model’s problem: w
does score the correct label y higher than the incor-
rect z; rather, it is a problem of the search, or its
interaction with the model that prunes away the cor-
rect (sub)sequence during the search.
What shall we do in this case? Collins and
Roark (2004) suggest that instead of the standard
full update, we should only update on the prefix
(x, y[1:i], z[1:i]) up to the point i where the correct
sequence falls off the beam. This intuitively makes
a lot of sense, since up to i we can still guarantee
violation, but after i we may not. The next section
formalizes this intuition.
</bodyText>
<sectionHeader confidence="0.964083" genericHeader="method">
4 Early Update is Violation-Fixing
</sectionHeader>
<bodyText confidence="0.99995975">
We now proceed to show that early update is always
valid and it is thus a special case of the violation-
fixing perceptron framework. First, let us study the
simplest special case, greedy search (beam=1).
</bodyText>
<subsectionHeader confidence="0.997059">
4.1 Greedy Search and Early Update
</subsectionHeader>
<bodyText confidence="0.9999415">
Greedy search is the simplest form of inexact search.
Shown in Algorithm 4, at each position, we com-
mit to the single best action (e.g., tag for the current
word) given the previous actions and continue to the
</bodyText>
<page confidence="0.9794">
145
</page>
<figure confidence="0.904104">
√ √ · · · √ ×
←− update −→ skip −→
Algorithm 6 Alternative presentation of Alg. 5 as a
Local Violation-Fixing Perceptron (Alg. 2).
</figure>
<figureCaption confidence="0.957262">
Figure 2: Early update at the first error in greedy search.
</figureCaption>
<bodyText confidence="0.754723333333333">
Algorithm 5 Early update for greedy search adapted
from Collins and Roark (2004).
Input: training scenario S = hD, 4?, Cg(D)i
</bodyText>
<listItem confidence="0.964919222222222">
1: repeat
2: for each example (x, y) in D do
3: z ← e &gt; empty sequence
4: for i ∈ 1 ... |x |do
5: z ← BEST(x, z, w)
6: if zi =6 yi then &gt; first wrong action
7: w ← w + A4?(x, y[1:i], z) &gt; early update
8: break &gt; skip the rest of this example
9: until converged
</listItem>
<bodyText confidence="0.9911146">
next position. The notation Yi(x) denotes the set of
possible actions at position i for example x (for in-
stance, the set of possible tags for a word).
The early update heuristic, originally proposed for
beam search (Collins and Roark, 2004), now simpli-
fies into “update at the first wrong action”, since this
is exactly the place where the correct sequence falls
off the singleton beam (see Algorithm 5 for pseu-
docode and Fig. 2). Informally, it is easy to show
(below) that this kind of update is always a valid vi-
olation, but we need to redefine confusion set.
Definition 5. The greedy confusion set Cg(D) for
training data D = {(x(t), y(t))}nt=1 is the set of
triples (x, y[1:i], z[1:i]) where y[1:i] is a i-prefix of the
correct label y, and z[1:i] is an incorrect i-prefix that
agrees with the correct prefix on all decisions except
the last one:
We can see intuitively that this new defintion
is specially tailored to the early updates in greedy
search. The concepts of separation/margin, viola-
tion, and diameter all change accordingly with this
new confusion set. In particular, we say that a
dataset D is greedily separable in representation
4? if and only if hD, 4?, Cg(D)i is linearly separa-
ble, and we say (x, y′, z′) is a greedy violation if
</bodyText>
<listItem confidence="0.90235025">
(x, y′, z′) ∈ Cg(D) and w · A4?(x, y′, z′) ≤ 0.
1: function FINDVIOLATION(x, y, w)
2: z ← e &gt; empty sequence
3: for i ∈ 1 ... |x |do
4: z ← BEST(x, z, w)
5: if zi =6 yi then &gt; first wrong action
6: return (x, y[1:i], z) &gt; return for early update
7: return (x, y, y) &gt; success (z = y), no violation
</listItem>
<bodyText confidence="0.999515166666667">
We now express early update for greedy search
(Algorithm 5) in terms of violation-fixing percep-
tron. Algorithm 6 implements the FINDVIOLATION
function for the generic Local Violation-Fixing Per-
ceptron in Algorithm 2. Thus Algorithm 5 is equiv-
alent to Algorithm 6 plugged into Algorithm 2.
</bodyText>
<construct confidence="0.529207">
Lemma 2. Each triple (x, y[1:i], z) returned at line 6
in Algorithm 6 is a greedy violation.
</construct>
<bodyText confidence="0.951555583333333">
Proof. Let y′ = y[1:i]. Clearly at line 6, |y′ |= i =
|z |and y′i =6 zi. But y′j = zj for all j &lt; i otherwise it
would have returned before position i, so (x, y′, z) ∈
Cg(D). Also z = BEST(x, z, w), so w · 4?(x, z) ≥
w · 4?(x, y′), thus w · A4?(x, y′, z) ≤ 0.
Theorem 4 (convergence of greedy search with
early update). For a separable training scenario
S = hD, 4?, Cg(D)i, the early update perceptron
by plugging Algorithm 6 into Algorithm 2 will make
finite number of updates (before convergence):
err(S) &lt; R2(S)/δ2(S).
Proof. By Lemma 2 and Theorem 2.
</bodyText>
<subsectionHeader confidence="0.998562">
4.2 Beam Search and Early Update
</subsectionHeader>
<bodyText confidence="0.99870025">
To formalize beam search, we need some notations:
Definition 6 (k-best). We denote argtopkzEZ f(z)
to return (a sorted list of) the top k unique z in terms
of f(z), i.e., it returns a list B = [z(1), z(2),... , z(k)I
where z(i) ∈ Z and f(z(1)) ≥ f(z(2)) ≥ . . . ≥
f(z(k)) ≥ f(z′) for all z′ ∈ Z − B.
By unique we mean that no two elements are
equivalent with respect to some equivalence relation,
i.e., z(i) ≡ z(j) ⇒ i = j. This equivalence rela-
tion is useful for dynamic programming (when used
with beam search). For example, in trigram tagging,
two tag sequences are equivalent if they are of the
</bodyText>
<equation confidence="0.893077833333333">
Cg(D) Δ {(x, y[1:i], z[1:i])  |(x, y, z) ∈ Cs(D),
1 ≤ i ≤ |y|, z[1:i−1] = y[1:i−1], zi =6 yi}.
146
Algorithm 7 Beam-Search.
BESTk(x,B,w) = argtopkz′EUz∈BNEXT(z)w·4)(x,z′)
⊲ top k (unique) extensions from the beam
</equation>
<listItem confidence="0.936042642857143">
1: function BEAMSEARCH(x, w, k) ⊲ k is beam width
2: B0 ← [ǫ] ⊲ initial beam
3: for i ∈ 1 ... |x |do
4: Bi ← BESTk(x,Bi−1, w)
5: return B|.,|[0] ⊲ best sequence in the final beam
Algorithm 8 Early update for beam search (Collins
and Roark 04) as Local Violation-Fixing Perceptron.
1: function FINDVIOLATION(x, y, w)
2: B0 ← [ǫ]
3: for i ∈ 1 ... |x |do
4: Bi ← BESTk(x, Bi−1, w)
5: if y[1:i] ∈/ Bi then ⊲ correct seq. falls off beam
6: return (x, y[1:i],Bi[0]) ⊲ update on prefix
7: return (x, y, B|.,|[0]) ⊲ full update if wrong final
</listItem>
<bodyText confidence="0.9842114">
same length and if they agree on the last two tags,
i.e. z ≡ z′ iff. |z |= |z′ |and z|z|_1:|z |= z′|z|_1:|z|. In
incremental parsing this equivalence relation could
be relevant bits of information on the last few trees
on the stack (depending on feature templates), as
suggested in (Huang and Sagae, 2010). 3
Algorithm 7 shows the pseudocode for beam
search. It is trivial to verify that greedy search is
a special case of beam search with k = 1. However,
the definition of confusion set changes considerably:
Definition 7. The beam confusion set Cb(D) for
training data D = {(x(t), y(t))}nt�1 is the set of
triples (x, y[1:i], z[1:i]) where y[1:i] is a i-prefix of the
correct label y, and z[1:i] is an incorrect i-prefix that
differs from the correct prefix (in at least one place):
</bodyText>
<equation confidence="0.999678">
Cb(D) � {(x, y[1:i], z[1:i])  |(x, y, z) ∈ C.(D),
1 ≤ i ≤ |y|, z[1:i] =6 y[1:i]}.
</equation>
<bodyText confidence="0.9953975">
Similarly, we say that a dataset D is beam
separable in representation 4) if and only if
3Note that when checking whether the correct sequence
falls off the beam (line 5), we could either store the whole
(sub)sequence for each candidate in the beam (which is what
we do for non-DP anyway), or check if the equivalence class of
the correct sequence is in the beam, i.e. Qy[1,i�j≡ E Bi, and if
its backpointer points to Qy[1,i−1fl≡. For example, in trigram
tagging, we just check if (yi−1, yi) E Bi and if its backpointer
points to (yi−2, yi−1).
</bodyText>
<figureCaption confidence="0.9877322">
Figure 3: Illustration of various update methods: early,
max-violation, latest, and standard (full) update, in the
case when standard update is invalid (shown in red). The
rectangle denotes the beam and the blue line segments
denote the trajectory of the correct sequence.
</figureCaption>
<bodyText confidence="0.964814384615385">
hD, 4), Cb(D)i is linearly separable, and we say
(x, y′, z′) is a beam violation if (x, y′, z′) ∈ Cb(D)
and w · 04)(x, y′, z′) ≤ 0.
It is easy to verify that beam confusion set is su-
perset of both greedy and standard confusion sets:
for all dataset D, Cg(D) C Cb(D), and C.(D) C
Cb(D). This means that beam separability is the
strongest condition among the three separabilities:
Theorem 5. If a dataset D is beam separable, then
it is also greedily and (standard) linear separable.
We now present early update for beam search as
a Local Violation Fixing Perceptron in Algorithm 8.
See Figure 3 for an illustration.
</bodyText>
<construct confidence="0.6742865">
Lemma 3. Each update (lines 6 or 7 in Algorithm 8)
involves a beam violation.
</construct>
<bodyText confidence="0.995058181818182">
Proof. Case 1: early update (line 6): Let z′ = Bi[0]
and y′ = y[1:i]. Case 2: full update (line 8): Let z′ =
B|x|[0] and y′ = y. In both cases we have z′ =6 y′
and |z′ |= |y′|, thus (x, y′, z′) ∈ Cb(D). Also we
have w · 4)(x, z′) ≥ w · 4)(x, y′) by defintion of
argtop, so w · 04)(x, y′, z′) ≤ 0.
Theorem 6 (convergence of beam search with early
update). For a separable training scenario S =
hD, 4), Cb(D)i, the early update perceptron by
plugging Algorithm 8 into Algorithm 2 will make fi-
nite number of updates (before convergence):
</bodyText>
<figure confidence="0.961684470588235">
err(S) &lt; R2(S)/δ2(S).
Proof. By Lemma 3 and Theorem 2.
best in the beam
full
(standard)
early
max-
violation
latest
worst in the beam
falls off
the beam biggest
violation
last valid
update
invalid
update!
</figure>
<page confidence="0.97691">
147
</page>
<sectionHeader confidence="0.952099" genericHeader="method">
5 New Update Methods for Inexact Search
</sectionHeader>
<bodyText confidence="0.9999276">
We now propose three novel update methods for
inexact search within the framework of violation-
fixing perceptron. These methods are inspired by
early update but addresses its very limitation of slow
learning. See Figure 3 for an illustration.
</bodyText>
<listItem confidence="0.952634">
1. “hybrid” update. When the standard update
is valid (i.e., a violation), we perform it, other-
wise we perform the early update.
2. “max-violation” update. While there are
</listItem>
<bodyText confidence="0.897883">
more than one possible violations on one exam-
ple x, we choose the triple that is most violated:
</bodyText>
<equation confidence="0.978085">
(x, y*, z*) = argmin w·A4?(x, y′, z′).
(x,y′,z′)EC,z′EUi{tai[0]1
</equation>
<listItem confidence="0.943164666666667">
3. “latest” update. Contrary to early update, we
can also choose the latest point where the up-
date is still a violation:
</listItem>
<equation confidence="0.9937395">
(x, y*, z*) = argmax |z′|.
(x,y′,z′)EC,z′EUi{tai[0]1,w·o4)&apos;(x,y′,z′)&gt;0
</equation>
<bodyText confidence="0.999838583333333">
All these three methods go beyond early update
but can be represented in the Local Violation Fixing
Perceptron (Algorithm 2), and are thus all guaran-
teed to converge. As we will see in the experiments,
these new methods are motivated to address the ma-
jor limitation of early update, that is, it learns too
slowly since it only updates on prefixes and neglect
the rest of the examples. Hybrid update is trying
to do as much standard (“full”) updates as possible,
and latest update further addresses the case when
standard update is invalid: instead of backing-off to
early update, it uses the longest possible update.
</bodyText>
<sectionHeader confidence="0.998807" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999993333333333">
We conduct experiments on two typical structured
learning tasks: part-of-speech tagging with a trigram
model where exact search is possible, and incremen-
tal dependency parsing with arbitrary non-local fea-
tures where exact search is intractable. We run both
experiments on state-of-the-art implementations.
</bodyText>
<subsectionHeader confidence="0.998638">
6.1 Part-of-Speech Tagging
</subsectionHeader>
<bodyText confidence="0.999827666666667">
Following the standard split for part-of-speech tag-
ging introduced by Collins (2002), we use sec-
tions 00–18 of the Penn Treebank (Marcus et al.,
</bodyText>
<figure confidence="0.942227">
1 2 3 4 5 6 7 8 9 10
beam size
</figure>
<figureCaption confidence="0.9642345">
Figure 4: POS tagging using beam search with various
update methods (hybrid/latest similar to early; omitted).
</figureCaption>
<table confidence="0.940124">
b = 1 b = 2 b = 7
method it dev it dev it dev
standard 12 96.27 6 97.07 4 97.17
early 13 96.97 6 97.15 7 97.19
max-viol. 7 96.97 3 97.20 4 97.20
</table>
<tableCaption confidence="0.967944666666667">
Table 1: Convergence rate of part-of-speech tagging. In
general, max-violation converges faster and better than
early and standard updates, esp. in smallest beams.
</tableCaption>
<bodyText confidence="0.999000875">
1993) for training, sections 19–21 as a held-out
development set, and sections 22–24 for testing.
Our baseline system is a faithful implementation of
the perceptron tagger in Collins (2002), i.e., a tri-
gram model with spelling features from Ratnaparkhi
(1996), except that we replace one-count words as
&lt;unk&gt;. With standard perceptron and exact search,
our baseline system performs slightly better than
Collins (2002) with a beam of 20 (M. Collins, p.c.).
We then implemented beam search on top of dy-
namic programming and experimented with stan-
dard, early, hybrid, and max-violation update meth-
ods with various beam settings (b = 1, 2, 4, 7,10).
Figure 4(a) summarizes these experiments. We ob-
serve that, first of all, the standard update performs
poorly with the smallest beams, esp. at b = 1
(greedy search), when search error is the most se-
vere causing lots of invalid updates (see Figure 5).
Secondly,max-violation is almost consistently the
best-performing method (except for b = 4). Table 1
shows convergence rates, where max-violation up-
date also converges faster than early and standard
methods. In particular, at b = 1, it achieves a 19%
error reduction over standard update, while converg-
</bodyText>
<figure confidence="0.834561851851852">
97.2
96.8
96.6
96.4
97
max-violation
early
standard
best tagging accuracy on held-out
148
method b it time dev test
early* 38 15.4 h 92.24 92.09
standard 1 0.4 h 78.99 79.14
hybrid 8 11 5.6 h 92.26 91.95
latest 9 4.5 h 92.06 91.96
max-viol. 12 5.5 h 92.32 92.18
early 8 Huang &amp; Sagae 2010 92.1
% of invalid updates
100
75
50
25
0
parsing
tagging
2 4 6 8 10 12 14 16
beam size
</figure>
<figureCaption confidence="0.969633833333333">
Figure 5: Percentages of invalid updates for standard up-
date. In tagging it quickly drops to 0% while in parsing it
converges to ∼ 50%. This means search-wise, parsing is
much harder than tagging, which explains why standard
update does OK in tagging but terribly in parsing. The
harder the search is, the more needed valid updates are.
</figureCaption>
<table confidence="0.872865125">
method b it time dev test
standard* ∞ 6 162 m 97.17 97.28
early 4 6 37 m 97.22 97.35
hybrid 5 5 30 m 97.18 97.19
latest 7 5 45 m 97.17 97.13
max-viol. 2 3 26 m 97.20 97.33
standard 20 Collins (2002) 97.11
guided 3 Shen et al. (2007) 97.33
</table>
<tableCaption confidence="0.999517">
Table 2: Final test results on POS tagging. *:baseline.
</tableCaption>
<bodyText confidence="0.999936722222222">
ing twice as fast as early update.4 This agrees with
our intuition that by choosing the “most-violated”
triple for update, the perceptron should learn faster.
Table 2 presents the final tagging results on the
test set. For each of the five update methods, we
choose the beam size at which it achieves the high-
est accuracy on the held-out. For standard update, its
best held-out accuracy 97.17 is indeed achieved by
exact search (i.e., b = +∞) since it does not work
well with beam search, but it costs 2.7 hours (162
minutes) to train. By contrast, the four valid up-
date methods handle beam search better. The max-
violation method achieves its highest held-out/test
accuracies of 97.20 / 97.33 with a beam size of
only 2, and only 26 minutes to train. Early up-
date achieves the highest held-out/test accuracies of
97.22 / 97.35 across all update methods at the beam
size of 4. This test accuracy is even better than Shen
</bodyText>
<footnote confidence="0.9801475">
4for tagging (but not parsing) the difference in per-iteration
speed between early update and max-violation update is small.
</footnote>
<figureCaption confidence="0.948751">
Figure 6: Training progress curves for incremental pars-
</figureCaption>
<bodyText confidence="0.855916111111111">
ing (b = 8). Max-violation learns faster and better: it
takes 4.6 hours (10 iterations) to reach 92.25 on held-out,
compared with early update’s 15.4 hours (38 iterations),
even though the latter is faster in each iteration due to
early stopping (esp. at the first few iterations).
et al. (2007), the best tagging accuracy reported on
the Penn Treebank to date.5,6 To conclude, with
valid update methods, we can learn a better tagging
model with 5 times faster training than exact search.
</bodyText>
<subsectionHeader confidence="0.985276">
6.2 Incremental Parsing
</subsectionHeader>
<bodyText confidence="0.999948">
While part-of-speech tagging is mainly a proof of
concept, incremental parsing is much harder since
non-local features rules out exact inference.
We use the standard split for parsing: secs 02–
21 for training, 22 as held-out, and 23 for testing.
Our baseline system is a faithful reimplementation
of the beam-search dynamic programming parser of
Huang and Sagae (2010). Like most incremental
parsers, it used early update as search error is severe.
</bodyText>
<footnote confidence="0.893424">
5according to ACL Wiki: http://aclweb.org/aclwiki/.
</footnote>
<note confidence="0.311589">
6Note that Shen et al. (2007) employ contextual features
</note>
<tableCaption confidence="0.560478">
up to 5-gram which go beyond our local trigram window. We
suspect that adding genuinely non-local features would demon-
strate even better the advantages of valid update methods with
beam search, since exact inference will no longer be tractable.
Table 3: Final results on incremental parsing. *: baseline.
</tableCaption>
<figure confidence="0.998408272727273">
0 2 4 6 8 10 12 14 16 18
training time (hours)
parsing accuracy on held-out
92.25
91.75
91.25
91.5
92
91
max-violation
early
</figure>
<page confidence="0.995229">
149
</page>
<bodyText confidence="0.99999336">
We first confirm that, as reported by Huang and
Sagae, early update learns very slowly, reaching
92.24 on held-out with 38 iterations (15.4 hours).
We then experimented with the other update
methods: standard, hybrid, latest, and max-
violation, with beam size b = 1, 2, 4, 8. We found
that, first of all, the standard update performs horri-
bly on this task: at b = 1 it only achieves 60.04%
on held-out, while at b = 8 it improves to 78.99%
but is still vastly below all other methods. This is
because search error is much more severe in incre-
mental parsing (than in part-of-speech tagging), thus
standard update produces an enormous amount of
invalid updates even at b = 8 (see Figure 5). This
suggests that the advantage of valid update meth-
ods is more pronounced with tougher search prob-
lems. Secondly, max-violation learns much faster
(and better) than early update: it takes only 10 it-
erations (4.6 hours) to reach 92.25, compared with
early update’s 15.4 hours (see Fig. 6). At its peak,
max-violation achieves 92.18 on test which is bet-
ter than (Huang and Sagae, 2010). To conclude, we
can train a parser with only 1/3 of training time with
max-violation update, and the harder the search is,
the more needed the valid update methods are.
</bodyText>
<sectionHeader confidence="0.999595" genericHeader="method">
7 Related Work and Discussions
</sectionHeader>
<bodyText confidence="0.99432517948718">
Besides the early update method of Collins and
Roark (2004) which inspired us, this work is also
related to the LaSO method of Daum´e and Marcu
(2005). LaSO is similar to early update, except that
after each update, instead of skipping the rest of the
example, LaSO continues on the same example with
the correct hypothesis. For example, in the greedy
case LaSO is just replacing the break statement in
Algorithm 5 by
8’: zi = yi
and in beam search it is replacing it with
8’: 13i = [y[,:i]].
This is beyond our Local Violation-Fixing Per-
ceptron since it makes more than one updates on one
example, but can be easily represented as a Global
Violation-Fixing Perceptron (Algorithm 3), since we
can prove any further updates on this example is a vi-
olation (under the new weights). We thus establish
LaSO as a special case within our framework.7
More interestingly, it is easy to verify that the
greedy case of LaSO update is equivalent to training
a local unstructured perceptron which indepen-
dently classifies at each position based on history,
which is related to SEARN (Daum´e et al., 2009).
Kulesza and Pereira (2007) study perceptron
learning with approximate inference that overgen-
erates instead of undergenerates as in our work,
but the underlying idea is similar: by learning in a
harder setting (LP-relaxed version in their case and
prefix-augmented version in our case) we can learn
the simpler original setting. Our “beam separabil-
ity” can be viewed as an instance of their “algorith-
mic separability”. Finley and Joachims (2008) study
similar approximate inference for structural SVMs.
Our max-violation update is also related to other
training methods for large-margin structured predic-
tion, in particular the cutting-plane (Joachims et al.,
2009) and subgradient (Ratliff et al., 2007) methods,
but detailed exploration is left to future work.
</bodyText>
<sectionHeader confidence="0.999363" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999997833333333">
We have presented a unifying framework of
“violation-fixing” perceptron which guarantees con-
vergence with inexact search. This theory satisfin-
gly explained why standard perceptron might not
work well with inexact search, and why the early
update works. We also proposed some new vari-
ants within this framework, among which the max-
violation method performs the best on state-of-the-
art tagging and parsing systems, leading to better
models with greatly reduced training times. Lastly,
the advantage of valid update methods is more pro-
nounced when search error is severe.
</bodyText>
<sectionHeader confidence="0.996549" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.994429857142857">
We are grateful to the four anonymous reviewers, es-
pecially the one who wrote the comprehensive re-
view. We also thank David Chiang, Kevin Knight,
Ben Taskar, Alex Kulesza, Joseph Keshet, David
McAllester, Mike Collins, Sasha Rush, and Fei Sha
for discussions. This work is supported in part by a
Google Faculty Research Award to the first author.
</bodyText>
<footnote confidence="0.900947333333333">
7It turns out the original theorem in the LaSO paper (Daum´e
and Marcu, 2005) contains a bug; see (Xu et al., 2009) for cor-
rections. Thanks to a reviewer for pointing it out.
</footnote>
<page confidence="0.997832">
150
</page>
<sectionHeader confidence="0.995715" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998082911764706">
Collins, Michael. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
EMNLP.
Collins, Michael and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceedings
ofACL.
Crammer, Koby and Yoram Singer. 2003. Ultra-
conservative online algorithms for multiclass prob-
lems. Journal ofMachine Learning Research (JMLR),
3:951–991.
Daum´e, Hal, John Langford, and Daniel Marcu. 2009.
Search-based structured prediction.
Daum´e, Hal and Daniel Marcu. 2005. Learning as search
optimization: Approximate large margin methods for
structured prediction. In Proceedings ofICML.
Finley, Thomas and Thorsten Joachims. 2008. Training
structural SVMs when exact inference is intractable.
In Proceedings ofICML.
Huang, Liang. 2008. Forest reranking: Discriminative
parsing with non-local features. In Proceedings of the
ACL: HLT, Columbus, OH, June.
Huang, Liang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In Pro-
ceedings ofACL 2010.
Joachims, T., T. Finley, and Chun-Nam Yu. 2009.
Cutting-plane training of structural svms. Machine
Learning, 77(1):27–59.
Kulesza, Alex and Fernando Pereira. 2007. Structured
learning with approximate inference. In NIPS.
Lafferty, John, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Probabilis-
tic models for segmenting and labeling sequence data.
In Proceedings ofICML.
Liang, Percy, Alexandre Bouchard-Cˆot´e, Dan Klein, and
Ben Taskar. 2006. An end-to-end discriminative
approach to machine translation. In Proceedings of
COLING-ACL, Sydney, Australia, July.
Marcus, Mitchell P., Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of English: the Penn Treebank. Computational
Linguistics, 19:313–330.
McDonald, Ryan and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Proceedings of EACL.
Ratliff, Nathan, J. Andrew Bagnell, and Martin Zinke-
vich. 2007. (online) subgradient methods for struc-
tured prediction. In Proceedings ofAIStats.
Ratnaparkhi, Adwait. 1996. A maximum entropy model
for part-of-speech tagging. In Proceedings ofEMNLP.
Shen, Libin, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proceedings ofACL.
Taskar, Ben, Carlos Guestrin, and Daphne Koller. 2003.
Max-margin markov networks. In Proceedings of
NIPS. MIT Press.
Tsochantaridis, I., T. Joachims, T. Hofmann, and Y. Al-
tun. 2005. Large margin methods for structured and
interdependent output variables. Journal of Machine
Learning Research, 6:1453–1484.
Xu, Yuehua, Alan Fern, and Sungwook Yoon. 2009.
Learning linear ranking functions for beam search with
application to planning. Journal ofMachine Learning
Research (JMLR), 10:1349–1388.
Zhang, Yue and Stephen Clark. 2008. A tale of
two parsers: investigating and combining graph-based
and transition-based dependency parsing using beam-
search. In Proceedings ofEMNLP.
</reference>
<page confidence="0.998349">
151
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.944142">
<title confidence="0.997878">Structured Perceptron with Inexact Search</title>
<author confidence="0.999282">Liang Huang Suphan Fayong Yang Guo</author>
<affiliation confidence="0.991465">Information Sciences Institute Dept. of Computer Science Bloomberg L.P. University of Southern California University of Southern California New York, NY</affiliation>
<email confidence="0.977658">liang.huang.sh@gmail.comsuphan.ying@gmail.comyangg86@gmail.com</email>
<abstract confidence="0.9992426">Most existing theory of structured prediction assumes exact inference, which is often intractable in many practical problems. This leads to the routine use of approximate inference such as beam search but there is not much theory behind it. Based on the structured perceptron, we propose a general framework of “violation-fixing” perceptrons for inexact search with a theoretical guarantee for convergence under new separability conditions. This framework subsumes and justifies the popular heuristic “early-update” for perceptron with beam search (Collins and Roark, 2004). We also propose several new update methods within this framework, among which the “max-violation” method dramatically reduces training time (by 3 fold as compared to earlyupdate) on state-of-the-art part-of-speech tagging and incremental parsing systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="1293" citStr="Collins, 2002" startWordPosition="175" endWordPosition="176">ical guarantee for convergence under new separability conditions. This framework subsumes and justifies the popular heuristic “early-update” for perceptron with beam search (Collins and Roark, 2004). We also propose several new update methods within this framework, among which the “max-violation” method dramatically reduces training time (by 3 fold as compared to earlyupdate) on state-of-the-art part-of-speech tagging and incremental parsing systems. 1 Introduction Discriminative structured prediction algorithms such as conditional random fields (Lafferty et al., 2001), structured perceptron (Collins, 2002), maxmargin markov networks (Taskar et al., 2003), and structural SVMs (Tsochantaridis et al., 2005) lead to state-of-the-art performance on many structured prediction problems such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important proble</context>
<context position="3603" citStr="Collins, 2002" startWordPosition="518" endWordPosition="519">ich updates on partial hypotheses when the correct solution falls out of the beam. This method works significantly better than standard perceptron, and is followed by later incremental parsers, for instance in (Zhang and Clark, 2008; Huang and Sagae, 2010). However, two problems remain: first, up till now there has been no theoretical justification for early update; and secondly, it makes learning extremely slow as witnessed by the above-cited papers because it only learns on partial examples and often requires 15–40 iterations to converge while normal perceptron converges in 5–10 iterations (Collins, 2002). We develop a theoretical framework of “violationfixing” perceptron that addresses these challenges. In particular, we make the following contributions: • We show that, somewhat surprisingly, exact 142 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 142–151, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics search is not required by perceptron convergence. All we need is that each update involves a “violation”, i.e., the 1-best sequence has a higher model score than the correct</context>
<context position="5363" citStr="Collins, 2002" startWordPosition="795" endWordPosition="796">rning (Sec. 6.2). • We show that the early update is always valid and is thus a special case in our framework; this is the first theoretical justification for early update (Section 4). We also show that (a variant of) LaSO (Daum´e and Marcu, 2005) is another special case (Section 7). • We then propose several other update methods within this framework (Section 5). Experiments in Section 6 confirm that among them, the max-violation method can learn equal or better models with dramatically reduced learning times (by 3 fold as compared to early update) on state-of-the-art part-of-speech tagging (Collins, 2002)1 and incremental parsing (Huang and Sagae, 2010) systems. We also found strong correlation between search error and invalid updates, suggesting that the advantage of valid update methods is more pronounced with harder inference problems. Our techniques are widely applicable to other strcutured prediction problems which require inexact search like machine translation and protein folding. 2 Structured Perceptron We review the convergence properties of the standard structured perceptron (Collins, 2002) in our 1Incidentally, we achieve the best POS tagging accuracy to date (97.35%) on English Tre</context>
<context position="24565" citStr="Collins (2002)" startWordPosition="4366" endWordPosition="4367">full”) updates as possible, and latest update further addresses the case when standard update is invalid: instead of backing-off to early update, it uses the longest possible update. 6 Experiments We conduct experiments on two typical structured learning tasks: part-of-speech tagging with a trigram model where exact search is possible, and incremental dependency parsing with arbitrary non-local features where exact search is intractable. We run both experiments on state-of-the-art implementations. 6.1 Part-of-Speech Tagging Following the standard split for part-of-speech tagging introduced by Collins (2002), we use sections 00–18 of the Penn Treebank (Marcus et al., 1 2 3 4 5 6 7 8 9 10 beam size Figure 4: POS tagging using beam search with various update methods (hybrid/latest similar to early; omitted). b = 1 b = 2 b = 7 method it dev it dev it dev standard 12 96.27 6 97.07 4 97.17 early 13 96.97 6 97.15 7 97.19 max-viol. 7 96.97 3 97.20 4 97.20 Table 1: Convergence rate of part-of-speech tagging. In general, max-violation converges faster and better than early and standard updates, esp. in smallest beams. 1993) for training, sections 19–21 as a held-out development set, and sections 22–24 for</context>
<context position="27186" citStr="Collins (2002)" startWordPosition="4842" endWordPosition="4843">f invalid updates 100 75 50 25 0 parsing tagging 2 4 6 8 10 12 14 16 beam size Figure 5: Percentages of invalid updates for standard update. In tagging it quickly drops to 0% while in parsing it converges to ∼ 50%. This means search-wise, parsing is much harder than tagging, which explains why standard update does OK in tagging but terribly in parsing. The harder the search is, the more needed valid updates are. method b it time dev test standard* ∞ 6 162 m 97.17 97.28 early 4 6 37 m 97.22 97.35 hybrid 5 5 30 m 97.18 97.19 latest 7 5 45 m 97.17 97.13 max-viol. 2 3 26 m 97.20 97.33 standard 20 Collins (2002) 97.11 guided 3 Shen et al. (2007) 97.33 Table 2: Final test results on POS tagging. *:baseline. ing twice as fast as early update.4 This agrees with our intuition that by choosing the “most-violated” triple for update, the perceptron should learn faster. Table 2 presents the final tagging results on the test set. For each of the five update methods, we choose the beam size at which it achieves the highest accuracy on the held-out. For standard update, its best held-out accuracy 97.17 is indeed achieved by exact search (i.e., b = +∞) since it does not work well with beam search, but it costs 2</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Collins, Michael. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="877" citStr="Collins and Roark, 2004" startWordPosition="117" endWordPosition="120">m suphan.ying@gmail.com yangg86@gmail.com Abstract Most existing theory of structured prediction assumes exact inference, which is often intractable in many practical problems. This leads to the routine use of approximate inference such as beam search but there is not much theory behind it. Based on the structured perceptron, we propose a general framework of “violation-fixing” perceptrons for inexact search with a theoretical guarantee for convergence under new separability conditions. This framework subsumes and justifies the popular heuristic “early-update” for perceptron with beam search (Collins and Roark, 2004). We also propose several new update methods within this framework, among which the “max-violation” method dramatically reduces training time (by 3 fold as compared to earlyupdate) on state-of-the-art part-of-speech tagging and incremental parsing systems. 1 Introduction Discriminative structured prediction algorithms such as conditional random fields (Lafferty et al., 2001), structured perceptron (Collins, 2002), maxmargin markov networks (Taskar et al., 2003), and structural SVMs (Tsochantaridis et al., 2005) lead to state-of-the-art performance on many structured prediction problems such as</context>
<context position="2899" citStr="Collins and Roark (2004)" startWordPosition="405" endWordPosition="408">earning algorithms, and besides notable exceptions discussed below and in Section 7, little is known for theoretical properties of structured prediction under inexact search. Among these notable exceptions, many examine how and which approximations break theoretical guarantees of existing learning algorithms (Kulesza and Pereira, 2007; Finley and Joachims, 2008), but we ask a deeper and practically more useful question: can we modify existing learning algorithms to accommodate the inexactness in inference, so that the theoretical properties are still maintained? For the structured perceptron, Collins and Roark (2004) provides a partial answer: they suggest variant called “early update” for beam search, which updates on partial hypotheses when the correct solution falls out of the beam. This method works significantly better than standard perceptron, and is followed by later incremental parsers, for instance in (Zhang and Clark, 2008; Huang and Sagae, 2010). However, two problems remain: first, up till now there has been no theoretical justification for early update; and secondly, it makes learning extremely slow as witnessed by the above-cited papers because it only learns on partial examples and often re</context>
<context position="14332" citStr="Collins and Roark (2004)" startWordPosition="2496" endWordPosition="2499">in Figure 1. This situation happens very often in NLP: often the search space Y(x) is too big either because it does not factor locally, or because it is still too big after factorization, which requires some approximate search. In either case, updating the model w on a non-violation (i.e., “invalid”) triple (x, y, z) does not make sense: it is not the model’s problem: w does score the correct label y higher than the incorrect z; rather, it is a problem of the search, or its interaction with the model that prunes away the correct (sub)sequence during the search. What shall we do in this case? Collins and Roark (2004) suggest that instead of the standard full update, we should only update on the prefix (x, y[1:i], z[1:i]) up to the point i where the correct sequence falls off the beam. This intuitively makes a lot of sense, since up to i we can still guarantee violation, but after i we may not. The next section formalizes this intuition. 4 Early Update is Violation-Fixing We now proceed to show that early update is always valid and it is thus a special case of the violationfixing perceptron framework. First, let us study the simplest special case, greedy search (beam=1). 4.1 Greedy Search and Early Update </context>
<context position="15964" citStr="Collins and Roark, 2004" startWordPosition="2804" endWordPosition="2807">orithm 5 Early update for greedy search adapted from Collins and Roark (2004). Input: training scenario S = hD, 4?, Cg(D)i 1: repeat 2: for each example (x, y) in D do 3: z ← e &gt; empty sequence 4: for i ∈ 1 ... |x |do 5: z ← BEST(x, z, w) 6: if zi =6 yi then &gt; first wrong action 7: w ← w + A4?(x, y[1:i], z) &gt; early update 8: break &gt; skip the rest of this example 9: until converged next position. The notation Yi(x) denotes the set of possible actions at position i for example x (for instance, the set of possible tags for a word). The early update heuristic, originally proposed for beam search (Collins and Roark, 2004), now simplifies into “update at the first wrong action”, since this is exactly the place where the correct sequence falls off the singleton beam (see Algorithm 5 for pseudocode and Fig. 2). Informally, it is easy to show (below) that this kind of update is always a valid violation, but we need to redefine confusion set. Definition 5. The greedy confusion set Cg(D) for training data D = {(x(t), y(t))}nt=1 is the set of triples (x, y[1:i], z[1:i]) where y[1:i] is a i-prefix of the correct label y, and z[1:i] is an incorrect i-prefix that agrees with the correct prefix on all decisions except th</context>
<context position="31223" citStr="Collins and Roark (2004)" startWordPosition="5524" endWordPosition="5527"> advantage of valid update methods is more pronounced with tougher search problems. Secondly, max-violation learns much faster (and better) than early update: it takes only 10 iterations (4.6 hours) to reach 92.25, compared with early update’s 15.4 hours (see Fig. 6). At its peak, max-violation achieves 92.18 on test which is better than (Huang and Sagae, 2010). To conclude, we can train a parser with only 1/3 of training time with max-violation update, and the harder the search is, the more needed the valid update methods are. 7 Related Work and Discussions Besides the early update method of Collins and Roark (2004) which inspired us, this work is also related to the LaSO method of Daum´e and Marcu (2005). LaSO is similar to early update, except that after each update, instead of skipping the rest of the example, LaSO continues on the same example with the correct hypothesis. For example, in the greedy case LaSO is just replacing the break statement in Algorithm 5 by 8’: zi = yi and in beam search it is replacing it with 8’: 13i = [y[,:i]]. This is beyond our Local Violation-Fixing Perceptron since it makes more than one updates on one example, but can be easily represented as a Global Violation-Fixing P</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Collins, Michael and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal ofMachine Learning Research (JMLR),</journal>
<pages>3--951</pages>
<contexts>
<context position="11464" citStr="Crammer and Singer (2003)" startWordPosition="1952" endWordPosition="1955">. For a separable training scenario S the perceptrons in Algorithms 2 and 3 both converge with the same update bounds of R2(S)/δ2(S) as long as the FINDVIOLATION and FINDVIOLATIONINDATA functions always return violation triples if there are any. Proof. Same as the proof to Theorem 1, except for replacing Lemma 1 in part 2 by the fact that the update triples are guaranteed to be violations. (Note a violation triple is by definition in the confusion set, thus we can still use separation and diameter). These generic violation-fixing perceptron algorithms can been seen as “interfaces” (or APIs), 2Crammer and Singer (2003) further demonstrates that a convex combination of violations can also be used for update. 144 Algorithm 3 Global Violation-Fixing Perceptron. Input: training scenario S = hD, Φ, Ci 1: repeat 2: (x, y, z) ← FINDVIOLATIONINDATA(C, w) 3: if x = ǫ then break ⊲ no more violation? 4: w ← w + 0Φ(x, y, z) 5: until converged data D = {(x, y)}: x fruit flies fly . y N N V . search space: Y(x) = {N} × {N, V} × {N, V} × {.}. feature map: Φ(x, y) = (#N1N(y), #V1.(y)). iter label z 0Φ(x, y, z) w·0Φ new w 0 (0,0) 1 NNN. (−1, +1) 0 √ (−1, 1) 2 NVN. (+1, +1) 0 √ (0,2) 3 NNN. (−1, +1) 2 × (−1,3) 4 NVN. (+1, +1</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Crammer, Koby and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal ofMachine Learning Research (JMLR), 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>John Langford</author>
<author>Daniel Marcu</author>
</authors>
<date>2009</date>
<note>Search-based structured prediction.</note>
<marker>Daum´e, Langford, Marcu, 2009</marker>
<rawString>Daum´e, Hal, John Langford, and Daniel Marcu. 2009. Search-based structured prediction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>Learning as search optimization: Approximate large margin methods for structured prediction.</title>
<date>2005</date>
<booktitle>In Proceedings ofICML.</booktitle>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>Daum´e, Hal and Daniel Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In Proceedings ofICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Finley</author>
<author>Thorsten Joachims</author>
</authors>
<title>Training structural SVMs when exact inference is intractable.</title>
<date>2008</date>
<booktitle>In Proceedings ofICML.</booktitle>
<contexts>
<context position="2639" citStr="Finley and Joachims, 2008" startWordPosition="366" endWordPosition="369">), and bottom-up parsing (McDonald and Pereira, 2006; Huang, 2008). This leads to routine use of approximate inference such as beam search as evidenced in the above-cited papers, but the inexactness unfortunately abandons existing theoretical guarantees of the learning algorithms, and besides notable exceptions discussed below and in Section 7, little is known for theoretical properties of structured prediction under inexact search. Among these notable exceptions, many examine how and which approximations break theoretical guarantees of existing learning algorithms (Kulesza and Pereira, 2007; Finley and Joachims, 2008), but we ask a deeper and practically more useful question: can we modify existing learning algorithms to accommodate the inexactness in inference, so that the theoretical properties are still maintained? For the structured perceptron, Collins and Roark (2004) provides a partial answer: they suggest variant called “early update” for beam search, which updates on partial hypotheses when the correct solution falls out of the beam. This method works significantly better than standard perceptron, and is followed by later incremental parsers, for instance in (Zhang and Clark, 2008; Huang and Sagae,</context>
<context position="32701" citStr="Finley and Joachims (2008)" startWordPosition="5773" endWordPosition="5776">O update is equivalent to training a local unstructured perceptron which independently classifies at each position based on history, which is related to SEARN (Daum´e et al., 2009). Kulesza and Pereira (2007) study perceptron learning with approximate inference that overgenerates instead of undergenerates as in our work, but the underlying idea is similar: by learning in a harder setting (LP-relaxed version in their case and prefix-augmented version in our case) we can learn the simpler original setting. Our “beam separability” can be viewed as an instance of their “algorithmic separability”. Finley and Joachims (2008) study similar approximate inference for structural SVMs. Our max-violation update is also related to other training methods for large-margin structured prediction, in particular the cutting-plane (Joachims et al., 2009) and subgradient (Ratliff et al., 2007) methods, but detailed exploration is left to future work. 8 Conclusions We have presented a unifying framework of “violation-fixing” perceptron which guarantees convergence with inexact search. This theory satisfingly explained why standard perceptron might not work well with inexact search, and why the early update works. We also propose</context>
</contexts>
<marker>Finley, Joachims, 2008</marker>
<rawString>Finley, Thomas and Thorsten Joachims. 2008. Training structural SVMs when exact inference is intractable. In Proceedings ofICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL: HLT,</booktitle>
<location>Columbus, OH,</location>
<contexts>
<context position="2079" citStr="Huang, 2008" startWordPosition="289" endWordPosition="290">ms such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important problems such as machine translation (Liang et al., 2006), incremental parsing (Collins and Roark, 2004; Huang and Sagae, 2010), and bottom-up parsing (McDonald and Pereira, 2006; Huang, 2008). This leads to routine use of approximate inference such as beam search as evidenced in the above-cited papers, but the inexactness unfortunately abandons existing theoretical guarantees of the learning algorithms, and besides notable exceptions discussed below and in Section 7, little is known for theoretical properties of structured prediction under inexact search. Among these notable exceptions, many examine how and which approximations break theoretical guarantees of existing learning algorithms (Kulesza and Pereira, 2007; Finley and Joachims, 2008), but we ask a deeper and practically mo</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Huang, Liang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of the ACL: HLT, Columbus, OH, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings ofACL</booktitle>
<contexts>
<context position="2014" citStr="Huang and Sagae, 2010" startWordPosition="278" endWordPosition="281">) lead to state-of-the-art performance on many structured prediction problems such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important problems such as machine translation (Liang et al., 2006), incremental parsing (Collins and Roark, 2004; Huang and Sagae, 2010), and bottom-up parsing (McDonald and Pereira, 2006; Huang, 2008). This leads to routine use of approximate inference such as beam search as evidenced in the above-cited papers, but the inexactness unfortunately abandons existing theoretical guarantees of the learning algorithms, and besides notable exceptions discussed below and in Section 7, little is known for theoretical properties of structured prediction under inexact search. Among these notable exceptions, many examine how and which approximations break theoretical guarantees of existing learning algorithms (Kulesza and Pereira, 2007; F</context>
<context position="3245" citStr="Huang and Sagae, 2010" startWordPosition="462" endWordPosition="465"> Joachims, 2008), but we ask a deeper and practically more useful question: can we modify existing learning algorithms to accommodate the inexactness in inference, so that the theoretical properties are still maintained? For the structured perceptron, Collins and Roark (2004) provides a partial answer: they suggest variant called “early update” for beam search, which updates on partial hypotheses when the correct solution falls out of the beam. This method works significantly better than standard perceptron, and is followed by later incremental parsers, for instance in (Zhang and Clark, 2008; Huang and Sagae, 2010). However, two problems remain: first, up till now there has been no theoretical justification for early update; and secondly, it makes learning extremely slow as witnessed by the above-cited papers because it only learns on partial examples and often requires 15–40 iterations to converge while normal perceptron converges in 5–10 iterations (Collins, 2002). We develop a theoretical framework of “violationfixing” perceptron that addresses these challenges. In particular, we make the following contributions: • We show that, somewhat surprisingly, exact 142 2012 Conference of the North American C</context>
<context position="5412" citStr="Huang and Sagae, 2010" startWordPosition="800" endWordPosition="803">y update is always valid and is thus a special case in our framework; this is the first theoretical justification for early update (Section 4). We also show that (a variant of) LaSO (Daum´e and Marcu, 2005) is another special case (Section 7). • We then propose several other update methods within this framework (Section 5). Experiments in Section 6 confirm that among them, the max-violation method can learn equal or better models with dramatically reduced learning times (by 3 fold as compared to early update) on state-of-the-art part-of-speech tagging (Collins, 2002)1 and incremental parsing (Huang and Sagae, 2010) systems. We also found strong correlation between search error and invalid updates, suggesting that the advantage of valid update methods is more pronounced with harder inference problems. Our techniques are widely applicable to other strcutured prediction problems which require inexact search like machine translation and protein folding. 2 Structured Perceptron We review the convergence properties of the standard structured perceptron (Collins, 2002) in our 1Incidentally, we achieve the best POS tagging accuracy to date (97.35%) on English Treebank by early update (Sec. 6.1). Algorithm 1 Str</context>
<context position="19897" citStr="Huang and Sagae, 2010" startWordPosition="3553" endWordPosition="3556">h (Collins and Roark 04) as Local Violation-Fixing Perceptron. 1: function FINDVIOLATION(x, y, w) 2: B0 ← [ǫ] 3: for i ∈ 1 ... |x |do 4: Bi ← BESTk(x, Bi−1, w) 5: if y[1:i] ∈/ Bi then ⊲ correct seq. falls off beam 6: return (x, y[1:i],Bi[0]) ⊲ update on prefix 7: return (x, y, B|.,|[0]) ⊲ full update if wrong final same length and if they agree on the last two tags, i.e. z ≡ z′ iff. |z |= |z′ |and z|z|_1:|z |= z′|z|_1:|z|. In incremental parsing this equivalence relation could be relevant bits of information on the last few trees on the stack (depending on feature templates), as suggested in (Huang and Sagae, 2010). 3 Algorithm 7 shows the pseudocode for beam search. It is trivial to verify that greedy search is a special case of beam search with k = 1. However, the definition of confusion set changes considerably: Definition 7. The beam confusion set Cb(D) for training data D = {(x(t), y(t))}nt�1 is the set of triples (x, y[1:i], z[1:i]) where y[1:i] is a i-prefix of the correct label y, and z[1:i] is an incorrect i-prefix that differs from the correct prefix (in at least one place): Cb(D) � {(x, y[1:i], z[1:i]) |(x, y, z) ∈ C.(D), 1 ≤ i ≤ |y|, z[1:i] =6 y[1:i]}. Similarly, we say that a dataset D is b</context>
<context position="29265" citStr="Huang and Sagae (2010)" startWordPosition="5189" endWordPosition="5192">irst few iterations). et al. (2007), the best tagging accuracy reported on the Penn Treebank to date.5,6 To conclude, with valid update methods, we can learn a better tagging model with 5 times faster training than exact search. 6.2 Incremental Parsing While part-of-speech tagging is mainly a proof of concept, incremental parsing is much harder since non-local features rules out exact inference. We use the standard split for parsing: secs 02– 21 for training, 22 as held-out, and 23 for testing. Our baseline system is a faithful reimplementation of the beam-search dynamic programming parser of Huang and Sagae (2010). Like most incremental parsers, it used early update as search error is severe. 5according to ACL Wiki: http://aclweb.org/aclwiki/. 6Note that Shen et al. (2007) employ contextual features up to 5-gram which go beyond our local trigram window. We suspect that adding genuinely non-local features would demonstrate even better the advantages of valid update methods with beam search, since exact inference will no longer be tractable. Table 3: Final results on incremental parsing. *: baseline. 0 2 4 6 8 10 12 14 16 18 training time (hours) parsing accuracy on held-out 92.25 91.75 91.25 91.5 92 91 </context>
<context position="30962" citStr="Huang and Sagae, 2010" startWordPosition="5479" endWordPosition="5482"> vastly below all other methods. This is because search error is much more severe in incremental parsing (than in part-of-speech tagging), thus standard update produces an enormous amount of invalid updates even at b = 8 (see Figure 5). This suggests that the advantage of valid update methods is more pronounced with tougher search problems. Secondly, max-violation learns much faster (and better) than early update: it takes only 10 iterations (4.6 hours) to reach 92.25, compared with early update’s 15.4 hours (see Fig. 6). At its peak, max-violation achieves 92.18 on test which is better than (Huang and Sagae, 2010). To conclude, we can train a parser with only 1/3 of training time with max-violation update, and the harder the search is, the more needed the valid update methods are. 7 Related Work and Discussions Besides the early update method of Collins and Roark (2004) which inspired us, this work is also related to the LaSO method of Daum´e and Marcu (2005). LaSO is similar to early update, except that after each update, instead of skipping the rest of the example, LaSO continues on the same example with the correct hypothesis. For example, in the greedy case LaSO is just replacing the break statemen</context>
<context position="26563" citStr="Huang &amp; Sagae 2010" startWordPosition="4715" endWordPosition="4718">lid updates (see Figure 5). Secondly,max-violation is almost consistently the best-performing method (except for b = 4). Table 1 shows convergence rates, where max-violation update also converges faster than early and standard methods. In particular, at b = 1, it achieves a 19% error reduction over standard update, while converg97.2 96.8 96.6 96.4 97 max-violation early standard best tagging accuracy on held-out 148 method b it time dev test early* 38 15.4 h 92.24 92.09 standard 1 0.4 h 78.99 79.14 hybrid 8 11 5.6 h 92.26 91.95 latest 9 4.5 h 92.06 91.96 max-viol. 12 5.5 h 92.32 92.18 early 8 Huang &amp; Sagae 2010 92.1 % of invalid updates 100 75 50 25 0 parsing tagging 2 4 6 8 10 12 14 16 beam size Figure 5: Percentages of invalid updates for standard update. In tagging it quickly drops to 0% while in parsing it converges to ∼ 50%. This means search-wise, parsing is much harder than tagging, which explains why standard update does OK in tagging but terribly in parsing. The harder the search is, the more needed valid updates are. method b it time dev test standard* ∞ 6 162 m 97.17 97.28 early 4 6 37 m 97.22 97.35 hybrid 5 5 30 m 97.18 97.19 latest 7 5 45 m 97.17 97.13 max-viol. 2 3 26 m 97.20 97.33 sta</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Huang, Liang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings ofACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
<author>T Finley</author>
<author>Chun-Nam Yu</author>
</authors>
<title>Cutting-plane training of structural svms.</title>
<date>2009</date>
<booktitle>Machine Learning,</booktitle>
<volume>77</volume>
<issue>1</issue>
<contexts>
<context position="32921" citStr="Joachims et al., 2009" startWordPosition="5803" endWordPosition="5806">n learning with approximate inference that overgenerates instead of undergenerates as in our work, but the underlying idea is similar: by learning in a harder setting (LP-relaxed version in their case and prefix-augmented version in our case) we can learn the simpler original setting. Our “beam separability” can be viewed as an instance of their “algorithmic separability”. Finley and Joachims (2008) study similar approximate inference for structural SVMs. Our max-violation update is also related to other training methods for large-margin structured prediction, in particular the cutting-plane (Joachims et al., 2009) and subgradient (Ratliff et al., 2007) methods, but detailed exploration is left to future work. 8 Conclusions We have presented a unifying framework of “violation-fixing” perceptron which guarantees convergence with inexact search. This theory satisfingly explained why standard perceptron might not work well with inexact search, and why the early update works. We also proposed some new variants within this framework, among which the maxviolation method performs the best on state-of-theart tagging and parsing systems, leading to better models with greatly reduced training times. Lastly, the a</context>
</contexts>
<marker>Joachims, Finley, Yu, 2009</marker>
<rawString>Joachims, T., T. Finley, and Chun-Nam Yu. 2009. Cutting-plane training of structural svms. Machine Learning, 77(1):27–59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Kulesza</author>
<author>Fernando Pereira</author>
</authors>
<title>Structured learning with approximate inference.</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="2611" citStr="Kulesza and Pereira, 2007" startWordPosition="362" endWordPosition="365">2004; Huang and Sagae, 2010), and bottom-up parsing (McDonald and Pereira, 2006; Huang, 2008). This leads to routine use of approximate inference such as beam search as evidenced in the above-cited papers, but the inexactness unfortunately abandons existing theoretical guarantees of the learning algorithms, and besides notable exceptions discussed below and in Section 7, little is known for theoretical properties of structured prediction under inexact search. Among these notable exceptions, many examine how and which approximations break theoretical guarantees of existing learning algorithms (Kulesza and Pereira, 2007; Finley and Joachims, 2008), but we ask a deeper and practically more useful question: can we modify existing learning algorithms to accommodate the inexactness in inference, so that the theoretical properties are still maintained? For the structured perceptron, Collins and Roark (2004) provides a partial answer: they suggest variant called “early update” for beam search, which updates on partial hypotheses when the correct solution falls out of the beam. This method works significantly better than standard perceptron, and is followed by later incremental parsers, for instance in (Zhang and C</context>
<context position="32283" citStr="Kulesza and Pereira (2007)" startWordPosition="5708" endWordPosition="5711">This is beyond our Local Violation-Fixing Perceptron since it makes more than one updates on one example, but can be easily represented as a Global Violation-Fixing Perceptron (Algorithm 3), since we can prove any further updates on this example is a violation (under the new weights). We thus establish LaSO as a special case within our framework.7 More interestingly, it is easy to verify that the greedy case of LaSO update is equivalent to training a local unstructured perceptron which independently classifies at each position based on history, which is related to SEARN (Daum´e et al., 2009). Kulesza and Pereira (2007) study perceptron learning with approximate inference that overgenerates instead of undergenerates as in our work, but the underlying idea is similar: by learning in a harder setting (LP-relaxed version in their case and prefix-augmented version in our case) we can learn the simpler original setting. Our “beam separability” can be viewed as an instance of their “algorithmic separability”. Finley and Joachims (2008) study similar approximate inference for structural SVMs. Our max-violation update is also related to other training methods for large-margin structured prediction, in particular the</context>
</contexts>
<marker>Kulesza, Pereira, 2007</marker>
<rawString>Kulesza, Alex and Fernando Pereira. 2007. Structured learning with approximate inference. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings ofICML.</booktitle>
<contexts>
<context position="1254" citStr="Lafferty et al., 2001" startWordPosition="169" endWordPosition="172">” perceptrons for inexact search with a theoretical guarantee for convergence under new separability conditions. This framework subsumes and justifies the popular heuristic “early-update” for perceptron with beam search (Collins and Roark, 2004). We also propose several new update methods within this framework, among which the “max-violation” method dramatically reduces training time (by 3 fold as compared to earlyupdate) on state-of-the-art part-of-speech tagging and incremental parsing systems. 1 Introduction Discriminative structured prediction algorithms such as conditional random fields (Lafferty et al., 2001), structured perceptron (Collins, 2002), maxmargin markov networks (Taskar et al., 2003), and structural SVMs (Tsochantaridis et al., 2005) lead to state-of-the-art performance on many structured prediction problems such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is oft</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, John, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings ofICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<location>Sydney, Australia,</location>
<marker>Liang, Bouchard-Cˆot´e, Klein, Taskar, 2006</marker>
<rawString>Liang, Percy, Alexandre Bouchard-Cˆot´e, Dan Klein, and Ben Taskar. 2006. An end-to-end discriminative approach to machine translation. In Proceedings of COLING-ACL, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus, Mitchell P., Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguistics, 19:313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="2065" citStr="McDonald and Pereira, 2006" startWordPosition="285" endWordPosition="288">structured prediction problems such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important problems such as machine translation (Liang et al., 2006), incremental parsing (Collins and Roark, 2004; Huang and Sagae, 2010), and bottom-up parsing (McDonald and Pereira, 2006; Huang, 2008). This leads to routine use of approximate inference such as beam search as evidenced in the above-cited papers, but the inexactness unfortunately abandons existing theoretical guarantees of the learning algorithms, and besides notable exceptions discussed below and in Section 7, little is known for theoretical properties of structured prediction under inexact search. Among these notable exceptions, many examine how and which approximations break theoretical guarantees of existing learning algorithms (Kulesza and Pereira, 2007; Finley and Joachims, 2008), but we ask a deeper and </context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>McDonald, Ryan and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathan Ratliff</author>
<author>J Andrew Bagnell</author>
<author>Martin Zinkevich</author>
</authors>
<title>(online) subgradient methods for structured prediction.</title>
<date>2007</date>
<booktitle>In Proceedings ofAIStats.</booktitle>
<contexts>
<context position="32960" citStr="Ratliff et al., 2007" startWordPosition="5809" endWordPosition="5812">at overgenerates instead of undergenerates as in our work, but the underlying idea is similar: by learning in a harder setting (LP-relaxed version in their case and prefix-augmented version in our case) we can learn the simpler original setting. Our “beam separability” can be viewed as an instance of their “algorithmic separability”. Finley and Joachims (2008) study similar approximate inference for structural SVMs. Our max-violation update is also related to other training methods for large-margin structured prediction, in particular the cutting-plane (Joachims et al., 2009) and subgradient (Ratliff et al., 2007) methods, but detailed exploration is left to future work. 8 Conclusions We have presented a unifying framework of “violation-fixing” perceptron which guarantees convergence with inexact search. This theory satisfingly explained why standard perceptron might not work well with inexact search, and why the early update works. We also proposed some new variants within this framework, among which the maxviolation method performs the best on state-of-theart tagging and parsing systems, leading to better models with greatly reduced training times. Lastly, the advantage of valid update methods is mor</context>
</contexts>
<marker>Ratliff, Bagnell, Zinkevich, 2007</marker>
<rawString>Ratliff, Nathan, J. Andrew Bagnell, and Martin Zinkevich. 2007. (online) subgradient methods for structured prediction. In Proceedings ofAIStats.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings ofEMNLP.</booktitle>
<contexts>
<context position="25336" citStr="Ratnaparkhi (1996)" startWordPosition="4506" endWordPosition="4507">ethods (hybrid/latest similar to early; omitted). b = 1 b = 2 b = 7 method it dev it dev it dev standard 12 96.27 6 97.07 4 97.17 early 13 96.97 6 97.15 7 97.19 max-viol. 7 96.97 3 97.20 4 97.20 Table 1: Convergence rate of part-of-speech tagging. In general, max-violation converges faster and better than early and standard updates, esp. in smallest beams. 1993) for training, sections 19–21 as a held-out development set, and sections 22–24 for testing. Our baseline system is a faithful implementation of the perceptron tagger in Collins (2002), i.e., a trigram model with spelling features from Ratnaparkhi (1996), except that we replace one-count words as &lt;unk&gt;. With standard perceptron and exact search, our baseline system performs slightly better than Collins (2002) with a beam of 20 (M. Collins, p.c.). We then implemented beam search on top of dynamic programming and experimented with standard, early, hybrid, and max-violation update methods with various beam settings (b = 1, 2, 4, 7,10). Figure 4(a) summarizes these experiments. We observe that, first of all, the standard update performs poorly with the smallest beams, esp. at b = 1 (greedy search), when search error is the most severe causing lot</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Ratnaparkhi, Adwait. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings ofEMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Giorgio Satta</author>
<author>Aravind Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL.</booktitle>
<contexts>
<context position="27220" citStr="Shen et al. (2007)" startWordPosition="4847" endWordPosition="4850"> 0 parsing tagging 2 4 6 8 10 12 14 16 beam size Figure 5: Percentages of invalid updates for standard update. In tagging it quickly drops to 0% while in parsing it converges to ∼ 50%. This means search-wise, parsing is much harder than tagging, which explains why standard update does OK in tagging but terribly in parsing. The harder the search is, the more needed valid updates are. method b it time dev test standard* ∞ 6 162 m 97.17 97.28 early 4 6 37 m 97.22 97.35 hybrid 5 5 30 m 97.18 97.19 latest 7 5 45 m 97.17 97.13 max-viol. 2 3 26 m 97.20 97.33 standard 20 Collins (2002) 97.11 guided 3 Shen et al. (2007) 97.33 Table 2: Final test results on POS tagging. *:baseline. ing twice as fast as early update.4 This agrees with our intuition that by choosing the “most-violated” triple for update, the perceptron should learn faster. Table 2 presents the final tagging results on the test set. For each of the five update methods, we choose the beam size at which it achieves the highest accuracy on the held-out. For standard update, its best held-out accuracy 97.17 is indeed achieved by exact search (i.e., b = +∞) since it does not work well with beam search, but it costs 2.7 hours (162 minutes) to train. B</context>
<context position="29427" citStr="Shen et al. (2007)" startWordPosition="5213" endWordPosition="5216"> tagging model with 5 times faster training than exact search. 6.2 Incremental Parsing While part-of-speech tagging is mainly a proof of concept, incremental parsing is much harder since non-local features rules out exact inference. We use the standard split for parsing: secs 02– 21 for training, 22 as held-out, and 23 for testing. Our baseline system is a faithful reimplementation of the beam-search dynamic programming parser of Huang and Sagae (2010). Like most incremental parsers, it used early update as search error is severe. 5according to ACL Wiki: http://aclweb.org/aclwiki/. 6Note that Shen et al. (2007) employ contextual features up to 5-gram which go beyond our local trigram window. We suspect that adding genuinely non-local features would demonstrate even better the advantages of valid update methods with beam search, since exact inference will no longer be tractable. Table 3: Final results on incremental parsing. *: baseline. 0 2 4 6 8 10 12 14 16 18 training time (hours) parsing accuracy on held-out 92.25 91.75 91.25 91.5 92 91 max-violation early 149 We first confirm that, as reported by Huang and Sagae, early update learns very slowly, reaching 92.24 on held-out with 38 iterations (15.</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>Shen, Libin, Giorgio Satta, and Aravind Joshi. 2007. Guided learning for bidirectional sequence classification. In Proceedings ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Carlos Guestrin</author>
<author>Daphne Koller</author>
</authors>
<title>Max-margin markov networks.</title>
<date>2003</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1342" citStr="Taskar et al., 2003" startWordPosition="181" endWordPosition="184">parability conditions. This framework subsumes and justifies the popular heuristic “early-update” for perceptron with beam search (Collins and Roark, 2004). We also propose several new update methods within this framework, among which the “max-violation” method dramatically reduces training time (by 3 fold as compared to earlyupdate) on state-of-the-art part-of-speech tagging and incremental parsing systems. 1 Introduction Discriminative structured prediction algorithms such as conditional random fields (Lafferty et al., 2001), structured perceptron (Collins, 2002), maxmargin markov networks (Taskar et al., 2003), and structural SVMs (Tsochantaridis et al., 2005) lead to state-of-the-art performance on many structured prediction problems such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important problems such as machine translation (Liang et al., 200</context>
</contexts>
<marker>Taskar, Guestrin, Koller, 2003</marker>
<rawString>Taskar, Ben, Carlos Guestrin, and Daphne Koller. 2003. Max-margin markov networks. In Proceedings of NIPS. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Tsochantaridis</author>
<author>T Joachims</author>
<author>T Hofmann</author>
<author>Y Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>6--1453</pages>
<contexts>
<context position="1393" citStr="Tsochantaridis et al., 2005" startWordPosition="188" endWordPosition="191">mes and justifies the popular heuristic “early-update” for perceptron with beam search (Collins and Roark, 2004). We also propose several new update methods within this framework, among which the “max-violation” method dramatically reduces training time (by 3 fold as compared to earlyupdate) on state-of-the-art part-of-speech tagging and incremental parsing systems. 1 Introduction Discriminative structured prediction algorithms such as conditional random fields (Lafferty et al., 2001), structured perceptron (Collins, 2002), maxmargin markov networks (Taskar et al., 2003), and structural SVMs (Tsochantaridis et al., 2005) lead to state-of-the-art performance on many structured prediction problems such as part-of-speech tagging, sequence labeling, and parsing. But despite their success, there remains a major problem: these learning algorithms all assume exact inference (over an exponentially-large search space), which is needed to ensure their theoretical properties such as convergence. This exactness assumption, however, rarely holds in practice since exact inference is often intractable in many important problems such as machine translation (Liang et al., 2006), incremental parsing (Collins and Roark, 2004; H</context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>Tsochantaridis, I., T. Joachims, T. Hofmann, and Y. Altun. 2005. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research, 6:1453–1484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuehua Xu</author>
<author>Alan Fern</author>
<author>Sungwook Yoon</author>
</authors>
<title>Learning linear ranking functions for beam search with application to planning.</title>
<date>2009</date>
<journal>Journal ofMachine Learning Research (JMLR),</journal>
<pages>10--1349</pages>
<marker>Xu, Fern, Yoon, 2009</marker>
<rawString>Xu, Yuehua, Alan Fern, and Sungwook Yoon. 2009. Learning linear ranking functions for beam search with application to planning. Journal ofMachine Learning Research (JMLR), 10:1349–1388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beamsearch.</title>
<date>2008</date>
<booktitle>In Proceedings ofEMNLP.</booktitle>
<contexts>
<context position="3221" citStr="Zhang and Clark, 2008" startWordPosition="458" endWordPosition="461">reira, 2007; Finley and Joachims, 2008), but we ask a deeper and practically more useful question: can we modify existing learning algorithms to accommodate the inexactness in inference, so that the theoretical properties are still maintained? For the structured perceptron, Collins and Roark (2004) provides a partial answer: they suggest variant called “early update” for beam search, which updates on partial hypotheses when the correct solution falls out of the beam. This method works significantly better than standard perceptron, and is followed by later incremental parsers, for instance in (Zhang and Clark, 2008; Huang and Sagae, 2010). However, two problems remain: first, up till now there has been no theoretical justification for early update; and secondly, it makes learning extremely slow as witnessed by the above-cited papers because it only learns on partial examples and often requires 15–40 iterations to converge while normal perceptron converges in 5–10 iterations (Collins, 2002). We develop a theoretical framework of “violationfixing” perceptron that addresses these challenges. In particular, we make the following contributions: • We show that, somewhat surprisingly, exact 142 2012 Conference</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Zhang, Yue and Stephen Clark. 2008. A tale of two parsers: investigating and combining graph-based and transition-based dependency parsing using beamsearch. In Proceedings ofEMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>