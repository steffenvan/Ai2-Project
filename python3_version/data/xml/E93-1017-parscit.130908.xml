<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9015825">
The donkey strikes back
Extending the dynamic interpretation &amp;quot;constructively&amp;quot;
</title>
<author confidence="0.659269">
Tim Fernando
fernandacwi.n1
</author>
<affiliation confidence="0.599774">
Centre for Mathematics and Computer Science
</affiliation>
<address confidence="0.421343">
P.O. Box 4079, 1009 AB Amsterdam, The Netherlands
</address>
<sectionHeader confidence="0.988973" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997315">
The dynamic interpretation of a formula
as a binary relation (inducing transitions)
on states is extended by alternative treat-
ments of implication, universal quantifi-
cation, negation and disjunction that are
more &amp;quot;dynamic&amp;quot; (in a precise sense) than
the usual reductions to tests from quanti-
fied dynamic logic (which, nonetheless, can
be recovered from the new connectives). An
analysis of the &amp;quot;donkey&amp;quot; sentence followed
by the assertion &amp;quot;It will kick back&amp;quot; is pro-
vided.
</bodyText>
<sectionHeader confidence="0.999503" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993105648148148">
The line
If a farmer owns a donkey he beats it (1)
from Geach [6] is often cited as one of the success sto-
ries of the so-called &amp;quot;dynamic&amp;quot; approach to natural
language semantics (by which is meant Kamp [12],
Heim [9], Barwise [1], and Groenendijk and Stokhof
[7], among others). But add the note
It will kick back (2)
and the picture turns sour: processing (1) may leave
no beaten donkey active. Accordingly, providing a
referent for the pronoun it in (2) would appear to
call for some non-compositional surgery (that may
upset many a squeamish linguist). The present pa-
per offers, as a preventive, a &amp;quot;dynamic&amp;quot; form of im-
plication applied to (1). Based on a &amp;quot;construc-
tive&amp;quot; conception of discourse analysis, an overhaul
of Groenendijk and Stokhof [71&apos;s Dynamic Predicate
Logic (DPL) is suggested, although can also be
introduced less destructively so as to extend DPL
conservatively. Thus, the reader who prefers the
old &amp;quot;static&amp;quot; interpretation of (1) can still make that
choice, and declare the continuation (2) to be &amp;quot;se-
mantically ill-formed.&amp;quot; On the other hand, Groe-
nendijk and Stokhof [7] themselves concede that &amp;quot;at
least in certain contexts, we need alternative exter-
nally dynamic interpretations of universal quantifi-
cation, implication and negation; a both internally
and externally dynamic treatment of disjunction.&amp;quot; A
proposal for such connectives is made below, extend-
ing the dynamic interpretation in a manner analo-
gous to the extension of classical logic by constructive
logic (with its richer collection of primitive connec-
tives), through a certain conjunctive notion of par-
allelism.
To put the problem in a somewhat general per-
spective, let us step back a bit and note that in as-
signing a natural language utterance a meaning, it is
convenient to isolate an intermediate notion of (say)
a formula. By taking for granted a translation of the
utterance to a formula, certain complexities in natu-
ral language can be abstracted away, and semantics
can be understood rigorously as a map from formu-
las to meanings. Characteristic of the dynamic ap-
proach mentioned above is the identification of the
meaning of a formula A with a binary relation on
states (or contexts) describing transitions A induces,
rather than with a set of states validating A. In the
present paper, formulas are given by first-order for-
mulas, and the target binary relations given by pro-
grams. To provide an account of anaphora in natu-
ral language, DPL translates first-order formulas A
to programs ADPL from (quantified) dynamic logic
(see, for example, Harel [8]) as follows
ADPL = A? for atomic A
</bodyText>
<page confidence="0.92428">
130
</page>
<equation confidence="0.958172">
(A&amp;B)DPL = ADPL; BDPL
(A)DPL (ADPL)
(3z A)DPL = :=?; ADPL
</equation>
<bodyText confidence="0.6011105">
The negation of a program p is the dynamic logic
test
</bodyText>
<equation confidence="0.827965">
([p] -L) ?
</equation>
<bodyText confidence="0.9993428">
with universal and static features (indicated respec-
tively by [p] and ?),1 neither of which is intrinsic to
the concept of negation. Whereas some notion of uni-
versality is essential to universal quantification and
implication (which are formulated through negation
</bodyText>
<listItem confidence="0.864071">
• Vx A = --ax
A j B =
</listItem>
<bodyText confidence="0.997229666666667">
and accordingly inherit some properties of negation),
our treatment of (2) will be based on a dynamic
(rather than static) form of implication. Dynamic
forms of negation universal quantification and dis-
junction will also be proposed, but first we focus on
implication.
</bodyText>
<sectionHeader confidence="0.871416" genericHeader="method">
2 The idea in brief
</sectionHeader>
<bodyText confidence="0.9945245">
The semantics [A]] assigned to a first-order formula
A is that given to the program ADPL — i.e., a binary
relation on states. In dynamic logic, states are val-
uations; more precisely, the set of states is defined,
relative to a fixed first-order model M and a set X of
variables (from which the free variables of formulas
A are drawn), as the set 1Mix of functions f , g, . .
from X to the universe IMI of M. Atomic programs
come in two flavors: tests A? where A is a formula
in the signature of M with free variables from X,
and random assignments x :=? where x E X. These
are analyzed semantically by a function p taking a
program p to a binary relation p(p) C IMIX x
according to
f p(A?)g if f = g and M = A[f]
f p(x :=?)g if f = g except possibly at x .
The programs are then closed under sequential com-
position (interpreted as relational composition)
</bodyText>
<construct confidence="0.605891333333333">
f p(p; pi)g if f p(p)h and hp(pi)g for some h ,
non-deterministic choice (interpreted as union)
f p(p pi)g if f p(p)g or hp(Og ,
</construct>
<bodyText confidence="0.97518625">
and Kleene star (interpreted as the reflexive transive
closure). Rather than extending k simultaneously
to formulas built from modalites [p] and (p) labelled
by programs p, it is sufficient to close the programs
</bodyText>
<footnote confidence="0.966993333333333">
1 The semantics of dynamic logic is reviewed in the
next section, where what exactly is meant, for example,
by &amp;quot;static&amp;quot; is explained.
</footnote>
<bodyText confidence="0.92527475">
under a negation operation interpreted semantically
as follows
f p(--p)g if f = g and f p(p)h for no h.
As previously noted, is equivalent to ([p]1.)?.
Returning to DPL, an implication A J B between
formulas is interpreted in DPL by equating it with
(A St -,B), which is in turn translated into the
dynamic logic program
</bodyText>
<equation confidence="0.8743294">
(ADPL ; _,(BD)).
Applying the semantic function p to this then yields
siA Bit if t = s and
(Vs&apos; such that s[A]ls&apos;)
3e . (3)
</equation>
<bodyText confidence="0.8896406875">
Now, given that a state is a single function from X
to IMI, it is hardly odd that implication is static
(in the sense that the input and output states s and
I must be the same), as any number of instantia-
tions of s&apos; (and 2&apos;) may be relevant to the right hand
side of (3). That is, in terms of (1), the difficulty
is that there may be several farmer/donkey couples,
whereas a state can accomodate only one such pair,
rendering an interpretation of (2) problematic. To
overcome this predicament, the collection of states
can be extended in at least two ways.
(P1) Borrowing and modifying an idea from Kleene
[14] (and Brouwer, Kolmogorov,...), incorporate
into the final state t a functional witness f to
the Vs-clause in the right hand side of (3) to
obtain
</bodyText>
<listItem confidence="0.8695562">
4A Bit if t = (s, f) and
f is a function with
domain Is&apos; I 4A]si}
and (Vs&apos; E dom(f))
s&apos; [MIAs&apos;) .
</listItem>
<bodyText confidence="0.815934">
Or, to simplify the state t slightly, break the con-
dition (in the righthand side) up into two mutu-
ally exclusive clauses depending on whether or
not the domain of f is empty
siA Bit if (t is a function with
non-empty domain
Is&apos; I 4.211.51 and
</bodyText>
<equation confidence="0.9741876">
(Vs&apos; E dom(0)
s&apos;EBit(s&apos;))
Or
(t = S and
,
</equation>
<bodyText confidence="0.9976085">
so that closing the notion of a state under a par-
tial function space construct becomes sufficient.
</bodyText>
<page confidence="0.965722">
131
</page>
<bodyText confidence="0.8483465">
t P2) Keep only the image of a functional witness so
that the new (expanded) set of states consists
simply of the old states (i.e, valuations) together
with sets of valuations. More precisely, define
</bodyText>
<equation confidence="0.87217">
4i4 = BJJt if (3 a function f with
</equation>
<bodyText confidence="0.761665">
non-empty domain
{s&apos; I 41.41.51} where
t is the collapsed
image of f and
(Vs&apos; E dom(f))
</bodyText>
<equation confidence="0.984726142857143">
s&apos;IP31f(s1))
or
(t = s and
-.3s&apos; s[Aiss) . (4)
The &amp;quot;collapsed image of f&amp;quot;,
E !MIX J 3s&apos; As&apos;) = U
Uiti g iMix I 3.91 As&apos;) = e})
</equation>
<bodyText confidence="0.970586272727273">
is simply the image of f except that the sets of
valuations in the image are &amp;quot;collapsed&amp;quot;, so that
the resulting set has only valuations as elements.
(The collapsing is &amp;quot;justified&amp;quot; by the associativity
of conjunction.)
Observe that, in either case, DPL&apos;s negation can be
derived
= A _L
(whence j is also definable from = and &amp;). The
first proposal, (P1), yields a dizzying tower of higher-
order functions, in comparison to which, the second
proposal is considerably simpler. Behind the step
from (3) to either proposal is the idea that implica-
tion can spawn processes running in parallel. (Buried
in (3) is the possibility of the input state s branching
off to a multiplicity of states t&apos;.) The parallelism here
is &amp;quot;conjunctive&amp;quot; in that a family of parallel processes
proceeds along happily so long as every member of
the family is well; all is lost as soon as one fails.2
More precisely, observe that, under (P2), a natural
clause for s[A]i, where s is a set of valuations and A
is an atomic formula, is3
</bodyText>
<equation confidence="0.9507315">
siAlt if 3 a function f : s —+onto t such that
(Vs&apos; E s) f(s&apos;).
</equation>
<footnote confidence="0.513484714285714">
2The notion of parallelism is thus not unlike that of
concurrent dynamic logic (Peleg [19]). By contrast, the
(non-empty) sets of valuations used (e.g., in Fernando
[41) to bring out the eliminative character of information
growth induced by tests A? live disjunctively (and die
conjunctively).
2A (non-equivalent) alternative is
</footnote>
<bodyText confidence="0.907680769230769">
spit if (Vs&apos; E s) (3e E t) s&apos;IA]le and
(Vt&apos; E t) (38&apos; E s) s&apos;EAlti ,
yielding a more promiscuous ontology. This is studied in
Fernando [5], concerning which, the reader is referred to
the next footnote.
(That is, in the case of (2), every donkey that a
farmer beats according to (1) must kick back.) A
similar clause must be added to (P1), although to
make the details for (P1) obvious, it should be suffi-
cient to focus (as we will) on the case of (P2), where
the states are structurally simpler. But, then, a few
words justifying the structural simplification in (P2)
relative to (P1) might be in order.4
</bodyText>
<sectionHeader confidence="0.863154" genericHeader="method">
3 A digression: forgetfulness and
information growth
</sectionHeader>
<bodyText confidence="0.998782957446808">
If semantic analysis amounts abstractly to a mapping
from syntactic objects (or formulas) to other math-
ematical objects (that we choose to call meanings),
then what (speaking in the same abstract terms) is
gained by the translation? Beyond some vague hope
that the meanings have more illuminating structure
than have the formulas, a reason for carrying out
the semantic analysis is to abstract away inessen-
tial syntactic detail (with a view towards isolating
the essential &amp;quot;core&amp;quot;). Thus, one might expect the
semantic function not to be 1-1. The more general
point is that an essential feature of semantic analysis
is the process of forgetting what can be forgotten.
More concretely, turning to dynamic logic and its
semantic function p, observe that after executing
a random assignment x :=?, the previous (=input
state) value of x is overwritten (i.e., forgotten) in the
output state.&apos; Perhaps an even more helpful example
is the semantic definition of a sequential composition
p; p&apos;. The intermediate state arising after p but be-
fore p&apos; is forgotten by p(p; p&apos;) (tracking, as it does,
only input/output states). Should such information
be stored? No doubt, recording state histories would
not decrease the scope of the account that can then
be developed. It would almost surely increase it, but
at what cost? The simpler the semantic framework,
the better — all other things being equal, that is
(chief among which is explanatory power). Other-
wise, a delicate balance must be struck between the
complexity of the framework and its scope. Now,
part of the computational intuition underlying dy-
namic logic is that at any point in time, a state (i.e.,
valuation) embodies all that is relevant about the
past to what can happen in the future. (In other
words, the meaning of a program is specified simply
by pairs of input/output states.) This same intu-
ition underlies (P2), discarding (as it does) the wit-
4The discussion here will be confined to a somewhat
intuitive and informal level. A somewhat more techni-
cal mathematical account is developed at length in Fer-
nando [5], where (P2) is presented as a reduction of (P1)
to a disjunctive normal form (in the sense of the &amp;quot;con-
junctive&amp;quot; and &amp;quot;disjunctive&amp;quot; notions of parallelism already
mentioned).
&apos;It should, in fairness, be pointed out that Vermeulen
[22] presents a variant of dynamic logic directed towards
revising this very feature.
</bodyText>
<page confidence="0.989862">
132
</page>
<bodyText confidence="0.999927354166667">
ness function tracing processes back to their &amp;quot;roots.&amp;quot;
(Forgetting that spawning record would seem to be
akin to forgetting the intermediate state in a sequen-
tial composition p; p&apos;.) Furthermore, for applications
to natural language discourse, forgetfulness would
appear quite innocuous if the information content
of a state increases in the course of interpreting dis-
course (so that all past states have no more infor-
mation content than has the current state). And it
is quite natural in discourse analysis to assume that
information does grow.
Consider the following claim in an early paper
(Karttunen [13]) pre-occupied with a problem (viz.,
that of presuppositions) that may appear peripheral
to (1) or (2), but is nonetheless fundamental to the
&amp;quot;constructive&amp;quot; outlook on which = is based
There are definitions of pragmatic presup-
position ... which suggest that there is
something amiss in a discourse that does
not proceed in [an] ideal orderly fashion. ...
All things considered, this is an unreason-
able view. ... People do make leaps and
shortcuts by using sentences whose presup-
positions are not satisfied in the conversa-
tional context. This is the rule rather than
the exception, and we should not base our
notion of presupposition on the false pre-
miss that it does not or should not happen.
But granting that ordinary discourse is not
always fully explicit in the above sense, I
think we can maintain that a sentence is
always taken to be an increment to a con-
text that satisfies its presuppositions. [p.
191, italics added]
To bring out an important dimension of &amp;quot;increment
to a context&amp;quot;, and at the same time get around the
destruction of information in DPI by a random as-
signment, we will modify the translation -DPI- (map-
ping first-order formulas into programs) slightly into
a translation .€, over which (P2) will be worked out
(though the reader should afterwards have no dif-
ficulty carrying out the similar extension to DPI).
The modification is based (following Fernando [4],
and, further back, Barwise [1]) on (i) a switch from
valuations defined on all variables to valuations de-
fined on only finitely many variables, and on (ii) the
use of guarded assignments x := * (in place of ran-
dom assignments), given by
</bodyText>
<equation confidence="0.716291">
x = x? = x?) ; x :=? ,
</equation>
<bodyText confidence="0.8964291">
which has the effect of assigning a value to x pre-
cisely when initially x is unbound (in which case
the test x = x? fails). Note that (i) spoils biva-
lence, which is to say that certain presuppositions
may fail.6 Accordingly, our translation R(7)€ of an
6To what extent an account of presuppositions can
be based on the break down in bivalence resulting from
atomic formula R(7) to a program must first attend
to presuppositions by plugging truth gaps through
guarded assignments, before testing R(7)
</bodyText>
<equation confidence="0.990713">
RCgY = := * ; MT)? (5)
(where := * abbreviates xi := *; ...; x := * for
</equation>
<bodyText confidence="0.993294">
= xi,...,xk). To avoid clashes with variables
bound by quantifiers, the latter variables might be
marked
</bodyText>
<equation confidence="0.732045">
(3x AY = yA,. * ; A[YA,./x]e , (6)
</equation>
<bodyText confidence="0.9998285">
the idea being to sharpen (5) by translating atomic
formulas R(7, y, .7) with unmarked variables 7, and
marked variables y, (for 3 and V respectively) as
follows
</bodyText>
<equation confidence="0.997463">
= := * ; R(7, y, IT (7)
</equation>
<bodyText confidence="0.999669428571429">
Note that to assert a formula A is not simply to test
A, but also to establish A (if this is at all possible).
Establishing not A is (intuitively) different from test-
ing (as in DPI) that A cannot be established.7 A
negation reflecting the former is described next,
avoiding an appeal to a modal notion (hidden in
by writing —12 instead of ([pil..)?).
</bodyText>
<sectionHeader confidence="0.889034" genericHeader="method">
4 Working out the idea formally
</sectionHeader>
<bodyText confidence="0.999734333333333">
Starting over and proceeding a bit more rigorously
now, given a first-order signature L, throw in, for
every n-ary predicate symbol R E L, a fresh n-ary
predicate symbol Rand extend the map to these
symbols by setting R = R. Then, interpret ft in an
L-structure M as the complement of R
</bodyText>
<equation confidence="0.496724">
= _ Rm
</equation>
<bodyText confidence="0.990959666666667">
So, without loss of generality, assume that we are
working with a signature L equipped with such a
map and let M be an L-model obeying the corn-
plementarity condition above (readily expressible in
the first-order language). Fix a countable set X0 of
variables, and define two fresh (disjoint) sets Y and
Z of &amp;quot;marked&amp;quot; variables inductively simultaneously
with a set (I■ of L-formulas (built from &amp;, V, V, 3 and
#.) as follows
</bodyText>
<listItem confidence="0.999288833333333">
(i) T, I. and every atomic L-formula with free vari-
ables from Xo UYUZ is in (1)
(ii) if A and B are in (I), then so are AS6B, AVB
and A B
(iii) for every (&amp;quot;unmarked&amp;quot;) x E X0, if A E (1), then
Vx A and 3x A belong to 4&gt;
</listItem>
<footnote confidence="0.735199142857143">
uninitialized variables will not be taken up here. The in-
terested reader is referred to Fernando [4] for an internal
notion of proposition as an initial step towards this end.
7As detailed in Fernando [4], this distinction can
be exploited to provide an account of Veltman [211&apos;s
might operator as relative to an internal notion of
proposition.
</footnote>
<page confidence="0.993558">
133
</page>
<bodyText confidence="0.698789">
tsiv) for every x E Xo, if A E 4), then the fresh
(&amp;quot;marked&amp;quot;) variables yA,, and zdt,x belong to
Y and Z respectively.
Next, define a &amp;quot;negation&amp;quot; map — on by
</bodyText>
<equation confidence="0.998107375">
T =1
1 =T
=
= V
— (A V B) =
—&apos;(Vs A) = 3x -A
(3x A) =
= A &amp; .
</equation>
<bodyText confidence="0.998437">
This approach, going back at least to Nelson [17] (a
particularly appropriate reference, given its connec-
tion with Kleene [14]), treats positive and negative
information in a nearly symmetric fashion; on for-
mulas in &apos;1&apos; without an occurrence of the function
is the identity. Furthermore, were it not for
our translation -e would map formulas in 4) to
programs interpreted as binary relations on
</bodyText>
<equation confidence="0.9221302">
So = I s is a function from
a finite subset of X to
where X is the full set of marked an unmarked vari-
ables
X = Xo UYUZ
</equation>
<bodyText confidence="0.84586725">
All the same, the clauses for s[A]t can be formulated
uniformly whether or not s E So, so long as it is
understood that for a set s of valuations, u E X, and
atomic A,
</bodyText>
<equation confidence="0.946366666666667">
sp(u := *)t if 3 a function f : s t such
that (Vs&apos; E .$) p(u := *)f(s1)
sp(A?)t if t = s and (Vs&apos; E s) p(A?).91 .
</equation>
<bodyText confidence="0.96440775">
(These clauses are consistent with the intuition de-
scribed in section 2 of a &amp;quot;conjunctive&amp;quot; family of pro-
cesses running in parallel.) The translation -e is then
given by (7),
</bodyText>
<equation confidence="0.986177">
(A&amp;B)e = Ac; Be
(A V B)e = A&apos; + Be ,
</equation>
<bodyText confidence="0.806094375">
(6) and (4), with &apos;Mix replaced by So. All that
is missing is the clause for universal quantification
Vs A, which (following Kleene [14]) can be inter-
preted essentially as zA,. = zA,. A[zA,./x], ex-
cept that in the antecedent, zkr is treated as un-
marked
s[Vx Alt if t is the collapsed image of
a function f with domain
</bodyText>
<equation confidence="0.479675666666667">
Is&apos; I sp(zkx *)s&apos;l such
that (Vs&apos; E dom(f))
IA[z A / x]] f (1) .
</equation>
<bodyText confidence="0.990770272727272">
The reader seeking the definition of [All spelled out
in full is referred to the appendix.
Observe that non-deterministic choice + (for
which DPL has no use) is essential for defining
Strong negation is different from and lacks the
universal force necessary to interpret implication (ei-
ther as -)) or as -V —). On the other hand,
can be recovered as A 1, whence static impli-
cation j is also derivable. Note also that an element
s of So can be identified with {s}, yielding states of
a homogeneous form.
</bodyText>
<sectionHeader confidence="0.99042" genericHeader="method">
5 A few examples
</sectionHeader>
<bodyText confidence="0.999790583333334">
The present work does not rest on the claim that the
disorderly character of discourse mentioned above by
Karttunen [13] admits a compositional translation to
a first-order formula. The problem of translating a
natural language utterance to a first-order formula
(e.g., assigning a variable to a discourse marker) is
essentially taken for granted, falling (as it does) out-
side the scope of formal semantics (conceived as a
function from formulas to meanings). This affords
us considerable freedom to accomodate various in-
terpretations. The donkey sentence (1) can be for-
mulated as
</bodyText>
<equation confidence="0.9782882">
farmer(x) &amp; owns(x, y) &amp; donkey(y)
beats(x, y)
or given an alternative &amp;quot;weak&amp;quot; reading
farmer(x) &amp; owns(x, z) &amp; donkey(z)
owns(x, &amp; donkey(y) &amp; beats(x, y)
</equation>
<bodyText confidence="0.867467">
so that not every donkey owned by a farmer need be
beaten (Chierchia [2]). In either case, the pay back
(2) can be formulated as
kicks-back(y, s).
A further alternative that avoids presupposing the
existence of a donkey is to formulate (1) and (2) as
</bodyText>
<equation confidence="0.80458775">
farmer(x) &amp; owns(x, y) &amp; donkey(y)
beats(x, &amp; kicks-back(y, x) ,
observing that
[(A B)SLCII [A (B&amp;C)] .
</equation>
<bodyText confidence="0.9900945">
Next, we consider a few examples from Groe-
nendijk and Stokhof [7]
If a client turns up, you treat him politely.
You offer him a cup of coffee and ask
him to wait. (8)
Every player chooses a pawn. He puts it
</bodyText>
<figure confidence="0.936521">
•
IMI},
</figure>
<page confidence="0.989364">
134
</page>
<bodyText confidence="0.885817">
on square one. (9)
It is not true that John doesn&apos;t own a car.
It is red, and it is parked in front of his
house. (10)
Either there is no bathroom here, or it
is a funny place. In any case, it is not
on the first floor. (11)
Example (8) can be formulated as
</bodyText>
<equation confidence="0.99232975">
client(x) &amp; turns-up(x)
treat-politely(y, x)
followed by
off er-coffee(y, x) &amp; ask-to-wait(y, x) ,
and (9) as
player(x) choose(x, &amp; pawn(y)
followed by
put-on-square-one(x, y) .
</equation>
<bodyText confidence="0.940636">
The double negation in (10) can be analyzed dynam-
ically using •, and (11) can be treated as
</bodyText>
<equation confidence="0.815529333333333">
bathroom(x) -there(x) V funny-place
followed by
-Ion-first-floor(x) ,
</equation>
<bodyText confidence="0.999301777777778">
where, in this case, the difference between and
is immaterial.
Groenendijk and Stokhof [7] suggest equating (not
A) implies B, in its dynamic form, with A V B. To
allow not A to be dynamic, not should not be inter-
preted as But even (— A) B is different from
A V B, as the non-determinism in A V B is lost in
A) B, and may lead to structurally more
complex states (V So). What is true is that
</bodyText>
<equation confidence="0.928188">
((—A) B) = ((, A) Sz -43)
A) V B
</equation>
<bodyText confidence="0.999859294117647">
which reduces to A V B if = occurs neither in A
nor B. Whereas the translation --, yields a static
approximation, the translation applied recur-
sively, projects to an approximation that is a binary
relation on So.
Notice that quantifers do not appear in the trans-
lations above of natural language utterances into
first-order formulas. The necessary quantification is
built into the semantic analysis of quantifier-free for-
mulas, following the spirit (if not the letter) of Pagin
and Westerstal [18]. (A crucial difference, of course,
is that the universal quantification above arises from
a dynamic The reader interested in composi-
tionality should be pleased by this feature, insofar as
quantifer-free formulas avoid the non-compositional
relabelling of variables bound by quantifiers (in the
semantic analysis above of quantified formulas).
</bodyText>
<sectionHeader confidence="0.925591" genericHeader="method">
6 Concerning certain points
</sectionHeader>
<bodyText confidence="0.984289928571428">
The present paper is admittedly short on linguistic
examples — a defect that the author hopes some
sympathetic reader (better qualified than he) will
correct. Towards this end, it may be helpful to take
up specific points (beyond the need for linguistic ex-
amples) raised in the review of the work (in the form
it was originally submitted to EACL).
Referee 1. What are the advantages over expla-
nations of the anaphoric phenomenon in question in
terms of discourse structure which do not require a
change of the formal semantics apparatus?
The &amp;quot;anaphoric phenomenon in question&amp;quot; amounts,
under the analysis of first-order formulas as pro-
grams, to the treatment of variables across sentential
boundaries. A variable can have existential force, as
does the farmer in
A farmer owns a donkey,
or universal force, as does the farmer in
Every farmer owns a donkey.
Taking the &amp;quot;the formal semantics apparatus&amp;quot; to
be dynamic logic, DPL treats existential variables
through random assignments. The advantage of the
proposal(s) above is the treatment of universal vari-
ables across sentential variables, based on an exten-
sion of dynamic logic with an implication connective
(defined by (4), if A and B are understood as pro-
grams). (Note that negation and disjunction can be
analyzed dynamically already within dynamic logic.)
</bodyText>
<figureCaption confidence="0.744059666666667">
Referee 2. Suggestions for choosing between the
static/dynamic versions would enhance the useful-
ness of the framework.
</figureCaption>
<bodyText confidence="0.9996858">
Choose the dynamic version. Matching discourse
items with variables is, afterall, done by magic,
falling (as it does) outside the scope of DPL or Dis-
course Representation Theory (DRT, Kamp [121).
But the reader may have good reason to object.
</bodyText>
<listItem confidence="0.8037915">
Programme Committee. A comparison to a
DRT-style semantics should be added.
</listItem>
<bodyText confidence="0.999752222222222">
Yes, the author would like to describe the discourse
representation structures (DRS&apos;s) for the extension
to higher-order states above. Unfortunately, he does
not (at present) know how to.8 Short of that, it
may be helpful to present the passage to states that
are conjunctive sets of valuations in a different light.
Given a state that is a set s of valuations si, 52, • • -)
let X, be the set of variables in the domain of some
si E s
</bodyText>
<equation confidence="0.6659195">
X, = U dom(si) .
si Es
</equation>
<footnote confidence="0.94173775">
8Some steps (related to footnote 4) towards that di-
rection are taken in Fernando [5]. Another approach,
somewhat more syntactic in spirit, would be to build on
K. Fine&apos;s arbitrary objects (Meyer Viol [15]).
</footnote>
<page confidence="0.997956">
135
</page>
<bodyText confidence="0.99918825">
Now, s can be viewed as a set F, of functions fr
labelled by variables x E X, as follows. Let fx be
the map with domain {si E s x E dom(si)} that
sends such an si to si(x). In pictures, we pass from
</bodyText>
<equation confidence="0.9745614">
/si : di --- ci
s2 : d2 ---). C2
to
Ifx&apos; : {si E s I xi E di} —■ ci
F, = Pa : {si E s I x2 E di} -- c2
</equation>
<bodyText confidence="0.9968342">
so that the step from states 81,82, in So to the
more complicated states s in Power(So) amounts to
a semantic analysis of variables as functions, rather
than as fixed values from the underlying first-order
model. (But now what is the domain of such a func-
tion?) The shift in point of view here is essentially
the &amp;quot;ingenious little trick&amp;quot; that Muskens [16] (p. 418)
traces back to Janssen [111 of swapping rows with
columns. We should be careful to note, however,
that the preceding analysis of variables was carried
out relative to a fixed state s — a state s that is
to be supplied as an argument to the partial binary
functions globally representing the variables.
Finally, A. Visser and J. van Eijck have suggested
that a comparison with type-theoretic and game-
theoretical semantics (e.g., Ranta [20] and Hintikka
and Kulas 1.10.1) is in order.
This again is no simple matter to discuss, and (alas)
falls somewhat beyond the scope of the present pa-
per. For now, suffice it to say that (i) the trans-
lation .6 above starts from first-order formulas, on
which (according to Ranta [20], p. 378) the game-
theoretic &amp;quot;truth definition is equivalent to the tra-
ditional Tarskian one&amp;quot;, and that (ii) the use of con-
structive logic in Ranta [20] renders the reduction
from the proposal (P1) to (P2) (described in section
2) implausible inasmuch as that represents a (con-
structively unsound) transformation to a disjunctive
normal form (referred to in footnote 4). But what
about constructiveness?
</bodyText>
<subsectionHeader confidence="0.509463">
7 Between construction and truth
</subsectionHeader>
<bodyText confidence="0.9999823125">
Having passed somewhat hastily from (P1) to (P2),
the reader is entitled to ask why the present au-
thor has bothered mentioning realizability (allud-
ing somewhat fashionably or unfashionably to &amp;quot;con-
structiveness&amp;quot;) and has said nothing about (classical)
modal logic-style formalizations (e.g., Van Eijck and
De Vries [3]), building say on concurrent dynamic
logic (Peleg [19]). A short answer is that the con-
nection with so-called and/or computations came to
the author only after trying to understand the inter-
pretation of implication in Kleene [14] (interpreting
implication as a program construct being nowhere
suggested in Peleg [19], which instead introduces a
&amp;quot;conjunction&amp;quot; n on programs). A more serious an-
swer would bring up his attitude towards the more
interesting question
</bodyText>
<note confidence="0.439833">
does all talk about so-called dynamic
semantics come to modal logic?
</note>
<bodyText confidence="0.99748112">
The crazy appeal dynamic semantics exerts on the
author is the claim that a formula (normally con-
ceived statically) is a program (i.e., something dy-
namic); showing how a program can be understood
statically is less exciting. Some may, of course, find
the possibility of &amp;quot;going static&amp;quot; as well as &amp;quot;going dy-
namic&amp;quot; comforting (if not pleasing). But if reduc-
ing dynamic semantics to static truth conditions is
to complete that circle, then formulas must first be
translated to programs. And that step ought not to
be taken completely for granted (or else why bother
talking about &amp;quot;dynamic semantics&amp;quot;). Understanding
a computer program in a precise (say &amp;quot;mathemati-
cal&amp;quot;) sense is, in principle, to be expected insofar
as the states through which the computer program
evolves can be examined. If a program can be im-
plemented in a machine, then it has a well-defined
operational semantics that, moreover, is subject (in
some sense or another) to Church&apos;s thesis. In that
sense, understanding a computer program relative
to a mathematical world of eternal truths and static
formulas is not too problematic. Not too problem-
atic, that is, when compared to natural language,
for which nothing like Church&apos;s thesis has gained ac-
ceptance. To say that
natural language is a programming language
is outrageous (— perhaps deliberately so —), and
those of us laboring under this slogan must admit
that we do not know how to translate an English
sentence into a FORTRAN program (whatever that
may mean). Nor, allowing for certain abstractions,
formulas into programs. Furthermore, a favorite toy
translation, DPL, goes beyond ordinary computabil-
ity (and FORTRAN) when interpreted over the nat-
ural numbers. (The culprit is Not that the
idea of a program must necessarily be understood
in the strict sense of ordinary recursion theory. But
some sensitivity to matters relating to computation
(&amp;quot;broadly construed&amp;quot;) is surely in order when speak-
ing of programs.
It was the uncomputable character of DPL&apos;s nega-
tion and implication that, in fact, drove the present
work. Strong negation — is, from this standpoint,
a mild improvement, but it would appear that the
situation for implication has only been made more
complicated. This complication can be seen, how-
ever, as only a first step towards getting a handle on
the computational character of the programs used
in interpreting formulas dynamically. Whether more
effective forms of realizability (incorporating, as was
</bodyText>
<equation confidence="0.785168">
S =
</equation>
<page confidence="0.991762">
136
</page>
<bodyText confidence="0.994787085106383">
originally conceived, some notion of construction or
proof into the witnessing by functions) can shed any
helpful light on the idea of dynamic semantics is
an open question. That realizability should, crazily
enough, have anything to say whatsoever about a lin-
guistic problem might hearten those of us inclined to
investigate the matter. (Of course, one might take
the easy way out, and simply restrict = to finite
models.)
Making certain features explicit that are typically
buried in classical logic (such as the witness to the
V3-clause in is a characteristic practice of con-
structive mathematics that just might prove fruit-
ful in natural language semantics. A feature that
would seem particularly relevant to the intuition that
discourse interpretation amounts to the construction
of a context is information growth.9 The extension
of the domain of a finite valuation is an important
aspect of that growth (as shown in Fernando [4],
appealing to Henkin witnesses, back-and-forth con-
structions, ...). The custom in dynamic logic of re-
ducing a finite valuation to the set of its total ex-
tensions (relative to which a static notion of truth is
then defined) would appear to run roughshod over
this feature — a feature carefully employed above to
draw a distinction between establishing and testing
a formula (mentioned back at the end of section 3).
But returning to the dynamic implication = intro-
duced above, observe that beyond the loss of struc-
ture (and information) in the step from (P1) to (P2),
it is possible within (P2) (or, for that matter, within
(P1)) to approximate by more modest extensions.
There is, for instance, the translation ,••••,••• • (not to
be confused with which (in general) abstracts
away structure with each application. The interpre-
tation of implication can be simplified further by not-
ing that –or can be recovered as r I, and thus the
static implication D of DPL can be derived from
Reflecting on these simplifications, it is natural to
ask what structure can dynamic semantics afford to
forget?
Is there more structure lurking behind
construction than concerns truth?
With the benefit of the discussion above about
the dual (establishing/testing) nature of asserting a
proposition — or perhaps even without being sub-
jected to all that babble —, surely we can agree that
</bodyText>
<subsubsectionHeader confidence="0.6425525">
Story-telling requires more imagination
than verifying facts.
</subsubsectionHeader>
<bodyText confidence="0.99987575">
&apos;The idea that information grows during the run of
a typical computer program is, by comparison, not so
clear. One difference is that whereas guarded assign-
ments would seem sufficient for natural language appli-
cations, a typical computer program will repeatedly as-
sign different values to the same variable. To pursue the
matter further, the reader may wish to (again) consult
Vermerden [22].
</bodyText>
<sectionHeader confidence="0.995467" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.953044647058824">
My thanks to J. van Eijck and J. Ginzburg for
criticisms of a draft, to K. Vermeulen, W. Meyer-
Viol, A. Visser, P. Blackburn D. Beaver, and M.
Kanazawa for helpful discussions, and to the con-
ference&apos;s anonymous referees for various suggestions.
Appendix: (P2) fleshed out without
prose
Fix a first-order model M and a set X of vari-
ables partitioned between the unmarked (x,...) and
marked (y,... and z, . .. for existential and universal
quantification, respectively). (It may be advisable to
ignore the marking of variables, and quantified for-
mulas; see section 5 for some examples.) Let So be
the set of functions defined on a finite subset of X,
ranging over the universe of M. Given a sequence Ti
of variables ui, , un in X, define the binary rela-
tion p(ii := 4,) on s and t E So U Power(S0) by
</bodyText>
<equation confidence="0.636897833333333">
sP(li := *)i if (s E So , t E So , t s and
dom(t) = dom(s) U {u1, • • • , un))
or
(s ,So and
3 a function f s —onto t such
that (Vs&apos; E s) :=
</equation>
<bodyText confidence="0.924140333333333">
L-formulas A from the set 4) defined in section 3 are
interpreted semantically by binary relations
IA] C (So U Power(S0)) x
(S0 U Power(So))
according to the following clauses, understood induc-
tively
</bodyText>
<reference confidence="0.563530555555556">
sl[R(7, Ti)]It if (s E So , sp(-Z
and M = R[t])
or
(3 a function f from
s onto t such that
(Vs&apos; E s)
417(7, -g , lf(s1))
si[A&amp;Bit if s[A]Ju and u[B]it for
some u
444 V Lilt if or 4/3]Jt
sIJVx AI if I is the collapsed image
of a function f with
domain
fs&apos; J sp(zA,z := &apos;OW}
such that
(Vs&apos; E dom(f))
s&apos;i[A[zA,r/xElf(si)
sPx AI if sP(YA,z := *)u and
</reference>
<page confidence="0.977733">
137
</page>
<figure confidence="0.951604">
nEA[yA,x/ xly for
some u
4A = Bit if (3 a function f with
non-empty domain
Is&apos; ( 4API where
t is the collapsed
image of f and
(Vs&apos; E dom(f))
s&apos;[B] f(s&apos;))
or
(1 = s and
s[A]s1) ,
</figure>
<bodyText confidence="0.71778175">
and, not to forget negation,
sirit if s = t
if you&apos;re a donkey
(in which case you are free to derive anything).
</bodyText>
<sectionHeader confidence="0.993887" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99994252">
[1] Jon Barwise. Noun phrases, generalized quan-
tifiers and anaphora. In E. Engda.h1 and
P. Gardenfors, editors, Generalized Quantifiers,
Studies in Language and Philosophy. Dordrecht:
Rediel, 1987.
[2] G. Chierchia. Anaphora and dynamic logic.
ITLI Prepublication, University of Amsterdam,
1990.
[3] J. van Eijck and F.J. de Vries. Dynamic inter-
pretation and Hoare deduction. J. Logic, Lan-
guage and Information, 1, 1992.
[4] Tim Fernando. Transition systems and dynamic
semantics. In D. Pearce and G. Wagner, edi-
tors, Logics in Al, LNCS 633 (subseries LNAI).
Springer-Verlag, Berlin, 1992. A slightly cor-
rected version has appeared as CWI Report CS-
R9217, June 1992.
[5] Tim Fernando. A higher-order extension of con-
straint programming in discourse analysis. Po-
sition paper for the First Workshop on Princi-
ples and Practice of Constraint Programming
(Rhode Island, April 1993).
[6] P.T. Geach. Reference and Generality: an Ex-
amination of Some Medieval and Modern The-
ories. Cornell University Press, Ithaca, 1962.
[7] J. Groenendijk and M. Stokhof. Dynamic predi-
cate logic. Linguistics and Philosophy, 14, 1991.
[8] David Hare!. Dynamic logic. In D. Gabbay and
F. Guenthner, editors, Handbook of Philosophi-
cal Logic, Volume 2. D. Reidel, 1984.
[9] Irene Heim. The semantics of definite and in-
definite noun phrases. Dissertation, University
of Massachusetts, Amherst, 1982.
[10] J. Hintikka and J. Kulas. The Game of Lan-
guage. D. Reidel, Dordrecht, 1983.
[11] Theo Janssen. Foundations and Applications of
Montague Grammar. Dissertation, University of
Amsterdam (published in 1986 by CWI, Ams-
terdam), 1983.
[12] J.A.W. Kamp. A theory of truth and semantic
representation. In J. Groenendijk et. al., edi-
tors, Formal Methods in the Study of Language.
Mathematical Centre Tracts 135, Amsterdam,
1981.
[13] Lauri Karttunen. Presupposition and linguistic
context. Theoretical Linguistics, pages 181-194,
1973.
[14] S.C. Kleene. On the interpretation of intuition-
istic number theory. J. Symbolic Logic, 10, 1945.
[15] W.P.M. Meyer Viol. Partial objects and DRT.
In P. Dekker and M. Stokhof, editors, Proceed-
ings of the Eighth Amsterdam Colloquium. In-
stitute for Logic, Language and Computation,
Amsterdam, 1992.
[16] Reinhard Muskens. Anaphora and the logic of
change. In J. van Eijck, editor, Logics in AI:
Proc. European Workshop JELIA &apos;90. Springer-
Verlag, 1991.
[17] David Nelson. Constructible falsity. J. Symbolic
Logic, 14, 1949.
[18] P. Pagin and D. Westerstahl. Predicate logic
with flexibly binding operators and natural lan-
guage semantics. Preprint.
[19] David Peleg. Concurrent dynamic logic. J. As-
soc. Computing Machinery, 34(2), 1987.
[20] Aarne Ranta. Propositions as games as types.
Synthese, 76, 1988.
[21] Frank Veltman. Defaults in update semantics.
In J.A.W. Kamp, editor, Conditionals, Defaults
and Belief Revision. Edinburgh, Dyana deliver-
able R2.5.A, 1990.
[22] C.F.M. Vermeulen. Sequence semantics for dy-
namic logic. Technical report, Philosophy De-
partment, Utrecht, 1991. To appear in J. Logic,
Language and Information.
</reference>
<page confidence="0.997344">
138
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.490650">
<title confidence="0.997367">The donkey strikes back Extending the dynamic interpretation &amp;quot;constructively&amp;quot;</title>
<author confidence="0.999933">Tim Fernando</author>
<email confidence="0.642774">fernandacwi.n1</email>
<affiliation confidence="0.994865">Centre for Mathematics and Computer Science</affiliation>
<address confidence="0.98496">P.O. Box 4079, 1009 AB Amsterdam, The Netherlands</address>
<abstract confidence="0.982987769230769">The dynamic interpretation of a formula as a binary relation (inducing transitions) on states is extended by alternative treatments of implication, universal quantification, negation and disjunction that are more &amp;quot;dynamic&amp;quot; (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives). An analysis of the &amp;quot;donkey&amp;quot; sentence followed by the assertion &amp;quot;It will kick back&amp;quot; is provided.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>slIt if</author>
</authors>
<title>R[t]) or (3 a function f from s onto t such that (Vs&apos; E s) 417(7, -g , lf(s1)) si[A&amp;Bit if s[A]Ju and u[B]it for some u 444 V Lilt if or 4/3]Jt sIJVx AI if I is the collapsed image of a function f with domain fs&apos; J sp(zA,z := &apos;OW} such that (Vs&apos; E dom(f)) s&apos;i[A[zA,r/xElf(si) sPx AI if sP(YA,z := *)u and</title>
<marker>if, </marker>
<rawString> sl[R(7, Ti)]It if (s E So , sp(-Z and M = R[t]) or (3 a function f from s onto t such that (Vs&apos; E s) 417(7, -g , lf(s1)) si[A&amp;Bit if s[A]Ju and u[B]it for some u 444 V Lilt if or 4/3]Jt sIJVx AI if I is the collapsed image of a function f with domain fs&apos; J sp(zA,z := &apos;OW} such that (Vs&apos; E dom(f)) s&apos;i[A[zA,r/xElf(si) sPx AI if sP(YA,z := *)u and</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Barwise</author>
</authors>
<title>Noun phrases, generalized quantifiers and anaphora.</title>
<date>1987</date>
<booktitle>Generalized Quantifiers, Studies in Language and Philosophy.</booktitle>
<editor>In E. Engda.h1 and P. Gardenfors, editors,</editor>
<location>Dordrecht: Rediel,</location>
<contexts>
<context position="922" citStr="[1]" startWordPosition="145" endWordPosition="145">lternative treatments of implication, universal quantification, negation and disjunction that are more &amp;quot;dynamic&amp;quot; (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives). An analysis of the &amp;quot;donkey&amp;quot; sentence followed by the assertion &amp;quot;It will kick back&amp;quot; is provided. 1 Introduction The line If a farmer owns a donkey he beats it (1) from Geach [6] is often cited as one of the success stories of the so-called &amp;quot;dynamic&amp;quot; approach to natural language semantics (by which is meant Kamp [12], Heim [9], Barwise [1], and Groenendijk and Stokhof [7], among others). But add the note It will kick back (2) and the picture turns sour: processing (1) may leave no beaten donkey active. Accordingly, providing a referent for the pronoun it in (2) would appear to call for some non-compositional surgery (that may upset many a squeamish linguist). The present paper offers, as a preventive, a &amp;quot;dynamic&amp;quot; form of implication applied to (1). Based on a &amp;quot;constructive&amp;quot; conception of discourse analysis, an overhaul of Groenendijk and Stokhof [71&apos;s Dynamic Predicate Logic (DPL) is suggested, although can also be introduced l</context>
<context position="13917" citStr="[1]" startWordPosition="2406" endWordPosition="2406">tence is always taken to be an increment to a context that satisfies its presuppositions. [p. 191, italics added] To bring out an important dimension of &amp;quot;increment to a context&amp;quot;, and at the same time get around the destruction of information in DPI by a random assignment, we will modify the translation -DPI- (mapping first-order formulas into programs) slightly into a translation .€, over which (P2) will be worked out (though the reader should afterwards have no difficulty carrying out the similar extension to DPI). The modification is based (following Fernando [4], and, further back, Barwise [1]) on (i) a switch from valuations defined on all variables to valuations defined on only finitely many variables, and on (ii) the use of guarded assignments x := * (in place of random assignments), given by x = x? = x?) ; x :=? , which has the effect of assigning a value to x precisely when initially x is unbound (in which case the test x = x? fails). Note that (i) spoils bivalence, which is to say that certain presuppositions may fail.6 Accordingly, our translation R(7)€ of an 6To what extent an account of presuppositions can be based on the break down in bivalence resulting from atomic formu</context>
</contexts>
<marker>[1]</marker>
<rawString>Jon Barwise. Noun phrases, generalized quantifiers and anaphora. In E. Engda.h1 and P. Gardenfors, editors, Generalized Quantifiers, Studies in Language and Philosophy. Dordrecht: Rediel, 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Chierchia</author>
</authors>
<title>Anaphora and dynamic logic. ITLI Prepublication,</title>
<date>1990</date>
<location>University of Amsterdam,</location>
<contexts>
<context position="19652" citStr="[2]" startWordPosition="3489" endWordPosition="3489">ing a natural language utterance to a first-order formula (e.g., assigning a variable to a discourse marker) is essentially taken for granted, falling (as it does) outside the scope of formal semantics (conceived as a function from formulas to meanings). This affords us considerable freedom to accomodate various interpretations. The donkey sentence (1) can be formulated as farmer(x) &amp; owns(x, y) &amp; donkey(y) beats(x, y) or given an alternative &amp;quot;weak&amp;quot; reading farmer(x) &amp; owns(x, z) &amp; donkey(z) owns(x, &amp; donkey(y) &amp; beats(x, y) so that not every donkey owned by a farmer need be beaten (Chierchia [2]). In either case, the pay back (2) can be formulated as kicks-back(y, s). A further alternative that avoids presupposing the existence of a donkey is to formulate (1) and (2) as farmer(x) &amp; owns(x, y) &amp; donkey(y) beats(x, &amp; kicks-back(y, x) , observing that [(A B)SLCII [A (B&amp;C)] . Next, we consider a few examples from Groenendijk and Stokhof [7] If a client turns up, you treat him politely. You offer him a cup of coffee and ask him to wait. (8) Every player chooses a pawn. He puts it • IMI}, 134 on square one. (9) It is not true that John doesn&apos;t own a car. It is red, and it is parked in fron</context>
</contexts>
<marker>[2]</marker>
<rawString>G. Chierchia. Anaphora and dynamic logic. ITLI Prepublication, University of Amsterdam, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van Eijck</author>
<author>F J de Vries</author>
</authors>
<title>Dynamic interpretation and Hoare deduction.</title>
<date>1992</date>
<journal>J. Logic, Language and Information,</journal>
<volume>1</volume>
<contexts>
<context position="26606" citStr="[3]" startWordPosition="4705" endWordPosition="4705">] renders the reduction from the proposal (P1) to (P2) (described in section 2) implausible inasmuch as that represents a (constructively unsound) transformation to a disjunctive normal form (referred to in footnote 4). But what about constructiveness? 7 Between construction and truth Having passed somewhat hastily from (P1) to (P2), the reader is entitled to ask why the present author has bothered mentioning realizability (alluding somewhat fashionably or unfashionably to &amp;quot;constructiveness&amp;quot;) and has said nothing about (classical) modal logic-style formalizations (e.g., Van Eijck and De Vries [3]), building say on concurrent dynamic logic (Peleg [19]). A short answer is that the connection with so-called and/or computations came to the author only after trying to understand the interpretation of implication in Kleene [14] (interpreting implication as a program construct being nowhere suggested in Peleg [19], which instead introduces a &amp;quot;conjunction&amp;quot; n on programs). A more serious answer would bring up his attitude towards the more interesting question does all talk about so-called dynamic semantics come to modal logic? The crazy appeal dynamic semantics exerts on the author is the clai</context>
</contexts>
<marker>[3]</marker>
<rawString>J. van Eijck and F.J. de Vries. Dynamic interpretation and Hoare deduction. J. Logic, Language and Information, 1, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Transition systems and dynamic semantics.</title>
<date>1992</date>
<booktitle>Logics in Al, LNCS 633 (subseries LNAI).</booktitle>
<editor>In D. Pearce and G. Wagner, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<location>Berlin,</location>
<contexts>
<context position="13885" citStr="[4]" startWordPosition="2401" endWordPosition="2401">think we can maintain that a sentence is always taken to be an increment to a context that satisfies its presuppositions. [p. 191, italics added] To bring out an important dimension of &amp;quot;increment to a context&amp;quot;, and at the same time get around the destruction of information in DPI by a random assignment, we will modify the translation -DPI- (mapping first-order formulas into programs) slightly into a translation .€, over which (P2) will be worked out (though the reader should afterwards have no difficulty carrying out the similar extension to DPI). The modification is based (following Fernando [4], and, further back, Barwise [1]) on (i) a switch from valuations defined on all variables to valuations defined on only finitely many variables, and on (ii) the use of guarded assignments x := * (in place of random assignments), given by x = x? = x?) ; x :=? , which has the effect of assigning a value to x precisely when initially x is unbound (in which case the test x = x? fails). Note that (i) spoils bivalence, which is to say that certain presuppositions may fail.6 Accordingly, our translation R(7)€ of an 6To what extent an account of presuppositions can be based on the break down in bival</context>
<context position="16466" citStr="[4]" startWordPosition="2889" endWordPosition="2889">rnplementarity condition above (readily expressible in the first-order language). Fix a countable set X0 of variables, and define two fresh (disjoint) sets Y and Z of &amp;quot;marked&amp;quot; variables inductively simultaneously with a set (I■ of L-formulas (built from &amp;, V, V, 3 and #.) as follows (i) T, I. and every atomic L-formula with free variables from Xo UYUZ is in (1) (ii) if A and B are in (I), then so are AS6B, AVB and A B (iii) for every (&amp;quot;unmarked&amp;quot;) x E X0, if A E (1), then Vx A and 3x A belong to 4&gt; uninitialized variables will not be taken up here. The interested reader is referred to Fernando [4] for an internal notion of proposition as an initial step towards this end. 7As detailed in Fernando [4], this distinction can be exploited to provide an account of Veltman [211&apos;s might operator as relative to an internal notion of proposition. 133 tsiv) for every x E Xo, if A E 4), then the fresh (&amp;quot;marked&amp;quot;) variables yA,, and zdt,x belong to Y and Z respectively. Next, define a &amp;quot;negation&amp;quot; map — on by T =1 1 =T = = V — (A V B) = —&apos;(Vs A) = 3x -A (3x A) = = A &amp; . This approach, going back at least to Nelson [17] (a particularly appropriate reference, given its connection with Kleene [14]), trea</context>
<context position="30529" citStr="[4]" startWordPosition="5336" endWordPosition="5336">tter. (Of course, one might take the easy way out, and simply restrict = to finite models.) Making certain features explicit that are typically buried in classical logic (such as the witness to the V3-clause in is a characteristic practice of constructive mathematics that just might prove fruitful in natural language semantics. A feature that would seem particularly relevant to the intuition that discourse interpretation amounts to the construction of a context is information growth.9 The extension of the domain of a finite valuation is an important aspect of that growth (as shown in Fernando [4], appealing to Henkin witnesses, back-and-forth constructions, ...). The custom in dynamic logic of reducing a finite valuation to the set of its total extensions (relative to which a static notion of truth is then defined) would appear to run roughshod over this feature — a feature carefully employed above to draw a distinction between establishing and testing a formula (mentioned back at the end of section 3). But returning to the dynamic implication = introduced above, observe that beyond the loss of structure (and information) in the step from (P1) to (P2), it is possible within (P2) (or, </context>
</contexts>
<marker>[4]</marker>
<rawString>Tim Fernando. Transition systems and dynamic semantics. In D. Pearce and G. Wagner, editors, Logics in Al, LNCS 633 (subseries LNAI). Springer-Verlag, Berlin, 1992. A slightly corrected version has appeared as CWI Report CSR9217, June 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>A higher-order extension of constraint programming in discourse analysis. Position paper for the</title>
<date>1993</date>
<booktitle>First Workshop on Principles and Practice of Constraint Programming</booktitle>
<location>Rhode Island,</location>
<contexts>
<context position="8981" citStr="[5]" startWordPosition="1585" endWordPosition="1585"> s[A]i, where s is a set of valuations and A is an atomic formula, is3 siAlt if 3 a function f : s —+onto t such that (Vs&apos; E s) f(s&apos;). 2The notion of parallelism is thus not unlike that of concurrent dynamic logic (Peleg [19]). By contrast, the (non-empty) sets of valuations used (e.g., in Fernando [41) to bring out the eliminative character of information growth induced by tests A? live disjunctively (and die conjunctively). 2A (non-equivalent) alternative is spit if (Vs&apos; E s) (3e E t) s&apos;IA]le and (Vt&apos; E t) (38&apos; E s) s&apos;EAlti , yielding a more promiscuous ontology. This is studied in Fernando [5], concerning which, the reader is referred to the next footnote. (That is, in the case of (2), every donkey that a farmer beats according to (1) must kick back.) A similar clause must be added to (P1), although to make the details for (P1) obvious, it should be sufficient to focus (as we will) on the case of (P2), where the states are structurally simpler. But, then, a few words justifying the structural simplification in (P2) relative to (P1) might be in order.4 3 A digression: forgetfulness and information growth If semantic analysis amounts abstractly to a mapping from syntactic objects (or</context>
<context position="11574" citStr="[5]" startWordPosition="2020" endWordPosition="2020">e must be struck between the complexity of the framework and its scope. Now, part of the computational intuition underlying dynamic logic is that at any point in time, a state (i.e., valuation) embodies all that is relevant about the past to what can happen in the future. (In other words, the meaning of a program is specified simply by pairs of input/output states.) This same intuition underlies (P2), discarding (as it does) the wit4The discussion here will be confined to a somewhat intuitive and informal level. A somewhat more technical mathematical account is developed at length in Fernando [5], where (P2) is presented as a reduction of (P1) to a disjunctive normal form (in the sense of the &amp;quot;conjunctive&amp;quot; and &amp;quot;disjunctive&amp;quot; notions of parallelism already mentioned). &apos;It should, in fairness, be pointed out that Vermeulen [22] presents a variant of dynamic logic directed towards revising this very feature. 132 ness function tracing processes back to their &amp;quot;roots.&amp;quot; (Forgetting that spawning record would seem to be akin to forgetting the intermediate state in a sequential composition p; p&apos;.) Furthermore, for applications to natural language discourse, forgetfulness would appear quite inno</context>
<context position="24340" citStr="[5]" startWordPosition="4298" endWordPosition="4298">tee. A comparison to a DRT-style semantics should be added. Yes, the author would like to describe the discourse representation structures (DRS&apos;s) for the extension to higher-order states above. Unfortunately, he does not (at present) know how to.8 Short of that, it may be helpful to present the passage to states that are conjunctive sets of valuations in a different light. Given a state that is a set s of valuations si, 52, • • -) let X, be the set of variables in the domain of some si E s X, = U dom(si) . si Es 8Some steps (related to footnote 4) towards that direction are taken in Fernando [5]. Another approach, somewhat more syntactic in spirit, would be to build on K. Fine&apos;s arbitrary objects (Meyer Viol [15]). 135 Now, s can be viewed as a set F, of functions fr labelled by variables x E X, as follows. Let fx be the map with domain {si E s x E dom(si)} that sends such an si to si(x). In pictures, we pass from /si : di --- ci s2 : d2 ---). C2 to Ifx&apos; : {si E s I xi E di} —■ ci F, = Pa : {si E s I x2 E di} -- c2 so that the step from states 81,82, in So to the more complicated states s in Power(So) amounts to a semantic analysis of variables as functions, rather than as fixed valu</context>
</contexts>
<marker>[5]</marker>
<rawString>Tim Fernando. A higher-order extension of constraint programming in discourse analysis. Position paper for the First Workshop on Principles and Practice of Constraint Programming (Rhode Island, April 1993).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P T Geach</author>
</authors>
<title>Reference and Generality: an Examination of Some Medieval and Modern Theories.</title>
<date>1962</date>
<publisher>Cornell University Press,</publisher>
<location>Ithaca,</location>
<contexts>
<context position="759" citStr="[6]" startWordPosition="116" endWordPosition="116">ox 4079, 1009 AB Amsterdam, The Netherlands Abstract The dynamic interpretation of a formula as a binary relation (inducing transitions) on states is extended by alternative treatments of implication, universal quantification, negation and disjunction that are more &amp;quot;dynamic&amp;quot; (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives). An analysis of the &amp;quot;donkey&amp;quot; sentence followed by the assertion &amp;quot;It will kick back&amp;quot; is provided. 1 Introduction The line If a farmer owns a donkey he beats it (1) from Geach [6] is often cited as one of the success stories of the so-called &amp;quot;dynamic&amp;quot; approach to natural language semantics (by which is meant Kamp [12], Heim [9], Barwise [1], and Groenendijk and Stokhof [7], among others). But add the note It will kick back (2) and the picture turns sour: processing (1) may leave no beaten donkey active. Accordingly, providing a referent for the pronoun it in (2) would appear to call for some non-compositional surgery (that may upset many a squeamish linguist). The present paper offers, as a preventive, a &amp;quot;dynamic&amp;quot; form of implication applied to (1). Based on a &amp;quot;constru</context>
</contexts>
<marker>[6]</marker>
<rawString>P.T. Geach. Reference and Generality: an Examination of Some Medieval and Modern Theories. Cornell University Press, Ithaca, 1962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Groenendijk</author>
<author>M Stokhof</author>
</authors>
<title>Dynamic predicate logic.</title>
<date>1991</date>
<journal>Linguistics and Philosophy,</journal>
<volume>14</volume>
<contexts>
<context position="955" citStr="[7]" startWordPosition="150" endWordPosition="150">ion, universal quantification, negation and disjunction that are more &amp;quot;dynamic&amp;quot; (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives). An analysis of the &amp;quot;donkey&amp;quot; sentence followed by the assertion &amp;quot;It will kick back&amp;quot; is provided. 1 Introduction The line If a farmer owns a donkey he beats it (1) from Geach [6] is often cited as one of the success stories of the so-called &amp;quot;dynamic&amp;quot; approach to natural language semantics (by which is meant Kamp [12], Heim [9], Barwise [1], and Groenendijk and Stokhof [7], among others). But add the note It will kick back (2) and the picture turns sour: processing (1) may leave no beaten donkey active. Accordingly, providing a referent for the pronoun it in (2) would appear to call for some non-compositional surgery (that may upset many a squeamish linguist). The present paper offers, as a preventive, a &amp;quot;dynamic&amp;quot; form of implication applied to (1). Based on a &amp;quot;constructive&amp;quot; conception of discourse analysis, an overhaul of Groenendijk and Stokhof [71&apos;s Dynamic Predicate Logic (DPL) is suggested, although can also be introduced less destructively so as to extend</context>
<context position="20000" citStr="[7]" startWordPosition="3550" endWordPosition="3550">ce (1) can be formulated as farmer(x) &amp; owns(x, y) &amp; donkey(y) beats(x, y) or given an alternative &amp;quot;weak&amp;quot; reading farmer(x) &amp; owns(x, z) &amp; donkey(z) owns(x, &amp; donkey(y) &amp; beats(x, y) so that not every donkey owned by a farmer need be beaten (Chierchia [2]). In either case, the pay back (2) can be formulated as kicks-back(y, s). A further alternative that avoids presupposing the existence of a donkey is to formulate (1) and (2) as farmer(x) &amp; owns(x, y) &amp; donkey(y) beats(x, &amp; kicks-back(y, x) , observing that [(A B)SLCII [A (B&amp;C)] . Next, we consider a few examples from Groenendijk and Stokhof [7] If a client turns up, you treat him politely. You offer him a cup of coffee and ask him to wait. (8) Every player chooses a pawn. He puts it • IMI}, 134 on square one. (9) It is not true that John doesn&apos;t own a car. It is red, and it is parked in front of his house. (10) Either there is no bathroom here, or it is a funny place. In any case, it is not on the first floor. (11) Example (8) can be formulated as client(x) &amp; turns-up(x) treat-politely(y, x) followed by off er-coffee(y, x) &amp; ask-to-wait(y, x) , and (9) as player(x) choose(x, &amp; pawn(y) followed by put-on-square-one(x, y) . The double</context>
</contexts>
<marker>[7]</marker>
<rawString>J. Groenendijk and M. Stokhof. Dynamic predicate logic. Linguistics and Philosophy, 14, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hare</author>
</authors>
<title>Dynamic logic.</title>
<date>1984</date>
<booktitle>Handbook of Philosophical Logic, Volume 2.</booktitle>
<editor>In D. Gabbay and F. Guenthner, editors,</editor>
<contexts>
<context position="3238" citStr="[8]" startWordPosition="522" endWordPosition="522">, and semantics can be understood rigorously as a map from formulas to meanings. Characteristic of the dynamic approach mentioned above is the identification of the meaning of a formula A with a binary relation on states (or contexts) describing transitions A induces, rather than with a set of states validating A. In the present paper, formulas are given by first-order formulas, and the target binary relations given by programs. To provide an account of anaphora in natural language, DPL translates first-order formulas A to programs ADPL from (quantified) dynamic logic (see, for example, Harel [8]) as follows ADPL = A? for atomic A 130 (A&amp;B)DPL = ADPL; BDPL (A)DPL (ADPL) (3z A)DPL = :=?; ADPL The negation of a program p is the dynamic logic test ([p] -L) ? with universal and static features (indicated respectively by [p] and ?),1 neither of which is intrinsic to the concept of negation. Whereas some notion of universality is essential to universal quantification and implication (which are formulated through negation • Vx A = --ax A j B = and accordingly inherit some properties of negation), our treatment of (2) will be based on a dynamic (rather than static) form of implication. Dynami</context>
</contexts>
<marker>[8]</marker>
<rawString>David Hare!. Dynamic logic. In D. Gabbay and F. Guenthner, editors, Handbook of Philosophical Logic, Volume 2. D. Reidel, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Heim</author>
</authors>
<title>The semantics of definite and indefinite noun phrases.</title>
<date>1982</date>
<institution>Dissertation, University of Massachusetts,</institution>
<location>Amherst,</location>
<contexts>
<context position="909" citStr="[9]" startWordPosition="143" endWordPosition="143">extended by alternative treatments of implication, universal quantification, negation and disjunction that are more &amp;quot;dynamic&amp;quot; (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives). An analysis of the &amp;quot;donkey&amp;quot; sentence followed by the assertion &amp;quot;It will kick back&amp;quot; is provided. 1 Introduction The line If a farmer owns a donkey he beats it (1) from Geach [6] is often cited as one of the success stories of the so-called &amp;quot;dynamic&amp;quot; approach to natural language semantics (by which is meant Kamp [12], Heim [9], Barwise [1], and Groenendijk and Stokhof [7], among others). But add the note It will kick back (2) and the picture turns sour: processing (1) may leave no beaten donkey active. Accordingly, providing a referent for the pronoun it in (2) would appear to call for some non-compositional surgery (that may upset many a squeamish linguist). The present paper offers, as a preventive, a &amp;quot;dynamic&amp;quot; form of implication applied to (1). Based on a &amp;quot;constructive&amp;quot; conception of discourse analysis, an overhaul of Groenendijk and Stokhof [71&apos;s Dynamic Predicate Logic (DPL) is suggested, although can also be</context>
</contexts>
<marker>[9]</marker>
<rawString>Irene Heim. The semantics of definite and indefinite noun phrases. Dissertation, University of Massachusetts, Amherst, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hintikka</author>
<author>J Kulas</author>
</authors>
<title>The Game of Language.</title>
<date>1983</date>
<location>D. Reidel, Dordrecht,</location>
<marker>[10]</marker>
<rawString>J. Hintikka and J. Kulas. The Game of Language. D. Reidel, Dordrecht, 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theo Janssen</author>
</authors>
<title>Foundations and Applications of Montague Grammar. Dissertation,</title>
<date>1986</date>
<institution>University of Amsterdam</institution>
<location>Amsterdam),</location>
<note>published in</note>
<marker>[11]</marker>
<rawString>Theo Janssen. Foundations and Applications of Montague Grammar. Dissertation, University of Amsterdam (published in 1986 by CWI, Amsterdam), 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A W Kamp</author>
</authors>
<title>A theory of truth and semantic representation.</title>
<date>1981</date>
<booktitle>Formal Methods in the Study of Language. Mathematical Centre Tracts 135,</booktitle>
<editor>In J. Groenendijk et. al., editors,</editor>
<location>Amsterdam,</location>
<contexts>
<context position="899" citStr="[12]" startWordPosition="141" endWordPosition="141"> states is extended by alternative treatments of implication, universal quantification, negation and disjunction that are more &amp;quot;dynamic&amp;quot; (in a precise sense) than the usual reductions to tests from quantified dynamic logic (which, nonetheless, can be recovered from the new connectives). An analysis of the &amp;quot;donkey&amp;quot; sentence followed by the assertion &amp;quot;It will kick back&amp;quot; is provided. 1 Introduction The line If a farmer owns a donkey he beats it (1) from Geach [6] is often cited as one of the success stories of the so-called &amp;quot;dynamic&amp;quot; approach to natural language semantics (by which is meant Kamp [12], Heim [9], Barwise [1], and Groenendijk and Stokhof [7], among others). But add the note It will kick back (2) and the picture turns sour: processing (1) may leave no beaten donkey active. Accordingly, providing a referent for the pronoun it in (2) would appear to call for some non-compositional surgery (that may upset many a squeamish linguist). The present paper offers, as a preventive, a &amp;quot;dynamic&amp;quot; form of implication applied to (1). Based on a &amp;quot;constructive&amp;quot; conception of discourse analysis, an overhaul of Groenendijk and Stokhof [71&apos;s Dynamic Predicate Logic (DPL) is suggested, although c</context>
</contexts>
<marker>[12]</marker>
<rawString>J.A.W. Kamp. A theory of truth and semantic representation. In J. Groenendijk et. al., editors, Formal Methods in the Study of Language. Mathematical Centre Tracts 135, Amsterdam, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lauri Karttunen</author>
</authors>
<title>Presupposition and linguistic context. Theoretical Linguistics,</title>
<date>1973</date>
<pages>181--194</pages>
<contexts>
<context position="12501" citStr="[13]" startWordPosition="2167" endWordPosition="2167"> function tracing processes back to their &amp;quot;roots.&amp;quot; (Forgetting that spawning record would seem to be akin to forgetting the intermediate state in a sequential composition p; p&apos;.) Furthermore, for applications to natural language discourse, forgetfulness would appear quite innocuous if the information content of a state increases in the course of interpreting discourse (so that all past states have no more information content than has the current state). And it is quite natural in discourse analysis to assume that information does grow. Consider the following claim in an early paper (Karttunen [13]) pre-occupied with a problem (viz., that of presuppositions) that may appear peripheral to (1) or (2), but is nonetheless fundamental to the &amp;quot;constructive&amp;quot; outlook on which = is based There are definitions of pragmatic presupposition ... which suggest that there is something amiss in a discourse that does not proceed in [an] ideal orderly fashion. ... All things considered, this is an unreasonable view. ... People do make leaps and shortcuts by using sentences whose presuppositions are not satisfied in the conversational context. This is the rule rather than the exception, and we should not b</context>
<context position="18964" citStr="[13]" startWordPosition="3378" endWordPosition="3378"> [All spelled out in full is referred to the appendix. Observe that non-deterministic choice + (for which DPL has no use) is essential for defining Strong negation is different from and lacks the universal force necessary to interpret implication (either as -)) or as -V —). On the other hand, can be recovered as A 1, whence static implication j is also derivable. Note also that an element s of So can be identified with {s}, yielding states of a homogeneous form. 5 A few examples The present work does not rest on the claim that the disorderly character of discourse mentioned above by Karttunen [13] admits a compositional translation to a first-order formula. The problem of translating a natural language utterance to a first-order formula (e.g., assigning a variable to a discourse marker) is essentially taken for granted, falling (as it does) outside the scope of formal semantics (conceived as a function from formulas to meanings). This affords us considerable freedom to accomodate various interpretations. The donkey sentence (1) can be formulated as farmer(x) &amp; owns(x, y) &amp; donkey(y) beats(x, y) or given an alternative &amp;quot;weak&amp;quot; reading farmer(x) &amp; owns(x, z) &amp; donkey(z) owns(x, &amp; donkey(y</context>
</contexts>
<marker>[13]</marker>
<rawString>Lauri Karttunen. Presupposition and linguistic context. Theoretical Linguistics, pages 181-194, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kleene</author>
</authors>
<title>On the interpretation of intuitionistic number theory.</title>
<date>1945</date>
<journal>J. Symbolic Logic,</journal>
<volume>10</volume>
<contexts>
<context position="6362" citStr="[14]" startWordPosition="1100" endWordPosition="1100">iven that a state is a single function from X to IMI, it is hardly odd that implication is static (in the sense that the input and output states s and I must be the same), as any number of instantiations of s&apos; (and 2&apos;) may be relevant to the right hand side of (3). That is, in terms of (1), the difficulty is that there may be several farmer/donkey couples, whereas a state can accomodate only one such pair, rendering an interpretation of (2) problematic. To overcome this predicament, the collection of states can be extended in at least two ways. (P1) Borrowing and modifying an idea from Kleene [14] (and Brouwer, Kolmogorov,...), incorporate into the final state t a functional witness f to the Vs-clause in the right hand side of (3) to obtain 4A Bit if t = (s, f) and f is a function with domain Is&apos; I 4A]si} and (Vs&apos; E dom(f)) s&apos; [MIAs&apos;) . Or, to simplify the state t slightly, break the condition (in the righthand side) up into two mutually exclusive clauses depending on whether or not the domain of f is empty siA Bit if (t is a function with non-empty domain Is&apos; I 4.211.51 and (Vs&apos; E dom(0) s&apos;EBit(s&apos;)) Or (t = S and , so that closing the notion of a state under a partial function space c</context>
<context position="17059" citStr="[14]" startWordPosition="3006" endWordPosition="3006">ernando [4] for an internal notion of proposition as an initial step towards this end. 7As detailed in Fernando [4], this distinction can be exploited to provide an account of Veltman [211&apos;s might operator as relative to an internal notion of proposition. 133 tsiv) for every x E Xo, if A E 4), then the fresh (&amp;quot;marked&amp;quot;) variables yA,, and zdt,x belong to Y and Z respectively. Next, define a &amp;quot;negation&amp;quot; map — on by T =1 1 =T = = V — (A V B) = —&apos;(Vs A) = 3x -A (3x A) = = A &amp; . This approach, going back at least to Nelson [17] (a particularly appropriate reference, given its connection with Kleene [14]), treats positive and negative information in a nearly symmetric fashion; on formulas in &apos;1&apos; without an occurrence of the function is the identity. Furthermore, were it not for our translation -e would map formulas in 4) to programs interpreted as binary relations on So = I s is a function from a finite subset of X to where X is the full set of marked an unmarked variables X = Xo UYUZ All the same, the clauses for s[A]t can be formulated uniformly whether or not s E So, so long as it is understood that for a set s of valuations, u E X, and atomic A, sp(u := *)t if 3 a function f : s t such th</context>
<context position="26836" citStr="[14]" startWordPosition="4742" endWordPosition="4742">about constructiveness? 7 Between construction and truth Having passed somewhat hastily from (P1) to (P2), the reader is entitled to ask why the present author has bothered mentioning realizability (alluding somewhat fashionably or unfashionably to &amp;quot;constructiveness&amp;quot;) and has said nothing about (classical) modal logic-style formalizations (e.g., Van Eijck and De Vries [3]), building say on concurrent dynamic logic (Peleg [19]). A short answer is that the connection with so-called and/or computations came to the author only after trying to understand the interpretation of implication in Kleene [14] (interpreting implication as a program construct being nowhere suggested in Peleg [19], which instead introduces a &amp;quot;conjunction&amp;quot; n on programs). A more serious answer would bring up his attitude towards the more interesting question does all talk about so-called dynamic semantics come to modal logic? The crazy appeal dynamic semantics exerts on the author is the claim that a formula (normally conceived statically) is a program (i.e., something dynamic); showing how a program can be understood statically is less exciting. Some may, of course, find the possibility of &amp;quot;going static&amp;quot; as well as &amp;quot;</context>
</contexts>
<marker>[14]</marker>
<rawString>S.C. Kleene. On the interpretation of intuitionistic number theory. J. Symbolic Logic, 10, 1945.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W P M Meyer Viol</author>
</authors>
<title>Partial objects and DRT.</title>
<date>1992</date>
<booktitle>Proceedings of the Eighth Amsterdam Colloquium. Institute for Logic, Language and Computation,</booktitle>
<editor>In P. Dekker and M. Stokhof, editors,</editor>
<location>Amsterdam,</location>
<contexts>
<context position="24460" citStr="[15]" startWordPosition="4317" endWordPosition="4317">entation structures (DRS&apos;s) for the extension to higher-order states above. Unfortunately, he does not (at present) know how to.8 Short of that, it may be helpful to present the passage to states that are conjunctive sets of valuations in a different light. Given a state that is a set s of valuations si, 52, • • -) let X, be the set of variables in the domain of some si E s X, = U dom(si) . si Es 8Some steps (related to footnote 4) towards that direction are taken in Fernando [5]. Another approach, somewhat more syntactic in spirit, would be to build on K. Fine&apos;s arbitrary objects (Meyer Viol [15]). 135 Now, s can be viewed as a set F, of functions fr labelled by variables x E X, as follows. Let fx be the map with domain {si E s x E dom(si)} that sends such an si to si(x). In pictures, we pass from /si : di --- ci s2 : d2 ---). C2 to Ifx&apos; : {si E s I xi E di} —■ ci F, = Pa : {si E s I x2 E di} -- c2 so that the step from states 81,82, in So to the more complicated states s in Power(So) amounts to a semantic analysis of variables as functions, rather than as fixed values from the underlying first-order model. (But now what is the domain of such a function?) The shift in point of view he</context>
</contexts>
<marker>[15]</marker>
<rawString>W.P.M. Meyer Viol. Partial objects and DRT. In P. Dekker and M. Stokhof, editors, Proceedings of the Eighth Amsterdam Colloquium. Institute for Logic, Language and Computation, Amsterdam, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Muskens</author>
</authors>
<title>Anaphora and the logic of change.</title>
<date>1991</date>
<booktitle>Logics in AI: Proc. European Workshop JELIA &apos;90.</booktitle>
<editor>In J. van Eijck, editor,</editor>
<publisher>SpringerVerlag,</publisher>
<contexts>
<context position="25124" citStr="[16]" startWordPosition="4461" endWordPosition="4461">lled by variables x E X, as follows. Let fx be the map with domain {si E s x E dom(si)} that sends such an si to si(x). In pictures, we pass from /si : di --- ci s2 : d2 ---). C2 to Ifx&apos; : {si E s I xi E di} —■ ci F, = Pa : {si E s I x2 E di} -- c2 so that the step from states 81,82, in So to the more complicated states s in Power(So) amounts to a semantic analysis of variables as functions, rather than as fixed values from the underlying first-order model. (But now what is the domain of such a function?) The shift in point of view here is essentially the &amp;quot;ingenious little trick&amp;quot; that Muskens [16] (p. 418) traces back to Janssen [111 of swapping rows with columns. We should be careful to note, however, that the preceding analysis of variables was carried out relative to a fixed state s — a state s that is to be supplied as an argument to the partial binary functions globally representing the variables. Finally, A. Visser and J. van Eijck have suggested that a comparison with type-theoretic and gametheoretical semantics (e.g., Ranta [20] and Hintikka and Kulas 1.10.1) is in order. This again is no simple matter to discuss, and (alas) falls somewhat beyond the scope of the present paper.</context>
</contexts>
<marker>[16]</marker>
<rawString>Reinhard Muskens. Anaphora and the logic of change. In J. van Eijck, editor, Logics in AI: Proc. European Workshop JELIA &apos;90. SpringerVerlag, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nelson</author>
</authors>
<title>Constructible falsity.</title>
<date>1949</date>
<journal>J. Symbolic Logic,</journal>
<volume>14</volume>
<contexts>
<context position="16982" citStr="[17]" startWordPosition="2995" endWordPosition="2995">d variables will not be taken up here. The interested reader is referred to Fernando [4] for an internal notion of proposition as an initial step towards this end. 7As detailed in Fernando [4], this distinction can be exploited to provide an account of Veltman [211&apos;s might operator as relative to an internal notion of proposition. 133 tsiv) for every x E Xo, if A E 4), then the fresh (&amp;quot;marked&amp;quot;) variables yA,, and zdt,x belong to Y and Z respectively. Next, define a &amp;quot;negation&amp;quot; map — on by T =1 1 =T = = V — (A V B) = —&apos;(Vs A) = 3x -A (3x A) = = A &amp; . This approach, going back at least to Nelson [17] (a particularly appropriate reference, given its connection with Kleene [14]), treats positive and negative information in a nearly symmetric fashion; on formulas in &apos;1&apos; without an occurrence of the function is the identity. Furthermore, were it not for our translation -e would map formulas in 4) to programs interpreted as binary relations on So = I s is a function from a finite subset of X to where X is the full set of marked an unmarked variables X = Xo UYUZ All the same, the clauses for s[A]t can be formulated uniformly whether or not s E So, so long as it is understood that for a set s of</context>
</contexts>
<marker>[17]</marker>
<rawString>David Nelson. Constructible falsity. J. Symbolic Logic, 14, 1949.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P Pagin</author>
<author>D Westerstahl</author>
</authors>
<title>Predicate logic with flexibly binding operators and natural language semantics.</title>
<tech>Preprint.</tech>
<contexts>
<context position="21674" citStr="[18]" startWordPosition="3862" endWordPosition="3862">may lead to structurally more complex states (V So). What is true is that ((—A) B) = ((, A) Sz -43) A) V B which reduces to A V B if = occurs neither in A nor B. Whereas the translation --, yields a static approximation, the translation applied recursively, projects to an approximation that is a binary relation on So. Notice that quantifers do not appear in the translations above of natural language utterances into first-order formulas. The necessary quantification is built into the semantic analysis of quantifier-free formulas, following the spirit (if not the letter) of Pagin and Westerstal [18]. (A crucial difference, of course, is that the universal quantification above arises from a dynamic The reader interested in compositionality should be pleased by this feature, insofar as quantifer-free formulas avoid the non-compositional relabelling of variables bound by quantifiers (in the semantic analysis above of quantified formulas). 6 Concerning certain points The present paper is admittedly short on linguistic examples — a defect that the author hopes some sympathetic reader (better qualified than he) will correct. Towards this end, it may be helpful to take up specific points (beyon</context>
</contexts>
<marker>[18]</marker>
<rawString>P. Pagin and D. Westerstahl. Predicate logic with flexibly binding operators and natural language semantics. Preprint.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Peleg</author>
</authors>
<title>Concurrent dynamic logic.</title>
<date>1987</date>
<journal>J. Assoc. Computing Machinery,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="8603" citStr="[19]" startWordPosition="1522" endWordPosition="1522">n processes running in parallel. (Buried in (3) is the possibility of the input state s branching off to a multiplicity of states t&apos;.) The parallelism here is &amp;quot;conjunctive&amp;quot; in that a family of parallel processes proceeds along happily so long as every member of the family is well; all is lost as soon as one fails.2 More precisely, observe that, under (P2), a natural clause for s[A]i, where s is a set of valuations and A is an atomic formula, is3 siAlt if 3 a function f : s —+onto t such that (Vs&apos; E s) f(s&apos;). 2The notion of parallelism is thus not unlike that of concurrent dynamic logic (Peleg [19]). By contrast, the (non-empty) sets of valuations used (e.g., in Fernando [41) to bring out the eliminative character of information growth induced by tests A? live disjunctively (and die conjunctively). 2A (non-equivalent) alternative is spit if (Vs&apos; E s) (3e E t) s&apos;IA]le and (Vt&apos; E t) (38&apos; E s) s&apos;EAlti , yielding a more promiscuous ontology. This is studied in Fernando [5], concerning which, the reader is referred to the next footnote. (That is, in the case of (2), every donkey that a farmer beats according to (1) must kick back.) A similar clause must be added to (P1), although to make the</context>
<context position="26661" citStr="[19]" startWordPosition="4713" endWordPosition="4713"> (described in section 2) implausible inasmuch as that represents a (constructively unsound) transformation to a disjunctive normal form (referred to in footnote 4). But what about constructiveness? 7 Between construction and truth Having passed somewhat hastily from (P1) to (P2), the reader is entitled to ask why the present author has bothered mentioning realizability (alluding somewhat fashionably or unfashionably to &amp;quot;constructiveness&amp;quot;) and has said nothing about (classical) modal logic-style formalizations (e.g., Van Eijck and De Vries [3]), building say on concurrent dynamic logic (Peleg [19]). A short answer is that the connection with so-called and/or computations came to the author only after trying to understand the interpretation of implication in Kleene [14] (interpreting implication as a program construct being nowhere suggested in Peleg [19], which instead introduces a &amp;quot;conjunction&amp;quot; n on programs). A more serious answer would bring up his attitude towards the more interesting question does all talk about so-called dynamic semantics come to modal logic? The crazy appeal dynamic semantics exerts on the author is the claim that a formula (normally conceived statically) is a p</context>
</contexts>
<marker>[19]</marker>
<rawString>David Peleg. Concurrent dynamic logic. J. Assoc. Computing Machinery, 34(2), 1987.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>Propositions as games as types.</title>
<date>1988</date>
<journal>Synthese,</journal>
<volume>76</volume>
<contexts>
<context position="25572" citStr="[20]" startWordPosition="4537" endWordPosition="4537">-order model. (But now what is the domain of such a function?) The shift in point of view here is essentially the &amp;quot;ingenious little trick&amp;quot; that Muskens [16] (p. 418) traces back to Janssen [111 of swapping rows with columns. We should be careful to note, however, that the preceding analysis of variables was carried out relative to a fixed state s — a state s that is to be supplied as an argument to the partial binary functions globally representing the variables. Finally, A. Visser and J. van Eijck have suggested that a comparison with type-theoretic and gametheoretical semantics (e.g., Ranta [20] and Hintikka and Kulas 1.10.1) is in order. This again is no simple matter to discuss, and (alas) falls somewhat beyond the scope of the present paper. For now, suffice it to say that (i) the translation .6 above starts from first-order formulas, on which (according to Ranta [20], p. 378) the gametheoretic &amp;quot;truth definition is equivalent to the traditional Tarskian one&amp;quot;, and that (ii) the use of constructive logic in Ranta [20] renders the reduction from the proposal (P1) to (P2) (described in section 2) implausible inasmuch as that represents a (constructively unsound) transformation to a di</context>
</contexts>
<marker>[20]</marker>
<rawString>Aarne Ranta. Propositions as games as types. Synthese, 76, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Veltman</author>
</authors>
<title>Defaults in update semantics.</title>
<date>1990</date>
<booktitle>Conditionals, Defaults and Belief Revision. Edinburgh, Dyana deliverable R2.5.A,</booktitle>
<editor>In J.A.W. Kamp, editor,</editor>
<marker>[21]</marker>
<rawString>Frank Veltman. Defaults in update semantics. In J.A.W. Kamp, editor, Conditionals, Defaults and Belief Revision. Edinburgh, Dyana deliverable R2.5.A, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F M Vermeulen</author>
</authors>
<title>Sequence semantics for dynamic logic.</title>
<date>1991</date>
<tech>Technical report, Philosophy Department,</tech>
<location>Utrecht,</location>
<note>To appear in</note>
<contexts>
<context position="11807" citStr="[22]" startWordPosition="2058" endWordPosition="2058">e past to what can happen in the future. (In other words, the meaning of a program is specified simply by pairs of input/output states.) This same intuition underlies (P2), discarding (as it does) the wit4The discussion here will be confined to a somewhat intuitive and informal level. A somewhat more technical mathematical account is developed at length in Fernando [5], where (P2) is presented as a reduction of (P1) to a disjunctive normal form (in the sense of the &amp;quot;conjunctive&amp;quot; and &amp;quot;disjunctive&amp;quot; notions of parallelism already mentioned). &apos;It should, in fairness, be pointed out that Vermeulen [22] presents a variant of dynamic logic directed towards revising this very feature. 132 ness function tracing processes back to their &amp;quot;roots.&amp;quot; (Forgetting that spawning record would seem to be akin to forgetting the intermediate state in a sequential composition p; p&apos;.) Furthermore, for applications to natural language discourse, forgetfulness would appear quite innocuous if the information content of a state increases in the course of interpreting discourse (so that all past states have no more information content than has the current state). And it is quite natural in discourse analysis to ass</context>
<context position="32351" citStr="[22]" startWordPosition="5635" endWordPosition="5635">dual (establishing/testing) nature of asserting a proposition — or perhaps even without being subjected to all that babble —, surely we can agree that Story-telling requires more imagination than verifying facts. &apos;The idea that information grows during the run of a typical computer program is, by comparison, not so clear. One difference is that whereas guarded assignments would seem sufficient for natural language applications, a typical computer program will repeatedly assign different values to the same variable. To pursue the matter further, the reader may wish to (again) consult Vermerden [22]. Acknowledgments My thanks to J. van Eijck and J. Ginzburg for criticisms of a draft, to K. Vermeulen, W. MeyerViol, A. Visser, P. Blackburn D. Beaver, and M. Kanazawa for helpful discussions, and to the conference&apos;s anonymous referees for various suggestions. Appendix: (P2) fleshed out without prose Fix a first-order model M and a set X of variables partitioned between the unmarked (x,...) and marked (y,... and z, . .. for existential and universal quantification, respectively). (It may be advisable to ignore the marking of variables, and quantified formulas; see section 5 for some examples.</context>
</contexts>
<marker>[22]</marker>
<rawString>C.F.M. Vermeulen. Sequence semantics for dynamic logic. Technical report, Philosophy Department, Utrecht, 1991. To appear in J. Logic, Language and Information.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>