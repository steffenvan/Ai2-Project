<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.984455">
Fast Consensus Decoding over Translation Forests
</title>
<author confidence="0.998396">
John DeNero David Chiang and Kevin Knight
</author>
<affiliation confidence="0.9991065">
Computer Science Division Information Sciences Institute
University of California, Berkeley University of Southern California
</affiliation>
<email confidence="0.974229">
denero@cs.berkeley.edu {chiang, knight}@isi.edu
</email>
<sectionHeader confidence="0.994347" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.989001052631579">
The minimum Bayes risk (MBR) decoding ob-
jective improves BLEU scores for machine trans-
lation output relative to the standard Viterbi ob-
jective of maximizing model score. However,
MBR targeting BLEU is prohibitively slow to op-
timize over k-best lists for large k. In this pa-
per, we introduce and analyze an alternative to
MBR that is equally effective at improving per-
formance, yet is asymptotically faster — running
80 times faster than MBR in experiments with
1000-best lists. Furthermore, our fast decoding
procedure can select output sentences based on
distributions over entire forests of translations, in
addition to k-best lists. We evaluate our proce-
dure on translation forests from two large-scale,
state-of-the-art hierarchical machine translation
systems. Our forest-based decoding objective
consistently outperforms k-best list MBR, giving
improvements of up to 1.0 BLEU.
</bodyText>
<sectionHeader confidence="0.998366" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999930046153846">
In statistical machine translation, output transla-
tions are evaluated by their similarity to human
reference translations, where similarity is most of-
ten measured by BLEU (Papineni et al., 2002).
A decoding objective specifies how to derive final
translations from a system’s underlying statistical
model. The Bayes optimal decoding objective is
to minimize risk based on the similarity measure
used for evaluation. The corresponding minimum
Bayes risk (MBR) procedure maximizes the ex-
pected similarity score of a system’s translations
relative to the model’s distribution over possible
translations (Kumar and Byrne, 2004). Unfortu-
nately, with a non-linear similarity measure like
BLEU, we must resort to approximating the ex-
pected loss using a k-best list, which accounts for
only a tiny fraction of a model’s full posterior dis-
tribution. In this paper, we introduce a variant
of the MBR decoding procedure that applies effi-
ciently to translation forests. Instead of maximiz-
ing expected similarity, we express similarity in
terms of features of sentences, and choose transla-
tions that are similar to expected feature values.
Our exposition begins with algorithms over k-
best lists. A naive algorithm for finding MBR
translations computes the similarity between every
pair of k sentences, entailing O(k�) comparisons.
We show that if the similarity measure is linear in
features of a sentence, then computing expected
similarity for all k sentences requires only k sim-
ilarity evaluations. Specific instances of this gen-
eral algorithm have recently been proposed for two
linear similarity measures (Tromble et al., 2008;
Zhang and Gildea, 2008).
However, the sentence similarity measures we
want to optimize in MT are not linear functions,
and so this fast algorithm for MBR does not ap-
ply. For this reason, we propose a new objective
that retains the benefits of MBR, but can be op-
timized efficiently, even for non-linear similarity
measures. In experiments using BLEU over 1000-
best lists, we found that our objective provided
benefits very similar to MBR, only much faster.
This same decoding objective can also be com-
puted efficiently from forest-based expectations.
Translation forests compactly encode distributions
over much larger sets of derivations and arise nat-
urally in chart-based decoding for a wide variety
of hierarchical translation systems (Chiang, 2007;
Galley et al., 2006; Mi et al., 2008; Venugopal
et al., 2007). The resulting forest-based decoding
procedure compares favorably in both complexity
and performance to the recently proposed lattice-
based MBR (Tromble et al., 2008).
The contributions of this paper include a linear-
time algorithm for MBR using linear similarities,
a linear-time alternative to MBR using non-linear
similarity measures, and a forest-based extension
to this procedure for similarities based on n-gram
counts. In experiments, we show that our fast pro-
cedure is on average 80 times faster than MBR
using 1000-best lists. We also show that using
forests outperforms using k-best lists consistently
across language pairs. Finally, in the first pub-
lished multi-system experiments on consensus de-
</bodyText>
<page confidence="0.95579">
567
</page>
<note confidence="0.999612">
Proceedings of the 47th Annual Meeting of the ACL and the 4th IJCNLP of the AFNLP, pages 567–575,
Suntec, Singapore, 2-7 August 2009. c�2009 ACL and AFNLP
</note>
<bodyText confidence="0.9682284">
coding for translation, we demonstrate that bene-
fits can differ substantially across systems. In all,
we show improvements of up to 1.0 BLEU from
consensus approaches for state-of-the-art large-
scale hierarchical translation systems.
</bodyText>
<sectionHeader confidence="0.962484" genericHeader="method">
2 Consensus Decoding Algorithms
</sectionHeader>
<bodyText confidence="0.999955352941177">
Let e be a candidate translation for a sentence f,
where e may stand for a sentence or its derivation
as appropriate. Modern statistical machine trans-
lation systems take as input some f and score each
derivation e according to a linear model of fea-
tures: Pi λi·θi(f, e). The standard Viterbi decod-
ing objective is to find e∗ = arg maxe λ · θ(f, e).
For MBR decoding, we instead leverage a sim-
ilarity measure S(e; e0) to choose a translation us-
ing the model’s probability distribution P(e|f),
which has support over a set of possible transla-
tions E. The Viterbi derivation e∗ is the mode of
this distribution. MBR is meant to choose a trans-
lation that will be similar, on expectation, to any
possible reference translation. To this end, MBR
chooses e� that maximizes expected similarity to
the sentences in E under P(e|f):1
</bodyText>
<equation confidence="0.994968">
e� = arg maxe EP(e&apos;|f) [S(e; e0)]
X= arg maxe P(e0|f) · S(e; e0)
e&apos;∈E
</equation>
<bodyText confidence="0.997798181818182">
MBR can also be interpreted as a consensus de-
coding procedure: it chooses a translation similar
to other high-posterior translations. Minimizing
risk has been shown to improve performance for
MT (Kumar and Byrne, 2004), as well as other
language processing tasks (Goodman, 1996; Goel
and Byrne, 2000; Kumar and Byrne, 2002; Titov
and Henderson, 2006; Smith and Smith, 2007).
The distribution P(e|f) can be induced from a
translation system’s features and weights by expo-
nentiating with base b to form a log-linear model:
</bodyText>
<equation confidence="0.99663">
P(e|f) = Pe&apos;∈E ba·B(f,e&apos;)
ba·B(f,e)
</equation>
<bodyText confidence="0.840026142857143">
We follow Ehling et al. (2007) in choosing b using
a held-out tuning set. For algorithms in this sec-
tion, we assume that E is a k-best list and b has
been chosen already, so P(e|f) is fully specified.
1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for
some loss function L, for example 1 − BLEU(e; e&apos;). These
definitions are equivalent.
</bodyText>
<subsectionHeader confidence="0.992535">
2.1 Minimum Bayes Risk over Sentence Pairs
</subsectionHeader>
<bodyText confidence="0.911478">
Given any similarity measure S and a k-best
list E, the minimum Bayes risk translation can
be found by computing the similarity between all
pairs of sentences in E, as in Algorithm 1.
Algorithm 1 MBR over Sentence Pairs
</bodyText>
<listItem confidence="0.995126">
1: A ← −∞
2: fore ∈ Edo
3: Ae ← 0
4: for e0 ∈ Edo
5: Ae ← Ae + P(e0|f) · S(e; e0)
6: if Ae &gt; A then A, e� ← Ae, e
7: return e�
</listItem>
<bodyText confidence="0.999816166666667">
We can sometimes exit the inner for loop early,
whenever Ae can never become larger than A
(Ehling et al., 2007). Even with this shortcut, the
running time of Algorithm 1 is O(k� · n), where
n is the maximum sentence length, assuming that
S(e; e0) can be computed in O(n) time.
</bodyText>
<subsectionHeader confidence="0.998996">
2.2 Minimum Bayes Risk over Features
</subsectionHeader>
<bodyText confidence="0.999994333333333">
We now consider the case when S(e; e0) is a lin-
ear function of sentence features. Let S(e; e0) be
a function of the form Pj ωj(e) · φj(e0), where
φj(e0) are real-valued features of e0, and ωj(e) are
sentence-specific weights on those features. Then,
the MBR objective can be re-written as
</bodyText>
<equation confidence="0.984652571428571">
arg maxe∈E EP(e&apos;|f) [S(e; e0)]
X= arg maxe P(e0|f) · X ωj(e) · φj(e0)
e&apos;∈E j
&amp;quot; X #
ωj(e) P(e0|f) · φj(e0)
e&apos;∈E
ωj(e) · EP(e&apos;|f) [φj(e0)I . (1)
</equation>
<bodyText confidence="0.9988754">
Equation 1 implies that we can find MBR trans-
lations by first computing all feature expectations,
then applying S only once for each e. Algorithm 2
proceduralizes this idea: lines 1-4 compute feature
expectations, and lines 5-11 find the translation
with highest S relative to those expectations. The
time complexity is O(k · n), assuming the number
of non-zero features φ(e0) and weights ω(e) grow
linearly in sentence length n and all features and
weights can be computed in constant time.
</bodyText>
<equation confidence="0.97645525">
X= arg maxe
j
X= arg maxe
j
</equation>
<page confidence="0.96872">
568
</page>
<construct confidence="0.46134">
Algorithm 2 MBR over Features
</construct>
<listItem confidence="0.987906909090909">
1: φ ← [0 for j ∈ J]
2: for e0 ∈ Edo
3: for j ∈ J such that φj(e0) =6 0 do
4: �φj ← φj + P(e0|f) · φj(e0)
5: A ← −∞
6: for e ∈ E do
7: Ae ← 0
8: for j ∈ J such that ωj(e) =6 0 do
9: Ae ← Ae + ωj(e) · φj
10: if Ae &gt; A then A, e� ← Ae, e
11: return e�
</listItem>
<bodyText confidence="0.954478">
An example of a linear similarity measure is
bag-of-words precision, which can be written as:
</bodyText>
<equation confidence="0.994364333333333">
�
U(e; e0) =
t∈T1
</equation>
<bodyText confidence="0.999704555555556">
where T1 is the set of unigrams in the language,
and δ(e, t) is an indicator function that equals 1
if t appears in e and 0 otherwise. Figure 1 com-
pares Algorithms 1 and 2 using U(e; e0). Other
linear functions have been explored for MBR, in-
cluding Taylor approximations to the logarithm of
BLEU (Tromble et al., 2008) and counts of match-
ing constituents (Zhang and Gildea, 2008), which
are discussed further in Section 3.3.
</bodyText>
<subsectionHeader confidence="0.9987555">
2.3 Fast Consensus Decoding using
Non-Linear Similarity Measures
</subsectionHeader>
<bodyText confidence="0.999093444444445">
Most similarity measures of interest for machine
translation are not linear, and so Algorithm 2 does
not apply. Computing MBR even with simple
non-linear measures such as BLEU, NIST or bag-
of-words F1 seems to require O(k�) computation
time. However, these measures are all functions
of features of e0. That is, they can be expressed as
S(e; φ(e0)) for a feature mapping φ : E → R.
For example, we can express BLEU(e; e0) =
</bodyText>
<equation confidence="0.47926">
exp I �1 − |e  |1 0, t))
L Je |/ 4r- Et∈Tn c(e, t)
</equation>
<bodyText confidence="0.8905415">
In this expression, BLEU(e; e0) references e0 only
via its n-gram count features c(e0, t).2
</bodyText>
<footnote confidence="0.819575">
2The length penalty (1 −  ||,  |) is also a function of n-
</footnote>
<equation confidence="0.995713523809524">
gram counts: |e0 |= Et∈T, c(e0, t). The negative part oper-
ator (·)− is equivalent to min(·, 0).
P(e1|f) = 0.3 e1 =efficient forest decoding
P(e2|f) = 0.3 e2 =efficient for rusty coating
P(e3|f) = 0.4 e3 = A fish ain’t forest decoding
MBR over Features
E [8(efficient)] = 0.6
E [8(forest)] = 0.7
E [8(decoding)] = 0.7
E [8(for)] = 0.3
E [8(rusty)] = 0.3
E [8(coating)] = 0.3
E [8(a)] = 0.4
E [8(fish)] = 0.4
E [8(ain’t)] = 0.4
3 Max feature similarity
0.6+0.7+0.7
U(e1; Eφ) = 3
= 0.667
U(e2; Eφ) = 0.375
U(e3; Eφ) = 0.520
</equation>
<figureCaption confidence="0.984330333333333">
Figure 1: For the linear similarity measure U(e; e0), which
computes unigram precision, the MBR translation can be
found by iterating either over sntence pairs (Algorithm 1) or
</figureCaption>
<figure confidence="0.575768090909091">
I ... telescope
over features (Algorithm 2). These two algorithms take the
same input (step 1), but diverge in their consensus computa-
04
tions (steps 2 &amp; 3). However, they produce identical result
the .. teles
saw the” 06
for U and any other linear similarity measure.
“man with” “saw the”
Following the structure of Equation 1, we can
I w e m
</figure>
<bodyText confidence="0.9798375">
choose a translation e based on the feature expec-
tations of e0. In particular, we can choose
</bodyText>
<equation confidence="0.95702375">
i l hb
e� = arg maxe∈ES(e; �P(e0|f
E [r(��� with) = 0.4 + 0 10
[φ(e0)]). (2)
</equation>
<bodyText confidence="0.999970647058824">
This objective differs from MBR, but has a simi-
lar consensus-building structure. We have simply
moved the expectation inside the similarity func-
tion, just as we did in Equation 1. This new ob-
jective can be optimized by Algorithm 3, a pro-
cedure that runs in O(k · n) time if the count of
non-zero features in e0 and the computation time
of S(e; φ(e0)) are both linear in sentence length n.
This fast consensus decoding procedure shares
the same structure as linear MBR: first we com-
pute feature expectations, then we choose the sen-
tence that is most similar to those expectations. In
fact, Algorithm 2 is a special case of Algorithm 3.
Lines 7-9 of the former and line 7 of the latter are
equivalent for linear S(e; e0). Thus, for any linear
similarity measure, Algorithm 3 is an algorithm
for minimum Bayes risk decoding.
</bodyText>
<figure confidence="0.78223370967742">
Choose a distribution P over a set of translations E
1
2
Compute expectations
δ(e, t) · δ(e0, t)
|e|
MBR over Sentence Pairs
Compute pairwise similarity
U(e2; e1) =
|efficient|
lefficient for rusty coatingl
rl
r2 1/3
r3 2/3
4/4
0/4
0/5
5/5
C1 C2 C3
3 Max expected similarity
2
EU(e1;e&apos;) = 0.3(1+ 1 3)+0.4· 3
= 0.667
EU(e2;e&apos;) = 0.375
EU(e3;e&apos;) = 0.520
2
3/3
2/5
1/4
569
Algorithm 3 Fast Consensus Decoding
</figure>
<listItem confidence="0.968691666666667">
1: O +— [0 for j E J]
2: for e0 E Edo
3: for j E J such that Oj(e0) =� 0 do
4: �Oj +— Oj + P(e0|f) - Oj(e0)
5: A +— -oc
6: for e E E do
7: Ae +— 5(e; O)
8: if Ae &gt; A then A, e� +— Ae, e
9: return e�
</listItem>
<figure confidence="0.970961">
Yo vi al hombre con el telescopio
I ... telescope
0.4
“saw the”
“man with”
0.6
“saw the”
I ... saw the ... man with ... telescope
1.0
“man with”
the ... telescope
�E [c(e, “man with”)] = P(h|f) · c(h, “man with”)
</figure>
<bodyText confidence="0.999957193548387">
As described, Algorithm 3 can use any sim-
ilarity measure that is defined in terms of real-
valued features of e0. There are some nuances
of this procedure, however. First, the precise
form of 5(e; O(e0)) will affect the output, but
5(e; E[O(e0)]) is often an input point for which a
sentence similarity measure 5 was not originally
defined. For example, our definition of BLEU
above will have integer valued O(e0) for any real
sentence e0, but E[O(e0)] will not be integer valued.
As a result, we are extending the domain of BLEU
beyond its original intent. One could imagine dif-
ferent feature-based expressions that also produce
BLEU scores for real sentences, but produce dif-
ferent values for fractional features. Some care
must be taken to define 5(e; O(e0)) to extend nat-
urally from integer-valued to real-valued features.
Second, while any similarity measure can in
principle be expressed as 5(e; O(e0)) for a suffi-
ciently rich feature space, fast consensus decoding
will not apply effectively to all functions. For in-
stance, we cannot naturally use functions that in-
clude alignments or matchings between e and e0,
such as METEOR (Agarwal and Lavie, 2007) and
TER (Snover et al., 2006). Though these functions
can in principle be expressed in terms of features
of e0 (for instance with indicator features for whole
sentences), fast consensus decoding will only be
effective if different sentences share many fea-
tures, so that the feature expectations effectively
capture trends in the underlying distribution.
</bodyText>
<sectionHeader confidence="0.983725" genericHeader="method">
3 Computing Feature Expectations
</sectionHeader>
<bodyText confidence="0.999953">
We now turn our focus to efficiently comput-
ing feature expectations, in service of our fast
consensus decoding procedure. Computing fea-
ture expectations from k-best lists is trivial, but
k-best lists capture very little of the underlying
model’s posterior distribution. In place of k-best
</bodyText>
<equation confidence="0.938774">
h
= 0.4 · 1 + (0.6 · 1.0) · 1
</equation>
<figureCaption confidence="0.697667714285714">
Figure 2: This translation forest for a Spanish sentence en-
codes two English parse trees. Hyper-edges (boxes) are an-
notated with normalized transition probabilities, as well as
the bigrams produced by each rule application. The expected
count of the bigram “man with” is the sum of posterior prob-
abilities of the two hyper-edges that produce it. In this exam-
ple, we normalized inside scores at all nodes to 1 for clarity.
</figureCaption>
<bodyText confidence="0.999836125">
lists, compact encodings of translation distribu-
tions have proven effective for MBR (Zhang and
Gildea, 2008; Tromble et al., 2008). In this sec-
tion, we consider BLEU in particular, for which
the relevant features O(e) are n-gram counts up to
length n = 4. We show how to compute expec-
tations of these counts efficiently from translation
forests.
</bodyText>
<subsectionHeader confidence="0.992951">
3.1 Translation Forests
</subsectionHeader>
<bodyText confidence="0.999969058823529">
Translation forests compactly encode an exponen-
tial number of output translations for an input
sentence, along with their model scores. Forests
arise naturally in chart-based decoding procedures
for many hierarchical translation systems (Chiang,
2007). Exploiting forests has proven a fruitful av-
enue of research in both parsing (Huang, 2008)
and machine translation (Mi et al., 2008).
Formally, translation forests are weighted
acyclic hyper-graphs. The nodes are states in the
decoding process that include the span (i, j) of the
sentence to be translated, the grammar symbol s
over that span, and the left and right context words
of the translation relevant for computing n-gram
language model scores.3 Each hyper-edge h rep-
resents the application of a synchronous rule r that
combines nodes corresponding to non-terminals in
</bodyText>
<footnote confidence="0.98459">
3Decoder states can include additional information as
well, such as local configurations for dependency language
model scoring.
</footnote>
<page confidence="0.991789">
570
</page>
<bodyText confidence="0.999952352941177">
r into a node spanning the union of the child spans
and perhaps some additional portion of the input
sentence covered directly by r’s lexical items. The
weight of h is the incremental score contributed
to all translations containing the rule application,
including translation model features on r and lan-
guage model features that depend on both r and
the English contexts of the child nodes. Figure 2
depicts a forest.
Each n-gram that appears in a translation e is as-
sociated with some h in its derivation: the h corre-
sponding to the rule that produces the n-gram. Un-
igrams are produced by lexical rules, while higher-
order n-grams can be produced either directly by
lexical rules, or by combining constituents. The
n-gram language model score of e similarly de-
composes over the h in e that produce n-grams.
</bodyText>
<subsectionHeader confidence="0.999541">
3.2 Computing Expected N-Gram Counts
</subsectionHeader>
<bodyText confidence="0.930688666666667">
We can compute expected n-gram counts effi-
ciently from a translation forest by appealing to
the linearity of expectations. Let φ(e) be a vector
of n-gram counts for a sentence e. Then, φ(e) is
the sum of hyper-edge-specific n-gram count vec-
tors φ(h) for all h in e. Therefore, E[φ(e)] =
</bodyText>
<equation confidence="0.7357105">
P
hEe E[φ(h)].
</equation>
<bodyText confidence="0.999826666666667">
To compute n-gram expectations for a hyper-
edge, we first compute the posterior probability of
each h, conditioned on the input sentence f:
</bodyText>
<equation confidence="0.9799645">
−1
ba·0(f,e) X ba·B(f,e)
! ,
e
</equation>
<bodyText confidence="0.998267944444444">
where e iterates over translations in the forest. We
compute the numerator using the inside-outside al-
gorithm, while the denominator is the inside score
of the root node. Note that many possible deriva-
tions of f are pruned from the forest during decod-
ing, and so this posterior is approximate.
The expected n-gram count vector for a hyper-
edge is E[φ(h)] = P(h|f) · φ(h). Hence, after
computing P(h|f) for every h, we need only sum
P(h|f) · φ(h) for all h to compute E[φ(e)]. This
entire procedure is a linear-time computation in
the number of hyper-edges in the forest.
To complete forest-based fast consensus de-
coding, we then extract a k-best list of unique
translations from the forest (Huang et al., 2006)
and continue Algorithm 3 from line 5, which
chooses the e� from the k-best list that maximizes
BLEU(e; E[φ(e&apos;)]).
</bodyText>
<subsectionHeader confidence="0.99792">
3.3 Comparison to Related Work
</subsectionHeader>
<bodyText confidence="0.999993961538462">
Zhang and Gildea (2008) embed a consensus de-
coding procedure into a larger multi-pass decoding
framework. They focus on inversion transduction
grammars, but their ideas apply to richer models as
well. They propose an MBR decoding objective
of maximizing the expected number of matching
constituent counts relative to the model’s distri-
bution. The corresponding constituent-matching
similarity measure can be expressed as a linear
function of features of e&apos;, which are indicators of
constituents. Expectations of constituent indicator
features are the same as posterior constituent prob-
abilities, which can be computed from a transla-
tion forest using the inside-outside algorithm. This
forest-based MBR approach improved translation
output relative to Viterbi translations.
Tromble et al. (2008) describe a similar ap-
proach using MBR with a linear similarity mea-
sure. They derive a first-order Taylor approxima-
tion to the logarithm of a slightly modified defini-
tion of corpus BLEU4, which is linear in n-gram
indicator features δ(e&apos;, t) of e&apos;. These features are
weighted by n-gram counts c(e, t) and constants
θ that are estimated from held-out data. The lin-
ear similarity measure takes the following form,
where Tn is the set of n-grams:
</bodyText>
<equation confidence="0.830281">
θt · c(e, t) · δ(e&apos;, t).
</equation>
<bodyText confidence="0.999831">
Using G, Tromble et al. (2008) extend MBR to
word lattices, which improves performance over
k-best list MBR.
Our approach differs from Tromble et al. (2008)
primarily in that we propose decoding with an al-
ternative to MBR using BLEU, while they propose
decoding with MBR using a linear alternative to
BLEU. The specifics of our approaches also differ
in important ways.
First, word lattices are a subclass of forests that
have only one source node for each edge (i.e., a
graph, rather than a hyper-graph). While forests
are more general, the techniques for computing
posterior edge probabilities in lattices and forests
are similar. One practical difference is that the
forests needed for fast consensus decoding are
</bodyText>
<footnote confidence="0.9954255">
4The log-BLEU function must be modified slightly to
yield a linear Taylor approximation: Tromble et al. (2008)
replace the clipped n-gram count with the product of an n-
gram count and an n-gram indicator function.
</footnote>
<equation confidence="0.978898222222222">
X
P(h|f) =
e:hEe
G(e; e&apos;) = θ0|e |+
4
X
n=1
X
tETn
</equation>
<page confidence="0.985343">
571
</page>
<bodyText confidence="0.999923195652174">
generated already by the decoder of a syntactic
translation system.
Second, rather than use BLEU as a sentence-
level similarity measure directly, Tromble et al.
(2008) approximate corpus BLEU with G above.
The parameters 0 of the approximation must be es-
timated on a held-out data set, while our approach
requires no such estimation step.
Third, our approach is also simpler computa-
tionally. The features required to compute G are
indicators S(e&apos;, t); the features relevant to us are
counts c(e&apos;, t). Tromble et al. (2008) compute ex-
pected feature values by intersecting the transla-
tion lattice with a lattices for each n-gram t. By
contrast, expectations of c(e&apos;, t) can all be com-
puted with a single pass over the forest. This con-
trast implies a complexity difference. Let H be the
number of hyper-edges in the forest or lattice, and
T the number of n-grams that can potentially ap-
pear in a translation. Computing indicator expec-
tations seems to require O(H · T) time because of
automata intersections. Computing count expec-
tations requires O(H) time, because only a con-
stant number of n-grams can be produced by each
hyper-edge.
Our approaches also differ in the space of trans-
lations from which e� is chosen. A linear similar-
ity measure like G allows for efficient search over
the lattice or forest, whereas fast consensus decod-
ing restricts this search to a k-best list. However,
Tromble et al. (2008) showed that most of the im-
provement from lattice-based consensus decoding
comes from lattice-based expectations, not search:
searching over lattices instead of k-best lists did
not change results for two language pairs, and im-
proved a third language pair by 0.3 BLEU. Thus,
we do not consider our use of k-best lists to be a
substantial liability of our approach.
Fast consensus decoding is also similar in char-
acter to the concurrently developed variational de-
coding approach of Li et al. (2009). Using BLEU,
both approaches choose outputs that match ex-
pected n-gram counts from forests, though differ
in the details. It is possible to define a similar-
ity measure under which the two approaches are
equivalent.5
</bodyText>
<footnote confidence="0.8431748">
5For example, decoding under a variational approxima-
tion to the model’s posterior that decomposes over bigram
probabilities is equivalent to fast consensus decoding with
c(e ,t) c(e,t)
( el ,h(t))i
</footnote>
<sectionHeader confidence="0.993086" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999980333333333">
We evaluate these consensus decoding techniques
on two different full-scale state-of-the-art hierar-
chical machine translation systems. Both systems
were trained for 2008 GALE evaluations, in which
they outperformed a phrase-based system trained
on identical data.
</bodyText>
<subsectionHeader confidence="0.995581">
4.1 Hiero: a Hierarchical MT Pipeline
</subsectionHeader>
<bodyText confidence="0.993337863636364">
Hiero is a hierarchical system that expresses its
translation model as a synchronous context-free
grammar (Chiang, 2007). No explicit syntactic in-
formation appears in the core model. A phrase
discovery procedure over word-aligned sentence
pairs provides rule frequency counts, which are
normalized to estimate features on rules.
The grammar rules of Hiero all share a single
non-terminal symbol X, and have at most two
non-terminals and six total items (non-terminals
and lexical items), for example:
my X2 ’s X1 —* X1 de mi X2
We extracted the grammar from training data using
standard parameters. Rules were allowed to span
at most 15 words in the training data.
The log-linear model weights were trained us-
ing MIRA, a margin-based optimization proce-
dure that accommodates many features (Crammer
and Singer, 2003; Chiang et al., 2008). In addition
to standard rule frequency features, we included
the distortion and syntactic features described in
Chiang et al. (2008).
</bodyText>
<subsectionHeader confidence="0.993492">
4.2 SBMT: a Syntax-Based MT Pipeline
</subsectionHeader>
<bodyText confidence="0.999842111111111">
SBMT is a string-to-tree translation system with
rich target-side syntactic information encoded in
the translation model. The synchronous grammar
rules are extracted from word aligned sentence
pairs where the target sentence is annotated with
a syntactic parse (Galley et al., 2004). Rules map
source-side strings to target-side parse tree frag-
ments, and non-terminal symbols correspond to
target-side grammatical categories:
</bodyText>
<equation confidence="0.812086">
(NP (NP (PRP$ my) NN2 (POS ’s)) NNS1) �
NNS1 de mi NN2
</equation>
<bodyText confidence="0.976100428571428">
We extracted the grammar via an array of criteria
(Galley et al., 2006; DeNeefe et al., 2007; Marcu
et al., 2006). The model was trained using min-
imum error rate training for Arabic (Och, 2003)
and MIRA for Chinese (Chiang et al., 2008).
the similarity measure B(e; e&apos;) = 11tc,2 [ c
where h(t) is the unigram prefix of bigram t.
</bodyText>
<page confidence="0.9286205">
,
572
</page>
<table confidence="0.9997583">
Arabic-English
Objective Hiero SBMT
Min. Bayes Risk (Alg 1) 2h 47m 12h 42m
Fast Consensus (Alg 3) 5m 49s 5m 22s
Speed Ratio 29 142
Chinese-English
Objective Hiero SBMT
Min. Bayes Risk (Alg 1) 10h 24m 3h 52m
Fast Consensus (Alg 3) 4m 52s 6m 32s
Speed Ratio 128 36
</table>
<tableCaption confidence="0.998705333333333">
Table 1: Fast consensus decoding is orders of magnitude
faster than MBR when using BLEU as a similarity measure.
Times only include reranking, not k-best list extraction.
</tableCaption>
<subsectionHeader confidence="0.997222">
4.3 Data Conditions
</subsectionHeader>
<bodyText confidence="0.999805925925926">
We evaluated on both Chinese-English and
Arabic-English translation tasks. Both Arabic-
English systems were trained on 220 million
words of word-aligned parallel text. For the
Chinese-English experiments, we used 260 mil-
lion words of word-aligned parallel text; the hi-
erarchical system used all of this data, and the
syntax-based system used a 65-million word sub-
set. All four systems used two language models:
one trained from the combined English sides of
both parallel texts, and another, larger, language
model trained on 2 billion words of English text
(1 billion for Chinese-English SBMT).
All systems were tuned on held-out data (1994
sentences for Arabic-English, 2010 sentences for
Chinese-English) and tested on another dataset
(2118 sentences for Arabic-English, 1994 sen-
tences for Chinese-English). These datasets were
drawn from the NIST 2004 and 2005 evaluation
data, plus some additional data from the GALE
program. There was no overlap at the segment or
document level between the tuning and test sets.
We tuned b, the base of the log-linear model,
to optimize consensus decoding performance. In-
terestingly, we found that tuning b on the same
dataset used for tuning A was as effective as tuning
b on an additional held-out dataset.
</bodyText>
<subsectionHeader confidence="0.986051">
4.4 Results over K-Best Lists
</subsectionHeader>
<bodyText confidence="0.998544">
Taking expectations over 1000-best lists6 and us-
ing BLEU7 as a similarity measure, both MBR
</bodyText>
<footnote confidence="0.990797">
6We ensured that k-best lists contained no duplicates.
7To prevent zero similarity scores, we also used a standard
smoothed version of BLEU that added 1 to the numerator and
denominator of all n-gram precisions. Performance results
</footnote>
<table confidence="0.99978275">
Arabic-English
Expectations Similarity Hiero SBMT
Baseline - 52.0 53.9
104-best BLEU 52.2 53.9
Forest BLEU 53.0 54.0
Forest Linear G 52.3 54.0
Chinese-English
Expectations Similarity Hiero SBMT
Baseline - 37.8 40.6
104-best BLEU 38.0 40.7
Forest BLEU 38.2 40.8
Forest Linear G 38.1 40.8
</table>
<tableCaption confidence="0.972465">
Table 2: Translation performance improves when computing
expected sentences from translation forests rather than 104-
best lists, which in turn improve over Viterbi translations. We
also contrasted forest-based consensus decoding with BLEU
and its linear approximation, G. Both similarity measures are
effective, but BLEU outperforms G.
</tableCaption>
<bodyText confidence="0.999981384615385">
and our variant provided consistent small gains of
0.0–0.2 BLEU. Algorithms 1 and 3 gave the same
small BLEU improvements in each data condition
up to three significant figures.
The two algorithms differed greatly in speed,
as shown in Table 1. For Algorithm 1, we ter-
minated the computation of ]E[BLEU(e; e&apos;)] for
each e whenever e could not become the maxi-
mal hypothesis. MBR speed depended on how
often this shortcut applied, which varied by lan-
guage and system. Despite this optimization, our
new Algorithm 3 was an average of 80 times faster
across systems and language pairs.
</bodyText>
<sectionHeader confidence="0.973607" genericHeader="evaluation">
4.5 Results for Forest-Based Decoding
</sectionHeader>
<bodyText confidence="0.999482333333333">
Table 2 contrasts Algorithm 3 over 104-best lists
and forests. Computing ]E[o(e&apos;)] from a transla-
tion forest rather than a 104-best list improved Hi-
ero by an additional 0.8 BLEU (1.0 over the base-
line). Forest-based expectations always outper-
formed k-best lists, but curiously the magnitude
of benefit was not consistent across systems. We
believe the difference is in part due to more ag-
gressive forest pruning within the SBMT decoder.
For forest-based decoding, we compared two
similarity measures: BLEU and its linear Taylor
approximation G from section 3.3.8 Table 2 shows
</bodyText>
<footnote confidence="0.5371646">
were identical to standard BLEU.
8We did not estimate the 0 parameters of G ourselves;
instead we used the parameters listed in Tromble et al.
(2008), which were also estimated for GALE data. We
also approximated E[6(e�, t)] with a clipped expected count
</footnote>
<page confidence="0.99598">
573
</page>
<figure confidence="0.9146304">
N-grams from baseline translations
N-grams with high expected count
61.4
50.5
Hiero SBMT
</figure>
<figureCaption confidence="0.9802287">
Figure 3: N-grams with high expected count are more likely
to appear in the reference translation that n-grams in the
translation model’s Viterbi translation, e*. Above, we com-
pare the precision, relative to reference translations, of sets of
n-grams chosen in two ways. The left bar is the precision of
the n-grams in e*. The right bar is the precision of n-grams
with E[c(e, t)] &gt; p. To justify this comparison, we chose p
so that both methods of choosing n-grams gave the same n-
gram recall: the fraction of n-grams in reference translations
that also appeared in e* or had E[c(e, t)] &gt; p.
</figureCaption>
<figure confidence="0.896575833333333">
a
that both similarities were effective, but BLEU
506
BL
outperformed its linear approximation.
Crp
</figure>
<subsectionHeader confidence="0.979237">
4.6 Analysis
</subsectionHeader>
<bodyText confidence="0.958179266666667">
Forest-based consensus decoding leverages infor-
mation about the correct translation from the en-
tire forest. In particular, consensus decoding
with BLEU chooses translations using n-gram
00
count expectations E[c(e, t)]. Improvements in
511,60 513,245
translation quality shuld therefore be directly at-
Total model score for 1000 tran
tributable to information in these expected counts.
We endeavored to test the hypothesis that ex-
pected n-gram counts under the forest distribution
carry more predictive information than the base-
line Viterbi derivation e*, which is the mode of the
distribution. To this end, we first tested the pre-
dictive accuracy of the n-grams proposed by e*:
the fraction of the n-grams in e* that appear in a
reference translation. We compared this n-gram
precision to a similar measure of predictive accu-
racy for expected n-gram counts: the fraction of
the n-grams t with ]E[c(e,t)] &gt; p that appear in
a reference. To make these two precisions com-
parable, we chose p such that the recall of ref-
erence n-grams was equal. Figure 3 shows that
computing n-gram expectations—which sum over
translations—improves the model’s ability to pre-
dict which n-grams will appear in the reference.
min(1,1E[c(e&apos;,t)]). Assuming an n-gram appears at most
once per sentence, these expressions are equivalent, and this
assumption holds for most n-grams.
</bodyText>
<subsectionHeader confidence="0.407719">
Reference translation:
</subsectionHeader>
<bodyText confidence="0.984699666666667">
Mubarak said that he received a telephone call from
Sharon in which he said he was “ready (to resume ne-
gotiations) but the Palestinians are hesitant.”
</bodyText>
<subsectionHeader confidence="0.928939">
Baseline translation:
</subsectionHeader>
<bodyText confidence="0.877450428571429">
Mubarak said he had received a telephone call from
Sharon told him he was ready to resume talks with the
Palestinians.
Fast forest-based consensus translation:
Mubarak said that he had received a telephone call from
Sharon told him that he “was ready to resume the nego-
tiations) , but the Palestinians are hesitant.”
</bodyText>
<figureCaption confidence="0.8429596">
Figure 4: Three translations of an example Arabic sentence:
its human-generated reference, the translation with the high-
est model score under Hiero (Viterbi), and the translation
chosen by forest-based consensus decoding. The consensus
translation reconstructs content lost in the Viterbi translation.
</figureCaption>
<bodyText confidence="0.9999732">
We attribute gains from fast consensus decoding
to this increased predictive accuracy.
Examining the translations chosen by fast con-
sensus decoding, we found that gains in BLEU of-
ten arose from improved lexical choice. However,
in our hierarchical systems, consensus decoding
did occasionally trigger large reordering. We also
found examples where the translation quality im-
proved by recovering content that was missing
from the baseline translation, as in Figure 4.
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99853705882353">
We have demonstrated substantial speed increases
ios
in k-best consensus decoding through a new pro-
cedure inspired by MBR under linear similarity
measures. To further improve this approach, we
computed expected n-gram counts from transla-
tion forests instead of k-best lists. Fast consensus
decoding using forest-based n-gram expectations
and BLEU as a similarity measure yielded con-
sistent improvements over MBR with k-best lists,
yet required only simple computations that scale
linearly with the size of the translation forest.
The space of similarity measures is large and
relatively unexplored, and the feature expectations
that can be computed from forests extend beyond
n-gram counts. Therefore, future work may show
additional benefits from fast consensus decoding.
</bodyText>
<sectionHeader confidence="0.997184" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.7062045">
This work was supported under DARPA GALE,
Contract No. HR0011-06-C-0022.
</bodyText>
<figure confidence="0.9978377">
N-gram Precision
80
60
40
20
0
51.1 56.6
EU
B
r
</figure>
<page confidence="0.992929">
574
</page>
<sectionHeader confidence="0.993054" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999489176470588">
Abhaya Agarwal and Alon Lavie. 2007. METEOR:
An automatic metric for MT evaluation with high
levels of correlation with human judgments. In Pro-
ceedings of the Workshop on Statistical Machine
Translation for the Association of Computational
Linguistics.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing.
David Chiang. 2007. Hierarchical phrase-based trans-
lation. Computational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultracon-
servative online algorithms for multiclass problems.
Journal of Machine Learning Research, 3:951–991.
Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel
Marcu. 2007. What can syntax-based MT learn
from phrase-based MT? In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing and CoNLL.
Nicola Ehling, Richard Zens, and Hermann Ney. 2007.
Minimum Bayes risk decoding for BLEU. In Pro-
ceedings of the Association for Computational Lin-
guistics: Short Paper Track.
Michel Galley, Mark Hopkins, Kevin Knight, and
Daniel Marcu. 2004. What’s in a translation rule?
In Proceedings of HLT: the North American Chapter
of the Association for Computational Linguistics.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve DeNeefe, Wei Wang, and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In Pro-
ceedings of the Association for Computational Lin-
guistics.
Vaibhava Goel and William Byrne. 2000. Minimum
Bayes-risk automatic speech recognition. In Com-
puter, Speech and Language.
Joshua Goodman. 1996. Parsing algorithms and met-
rics. In Proceedings of the Association for Compu-
tational Linguistics.
Liang Huang, Kevin Knight, and Aravind Joshi. 2006.
Statistical syntax-directed translation with extended
domain of locality. In Proceedings of the Associa-
tion for Machine Translation in the Americas.
Liang Huang. 2008. Forest reranking: Discriminative
parsing with non-local features. In Proceedings of
the Association for Computational Linguistics.
Shankar Kumar and William Byrne. 2002. Minimum
Bayes-risk word alignments of bilingual texts. In
Proceedings of the Conference on Empirical Meth-
ods in Natural Language Processing.
Shankar Kumar and William Byrne. 2004. Minimum
Bayes-risk decoding for statistical machine transla-
tion. In Proceedings of the North American Chapter
of the Association for Computational Linguistics.
Zhifei Li, Jason Eisner, and Sanjeev Khudanpur. 2009.
Variational decoding for statistical machine transla-
tion. In Proceedings of the Association for Compu-
tational Linguistics and IJCNLP.
Daniel Marcu, Wei Wang, Abdessamad Echihabi, and
Kevin Knight. 2006. SPMT: Statistical machine
translation with syntactified target language phrases.
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing.
Haitao Mi, Liang Huang, and Qun Liu. 2008. Forest-
based translation. In Proceedings of the Association
for Computational Linguistics.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the Association for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: A method for automatic
evaluation of machine translation. In Proceedings
of the Association for Computational Linguistics.
David Smith and Noah Smith. 2007. Probabilistic
models of nonprojective dependency trees. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing and CoNLL.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of Association for Machine Transla-
tion in the Americas.
Ivan Titov and James Henderson. 2006. Loss mini-
mization in parse reranking. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing.
Roy Tromble, Shankar Kumar, Franz Josef Och, and
Wolfgang Macherey. 2008. Lattice minimum
Bayes-risk decoding for statistical machine transla-
tion. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing.
Ashish Venugopal, Andreas Zollmann, and Stephan
Vogel. 2007. An efficient two-pass approach to
synchronous-CFG driven statistical MT. In Pro-
ceedings of HLT: the North American Association
for Computational Linguistics Conference.
Hao Zhang and Daniel Gildea. 2008. Efficient multi-
pass decoding for synchronous context free gram-
mars. In Proceedings of the Association for Compu-
tational Linguistics.
</reference>
<page confidence="0.998456">
575
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.927735">
<title confidence="0.999962">Fast Consensus Decoding over Translation Forests</title>
<author confidence="0.996736">DeNero David Chiang Knight</author>
<affiliation confidence="0.995778">Computer Science Division Information Sciences Institute University of California, Berkeley University of Southern California</affiliation>
<abstract confidence="0.99688955">The minimum Bayes risk (MBR) decoding objective improves BLEU scores for machine translation output relative to the standard Viterbi objective of maximizing model score. However, MBR targeting BLEU is prohibitively slow to opover lists for large In this paper, we introduce and analyze an alternative to MBR that is equally effective at improving performance, yet is asymptotically faster — running 80 times faster than MBR in experiments with 1000-best lists. Furthermore, our fast decoding procedure can select output sentences based on distributions over entire forests of translations, in to lists. We evaluate our procedure on translation forests from two large-scale, state-of-the-art hierarchical machine translation systems. Our forest-based decoding objective outperforms list MBR, giving improvements of up to 1.0 BLEU.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abhaya Agarwal</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on Statistical Machine Translation for the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="13702" citStr="Agarwal and Lavie, 2007" startWordPosition="2390" endWordPosition="2393"> its original intent. One could imagine different feature-based expressions that also produce BLEU scores for real sentences, but produce different values for fractional features. Some care must be taken to define 5(e; O(e0)) to extend naturally from integer-valued to real-valued features. Second, while any similarity measure can in principle be expressed as 5(e; O(e0)) for a sufficiently rich feature space, fast consensus decoding will not apply effectively to all functions. For instance, we cannot naturally use functions that include alignments or matchings between e and e0, such as METEOR (Agarwal and Lavie, 2007) and TER (Snover et al., 2006). Though these functions can in principle be expressed in terms of features of e0 (for instance with indicator features for whole sentences), fast consensus decoding will only be effective if different sentences share many features, so that the feature expectations effectively capture trends in the underlying distribution. 3 Computing Feature Expectations We now turn our focus to efficiently computing feature expectations, in service of our fast consensus decoding procedure. Computing feature expectations from k-best lists is trivial, but k-best lists capture very</context>
</contexts>
<marker>Agarwal, Lavie, 2007</marker>
<rawString>Abhaya Agarwal and Alon Lavie. 2007. METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments. In Proceedings of the Workshop on Statistical Machine Translation for the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="24061" citStr="Chiang et al., 2008" startWordPosition="4083" endWordPosition="4086"> word-aligned sentence pairs provides rule frequency counts, which are normalized to estimate features on rules. The grammar rules of Hiero all share a single non-terminal symbol X, and have at most two non-terminals and six total items (non-terminals and lexical items), for example: my X2 ’s X1 —* X1 de mi X2 We extracted the grammar from training data using standard parameters. Rules were allowed to span at most 15 words in the training data. The log-linear model weights were trained using MIRA, a margin-based optimization procedure that accommodates many features (Crammer and Singer, 2003; Chiang et al., 2008). In addition to standard rule frequency features, we included the distortion and syntactic features described in Chiang et al. (2008). 4.2 SBMT: a Syntax-Based MT Pipeline SBMT is a string-to-tree translation system with rich target-side syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side grammatical categories: (</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation. Computational Linguistics.</title>
<date>2007</date>
<contexts>
<context position="3543" citStr="Chiang, 2007" startWordPosition="529" endWordPosition="530">orithm for MBR does not apply. For this reason, we propose a new objective that retains the benefits of MBR, but can be optimized efficiently, even for non-linear similarity measures. In experiments using BLEU over 1000- best lists, we found that our objective provided benefits very similar to MBR, only much faster. This same decoding objective can also be computed efficiently from forest-based expectations. Translation forests compactly encode distributions over much larger sets of derivations and arise naturally in chart-based decoding for a wide variety of hierarchical translation systems (Chiang, 2007; Galley et al., 2006; Mi et al., 2008; Venugopal et al., 2007). The resulting forest-based decoding procedure compares favorably in both complexity and performance to the recently proposed latticebased MBR (Tromble et al., 2008). The contributions of this paper include a lineartime algorithm for MBR using linear similarities, a linear-time alternative to MBR using non-linear similarity measures, and a forest-based extension to this procedure for similarities based on n-gram counts. In experiments, we show that our fast procedure is on average 80 times faster than MBR using 1000-best lists. We</context>
<context position="15452" citStr="Chiang, 2007" startWordPosition="2671" endWordPosition="2672">ompact encodings of translation distributions have proven effective for MBR (Zhang and Gildea, 2008; Tromble et al., 2008). In this section, we consider BLEU in particular, for which the relevant features O(e) are n-gram counts up to length n = 4. We show how to compute expectations of these counts efficiently from translation forests. 3.1 Translation Forests Translation forests compactly encode an exponential number of output translations for an input sentence, along with their model scores. Forests arise naturally in chart-based decoding procedures for many hierarchical translation systems (Chiang, 2007). Exploiting forests has proven a fruitful avenue of research in both parsing (Huang, 2008) and machine translation (Mi et al., 2008). Formally, translation forests are weighted acyclic hyper-graphs. The nodes are states in the decoding process that include the span (i, j) of the sentence to be translated, the grammar symbol s over that span, and the left and right context words of the translation relevant for computing n-gram language model scores.3 Each hyper-edge h represents the application of a synchronous rule r that combines nodes corresponding to non-terminals in 3Decoder states can in</context>
<context position="23345" citStr="Chiang, 2007" startWordPosition="3969" endWordPosition="3970"> variational approximation to the model’s posterior that decomposes over bigram probabilities is equivalent to fast consensus decoding with c(e ,t) c(e,t) ( el ,h(t))i 4 Experimental Results We evaluate these consensus decoding techniques on two different full-scale state-of-the-art hierarchical machine translation systems. Both systems were trained for 2008 GALE evaluations, in which they outperformed a phrase-based system trained on identical data. 4.1 Hiero: a Hierarchical MT Pipeline Hiero is a hierarchical system that expresses its translation model as a synchronous context-free grammar (Chiang, 2007). No explicit syntactic information appears in the core model. A phrase discovery procedure over word-aligned sentence pairs provides rule frequency counts, which are normalized to estimate features on rules. The grammar rules of Hiero all share a single non-terminal symbol X, and have at most two non-terminals and six total items (non-terminals and lexical items), for example: my X2 ’s X1 —* X1 de mi X2 We extracted the grammar from training data using standard parameters. Rules were allowed to span at most 15 words in the training data. The log-linear model weights were trained using MIRA, a</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--951</pages>
<contexts>
<context position="24039" citStr="Crammer and Singer, 2003" startWordPosition="4079" endWordPosition="4082">e discovery procedure over word-aligned sentence pairs provides rule frequency counts, which are normalized to estimate features on rules. The grammar rules of Hiero all share a single non-terminal symbol X, and have at most two non-terminals and six total items (non-terminals and lexical items), for example: my X2 ’s X1 —* X1 de mi X2 We extracted the grammar from training data using standard parameters. Rules were allowed to span at most 15 words in the training data. The log-linear model weights were trained using MIRA, a margin-based optimization procedure that accommodates many features (Crammer and Singer, 2003; Chiang et al., 2008). In addition to standard rule frequency features, we included the distortion and syntactic features described in Chiang et al. (2008). 4.2 SBMT: a Syntax-Based MT Pipeline SBMT is a string-to-tree translation system with rich target-side syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side gra</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. Journal of Machine Learning Research, 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve DeNeefe</author>
<author>Kevin Knight</author>
<author>Wei Wang</author>
<author>Daniel Marcu</author>
</authors>
<title>What can syntax-based MT learn from phrase-based MT?</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing and CoNLL.</booktitle>
<contexts>
<context position="24807" citStr="DeNeefe et al., 2007" startWordPosition="4198" endWordPosition="4201">. (2008). 4.2 SBMT: a Syntax-Based MT Pipeline SBMT is a string-to-tree translation system with rich target-side syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side grammatical categories: (NP (NP (PRP$ my) NN2 (POS ’s)) NNS1) � NNS1 de mi NN2 We extracted the grammar via an array of criteria (Galley et al., 2006; DeNeefe et al., 2007; Marcu et al., 2006). The model was trained using minimum error rate training for Arabic (Och, 2003) and MIRA for Chinese (Chiang et al., 2008). the similarity measure B(e; e&apos;) = 11tc,2 [ c where h(t) is the unigram prefix of bigram t. , 572 Arabic-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 2h 47m 12h 42m Fast Consensus (Alg 3) 5m 49s 5m 22s Speed Ratio 29 142 Chinese-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 10h 24m 3h 52m Fast Consensus (Alg 3) 4m 52s 6m 32s Speed Ratio 128 36 Table 1: Fast consensus decoding is orders of magnitude faster than MBR when using BLEU as a s</context>
</contexts>
<marker>DeNeefe, Knight, Wang, Marcu, 2007</marker>
<rawString>Steve DeNeefe, Kevin Knight, Wei Wang, and Daniel Marcu. 2007. What can syntax-based MT learn from phrase-based MT? In Proceedings of the Conference on Empirical Methods in Natural Language Processing and CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ehling</author>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Minimum Bayes risk decoding for BLEU.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics: Short Paper Track.</booktitle>
<contexts>
<context position="6216" citStr="Ehling et al. (2007)" startWordPosition="964" endWordPosition="967">arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for some loss function L, for example 1 − BLEU(e; e&apos;). These definitions are equivalent. 2.1 Minimum Bayes Risk over Sentence Pairs Given any similarity measure S and a k-best list E, the minimum Bayes risk translation can be found by computing the similarity between all pairs of sentences in E, as in Algorithm 1. Algorithm 1 MBR over Sentence Pairs 1: A ← −∞ 2: fore ∈ Edo </context>
</contexts>
<marker>Ehling, Zens, Ney, 2007</marker>
<rawString>Nicola Ehling, Richard Zens, and Hermann Ney. 2007. Minimum Bayes risk decoding for BLEU. In Proceedings of the Association for Computational Linguistics: Short Paper Track.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Mark Hopkins</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proceedings of HLT: the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="24516" citStr="Galley et al., 2004" startWordPosition="4150" endWordPosition="4153">g-linear model weights were trained using MIRA, a margin-based optimization procedure that accommodates many features (Crammer and Singer, 2003; Chiang et al., 2008). In addition to standard rule frequency features, we included the distortion and syntactic features described in Chiang et al. (2008). 4.2 SBMT: a Syntax-Based MT Pipeline SBMT is a string-to-tree translation system with rich target-side syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side grammatical categories: (NP (NP (PRP$ my) NN2 (POS ’s)) NNS1) � NNS1 de mi NN2 We extracted the grammar via an array of criteria (Galley et al., 2006; DeNeefe et al., 2007; Marcu et al., 2006). The model was trained using minimum error rate training for Arabic (Och, 2003) and MIRA for Chinese (Chiang et al., 2008). the similarity measure B(e; e&apos;) = 11tc,2 [ c where h(t) is the unigram prefix of bigram t. , 572 Arabic-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 2h 47m</context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>Michel Galley, Mark Hopkins, Kevin Knight, and Daniel Marcu. 2004. What’s in a translation rule? In Proceedings of HLT: the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve DeNeefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3564" citStr="Galley et al., 2006" startWordPosition="531" endWordPosition="534"> does not apply. For this reason, we propose a new objective that retains the benefits of MBR, but can be optimized efficiently, even for non-linear similarity measures. In experiments using BLEU over 1000- best lists, we found that our objective provided benefits very similar to MBR, only much faster. This same decoding objective can also be computed efficiently from forest-based expectations. Translation forests compactly encode distributions over much larger sets of derivations and arise naturally in chart-based decoding for a wide variety of hierarchical translation systems (Chiang, 2007; Galley et al., 2006; Mi et al., 2008; Venugopal et al., 2007). The resulting forest-based decoding procedure compares favorably in both complexity and performance to the recently proposed latticebased MBR (Tromble et al., 2008). The contributions of this paper include a lineartime algorithm for MBR using linear similarities, a linear-time alternative to MBR using non-linear similarity measures, and a forest-based extension to this procedure for similarities based on n-gram counts. In experiments, we show that our fast procedure is on average 80 times faster than MBR using 1000-best lists. We also show that using</context>
<context position="24785" citStr="Galley et al., 2006" startWordPosition="4194" endWordPosition="4197">ribed in Chiang et al. (2008). 4.2 SBMT: a Syntax-Based MT Pipeline SBMT is a string-to-tree translation system with rich target-side syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side grammatical categories: (NP (NP (PRP$ my) NN2 (POS ’s)) NNS1) � NNS1 de mi NN2 We extracted the grammar via an array of criteria (Galley et al., 2006; DeNeefe et al., 2007; Marcu et al., 2006). The model was trained using minimum error rate training for Arabic (Och, 2003) and MIRA for Chinese (Chiang et al., 2008). the similarity measure B(e; e&apos;) = 11tc,2 [ c where h(t) is the unigram prefix of bigram t. , 572 Arabic-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 2h 47m 12h 42m Fast Consensus (Alg 3) 5m 49s 5m 22s Speed Ratio 29 142 Chinese-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 10h 24m 3h 52m Fast Consensus (Alg 3) 4m 52s 6m 32s Speed Ratio 128 36 Table 1: Fast consensus decoding is orders of magnitude faster than MBR </context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, DeNeefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve DeNeefe, Wei Wang, and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vaibhava Goel</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-risk automatic speech recognition.</title>
<date>2000</date>
<journal>In Computer, Speech and Language.</journal>
<contexts>
<context position="5928" citStr="Goel and Byrne, 2000" startWordPosition="917" endWordPosition="920">e∗ is the mode of this distribution. MBR is meant to choose a translation that will be similar, on expectation, to any possible reference translation. To this end, MBR chooses e� that maximizes expected similarity to the sentences in E under P(e|f):1 e� = arg maxe EP(e&apos;|f) [S(e; e0)] X= arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for some loss function L, for example 1 − BLEU(e; e&apos;). These definitions are equivalent.</context>
</contexts>
<marker>Goel, Byrne, 2000</marker>
<rawString>Vaibhava Goel and William Byrne. 2000. Minimum Bayes-risk automatic speech recognition. In Computer, Speech and Language.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joshua Goodman</author>
</authors>
<title>Parsing algorithms and metrics.</title>
<date>1996</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5906" citStr="Goodman, 1996" startWordPosition="915" endWordPosition="916">rbi derivation e∗ is the mode of this distribution. MBR is meant to choose a translation that will be similar, on expectation, to any possible reference translation. To this end, MBR chooses e� that maximizes expected similarity to the sentences in E under P(e|f):1 e� = arg maxe EP(e&apos;|f) [S(e; e0)] X= arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for some loss function L, for example 1 − BLEU(e; e&apos;). These defin</context>
</contexts>
<marker>Goodman, 1996</marker>
<rawString>Joshua Goodman. 1996. Parsing algorithms and metrics. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kevin Knight</author>
<author>Aravind Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>In Proceedings of the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="18188" citStr="Huang et al., 2006" startWordPosition="3131" endWordPosition="3134">e-outside algorithm, while the denominator is the inside score of the root node. Note that many possible derivations of f are pruned from the forest during decoding, and so this posterior is approximate. The expected n-gram count vector for a hyperedge is E[φ(h)] = P(h|f) · φ(h). Hence, after computing P(h|f) for every h, we need only sum P(h|f) · φ(h) for all h to compute E[φ(e)]. This entire procedure is a linear-time computation in the number of hyper-edges in the forest. To complete forest-based fast consensus decoding, we then extract a k-best list of unique translations from the forest (Huang et al., 2006) and continue Algorithm 3 from line 5, which chooses the e� from the k-best list that maximizes BLEU(e; E[φ(e&apos;)]). 3.3 Comparison to Related Work Zhang and Gildea (2008) embed a consensus decoding procedure into a larger multi-pass decoding framework. They focus on inversion transduction grammars, but their ideas apply to richer models as well. They propose an MBR decoding objective of maximizing the expected number of matching constituent counts relative to the model’s distribution. The corresponding constituent-matching similarity measure can be expressed as a linear function of features of </context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>Liang Huang, Kevin Knight, and Aravind Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proceedings of the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15543" citStr="Huang, 2008" startWordPosition="2686" endWordPosition="2687">a, 2008; Tromble et al., 2008). In this section, we consider BLEU in particular, for which the relevant features O(e) are n-gram counts up to length n = 4. We show how to compute expectations of these counts efficiently from translation forests. 3.1 Translation Forests Translation forests compactly encode an exponential number of output translations for an input sentence, along with their model scores. Forests arise naturally in chart-based decoding procedures for many hierarchical translation systems (Chiang, 2007). Exploiting forests has proven a fruitful avenue of research in both parsing (Huang, 2008) and machine translation (Mi et al., 2008). Formally, translation forests are weighted acyclic hyper-graphs. The nodes are states in the decoding process that include the span (i, j) of the sentence to be translated, the grammar symbol s over that span, and the left and right context words of the translation relevant for computing n-gram language model scores.3 Each hyper-edge h represents the application of a synchronous rule r that combines nodes corresponding to non-terminals in 3Decoder states can include additional information as well, such as local configurations for dependency language </context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-risk word alignments of bilingual texts.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5951" citStr="Kumar and Byrne, 2002" startWordPosition="921" endWordPosition="924"> distribution. MBR is meant to choose a translation that will be similar, on expectation, to any possible reference translation. To this end, MBR chooses e� that maximizes expected similarity to the sentences in E under P(e|f):1 e� = arg maxe EP(e&apos;|f) [S(e; e0)] X= arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for some loss function L, for example 1 − BLEU(e; e&apos;). These definitions are equivalent. 2.1 Minimum Bayes Risk</context>
</contexts>
<marker>Kumar, Byrne, 2002</marker>
<rawString>Shankar Kumar and William Byrne. 2002. Minimum Bayes-risk word alignments of bilingual texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>William Byrne</author>
</authors>
<title>Minimum Bayes-risk decoding for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1795" citStr="Kumar and Byrne, 2004" startWordPosition="252" endWordPosition="255">n statistical machine translation, output translations are evaluated by their similarity to human reference translations, where similarity is most often measured by BLEU (Papineni et al., 2002). A decoding objective specifies how to derive final translations from a system’s underlying statistical model. The Bayes optimal decoding objective is to minimize risk based on the similarity measure used for evaluation. The corresponding minimum Bayes risk (MBR) procedure maximizes the expected similarity score of a system’s translations relative to the model’s distribution over possible translations (Kumar and Byrne, 2004). Unfortunately, with a non-linear similarity measure like BLEU, we must resort to approximating the expected loss using a k-best list, which accounts for only a tiny fraction of a model’s full posterior distribution. In this paper, we introduce a variant of the MBR decoding procedure that applies efficiently to translation forests. Instead of maximizing expected similarity, we express similarity in terms of features of sentences, and choose translations that are similar to expected feature values. Our exposition begins with algorithms over kbest lists. A naive algorithm for finding MBR transl</context>
<context position="5847" citStr="Kumar and Byrne, 2004" startWordPosition="904" endWordPosition="907">), which has support over a set of possible translations E. The Viterbi derivation e∗ is the mode of this distribution. MBR is meant to choose a translation that will be similar, on expectation, to any possible reference translation. To this end, MBR chooses e� that maximizes expected similarity to the sentences in E under P(e|f):1 e� = arg maxe EP(e&apos;|f) [S(e; e0)] X= arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for som</context>
</contexts>
<marker>Kumar, Byrne, 2004</marker>
<rawString>Shankar Kumar and William Byrne. 2004. Minimum Bayes-risk decoding for statistical machine translation. In Proceedings of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Jason Eisner</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Variational decoding for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Association for Computational Linguistics and IJCNLP.</booktitle>
<contexts>
<context position="22485" citStr="Li et al. (2009)" startWordPosition="3841" endWordPosition="3844">ttice or forest, whereas fast consensus decoding restricts this search to a k-best list. However, Tromble et al. (2008) showed that most of the improvement from lattice-based consensus decoding comes from lattice-based expectations, not search: searching over lattices instead of k-best lists did not change results for two language pairs, and improved a third language pair by 0.3 BLEU. Thus, we do not consider our use of k-best lists to be a substantial liability of our approach. Fast consensus decoding is also similar in character to the concurrently developed variational decoding approach of Li et al. (2009). Using BLEU, both approaches choose outputs that match expected n-gram counts from forests, though differ in the details. It is possible to define a similarity measure under which the two approaches are equivalent.5 5For example, decoding under a variational approximation to the model’s posterior that decomposes over bigram probabilities is equivalent to fast consensus decoding with c(e ,t) c(e,t) ( el ,h(t))i 4 Experimental Results We evaluate these consensus decoding techniques on two different full-scale state-of-the-art hierarchical machine translation systems. Both systems were trained f</context>
</contexts>
<marker>Li, Eisner, Khudanpur, 2009</marker>
<rawString>Zhifei Li, Jason Eisner, and Sanjeev Khudanpur. 2009. Variational decoding for statistical machine translation. In Proceedings of the Association for Computational Linguistics and IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical machine translation with syntactified target language phrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="24828" citStr="Marcu et al., 2006" startWordPosition="4202" endWordPosition="4205">Syntax-Based MT Pipeline SBMT is a string-to-tree translation system with rich target-side syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side grammatical categories: (NP (NP (PRP$ my) NN2 (POS ’s)) NNS1) � NNS1 de mi NN2 We extracted the grammar via an array of criteria (Galley et al., 2006; DeNeefe et al., 2007; Marcu et al., 2006). The model was trained using minimum error rate training for Arabic (Och, 2003) and MIRA for Chinese (Chiang et al., 2008). the similarity measure B(e; e&apos;) = 11tc,2 [ c where h(t) is the unigram prefix of bigram t. , 572 Arabic-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 2h 47m 12h 42m Fast Consensus (Alg 3) 5m 49s 5m 22s Speed Ratio 29 142 Chinese-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 10h 24m 3h 52m Fast Consensus (Alg 3) 4m 52s 6m 32s Speed Ratio 128 36 Table 1: Fast consensus decoding is orders of magnitude faster than MBR when using BLEU as a similarity measure. Ti</context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin Knight. 2006. SPMT: Statistical machine translation with syntactified target language phrases. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
</authors>
<title>Forestbased translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3581" citStr="Mi et al., 2008" startWordPosition="535" endWordPosition="538">this reason, we propose a new objective that retains the benefits of MBR, but can be optimized efficiently, even for non-linear similarity measures. In experiments using BLEU over 1000- best lists, we found that our objective provided benefits very similar to MBR, only much faster. This same decoding objective can also be computed efficiently from forest-based expectations. Translation forests compactly encode distributions over much larger sets of derivations and arise naturally in chart-based decoding for a wide variety of hierarchical translation systems (Chiang, 2007; Galley et al., 2006; Mi et al., 2008; Venugopal et al., 2007). The resulting forest-based decoding procedure compares favorably in both complexity and performance to the recently proposed latticebased MBR (Tromble et al., 2008). The contributions of this paper include a lineartime algorithm for MBR using linear similarities, a linear-time alternative to MBR using non-linear similarity measures, and a forest-based extension to this procedure for similarities based on n-gram counts. In experiments, we show that our fast procedure is on average 80 times faster than MBR using 1000-best lists. We also show that using forests outperfo</context>
<context position="15585" citStr="Mi et al., 2008" startWordPosition="2691" endWordPosition="2694">s section, we consider BLEU in particular, for which the relevant features O(e) are n-gram counts up to length n = 4. We show how to compute expectations of these counts efficiently from translation forests. 3.1 Translation Forests Translation forests compactly encode an exponential number of output translations for an input sentence, along with their model scores. Forests arise naturally in chart-based decoding procedures for many hierarchical translation systems (Chiang, 2007). Exploiting forests has proven a fruitful avenue of research in both parsing (Huang, 2008) and machine translation (Mi et al., 2008). Formally, translation forests are weighted acyclic hyper-graphs. The nodes are states in the decoding process that include the span (i, j) of the sentence to be translated, the grammar symbol s over that span, and the left and right context words of the translation relevant for computing n-gram language model scores.3 Each hyper-edge h represents the application of a synchronous rule r that combines nodes corresponding to non-terminals in 3Decoder states can include additional information as well, such as local configurations for dependency language model scoring. 570 r into a node spanning </context>
</contexts>
<marker>Mi, Huang, Liu, 2008</marker>
<rawString>Haitao Mi, Liang Huang, and Qun Liu. 2008. Forestbased translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="24908" citStr="Och, 2003" startWordPosition="4218" endWordPosition="4219">e syntactic information encoded in the translation model. The synchronous grammar rules are extracted from word aligned sentence pairs where the target sentence is annotated with a syntactic parse (Galley et al., 2004). Rules map source-side strings to target-side parse tree fragments, and non-terminal symbols correspond to target-side grammatical categories: (NP (NP (PRP$ my) NN2 (POS ’s)) NNS1) � NNS1 de mi NN2 We extracted the grammar via an array of criteria (Galley et al., 2006; DeNeefe et al., 2007; Marcu et al., 2006). The model was trained using minimum error rate training for Arabic (Och, 2003) and MIRA for Chinese (Chiang et al., 2008). the similarity measure B(e; e&apos;) = 11tc,2 [ c where h(t) is the unigram prefix of bigram t. , 572 Arabic-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 2h 47m 12h 42m Fast Consensus (Alg 3) 5m 49s 5m 22s Speed Ratio 29 142 Chinese-English Objective Hiero SBMT Min. Bayes Risk (Alg 1) 10h 24m 3h 52m Fast Consensus (Alg 3) 4m 52s 6m 32s Speed Ratio 128 36 Table 1: Fast consensus decoding is orders of magnitude faster than MBR when using BLEU as a similarity measure. Times only include reranking, not k-best list extraction. 4.3 Data Conditions We e</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: A method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1366" citStr="Papineni et al., 2002" startWordPosition="191" endWordPosition="194"> lists. Furthermore, our fast decoding procedure can select output sentences based on distributions over entire forests of translations, in addition to k-best lists. We evaluate our procedure on translation forests from two large-scale, state-of-the-art hierarchical machine translation systems. Our forest-based decoding objective consistently outperforms k-best list MBR, giving improvements of up to 1.0 BLEU. 1 Introduction In statistical machine translation, output translations are evaluated by their similarity to human reference translations, where similarity is most often measured by BLEU (Papineni et al., 2002). A decoding objective specifies how to derive final translations from a system’s underlying statistical model. The Bayes optimal decoding objective is to minimize risk based on the similarity measure used for evaluation. The corresponding minimum Bayes risk (MBR) procedure maximizes the expected similarity score of a system’s translations relative to the model’s distribution over possible translations (Kumar and Byrne, 2004). Unfortunately, with a non-linear similarity measure like BLEU, we must resort to approximating the expected loss using a k-best list, which accounts for only a tiny frac</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: A method for automatic evaluation of machine translation. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Smith</author>
<author>Noah Smith</author>
</authors>
<title>Probabilistic models of nonprojective dependency trees.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing and CoNLL.</booktitle>
<contexts>
<context position="6002" citStr="Smith and Smith, 2007" startWordPosition="929" endWordPosition="932">n that will be similar, on expectation, to any possible reference translation. To this end, MBR chooses e� that maximizes expected similarity to the sentences in E under P(e|f):1 e� = arg maxe EP(e&apos;|f) [S(e; e0)] X= arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for some loss function L, for example 1 − BLEU(e; e&apos;). These definitions are equivalent. 2.1 Minimum Bayes Risk over Sentence Pairs Given any similarity measure S</context>
</contexts>
<marker>Smith, Smith, 2007</marker>
<rawString>David Smith and Noah Smith. 2007. Probabilistic models of nonprojective dependency trees. In Proceedings of the Conference on Empirical Methods in Natural Language Processing and CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="13732" citStr="Snover et al., 2006" startWordPosition="2396" endWordPosition="2399">agine different feature-based expressions that also produce BLEU scores for real sentences, but produce different values for fractional features. Some care must be taken to define 5(e; O(e0)) to extend naturally from integer-valued to real-valued features. Second, while any similarity measure can in principle be expressed as 5(e; O(e0)) for a sufficiently rich feature space, fast consensus decoding will not apply effectively to all functions. For instance, we cannot naturally use functions that include alignments or matchings between e and e0, such as METEOR (Agarwal and Lavie, 2007) and TER (Snover et al., 2006). Though these functions can in principle be expressed in terms of features of e0 (for instance with indicator features for whole sentences), fast consensus decoding will only be effective if different sentences share many features, so that the feature expectations effectively capture trends in the underlying distribution. 3 Computing Feature Expectations We now turn our focus to efficiently computing feature expectations, in service of our fast consensus decoding procedure. Computing feature expectations from k-best lists is trivial, but k-best lists capture very little of the underlying mode</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>Loss minimization in parse reranking.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5978" citStr="Titov and Henderson, 2006" startWordPosition="925" endWordPosition="928">eant to choose a translation that will be similar, on expectation, to any possible reference translation. To this end, MBR chooses e� that maximizes expected similarity to the sentences in E under P(e|f):1 e� = arg maxe EP(e&apos;|f) [S(e; e0)] X= arg maxe P(e0|f) · S(e; e0) e&apos;∈E MBR can also be interpreted as a consensus decoding procedure: it chooses a translation similar to other high-posterior translations. Minimizing risk has been shown to improve performance for MT (Kumar and Byrne, 2004), as well as other language processing tasks (Goodman, 1996; Goel and Byrne, 2000; Kumar and Byrne, 2002; Titov and Henderson, 2006; Smith and Smith, 2007). The distribution P(e|f) can be induced from a translation system’s features and weights by exponentiating with base b to form a log-linear model: P(e|f) = Pe&apos;∈E ba·B(f,e&apos;) ba·B(f,e) We follow Ehling et al. (2007) in choosing b using a held-out tuning set. For algorithms in this section, we assume that E is a k-best list and b has been chosen already, so P(e|f) is fully specified. 1Typically, MBR is defined as arg min.EElE[L(e; e&apos;)] for some loss function L, for example 1 − BLEU(e; e&apos;). These definitions are equivalent. 2.1 Minimum Bayes Risk over Sentence Pairs Given </context>
</contexts>
<marker>Titov, Henderson, 2006</marker>
<rawString>Ivan Titov and James Henderson. 2006. Loss minimization in parse reranking. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Tromble</author>
<author>Shankar Kumar</author>
<author>Franz Josef Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Lattice minimum Bayes-risk decoding for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="2790" citStr="Tromble et al., 2008" startWordPosition="409" endWordPosition="412">y, we express similarity in terms of features of sentences, and choose translations that are similar to expected feature values. Our exposition begins with algorithms over kbest lists. A naive algorithm for finding MBR translations computes the similarity between every pair of k sentences, entailing O(k�) comparisons. We show that if the similarity measure is linear in features of a sentence, then computing expected similarity for all k sentences requires only k similarity evaluations. Specific instances of this general algorithm have recently been proposed for two linear similarity measures (Tromble et al., 2008; Zhang and Gildea, 2008). However, the sentence similarity measures we want to optimize in MT are not linear functions, and so this fast algorithm for MBR does not apply. For this reason, we propose a new objective that retains the benefits of MBR, but can be optimized efficiently, even for non-linear similarity measures. In experiments using BLEU over 1000- best lists, we found that our objective provided benefits very similar to MBR, only much faster. This same decoding objective can also be computed efficiently from forest-based expectations. Translation forests compactly encode distributi</context>
<context position="8900" citStr="Tromble et al., 2008" startWordPosition="1500" endWordPosition="1503"> φj(e0) =6 0 do 4: �φj ← φj + P(e0|f) · φj(e0) 5: A ← −∞ 6: for e ∈ E do 7: Ae ← 0 8: for j ∈ J such that ωj(e) =6 0 do 9: Ae ← Ae + ωj(e) · φj 10: if Ae &gt; A then A, e� ← Ae, e 11: return e� An example of a linear similarity measure is bag-of-words precision, which can be written as: � U(e; e0) = t∈T1 where T1 is the set of unigrams in the language, and δ(e, t) is an indicator function that equals 1 if t appears in e and 0 otherwise. Figure 1 compares Algorithms 1 and 2 using U(e; e0). Other linear functions have been explored for MBR, including Taylor approximations to the logarithm of BLEU (Tromble et al., 2008) and counts of matching constituents (Zhang and Gildea, 2008), which are discussed further in Section 3.3. 2.3 Fast Consensus Decoding using Non-Linear Similarity Measures Most similarity measures of interest for machine translation are not linear, and so Algorithm 2 does not apply. Computing MBR even with simple non-linear measures such as BLEU, NIST or bagof-words F1 seems to require O(k�) computation time. However, these measures are all functions of features of e0. That is, they can be expressed as S(e; φ(e0)) for a feature mapping φ : E → R. For example, we can express BLEU(e; e0) = exp I</context>
<context position="14961" citStr="Tromble et al., 2008" startWordPosition="2594" endWordPosition="2597">erior distribution. In place of k-best h = 0.4 · 1 + (0.6 · 1.0) · 1 Figure 2: This translation forest for a Spanish sentence encodes two English parse trees. Hyper-edges (boxes) are annotated with normalized transition probabilities, as well as the bigrams produced by each rule application. The expected count of the bigram “man with” is the sum of posterior probabilities of the two hyper-edges that produce it. In this example, we normalized inside scores at all nodes to 1 for clarity. lists, compact encodings of translation distributions have proven effective for MBR (Zhang and Gildea, 2008; Tromble et al., 2008). In this section, we consider BLEU in particular, for which the relevant features O(e) are n-gram counts up to length n = 4. We show how to compute expectations of these counts efficiently from translation forests. 3.1 Translation Forests Translation forests compactly encode an exponential number of output translations for an input sentence, along with their model scores. Forests arise naturally in chart-based decoding procedures for many hierarchical translation systems (Chiang, 2007). Exploiting forests has proven a fruitful avenue of research in both parsing (Huang, 2008) and machine trans</context>
<context position="19128" citStr="Tromble et al. (2008)" startWordPosition="3269" endWordPosition="3272">y to richer models as well. They propose an MBR decoding objective of maximizing the expected number of matching constituent counts relative to the model’s distribution. The corresponding constituent-matching similarity measure can be expressed as a linear function of features of e&apos;, which are indicators of constituents. Expectations of constituent indicator features are the same as posterior constituent probabilities, which can be computed from a translation forest using the inside-outside algorithm. This forest-based MBR approach improved translation output relative to Viterbi translations. Tromble et al. (2008) describe a similar approach using MBR with a linear similarity measure. They derive a first-order Taylor approximation to the logarithm of a slightly modified definition of corpus BLEU4, which is linear in n-gram indicator features δ(e&apos;, t) of e&apos;. These features are weighted by n-gram counts c(e, t) and constants θ that are estimated from held-out data. The linear similarity measure takes the following form, where Tn is the set of n-grams: θt · c(e, t) · δ(e&apos;, t). Using G, Tromble et al. (2008) extend MBR to word lattices, which improves performance over k-best list MBR. Our approach differs </context>
<context position="20425" citStr="Tromble et al. (2008)" startWordPosition="3487" endWordPosition="3490">ernative to MBR using BLEU, while they propose decoding with MBR using a linear alternative to BLEU. The specifics of our approaches also differ in important ways. First, word lattices are a subclass of forests that have only one source node for each edge (i.e., a graph, rather than a hyper-graph). While forests are more general, the techniques for computing posterior edge probabilities in lattices and forests are similar. One practical difference is that the forests needed for fast consensus decoding are 4The log-BLEU function must be modified slightly to yield a linear Taylor approximation: Tromble et al. (2008) replace the clipped n-gram count with the product of an ngram count and an n-gram indicator function. X P(h|f) = e:hEe G(e; e&apos;) = θ0|e |+ 4 X n=1 X tETn 571 generated already by the decoder of a syntactic translation system. Second, rather than use BLEU as a sentencelevel similarity measure directly, Tromble et al. (2008) approximate corpus BLEU with G above. The parameters 0 of the approximation must be estimated on a held-out data set, while our approach requires no such estimation step. Third, our approach is also simpler computationally. The features required to compute G are indicators S</context>
<context position="21988" citStr="Tromble et al. (2008)" startWordPosition="3759" endWordPosition="3762">umber of hyper-edges in the forest or lattice, and T the number of n-grams that can potentially appear in a translation. Computing indicator expectations seems to require O(H · T) time because of automata intersections. Computing count expectations requires O(H) time, because only a constant number of n-grams can be produced by each hyper-edge. Our approaches also differ in the space of translations from which e� is chosen. A linear similarity measure like G allows for efficient search over the lattice or forest, whereas fast consensus decoding restricts this search to a k-best list. However, Tromble et al. (2008) showed that most of the improvement from lattice-based consensus decoding comes from lattice-based expectations, not search: searching over lattices instead of k-best lists did not change results for two language pairs, and improved a third language pair by 0.3 BLEU. Thus, we do not consider our use of k-best lists to be a substantial liability of our approach. Fast consensus decoding is also similar in character to the concurrently developed variational decoding approach of Li et al. (2009). Using BLEU, both approaches choose outputs that match expected n-gram counts from forests, though dif</context>
<context position="29076" citStr="Tromble et al. (2008)" startWordPosition="4889" endWordPosition="4892">est rather than a 104-best list improved Hiero by an additional 0.8 BLEU (1.0 over the baseline). Forest-based expectations always outperformed k-best lists, but curiously the magnitude of benefit was not consistent across systems. We believe the difference is in part due to more aggressive forest pruning within the SBMT decoder. For forest-based decoding, we compared two similarity measures: BLEU and its linear Taylor approximation G from section 3.3.8 Table 2 shows were identical to standard BLEU. 8We did not estimate the 0 parameters of G ourselves; instead we used the parameters listed in Tromble et al. (2008), which were also estimated for GALE data. We also approximated E[6(e�, t)] with a clipped expected count 573 N-grams from baseline translations N-grams with high expected count 61.4 50.5 Hiero SBMT Figure 3: N-grams with high expected count are more likely to appear in the reference translation that n-grams in the translation model’s Viterbi translation, e*. Above, we compare the precision, relative to reference translations, of sets of n-grams chosen in two ways. The left bar is the precision of the n-grams in e*. The right bar is the precision of n-grams with E[c(e, t)] &gt; p. To justify this</context>
</contexts>
<marker>Tromble, Kumar, Och, Macherey, 2008</marker>
<rawString>Roy Tromble, Shankar Kumar, Franz Josef Och, and Wolfgang Macherey. 2008. Lattice minimum Bayes-risk decoding for statistical machine translation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Venugopal</author>
<author>Andreas Zollmann</author>
<author>Stephan Vogel</author>
</authors>
<title>An efficient two-pass approach to synchronous-CFG driven statistical MT.</title>
<date>2007</date>
<booktitle>In Proceedings of HLT: the North American Association for Computational Linguistics Conference.</booktitle>
<contexts>
<context position="3606" citStr="Venugopal et al., 2007" startWordPosition="539" endWordPosition="542">ropose a new objective that retains the benefits of MBR, but can be optimized efficiently, even for non-linear similarity measures. In experiments using BLEU over 1000- best lists, we found that our objective provided benefits very similar to MBR, only much faster. This same decoding objective can also be computed efficiently from forest-based expectations. Translation forests compactly encode distributions over much larger sets of derivations and arise naturally in chart-based decoding for a wide variety of hierarchical translation systems (Chiang, 2007; Galley et al., 2006; Mi et al., 2008; Venugopal et al., 2007). The resulting forest-based decoding procedure compares favorably in both complexity and performance to the recently proposed latticebased MBR (Tromble et al., 2008). The contributions of this paper include a lineartime algorithm for MBR using linear similarities, a linear-time alternative to MBR using non-linear similarity measures, and a forest-based extension to this procedure for similarities based on n-gram counts. In experiments, we show that our fast procedure is on average 80 times faster than MBR using 1000-best lists. We also show that using forests outperforms using k-best lists co</context>
</contexts>
<marker>Venugopal, Zollmann, Vogel, 2007</marker>
<rawString>Ashish Venugopal, Andreas Zollmann, and Stephan Vogel. 2007. An efficient two-pass approach to synchronous-CFG driven statistical MT. In Proceedings of HLT: the North American Association for Computational Linguistics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
</authors>
<title>Efficient multipass decoding for synchronous context free grammars.</title>
<date>2008</date>
<booktitle>In Proceedings of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2815" citStr="Zhang and Gildea, 2008" startWordPosition="413" endWordPosition="416">ty in terms of features of sentences, and choose translations that are similar to expected feature values. Our exposition begins with algorithms over kbest lists. A naive algorithm for finding MBR translations computes the similarity between every pair of k sentences, entailing O(k�) comparisons. We show that if the similarity measure is linear in features of a sentence, then computing expected similarity for all k sentences requires only k similarity evaluations. Specific instances of this general algorithm have recently been proposed for two linear similarity measures (Tromble et al., 2008; Zhang and Gildea, 2008). However, the sentence similarity measures we want to optimize in MT are not linear functions, and so this fast algorithm for MBR does not apply. For this reason, we propose a new objective that retains the benefits of MBR, but can be optimized efficiently, even for non-linear similarity measures. In experiments using BLEU over 1000- best lists, we found that our objective provided benefits very similar to MBR, only much faster. This same decoding objective can also be computed efficiently from forest-based expectations. Translation forests compactly encode distributions over much larger sets</context>
<context position="8961" citStr="Zhang and Gildea, 2008" startWordPosition="1510" endWordPosition="1513"> for e ∈ E do 7: Ae ← 0 8: for j ∈ J such that ωj(e) =6 0 do 9: Ae ← Ae + ωj(e) · φj 10: if Ae &gt; A then A, e� ← Ae, e 11: return e� An example of a linear similarity measure is bag-of-words precision, which can be written as: � U(e; e0) = t∈T1 where T1 is the set of unigrams in the language, and δ(e, t) is an indicator function that equals 1 if t appears in e and 0 otherwise. Figure 1 compares Algorithms 1 and 2 using U(e; e0). Other linear functions have been explored for MBR, including Taylor approximations to the logarithm of BLEU (Tromble et al., 2008) and counts of matching constituents (Zhang and Gildea, 2008), which are discussed further in Section 3.3. 2.3 Fast Consensus Decoding using Non-Linear Similarity Measures Most similarity measures of interest for machine translation are not linear, and so Algorithm 2 does not apply. Computing MBR even with simple non-linear measures such as BLEU, NIST or bagof-words F1 seems to require O(k�) computation time. However, these measures are all functions of features of e0. That is, they can be expressed as S(e; φ(e0)) for a feature mapping φ : E → R. For example, we can express BLEU(e; e0) = exp I �1 − |e |1 0, t)) L Je |/ 4r- Et∈Tn c(e, t) In this expressi</context>
<context position="14938" citStr="Zhang and Gildea, 2008" startWordPosition="2590" endWordPosition="2593"> underlying model’s posterior distribution. In place of k-best h = 0.4 · 1 + (0.6 · 1.0) · 1 Figure 2: This translation forest for a Spanish sentence encodes two English parse trees. Hyper-edges (boxes) are annotated with normalized transition probabilities, as well as the bigrams produced by each rule application. The expected count of the bigram “man with” is the sum of posterior probabilities of the two hyper-edges that produce it. In this example, we normalized inside scores at all nodes to 1 for clarity. lists, compact encodings of translation distributions have proven effective for MBR (Zhang and Gildea, 2008; Tromble et al., 2008). In this section, we consider BLEU in particular, for which the relevant features O(e) are n-gram counts up to length n = 4. We show how to compute expectations of these counts efficiently from translation forests. 3.1 Translation Forests Translation forests compactly encode an exponential number of output translations for an input sentence, along with their model scores. Forests arise naturally in chart-based decoding procedures for many hierarchical translation systems (Chiang, 2007). Exploiting forests has proven a fruitful avenue of research in both parsing (Huang, </context>
<context position="18357" citStr="Zhang and Gildea (2008)" startWordPosition="3159" endWordPosition="3162"> and so this posterior is approximate. The expected n-gram count vector for a hyperedge is E[φ(h)] = P(h|f) · φ(h). Hence, after computing P(h|f) for every h, we need only sum P(h|f) · φ(h) for all h to compute E[φ(e)]. This entire procedure is a linear-time computation in the number of hyper-edges in the forest. To complete forest-based fast consensus decoding, we then extract a k-best list of unique translations from the forest (Huang et al., 2006) and continue Algorithm 3 from line 5, which chooses the e� from the k-best list that maximizes BLEU(e; E[φ(e&apos;)]). 3.3 Comparison to Related Work Zhang and Gildea (2008) embed a consensus decoding procedure into a larger multi-pass decoding framework. They focus on inversion transduction grammars, but their ideas apply to richer models as well. They propose an MBR decoding objective of maximizing the expected number of matching constituent counts relative to the model’s distribution. The corresponding constituent-matching similarity measure can be expressed as a linear function of features of e&apos;, which are indicators of constituents. Expectations of constituent indicator features are the same as posterior constituent probabilities, which can be computed from </context>
</contexts>
<marker>Zhang, Gildea, 2008</marker>
<rawString>Hao Zhang and Daniel Gildea. 2008. Efficient multipass decoding for synchronous context free grammars. In Proceedings of the Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>