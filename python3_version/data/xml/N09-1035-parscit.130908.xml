<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003606">
<title confidence="0.989547">
On the Syllabification of Phonemes
</title>
<author confidence="0.997674">
Susan Bartlett† and Grzegorz Kondrak† and Colin Cherry$
</author>
<affiliation confidence="0.9977735">
†Department of Computing Science $Microsoft Research
University of Alberta One Microsoft Way
</affiliation>
<address confidence="0.860982">
Edmonton, AB, T6G 2E8, Canada Redmond, WA, 98052
</address>
<email confidence="0.993189">
{susan,kondrak}@cs.ualberta.ca colinc@microsoft.com
</email>
<sectionHeader confidence="0.993759" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998445588235294">
Syllables play an important role in speech
synthesis and recognition. We present sev-
eral different approaches to the syllabifica-
tion of phonemes. We investigate approaches
based on linguistic theories of syllabification,
as well as a discriminative learning technique
that combines Support Vector Machine and
Hidden Markov Model technologies. Our
experiments on English, Dutch and German
demonstrate that our transparent implemen-
tation of the sonority sequencing principle
is more accurate than previous implemen-
tations, and that our language-independent
SVM-based approach advances the current
state-of-the-art, achieving word accuracy of
over 98% in English and 99% in German and
Dutch.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999828730769231">
Syllabification is the process of dividing a word
into its constituent syllables. Although some work
has been done on syllabifying orthographic forms
(M¨uller et al., 2000; Bouma, 2002; Marchand and
Damper, 2007; Bartlett et al., 2008), syllables are,
technically speaking, phonological entities that can
only be composed of strings of phonemes. Most
linguists view syllables as an important unit of
prosody because many phonological rules and con-
straints apply within syllables or at syllable bound-
aries (Blevins, 1995).
Apart from their purely linguistic significance,
syllables play an important role in speech synthesis
and recognition (Kiraz and M¨obius, 1998; Pearson
et al., 2000). The pronunciation of a given phoneme
tends to vary depending on its location within a syl-
lable. While actual implementations vary, text-to-
speech (TTS) systems must have, at minimum, three
components (Damper, 2001): a letter-to-phoneme
(L2P) module, a prosody module, and a synthesis
module. Syllabification can play a role in all three
modules.
Because of the productive nature of language, a
dictionary look-up process for syllabification is in-
adequate. No dictionary can ever contain all possi-
ble words in a language. For this reason, it is neces-
sary to develop systems that can automatically syl-
labify out-of-dictionary words.
In this paper, we advance the state-of-the-art
in both categorical (non-statistical) and supervised
syllabification. We outline three categorical ap-
proaches based on common linguistic theories of
syllabification. We demonstrate that when imple-
mented carefully, such approaches can be very ef-
fective, approaching supervised performance. We
also present a data-driven, discriminative solution:
a Support Vector Machine Hidden Markov Model
(SVM-HMM), which tags each phoneme with its
syllabic role. Given enough data, the SVM-HMM
achieves impressive accuracy thanks to its ability
to capture context-dependent generalizations, while
also memorizing inevitable exceptions. Our ex-
periments on English, Dutch and German demon-
strate that our SVM-HMM approach substantially
outperforms the existing state-of-the-art learning ap-
proaches. Although direct comparisons are difficult,
our system achieves over 99% word accuracy on
German and Dutch, and the highest reported accu-
racy on English.
The paper is organized as follows. We outline
common linguistic theories of syllabification in Sec-
tion 2, and we survey previous computational sys-
</bodyText>
<page confidence="0.979986">
308
</page>
<note confidence="0.890831">
Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the ACL, pages 308–316,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.99837">
tems in Section 3. Our linguistically-motivated ap-
proaches are described in Section 4. In Section 5,
we describe our system based on the SVM-HMM.
The experimental results are presented in Section 6.
</bodyText>
<sectionHeader confidence="0.611267" genericHeader="method">
2 Theories of Syllabification
</sectionHeader>
<bodyText confidence="0.999957305084746">
There is some debate as to the exact structure of
a syllable. However, phonologists are in gen-
eral agreement that a syllable consists of a nucleus
(vowel sound), preceded by an optional onset and
followed by an optional coda. In many languages,
both the onset and the coda can be complex, i.e.,
composed of more than one consonant. For exam-
ple, the word breakfast [brEk-fast] contains two syl-
lables, of which the first has a complex onset [br],
and the second a complex coda [st]. Languages dif-
fer with respect to various typological parameters,
such as optionality of onsets, admissibility of co-
das, and the allowed complexity of the syllable con-
stituents. For example, onsets are required in Ger-
man, while Spanish prohibits complex codas.
There are a number of theories of syllabification;
we present three of the most prevalent. The Legal-
ity Principle constrains the segments that can be-
gin and end syllables to those that appear at the be-
ginning and end of words. In other words, a sylla-
ble is not allowed to begin with a consonant clus-
ter that is not found at the beginning of some word,
or end with a cluster that is not found at the end of
some word (Goslin and Frauenfelder, 2001). Thus,
a word like admit [admIt] must be syllabified [ad-
mIt] because [dm] never appears word-initially or
word-finally in English. A shortcoming of the le-
gality principle is that it does not always imply a
unique syllabification. For example, in a word like
askew [askju], the principle does not rule out any of
[a-skju], [as-kju], or [ask-ju], as all three employ le-
gal onsets and codas.
The Sonority Sequencing Principle (SSP) pro-
vides a stricter definition of legality. The sonor-
ity of a sound is its inherent loudness, holding fac-
tors like pitch and duration constant (Crystal, 2003).
Low vowels like [a], the most sonorous sounds, are
high on the sonority scale, while plosive consonants
like [t] are at the bottom. When syllabifying a
word, SSP states that sonority should increase from
the first phoneme of the onset to the syllable’s nu-
cleus, and then fall off to the coda (Selkirk, 1984).
Consequently, in a word like vintage [vIntIt], we
can rule out a syllabification like [vI-ntId3] because
[n] is more sonorant than [t]. However, SSP does
not tell us whether to prefer [vIn-tIt] or [vInt-It].
Moreover, when syllabifying a word like vintner
[vIntnar], the theory allows both [vIn-tnar] and [vInt-
nar], even though [tn] is an illegal onset in English.
Both the Legality Principle and SSP tell us which
onsets and codas are permitted in legal syllables, and
which are not. However, neither theory gives us any
guidance when deciding between legal onsets. The
Maximal Onset Principle addresses this by stating
we should extend a syllable’s onset at the expense
of the preceding syllable’s coda whenever it is legal
to do so (Kahn, 1976). For example, the principle
gives preference to [a-skju] and [vIn-tIt] over their
alternatives.
</bodyText>
<sectionHeader confidence="0.946877" genericHeader="method">
3 Previous Computational Approaches
</sectionHeader>
<bodyText confidence="0.998560222222222">
Unlike tasks such as part of speech tagging or syn-
tactic parsing, syllabification does not involve struc-
tural ambiguity. It is generally believed that syllable
structure is usually predictable in a language pro-
vided that the rules have access to all conditioning
factors: stress, morphological boundaries, part of
speech, etymology, etc. (Blevins, 1995). However,
in speech applications, the phonemic transcription of
a word is often the only linguistic information avail-
able to the system. This is the common assumption
underlying a number of computational approaches
that have been proposed for the syllabification of
phonemes.
Daelemans and van den Bosch (1992) present one
of the earliest systems on automatic syllabification:
a neural network-based implementation for Dutch.
Daelemans et al. (1997) also explore the application
of exemplar-based generalization (EBG), sometimes
called instance-based learning. EBG generally per-
forms a simple database look-up to syllabify a test
pattern, choosing the most common syllabification.
In cases where the test pattern is not found in the
database, the most similar pattern is used to syllab-
ify the test pattern.
Hidden Markov Models (HMMs) are another
popular approach to syllabification. Krenn (1997)
introduces the idea of treating syllabification as a
</bodyText>
<page confidence="0.998728">
309
</page>
<bodyText confidence="0.999977209677419">
tagging task. Working from a list of syllabified
phoneme strings, she automatically generates tags
for each phone. She uses a second-order HMM to
predict sequences of tags; syllable boundaries can be
trivially recovered from the tags. Demberg (2006)
applies a fourth-order HMM to the syllabification
task, as a component of a larger German text-to-
speech system. Schmid et al. (2007) improve on
Demberg’s results by applying a fifth-order HMM
that conditions on both the previous tags and their
corresponding phonemes.
Kiraz and M¨obius (1998) present a weighted
finite-state-based approach to syllabification. Their
language-independent method builds an automaton
for each of onsets, nuclei, and codas, by count-
ing occurrences in training data. These automatons
are then composed into a transducer accepting se-
quences of one or more syllables. They do not report
quantitative results for their method.
Pearson et al. (2000) compare two rule-based sys-
tems (they do not elaborate on the rules employed)
with a CART decision tree-based approach and a
“global statistics” algorithm. The global statistics
method is based on counts of consonant clusters
in contexts such as word boundaries, short vow-
els, or long vowels. Each test word has syllable
boundaries placed according to the most likely lo-
cation given a cluster and its context. In experi-
ments performed with their in-house dataset, their
statistics-based method outperforms the decision-
tree approach and the two rule-based methods.
M¨uller (2001) presents a hybrid of a categori-
cal and data-driven approach. First, she manually
constructs a context-free grammar of possible sylla-
bles. This grammar is then made probabilistic using
counts obtained from training data. M¨uller (2006)
attempts to make her method language-independent.
Rather than hand-crafting her context-free grammar,
she automatically generates all possible onsets, nu-
clei, and codas, based on the phonemes existing in
the language. The results are somewhat lower than
in (M¨uller, 2001), but the approach can be more eas-
ily ported across languages.
Goldwater and Johnson (2005) also explore us-
ing EM to learn the structure of English and Ger-
man phonemes in an unsupervised setting, following
M¨uller in modeling syllable structure with PCFGs.
They initialize their parameters using a deterministic
parser implementing the sonority principle and esti-
mate the parameters for their maximum likelihood
approach using EM.
Marchand et al. (2007) apply their Syllabification
by Analogy (SbA) technique, originally developed
for orthographic forms, to the pronunciation do-
main. For each input word, SbA finds the most sim-
ilar substrings in a lexicon of syllabified phoneme
strings and then applies the dictionary syllabifica-
tions to the input word. Their survey paper also in-
cludes comparisons with a method broadly based on
the legality principle. The authors find their legality-
based implementation fares significantly worse than
SbA.
</bodyText>
<sectionHeader confidence="0.993344" genericHeader="method">
4 Categorical Approaches
</sectionHeader>
<bodyText confidence="0.999938225806451">
Categorical approaches to syllabification are appeal-
ing because they are efficient and linguistically intu-
itive. In addition, they require little or no syllable-
annotated data. We present three categorical al-
gorithms that implement the linguistic insights out-
lined in Section 2. All three can be viewed as vari-
ations on the basic pseudo-code shown in Figure 1.
Every vowel is labeled as a nucleus, and every con-
sonant is labeled as either an onset or a coda. The
algorithm labels all consonants as onsets unless it is
illegal to do so. Given the labels, it is straightfor-
ward to syllabify a word. The three methods differ
in how they determine a “legal” onset.
As a rough baseline, the MAXONSET implemen-
tation considers all combinations of consonants to be
legal onsets. Only word-final consonants are labeled
as codas.
LEGALITY combines the Legality Principle with
onset maximization. In our implementation, we col-
lect all word-initial consonant clusters from the cor-
pus and deem them to be legal onsets. With this
method, no syllable can have an onset that does not
appear word-initially in the training data. We do not
test for the legality of codas. The performance of
LEGALITY depends on the number of phonetic tran-
scriptions that are available, but the transcriptions
need not be annotated with syllable breaks.
SONORITY combines the Sonority Sequencing
Principle with onset maximization. In this approach,
an onset is considered legal if every member of the
onset ranks lower on the sonority scale than ensuing
</bodyText>
<page confidence="0.987562">
310
</page>
<bodyText confidence="0.9246195">
until current phoneme is a vowel
label current phoneme as an onset
</bodyText>
<subsectionHeader confidence="0.767382">
end loop
</subsectionHeader>
<bodyText confidence="0.83442875">
until all phonemes have been labeled
label current phoneme as a nucleus
if there are no more vowels in the word
label all remaining consonants as codas
</bodyText>
<figure confidence="0.972134">
else
onset := all consonants before next vowel
coda := empty
until onset is legal
coda := coda plus first phoneme of onset
onset := onset less first phoneme
end loop
end if
end loop
Insert syllable boundaries before onsets
</figure>
<figureCaption confidence="0.9969195">
Figure 1: Pseudo-code for syllabifying a string of
phonemes.
</figureCaption>
<bodyText confidence="0.999841333333333">
consonants. SONORITY requires no training data be-
cause it implements a sound linguistic theory. How-
ever, an existing development set for a given lan-
guage can help with defining and validating addi-
tional language-specific constraints.
Several sonority scales of varying complexity
have been proposed. For example, Selkirk (1984)
specifies a hierarchy of eleven distinct levels. We
adopt a minimalistic scale shown in Figure 2. which
avoids most of the disputed sonority contrasts (Jany
et al., 2007). We set the sonority distance parame-
ter to 2, which ensures that adjacent consonants in
the onset differ by at least two levels of the scale.
For example, [pr] is an acceptable onset because it
is composed of an obstruent and a liquid, but [pn] is
not, because nasals directly follow obstruents on our
sonority scale.
In addition, we incorporate several English-
specific constraints listed by Kenstowicz (1994,
pages 257–258). The constraints, or filters, prohibit
complex onsets containing:
</bodyText>
<listItem confidence="0.822858">
(i) two labials (e.g., [pw], [bw], [fw], [vw]),
(ii) a non-strident coronal followed by a lateral
(e.g., [tl], [dl], [0l])
(iii) a voiced fricative (e.g., [vr], [zw], except [vj]),
(iv) a palatal consonant (e.g., [ fl], [#r], except [ fr]).
</listItem>
<subsectionHeader confidence="0.353591">
Sound Examples Level
</subsectionHeader>
<equation confidence="0.820191">
Vowels u,a, ... 4
Glides w, j, .. . 3
Liquids l, r, ... 2
Nasals m,rl, ... 1
Obstruents g,0, ... 0
</equation>
<figureCaption confidence="0.999306">
Figure 2: The sonority scale employed by SONORITY.
</figureCaption>
<bodyText confidence="0.999922">
A special provision allows for prepending the
phoneme [s] to onsets beginning with a voiceless
plosive. This reflects the special status of [s] in En-
glish, where onsets like [sk] and [sp] are legal even
though the sonority is not strictly increasing.
</bodyText>
<sectionHeader confidence="0.991571" genericHeader="method">
5 Supervised Approach: SVM-HMM
</sectionHeader>
<bodyText confidence="0.999985071428571">
If annotated data is available, a classifier can be
trained to predict the syllable breaks. A Support
Vector Machine (SVM) is a discriminative super-
vised learning technique that allows for a rich fea-
ture representation of the input space. In principle,
we could use a multi-class SVM to classify each
phoneme according to its position in a syllable on
the basis of a set of features. However, a traditional
SVM would treat each phoneme in a word as an in-
dependent instance, preventing us from considering
interactions between labels. In order to overcome
this shortcoming, we employ an SVM-HMM1 (Al-
tun et al., 2003), an instance of the Structured SVM
formalism (Tsochantaridis et al., 2004) that has been
specialized for sequence tagging.
When training a structured SVM, each training
instance xi is paired with its label yi, drawn from
the set of possible labels, Yi. In our case, the train-
ing instances xi are words, represented as sequences
of phonemes, and their labels yi are syllabifications,
represented as sequences of onset/nucleus/coda tags.
For each training example, a feature vector Ψ(x, y)
represents the relationship between the example and
a candidate tag sequence. The SVM finds a weight
vector w, such that w ·Ψ(x, y) separates correct tag-
gings from incorrect taggings by as large a margin
as possible. Hamming distance DH is used to cap-
ture how close a wrong sequence y is to yi, which
</bodyText>
<footnote confidence="0.998258">
1http://svmlight.joachims.org/svm struct.html
</footnote>
<page confidence="0.997308">
311
</page>
<bodyText confidence="0.9993572">
in turn impacts the required margin. Tag sequences
that share fewer tags in common with the correct se-
quence are separated by a larger margin.
Mathematically, a (simplified) statement of the
SVM learning objective is:
</bodyText>
<equation confidence="0.9985375">
∀i∀y∈Yi,y=,4yi : (1)
[Ψ(xi, yi) &apos; w &gt; Ψ(xi, y) &apos; w + DH(y, yi)]
</equation>
<bodyText confidence="0.997522">
This objective is only satisfied when w tags all train-
ing examples correctly. In practice, slack variables
are introduced, which allow us to trade off training
accuracy and the complexity of w via a cost parame-
ter. We tune this parameter on our development set.
The SVM-HMM training procedure repeatedly
uses the Viterbi algorithm to find, for the current
w and each (xi, yi) training pair, the sequence y
that most drastically violates the inequality shown in
Equation 1. These incorrect tag sequences are added
to a growing set, which constrains the quadratic op-
timization procedure used to find the next w. The
process iterates until no new violating sequences are
found, producing an approximation to the inequality
over all y E Yi. A complete explanation is given by
Tsochantaridis et al. (2004).
Given a weight vector w, a structured SVM tags
new instances x according to:
</bodyText>
<equation confidence="0.845844">
argmaxy∈Y [Ψ(x, y) &apos; w] (2)
</equation>
<bodyText confidence="0.999144333333333">
The SVM-HMM gets the HMM portion of its name
from its use of the HMM Viterbi algorithm to solve
this argmax.
</bodyText>
<subsectionHeader confidence="0.710108">
5.1 Features
</subsectionHeader>
<bodyText confidence="0.999979785714286">
We investigated several tagging schemes, described
in detail by Bartlett (2007). During development,
we found that tagging each phoneme with its syl-
labic role (Krenn, 1997) works better than the simple
binary distinction between syllable-final and other
phonemes (van den Bosch, 1997). We also dis-
covered that accuracy can be improved by number-
ing the tags. Therefore, in our tagging scheme, the
single-syllable word strengths [strvrOs] would be la-
beled with the sequence {O1 O2 O3 N1 C1 C2 C3}.
Through the use of the Viterbi algorithm, our fea-
ture vector Ψ(x, y) is naturally divided into emis-
sion and transition features. Emission features link
an aspect of the input word x with a single tag in the
</bodyText>
<table confidence="0.9881455">
Method English
MAXONSET 61.38
LEGALITY 93.16
SONORITY 95.00
SVM-HMM 98.86
tsylb 93.72
</table>
<tableCaption confidence="0.999872">
Table 1: Word accuracy on the CELEX dataset.
</tableCaption>
<bodyText confidence="0.999861909090909">
sequence y. Unlike a generative HMM, these emis-
sion features do not require any conditional indepen-
dence assumptions. Transition features link tags to
tags. Our only transition features are counts of adja-
cent tag pairs occurring in y.
For the emission features, we use the current
phoneme and a fixed-size context window of sur-
rounding phonemes. Thus, the features for the
phoneme [k] in hockey [haki] might include the [a]
preceding it, and the [i] following it. In experiments
on our development set, we found that the optimal
window size is nine: four phonemes on either side
of the focus phoneme. Because the SVM-HMM is a
linear classifier, we need to explicitly state any im-
portant conjunctions of features. This allows us to
capture more complex patterns in the language that
unigrams alone cannot describe. For example, the
bigram [ps] is illegal as an onset in English, but per-
fectly reasonable as a coda. Experiments on the de-
velopment set showed that performance peaked us-
ing all unigrams, bigrams, trigrams, and four-grams
found within our context window.
</bodyText>
<sectionHeader confidence="0.983812" genericHeader="method">
6 Syllabification Experiments
</sectionHeader>
<bodyText confidence="0.999987928571429">
We developed our approach using the English por-
tion of the CELEX lexical database (Baayen et al.,
1995). CELEX provides the phonemes of a word
and its correct syllabification. It does not designate
the phonemes as onsets, nuclei, or codas, which is
the labeling we want to predict. Fortunately, extract-
ing the labels from a syllabified word is straightfor-
ward. All vowel phones are assigned to be nuclei;
consonants preceding the nucleus in a syllable are
assigned to be onsets, while consonants following
the nucleus in a syllable are assigned to be codas.
The results in Table 1 were obtained on a test set
of 5K randomly selected words. For training the
SVM-HMM, we randomly selected 30K words not
</bodyText>
<page confidence="0.997323">
312
</page>
<bodyText confidence="0.999977666666667">
appearing in the test set, while 6K training examples
were held out for development testing. We report
the performance in terms of word accuracy (entire
words syllabified correctly). Among the categori-
cal approaches, SONORITY clearly outperforms not
only LEGALITY, but also tsylb (Fisher, 1996), an
implementation of the complex algorithm of Kahn
(1976), which makes use of lists of legal English
onsets. Overall, our SVM-based approach is a clear
winner.
The results of our discriminative method com-
pares favorably with the results of competing ap-
proaches on English CELEX. Since there are no
standard train-test splits for syllabification, the
comparison is necessarily indirect, but note that
our training set is substantially smaller. For
her language-independent PCFG-based approach,
M¨uller (2006) reports 92.64% word accuracy on the
set of 64K examples from CELEX using 10-fold
cross-validation. The Learned EBG approach of
van den Bosch (1997) achieves 97.78% word accu-
racy when training on approximately 60K examples.
Therefore, our results represent a nearly 50% reduc-
tion of the error rate.
</bodyText>
<figureCaption confidence="0.9776185">
Figure 3: Word accuracy on English CELEX as a func-
tion of the number of thousands of training examples.
</figureCaption>
<bodyText confidence="0.999976333333333">
Though the SVM-HMM’s training data require-
ments are lower than previous supervised syllabi-
fication approaches, they are still substantial. Fig-
ure 3 shows a learning curve over varying amounts
of training data. Performance does not reach accept-
able levels until 5K training examples are provided.
</bodyText>
<subsectionHeader confidence="0.950202">
6.1 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999964">
There is a fair amount of overlap in the errors made
by the SVM-HMM and the SONORITY. Table 4
shows a few characteristic examples. The CELEX
syllabifications of tooth-ache and pass-ports fol-
low the morphological boundaries of the compound
words. Morphological factors are a source of er-
rors for both approaches, but significantly more so
for SONORITY. The performance difference comes
mainly from the SVM’s ability to handle many of
these morphological exceptions. The SVM gener-
ates the correct syllabification of northeast [nor0-
ist], even though an onset of [0] is perfectly legal.
On the other hand, the SVM sometimes overgener-
alizes, as in the last example in Table 4.
</bodyText>
<figure confidence="0.947650333333333">
SVM-HMM SONORITY
tu-Tek tu-Tek toothache
pae-sports pae-sports passports
nor&amp;-ist nor-Tist northeast
dIs-plizd dI-splizd displeased
dIs-koz dI-skoz discos
</figure>
<figureCaption confidence="0.9987885">
Figure 4: Examples of syllabification errors. (Correct
syllabifications are shown in bold.)
</figureCaption>
<subsectionHeader confidence="0.999276">
6.2 The NETtalk Dataset
</subsectionHeader>
<bodyText confidence="0.998875166666667">
Marchand et al. (2007) report a disappointing word
accuracy of 54.14% for their legality-based imple-
mentation, which does not accord with the results
of our categorical approaches on English CELEX.
Consequently, we also apply our methods to the
dataset they used for their experiments: the NETtalk
dictionary. NETtalk contains 20K English words; in
the experiments reported here, we use 13K training
examples and 7K test words.
As is apparent from Table 2, our performance
degrades significantly when switching to NETtalk.
The steep decline found in the categorical meth-
ods is particularly notable, and indicates significant
divergence between the syllabifications employed
in the two datasets. Phonologists do not always
agree on the correct syllable breaks for a word,
but the NETtalk syllabifications are often at odds
with linguistic intuitions. We randomly selected 50
words and compared their syllabifications against
those found in Merriam-Webster Online. We found
that CELEX syllabifications agree with Merriam-
Webster in 84% of cases, while NETtalk only agrees
52% of the time.
Figure 5 shows several words from the NETtalk
</bodyText>
<page confidence="0.997767">
313
</page>
<table confidence="0.994443363636363">
Method German Dutch
MAXONSET 19.51 23.44
SONORITY 76.32 77.51
LEGALITY 79.55 64.31
SVM-HMM (50K words) 99.26 97.79
SVM-HMM (250K words) 99.87 99.16
Method English
MAXONSET 33.64
SONORITY 52.80
LEGALITY 53.08
SVM-HMM 92.99
</table>
<tableCaption confidence="0.9093915">
Table 2: Word accuracy on the NETtalk dataset.
Table 3: Word accuracy on the CELEX dataset.
</tableCaption>
<bodyText confidence="0.988808818181818">
and CELEX datasets. We see that CELEX fol-
lows the maximal onset principle consistently, while
NETtalk does in some instances but not others. We
also note that there are a number of NETtalk syllab-
ifications that are clearly wrong, such as the last two
examples in Figure 5. The variability of NETtalk
is much more difficult to capture with any kind of
principled approach. Thus, we argue that low per-
formance on NETtalk indicate inconsistent syllabi-
fications within that dataset, rather than any actual
deficiency of the methods.
</bodyText>
<figure confidence="0.827949571428571">
NETtalk CELEX
Ùaes-taIz Ùae-staIz chastise
rEz-Id-ans rE-zI-dans residence
dI-strOI dI-strOI destroy
fo-tAn fo-tAn photon
Ar-pEt-io Ar-pE-ti-o arpeggio
Der-a-baU-t DE-ra-baUt thereabout
</figure>
<figureCaption confidence="0.9976105">
Figure 5: Examples of CELEX and NETtalk syllabifica-
tions.
</figureCaption>
<bodyText confidence="0.9985485">
NETtalk’s variable syllabification practices
notwithstanding, the SVM-HMM approach still
outperforms the previous benchmark on the dataset.
Marchand et al. (2007) report 88.53% word accu-
racy for their SbA technique using leave-one-out
testing on the entire NETtalk set (20K words). With
fewer training examples, we reduce the error rate by
almost 40%.
</bodyText>
<subsectionHeader confidence="0.997902">
6.3 Other Languages
</subsectionHeader>
<bodyText confidence="0.999734866666667">
We performed experiments on German and Dutch,
the two other languages available in the CELEX lex-
ical database. The German and Dutch lexicons of
CELEX are larger than the English lexicon. For both
languages, we selected a 25K test set, and two dif-
ferent training sets, one containing 50K words and
the other containing 250K words. The results are
presented in Table 3.
While our SVM-HMM approach is entirely lan-
guage independent, the same cannot be said about
other methods. The maximal onset principle appears
to hold much more strongly for English than for Ger-
man and Dutch (e.g., patron: [pe-tran] vs. [pat-ron]).
LEGALITY and SONORITY also appear to be less
effective, possibly because of greater tendency for
syllabifications to match morphological boundaries
(e.g., English exclusive: [ik-sklu-siv] vs. Dutch ex-
clusief [rks-kly-zif]). SONORITY is further affected
by our decision to employ the constraints of Ken-
stowicz (1994), although they clearly pertain to En-
glish. We expect that adapting them to specific lan-
guages would bring the results closer to the level of
the English experiments.
Although our SVM system is tuned using an
English development set, the results on both Ger-
man and Dutch are excellent. We could not find
any quantitative data for comparisons on Dutch,
but the comparison with the previously reported re-
sults on German CELEX demonstrates the qual-
ity of our approach. The numbers that follow re-
fer to 10-fold cross-validation on the entire lex-
icon (over 320K entries) unless noted otherwise.
Krenn (1997) obtains tag accuracy of 98.34%, com-
pared to our system’s tag accuracy of 99.97% when
trained on 250K words. With a hand-crafted gram-
mar, M¨uller (2002) achieves 96.88% word accuracy
on CELEX-derived syllabifications, with a training
corpus of two million tokens. Without a hand-
crafted grammar, she reports 90.45% word accu-
racy (M¨uller, 2006). Applying a standard smoothing
algorithm and fourth-order HMM, Demberg (2006)
scores 98.47% word accuracy. A fifth-order joint
N-gram model of Schmid et al. (2007) achieves
99.85% word accuracy with about 278K training
points. However, unlike generative approaches, our
</bodyText>
<page confidence="0.996019">
314
</page>
<table confidence="0.9962474">
Method English German
SONORITY 97.0 94.2
SVM-HMM 99.9 99.4
Categorical Parser 94.9 92.7
Maximum Likelihood 98.1 97.4
</table>
<tableCaption confidence="0.9954325">
Table 4: Word accuracy on the datasets of Goldwater and
Johnson (2005).
</tableCaption>
<bodyText confidence="0.99754675">
SVM-HMM can condition each emission on large
portions of the input using only a first-order Markov
model, which implies much faster syllabification
performance.
</bodyText>
<subsectionHeader confidence="0.887976">
6.4 Direct Comparison with an MLE approach
</subsectionHeader>
<bodyText confidence="0.9999845625">
The results of the competitive approaches that have
been quoted so far (with the exception of tsylb)
are not directly comparable, because neither the re-
spective implementations, nor the actual train-test
splits are publicly available. However, we managed
to obtain the English and German data sets used
by Goldwater and Johnson (2005) in their study,
which focused primarily on unsupervised syllabi-
fication. Their experimental framework is similar
to (M¨uller, 2001). They collect words from running
text and create a training set of 20K tokens and a
test set of 10K tokens. The running text was taken
from the Penn WSJ and ECI corpora, and the syl-
labified phonemic transcriptions were obtained from
CELEX. Table 4 compares our experimental results
with their reported results obtained with: (a) su-
pervised Maximum Likelihood training procedures,
and (b) a Categorical Syllable Parser implementing
the principles of sonority sequencing and onset max-
imization without Kenstowicz’s (1994) onset con-
straints.
The accuracy figures in Table 4 are noticeably
higher than in Table 1. This stems from fundamen-
tal differences in the experimental set-up; Goldwater
and Johnson (2005) test on tokens as found in text,
therefore many frequent short words are duplicated.
Furthermore, some words occur during both training
and testing, to the benefit of the supervised systems
(SVM-HMM and Maximum Likelihood). Neverthe-
less, the results confirm the level of improvement
obtained by both our categorical and supervised ap-
proaches.
</bodyText>
<sectionHeader confidence="0.996742" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999962772727273">
We have presented several different approaches to
the syllabification of phonemes. The results of our
linguistically-motivated algorithms, show that it is
possible to achieve adequate syllabification word
accuracy in English with no little or no syllable-
annotated training data. We have demonstrated that
the poor performance of categorical methods on En-
glish NETtalk actually points to problems with the
NETtalk annotations, rather than with the methods
themselves.
We have also shown that SVM-HMMs can be
used to great effect when syllabifying phonemes.
In addition to being both efficient and language-
independent, they establish a new state-of-the-art for
English and Dutch syllabification. However, they
do require thousands of labeled training examples to
achieve this level of accuracy. In the future, we plan
to explore a hybrid approach, which would benefit
from both the generality of linguistic principles and
the smooth exception-handling of supervised tech-
niques, in order to make best use of whatever data is
available.
</bodyText>
<sectionHeader confidence="0.994725" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9988044">
We are grateful to Sharon Goldwater for providing
the experimental data sets for comparison. This re-
search was supported by the Natural Sciences and
Engineering Research Council of Canada and the
Alberta Informatics Circle of Research Excellence.
</bodyText>
<sectionHeader confidence="0.998508" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9988731875">
Yasemin Altun, Ioannis Tsochantaridis, and Thomas
Hofmann. 2003. Hidden markov support vector ma-
chines. Proceedings of the 20Th International Confer-
ence on Machine Learning (ICML).
R. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The
CELEX lexical database (CD-ROM).
Susan Bartlett, Grzegorz Kondrak, and Colin Cherry.
2008. Automatic syllabification with structured SVMs
for letter-to-phoneme conversion. In Proceedings of
ACL-08: HLT, pages 568–576, Columbus, Ohio.
Susan Bartlett. 2007. Discriminative approach to auto-
matic syllabification. Master’s thesis, Department of
Computing Science, University of Alberta.
Juliette Blevins. 1995. The syllable in phonological
theory. In John Goldsmith, editor, The handbook of
phonological theory, pages 206–244. Blackwell.
</reference>
<page confidence="0.989385">
315
</page>
<reference confidence="0.999927988636364">
Gosse Bouma. 2002. Finite state methods for hyphen-
ation. Natural Language Engineering, 1:1–16.
David Crystal. 2003. A dictionary of linguistics and pho-
netics. Blackwell.
Walter Daelemans and Antal van den Bosch. 1992. Gen-
eralization performance of backpropagaion learning
on a syllabification task. In Proceedings of the 3rd
Twente Workshop on Language Technology, pages 27–
38.
Walter Daelemans, Antal van den Bosch, and Ton Wei-
jters. 1997. IGTree: Using trees for compression and
classification in lazy learning algorithms. Artificial In-
telligence Review, pages 407–423.
Robert Damper. 2001. Learning about speech from
data: Beyond NETtalk. In Data-Driven Techniques in
Speech Synthesis, pages 1–25. Kluwer Academic Pub-
lishers.
Vera Demberg. 2006. Letter-to-phoneme conversion for
a German text-to-speech system. Master’s thesis, Uni-
versity of Stuttgart.
William Fisher. 1996. Tsylb syllabification package.
ftp://jaguar.ncsl.nist.gov/pub/tsylb2-1.1.tar.Z. Last ac-
cessed 31 March 2008.
Sharon Goldwater and Mark Johnson. 2005. Represen-
tational bias in usupervised learning of syllable struc-
ture. In Prcoeedings of the 9th Conference on Compu-
tational Natural Language Learning (CoNLL), pages
112–119.
Jeremy Goslin and Ulrich Frauenfelder. 2001. A com-
parison of theoretical and human syllabification. Lan-
guage and Speech, 44:409–436.
Carmen Jany, Matthew Gordon, Carlos M Nash, and
Nobutaka Takara. 2007. How universal is the sonor-
ity hierarchy? A cross-linguistic study. In 16th Inter-
national Congress of Phonetic Sciences, pages 1401–
1404.
Daniel Kahn. 1976. Syllable-based generalizations in
English Phonology. Ph.D. thesis, Indiana University.
Michael Kenstowicz. 1994. Phonology in Generative
Grammar. Blackwell.
George Kiraz and Bernd M¨obius. 1998. Multilingual
syllabification using weighted finite-state transducers.
In Proceedings of the 3rd Workshop on Speech Synthe-
sis.
Brigitte Krenn. 1997. Tagging syllables. In Proceedings
ofEurospeech, pages 991–994.
Yannick Marchand and Robert Damper. 2007. Can syl-
labification improve pronunciation by analogy of En-
glish? Natural Language Engineering, 13(1):1–24.
Yannick Marchand, Connie Adsett, and Robert Damper.
2007. Automatic syllabification in English: A com-
parison of different algorithms. Language and Speech.
To appear.
Karin M¨uller, Bernd M¨obius, and Detlef Prescher. 2000.
Inducing probabilistic syllable classes using multivari-
ate clustering. In Prcoeedings of the 38th meeting of
the ACL.
Karin M¨uller. 2001. Automatic detection of syllable
boundaries combining the advantages of treebank and
bracketed corpora training. Proceedings on the 39Th
Meeting of the ACL.
Karin M¨uller. 2002. Probabilistic context-free grammars
for phonology. Proceedings of the 6th Workshop of the
ACL Special Interest Group in Computational Phonol-
ogy (SIGPHON), pages 80–90.
Karin M¨uller. 2006. Improving syllabification mod-
els with phonotactic knowledge. Proceedings of the
Eighth Meeting of the ACL Special Interest Group on
Computational Phonology At HLT-NAACL.
Steve Pearson, Roland Kuhn, Steven Fincke, and Nick
Kibre. 2000. Automatic methods for lexical stress as-
signment and syllabification. In Proceedings of the 6th
International Conference on Spoken Language Pro-
cessing (ICSLP).
Helmut Schmid, Bernd M¨obius, and Julia Weidenkaff.
2007. Tagging syllable boundaries with joint N-gram
models. In Proceedings ofInterspeech.
Elisabeth Selkirk. 1984. On the major class features and
syllable theory. In Language Sound Structure. MIT
Press.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. Proceedings of the 21st International
Conference on Machine Learning (ICML).
Antal van den Bosch. 1997. Learning to pronounce
written words: a study in inductive language learning.
Ph.D. thesis, Universiteit Maastricht.
</reference>
<page confidence="0.999278">
316
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.453392">
<title confidence="0.984257">On the Syllabification of Phonemes</title>
<affiliation confidence="0.968829">of Computing Science Research University of Alberta One Microsoft Way</affiliation>
<address confidence="0.985461">Edmonton, AB, T6G 2E8, Canada Redmond, WA,</address>
<email confidence="0.9999">colinc@microsoft.com</email>
<abstract confidence="0.971462611111111">Syllables play an important role in speech synthesis and recognition. We present several different approaches to the syllabification of phonemes. We investigate approaches based on linguistic theories of syllabification, as well as a discriminative learning technique that combines Support Vector Machine and Hidden Markov Model technologies. Our experiments on English, Dutch and German demonstrate that our transparent implementation of the sonority sequencing principle is more accurate than previous implementations, and that our language-independent SVM-based approach advances the current state-of-the-art, achieving word accuracy of over 98% in English and 99% in German and Dutch.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yasemin Altun</author>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
</authors>
<title>Hidden markov support vector machines.</title>
<date>2003</date>
<booktitle>Proceedings of the 20Th International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="15454" citStr="Altun et al., 2003" startWordPosition="2416" endWordPosition="2420">HMM If annotated data is available, a classifier can be trained to predict the syllable breaks. A Support Vector Machine (SVM) is a discriminative supervised learning technique that allows for a rich feature representation of the input space. In principle, we could use a multi-class SVM to classify each phoneme according to its position in a syllable on the basis of a set of features. However, a traditional SVM would treat each phoneme in a word as an independent instance, preventing us from considering interactions between labels. In order to overcome this shortcoming, we employ an SVM-HMM1 (Altun et al., 2003), an instance of the Structured SVM formalism (Tsochantaridis et al., 2004) that has been specialized for sequence tagging. When training a structured SVM, each training instance xi is paired with its label yi, drawn from the set of possible labels, Yi. In our case, the training instances xi are words, represented as sequences of phonemes, and their labels yi are syllabifications, represented as sequences of onset/nucleus/coda tags. For each training example, a feature vector Ψ(x, y) represents the relationship between the example and a candidate tag sequence. The SVM finds a weight vector w, </context>
</contexts>
<marker>Altun, Tsochantaridis, Hofmann, 2003</marker>
<rawString>Yasemin Altun, Ioannis Tsochantaridis, and Thomas Hofmann. 2003. Hidden markov support vector machines. Proceedings of the 20Th International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Baayen</author>
<author>R Piepenbrock</author>
<author>L Gulikers</author>
</authors>
<date>1995</date>
<booktitle>The CELEX lexical database (CD-ROM).</booktitle>
<contexts>
<context position="19639" citStr="Baayen et al., 1995" startWordPosition="3114" endWordPosition="3117">f the focus phoneme. Because the SVM-HMM is a linear classifier, we need to explicitly state any important conjunctions of features. This allows us to capture more complex patterns in the language that unigrams alone cannot describe. For example, the bigram [ps] is illegal as an onset in English, but perfectly reasonable as a coda. Experiments on the development set showed that performance peaked using all unigrams, bigrams, trigrams, and four-grams found within our context window. 6 Syllabification Experiments We developed our approach using the English portion of the CELEX lexical database (Baayen et al., 1995). CELEX provides the phonemes of a word and its correct syllabification. It does not designate the phonemes as onsets, nuclei, or codas, which is the labeling we want to predict. Fortunately, extracting the labels from a syllabified word is straightforward. All vowel phones are assigned to be nuclei; consonants preceding the nucleus in a syllable are assigned to be onsets, while consonants following the nucleus in a syllable are assigned to be codas. The results in Table 1 were obtained on a test set of 5K randomly selected words. For training the SVM-HMM, we randomly selected 30K words not 31</context>
</contexts>
<marker>Baayen, Piepenbrock, Gulikers, 1995</marker>
<rawString>R. Baayen, R. Piepenbrock, and L. Gulikers. 1995. The CELEX lexical database (CD-ROM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Bartlett</author>
<author>Grzegorz Kondrak</author>
<author>Colin Cherry</author>
</authors>
<title>Automatic syllabification with structured SVMs for letter-to-phoneme conversion.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>568--576</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1233" citStr="Bartlett et al., 2008" startWordPosition="167" endWordPosition="170">arkov Model technologies. Our experiments on English, Dutch and German demonstrate that our transparent implementation of the sonority sequencing principle is more accurate than previous implementations, and that our language-independent SVM-based approach advances the current state-of-the-art, achieving word accuracy of over 98% in English and 99% in German and Dutch. 1 Introduction Syllabification is the process of dividing a word into its constituent syllables. Although some work has been done on syllabifying orthographic forms (M¨uller et al., 2000; Bouma, 2002; Marchand and Damper, 2007; Bartlett et al., 2008), syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes. Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries (Blevins, 1995). Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition (Kiraz and M¨obius, 1998; Pearson et al., 2000). The pronunciation of a given phoneme tends to vary depending on its location within a syllable. While actual implementations vary, text-tospeech (</context>
</contexts>
<marker>Bartlett, Kondrak, Cherry, 2008</marker>
<rawString>Susan Bartlett, Grzegorz Kondrak, and Colin Cherry. 2008. Automatic syllabification with structured SVMs for letter-to-phoneme conversion. In Proceedings of ACL-08: HLT, pages 568–576, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Bartlett</author>
</authors>
<title>Discriminative approach to automatic syllabification.</title>
<date>2007</date>
<tech>Master’s thesis,</tech>
<institution>Department of Computing Science, University of Alberta.</institution>
<contexts>
<context position="17684" citStr="Bartlett (2007)" startWordPosition="2791" endWordPosition="2792">sequences are added to a growing set, which constrains the quadratic optimization procedure used to find the next w. The process iterates until no new violating sequences are found, producing an approximation to the inequality over all y E Yi. A complete explanation is given by Tsochantaridis et al. (2004). Given a weight vector w, a structured SVM tags new instances x according to: argmaxy∈Y [Ψ(x, y) &apos; w] (2) The SVM-HMM gets the HMM portion of its name from its use of the HMM Viterbi algorithm to solve this argmax. 5.1 Features We investigated several tagging schemes, described in detail by Bartlett (2007). During development, we found that tagging each phoneme with its syllabic role (Krenn, 1997) works better than the simple binary distinction between syllable-final and other phonemes (van den Bosch, 1997). We also discovered that accuracy can be improved by numbering the tags. Therefore, in our tagging scheme, the single-syllable word strengths [strvrOs] would be labeled with the sequence {O1 O2 O3 N1 C1 C2 C3}. Through the use of the Viterbi algorithm, our feature vector Ψ(x, y) is naturally divided into emission and transition features. Emission features link an aspect of the input word x w</context>
</contexts>
<marker>Bartlett, 2007</marker>
<rawString>Susan Bartlett. 2007. Discriminative approach to automatic syllabification. Master’s thesis, Department of Computing Science, University of Alberta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juliette Blevins</author>
</authors>
<title>The syllable in phonological theory. In</title>
<date>1995</date>
<booktitle>The handbook of phonological theory,</booktitle>
<pages>206--244</pages>
<editor>John Goldsmith, editor,</editor>
<publisher>Blackwell.</publisher>
<contexts>
<context position="1518" citStr="Blevins, 1995" startWordPosition="211" endWordPosition="212">t, achieving word accuracy of over 98% in English and 99% in German and Dutch. 1 Introduction Syllabification is the process of dividing a word into its constituent syllables. Although some work has been done on syllabifying orthographic forms (M¨uller et al., 2000; Bouma, 2002; Marchand and Damper, 2007; Bartlett et al., 2008), syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes. Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries (Blevins, 1995). Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition (Kiraz and M¨obius, 1998; Pearson et al., 2000). The pronunciation of a given phoneme tends to vary depending on its location within a syllable. While actual implementations vary, text-tospeech (TTS) systems must have, at minimum, three components (Damper, 2001): a letter-to-phoneme (L2P) module, a prosody module, and a synthesis module. Syllabification can play a role in all three modules. Because of the productive nature of language, a dictionary look-up process for syllabi</context>
<context position="7190" citStr="Blevins, 1995" startWordPosition="1109" endWordPosition="1110">g we should extend a syllable’s onset at the expense of the preceding syllable’s coda whenever it is legal to do so (Kahn, 1976). For example, the principle gives preference to [a-skju] and [vIn-tIt] over their alternatives. 3 Previous Computational Approaches Unlike tasks such as part of speech tagging or syntactic parsing, syllabification does not involve structural ambiguity. It is generally believed that syllable structure is usually predictable in a language provided that the rules have access to all conditioning factors: stress, morphological boundaries, part of speech, etymology, etc. (Blevins, 1995). However, in speech applications, the phonemic transcription of a word is often the only linguistic information available to the system. This is the common assumption underlying a number of computational approaches that have been proposed for the syllabification of phonemes. Daelemans and van den Bosch (1992) present one of the earliest systems on automatic syllabification: a neural network-based implementation for Dutch. Daelemans et al. (1997) also explore the application of exemplar-based generalization (EBG), sometimes called instance-based learning. EBG generally performs a simple databa</context>
</contexts>
<marker>Blevins, 1995</marker>
<rawString>Juliette Blevins. 1995. The syllable in phonological theory. In John Goldsmith, editor, The handbook of phonological theory, pages 206–244. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gosse Bouma</author>
</authors>
<title>Finite state methods for hyphenation.</title>
<date>2002</date>
<journal>Natural Language Engineering,</journal>
<pages>1--1</pages>
<contexts>
<context position="1182" citStr="Bouma, 2002" startWordPosition="161" endWordPosition="162">ines Support Vector Machine and Hidden Markov Model technologies. Our experiments on English, Dutch and German demonstrate that our transparent implementation of the sonority sequencing principle is more accurate than previous implementations, and that our language-independent SVM-based approach advances the current state-of-the-art, achieving word accuracy of over 98% in English and 99% in German and Dutch. 1 Introduction Syllabification is the process of dividing a word into its constituent syllables. Although some work has been done on syllabifying orthographic forms (M¨uller et al., 2000; Bouma, 2002; Marchand and Damper, 2007; Bartlett et al., 2008), syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes. Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries (Blevins, 1995). Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition (Kiraz and M¨obius, 1998; Pearson et al., 2000). The pronunciation of a given phoneme tends to vary depending on its location within a syllable.</context>
</contexts>
<marker>Bouma, 2002</marker>
<rawString>Gosse Bouma. 2002. Finite state methods for hyphenation. Natural Language Engineering, 1:1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Crystal</author>
</authors>
<title>A dictionary of linguistics and phonetics.</title>
<date>2003</date>
<publisher>Blackwell.</publisher>
<contexts>
<context position="5646" citStr="Crystal, 2003" startWordPosition="862" endWordPosition="863">in and Frauenfelder, 2001). Thus, a word like admit [admIt] must be syllabified [admIt] because [dm] never appears word-initially or word-finally in English. A shortcoming of the legality principle is that it does not always imply a unique syllabification. For example, in a word like askew [askju], the principle does not rule out any of [a-skju], [as-kju], or [ask-ju], as all three employ legal onsets and codas. The Sonority Sequencing Principle (SSP) provides a stricter definition of legality. The sonority of a sound is its inherent loudness, holding factors like pitch and duration constant (Crystal, 2003). Low vowels like [a], the most sonorous sounds, are high on the sonority scale, while plosive consonants like [t] are at the bottom. When syllabifying a word, SSP states that sonority should increase from the first phoneme of the onset to the syllable’s nucleus, and then fall off to the coda (Selkirk, 1984). Consequently, in a word like vintage [vIntIt], we can rule out a syllabification like [vI-ntId3] because [n] is more sonorant than [t]. However, SSP does not tell us whether to prefer [vIn-tIt] or [vInt-It]. Moreover, when syllabifying a word like vintner [vIntnar], the theory allows both</context>
</contexts>
<marker>Crystal, 2003</marker>
<rawString>David Crystal. 2003. A dictionary of linguistics and phonetics. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<title>Generalization performance of backpropagaion learning on a syllabification task.</title>
<date>1992</date>
<booktitle>In Proceedings of the 3rd Twente Workshop on Language Technology,</booktitle>
<pages>27--38</pages>
<marker>Daelemans, van den Bosch, 1992</marker>
<rawString>Walter Daelemans and Antal van den Bosch. 1992. Generalization performance of backpropagaion learning on a syllabification task. In Proceedings of the 3rd Twente Workshop on Language Technology, pages 27– 38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
<author>Ton Weijters</author>
</authors>
<title>IGTree: Using trees for compression and classification in lazy learning algorithms.</title>
<date>1997</date>
<journal>Artificial Intelligence Review,</journal>
<pages>407--423</pages>
<marker>Daelemans, van den Bosch, Weijters, 1997</marker>
<rawString>Walter Daelemans, Antal van den Bosch, and Ton Weijters. 1997. IGTree: Using trees for compression and classification in lazy learning algorithms. Artificial Intelligence Review, pages 407–423.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Damper</author>
</authors>
<title>Learning about speech from data: Beyond NETtalk.</title>
<date>2001</date>
<booktitle>In Data-Driven Techniques in Speech Synthesis,</booktitle>
<pages>1--25</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1900" citStr="Damper, 2001" startWordPosition="268" endWordPosition="269">tities that can only be composed of strings of phonemes. Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries (Blevins, 1995). Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition (Kiraz and M¨obius, 1998; Pearson et al., 2000). The pronunciation of a given phoneme tends to vary depending on its location within a syllable. While actual implementations vary, text-tospeech (TTS) systems must have, at minimum, three components (Damper, 2001): a letter-to-phoneme (L2P) module, a prosody module, and a synthesis module. Syllabification can play a role in all three modules. Because of the productive nature of language, a dictionary look-up process for syllabification is inadequate. No dictionary can ever contain all possible words in a language. For this reason, it is necessary to develop systems that can automatically syllabify out-of-dictionary words. In this paper, we advance the state-of-the-art in both categorical (non-statistical) and supervised syllabification. We outline three categorical approaches based on common linguistic</context>
</contexts>
<marker>Damper, 2001</marker>
<rawString>Robert Damper. 2001. Learning about speech from data: Beyond NETtalk. In Data-Driven Techniques in Speech Synthesis, pages 1–25. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vera Demberg</author>
</authors>
<title>Letter-to-phoneme conversion for a German text-to-speech system. Master’s thesis,</title>
<date>2006</date>
<institution>University of Stuttgart.</institution>
<contexts>
<context position="8394" citStr="Demberg (2006)" startWordPosition="1288" endWordPosition="1289">ple database look-up to syllabify a test pattern, choosing the most common syllabification. In cases where the test pattern is not found in the database, the most similar pattern is used to syllabify the test pattern. Hidden Markov Models (HMMs) are another popular approach to syllabification. Krenn (1997) introduces the idea of treating syllabification as a 309 tagging task. Working from a list of syllabified phoneme strings, she automatically generates tags for each phone. She uses a second-order HMM to predict sequences of tags; syllable boundaries can be trivially recovered from the tags. Demberg (2006) applies a fourth-order HMM to the syllabification task, as a component of a larger German text-tospeech system. Schmid et al. (2007) improve on Demberg’s results by applying a fifth-order HMM that conditions on both the previous tags and their corresponding phonemes. Kiraz and M¨obius (1998) present a weighted finite-state-based approach to syllabification. Their language-independent method builds an automaton for each of onsets, nuclei, and codas, by counting occurrences in training data. These automatons are then composed into a transducer accepting sequences of one or more syllables. They </context>
<context position="27256" citStr="Demberg (2006)" startWordPosition="4299" endWordPosition="4300">n German CELEX demonstrates the quality of our approach. The numbers that follow refer to 10-fold cross-validation on the entire lexicon (over 320K entries) unless noted otherwise. Krenn (1997) obtains tag accuracy of 98.34%, compared to our system’s tag accuracy of 99.97% when trained on 250K words. With a hand-crafted grammar, M¨uller (2002) achieves 96.88% word accuracy on CELEX-derived syllabifications, with a training corpus of two million tokens. Without a handcrafted grammar, she reports 90.45% word accuracy (M¨uller, 2006). Applying a standard smoothing algorithm and fourth-order HMM, Demberg (2006) scores 98.47% word accuracy. A fifth-order joint N-gram model of Schmid et al. (2007) achieves 99.85% word accuracy with about 278K training points. However, unlike generative approaches, our 314 Method English German SONORITY 97.0 94.2 SVM-HMM 99.9 99.4 Categorical Parser 94.9 92.7 Maximum Likelihood 98.1 97.4 Table 4: Word accuracy on the datasets of Goldwater and Johnson (2005). SVM-HMM can condition each emission on large portions of the input using only a first-order Markov model, which implies much faster syllabification performance. 6.4 Direct Comparison with an MLE approach The result</context>
</contexts>
<marker>Demberg, 2006</marker>
<rawString>Vera Demberg. 2006. Letter-to-phoneme conversion for a German text-to-speech system. Master’s thesis, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Fisher</author>
</authors>
<title>Tsylb syllabification package. ftp://jaguar.ncsl.nist.gov/pub/tsylb2-1.1.tar.Z. Last accessed 31</title>
<date>1996</date>
<contexts>
<context position="20535" citStr="Fisher, 1996" startWordPosition="3262" endWordPosition="3263">gned to be nuclei; consonants preceding the nucleus in a syllable are assigned to be onsets, while consonants following the nucleus in a syllable are assigned to be codas. The results in Table 1 were obtained on a test set of 5K randomly selected words. For training the SVM-HMM, we randomly selected 30K words not 312 appearing in the test set, while 6K training examples were held out for development testing. We report the performance in terms of word accuracy (entire words syllabified correctly). Among the categorical approaches, SONORITY clearly outperforms not only LEGALITY, but also tsylb (Fisher, 1996), an implementation of the complex algorithm of Kahn (1976), which makes use of lists of legal English onsets. Overall, our SVM-based approach is a clear winner. The results of our discriminative method compares favorably with the results of competing approaches on English CELEX. Since there are no standard train-test splits for syllabification, the comparison is necessarily indirect, but note that our training set is substantially smaller. For her language-independent PCFG-based approach, M¨uller (2006) reports 92.64% word accuracy on the set of 64K examples from CELEX using 10-fold cross-val</context>
</contexts>
<marker>Fisher, 1996</marker>
<rawString>William Fisher. 1996. Tsylb syllabification package. ftp://jaguar.ncsl.nist.gov/pub/tsylb2-1.1.tar.Z. Last accessed 31 March 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Goldwater</author>
<author>Mark Johnson</author>
</authors>
<title>Representational bias in usupervised learning of syllable structure.</title>
<date>2005</date>
<booktitle>In Prcoeedings of the 9th Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>112--119</pages>
<contexts>
<context position="10245" citStr="Goldwater and Johnson (2005)" startWordPosition="1567" endWordPosition="1570">based methods. M¨uller (2001) presents a hybrid of a categorical and data-driven approach. First, she manually constructs a context-free grammar of possible syllables. This grammar is then made probabilistic using counts obtained from training data. M¨uller (2006) attempts to make her method language-independent. Rather than hand-crafting her context-free grammar, she automatically generates all possible onsets, nuclei, and codas, based on the phonemes existing in the language. The results are somewhat lower than in (M¨uller, 2001), but the approach can be more easily ported across languages. Goldwater and Johnson (2005) also explore using EM to learn the structure of English and German phonemes in an unsupervised setting, following M¨uller in modeling syllable structure with PCFGs. They initialize their parameters using a deterministic parser implementing the sonority principle and estimate the parameters for their maximum likelihood approach using EM. Marchand et al. (2007) apply their Syllabification by Analogy (SbA) technique, originally developed for orthographic forms, to the pronunciation domain. For each input word, SbA finds the most similar substrings in a lexicon of syllabified phoneme strings and </context>
<context position="27640" citStr="Goldwater and Johnson (2005)" startWordPosition="4355" endWordPosition="4358">uracy on CELEX-derived syllabifications, with a training corpus of two million tokens. Without a handcrafted grammar, she reports 90.45% word accuracy (M¨uller, 2006). Applying a standard smoothing algorithm and fourth-order HMM, Demberg (2006) scores 98.47% word accuracy. A fifth-order joint N-gram model of Schmid et al. (2007) achieves 99.85% word accuracy with about 278K training points. However, unlike generative approaches, our 314 Method English German SONORITY 97.0 94.2 SVM-HMM 99.9 99.4 Categorical Parser 94.9 92.7 Maximum Likelihood 98.1 97.4 Table 4: Word accuracy on the datasets of Goldwater and Johnson (2005). SVM-HMM can condition each emission on large portions of the input using only a first-order Markov model, which implies much faster syllabification performance. 6.4 Direct Comparison with an MLE approach The results of the competitive approaches that have been quoted so far (with the exception of tsylb) are not directly comparable, because neither the respective implementations, nor the actual train-test splits are publicly available. However, we managed to obtain the English and German data sets used by Goldwater and Johnson (2005) in their study, which focused primarily on unsupervised syl</context>
<context position="29019" citStr="Goldwater and Johnson (2005)" startWordPosition="4566" endWordPosition="4569">and a test set of 10K tokens. The running text was taken from the Penn WSJ and ECI corpora, and the syllabified phonemic transcriptions were obtained from CELEX. Table 4 compares our experimental results with their reported results obtained with: (a) supervised Maximum Likelihood training procedures, and (b) a Categorical Syllable Parser implementing the principles of sonority sequencing and onset maximization without Kenstowicz’s (1994) onset constraints. The accuracy figures in Table 4 are noticeably higher than in Table 1. This stems from fundamental differences in the experimental set-up; Goldwater and Johnson (2005) test on tokens as found in text, therefore many frequent short words are duplicated. Furthermore, some words occur during both training and testing, to the benefit of the supervised systems (SVM-HMM and Maximum Likelihood). Nevertheless, the results confirm the level of improvement obtained by both our categorical and supervised approaches. 7 Conclusion We have presented several different approaches to the syllabification of phonemes. The results of our linguistically-motivated algorithms, show that it is possible to achieve adequate syllabification word accuracy in English with no little or </context>
</contexts>
<marker>Goldwater, Johnson, 2005</marker>
<rawString>Sharon Goldwater and Mark Johnson. 2005. Representational bias in usupervised learning of syllable structure. In Prcoeedings of the 9th Conference on Computational Natural Language Learning (CoNLL), pages 112–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeremy Goslin</author>
<author>Ulrich Frauenfelder</author>
</authors>
<title>A comparison of theoretical and human syllabification. Language and Speech,</title>
<date>2001</date>
<pages>44--409</pages>
<contexts>
<context position="5058" citStr="Goslin and Frauenfelder, 2001" startWordPosition="762" endWordPosition="765">onality of onsets, admissibility of codas, and the allowed complexity of the syllable constituents. For example, onsets are required in German, while Spanish prohibits complex codas. There are a number of theories of syllabification; we present three of the most prevalent. The Legality Principle constrains the segments that can begin and end syllables to those that appear at the beginning and end of words. In other words, a syllable is not allowed to begin with a consonant cluster that is not found at the beginning of some word, or end with a cluster that is not found at the end of some word (Goslin and Frauenfelder, 2001). Thus, a word like admit [admIt] must be syllabified [admIt] because [dm] never appears word-initially or word-finally in English. A shortcoming of the legality principle is that it does not always imply a unique syllabification. For example, in a word like askew [askju], the principle does not rule out any of [a-skju], [as-kju], or [ask-ju], as all three employ legal onsets and codas. The Sonority Sequencing Principle (SSP) provides a stricter definition of legality. The sonority of a sound is its inherent loudness, holding factors like pitch and duration constant (Crystal, 2003). Low vowels</context>
</contexts>
<marker>Goslin, Frauenfelder, 2001</marker>
<rawString>Jeremy Goslin and Ulrich Frauenfelder. 2001. A comparison of theoretical and human syllabification. Language and Speech, 44:409–436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carmen Jany</author>
<author>Matthew Gordon</author>
<author>Carlos M Nash</author>
<author>Nobutaka Takara</author>
</authors>
<title>How universal is the sonority hierarchy? A cross-linguistic study.</title>
<date>2007</date>
<booktitle>In 16th International Congress of Phonetic Sciences,</booktitle>
<pages>1401--1404</pages>
<contexts>
<context position="13653" citStr="Jany et al., 2007" startWordPosition="2115" endWordPosition="2118">p end if end loop Insert syllable boundaries before onsets Figure 1: Pseudo-code for syllabifying a string of phonemes. consonants. SONORITY requires no training data because it implements a sound linguistic theory. However, an existing development set for a given language can help with defining and validating additional language-specific constraints. Several sonority scales of varying complexity have been proposed. For example, Selkirk (1984) specifies a hierarchy of eleven distinct levels. We adopt a minimalistic scale shown in Figure 2. which avoids most of the disputed sonority contrasts (Jany et al., 2007). We set the sonority distance parameter to 2, which ensures that adjacent consonants in the onset differ by at least two levels of the scale. For example, [pr] is an acceptable onset because it is composed of an obstruent and a liquid, but [pn] is not, because nasals directly follow obstruents on our sonority scale. In addition, we incorporate several Englishspecific constraints listed by Kenstowicz (1994, pages 257–258). The constraints, or filters, prohibit complex onsets containing: (i) two labials (e.g., [pw], [bw], [fw], [vw]), (ii) a non-strident coronal followed by a lateral (e.g., [tl</context>
</contexts>
<marker>Jany, Gordon, Nash, Takara, 2007</marker>
<rawString>Carmen Jany, Matthew Gordon, Carlos M Nash, and Nobutaka Takara. 2007. How universal is the sonority hierarchy? A cross-linguistic study. In 16th International Congress of Phonetic Sciences, pages 1401– 1404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Kahn</author>
</authors>
<title>Syllable-based generalizations in English Phonology.</title>
<date>1976</date>
<tech>Ph.D. thesis,</tech>
<institution>Indiana University.</institution>
<contexts>
<context position="6704" citStr="Kahn, 1976" startWordPosition="1039" endWordPosition="1040">However, SSP does not tell us whether to prefer [vIn-tIt] or [vInt-It]. Moreover, when syllabifying a word like vintner [vIntnar], the theory allows both [vIn-tnar] and [vIntnar], even though [tn] is an illegal onset in English. Both the Legality Principle and SSP tell us which onsets and codas are permitted in legal syllables, and which are not. However, neither theory gives us any guidance when deciding between legal onsets. The Maximal Onset Principle addresses this by stating we should extend a syllable’s onset at the expense of the preceding syllable’s coda whenever it is legal to do so (Kahn, 1976). For example, the principle gives preference to [a-skju] and [vIn-tIt] over their alternatives. 3 Previous Computational Approaches Unlike tasks such as part of speech tagging or syntactic parsing, syllabification does not involve structural ambiguity. It is generally believed that syllable structure is usually predictable in a language provided that the rules have access to all conditioning factors: stress, morphological boundaries, part of speech, etymology, etc. (Blevins, 1995). However, in speech applications, the phonemic transcription of a word is often the only linguistic information a</context>
<context position="20594" citStr="Kahn (1976)" startWordPosition="3271" endWordPosition="3272">able are assigned to be onsets, while consonants following the nucleus in a syllable are assigned to be codas. The results in Table 1 were obtained on a test set of 5K randomly selected words. For training the SVM-HMM, we randomly selected 30K words not 312 appearing in the test set, while 6K training examples were held out for development testing. We report the performance in terms of word accuracy (entire words syllabified correctly). Among the categorical approaches, SONORITY clearly outperforms not only LEGALITY, but also tsylb (Fisher, 1996), an implementation of the complex algorithm of Kahn (1976), which makes use of lists of legal English onsets. Overall, our SVM-based approach is a clear winner. The results of our discriminative method compares favorably with the results of competing approaches on English CELEX. Since there are no standard train-test splits for syllabification, the comparison is necessarily indirect, but note that our training set is substantially smaller. For her language-independent PCFG-based approach, M¨uller (2006) reports 92.64% word accuracy on the set of 64K examples from CELEX using 10-fold cross-validation. The Learned EBG approach of van den Bosch (1997) a</context>
</contexts>
<marker>Kahn, 1976</marker>
<rawString>Daniel Kahn. 1976. Syllable-based generalizations in English Phonology. Ph.D. thesis, Indiana University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kenstowicz</author>
</authors>
<date>1994</date>
<booktitle>Phonology in Generative Grammar.</booktitle>
<publisher>Blackwell.</publisher>
<contexts>
<context position="14062" citStr="Kenstowicz (1994" startWordPosition="2185" endWordPosition="2186">roposed. For example, Selkirk (1984) specifies a hierarchy of eleven distinct levels. We adopt a minimalistic scale shown in Figure 2. which avoids most of the disputed sonority contrasts (Jany et al., 2007). We set the sonority distance parameter to 2, which ensures that adjacent consonants in the onset differ by at least two levels of the scale. For example, [pr] is an acceptable onset because it is composed of an obstruent and a liquid, but [pn] is not, because nasals directly follow obstruents on our sonority scale. In addition, we incorporate several Englishspecific constraints listed by Kenstowicz (1994, pages 257–258). The constraints, or filters, prohibit complex onsets containing: (i) two labials (e.g., [pw], [bw], [fw], [vw]), (ii) a non-strident coronal followed by a lateral (e.g., [tl], [dl], [0l]) (iii) a voiced fricative (e.g., [vr], [zw], except [vj]), (iv) a palatal consonant (e.g., [ fl], [#r], except [ fr]). Sound Examples Level Vowels u,a, ... 4 Glides w, j, .. . 3 Liquids l, r, ... 2 Nasals m,rl, ... 1 Obstruents g,0, ... 0 Figure 2: The sonority scale employed by SONORITY. A special provision allows for prepending the phoneme [s] to onsets beginning with a voiceless plosive. T</context>
<context position="26233" citStr="Kenstowicz (1994)" startWordPosition="4133" endWordPosition="4135">ing 250K words. The results are presented in Table 3. While our SVM-HMM approach is entirely language independent, the same cannot be said about other methods. The maximal onset principle appears to hold much more strongly for English than for German and Dutch (e.g., patron: [pe-tran] vs. [pat-ron]). LEGALITY and SONORITY also appear to be less effective, possibly because of greater tendency for syllabifications to match morphological boundaries (e.g., English exclusive: [ik-sklu-siv] vs. Dutch exclusief [rks-kly-zif]). SONORITY is further affected by our decision to employ the constraints of Kenstowicz (1994), although they clearly pertain to English. We expect that adapting them to specific languages would bring the results closer to the level of the English experiments. Although our SVM system is tuned using an English development set, the results on both German and Dutch are excellent. We could not find any quantitative data for comparisons on Dutch, but the comparison with the previously reported results on German CELEX demonstrates the quality of our approach. The numbers that follow refer to 10-fold cross-validation on the entire lexicon (over 320K entries) unless noted otherwise. Krenn (199</context>
</contexts>
<marker>Kenstowicz, 1994</marker>
<rawString>Michael Kenstowicz. 1994. Phonology in Generative Grammar. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Kiraz</author>
<author>Bernd M¨obius</author>
</authors>
<title>Multilingual syllabification using weighted finite-state transducers.</title>
<date>1998</date>
<booktitle>In Proceedings of the 3rd Workshop on Speech Synthesis.</booktitle>
<marker>Kiraz, M¨obius, 1998</marker>
<rawString>George Kiraz and Bernd M¨obius. 1998. Multilingual syllabification using weighted finite-state transducers. In Proceedings of the 3rd Workshop on Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
</authors>
<title>Tagging syllables.</title>
<date>1997</date>
<booktitle>In Proceedings ofEurospeech,</booktitle>
<pages>991--994</pages>
<contexts>
<context position="8087" citStr="Krenn (1997)" startWordPosition="1241" endWordPosition="1242">s and van den Bosch (1992) present one of the earliest systems on automatic syllabification: a neural network-based implementation for Dutch. Daelemans et al. (1997) also explore the application of exemplar-based generalization (EBG), sometimes called instance-based learning. EBG generally performs a simple database look-up to syllabify a test pattern, choosing the most common syllabification. In cases where the test pattern is not found in the database, the most similar pattern is used to syllabify the test pattern. Hidden Markov Models (HMMs) are another popular approach to syllabification. Krenn (1997) introduces the idea of treating syllabification as a 309 tagging task. Working from a list of syllabified phoneme strings, she automatically generates tags for each phone. She uses a second-order HMM to predict sequences of tags; syllable boundaries can be trivially recovered from the tags. Demberg (2006) applies a fourth-order HMM to the syllabification task, as a component of a larger German text-tospeech system. Schmid et al. (2007) improve on Demberg’s results by applying a fifth-order HMM that conditions on both the previous tags and their corresponding phonemes. Kiraz and M¨obius (1998)</context>
<context position="17777" citStr="Krenn, 1997" startWordPosition="2806" endWordPosition="2807"> to find the next w. The process iterates until no new violating sequences are found, producing an approximation to the inequality over all y E Yi. A complete explanation is given by Tsochantaridis et al. (2004). Given a weight vector w, a structured SVM tags new instances x according to: argmaxy∈Y [Ψ(x, y) &apos; w] (2) The SVM-HMM gets the HMM portion of its name from its use of the HMM Viterbi algorithm to solve this argmax. 5.1 Features We investigated several tagging schemes, described in detail by Bartlett (2007). During development, we found that tagging each phoneme with its syllabic role (Krenn, 1997) works better than the simple binary distinction between syllable-final and other phonemes (van den Bosch, 1997). We also discovered that accuracy can be improved by numbering the tags. Therefore, in our tagging scheme, the single-syllable word strengths [strvrOs] would be labeled with the sequence {O1 O2 O3 N1 C1 C2 C3}. Through the use of the Viterbi algorithm, our feature vector Ψ(x, y) is naturally divided into emission and transition features. Emission features link an aspect of the input word x with a single tag in the Method English MAXONSET 61.38 LEGALITY 93.16 SONORITY 95.00 SVM-HMM 9</context>
<context position="26835" citStr="Krenn (1997)" startWordPosition="4235" endWordPosition="4236">icz (1994), although they clearly pertain to English. We expect that adapting them to specific languages would bring the results closer to the level of the English experiments. Although our SVM system is tuned using an English development set, the results on both German and Dutch are excellent. We could not find any quantitative data for comparisons on Dutch, but the comparison with the previously reported results on German CELEX demonstrates the quality of our approach. The numbers that follow refer to 10-fold cross-validation on the entire lexicon (over 320K entries) unless noted otherwise. Krenn (1997) obtains tag accuracy of 98.34%, compared to our system’s tag accuracy of 99.97% when trained on 250K words. With a hand-crafted grammar, M¨uller (2002) achieves 96.88% word accuracy on CELEX-derived syllabifications, with a training corpus of two million tokens. Without a handcrafted grammar, she reports 90.45% word accuracy (M¨uller, 2006). Applying a standard smoothing algorithm and fourth-order HMM, Demberg (2006) scores 98.47% word accuracy. A fifth-order joint N-gram model of Schmid et al. (2007) achieves 99.85% word accuracy with about 278K training points. However, unlike generative ap</context>
</contexts>
<marker>Krenn, 1997</marker>
<rawString>Brigitte Krenn. 1997. Tagging syllables. In Proceedings ofEurospeech, pages 991–994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Marchand</author>
<author>Robert Damper</author>
</authors>
<title>Can syllabification improve pronunciation by analogy of English?</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>1</issue>
<contexts>
<context position="1209" citStr="Marchand and Damper, 2007" startWordPosition="163" endWordPosition="166">Vector Machine and Hidden Markov Model technologies. Our experiments on English, Dutch and German demonstrate that our transparent implementation of the sonority sequencing principle is more accurate than previous implementations, and that our language-independent SVM-based approach advances the current state-of-the-art, achieving word accuracy of over 98% in English and 99% in German and Dutch. 1 Introduction Syllabification is the process of dividing a word into its constituent syllables. Although some work has been done on syllabifying orthographic forms (M¨uller et al., 2000; Bouma, 2002; Marchand and Damper, 2007; Bartlett et al., 2008), syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes. Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries (Blevins, 1995). Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition (Kiraz and M¨obius, 1998; Pearson et al., 2000). The pronunciation of a given phoneme tends to vary depending on its location within a syllable. While actual implementatio</context>
</contexts>
<marker>Marchand, Damper, 2007</marker>
<rawString>Yannick Marchand and Robert Damper. 2007. Can syllabification improve pronunciation by analogy of English? Natural Language Engineering, 13(1):1–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannick Marchand</author>
<author>Connie Adsett</author>
<author>Robert Damper</author>
</authors>
<title>Automatic syllabification in English: A comparison of different algorithms. Language and Speech.</title>
<date>2007</date>
<note>To appear.</note>
<contexts>
<context position="10607" citStr="Marchand et al. (2007)" startWordPosition="1622" endWordPosition="1625">he automatically generates all possible onsets, nuclei, and codas, based on the phonemes existing in the language. The results are somewhat lower than in (M¨uller, 2001), but the approach can be more easily ported across languages. Goldwater and Johnson (2005) also explore using EM to learn the structure of English and German phonemes in an unsupervised setting, following M¨uller in modeling syllable structure with PCFGs. They initialize their parameters using a deterministic parser implementing the sonority principle and estimate the parameters for their maximum likelihood approach using EM. Marchand et al. (2007) apply their Syllabification by Analogy (SbA) technique, originally developed for orthographic forms, to the pronunciation domain. For each input word, SbA finds the most similar substrings in a lexicon of syllabified phoneme strings and then applies the dictionary syllabifications to the input word. Their survey paper also includes comparisons with a method broadly based on the legality principle. The authors find their legalitybased implementation fares significantly worse than SbA. 4 Categorical Approaches Categorical approaches to syllabification are appealing because they are efficient an</context>
<context position="22729" citStr="Marchand et al. (2007)" startWordPosition="3597" endWordPosition="3600">ORITY. The performance difference comes mainly from the SVM’s ability to handle many of these morphological exceptions. The SVM generates the correct syllabification of northeast [nor0- ist], even though an onset of [0] is perfectly legal. On the other hand, the SVM sometimes overgeneralizes, as in the last example in Table 4. SVM-HMM SONORITY tu-Tek tu-Tek toothache pae-sports pae-sports passports nor&amp;-ist nor-Tist northeast dIs-plizd dI-splizd displeased dIs-koz dI-skoz discos Figure 4: Examples of syllabification errors. (Correct syllabifications are shown in bold.) 6.2 The NETtalk Dataset Marchand et al. (2007) report a disappointing word accuracy of 54.14% for their legality-based implementation, which does not accord with the results of our categorical approaches on English CELEX. Consequently, we also apply our methods to the dataset they used for their experiments: the NETtalk dictionary. NETtalk contains 20K English words; in the experiments reported here, we use 13K training examples and 7K test words. As is apparent from Table 2, our performance degrades significantly when switching to NETtalk. The steep decline found in the categorical methods is particularly notable, and indicates significa</context>
<context position="25092" citStr="Marchand et al. (2007)" startWordPosition="3951" endWordPosition="3954">difficult to capture with any kind of principled approach. Thus, we argue that low performance on NETtalk indicate inconsistent syllabifications within that dataset, rather than any actual deficiency of the methods. NETtalk CELEX Ùaes-taIz Ùae-staIz chastise rEz-Id-ans rE-zI-dans residence dI-strOI dI-strOI destroy fo-tAn fo-tAn photon Ar-pEt-io Ar-pE-ti-o arpeggio Der-a-baU-t DE-ra-baUt thereabout Figure 5: Examples of CELEX and NETtalk syllabifications. NETtalk’s variable syllabification practices notwithstanding, the SVM-HMM approach still outperforms the previous benchmark on the dataset. Marchand et al. (2007) report 88.53% word accuracy for their SbA technique using leave-one-out testing on the entire NETtalk set (20K words). With fewer training examples, we reduce the error rate by almost 40%. 6.3 Other Languages We performed experiments on German and Dutch, the two other languages available in the CELEX lexical database. The German and Dutch lexicons of CELEX are larger than the English lexicon. For both languages, we selected a 25K test set, and two different training sets, one containing 50K words and the other containing 250K words. The results are presented in Table 3. While our SVM-HMM appr</context>
</contexts>
<marker>Marchand, Adsett, Damper, 2007</marker>
<rawString>Yannick Marchand, Connie Adsett, and Robert Damper. 2007. Automatic syllabification in English: A comparison of different algorithms. Language and Speech. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin M¨uller</author>
<author>Bernd M¨obius</author>
<author>Detlef Prescher</author>
</authors>
<title>Inducing probabilistic syllable classes using multivariate clustering.</title>
<date>2000</date>
<booktitle>In Prcoeedings of the 38th meeting of the ACL.</booktitle>
<marker>M¨uller, M¨obius, Prescher, 2000</marker>
<rawString>Karin M¨uller, Bernd M¨obius, and Detlef Prescher. 2000. Inducing probabilistic syllable classes using multivariate clustering. In Prcoeedings of the 38th meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin M¨uller</author>
</authors>
<title>Automatic detection of syllable boundaries combining the advantages of treebank and bracketed corpora training.</title>
<date>2001</date>
<booktitle>Proceedings on the 39Th Meeting of the ACL.</booktitle>
<marker>M¨uller, 2001</marker>
<rawString>Karin M¨uller. 2001. Automatic detection of syllable boundaries combining the advantages of treebank and bracketed corpora training. Proceedings on the 39Th Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin M¨uller</author>
</authors>
<title>Probabilistic context-free grammars for phonology.</title>
<date>2002</date>
<booktitle>Proceedings of the 6th Workshop of the ACL Special Interest Group in Computational Phonology (SIGPHON),</booktitle>
<pages>80--90</pages>
<marker>M¨uller, 2002</marker>
<rawString>Karin M¨uller. 2002. Probabilistic context-free grammars for phonology. Proceedings of the 6th Workshop of the ACL Special Interest Group in Computational Phonology (SIGPHON), pages 80–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin M¨uller</author>
</authors>
<title>Improving syllabification models with phonotactic knowledge.</title>
<date>2006</date>
<booktitle>Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology At HLT-NAACL.</booktitle>
<marker>M¨uller, 2006</marker>
<rawString>Karin M¨uller. 2006. Improving syllabification models with phonotactic knowledge. Proceedings of the Eighth Meeting of the ACL Special Interest Group on Computational Phonology At HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve Pearson</author>
<author>Roland Kuhn</author>
<author>Steven Fincke</author>
<author>Nick Kibre</author>
</authors>
<title>Automatic methods for lexical stress assignment and syllabification.</title>
<date>2000</date>
<booktitle>In Proceedings of the 6th International Conference on Spoken Language Processing (ICSLP).</booktitle>
<contexts>
<context position="1685" citStr="Pearson et al., 2000" startWordPosition="233" endWordPosition="236">uent syllables. Although some work has been done on syllabifying orthographic forms (M¨uller et al., 2000; Bouma, 2002; Marchand and Damper, 2007; Bartlett et al., 2008), syllables are, technically speaking, phonological entities that can only be composed of strings of phonemes. Most linguists view syllables as an important unit of prosody because many phonological rules and constraints apply within syllables or at syllable boundaries (Blevins, 1995). Apart from their purely linguistic significance, syllables play an important role in speech synthesis and recognition (Kiraz and M¨obius, 1998; Pearson et al., 2000). The pronunciation of a given phoneme tends to vary depending on its location within a syllable. While actual implementations vary, text-tospeech (TTS) systems must have, at minimum, three components (Damper, 2001): a letter-to-phoneme (L2P) module, a prosody module, and a synthesis module. Syllabification can play a role in all three modules. Because of the productive nature of language, a dictionary look-up process for syllabification is inadequate. No dictionary can ever contain all possible words in a language. For this reason, it is necessary to develop systems that can automatically syl</context>
<context position="9068" citStr="Pearson et al. (2000)" startWordPosition="1388" endWordPosition="1391">sk, as a component of a larger German text-tospeech system. Schmid et al. (2007) improve on Demberg’s results by applying a fifth-order HMM that conditions on both the previous tags and their corresponding phonemes. Kiraz and M¨obius (1998) present a weighted finite-state-based approach to syllabification. Their language-independent method builds an automaton for each of onsets, nuclei, and codas, by counting occurrences in training data. These automatons are then composed into a transducer accepting sequences of one or more syllables. They do not report quantitative results for their method. Pearson et al. (2000) compare two rule-based systems (they do not elaborate on the rules employed) with a CART decision tree-based approach and a “global statistics” algorithm. The global statistics method is based on counts of consonant clusters in contexts such as word boundaries, short vowels, or long vowels. Each test word has syllable boundaries placed according to the most likely location given a cluster and its context. In experiments performed with their in-house dataset, their statistics-based method outperforms the decisiontree approach and the two rule-based methods. M¨uller (2001) presents a hybrid of </context>
</contexts>
<marker>Pearson, Kuhn, Fincke, Kibre, 2000</marker>
<rawString>Steve Pearson, Roland Kuhn, Steven Fincke, and Nick Kibre. 2000. Automatic methods for lexical stress assignment and syllabification. In Proceedings of the 6th International Conference on Spoken Language Processing (ICSLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Bernd M¨obius</author>
<author>Julia Weidenkaff</author>
</authors>
<title>Tagging syllable boundaries with joint N-gram models.</title>
<date>2007</date>
<booktitle>In Proceedings ofInterspeech.</booktitle>
<marker>Schmid, M¨obius, Weidenkaff, 2007</marker>
<rawString>Helmut Schmid, Bernd M¨obius, and Julia Weidenkaff. 2007. Tagging syllable boundaries with joint N-gram models. In Proceedings ofInterspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Selkirk</author>
</authors>
<title>On the major class features and syllable theory. In Language Sound Structure.</title>
<date>1984</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5955" citStr="Selkirk, 1984" startWordPosition="916" endWordPosition="917">iple does not rule out any of [a-skju], [as-kju], or [ask-ju], as all three employ legal onsets and codas. The Sonority Sequencing Principle (SSP) provides a stricter definition of legality. The sonority of a sound is its inherent loudness, holding factors like pitch and duration constant (Crystal, 2003). Low vowels like [a], the most sonorous sounds, are high on the sonority scale, while plosive consonants like [t] are at the bottom. When syllabifying a word, SSP states that sonority should increase from the first phoneme of the onset to the syllable’s nucleus, and then fall off to the coda (Selkirk, 1984). Consequently, in a word like vintage [vIntIt], we can rule out a syllabification like [vI-ntId3] because [n] is more sonorant than [t]. However, SSP does not tell us whether to prefer [vIn-tIt] or [vInt-It]. Moreover, when syllabifying a word like vintner [vIntnar], the theory allows both [vIn-tnar] and [vIntnar], even though [tn] is an illegal onset in English. Both the Legality Principle and SSP tell us which onsets and codas are permitted in legal syllables, and which are not. However, neither theory gives us any guidance when deciding between legal onsets. The Maximal Onset Principle add</context>
<context position="13482" citStr="Selkirk (1984)" startWordPosition="2089" endWordPosition="2090">as else onset := all consonants before next vowel coda := empty until onset is legal coda := coda plus first phoneme of onset onset := onset less first phoneme end loop end if end loop Insert syllable boundaries before onsets Figure 1: Pseudo-code for syllabifying a string of phonemes. consonants. SONORITY requires no training data because it implements a sound linguistic theory. However, an existing development set for a given language can help with defining and validating additional language-specific constraints. Several sonority scales of varying complexity have been proposed. For example, Selkirk (1984) specifies a hierarchy of eleven distinct levels. We adopt a minimalistic scale shown in Figure 2. which avoids most of the disputed sonority contrasts (Jany et al., 2007). We set the sonority distance parameter to 2, which ensures that adjacent consonants in the onset differ by at least two levels of the scale. For example, [pr] is an acceptable onset because it is composed of an obstruent and a liquid, but [pn] is not, because nasals directly follow obstruents on our sonority scale. In addition, we incorporate several Englishspecific constraints listed by Kenstowicz (1994, pages 257–258). Th</context>
</contexts>
<marker>Selkirk, 1984</marker>
<rawString>Elisabeth Selkirk. 1984. On the major class features and syllable theory. In Language Sound Structure. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>Proceedings of the 21st International Conference on Machine Learning (ICML).</booktitle>
<contexts>
<context position="15529" citStr="Tsochantaridis et al., 2004" startWordPosition="2428" endWordPosition="2431"> predict the syllable breaks. A Support Vector Machine (SVM) is a discriminative supervised learning technique that allows for a rich feature representation of the input space. In principle, we could use a multi-class SVM to classify each phoneme according to its position in a syllable on the basis of a set of features. However, a traditional SVM would treat each phoneme in a word as an independent instance, preventing us from considering interactions between labels. In order to overcome this shortcoming, we employ an SVM-HMM1 (Altun et al., 2003), an instance of the Structured SVM formalism (Tsochantaridis et al., 2004) that has been specialized for sequence tagging. When training a structured SVM, each training instance xi is paired with its label yi, drawn from the set of possible labels, Yi. In our case, the training instances xi are words, represented as sequences of phonemes, and their labels yi are syllabifications, represented as sequences of onset/nucleus/coda tags. For each training example, a feature vector Ψ(x, y) represents the relationship between the example and a candidate tag sequence. The SVM finds a weight vector w, such that w ·Ψ(x, y) separates correct taggings from incorrect taggings by </context>
<context position="17376" citStr="Tsochantaridis et al. (2004)" startWordPosition="2735" endWordPosition="2738"> the complexity of w via a cost parameter. We tune this parameter on our development set. The SVM-HMM training procedure repeatedly uses the Viterbi algorithm to find, for the current w and each (xi, yi) training pair, the sequence y that most drastically violates the inequality shown in Equation 1. These incorrect tag sequences are added to a growing set, which constrains the quadratic optimization procedure used to find the next w. The process iterates until no new violating sequences are found, producing an approximation to the inequality over all y E Yi. A complete explanation is given by Tsochantaridis et al. (2004). Given a weight vector w, a structured SVM tags new instances x according to: argmaxy∈Y [Ψ(x, y) &apos; w] (2) The SVM-HMM gets the HMM portion of its name from its use of the HMM Viterbi algorithm to solve this argmax. 5.1 Features We investigated several tagging schemes, described in detail by Bartlett (2007). During development, we found that tagging each phoneme with its syllabic role (Krenn, 1997) works better than the simple binary distinction between syllable-final and other phonemes (van den Bosch, 1997). We also discovered that accuracy can be improved by numbering the tags. Therefore, in</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. Proceedings of the 21st International Conference on Machine Learning (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antal van den Bosch</author>
</authors>
<title>Learning to pronounce written words: a study in inductive language learning.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Universiteit Maastricht.</institution>
<marker>van den Bosch, 1997</marker>
<rawString>Antal van den Bosch. 1997. Learning to pronounce written words: a study in inductive language learning. Ph.D. thesis, Universiteit Maastricht.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>