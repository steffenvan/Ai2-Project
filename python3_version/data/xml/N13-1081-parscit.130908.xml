<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.038584">
<title confidence="0.981012">
An opinion about opinions about opinions: subjectivity and the aggregate
reader
</title>
<author confidence="0.946439">
Asad Sayeed
</author>
<affiliation confidence="0.964298">
Computational Linguistics and Phonetics / M2CI Cluster of Excellence
Saarland University
</affiliation>
<address confidence="0.70339">
66123 Saarbr¨ucken, Germany
</address>
<email confidence="0.997263">
asayeed@coli.uni-saarland.de
</email>
<sectionHeader confidence="0.993866" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998161875">
This opinion piece proposes that recent ad-
vances in opinion detection are limited in the
extent to which they can detect important cat-
egories of opinion because they are not de-
signed to capture some of the pragmatic as-
pects of opinion. A component of these is the
perspective of the user of an opinion-mining
system as to what an opinion really is, which is
in itself a matter of opinion (metasubjectivity).
We propose a way to define this component of
opinion and describe the challenges it poses
for corpus development and sentence-level de-
tection technologies. Finally, we suggest that
investment in techniques to handle metasub-
jectivity will likely bear costs but bring bene-
fits in the longer term.
</bodyText>
<sectionHeader confidence="0.998985" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999780641509434">
Opinion mining, also known as sentiment analysis
(Pang and Lee, 2008), is a relatively recent area
of research in natural language processing. It has
grown very quickly as a research area, developing
around a small number of basic approaches. How-
ever, these approaches are based on particular def-
initions of opinion, assumptions about opinion ex-
pressions, and evaluation practices that we believe
need to be expanded in order for sentiment analysis
to reach new domains and applications.
We are not the first to express concern over the
direction of sentiment analysis as a field. This paper
seeks to further expand upon the views expressed
in Alm (2011) that prevailing evaluation concepts in
sentiment analysis limit the kinds of models we can
build, particularly through the encouragement of a
focus on “high-performing” systems.
The central thread that connects our view of the
field is the idea that the basis of standard techniques
and evaluation in information retrieval and extrac-
tion that underlie existing approaches needs to be
rethought for applications that are inherently subjec-
tive and that the field needs to return to more theoret-
ical groundwork. This will entail sacrificing some of
the performance gains made in recent times, as well
as potentially reducing the capacity for easily com-
parable research that has been gained by the rapid
adoption of corpora that are very easily produced,
shared, and used.
This problem is particularly relevant in the expan-
sion of sentiment analysis techniques to areas such
as market prediction (Bollen et al., 2010) and social
science. In these areas, it is not enough to detect
opinions in predefined areas of text or even to mine
for the locations of opinions in large corpora, but it is
necessary to be able to connect opinions across doc-
uments and to reconstruct the social networks that
underlie social trends. Furthermore, it must be pos-
sible to do this in text that can have an arbitrary num-
ber of opinions intertwined in ways that go beyond
the base case of product review text. This requires
both additional consideration of the perspective of
the user and attention to the finer-grained details of
sentiment expression.
Do existing resources and techniques really re-
flect the ultimate goals and end-uses of fine-grained
opinion-mining, particularly focusing on the senten-
tial and sub-sentential levels? Consider an “ideal
case” of a marketing director or a political campaign
manager requesting a forecast of how a product or
concept will unfold in the media and market. How
do the present conceptions of opinion mining relate
to this among other real-world problems of affect?
</bodyText>
<page confidence="0.977877">
691
</page>
<subsectionHeader confidence="0.293717">
Proceedings of NAACL-HLT 2013, pages 691–696,
</subsectionHeader>
<bodyText confidence="0.928723">
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
In the remainder of this position paper, we briefly
describe three closely related issues in sentiment
analysis that pertain to expanding beyond the cur-
rent limits of the field.
</bodyText>
<sectionHeader confidence="0.994674" genericHeader="method">
2 Challenges
</sectionHeader>
<subsectionHeader confidence="0.999346">
2.1 Metasubjectivity and pragmatic opinion
</subsectionHeader>
<bodyText confidence="0.999908886363636">
Recent efforts in opinion mining (Ruppenhofer
et al., 2008) technology have often tended to take
the position that opinion is an internal characteristic
of the speaker, a “private state”, and that the overall
aim of the opinion mining field is to discover tech-
niques that allow us to infer the that latent state from
the evidence presented in text. But this may not al-
ways be appropriate to all circumstances.
A very simple boundary example comes from So-
masundaran and Wiebe (2009): The blackberry is
something like $150 and the iPhone is $500. This
comes from a corpus of opinions on cell phone pref-
erence, and this sentence is intended to be a negative
opinion about the iPhone. According to Somasun-
daran and Wiebe, this kind of opinion-expression
requires a model of world-knowledge that is either
not practical under current technologies, or it re-
quires the development of techniques that can re-
cruit a larger context in the text in order to make the
correct inference. They refer to this phenomenon as
“pragmatic opinion”.
One crucial piece of world-knowledge that pro-
vides an opinion its polarity is that of the perspective
of the reader or listener to the opinion; we can min-
imally represent this as the “application” to which
the opinion will be put. We refer to variation in the
application-specific interpretation of the concept of
opinion as “metasubjectivity.” Metasubjectivity is
a serious problem in extending sentiment analysis
work to other domains, particularly for reasons that
we describe in the next section.
Metasubjectivity is closely related to the underly-
ing relative nature of veridicality assessment. The
veridicality of an utterance is the level to which the
listener may judge it as a factual statement about the
world. de Marneffe et al. (2012) note that this re-
quires, in some cases, extensive pragmatic knowl-
edge. They present this sentence as an example:
FBI agents alleged in court documents today that
Zazi had admitted receiving weapons and explosives
training from al-Qaeda operatives in Pakistan last
year. There is an interplay between the trustworthi-
ness of the source of the sentence, the mentioned en-
tities, and the veridicality of words alleged and ad-
mitted, all of which are mediated by the perspective
of the reader. For example, if the reader is strongly
inclined to trust the FBI, then there may be a high
level of veridicality in “alleged” than otherwise. But
it could also be the case that the reader believes that
Zazi is misleading the FBI.
These distinctions operate directly in the context
of determining polarity in opinion mining. Consider
the following example sentence from a major in-
formation technology (IT) business journal: Lloyd
Hession, chief security officer at BT Radianz in New
York, said that virtualization also opens up a slew of
potential network access control issues.
This sentence can be taken to represent an opinion
or merely a factual statement. A casual reader with-
out experience in the domain of IT might be con-
vinced that this sentence is simply a neutral state-
ment of fact. But from the perspective of an inter-
ested reader such as an investor, this may actually
represent a mildly negative statement about virtu-
alization, or it may represent a negative statement
about network access control. From the perspective
of the manager of an IT support department, it may
well be very negative. But from the perspective of
Lloyd Hession, we have no idea outside of the prag-
matic context. Mr. Hession could be a developer of
IT solutions, in which case he would view this as a
positive development for the market in new network
access control technologies, or, for that matter, he
may be invested in a set of technological approaches
that compete with virtualization.
This extends to the vocabulary used to express
opinions. The use of the word “slew”, in this case,
has negative connotations, but only if the whole
statement is construed by the perspective of the
reader to represent an opinion. However, if Lloyd
Hession is a provider of new network access control
solutions, then the use of “open” may convert this
negative context into a positive context.
This is not merely a matter of the perspectives
of individual users and participants. It is a matter
of how providers of sentiment analysis applications
choose to represent these choices to the user, which
is in turn reflected in the way in which they create
</bodyText>
<page confidence="0.993179">
692
</page>
<bodyText confidence="0.997704147058823">
resources, models, and algorithms. If, for example,
our goal is to provide sentiment analysis for domain-
specific market prediction or social science, then we
need to model the reactions not of the private state
of Mr. Hession or of the writer of the article, but
of an “aggregate reader” with a presumed interest in
the text. Here is a definition of this external state
aggregate reader model that might apply to the IT
business domain:
Opinion source A expresses opinion about opinion
target B if an interested third party C’s actions to-
wards B may be affected by A’s textually recorded
actions, in a context where actions have positive or
negative weight.
This accounts for the cases in which the opinion of
interest in the IT example happens to be held by an
investor or a IT support manager or other interested
readers, and it can be generalized to apply to other
domains in which the world’s opinion matters.
It is once again within the area of veridicality as-
sessment that we suggest that a possible form of
solution exists. de Marneffe et al. (2012) present
a model in which the uncertainty in veridicality is
represented as a distribution rather than a discrete
labelling problem.
In the case of veridicality, there is generally an
ultimate ground truth in verifiable facts about the
world, apart from the relative veridical nature of a
statement. For sentiment, however, there is no such
foundation: opinion presence and opinion polarity
exist entirely relative to the perspective of the ag-
gregate reader. This requires a different process of
annotation, the challenges of which we describe in
the next section.
</bodyText>
<subsectionHeader confidence="0.999508">
2.2 Corpus development and evaluation
</subsectionHeader>
<bodyText confidence="0.9998689">
Considering the prevalence of machine learning
techniques in opinion mining research, addressing
the issue of metasubjectivity must mean addressing
the matter of the corpus development.
Existing evaluation techniques depend on a no-
tion of “gold standard data” that are produced by
expert judges or crowdsourced annotators (Wilson,
2007; Kessler et al., 2010; Hsueh et al., 2009). There
are NLP areas in which popular notions of objec-
tivity may partly apply, such as query relevance;
due, among other things, to metasubjectivity, opin-
ion mining is not entirely one of these. However,
gold standard data for opinion mining is typically
produced using procedures that are standard for in-
formation retrieval research, and the quality mea-
sures that are generally used happen to assume the
presence of an underlying objective truth.
This assumption can be coerced to fit particular
cases. For example, a large proportion of opinion
mining research is invested in predicting the rat-
ings of product reviews and then aggregating results
into a single ratings summary, sometimes based on
a lower-level breakdown of product features (de Al-
bornoz et al., 2011). Implicit in this type of work
is the assumption of the existence of an ideal rater
who uses language in a roughly predictable way to
express his or her feelings about the text.
The users of these types of systems can be as-
sumed, to some degree of safety, to share some of
the expectations of the builders of these systems,
particularly since groups of users as product raters
are often the source of the information itself.
But in environments where the users of the sys-
tem may have various different perspectives on the
nature of sentiment, it does not make sense to as-
sume that there would ever be significant agree-
ment among annotators, particularly for market-
relevant applications where prediction of reader re-
action is central to the task. We attempted to an-
notate IT business press articles for sentence-level
reader-perspective opinion occurrences and found
that multiple trained annotators had very low inter-
rater agreement by Cohen’s r.. Multiple attempts
at further annotator training and error analysis re-
vealed that the annotators simply found it very dif-
ficult to agree on what the definition of an opinion
was. Originally, we had two trained student anno-
tators for this task, with repeated training and joint
practice annotations in order to achieve consensus as
to what counts as an opinion mention instance and
what does not. Other groups of annotators and an-
notation designs had no better success.
However, we observed that this appears to be pri-
marily a problem of conservativity where annotators
differed in the quantity of sentences that they con-
sidered to be opinionated, and had a large amount of
overlap in those that they did consider to be opinion-
ated. Further discussion with the annotators found
that some simply had a much lower threshold at
which they would consider a sentence to contain an
</bodyText>
<page confidence="0.998521">
693
</page>
<bodyText confidence="0.999901263157895">
opinion. In other words, this form of annotation is
more affected by metasubjectivity than opinion an-
notation focused on opinion source perspective. It
should be noted that this is a different task from
finding opinion sources and labelling the textual ev-
idence of their private states; we were attempting to
model the “ideal case” we identified in section 1.
We suggest that the answer to this problem is
to deploy the concept of the aggregate reader men-
tioned in the previous section and to pose the anno-
tation question indirectly. The former requires the
collection of data from a larger number of people
and can be provided by existing crowdsourcing tech-
niques (Snow et al., 2008). The latter, however, re-
quires designing the annotation in such a way that
it avoids letting the annotator consider the question:
“What is an opinion?” This is most likely done by
a user interface that simulates the behaviour of the
intended aggregate reader (Sayeed et al., 2011).
</bodyText>
<subsectionHeader confidence="0.996477">
2.3 Grammatical expression
</subsectionHeader>
<bodyText confidence="0.999908826086957">
There are a number of types of features with which
one can construct and train supervised sentence-
level sentiment detection models. Most recent tech-
niques (Kim and Hovy, 2006; Choi et al., 2006;
Jakob and Gurevych, 2010) take into account the
syntactic context of the sentence but limit the
amount of syntactic context thus used. These re-
strictions reduce the presence or absence of partic-
ular structures to binary features in the model. We
argue that we need techniques that take into account
more syntactic context, particularly without making
use of predefined structures.
The latest techniques make use of larger syntac-
tic contexts with potentially unlimited scope. One
example is Nakagawa et al. (2010), who use fac-
tor graphs (McCallum et al., 2009) to learn a model
that traces paths through the dependency trees of
opinion-relevant sentences (de Marneffe and Man-
ning, 2008). However, this is in the service of polar-
ity classification, as it assumes that the appropriate
sentences have already been identified; then it is a
matter of correctly processing negations and other
polarity-changing items. The challenge of metasub-
jectivity is a barrier to opinion sentence detection it-
self, well before polarity classification.
Another example is Qiu et al. (2011). They are
more directly focused on detecting opinion-relevant
language. However, they make use of a system of
hard-coded heuristics to find opinion words in de-
pendency parses. While these types of heuristics
support longer-distance syntactic relations, they tend
to focus on cases where some form of semantic com-
positionality holds. However, consider this sentence
from the IT business press: The contract is consis-
tent with the desktop computing Outsourcing deals
Citibank awarded EDS and Digital Equipment in
1996... In this case, an interested aggregate reader
might note that “awarded” is a word that puts “out-
sourcing” in a positive light. However, the syntac-
tic relationship between these two words does not
directly imply or permit any semantic composition-
ality, In order to find these relationships, we would
need to invest in techniques that can learn from ar-
bitrary non-compositional structure, thereby poten-
tially capturing patterns in grammar that actually re-
flect some aspects of external pragmatic knowledge.
</bodyText>
<sectionHeader confidence="0.997059" genericHeader="conclusions">
3 Conclusions
</sectionHeader>
<bodyText confidence="0.999987961538461">
This paper has proposed a challenge for opinion
mining, the challenge of metasubjectivity: where the
answer to the question “What is an opinion?” is in
itself an opinion and an intrinsic part of the task. We
first established the context of metasubjectivity rela-
tive to existing characterizations of the opinion min-
ing task, establishing the notion of an external aggre-
gate reader as a way to extend from existing notions
of sentiment as an internal state. Then we described
how this affects the annotation process, given the
as-yet-continuing dependence on supervised corpus-
based detection techniques. Finally, we described
how this affects sentence-level fine-grained opinion
detection at the level of syntactic analysis.
One of the risks for the field in proceeding to
investigations of how to deal with the question
of metasubjectivity is one familiar in natural lan-
guage processing as a whole: there is a strong risk
that these techniques will—initially and for a non-
trivial quantity of time—cause the incremental per-
formance gains in existing research to be lost or
damaged. It will also require the creation of new
training corpora and related resources, temporarily
threatening comparability. Nevertheless, we believe
that these risks need to be accepted in order to make
progress in sentiment analysis.
</bodyText>
<page confidence="0.998333">
694
</page>
<sectionHeader confidence="0.990026" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9166494375">
Alm, C. O. (2011). Subjective natural language
problems: Motivations, applications, characteri-
zations, and implications. In ACL (Short Papers).
Bollen, J., Mao, H., and Zeng, X.-J. (2010). Twit-
ter mood predicts the stock market. CoRR,
abs/1010.3003.
Choi, Y., Breck, E., and Cardie, C. (2006). Joint ex-
traction of entities and relations for opinion recog-
nition. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP).
de Albornoz, J., Plaza, L., Gerv´as, P., and Diaz,
A. (2011). A joint model of feature mining
and sentiment analysis for product review rating.
In Clough, P., Foley, C., Gurrin, C., Jones, G.,
Kraaij, W., Lee, H., and Mudoch, V., editors, Ad-
</reference>
<bodyText confidence="0.972338111111111">
vances in information retrieval, volume 6611 of
Lecture Notes in Computer Science, pages 55–66.
Springer Berlin / Heidelberg.
de Marneffe, M.-C. and Manning, C. D. (2008).
The stanford typed dependencies representation.
In CrossParser ’08: Coling 2008: Proceed-
ings of the workshop on Cross-Framework and
Cross-Domain Parser Evaluation, Morristown,
NJ, USA. Association for Computational Linguis-
tics.
de Marneffe, M.-C., Manning, C. D., and Potts, C.
(2012). Did it happen? the pragmatic complex-
ity of veridicality assessment. Computational lin-
guistics, 35(1).
Hsueh, P.-Y., Melville, P., and Sindhwani, V. (2009).
Data quality from crowdsourcing: a study of an-
notation selection criteria. In Proceedings of the
NAACL HLT 2009 Workshop on Active Learn-
ing for Natural Language Processing, HLT ’09,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Jakob, N. and Gurevych, I. (2010). Extracting opin-
ion targets in a single and cross-domain setting
with conditional random fields. In EMNLP.
Kessler, J. S., Eckert, M., Clark, L., and Nicolov, N.
(2010). The 2010 ICWSM JDPA sentment cor-
pus for the automotive domain. In 4th Int’l AAAI
</bodyText>
<reference confidence="0.999064422222222">
Conference on Weblogs and Social Media Data
Workshop Challenge (ICWSM-DWC 2010).
Kim, S.-M. and Hovy, E. (2006). Extracting opin-
ions, opinion holders, and topics expressed in on-
line news media text. In SST ’06: Proceedings
of the Workshop on Sentiment and Subjectivity in
Text, pages 1–8, Morristown, NJ, USA. Associa-
tion for Computational Linguistics.
McCallum, A., Schultz, K., and Singh, S. (2009).
Factorie: Probabilistic programming via impera-
tively defined factor graphs. In Neural Informa-
tion Processing Systems (NIPS).
Nakagawa, T., Inui, K., and Kurohashi, S. (2010).
Dependency tree-based sentiment classification
using crfs with hidden variables. In HLT-NAACL.
Pang, B. and Lee, L. (2008). Opinion mining and
sentiment analysis. Found. Trends Inf. Retr., 2(1-
2).
Qiu, G., Liu, B., Bu, J., and Chen, C. (2011). Opin-
ion word expansion and target extraction through
double propagation. Computational linguistics,
37(1):9—27.
Ruppenhofer, J., Somasundaran, S., and Wiebe, J.
(2008). Finding the sources and targets of sub-
jective expressions. In Calzolari, N., Choukri, K.,
Maegaard, B., Mariani, J., Odjik, J., Piperidis, S.,
and Tapias, D., editors, Proceedings of the Sixth
International Language Resources and Evalua-
tion (LREC’08), Marrakech, Morocco. European
Language Resources Association (ELRA).
Sayeed, A. B., Rusk, B., Petrov, M., Nguyen,
H. C., Meyer, T. J., and Weinberg, A. (2011).
Crowdsourcing syntactic relatedness judgements
for opinion mining in the study of information
technology adoption. In Proceedings of the Asso-
ciation for Computational Linguistics 2011 work-
shop on Language Technology for Cultural Her-
itage, Social Sciences, and the Humanities (LaT-
eCH). Association for Computational Linguistics.
Snow, R., O’Connor, B., Jurafsky, D., and Ng, A. Y.
(2008). Cheap and fast—but is it good?: evalu-
ating non-expert annotations for natural language
tasks. In EMNLP 2008.
Somasundaran, S. and Wiebe, J. (2009). Recogniz-
ing stances in online debates. In Proceedings of
</reference>
<page confidence="0.991472">
695
</page>
<reference confidence="0.552584333333333">
the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Con-
ference on Natural Language Processing of the
AFNLP: Volume 1, ACL ’09.
Wilson, T. (2007). Fine-grained Subjectivity and
Sentiment Analysis: Recognizing the Intensity,
Polarity, and Attitudes ofprivate states. PhD the-
sis, Intelligent Systems Program, University of
Pittsburgh.
</reference>
<page confidence="0.998545">
696
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.082585">
<title confidence="0.855972">An opinion about opinions about opinions: subjectivity and the aggregate</title>
<author confidence="0.3693865">reader Asad</author>
<affiliation confidence="0.4762115">Linguistics and Phonetics / Cluster of Saarland</affiliation>
<address confidence="0.855626">66123 Saarbr¨ucken,</address>
<email confidence="0.987315">asayeed@coli.uni-saarland.de</email>
<abstract confidence="0.995978294117647">This opinion piece proposes that recent advances in opinion detection are limited in the extent to which they can detect important categories of opinion because they are not designed to capture some of the pragmatic aspects of opinion. A component of these is the perspective of the user of an opinion-mining system as to what an opinion really is, which is in itself a matter of opinion (metasubjectivity). We propose a way to define this component of opinion and describe the challenges it poses for corpus development and sentence-level detection technologies. Finally, we suggest that investment in techniques to handle metasubjectivity will likely bear costs but bring benefits in the longer term.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>C O Alm</author>
</authors>
<title>Subjective natural language problems: Motivations, applications, characterizations, and implications.</title>
<date>2011</date>
<booktitle>In ACL (Short Papers).</booktitle>
<contexts>
<context position="1619" citStr="Alm (2011)" startWordPosition="255" endWordPosition="256">ysis (Pang and Lee, 2008), is a relatively recent area of research in natural language processing. It has grown very quickly as a research area, developing around a small number of basic approaches. However, these approaches are based on particular definitions of opinion, assumptions about opinion expressions, and evaluation practices that we believe need to be expanded in order for sentiment analysis to reach new domains and applications. We are not the first to express concern over the direction of sentiment analysis as a field. This paper seeks to further expand upon the views expressed in Alm (2011) that prevailing evaluation concepts in sentiment analysis limit the kinds of models we can build, particularly through the encouragement of a focus on “high-performing” systems. The central thread that connects our view of the field is the idea that the basis of standard techniques and evaluation in information retrieval and extraction that underlie existing approaches needs to be rethought for applications that are inherently subjective and that the field needs to return to more theoretical groundwork. This will entail sacrificing some of the performance gains made in recent times, as well a</context>
</contexts>
<marker>Alm, 2011</marker>
<rawString>Alm, C. O. (2011). Subjective natural language problems: Motivations, applications, characterizations, and implications. In ACL (Short Papers).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bollen</author>
<author>H Mao</author>
<author>X-J Zeng</author>
</authors>
<date>2010</date>
<note>Twitter mood predicts the stock market. CoRR, abs/1010.3003.</note>
<contexts>
<context position="2533" citStr="Bollen et al., 2010" startWordPosition="398" endWordPosition="401">tion in information retrieval and extraction that underlie existing approaches needs to be rethought for applications that are inherently subjective and that the field needs to return to more theoretical groundwork. This will entail sacrificing some of the performance gains made in recent times, as well as potentially reducing the capacity for easily comparable research that has been gained by the rapid adoption of corpora that are very easily produced, shared, and used. This problem is particularly relevant in the expansion of sentiment analysis techniques to areas such as market prediction (Bollen et al., 2010) and social science. In these areas, it is not enough to detect opinions in predefined areas of text or even to mine for the locations of opinions in large corpora, but it is necessary to be able to connect opinions across documents and to reconstruct the social networks that underlie social trends. Furthermore, it must be possible to do this in text that can have an arbitrary number of opinions intertwined in ways that go beyond the base case of product review text. This requires both additional consideration of the perspective of the user and attention to the finer-grained details of sentime</context>
</contexts>
<marker>Bollen, Mao, Zeng, 2010</marker>
<rawString>Bollen, J., Mao, H., and Zeng, X.-J. (2010). Twitter mood predicts the stock market. CoRR, abs/1010.3003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Choi</author>
<author>E Breck</author>
<author>C Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="14188" citStr="Choi et al., 2006" startWordPosition="2329" endWordPosition="2332">f data from a larger number of people and can be provided by existing crowdsourcing techniques (Snow et al., 2008). The latter, however, requires designing the annotation in such a way that it avoids letting the annotator consider the question: “What is an opinion?” This is most likely done by a user interface that simulates the behaviour of the intended aggregate reader (Sayeed et al., 2011). 2.3 Grammatical expression There are a number of types of features with which one can construct and train supervised sentencelevel sentiment detection models. Most recent techniques (Kim and Hovy, 2006; Choi et al., 2006; Jakob and Gurevych, 2010) take into account the syntactic context of the sentence but limit the amount of syntactic context thus used. These restrictions reduce the presence or absence of particular structures to binary features in the model. We argue that we need techniques that take into account more syntactic context, particularly without making use of predefined structures. The latest techniques make use of larger syntactic contexts with potentially unlimited scope. One example is Nakagawa et al. (2010), who use factor graphs (McCallum et al., 2009) to learn a model that traces paths thr</context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Choi, Y., Breck, E., and Cardie, C. (2006). Joint extraction of entities and relations for opinion recognition. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J de Albornoz</author>
<author>L Plaza</author>
<author>P Gerv´as</author>
<author>A Diaz</author>
</authors>
<title>A joint model of feature mining and sentiment analysis for product review rating.</title>
<date>2011</date>
<booktitle>AdConference on Weblogs and Social Media Data Workshop Challenge (ICWSM-DWC</booktitle>
<editor>In Clough, P., Foley, C., Gurrin, C., Jones, G., Kraaij, W., Lee, H., and Mudoch, V., editors,</editor>
<marker>de Albornoz, Plaza, Gerv´as, Diaz, 2011</marker>
<rawString>de Albornoz, J., Plaza, L., Gerv´as, P., and Diaz, A. (2011). A joint model of feature mining and sentiment analysis for product review rating. In Clough, P., Foley, C., Gurrin, C., Jones, G., Kraaij, W., Lee, H., and Mudoch, V., editors, AdConference on Weblogs and Social Media Data Workshop Challenge (ICWSM-DWC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S-M Kim</author>
<author>E Hovy</author>
</authors>
<title>Extracting opinions, opinion holders, and topics expressed in online news media text.</title>
<date>2006</date>
<booktitle>In SST ’06: Proceedings of the Workshop on Sentiment and Subjectivity in Text,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="14169" citStr="Kim and Hovy, 2006" startWordPosition="2325" endWordPosition="2328">res the collection of data from a larger number of people and can be provided by existing crowdsourcing techniques (Snow et al., 2008). The latter, however, requires designing the annotation in such a way that it avoids letting the annotator consider the question: “What is an opinion?” This is most likely done by a user interface that simulates the behaviour of the intended aggregate reader (Sayeed et al., 2011). 2.3 Grammatical expression There are a number of types of features with which one can construct and train supervised sentencelevel sentiment detection models. Most recent techniques (Kim and Hovy, 2006; Choi et al., 2006; Jakob and Gurevych, 2010) take into account the syntactic context of the sentence but limit the amount of syntactic context thus used. These restrictions reduce the presence or absence of particular structures to binary features in the model. We argue that we need techniques that take into account more syntactic context, particularly without making use of predefined structures. The latest techniques make use of larger syntactic contexts with potentially unlimited scope. One example is Nakagawa et al. (2010), who use factor graphs (McCallum et al., 2009) to learn a model th</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Kim, S.-M. and Hovy, E. (2006). Extracting opinions, opinion holders, and topics expressed in online news media text. In SST ’06: Proceedings of the Workshop on Sentiment and Subjectivity in Text, pages 1–8, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>K Schultz</author>
<author>S Singh</author>
</authors>
<title>Factorie: Probabilistic programming via imperatively defined factor graphs.</title>
<date>2009</date>
<booktitle>In Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="14749" citStr="McCallum et al., 2009" startWordPosition="2419" endWordPosition="2422">Most recent techniques (Kim and Hovy, 2006; Choi et al., 2006; Jakob and Gurevych, 2010) take into account the syntactic context of the sentence but limit the amount of syntactic context thus used. These restrictions reduce the presence or absence of particular structures to binary features in the model. We argue that we need techniques that take into account more syntactic context, particularly without making use of predefined structures. The latest techniques make use of larger syntactic contexts with potentially unlimited scope. One example is Nakagawa et al. (2010), who use factor graphs (McCallum et al., 2009) to learn a model that traces paths through the dependency trees of opinion-relevant sentences (de Marneffe and Manning, 2008). However, this is in the service of polarity classification, as it assumes that the appropriate sentences have already been identified; then it is a matter of correctly processing negations and other polarity-changing items. The challenge of metasubjectivity is a barrier to opinion sentence detection itself, well before polarity classification. Another example is Qiu et al. (2011). They are more directly focused on detecting opinion-relevant language. However, they mak</context>
</contexts>
<marker>McCallum, Schultz, Singh, 2009</marker>
<rawString>McCallum, A., Schultz, K., and Singh, S. (2009). Factorie: Probabilistic programming via imperatively defined factor graphs. In Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nakagawa</author>
<author>K Inui</author>
<author>S Kurohashi</author>
</authors>
<title>Dependency tree-based sentiment classification using crfs with hidden variables.</title>
<date>2010</date>
<booktitle>In HLT-NAACL.</booktitle>
<contexts>
<context position="14702" citStr="Nakagawa et al. (2010)" startWordPosition="2410" endWordPosition="2413">ised sentencelevel sentiment detection models. Most recent techniques (Kim and Hovy, 2006; Choi et al., 2006; Jakob and Gurevych, 2010) take into account the syntactic context of the sentence but limit the amount of syntactic context thus used. These restrictions reduce the presence or absence of particular structures to binary features in the model. We argue that we need techniques that take into account more syntactic context, particularly without making use of predefined structures. The latest techniques make use of larger syntactic contexts with potentially unlimited scope. One example is Nakagawa et al. (2010), who use factor graphs (McCallum et al., 2009) to learn a model that traces paths through the dependency trees of opinion-relevant sentences (de Marneffe and Manning, 2008). However, this is in the service of polarity classification, as it assumes that the appropriate sentences have already been identified; then it is a matter of correctly processing negations and other polarity-changing items. The challenge of metasubjectivity is a barrier to opinion sentence detection itself, well before polarity classification. Another example is Qiu et al. (2011). They are more directly focused on detecti</context>
</contexts>
<marker>Nakagawa, Inui, Kurohashi, 2010</marker>
<rawString>Nakagawa, T., Inui, K., and Kurohashi, S. (2010). Dependency tree-based sentiment classification using crfs with hidden variables. In HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="1034" citStr="Pang and Lee, 2008" startWordPosition="157" endWordPosition="160">e not designed to capture some of the pragmatic aspects of opinion. A component of these is the perspective of the user of an opinion-mining system as to what an opinion really is, which is in itself a matter of opinion (metasubjectivity). We propose a way to define this component of opinion and describe the challenges it poses for corpus development and sentence-level detection technologies. Finally, we suggest that investment in techniques to handle metasubjectivity will likely bear costs but bring benefits in the longer term. 1 Introduction Opinion mining, also known as sentiment analysis (Pang and Lee, 2008), is a relatively recent area of research in natural language processing. It has grown very quickly as a research area, developing around a small number of basic approaches. However, these approaches are based on particular definitions of opinion, assumptions about opinion expressions, and evaluation practices that we believe need to be expanded in order for sentiment analysis to reach new domains and applications. We are not the first to express concern over the direction of sentiment analysis as a field. This paper seeks to further expand upon the views expressed in Alm (2011) that prevailin</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Pang, B. and Lee, L. (2008). Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Qiu</author>
<author>B Liu</author>
<author>J Bu</author>
<author>C Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational linguistics,</journal>
<pages>37--1</pages>
<contexts>
<context position="15259" citStr="Qiu et al. (2011)" startWordPosition="2498" endWordPosition="2501">ially unlimited scope. One example is Nakagawa et al. (2010), who use factor graphs (McCallum et al., 2009) to learn a model that traces paths through the dependency trees of opinion-relevant sentences (de Marneffe and Manning, 2008). However, this is in the service of polarity classification, as it assumes that the appropriate sentences have already been identified; then it is a matter of correctly processing negations and other polarity-changing items. The challenge of metasubjectivity is a barrier to opinion sentence detection itself, well before polarity classification. Another example is Qiu et al. (2011). They are more directly focused on detecting opinion-relevant language. However, they make use of a system of hard-coded heuristics to find opinion words in dependency parses. While these types of heuristics support longer-distance syntactic relations, they tend to focus on cases where some form of semantic compositionality holds. However, consider this sentence from the IT business press: The contract is consistent with the desktop computing Outsourcing deals Citibank awarded EDS and Digital Equipment in 1996... In this case, an interested aggregate reader might note that “awarded” is a word</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Qiu, G., Liu, B., Bu, J., and Chen, C. (2011). Opinion word expansion and target extraction through double propagation. Computational linguistics, 37(1):9—27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ruppenhofer</author>
<author>S Somasundaran</author>
<author>J Wiebe</author>
</authors>
<title>Finding the sources and targets of subjective expressions.</title>
<date>2008</date>
<booktitle>Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<editor>In Calzolari, N., Choukri, K., Maegaard, B., Mariani, J., Odjik, J., Piperidis, S., and Tapias, D., editors,</editor>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="4032" citStr="Ruppenhofer et al., 2008" startWordPosition="637" endWordPosition="640">ager requesting a forecast of how a product or concept will unfold in the media and market. How do the present conceptions of opinion mining relate to this among other real-world problems of affect? 691 Proceedings of NAACL-HLT 2013, pages 691–696, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics In the remainder of this position paper, we briefly describe three closely related issues in sentiment analysis that pertain to expanding beyond the current limits of the field. 2 Challenges 2.1 Metasubjectivity and pragmatic opinion Recent efforts in opinion mining (Ruppenhofer et al., 2008) technology have often tended to take the position that opinion is an internal characteristic of the speaker, a “private state”, and that the overall aim of the opinion mining field is to discover techniques that allow us to infer the that latent state from the evidence presented in text. But this may not always be appropriate to all circumstances. A very simple boundary example comes from Somasundaran and Wiebe (2009): The blackberry is something like $150 and the iPhone is $500. This comes from a corpus of opinions on cell phone preference, and this sentence is intended to be a negative opin</context>
</contexts>
<marker>Ruppenhofer, Somasundaran, Wiebe, 2008</marker>
<rawString>Ruppenhofer, J., Somasundaran, S., and Wiebe, J. (2008). Finding the sources and targets of subjective expressions. In Calzolari, N., Choukri, K., Maegaard, B., Mariani, J., Odjik, J., Piperidis, S., and Tapias, D., editors, Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), Marrakech, Morocco. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="false">
<authors>
<author>A B Sayeed</author>
<author>B Rusk</author>
<author>M Petrov</author>
<author>H C Nguyen</author>
<author>T J Meyer</author>
<author>A Weinberg</author>
</authors>
<title>Crowdsourcing syntactic relatedness judgements for opinion mining in the study of information technology adoption.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics</booktitle>
<contexts>
<context position="13966" citStr="Sayeed et al., 2011" startWordPosition="2293" endWordPosition="2296"> in section 1. We suggest that the answer to this problem is to deploy the concept of the aggregate reader mentioned in the previous section and to pose the annotation question indirectly. The former requires the collection of data from a larger number of people and can be provided by existing crowdsourcing techniques (Snow et al., 2008). The latter, however, requires designing the annotation in such a way that it avoids letting the annotator consider the question: “What is an opinion?” This is most likely done by a user interface that simulates the behaviour of the intended aggregate reader (Sayeed et al., 2011). 2.3 Grammatical expression There are a number of types of features with which one can construct and train supervised sentencelevel sentiment detection models. Most recent techniques (Kim and Hovy, 2006; Choi et al., 2006; Jakob and Gurevych, 2010) take into account the syntactic context of the sentence but limit the amount of syntactic context thus used. These restrictions reduce the presence or absence of particular structures to binary features in the model. We argue that we need techniques that take into account more syntactic context, particularly without making use of predefined structu</context>
</contexts>
<marker>Sayeed, Rusk, Petrov, Nguyen, Meyer, Weinberg, 2011</marker>
<rawString>Sayeed, A. B., Rusk, B., Petrov, M., Nguyen, H. C., Meyer, T. J., and Weinberg, A. (2011). Crowdsourcing syntactic relatedness judgements for opinion mining in the study of information technology adoption. In Proceedings of the Association for Computational Linguistics 2011 workshop on Language Technology for Cultural Heritage, Social Sciences, and the Humanities (LaTeCH). Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>B O’Connor</author>
<author>D Jurafsky</author>
<author>A Y Ng</author>
</authors>
<title>Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks.</title>
<date>2008</date>
<booktitle>In EMNLP</booktitle>
<marker>Snow, O’Connor, Jurafsky, Ng, 2008</marker>
<rawString>Snow, R., O’Connor, B., Jurafsky, D., and Ng, A. Y. (2008). Cheap and fast—but is it good?: evaluating non-expert annotations for natural language tasks. In EMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Somasundaran</author>
<author>J Wiebe</author>
</authors>
<title>Recognizing stances in online debates.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1, ACL ’09.</booktitle>
<contexts>
<context position="4454" citStr="Somasundaran and Wiebe (2009)" startWordPosition="709" endWordPosition="713">ues in sentiment analysis that pertain to expanding beyond the current limits of the field. 2 Challenges 2.1 Metasubjectivity and pragmatic opinion Recent efforts in opinion mining (Ruppenhofer et al., 2008) technology have often tended to take the position that opinion is an internal characteristic of the speaker, a “private state”, and that the overall aim of the opinion mining field is to discover techniques that allow us to infer the that latent state from the evidence presented in text. But this may not always be appropriate to all circumstances. A very simple boundary example comes from Somasundaran and Wiebe (2009): The blackberry is something like $150 and the iPhone is $500. This comes from a corpus of opinions on cell phone preference, and this sentence is intended to be a negative opinion about the iPhone. According to Somasundaran and Wiebe, this kind of opinion-expression requires a model of world-knowledge that is either not practical under current technologies, or it requires the development of techniques that can recruit a larger context in the text in order to make the correct inference. They refer to this phenomenon as “pragmatic opinion”. One crucial piece of world-knowledge that provides an</context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Somasundaran, S. and Wiebe, J. (2009). Recognizing stances in online debates. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1, ACL ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Wilson</author>
</authors>
<title>Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes ofprivate states.</title>
<date>2007</date>
<tech>PhD thesis,</tech>
<institution>Intelligent Systems Program, University of Pittsburgh.</institution>
<contexts>
<context position="10361" citStr="Wilson, 2007" startWordPosition="1691" endWordPosition="1692">ere is no such foundation: opinion presence and opinion polarity exist entirely relative to the perspective of the aggregate reader. This requires a different process of annotation, the challenges of which we describe in the next section. 2.2 Corpus development and evaluation Considering the prevalence of machine learning techniques in opinion mining research, addressing the issue of metasubjectivity must mean addressing the matter of the corpus development. Existing evaluation techniques depend on a notion of “gold standard data” that are produced by expert judges or crowdsourced annotators (Wilson, 2007; Kessler et al., 2010; Hsueh et al., 2009). There are NLP areas in which popular notions of objectivity may partly apply, such as query relevance; due, among other things, to metasubjectivity, opinion mining is not entirely one of these. However, gold standard data for opinion mining is typically produced using procedures that are standard for information retrieval research, and the quality measures that are generally used happen to assume the presence of an underlying objective truth. This assumption can be coerced to fit particular cases. For example, a large proportion of opinion mining re</context>
</contexts>
<marker>Wilson, 2007</marker>
<rawString>Wilson, T. (2007). Fine-grained Subjectivity and Sentiment Analysis: Recognizing the Intensity, Polarity, and Attitudes ofprivate states. PhD thesis, Intelligent Systems Program, University of Pittsburgh.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>