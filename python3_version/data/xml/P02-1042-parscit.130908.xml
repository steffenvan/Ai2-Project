<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.987246">
Building Deep Dependency Structures with a Wide-Coverage CCG Parser
</title>
<author confidence="0.998568">
Stephen Clark, Julia Hockenmaier and Mark Steedman
</author>
<affiliation confidence="0.9980445">
Division of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.942672">
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.98385">
stephenc, julia, steedman @cogsci.ed.ac.uk
</email>
<sectionHeader confidence="0.993241" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999890277777778">
This paper describes a wide-coverage sta-
tistical parser that uses Combinatory Cat-
egorial Grammar (CCG) to derive de-
pendency structures. The parser differs
from most existing wide-coverage tree-
bank parsers in capturing the long-range
dependencies inherent in constructions
such as coordination, extraction, raising
and control, as well as the standard local
predicate-argument dependencies. A set
of dependency structures used for train-
ing and testing the parser is obtained from
a treebank of CCG normal-form deriva-
tions, which have been derived (semi-) au-
tomatically from the Penn Treebank. The
parser correctly recovers over 80% of la-
belled dependencies, and around 90% of
unlabelled dependencies.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999873404255319">
Most recent wide-coverage statistical parsers have
used models based on lexical dependencies (e.g.
Collins (1999), Charniak (2000)). However, the de-
pendencies are typically derived from a context-free
phrase structure tree using simple head percolation
heuristics. This approach does not work well for the
long-range dependencies involved in raising, con-
trol, extraction and coordination, all of which are
common in text such as the Wall Street Journal.
Chiang (2000) uses Tree Adjoining Grammar
as an alternative to context-free grammar, and
here we use another “mildly context-sensitive” for-
malism, Combinatory Categorial Grammar (CCG,
Steedman (2000)), which arguably provides the
most linguistically satisfactory account of the de-
pendencies inherent in coordinate constructions and
extraction phenomena. The potential advantage
from using such an expressive grammar is to facili-
tate recovery of such unbounded dependencies. As
well as having a potential impact on the accuracy of
the parser, recovering such dependencies may make
the output more useful.
CCG is unlike other formalisms in that the stan-
dard predicate-argument relations relevant to inter-
pretation can be derived via extremely non-standard
surface derivations. This impacts on how best to de-
fine a probability model for CCG, since the “spuri-
ous ambiguity” of CCG derivations may lead to an
exponential number of derivations for a given con-
stituent. In addition, some of the spurious deriva-
tions may not be present in the training data. One
solution is to consider only the normal-form (Eis-
ner, 1996a) derivation, which is the route taken in
Hockenmaier and Steedman (2002b).1
Another problem with the non-standard surface
derivations is that the standard PARSEVAL per-
formance measures over such derivations are unin-
formative (Clark and Hockenmaier, 2002). Such
measures have been criticised by Lin (1995) and
Carroll et al. (1998), who propose recovery of head-
dependencies characterising predicate-argument re-
lations as a more meaningful measure.
If the end-result of parsing is interpretable
predicate-argument structure or the related depen-
dency structure, then the question arises: why build
derivation structure at all? A CCG parser can
directly build derived structures, including long-
</bodyText>
<footnote confidence="0.4929805">
1Another, more speculative, possibility is to treat the alter-
native derivations as hidden and apply the EM algorithm.
</footnote>
<note confidence="0.837838">
Proceedings of the 40th Annual Meeting of the Association for
</note>
<page confidence="0.30708">
Computational Linguistics (ACL), Philadelphia, July 2002, pp. 327-334.
</page>
<bodyText confidence="0.999547055555556">
range dependencies. These derived structures can
be of any form we like—for example, they could
in principle be standard Penn Treebank structures.
Since we are interested in dependency-based parser
evaluation, our parser currently builds dependency
structures. Furthermore, since we want to model
the dependencies in such structures, the probability
model is defined over these structures rather than the
derivation.
The training and testing material for this CCG
parser is a treebank of dependency structures, which
have been derived from a set of CCG deriva-
tions developed for use with another (normal-form)
CCG parser (Hockenmaier and Steedman, 2002b).
The treebank of derivations, which we call CCG-
bank (Hockenmaier and Steedman, 2002a), was in
turn derived (semi-)automatically from the hand-
annotated Penn Treebank.
</bodyText>
<sectionHeader confidence="0.907685" genericHeader="method">
2 The Grammar
</sectionHeader>
<bodyText confidence="0.9989792">
In CCG, most language-specific aspects of the gram-
mar are specified in the lexicon, in the form of syn-
tactic categories that identify a lexical item as either
a functor or argument. For the functors, the category
specifies the type and directionality of the arguments
and the type of the result. For example, the follow-
ing category for the transitive verb bought specifies
its first argument as a noun phrase (NP) to its right
and its second argument as an NP to its left, and its
result as a sentence:
</bodyText>
<listItem confidence="0.921109">
(1) bought := S NP NP
</listItem>
<bodyText confidence="0.977368333333333">
For parsing purposes, we extend CCG categories
to express category features, and head-word and de-
pendency information directly, as follows:
</bodyText>
<listItem confidence="0.973175">
(2) bought := Sdclbought NP1 NP2
</listItem>
<bodyText confidence="0.996335083333333">
The feature dcl specifies the category’s S result as a
declarative sentence, bought identifies its head, and
the numbers denote dependency relations. Heads
and dependencies are always marked up on atomic
categories (S, N, NP, PP, and conj in our implemen-
tation).
The categories are combined using a small set of
typed combinatory rules, such as functional applica-
tion and composition (see Steedman (2000) for de-
tails). Derivations are written as follows, with under-
lines indicating combinatory reduction and arrows
indicating the direction of the application:
</bodyText>
<figure confidence="0.841744">
(3) Marks bought Brooks
NPMarks Sdcl�bought NP1 NP2 NPBrooks
Sdcl bought NP1
Sdcl bought
</figure>
<bodyText confidence="0.999558142857143">
Formally, a dependency is defined as a 4-tuple:
hf f s ha , where hf is the head word of the func-
tor,2 f is the functor category (extended with head
and dependency information), s is the argument slot,
and ha is the head word of the argument—for exam-
ple, the following is the object dependency yielded
by the first step of derivation (3):
</bodyText>
<listItem confidence="0.979807">
(4) bought Sdcl
Variables can also be used to denote heads, and
used via unification to pass head information from
one category to another. For example, the expanded
category for the control verb persuade is as follows:
(5) persuade := Sto2 NPX
</listItem>
<equation confidence="0.591694">
Sdcl�persuade NP1 NPX,3
</equation>
<bodyText confidence="0.999860923076923">
The head of the infinitival complement’s subject is
identified with the head of the object, using the vari-
able X. Unification then “passes” the head of the ob-
ject to the subject of the infinitival, as in standard
unification-based accounts of control.3
The kinds of lexical items that use the head pass-
ing mechanism are raising, auxiliary and control
verbs, modifiers, and relative pronouns. Among the
constructions that project unbounded dependencies
are relativisation and right node raising. The follow-
ing category for the relative pronoun category (for
words such as who, which, that) shows how heads
are co-indexed for object-extraction:
</bodyText>
<listItem confidence="0.923156">
(6) who := NPX NPX,1 Sdcl 2 NPX
</listItem>
<bodyText confidence="0.999843">
The derivation for the phrase The company that
Marks wants to buy is given in Figure 1 (with the
features on S categories removed to save space, and
the constant heads reduced to the first letter). Type-
raising ( ) and functional composition ( ), along
</bodyText>
<footnote confidence="0.972921777777778">
2Note that the functor does not always correspond to the lin-
guistic notion of a head.
3The extension of CCG categories in the lexicon and the la-
belled data is simplified in the current system to make it entirely
automatic. For example, any word with the same category (5)
as persuade gets the object-control extension. In certain rare
cases (such as promise) this gives semantically incorrect depen-
dencies in both the grammar and the data (promise Brooks to go
has a structure meaning promise Brooks that Brooks will go).
</footnote>
<figure confidence="0.9723135">
bought NP1 NP2 2 Brooks
The company that Marks wants to buy
NPx Nx,1 Nc NPx NPx,1 S2 NPx NPm Sw NPx,1 S2 NPx Sy NPx,1 Sy,2 NPx Sb NP1 NP2
NPc Sx Sx NPm Sb NP NP
Sw NP ✍NP
Sw NP
NPx NPx
NPc
</figure>
<figureCaption confidence="0.999982">
Figure 1: Relative clause derivation
</figureCaption>
<bodyText confidence="0.999976916666666">
with co-indexing of heads, mediate transmission of
the head of the NP the company onto the object of
buy. The corresponding dependencies are given in
the following figure, with the convention that arcs
point away from arguments. The relevant argument
slot in the functor category labels the arcs.
Note that we encode the subject argument of the
to category as a dependency relation (Marks is a
“subject” of to), since our philosophy at this stage
is to encode every argument as a dependency, where
possible. The number of dependency types may be
reduced in future work.
</bodyText>
<sectionHeader confidence="0.997034" genericHeader="method">
3 The Probability Model
</sectionHeader>
<bodyText confidence="0.98923908">
The DAG-like nature of the dependency structures
makes it difficult to apply generative modelling tech-
niques (Abney, 1997; Johnson et al., 1999), so
we have defined a conditional model, similar to
the model of Collins (1996) (see also the condi-
tional model in Eisner (1996b)). While the model
of Collins (1996) is technically unsound (Collins,
1999), our aim at this stage is to demonstrate that
accurate, efficient wide-coverage parsing is possible
with CCG, even with an over-simplified statistical
model. Future work will look at alternative models.4
4The reentrancies creating the DAG-like structures are fairly
limited, and moreover determined by the lexical categories. We
conjecture that it is possible to define a generative model that
includes the deep dependencies.
The parse selection component must choose the
most probable dependency structure, given the sen-
tence S. A sentence S w1t1 w2t2 wntn
is assumed to be a sequence of word, pos-tag
pairs. For our purposes, a dependency structure n
is a C D pair, where C c1 c2 cn is the se-
quence of categories assigned to the words, and
D hfi fi si hai i 1 m is the set of de-
pendencies. The probability of a dependency struc-
ture can be written as follows:
</bodyText>
<listItem confidence="0.849861">
(7) Pn PCDS PCSPDCS
</listItem>
<bodyText confidence="0.9721375">
The probability PCS can be approximated as
follows:
</bodyText>
<listItem confidence="0.557215">
(8) PCS rjni 1 PciXi
</listItem>
<bodyText confidence="0.9578501">
where Xi is the local context for the ith word. We
have explained elsewhere (Clark, 2002) how suit-
able features can be defined in terms of the word,
pos-tag pairs in the context, and how maximum en-
tropy techniques can be used to estimate the proba-
bilities, following Ratnaparkhi (1996).
We assume that each argument slot in the cat-
egory sequence is filled independently, and write
PDC S as follows:
rj m
</bodyText>
<listItem confidence="0.793958">
(9) PDC S☎ i 1 PhaiC S
</listItem>
<bodyText confidence="0.999993333333333">
where hai is the head word filling the argument slot
of the ith dependency, and m is the number of de-
pendencies entailed by the category sequence C.
</bodyText>
<subsectionHeader confidence="0.998733">
3.1 Estimating the dependency probabilities
</subsectionHeader>
<bodyText confidence="0.999932714285714">
The estimation method is based on Collins (1996).
We assume that the probability of a dependency only
depends on those words involved in the dependency,
together with their categories. We follow Collins
and base the estimate of a dependency probability
on the following intuition: given a pair of words,
with a pair of categories, which are in the same sen-
</bodyText>
<figure confidence="0.712145583333333">
2
2 2
2
The company that Marks wants to buy
1 1
1
1
1
be introduced through coordination), and so a geo-
metric mean of pπ is used as the ranking function,
averaged by the number of dependencies in D.
4 The Parser
</figure>
<bodyText confidence="0.98918025">
tence, what is the probability that the words are in a
particular dependency relationship?
We again follow Collins in defining the following
functions, where is the set of words in the data,
and is the set of lexical categories.
C ab cd for ac and bd is the number
of times that word-category pairs ab and cd are in
the same word-category sequence in the training data.
CR ab cd is the number of times that ab and
cd are in the same word-category sequence, with a and
c in dependency relation R.
FRab cd is the probability that a and c are in de-
pendency relation R, given thatab andcd are in the
same word-category sequence.
The relative frequency estimate of the probability
FRa b c d is as follows:
</bodyText>
<equation confidence="0.3337595">
ˆFRhfifi haicai
∑jn 1 ˆFRhfifi wjcj
</equation>
<bodyText confidence="0.992543696969697">
where cai is the lexical category of the argument
head ai. The normalising factor ensures that the
probabilities for each argument slot sum to one over
all the word-category pairs in the sequence.5 This
factor is constant for the given category sequence,
but not for different category sequences. However,
the dependency structures with high enough PCS
to be among the highest probability structures are
likely to have similar category sequences. Thus we
ignore the normalisation factor, thereby simplifying
the parsing process. (A similar argument is used by
Collins (1996) in the context of his parsing model.)
The estimate in equation 10 suffers from sparse
data problems, and so a backing-off strategy is em-
ployed. We omit details here, but there are four lev-
els of back-off: the first uses both words and both
categories; the second uses only one of the words
and both categories; the third uses the categories
only; and a final level substitutes pos-tags for the
categories.
One final point is that, in practice, the number of
dependencies can vary for a given category sequence
(because multiple arguments for the same slot can
5One of the problems with the model is that it is deficient, as-
signing probability mass to dependency structures not licensed
by the grammar.
The parser analyses a sentence in two stages. First,
in order to limit the number of categories assigned
to each word in the sentence, a “supertagger” (Ban-
galore and Joshi, 1999) assigns to each word a small
number of possible lexical categories. The supertag-
ger (described in Clark (2002)) assigns to each word
all categories whose probabilities are within some
constant factor, β, of the highest probability cate-
gory for that word, given the surrounding context.
Note that the supertagger does not provide a single
category sequence for each sentence, and the final
sequence returned by the parser (along with the de-
pendencies) is determined by the probability model
described in the previous section. The supertagger is
performing two roles: cutting down the search space
explored by the parser, and providing the category-
sequence model in equation 8.
The supertagger consults a “category dictionary”
which contains, for each word, the set of categories
the word was seen with in the data. If a word ap-
pears at least K times in the data, the supertagger
only considers categories that appear in the word’s
category set, rather than all lexical categories.
The second parsing stage applies a CKY
bottom-up chart-parsing algorithm, as described in
Steedman (2000). The combinatory rules currently
used by the parser are as follows: functional ap-
plication (forward and backward), generalised for-
ward composition, backward composition, gener-
alised backward-crossed composition, and type-
raising. There is also a coordination rule which con-
joins categories of the same type.6
Type-raising is applied to the categories NP, PP,
and Sadj NP (adjectival phrase); it is currently
implemented by simply adding pre-defined sets of
type-raised categories to the chart whenever an NP,
PP or Sadj NP is present. The sets were chosen
on the basis of the most frequent type-raising rule
instantiations in sections 02-21 of the CCGbank,
which resulted in 8 type-raised categories for NP,
</bodyText>
<footnote confidence="0.869212">
6Restrictions are placed on some of the rules, such as that
given by Steedman (2000) for backward-crossed composition
(p.62).
</footnote>
<figure confidence="0.7358664">
(10) ˆFR a b c d CR C a b cd
b cd
The probability PhaiC S can now be approxi-
mated as follows:
(11)PhaiCS
</figure>
<bodyText confidence="0.996449428571429">
and 2 categories each for PP and Sadj NP.
As well as combinatory rules, the parser also uses
a number of lexical rules and rules involving punc-
tuation. The set of rules consists of those occurring
roughly more than 200 times in sections 02-21 of the
CCGbank. For example, one rule used by the parser
is the following:
</bodyText>
<listItem confidence="0.76952">
(12) Sing NP NPX NPX
</listItem>
<bodyText confidence="0.999941545454546">
This rule creates a nominal modifier from an ing-
form of a verb phrase.
A set of rules allows the parser to deal with com-
mas (all other punctuation is removed after the su-
pertagging phase). For example, one kind of rule
treats a comma as a conjunct, which allows the NP
object in John likes apples, bananas and pears to
have three heads, which can all be direct objects of
like.7
The search space explored by the parser is re-
duced by exploiting the statistical model. First, a
constituent is only placed in a chart cell if there is
not already a constituent with the same head word,
same category, and some dependency structure with
a higher or equal score (where score is the geomet-
ric mean of the probability of the dependency struc-
ture). This tactic also has the effect of eliminat-
ing “spuriously ambiguous” entries from the chart—
cf. Komagata (1997). Second, a constituent is only
placed in a cell if the score for its dependency struc-
ture is within some factor, a, of the highest scoring
dependency structure for that cell.
</bodyText>
<sectionHeader confidence="0.999464" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999323">
Sections 02-21 of the CCGbank were used for train-
ing (39 161 sentences); section 00 for development
(1 901 sentences); and section 23 for testing (2 379
sentences).8 Sections 02-21 were also used to obtain
the category set, by including all categories that ap-
pear at least 10 times, which resulted in a set of 398
category types.
The word-category sequences needed for estimat-
ing the probabilities in equation 8 can be read di-
rectly from the CCGbank. To obtain dependencies
</bodyText>
<footnote confidence="0.764489166666667">
7These rules are currently applied deterministically. In fu-
ture work we will investigate approaches which integrate the
rule applications with the statistical model.
8A small number of sentences in the Penn
Treebank do not appear in the CCGbank (see
Hockenmaier and Steedman (2002a)).
</footnote>
<bodyText confidence="0.999981738095238">
for estimating PDC S , we ran the parser over the
trees, tracing out the combinatory rules applied dur-
ing the derivation, and outputting the dependencies.
This method was also applied to the trees in section
23 to provide the gold standard test set.
Not all trees produced dependency structures,
since not all categories and type-changing rules in
the CCGbank are encoded in the parser. We obtained
dependency structures for roughly 95% of the trees
in the data. For evaluation purposes, we increased
the coverage on section 23 to 990% (2 352 sen-
tences) by identifying the cause of the parse failures
and adding the additional rules and categories when
creating the gold-standard; so the final test set con-
sisted of gold-standard dependency structures from
2 352 sentences. The coverage was increased to en-
sure the test set was representative of the full section.
We emphasise that these additional rules and cate-
gories were not made available to the parser during
testing, or used for training.
Initially the parser was run with 0 001 for the
supertagger (an average of 38 categories per word),
K 20 for the category dictionary, and a 0001
for the parser. A time-out was applied so that the
parser was stopped if any sentence took longer than
2 CPU minutes to parse. With these parameters,
2 098 of the 2 352 sentences received some anal-
ysis, with 206 timing out and 48 failing to parse.
To deal with the 48 no-analysis cases, the cut-off
for the category-dictionary, K, was increased to 100.
Of the 48 cases, 23 sentences then received an anal-
ysis. To deal with the 206 time-out cases, 0 was
increased to 005, which resulted in 181 of the 206
sentences then receiving an analysis, with 18 failing
to parse, and 7 timing out. So overall, almost 98% of
the 2 352 unseen sentences were given some analy-
sis.
To return a single dependency structure, we chose
the most probable structure from the S dcl categories
spanning the whole sentence. If there was no such
category, all categories spanning the whole string
were considered.
</bodyText>
<sectionHeader confidence="0.999958" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999988608695652">
To measure the performance of the parser, we com-
pared the dependencies output by the parser with
those in the gold standard, and computed precision
and recall figures over the dependencies. Recall that
a dependency is defined as a 4-tuple: a head of a
functor, a functor category, an argument slot, and a
head of an argument. Figures were calculated for la-
belled dependencies (LP,LR) and unlabelled depen-
dencies (UP,UR). To obtain a point for a labelled de-
pendency, each element of the 4-tuple must match
exactly. Note that the category set we are using dis-
tinguishes around 400 distinct types; for example,
tensed transitive buy is treated as a distinct category
from infinitival transitive buy. Thus this evaluation
criterion is much more stringent than that for a stan-
dard pos-tag label-set (there are around 50 pos-tags
used in the Penn Treebank).
To obtain a point for an unlabelled dependency,
the heads of the functor and argument must appear
together in some relation (either as functor or argu-
ment) for the relevant sentence in the gold standard.
The results are shown in Table 1, with an additional
column giving the category accuracy.
</bodyText>
<table confidence="0.973509666666667">
LP % LR % UP % UR% category %
no A 813 821 891 901 906
with A 819 818 901 899 903
</table>
<tableCaption confidence="0.999749">
Table 1: Overall dependency results for section 23
</tableCaption>
<bodyText confidence="0.947027150684931">
As an additional experiment, we conditioned the
dependency probabilities in 10 on a “distance mea-
sure” (A). Distance has been shown to be a use-
ful feature for context-free treebank style parsers
(e.g. Collins (1996), Collins (1999)), although our
hypothesis was that it would be less useful here, be-
cause the CCG grammar provides many of the con-
straints given by A, and distance measures are biased
against long-range dependencies.
We tried a number of distance measures, and the
one used here encodes the relative position of the
heads of the argument and functor (left or right),
counts the number of verbs between argument and
functor (up to 1), and counts the number of punctu-
ation marks (up to 2). The results are also given in
Table 1, and show that, as expected, adding distance
gives no improvement overall.
An advantage of the dependency-based evalua-
tion is that results can be given for individual de-
pendency relations. Labelled precision and recall on
Section 00 for the most frequent dependency types
are shown in Table 2 (for the model without distance
measures).9 The columns # deps give the total num-
ber of dependencies, first the number put forward by
the parser, and second the number in the gold stan-
dard. F-score is calculated as (2*LP*LR)/(LP+LR).
We also give the scores for the dependencies cre-
ated by the subject and object relative pronoun cat-
egories, including the headless object relative pro-
noun category.
We would like to compare these results with those
of other parsers that have presented dependency-
based evaluations. However, the few that exist (Lin,
1995; Carroll et al., 1998; Collins, 1999) have used
either different data or different sets of dependen-
cies (or both). In future work we plan to map our
CCG dependencies onto the set used by Carroll and
Briscoe and parse their evaluation corpus so a direct
comparison can be made.
As far as long-range dependencies are concerned,
it is similarly hard to give a precise evaluation. Note
that the scores in Table 2 currently conflate extracted
and in-situ arguments, so that the scores for the di-
rect objects, for example, include extracted objects.
The scores for the relative pronoun categories give
a good indication of the performance on extraction
cases, although even here it is not possible at present
to determine exactly how well the parser is perform-
ing at recovering extracted arguments.
In an attempt to obtain a more thorough anal-
ysis, we analysed the performance of the parser
on the 24 cases of extracted objects in the gold-
standard Section 00 (development set) that were
passed down the object relative pronoun category
Sdcl✟
NPX NPX NPX .10 Of these, 10 (41.7%)
were recovered correctly by the parser; 10 were in-
correct because the wrong category was assigned to
the relative pronoun, 3 were incorrect because the
relative pronoun was attached to the wrong noun,
and 1 was incorrect because the wrong category was
assigned to the predicate from which the object was
9Currently all the modifiers in nominal compounds are anal-
ysed in CCGbank as N N, as a default, since the structure of the
compound is not present in the Penn Treebank. Thus the scores
for N N are not particularly informative. Removing these rela-
tions reduces the overall scores by around 2%. Also, the scores
in Table 2 are for around 95% of the sentences in Section 00, be-
cause of the problem obtaining gold standard dependency struc-
tures for all sentences, noted earlier.
10The number of extracted objects need not equal the occur-
rences of the category since coordination can introduce more
than one object per category.
</bodyText>
<table confidence="0.999852964285714">
Functor Relation LP % # deps LR % # deps F-score
NX NX,1 1 nominal modifier 929 6769 951 6610 94.0
NPX✍NX,1 1 determiner 957 3804 958 3800 95.7
NPX NPX,1 NP2 2 np modifying preposition 842 2046 773 2230 80.6
NPX NPX,1 NP2 1 np modifying preposition 758 2002 742 2045 75.0
SX NPY SX,1 NPY NP2 2 vp modifying preposition 603 1368 758 1089 67.2
SX NPY SX,1 NPY NP2 1 vp modifying preposition 548 1263 694 997 61.2
Sdcl☛ NP1 NP2 1 transitive verb 748 967 864 837 80.2
S dcl NP1 NP2 2 transitive verb 774 913 836 846 80.4
SX NPY SX,1 NPY 1 adverbial modifier 770 683 756 696 76.3
PP✍NP1 1 preposition complement 709 729 672 769 69.0
Sb NP1 NP2 2 infinitival transitive verb 821 608 854 584 83.7
Sdcl☛ NPX,1 Sb2 NPX 2 auxiliary 984 447 976 451 98.0
Sdcl☛ NPX,1 Sb2 NPX 1 auxiliary
921 455 917 457 91.9
Sb NP1 NP2 1 infinitival transitive verb 796 417 783 424 78.9
NPX NX,1 NP2 1 s genitive 932 366 945 361 93.8
NPX NX,1 NP2 2 s genitive 912 365 946 352 92.9
StoX NPYS bX,2 NPY 1 to-complementiser 856 320 811 338 83.3
S dcl NP1 S dcl☛2 1 sentential complement verb 871 372 900 360 88.5
Sdcl☛2 NPX 738 237 692 253 71.4
NPX NPX,1 1 subject relative pronoun
NPX NPX,1 2 subject relative pronoun 952 229 869 251 90.9
Sdcl☛2 NPX
Sdcl☛2 NPX 667 15 455 22 54.1
NPX NPX,1 1 object relative pronoun
NPX NPX,1 S dcl☛2 NPX 2 object relative pronoun 857 14 632 19 72.8
NP S dcl☛1 NP 1 headless object relative pronoun 1000 10 833 12 90.9
</table>
<tableCaption confidence="0.994586">
Table 2: Results for section 00 by dependency relation
</tableCaption>
<bodyText confidence="0.999938181818182">
extracted. The tendency for the parser to assign
the wrong category to the relative pronoun in part
reflects the fact that complementiser that is fifteen
times as frequent as object relative pronoun that.
However, the supertagger alone gets 74% of the ob-
ject relative pronouns correct, if it is used to provide
a single category per word, so it seems that our de-
pendency model is further biased against object ex-
tractions, possibly because of the technical unsound-
ness noted earlier.
It should be recalled in judging these figures that
they are only a first attempt at recovering these
long-range dependencies, which most other wide-
coverage parsers make no attempt to recover at all.
To get an idea of just how demanding this task is, it
is worth looking at an example of object relativiza-
tion that the parser gets correct. Figure 2 gives part
of a dependency structure returned by the parser for
a sentence from section 00 (with the relations omit-
ted).11 Notice that both respect and confidence are
objects of had. The relevant dependency quadruples
found by the parser are the following:
</bodyText>
<footnote confidence="0.945444">
11The full sentence is The events ofApril through June dam-
aged the respect and confidence which most Americans previ-
ously hadfor the leaders of China.
</footnote>
<note confidence="0.246084">
respect and confidence which most Americans previously had
</note>
<figureCaption confidence="0.9905145">
Figure 2: A dependency structure recovered by the
parser from unseen data
</figureCaption>
<figure confidence="0.503168">
(13) which ✠NPX NPX,1 Sdcl☛2 NPX 2had
which ✠NPX NPX,1 Sdcl☛2 NPX 1confidence
which ✠NPX NPX,1 Sdcl☛2 NPX 1respect
had Sdcl☛had NP1 NP2 2 confidence
had S dcl had NP1 NP22respect
</figure>
<sectionHeader confidence="0.984907" genericHeader="conclusions">
7 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.999977705882353">
This paper has shown that accurate, efficient wide-
coverage parsing is possible with CCG. Along with
Hockenmaier and Steedman (2002b), this is the first
CCG parsing work that we are aware of in which
almost 98% of unseen sentences from the CCGbank
can be parsed.
The parser is able to capture a number of long-
range dependencies that are not dealt with by ex-
isting treebank parsers. Capturing such dependen-
cies is necessary for any parser that aims to sup-
port wide-coverage semantic analysis—say to sup-
port question-answering in any domain in which the
difference between questions like Which company
did Marks sue? and Which company sued Marks?
matters. An advantage of our approach is that the
recovery of long-range dependencies is fully inte-
grated with the grammar and parser, rather than be-
ing relegated to a post-processing phase.
Because of the extreme naivety of the statistical
model, these results represent no more than a first
attempt at combining wide-coverage CCG parsing
with recovery of deep dependencies. However, we
believe that the results are promising.
In future work we will present an evaluation
which teases out the differences in extracted and in-
situ arguments. For the purposes of the statistical
modelling, we are also considering building alterna-
tive structures that include the long-range dependen-
cies, but which can be modelled using better moti-
vated probability models, such as generative mod-
els. This will be important for applying the parser to
tasks such as language modelling, for which the pos-
sibility of incremental processing of CCG appears
particularly attractive.
</bodyText>
<sectionHeader confidence="0.996007" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998922">
Thanks to Miles Osborne and the ACL-02 refer-
ees for comments. Various parts of the research
were funded by EPSRC grants GR/M96889 and
GR/R02450 and EU (FET) grant MAGICSTER.
</bodyText>
<sectionHeader confidence="0.99926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930265625">
Steven Abney. 1997. Stochastic attribute-value gram-
mars. Computational Linguistics, 23(4):597–618.
Srinivas Bangalore and Aravind Joshi. 1999. Supertag-
ging: An approach to almost parsing. Computational
Linguistics, 25(2):237–265.
John Carroll, Ted Briscoe, and Antonio Sanfilippo. 1998.
Parser evaluation: a survey and a new proposal. In
Proceedings of the 1st LREC Conference, pages 447–
454, Granada, Spain.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the 1st Meeting of the
NAACL, pages 132–139, Seattle, WA.
David Chiang. 2000. Statistical parsing with an
automatically-extracted Tree Adjoining Grammar. In
Proceedings of the 38th Meeting of the ACL, pages
456–463, Hong Kong.
Stephen Clark and Julia Hockenmaier. 2002. Evaluating
a wide-coverage CCG parser. In Proceedings of the
LREC Beyond PARSEVAL workshop (to appear), Las
Palmas, Spain.
Stephen Clark. 2002. A supertagger for Combinatory
Categorial Grammar. In Proceedings of the 6th Inter-
national Workshop on Tree Adjoining Grammars and
Related Frameworks (to appear), Venice, Italy.
Michael Collins. 1996. A new statistical parser based
on bigram lexical dependencies. In Proceedings of the
34th Meeting of the ACL, pages 184–191, Santa Cruz,
CA.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, Univer-
sity of Pennsylvania.
Jason Eisner. 1996a. Efficient normal-form parsing for
Combinatory Categorial Grammar. In Proceedings of
the 34th Meeting of the ACL, pages 79–86, Santa Cruz,
CA.
Jason Eisner. 1996b. Three new probabilistic models
for dependency parsing: An exploration. In Proceed-
ings of the 16th COLING Conference, pages 340–345,
Copenhagen, Denmark.
Julia Hockenmaier and Mark Steedman. 2002a. Acquir-
ing compact lexicalized grammars from a cleaner tree-
bank. In Proceedings of the Third LREC Conference
(to appear), Las Palmas, Spain.
Julia Hockenmaier and Mark Steedman. 2002b. Gener-
ative models for statistical parsing with Combinatory
Categorial Grammar. In Proceedings of the 40th Meet-
ing of the ACL (to appear), Philadelphia, PA.
Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi,
and Stefan Riezler. 1999. Estimators for stochastic
‘unification-based’ grammars. In Proceedings of the
37th Meeting of the ACL, pages 535–541, University
of Maryland, MD.
Nobo Komagata. 1997. Efficient parsing for CCGs with
generalized type-raised categories. In Proceedings of
the 5th International Workshop on Parsing Technolo-
gies, pages 135–146, Boston, MA.
Dekang Lin. 1995. A dependency-based method for
evaluating broad-coverage parsers. In Proceedings of
IJCAI-95, pages 1420–1425, Montreal, Canada.
Adwait Ratnaparkhi. 1996. A maximum entropy part-
of-speech tagger. In Proceedings of the EMNLP Con-
ference, pages 133–142, Philadelphia, PA.
Mark Steedman. 2000. The Syntactic Process. The MIT
Press, Cambridge, MA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.954374">
<title confidence="0.998663">Building Deep Dependency Structures with a Wide-Coverage CCG Parser</title>
<author confidence="0.983715">Julia Hockenmaier Steedman Clark</author>
<affiliation confidence="0.999935">Division of Informatics University of Edinburgh</affiliation>
<address confidence="0.998904">Edinburgh EH8 9LW, UK</address>
<email confidence="0.982403">stephenc,julia,steedman@cogsci.ed.ac.uk</email>
<abstract confidence="0.999334157894737">This paper describes a wide-coverage statistical parser that uses Combinatory Categorial Grammar (CCG) to derive dependency structures. The parser differs from most existing wide-coverage treebank parsers in capturing the long-range dependencies inherent in constructions such as coordination, extraction, raising and control, as well as the standard local predicate-argument dependencies. A set of dependency structures used for training and testing the parser is obtained from a treebank of CCG normal-form derivations, which have been derived (semi-) automatically from the Penn Treebank. The parser correctly recovers over 80% of labelled dependencies, and around 90% of unlabelled dependencies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
</authors>
<title>Stochastic attribute-value grammars.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>4</issue>
<contexts>
<context position="8645" citStr="Abney, 1997" startWordPosition="1373" endWordPosition="1374">. The corresponding dependencies are given in the following figure, with the convention that arcs point away from arguments. The relevant argument slot in the functor category labels the arcs. Note that we encode the subject argument of the to category as a dependency relation (Marks is a “subject” of to), since our philosophy at this stage is to encode every argument as a dependency, where possible. The number of dependency types may be reduced in future work. 3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques (Abney, 1997; Johnson et al., 1999), so we have defined a conditional model, similar to the model of Collins (1996) (see also the conditional model in Eisner (1996b)). While the model of Collins (1996) is technically unsound (Collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model. Future work will look at alternative models.4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories. We conjecture that it is possible to define a</context>
</contexts>
<marker>Abney, 1997</marker>
<rawString>Steven Abney. 1997. Stochastic attribute-value grammars. Computational Linguistics, 23(4):597–618.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Aravind Joshi</author>
</authors>
<title>Supertagging: An approach to almost parsing.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="13208" citStr="Bangalore and Joshi, 1999" startWordPosition="2168" endWordPosition="2172">e second uses only one of the words and both categories; the third uses the categories only; and a final level substitutes pos-tags for the categories. One final point is that, in practice, the number of dependencies can vary for a given category sequence (because multiple arguments for the same slot can 5One of the problems with the model is that it is deficient, assigning probability mass to dependency structures not licensed by the grammar. The parser analyses a sentence in two stages. First, in order to limit the number of categories assigned to each word in the sentence, a “supertagger” (Bangalore and Joshi, 1999) assigns to each word a small number of possible lexical categories. The supertagger (described in Clark (2002)) assigns to each word all categories whose probabilities are within some constant factor, β, of the highest probability category for that word, given the surrounding context. Note that the supertagger does not provide a single category sequence for each sentence, and the final sequence returned by the parser (along with the dependencies) is determined by the probability model described in the previous section. The supertagger is performing two roles: cutting down the search space exp</context>
</contexts>
<marker>Bangalore, Joshi, 1999</marker>
<rawString>Srinivas Bangalore and Aravind Joshi. 1999. Supertagging: An approach to almost parsing. Computational Linguistics, 25(2):237–265.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ted Briscoe</author>
<author>Antonio Sanfilippo</author>
</authors>
<title>Parser evaluation: a survey and a new proposal.</title>
<date>1998</date>
<booktitle>In Proceedings of the 1st LREC Conference,</booktitle>
<pages>447--454</pages>
<location>Granada,</location>
<contexts>
<context position="2854" citStr="Carroll et al. (1998)" startWordPosition="418" endWordPosition="421"> model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all? A CCG parser can directly build derived structures, including long1Another, more speculative, possibility is to treat the alternative derivations as hidden and apply the EM algorithm. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), Philadelphia, July 2002, pp</context>
<context position="22300" citStr="Carroll et al., 1998" startWordPosition="3716" endWordPosition="3719">equent dependency types are shown in Table 2 (for the model without distance measures).9 The columns # deps give the total number of dependencies, first the number put forward by the parser, and second the number in the gold standard. F-score is calculated as (2*LP*LR)/(LP+LR). We also give the scores for the dependencies created by the subject and object relative pronoun categories, including the headless object relative pronoun category. We would like to compare these results with those of other parsers that have presented dependencybased evaluations. However, the few that exist (Lin, 1995; Carroll et al., 1998; Collins, 1999) have used either different data or different sets of dependencies (or both). In future work we plan to map our CCG dependencies onto the set used by Carroll and Briscoe and parse their evaluation corpus so a direct comparison can be made. As far as long-range dependencies are concerned, it is similarly hard to give a precise evaluation. Note that the scores in Table 2 currently conflate extracted and in-situ arguments, so that the scores for the direct objects, for example, include extracted objects. The scores for the relative pronoun categories give a good indication of the </context>
</contexts>
<marker>Carroll, Briscoe, Sanfilippo, 1998</marker>
<rawString>John Carroll, Ted Briscoe, and Antonio Sanfilippo. 1998. Parser evaluation: a survey and a new proposal. In Proceedings of the 1st LREC Conference, pages 447– 454, Granada, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Meeting of the NAACL,</booktitle>
<pages>132--139</pages>
<location>Seattle, WA.</location>
<contexts>
<context position="1086" citStr="Charniak (2000)" startWordPosition="151" endWordPosition="152">ge dependencies inherent in constructions such as coordination, extraction, raising and control, as well as the standard local predicate-argument dependencies. A set of dependency structures used for training and testing the parser is obtained from a treebank of CCG normal-form derivations, which have been derived (semi-) automatically from the Penn Treebank. The parser correctly recovers over 80% of labelled dependencies, and around 90% of unlabelled dependencies. 1 Introduction Most recent wide-coverage statistical parsers have used models based on lexical dependencies (e.g. Collins (1999), Charniak (2000)). However, the dependencies are typically derived from a context-free phrase structure tree using simple head percolation heuristics. This approach does not work well for the long-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the Wall Street Journal. Chiang (2000) uses Tree Adjoining Grammar as an alternative to context-free grammar, and here we use another “mildly context-sensitive” formalism, Combinatory Categorial Grammar (CCG, Steedman (2000)), which arguably provides the most linguistically satisfactory account of th</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the 1st Meeting of the NAACL, pages 132–139, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Statistical parsing with an automatically-extracted Tree Adjoining Grammar.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Meeting of the ACL,</booktitle>
<pages>456--463</pages>
<location>Hong Kong.</location>
<contexts>
<context position="1423" citStr="Chiang (2000)" startWordPosition="202" endWordPosition="203">rom the Penn Treebank. The parser correctly recovers over 80% of labelled dependencies, and around 90% of unlabelled dependencies. 1 Introduction Most recent wide-coverage statistical parsers have used models based on lexical dependencies (e.g. Collins (1999), Charniak (2000)). However, the dependencies are typically derived from a context-free phrase structure tree using simple head percolation heuristics. This approach does not work well for the long-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the Wall Street Journal. Chiang (2000) uses Tree Adjoining Grammar as an alternative to context-free grammar, and here we use another “mildly context-sensitive” formalism, Combinatory Categorial Grammar (CCG, Steedman (2000)), which arguably provides the most linguistically satisfactory account of the dependencies inherent in coordinate constructions and extraction phenomena. The potential advantage from using such an expressive grammar is to facilitate recovery of such unbounded dependencies. As well as having a potential impact on the accuracy of the parser, recovering such dependencies may make the output more useful. CCG is un</context>
</contexts>
<marker>Chiang, 2000</marker>
<rawString>David Chiang. 2000. Statistical parsing with an automatically-extracted Tree Adjoining Grammar. In Proceedings of the 38th Meeting of the ACL, pages 456–463, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Evaluating a wide-coverage CCG parser.</title>
<date>2002</date>
<booktitle>In Proceedings of the LREC Beyond PARSEVAL workshop (to appear),</booktitle>
<location>Las Palmas,</location>
<contexts>
<context position="2778" citStr="Clark and Hockenmaier, 2002" startWordPosition="405" endWordPosition="408"> non-standard surface derivations. This impacts on how best to define a probability model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all? A CCG parser can directly build derived structures, including long1Another, more speculative, possibility is to treat the alternative derivations as hidden and apply the EM algorithm. Proceedings of the 40th Annual Meeting of the </context>
</contexts>
<marker>Clark, Hockenmaier, 2002</marker>
<rawString>Stephen Clark and Julia Hockenmaier. 2002. Evaluating a wide-coverage CCG parser. In Proceedings of the LREC Beyond PARSEVAL workshop (to appear), Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
</authors>
<title>A supertagger for Combinatory Categorial Grammar.</title>
<date>2002</date>
<booktitle>In Proceedings of the 6th International Workshop on Tree Adjoining Grammars and Related Frameworks (to appear),</booktitle>
<location>Venice, Italy.</location>
<contexts>
<context position="9917" citStr="Clark, 2002" startWordPosition="1592" endWordPosition="1593">arse selection component must choose the most probable dependency structure, given the sentence S. A sentence S w1t1 w2t2 wntn is assumed to be a sequence of word, pos-tag pairs. For our purposes, a dependency structure n is a C D pair, where C c1 c2 cn is the sequence of categories assigned to the words, and D hfi fi si hai i 1 m is the set of dependencies. The probability of a dependency structure can be written as follows: (7) Pn PCDS PCSPDCS The probability PCS can be approximated as follows: (8) PCS rjni 1 PciXi where Xi is the local context for the ith word. We have explained elsewhere (Clark, 2002) how suitable features can be defined in terms of the word, pos-tag pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi (1996). We assume that each argument slot in the category sequence is filled independently, and write PDC S as follows: rj m (9) PDC S☎ i 1 PhaiC S where hai is the head word filling the argument slot of the ith dependency, and m is the number of dependencies entailed by the category sequence C. 3.1 Estimating the dependency probabilities The estimation method is based on Collins (1996). We assume that the </context>
<context position="13319" citStr="Clark (2002)" startWordPosition="2189" endWordPosition="2190">s-tags for the categories. One final point is that, in practice, the number of dependencies can vary for a given category sequence (because multiple arguments for the same slot can 5One of the problems with the model is that it is deficient, assigning probability mass to dependency structures not licensed by the grammar. The parser analyses a sentence in two stages. First, in order to limit the number of categories assigned to each word in the sentence, a “supertagger” (Bangalore and Joshi, 1999) assigns to each word a small number of possible lexical categories. The supertagger (described in Clark (2002)) assigns to each word all categories whose probabilities are within some constant factor, β, of the highest probability category for that word, given the surrounding context. Note that the supertagger does not provide a single category sequence for each sentence, and the final sequence returned by the parser (along with the dependencies) is determined by the probability model described in the previous section. The supertagger is performing two roles: cutting down the search space explored by the parser, and providing the categorysequence model in equation 8. The supertagger consults a “catego</context>
</contexts>
<marker>Clark, 2002</marker>
<rawString>Stephen Clark. 2002. A supertagger for Combinatory Categorial Grammar. In Proceedings of the 6th International Workshop on Tree Adjoining Grammars and Related Frameworks (to appear), Venice, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>A new statistical parser based on bigram lexical dependencies.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Meeting of the ACL,</booktitle>
<pages>184--191</pages>
<location>Santa Cruz, CA.</location>
<contexts>
<context position="8748" citStr="Collins (1996)" startWordPosition="1391" endWordPosition="1392">int away from arguments. The relevant argument slot in the functor category labels the arcs. Note that we encode the subject argument of the to category as a dependency relation (Marks is a “subject” of to), since our philosophy at this stage is to encode every argument as a dependency, where possible. The number of dependency types may be reduced in future work. 3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques (Abney, 1997; Johnson et al., 1999), so we have defined a conditional model, similar to the model of Collins (1996) (see also the conditional model in Eisner (1996b)). While the model of Collins (1996) is technically unsound (Collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model. Future work will look at alternative models.4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories. We conjecture that it is possible to define a generative model that includes the deep dependencies. The parse selection component must choose the mo</context>
<context position="10496" citStr="Collins (1996)" startWordPosition="1696" endWordPosition="1697">e explained elsewhere (Clark, 2002) how suitable features can be defined in terms of the word, pos-tag pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi (1996). We assume that each argument slot in the category sequence is filled independently, and write PDC S as follows: rj m (9) PDC S☎ i 1 PhaiC S where hai is the head word filling the argument slot of the ith dependency, and m is the number of dependencies entailed by the category sequence C. 3.1 Estimating the dependency probabilities The estimation method is based on Collins (1996). We assume that the probability of a dependency only depends on those words involved in the dependency, together with their categories. We follow Collins and base the estimate of a dependency probability on the following intuition: given a pair of words, with a pair of categories, which are in the same sen2 2 2 2 The company that Marks wants to buy 1 1 1 1 1 be introduced through coordination), and so a geometric mean of pπ is used as the ranking function, averaged by the number of dependencies in D. 4 The Parser tence, what is the probability that the words are in a particular dependency rel</context>
<context position="12327" citStr="Collins (1996)" startWordPosition="2019" endWordPosition="2020">ws: ˆFRhfifi haicai ∑jn 1 ˆFRhfifi wjcj where cai is the lexical category of the argument head ai. The normalising factor ensures that the probabilities for each argument slot sum to one over all the word-category pairs in the sequence.5 This factor is constant for the given category sequence, but not for different category sequences. However, the dependency structures with high enough PCS to be among the highest probability structures are likely to have similar category sequences. Thus we ignore the normalisation factor, thereby simplifying the parsing process. (A similar argument is used by Collins (1996) in the context of his parsing model.) The estimate in equation 10 suffers from sparse data problems, and so a backing-off strategy is employed. We omit details here, but there are four levels of back-off: the first uses both words and both categories; the second uses only one of the words and both categories; the third uses the categories only; and a final level substitutes pos-tags for the categories. One final point is that, in practice, the number of dependencies can vary for a given category sequence (because multiple arguments for the same slot can 5One of the problems with the model is </context>
<context position="20906" citStr="Collins (1996)" startWordPosition="3483" endWordPosition="3484">abelled dependency, the heads of the functor and argument must appear together in some relation (either as functor or argument) for the relevant sentence in the gold standard. The results are shown in Table 1, with an additional column giving the category accuracy. LP % LR % UP % UR% category % no A 813 821 891 901 906 with A 819 818 901 899 903 Table 1: Overall dependency results for section 23 As an additional experiment, we conditioned the dependency probabilities in 10 on a “distance measure” (A). Distance has been shown to be a useful feature for context-free treebank style parsers (e.g. Collins (1996), Collins (1999)), although our hypothesis was that it would be less useful here, because the CCG grammar provides many of the constraints given by A, and distance measures are biased against long-range dependencies. We tried a number of distance measures, and the one used here encodes the relative position of the heads of the argument and functor (left or right), counts the number of verbs between argument and functor (up to 1), and counts the number of punctuation marks (up to 2). The results are also given in Table 1, and show that, as expected, adding distance gives no improvement overall.</context>
</contexts>
<marker>Collins, 1996</marker>
<rawString>Michael Collins. 1996. A new statistical parser based on bigram lexical dependencies. In Proceedings of the 34th Meeting of the ACL, pages 184–191, Santa Cruz, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="1069" citStr="Collins (1999)" startWordPosition="149" endWordPosition="150">ing the long-range dependencies inherent in constructions such as coordination, extraction, raising and control, as well as the standard local predicate-argument dependencies. A set of dependency structures used for training and testing the parser is obtained from a treebank of CCG normal-form derivations, which have been derived (semi-) automatically from the Penn Treebank. The parser correctly recovers over 80% of labelled dependencies, and around 90% of unlabelled dependencies. 1 Introduction Most recent wide-coverage statistical parsers have used models based on lexical dependencies (e.g. Collins (1999), Charniak (2000)). However, the dependencies are typically derived from a context-free phrase structure tree using simple head percolation heuristics. This approach does not work well for the long-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the Wall Street Journal. Chiang (2000) uses Tree Adjoining Grammar as an alternative to context-free grammar, and here we use another “mildly context-sensitive” formalism, Combinatory Categorial Grammar (CCG, Steedman (2000)), which arguably provides the most linguistically satisfact</context>
<context position="8873" citStr="Collins, 1999" startWordPosition="1411" endWordPosition="1412">argument of the to category as a dependency relation (Marks is a “subject” of to), since our philosophy at this stage is to encode every argument as a dependency, where possible. The number of dependency types may be reduced in future work. 3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques (Abney, 1997; Johnson et al., 1999), so we have defined a conditional model, similar to the model of Collins (1996) (see also the conditional model in Eisner (1996b)). While the model of Collins (1996) is technically unsound (Collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model. Future work will look at alternative models.4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories. We conjecture that it is possible to define a generative model that includes the deep dependencies. The parse selection component must choose the most probable dependency structure, given the sentence S. A sentence S w1t1 w2t2 wntn is assumed to be a sequence of word, pos-</context>
<context position="20922" citStr="Collins (1999)" startWordPosition="3485" endWordPosition="3486">cy, the heads of the functor and argument must appear together in some relation (either as functor or argument) for the relevant sentence in the gold standard. The results are shown in Table 1, with an additional column giving the category accuracy. LP % LR % UP % UR% category % no A 813 821 891 901 906 with A 819 818 901 899 903 Table 1: Overall dependency results for section 23 As an additional experiment, we conditioned the dependency probabilities in 10 on a “distance measure” (A). Distance has been shown to be a useful feature for context-free treebank style parsers (e.g. Collins (1996), Collins (1999)), although our hypothesis was that it would be less useful here, because the CCG grammar provides many of the constraints given by A, and distance measures are biased against long-range dependencies. We tried a number of distance measures, and the one used here encodes the relative position of the heads of the argument and functor (left or right), counts the number of verbs between argument and functor (up to 1), and counts the number of punctuation marks (up to 2). The results are also given in Table 1, and show that, as expected, adding distance gives no improvement overall. An advantage of</context>
<context position="22316" citStr="Collins, 1999" startWordPosition="3720" endWordPosition="3721">s are shown in Table 2 (for the model without distance measures).9 The columns # deps give the total number of dependencies, first the number put forward by the parser, and second the number in the gold standard. F-score is calculated as (2*LP*LR)/(LP+LR). We also give the scores for the dependencies created by the subject and object relative pronoun categories, including the headless object relative pronoun category. We would like to compare these results with those of other parsers that have presented dependencybased evaluations. However, the few that exist (Lin, 1995; Carroll et al., 1998; Collins, 1999) have used either different data or different sets of dependencies (or both). In future work we plan to map our CCG dependencies onto the set used by Carroll and Briscoe and parse their evaluation corpus so a direct comparison can be made. As far as long-range dependencies are concerned, it is similarly hard to give a precise evaluation. Note that the scores in Table 2 currently conflate extracted and in-situ arguments, so that the scores for the direct objects, for example, include extracted objects. The scores for the relative pronoun categories give a good indication of the performance on e</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Efficient normal-form parsing for Combinatory Categorial Grammar.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Meeting of the ACL,</booktitle>
<pages>79--86</pages>
<location>Santa Cruz, CA.</location>
<contexts>
<context position="2522" citStr="Eisner, 1996" startWordPosition="370" endWordPosition="372">ial impact on the accuracy of the parser, recovering such dependencies may make the output more useful. CCG is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standard surface derivations. This impacts on how best to define a probability model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build der</context>
<context position="8796" citStr="Eisner (1996" startWordPosition="1400" endWordPosition="1401">t in the functor category labels the arcs. Note that we encode the subject argument of the to category as a dependency relation (Marks is a “subject” of to), since our philosophy at this stage is to encode every argument as a dependency, where possible. The number of dependency types may be reduced in future work. 3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques (Abney, 1997; Johnson et al., 1999), so we have defined a conditional model, similar to the model of Collins (1996) (see also the conditional model in Eisner (1996b)). While the model of Collins (1996) is technically unsound (Collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model. Future work will look at alternative models.4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories. We conjecture that it is possible to define a generative model that includes the deep dependencies. The parse selection component must choose the most probable dependency structure, given the sent</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996a. Efficient normal-form parsing for Combinatory Categorial Grammar. In Proceedings of the 34th Meeting of the ACL, pages 79–86, Santa Cruz, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th COLING Conference,</booktitle>
<pages>340--345</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="2522" citStr="Eisner, 1996" startWordPosition="370" endWordPosition="372">ial impact on the accuracy of the parser, recovering such dependencies may make the output more useful. CCG is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standard surface derivations. This impacts on how best to define a probability model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build der</context>
<context position="8796" citStr="Eisner (1996" startWordPosition="1400" endWordPosition="1401">t in the functor category labels the arcs. Note that we encode the subject argument of the to category as a dependency relation (Marks is a “subject” of to), since our philosophy at this stage is to encode every argument as a dependency, where possible. The number of dependency types may be reduced in future work. 3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques (Abney, 1997; Johnson et al., 1999), so we have defined a conditional model, similar to the model of Collins (1996) (see also the conditional model in Eisner (1996b)). While the model of Collins (1996) is technically unsound (Collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model. Future work will look at alternative models.4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories. We conjecture that it is possible to define a generative model that includes the deep dependencies. The parse selection component must choose the most probable dependency structure, given the sent</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner. 1996b. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of the 16th COLING Conference, pages 340–345, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Acquiring compact lexicalized grammars from a cleaner treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third LREC Conference (to appear),</booktitle>
<location>Las Palmas,</location>
<contexts>
<context position="2595" citStr="Hockenmaier and Steedman (2002" startWordPosition="380" endWordPosition="383">ch dependencies may make the output more useful. CCG is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standard surface derivations. This impacts on how best to define a probability model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all? A CCG parser can directly build derived structu</context>
<context position="4117" citStr="Hockenmaier and Steedman, 2002" startWordPosition="601" endWordPosition="604">ese derived structures can be of any form we like—for example, they could in principle be standard Penn Treebank structures. Since we are interested in dependency-based parser evaluation, our parser currently builds dependency structures. Furthermore, since we want to model the dependencies in such structures, the probability model is defined over these structures rather than the derivation. The training and testing material for this CCG parser is a treebank of dependency structures, which have been derived from a set of CCG derivations developed for use with another (normal-form) CCG parser (Hockenmaier and Steedman, 2002b). The treebank of derivations, which we call CCGbank (Hockenmaier and Steedman, 2002a), was in turn derived (semi-)automatically from the handannotated Penn Treebank. 2 The Grammar In CCG, most language-specific aspects of the grammar are specified in the lexicon, in the form of syntactic categories that identify a lexical item as either a functor or argument. For the functors, the category specifies the type and directionality of the arguments and the type of the result. For example, the following category for the transitive verb bought specifies its first argument as a noun phrase (NP) to </context>
<context position="17369" citStr="Hockenmaier and Steedman (2002" startWordPosition="2870" endWordPosition="2873">ection 23 for testing (2 379 sentences).8 Sections 02-21 were also used to obtain the category set, by including all categories that appear at least 10 times, which resulted in a set of 398 category types. The word-category sequences needed for estimating the probabilities in equation 8 can be read directly from the CCGbank. To obtain dependencies 7These rules are currently applied deterministically. In future work we will investigate approaches which integrate the rule applications with the statistical model. 8A small number of sentences in the Penn Treebank do not appear in the CCGbank (see Hockenmaier and Steedman (2002a)). for estimating PDC S , we ran the parser over the trees, tracing out the combinatory rules applied during the derivation, and outputting the dependencies. This method was also applied to the trees in section 23 to provide the gold standard test set. Not all trees produced dependency structures, since not all categories and type-changing rules in the CCGbank are encoded in the parser. We obtained dependency structures for roughly 95% of the trees in the data. For evaluation purposes, we increased the coverage on section 23 to 990% (2 352 sentences) by identifying the cause of the parse fai</context>
<context position="27469" citStr="Hockenmaier and Steedman (2002" startWordPosition="4633" endWordPosition="4636">wing: 11The full sentence is The events ofApril through June damaged the respect and confidence which most Americans previously hadfor the leaders of China. respect and confidence which most Americans previously had Figure 2: A dependency structure recovered by the parser from unseen data (13) which ✠NPX NPX,1 Sdcl☛2 NPX 2had which ✠NPX NPX,1 Sdcl☛2 NPX 1confidence which ✠NPX NPX,1 Sdcl☛2 NPX 1respect had Sdcl☛had NP1 NP2 2 confidence had S dcl had NP1 NP22respect 7 Conclusions and Further Work This paper has shown that accurate, efficient widecoverage parsing is possible with CCG. Along with Hockenmaier and Steedman (2002b), this is the first CCG parsing work that we are aware of in which almost 98% of unseen sentences from the CCGbank can be parsed. The parser is able to capture a number of longrange dependencies that are not dealt with by existing treebank parsers. Capturing such dependencies is necessary for any parser that aims to support wide-coverage semantic analysis—say to support question-answering in any domain in which the difference between questions like Which company did Marks sue? and Which company sued Marks? matters. An advantage of our approach is that the recovery of long-range dependencies </context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002a. Acquiring compact lexicalized grammars from a cleaner treebank. In Proceedings of the Third LREC Conference (to appear), Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Generative models for statistical parsing with Combinatory Categorial Grammar.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Meeting of the ACL (to appear),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="2595" citStr="Hockenmaier and Steedman (2002" startWordPosition="380" endWordPosition="383">ch dependencies may make the output more useful. CCG is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standard surface derivations. This impacts on how best to define a probability model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all? A CCG parser can directly build derived structu</context>
<context position="4117" citStr="Hockenmaier and Steedman, 2002" startWordPosition="601" endWordPosition="604">ese derived structures can be of any form we like—for example, they could in principle be standard Penn Treebank structures. Since we are interested in dependency-based parser evaluation, our parser currently builds dependency structures. Furthermore, since we want to model the dependencies in such structures, the probability model is defined over these structures rather than the derivation. The training and testing material for this CCG parser is a treebank of dependency structures, which have been derived from a set of CCG derivations developed for use with another (normal-form) CCG parser (Hockenmaier and Steedman, 2002b). The treebank of derivations, which we call CCGbank (Hockenmaier and Steedman, 2002a), was in turn derived (semi-)automatically from the handannotated Penn Treebank. 2 The Grammar In CCG, most language-specific aspects of the grammar are specified in the lexicon, in the form of syntactic categories that identify a lexical item as either a functor or argument. For the functors, the category specifies the type and directionality of the arguments and the type of the result. For example, the following category for the transitive verb bought specifies its first argument as a noun phrase (NP) to </context>
<context position="17369" citStr="Hockenmaier and Steedman (2002" startWordPosition="2870" endWordPosition="2873">ection 23 for testing (2 379 sentences).8 Sections 02-21 were also used to obtain the category set, by including all categories that appear at least 10 times, which resulted in a set of 398 category types. The word-category sequences needed for estimating the probabilities in equation 8 can be read directly from the CCGbank. To obtain dependencies 7These rules are currently applied deterministically. In future work we will investigate approaches which integrate the rule applications with the statistical model. 8A small number of sentences in the Penn Treebank do not appear in the CCGbank (see Hockenmaier and Steedman (2002a)). for estimating PDC S , we ran the parser over the trees, tracing out the combinatory rules applied during the derivation, and outputting the dependencies. This method was also applied to the trees in section 23 to provide the gold standard test set. Not all trees produced dependency structures, since not all categories and type-changing rules in the CCGbank are encoded in the parser. We obtained dependency structures for roughly 95% of the trees in the data. For evaluation purposes, we increased the coverage on section 23 to 990% (2 352 sentences) by identifying the cause of the parse fai</context>
<context position="27469" citStr="Hockenmaier and Steedman (2002" startWordPosition="4633" endWordPosition="4636">wing: 11The full sentence is The events ofApril through June damaged the respect and confidence which most Americans previously hadfor the leaders of China. respect and confidence which most Americans previously had Figure 2: A dependency structure recovered by the parser from unseen data (13) which ✠NPX NPX,1 Sdcl☛2 NPX 2had which ✠NPX NPX,1 Sdcl☛2 NPX 1confidence which ✠NPX NPX,1 Sdcl☛2 NPX 1respect had Sdcl☛had NP1 NP2 2 confidence had S dcl had NP1 NP22respect 7 Conclusions and Further Work This paper has shown that accurate, efficient widecoverage parsing is possible with CCG. Along with Hockenmaier and Steedman (2002b), this is the first CCG parsing work that we are aware of in which almost 98% of unseen sentences from the CCGbank can be parsed. The parser is able to capture a number of longrange dependencies that are not dealt with by existing treebank parsers. Capturing such dependencies is necessary for any parser that aims to support wide-coverage semantic analysis—say to support question-answering in any domain in which the difference between questions like Which company did Marks sue? and Which company sued Marks? matters. An advantage of our approach is that the recovery of long-range dependencies </context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002b. Generative models for statistical parsing with Combinatory Categorial Grammar. In Proceedings of the 40th Meeting of the ACL (to appear), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
<author>Stuart Geman</author>
<author>Stephen Canon</author>
<author>Zhiyi Chi</author>
<author>Stefan Riezler</author>
</authors>
<title>Estimators for stochastic ‘unification-based’ grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Meeting of the ACL,</booktitle>
<pages>535--541</pages>
<institution>University of Maryland, MD.</institution>
<contexts>
<context position="8668" citStr="Johnson et al., 1999" startWordPosition="1375" endWordPosition="1378">onding dependencies are given in the following figure, with the convention that arcs point away from arguments. The relevant argument slot in the functor category labels the arcs. Note that we encode the subject argument of the to category as a dependency relation (Marks is a “subject” of to), since our philosophy at this stage is to encode every argument as a dependency, where possible. The number of dependency types may be reduced in future work. 3 The Probability Model The DAG-like nature of the dependency structures makes it difficult to apply generative modelling techniques (Abney, 1997; Johnson et al., 1999), so we have defined a conditional model, similar to the model of Collins (1996) (see also the conditional model in Eisner (1996b)). While the model of Collins (1996) is technically unsound (Collins, 1999), our aim at this stage is to demonstrate that accurate, efficient wide-coverage parsing is possible with CCG, even with an over-simplified statistical model. Future work will look at alternative models.4 4The reentrancies creating the DAG-like structures are fairly limited, and moreover determined by the lexical categories. We conjecture that it is possible to define a generative model that </context>
</contexts>
<marker>Johnson, Geman, Canon, Chi, Riezler, 1999</marker>
<rawString>Mark Johnson, Stuart Geman, Stephen Canon, Zhiyi Chi, and Stefan Riezler. 1999. Estimators for stochastic ‘unification-based’ grammars. In Proceedings of the 37th Meeting of the ACL, pages 535–541, University of Maryland, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobo Komagata</author>
</authors>
<title>Efficient parsing for CCGs with generalized type-raised categories.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th International Workshop on Parsing Technologies,</booktitle>
<pages>135--146</pages>
<location>Boston, MA.</location>
<contexts>
<context position="16425" citStr="Komagata (1997)" startWordPosition="2715" endWordPosition="2716"> conjunct, which allows the NP object in John likes apples, bananas and pears to have three heads, which can all be direct objects of like.7 The search space explored by the parser is reduced by exploiting the statistical model. First, a constituent is only placed in a chart cell if there is not already a constituent with the same head word, same category, and some dependency structure with a higher or equal score (where score is the geometric mean of the probability of the dependency structure). This tactic also has the effect of eliminating “spuriously ambiguous” entries from the chart— cf. Komagata (1997). Second, a constituent is only placed in a cell if the score for its dependency structure is within some factor, a, of the highest scoring dependency structure for that cell. 5 Experiments Sections 02-21 of the CCGbank were used for training (39 161 sentences); section 00 for development (1 901 sentences); and section 23 for testing (2 379 sentences).8 Sections 02-21 were also used to obtain the category set, by including all categories that appear at least 10 times, which resulted in a set of 398 category types. The word-category sequences needed for estimating the probabilities in equation </context>
</contexts>
<marker>Komagata, 1997</marker>
<rawString>Nobo Komagata. 1997. Efficient parsing for CCGs with generalized type-raised categories. In Proceedings of the 5th International Workshop on Parsing Technologies, pages 135–146, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>A dependency-based method for evaluating broad-coverage parsers.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI-95,</booktitle>
<pages>1420--1425</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="2828" citStr="Lin (1995)" startWordPosition="415" endWordPosition="416">e a probability model for CCG, since the “spurious ambiguity” of CCG derivations may lead to an exponential number of derivations for a given constituent. In addition, some of the spurious derivations may not be present in the training data. One solution is to consider only the normal-form (Eisner, 1996a) derivation, which is the route taken in Hockenmaier and Steedman (2002b).1 Another problem with the non-standard surface derivations is that the standard PARSEVAL performance measures over such derivations are uninformative (Clark and Hockenmaier, 2002). Such measures have been criticised by Lin (1995) and Carroll et al. (1998), who propose recovery of headdependencies characterising predicate-argument relations as a more meaningful measure. If the end-result of parsing is interpretable predicate-argument structure or the related dependency structure, then the question arises: why build derivation structure at all? A CCG parser can directly build derived structures, including long1Another, more speculative, possibility is to treat the alternative derivations as hidden and apply the EM algorithm. Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), P</context>
<context position="22278" citStr="Lin, 1995" startWordPosition="3714" endWordPosition="3715">the most frequent dependency types are shown in Table 2 (for the model without distance measures).9 The columns # deps give the total number of dependencies, first the number put forward by the parser, and second the number in the gold standard. F-score is calculated as (2*LP*LR)/(LP+LR). We also give the scores for the dependencies created by the subject and object relative pronoun categories, including the headless object relative pronoun category. We would like to compare these results with those of other parsers that have presented dependencybased evaluations. However, the few that exist (Lin, 1995; Carroll et al., 1998; Collins, 1999) have used either different data or different sets of dependencies (or both). In future work we plan to map our CCG dependencies onto the set used by Carroll and Briscoe and parse their evaluation corpus so a direct comparison can be made. As far as long-range dependencies are concerned, it is similarly hard to give a precise evaluation. Note that the scores in Table 2 currently conflate extracted and in-situ arguments, so that the scores for the direct objects, for example, include extracted objects. The scores for the relative pronoun categories give a g</context>
</contexts>
<marker>Lin, 1995</marker>
<rawString>Dekang Lin. 1995. A dependency-based method for evaluating broad-coverage parsers. In Proceedings of IJCAI-95, pages 1420–1425, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy partof-speech tagger.</title>
<date>1996</date>
<booktitle>In Proceedings of the EMNLP Conference,</booktitle>
<pages>133--142</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="10113" citStr="Ratnaparkhi (1996)" startWordPosition="1626" endWordPosition="1627">poses, a dependency structure n is a C D pair, where C c1 c2 cn is the sequence of categories assigned to the words, and D hfi fi si hai i 1 m is the set of dependencies. The probability of a dependency structure can be written as follows: (7) Pn PCDS PCSPDCS The probability PCS can be approximated as follows: (8) PCS rjni 1 PciXi where Xi is the local context for the ith word. We have explained elsewhere (Clark, 2002) how suitable features can be defined in terms of the word, pos-tag pairs in the context, and how maximum entropy techniques can be used to estimate the probabilities, following Ratnaparkhi (1996). We assume that each argument slot in the category sequence is filled independently, and write PDC S as follows: rj m (9) PDC S☎ i 1 PhaiC S where hai is the head word filling the argument slot of the ith dependency, and m is the number of dependencies entailed by the category sequence C. 3.1 Estimating the dependency probabilities The estimation method is based on Collins (1996). We assume that the probability of a dependency only depends on those words involved in the dependency, together with their categories. We follow Collins and base the estimate of a dependency probability on the follo</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy partof-speech tagger. In Proceedings of the EMNLP Conference, pages 133–142, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1609" citStr="Steedman (2000)" startWordPosition="227" endWordPosition="228">parsers have used models based on lexical dependencies (e.g. Collins (1999), Charniak (2000)). However, the dependencies are typically derived from a context-free phrase structure tree using simple head percolation heuristics. This approach does not work well for the long-range dependencies involved in raising, control, extraction and coordination, all of which are common in text such as the Wall Street Journal. Chiang (2000) uses Tree Adjoining Grammar as an alternative to context-free grammar, and here we use another “mildly context-sensitive” formalism, Combinatory Categorial Grammar (CCG, Steedman (2000)), which arguably provides the most linguistically satisfactory account of the dependencies inherent in coordinate constructions and extraction phenomena. The potential advantage from using such an expressive grammar is to facilitate recovery of such unbounded dependencies. As well as having a potential impact on the accuracy of the parser, recovering such dependencies may make the output more useful. CCG is unlike other formalisms in that the standard predicate-argument relations relevant to interpretation can be derived via extremely non-standard surface derivations. This impacts on how best</context>
<context position="5402" citStr="Steedman (2000)" startWordPosition="816" endWordPosition="817"> as a sentence: (1) bought := S NP NP For parsing purposes, we extend CCG categories to express category features, and head-word and dependency information directly, as follows: (2) bought := Sdclbought NP1 NP2 The feature dcl specifies the category’s S result as a declarative sentence, bought identifies its head, and the numbers denote dependency relations. Heads and dependencies are always marked up on atomic categories (S, N, NP, PP, and conj in our implementation). The categories are combined using a small set of typed combinatory rules, such as functional application and composition (see Steedman (2000) for details). Derivations are written as follows, with underlines indicating combinatory reduction and arrows indicating the direction of the application: (3) Marks bought Brooks NPMarks Sdcl�bought NP1 NP2 NPBrooks Sdcl bought NP1 Sdcl bought Formally, a dependency is defined as a 4-tuple: hf f s ha , where hf is the head word of the functor,2 f is the functor category (extended with head and dependency information), s is the argument slot, and ha is the head word of the argument—for example, the following is the object dependency yielded by the first step of derivation (3): (4) bought Sdcl </context>
<context position="14294" citStr="Steedman (2000)" startWordPosition="2345" endWordPosition="2346">e probability model described in the previous section. The supertagger is performing two roles: cutting down the search space explored by the parser, and providing the categorysequence model in equation 8. The supertagger consults a “category dictionary” which contains, for each word, the set of categories the word was seen with in the data. If a word appears at least K times in the data, the supertagger only considers categories that appear in the word’s category set, rather than all lexical categories. The second parsing stage applies a CKY bottom-up chart-parsing algorithm, as described in Steedman (2000). The combinatory rules currently used by the parser are as follows: functional application (forward and backward), generalised forward composition, backward composition, generalised backward-crossed composition, and typeraising. There is also a coordination rule which conjoins categories of the same type.6 Type-raising is applied to the categories NP, PP, and Sadj NP (adjectival phrase); it is currently implemented by simply adding pre-defined sets of type-raised categories to the chart whenever an NP, PP or Sadj NP is present. The sets were chosen on the basis of the most frequent type-raisi</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. The MIT Press, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>