<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000397">
<title confidence="0.983311">
LIMSI : Cross-lingual Word Sense Disambiguation using
Translation Sense Clustering
</title>
<author confidence="0.767899">
Marianna Apidianaki
</author>
<affiliation confidence="0.523312">
LIMSI-CNRS
Rue John Von Neumann
91403 Orsay Cedex, France
</affiliation>
<email confidence="0.996215">
marianna@limsi.fr
</email>
<sectionHeader confidence="0.998585" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9996829">
We describe the LIMSI system for the
SemEval-2013 Cross-lingual Word Sense Dis-
ambiguation (CLWSD) task. Word senses are
represented by means of translation clusters
in different languages built by a cross-lingual
Word Sense Induction (WSI) method. Our
CLWSD classifier exploits the WSI output for
selecting appropriate translations for target
words in context. We present the design of the
system and the obtained results.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999985333333334">
This paper describes the LIMSI system that partici-
pated in the Cross-Lingual Word Sense Disambigua-
tion (CLWSD) task of SemEval-2013. The goal of
CLWSD is to predict semantically correct transla-
tions for ambiguous words in context (Resnik and
Yarowsky, 2000; Carpuat and Wu, 2007; Apidi-
anaki, 2009). The CLWSD task of the SemEval-2013
evaluation campaign is a lexical sample task for En-
glish nouns and is divided into two subtasks: the
best subtask where systems are asked to provide a
unique good translation for words in context; the
out-of-five (oof) subtask where systems can propose
up to five semantically related translations for each
target word instance (Lefever and Hoste, 2013). The
CLWSD lexical sample contains 20 nouns and the
test set is composed of 50 instances per noun. Sys-
tem performance is evaluated by comparing the sys-
tem output to a set of gold standard annotations in
five languages: French, Spanish, Italian, Dutch and
German. Participating systems have to provide con-
textually appropriate translations for target words in
context in each or a subset of the target languages.
We apply the CLWSD method proposed by Apid-
ianaki (2009) to three bilingual tasks: English-
Spanish, English-French and English-Italian. The
method exploits the translation clusters generated in
the three target languages by a cross-lingual Word
Sense Induction (WSI) method. The WSI method
clusters the translations of target words in a parallel
corpus using source language context vectors. The
same vectors are exploited during disambiguation in
order to select the most appropriate translations for
new instances of the target words in context.
</bodyText>
<sectionHeader confidence="0.991806" genericHeader="method">
2 System Description
</sectionHeader>
<subsectionHeader confidence="0.991368">
2.1 Translation clustering
</subsectionHeader>
<bodyText confidence="0.999852588235294">
Contrary to monolingual WSI methods which group
the instances of the words into clusters describ-
ing their senses, the cross-lingual WSI method used
here clusters the translations of words in a paral-
lel corpus. The corpus used for French consists
of the English-French parts of Europarl (version 7)
(Koehn, 2005) and of the JRC-Acquis corpus (Stein-
berger et al., 2006), joined together. For English-
Spanish and English-Italian we only use the corre-
sponding parts of Europarl. The corpora are first
tokenized and lowercased using the Moses scripts,
then lemmatized and tagged by part-of-speech (PoS)
using the TreeTagger (Schmid, 1994). Words in the
corpus are replaced by a lemma and PoS tag pair be-
fore word alignment, to resolve categorical ambigu-
ities in context. The corpus is aligned in both trans-
lation directions with GIZA++ (Och and Ney, 2000)
</bodyText>
<page confidence="0.945475">
178
</page>
<bodyText confidence="0.591347">
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 178–182, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
</bodyText>
<figure confidence="0.7108494">
Target word
Italian
range
mood
mission
</figure>
<equation confidence="0.953427727272727">
{ensemble, diversit´e, palette,
nombre} {domaine} {port´ee}
{´eventail, nombre, gamme, s´erie,
ensemble}
{climat, atmosph`ere}, {esprit,
atmosph`ere, ambiance, humeur}
{opinion} {volont´e} {attitude}
{op´eration, mandat}
{d´el´egation, commission}
{d´el´egation, tˆache, voyage,
op´eration}
</equation>
<construct confidence="0.462646583333333">
{gama, serie, abanico,
diversidad, variedad, espectro,
conjunto} {cantidad, alcance,
`ambito, n´umero, tipo, espectro,
rango} {amplitud}
{clima, atm`osfera, ambiente}
{`animo, sentimiento} {talante}
{`animo, clima, ambiente}
{`animo, humor, ambiente}
{funci´on, cometido, objetivo,
tarea} {viaje, tarea, delegaci´on}
{tarea, mandato, cometido}
</construct>
<bodyText confidence="0.788667538461539">
{serie, gamma, spettro, numero,
ventaglio} {ampiezza, portata}
{settore, ambito}
{diversit´a, fascia}
{clima} {atmosfera}
{chiarezza, predisposizione}
{opinione} {atteggiamento}
{mandato, obiettivo, compito,
mission, funzione, operazione,}
{viaggio, mission, commissione,
delegazione}
French
Spanish
</bodyText>
<tableCaption confidence="0.996002">
Table 1: Sense clusters generated by the WSI method in the three languages.
</tableCaption>
<bodyText confidence="0.99991952173913">
and three bilingual lexicons are built from the align-
ment results (one for each language pair) containing
intersecting alignments. The lexicons contain noun
translations of each English target word in the three
languages. We keep French translations that trans-
late the target words at least 10 times in the train-
ing corpus; for Spanish and Italian, where the corpus
was smaller, the translation frequency threshold was
set to 5.
For each translation Ti of a word w, we extract the
content words that occur in the same sentence as w
whenever it is translated by Ti. These constitute the
features of the vector built for the translation. Let N
be the number of features retained for each Ti from
the corresponding source contexts. Each feature Fj
(1 G j G N) receives a total weight tw(Fj,Ti) de-
fined as the product of the feature’s global weight,
gw(Fj), and its local weight with that translation,
lw(Fj, Ti). The global weight of a feature Fj is a
function of the number Ni of translations (Ti’s) to
which Fj is related, and of the probabilities (pij) that
Fj co-occurs with instances of w translated by each
of the Ti’s:
</bodyText>
<equation confidence="0.9224885">
gw(Fj) = 1 − ETz pij log(pij) (1)
Ni
</equation>
<bodyText confidence="0.9999105">
Each of the pij’s is computed as the ratio between
the co-occurrence frequency of Fj with w when
translated as Ti, denoted as cooc frequency(Fj, Ti),
and the total number of features (N) seen with Ti:
</bodyText>
<equation confidence="0.846019333333333">
cooc frequency(Fj, Ti)
(2)
N
</equation>
<bodyText confidence="0.8157655">
The local weight lw(Fj, Ti) between Fj and Ti di-
rectly depends on their co-occurrence frequency:
</bodyText>
<equation confidence="0.999071">
lw(Fj,Ti) = log(cooc frequency(Fj,Ti)) (3)
</equation>
<bodyText confidence="0.999984461538462">
The pairwise similarity of the translation vectors
is calculated using the Weighted Jaccard Coeffi-
cient (Grefenstette, 1994). The similarity score of
each translation pair is compared to a threshold lo-
cally defined for each w, which serves to distinguish
strongly related translations from semantically un-
related ones. The semantically related translations
of a word w are then grouped into clusters. Trans-
lation pairs with a score above the threshold form a
set of initial clusters that might be further enriched
with other translations through an iterative proce-
dure, provided that there are other translations that
are strongly related to the elements in the cluster.1
The clustering stops when all the translations of w
have been clustered and all their relations have been
checked. The algorithm performs a soft clustering
so translations might be found in different clusters.
Final clusters are characterized by global connectiv-
ity, meaning that all their elements are linked by per-
tinent relations. Table 1 gives examples of clusters
generated for CLWSD target words in the three lan-
guages. The clusters group translations carrying the
same sense and their overlaps describe relations be-
tween senses. The translation clusters serve as the
target words’ candidate senses from which one has
to be selected during disambiguation.
</bodyText>
<footnote confidence="0.945756333333333">
1The thresholding procedure and the clustering algorithm
are described in detail in Apidianaki and He (2010).
pij =
</footnote>
<page confidence="0.967815">
179
</page>
<table confidence="0.999518125">
Subtask Metric Spanish Best LIMSI French Best Italian Best
LIMSI Baseline system Baseline system LIMSI Baseline system
Best P/R 24,7 23,23 32,16 24,56 25,73 30,11 21,2 20,21 25,66
Mode P/R 32,09 27,48 37,11 22,16 20,19 26,62 23,06 19,88 31,61
OOF P/R 49,01 53,07 61,69 45,37 51,35 59,8 40,25 42,62 53,57
Mode P/R 51,41 57,34 64,65 39,54 47,42 57,57 47,21 41,68 56,61
OOF P/R 98,6 - - 101,75 - - 90,23 - -
(dupl) Mode P/R 51,41 - - 39,54 - - 47,21 - -
</table>
<tableCaption confidence="0.999642">
Table 2: Results at the SemEval 2013 CLWSD task.
</tableCaption>
<subsectionHeader confidence="0.997256">
2.2 Word Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.999831166666667">
The vectors used for clustering the translations also
serve for disambiguating new instances of the tar-
get words in context. The new contexts are tok-
enized, lowercased, PoS tagged and lemmatized to
facilitate comparison with the vectors. We use the
features shared by each pair of clustered transla-
tions, or the vector corresponding to the translation
in an one-element cluster. If no CFs exist between
the new context and a pair of translations, WSD is
performed by comparing context information sep-
arately to the vector of each clustered translation.
Once the common features (CFs) between the vec-
tors and the new context are identified, a score is
calculated corresponding to the mean of the weights
of the CFs with the translations (weights assigned to
the features during WSI). In formula 4, CFj is the
set of CFs and NCF is the number of translations Ti
characterized by a CF.
</bodyText>
<equation confidence="0.68674075">
NCF
wsd score = Ei 1 Ej w(Ti, CFj)
(4)
NCF ��CFj�
</equation>
<bodyText confidence="0.999937142857143">
The cluster containing the highest ranked transla-
tion or translation pair is selected and assigned to
the new target word instance. If the translations are
present in more than one clusters, a new score is cal-
culated using equation 4 and by taking into account
the weights of the CFs with the other translations
(Ti’s) in the cluster.
</bodyText>
<sectionHeader confidence="0.999381" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999924425">
Systems participating to the CLWSD task have to
provide the most plausible translation for a word
in context in the best subtask, and five semanti-
cally correct translations in oof. The baselines pro-
vided by the organizers are based on the output of
GIZA++ alignments on Europarl. The best base-
line corresponds to the most frequent translation of
the target word in the corpus and the oof baseline
to the five most frequent translations. Our CLWSD
system makes predictions in three languages for all
1000 test instances. If the selected cluster contains
five translations, all of them are proposed in the
oof subtask while if it is bigger, the five most fre-
quent translations are selected. In case of smaller
clusters, the best translation is repeated in the out-
put until reaching five suggestions. Duplicate sug-
gestions were allowed in previous cross-lingual Se-
mEval tasks as a means to boost translations with
high confidence (Mihalcea et al., 2010). However,
as in this year’s CLWSD task the oof system output
has been post-processed by the organizers to keep
only unique translations, the number of predictions
made by our system for some words has been signif-
icantly reduced. This has had a negative impact on
the oof results, as we will show in the next section.
For selecting best translations, each translation of
a target word w is scored separately by comparing its
vector to the new context. In case the highest-ranked
translation has a score lower than 1, the system falls
back to using the most frequent translation (MFT).
To note that frequency information differs from the
one used in the MFT baseline because words in our
corpus were replaced by a lemma and PoS tag pair
prior to alignment. The discrepancy is more ap-
parent in French where MFT is the most frequent
translation of the target word in the joint Europarl
and JRC-Acquis corpus. Five teams participated to
the CLWSD task with a varying number of systems:
twelve systems provided output for Spanish and ten
for French and Italian.
</bodyText>
<page confidence="0.997708">
180
</page>
<sectionHeader confidence="0.999949" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.988136978723404">
The results obtained by our system for the best
and oof evaluations in the three languages (Span-
ish, French and Italian) are presented in Table 2. We
contrast them with the baselines provided by the or-
ganizers and with the score of the system that per-
formed best in each subtask. Our system made sug-
gestions for all test instances, so recall (R) coincides
with precision (P). The baselines are quite challeng-
ing, as noted in Lefever and Hoste (2010), especially
the oof one which contains the five most frequent
Europarl translations. These often correspond to the
most frequent translations from different sense clus-
ters and cover multiple senses of the target word.
Our system outperforms the best baseline in all
languages except for French, where the best score
lies near below the baseline. This is not surprising
given that the training corpus for French is the joint
Europarl and JRC-Acquis corpus, which causes a
discrepancy between the selected best translations
and the baseline. The mode precision and recall
scores reflect the capacity of the system to predict
the translations that were most frequently selected
by the annotators for each instance and are thus con-
sidered as the most plausible ones. Our system out-
performs the mode best baselines for all languages.
In the oof task, the system has been penalized
by the elimination of duplicate translations from
the output after submission. In previous work, the
CLWSD system gave very good results when applied,
with some slight variations, to the out-of-ten subtask
of the SemEval-2010 Cross-Lingual Lexical Substi-
tution task where duplicates served to promote trans-
lations with high confidence (Mihalcea et al., 2010;
Apidianaki, 2011). Here, after the post-processing
step, oof suggestions contain in many cases less than
five translations which explains the low scores. In
Table 2 we provide oof results before and after post-
processing the output and show how the system was
affected by this change in evaluation. By boosting
plausible translations, precision and recall scores get
higher while mode scores are naturally not affected.2
As the other systems might have been impacted to
different extents by this change, we cannot estimate
2Precision scores might be inflated, as in the case of French,
because the credit for each item is not divided by the number of
predictions and the annotation frequencies are used.
how this affects the global system ranking.
</bodyText>
<sectionHeader confidence="0.895787" genericHeader="conclusions">
5 Discussion and future work
</sectionHeader>
<bodyText confidence="0.999975068181818">
We presented a CLWSD system that uses translation
clusters as candidate senses. Disambiguation is per-
formed by comparing the feature vectors that served
for clustering to the context of new target word in-
stances. We observe that the use of a bigger cor-
pus – as in the case of French – not only does not
help in this task but actually has a negative impact
on the results. This is due to the inclusion of transla-
tions that are not present in the gold standard (built
from Europarl) and to the discrepancy between most
frequent translations in the large corpus and the Eu-
roparl MFT baselines. This discrepancy affects all
three languages, as words in the training corpora
were replaced by lemma and PoS tag pairs prior to
alignment.
It is important to note that our CLWSD method ex-
ploits the output of another unsupervised semantic
analysis method (WSI) which groups the translations
into clusters. This is an important feature of the sys-
tem and affects the results in two ways. First, the
translation clusters of a word constitute its candi-
date senses from which the CLWSD method selects
the most appropriate one for a given context. This
means that no variation regarding the contents of a
cluster is permitted and that different instances are
tagged by the same set of translations, contrary to
the gold standard annotations which might, at the
same time, be very close and contain some varia-
tions. In the system output, this is the case only
when overlapping clusters are selected for different
instances. Moreover, given that the WSI method is
automatic and that the clusters are not manually val-
idated, the noise that might be introduced during
clustering is propagated and reflected in the disam-
biguation results. So, if a cluster contains one or
more noisy translations, these occur in the disam-
biguation output and naturally count as wrong pre-
dictions. However, in an application setting like
Machine Translation (MT), the translation clusters
could be filtered using information from the target
language context. Future work will focus on inte-
grating this method into MT systems and examining
ways for optimally taking advantage of CLWSD pre-
dictions in this context.
</bodyText>
<page confidence="0.997876">
181
</page>
<sectionHeader confidence="0.996284" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9995515">
Marianna Apidianaki and Yifan He. 2010. An algorithm
for cross-lingual sense clustering tested in a MT eval-
uation setting. In Proceedings of the 7th International
Workshop on Spoken Language Translation (IWSLT-
10), pages 219–226, Paris, France.
Marianna Apidianaki. 2009. Data-driven Semantic
Analysis for Multilingual WSD and Lexical Selection
in Translation. In Proceedings of the 12th Confer-
ence of the European Chapter of the Association for
Computational Linguistics (EACL-09), pages 77–85,
Athens, Greece.
Marianna Apidianaki. 2011. Unsupervised Cross-
Lingual Lexical Substitution. In Proceedings of the
First workshop on Unsupervised Learning in NLP in
conjunction with EMNLP, pages 13–23, Edinburgh,
Scotland, July. Association for Computational Lin-
guistics.
Marine Carpuat and Dekai Wu. 2007. Improving statisti-
cal machine translation using word sense disambigua-
tion. In EMNLP-CoNLL, pages 61–72.
Gregory Grefenstette. 1994. Explorations in Automatic
Thesaurus Discovery. Kluwer Academic Publishers,
Norwell, MA.
Philipp Koehn. 2005. Europarl: A Parallel Corpus for
Statistical Machine Translation. In Proceedings of MT
Summit X, pages 79–86, Phuket, Thailand.
Els Lefever and Veronique Hoste. 2010. SemEval-2010
Task 3: Cross-lingual Word Sense Disambiguation.
In Proceedings of the 5th International Workshop on
Semantic Evaluations (SemEval-2), ACL 2010, pages
15–20, Uppsala, Sweden.
Els Lefever and V´eronique Hoste. 2013. SemEval-2013
Task 10: Cross-Lingual Word Sense Disambiguation.
In Proceedings of the 7th International Workshop on
Semantic Evaluation (SemEval 2013), in conjunction
with the Second Joint Conference on Lexical and Com-
putational Semantcis (*SEM 2013), pages 63–72, At-
lanta, USA.
Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010.
SemEval-2010 Task 2: Cross-Lingual Lexical Sub-
stitution. In Proceedings of the 5th International
Workshop on Semantic Evaluations (SemEval-2), ACL
2010, pages 9–14, Uppsala, Sweden.
Franz Josef Och and Hermann Ney. 2000. Im-
proved statistical alignment models. In Proceedings
of the 38th Annual Meeting of the Association for
Computational Linguistics (ACL’00), pages 440–447,
Hongkong, China.
Philip Resnik and David Yarowsky. 2000. Distinguish-
ing Systems and Distinguishing Senses: New Evalua-
tion Methods for Word Sense Disambiguation. Natu-
ral Language Engineering, 5(3):113–133.
Helmut Schmid. 1994. Probabilistic Part-of-Speech Tag-
ging Using Decision Trees. In Proceedings of the In-
ternational Conference on New Methods in Language
Processing, pages 44–49, Manchester, UK.
Ralf Steinberger, Bruno Pouliquen, Anna Widiger,
Camelia Ignat, Tomaˇz Erjavec, and Dan Tufis¸. 2006.
The JRC-Acquis: A multilingual aligned parallel cor-
pus with 20+ languages. In Proceedings of the 5th
International Conference on Language Resources and
Evaluation (LREC’2006), pages 2142–2147.
</reference>
<page confidence="0.997999">
182
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.705319">
<title confidence="0.998218">LIMSI : Cross-lingual Word Sense Disambiguation using Translation Sense Clustering</title>
<author confidence="0.9165635">Marianna Rue John Von</author>
<address confidence="0.857603">91403 Orsay Cedex,</address>
<email confidence="0.985158">marianna@limsi.fr</email>
<abstract confidence="0.999545454545455">describe the for the SemEval-2013 Cross-lingual Word Sense Distask. Word senses are represented by means of translation clusters in different languages built by a cross-lingual Sense Induction method. Our exploits the for selecting appropriate translations for target words in context. We present the design of the system and the obtained results.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
<author>Yifan He</author>
</authors>
<title>An algorithm for cross-lingual sense clustering tested in a MT evaluation setting.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Workshop on Spoken Language Translation (IWSLT10),</booktitle>
<pages>219--226</pages>
<location>Paris, France.</location>
<contexts>
<context position="7447" citStr="Apidianaki and He (2010)" startWordPosition="1122" endWordPosition="1125">lustering so translations might be found in different clusters. Final clusters are characterized by global connectivity, meaning that all their elements are linked by pertinent relations. Table 1 gives examples of clusters generated for CLWSD target words in the three languages. The clusters group translations carrying the same sense and their overlaps describe relations between senses. The translation clusters serve as the target words’ candidate senses from which one has to be selected during disambiguation. 1The thresholding procedure and the clustering algorithm are described in detail in Apidianaki and He (2010). pij = 179 Subtask Metric Spanish Best LIMSI French Best Italian Best LIMSI Baseline system Baseline system LIMSI Baseline system Best P/R 24,7 23,23 32,16 24,56 25,73 30,11 21,2 20,21 25,66 Mode P/R 32,09 27,48 37,11 22,16 20,19 26,62 23,06 19,88 31,61 OOF P/R 49,01 53,07 61,69 45,37 51,35 59,8 40,25 42,62 53,57 Mode P/R 51,41 57,34 64,65 39,54 47,42 57,57 47,21 41,68 56,61 OOF P/R 98,6 - - 101,75 - - 90,23 - - (dupl) Mode P/R 51,41 - - 39,54 - - 47,21 - - Table 2: Results at the SemEval 2013 CLWSD task. 2.2 Word Sense Disambiguation The vectors used for clustering the translations also serv</context>
</contexts>
<marker>Apidianaki, He, 2010</marker>
<rawString>Marianna Apidianaki and Yifan He. 2010. An algorithm for cross-lingual sense clustering tested in a MT evaluation setting. In Proceedings of the 7th International Workshop on Spoken Language Translation (IWSLT10), pages 219–226, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
</authors>
<title>Data-driven Semantic Analysis for Multilingual WSD and Lexical Selection in Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09),</booktitle>
<pages>77--85</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="923" citStr="Apidianaki, 2009" startWordPosition="132" endWordPosition="134">e represented by means of translation clusters in different languages built by a cross-lingual Word Sense Induction (WSI) method. Our CLWSD classifier exploits the WSI output for selecting appropriate translations for target words in context. We present the design of the system and the obtained results. 1 Introduction This paper describes the LIMSI system that participated in the Cross-Lingual Word Sense Disambiguation (CLWSD) task of SemEval-2013. The goal of CLWSD is to predict semantically correct translations for ambiguous words in context (Resnik and Yarowsky, 2000; Carpuat and Wu, 2007; Apidianaki, 2009). The CLWSD task of the SemEval-2013 evaluation campaign is a lexical sample task for English nouns and is divided into two subtasks: the best subtask where systems are asked to provide a unique good translation for words in context; the out-of-five (oof) subtask where systems can propose up to five semantically related translations for each target word instance (Lefever and Hoste, 2013). The CLWSD lexical sample contains 20 nouns and the test set is composed of 50 instances per noun. System performance is evaluated by comparing the system output to a set of gold standard annotations in five l</context>
</contexts>
<marker>Apidianaki, 2009</marker>
<rawString>Marianna Apidianaki. 2009. Data-driven Semantic Analysis for Multilingual WSD and Lexical Selection in Translation. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL-09), pages 77–85, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marianna Apidianaki</author>
</authors>
<title>Unsupervised CrossLingual Lexical Substitution.</title>
<date>2011</date>
<booktitle>In Proceedings of the First workshop on Unsupervised Learning in NLP in conjunction with EMNLP,</booktitle>
<pages>13--23</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="12993" citStr="Apidianaki, 2011" startWordPosition="2064" endWordPosition="2065">ions that were most frequently selected by the annotators for each instance and are thus considered as the most plausible ones. Our system outperforms the mode best baselines for all languages. In the oof task, the system has been penalized by the elimination of duplicate translations from the output after submission. In previous work, the CLWSD system gave very good results when applied, with some slight variations, to the out-of-ten subtask of the SemEval-2010 Cross-Lingual Lexical Substitution task where duplicates served to promote translations with high confidence (Mihalcea et al., 2010; Apidianaki, 2011). Here, after the post-processing step, oof suggestions contain in many cases less than five translations which explains the low scores. In Table 2 we provide oof results before and after postprocessing the output and show how the system was affected by this change in evaluation. By boosting plausible translations, precision and recall scores get higher while mode scores are naturally not affected.2 As the other systems might have been impacted to different extents by this change, we cannot estimate 2Precision scores might be inflated, as in the case of French, because the credit for each item</context>
</contexts>
<marker>Apidianaki, 2011</marker>
<rawString>Marianna Apidianaki. 2011. Unsupervised CrossLingual Lexical Substitution. In Proceedings of the First workshop on Unsupervised Learning in NLP in conjunction with EMNLP, pages 13–23, Edinburgh, Scotland, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marine Carpuat</author>
<author>Dekai Wu</author>
</authors>
<title>Improving statistical machine translation using word sense disambiguation.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>61--72</pages>
<contexts>
<context position="904" citStr="Carpuat and Wu, 2007" startWordPosition="128" endWordPosition="131">) task. Word senses are represented by means of translation clusters in different languages built by a cross-lingual Word Sense Induction (WSI) method. Our CLWSD classifier exploits the WSI output for selecting appropriate translations for target words in context. We present the design of the system and the obtained results. 1 Introduction This paper describes the LIMSI system that participated in the Cross-Lingual Word Sense Disambiguation (CLWSD) task of SemEval-2013. The goal of CLWSD is to predict semantically correct translations for ambiguous words in context (Resnik and Yarowsky, 2000; Carpuat and Wu, 2007; Apidianaki, 2009). The CLWSD task of the SemEval-2013 evaluation campaign is a lexical sample task for English nouns and is divided into two subtasks: the best subtask where systems are asked to provide a unique good translation for words in context; the out-of-five (oof) subtask where systems can propose up to five semantically related translations for each target word instance (Lefever and Hoste, 2013). The CLWSD lexical sample contains 20 nouns and the test set is composed of 50 instances per noun. System performance is evaluated by comparing the system output to a set of gold standard an</context>
</contexts>
<marker>Carpuat, Wu, 2007</marker>
<rawString>Marine Carpuat and Dekai Wu. 2007. Improving statistical machine translation using word sense disambiguation. In EMNLP-CoNLL, pages 61–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Explorations in Automatic Thesaurus Discovery.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Norwell, MA.</location>
<contexts>
<context position="6129" citStr="Grefenstette, 1994" startWordPosition="918" endWordPosition="919">obabilities (pij) that Fj co-occurs with instances of w translated by each of the Ti’s: gw(Fj) = 1 − ETz pij log(pij) (1) Ni Each of the pij’s is computed as the ratio between the co-occurrence frequency of Fj with w when translated as Ti, denoted as cooc frequency(Fj, Ti), and the total number of features (N) seen with Ti: cooc frequency(Fj, Ti) (2) N The local weight lw(Fj, Ti) between Fj and Ti directly depends on their co-occurrence frequency: lw(Fj,Ti) = log(cooc frequency(Fj,Ti)) (3) The pairwise similarity of the translation vectors is calculated using the Weighted Jaccard Coefficient (Grefenstette, 1994). The similarity score of each translation pair is compared to a threshold locally defined for each w, which serves to distinguish strongly related translations from semantically unrelated ones. The semantically related translations of a word w are then grouped into clusters. Translation pairs with a score above the threshold form a set of initial clusters that might be further enriched with other translations through an iterative procedure, provided that there are other translations that are strongly related to the elements in the cluster.1 The clustering stops when all the translations of w </context>
</contexts>
<marker>Grefenstette, 1994</marker>
<rawString>Gregory Grefenstette. 1994. Explorations in Automatic Thesaurus Discovery. Kluwer Academic Publishers, Norwell, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A Parallel Corpus for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of MT Summit X,</booktitle>
<pages>79--86</pages>
<location>Phuket, Thailand.</location>
<contexts>
<context position="2631" citStr="Koehn, 2005" startWordPosition="401" endWordPosition="402">ers the translations of target words in a parallel corpus using source language context vectors. The same vectors are exploited during disambiguation in order to select the most appropriate translations for new instances of the target words in context. 2 System Description 2.1 Translation clustering Contrary to monolingual WSI methods which group the instances of the words into clusters describing their senses, the cross-lingual WSI method used here clusters the translations of words in a parallel corpus. The corpus used for French consists of the English-French parts of Europarl (version 7) (Koehn, 2005) and of the JRC-Acquis corpus (Steinberger et al., 2006), joined together. For EnglishSpanish and English-Italian we only use the corresponding parts of Europarl. The corpora are first tokenized and lowercased using the Moses scripts, then lemmatized and tagged by part-of-speech (PoS) using the TreeTagger (Schmid, 1994). Words in the corpus are replaced by a lemma and PoS tag pair before word alignment, to resolve categorical ambiguities in context. The corpus is aligned in both translation directions with GIZA++ (Och and Ney, 2000) 178 Second Joint Conference on Lexical and Computational Sema</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A Parallel Corpus for Statistical Machine Translation. In Proceedings of MT Summit X, pages 79–86, Phuket, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>Veronique Hoste</author>
</authors>
<title>SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2), ACL 2010,</booktitle>
<pages>15--20</pages>
<location>Uppsala,</location>
<contexts>
<context position="11740" citStr="Lefever and Hoste (2010)" startWordPosition="1866" endWordPosition="1869">s corpus. Five teams participated to the CLWSD task with a varying number of systems: twelve systems provided output for Spanish and ten for French and Italian. 180 4 Results The results obtained by our system for the best and oof evaluations in the three languages (Spanish, French and Italian) are presented in Table 2. We contrast them with the baselines provided by the organizers and with the score of the system that performed best in each subtask. Our system made suggestions for all test instances, so recall (R) coincides with precision (P). The baselines are quite challenging, as noted in Lefever and Hoste (2010), especially the oof one which contains the five most frequent Europarl translations. These often correspond to the most frequent translations from different sense clusters and cover multiple senses of the target word. Our system outperforms the best baseline in all languages except for French, where the best score lies near below the baseline. This is not surprising given that the training corpus for French is the joint Europarl and JRC-Acquis corpus, which causes a discrepancy between the selected best translations and the baseline. The mode precision and recall scores reflect the capacity o</context>
</contexts>
<marker>Lefever, Hoste, 2010</marker>
<rawString>Els Lefever and Veronique Hoste. 2010. SemEval-2010 Task 3: Cross-lingual Word Sense Disambiguation. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2), ACL 2010, pages 15–20, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Els Lefever</author>
<author>V´eronique Hoste</author>
</authors>
<title>SemEval-2013 Task 10: Cross-Lingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantcis (*SEM</booktitle>
<pages>63--72</pages>
<location>Atlanta, USA.</location>
<contexts>
<context position="1313" citStr="Lefever and Hoste, 2013" startWordPosition="194" endWordPosition="197">Cross-Lingual Word Sense Disambiguation (CLWSD) task of SemEval-2013. The goal of CLWSD is to predict semantically correct translations for ambiguous words in context (Resnik and Yarowsky, 2000; Carpuat and Wu, 2007; Apidianaki, 2009). The CLWSD task of the SemEval-2013 evaluation campaign is a lexical sample task for English nouns and is divided into two subtasks: the best subtask where systems are asked to provide a unique good translation for words in context; the out-of-five (oof) subtask where systems can propose up to five semantically related translations for each target word instance (Lefever and Hoste, 2013). The CLWSD lexical sample contains 20 nouns and the test set is composed of 50 instances per noun. System performance is evaluated by comparing the system output to a set of gold standard annotations in five languages: French, Spanish, Italian, Dutch and German. Participating systems have to provide contextually appropriate translations for target words in context in each or a subset of the target languages. We apply the CLWSD method proposed by Apidianaki (2009) to three bilingual tasks: EnglishSpanish, English-French and English-Italian. The method exploits the translation clusters generate</context>
</contexts>
<marker>Lefever, Hoste, 2013</marker>
<rawString>Els Lefever and V´eronique Hoste. 2013. SemEval-2013 Task 10: Cross-Lingual Word Sense Disambiguation. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantcis (*SEM 2013), pages 63–72, Atlanta, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Ravi Sinha</author>
<author>Diana McCarthy</author>
</authors>
<title>SemEval-2010 Task 2: Cross-Lingual Lexical Substitution.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2), ACL 2010,</booktitle>
<pages>9--14</pages>
<location>Uppsala,</location>
<contexts>
<context position="10220" citStr="Mihalcea et al., 2010" startWordPosition="1601" endWordPosition="1604">nt translation of the target word in the corpus and the oof baseline to the five most frequent translations. Our CLWSD system makes predictions in three languages for all 1000 test instances. If the selected cluster contains five translations, all of them are proposed in the oof subtask while if it is bigger, the five most frequent translations are selected. In case of smaller clusters, the best translation is repeated in the output until reaching five suggestions. Duplicate suggestions were allowed in previous cross-lingual SemEval tasks as a means to boost translations with high confidence (Mihalcea et al., 2010). However, as in this year’s CLWSD task the oof system output has been post-processed by the organizers to keep only unique translations, the number of predictions made by our system for some words has been significantly reduced. This has had a negative impact on the oof results, as we will show in the next section. For selecting best translations, each translation of a target word w is scored separately by comparing its vector to the new context. In case the highest-ranked translation has a score lower than 1, the system falls back to using the most frequent translation (MFT). To note that fr</context>
<context position="12974" citStr="Mihalcea et al., 2010" startWordPosition="2060" endWordPosition="2063">to predict the translations that were most frequently selected by the annotators for each instance and are thus considered as the most plausible ones. Our system outperforms the mode best baselines for all languages. In the oof task, the system has been penalized by the elimination of duplicate translations from the output after submission. In previous work, the CLWSD system gave very good results when applied, with some slight variations, to the out-of-ten subtask of the SemEval-2010 Cross-Lingual Lexical Substitution task where duplicates served to promote translations with high confidence (Mihalcea et al., 2010; Apidianaki, 2011). Here, after the post-processing step, oof suggestions contain in many cases less than five translations which explains the low scores. In Table 2 we provide oof results before and after postprocessing the output and show how the system was affected by this change in evaluation. By boosting plausible translations, precision and recall scores get higher while mode scores are naturally not affected.2 As the other systems might have been impacted to different extents by this change, we cannot estimate 2Precision scores might be inflated, as in the case of French, because the c</context>
</contexts>
<marker>Mihalcea, Sinha, McCarthy, 2010</marker>
<rawString>Rada Mihalcea, Ravi Sinha, and Diana McCarthy. 2010. SemEval-2010 Task 2: Cross-Lingual Lexical Substitution. In Proceedings of the 5th International Workshop on Semantic Evaluations (SemEval-2), ACL 2010, pages 9–14, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved statistical alignment models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL’00),</booktitle>
<pages>440--447</pages>
<location>Hongkong, China.</location>
<contexts>
<context position="3169" citStr="Och and Ney, 2000" startWordPosition="487" endWordPosition="490">rench consists of the English-French parts of Europarl (version 7) (Koehn, 2005) and of the JRC-Acquis corpus (Steinberger et al., 2006), joined together. For EnglishSpanish and English-Italian we only use the corresponding parts of Europarl. The corpora are first tokenized and lowercased using the Moses scripts, then lemmatized and tagged by part-of-speech (PoS) using the TreeTagger (Schmid, 1994). Words in the corpus are replaced by a lemma and PoS tag pair before word alignment, to resolve categorical ambiguities in context. The corpus is aligned in both translation directions with GIZA++ (Och and Ney, 2000) 178 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 178–182, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics Target word Italian range mood mission {ensemble, diversit´e, palette, nombre} {domaine} {port´ee} {´eventail, nombre, gamme, s´erie, ensemble} {climat, atmosph`ere}, {esprit, atmosph`ere, ambiance, humeur} {opinion} {volont´e} {attitude} {op´eration, mandat} {d´el´egation, commission} {d´el´egation, tˆache, voyage, op´eration} {gama, serie, </context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved statistical alignment models. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL’00), pages 440–447, Hongkong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>David Yarowsky</author>
</authors>
<title>Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="882" citStr="Resnik and Yarowsky, 2000" startWordPosition="124" endWordPosition="127">Sense Disambiguation (CLWSD) task. Word senses are represented by means of translation clusters in different languages built by a cross-lingual Word Sense Induction (WSI) method. Our CLWSD classifier exploits the WSI output for selecting appropriate translations for target words in context. We present the design of the system and the obtained results. 1 Introduction This paper describes the LIMSI system that participated in the Cross-Lingual Word Sense Disambiguation (CLWSD) task of SemEval-2013. The goal of CLWSD is to predict semantically correct translations for ambiguous words in context (Resnik and Yarowsky, 2000; Carpuat and Wu, 2007; Apidianaki, 2009). The CLWSD task of the SemEval-2013 evaluation campaign is a lexical sample task for English nouns and is divided into two subtasks: the best subtask where systems are asked to provide a unique good translation for words in context; the out-of-five (oof) subtask where systems can propose up to five semantically related translations for each target word instance (Lefever and Hoste, 2013). The CLWSD lexical sample contains 20 nouns and the test set is composed of 50 instances per noun. System performance is evaluated by comparing the system output to a s</context>
</contexts>
<marker>Resnik, Yarowsky, 2000</marker>
<rawString>Philip Resnik and David Yarowsky. 2000. Distinguishing Systems and Distinguishing Senses: New Evaluation Methods for Word Sense Disambiguation. Natural Language Engineering, 5(3):113–133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic Part-of-Speech Tagging Using Decision Trees.</title>
<date>1994</date>
<booktitle>In Proceedings of the International Conference on New Methods in Language Processing,</booktitle>
<pages>44--49</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="2952" citStr="Schmid, 1994" startWordPosition="450" endWordPosition="451">gual WSI methods which group the instances of the words into clusters describing their senses, the cross-lingual WSI method used here clusters the translations of words in a parallel corpus. The corpus used for French consists of the English-French parts of Europarl (version 7) (Koehn, 2005) and of the JRC-Acquis corpus (Steinberger et al., 2006), joined together. For EnglishSpanish and English-Italian we only use the corresponding parts of Europarl. The corpora are first tokenized and lowercased using the Moses scripts, then lemmatized and tagged by part-of-speech (PoS) using the TreeTagger (Schmid, 1994). Words in the corpus are replaced by a lemma and PoS tag pair before word alignment, to resolve categorical ambiguities in context. The corpus is aligned in both translation directions with GIZA++ (Och and Ney, 2000) 178 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 178–182, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics Target word Italian range mood mission {ensemble, diversit´e, palette, nombre} {domaine} {port´ee} {´eventail, nombre, gamme, s</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic Part-of-Speech Tagging Using Decision Trees. In Proceedings of the International Conference on New Methods in Language Processing, pages 44–49, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Steinberger</author>
<author>Bruno Pouliquen</author>
<author>Anna Widiger</author>
<author>Camelia Ignat</author>
<author>Tomaˇz Erjavec</author>
<author>Dan Tufis¸</author>
</authors>
<title>The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC’2006),</booktitle>
<pages>2142--2147</pages>
<marker>Steinberger, Pouliquen, Widiger, Ignat, Erjavec, Tufis¸, 2006</marker>
<rawString>Ralf Steinberger, Bruno Pouliquen, Anna Widiger, Camelia Ignat, Tomaˇz Erjavec, and Dan Tufis¸. 2006. The JRC-Acquis: A multilingual aligned parallel corpus with 20+ languages. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC’2006), pages 2142–2147.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>