<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006374">
<title confidence="0.99439">
Improving Translation through Contextual Information
</title>
<author confidence="0.987692">
Maite Taboada-
</author>
<affiliation confidence="0.985038">
Carnegie Mellon University
</affiliation>
<address confidence="0.777998">
.5000 Forbes Avenue
Pittsburgh. PA 15213
</address>
<email confidence="0.952645">
taboada+Ocmu.edu
</email>
<sectionHeader confidence="0.996676" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954">
This paper proposes a two-layered model
of dialogue structure for task-oriented di-
alogues that processes contextual informa-
tion and disambiguates speech acts. The
final goal is to improve translation quality
in a speech-to-speech translation system.
</bodyText>
<sectionHeader confidence="0.945152" genericHeader="method">
1 Ambiguity in Speech Translation
</sectionHeader>
<bodyText confidence="0.999767433333333">
For any given utterance out of what we can loosely
call context, there is usually more than one possible
interpretation. A speaker&apos;s utterance of an ellipti-
cal expression, like the figure &amp;quot;twelve fifteen&amp;quot;, might
have a different meaning depending on the context of
situation, the way the conversation has evolved un-
til that point, and the previous speaker&apos;s utterance.
&amp;quot;Twelve fifteen&amp;quot; could be the time &amp;quot;a quarter after
twelve&amp;quot;, the price &amp;quot;one thousand two hundred and
fifteen- the room number &amp;quot;one two one five&amp;quot;, and so
on. Although English can conflate all those possible
meanings into one expression. the translation into
other languages usually requires more specificity.
If this is a problem for any human listener, the
problem grows considerably when it is a parser do-
ing the disambiguation. In this paper. I explain how
we can use discourse knowledge in order to help a
parser disambiguate among different possible parses
for an input sentence, with the final goal of improv-
ing the translation in an end-to-end speech transla-
tion system.
The work described was conducted within the
JANUS multi-lingual speech-to-speech translation
system designed to. translate spontaneous dialogue
in a limited domain (Lavie et al.. 1996). The
machine translation component of JANUS handles
these problems using two different approaches: the
Generalized Left-to-Right parser GLR* (Lavie and
Tomita, 1993) and Phoenix. the latter being the fo-
cus of this paper.
</bodyText>
<listItem confidence="0.219610333333333">
•The author gratefully acknowledges support from -la
Caixa&amp;quot; Fellowship Program. ATR Interpreting Labora-
tories. and Project Enthusiast.
</listItem>
<sectionHeader confidence="0.96476" genericHeader="method">
2 Disambiguation through
Contextual Information
</sectionHeader>
<bodyText confidence="0.999974571428571">
This project addresses the problem of choosing the
most appropriate semantic parse for any given in-
put. The approach is to combine discourse informa-
tion with the set of possible parses provided by the
Phoenix parser for an input string. The discourse
module selects one of these possibilities. The deci-
sion is to be based on:
</bodyText>
<listItem confidence="0.825878285714286">
1. The domain of the dialogue. JANUS deals
with dialogues restricted to a domain, such as
scheduling an appointment or making travel ar-
rangements. The general topic provides some
information about what types of exchanges, and
therefore speech acts, can be expected.
2. The macro-structure of the dialogue up to that
point. We can divide a dialogue into smaller,
self-contained units that provide information on
what phases are over or yet to be covered: Are
we past the greeting phase? If a flight was re-
served, should we expect a payment phase at
some point in the rest of the conversation&apos;?
3. The structure of adjacency pairs (Schegloff and
</listItem>
<bodyText confidence="0.918007210526316">
Sacks, 1973), together with the responses to
speech functions (Halliday, 1994; Martin. 1992).
If one speaker has uttered a request for infor-
mation, we expect some sort of response to that
— an answer, a disclaimer or a clarification.
The domain of the dialogues, named travel plan-
ning domain, consists of dialogues where a customer
makes travel arrangements with a travel agent or
a hotel clerk to book hotel rooms, flights or other
forms of transportation. They are task-oriented di-
alogues. in which the speakers have specific goals of
carrying out a task that involves the exchange of
both information and services.
Discourse processing is structured in two different
levels: the context module keeps a global history of
the conversation, from which it will be able to esti-
mate, for instance, the likelihood of a greeting once
the opening phase of the conversation is over. A
more local history predicts the expected response in
</bodyText>
<page confidence="0.966673">
510
</page>
<bodyText confidence="0.958216904761905">
any adjacency pair. such as a question-answer se-
quence. The model adopted here is that of a two-
layered finite state machine (henceforth FSM). and
the approach is that of late-stage disambiguation.
where as much information as possible is collected
before proceeding on to disambiguation. rather than
restricting the parser&apos;s search earlier on.
3 Representation of Speech Acts in
Phoenix
Writing the appropriate grammars and deciding on
the set of speech acts for this domain is also an im-
portant part of this project. The selected speech
acts are encoded in the grammar — in the Phoenix
case. a semantic grammar — the tokens of which
are concepts that the segment in question represents.
Any utterance is divided into SDUs — Semantic Di-
alogue Units — which are fed to the parser one at a
time. SDL&apos;s represent a full concept. expression. or
thought. but not necessarily a complete grammati-
cal sentence. Let us take an example input, and a
possible parse for it:
</bodyText>
<equation confidence="0.697993166666667">
(1) Could you tell me the prices at the Holiday Inn?
((request) (COULD YOU
([request-info) (TELL ME
qprice-infol (THE PRICES
([establishment) (AT THE
,[establishment-name] (HOLIDAY INN))))))))))
</equation>
<bodyText confidence="0.999701">
The top-level concepts of the grammar are speech
acts themselves, the ones immediately after are fur-
ther refinements of the speech act, and the lower
level concepts capture the specifics of the utterance.
such as the name of the hotel in the above example.
</bodyText>
<sectionHeader confidence="0.986466" genericHeader="method">
4 The Discourse Processor
</sectionHeader>
<bodyText confidence="0.999902782608696">
The discourse module processes the global and lo-
cal structure of the dialogue in two different lay-
ers. The first one is a general organization of
the dialogue&apos;s subparts: the layer under that pro-
esses the possible sequence of speech acts in a
subpart. The assumption is that negotiation di-
alogues develop in a predictable way — this as-
sumption was also made for scheduling dialogues in
the Verbmobil project (Maier. 1996) —. with three
clear phases: initialization. negotiation. and clos-
ing. We will call the middle phase in our dialogues
the task performance phase, since it is not always
a negotiation per se. Within the task performance
phase very many subdialogues can take place. such
as information-seeking, decision-making, payment.
clarification. etc.
Discourse processing has frequently made use of
sequences of speech acts as they occur in the dia-
logue. through bigram probabilities of occurrences.
or through modelling in a finite state machine.
Maier. 1996: Reithinger et al.. 1996: 1ida and Ya-
niaoka. 1990: Qu et al.. 1996). However, taking into
account only the speech act of the previous segment
</bodyText>
<figure confidence="0.9931419">
Phoenix Parser
&apos;UMW. y
Pune Tr. i
Pursc race .
Discourse Module
Gimlet Structure
multt,..usu
Local structure
FinalCho
I Pane Tree
</figure>
<figureCaption confidence="0.999998">
Figure 1: The Discourse Module
</figureCaption>
<bodyText confidence="0.976496464285714">
might leave us with insufficient information to decide
— as is the case in some elliptical utterances which
do not follow a strict adjacency pair sequence:
(2) (talking about flight times...)
Si I can give you the arrival time. Do you
have that information already?
S2 No. I don&apos;t.
Si It&apos;s twelve fifteen.
If we are in parsing the segment &amp;quot;It&apos;s twelve fif-
teen&amp;quot;. and our only source of information is the pre-
vious segment. &amp;quot;No. I don&apos;t&amp;quot;. we cannot possibly
find the referent for &amp;quot;twelve fifteen&amp;quot;, unless we know
we are in a subdialogue discussing flight times, and
arrival times have been previously mentioned.
Our approach aims at obtaining information both
from the subdialogue structure and the speech act
sequence by modelling the global structure of the di-
alogue with a FSM. with opening and closing as
initial and final states. and other possible subdia-
logues in the intervening states. Each one of those
states contains a FSM itself. which determines the
allowed speech acts in a given subdialogue and their
sequence. For a picture of the discourse component
here proposed. see Figure 1.
Let us look at another example where the use
of information on the previous context and on the
speaker alternance will help choose the most appro-
priate parse and thus achieve a better translation.
</bodyText>
<page confidence="0.993579">
511
</page>
<bodyText confidence="0.999183">
The expression &amp;quot;okay&amp;quot; can be a prompt for an an-
swer (3), an acceptance of a previous offer (4) or
a backchanneling element, i.e., an acknowledgement
that the previous speaker&apos;s utterance has been un-
derstood (5).
</bodyText>
<listItem confidence="0.9982584">
(3) SI So we&apos;ll switch you to a double room, okay?
(4) SI So we&apos;ll switch you to a double room.
S2 Okay.
(5) SI The double room is $90 a night.
S2 Okay, and how much is a single room?
</listItem>
<bodyText confidence="0.999733258064516">
In example (3), we will know that &amp;quot;okay&amp;quot; is a
prompt, because it is uttered by the speaker after
he or she has made a suggestion. In example (4), it
will be an acceptance because it is uttered after the
previous speaker&apos;s suggestion. And in (5) it is an
acknowledgment of the information provided. The
correct assignment of speech acts will provide a more
accurate translation into other languages.
To summarize, the two-layered FSM models a con-
versation through transitions of speech acts that are
included in subdialogues. When the parser returns
an ambiguity in the form of two or more possible
speech acts, the FSM will help decide which one is
the most appropriate given the context.
There are situations where the path followed in
the two layers of the structure does not match the
parse possibility we are trying to accept or reject.
One such situation is the presence of clarification
and correction subdialogues at any point in the con-
versation. In that case, the processor will try to
jump to the upper layer, in order to switch the sub-
dialogue under consideration. We also take into ac-
count the situation where there is no possible choice,
either because the FSNI does not restrict the choice
— i.e., the FSM allows all the parses returned by
the parser — or because the model does not allow
any of them. In either of those cases, the transition
is determined by unigram probabilities of the speech
act in isolation, and bigrams of the combination of
the speech act we are trying to disambiguate plus its
predecessor.
</bodyText>
<sectionHeader confidence="0.997756" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.98762">
The discourse module is being developed on a set of
29 dialogues, totalling 1,393 utterances. An evalu-
ation will be performed on 10 dialogues, previously
unseen by the discourse module. Since the mod-
ule can be either incorporated into the system, or
turned off, the evaluation will be on the system&apos;s
performance with and without the discourse module.
Independent graders assign a grade to the quality
of the translation&apos;. A secondary evaluation will be
&apos;The final results of this evaluation will be available
at the time of the ACL conference.
based on the quality of the speech act disambigua-
tion itself, regardless of its contribution to transla-
tion quality.
</bodyText>
<sectionHeader confidence="0.962477" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999854076923077">
In this paper I have presented a model of dialogue
structure in two layers, which processes the sequence
of subdialogues and speech acts in task-oriented
dialogues in order to select the most appropriate
from the ambiguous parses returned by the Phoenix
parser. The model structures dialogue in two lev-
els of finite state machines, with the final goal of
improving translation quality.
A possible extension to the work here described
would be to generalize the two-layer model to other.
less homogeneous domains. The use of statistical
information in different parts of the processing, such
as the arcs of the FSM, could enhance performance.
</bodyText>
<sectionHeader confidence="0.997822" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999170114285714">
Michael A. K. Halliday. 1994. An Introduction to Func-
tional Grammar. Edward Arnold, London (2nd edi-
tion).
Hitoshi lida and Takyuki Yamaoka. 1990. Dialogue
Structure Analysis Method and Its Application to Pre-
dicting the Next Utterance. Dialogue Structure Anal-
ysis. German-Japanese Workshop, Kyoto, Japan.
Alon Lavie, Donna Gates, Marsal Gavalda, Laura May-
field, Alex Waibel, Lori Levin. 1996. Multi-lingual
Translation of Spontaneously Spoken Language in a
Limited Domain. In Proceedings of COLING 96.
Copenhagen.
Alon Lavie and Masaru Tomita. 1993. GLR*: An Ef-
ficient Noise Skipping Parsing Algorithm for Context
Free Grammars. In Proceedings of the Third Interna-
tional Workshop on Parsing Technologies, IWPT 93,
Tilburg, The Netherlands.
Elisabeth Maier. 1996. Context Construction as Sub-
task of Dialogue Processing: The Verbmobil Case. In
Proceedings of the Eleventh Twente Workshop on Lan-
guage Technology. T4VLT 11.
James Martin. 1992. English Text: System and Struc-
ture. John Benjamins. Philadelphia/Amsterdam.
Yan Qu, Barbara Di Eugenio, Alon Lavie, Lori Levin.
1996. Minimizing Cumulative Error in Discourse Con-
text. In Proceedings of ECA I 96, Budapest, Hungary.
Norbert Reithinger, Ralf Engel, Michael Kipp. Martin
Klesen. 1996. Predicting Dialogue Acts for a Speech-
to-Speech Translation System. In Proceedings of IC-
SLP 96, Philadelphia, USA.
Emmanuel Schegloff and Harvey Sacks. 1973. Opening
up Closings. Semiotica 7, pages 289-327.
Wayne Ward. 1991. Understanding Spontaneous
Speech: the Phoenix System. In Proceedings of
ICASSP 91.
</reference>
<page confidence="0.996914">
512
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.030945">
<title confidence="0.93598">Improving Translation through Contextual Information</title>
<affiliation confidence="0.997602">Carnegie Mellon University</affiliation>
<address confidence="0.9991665">5000 Forbes Avenue Pittsburgh. PA 15213</address>
<email confidence="0.998457">taboada+Ocmu.edu</email>
<abstract confidence="0.987528931451614">This paper proposes a two-layered model of dialogue structure for task-oriented dialogues that processes contextual information and disambiguates speech acts. The final goal is to improve translation quality in a speech-to-speech translation system. 1 Ambiguity in Speech Translation For any given utterance out of what we can loosely is usually more than one possible interpretation. A speaker&apos;s utterance of an elliptical expression, like the figure &amp;quot;twelve fifteen&amp;quot;, might have a different meaning depending on the context of situation, the way the conversation has evolved until that point, and the previous speaker&apos;s utterance. &amp;quot;Twelve fifteen&amp;quot; could be the time &amp;quot;a quarter after twelve&amp;quot;, the price &amp;quot;one thousand two hundred and the room number &amp;quot;one two one five&amp;quot;, and so on. Although English can conflate all those possible meanings into one expression. the translation into other languages usually requires more specificity. If this is a problem for any human listener, the problem grows considerably when it is a parser doing the disambiguation. In this paper. I explain how we can use discourse knowledge in order to help a parser disambiguate among different possible parses for an input sentence, with the final goal of improving the translation in an end-to-end speech translation system. The work described was conducted within the JANUS multi-lingual speech-to-speech translation system designed to. translate spontaneous dialogue in a limited domain (Lavie et al.. 1996). The machine translation component of JANUS handles these problems using two different approaches: the Generalized Left-to-Right parser GLR* (Lavie and Tomita, 1993) and Phoenix. the latter being the focus of this paper. The author gratefully acknowledges support from Caixa&amp;quot; Fellowship Program. ATR Interpreting Laboratories. and Project Enthusiast. 2 Disambiguation through Contextual Information This project addresses the problem of choosing the most appropriate semantic parse for any given input. The approach is to combine discourse information with the set of possible parses provided by the Phoenix parser for an input string. The discourse module selects one of these possibilities. The decision is to be based on: 1. The domain of the dialogue. JANUS deals with dialogues restricted to a domain, such as scheduling an appointment or making travel arrangements. The general topic provides some information about what types of exchanges, and therefore speech acts, can be expected. 2. The macro-structure of the dialogue up to that point. We can divide a dialogue into smaller, self-contained units that provide information on what phases are over or yet to be covered: Are we past the greeting phase? If a flight was rewe expect a payment phase at some point in the rest of the conversation&apos;? 3. The structure of adjacency pairs (Schegloff and Sacks, 1973), together with the responses to speech functions (Halliday, 1994; Martin. 1992). If one speaker has uttered a request for inforwe expect some sort of response to — an answer, a disclaimer or a clarification. domain of the dialogues, named plandomain, of dialogues where a customer makes travel arrangements with a travel agent or a hotel clerk to book hotel rooms, flights or other of transportation. They are diwhich the speakers have specific goals of carrying out a task that involves the exchange of both information and services. Discourse processing is structured in two different levels: the context module keeps a global history of the conversation, from which it will be able to estimate, for instance, the likelihood of a greeting once the opening phase of the conversation is over. A more local history predicts the expected response in 510 any adjacency pair. such as a question-answer sequence. The model adopted here is that of a twolayered finite state machine (henceforth FSM). and approach is that of disambiguation. where as much information as possible is collected before proceeding on to disambiguation. rather than restricting the parser&apos;s search earlier on. 3 Representation of Speech Acts in Phoenix Writing the appropriate grammars and deciding on the set of speech acts for this domain is also an important part of this project. The selected speech acts are encoded in the grammar — in the Phoenix case. a semantic grammar — the tokens of which are concepts that the segment in question represents. Any utterance is divided into SDUs — Semantic Dialogue Units — which are fed to the parser one at a time. SDL&apos;s represent a full concept. expression. or thought. but not necessarily a complete grammatical sentence. Let us take an example input, and a possible parse for it: you tell me the prices at the Holiday Inn? ((request) (COULD YOU ([request-info) (TELL ME qprice-infol (THE PRICES ([establishment) (AT THE (HOLIDAY INN)))))))))) concepts of the grammar are speech acts themselves, the ones immediately after are further refinements of the speech act, and the lower level concepts capture the specifics of the utterance. such as the name of the hotel in the above example. 4 The Discourse Processor The discourse module processes the global and lostructure of the dialogue in two different layers. The first one is a general organization of the dialogue&apos;s subparts: the layer under that proesses the possible sequence of speech acts in a subpart. The assumption is that negotiation dialogues develop in a predictable way — this assumption was also made for scheduling dialogues in the Verbmobil project (Maier. 1996) —. with three phases: negotiation. clos- We call the middle phase in our dialogues performance phase, it is not always negotiation se. the task performance phase very many subdialogues can take place. such decision-making, payment. clarification. etc. Discourse processing has frequently made use of sequences of speech acts as they occur in the dialogue. through bigram probabilities of occurrences. or through modelling in a finite state machine. Maier. 1996: Reithinger et al.. 1996: 1ida and Yaniaoka. 1990: Qu et al.. 1996). However, taking into account only the speech act of the previous segment Phoenix Parser y Pune Tr. i Pursc race . Discourse Module Gimlet Structure Local structure Tree 1: Discourse Module might leave us with insufficient information to decide — as is the case in some elliptical utterances which do not follow a strict adjacency pair sequence: about flight times...) Si I can give you the arrival time. Do you have that information already? S2 No. I don&apos;t. Si It&apos;s twelve fifteen. If we are in parsing the segment &amp;quot;It&apos;s twelve fifteen&amp;quot;. and our only source of information is the previous segment. &amp;quot;No. I don&apos;t&amp;quot;. we cannot possibly find the referent for &amp;quot;twelve fifteen&amp;quot;, unless we know we are in a subdialogue discussing flight times, and arrival times have been previously mentioned. Our approach aims at obtaining information both from the subdialogue structure and the speech act sequence by modelling the global structure of the diwith a and closing initial and final states. and other possible subdialogues in the intervening states. Each one of those states contains a FSM itself. which determines the allowed speech acts in a given subdialogue and their sequence. For a picture of the discourse component here proposed. see Figure 1. Let us look at another example where the use information on the previous context the speaker alternance will help choose the most approparse and thus achieve a translation. 511 The expression &amp;quot;okay&amp;quot; can be a prompt for an answer (3), an acceptance of a previous offer (4) or a backchanneling element, i.e., an acknowledgement that the previous speaker&apos;s utterance has been understood (5). (3) SI So we&apos;ll switch you to a double room, okay? (4) SI So we&apos;ll switch you to a double room. S2 Okay. (5) SI The double room is $90 a night. S2 Okay, and how much is a single room? In example (3), we will know that &amp;quot;okay&amp;quot; is a prompt, because it is uttered by the speaker after he or she has made a suggestion. In example (4), it will be an acceptance because it is uttered after the previous speaker&apos;s suggestion. And in (5) it is an acknowledgment of the information provided. The correct assignment of speech acts will provide a more accurate translation into other languages. To summarize, the two-layered FSM models a conversation through transitions of speech acts that are included in subdialogues. When the parser returns an ambiguity in the form of two or more possible speech acts, the FSM will help decide which one is the most appropriate given the context. are situations where the path followed two of the structure does not match the parse possibility we are trying to accept or reject. One such situation is the presence of clarification and correction subdialogues at any point in the conversation. In that case, the processor will try to jump to the upper layer, in order to switch the subunder consideration. We also take into account the situation where there is no possible choice, because the does not restrict the choice — i.e., the FSM allows all the parses returned by the parser — or because the model does not allow any of them. In either of those cases, the transition is determined by unigram probabilities of the speech act in isolation, and bigrams of the combination of speech act we are trying disambiguate plus its predecessor. 5 Evaluation The discourse module is being developed on a set of 29 dialogues, totalling 1,393 utterances. An evaluation will be performed on 10 dialogues, previously unseen by the discourse module. Since the module can be either incorporated into the system, or turned off, the evaluation will be on the system&apos;s performance with and without the discourse module. Independent graders assign a grade to the quality of the translation&apos;. A secondary evaluation will be &apos;The final results of this evaluation will be available at the time of the ACL conference. based on the quality of the speech act disambiguation itself, regardless of its contribution to translation quality. 6 Conclusion and Future Work In this paper I have presented a model of dialogue structure in two layers, which processes the sequence of subdialogues and speech acts in task-oriented dialogues in order to select the most appropriate from the ambiguous parses returned by the Phoenix parser. The model structures dialogue in two levels of finite state machines, with the final goal of improving translation quality. A possible extension to the work here described would be to generalize the two-layer model to other. less homogeneous domains. The use of statistical information in different parts of the processing, such as the arcs of the FSM, could enhance performance.</abstract>
<note confidence="0.896872675675676">References A. K. Halliday. 1994. An to Func- Edward Arnold, London (2nd edition). Hitoshi lida and Takyuki Yamaoka. 1990. Dialogue Structure Analysis Method and Its Application to Predicting the Next Utterance. Dialogue Structure Analysis. German-Japanese Workshop, Kyoto, Japan. Alon Lavie, Donna Gates, Marsal Gavalda, Laura Mayfield, Alex Waibel, Lori Levin. 1996. Multi-lingual Translation of Spontaneously Spoken Language in a Domain. In of COLING 96. Copenhagen. Alon Lavie and Masaru Tomita. 1993. GLR*: An Efficient Noise Skipping Parsing Algorithm for Context Grammars. In of the Interna- Workshop Technologies, IWPT 93, Tilburg, The Netherlands. Elisabeth Maier. 1996. Context Construction as Subtask of Dialogue Processing: The Verbmobil Case. In Proceedings of the Eleventh Twente Workshop on Language Technology. T4VLT 11. Martin. 1992. Text: System Struc- Benjamins. Philadelphia/Amsterdam. Yan Qu, Barbara Di Eugenio, Alon Lavie, Lori Levin. 1996. Minimizing Cumulative Error in Discourse Con- In of ECA I 96, Hungary. Norbert Reithinger, Ralf Engel, Michael Kipp. Martin Klesen. 1996. Predicting Dialogue Acts for a Speech- Translation System. In of IC- 96, USA. Emmanuel Schegloff and Harvey Sacks. 1973. Opening Closings. 7, 289-327. Wayne Ward. 1991. Understanding Spontaneous the Phoenix System. In of ICASSP 91. 512</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
</authors>
<title>An Introduction to Functional Grammar. Edward Arnold, London (2nd edition).</title>
<date>1994</date>
<contexts>
<context position="3126" citStr="Halliday, 1994" startWordPosition="483" endWordPosition="484">ointment or making travel arrangements. The general topic provides some information about what types of exchanges, and therefore speech acts, can be expected. 2. The macro-structure of the dialogue up to that point. We can divide a dialogue into smaller, self-contained units that provide information on what phases are over or yet to be covered: Are we past the greeting phase? If a flight was reserved, should we expect a payment phase at some point in the rest of the conversation&apos;? 3. The structure of adjacency pairs (Schegloff and Sacks, 1973), together with the responses to speech functions (Halliday, 1994; Martin. 1992). If one speaker has uttered a request for information, we expect some sort of response to that — an answer, a disclaimer or a clarification. The domain of the dialogues, named travel planning domain, consists of dialogues where a customer makes travel arrangements with a travel agent or a hotel clerk to book hotel rooms, flights or other forms of transportation. They are task-oriented dialogues. in which the speakers have specific goals of carrying out a task that involves the exchange of both information and services. Discourse processing is structured in two different levels:</context>
</contexts>
<marker>Halliday, 1994</marker>
<rawString>Michael A. K. Halliday. 1994. An Introduction to Functional Grammar. Edward Arnold, London (2nd edition).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitoshi lida</author>
<author>Takyuki Yamaoka</author>
</authors>
<title>Dialogue Structure Analysis Method and Its Application to Predicting the Next Utterance. Dialogue Structure Analysis. German-Japanese Workshop,</title>
<date>1990</date>
<location>Kyoto, Japan.</location>
<marker>lida, Yamaoka, 1990</marker>
<rawString>Hitoshi lida and Takyuki Yamaoka. 1990. Dialogue Structure Analysis Method and Its Application to Predicting the Next Utterance. Dialogue Structure Analysis. German-Japanese Workshop, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Donna Gates</author>
<author>Marsal Gavalda</author>
<author>Laura Mayfield</author>
<author>Alex Waibel</author>
<author>Lori Levin</author>
</authors>
<title>Multi-lingual Translation of Spontaneously Spoken Language in a Limited Domain.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING 96.</booktitle>
<location>Copenhagen.</location>
<marker>Lavie, Gates, Gavalda, Mayfield, Waibel, Levin, 1996</marker>
<rawString>Alon Lavie, Donna Gates, Marsal Gavalda, Laura Mayfield, Alex Waibel, Lori Levin. 1996. Multi-lingual Translation of Spontaneously Spoken Language in a Limited Domain. In Proceedings of COLING 96. Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Masaru Tomita</author>
</authors>
<title>GLR*: An Efficient Noise Skipping Parsing Algorithm for Context Free Grammars.</title>
<date>1993</date>
<booktitle>In Proceedings of the Third International Workshop on Parsing Technologies, IWPT 93,</booktitle>
<location>Tilburg, The Netherlands.</location>
<contexts>
<context position="1840" citStr="Lavie and Tomita, 1993" startWordPosition="272" endWordPosition="275">doing the disambiguation. In this paper. I explain how we can use discourse knowledge in order to help a parser disambiguate among different possible parses for an input sentence, with the final goal of improving the translation in an end-to-end speech translation system. The work described was conducted within the JANUS multi-lingual speech-to-speech translation system designed to. translate spontaneous dialogue in a limited domain (Lavie et al.. 1996). The machine translation component of JANUS handles these problems using two different approaches: the Generalized Left-to-Right parser GLR* (Lavie and Tomita, 1993) and Phoenix. the latter being the focus of this paper. •The author gratefully acknowledges support from -la Caixa&amp;quot; Fellowship Program. ATR Interpreting Laboratories. and Project Enthusiast. 2 Disambiguation through Contextual Information This project addresses the problem of choosing the most appropriate semantic parse for any given input. The approach is to combine discourse information with the set of possible parses provided by the Phoenix parser for an input string. The discourse module selects one of these possibilities. The decision is to be based on: 1. The domain of the dialogue. JANU</context>
</contexts>
<marker>Lavie, Tomita, 1993</marker>
<rawString>Alon Lavie and Masaru Tomita. 1993. GLR*: An Efficient Noise Skipping Parsing Algorithm for Context Free Grammars. In Proceedings of the Third International Workshop on Parsing Technologies, IWPT 93, Tilburg, The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Maier</author>
</authors>
<title>Context Construction as Subtask of Dialogue Processing: The Verbmobil Case.</title>
<date>1996</date>
<booktitle>In Proceedings of the Eleventh Twente Workshop on Language Technology. T4VLT</booktitle>
<pages>11</pages>
<marker>Maier, 1996</marker>
<rawString>Elisabeth Maier. 1996. Context Construction as Subtask of Dialogue Processing: The Verbmobil Case. In Proceedings of the Eleventh Twente Workshop on Language Technology. T4VLT 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Martin</author>
</authors>
<title>English Text: System and Structure. John Benjamins.</title>
<date>1992</date>
<publisher>Philadelphia/Amsterdam.</publisher>
<marker>Martin, 1992</marker>
<rawString>James Martin. 1992. English Text: System and Structure. John Benjamins. Philadelphia/Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Qu</author>
<author>Barbara Di Eugenio</author>
<author>Alon Lavie</author>
<author>Lori Levin</author>
</authors>
<title>Minimizing Cumulative Error in Discourse Context.</title>
<date>1996</date>
<booktitle>In Proceedings of ECA I 96,</booktitle>
<location>Budapest, Hungary.</location>
<marker>Qu, Di Eugenio, Lavie, Levin, 1996</marker>
<rawString>Yan Qu, Barbara Di Eugenio, Alon Lavie, Lori Levin. 1996. Minimizing Cumulative Error in Discourse Context. In Proceedings of ECA I 96, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Klesen</author>
</authors>
<title>Predicting Dialogue Acts for a Speechto-Speech Translation System. In</title>
<date>1996</date>
<booktitle>Proceedings of ICSLP 96,</booktitle>
<location>Philadelphia, USA.</location>
<marker>Klesen, 1996</marker>
<rawString>Norbert Reithinger, Ralf Engel, Michael Kipp. Martin Klesen. 1996. Predicting Dialogue Acts for a Speechto-Speech Translation System. In Proceedings of ICSLP 96, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Schegloff</author>
<author>Harvey Sacks</author>
</authors>
<title>Opening up Closings. Semiotica 7,</title>
<date>1973</date>
<pages>289--327</pages>
<contexts>
<context position="3061" citStr="Schegloff and Sacks, 1973" startWordPosition="472" endWordPosition="475"> JANUS deals with dialogues restricted to a domain, such as scheduling an appointment or making travel arrangements. The general topic provides some information about what types of exchanges, and therefore speech acts, can be expected. 2. The macro-structure of the dialogue up to that point. We can divide a dialogue into smaller, self-contained units that provide information on what phases are over or yet to be covered: Are we past the greeting phase? If a flight was reserved, should we expect a payment phase at some point in the rest of the conversation&apos;? 3. The structure of adjacency pairs (Schegloff and Sacks, 1973), together with the responses to speech functions (Halliday, 1994; Martin. 1992). If one speaker has uttered a request for information, we expect some sort of response to that — an answer, a disclaimer or a clarification. The domain of the dialogues, named travel planning domain, consists of dialogues where a customer makes travel arrangements with a travel agent or a hotel clerk to book hotel rooms, flights or other forms of transportation. They are task-oriented dialogues. in which the speakers have specific goals of carrying out a task that involves the exchange of both information and serv</context>
</contexts>
<marker>Schegloff, Sacks, 1973</marker>
<rawString>Emmanuel Schegloff and Harvey Sacks. 1973. Opening up Closings. Semiotica 7, pages 289-327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Ward</author>
</authors>
<title>Understanding Spontaneous Speech: the Phoenix System. In</title>
<date>1991</date>
<booktitle>Proceedings of ICASSP 91.</booktitle>
<marker>Ward, 1991</marker>
<rawString>Wayne Ward. 1991. Understanding Spontaneous Speech: the Phoenix System. In Proceedings of ICASSP 91.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>