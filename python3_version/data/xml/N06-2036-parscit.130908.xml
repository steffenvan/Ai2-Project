<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005470">
<title confidence="0.914442">
Word Domain Disambiguation via Word Sense Disambiguation
</title>
<author confidence="0.650516">
Antonio Sanfilippo, Stephen Tratz, Michelle Gregory
</author>
<affiliation confidence="0.156587">
Pacific Northwest National Laboratory
</affiliation>
<address confidence="0.33002">
Richland, WA 99352
</address>
<email confidence="0.931498">
{Antonio.Sanfilippo, Stephen.Tratz, Michelle.Gregory}@pnl.gov
</email>
<sectionHeader confidence="0.99498" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999824368421053">
Word subject domains have been
widely used to improve the perform-
ance of word sense disambiguation al-
gorithms. However, comparatively little
effort has been devoted so far to the
disambiguation of word subject do-
mains. The few existing approaches
have focused on the development of al-
gorithms specific to word domain dis-
ambiguation. In this paper we explore
an alternative approach where word
domain disambiguation is achieved via
word sense disambiguation. Our study
shows that this approach yields very
strong results, suggesting that word
domain disambiguation can be ad-
dressed in terms of word sense disam-
biguation with no need for special
purpose algorithms.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999647333333333">
Word subject domains have been ubiquitously
used in dictionaries to help human readers pin-
point the specific sense of a word by specifying
technical usage, e.g. see “subject field codes” in
Procter (1978). In computational linguistics,
word subject domains have been widely used to
improve the performance of machine translation
systems. For example, in a review of commonly
used features in automated translation, Mowatt
(1999) reports that most of the machine transla-
tion systems surveyed made use of word subject
domains. Word subject domains have also been
used in information systems. For example, San-
filippo (1998) describes a summarization system
where subject domains provide users with useful
conceptual parameters to tailor summary re-
quests to a user’s interest.
Successful usage of word domains in applica-
tions such as machine translation and summari-
zation is strongly dependent on the ability to
assign the appropriate subject domain to a word
in its context. Such an assignment requires a
process of Word Domain Disambiguation
(WDD) because the same word can often be as-
signed different subject domains out of context
(e.g. the word partner can potentially be re-
lated to FINANCE or MARRIAGE).
Interestingly enough, word subject domains
have been widely used to improve the perform-
ance of Word Sense Disambiguation (WSD)
algorithms (Wilks and Stevenson 1998, Magnini
et al. 2001; Gliozzo et al. 2004). However, com-
paratively little effort has been devoted so far to
the word domain disambiguation itself. The
most notable exceptions are the work of Magnini
and Strapparava (2000) and Suarez &amp; Palomar
(2002). Both studies propose algorithms specific
to the WDD task and have focused on the dis-
ambiguation of noun domains.
In this paper we explore an alternative ap-
proach where word domain disambiguation is
achieved via word sense disambiguation. More-
over, we extend the treatment of WDD to verbs
and adjectives. Initial results show that this ap-
proach yield very strong results, suggesting that
WDD can be addressed in terms of word sense
disambiguation with no need of special purpose
algorithms.
</bodyText>
<page confidence="0.9657">
141
</page>
<note confidence="0.9333875">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 141–144,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9002475">
Figure 1: Senses and domains for the word bank in WordNet Domains, with number of occurrences in SemCor,
adapted from Magnini et al. (2002).
</figureCaption>
<sectionHeader confidence="0.885216" genericHeader="method">
2 WDD via WSD
</sectionHeader>
<bodyText confidence="0.8374852">
Our approach relies on the use of WordNet Do-
mains (Bagnini and Cavaglià 2000) and can be
outlined in the following two steps:
1. use a WordNet-based WSD algorithm to
assign a sense to each word in the input
text, e.g. doctor 4 doctor#n#1
2. use WordNet Domains to map disam-
biguated words into the subject domain
associated with the word, e.g. doc-
tor#n#14doctor#n#1#MEDICINE.
</bodyText>
<subsectionHeader confidence="0.989466">
2.1 WordNet Domains
</subsectionHeader>
<bodyText confidence="0.99970275">
WordNet Domains is an extension of WordNet
(http://wordnet.princeton.edu/) where synonym
sets have been annotated with one or more sub-
ject domain labels, as shown in Figure 1. Subject
domains provide an interesting and useful classi-
fication which cuts across part of speech and
WordNet sub-hierarchies. For example, doc-
tor#n#1 and operate#n#1 both have sub-
ject domain MEDICINE, and SPORT includes both
athlete#n#1 with top hypernym life-
form#n#1 and sport#n#1 with top hy-
pernym act#n#2.
</bodyText>
<subsectionHeader confidence="0.999595">
2.2 Word Sense Disambiguation
</subsectionHeader>
<bodyText confidence="0.999878411764706">
To assign a sense to each word in the input text,
we used the WSD algorithm presented in San-
filippo et al. (2006). This WSD algorithm is
based on a supervised classification approach
that uses SemCor1 as training corpus. The algo-
rithm employs the OpenNLP MaxEnt imple-
mentation of the maximum entropy
classification algorithm (Berger et al. 1996) to
develop word sense recognition signatures for
each lemma which predicts the most likely sense
for the lemma according to the context in which
the lemma occurs.
Following Dang &amp; Palmer (2005) and Ko-
homban &amp; Lee (2005), Sanfilippo et al. (2006)
use contextual, syntactic and semantic informa-
tion to inform our verb class disambiguation
system.
</bodyText>
<listItem confidence="0.95997875">
• Contextual information includes the verb
under analysis plus three tokens found on
each side of the verb, within sentence
boundaries. Tokens included word as well
as punctuation.
• Syntactic information includes grammatical
dependencies (e.g. subject, object) and mor-
pho-syntactic features such as part of
speech, case, number and tense.
• Semantic information includes named entity
types (e.g. person, location, organization)
and hypernyms.
</listItem>
<bodyText confidence="0.9978045">
We chose this WSD algorithm as it provides
some of the best published results to date, as the
comparison with top performing WSD systems
in Senseval3 presented in Table 1 shows---see
http://www.senseval.org and Snyder &amp; Palmer
(2004) for terms of reference on Senseval3.
</bodyText>
<footnote confidence="0.879244">
1 http://www.cs.unt.edu/~rada/downloads.html.
</footnote>
<page confidence="0.968115">
142
</page>
<table confidence="0.999843166666667">
System Precision Fraction of
Recall
Sanfilippo et al. 2006 61% 22%
GAMBL 59.0% 21.3%
SenseLearner 56.1% 20.2%
Baseline 52.9% 19.1%
</table>
<tableCaption confidence="0.956564">
Table 1: Results for verb sense disambiguation on
Senseval3 data, adapted from Sanfilippo et al. (2006).
</tableCaption>
<sectionHeader confidence="0.996859" genericHeader="method">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.976429545454545">
To evaluate our WDD approach, we used both
the SemCor and Senseval3 data sets. Both cor-
pora were stripped of their sense annotations and
processed with an extension of the WSD algo-
rithm of Sanfilippo et al. (2006) to assign a
WordNet sense to each noun, verb and adjective.
The extension consisted in extending the train-
ing data set so as to include a selection of
WordNet examples (full sentences containing a
main verb) and the Open Mind Word Expert
corpus (Chklovski and Mihalcea 2002).
The original hand-coded word sense annota-
tions of the SemCor and Senseval3 corpora and
the word sense annotations assigned by the
WSD algorithm used in this study were mapped
into subject domain annotations using WordNet
Domains, as described in the opening paragraph
of section 2 above. The version of the SemCor
and Senseval3 corpora where subject domain
annotations were generated from hand-coded
word senses served as gold standard. A baseline
for both corpora was obtained by assigning to
each lemma the subject domain corresponding to
sense 1 of the lemma.
WDD results of a tenfold cross-validation for
the SemCor data set are given in Table 2. Accu-
racy is high across nouns, verbs and adjectives.2
To verify the statistical significance of these re-
sults against the baseline, we used a standard
proportions comparison test (see Fleiss 1981, p.
30). According to this test, the accuracy of our
system is significantly better than the baseline.
The high accuracy of our WDD algorithm is
corroborated by the results for the Senseval3
data set in Table 3. Such corroboration is impor-
tant as the Senseval3 corpus was not part of the
data set used to train the WSD algorithm which
provided the basis for subject domain assign-
2 We have not worked on adverbs yet, but we expect com-
parable results.
ment. The standard comparison test for the Sen-
seval3 is not as conclusive as with SemCor. This
is probably due to the comparatively smaller size
of the Senseval3 corpus.
</bodyText>
<table confidence="0.99770225">
Nouns Verbs Adj.s Overall
Accuracy 0.874 0.933 0.942 0.912
Baseline 0.848 0.927 0.932 0.897
p-value 4.6e-54 1.4e-07 5.5e-08 1.4e-58
</table>
<tableCaption confidence="0.93869">
Table 2: SemCor WDD results.
</tableCaption>
<table confidence="0.99970575">
Nouns Verbs Adj.s Overall
Accuracy 0.797 0.908 0.888 0.848
Baseline 0.783 0.893 0.862 0.829
p-value 0.227 0.169 0.151 0.048
</table>
<tableCaption confidence="0.998995">
Table 3: Senseval3 WDD results.
</tableCaption>
<sectionHeader confidence="0.973601" genericHeader="method">
4 Comparison with Previous WDD
Work
</sectionHeader>
<bodyText confidence="0.999896055555555">
Our WDD algorithm compares favorably with
the approach explored in Bagnini and Strap-
parava (2000), who report 0.82 p/r in the WDD
tasks for a subset of nouns in SemCor.
Suarez and Palomar (2002) report WDD re-
sults of 78.7% accuracy for nouns against a
baseline of 68.7% accuracy for the same data
set. As in the present study, Suarez and Palomar
derive the baseline by assigning to each lemma
the subject domain corresponding to sense 1 of
the lemma. Unfortunately, a meaningful com-
parison with Suarez and Palomar (2002) is not
possible as they use a different data set, the DSO
corpus.3 We are currently working on repeating
our study with the DSO corpus and will include
the results of this evaluation in the final version
of the paper to achieve commensurability with
the results reported by Suarez and Palomar.
</bodyText>
<sectionHeader confidence="0.977317" genericHeader="conclusions">
5 Conclusions and Further Work
</sectionHeader>
<bodyText confidence="0.9992845">
Current approaches to WDD have assumed that
special purpose algorithms are needed to model
the WDD task. We have shown that very com-
petitive and perhaps unrivaled results (pending
on evaluation of our WDD algorithm with the
DSO corpus) can be obtained using WSD as the
basis for subject domain assignment. This im-
provement in WDD performance can be used to
</bodyText>
<footnote confidence="0.9819755">
3 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?cata
logId=LDC97T12.
</footnote>
<page confidence="0.998535">
143
</page>
<bodyText confidence="0.999960692307692">
obtain further gains in WSD accuracy, following
Wilks and Stevenson (1998), Magnini et al.
(2001) and Gliozzo et al. (2004). A more accu-
rate WSD model will in turn yield yet better
WDD results, as demonstrated in this paper.
Consequently, further improvements in accuracy
for both WSD and WDD can be expected
through a bootstrapping cycle where WDD re-
sults are fed as input to the WSD process, and
the resulting improved WSD model is then used
to achieve better WDD results. We intend to
explore this possibility in future extensions of
this work.
</bodyText>
<sectionHeader confidence="0.996932" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998793">
We would like to thank Paul Whitney for help
with the evaluation of the results presented in
Section 3.
</bodyText>
<sectionHeader confidence="0.998878" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.962088883116883">
Berger, A., S. Della Pietra and V. Della Pietra (1996)
A Maximum Entropy Approach to Natural Lan-
guage Processing. Computational Linguistics, vol-
ume 22, number 1, pages 39-71.
Chklovski, T. and R. Mihalcea (2002) Building a
Sense Tagged Corpus with Open Mind Word Ex-
pert. Proceedings of the ACL 2002 Workshop on
&amp;quot;Word Sense Disambiguation: Recent Successes
and Future Directions, Philadelphia, July 2002, pp.
116-122.
Dang, H. T. and M. Palmer (2005) The Role of Se-
mantic Roles in Disambiguating Verb Senses. In
Proceedings of the 43rd Annual Meeting of the As-
sociation for Computational Linguistics, Ann Ar-
bor MI, June 26-28, 2005.
Fleiss, J. L. (1981) Statistical Methods for Rates and
Proportions. 2nd edition. New York: John Wiley
&amp; Sons.
Gliozzo, A., C. Strapparava, I. Dagan (2004) Unsu-
pervised and Supervised Exploitation of Semantic
Domains in Lexical Disambiguation. Computer
Speech and Language,18(3), Pages 275-299.
Kohomban, U. and W. Lee (2005) Learning seman-
tic classes for word sense disambiguation. In Pro-
ceedings of the 43rd Annual meeting of the
Association for Computational Linguistics, Ann
Arbor, MI.
Magnini, B., Cavaglià, G. (2000) Integrating Subject
Field Codes into WordNet. Proceedings of LREC-
2000, Second International Conference on Lan-
guage Resources and Evaluation, Athens, Greece,
31 MAY- 2 JUNE 2000, pp. 1413-1418.
Magnini, B., Strapparava C. (2000) Experiments in
Word Domain Disambiguation for Parallel Texts.
Proceedings of the ACL Workshop on Word
Senses and Multilinguality, Hong-Kong, October
7, 2000, pp. 27-33
Magnini, B., C. Strapparava, G. Pezzulo and A.
Gliozzo (2001) Using Domain Information for
Word Sense Disambiguation. In Proceeding of
SENSEVAL-2: Second International Workshop on
Evaluating Word Sense Disambiguation Systems,
pp. 111-114, 5-6 July 2001, Toulouse, France.
Magnini, B., C. Strapparava, G. Pezzulo and A.
Gliozzo (2002) The Role of Domain Information
in Word Sense Disambiguation. Natural Language
Engineering, 8(4):359—373.
Mowatt, D. (1999) Types of Semantic Information
Necessary in a Machine Translation Lexicon. Con-
férence TALN, Cargèse, pp. 12-17.
Procter, Paul (Ed.) (1978) Longman Dictionary o
Contemporary English. Longman Group Ltd., Es-
sex, UK.
Sanfilippo, A. (1998) Ranking Text Units According
to Textual Saliency, Connectivity and Topic Apt-
ness. COLING-ACL 1998: 1157-1163.
Sanfilippo, A., S. Tratz, M. Gregory, A.Chappell, P.
Whitney, C. Posse, P. Paulson, B. Baddeley, R.
Hohimer, A. White. (2006) Automating Ontologi-
cal Annotation with WordNet. Proceedings of the
3rd Global WordNet Conference, Jeju Island,
South Korea, Jan 19-26 2006.
Snyder, B. and M. Palmer. 2004. The English all-
words task. SENSEVAL-3: Third International
Workshop on the Evaluation of Systems for the
Semantic Analysis of Text. Barcelona, Spain.
Suárez, A., Palomar, M. (2002) Word sense vs. word
domain disambiguation: a maximum entropy ap-
proach. In Sojka P., Kopecek I., Pala K., eds.:
Text, Speech and Dialogue (TSD 2002). Volume
2448 of Lecture Notes in Artificial Intelligence,
Springer, (2002) 131—138.
Wilks, Y. and Stevenson, M. (1998) Word sense dis-
ambiguation using optimised combinations of
knowledge sources. Proceedings of the 17th inter-
national conference on Computational Linguistics,
pp. 1398—1402.
</reference>
<page confidence="0.998593">
144
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.686200">
<title confidence="0.999911">Word Domain Disambiguation via Word Sense Disambiguation</title>
<author confidence="0.999121">Antonio Sanfilippo</author>
<author confidence="0.999121">Stephen Tratz</author>
<author confidence="0.999121">Michelle</author>
<affiliation confidence="0.999421">Pacific Northwest National Laboratory</affiliation>
<address confidence="0.999858">Richland, WA 99352</address>
<email confidence="0.699674">Antonio.Sanfilippo@pnl.gov</email>
<email confidence="0.699674">Stephen.Tratz@pnl.gov</email>
<email confidence="0.699674">Michelle.Gregory@pnl.gov</email>
<abstract confidence="0.99906825">Word subject domains have been widely used to improve the performance of word sense disambiguation algorithms. However, comparatively little effort has been devoted so far to the disambiguation of word subject domains. The few existing approaches have focused on the development of algorithms specific to word domain disambiguation. In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation. Our study shows that this approach yields very strong results, suggesting that word domain disambiguation can be addressed in terms of word sense disambiguation with no need for special purpose algorithms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A Maximum Entropy Approach to Natural Language Processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<pages>39--71</pages>
<contexts>
<context position="4625" citStr="Berger et al. 1996" startWordPosition="719" endWordPosition="722">hich cuts across part of speech and WordNet sub-hierarchies. For example, doctor#n#1 and operate#n#1 both have subject domain MEDICINE, and SPORT includes both athlete#n#1 with top hypernym lifeform#n#1 and sport#n#1 with top hypernym act#n#2. 2.2 Word Sense Disambiguation To assign a sense to each word in the input text, we used the WSD algorithm presented in Sanfilippo et al. (2006). This WSD algorithm is based on a supervised classification approach that uses SemCor1 as training corpus. The algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm (Berger et al. 1996) to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs. Following Dang &amp; Palmer (2005) and Kohomban &amp; Lee (2005), Sanfilippo et al. (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system. • Contextual information includes the verb under analysis plus three tokens found on each side of the verb, within sentence boundaries. Tokens included word as well as punctuation. • Syntactic information includes grammatical dependencies (e.g. subject, </context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Berger, A., S. Della Pietra and V. Della Pietra (1996) A Maximum Entropy Approach to Natural Language Processing. Computational Linguistics, volume 22, number 1, pages 39-71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chklovski</author>
<author>R Mihalcea</author>
</authors>
<title>Building a Sense Tagged Corpus with Open Mind Word Expert.</title>
<date>2002</date>
<booktitle>Proceedings of the ACL 2002 Workshop on &amp;quot;Word Sense Disambiguation: Recent Successes and Future Directions,</booktitle>
<pages>116--122</pages>
<location>Philadelphia,</location>
<contexts>
<context position="6473" citStr="Chklovski and Mihalcea 2002" startWordPosition="1007" endWordPosition="1010"> Baseline 52.9% 19.1% Table 1: Results for verb sense disambiguation on Senseval3 data, adapted from Sanfilippo et al. (2006). 3 Evaluation To evaluate our WDD approach, we used both the SemCor and Senseval3 data sets. Both corpora were stripped of their sense annotations and processed with an extension of the WSD algorithm of Sanfilippo et al. (2006) to assign a WordNet sense to each noun, verb and adjective. The extension consisted in extending the training data set so as to include a selection of WordNet examples (full sentences containing a main verb) and the Open Mind Word Expert corpus (Chklovski and Mihalcea 2002). The original hand-coded word sense annotations of the SemCor and Senseval3 corpora and the word sense annotations assigned by the WSD algorithm used in this study were mapped into subject domain annotations using WordNet Domains, as described in the opening paragraph of section 2 above. The version of the SemCor and Senseval3 corpora where subject domain annotations were generated from hand-coded word senses served as gold standard. A baseline for both corpora was obtained by assigning to each lemma the subject domain corresponding to sense 1 of the lemma. WDD results of a tenfold cross-vali</context>
</contexts>
<marker>Chklovski, Mihalcea, 2002</marker>
<rawString>Chklovski, T. and R. Mihalcea (2002) Building a Sense Tagged Corpus with Open Mind Word Expert. Proceedings of the ACL 2002 Workshop on &amp;quot;Word Sense Disambiguation: Recent Successes and Future Directions, Philadelphia, July 2002, pp. 116-122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Dang</author>
<author>M Palmer</author>
</authors>
<title>The Role of Semantic Roles in Disambiguating Verb Senses.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>Ann Arbor MI,</location>
<contexts>
<context position="4819" citStr="Dang &amp; Palmer (2005)" startWordPosition="751" endWordPosition="754">eform#n#1 and sport#n#1 with top hypernym act#n#2. 2.2 Word Sense Disambiguation To assign a sense to each word in the input text, we used the WSD algorithm presented in Sanfilippo et al. (2006). This WSD algorithm is based on a supervised classification approach that uses SemCor1 as training corpus. The algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm (Berger et al. 1996) to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs. Following Dang &amp; Palmer (2005) and Kohomban &amp; Lee (2005), Sanfilippo et al. (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system. • Contextual information includes the verb under analysis plus three tokens found on each side of the verb, within sentence boundaries. Tokens included word as well as punctuation. • Syntactic information includes grammatical dependencies (e.g. subject, object) and morpho-syntactic features such as part of speech, case, number and tense. • Semantic information includes named entity types (e.g. person, location, organization) and hypernyms. We c</context>
</contexts>
<marker>Dang, Palmer, 2005</marker>
<rawString>Dang, H. T. and M. Palmer (2005) The Role of Semantic Roles in Disambiguating Verb Senses. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, Ann Arbor MI, June 26-28, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Fleiss</author>
</authors>
<title>Statistical Methods for Rates and Proportions. 2nd edition.</title>
<date>1981</date>
<publisher>John Wiley &amp; Sons.</publisher>
<location>New York:</location>
<contexts>
<context position="7321" citStr="Fleiss 1981" startWordPosition="1146" endWordPosition="1147">scribed in the opening paragraph of section 2 above. The version of the SemCor and Senseval3 corpora where subject domain annotations were generated from hand-coded word senses served as gold standard. A baseline for both corpora was obtained by assigning to each lemma the subject domain corresponding to sense 1 of the lemma. WDD results of a tenfold cross-validation for the SemCor data set are given in Table 2. Accuracy is high across nouns, verbs and adjectives.2 To verify the statistical significance of these results against the baseline, we used a standard proportions comparison test (see Fleiss 1981, p. 30). According to this test, the accuracy of our system is significantly better than the baseline. The high accuracy of our WDD algorithm is corroborated by the results for the Senseval3 data set in Table 3. Such corroboration is important as the Senseval3 corpus was not part of the data set used to train the WSD algorithm which provided the basis for subject domain assign2 We have not worked on adverbs yet, but we expect comparable results. ment. The standard comparison test for the Senseval3 is not as conclusive as with SemCor. This is probably due to the comparatively smaller size of t</context>
</contexts>
<marker>Fleiss, 1981</marker>
<rawString>Fleiss, J. L. (1981) Statistical Methods for Rates and Proportions. 2nd edition. New York: John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gliozzo</author>
<author>C Strapparava</author>
<author>I Dagan</author>
</authors>
<title>Unsupervised and Supervised Exploitation of Semantic Domains in Lexical Disambiguation.</title>
<date>2004</date>
<journal>Computer Speech and</journal>
<volume>18</volume>
<issue>3</issue>
<pages>275--299</pages>
<contexts>
<context position="2328" citStr="Gliozzo et al. 2004" startWordPosition="348" endWordPosition="351"> word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to a word in its context. Such an assignment requires a process of Word Domain Disambiguation (WDD) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to FINANCE or MARRIAGE). Interestingly enough, word subject domains have been widely used to improve the performance of Word Sense Disambiguation (WSD) algorithms (Wilks and Stevenson 1998, Magnini et al. 2001; Gliozzo et al. 2004). However, comparatively little effort has been devoted so far to the word domain disambiguation itself. The most notable exceptions are the work of Magnini and Strapparava (2000) and Suarez &amp; Palomar (2002). Both studies propose algorithms specific to the WDD task and have focused on the disambiguation of noun domains. In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation. Moreover, we extend the treatment of WDD to verbs and adjectives. Initial results show that this approach yield very strong results, suggesting that WDD </context>
</contexts>
<marker>Gliozzo, Strapparava, Dagan, 2004</marker>
<rawString>Gliozzo, A., C. Strapparava, I. Dagan (2004) Unsupervised and Supervised Exploitation of Semantic Domains in Lexical Disambiguation. Computer Speech and Language,18(3), Pages 275-299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Kohomban</author>
<author>W Lee</author>
</authors>
<title>Learning semantic classes for word sense disambiguation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual meeting of the Association for Computational Linguistics,</booktitle>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="4845" citStr="Kohomban &amp; Lee (2005)" startWordPosition="756" endWordPosition="760">ith top hypernym act#n#2. 2.2 Word Sense Disambiguation To assign a sense to each word in the input text, we used the WSD algorithm presented in Sanfilippo et al. (2006). This WSD algorithm is based on a supervised classification approach that uses SemCor1 as training corpus. The algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm (Berger et al. 1996) to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs. Following Dang &amp; Palmer (2005) and Kohomban &amp; Lee (2005), Sanfilippo et al. (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system. • Contextual information includes the verb under analysis plus three tokens found on each side of the verb, within sentence boundaries. Tokens included word as well as punctuation. • Syntactic information includes grammatical dependencies (e.g. subject, object) and morpho-syntactic features such as part of speech, case, number and tense. • Semantic information includes named entity types (e.g. person, location, organization) and hypernyms. We chose this WSD algorithm as</context>
</contexts>
<marker>Kohomban, Lee, 2005</marker>
<rawString>Kohomban, U. and W. Lee (2005) Learning semantic classes for word sense disambiguation. In Proceedings of the 43rd Annual meeting of the Association for Computational Linguistics, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavaglià</author>
</authors>
<title>Integrating Subject Field Codes into WordNet.</title>
<date>2000</date>
<booktitle>Proceedings of LREC2000, Second International Conference on Language Resources and Evaluation,</booktitle>
<pages>1413--1418</pages>
<location>Athens, Greece, 31</location>
<marker>Magnini, Cavaglià, 2000</marker>
<rawString>Magnini, B., Cavaglià, G. (2000) Integrating Subject Field Codes into WordNet. Proceedings of LREC2000, Second International Conference on Language Resources and Evaluation, Athens, Greece, 31 MAY- 2 JUNE 2000, pp. 1413-1418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>C Strapparava</author>
</authors>
<title>Experiments in Word Domain Disambiguation for Parallel Texts.</title>
<date>2000</date>
<booktitle>Proceedings of the ACL Workshop on Word Senses and Multilinguality, Hong-Kong,</booktitle>
<pages>27--33</pages>
<contexts>
<context position="2507" citStr="Magnini and Strapparava (2000)" startWordPosition="376" endWordPosition="379">s context. Such an assignment requires a process of Word Domain Disambiguation (WDD) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to FINANCE or MARRIAGE). Interestingly enough, word subject domains have been widely used to improve the performance of Word Sense Disambiguation (WSD) algorithms (Wilks and Stevenson 1998, Magnini et al. 2001; Gliozzo et al. 2004). However, comparatively little effort has been devoted so far to the word domain disambiguation itself. The most notable exceptions are the work of Magnini and Strapparava (2000) and Suarez &amp; Palomar (2002). Both studies propose algorithms specific to the WDD task and have focused on the disambiguation of noun domains. In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation. Moreover, we extend the treatment of WDD to verbs and adjectives. Initial results show that this approach yield very strong results, suggesting that WDD can be addressed in terms of word sense disambiguation with no need of special purpose algorithms. 141 Proceedings of the Human Language Technology Conference of the North America</context>
</contexts>
<marker>Magnini, Strapparava, 2000</marker>
<rawString>Magnini, B., Strapparava C. (2000) Experiments in Word Domain Disambiguation for Parallel Texts. Proceedings of the ACL Workshop on Word Senses and Multilinguality, Hong-Kong, October 7, 2000, pp. 27-33</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>C Strapparava</author>
<author>G Pezzulo</author>
<author>A Gliozzo</author>
</authors>
<title>Using Domain Information for Word Sense Disambiguation.</title>
<date>2001</date>
<booktitle>In Proceeding of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems,</booktitle>
<pages>111--114</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="2306" citStr="Magnini et al. 2001" startWordPosition="344" endWordPosition="347">. Successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to a word in its context. Such an assignment requires a process of Word Domain Disambiguation (WDD) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to FINANCE or MARRIAGE). Interestingly enough, word subject domains have been widely used to improve the performance of Word Sense Disambiguation (WSD) algorithms (Wilks and Stevenson 1998, Magnini et al. 2001; Gliozzo et al. 2004). However, comparatively little effort has been devoted so far to the word domain disambiguation itself. The most notable exceptions are the work of Magnini and Strapparava (2000) and Suarez &amp; Palomar (2002). Both studies propose algorithms specific to the WDD task and have focused on the disambiguation of noun domains. In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation. Moreover, we extend the treatment of WDD to verbs and adjectives. Initial results show that this approach yield very strong results</context>
</contexts>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2001</marker>
<rawString>Magnini, B., C. Strapparava, G. Pezzulo and A. Gliozzo (2001) Using Domain Information for Word Sense Disambiguation. In Proceeding of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguation Systems, pp. 111-114, 5-6 July 2001, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>C Strapparava</author>
<author>G Pezzulo</author>
<author>A Gliozzo</author>
</authors>
<date>2002</date>
<booktitle>The Role of Domain Information in Word Sense Disambiguation. Natural Language Engineering,</booktitle>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="3353" citStr="Magnini et al. (2002)" startWordPosition="512" endWordPosition="515">is achieved via word sense disambiguation. Moreover, we extend the treatment of WDD to verbs and adjectives. Initial results show that this approach yield very strong results, suggesting that WDD can be addressed in terms of word sense disambiguation with no need of special purpose algorithms. 141 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 141–144, New York, June 2006. c�2006 Association for Computational Linguistics Figure 1: Senses and domains for the word bank in WordNet Domains, with number of occurrences in SemCor, adapted from Magnini et al. (2002). 2 WDD via WSD Our approach relies on the use of WordNet Domains (Bagnini and Cavaglià 2000) and can be outlined in the following two steps: 1. use a WordNet-based WSD algorithm to assign a sense to each word in the input text, e.g. doctor 4 doctor#n#1 2. use WordNet Domains to map disambiguated words into the subject domain associated with the word, e.g. doctor#n#14doctor#n#1#MEDICINE. 2.1 WordNet Domains WordNet Domains is an extension of WordNet (http://wordnet.princeton.edu/) where synonym sets have been annotated with one or more subject domain labels, as shown in Figure 1. Subject domai</context>
</contexts>
<marker>Magnini, Strapparava, Pezzulo, Gliozzo, 2002</marker>
<rawString>Magnini, B., C. Strapparava, G. Pezzulo and A. Gliozzo (2002) The Role of Domain Information in Word Sense Disambiguation. Natural Language Engineering, 8(4):359—373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Mowatt</author>
</authors>
<title>Types of Semantic Information Necessary in a Machine Translation Lexicon. Conférence TALN, Cargèse,</title>
<date>1999</date>
<pages>12--17</pages>
<contexts>
<context position="1344" citStr="Mowatt (1999)" startWordPosition="193" endWordPosition="194">ields very strong results, suggesting that word domain disambiguation can be addressed in terms of word sense disambiguation with no need for special purpose algorithms. 1 Introduction Word subject domains have been ubiquitously used in dictionaries to help human readers pinpoint the specific sense of a word by specifying technical usage, e.g. see “subject field codes” in Procter (1978). In computational linguistics, word subject domains have been widely used to improve the performance of machine translation systems. For example, in a review of commonly used features in automated translation, Mowatt (1999) reports that most of the machine translation systems surveyed made use of word subject domains. Word subject domains have also been used in information systems. For example, Sanfilippo (1998) describes a summarization system where subject domains provide users with useful conceptual parameters to tailor summary requests to a user’s interest. Successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to a word in its context. Such an assignment requires a process of Word Domain Dis</context>
</contexts>
<marker>Mowatt, 1999</marker>
<rawString>Mowatt, D. (1999) Types of Semantic Information Necessary in a Machine Translation Lexicon. Conférence TALN, Cargèse, pp. 12-17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Procter</author>
</authors>
<title>Longman Dictionary o Contemporary English.</title>
<date>1978</date>
<publisher>Longman Group Ltd.,</publisher>
<location>Essex, UK.</location>
<contexts>
<context position="1120" citStr="Procter (1978)" startWordPosition="161" endWordPosition="162">velopment of algorithms specific to word domain disambiguation. In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation. Our study shows that this approach yields very strong results, suggesting that word domain disambiguation can be addressed in terms of word sense disambiguation with no need for special purpose algorithms. 1 Introduction Word subject domains have been ubiquitously used in dictionaries to help human readers pinpoint the specific sense of a word by specifying technical usage, e.g. see “subject field codes” in Procter (1978). In computational linguistics, word subject domains have been widely used to improve the performance of machine translation systems. For example, in a review of commonly used features in automated translation, Mowatt (1999) reports that most of the machine translation systems surveyed made use of word subject domains. Word subject domains have also been used in information systems. For example, Sanfilippo (1998) describes a summarization system where subject domains provide users with useful conceptual parameters to tailor summary requests to a user’s interest. Successful usage of word domain</context>
</contexts>
<marker>Procter, 1978</marker>
<rawString>Procter, Paul (Ed.) (1978) Longman Dictionary o Contemporary English. Longman Group Ltd., Essex, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sanfilippo</author>
</authors>
<title>Ranking Text Units According to Textual Saliency, Connectivity and Topic Aptness. COLING-ACL</title>
<date>1998</date>
<pages>1157--1163</pages>
<contexts>
<context position="1536" citStr="Sanfilippo (1998)" startWordPosition="223" endWordPosition="225">d subject domains have been ubiquitously used in dictionaries to help human readers pinpoint the specific sense of a word by specifying technical usage, e.g. see “subject field codes” in Procter (1978). In computational linguistics, word subject domains have been widely used to improve the performance of machine translation systems. For example, in a review of commonly used features in automated translation, Mowatt (1999) reports that most of the machine translation systems surveyed made use of word subject domains. Word subject domains have also been used in information systems. For example, Sanfilippo (1998) describes a summarization system where subject domains provide users with useful conceptual parameters to tailor summary requests to a user’s interest. Successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to a word in its context. Such an assignment requires a process of Word Domain Disambiguation (WDD) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to FINANCE or MARRIAGE). Interestingly </context>
</contexts>
<marker>Sanfilippo, 1998</marker>
<rawString>Sanfilippo, A. (1998) Ranking Text Units According to Textual Saliency, Connectivity and Topic Aptness. COLING-ACL 1998: 1157-1163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Sanfilippo</author>
<author>S Tratz</author>
<author>M Gregory</author>
<author>P Whitney A Chappell</author>
<author>C Posse</author>
<author>P Paulson</author>
<author>B Baddeley</author>
<author>R Hohimer</author>
<author>A White</author>
</authors>
<title>Automating Ontological Annotation with WordNet.</title>
<date>2006</date>
<booktitle>Proceedings of the 3rd Global WordNet Conference, Jeju Island, South Korea,</booktitle>
<contexts>
<context position="4393" citStr="Sanfilippo et al. (2006)" startWordPosition="683" endWordPosition="687">et Domains is an extension of WordNet (http://wordnet.princeton.edu/) where synonym sets have been annotated with one or more subject domain labels, as shown in Figure 1. Subject domains provide an interesting and useful classification which cuts across part of speech and WordNet sub-hierarchies. For example, doctor#n#1 and operate#n#1 both have subject domain MEDICINE, and SPORT includes both athlete#n#1 with top hypernym lifeform#n#1 and sport#n#1 with top hypernym act#n#2. 2.2 Word Sense Disambiguation To assign a sense to each word in the input text, we used the WSD algorithm presented in Sanfilippo et al. (2006). This WSD algorithm is based on a supervised classification approach that uses SemCor1 as training corpus. The algorithm employs the OpenNLP MaxEnt implementation of the maximum entropy classification algorithm (Berger et al. 1996) to develop word sense recognition signatures for each lemma which predicts the most likely sense for the lemma according to the context in which the lemma occurs. Following Dang &amp; Palmer (2005) and Kohomban &amp; Lee (2005), Sanfilippo et al. (2006) use contextual, syntactic and semantic information to inform our verb class disambiguation system. • Contextual informati</context>
<context position="5794" citStr="Sanfilippo et al. 2006" startWordPosition="893" endWordPosition="896">ion includes grammatical dependencies (e.g. subject, object) and morpho-syntactic features such as part of speech, case, number and tense. • Semantic information includes named entity types (e.g. person, location, organization) and hypernyms. We chose this WSD algorithm as it provides some of the best published results to date, as the comparison with top performing WSD systems in Senseval3 presented in Table 1 shows---see http://www.senseval.org and Snyder &amp; Palmer (2004) for terms of reference on Senseval3. 1 http://www.cs.unt.edu/~rada/downloads.html. 142 System Precision Fraction of Recall Sanfilippo et al. 2006 61% 22% GAMBL 59.0% 21.3% SenseLearner 56.1% 20.2% Baseline 52.9% 19.1% Table 1: Results for verb sense disambiguation on Senseval3 data, adapted from Sanfilippo et al. (2006). 3 Evaluation To evaluate our WDD approach, we used both the SemCor and Senseval3 data sets. Both corpora were stripped of their sense annotations and processed with an extension of the WSD algorithm of Sanfilippo et al. (2006) to assign a WordNet sense to each noun, verb and adjective. The extension consisted in extending the training data set so as to include a selection of WordNet examples (full sentences containing </context>
</contexts>
<marker>Sanfilippo, Tratz, Gregory, Chappell, Posse, Paulson, Baddeley, Hohimer, White, 2006</marker>
<rawString>Sanfilippo, A., S. Tratz, M. Gregory, A.Chappell, P. Whitney, C. Posse, P. Paulson, B. Baddeley, R. Hohimer, A. White. (2006) Automating Ontological Annotation with WordNet. Proceedings of the 3rd Global WordNet Conference, Jeju Island, South Korea, Jan 19-26 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Snyder</author>
<author>M Palmer</author>
</authors>
<title>The English allwords task.</title>
<date>2004</date>
<booktitle>SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text.</booktitle>
<location>Barcelona,</location>
<contexts>
<context position="5648" citStr="Snyder &amp; Palmer (2004)" startWordPosition="875" endWordPosition="878">is plus three tokens found on each side of the verb, within sentence boundaries. Tokens included word as well as punctuation. • Syntactic information includes grammatical dependencies (e.g. subject, object) and morpho-syntactic features such as part of speech, case, number and tense. • Semantic information includes named entity types (e.g. person, location, organization) and hypernyms. We chose this WSD algorithm as it provides some of the best published results to date, as the comparison with top performing WSD systems in Senseval3 presented in Table 1 shows---see http://www.senseval.org and Snyder &amp; Palmer (2004) for terms of reference on Senseval3. 1 http://www.cs.unt.edu/~rada/downloads.html. 142 System Precision Fraction of Recall Sanfilippo et al. 2006 61% 22% GAMBL 59.0% 21.3% SenseLearner 56.1% 20.2% Baseline 52.9% 19.1% Table 1: Results for verb sense disambiguation on Senseval3 data, adapted from Sanfilippo et al. (2006). 3 Evaluation To evaluate our WDD approach, we used both the SemCor and Senseval3 data sets. Both corpora were stripped of their sense annotations and processed with an extension of the WSD algorithm of Sanfilippo et al. (2006) to assign a WordNet sense to each noun, verb and </context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Snyder, B. and M. Palmer. 2004. The English allwords task. SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Suárez</author>
<author>M Palomar</author>
</authors>
<title>Word sense vs. word domain disambiguation: a maximum entropy approach.</title>
<date>2002</date>
<booktitle>Text, Speech and Dialogue (TSD 2002). Volume 2448 of Lecture Notes in Artificial Intelligence,</booktitle>
<pages>131--138</pages>
<editor>In Sojka P., Kopecek I., Pala K., eds.:</editor>
<publisher>Springer,</publisher>
<marker>Suárez, Palomar, 2002</marker>
<rawString>Suárez, A., Palomar, M. (2002) Word sense vs. word domain disambiguation: a maximum entropy approach. In Sojka P., Kopecek I., Pala K., eds.: Text, Speech and Dialogue (TSD 2002). Volume 2448 of Lecture Notes in Artificial Intelligence, Springer, (2002) 131—138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wilks</author>
<author>M Stevenson</author>
</authors>
<title>Word sense disambiguation using optimised combinations of knowledge sources.</title>
<date>1998</date>
<booktitle>Proceedings of the 17th international conference on Computational Linguistics,</booktitle>
<pages>1398--1402</pages>
<contexts>
<context position="2285" citStr="Wilks and Stevenson 1998" startWordPosition="340" endWordPosition="343">uests to a user’s interest. Successful usage of word domains in applications such as machine translation and summarization is strongly dependent on the ability to assign the appropriate subject domain to a word in its context. Such an assignment requires a process of Word Domain Disambiguation (WDD) because the same word can often be assigned different subject domains out of context (e.g. the word partner can potentially be related to FINANCE or MARRIAGE). Interestingly enough, word subject domains have been widely used to improve the performance of Word Sense Disambiguation (WSD) algorithms (Wilks and Stevenson 1998, Magnini et al. 2001; Gliozzo et al. 2004). However, comparatively little effort has been devoted so far to the word domain disambiguation itself. The most notable exceptions are the work of Magnini and Strapparava (2000) and Suarez &amp; Palomar (2002). Both studies propose algorithms specific to the WDD task and have focused on the disambiguation of noun domains. In this paper we explore an alternative approach where word domain disambiguation is achieved via word sense disambiguation. Moreover, we extend the treatment of WDD to verbs and adjectives. Initial results show that this approach yiel</context>
<context position="9649" citStr="Wilks and Stevenson (1998)" startWordPosition="1530" endWordPosition="1533">the paper to achieve commensurability with the results reported by Suarez and Palomar. 5 Conclusions and Further Work Current approaches to WDD have assumed that special purpose algorithms are needed to model the WDD task. We have shown that very competitive and perhaps unrivaled results (pending on evaluation of our WDD algorithm with the DSO corpus) can be obtained using WSD as the basis for subject domain assignment. This improvement in WDD performance can be used to 3 http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp?cata logId=LDC97T12. 143 obtain further gains in WSD accuracy, following Wilks and Stevenson (1998), Magnini et al. (2001) and Gliozzo et al. (2004). A more accurate WSD model will in turn yield yet better WDD results, as demonstrated in this paper. Consequently, further improvements in accuracy for both WSD and WDD can be expected through a bootstrapping cycle where WDD results are fed as input to the WSD process, and the resulting improved WSD model is then used to achieve better WDD results. We intend to explore this possibility in future extensions of this work. Acknowledgements We would like to thank Paul Whitney for help with the evaluation of the results presented in Section 3. Refer</context>
</contexts>
<marker>Wilks, Stevenson, 1998</marker>
<rawString>Wilks, Y. and Stevenson, M. (1998) Word sense disambiguation using optimised combinations of knowledge sources. Proceedings of the 17th international conference on Computational Linguistics, pp. 1398—1402.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>