<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000018">
<title confidence="0.77336">
Measuring frame relatedness
</title>
<author confidence="0.913592">
Marco Pennacchiotti Michael Wirth
</author>
<affiliation confidence="0.882065">
Yahoo! Inc. Computational Linguistics
</affiliation>
<address confidence="0.949955">
Santa Clara, CA 95054 Saarland University, Germany
</address>
<email confidence="0.99332">
pennac@yahoo-inc.com miwirth@coli.uni-sb.de
</email>
<sectionHeader confidence="0.994695" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998935818181818">
In this paper we introduce the notion
of “frame relatedness”, i.e. relatedness
among prototypical situations as repre-
sented in the FrameNet database. We first
demonstrate the cognitive plausibility of
that notion through an annotation experi-
ment, and then propose different types of
computational measures to automatically
assess relatedness. Results show that our
measures provide good performance on
the task of ranking pairs of frames.
</bodyText>
<sectionHeader confidence="0.998425" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998036461538462">
Measuring relatedness among linguistic entities
is a crucial topic in NLP. Automatically assess-
ing the degree of similarity or relatedness be-
tween two words or two expressions, is of great
help in a variety of tasks, such as Question An-
swering, Recognizing Textual Entailment (RTE),
Information Extraction and discourse processing.
Since the very beginning of computational lin-
guistics, many studies have been devoted to the
definition and the implementation of automatic
measures for word relatedness (e.g. (Ruben-
stein and Goodenough, 1965; Resnik, 1995; Lin,
1998; Budanitsky and Hirst, 2006; Mohammad
and Hirst, 2006)). More recently, relatedness
between lexical-syntactic patterns has also been
studied (Lin and Pantel, 2001; Szpektor et al.,
2004), to support advanced tasks such as para-
phrasing and RTE. Unfortunately, no attention has
been paid so far to the definition of relatedness at
the more abstract situational level – i.e. related-
ness between two prototypical actions, events or
state-of-affairs, taken out of context (e.g. the sit-
uations of Killing and Death). A prominent defi-
nition of “prototypical situation” is given in frame
semantics (Fillmore, 1985), where a situation is
modelled as a conceptual structure (a frame) con-
stituted by the predicates that can evoke the situ-
ation, and the semantic roles expressing the situa-
tion’s participants.
As measures of word relatedness help in discov-
ering if two word occurrences express related con-
cepts, so measures of frame relatedness should
help to discover if two large text fragments are re-
lated or talk about similar situations. Such mea-
sures would be valuable in many tasks. For exam-
ple, consider the following fragment, in the con-
text of discourse processing:
“In the 1950s the Shah initiated Iran ’s nu-
clear research program and developed an ambi-
tious plan to produce 23,000MW from nuclear
power. The program was stopped by the Islamic
Revolution in 1979, but it was revived later in the
decade, when strategic interests began to drive the
nuclear program.”
The underlined words evoke highly related
frames, namely ACTIVITY START, ACTIV-
ITY STOP and CAUSE TO RESUME. This could
suggest to link the three textual fragments associ-
ated to the words, into a single coherent discourse
unit, where the semantic roles of the different
fragments can be easily mapped as co-referential
(e.g. “Iran’s nuclear research program” - “The
program” - “it”). Frame relatedness can also
help in RTE. Consider for example the following
entailment pair:
Text : “An avalanche has struck a popular skiing
resort in Austria, killing at least 11 people.”
Hypothesis: “Humans died in an avalanche.”
The frames KILLING and DEATH, respectively
evoked by killing and died, are highly related and
can then be mapped. Leveraging this mapping, an
RTE system could easily discover that the Text en-
tails the Hypothesis, by verifying that the fillers of
the mapped semantic roles of the two frames are
semantically equivalent.
</bodyText>
<note confidence="0.923042">
Proceedings of the 12th Conference of the European Chapter of the ACL, pages 657–665,
Athens, Greece, 30 March – 3 April 2009. c�2009 Association for Computational Linguistics
</note>
<page confidence="0.997174">
657
</page>
<bodyText confidence="0.9998946">
In this paper we investigate the notion of re-
latedness in the context of frame semantics, and
propose different types of automatic measures to
compute relatedness between frames. Our main
contributions can be summarized as follows: (1)
We empirically show that the notion of frame re-
latedness is intuitive and principled from a cogni-
tive perspective: to support this claim, we report
agreement results over a pool of human annota-
tors on the task of ranking frame pairs on relat-
edness; (2) We propose a variety of measures for
computing frame relatedness, inspired by differ-
ent approaches and by existing measures for word
relatedness; (3) We show that our measures offer
good performance, thus opening the path to the use
of frame relatedness as a practical tool for NLP,
and showing that measures for word relatedness
can be successfully adapted to frames. The paper
is organized as follows. In Section 2 we summa-
rize related work. In Section 3 we describe the ex-
periment of humans ranking frame pairs, and dis-
cuss the results. In Section 4 and 5 we respectively
introduce our relatedness measures, and test them
over a manual gold standard. In Section 6 we draw
final conclusions and outline future work.
</bodyText>
<sectionHeader confidence="0.999787" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999817255813954">
Much research in NLP has studied similarity and
relatedness between words. Rubenstein and Good-
enough (1965) were the first to propose a pro-
cedure to assess human agreement on ranking
pairs of words on relatedness. Their experi-
ment was later replicated by Resnik (1995) and
Charles (2000). All these studies reported good
levels of agreements among annotators, suggest-
ing that the notion of word relatedness is cogni-
tively principled. In our experiment in Section 3.2
we apply the same procedure to assess agreement
on ranking frames.
Measures for estimating word relatedness have
been systematically proposed since the early 90’s,
and are today widely used in NLP for various
tasks. Most measures can be classified either as
corpus-based or ontology-based. Corpus-based
measures compute relatedness looking at the dis-
tributional properties of the two words: words that
tend to co-occur in the same contexts or having
similar distributional profiles, are deemed to be
highly related. A complete survey on these mea-
sures is reported in (Mohammad and Hirst, 2006).
Ontology-based measures estimate relatedness by
studying the path connecting the two words in an
ontology or a hierarchical lexicon (e.g. WordNet).
The basic idea is that closer words are more related
than distant ones. Budanitsky and Hirst (2006)
provide an extensive survey of these measures.
Budanitsky and Hirst (2006) also point out an
important distinction, between relatedness and
similarity. Two words are related if any type of
relation stands between them, e.g. antonymy or
meronymy; they are similar when related through
an is-a like hierarchy. Similarity is then a spe-
cial case of relatedness. Following Budanitsky and
Hirst (2006), we consider two frames as similar if
they are linked via is-a like relations (e.g. GET-
TING and COMMERCE BUY), while as related if
any relation stands between them (e.g. causation
between KILLING and DEATH). In this paper, we
focus our attention solely on the notion of frame
relatedness.
</bodyText>
<sectionHeader confidence="0.981357" genericHeader="method">
3 Defining frame relatedness
</sectionHeader>
<bodyText confidence="0.99994">
In this section we check if the notion of frame re-
latedness is intuitive and principled from a cog-
nitive perspective. In Section 3.1 we first intro-
duce the basic concepts or frame semantics; in
Section 3.2 we report the agreement results ob-
tained by human annotators, on the task of ranking
a dataset of frame pairs according to relatedness.
</bodyText>
<subsectionHeader confidence="0.999978">
3.1 Frame Semantics and FrameNet
</subsectionHeader>
<bodyText confidence="0.999961904761905">
Frame semantics (Fillmore, 1985) seeks to de-
scribe the meaning of a sentence as it is actu-
ally understood by characterizing the background
knowledge necessary to understand the sentence.
Background knowledge is represented in the form
of frames, conceptual structures modelling proto-
typical situations. Linguistically, a frame is a se-
mantic class containing predicates called lexical
units (LU), that can evoke the described situation
(see example in Table 1). Each frame comes with
its own set of semantic roles, called frame ele-
ments (FE). These are the participants and props in
the abstract situation described. Roles are local to
individual frames, thus avoiding the commitment
to a small set of universal roles, whose specifica-
tion has turned out to be unfeasible in the past.
The Berkeley FrameNet project (Baker et al.,
1998) has been developing a frame-semantic lexi-
con for the core vocabulary of English since 1997.
The current FrameNet release contains about 800
frames and 10,000 lexical units. Part of FrameNet
</bodyText>
<page confidence="0.996191">
658
</page>
<subsectionHeader confidence="0.345423">
Frame: STATEMENT
</subsectionHeader>
<bodyText confidence="0.981689">
This frame contains verbs and nouns that communicate
the act of a SPEAKER to address a MESSAGE to some
ADDRESSEE using language. A number of the words
can be used performatively, such as declare and insist.
</bodyText>
<figure confidence="0.942948857142857">
SPEAKER Evelyn said she wanted to leave.
MESSAGE Evelyn announced that she wanted
to leave.
ADDRESSEE Evelyn spoke to me about her past.
TOPIC Evelyn’s statement about her past
MEDIUM Evelyn preached to me over the
phone.
</figure>
<tableCaption confidence="0.67285775">
acknowledge.v, acknowledgment.n, add.v, ad-
dress.v, admission.n, admit.v, affirm.v, affirma-
tion.n, allegation.n, allege.v, announce.v, ...
Table 1: Example frame from FrameNet.
</tableCaption>
<bodyText confidence="0.998410869565218">
is also a corpus of annotated example sentences
from the British National Corpus, currently con-
taining 135,000 sentences.
In FrameNet, asymmetric frame relations can
relate two frames, forming a complex hierarchy
(Ruppenhofer et al., 2005): Inheritance: anything
true in the semantics of the parent frame, must
also be true for the other (e.g. KILLING – EX-
ECUTION). Uses: a part of the situation evoked
by one frame refers to the other. Subframe: one
frame describes a subpart of a complex situation
described in the other (e.g. CRIMINAL-PROCESS
– SENTENCING). Causative of : the action in
one frame causes the event described in the other
(e.g. KILLING – DEATH). Inchoative of: the
event in one frame ends in the state described in
the other (e.g. DEATH – DEAD OR ALIVE). Pre-
cedes: one frame temporally proceeds the other
(e.g. FALL ASLEEP – SLEEP). Perspective on:
one frame describes a specific point-of-view on a
neutral frame.
The first two are is-a like relations, while the
others are non-hierarchical.
</bodyText>
<subsectionHeader confidence="0.999744">
3.2 Manually ranking related frames
</subsectionHeader>
<bodyText confidence="0.999978118644068">
We asked a pool of human annotators to manually
rank a set of frame pairs according to their relat-
edness. The goal was twofolds. First, we wanted
to check how intuitive the notion of frame related-
ness is, by computing inter-annotator agreement,
and by comparing the agreement results to those
obtained by Rubenstein and Goodenough (1965)
for word relatedness. Second, we planned to use
the produced dataset as a gold standard for test-
ing the relatedness measures, as described in Sec-
tion 5. In the rest of the section we describe the
annotation process in detail.
Dataset creation. We created two different
datasets, a simple and a controlled set, each con-
taining 155 pairs. Frame pairs in the simple
set were randomly selected from the FrameNet
database. Frame pairs in the controlled set were
either composed of two frames belonging to the
same scenario1, or being so that one frame is one
edge from the scenario of the other. This ensured
that all pairs in the controlled set contained seman-
tically related frames. Indeed, we use the con-
trolled set to check if human agreement and au-
tomatic measure accuracy get better when consid-
ering only highly related frames.
Human ranking agreement. A preliminary an-
notation phase involved a group of 15 annotators
consisting of graduate students and researchers,
native or nearly native speakers of English. For
each set, each annotator was given 15 frame pairs
from the original 155 set: 5 of these where shared
with all other annotators. This setting has three
advantages: (1) The set is small enough to obtain
a reliable annotation in a short time; (2) We can
compute the agreement among the 15 annotators
over the shared pairs; (3) We can check the relia-
bility of the final gold standard created in the sec-
ond phase (see following section) by comparing to
the annotations. Each annotator was asked to or-
der a shuffled deck of 15 cards, each one describ-
ing a pair of frames. The card contained the fol-
lowing information about the two frames: names;
definitions; the lists of core FEs; a frame anno-
tated sentence for each frame, randomly chosen
from the FrameNet database. Similarly to Ruben-
stein and Goodenough (1965) we gave the anno-
tators the following instructions: (i) After looking
through the whole deck, order the pairs according
to amount of relatedness; (ii) You may assign the
same rank to pairs having the same degree of re-
latedness (i.e. ties are allowed).
We checked the agreement among the 15 an-
notators in ranking the 5 shared pairs by using
the Kendall’s T correlation coefficient (Kendall,
1938). Kendall’s T can be interpreted as the dif-
ference between the probability that in the dataset
two variables are in the same order versus the
probability that they are in different orders (see
(Lapata, 2006) for details). The average corre-
</bodyText>
<footnote confidence="0.8204518">
1A scenario frame is a “hub” frame describing a gen-
eral topic; specific frames modelling situations related to the
topic are linked to it (e.g. COMMERCE BUY and COMMER-
CIAL TRANSACTION are linked to COMMERCE SCENARIO).
FrameNet contains 16 scenarios.
</footnote>
<figure confidence="0.536413666666667">
FEs
FEs
LUs
</figure>
<page confidence="0.984219">
659
</page>
<bodyText confidence="0.999895756756757">
lation2 among annotators on the simple and con-
trolled sets was r = 0.600 and r = 0.547.
Gold standard ranking. The final dataset was
created by two expert annotators, jointly working
to rank the 155 pairs collected in the data creation
phase. We computed the rank correlation agree-
ment between this annotation and the 15 annota-
tion produced in the first stage. We obtained an av-
erage Kendall’s r = 0.530 and r = 0.566 respec-
tively on the simple and controlled sets (Standard
deviations from the average are StdDev = 0.146
and StdDev = 0.173). These results are all statis-
tically significant at the 99% level, indicating that
the notion of “frame relatedness” is intuitive and
principled for humans, and that the final datasets
are reliable enough to be used as gold standard for
our experiments. Table 2 reports the first and last
5 ranked frame pairs for the two datasets.
We compared the correlation results obtained
above on “frame relatedness”, to those derived
from previous works on “word relatedness”. This
comparison should indicate if ranking related
frames (i.e. situations) is more or less complex
and intuitive than ranking words.3 As for words,
we computed the average Kendall’s T among three
different annotation efforts (namely, (Rubenstein
and Goodenough, 1965; Resnik, 1995; Charles,
2000)) carried out over a same dataset of 28 word
pairs originally created by Rubenstein and Goode-
nough. Note that the annotation schema followed
in the three works is the same as ours. We ob-
tained a Kendall’s r = 0.775, which is statisti-
cally significant at the 99% level. As expected,
the correlation for word relatedness is higher than
for frames: Humans find it easier to compare two
words than two complex situations, as the former
are less complex linguistic entities than the latter.
</bodyText>
<sectionHeader confidence="0.997997" genericHeader="method">
4 Measures for frame relatedness
</sectionHeader>
<bodyText confidence="0.99728675">
Manually computing relatedness between all pos-
sible frame pairs in FrameNet is an unfeasible
task. The on-going FrameNet project and auto-
matic methods for FrameNet expansion (e.g. (Pen-
</bodyText>
<footnote confidence="0.776973555555556">
2Average correlation is computed by averaging the T ob-
tained on each pair of annotators, as suggested in (Siegel and
Castellan, 1988); note that the obtained value corresponds
to the Kendall u correlation coefficient. Ties are properly
treated with the correction factor described in (Siegel and
Castellan, 1988).
3The comparison should be taken only as indicative, as
words can be ambiguous while frames are not. A more prin-
cipled comparison should involve word senses, not words.
</footnote>
<bodyText confidence="0.9638104">
nacchiotti et al., 2008)) are expected to produce an
ever growing set of frames. The definition of auto-
matic measures for frame relatedness is thus a key
issue. In this section we propose different types of
such measures.
</bodyText>
<subsectionHeader confidence="0.966407">
4.1 WordNet-based measures
</subsectionHeader>
<bodyText confidence="0.9995568">
WordNet-based measures estimate relatedness by
leveraging the WordNet hierarchy. The hypothesis
is that two frames whose sets of LUs are close in
WordNet are likely to be related. We assume that
LUs are sense-tagged, i.e. we know which Word-
Net senses of a LU map to a given frame. For ex-
ample, among the 25 senses of the LU charge.v,
only the sense charge.v#3 (“demand payment”)
maps to the frame COMMERCE COLLECT.
Given a frame F, we define SF as the set
of all WordNet senses that map to any frame’s
LU (e.g. for COMMERCE COLLECT, SF con-
tains charge.v#3, collect.v#4, bill.v#1). A generic
WordNet-based measure is then defined as fol-
lows:
</bodyText>
<equation confidence="0.989879333333333">
wn rel(s1, s2)
|SF1 |- |SF2|
(1)
</equation>
<bodyText confidence="0.99940775">
where wn rel(s1, s2) is a sense function estimat-
ing the relatedness between two senses in Word-
Net. Since we focus on frame relatedness, we
are interested in assigning high scores to pairs of
senses which are related by any type of relations
in WordNet (i.e. not limited to is-a). We there-
fore adopt as function wn rel the Hirst-St.Onge
measure (Hirst and St.Onge, 1998) as it accounts
for different relations. We also experiment with
the Jiang and Conrath’s (Jiang and Conrath, 1997)
measure which relies only on the is-a hierarchy,
but proved to be the best WordNet-based mea-
sure in the task of ranking words (Budanitsky
and Hirst, 2006). We call the frame relatedness
measures using the two functions respectively as
wn hso(F1, F2) and wn jen(F1, F2).
</bodyText>
<subsectionHeader confidence="0.929338">
4.2 Corpus-based measures
</subsectionHeader>
<bodyText confidence="0.9964284">
Corpus-based measures compute relatedness look-
ing at the distributional properties of the two
frames over a corpus. The intuition is that related
frames should occur in the same or similar con-
texts.
</bodyText>
<figure confidence="0.6994426">
wn(F1, F2) =
11
s1ESF1
11
s2ESF2
</figure>
<page confidence="0.908897">
660
</page>
<table confidence="0.999890416666667">
SIMPLE SET CONTROLLED SET
Measure volume - Measure mass (1) Knot creation - Rope manipulation (1,5)
Communication manner - Statement (2) Shoot projectiles - Use firearm (1,5)
Giving - Sent items (3) Scouring - Scrutiny (3)
Abundance - Measure linear extent (4) Ambient temperature - Temperature (4)
Remembering information - Reporting (5) Fleeing - Escaping (5)
... ...
Research - Immobilization (126) Reason - Taking time (142)
Resurrection - Strictness (126) Rejuvenation - Physical artworks (142)
Social event - Word relations (126) Revenge - Bungling (142)
Social event - Rope manipulation (126) Security - Likelihood (142)
Sole instance - Chatting (126) Sidereal appearance - Aggregate (142)
</table>
<tableCaption confidence="0.99961">
Table 2: Human gold standard ranking: first and last 5 ranked pairs (in brackets ranks allowing ties).
</tableCaption>
<subsubsectionHeader confidence="0.693403">
4.2.1 Co-occurrence measures
</subsubsectionHeader>
<bodyText confidence="0.999938666666667">
Given two frames F1 and F2, the co-occurrence
measure computes relatedness as the pointwise
mutual information (pmi) between them:
</bodyText>
<equation confidence="0.999745">
P(F1, F2)
pmi(F1, F2) = log2 (2)
P(F1)P(F2)
</equation>
<bodyText confidence="0.99970675">
Given a corpus C consisting of a set of documents
c ∈ C, we estimate pmi as the number of contexts
in the corpus (either documents or sentences)4 in
which the two frames co-occur:
</bodyText>
<equation confidence="0.999323">
cr occ(F1, F2) = log2 |CF1,F2|
|CF1||CF2 |(3)
</equation>
<bodyText confidence="0.9995958">
where CFi is the set of documents in which Fi oc-
curs, and CF1,F2 is the set of documents in which
F1 and F2 co-occur. A frame Fi is said to occur in
a document if at least one of its LUs lFi occurs in
the document, i.e.:
</bodyText>
<equation confidence="0.9998535">
CFi = {c ∈ C : ∃lFi in c} (4)
CF1,F2 = {c ∈ C : ∃lF1 and ∃lF2 in c} (5)
</equation>
<bodyText confidence="0.998686411764706">
A limitation of the above measure is that it does
not treat ambiguity. If a word is a LU of a frame
F , but it occurs in a document with a sense
s ∈/ SF , it still counts as a frame occurrence.
For example, consider the word charge.v, whose
third sense charge.v#3 maps in FrameNet to COM-
MERCE COLLECT. In the sentence: “Tripp Isen-
hour was charged with killing a hawk on pur-
pose”, charge.v co-occurs with kill.v, which in
FrameNet maps to KILLING. The sentence would
then result as a co-occurrence of the two above
frames. Unfortunately this is not the case, as
the sentence’s sense charge.v#2 does not map to
the frame. Ideally, one could solve the problem
by using a sense-tagged corpus where senses’ oc-
currences are mapped to frames. While sense-
to-frame mappings exist (e.g. mapping between
</bodyText>
<footnote confidence="0.984191">
4For sake of simplicity in the rest of the section we refer
to documents, but the same holds for sentences.
</footnote>
<figureCaption confidence="0.8510788">
frames and WordNet senses in (Shi and Mihal-
cea, 2005)), sense-tagged corpora large enough for
distributional studies are not yet available (e.g.,
the SemCor WordNet-tagged corpus (Miller et al.,
1993) consists of only 700,000 words).
</figureCaption>
<bodyText confidence="0.9999405">
We therefore circumvent the problem, by imple-
menting pmi in a weighted co-occurrence mea-
sure, which gives lower weights to co-occurrences
of ambiguous words:
</bodyText>
<equation confidence="0.99743025">
11 wF1(c) - wF2(c)
cECF1,F2
11 wF1(c) -
cECF2
</equation>
<bodyText confidence="0.999767125">
The weighting function wF(c) estimates the
probability that the document c contains a LU
of the frame F in the correct sense. For-
mally, given the set of senses Sl of a LU (e.g.
charge.v#1...charge.v#24), we define SlF as the set
of senses mapping to the frame (e.g. charge.v#3
for COMMERCE COLLECT). The weighting func-
tion is then:
</bodyText>
<equation confidence="0.999688">
wF (c) = arg max P(SlF |lF) (7)
lF ELF in c
</equation>
<bodyText confidence="0.973548666666667">
where LF is the set of LUs of F. We estimate
P(SlF |lF) by counting sense occurrences of lF
over the SemCor corpus:
</bodyText>
<equation confidence="0.99073">
P(SlF |lF) = |SlF  |(8)
|Sl|
</equation>
<bodyText confidence="0.999803857142857">
In other terms, a frame receives a high weight in
a document when the document contains a LU
whose most frequent senses are those mapped to
the frame.5 For example, in the sentence: “Tripp
Isenhour was charged with killing a hawk on pur-
pose.”, wF(c) = 0.17, as charge.v#3 is not very
frequent in SemCor.
</bodyText>
<footnote confidence="0.9708905">
5In Eq.8 we use Lidstone smoothing (Lidstone, 1920) to
account for unseen senses in SemCor. Also, if a LU does not
occur in SemCor, an equal probability (corresponding to the
inverse of the number of word’s senses) is given to all senses.
</footnote>
<equation confidence="0.8800156">
cr wgt(F1, F2) = log2
11
c�CF1
wF2(c)
(6)
</equation>
<page confidence="0.985856">
661
</page>
<subsubsectionHeader confidence="0.634063">
4.2.2 Distributional measure
</subsubsectionHeader>
<bodyText confidence="0.995422692307692">
The previous measures promote (i.e. give a higher
rank to) frames co-occurring in the same con-
texts. The distributional measure promotes frames
occurring in similar contexts. The distributional
hypothesis (Harris, 1964) has been widely and
successfully used in NLP to compute relatedness
among words (Lin, 1998), lexical patterns (Lin
and Pantel, 2001), and other entities. The underly-
ing intuition is that target entities occurring in sim-
ilar contexts are likely to be semantically related.
In our setting, we consider either documents and
sentences as valid contexts.
Each frame F is modelled by a distributional
</bodyText>
<equation confidence="0.4758525">
�
vector F, whose dimensions are documents. The
</equation>
<bodyText confidence="0.9968846">
value of each dimension expresses the association
ratio A(F, c) between a document c and the frame.
We say that a document is highly associated to a
frame when most of the FrameNet LUs it contains,
map to the given frame in the correct senses:
</bodyText>
<equation confidence="0.999813333333333">
E P(SlF |lF)
lELF in c
P(SlFi |lFi) (9)
</equation>
<bodyText confidence="0.784214857142857">
where F is the set of all FrameNet frames, and
P(SlF |lF) is as in Eq. 8. We then compute relat-
edness between two frames using cosine similar-
ity:
When we use sentences as contexts we re-
fer to cr dist sent(F1, F2), otherwise to
cr dist doc(F1, F2)
</bodyText>
<subsectionHeader confidence="0.995072">
4.3 Hierarchy-based measures
</subsectionHeader>
<bodyText confidence="0.999892307692308">
A third family or relatedness measures leverages
the FrameNet hierarchy. The hierarchy forms a
directed graph of 795 nodes (frames), 1136 edges,
86 roots, 7 islands and 26 independent compo-
nents. Similarly to measures for word related-
ness, we here compute frame relatedness leverag-
ing graph-based measures over the FrameNet hi-
erarchy. The intuition is that the closer in the hier-
archy two frames are, the more related they are6.
We here experiment with the Hirst-St.Onge and
the Wu and Palmer (Wu and Palmer, 1994) mea-
sures, as they are pure taxonomic measures, i.e.
they do not require any corpus statistics.
</bodyText>
<footnote confidence="0.957529666666667">
6The Pathfinder Through FrameNet tool gives a prac-
tical proof of this intuition: http://fnps.coli.
uni-saarland.de/pathsearch.
</footnote>
<bodyText confidence="0.966883">
WU and Palmer: this measure calculates relat-
edness by considering the depths of the two frames
in the hierarchy, along with the depth of their least
common subsumer (LCS):
</bodyText>
<equation confidence="0.998388">
2·dp(LCS)
hr wu(F1, F2) =
ln(F1, LCS)+ln(F2, LCS)+2·dp(LCS)
(11)
</equation>
<bodyText confidence="0.98588475">
where ln is the length of the path connecting two
frames, and dp is the length of the path between
a frame and a root. If a path does not exist, then
hr wu(F1, F2) = 0.
Hirst-St.Onge: two frames are semantically
close if they are connected in the FrameNet hier-
archy through a “not too long path which does not
change direction too often”:
</bodyText>
<equation confidence="0.862184">
hr hso(F1, F2) = M − path length −k ·d (12)
</equation>
<bodyText confidence="0.99999825">
where M and and k are constants, and d is the
number of changes of direction in the path. If a
path does not exist, hr hso(F1, F2) = 0. For both
measures we consider as valid edges all relations.
The FrameNet hierarchy also provides for each
relation a partial or complete FE mapping between
the two linked frames (for example the role Vic-
tim of KILLING maps to the role Protagonist of
DEATH). We leverage this property implementing
a FE overlap measure, which given the set of FEs
of the two frames, FE1 and FE2 , computes re-
latedness as the percentage of mapped FEs:
</bodyText>
<equation confidence="0.935104666666667">
hrF F =
2) I FE1 n FE2  |(13)
f e (i, max (I FE1 |, |FE2|)
</equation>
<bodyText confidence="0.996221833333333">
The intuition is that FE overlap between frames
is a more fine grained and accurate predictor of
relatedness wrt. simple frame relation measures
as those above – i.e. two frames are highly related
not only if they describe connected situations, but
also if they share many participants.
</bodyText>
<sectionHeader confidence="0.998176" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999997375">
We evaluate the relatedness measures by compar-
ing their rankings over the two datasets described
in Section 3.2, using the manual gold standard an-
notation as reference. As evaluation metrics we
use Kendall’s T. As baselines, we adopt a def-
inition overlap measure that counts the percent-
age of overlapping content words in the definition
of the two frames;7 and a LU overlap baseline
</bodyText>
<footnote confidence="0.626773">
7We use stems of nouns, verbs and adjectives.
</footnote>
<equation confidence="0.8427069">
cr dist(F1, F2) =
F2 (10)
-A|
A ·
 |A1 |* |
A(F, c) =
�
lEFi in c
�
FiE�
</equation>
<page confidence="0.98601">
662
</page>
<table confidence="0.9997165">
Measure Simple Set Controlled Set
wn jcn 0.114 0.141
wn hso 0.106 0.141
cr occ sent 0.239 0.340
cr wgt sent 0.281 0.349
cr occ doc 0.143 0.227
cr wgt doc 0.173 0.240
cr dist doc 0.152 0.240
hr wu 0.139 0.286
hr hso 0.134 0.296
hr fe 0.252 0.326
def overlap baseline 0.056 0.210
LU overlap baseline 0.080 0.253
human upper bound 0.530 0.566
</table>
<tableCaption confidence="0.897774">
Table 3: Kendall’s T correlation results for differ-
ent measures over the two dataset.
</tableCaption>
<bodyText confidence="0.99992172">
that counts the percentage of overlapping LUs be-
tween the two frames. We also defined as upper-
bound the human agreement over the gold stan-
dard. As regards distributional measures, statis-
tics are drawn from the TREC-2002 Vol.2 cor-
pus, consisting of about 110 million words, orga-
nized in 230,401 news documents and 5,433,048
sentences8. LUs probabilities in Eq. 8 are esti-
mate over the SemCor 2.0 corpus, consisting of
700,000 running words, sense-tagged with Word-
Net 2.0 senses.9. WordNet-based measures are
computed using WordNet 2.0 and implemented
as in (Patwardhan et al., 2003). Mappings be-
tween WordNet senses and FrameNet verbal LUs
are taken from Shi and Mihalcea (2005); as map-
pings for nouns and adjectives are not available,
for the WordNet-based measures we use the first
sense heuristic.
Note that some of the measures we adopt need
some degree of supervision. The WordNet-based
and the cr wgt measures rely on a WordNet-
FrameNet mapping, which has to be created man-
ually or by some reliable automatic technique.
Hierarchy-based measures instead rely on the
FrameNet hierarchy that is also a manual artifact.
</bodyText>
<subsectionHeader confidence="0.995477">
5.1 Experimental Results
</subsectionHeader>
<bodyText confidence="0.98525">
Table 3 reports the correlation results over the two
datasets. Table 4 reports the best 10 ranks pro-
duced by some of the best performing measures.
Results show that all measures are positively cor-
related with the human gold standard, with a level
</bodyText>
<footnote confidence="0.9977206">
8For computational limitations we could not afford exper-
imenting the cr dist sent measure, as the number and size of
the vectors was too big.
9We did not use directly the SemCor for drawing distribu-
tional statistics, because of its small size.
</footnote>
<bodyText confidence="0.970071673076923">
of significance beyond the p &lt; 0.01 level , but
the wn jcn measure which is at p &lt; 0.05. All
measures, but the WordNet-based ones, signifi-
cantly outperform the definition overlap baseline
on both datasets, and most of them also beat the
more informed LU overlap baseline.10 It is in-
teresting to notice that the two best performing
measures, namely cr wgt sent and hr fe, use re-
spectively a distributional and a hierarchy-based
strategy, suggesting that both approaches are valu-
able. WordNet-based measures are less effective,
performing close or below the baselines.
Results obtained on the simple set are in gen-
eral lower than those on the controlled set, sug-
gesting that it is easier to discriminate among pairs
of connected frames than random ones. A possi-
ble explanation is that when frames are connected,
all measures can rely on meaningful evidence for
most of the pairs, while this is not always the case
for random pairs. For example, corpus-based mea-
sures tend to suffer the problem of data sparseness
much more on the simple set, because many of the
pairs are so loosely related that statistical informa-
tion cannot significantly emerge from the corpus.
WordNet-based measures. The low perfor-
mance of these measures is mainly due to the
fact that they fail to predict relatedness for many
pairs, e.g. wn hso assigns zero to 137 and 119
pairs, respectively on the simple and controlled
sets. This is mostly caused by the limited set of
relations of the WordNet database. Most impor-
tantly in our case, WordNet misses the situational
relation (Hirst and St.Onge, 1998), which typi-
cally relates words participating in the same sit-
uation (e.g. child care - school). This is exactly
the relation that would help in mapping frames’
LUs. Another problem relates to adjectives and
adverbs: WordNet measures cannot be trustfully
applied to these part-of-speech, as they are not
hierarchically organized. Unfortunately, 18% of
FrameNet LUs are either adjectives or adverbs,
meaning that such amount of useful information
is lost. Finally, WordNet has in general an incom-
plete lexical coverage: Shi and Mihalcea (2005)
show that 7% of FrameNet verbal LUs do not have
a mapping in WordNet.
Corpus-based measures. Table 3 shows that
co-occurrence measures are effective when using
10The average level of correlation obtained by our mea-
sures is comparable to that obtained in other complex
information-ordering tasks, e.g. measuring compositionality
of verb-noun collations (Venkatapathy and Joshi, 2005)
</bodyText>
<page confidence="0.99493">
663
</page>
<table confidence="0.999217636363636">
WN JCN CR WGT SENT HR FE
Ambient temperature - Temperature (4) Change of phase - Cause change of phase (7) Shoot projectiles - Use firearm (1,5)
Run risk - Endangering (27) Knot creation - Rope manipulation (1,5) Intentionally affect - Rope manipulation (37,5)
Run risk - Safe situation (51) Ambient temperature - Temperature (4) Knot creation - Rope manipulation (1,5)
Knot creation - Rope manipulation (1,5) Shoot projectiles - Use firearm (1,5) Ambient temperature - Temperature (4)
Endangering - Safe situation (62) Hit target - Use firearm (18) Hit target - Intentionally affect (91,5)
Shoot projectiles - Use firearm (1,5) Run risk - Safe situation (51) Safe situation - Security (28)
Scouring - Scrutiny (3) Safe situation - Security (28) Suspicion - Criminal investigation (40)
Reliance - Contingency (109) Cause impact - Hit target (10) Age - Speed (113)
Safe situation - Security (28) Rape - Arson (22) Motion noise - Motion directional (55)
Change of phase - Cause change of phase (7) Suspicion - Robbery (98) Body movement - Motion (45)
</table>
<tableCaption confidence="0.960995">
Table 4: First 10 ranked frame pairs for different relatedness measure on the Controlled Set; in brackets,
</tableCaption>
<bodyText confidence="0.994486571428572">
the rank in the gold standard (full list available at (suppressed)).
sentences as contexts, while correlation decreases
by about 10 points using documents as contexts.
This suggest that sentences are suitable contex-
tual units to model situational relatedness, while
documents (i.e. news) may be so large to include
unrelated situations. It is interesting to notice
that corpus-based measures promote frame pairs
which are in a non-hierarchical relation, more than
other measures do. For example the pair CHANGE
OF PHASE - CAUSE CHANGE OF PHASE score
first, and RAPE - ARSON score ninth, while the
other measures tend to rank them much lower.
By contrast, the two frames SCOURING - IN-
SPECTING which are siblings in the FrameNet hi-
erarchy and rank 17th in the gold standard, are
ranked only 126th by cr wgt sent. This is due
to the fact that hierarchically related frames are
substitutional – i.e. they tend not to co-occur
in the same documents; while otherwise related
frames are mostly in syntagmatic relation. As for
cr dist doc, it performs in line with cr wgt doc,
but their ranks differ; cr dist doc promotes more
hierarchical relations: distributional methods cap-
ture both paradigmatically and syntagmatically re-
lated entities.
Hierarchy-based measures. As results show,
the FrameNet hierarchy is a good indicator of re-
latedness, especially when considering FE map-
pings. Hierarchy-based measures promote frame
pairs related by diverse relations, with a slight pre-
dominance of is-a like ones (indeed, the FrameNet
hierarchy contains roughly twice as many is-a re-
lations as other ones). These measures are slightly
penalized by the low coverage of the FrameNet
hierarchy. For example, they assign zero to
CHANGE OF PHASE - ALTERED PHASE, as an in-
choative link connecting the frames is missing.
Correlation between measures. We computed
the Kendall’s τ among the experimented mea-
sures, to investigate if they model relatedness in
different or similar ways. As expected, measures
of the same type are highly correlated (e.g. hr fe
and hr wu have τ = 0.52), while those of differ-
ent types seem complementary, showing negative
or non-significant correlation (e.g. cr wgt sent has
τ = −0.034 with hr wu, and τ = 0.078 with
wn jcn). The LU overlap baseline shows signif-
icant correlation only with hr wu (τ = 0.284),
suggesting that in the FrameNet hierarchy frames
correlated by some relation do share LUs.
Comparison to word relatedness. The best
performing measures score about 0.200 points be-
low the human upper bound, indicating that rank-
ing frames is much easier for humans than for ma-
chines. A direct comparison to the word ranking
task, suggests that ranking frames is harder than
words, not only for humans (as reported in Sec-
tion 3.2), but also for machines: Budanitsky and
Hirst (2006) show that measures for ranking words
get much closer to the human upper-bound than
our measures do, confirming that frame related-
ness is a fairly complex notion to model.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.9998800625">
We empirically defined a notion of frame relat-
edness. Experiments suggest that this notion is
cognitively principled, and can be safely used in
NLP tasks. We introduced a variety of measures
for automatically estimating relatedness. Results
show that our measures have good performance,
all statistically significant at the 99% level, though
improvements are expected by using other evi-
dence. As future work, we will build up and refine
these basic measures, and investigate more com-
plex ones. We will also use our measures in appli-
cations, to check their effectiveness in supporting
various tasks, e.g. in mapping frames across Text
and Hypothesis in RTE, in linking related frames
in discourse, or in inducing frames for LU which
are not in FrameNet (Baker et al., 2007).
</bodyText>
<page confidence="0.998059">
664
</page>
<sectionHeader confidence="0.993885" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999817085106383">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet project. In Proceed-
ings of COLING-ACL, Montreal, Canada.
Collin Baker, Michael Ellsworth, and Katrin Erk.
2007. SemEval-2007 Task 19: Frame Semantic
Structure Extraction. In Proceedings of the Fourth
International Workshop on Semantic Evaluations
(SemEval-2007), pages 99–104, Prague, Czech Re-
public, June.
Alexander Budanitsky and Graeme Hirst. 2006. Eval-
uating WordNet-based measures of lexical semantic
relatedness. Computational Linguistics, 32(1):13–
47.
Walter Charles. 2000. Contextual correlates of mean-
ing. Applied Psycholinguistics, (21):502–524.
C. J. Fillmore. 1985. Frames and the Semantics of
Understanding. Quaderni di Semantica, IV(2).
Zellig Harris. 1964. Distributional structure. In Jer-
rold J. Katz and Jerry A. Fodor, editors, The Philos-
ophy of Linguistics, New York. Oxford University
Press.
Graeme Hirst and David St.Onge, 1998. Lexical chains
as representations of context for the detection and
correction of malapropisms, pages 305–332. MIT
press.
Jay J. Jiang and David W. Conrath. 1997. Seman-
tic similarity based on corpus statistics and lexical
taxonomy. In Proceedings of International Confer-
ence on Research in Computational Linguistics (RO-
CLING X), Taiwan.
Maurice Kendall. 1938. A new measure of rank corre-
lation. Biometrika, (30):81–93.
Mirella Lapata. 2006. Automatic evaluation of infor-
mation ordering: Kendall’s tau. Computational Lin-
guistics, 32(4):471–484.
G.J. Lidstone. 1920. Note on the general case of the
Bayes-Laplace formula for inductive or a posteriori
probabilities. Transactions of the Faculty ofActuar-
ies, 8:182–192.
Dekang Lin and Patrick Pantel. 2001. DIRT-discovery
of inference rules from text. In Proceedings of
KDD-01, San Francisco, CA.
Dekang Lin. 1998. Automatic retrieval and clustering
of similar word. In Proceedings of COLING-ACL,
Montreal, Canada.
G. A. Miller, C. Leacock, T. Randee, and Bunker R.
1993. A Semantic Concordance. In In Proceedings
of the 3rd DARPA Workshop on Human Language
Technology, Plainsboro, New Jersey.
Saif Mohammad and Graeme Hirst. 2006. Distribu-
tional measures of concept-distance. a task-oriented
evaluation. In Proceedings of EMNLP-2006, Syd-
ney,Australia.
S. Patwardhan, S. Banerjee, and T. Pedersen. 2003.
Using measures of semantic relatedness for word
sense disambiguation. In Proceedings of Fourth In-
ternational Conference on Intelligent Text Process-
ing and Computational Linguistics, Mexico City,
Mexico.
Marco Pennacchiotti, Diego De Cao, Paolo Marocco,
and Roberto Basili. 2008. Towards a vector space
model for framenet-like resources. In Proceedings
of LREC, Marrakech, Marocco.
Philip Resnik. 1995. Using information content to
evaluate semantic similarity. In Proceedings of the
14th International Joint Conference on Artificial In-
telligence, Montreal, Canada.
H. Rubenstein and J.B. Goodenough. 1965. Contex-
tual correlates of synonymy. Communications of the
ACM, 8(10):627–633.
Josef Ruppenhofer, Michael Ellsworth, Miriam R. L.
Petruck, and Christopher R. Johnson. 2005.
FrameNet II: Extended Theory and Practice. In ICSI
Technical Report.
Lei Shi and Rada Mihalcea. 2005. Putting Pieces To-
gether: Combining FrameNet, VerbNet and Word-
Net for Robust Semantic Parsing. In In Proceedings
of Cicling, Mexico.
S. Siegel and N. J. Castellan. 1988. Nonparamet-
ric Statistics for the Behavioral Sciences. McGraw-
Hill.
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaven-
tura Coppola. 2004. Scaling web-based acquisition
of entailment relations. In Proceedings of the 2004
Conference on Empirical Methods in Natural Lan-
guage Processing, Barcellona, Spain.
Sriram Venkatapathy and Aravind K. Joshi. 2005.
Measuring the relative compositionality of verb
noun (V-N) collocations by integrating features. In
Proceedings of HLT/EMNLP, Vancouver, Canad.
Z. Wu and M. Palmer. 1994. Verb semantics and lex-
ical selection. In 32nd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 133–
138, Las Cruces, New Mexico.
</reference>
<page confidence="0.998418">
665
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.955589">
<title confidence="0.999779">Measuring frame relatedness</title>
<author confidence="0.99999">Marco Pennacchiotti Michael Wirth</author>
<affiliation confidence="0.99547">Yahoo! Inc. Computational Linguistics</affiliation>
<address confidence="0.981967">Santa Clara, CA 95054 Saarland University, Germany</address>
<email confidence="0.990158">pennac@yahoo-inc.commiwirth@coli.uni-sb.de</email>
<abstract confidence="0.998919416666667">In this paper we introduce the notion of “frame relatedness”, i.e. relatedness among prototypical situations as represented in the FrameNet database. We first demonstrate the cognitive plausibility of that notion through an annotation experiment, and then propose different types of computational measures to automatically assess relatedness. Results show that our measures provide good performance on the task of ranking pairs of frames.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="8255" citStr="Baker et al., 1998" startWordPosition="1305" endWordPosition="1308">resented in the form of frames, conceptual structures modelling prototypical situations. Linguistically, a frame is a semantic class containing predicates called lexical units (LU), that can evoke the described situation (see example in Table 1). Each frame comes with its own set of semantic roles, called frame elements (FE). These are the participants and props in the abstract situation described. Roles are local to individual frames, thus avoiding the commitment to a small set of universal roles, whose specification has turned out to be unfeasible in the past. The Berkeley FrameNet project (Baker et al., 1998) has been developing a frame-semantic lexicon for the core vocabulary of English since 1997. The current FrameNet release contains about 800 frames and 10,000 lexical units. Part of FrameNet 658 Frame: STATEMENT This frame contains verbs and nouns that communicate the act of a SPEAKER to address a MESSAGE to some ADDRESSEE using language. A number of the words can be used performatively, such as declare and insist. SPEAKER Evelyn said she wanted to leave. MESSAGE Evelyn announced that she wanted to leave. ADDRESSEE Evelyn spoke to me about her past. TOPIC Evelyn’s statement about her past MEDI</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet project. In Proceedings of COLING-ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin Baker</author>
<author>Michael Ellsworth</author>
<author>Katrin Erk</author>
</authors>
<title>SemEval-2007 Task 19: Frame Semantic Structure Extraction.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>99--104</pages>
<location>Prague, Czech Republic,</location>
<marker>Baker, Ellsworth, Erk, 2007</marker>
<rawString>Collin Baker, Michael Ellsworth, and Katrin Erk. 2007. SemEval-2007 Task 19: Frame Semantic Structure Extraction. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 99–104, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Budanitsky</author>
<author>Graeme Hirst</author>
</authors>
<title>Evaluating WordNet-based measures of lexical semantic relatedness.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>1</issue>
<pages>47</pages>
<contexts>
<context position="1251" citStr="Budanitsky and Hirst, 2006" startWordPosition="172" endWordPosition="175"> pairs of frames. 1 Introduction Measuring relatedness among linguistic entities is a crucial topic in NLP. Automatically assessing the degree of similarity or relatedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantics (Fillmore, 1985), where a situation i</context>
<context position="6332" citStr="Budanitsky and Hirst (2006)" startWordPosition="994" endWordPosition="997"> Most measures can be classified either as corpus-based or ontology-based. Corpus-based measures compute relatedness looking at the distributional properties of the two words: words that tend to co-occur in the same contexts or having similar distributional profiles, are deemed to be highly related. A complete survey on these measures is reported in (Mohammad and Hirst, 2006). Ontology-based measures estimate relatedness by studying the path connecting the two words in an ontology or a hierarchical lexicon (e.g. WordNet). The basic idea is that closer words are more related than distant ones. Budanitsky and Hirst (2006) provide an extensive survey of these measures. Budanitsky and Hirst (2006) also point out an important distinction, between relatedness and similarity. Two words are related if any type of relation stands between them, e.g. antonymy or meronymy; they are similar when related through an is-a like hierarchy. Similarity is then a special case of relatedness. Following Budanitsky and Hirst (2006), we consider two frames as similar if they are linked via is-a like relations (e.g. GETTING and COMMERCE BUY), while as related if any relation stands between them (e.g. causation between KILLING and DEA</context>
<context position="17233" citStr="Budanitsky and Hirst, 2006" startWordPosition="2801" endWordPosition="2804">l(s1, s2) is a sense function estimating the relatedness between two senses in WordNet. Since we focus on frame relatedness, we are interested in assigning high scores to pairs of senses which are related by any type of relations in WordNet (i.e. not limited to is-a). We therefore adopt as function wn rel the Hirst-St.Onge measure (Hirst and St.Onge, 1998) as it accounts for different relations. We also experiment with the Jiang and Conrath’s (Jiang and Conrath, 1997) measure which relies only on the is-a hierarchy, but proved to be the best WordNet-based measure in the task of ranking words (Budanitsky and Hirst, 2006). We call the frame relatedness measures using the two functions respectively as wn hso(F1, F2) and wn jen(F1, F2). 4.2 Corpus-based measures Corpus-based measures compute relatedness looking at the distributional properties of the two frames over a corpus. The intuition is that related frames should occur in the same or similar contexts. wn(F1, F2) = 11 s1ESF1 11 s2ESF2 660 SIMPLE SET CONTROLLED SET Measure volume - Measure mass (1) Knot creation - Rope manipulation (1,5) Communication manner - Statement (2) Shoot projectiles - Use firearm (1,5) Giving - Sent items (3) Scouring - Scrutiny (3)</context>
<context position="34138" citStr="Budanitsky and Hirst (2006)" startWordPosition="5679" endWordPosition="5682"> wgt sent has τ = −0.034 with hr wu, and τ = 0.078 with wn jcn). The LU overlap baseline shows significant correlation only with hr wu (τ = 0.284), suggesting that in the FrameNet hierarchy frames correlated by some relation do share LUs. Comparison to word relatedness. The best performing measures score about 0.200 points below the human upper bound, indicating that ranking frames is much easier for humans than for machines. A direct comparison to the word ranking task, suggests that ranking frames is harder than words, not only for humans (as reported in Section 3.2), but also for machines: Budanitsky and Hirst (2006) show that measures for ranking words get much closer to the human upper-bound than our measures do, confirming that frame relatedness is a fairly complex notion to model. 6 Conclusions We empirically defined a notion of frame relatedness. Experiments suggest that this notion is cognitively principled, and can be safely used in NLP tasks. We introduced a variety of measures for automatically estimating relatedness. Results show that our measures have good performance, all statistically significant at the 99% level, though improvements are expected by using other evidence. As future work, we wi</context>
</contexts>
<marker>Budanitsky, Hirst, 2006</marker>
<rawString>Alexander Budanitsky and Graeme Hirst. 2006. Evaluating WordNet-based measures of lexical semantic relatedness. Computational Linguistics, 32(1):13– 47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Charles</author>
</authors>
<title>Contextual correlates of meaning.</title>
<date>2000</date>
<journal>Applied Psycholinguistics,</journal>
<pages>21--502</pages>
<contexts>
<context position="5310" citStr="Charles (2000)" startWordPosition="838" endWordPosition="839"> Section 2 we summarize related work. In Section 3 we describe the experiment of humans ranking frame pairs, and discuss the results. In Section 4 and 5 we respectively introduce our relatedness measures, and test them over a manual gold standard. In Section 6 we draw final conclusions and outline future work. 2 Related Work Much research in NLP has studied similarity and relatedness between words. Rubenstein and Goodenough (1965) were the first to propose a procedure to assess human agreement on ranking pairs of words on relatedness. Their experiment was later replicated by Resnik (1995) and Charles (2000). All these studies reported good levels of agreements among annotators, suggesting that the notion of word relatedness is cognitively principled. In our experiment in Section 3.2 we apply the same procedure to assess agreement on ranking frames. Measures for estimating word relatedness have been systematically proposed since the early 90’s, and are today widely used in NLP for various tasks. Most measures can be classified either as corpus-based or ontology-based. Corpus-based measures compute relatedness looking at the distributional properties of the two words: words that tend to co-occur i</context>
<context position="14487" citStr="Charles, 2000" startWordPosition="2340" endWordPosition="2341">umans, and that the final datasets are reliable enough to be used as gold standard for our experiments. Table 2 reports the first and last 5 ranked frame pairs for the two datasets. We compared the correlation results obtained above on “frame relatedness”, to those derived from previous works on “word relatedness”. This comparison should indicate if ranking related frames (i.e. situations) is more or less complex and intuitive than ranking words.3 As for words, we computed the average Kendall’s T among three different annotation efforts (namely, (Rubenstein and Goodenough, 1965; Resnik, 1995; Charles, 2000)) carried out over a same dataset of 28 word pairs originally created by Rubenstein and Goodenough. Note that the annotation schema followed in the three works is the same as ours. We obtained a Kendall’s r = 0.775, which is statistically significant at the 99% level. As expected, the correlation for word relatedness is higher than for frames: Humans find it easier to compare two words than two complex situations, as the former are less complex linguistic entities than the latter. 4 Measures for frame relatedness Manually computing relatedness between all possible frame pairs in FrameNet is an</context>
</contexts>
<marker>Charles, 2000</marker>
<rawString>Walter Charles. 2000. Contextual correlates of meaning. Applied Psycholinguistics, (21):502–524.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Fillmore</author>
</authors>
<title>Frames and the Semantics of Understanding.</title>
<date>1985</date>
<booktitle>Quaderni di Semantica, IV(2).</booktitle>
<contexts>
<context position="1830" citStr="Fillmore, 1985" startWordPosition="262" endWordPosition="263">in, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantics (Fillmore, 1985), where a situation is modelled as a conceptual structure (a frame) constituted by the predicates that can evoke the situation, and the semantic roles expressing the situation’s participants. As measures of word relatedness help in discovering if two word occurrences express related concepts, so measures of frame relatedness should help to discover if two large text fragments are related or talk about similar situations. Such measures would be valuable in many tasks. For example, consider the following fragment, in the context of discourse processing: “In the 1950s the Shah initiated Iran ’s n</context>
<context position="7454" citStr="Fillmore, 1985" startWordPosition="1179" endWordPosition="1180"> while as related if any relation stands between them (e.g. causation between KILLING and DEATH). In this paper, we focus our attention solely on the notion of frame relatedness. 3 Defining frame relatedness In this section we check if the notion of frame relatedness is intuitive and principled from a cognitive perspective. In Section 3.1 we first introduce the basic concepts or frame semantics; in Section 3.2 we report the agreement results obtained by human annotators, on the task of ranking a dataset of frame pairs according to relatedness. 3.1 Frame Semantics and FrameNet Frame semantics (Fillmore, 1985) seeks to describe the meaning of a sentence as it is actually understood by characterizing the background knowledge necessary to understand the sentence. Background knowledge is represented in the form of frames, conceptual structures modelling prototypical situations. Linguistically, a frame is a semantic class containing predicates called lexical units (LU), that can evoke the described situation (see example in Table 1). Each frame comes with its own set of semantic roles, called frame elements (FE). These are the participants and props in the abstract situation described. Roles are local </context>
</contexts>
<marker>Fillmore, 1985</marker>
<rawString>C. J. Fillmore. 1985. Frames and the Semantics of Understanding. Quaderni di Semantica, IV(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Distributional structure.</title>
<date>1964</date>
<booktitle>The Philosophy of Linguistics,</booktitle>
<editor>In Jerrold J. Katz and Jerry A. Fodor, editors,</editor>
<publisher>University Press.</publisher>
<location>New York. Oxford</location>
<contexts>
<context position="21830" citStr="Harris, 1964" startWordPosition="3601" endWordPosition="3602"> hawk on purpose.”, wF(c) = 0.17, as charge.v#3 is not very frequent in SemCor. 5In Eq.8 we use Lidstone smoothing (Lidstone, 1920) to account for unseen senses in SemCor. Also, if a LU does not occur in SemCor, an equal probability (corresponding to the inverse of the number of word’s senses) is given to all senses. cr wgt(F1, F2) = log2 11 c�CF1 wF2(c) (6) 661 4.2.2 Distributional measure The previous measures promote (i.e. give a higher rank to) frames co-occurring in the same contexts. The distributional measure promotes frames occurring in similar contexts. The distributional hypothesis (Harris, 1964) has been widely and successfully used in NLP to compute relatedness among words (Lin, 1998), lexical patterns (Lin and Pantel, 2001), and other entities. The underlying intuition is that target entities occurring in similar contexts are likely to be semantically related. In our setting, we consider either documents and sentences as valid contexts. Each frame F is modelled by a distributional � vector F, whose dimensions are documents. The value of each dimension expresses the association ratio A(F, c) between a document c and the frame. We say that a document is highly associated to a frame w</context>
</contexts>
<marker>Harris, 1964</marker>
<rawString>Zellig Harris. 1964. Distributional structure. In Jerrold J. Katz and Jerry A. Fodor, editors, The Philosophy of Linguistics, New York. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>David St Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms,</title>
<date>1998</date>
<pages>305--332</pages>
<publisher>MIT press.</publisher>
<marker>Hirst, Onge, 1998</marker>
<rawString>Graeme Hirst and David St.Onge, 1998. Lexical chains as representations of context for the detection and correction of malapropisms, pages 305–332. MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proceedings of International Conference on Research in Computational Linguistics (ROCLING X),</booktitle>
<contexts>
<context position="17078" citStr="Jiang and Conrath, 1997" startWordPosition="2774" endWordPosition="2777">SF contains charge.v#3, collect.v#4, bill.v#1). A generic WordNet-based measure is then defined as follows: wn rel(s1, s2) |SF1 |- |SF2| (1) where wn rel(s1, s2) is a sense function estimating the relatedness between two senses in WordNet. Since we focus on frame relatedness, we are interested in assigning high scores to pairs of senses which are related by any type of relations in WordNet (i.e. not limited to is-a). We therefore adopt as function wn rel the Hirst-St.Onge measure (Hirst and St.Onge, 1998) as it accounts for different relations. We also experiment with the Jiang and Conrath’s (Jiang and Conrath, 1997) measure which relies only on the is-a hierarchy, but proved to be the best WordNet-based measure in the task of ranking words (Budanitsky and Hirst, 2006). We call the frame relatedness measures using the two functions respectively as wn hso(F1, F2) and wn jen(F1, F2). 4.2 Corpus-based measures Corpus-based measures compute relatedness looking at the distributional properties of the two frames over a corpus. The intuition is that related frames should occur in the same or similar contexts. wn(F1, F2) = 11 s1ESF1 11 s2ESF2 660 SIMPLE SET CONTROLLED SET Measure volume - Measure mass (1) Knot cr</context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proceedings of International Conference on Research in Computational Linguistics (ROCLING X), Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice Kendall</author>
</authors>
<title>A new measure of rank correlation.</title>
<date>1938</date>
<journal>Biometrika,</journal>
<pages>30--81</pages>
<contexts>
<context position="12676" citStr="Kendall, 1938" startWordPosition="2041" endWordPosition="2042">following information about the two frames: names; definitions; the lists of core FEs; a frame annotated sentence for each frame, randomly chosen from the FrameNet database. Similarly to Rubenstein and Goodenough (1965) we gave the annotators the following instructions: (i) After looking through the whole deck, order the pairs according to amount of relatedness; (ii) You may assign the same rank to pairs having the same degree of relatedness (i.e. ties are allowed). We checked the agreement among the 15 annotators in ranking the 5 shared pairs by using the Kendall’s T correlation coefficient (Kendall, 1938). Kendall’s T can be interpreted as the difference between the probability that in the dataset two variables are in the same order versus the probability that they are in different orders (see (Lapata, 2006) for details). The average corre1A scenario frame is a “hub” frame describing a general topic; specific frames modelling situations related to the topic are linked to it (e.g. COMMERCE BUY and COMMERCIAL TRANSACTION are linked to COMMERCE SCENARIO). FrameNet contains 16 scenarios. FEs FEs LUs 659 lation2 among annotators on the simple and controlled sets was r = 0.600 and r = 0.547. Gold st</context>
</contexts>
<marker>Kendall, 1938</marker>
<rawString>Maurice Kendall. 1938. A new measure of rank correlation. Biometrika, (30):81–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Automatic evaluation of information ordering: Kendall’s tau.</title>
<date>2006</date>
<journal>Computational Linguistics,</journal>
<volume>32</volume>
<issue>4</issue>
<contexts>
<context position="12883" citStr="Lapata, 2006" startWordPosition="2076" endWordPosition="2077">ough (1965) we gave the annotators the following instructions: (i) After looking through the whole deck, order the pairs according to amount of relatedness; (ii) You may assign the same rank to pairs having the same degree of relatedness (i.e. ties are allowed). We checked the agreement among the 15 annotators in ranking the 5 shared pairs by using the Kendall’s T correlation coefficient (Kendall, 1938). Kendall’s T can be interpreted as the difference between the probability that in the dataset two variables are in the same order versus the probability that they are in different orders (see (Lapata, 2006) for details). The average corre1A scenario frame is a “hub” frame describing a general topic; specific frames modelling situations related to the topic are linked to it (e.g. COMMERCE BUY and COMMERCIAL TRANSACTION are linked to COMMERCE SCENARIO). FrameNet contains 16 scenarios. FEs FEs LUs 659 lation2 among annotators on the simple and controlled sets was r = 0.600 and r = 0.547. Gold standard ranking. The final dataset was created by two expert annotators, jointly working to rank the 155 pairs collected in the data creation phase. We computed the rank correlation agreement between this ann</context>
</contexts>
<marker>Lapata, 2006</marker>
<rawString>Mirella Lapata. 2006. Automatic evaluation of information ordering: Kendall’s tau. Computational Linguistics, 32(4):471–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G J Lidstone</author>
</authors>
<title>Note on the general case of the Bayes-Laplace formula for inductive or a posteriori probabilities. Transactions of the Faculty ofActuaries,</title>
<date>1920</date>
<pages>8--182</pages>
<contexts>
<context position="21348" citStr="Lidstone, 1920" startWordPosition="3523" endWordPosition="3524">(e.g. charge.v#3 for COMMERCE COLLECT). The weighting function is then: wF (c) = arg max P(SlF |lF) (7) lF ELF in c where LF is the set of LUs of F. We estimate P(SlF |lF) by counting sense occurrences of lF over the SemCor corpus: P(SlF |lF) = |SlF |(8) |Sl| In other terms, a frame receives a high weight in a document when the document contains a LU whose most frequent senses are those mapped to the frame.5 For example, in the sentence: “Tripp Isenhour was charged with killing a hawk on purpose.”, wF(c) = 0.17, as charge.v#3 is not very frequent in SemCor. 5In Eq.8 we use Lidstone smoothing (Lidstone, 1920) to account for unseen senses in SemCor. Also, if a LU does not occur in SemCor, an equal probability (corresponding to the inverse of the number of word’s senses) is given to all senses. cr wgt(F1, F2) = log2 11 c�CF1 wF2(c) (6) 661 4.2.2 Distributional measure The previous measures promote (i.e. give a higher rank to) frames co-occurring in the same contexts. The distributional measure promotes frames occurring in similar contexts. The distributional hypothesis (Harris, 1964) has been widely and successfully used in NLP to compute relatedness among words (Lin, 1998), lexical patterns (Lin an</context>
</contexts>
<marker>Lidstone, 1920</marker>
<rawString>G.J. Lidstone. 1920. Note on the general case of the Bayes-Laplace formula for inductive or a posteriori probabilities. Transactions of the Faculty ofActuaries, 8:182–192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT-discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of KDD-01,</booktitle>
<location>San Francisco, CA.</location>
<contexts>
<context position="1386" citStr="Lin and Pantel, 2001" startWordPosition="190" endWordPosition="193">e of similarity or relatedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantics (Fillmore, 1985), where a situation is modelled as a conceptual structure (a frame) constituted by the predicates that can evoke the situation, and the semantic roles expre</context>
<context position="21963" citStr="Lin and Pantel, 2001" startWordPosition="3620" endWordPosition="3623"> 1920) to account for unseen senses in SemCor. Also, if a LU does not occur in SemCor, an equal probability (corresponding to the inverse of the number of word’s senses) is given to all senses. cr wgt(F1, F2) = log2 11 c�CF1 wF2(c) (6) 661 4.2.2 Distributional measure The previous measures promote (i.e. give a higher rank to) frames co-occurring in the same contexts. The distributional measure promotes frames occurring in similar contexts. The distributional hypothesis (Harris, 1964) has been widely and successfully used in NLP to compute relatedness among words (Lin, 1998), lexical patterns (Lin and Pantel, 2001), and other entities. The underlying intuition is that target entities occurring in similar contexts are likely to be semantically related. In our setting, we consider either documents and sentences as valid contexts. Each frame F is modelled by a distributional � vector F, whose dimensions are documents. The value of each dimension expresses the association ratio A(F, c) between a document c and the frame. We say that a document is highly associated to a frame when most of the FrameNet LUs it contains, map to the given frame in the correct senses: E P(SlF |lF) lELF in c P(SlFi |lFi) (9) where</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT-discovery of inference rules from text. In Proceedings of KDD-01, San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar word.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1223" citStr="Lin, 1998" startWordPosition="170" endWordPosition="171"> of ranking pairs of frames. 1 Introduction Measuring relatedness among linguistic entities is a crucial topic in NLP. Automatically assessing the degree of similarity or relatedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantics (Fillmore</context>
<context position="21922" citStr="Lin, 1998" startWordPosition="3616" endWordPosition="3617"> Lidstone smoothing (Lidstone, 1920) to account for unseen senses in SemCor. Also, if a LU does not occur in SemCor, an equal probability (corresponding to the inverse of the number of word’s senses) is given to all senses. cr wgt(F1, F2) = log2 11 c�CF1 wF2(c) (6) 661 4.2.2 Distributional measure The previous measures promote (i.e. give a higher rank to) frames co-occurring in the same contexts. The distributional measure promotes frames occurring in similar contexts. The distributional hypothesis (Harris, 1964) has been widely and successfully used in NLP to compute relatedness among words (Lin, 1998), lexical patterns (Lin and Pantel, 2001), and other entities. The underlying intuition is that target entities occurring in similar contexts are likely to be semantically related. In our setting, we consider either documents and sentences as valid contexts. Each frame F is modelled by a distributional � vector F, whose dimensions are documents. The value of each dimension expresses the association ratio A(F, c) between a document c and the frame. We say that a document is highly associated to a frame when most of the FrameNet LUs it contains, map to the given frame in the correct senses: E P(</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar word. In Proceedings of COLING-ACL, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>C Leacock</author>
<author>T Randee</author>
<author>R Bunker</author>
</authors>
<title>A Semantic Concordance. In</title>
<date>1993</date>
<booktitle>In Proceedings of the 3rd DARPA Workshop on Human Language Technology,</booktitle>
<location>Plainsboro, New Jersey.</location>
<contexts>
<context position="20235" citStr="Miller et al., 1993" startWordPosition="3321" endWordPosition="3324">a co-occurrence of the two above frames. Unfortunately this is not the case, as the sentence’s sense charge.v#2 does not map to the frame. Ideally, one could solve the problem by using a sense-tagged corpus where senses’ occurrences are mapped to frames. While senseto-frame mappings exist (e.g. mapping between 4For sake of simplicity in the rest of the section we refer to documents, but the same holds for sentences. frames and WordNet senses in (Shi and Mihalcea, 2005)), sense-tagged corpora large enough for distributional studies are not yet available (e.g., the SemCor WordNet-tagged corpus (Miller et al., 1993) consists of only 700,000 words). We therefore circumvent the problem, by implementing pmi in a weighted co-occurrence measure, which gives lower weights to co-occurrences of ambiguous words: 11 wF1(c) - wF2(c) cECF1,F2 11 wF1(c) - cECF2 The weighting function wF(c) estimates the probability that the document c contains a LU of the frame F in the correct sense. Formally, given the set of senses Sl of a LU (e.g. charge.v#1...charge.v#24), we define SlF as the set of senses mapping to the frame (e.g. charge.v#3 for COMMERCE COLLECT). The weighting function is then: wF (c) = arg max P(SlF |lF) (7</context>
</contexts>
<marker>Miller, Leacock, Randee, Bunker, 1993</marker>
<rawString>G. A. Miller, C. Leacock, T. Randee, and Bunker R. 1993. A Semantic Concordance. In In Proceedings of the 3rd DARPA Workshop on Human Language Technology, Plainsboro, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Graeme Hirst</author>
</authors>
<title>Distributional measures of concept-distance. a task-oriented evaluation.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP-2006, Sydney,Australia.</booktitle>
<contexts>
<context position="1278" citStr="Mohammad and Hirst, 2006" startWordPosition="176" endWordPosition="179">tion Measuring relatedness among linguistic entities is a crucial topic in NLP. Automatically assessing the degree of similarity or relatedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantics (Fillmore, 1985), where a situation is modelled as a conceptual </context>
<context position="6083" citStr="Mohammad and Hirst, 2006" startWordPosition="956" endWordPosition="959">n our experiment in Section 3.2 we apply the same procedure to assess agreement on ranking frames. Measures for estimating word relatedness have been systematically proposed since the early 90’s, and are today widely used in NLP for various tasks. Most measures can be classified either as corpus-based or ontology-based. Corpus-based measures compute relatedness looking at the distributional properties of the two words: words that tend to co-occur in the same contexts or having similar distributional profiles, are deemed to be highly related. A complete survey on these measures is reported in (Mohammad and Hirst, 2006). Ontology-based measures estimate relatedness by studying the path connecting the two words in an ontology or a hierarchical lexicon (e.g. WordNet). The basic idea is that closer words are more related than distant ones. Budanitsky and Hirst (2006) provide an extensive survey of these measures. Budanitsky and Hirst (2006) also point out an important distinction, between relatedness and similarity. Two words are related if any type of relation stands between them, e.g. antonymy or meronymy; they are similar when related through an is-a like hierarchy. Similarity is then a special case of relat</context>
</contexts>
<marker>Mohammad, Hirst, 2006</marker>
<rawString>Saif Mohammad and Graeme Hirst. 2006. Distributional measures of concept-distance. a task-oriented evaluation. In Proceedings of EMNLP-2006, Sydney,Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Patwardhan</author>
<author>S Banerjee</author>
<author>T Pedersen</author>
</authors>
<title>Using measures of semantic relatedness for word sense disambiguation.</title>
<date>2003</date>
<booktitle>In Proceedings of Fourth International Conference on Intelligent Text Processing and Computational Linguistics,</booktitle>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="26631" citStr="Patwardhan et al., 2003" startWordPosition="4445" endWordPosition="4448">r different measures over the two dataset. that counts the percentage of overlapping LUs between the two frames. We also defined as upperbound the human agreement over the gold standard. As regards distributional measures, statistics are drawn from the TREC-2002 Vol.2 corpus, consisting of about 110 million words, organized in 230,401 news documents and 5,433,048 sentences8. LUs probabilities in Eq. 8 are estimate over the SemCor 2.0 corpus, consisting of 700,000 running words, sense-tagged with WordNet 2.0 senses.9. WordNet-based measures are computed using WordNet 2.0 and implemented as in (Patwardhan et al., 2003). Mappings between WordNet senses and FrameNet verbal LUs are taken from Shi and Mihalcea (2005); as mappings for nouns and adjectives are not available, for the WordNet-based measures we use the first sense heuristic. Note that some of the measures we adopt need some degree of supervision. The WordNet-based and the cr wgt measures rely on a WordNetFrameNet mapping, which has to be created manually or by some reliable automatic technique. Hierarchy-based measures instead rely on the FrameNet hierarchy that is also a manual artifact. 5.1 Experimental Results Table 3 reports the correlation resu</context>
</contexts>
<marker>Patwardhan, Banerjee, Pedersen, 2003</marker>
<rawString>S. Patwardhan, S. Banerjee, and T. Pedersen. 2003. Using measures of semantic relatedness for word sense disambiguation. In Proceedings of Fourth International Conference on Intelligent Text Processing and Computational Linguistics, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Diego De Cao</author>
<author>Paolo Marocco</author>
<author>Roberto Basili</author>
</authors>
<title>Towards a vector space model for framenet-like resources.</title>
<date>2008</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Marrakech, Marocco.</location>
<marker>Pennacchiotti, De Cao, Marocco, Basili, 2008</marker>
<rawString>Marco Pennacchiotti, Diego De Cao, Paolo Marocco, and Roberto Basili. 2008. Towards a vector space model for framenet-like resources. In Proceedings of LREC, Marrakech, Marocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Using information content to evaluate semantic similarity.</title>
<date>1995</date>
<booktitle>In Proceedings of the 14th International Joint Conference on Artificial Intelligence,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1212" citStr="Resnik, 1995" startWordPosition="168" endWordPosition="169">ce on the task of ranking pairs of frames. 1 Introduction Measuring relatedness among linguistic entities is a crucial topic in NLP. Automatically assessing the degree of similarity or relatedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantic</context>
<context position="5291" citStr="Resnik (1995)" startWordPosition="835" endWordPosition="836">zed as follows. In Section 2 we summarize related work. In Section 3 we describe the experiment of humans ranking frame pairs, and discuss the results. In Section 4 and 5 we respectively introduce our relatedness measures, and test them over a manual gold standard. In Section 6 we draw final conclusions and outline future work. 2 Related Work Much research in NLP has studied similarity and relatedness between words. Rubenstein and Goodenough (1965) were the first to propose a procedure to assess human agreement on ranking pairs of words on relatedness. Their experiment was later replicated by Resnik (1995) and Charles (2000). All these studies reported good levels of agreements among annotators, suggesting that the notion of word relatedness is cognitively principled. In our experiment in Section 3.2 we apply the same procedure to assess agreement on ranking frames. Measures for estimating word relatedness have been systematically proposed since the early 90’s, and are today widely used in NLP for various tasks. Most measures can be classified either as corpus-based or ontology-based. Corpus-based measures compute relatedness looking at the distributional properties of the two words: words that</context>
<context position="14471" citStr="Resnik, 1995" startWordPosition="2338" endWordPosition="2339">incipled for humans, and that the final datasets are reliable enough to be used as gold standard for our experiments. Table 2 reports the first and last 5 ranked frame pairs for the two datasets. We compared the correlation results obtained above on “frame relatedness”, to those derived from previous works on “word relatedness”. This comparison should indicate if ranking related frames (i.e. situations) is more or less complex and intuitive than ranking words.3 As for words, we computed the average Kendall’s T among three different annotation efforts (namely, (Rubenstein and Goodenough, 1965; Resnik, 1995; Charles, 2000)) carried out over a same dataset of 28 word pairs originally created by Rubenstein and Goodenough. Note that the annotation schema followed in the three works is the same as ours. We obtained a Kendall’s r = 0.775, which is statistically significant at the 99% level. As expected, the correlation for word relatedness is higher than for frames: Humans find it easier to compare two words than two complex situations, as the former are less complex linguistic entities than the latter. 4 Measures for frame relatedness Manually computing relatedness between all possible frame pairs i</context>
</contexts>
<marker>Resnik, 1995</marker>
<rawString>Philip Resnik. 1995. Using information content to evaluate semantic similarity. In Proceedings of the 14th International Joint Conference on Artificial Intelligence, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Rubenstein</author>
<author>J B Goodenough</author>
</authors>
<title>Contextual correlates of synonymy.</title>
<date>1965</date>
<journal>Communications of the ACM,</journal>
<volume>8</volume>
<issue>10</issue>
<contexts>
<context position="1198" citStr="Rubenstein and Goodenough, 1965" startWordPosition="163" endWordPosition="167">r measures provide good performance on the task of ranking pairs of frames. 1 Introduction Measuring relatedness among linguistic entities is a crucial topic in NLP. Automatically assessing the degree of similarity or relatedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in </context>
<context position="5130" citStr="Rubenstein and Goodenough (1965)" startWordPosition="804" endWordPosition="808">ning the path to the use of frame relatedness as a practical tool for NLP, and showing that measures for word relatedness can be successfully adapted to frames. The paper is organized as follows. In Section 2 we summarize related work. In Section 3 we describe the experiment of humans ranking frame pairs, and discuss the results. In Section 4 and 5 we respectively introduce our relatedness measures, and test them over a manual gold standard. In Section 6 we draw final conclusions and outline future work. 2 Related Work Much research in NLP has studied similarity and relatedness between words. Rubenstein and Goodenough (1965) were the first to propose a procedure to assess human agreement on ranking pairs of words on relatedness. Their experiment was later replicated by Resnik (1995) and Charles (2000). All these studies reported good levels of agreements among annotators, suggesting that the notion of word relatedness is cognitively principled. In our experiment in Section 3.2 we apply the same procedure to assess agreement on ranking frames. Measures for estimating word relatedness have been systematically proposed since the early 90’s, and are today widely used in NLP for various tasks. Most measures can be cla</context>
<context position="10455" citStr="Rubenstein and Goodenough (1965)" startWordPosition="1658" endWordPosition="1661">ATH – DEAD OR ALIVE). Precedes: one frame temporally proceeds the other (e.g. FALL ASLEEP – SLEEP). Perspective on: one frame describes a specific point-of-view on a neutral frame. The first two are is-a like relations, while the others are non-hierarchical. 3.2 Manually ranking related frames We asked a pool of human annotators to manually rank a set of frame pairs according to their relatedness. The goal was twofolds. First, we wanted to check how intuitive the notion of frame relatedness is, by computing inter-annotator agreement, and by comparing the agreement results to those obtained by Rubenstein and Goodenough (1965) for word relatedness. Second, we planned to use the produced dataset as a gold standard for testing the relatedness measures, as described in Section 5. In the rest of the section we describe the annotation process in detail. Dataset creation. We created two different datasets, a simple and a controlled set, each containing 155 pairs. Frame pairs in the simple set were randomly selected from the FrameNet database. Frame pairs in the controlled set were either composed of two frames belonging to the same scenario1, or being so that one frame is one edge from the scenario of the other. This ens</context>
<context position="12281" citStr="Rubenstein and Goodenough (1965)" startWordPosition="1971" endWordPosition="1975">s small enough to obtain a reliable annotation in a short time; (2) We can compute the agreement among the 15 annotators over the shared pairs; (3) We can check the reliability of the final gold standard created in the second phase (see following section) by comparing to the annotations. Each annotator was asked to order a shuffled deck of 15 cards, each one describing a pair of frames. The card contained the following information about the two frames: names; definitions; the lists of core FEs; a frame annotated sentence for each frame, randomly chosen from the FrameNet database. Similarly to Rubenstein and Goodenough (1965) we gave the annotators the following instructions: (i) After looking through the whole deck, order the pairs according to amount of relatedness; (ii) You may assign the same rank to pairs having the same degree of relatedness (i.e. ties are allowed). We checked the agreement among the 15 annotators in ranking the 5 shared pairs by using the Kendall’s T correlation coefficient (Kendall, 1938). Kendall’s T can be interpreted as the difference between the probability that in the dataset two variables are in the same order versus the probability that they are in different orders (see (Lapata, 200</context>
<context position="14457" citStr="Rubenstein and Goodenough, 1965" startWordPosition="2334" endWordPosition="2337"> relatedness” is intuitive and principled for humans, and that the final datasets are reliable enough to be used as gold standard for our experiments. Table 2 reports the first and last 5 ranked frame pairs for the two datasets. We compared the correlation results obtained above on “frame relatedness”, to those derived from previous works on “word relatedness”. This comparison should indicate if ranking related frames (i.e. situations) is more or less complex and intuitive than ranking words.3 As for words, we computed the average Kendall’s T among three different annotation efforts (namely, (Rubenstein and Goodenough, 1965; Resnik, 1995; Charles, 2000)) carried out over a same dataset of 28 word pairs originally created by Rubenstein and Goodenough. Note that the annotation schema followed in the three works is the same as ours. We obtained a Kendall’s r = 0.775, which is statistically significant at the 99% level. As expected, the correlation for word relatedness is higher than for frames: Humans find it easier to compare two words than two complex situations, as the former are less complex linguistic entities than the latter. 4 Measures for frame relatedness Manually computing relatedness between all possible</context>
</contexts>
<marker>Rubenstein, Goodenough, 1965</marker>
<rawString>H. Rubenstein and J.B. Goodenough. 1965. Contextual correlates of synonymy. Communications of the ACM, 8(10):627–633.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josef Ruppenhofer</author>
<author>Michael Ellsworth</author>
<author>Miriam R L Petruck</author>
<author>Christopher R Johnson</author>
</authors>
<title>FrameNet II: Extended Theory and Practice. In ICSI</title>
<date>2005</date>
<tech>Technical Report.</tech>
<contexts>
<context position="9311" citStr="Ruppenhofer et al., 2005" startWordPosition="1466" endWordPosition="1469">yn said she wanted to leave. MESSAGE Evelyn announced that she wanted to leave. ADDRESSEE Evelyn spoke to me about her past. TOPIC Evelyn’s statement about her past MEDIUM Evelyn preached to me over the phone. acknowledge.v, acknowledgment.n, add.v, address.v, admission.n, admit.v, affirm.v, affirmation.n, allegation.n, allege.v, announce.v, ... Table 1: Example frame from FrameNet. is also a corpus of annotated example sentences from the British National Corpus, currently containing 135,000 sentences. In FrameNet, asymmetric frame relations can relate two frames, forming a complex hierarchy (Ruppenhofer et al., 2005): Inheritance: anything true in the semantics of the parent frame, must also be true for the other (e.g. KILLING – EXECUTION). Uses: a part of the situation evoked by one frame refers to the other. Subframe: one frame describes a subpart of a complex situation described in the other (e.g. CRIMINAL-PROCESS – SENTENCING). Causative of : the action in one frame causes the event described in the other (e.g. KILLING – DEATH). Inchoative of: the event in one frame ends in the state described in the other (e.g. DEATH – DEAD OR ALIVE). Precedes: one frame temporally proceeds the other (e.g. FALL ASLEE</context>
</contexts>
<marker>Ruppenhofer, Ellsworth, Petruck, Johnson, 2005</marker>
<rawString>Josef Ruppenhofer, Michael Ellsworth, Miriam R. L. Petruck, and Christopher R. Johnson. 2005. FrameNet II: Extended Theory and Practice. In ICSI Technical Report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Shi</author>
<author>Rada Mihalcea</author>
</authors>
<title>Putting Pieces Together: Combining FrameNet, VerbNet and WordNet for Robust Semantic Parsing. In</title>
<date>2005</date>
<booktitle>In Proceedings of Cicling,</booktitle>
<location>Mexico.</location>
<contexts>
<context position="20088" citStr="Shi and Mihalcea, 2005" startWordPosition="3300" endWordPosition="3304">our was charged with killing a hawk on purpose”, charge.v co-occurs with kill.v, which in FrameNet maps to KILLING. The sentence would then result as a co-occurrence of the two above frames. Unfortunately this is not the case, as the sentence’s sense charge.v#2 does not map to the frame. Ideally, one could solve the problem by using a sense-tagged corpus where senses’ occurrences are mapped to frames. While senseto-frame mappings exist (e.g. mapping between 4For sake of simplicity in the rest of the section we refer to documents, but the same holds for sentences. frames and WordNet senses in (Shi and Mihalcea, 2005)), sense-tagged corpora large enough for distributional studies are not yet available (e.g., the SemCor WordNet-tagged corpus (Miller et al., 1993) consists of only 700,000 words). We therefore circumvent the problem, by implementing pmi in a weighted co-occurrence measure, which gives lower weights to co-occurrences of ambiguous words: 11 wF1(c) - wF2(c) cECF1,F2 11 wF1(c) - cECF2 The weighting function wF(c) estimates the probability that the document c contains a LU of the frame F in the correct sense. Formally, given the set of senses Sl of a LU (e.g. charge.v#1...charge.v#24), we define S</context>
<context position="26727" citStr="Shi and Mihalcea (2005)" startWordPosition="4461" endWordPosition="4464">the two frames. We also defined as upperbound the human agreement over the gold standard. As regards distributional measures, statistics are drawn from the TREC-2002 Vol.2 corpus, consisting of about 110 million words, organized in 230,401 news documents and 5,433,048 sentences8. LUs probabilities in Eq. 8 are estimate over the SemCor 2.0 corpus, consisting of 700,000 running words, sense-tagged with WordNet 2.0 senses.9. WordNet-based measures are computed using WordNet 2.0 and implemented as in (Patwardhan et al., 2003). Mappings between WordNet senses and FrameNet verbal LUs are taken from Shi and Mihalcea (2005); as mappings for nouns and adjectives are not available, for the WordNet-based measures we use the first sense heuristic. Note that some of the measures we adopt need some degree of supervision. The WordNet-based and the cr wgt measures rely on a WordNetFrameNet mapping, which has to be created manually or by some reliable automatic technique. Hierarchy-based measures instead rely on the FrameNet hierarchy that is also a manual artifact. 5.1 Experimental Results Table 3 reports the correlation results over the two datasets. Table 4 reports the best 10 ranks produced by some of the best perfor</context>
<context position="29801" citStr="Shi and Mihalcea (2005)" startWordPosition="4972" endWordPosition="4975">tly in our case, WordNet misses the situational relation (Hirst and St.Onge, 1998), which typically relates words participating in the same situation (e.g. child care - school). This is exactly the relation that would help in mapping frames’ LUs. Another problem relates to adjectives and adverbs: WordNet measures cannot be trustfully applied to these part-of-speech, as they are not hierarchically organized. Unfortunately, 18% of FrameNet LUs are either adjectives or adverbs, meaning that such amount of useful information is lost. Finally, WordNet has in general an incomplete lexical coverage: Shi and Mihalcea (2005) show that 7% of FrameNet verbal LUs do not have a mapping in WordNet. Corpus-based measures. Table 3 shows that co-occurrence measures are effective when using 10The average level of correlation obtained by our measures is comparable to that obtained in other complex information-ordering tasks, e.g. measuring compositionality of verb-noun collations (Venkatapathy and Joshi, 2005) 663 WN JCN CR WGT SENT HR FE Ambient temperature - Temperature (4) Change of phase - Cause change of phase (7) Shoot projectiles - Use firearm (1,5) Run risk - Endangering (27) Knot creation - Rope manipulation (1,5)</context>
</contexts>
<marker>Shi, Mihalcea, 2005</marker>
<rawString>Lei Shi and Rada Mihalcea. 2005. Putting Pieces Together: Combining FrameNet, VerbNet and WordNet for Robust Semantic Parsing. In In Proceedings of Cicling, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Siegel</author>
<author>N J Castellan</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences.</title>
<date>1988</date>
<publisher>McGrawHill.</publisher>
<contexts>
<context position="15323" citStr="Siegel and Castellan, 1988" startWordPosition="2477" endWordPosition="2480">0.775, which is statistically significant at the 99% level. As expected, the correlation for word relatedness is higher than for frames: Humans find it easier to compare two words than two complex situations, as the former are less complex linguistic entities than the latter. 4 Measures for frame relatedness Manually computing relatedness between all possible frame pairs in FrameNet is an unfeasible task. The on-going FrameNet project and automatic methods for FrameNet expansion (e.g. (Pen2Average correlation is computed by averaging the T obtained on each pair of annotators, as suggested in (Siegel and Castellan, 1988); note that the obtained value corresponds to the Kendall u correlation coefficient. Ties are properly treated with the correction factor described in (Siegel and Castellan, 1988). 3The comparison should be taken only as indicative, as words can be ambiguous while frames are not. A more principled comparison should involve word senses, not words. nacchiotti et al., 2008)) are expected to produce an ever growing set of frames. The definition of automatic measures for frame relatedness is thus a key issue. In this section we propose different types of such measures. 4.1 WordNet-based measures Wo</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>S. Siegel and N. J. Castellan. 1988. Nonparametric Statistics for the Behavioral Sciences. McGrawHill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Barcellona,</location>
<contexts>
<context position="1410" citStr="Szpektor et al., 2004" startWordPosition="194" endWordPosition="197">atedness between two words or two expressions, is of great help in a variety of tasks, such as Question Answering, Recognizing Textual Entailment (RTE), Information Extraction and discourse processing. Since the very beginning of computational linguistics, many studies have been devoted to the definition and the implementation of automatic measures for word relatedness (e.g. (Rubenstein and Goodenough, 1965; Resnik, 1995; Lin, 1998; Budanitsky and Hirst, 2006; Mohammad and Hirst, 2006)). More recently, relatedness between lexical-syntactic patterns has also been studied (Lin and Pantel, 2001; Szpektor et al., 2004), to support advanced tasks such as paraphrasing and RTE. Unfortunately, no attention has been paid so far to the definition of relatedness at the more abstract situational level – i.e. relatedness between two prototypical actions, events or state-of-affairs, taken out of context (e.g. the situations of Killing and Death). A prominent definition of “prototypical situation” is given in frame semantics (Fillmore, 1985), where a situation is modelled as a conceptual structure (a frame) constituted by the predicates that can evoke the situation, and the semantic roles expressing the situation’s pa</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Barcellona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sriram Venkatapathy</author>
<author>Aravind K Joshi</author>
</authors>
<title>Measuring the relative compositionality of verb noun (V-N) collocations by integrating features.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP,</booktitle>
<location>Vancouver, Canad.</location>
<contexts>
<context position="30184" citStr="Venkatapathy and Joshi, 2005" startWordPosition="5028" endWordPosition="5031">are not hierarchically organized. Unfortunately, 18% of FrameNet LUs are either adjectives or adverbs, meaning that such amount of useful information is lost. Finally, WordNet has in general an incomplete lexical coverage: Shi and Mihalcea (2005) show that 7% of FrameNet verbal LUs do not have a mapping in WordNet. Corpus-based measures. Table 3 shows that co-occurrence measures are effective when using 10The average level of correlation obtained by our measures is comparable to that obtained in other complex information-ordering tasks, e.g. measuring compositionality of verb-noun collations (Venkatapathy and Joshi, 2005) 663 WN JCN CR WGT SENT HR FE Ambient temperature - Temperature (4) Change of phase - Cause change of phase (7) Shoot projectiles - Use firearm (1,5) Run risk - Endangering (27) Knot creation - Rope manipulation (1,5) Intentionally affect - Rope manipulation (37,5) Run risk - Safe situation (51) Ambient temperature - Temperature (4) Knot creation - Rope manipulation (1,5) Knot creation - Rope manipulation (1,5) Shoot projectiles - Use firearm (1,5) Ambient temperature - Temperature (4) Endangering - Safe situation (62) Hit target - Use firearm (18) Hit target - Intentionally affect (91,5) Shoo</context>
</contexts>
<marker>Venkatapathy, Joshi, 2005</marker>
<rawString>Sriram Venkatapathy and Aravind K. Joshi. 2005. Measuring the relative compositionality of verb noun (V-N) collocations by integrating features. In Proceedings of HLT/EMNLP, Vancouver, Canad.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Wu</author>
<author>M Palmer</author>
</authors>
<title>Verb semantics and lexical selection.</title>
<date>1994</date>
<booktitle>In 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>133--138</pages>
<location>Las Cruces, New Mexico.</location>
<contexts>
<context position="23348" citStr="Wu and Palmer, 1994" startWordPosition="3861" endWordPosition="3864"> contexts we refer to cr dist sent(F1, F2), otherwise to cr dist doc(F1, F2) 4.3 Hierarchy-based measures A third family or relatedness measures leverages the FrameNet hierarchy. The hierarchy forms a directed graph of 795 nodes (frames), 1136 edges, 86 roots, 7 islands and 26 independent components. Similarly to measures for word relatedness, we here compute frame relatedness leveraging graph-based measures over the FrameNet hierarchy. The intuition is that the closer in the hierarchy two frames are, the more related they are6. We here experiment with the Hirst-St.Onge and the Wu and Palmer (Wu and Palmer, 1994) measures, as they are pure taxonomic measures, i.e. they do not require any corpus statistics. 6The Pathfinder Through FrameNet tool gives a practical proof of this intuition: http://fnps.coli. uni-saarland.de/pathsearch. WU and Palmer: this measure calculates relatedness by considering the depths of the two frames in the hierarchy, along with the depth of their least common subsumer (LCS): 2·dp(LCS) hr wu(F1, F2) = ln(F1, LCS)+ln(F2, LCS)+2·dp(LCS) (11) where ln is the length of the path connecting two frames, and dp is the length of the path between a frame and a root. If a path does not ex</context>
</contexts>
<marker>Wu, Palmer, 1994</marker>
<rawString>Z. Wu and M. Palmer. 1994. Verb semantics and lexical selection. In 32nd Annual Meeting of the Association for Computational Linguistics, pages 133– 138, Las Cruces, New Mexico.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>