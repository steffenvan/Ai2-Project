<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010868">
<title confidence="0.965963">
Language and Translation Model Adaptation using Comparable Corpora
</title>
<author confidence="0.96869">
Matthew Snover and Bonnie Dorr Richard Schwartz
</author>
<affiliation confidence="0.9828606">
Laboratory for Computational Linguistics BBN Technologies
and Information Processing 10 Moulton Street
Institute for Advanced Computer Studies Cambridge, MA 02138, USA
Department of Computer Science schwartz@bbn.com
University of Maryland
</affiliation>
<address confidence="0.958288">
College Park, MD 20742
</address>
<email confidence="0.99571">
{snover, bonnie}@umiacs.umd.edu
</email>
<sectionHeader confidence="0.995563" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999685961538462">
Traditionally, statistical machine translation
systems have relied on parallel bi-lingual data
to train a translation model. While bi-lingual
parallel data are expensive to generate, mono-
lingual data are relatively common. Yet mono-
lingual data have been under-utilized, having
been used primarily for training a language
model in the target language. This paper de-
scribes a novel method for utilizing monolin-
gual target data to improve the performance
of a statistical machine translation system on
news stories. The method exploits the exis-
tence of comparable text—multiple texts in
the target language that discuss the same or
similar stories as found in the source language
document. For every source document that is
to be translated, a large monolingual data set
in the target language is searched for docu-
ments that might be comparable to the source
documents. These documents are then used
to adapt the MT system to increase the prob-
ability of generating texts that resemble the
comparable document. Experimental results
obtained by adapting both the language and
translation models show substantial gains over
the baseline system.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999689609756098">
While the amount of parallel data available to train a
statistical machine translation system is sharply lim-
ited, vast amounts of monolingual data are generally
available, especially when translating to languages
such as English. Yet monolingual data are generally
only used to train the language model of the trans-
lation system. Previous work (Fung and Yee, 1998;
Rapp, 1999) has sought to learn new translations for
words by looking at comparable, but not parallel,
corpora in multiple languages and analyzing the co-
occurrence of words, resulting in the generation of
new word-to-word translations.
More recently, Resnik and Smith (2003)
and Munteanu and Marcu (2005) have exploited
monolingual data in both the source and target
languages to find document or sentence pairs that
appear to be parallel. This newly discovered bilin-
gual data can then be used as additional training data
for the translation system. Such methods generally
have a very low yield leaving vast amounts of data
that is only used for language modeling.
These methods rely upon comparable corpora,
that is, multiple corpora that are of the same gen-
eral genre. In addition to this, documents can be
comparable—two documents that are both on the
same event or topic. Comparable documents occur
because of the repetition of information across lan-
guages, and in the case of news data, on the fact that
stories reported in one language are often reported
in another language. In cases where no direct trans-
lation can be found for a source document, it is of-
ten possible to find documents in the target language
that are on the same story, or even on a related story,
either in subject matter or historically. Such docu-
ments can be classified as comparable to the origi-
nal source document. Phrases within this compara-
ble document are likely to be translations of phrases
in the source document, even if the documents them-
selves are not parallel.
Figure 1 shows an excerpt of the reference trans-
lation of an Arabic document, and figure 2 shows a
</bodyText>
<page confidence="0.968999">
857
</page>
<note confidence="0.9798645">
Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 857–866,
Honolulu, October 2008.c�2008 Association for Computational Linguistics
</note>
<bodyText confidence="0.4608341875">
Cameras are flashing and reporters are following up, for
Hollywood star Angelina Jolie is finally talking to the pub-
lic after a one-month stay in India, but not as a movie star.
The Hollywood actress, goodwill ambassador of the United
Nations high commissioner for refugees, met with the In-
dian minister of state for external affairs, Anand Sharma,
here today, Sunday, to discuss issues of refugees and chil-
dren. ... Jolie, accompanied by her five-year-old son, Mad-
dox, visited the refugee camps that are run by the Khalsa
Diwan Society for social services and the high commis-
sioner for refugees Saturday afternoon after she arrived in
Delhi. Jolie has been in India since October 5th shooting
the movie ”A Mighty Heart,” which is based on the life of
Wall Street Journal correspondent Daniel Pearl, who was
kidnapped and killed in Pakistan. Jolie plays the role of
Pearl’s wife, Mariane.
</bodyText>
<figureCaption confidence="0.994053">
Figure 1: Excerpt of Example Reference Translation of
an Arabic Source Document
</figureCaption>
<bodyText confidence="0.999975416666667">
comparable passage.1 In this case, the two new sto-
ries are not translations of each other and were not
reported at the same time—the comparable passage
being an older news story—but both discuss actress
Angelina Jolie’s visit to India. Many phrases and
words are shared between the two, including: the
name of the movie, the name and relationship of the
actress’ character, the name and age of her son and
many others. Such a pairing is extremely compara-
ble, although even less related document pairs could
easily be considered comparable.
We seek to take advantage of these comparable
documents to inform the translation of the source
document. This can be done by augmenting the ma-
jor components of the statistical translation system:
the Language Model and the Translation Model.
This work is in the same tradition as Kim and
Khudanpur (2003), Zhao et al. (2004), and Kim
(2005). Kim (2005) used large amounts of compa-
rable data to adapt language models on a document-
by-document basis, while Zhao et al. (2004) used
comparable data to perform sentence level adapta-
tion of the language model. These adapted lan-
guage models were shown to improve performance
</bodyText>
<footnote confidence="0.997336">
1This is an actual source document from the tuning set used
in our experiments, and the first of a number of similar passages
found by the comparable text selection system described in sec-
tion 2.
</footnote>
<bodyText confidence="0.921185166666666">
Actress Angelina Jolie hopped onto a crowded Mumbai
commuter train Monday to film a scene for a movie about
slain journalist Daniel Pearl, who lived and worked in In-
dia’s financial and entertainment capital. Hollywood actor
Dan Futterman portrays Pearl and Jolie plays his wife Mar-
iane in the ”A Mighty Heart” co-produced by Plan B, a pro-
duction company founded by Brad Pitt and his ex-wife, ac-
tress Jennifer Aniston. Jolie and Pitt, accompanied by their
three children – Maddox, 5, 18-month-old Zahara and 5-
month-old Shiloh Nouvel – arrived in Mumbai on Saturday
from the western Indian city Pune where they were shooting
the movie for nearly a month....
</bodyText>
<figureCaption confidence="0.998603">
Figure 2: Excerpt of Example Comparable Document
</figureCaption>
<bodyText confidence="0.9959423125">
for both automatic speech recognition as well as ma-
chine translation.
In addition to language model adaptation we
also modify the translation model, adding additional
translation rules that enable the translation of new
words and phrases in both the source and target lan-
guages, as well as increasing the probability of ex-
isting translation rules. Translation adaptation us-
ing the translation system’s own output, known as
Self-Training (Ueffing, 2006) has previously shown
gains by augmenting the translation model with ad-
ditional translation rules. In that approach however,
the translation model was augmented using parallel
data, rather than comparable data, by interpolating
a translation model trained using the system output
with the original translation model.
Translation model adaptation using comparable
out-of-domain parallel data, rather than monolingual
data was shown by Hildebrand et al. (2005) to yield
significant gains over a baseline system. The trans-
lation model was adapted by selecting comparable
sentences from parallel corpora for each of the sen-
tences to be translated. In addition to selecting out-
of-domain data to adapt the translation model, com-
parable data selection techniques have been used to
select and weight portions of the existing training
data for the translation model to improve translation
performance (Lu et al., 2007).
The research presented in this paper utilizes a dif-
ferent approach to translation model adaptation us-
ing comparable monolingual text rather than parallel
text, exploiting data that would otherwise be unused
</bodyText>
<page confidence="0.997114">
858
</page>
<bodyText confidence="0.999296461538462">
for estimating the translation model. In addition,
this data also informs the translation system by in-
terpolating the original language model with a new
language model trained from the same comparable
documents.
We discuss the selection of comparable text for
model adaptation in section 2. In sections 3.1
and 3.2, we describe the model adaptation for the
language model and translation model, respectively.
Experimental results describing the application of
model adaptation to a hierarchical Arabic-to-English
MT system are presented in section 4. Finally we
draw conclusions in sections 5.
</bodyText>
<sectionHeader confidence="0.950352" genericHeader="method">
2 Comparable Text Selection
</sectionHeader>
<bodyText confidence="0.999590322580645">
Comparable text is selected for every source doc-
ument from a large monolingual corpus in the tar-
get language. In practice, one could search the
World Wide Web for documents that are compara-
ble to a set of source documents, but this approach
presents problems for ensuring the quality of the re-
trieved documents. The experiments in this paper
use comparable text selected from a collection of
English news texts. Because these texts are all flu-
ent English, and of comparable genre to the test set,
they are also used for training the standard language
model training.
The problem of selecting comparable text has
been widely studied in the information retrieval
community and cross-lingual information retrieval
(CLIR) (Oard and Dorr, 1998; Levow et al., 2005)
has been largely successful at the task of selecting
comparable or relevant documents in one language
given a query in another language. We use CLIR to
select a ranked list of documents in our target lan-
guage, English in the experiments described in this
paper, for each source document, designated as the
query in the CLIR framework, that we wish to trans-
late.
The CLIR problem can be framed probabilisti-
cally as: Given a query Q, find a document D that
maximizes the equation Pr(D is rel|Q). This equa-
tion can be expanded using Bayes’ Law as shown
in equation 1. The prior probability of a document
being relevant can be viewed as uniform, and thus
in this work, we assume Pr(D is rel) is a constant.2
</bodyText>
<footnote confidence="0.897698">
2In fact, it can be beneficial to use features of the document
</footnote>
<bodyText confidence="0.933591">
The Pr(Q) is constant across all documents. There-
fore finding a document to maximize Pr(D is rel|Q)
is equivalent to finding a document that maximizes
Pr(Q|D is rel).
</bodyText>
<equation confidence="0.999246">
Pr(D is rel) Pr(Q|D is rel)
Pr(D is rel|Q) = (1)
Pr(Q)
</equation>
<bodyText confidence="0.999987705882353">
A method of calculating the probability of a query
given a document was proposed by (Xu et al., 2001)3
and is shown in Equation 2. In this formulation, each
foreign word, f, in the query is generated from the
foreign vocabulary with probability α and from the
English document with probability 1 − α, where α
is a constant.4 The probability of f being generated
by the general foreign vocabulary, F, is Pr(f|F) =
freq(f, F)/|F |, the frequency of the word f in the
vocabulary divided by the size of the vocabulary.
The probability of the word being generated by the
English document is the sum of the probabilities of it
being generated by each English word, e, in the doc-
ument which is the frequency of the English word in
the document, (Pr(e|D) = freq(e, D)/|D|) multi-
plied by the probability of the translation of the En-
glish word to the foreign word, Pr(f|e).
</bodyText>
<equation confidence="0.99593925">
Pr(Q|D) = � (α Pr(f|F)+ (2)
fEQ
(1 − α) 1: Pr(e|D) Pr(f|e))
e
</equation>
<bodyText confidence="0.9959166">
This formulation favors longer English docu-
ments over shorter English documents. In addition,
many documents cover multiple stories and topics.
For the purposes of adaptation, shorter, fully com-
parable documents are preferred to longer, only par-
tially comparable documents. We modify the CLIR
system by taking the 1000 highest ranked target lan-
guage documents found by the CLIR system for
each source document, and dividing them into over-
lapping passages of approximately 300 words.5 Sen-
to estimate Pr(D is rel) (Miller and Schwartz, 1998) but we
have not explored that here.
3Xu et al. (2001) formulated this for the selection of foreign
documents given an English query. We reverse this to select
English documents given a foreign query.
</bodyText>
<footnote confidence="0.916192666666667">
4As in Xu et al. (2001), a value of 0.3 was used for α.
5The length of 300 was chosen as this was approximately
the same length as the source documents.
</footnote>
<page confidence="0.998284">
859
</page>
<bodyText confidence="0.999986193548387">
tence boundaries are preserved when creating pas-
sages, insuring that the text is fluent within each pas-
sage. These passages are then scored again by the
CLIR system, resulting in a list of passages of about
300 words each for each source document. Finally,
we select the top N passages to be used for adapta-
tion.
The N passages selected by this method are not
guaranteed to be comparable and are often largely
unrelated to the story or topic in the source docu-
ment. We shall refer to the set of passages selected
by the CLIR system as the bias text to differentiate
it from comparable text, as the adaptation methods
will use this text to bias the MT system so that its
output will be more similar to the bias text.
While we have not conducted experiments using
other CLIR systems, the adaptation methods pre-
sented in this paper could be applied without modifi-
cation using another CLIR system, as the adaptation
method treats the CLIR system as a black box. With
the exception of running a second pass of CLIR, we
use the algorithm of Xu et al. (2001) without any
significant modification, including the use of a stop
word list for both the English and foreign texts. The
parameters for Pr(f|F) and Pr(f|e) were estimated
using the same parallel data that our translation sys-
tem was trained on.
The bias text selected for a source document is
used to adapt the language model (described in sec-
tion 3.1) and the translation model (described in sec-
tion 3.2) when translating that source document.
</bodyText>
<sectionHeader confidence="0.96215" genericHeader="method">
3 Model Adaptation
</sectionHeader>
<bodyText confidence="0.999984516129032">
We use the same bias text to adapt both the lan-
guage model and the translation model. For lan-
guage model adaptation, we increase the probability
of the word sequences in the bias text, and for trans-
lation model adaptation we use additional phrasal
translation rules. The adaptations can be done in-
dependently and while they can augment each other
when used together, this is not required. It is not
necessary to use the same number of passages for
both forms of adaptation, although doing so makes
it more likely both that the English side of the new
translation rule will be assigned a high probability
by the adapted language model, and that the transla-
tion model produces the English text to which the
language model has been adapted. Bias text that
is used by one adaptation but not the other will re-
ceive no special treatment by the other model. This
could result in new translation rules that produce text
to which the language assigns low probability, or it
could result in the language model being able to as-
sign a high probability to a good English translation
that cannot be produced by the translation model due
to a lack of necessary translation rules.
While both adaptation methods are integrated into
a hierarchical translation model (Chiang, 2005),
they are largely implementation independent. Lan-
guage model adaptation could be integrated into any
statistical machine translation that uses a language
model over words, while translation model adapta-
tion could be added to any statistical machine trans-
lation that can utilize phrasal translation rules.
</bodyText>
<subsectionHeader confidence="0.984746">
3.1 Language Model Adaptation
</subsectionHeader>
<bodyText confidence="0.999988655172414">
For every source document, we estimate a new lan-
guage model, the bias language model, from the cor-
responding bias text. Since this bias text is short, the
corresponding bias language model is small and spe-
cific, giving high probabilities to those phrases that
occur in the bias text. The bias language model is
interpolated with the generic language model that
would otherwise be used for translation if no LM
adaptation was used. The new bias language model
is of the same order as the generic language model,
so that if a trigram language model is used for the
MT decoding, then the biased language model will
also be a trigram language model. The bias lan-
guage model is created using the same settings as
the generic language model. In our particular im-
plementation however, the generic language model
uses Kneser-Ney smoothing, while the biased lan-
guage model uses Witten-Bell smoothing due to im-
plementation limitations. In principle the biased lan-
guage model can be smoothed in the same manner as
the generic language model.
We interpolate the bias language model and
the generic language model as shown in equa-
tion 3, where Pry and Prb are the probabilities
from the generic language model and the bias lan-
guage model, respectively. A constant interpolation
weight, A is used to weight the two probabilities for
all documents. While a value for A could be cho-
sen that minimizes perplexity on a tuning set, in a
</bodyText>
<page confidence="0.978645">
860
</page>
<bodyText confidence="0.999873714285714">
similar fashion to Kim (2005), it is unclear that such
a weight would be ideal when the interpolated lan-
guage model is used as part of a statistical translation
system. In practice we have observed that weights
other than one that minimizes perplexity, typically a
lower weight, can yield better translation results on
the tuning set.
</bodyText>
<equation confidence="0.991985">
Pr(e) _ (1 − A) Pr(e) + A Pr(e) (3)
</equation>
<bodyText confidence="0.999976733333333">
� The resulting interpolated language model is then
used in place of the generic language model in the
translation process, increasing the probability that
the translation output will resemble the bias text. It
is important to note that, unlike the translation model
adaptation described in section 3.2, no new infor-
mation is added to the system with language model
adaptation. Because the bias text is extracted from
the same monolingual corpus that the generic lan-
guage model was estimated from, all of the word se-
quences used for training the bias language model
were also used for training the generic language
model. Language model adaptation only increases
the weight of the portion of the language model data
that was selected as comparable.
</bodyText>
<subsectionHeader confidence="0.97377">
3.2 Translation Model Adaptation
</subsectionHeader>
<bodyText confidence="0.999972893939394">
It is frequently the case in machine translation that
unknown words or phrases are present in the source
document, or that the known translations of source
words are based on a very small number of oc-
currences in the training data. In other cases,
translations may be known for individual words in
the source document, but not for longer phrases.
Translation model adaptation seeks to generate new
phrasal translation rules for these source words and
phrases. The bias text for a source document may,
if comparable, contain a number of English words
and phrases that are the English side of these desired
rules.
Because the source data and the bias text are
not translations of each other and are not sen-
tence aligned, conventional alignment tools, such as
GIZA++ (Och and Ney, 2000), cannot be used to
align the source and bias text. Because the passages
in the bias text are not translations of the source doc-
ument, it will always be the case that portions of the
source document have no translation in the bias text,
and portions of the bias text have no translation in
the source document. In addition a phrase in one
of these texts might have multiple, differing transla-
tions in the other text.
Unlike language model adaptation, the entirety of
the bias text is not used for translation adaptation.
We extract those phrases that occur in at least M
of the passages in the bias texts. A phrase is only
counted once for every passage in which it occurs,
so that repeated use of a phrase within a passage
does not affect whether it used to generate new rules.
Typically, passages selected by the CLIR tend to be
very similar to each other if they are comparable
to the source document and are very different from
each other if they are not comparable to the source
document. Phrases that are identical across passages
are the ones that are most likely to be comparable,
whereas a phrase or word that occurs in only one
passage is likely to be present only by chance or if
the passage it is in is not comparable. Filtering the
target phrases to those that occur in multiple pas-
sages therefore serves not only to reduce the total
number of rules, but also to filter out phrases from
passages that are not comparable.
For each phrase in the source document we gener-
ate a new translation to each of the phrases selected
from the bias text, and assign it a low uniform prob-
ability.6 For each translation rule we also have a
lexical translation probability that we estimate cor-
rectly from the trained word model. These new rules
are then added to the phrase table of the existing
translation model when translating the source doc-
ument. Rather than adding probability to the ex-
isting generic rules, the new rules are marked as
bias rules by the system and given their own fea-
ture weight. While the vast majority of these rules
are incorrect translations, these incorrect rules will
be naturally biased against by the translation sys-
tem. If the source side of a translation already has a
number of observed translations, then the low prob-
ability of the new bias rule will cause it to not be
selected by the translation system. If the new trans-
lation rules would produce garbled English, then it
will be biased against by the language model. When
this is combined with the language model adapta-
</bodyText>
<footnote confidence="0.99654">
6A probability of 1/700 is arbitrarily used for the bias rules
although it is then weighted by the bias translation rule weight.
</footnote>
<page confidence="0.995583">
861
</page>
<bodyText confidence="0.999724666666667">
tion, a natural pressure is exerted to use the bias rules
for source phrases primarily when it would cause the
output to look more like the bias text.
</bodyText>
<sectionHeader confidence="0.996766" genericHeader="method">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999993333333333">
We evaluated the performance of language and
translation model adaptation with our translation
system on two conditions, the details of which are
presented in section 4.1. One condition involved a
small amount of parallel training, such as one might
find when translating a less commonly taught lan-
guage (LCTL). The other condition involved the full
amount of training available for Arabic-to-English
translation. In the case of LCTLs we expect our
translation model to have the most deficiencies and
be most in need of additional translation rules. So,
it is under such a condition we would expect the
translation model adaptation to be the most bene-
ficial. We evaluate the system’s performance under
this condition in section 4.2. The effectiveness of
this technique on state-of-the-art systems, and its ef-
ficiency when used with a well trained generic trans-
lation model is presented in section 4.3.
</bodyText>
<subsectionHeader confidence="0.993862">
4.1 Implementation Details
</subsectionHeader>
<bodyText confidence="0.999985214285714">
Both language-model and translation-model adap-
tation are implemented on top of a hierarchical
Arabic-to-English translation system with string-to-
dependency rules as described in Shen et al. (2008).
While generalized rules are generated from the par-
allel data, rules generated by the translation model
adaptation are not generalized and are used only as
phrasal rules. A trigram language model was used
during decoding, and a 5-gram language model was
used to re-score the n-best list after decoding. In ad-
dition to the features described in Shen et al. (2008),
a new feature is added to the model for the bias
rule weight, allowing the translation system to ef-
fectively tune the probability of the rules added by
translation model adaptation in order to improve per-
formance on the tuning set.
Bias texts were selected from three mono-
lingual corpora: the English Gigaword cor-
pus (2,793,350,201 words), the FBIS corpus
(28,465,936 words), and a collection of news archive
data collected from the websites of various on-
line, public news sites (828,435,409 words). All
three corpora were also part of the generic language
model training data. Language model adaptation
on both the trigram and 5-gram language models
used 10 comparable passages with an interpolation
weight of 0.1. Translation model adaptation used 10
comparable passages for the bias text and a value of
2 for M.
Each selected passage contains approximately
300 words, so in the case where 10 comparable pas-
sages are used to create a bias text, the resulting text
will be 3000 words long on average. The language
models created using these bias texts are very spe-
cific giving large probability to n-gram sequences
seen in those texts.
The construction of the bias texts increases the
overall run-time of the translation system, although
in practice this is a small expenditure. The most in-
tensive portion is the initial indexing of the monolin-
gual corpus, but this is only required once and can be
reused for any subsequent test set that is evaluated.
This index can then be quickly searched for com-
parable passages. When considering research envi-
ronments, test sets are used repeatedly and bias texts
only need to be built once per set, making the build-
ing cost negligible. Otherwise, the time required to
build the bias text is still small compared to the ac-
tual translation time.
All conditions were optimized using BLEU (Pap-
ineni et al., 2002) and evaluated using both BLEU
and Translation Edit Rate (TER) (Snover et al.,
2006). BLEU is an accuracy measure, so higher
values indicate better performance, while TER is an
error metric, so lower values indicate better perfor-
mance. Optimization was performed on a tuning set
of newswire data, comprised of portions of MTEval
2004, MTEval 2005, and GALE 2007 newswire de-
velopment data, a total of 48921 words of English
in 1385 segments and 173 documents. Results were
measured on the NIST MTEval 2006 Arabic Evalu-
ation set, which was 55578 words of English in 1797
segments and 104 documents. Four reference trans-
lations were used for scoring each translation.
Parameter optimization method was done using n-
best optimization, although the adaptation process
is not tied to this method. The MT decoder is run
on the tuning set generating an n-best list (where
n = 300), on which all of the translation features
(including bias rule weights) are optimized using
</bodyText>
<page confidence="0.994559">
862
</page>
<bodyText confidence="0.999971956521739">
Powell’s method. These new weights are then used
to decode again, repeating the whole process, using
a cumulative n-best list. This continues for several
iterations until performance on the tuning set stabi-
lizes. The resulting feature weights are used when
decoding the test set. A similar, but simpler, method
is used to determine the feature weights after 5-gram
rescoring. This n-best optimization method has sub-
tle implications for translation model adaptation. In
the first iteration, few bias rules are used in decoding
the 300-best, and those that are used frequently help,
although the overall gain is small due to the small
number of bias rules used. This causes the opti-
mizer to greatly increase the weight of the bias rules,
causing the decoder to overuse the bias rules in the
next iteration causing a sharp decrease in translation
quality. Several iterations are needed for the cumu-
lative n-best to achieve sufficient diversity and size
to assign a weight for the bias translation rules that
results in an increase in performance over the base-
line. Alternative optimization methods could likely
circumvent this process. Language model adapta-
tion does not suffer from this phenomenon.
</bodyText>
<subsectionHeader confidence="0.9947895">
4.2 Less Commonly Taught Language
Simulation
</subsectionHeader>
<bodyText confidence="0.999981844444444">
In order to better examine the nature of translation
model adaptation, we elected to work with a transla-
tion model that was trained on only 5 million words
of parallel Arabic-English text. Limiting the trans-
lation model training in this way simulates the prob-
lem of translating less commonly taught languages
(LCTL) where less parallel text is available, a situa-
tion that is not the case for Arabic. Since the model
is trained on less parallel data, it is lacking a large
number of translation rules, which is expected to be
addressed by the translation model adaptation. By
working in an environment with a more deprived
baseline translation model, we are giving the trans-
lation model adaptation more room to assist.
The experiments described below use a 5 million
word Arabic parallel text corpus constructed from
the LDC2004T18 and LDC2006E25 corpora. The
full monolingual English data were used for the lan-
guage model and for selection of comparable doc-
uments. Unless otherwise specified no language
model adaptation was used.
We first establish an upper limit on the gain us-
ing translation model adaptation, using the reference
data to adapt the translation system. These reference
data can be considered to be extremely comparable,
better than could ever be hoped to gain by compara-
ble document selection. We first aligned this data
using GIZA++ to the source data, simulating the
ideal case where we can perfectly determine which
source words translate to which comparable words.
Because our translation model adaptation system as-
signs uniform probability to all bias rules, we ignore
the correct rule probabilities that we could extract
from word alignment and assign uniform probabil-
ity to all of the bias translation rules. As expected,
this gives a large gain over the baseline.
We also examine limiting these new translation
rules to those rules whose target side occurs in the
top 100 passages selected by CLIR, thus minimiz-
ing the adaption to those rules that it theoretically
could learn from the bias text. On average, 50% of
the rules were removed by this filtering, resulting in
a corresponding 50% decrease in the gain over the
baseline. The results of these experiments and an
unadapted baseline are shown in table 1.
</bodyText>
<table confidence="0.999775428571429">
Test Set TM Adaptation TER BLEU
Tune None 0.4984 0.4080
Aligned Reference 0.3692 0.5841
Overlapping Only 0.4179 0.5138
MT06 None 0.5516 0.3468
Aligned Reference 0.4517 0.5216
Overlapping Only 0.4899 0.4335
</table>
<tableCaption confidence="0.99992">
Table 1: LCTL Aligned Reference Adaptation Results
</tableCaption>
<bodyText confidence="0.998972571428571">
The fair translation model adaptation system,
however, does not align source phrases to the cor-
rect bias text phrases in such a fashion, and instead
aligns all source words to all target words. To in-
vestigate the effect of this over production of rules,
we again used the reference translations as if they
were comparable data, but we ignored the align-
ments learned by GIZA++, and instead allowed all
source phrases to translate to all English phrases in
the reference text, with uniform probability. This
still shows large gains in translation quality over the
baseline, as measured by TER and BLEU. Again,
we also examined limiting the text used for transla-
tion model adaptation to those phrases that occur in
</bodyText>
<page confidence="0.997129">
863
</page>
<bodyText confidence="0.9998356">
both the reference text and the top 100 comparable
passages selected the CLIR system. While this de-
creased performance, the system still performs sig-
nificantly better than the baseline, as shown in the
following table 2.
</bodyText>
<table confidence="0.999824714285714">
Test Set TM Adaptation TER BLEU
Tune None 0.4984 0.4080
Unaligned Ref. 0.4492 0.4566
Overlapping Only 0.4808 0.4313
MT06 None 0.5516 0.3468
Unaligned Ref. 0.5254 0.3990
Overlapping Only 0.5390 0.3695
</table>
<tableCaption confidence="0.999567">
Table 2: LCTL Unaligned Reference Adaptation Results
</tableCaption>
<bodyText confidence="0.999258625">
Applying translation model and language model
adaptation fairly, using only bias text from the com-
parable data selection, yields smaller gains on both
the tuning and MT06 sets, as shown in table 3.
The combination of language-model and translation-
model adaptation exceeds the gains that would be
achieved over the baseline by either method sepa-
rately.
</bodyText>
<table confidence="0.999626555555556">
Test Set Adaptation TER BLEU
Tune None 0.4984 0.4080
LM 0.4922 0.4140
TM 0.4916 0.4169
LM &amp; TM 0.4888 0.4244
MT06 None 0.5516 0.3468
LM 0.5559 0.3490
TM 0.5545 0.3478
LM &amp; TM 0.5509 0.3536
</table>
<tableCaption confidence="0.999786">
Table 3: LCTL Fair Adaptation Results
</tableCaption>
<bodyText confidence="0.99920212">
the techniques used in that work are separate and
independent from the adaptation methods we de-
scribe in this paper.7 Language model adaptation
and translation model adaptation were applied both
independently and jointly to the translation system,
and the results were evaluated against an unadapted
baseline, as shown in table 4.
While gains from language model adaptation
were substantial on the tuning set, on the MT06 test
set they are reduced to a 0.65% gain on BLEU and
a negligible improvement in TER. The translation
model adaptation performs better with 1.37% im-
provement in BLEU and a 0.26% improvement in
TER. This gain increases to a 2.07% improvement
in BLEU and a 0.64% improvement in TER when
language adaptation is used in conjunction with the
translation model adaptation, showing the impor-
tance of using both adaptation methods. While it
could be expected that a more heavily trained trans-
lation model might not require the benefit of lan-
guage and translation model adaptation, a more sub-
stantial gain over the baseline can be seen when both
forms of adaptation are used than in the case with
less parallel training—a difference of 2.07% BLEU
versus 0.68% BLEU.
</bodyText>
<table confidence="0.999530222222222">
Test Set Adaptation TER BLEU
Tune None 0.4339 0.4661
LM 0.4227 0.4857
TM 0.4351 0.4657
LM &amp; TM 0.4245 0.4882
MT06 None 0.5146 0.3852
LM 0.5140 0.3917
TM 0.5120 0.3989
LM &amp; TM 0.5082 0.4059
</table>
<tableCaption confidence="0.999202">
Table 4: Full Training Adaptation Results
</tableCaption>
<subsectionHeader confidence="0.983274">
4.3 Full Parallel Training Results
</subsectionHeader>
<bodyText confidence="0.803526904761905">
While the simulation described in section 4.2 used
only 5 million words of parallel training, 230 mil-
lion words of parallel data from 18.5 million seg-
ments were used for training the full Arabic-to-
English translation system. This parallel data in-
cludes the LDC2007T08 ”ISI Arabic-English Auto-
matically Extracted Parallel Text” corpus (Munteanu
and Marcu, 2007), which was created from monolin-
gual corpora in English and Arabic using the algo-
rithm described in Munteanu and Marcu (2005), as
Of the comparable passages selected by the CLIR
system for the MT06 test set in the full training
experiment, 16.3% were selected from the News
7The two methods are not directly comparable, and so we
do not make any attempt to do so. Munteanu and Marcu (2005)
creates new parallel corpora from two monolingual corpora.
This new parallel data is generally applicable for training a
translation model but does not target any particular test set. Our
adaptation method does not generate new parallel data, but cre-
ates a new specific translation model for a test document that is
being translated.
</bodyText>
<page confidence="0.995523">
864
</page>
<bodyText confidence="0.999911125">
Archive corpus, 81.2% were selected from the En-
glish GigaWord corpus and 2.5% were selected from
the FBIS corpus. A slightly different distribution
was found for the Tuning set, where 17.8% of the
passages were selected from the News Archive cor-
pus, 77.1% were selected from the English Giga-
Word corpus, and 5.1% were selected from the FBIS
corpus.
</bodyText>
<sectionHeader confidence="0.999644" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.989136138888889">
The reuse of a monolingual corpus that was already
used by a translation system for language model
training to perform both language and translation
model adaptation shows large gains over an un-
adapted baseline. By leveraging off of a CLIR sys-
tem, which itself contains no information not al-
ready given to the translation system,8 potentially
comparable passages can be found which allow im-
proved translation. Surprisingly, these gains are
largest when the baseline model is better trained, in-
dicating that a strong reliance of the adaptation on
the existing models.
One explantation for these counter-intuitive
results–larger gains in the full training scenario ver-
sus the LCTL scenario–is that the lexical probabili-
ties are better estimated in the former case. The bias
rules all have equal translation probability and only
vary in probability according to the lexical proba-
bility of the rules. Better estimates of these lexical
probabilities may enable the translation system to
more clearly distinguish between helpful and harm-
ful bias rules.
There are many clear directions for the improve-
ment of these methods. The current adaptation
method does not utilize the probabilities from the
CLIR system and treats the top-ranked passages all
as equally comparable regardless of the probabil-
ity assigned. Variable weighting of passages could
prove beneficial to both language model adaptation,
where the passages could be weighted proportion-
ally to the probability of the passage being relevant,
and translation model adaptation, where the require-
ment on repetition of phrases across passages could
be weighted, as could the probability of the new
8The probabilistic parameters of the CLIR system are esti-
mated from the same parallel corpora that is used to train the
generic translation model.
rules produced by the translation system. In ad-
dition, the CLIR score, among other possible fea-
tures such as phrase overlap, could be used to de-
termine those documents where no comparable pas-
sage could be detected and where it would be bene-
ficial to not adapt the models.
A clear limitation of using comparable documents
to adapt the language and translation model is that
comparable documents must be found. For many
source documents, none of the top passages found
by the CLIR system were comparable. We suspect
that while this will always occur to some extent, this
becomes more common as the monolingual data be-
comes less like the source data, such as when there is
a large time gap between the two. The full extent of
this and the effect of the level of document compa-
rability on translation remains an open question. In
addition, while newswire is an excellent source of
comparable text, it is unclear how well this method
can be used on newsgroups or spoken data, where
the fluency of the source text is diminished. When
translating news stories, this technique is not lim-
ited to major news events. While many of the events
discussed in the source data receive world-wide at-
tention, many are local events that are unreported
in the English comparable data used in our experi-
ments. Events of a similar nature or events involving
many of the same people often do occur in the En-
glish comparable data, allowing improvement even
when the stories are quite different.
The adaptation methods described in this paper
are not limited to a particular framework of statis-
tical machine translation, but have applicability to
any statistical machine translation system that uses
a language model or translation rules.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999955">
This work was supported, in part, by BBN Tech-
nologies under the GALE Program, DARPA/IPTO
Contract No. HR0011-06-C-0022. Any opinions,
findings, and conclusions or recommendations ex-
pressed in this material are those of the authors and
do not necessarily reflect the views of the sponsor.
We are very grateful to all three reviewers for their
careful and thoughtful reviews.
</bodyText>
<page confidence="0.99787">
865
</page>
<sectionHeader confidence="0.995895" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999943813953488">
David Chiang. 2005. A Hierarchical Phrase-Based
Model for Statistical Machine Translation. In Pro-
ceedings of ACL, pages 263–270.
Pascale Fung and Lo Yuen Yee. 1998. An IR Approach
for Translating New Words from Nonparallel, Compa-
rable Texts. In Proceedings of COLING-ACL98, pages
414–420, August.
Almut Silja Hildebrand, Matthias Eck, Stephan Vogel,
and Alex Waibel. 2005. Adaptation of the Translation
Model for Statistical Machine Translation based on In-
formation Retrieval. In Proceedings of EAMT 2005,
Budapest, Hungary, May.
Woosung Kim and Sanjeev Khudanpur. 2003. Cross-
Lingual Lexical Triggers in Statistical Language Mod-
eling. In 2003 Conference on Empirical Methods in
Natural Language Processing (EMNLP 2003), pages
17–24, July.
Woosung Kim. 2005. Language Model Adaptation for
Automatic Speech Recognition and Statistical Machine
Translation. Ph.D. thesis, The Johns Hopkins Univer-
sity, Baltimore, MD.
Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.
2005. Dictionary-based cross-language retrieval. In-
formation Processing and Management, 41:523–547.
Yajuan Lu, Jin Huang, and Qun Liu. 2007. Improving
Statistical Machine Translation Performance by Train-
ing Data Selection and Optimization. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
343–350.
T. Leek Miller and Richard Schwartz. 1998. BBN at
TREC7: Using Hidden Markov Models for Informa-
tion Retrieval. In TREC 1998, pages 80–89, Gaithers-
burg, MD.
Dragos Stefan Munteanu and Daniel Marcu. 2005. Im-
proving Machine Translation Performance by Exploit-
ing Non-Parallel Corpora. Computational Linguistics,
31:477–504.
Dragos Stefan Munteanu and Daniel Marcu. 2007. Isi
arabic-english automatically extracted parallel text.
Linguistic Data Consortium, Philadelphia.
Douglas W. Oard and Bonnie J. Dorr. 1998. Evaluat-
ing Cross-Language Text Retrieval Effectiveness. In
Gregory Grefenstette, editor, Cross-Language Infor-
mation Retrieval, pages 151–161. Kluwer Academic
Publishers, Boston, MA.
F. J. Och and H. Ney. 2000. Improved Statistical Align-
ment Models. In Proceedings of the 38th Annual Con-
ference of the Association for Computational Linguis-
tics, pages 440–447, Hongkong, China.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Traslation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics.
Reinhard Rapp. 1999. Automatic identification of word
translations from unrelated english and german cor-
pora. In Proceedings of the 37th Annual Meeting of
the Association for Computational Linguistics, pages
519–526.
Philip Resnik and Noah Smith. 2003. The Web as a
Parallel Corpus. Computational Linguistics, 29:349–
380.
Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A
New String-to-Dependency Machine Translation Al-
gorithm with a Target Dependency Language Model.
In Proceedings of the 46th Annual Meeting of the As-
sociation for Computational Linguistics (ACL), June.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Edit Rate with Targeted Human An-
notation. In Proceedings of Association for Machine
Translation in the Americas.
Nicola Ueffing. 2006. Using Monolingual Source-
Language to Improve MT Performance. In Proceed-
ings of IWSLT 2006.
Jinxi Xu, Ralpha Weischedel, and Chanh Nguyen. 2001.
Evaluating a Probabilistic Model for Cross-lingual In-
formation Retrieval. In Proceedings of SIGIR 2001
Conference, pages 105–110.
Bing Zhao, Matthias Eck, and Stephan Vogel. 2004.
Language Model Adaptation for Statistical Machine
Translation via Structured Query Models. In Proceed-
ings of Coling 2004, pages 411–417, Geneva, Switzer-
land, Aug 23–Aug 27. COLING.
</reference>
<page confidence="0.998849">
866
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.774614">
<title confidence="0.999461">Language and Translation Model Adaptation using Comparable Corpora</title>
<author confidence="0.998924">Snover Richard</author>
<affiliation confidence="0.9575896">Laboratory for Computational BBN and Information 10 Moulton Institute for Advanced Computer Cambridge, MA 02138, Department of Computer schwartz@bbn.com University of</affiliation>
<address confidence="0.988655">College Park, MD</address>
<abstract confidence="0.999678518518518">Traditionally, statistical machine translation systems have relied on parallel bi-lingual data to train a translation model. While bi-lingual parallel data are expensive to generate, monolingual data are relatively common. Yet monolingual data have been under-utilized, having been used primarily for training a language model in the target language. This paper describes a novel method for utilizing monolingual target data to improve the performance of a statistical machine translation system on news stories. The method exploits the existence of comparable text—multiple texts in the target language that discuss the same or similar stories as found in the source language document. For every source document that is to be translated, a large monolingual data set in the target language is searched for documents that might be comparable to the source documents. These documents are then used to adapt the MT system to increase the probability of generating texts that resemble the comparable document. Experimental results obtained by adapting both the language and translation models show substantial gains over the baseline system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A Hierarchical Phrase-Based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="15341" citStr="Chiang, 2005" startWordPosition="2534" endWordPosition="2535">ranslation model produces the English text to which the language model has been adapted. Bias text that is used by one adaptation but not the other will receive no special treatment by the other model. This could result in new translation rules that produce text to which the language assigns low probability, or it could result in the language model being able to assign a high probability to a good English translation that cannot be produced by the translation model due to a lack of necessary translation rules. While both adaptation methods are integrated into a hierarchical translation model (Chiang, 2005), they are largely implementation independent. Language model adaptation could be integrated into any statistical machine translation that uses a language model over words, while translation model adaptation could be added to any statistical machine translation that can utilize phrasal translation rules. 3.1 Language Model Adaptation For every source document, we estimate a new language model, the bias language model, from the corresponding bias text. Since this bias text is short, the corresponding bias language model is small and specific, giving high probabilities to those phrases that occu</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proceedings of ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An IR Approach for Translating New Words from Nonparallel, Comparable Texts.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING-ACL98,</booktitle>
<pages>414--420</pages>
<contexts>
<context position="1935" citStr="Fung and Yee, 1998" startWordPosition="282" endWordPosition="285"> adapt the MT system to increase the probability of generating texts that resemble the comparable document. Experimental results obtained by adapting both the language and translation models show substantial gains over the baseline system. 1 Introduction While the amount of parallel data available to train a statistical machine translation system is sharply limited, vast amounts of monolingual data are generally available, especially when translating to languages such as English. Yet monolingual data are generally only used to train the language model of the translation system. Previous work (Fung and Yee, 1998; Rapp, 1999) has sought to learn new translations for words by looking at comparable, but not parallel, corpora in multiple languages and analyzing the cooccurrence of words, resulting in the generation of new word-to-word translations. More recently, Resnik and Smith (2003) and Munteanu and Marcu (2005) have exploited monolingual data in both the source and target languages to find document or sentence pairs that appear to be parallel. This newly discovered bilingual data can then be used as additional training data for the translation system. Such methods generally have a very low yield lea</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An IR Approach for Translating New Words from Nonparallel, Comparable Texts. In Proceedings of COLING-ACL98, pages 414–420, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Almut Silja Hildebrand</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Adaptation of the Translation Model for Statistical Machine Translation based on Information Retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of EAMT 2005,</booktitle>
<location>Budapest, Hungary,</location>
<contexts>
<context position="7707" citStr="Hildebrand et al. (2005)" startWordPosition="1225" endWordPosition="1228"> as increasing the probability of existing translation rules. Translation adaptation using the translation system’s own output, known as Self-Training (Ueffing, 2006) has previously shown gains by augmenting the translation model with additional translation rules. In that approach however, the translation model was augmented using parallel data, rather than comparable data, by interpolating a translation model trained using the system output with the original translation model. Translation model adaptation using comparable out-of-domain parallel data, rather than monolingual data was shown by Hildebrand et al. (2005) to yield significant gains over a baseline system. The translation model was adapted by selecting comparable sentences from parallel corpora for each of the sentences to be translated. In addition to selecting outof-domain data to adapt the translation model, comparable data selection techniques have been used to select and weight portions of the existing training data for the translation model to improve translation performance (Lu et al., 2007). The research presented in this paper utilizes a different approach to translation model adaptation using comparable monolingual text rather than pa</context>
</contexts>
<marker>Hildebrand, Eck, Vogel, Waibel, 2005</marker>
<rawString>Almut Silja Hildebrand, Matthias Eck, Stephan Vogel, and Alex Waibel. 2005. Adaptation of the Translation Model for Statistical Machine Translation based on Information Retrieval. In Proceedings of EAMT 2005, Budapest, Hungary, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Woosung Kim</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>CrossLingual Lexical Triggers in Statistical Language Modeling.</title>
<date>2003</date>
<booktitle>In 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>17--24</pages>
<contexts>
<context position="5580" citStr="Kim and Khudanpur (2003)" startWordPosition="886" endWordPosition="889">isit to India. Many phrases and words are shared between the two, including: the name of the movie, the name and relationship of the actress’ character, the name and age of her son and many others. Such a pairing is extremely comparable, although even less related document pairs could easily be considered comparable. We seek to take advantage of these comparable documents to inform the translation of the source document. This can be done by augmenting the major components of the statistical translation system: the Language Model and the Translation Model. This work is in the same tradition as Kim and Khudanpur (2003), Zhao et al. (2004), and Kim (2005). Kim (2005) used large amounts of comparable data to adapt language models on a documentby-document basis, while Zhao et al. (2004) used comparable data to perform sentence level adaptation of the language model. These adapted language models were shown to improve performance 1This is an actual source document from the tuning set used in our experiments, and the first of a number of similar passages found by the comparable text selection system described in section 2. Actress Angelina Jolie hopped onto a crowded Mumbai commuter train Monday to film a scene </context>
</contexts>
<marker>Kim, Khudanpur, 2003</marker>
<rawString>Woosung Kim and Sanjeev Khudanpur. 2003. CrossLingual Lexical Triggers in Statistical Language Modeling. In 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP 2003), pages 17–24, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Woosung Kim</author>
</authors>
<title>Language Model Adaptation for Automatic Speech Recognition and Statistical Machine Translation.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>The Johns Hopkins University,</institution>
<location>Baltimore, MD.</location>
<contexts>
<context position="5616" citStr="Kim (2005)" startWordPosition="895" endWordPosition="896">etween the two, including: the name of the movie, the name and relationship of the actress’ character, the name and age of her son and many others. Such a pairing is extremely comparable, although even less related document pairs could easily be considered comparable. We seek to take advantage of these comparable documents to inform the translation of the source document. This can be done by augmenting the major components of the statistical translation system: the Language Model and the Translation Model. This work is in the same tradition as Kim and Khudanpur (2003), Zhao et al. (2004), and Kim (2005). Kim (2005) used large amounts of comparable data to adapt language models on a documentby-document basis, while Zhao et al. (2004) used comparable data to perform sentence level adaptation of the language model. These adapted language models were shown to improve performance 1This is an actual source document from the tuning set used in our experiments, and the first of a number of similar passages found by the comparable text selection system described in section 2. Actress Angelina Jolie hopped onto a crowded Mumbai commuter train Monday to film a scene for a movie about slain journalist D</context>
<context position="17128" citStr="Kim (2005)" startWordPosition="2832" endWordPosition="2833"> biased language model uses Witten-Bell smoothing due to implementation limitations. In principle the biased language model can be smoothed in the same manner as the generic language model. We interpolate the bias language model and the generic language model as shown in equation 3, where Pry and Prb are the probabilities from the generic language model and the bias language model, respectively. A constant interpolation weight, A is used to weight the two probabilities for all documents. While a value for A could be chosen that minimizes perplexity on a tuning set, in a 860 similar fashion to Kim (2005), it is unclear that such a weight would be ideal when the interpolated language model is used as part of a statistical translation system. In practice we have observed that weights other than one that minimizes perplexity, typically a lower weight, can yield better translation results on the tuning set. Pr(e) _ (1 − A) Pr(e) + A Pr(e) (3) � The resulting interpolated language model is then used in place of the generic language model in the translation process, increasing the probability that the translation output will resemble the bias text. It is important to note that, unlike the translati</context>
</contexts>
<marker>Kim, 2005</marker>
<rawString>Woosung Kim. 2005. Language Model Adaptation for Automatic Speech Recognition and Statistical Machine Translation. Ph.D. thesis, The Johns Hopkins University, Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gina-Anne Levow</author>
<author>Douglas W Oard</author>
<author>Philip Resnik</author>
</authors>
<date>2005</date>
<booktitle>Dictionary-based cross-language retrieval. Information Processing and Management,</booktitle>
<pages>41--523</pages>
<contexts>
<context position="9752" citStr="Levow et al., 2005" startWordPosition="1547" endWordPosition="1550">the World Wide Web for documents that are comparable to a set of source documents, but this approach presents problems for ensuring the quality of the retrieved documents. The experiments in this paper use comparable text selected from a collection of English news texts. Because these texts are all fluent English, and of comparable genre to the test set, they are also used for training the standard language model training. The problem of selecting comparable text has been widely studied in the information retrieval community and cross-lingual information retrieval (CLIR) (Oard and Dorr, 1998; Levow et al., 2005) has been largely successful at the task of selecting comparable or relevant documents in one language given a query in another language. We use CLIR to select a ranked list of documents in our target language, English in the experiments described in this paper, for each source document, designated as the query in the CLIR framework, that we wish to translate. The CLIR problem can be framed probabilistically as: Given a query Q, find a document D that maximizes the equation Pr(D is rel|Q). This equation can be expanded using Bayes’ Law as shown in equation 1. The prior probability of a documen</context>
</contexts>
<marker>Levow, Oard, Resnik, 2005</marker>
<rawString>Gina-Anne Levow, Douglas W. Oard, and Philip Resnik. 2005. Dictionary-based cross-language retrieval. Information Processing and Management, 41:523–547.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yajuan Lu</author>
<author>Jin Huang</author>
<author>Qun Liu</author>
</authors>
<title>Improving Statistical Machine Translation Performance by Training Data Selection and Optimization.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>343--350</pages>
<contexts>
<context position="8158" citStr="Lu et al., 2007" startWordPosition="1297" endWordPosition="1300">inal translation model. Translation model adaptation using comparable out-of-domain parallel data, rather than monolingual data was shown by Hildebrand et al. (2005) to yield significant gains over a baseline system. The translation model was adapted by selecting comparable sentences from parallel corpora for each of the sentences to be translated. In addition to selecting outof-domain data to adapt the translation model, comparable data selection techniques have been used to select and weight portions of the existing training data for the translation model to improve translation performance (Lu et al., 2007). The research presented in this paper utilizes a different approach to translation model adaptation using comparable monolingual text rather than parallel text, exploiting data that would otherwise be unused 858 for estimating the translation model. In addition, this data also informs the translation system by interpolating the original language model with a new language model trained from the same comparable documents. We discuss the selection of comparable text for model adaptation in section 2. In sections 3.1 and 3.2, we describe the model adaptation for the language model and translation</context>
</contexts>
<marker>Lu, Huang, Liu, 2007</marker>
<rawString>Yajuan Lu, Jin Huang, and Qun Liu. 2007. Improving Statistical Machine Translation Performance by Training Data Selection and Optimization. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 343–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Leek Miller</author>
<author>Richard Schwartz</author>
</authors>
<title>BBN at TREC7: Using Hidden Markov Models for Information Retrieval. In TREC</title>
<date>1998</date>
<pages>80--89</pages>
<location>Gaithersburg, MD.</location>
<contexts>
<context position="12207" citStr="Miller and Schwartz, 1998" startWordPosition="1980" endWordPosition="1983">e foreign word, Pr(f|e). Pr(Q|D) = � (α Pr(f|F)+ (2) fEQ (1 − α) 1: Pr(e|D) Pr(f|e)) e This formulation favors longer English documents over shorter English documents. In addition, many documents cover multiple stories and topics. For the purposes of adaptation, shorter, fully comparable documents are preferred to longer, only partially comparable documents. We modify the CLIR system by taking the 1000 highest ranked target language documents found by the CLIR system for each source document, and dividing them into overlapping passages of approximately 300 words.5 Sento estimate Pr(D is rel) (Miller and Schwartz, 1998) but we have not explored that here. 3Xu et al. (2001) formulated this for the selection of foreign documents given an English query. We reverse this to select English documents given a foreign query. 4As in Xu et al. (2001), a value of 0.3 was used for α. 5The length of 300 was chosen as this was approximately the same length as the source documents. 859 tence boundaries are preserved when creating passages, insuring that the text is fluent within each passage. These passages are then scored again by the CLIR system, resulting in a list of passages of about 300 words each for each source docu</context>
</contexts>
<marker>Miller, Schwartz, 1998</marker>
<rawString>T. Leek Miller and Richard Schwartz. 1998. BBN at TREC7: Using Hidden Markov Models for Information Retrieval. In TREC 1998, pages 80–89, Gaithersburg, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Improving Machine Translation Performance by Exploiting Non-Parallel Corpora. Computational Linguistics,</title>
<date>2005</date>
<pages>31--477</pages>
<contexts>
<context position="2241" citStr="Munteanu and Marcu (2005)" startWordPosition="329" endWordPosition="332">to train a statistical machine translation system is sharply limited, vast amounts of monolingual data are generally available, especially when translating to languages such as English. Yet monolingual data are generally only used to train the language model of the translation system. Previous work (Fung and Yee, 1998; Rapp, 1999) has sought to learn new translations for words by looking at comparable, but not parallel, corpora in multiple languages and analyzing the cooccurrence of words, resulting in the generation of new word-to-word translations. More recently, Resnik and Smith (2003) and Munteanu and Marcu (2005) have exploited monolingual data in both the source and target languages to find document or sentence pairs that appear to be parallel. This newly discovered bilingual data can then be used as additional training data for the translation system. Such methods generally have a very low yield leaving vast amounts of data that is only used for language modeling. These methods rely upon comparable corpora, that is, multiple corpora that are of the same general genre. In addition to this, documents can be comparable—two documents that are both on the same event or topic. Comparable documents occur b</context>
<context position="33590" citStr="Munteanu and Marcu (2005)" startWordPosition="5572" endWordPosition="5575">0.3852 LM 0.5140 0.3917 TM 0.5120 0.3989 LM &amp; TM 0.5082 0.4059 Table 4: Full Training Adaptation Results 4.3 Full Parallel Training Results While the simulation described in section 4.2 used only 5 million words of parallel training, 230 million words of parallel data from 18.5 million segments were used for training the full Arabic-toEnglish translation system. This parallel data includes the LDC2007T08 ”ISI Arabic-English Automatically Extracted Parallel Text” corpus (Munteanu and Marcu, 2007), which was created from monolingual corpora in English and Arabic using the algorithm described in Munteanu and Marcu (2005), as Of the comparable passages selected by the CLIR system for the MT06 test set in the full training experiment, 16.3% were selected from the News 7The two methods are not directly comparable, and so we do not make any attempt to do so. Munteanu and Marcu (2005) creates new parallel corpora from two monolingual corpora. This new parallel data is generally applicable for training a translation model but does not target any particular test set. Our adaptation method does not generate new parallel data, but creates a new specific translation model for a test document that is being translated. 8</context>
</contexts>
<marker>Munteanu, Marcu, 2005</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2005. Improving Machine Translation Performance by Exploiting Non-Parallel Corpora. Computational Linguistics, 31:477–504.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragos Stefan Munteanu</author>
<author>Daniel Marcu</author>
</authors>
<title>Isi arabic-english automatically extracted parallel text. Linguistic Data Consortium,</title>
<date>2007</date>
<location>Philadelphia.</location>
<contexts>
<context position="33465" citStr="Munteanu and Marcu, 2007" startWordPosition="5551" endWordPosition="5554">est Set Adaptation TER BLEU Tune None 0.4339 0.4661 LM 0.4227 0.4857 TM 0.4351 0.4657 LM &amp; TM 0.4245 0.4882 MT06 None 0.5146 0.3852 LM 0.5140 0.3917 TM 0.5120 0.3989 LM &amp; TM 0.5082 0.4059 Table 4: Full Training Adaptation Results 4.3 Full Parallel Training Results While the simulation described in section 4.2 used only 5 million words of parallel training, 230 million words of parallel data from 18.5 million segments were used for training the full Arabic-toEnglish translation system. This parallel data includes the LDC2007T08 ”ISI Arabic-English Automatically Extracted Parallel Text” corpus (Munteanu and Marcu, 2007), which was created from monolingual corpora in English and Arabic using the algorithm described in Munteanu and Marcu (2005), as Of the comparable passages selected by the CLIR system for the MT06 test set in the full training experiment, 16.3% were selected from the News 7The two methods are not directly comparable, and so we do not make any attempt to do so. Munteanu and Marcu (2005) creates new parallel corpora from two monolingual corpora. This new parallel data is generally applicable for training a translation model but does not target any particular test set. Our adaptation method does</context>
</contexts>
<marker>Munteanu, Marcu, 2007</marker>
<rawString>Dragos Stefan Munteanu and Daniel Marcu. 2007. Isi arabic-english automatically extracted parallel text. Linguistic Data Consortium, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas W Oard</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Evaluating Cross-Language Text Retrieval Effectiveness.</title>
<date>1998</date>
<booktitle>Cross-Language Information Retrieval,</booktitle>
<pages>151--161</pages>
<editor>In Gregory Grefenstette, editor,</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston, MA.</location>
<contexts>
<context position="9731" citStr="Oard and Dorr, 1998" startWordPosition="1543" endWordPosition="1546">ce, one could search the World Wide Web for documents that are comparable to a set of source documents, but this approach presents problems for ensuring the quality of the retrieved documents. The experiments in this paper use comparable text selected from a collection of English news texts. Because these texts are all fluent English, and of comparable genre to the test set, they are also used for training the standard language model training. The problem of selecting comparable text has been widely studied in the information retrieval community and cross-lingual information retrieval (CLIR) (Oard and Dorr, 1998; Levow et al., 2005) has been largely successful at the task of selecting comparable or relevant documents in one language given a query in another language. We use CLIR to select a ranked list of documents in our target language, English in the experiments described in this paper, for each source document, designated as the query in the CLIR framework, that we wish to translate. The CLIR problem can be framed probabilistically as: Given a query Q, find a document D that maximizes the equation Pr(D is rel|Q). This equation can be expanded using Bayes’ Law as shown in equation 1. The prior pro</context>
</contexts>
<marker>Oard, Dorr, 1998</marker>
<rawString>Douglas W. Oard and Bonnie J. Dorr. 1998. Evaluating Cross-Language Text Retrieval Effectiveness. In Gregory Grefenstette, editor, Cross-Language Information Retrieval, pages 151–161. Kluwer Academic Publishers, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>440--447</pages>
<location>Hongkong, China.</location>
<contexts>
<context position="19035" citStr="Och and Ney, 2000" startWordPosition="3150" endWordPosition="3153"> based on a very small number of occurrences in the training data. In other cases, translations may be known for individual words in the source document, but not for longer phrases. Translation model adaptation seeks to generate new phrasal translation rules for these source words and phrases. The bias text for a source document may, if comparable, contain a number of English words and phrases that are the English side of these desired rules. Because the source data and the bias text are not translations of each other and are not sentence aligned, conventional alignment tools, such as GIZA++ (Och and Ney, 2000), cannot be used to align the source and bias text. Because the passages in the bias text are not translations of the source document, it will always be the case that portions of the source document have no translation in the bias text, and portions of the bias text have no translation in the source document. In addition a phrase in one of these texts might have multiple, differing translations in the other text. Unlike language model adaptation, the entirety of the bias text is not used for translation adaptation. We extract those phrases that occur in at least M of the passages in the bias t</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>F. J. Och and H. Ney. 2000. Improved Statistical Alignment Models. In Proceedings of the 38th Annual Conference of the Association for Computational Linguistics, pages 440–447, Hongkong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Traslation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="25185" citStr="Papineni et al., 2002" startWordPosition="4197" endWordPosition="4201">m, although in practice this is a small expenditure. The most intensive portion is the initial indexing of the monolingual corpus, but this is only required once and can be reused for any subsequent test set that is evaluated. This index can then be quickly searched for comparable passages. When considering research environments, test sets are used repeatedly and bias texts only need to be built once per set, making the building cost negligible. Otherwise, the time required to build the bias text is still small compared to the actual translation time. All conditions were optimized using BLEU (Papineni et al., 2002) and evaluated using both BLEU and Translation Edit Rate (TER) (Snover et al., 2006). BLEU is an accuracy measure, so higher values indicate better performance, while TER is an error metric, so lower values indicate better performance. Optimization was performed on a tuning set of newswire data, comprised of portions of MTEval 2004, MTEval 2005, and GALE 2007 newswire development data, a total of 48921 words of English in 1385 segments and 173 documents. Results were measured on the NIST MTEval 2006 Arabic Evaluation set, which was 55578 words of English in 1797 segments and 104 documents. Fou</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Traslation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="1948" citStr="Rapp, 1999" startWordPosition="286" endWordPosition="287"> to increase the probability of generating texts that resemble the comparable document. Experimental results obtained by adapting both the language and translation models show substantial gains over the baseline system. 1 Introduction While the amount of parallel data available to train a statistical machine translation system is sharply limited, vast amounts of monolingual data are generally available, especially when translating to languages such as English. Yet monolingual data are generally only used to train the language model of the translation system. Previous work (Fung and Yee, 1998; Rapp, 1999) has sought to learn new translations for words by looking at comparable, but not parallel, corpora in multiple languages and analyzing the cooccurrence of words, resulting in the generation of new word-to-word translations. More recently, Resnik and Smith (2003) and Munteanu and Marcu (2005) have exploited monolingual data in both the source and target languages to find document or sentence pairs that appear to be parallel. This newly discovered bilingual data can then be used as additional training data for the translation system. Such methods generally have a very low yield leaving vast amo</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah Smith</author>
</authors>
<title>The Web as a Parallel Corpus. Computational Linguistics,</title>
<date>2003</date>
<pages>29--349</pages>
<contexts>
<context position="2211" citStr="Resnik and Smith (2003)" startWordPosition="324" endWordPosition="327"> of parallel data available to train a statistical machine translation system is sharply limited, vast amounts of monolingual data are generally available, especially when translating to languages such as English. Yet monolingual data are generally only used to train the language model of the translation system. Previous work (Fung and Yee, 1998; Rapp, 1999) has sought to learn new translations for words by looking at comparable, but not parallel, corpora in multiple languages and analyzing the cooccurrence of words, resulting in the generation of new word-to-word translations. More recently, Resnik and Smith (2003) and Munteanu and Marcu (2005) have exploited monolingual data in both the source and target languages to find document or sentence pairs that appear to be parallel. This newly discovered bilingual data can then be used as additional training data for the translation system. Such methods generally have a very low yield leaving vast amounts of data that is only used for language modeling. These methods rely upon comparable corpora, that is, multiple corpora that are of the same general genre. In addition to this, documents can be comparable—two documents that are both on the same event or topic</context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik and Noah Smith. 2003. The Web as a Parallel Corpus. Computational Linguistics, 29:349– 380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="22971" citStr="Shen et al. (2008)" startWordPosition="3826" endWordPosition="3829">t in need of additional translation rules. So, it is under such a condition we would expect the translation model adaptation to be the most beneficial. We evaluate the system’s performance under this condition in section 4.2. The effectiveness of this technique on state-of-the-art systems, and its efficiency when used with a well trained generic translation model is presented in section 4.3. 4.1 Implementation Details Both language-model and translation-model adaptation are implemented on top of a hierarchical Arabic-to-English translation system with string-todependency rules as described in Shen et al. (2008). While generalized rules are generated from the parallel data, rules generated by the translation model adaptation are not generalized and are used only as phrasal rules. A trigram language model was used during decoding, and a 5-gram language model was used to re-score the n-best list after decoding. In addition to the features described in Shen et al. (2008), a new feature is added to the model for the bias rule weight, allowing the translation system to effectively tune the probability of the rules added by translation model adaptation in order to improve performance on the tuning set. Bia</context>
</contexts>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu, and Ralph Weischedel. 2008. A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL), June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="25269" citStr="Snover et al., 2006" startWordPosition="4212" endWordPosition="4215"> initial indexing of the monolingual corpus, but this is only required once and can be reused for any subsequent test set that is evaluated. This index can then be quickly searched for comparable passages. When considering research environments, test sets are used repeatedly and bias texts only need to be built once per set, making the building cost negligible. Otherwise, the time required to build the bias text is still small compared to the actual translation time. All conditions were optimized using BLEU (Papineni et al., 2002) and evaluated using both BLEU and Translation Edit Rate (TER) (Snover et al., 2006). BLEU is an accuracy measure, so higher values indicate better performance, while TER is an error metric, so lower values indicate better performance. Optimization was performed on a tuning set of newswire data, comprised of portions of MTEval 2004, MTEval 2005, and GALE 2007 newswire development data, a total of 48921 words of English in 1385 segments and 173 documents. Results were measured on the NIST MTEval 2006 Arabic Evaluation set, which was 55578 words of English in 1797 segments and 104 documents. Four reference translations were used for scoring each translation. Parameter optimizat</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
</authors>
<title>Using Monolingual SourceLanguage to Improve MT Performance.</title>
<date>2006</date>
<booktitle>In Proceedings of IWSLT</booktitle>
<contexts>
<context position="7249" citStr="Ueffing, 2006" startWordPosition="1163" endWordPosition="1164">n Mumbai on Saturday from the western Indian city Pune where they were shooting the movie for nearly a month.... Figure 2: Excerpt of Example Comparable Document for both automatic speech recognition as well as machine translation. In addition to language model adaptation we also modify the translation model, adding additional translation rules that enable the translation of new words and phrases in both the source and target languages, as well as increasing the probability of existing translation rules. Translation adaptation using the translation system’s own output, known as Self-Training (Ueffing, 2006) has previously shown gains by augmenting the translation model with additional translation rules. In that approach however, the translation model was augmented using parallel data, rather than comparable data, by interpolating a translation model trained using the system output with the original translation model. Translation model adaptation using comparable out-of-domain parallel data, rather than monolingual data was shown by Hildebrand et al. (2005) to yield significant gains over a baseline system. The translation model was adapted by selecting comparable sentences from parallel corpora </context>
</contexts>
<marker>Ueffing, 2006</marker>
<rawString>Nicola Ueffing. 2006. Using Monolingual SourceLanguage to Improve MT Performance. In Proceedings of IWSLT 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>Ralpha Weischedel</author>
<author>Chanh Nguyen</author>
</authors>
<title>Evaluating a Probabilistic Model for Cross-lingual Information Retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of SIGIR 2001 Conference,</booktitle>
<pages>105--110</pages>
<contexts>
<context position="10843" citStr="Xu et al., 2001" startWordPosition="1745" endWordPosition="1748">ion Pr(D is rel|Q). This equation can be expanded using Bayes’ Law as shown in equation 1. The prior probability of a document being relevant can be viewed as uniform, and thus in this work, we assume Pr(D is rel) is a constant.2 2In fact, it can be beneficial to use features of the document The Pr(Q) is constant across all documents. Therefore finding a document to maximize Pr(D is rel|Q) is equivalent to finding a document that maximizes Pr(Q|D is rel). Pr(D is rel) Pr(Q|D is rel) Pr(D is rel|Q) = (1) Pr(Q) A method of calculating the probability of a query given a document was proposed by (Xu et al., 2001)3 and is shown in Equation 2. In this formulation, each foreign word, f, in the query is generated from the foreign vocabulary with probability α and from the English document with probability 1 − α, where α is a constant.4 The probability of f being generated by the general foreign vocabulary, F, is Pr(f|F) = freq(f, F)/|F |, the frequency of the word f in the vocabulary divided by the size of the vocabulary. The probability of the word being generated by the English document is the sum of the probabilities of it being generated by each English word, e, in the document which is the frequency </context>
<context position="12261" citStr="Xu et al. (2001)" startWordPosition="1991" endWordPosition="1994"> 1: Pr(e|D) Pr(f|e)) e This formulation favors longer English documents over shorter English documents. In addition, many documents cover multiple stories and topics. For the purposes of adaptation, shorter, fully comparable documents are preferred to longer, only partially comparable documents. We modify the CLIR system by taking the 1000 highest ranked target language documents found by the CLIR system for each source document, and dividing them into overlapping passages of approximately 300 words.5 Sento estimate Pr(D is rel) (Miller and Schwartz, 1998) but we have not explored that here. 3Xu et al. (2001) formulated this for the selection of foreign documents given an English query. We reverse this to select English documents given a foreign query. 4As in Xu et al. (2001), a value of 0.3 was used for α. 5The length of 300 was chosen as this was approximately the same length as the source documents. 859 tence boundaries are preserved when creating passages, insuring that the text is fluent within each passage. These passages are then scored again by the CLIR system, resulting in a list of passages of about 300 words each for each source document. Finally, we select the top N passages to be used</context>
<context position="13616" citStr="Xu et al. (2001)" startWordPosition="2237" endWordPosition="2240"> topic in the source document. We shall refer to the set of passages selected by the CLIR system as the bias text to differentiate it from comparable text, as the adaptation methods will use this text to bias the MT system so that its output will be more similar to the bias text. While we have not conducted experiments using other CLIR systems, the adaptation methods presented in this paper could be applied without modification using another CLIR system, as the adaptation method treats the CLIR system as a black box. With the exception of running a second pass of CLIR, we use the algorithm of Xu et al. (2001) without any significant modification, including the use of a stop word list for both the English and foreign texts. The parameters for Pr(f|F) and Pr(f|e) were estimated using the same parallel data that our translation system was trained on. The bias text selected for a source document is used to adapt the language model (described in section 3.1) and the translation model (described in section 3.2) when translating that source document. 3 Model Adaptation We use the same bias text to adapt both the language model and the translation model. For language model adaptation, we increase the prob</context>
</contexts>
<marker>Xu, Weischedel, Nguyen, 2001</marker>
<rawString>Jinxi Xu, Ralpha Weischedel, and Chanh Nguyen. 2001. Evaluating a Probabilistic Model for Cross-lingual Information Retrieval. In Proceedings of SIGIR 2001 Conference, pages 105–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Zhao</author>
<author>Matthias Eck</author>
<author>Stephan Vogel</author>
</authors>
<title>Language Model Adaptation for Statistical Machine Translation via Structured Query Models.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>411--417</pages>
<publisher>COLING.</publisher>
<location>Geneva, Switzerland,</location>
<contexts>
<context position="5600" citStr="Zhao et al. (2004)" startWordPosition="890" endWordPosition="893">s and words are shared between the two, including: the name of the movie, the name and relationship of the actress’ character, the name and age of her son and many others. Such a pairing is extremely comparable, although even less related document pairs could easily be considered comparable. We seek to take advantage of these comparable documents to inform the translation of the source document. This can be done by augmenting the major components of the statistical translation system: the Language Model and the Translation Model. This work is in the same tradition as Kim and Khudanpur (2003), Zhao et al. (2004), and Kim (2005). Kim (2005) used large amounts of comparable data to adapt language models on a documentby-document basis, while Zhao et al. (2004) used comparable data to perform sentence level adaptation of the language model. These adapted language models were shown to improve performance 1This is an actual source document from the tuning set used in our experiments, and the first of a number of similar passages found by the comparable text selection system described in section 2. Actress Angelina Jolie hopped onto a crowded Mumbai commuter train Monday to film a scene for a movie about sl</context>
</contexts>
<marker>Zhao, Eck, Vogel, 2004</marker>
<rawString>Bing Zhao, Matthias Eck, and Stephan Vogel. 2004. Language Model Adaptation for Statistical Machine Translation via Structured Query Models. In Proceedings of Coling 2004, pages 411–417, Geneva, Switzerland, Aug 23–Aug 27. COLING.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>