<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002686">
<title confidence="0.997568">
Semantic Class Learning from the Web with Hyponym Pattern Linkage
Graphs
</title>
<author confidence="0.996811">
Zornitsa Kozareva
</author>
<affiliation confidence="0.998813">
DLSI, University of Alicante
</affiliation>
<address confidence="0.8273435">
Campus de San Vicente
Alicante, Spain 03080
</address>
<email confidence="0.996533">
zkozareva@dlsi.ua.es
</email>
<author confidence="0.996038">
Ellen Riloff
</author>
<affiliation confidence="0.909211">
School of Computing
University of Utah
Salt Lake City, UT 84112
</affiliation>
<email confidence="0.997386">
riloff@cs.utah.edu
</email>
<author confidence="0.929935">
Eduard Hovy
</author>
<affiliation confidence="0.894508">
USC Information Sciences Institute
</affiliation>
<address confidence="0.8534335">
4676 Admiralty Way
Marina del Rey, CA 90292-6695
</address>
<email confidence="0.999362">
hovy@isi.edu
</email>
<sectionHeader confidence="0.99565" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99992155">
We present a novel approach to weakly super-
vised semantic class learning from the web,
using a single powerful hyponym pattern com-
bined with graph structures, which capture
two properties associated with pattern-based
extractions: popularity and productivity. In-
tuitively, a candidate is popular if it was dis-
covered many times by other instances in the
hyponym pattern. A candidate is productive
if it frequently leads to the discovery of other
instances. Together, these two measures cap-
ture not only frequency of occurrence, but also
cross-checking that the candidate occurs both
near the class name and near other class mem-
bers. We developed two algorithms that begin
with just a class name and one seed instance
and then automatically generate a ranked list
of new class instances. We conducted exper-
iments on four semantic classes and consis-
tently achieved high accuracies.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999176">
Knowing the semantic classes of words (e.g., “trout”
is a kind of FISH) can be extremely valuable for
many natural language processing tasks. Although
some semantic dictionaries do exist (e.g., Word-
Net (Miller, 1990)), they are rarely complete, espe-
cially for large open classes (e.g., classes of people
and objects) and rapidly changing categories (e.g.,
computer technology). (Roark and Charniak, 1998)
reported that 3 of every 5 terms generated by their
semantic lexicon learner were not present in Word-
Net. Automatic semantic lexicon acquisition could
be used to enhance existing resources such as Word-
Net, or to produce semantic lexicons for specialized
categories or domains.
A variety of methods have been developed for
automatic semantic class identification, under the
rubrics of lexical acquisition, hyponym acquisition,
semantic lexicon induction, semantic class learn-
ing, and web-based information extraction. Many
of these approaches employ surface-level patterns to
identify words and their associated semantic classes.
However, such patterns tend to overgenerate (i.e.,
deliver incorrect results) and hence require addi-
tional filtering mechanisms.
To overcome this problem, we employed one sin-
gle powerful doubly-anchored hyponym pattern to
query the web and extract semantic class instances:
CLASS NAME such as CLASS MEMBER and *.
We hypothesized that a doubly-anchored pattern,
which includes both the class name and a class
member, would achieve high accuracy because of
its specificity. To address concerns about coverage,
we embedded the search in a bootstrapping process.
This method produced many correct instances, but
despite the highly restrictive nature of the pattern,
still produced many incorrect instances. This re-
sult led us to explore new ways to improve the ac-
curacy of hyponym patterns without requiring addi-
tional training resources.
The main contribution of this work is a novel
method for combining hyponym patterns with graph
structures that capture two properties associated
with pattern extraction: popularity and productivity.
Intuitively, a candidate word (or phrase) is popular
if it was discovered many times by other words (or
</bodyText>
<page confidence="0.948162">
1048
</page>
<note confidence="0.714724">
Proceedings of ACL-08: HLT, pages 1048–1056,
</note>
<page confidence="0.537905">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999919826086957">
phrases) in a hyponym pattern. A candidate word is
productive if it frequently leads to the discovery of
other words. Together, these two measures capture
not only frequency of occurrence, but also cross-
checking that the word occurs both near the class
name and near other class members.
We present two algorithms that use hyponym pat-
tern linkage graphs (HPLGs) to represent popularity
and productivity information. The first method uses
a dynamically constructed HPLG to assess the pop-
ularity of each candidate and steer the bootstrapping
process. This approach produces an efficient boot-
strapping process that performs reasonably well, but
it cannot take advantage of productivity information
because of the dynamic nature of the process.
The second method is a two-step procedure that
begins with an exhaustive pattern search that ac-
quires popularity and productivity information about
candidate instances. The candidates are then ranked
based on properties of the HPLG. We conducted ex-
periments with four semantic classes, achieving high
accuracies and outperforming the results reported by
others who have worked on the same classes.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.992688582089553">
A substantial amount of research has been done in
the area of semantic class learning, under a variety
of different names and with a variety of different
goals. Given the great deal of similar work in infor-
mation extraction and ontology learning, we focus
here only on techniques for weakly supervised or
unsupervised semantic class (i.e., supertype-based)
learning, since that is most related to the work in
this paper.
Fully unsupervised semantic clustering (e.g.,
(Lin, 1998; Lin and Pantel, 2002; Davidov and Rap-
poport, 2006)) has the disadvantage that it may or
may not produce the types and granularities of se-
mantic classes desired by a user. Another related
line of work is automated ontology construction,
which aims to create lexical hierarchies based on se-
mantic classes (e.g., (Caraballo, 1999; Cimiano and
Volker, 2005; Mann, 2002)), and learning semantic
relations such as meronymy (Berland and Charniak,
1999; Girju et al., 2003).
Our research focuses on semantic lexicon induc-
tion, which aims to generate lists of words that be-
long to a given semantic class (e.g., lists of FISH
or VEHICLE words). Weakly supervised learning
methods for semantic lexicon generation have uti-
lized co-occurrence statistics (Riloff and Shepherd,
1997; Roark and Charniak, 1998), syntactic in-
formation (Tanev and Magnini, 2006; Pantel and
Ravichandran, 2004; Phillips and Riloff, 2002),
lexico-syntactic contextual patterns (e.g., “resides
in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff
and Jones, 1999; Thelen and Riloff, 2002), and
local and global contexts (Fleischman and Hovy,
2002). These methods have been evaluated only on
fixed corpora1, although (Pantel et al., 2004) demon-
strated how to scale up their algorithms for the web.
Several techniques for semantic class induction
have also been developed specifically for learning
from the web. (Pas¸ca, 2004) uses Hearst’s pat-
terns (Hearst, 1992) to learn semantic class instances
and class groups by acquiring contexts around the
pattern. Pasca also developed a second technique
(Pas¸ca, 2007b) that creates context vectors for a
group of seed instances by searching web query
logs, and uses them to learn similar instances.
The work most closely related to ours is Hearst’s
early work on hyponym learning (Hearst, 1992)
and more recent work that has followed up on her
idea. Hearst’s system exploited patterns that explic-
itly identify a hyponym relation between a seman-
tic class and a word (e.g., “such authors as Shake-
speare”). We will refer to these as hyponym pat-
terns. Pasca’s previously mentioned system (Pas¸ca,
2004) applies hyponym patterns to the web and ac-
quires contexts around them. The KnowItAll system
(Etzioni et al., 2005) also uses hyponym patterns to
extract class instances from the web and then evalu-
ates them further by computing mutual information
scores based on web queries.
The work by (Widdows and Dorow, 2002) on lex-
ical acquisition is similar to ours because they also
use graph structures to learn semantic classes. How-
ever, their graph is based entirely on syntactic rela-
tions between words, while our graph captures the
ability of instances to find each other in a hyponym
pattern based on web querying, without any part-of-
speech tagging or parsing.
</bodyText>
<footnote confidence="0.874344333333333">
1Meta-bootstrapping (Riloff and Jones, 1999) was evaluated
on web pages, but used a precompiled corpus of downloaded
web pages.
</footnote>
<page confidence="0.997932">
1049
</page>
<sectionHeader confidence="0.9090705" genericHeader="method">
3 Semantic Class Learning with Hyponym
Pattern Linkage Graphs
</sectionHeader>
<subsectionHeader confidence="0.999896">
3.1 A Doubly-Anchored Hyponym Pattern
</subsectionHeader>
<bodyText confidence="0.999246046511628">
Our work was motivated by early research on hy-
ponym learning (Hearst, 1992), which applied pat-
terns to a corpus to associate words with semantic
classes. Hearst’s system exploited patterns that ex-
plicitly link a class name with a class member, such
as “X and other Ys” and “Ys such as X”. Relying
on surface-level patterns, however, is risky because
incorrect items are frequently extracted due to poly-
semy, idiomatic expressions, parsing errors, etc.
Our work began with the simple idea of using an
extremely specific pattern to extract semantic class
members with high accuracy. Our expectation was
that a very specific pattern would virtually eliminate
the most common types of false hits that are caused
by phenomena such as polysemy and idiomatic ex-
pressions. A concern, however, was that an ex-
tremely specific pattern would suffer from sparse
data and not extract many new instances. By using
the web as a corpus, we hoped that the pattern could
extract at least a few instances for virtually any class,
and then we could gain additional traction by boot-
strapping these instances.
All of the work presented in this paper uses just
one doubly-anchored pattern to identify candidate
instances for a semantic class:
&lt;class name&gt; such as &lt;class member&gt; and *
This pattern has two variables: the name of the se-
mantic class to be learned (class name) and a mem-
ber of the semantic class (class member). The aster-
isk (*) indicates the location of the extracted words.
We describe this pattern as being doubly-anchored
because it is instantiated with both the name of the
semantic class as well as a class member.
For example, the pattern “CARS such as FORD
and *” will extract automobiles, and the pattern
“PRESIDENTS such as FORD and *” will extract
presidents. The doubly-anchored nature of the pat-
tern serves two purposes. First, it increases the like-
lihood of finding a true list construction for the class.
Our system does not use part-of-speech tagging or
parsing, so the pattern itself is the only guide for
finding an appropriate linguistic context.
Second, the doubly-anchored pattern virtually
</bodyText>
<equation confidence="0.9979173125">
Members = {Seed};
Po= “Class such as Seed and *”;
P = {Po};
iter = 0;
While ((iter &lt; Max Iters) and (P # {}))
iter++;
For each Pi ∈ P
Snippets = web query(Pi);
Candidates = extract words(Snippets,Pi);
Pnew = {};
For each Candidatek ∈ Candidates
If (Candidatek ∈� Members);
Members = Members ∪ {Candidatek};
Pk= “Class such as Candidatek and *”;
Pnew = Pnew ∪ { Pk };
P = Pnew;
</equation>
<figureCaption confidence="0.998896">
Figure 1: Reckless Bootstrapping
</figureCaption>
<bodyText confidence="0.999891956521739">
eliminates ambiguity because the class name and
class member mutually disambiguate each other.
For example, the word FORD could refer to an auto-
mobile or a person, but in the pattern “CARS such as
FORD and *” it will almost certainly refer to an au-
tomobile. Similarly, the class “PRESIDENT” could
refer to country presidents or corporate presidents,
and “BUSH” could refer to a plant or a person. But
in the pattern “PRESIDENTS such as BUSH”, both
words will surely refer to country presidents.
Another advantage of the doubly-anchored pat-
tern is that an ambiguous or underspecified class
name will be constrained by the presence of the class
member. For example, to generate a list of com-
pany presidents, someone might naively define the
class name as PRESIDENTS. A singly-anchored pat-
tern (e.g., “PRESIDENTS such as *”) might gener-
ate lists of other types of presidents (e.g., country
presidents, university presidents, etc.). Because the
doubly-anchored pattern also requires a class mem-
ber (e.g., “PRESIDENTS such as BILL GATES and
*”), it is likely to generate only the desired types of
instances.
</bodyText>
<subsectionHeader confidence="0.999754">
3.2 Reckless Bootstrapping
</subsectionHeader>
<bodyText confidence="0.9999756">
To evaluate the performance of the doubly-anchored
pattern, we began by using the pattern to search the
web and embedded this process in a simple boot-
strapping loop, which is presented in Figure 1. As
input, the user must provide the name of the desired
</bodyText>
<page confidence="0.962458">
1050
</page>
<bodyText confidence="0.9988125">
semantic class (Class) and a seed example (Seed),
which are used to instantiate the pattern. On the
first iteration, the pattern is given to Google as a
web query, and new class members are extracted
from the retrieved text snippets. We wanted the
system to be as language-independent as possible,
so we refrained from using any taggers or parsing
tools. As a result, instances are extracted using only
word boundaries and orthographic information. For
proper name classes, we extract all capitalized words
that immediately follow the pattern. For common
noun classes, we extract just one word, if it is not
capitalized. Examples are shown below, with the ex-
tracted items underlined:
countries such as China and Sri Lanka are ...
fishes such as trout and bass can ...
One limitation is that our system cannot learn
multi-word instances of common noun categories,
or proper names that include uncapitalized words
(e.g., “United States of America”). These limita-
tions could be easily overcome by incorporating a
noun phrase (NP) chunker and extracting NPs.
Each new class member is then used as a seed in-
stance in the bootstrapping loop. We implemented
this process as breadth-first search, where each “ply”
of the search process is the result of bootstrapping
the class members learned during the previous it-
eration as seed instances for the next one. During
each iteration, we issue a new web query and add
the newly extracted class members to the queue for
the next cycle. We run this bootstrapping process for
a fixed number of iterations (search ply), or until no
new class members are produced. We will refer to
this process as reckless bootstrapping because there
are no checks of any kind. Every term extracted by
the pattern is assumed to be a class member.
</bodyText>
<sectionHeader confidence="0.883518" genericHeader="evaluation">
3.2.1 Results
</sectionHeader>
<bodyText confidence="0.996843714285714">
Table 1 shows the results for 4 iterations of reck-
less bootstrapping for four semantic categories: U.S.
states, countries, singers, and fish. The first two
categories are relatively small, closed sets (our gold
standard contains 50 U.S. states and 194 countries).
The singers andfish categories are much larger, open
sets (see Section 4 for details).
</bodyText>
<tableCaption confidence="0.6969955">
Table 1 reveals that the doubly-anchored pattern
achieves high accuracy during the first iteration, but
</tableCaption>
<table confidence="0.9890824">
Iter. countries states singers fish
1 .80 .79 .91 .76
2 .57 .21 .87 .64
3 .21 .18 .86 .54
4 .16 – .83 .54
</table>
<tableCaption confidence="0.999419">
Table 1: Reckless Bootstrapping Accuracies
</tableCaption>
<bodyText confidence="0.999769555555556">
quality deteriorates rapidly as bootstrapping pro-
gresses. Figure 2 shows the recall and precision
curves for countries and states. High precision is
achieved only with low levels of recall for countries.
Our initial hypothesis was that such a specific pat-
tern would be able to maintain high precision be-
cause non-class members would be unlikely to co-
occur with the pattern. But we were surprised to find
that many incorrect entries were generated for rea-
sons such as broken expressions like “Merce -dez”,
misidentified list constructions (e.g., “In countries
such as China U.S. Policy is failing...”), and incom-
plete proper names due to insufficient length of the
retrieved text snippet.
Incorporating a noun phrase chunker would elim-
inate some of these cases, but far from all of them.
We concluded that even such a restrictive pattern is
not sufficient for semantic class learning on its own.
</bodyText>
<figure confidence="0.627499">
Country/State
</figure>
<figureCaption confidence="0.996409">
Figure 2: Recall/precision for reckless bootstrapping
</figureCaption>
<bodyText confidence="0.999811333333333">
In the next section, we present a new approach
that creates a Hyponym Pattern Linkage Graph to
steer bootstrapping and improve accuracy.
</bodyText>
<subsectionHeader confidence="0.983932">
3.3 Using Dynamic Graphs to Steer
Bootstrapping
</subsectionHeader>
<bodyText confidence="0.9991065">
Intuitively, we expect true class members to occur
frequently in pattern contexts with other class mem-
</bodyText>
<figure confidence="0.997686625">
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Recall
Precision
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
Country
State
</figure>
<page confidence="0.980851">
1051
</page>
<bodyText confidence="0.994667020833333">
bers. To operationalize this intuition, we create a hy-
ponym pattern linkage graph, which represents the
frequencies with which candidate instances generate
each other in the pattern contexts.
We define a hyponym pattern linkage graph
(HPLG) as a G = (V, E), where each vertex v ∈ V
is a candidate instance and each edge (u, v) ∈ E
means that instance v was generated by instance u.
The weight w of an edge is the frequency with which
u generated v. For example, consider the following
sentence, where the pattern is italicized and the ex-
tracted instance is underlined:
Countries such as China and Laos have been...
In the HPLG, an edge e = (China, Laos) would
be created because the pattern anchored by China
extracted Laos as a new candidate instance. If this
pattern extracted Laos from 15 different snippets,
then the edge’s weight would be 15. The in-degree
of a node represents its popularity, i.e., the number
of instance occurrences that generated it.
The graph is constructed dynamically as boot-
strapping progresses. Initially, the seed is the only
trusted class member and the only vertex in the
graph. The bootstrapping process begins by instan-
tiating the doubly-anchored pattern with the seed
class member, issuing a web query to generate new
candidate instances, and adding these new instances
to the graph. A score is then assigned to every node
in the graph, using one of several different metrics
defined below. The highest-scoring unexplored node
is then added to the set of trusted class members, and
used as the seed for the next bootstrapping iteration.
We experimented with three scoring functions for
selecting nodes. The In-Degree (inD) score for ver-
tex v is the sum of the weights of all incoming edges
(u, v), where u is a trusted class member. Intuitively,
this captures the popularity of v among instances
that have already been identified as good instances.
The Best Edge (BE) score for vertex v is the maxi-
mum edge weight among the incoming edges (u, v),
where u is a trusted class member.
The Key Player Problem (KPP) measure is used in
social network analysis (Borgatti and Everett, 2006)
to identify nodes whose removal would result in a
residual network of minimum cohesion. A node re-
ceives a high value if it is highly connected and rel-
atively close to most other nodes in the graph. The
KPP score for vertex v is computed as:
</bodyText>
<equation confidence="0.992592">
KPP(v) =
</equation>
<bodyText confidence="0.9999251">
where d(u, v) is the shortest path between two ver-
tices, where u is a trusted node. For tie-breaking, the
distances are multiplied by the weight of the edge.
Note that all of these measures rely only on in-
coming edges because a node does not acquire out-
going edges until it has already been selected as a
trusted class member and used to acquire new in-
stances. In the next section, we describe a two-step
process for creating graphs that can take advantage
of both incoming and outgoing edges.
</bodyText>
<subsectionHeader confidence="0.99688">
3.4 Re-Ranking with Precompiled Graphs
</subsectionHeader>
<bodyText confidence="0.99998864516129">
One way to try to confirm (or disconfirm) whether
a candidate instance is a true class member is to see
whether it can produce new candidate instances. If
we instantiate our pattern with the candidate (i.e.,
“CLASS NAME such as CANDIDATE and *”) and
successfully extract many new instances, then this
is evidence that the candidate frequently occurs with
the CLASS NAME in list constructions. We will re-
fer to the ability of a candidate to generate new in-
stances as its productivity.
The previous bootstrapping algorithm uses a dy-
namically constructed graph that is constantly evolv-
ing as new nodes are selected and explored. Each
node is scored based only on the set of instances
that have been generated and identified as “trusted”
at that point in the bootstrapping process. To use
productivity information, we must adopt a different
procedure because we need to know not only who
generated each candidate, but also the complete set
of instances that the candidate itself can generate.
We adopted a two-step process that can use both
popularity and productivity information in a hy-
ponym pattern linkage graph to assess the quality of
candidate instances. First, we perform reckless boot-
strapping for a class name and seed until no new
instances are generated. Second, we assign a score
to each node in the graph using a scoring function
that takes into account both the in-degree (popular-
ity) and out-degree (productivity) of each node. We
experimented with four different scoring functions,
some of which were motivated by work on word
</bodyText>
<equation confidence="0.6820052">
1
E
UEV
d(u, v)
|V |−1
</equation>
<page confidence="0.972133">
1052
</page>
<bodyText confidence="0.999574166666667">
sense disambiguation to identify the most “impor-
tant” node in a graph containing its possible senses
(Navigli and Lapata, 2007).
The Out-degree (outD) score for vertex v is the
weighted sum of v’s outgoing edges, normalized by
the number of other nodes in the graph.
</bodyText>
<equation confidence="0.993544">
outD(v) =
</equation>
<bodyText confidence="0.999314222222222">
This measure captures only productivity, while the
next three measures consider both productivity and
popularity. The Total-degree (totD) score for ver-
tex v is the weighted sum of both incoming and
outgoing edges, normalized by the number of other
nodes in the graph. The Betweenness (BT) score
(Freeman, 1979) considers a vertex to be important
if it occurs on many shortest paths between other
vertices.
</bodyText>
<equation confidence="0.967329666666667">
�
BT(v) =
s,t∈V s6�v6�t
</equation>
<bodyText confidence="0.999983285714286">
where Qst is the number of shortest paths from s to t,
and Qst(v) is the number of shortest paths from s to
t that pass through vertex v. PageRank (Page et al.,
1998) establishes the relative importance of a ver-
tex v through an iterative Markov chain model. The
PageRank (PR) score of a vertex v is determined
on the basis of the nodes it is connected to.
</bodyText>
<equation confidence="0.930707666666667">
�
PR(v) = (1−�) |V |+ a
u,v∈E
</equation>
<bodyText confidence="0.963752">
a is a damping factor that we set to 0.85. We dis-
carded all instances that produced zero productivity
links, meaning that they did not generate any other
candidates when used in web queries.
</bodyText>
<sectionHeader confidence="0.994802" genericHeader="evaluation">
4 Experimental evaluation
</sectionHeader>
<subsectionHeader confidence="0.953986">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.996853666666667">
We evaluated our algorithms on four semantic cat-
egories: U.S. states, countries, singers, and fish.
The states and countries categories are relatively
small, closed sets: our gold standards consist of 50
U.S. states and 194 countries (based on a list found
on Wikipedia). The singers and fish categories are
much larger, open classes. As our gold standard for
fish, we used a list of common fish names found on
Wikipedia.2 All the singer names generated by our
</bodyText>
<footnote confidence="0.9606115">
2We also counted as correct plural versions of items found
on the list. The total size of our fish list is 1102.
</footnote>
<table confidence="0.999724705882353">
States
Popularity Prd Pop&amp;Prd
N BE KPP inD outD totD BT PR
25 1.0 1.0 1.0 1.0 1.0 .88 .88
50 .96 .98 .98 1.0 1.0 .86 .82
64 .77 .78 .77 .78 .78 .77 .67
Countries
Popularity Prd Pop&amp;Prd
N BE KPP inD outD totD BT PR
50 .98 .97 .98 1.0 1.0 .98 .97
100 .96 .97 .94 1.0 .99 .97 .95
150 .90 .92 .91 1.0 .95 .94 .92
200 .83 .81 .83 .90 .87 .82 .80
300 .60 .59 .61 .61 .62 .56 .60
323 .57 .55 .57 .57 .58 .52 .57
Singers
Popularity Prd Pop&amp;Prd
N BE KPP inD outD totD BT PR
10 .92 .96 .92 1.0 1.0 1.0 1.0
25 .89 .90 .91 1.0 1.0 1.0 .99
50 .92 .85 .92 .97 .98 .95 .97
75 .89 .83 .91 .96 .95 .93 .95
100 .86 .81 .89 .96 .93 .94 .94
150 .86 .79 .88 .95 .92 .93 .87
180 .86 .80 .87 .91 .91 .91 .88
Fish
Popularity Prd Pop&amp;Prd
N BE KPP inD outD totD BT PR
10 .90 .90 .90 1.0 1.0 .90 .70
25 .80 .88 .76 1.0 .96 .96 .72
50 .82 .80 .78 1.0 .94 .88 .66
75 .72 .69 .72 .93 .87 .79 .64
100 .63 .68 .66 .84 .80 .74 .62
116 .60 .65 .66 .80 .78 .71 .59
</table>
<tableCaption confidence="0.98916">
Table 2: Accuracies for each semantic class
</tableCaption>
<bodyText confidence="0.999578666666667">
algorithms were manually reviewed for correctness.
We evaluated performance in terms of accuracy (the
percentage of instances that were correct).3
</bodyText>
<subsectionHeader confidence="0.987308">
4.2 Performance
</subsectionHeader>
<bodyText confidence="0.9987076">
Table 2 shows the accuracy results of the two al-
gorithms that use hyponym pattern linkage graphs.
We display results for the top-ranked N candidates,
for all instances that have a productivity value &gt;
zero.4 The Popularity columns show results for the
</bodyText>
<footnote confidence="0.93609275">
3We never generated duplicates so the instances are distinct.
4Obviously, this cutoff is not available to the popularity-
based bootstrapping algorithm, but here we are just comparing
the top N results for both algorithms.
</footnote>
<equation confidence="0.895213142857143">
E w(v, p)
∀(v,p)∈E
|V |−1
Qst(v)
Qst
PR(u)
outdegree(u)
</equation>
<page confidence="0.8893">
1053
</page>
<bodyText confidence="0.999982177777778">
bootstrapping algorithm described in Section 3.3,
using three different scoring functions. The re-
sults for the ranking algorithm described in Sec-
tion 3.4 are shown in the Productivity (Prd) and
Popularity&amp;Productivity (Pop&amp;Prd) columns. For
the states, countries, and singers categories, we ran-
domly selected 5 different initial seeds and then av-
eraged the results. For the fish category we ran each
algorithm using just the seed “salmon”.
The popularity-based metrics produced good ac-
curacies on the states, countries, and singers cate-
gories under all 3 scoring functions. For fish, KPP
performed better than the others.
The Out-degree (outD) scoring function, which
uses only Productivity information, obtained the
best results across all 4 categories. OutD achieved
100% accuracy for the first 50 states and fish, 100%
accuracy for the top 150 countries, and 97% accu-
racy for the top 50 singers. The three scoring met-
rics that use both popularity and productivity also
performed well, but productivity information by it-
self seems to perform better in some cases.
It can be difficult to compare the results of differ-
ent semantic class learners because there is no stan-
dard set of benchmark categories, so researchers re-
port results for different classes. For the state and
country categories, however, we can compare our
results with that of other web-based semantic class
learners such as Pasca (Pas¸ca, 2007a) and the Know-
ItAll system (Etzioni et al., 2005). For the U.S.
states category, our system achieved 100% recall
and 100% precision for the first 50 items generated,
and KnowItAll performed similarly achieving 98%
recall with 100% precision. Pasca did not evaluate
his system on states.
For the countries category, our system achieved
100% precision for the first 150 generated instances
(77% recall). (Pas¸ca, 2007a) reports results of 100%
precision for the first 25 instances generated, and
82% precision for the first 150 instances gener-
ated. The KnowItAll system (Etzioni et al., 2005)
achieved 97% precision with 58% recall, and 79%
precision with 87% recall.5 To the best of our
knowledge, other researchers have not reported re-
sults for the singer and fish categories.
</bodyText>
<footnote confidence="0.901936">
5(Etzioni et al., 2005) do not report exactly how many coun-
tries were in their gold standard.
</footnote>
<figure confidence="0.9610005">
0 50 100 150 200 250 300 350 400
Iterations
</figure>
<figureCaption confidence="0.999871">
Figure 3: Learning curve for Placido Domingo
</figureCaption>
<bodyText confidence="0.998757714285714">
Figure 3 shows the learning curve for both al-
gorithms using their best scoring functions on the
singer category with Placido Domingo as the initial
seed. In total, 400 candidate words were generated.
The Out-degree scoring function ranked the candi-
dates well. Figure 3 also includes a vertical line
indicating where the candidate list was cut (at 180
instances) based on the zero productivity cutoff.
One observation is that the rankings do a good
job of identifying borderline cases, which typically
are ranked just below most correct instances but just
above the obviously bad entries. For example, for
states, the 50 U.S. states are ranked first, followed
by 14 more entries (in order):
</bodyText>
<affiliation confidence="0.963131">
Russia, Ukraine, Uzbekistan, Azerbaijan,
Moldova, Tajikistan, Armenia, Chicago,
Boston, Atlanta, Detroit, Philadelphia, Tampa,
</affiliation>
<subsectionHeader confidence="0.686531">
Moldavia
</subsectionHeader>
<bodyText confidence="0.999817571428572">
The first 7 entries are all former states of the So-
viet Union. In retrospect, we realized that we
should have searched for “U.S. states” instead ofjust
“states”. This example illustrates the power of the
doubly-anchored hyponym pattern to correctly iden-
tify our intended semantic class by disambiguating
our class name based on the seed class member.
The algorithms also seem to be robust with re-
spect to initial seed choice. For the states, coun-
tries, and singers categories, we ran experiments
with 5 different initial seeds, which were randomly
selected. The 5 country seeds represented a diverse
set of nations, some of which are rarely mentioned in
the news: Brazil, France, Guinea-Bissau, Uganda,
</bodyText>
<figure confidence="0.998565733333333">
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
outD
inD
cutoff, t
Accuracy
</figure>
<page confidence="0.988248">
1054
</page>
<bodyText confidence="0.9609275">
and Zimbabwe. All of these seeds obtained &gt; 92%
recall with &gt; 90% precision.
</bodyText>
<subsectionHeader confidence="0.974183">
4.3 Error Analysis
</subsectionHeader>
<bodyText confidence="0.999968435897436">
We examined the incorrect instances produced by
our algorithms and found that most of them fell into
five categories.
Type 1 errors were caused by incorrect proper
name extraction. For example, in the sentence
“states such as Georgia and English speaking coun-
tries like Canada...”, “English” was extracted as
a state. These errors resulted from complex noun
phrases and conjunctions, as well as unusual syn-
tactic constructions. An NP chunker might prevent
some of these cases, but we suspect that many of
them would have been misparsed regardless.
Type 2 errors were caused by instances that for-
merly belonged to the semantic class (e.g., Serbia-
Montenegro and Czechoslovakia are no longer coun-
tries). In this error type, we also include border-
line cases that could arguably belong to the semantic
class (e.g., Wales as a country).
Type 3 errors were spelling variants (e.g., Kyrgys-
tan vs. Kyrgyzhstan) and name variants (e.g., Bey-
once vs. Beyonce Knowles). Officially, every entity
has one official spelling and one complete name, but
in practice there are often variations that may occur
nearly as frequently as the official name. For exam-
ple, it is most common to refer to the singer Beyonce
by just her first name.
Type 4 errors were caused by sentences that were
just flat out wrong in their factual assertions. For ex-
ample, some sentences referred to “North America”
as a country.
Type 5 errors were caused by broken expressions
found in the retrieved snippets (e.g. Michi -gan).
These errors may be fixable by cleaning up the web
pages or applying heuristics to prevent or recognize
partial words.
It is worth noting that incorrect instances of Types
2 and 3 may not be problematic to encounter in a
dictionary or ontology. Name variants and former
class members may in fact be useful to have.
</bodyText>
<sectionHeader confidence="0.999715" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999977690476191">
Combining hyponym patterns with pattern linkage
graphs is an effective way to produce a highly ac-
curate semantic class learner that requires truly min-
imal supervision: just the class name and one class
member as a seed. Our results consistently produced
high accuracy and for the states and countries cate-
gories produced very high recall.
The singers and fish categories, which are much
larger open classes, also achieved high accuracy and
generated many instances, but the resulting lists are
far from complete. Even on the web, the doubly-
anchored hyponym pattern eventually ran out of
steam and could not produce more instances. How-
ever, all of our experiments were conducted using
just a single hyponym pattern. Other researchers
have successfully used sets of hyponym patterns
(e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca,
2004)), and multiple patterns could be used with
our algorithms as well. Incorporating additional hy-
ponym patterns will almost certainly improve cover-
age, and could potentially improve the quality of the
graphs as well.
Our popularity-based algorithm was very effec-
tive and is practical to use. Our best-performing al-
gorithm, however, was the 2-step process that be-
gins with an exhaustive search (reckless bootstrap-
ping) and then ranks the candidates using the Out-
degree scoring function, which represents produc-
tivity. The first step is expensive, however, because
it exhaustively applies the pattern to the web until
no more extractions are found. In our evaluation, we
ran this process on a single PC and it usually finished
overnight, and we were able to learn a substantial
number of new class instances. If more hyponym
patterns are used, then this could get considerably
more expensive, but the process could be easily par-
allelized to perform queries across a cluster of ma-
chines. With access to a cluster of ordinary PCs,
this technique could be used to automatically create
extremely large, high-quality semantic lexicons, for
virtually any categories, without external training re-
sources.
</bodyText>
<sectionHeader confidence="0.998282" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.959394333333333">
This research was supported in part by the Department
of Homeland Security under ONR Grants N00014-07-1-014
and N0014-07-1-0152, the European Union Sixth Framework
project QALLME FP6 IST-033860, and the Spanish Ministry
of Science and Technology TEXT-MESS TIN2006-15265-C06-
01.
</bodyText>
<page confidence="0.990328">
1055
</page>
<sectionHeader confidence="0.995869" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999930923809524">
M. Berland and E. Charniak. 1999. Finding Parts in Very
Large Corpora. In Proc. of the 37th Annual Meeting of
the Association for Computational Linguistics.
S. Borgatti and M. Everett. 2006. A graph-theoretic per-
spective on centrality. Social Networks, 28(4).
S. Caraballo. 1999. Automatic Acquisition of a
Hypernym-Labeled Noun Hierarchy from Text. In
Proc. of the 37th Annual Meeting of the Association
for Computational Linguistics, pages 120–126.
P. Cimiano and J. Volker. 2005. Towards large-scale,
open-domain and ontology-based named entity classi-
fication. In Proc. of Recent Advances in Natural Lan-
guage Processing, pages 166–172.
D. Davidov and A. Rappoport. 2006. Efficient unsu-
pervised discovery of word categories using symmet-
ric patterns and high frequency words. In Proc. of the
21st International Conference on Computational Lin-
guistics and the 44th annual meeting of the ACL.
O. Etzioni, M. Cafarella, D. Downey, A. Popescu,
T. Shaked, S. Soderland, D. Weld, and A. Yates.
2005. Unsupervised named-entity extraction from the
web: an experimental study. Artificial Intelligence,
165(1):91–134, June.
M.B. Fleischman and E.H. Hovy. 2002. Fine grained
classification of named entities. In Proc. of the 19th
International Conference on Computational Linguis-
tics, pages 1–7.
C. Freeman. 1979. Centrality in social networks: Con-
ceptual clarification. Social Networks, 1:215–239.
R. Girju, A. Badulescu, and D. Moldovan. 2003. Learn-
ing semantic constraints for the automatic discovery of
part-whole relations. In Proc. of Conference of HLT /
North American Chapter of the Association for Com-
putational Linguistics.
M. Hearst. 1992. Automatic acquisition of hyponyms
from large text corpora. In Proc. of the 14th confer-
ence on Computational linguistics, pages 539–545.
D. Lin and P. Pantel. 2002. Concept discovery from text.
In Proc. of the 19th International Conference on Com-
putational linguistics, pages 1–7.
D. Lin. 1998. Automatic retrieval and clustering of sim-
ilar words. In Proc. of the 17th international confer-
ence on Computational linguistics, pages 768–774.
G. Mann. 2002. Fine-grained proper noun ontologies for
question answering. In Proc. of the 19th International
Conference on Computational Linguistics, pages 1–7.
G. Miller. 1990. Wordnet: An On-line Lexical Database.
International Journal ofLexicography, 3(4).
R. Navigli and M. Lapata. 2007. Graph connectiv-
ity measures for unsupervised word sense disambigua-
tion. In Proc. of the 20th International Joint Confer-
ence on Artificial Intelligence, pages 1683–1688.
M. Pas¸ca. 2004. Acquisition of categorized named en-
tities for web search. In Proc. of the Thirteenth ACM
International Conference on Information and Knowl-
edge Management, pages 137–145.
M. Pas¸ca. 2007a. Organizing and searching the world
wide web of facts – step two: harnessing the wisdom
of the crowds. In Proc. of the 16th International Con-
ference on World Wide Web, pages 101–110.
M. Pas¸ca. 2007b. Weakly-supervised discovery of
named entities using web search queries. In Proc. of
the sixteenth ACM conference on Conference on infor-
mation and knowledge management, pages 683–690.
L. Page, S. Brin, R. Motwani, and T. Winograd. 1998.
The pagerank citation ranking: Bringing order to the
web. Technical report, Stanford Digital Library Tech-
nologies Project.
P. Pantel and D. Ravichandran. 2004. Automatically
labeling semantic classes. In Proc. of Conference of
HLT / North American Chapter of the Association for
Computational Linguistics, pages 321–328.
P. Pantel, D. Ravichandran, and E. Hovy. 2004. To-
wards terascale knowledge acquisition. In Proc. of the
20th international conference on Computational Lin-
guistics, page 771.
W. Phillips and E. Riloff. 2002. Exploiting Strong Syn-
tactic Heuristics and Co-Training to Learn Semantic
Lexicons. In Proc. of the 2002 Conference on Empiri-
cal Methods in Natural Language Processing.
E. Riloff and R. Jones. 1999. Learning Dictionaries for
Information Extraction by Multi-Level Bootstrapping.
In Proc. of the Sixteenth National Conference on Arti-
ficial Intelligence.
E. Riloff and J. Shepherd. 1997. A Corpus-Based Ap-
proach for Building Semantic Lexicons. In Proc. of
the Second Conference on Empirical Methods in Nat-
ural Language Processing, pages 117–124.
B. Roark and E. Charniak. 1998. Noun-phrase Co-
occurrence Statistics for Semi-automatic Semantic
Lexicon Construction. In Proc. of the 36th Annual
Meeting of the Association for Computational Linguis-
tics, pages 1110–1116.
H. Tanev and B. Magnini. 2006. Weakly supervised ap-
proaches for ontology population. In Proc. of 11st
Conference of the European Chapter of the Associa-
tion for Computational Linguistics.
M. Thelen and E. Riloff. 2002. A Bootstrapping Method
for Learning Semantic Lexicons Using Extraction Pat-
tern Contexts. In Proc. of the 2002 Conference on Em-
pirical Methods in Natural Language Processing.
D. Widdows and B. Dorow. 2002. A graph model for
unsupervised lexical acquisition. In Proc. of the 19th
International Conference on Computational Linguis-
tics, pages 1–7.
</reference>
<page confidence="0.993179">
1056
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.442931">
<title confidence="0.99742">Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs</title>
<author confidence="0.998683">Zornitsa Kozareva</author>
<affiliation confidence="0.833543">DLSI, University of Alicante Campus de San Vicente</affiliation>
<address confidence="0.994656">Alicante, Spain 03080</address>
<email confidence="0.705896">zkozareva@dlsi.ua.es</email>
<author confidence="0.99966">Ellen Riloff</author>
<affiliation confidence="0.999894">School of Computing University of Utah</affiliation>
<address confidence="0.991936">Salt Lake City, UT 84112</address>
<email confidence="0.999789">riloff@cs.utah.edu</email>
<author confidence="0.998177">Eduard Hovy</author>
<affiliation confidence="0.999963">USC Information Sciences Institute</affiliation>
<address confidence="0.9973725">4676 Admiralty Way Marina del Rey, CA 90292-6695</address>
<email confidence="0.999468">hovy@isi.edu</email>
<abstract confidence="0.998098571428572">We present a novel approach to weakly supervised semantic class learning from the web, using a single powerful hyponym pattern combined with graph structures, which capture two properties associated with pattern-based Ina candidate is it was discovered many times by other instances in the pattern. A candidate is if it frequently leads to the discovery of other instances. Together, these two measures capture not only frequency of occurrence, but also cross-checking that the candidate occurs both near the class name and near other class members. We developed two algorithms that begin with just a class name and one seed instance and then automatically generate a ranked list of new class instances. We conducted experiments on four semantic classes and consistently achieved high accuracies.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Berland</author>
<author>E Charniak</author>
</authors>
<title>Finding Parts in Very Large Corpora.</title>
<date>1999</date>
<booktitle>In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5674" citStr="Berland and Charniak, 1999" startWordPosition="859" endWordPosition="862">ised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 200</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>M. Berland and E. Charniak. 1999. Finding Parts in Very Large Corpora. In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Borgatti</author>
<author>M Everett</author>
</authors>
<title>A graph-theoretic perspective on centrality.</title>
<date>2006</date>
<journal>Social Networks,</journal>
<volume>28</volume>
<issue>4</issue>
<contexts>
<context position="17988" citStr="Borgatti and Everett, 2006" startWordPosition="2904" endWordPosition="2907">trusted class members, and used as the seed for the next bootstrapping iteration. We experimented with three scoring functions for selecting nodes. The In-Degree (inD) score for vertex v is the sum of the weights of all incoming edges (u, v), where u is a trusted class member. Intuitively, this captures the popularity of v among instances that have already been identified as good instances. The Best Edge (BE) score for vertex v is the maximum edge weight among the incoming edges (u, v), where u is a trusted class member. The Key Player Problem (KPP) measure is used in social network analysis (Borgatti and Everett, 2006) to identify nodes whose removal would result in a residual network of minimum cohesion. A node receives a high value if it is highly connected and relatively close to most other nodes in the graph. The KPP score for vertex v is computed as: KPP(v) = where d(u, v) is the shortest path between two vertices, where u is a trusted node. For tie-breaking, the distances are multiplied by the weight of the edge. Note that all of these measures rely only on incoming edges because a node does not acquire outgoing edges until it has already been selected as a trusted class member and used to acquire new</context>
</contexts>
<marker>Borgatti, Everett, 2006</marker>
<rawString>S. Borgatti and M. Everett. 2006. A graph-theoretic perspective on centrality. Social Networks, 28(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Caraballo</author>
</authors>
<title>Automatic Acquisition of a Hypernym-Labeled Noun Hierarchy from Text.</title>
<date>1999</date>
<booktitle>In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>120--126</pages>
<contexts>
<context position="5556" citStr="Caraballo, 1999" startWordPosition="844" endWordPosition="845">ar work in information extraction and ontology learning, we focus here only on techniques for weakly supervised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contex</context>
</contexts>
<marker>Caraballo, 1999</marker>
<rawString>S. Caraballo. 1999. Automatic Acquisition of a Hypernym-Labeled Noun Hierarchy from Text. In Proc. of the 37th Annual Meeting of the Association for Computational Linguistics, pages 120–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cimiano</author>
<author>J Volker</author>
</authors>
<title>Towards large-scale, open-domain and ontology-based named entity classification.</title>
<date>2005</date>
<booktitle>In Proc. of Recent Advances in Natural Language Processing,</booktitle>
<pages>166--172</pages>
<contexts>
<context position="5582" citStr="Cimiano and Volker, 2005" startWordPosition="846" endWordPosition="849">ation extraction and ontology learning, we focus here only on techniques for weakly supervised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resi</context>
</contexts>
<marker>Cimiano, Volker, 2005</marker>
<rawString>P. Cimiano and J. Volker. 2005. Towards large-scale, open-domain and ontology-based named entity classification. In Proc. of Recent Advances in Natural Language Processing, pages 166–172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidov</author>
<author>A Rappoport</author>
</authors>
<title>Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words.</title>
<date>2006</date>
<booktitle>In Proc. of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL.</booktitle>
<contexts>
<context position="5280" citStr="Davidov and Rappoport, 2006" startWordPosition="796" endWordPosition="800">d outperforming the results reported by others who have worked on the same classes. 2 Related Work A substantial amount of research has been done in the area of semantic class learning, under a variety of different names and with a variety of different goals. Given the great deal of similar work in information extraction and ontology learning, we focus here only on techniques for weakly supervised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervis</context>
</contexts>
<marker>Davidov, Rappoport, 2006</marker>
<rawString>D. Davidov and A. Rappoport. 2006. Efficient unsupervised discovery of word categories using symmetric patterns and high frequency words. In Proc. of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M Cafarella</author>
<author>D Downey</author>
<author>A Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D Weld</author>
<author>A Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: an experimental study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="7444" citStr="Etzioni et al., 2005" startWordPosition="1136" endWordPosition="1139">ctors for a group of seed instances by searching web query logs, and uses them to learn similar instances. The work most closely related to ours is Hearst’s early work on hyponym learning (Hearst, 1992) and more recent work that has followed up on her idea. Hearst’s system exploited patterns that explicitly identify a hyponym relation between a semantic class and a word (e.g., “such authors as Shakespeare”). We will refer to these as hyponym patterns. Pasca’s previously mentioned system (Pas¸ca, 2004) applies hyponym patterns to the web and acquires contexts around them. The KnowItAll system (Etzioni et al., 2005) also uses hyponym patterns to extract class instances from the web and then evaluates them further by computing mutual information scores based on web queries. The work by (Widdows and Dorow, 2002) on lexical acquisition is similar to ours because they also use graph structures to learn semantic classes. However, their graph is based entirely on syntactic relations between words, while our graph captures the ability of instances to find each other in a hyponym pattern based on web querying, without any part-ofspeech tagging or parsing. 1Meta-bootstrapping (Riloff and Jones, 1999) was evaluate</context>
<context position="25365" citStr="Etzioni et al., 2005" startWordPosition="4216" endWordPosition="4219">op 150 countries, and 97% accuracy for the top 50 singers. The three scoring metrics that use both popularity and productivity also performed well, but productivity information by itself seems to perform better in some cases. It can be difficult to compare the results of different semantic class learners because there is no standard set of benchmark categories, so researchers report results for different classes. For the state and country categories, however, we can compare our results with that of other web-based semantic class learners such as Pasca (Pas¸ca, 2007a) and the KnowItAll system (Etzioni et al., 2005). For the U.S. states category, our system achieved 100% recall and 100% precision for the first 50 items generated, and KnowItAll performed similarly achieving 98% recall with 100% precision. Pasca did not evaluate his system on states. For the countries category, our system achieved 100% precision for the first 150 generated instances (77% recall). (Pas¸ca, 2007a) reports results of 100% precision for the first 25 instances generated, and 82% precision for the first 150 instances generated. The KnowItAll system (Etzioni et al., 2005) achieved 97% precision with 58% recall, and 79% precision </context>
<context position="30611" citStr="Etzioni et al., 2005" startWordPosition="5077" endWordPosition="5080">ember as a seed. Our results consistently produced high accuracy and for the states and countries categories produced very high recall. The singers and fish categories, which are much larger open classes, also achieved high accuracy and generated many instances, but the resulting lists are far from complete. Even on the web, the doublyanchored hyponym pattern eventually ran out of steam and could not produce more instances. However, all of our experiments were conducted using just a single hyponym pattern. Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well. Incorporating additional hyponym patterns will almost certainly improve coverage, and could potentially improve the quality of the graphs as well. Our popularity-based algorithm was very effective and is practical to use. Our best-performing algorithm, however, was the 2-step process that begins with an exhaustive search (reckless bootstrapping) and then ranks the candidates using the Outdegree scoring function, which represents productivity. The first step is expensive, however, because it exhaustively applies </context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>O. Etzioni, M. Cafarella, D. Downey, A. Popescu, T. Shaked, S. Soderland, D. Weld, and A. Yates. 2005. Unsupervised named-entity extraction from the web: an experimental study. Artificial Intelligence, 165(1):91–134, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M B Fleischman</author>
<author>E H Hovy</author>
</authors>
<title>Fine grained classification of named entities.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="6335" citStr="Fleischman and Hovy, 2002" startWordPosition="957" endWordPosition="960"> focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern. Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed instances by searching web query logs, and uses them to learn similar instances. The w</context>
</contexts>
<marker>Fleischman, Hovy, 2002</marker>
<rawString>M.B. Fleischman and E.H. Hovy. 2002. Fine grained classification of named entities. In Proc. of the 19th International Conference on Computational Linguistics, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Freeman</author>
</authors>
<title>Centrality in social networks: Conceptual clarification.</title>
<date>1979</date>
<journal>Social Networks,</journal>
<pages>1--215</pages>
<contexts>
<context position="20927" citStr="Freeman, 1979" startWordPosition="3409" endWordPosition="3410"> E UEV d(u, v) |V |−1 1052 sense disambiguation to identify the most “important” node in a graph containing its possible senses (Navigli and Lapata, 2007). The Out-degree (outD) score for vertex v is the weighted sum of v’s outgoing edges, normalized by the number of other nodes in the graph. outD(v) = This measure captures only productivity, while the next three measures consider both productivity and popularity. The Total-degree (totD) score for vertex v is the weighted sum of both incoming and outgoing edges, normalized by the number of other nodes in the graph. The Betweenness (BT) score (Freeman, 1979) considers a vertex to be important if it occurs on many shortest paths between other vertices. � BT(v) = s,t∈V s6�v6�t where Qst is the number of shortest paths from s to t, and Qst(v) is the number of shortest paths from s to t that pass through vertex v. PageRank (Page et al., 1998) establishes the relative importance of a vertex v through an iterative Markov chain model. The PageRank (PR) score of a vertex v is determined on the basis of the nodes it is connected to. � PR(v) = (1−�) |V |+ a u,v∈E a is a damping factor that we set to 0.85. We discarded all instances that produced zero produ</context>
</contexts>
<marker>Freeman, 1979</marker>
<rawString>C. Freeman. 1979. Centrality in social networks: Conceptual clarification. Social Networks, 1:215–239.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Girju</author>
<author>A Badulescu</author>
<author>D Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proc. of Conference of HLT / North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5695" citStr="Girju et al., 2003" startWordPosition="863" endWordPosition="866">c class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and glo</context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>R. Girju, A. Badulescu, and D. Moldovan. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proc. of Conference of HLT / North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. of the 14th conference on Computational linguistics,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="6650" citStr="Hearst, 1992" startWordPosition="1008" endWordPosition="1009">nformation (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern. Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed instances by searching web query logs, and uses them to learn similar instances. The work most closely related to ours is Hearst’s early work on hyponym learning (Hearst, 1992) and more recent work that has followed up on her idea. Hearst’s system exploited patterns that explicitly identify a hyponym relation between a semantic class and a word (e.g., “such authors as Shakespeare”). We will refer t</context>
<context position="8295" citStr="Hearst, 1992" startWordPosition="1276" endWordPosition="1277">rs because they also use graph structures to learn semantic classes. However, their graph is based entirely on syntactic relations between words, while our graph captures the ability of instances to find each other in a hyponym pattern based on web querying, without any part-ofspeech tagging or parsing. 1Meta-bootstrapping (Riloff and Jones, 1999) was evaluated on web pages, but used a precompiled corpus of downloaded web pages. 1049 3 Semantic Class Learning with Hyponym Pattern Linkage Graphs 3.1 A Doubly-Anchored Hyponym Pattern Our work was motivated by early research on hyponym learning (Hearst, 1992), which applied patterns to a corpus to associate words with semantic classes. Hearst’s system exploited patterns that explicitly link a class name with a class member, such as “X and other Ys” and “Ys such as X”. Relying on surface-level patterns, however, is risky because incorrect items are frequently extracted due to polysemy, idiomatic expressions, parsing errors, etc. Our work began with the simple idea of using an extremely specific pattern to extract semantic class members with high accuracy. Our expectation was that a very specific pattern would virtually eliminate the most common typ</context>
<context position="30589" citStr="Hearst, 1992" startWordPosition="5075" endWordPosition="5076">nd one class member as a seed. Our results consistently produced high accuracy and for the states and countries categories produced very high recall. The singers and fish categories, which are much larger open classes, also achieved high accuracy and generated many instances, but the resulting lists are far from complete. Even on the web, the doublyanchored hyponym pattern eventually ran out of steam and could not produce more instances. However, all of our experiments were conducted using just a single hyponym pattern. Other researchers have successfully used sets of hyponym patterns (e.g., (Hearst, 1992; Etzioni et al., 2005; Pas¸ca, 2004)), and multiple patterns could be used with our algorithms as well. Incorporating additional hyponym patterns will almost certainly improve coverage, and could potentially improve the quality of the graphs as well. Our popularity-based algorithm was very effective and is practical to use. Our best-performing algorithm, however, was the 2-step process that begins with an exhaustive search (reckless bootstrapping) and then ranks the candidates using the Outdegree scoring function, which represents productivity. The first step is expensive, however, because it</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>M. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. of the 14th conference on Computational linguistics, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Concept discovery from text.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="5250" citStr="Lin and Pantel, 2002" startWordPosition="792" endWordPosition="795">ing high accuracies and outperforming the results reported by others who have worked on the same classes. 2 Related Work A substantial amount of research has been done in the area of semantic class learning, under a variety of different names and with a variety of different goals. Given the great deal of similar work in information extraction and ontology learning, we focus here only on techniques for weakly supervised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or V</context>
</contexts>
<marker>Lin, Pantel, 2002</marker>
<rawString>D. Lin and P. Pantel. 2002. Concept discovery from text. In Proc. of the 19th International Conference on Computational linguistics, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. of the 17th international conference on Computational linguistics,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="5228" citStr="Lin, 1998" startWordPosition="790" endWordPosition="791">ses, achieving high accuracies and outperforming the results reported by others who have worked on the same classes. 2 Related Work A substantial amount of research has been done in the area of semantic class learning, under a variety of different names and with a variety of different goals. Given the great deal of similar work in information extraction and ontology learning, we focus here only on techniques for weakly supervised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>D. Lin. 1998. Automatic retrieval and clustering of similar words. In Proc. of the 17th international conference on Computational linguistics, pages 768–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Mann</author>
</authors>
<title>Fine-grained proper noun ontologies for question answering.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="5595" citStr="Mann, 2002" startWordPosition="850" endWordPosition="851">ogy learning, we focus here only on techniques for weakly supervised or unsupervised semantic class (i.e., supertype-based) learning, since that is most related to the work in this paper. Fully unsupervised semantic clustering (e.g., (Lin, 1998; Lin and Pantel, 2002; Davidov and Rappoport, 2006)) has the disadvantage that it may or may not produce the types and granularities of semantic classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;locat</context>
</contexts>
<marker>Mann, 2002</marker>
<rawString>G. Mann. 2002. Fine-grained proper noun ontologies for question answering. In Proc. of the 19th International Conference on Computational Linguistics, pages 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>Wordnet: An On-line Lexical Database.</title>
<date>1990</date>
<journal>International Journal ofLexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="1510" citStr="Miller, 1990" startWordPosition="229" endWordPosition="230">only frequency of occurrence, but also cross-checking that the candidate occurs both near the class name and near other class members. We developed two algorithms that begin with just a class name and one seed instance and then automatically generate a ranked list of new class instances. We conducted experiments on four semantic classes and consistently achieved high accuracies. 1 Introduction Knowing the semantic classes of words (e.g., “trout” is a kind of FISH) can be extremely valuable for many natural language processing tasks. Although some semantic dictionaries do exist (e.g., WordNet (Miller, 1990)), they are rarely complete, especially for large open classes (e.g., classes of people and objects) and rapidly changing categories (e.g., computer technology). (Roark and Charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in WordNet. Automatic semantic lexicon acquisition could be used to enhance existing resources such as WordNet, or to produce semantic lexicons for specialized categories or domains. A variety of methods have been developed for automatic semantic class identification, under the rubrics of lexical acquisition, hypony</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. Wordnet: An On-line Lexical Database. International Journal ofLexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>M Lapata</author>
</authors>
<title>Graph connectivity measures for unsupervised word sense disambiguation.</title>
<date>2007</date>
<booktitle>In Proc. of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1683--1688</pages>
<contexts>
<context position="20467" citStr="Navigli and Lapata, 2007" startWordPosition="3331" endWordPosition="3334">mation in a hyponym pattern linkage graph to assess the quality of candidate instances. First, we perform reckless bootstrapping for a class name and seed until no new instances are generated. Second, we assign a score to each node in the graph using a scoring function that takes into account both the in-degree (popularity) and out-degree (productivity) of each node. We experimented with four different scoring functions, some of which were motivated by work on word 1 E UEV d(u, v) |V |−1 1052 sense disambiguation to identify the most “important” node in a graph containing its possible senses (Navigli and Lapata, 2007). The Out-degree (outD) score for vertex v is the weighted sum of v’s outgoing edges, normalized by the number of other nodes in the graph. outD(v) = This measure captures only productivity, while the next three measures consider both productivity and popularity. The Total-degree (totD) score for vertex v is the weighted sum of both incoming and outgoing edges, normalized by the number of other nodes in the graph. The Betweenness (BT) score (Freeman, 1979) considers a vertex to be important if it occurs on many shortest paths between other vertices. � BT(v) = s,t∈V s6�v6�t where Qst is the num</context>
</contexts>
<marker>Navigli, Lapata, 2007</marker>
<rawString>R. Navigli and M. Lapata. 2007. Graph connectivity measures for unsupervised word sense disambiguation. In Proc. of the 20th International Joint Conference on Artificial Intelligence, pages 1683–1688.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
</authors>
<title>Acquisition of categorized named entities for web search.</title>
<date>2004</date>
<booktitle>In Proc. of the Thirteenth ACM International Conference on Information and Knowledge Management,</booktitle>
<pages>137--145</pages>
<marker>Pas¸ca, 2004</marker>
<rawString>M. Pas¸ca. 2004. Acquisition of categorized named entities for web search. In Proc. of the Thirteenth ACM International Conference on Information and Knowledge Management, pages 137–145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
</authors>
<title>Organizing and searching the world wide web of facts – step two: harnessing the wisdom of the crowds.</title>
<date>2007</date>
<booktitle>In Proc. of the 16th International Conference on World Wide Web,</booktitle>
<pages>101--110</pages>
<marker>Pas¸ca, 2007</marker>
<rawString>M. Pas¸ca. 2007a. Organizing and searching the world wide web of facts – step two: harnessing the wisdom of the crowds. In Proc. of the 16th International Conference on World Wide Web, pages 101–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Pas¸ca</author>
</authors>
<title>Weakly-supervised discovery of named entities using web search queries.</title>
<date>2007</date>
<booktitle>In Proc. of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>683--690</pages>
<marker>Pas¸ca, 2007</marker>
<rawString>M. Pas¸ca. 2007b. Weakly-supervised discovery of named entities using web search queries. In Proc. of the sixteenth ACM conference on Conference on information and knowledge management, pages 683–690.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Page</author>
<author>S Brin</author>
<author>R Motwani</author>
<author>T Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1998</date>
<tech>Technical report,</tech>
<institution>Stanford Digital Library Technologies Project.</institution>
<contexts>
<context position="21213" citStr="Page et al., 1998" startWordPosition="3462" endWordPosition="3465"> the graph. outD(v) = This measure captures only productivity, while the next three measures consider both productivity and popularity. The Total-degree (totD) score for vertex v is the weighted sum of both incoming and outgoing edges, normalized by the number of other nodes in the graph. The Betweenness (BT) score (Freeman, 1979) considers a vertex to be important if it occurs on many shortest paths between other vertices. � BT(v) = s,t∈V s6�v6�t where Qst is the number of shortest paths from s to t, and Qst(v) is the number of shortest paths from s to t that pass through vertex v. PageRank (Page et al., 1998) establishes the relative importance of a vertex v through an iterative Markov chain model. The PageRank (PR) score of a vertex v is determined on the basis of the nodes it is connected to. � PR(v) = (1−�) |V |+ a u,v∈E a is a damping factor that we set to 0.85. We discarded all instances that produced zero productivity links, meaning that they did not generate any other candidates when used in web queries. 4 Experimental evaluation 4.1 Data We evaluated our algorithms on four semantic categories: U.S. states, countries, singers, and fish. The states and countries categories are relatively sma</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1998</marker>
<rawString>L. Page, S. Brin, R. Motwani, and T. Winograd. 1998. The pagerank citation ranking: Bringing order to the web. Technical report, Stanford Digital Library Technologies Project.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Ravichandran</author>
</authors>
<title>Automatically labeling semantic classes.</title>
<date>2004</date>
<booktitle>In Proc. of Conference of HLT / North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>321--328</pages>
<contexts>
<context position="6103" citStr="Pantel and Ravichandran, 2004" startWordPosition="925" endWordPosition="928">ms to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups b</context>
</contexts>
<marker>Pantel, Ravichandran, 2004</marker>
<rawString>P. Pantel and D. Ravichandran. 2004. Automatically labeling semantic classes. In Proc. of Conference of HLT / North American Chapter of the Association for Computational Linguistics, pages 321–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pantel</author>
<author>D Ravichandran</author>
<author>E Hovy</author>
</authors>
<title>Towards terascale knowledge acquisition.</title>
<date>2004</date>
<booktitle>In Proc. of the 20th international conference on Computational Linguistics,</booktitle>
<pages>771</pages>
<contexts>
<context position="6425" citStr="Pantel et al., 2004" startWordPosition="971" endWordPosition="974">iven semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern. Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed instances by searching web query logs, and uses them to learn similar instances. The work most closely related to ours is Hearst’s early work on hyponym learning (Hearst, 1992)</context>
</contexts>
<marker>Pantel, Ravichandran, Hovy, 2004</marker>
<rawString>P. Pantel, D. Ravichandran, and E. Hovy. 2004. Towards terascale knowledge acquisition. In Proc. of the 20th international conference on Computational Linguistics, page 771.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Phillips</author>
<author>E Riloff</author>
</authors>
<title>Exploiting Strong Syntactic Heuristics and Co-Training to Learn Semantic Lexicons.</title>
<date>2002</date>
<booktitle>In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="6131" citStr="Phillips and Riloff, 2002" startWordPosition="929" endWordPosition="932">s based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around </context>
</contexts>
<marker>Phillips, Riloff, 2002</marker>
<rawString>W. Phillips and E. Riloff. 2002. Exploiting Strong Syntactic Heuristics and Co-Training to Learn Semantic Lexicons. In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.</title>
<date>1999</date>
<booktitle>In Proc. of the Sixteenth National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="6250" citStr="Riloff and Jones, 1999" startWordPosition="944" endWordPosition="947">s such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern. Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed i</context>
<context position="8031" citStr="Riloff and Jones, 1999" startWordPosition="1232" endWordPosition="1235">wItAll system (Etzioni et al., 2005) also uses hyponym patterns to extract class instances from the web and then evaluates them further by computing mutual information scores based on web queries. The work by (Widdows and Dorow, 2002) on lexical acquisition is similar to ours because they also use graph structures to learn semantic classes. However, their graph is based entirely on syntactic relations between words, while our graph captures the ability of instances to find each other in a hyponym pattern based on web querying, without any part-ofspeech tagging or parsing. 1Meta-bootstrapping (Riloff and Jones, 1999) was evaluated on web pages, but used a precompiled corpus of downloaded web pages. 1049 3 Semantic Class Learning with Hyponym Pattern Linkage Graphs 3.1 A Doubly-Anchored Hyponym Pattern Our work was motivated by early research on hyponym learning (Hearst, 1992), which applied patterns to a corpus to associate words with semantic classes. Hearst’s system exploited patterns that explicitly link a class name with a class member, such as “X and other Ys” and “Ys such as X”. Relying on surface-level patterns, however, is risky because incorrect items are frequently extracted due to polysemy, idi</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>E. Riloff and R. Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proc. of the Sixteenth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>J Shepherd</author>
</authors>
<title>A Corpus-Based Approach for Building Semantic Lexicons.</title>
<date>1997</date>
<booktitle>In Proc. of the Second Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>117--124</pages>
<contexts>
<context position="5997" citStr="Riloff and Shepherd, 1997" startWordPosition="910" endWordPosition="913">c classes desired by a user. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web.</context>
</contexts>
<marker>Riloff, Shepherd, 1997</marker>
<rawString>E. Riloff and J. Shepherd. 1997. A Corpus-Based Approach for Building Semantic Lexicons. In Proc. of the Second Conference on Empirical Methods in Natural Language Processing, pages 117–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>E Charniak</author>
</authors>
<title>Noun-phrase Cooccurrence Statistics for Semi-automatic Semantic Lexicon Construction.</title>
<date>1998</date>
<booktitle>In Proc. of the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1110--1116</pages>
<contexts>
<context position="1698" citStr="Roark and Charniak, 1998" startWordPosition="254" endWordPosition="257">th just a class name and one seed instance and then automatically generate a ranked list of new class instances. We conducted experiments on four semantic classes and consistently achieved high accuracies. 1 Introduction Knowing the semantic classes of words (e.g., “trout” is a kind of FISH) can be extremely valuable for many natural language processing tasks. Although some semantic dictionaries do exist (e.g., WordNet (Miller, 1990)), they are rarely complete, especially for large open classes (e.g., classes of people and objects) and rapidly changing categories (e.g., computer technology). (Roark and Charniak, 1998) reported that 3 of every 5 terms generated by their semantic lexicon learner were not present in WordNet. Automatic semantic lexicon acquisition could be used to enhance existing resources such as WordNet, or to produce semantic lexicons for specialized categories or domains. A variety of methods have been developed for automatic semantic class identification, under the rubrics of lexical acquisition, hyponym acquisition, semantic lexicon induction, semantic class learning, and web-based information extraction. Many of these approaches employ surface-level patterns to identify words and their</context>
<context position="6024" citStr="Roark and Charniak, 1998" startWordPosition="914" endWordPosition="917">. Another related line of work is automated ontology construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>B. Roark and E. Charniak. 1998. Noun-phrase Cooccurrence Statistics for Semi-automatic Semantic Lexicon Construction. In Proc. of the 36th Annual Meeting of the Association for Computational Linguistics, pages 1110–1116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Tanev</author>
<author>B Magnini</author>
</authors>
<title>Weakly supervised approaches for ontology population.</title>
<date>2006</date>
<booktitle>In Proc. of 11st Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6072" citStr="Tanev and Magnini, 2006" startWordPosition="921" endWordPosition="924">gy construction, which aims to create lexical hierarchies based on semantic classes (e.g., (Caraballo, 1999; Cimiano and Volker, 2005; Mann, 2002)), and learning semantic relations such as meronymy (Berland and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic cla</context>
</contexts>
<marker>Tanev, Magnini, 2006</marker>
<rawString>H. Tanev and B. Magnini. 2006. Weakly supervised approaches for ontology population. In Proc. of 11st Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Thelen</author>
<author>E Riloff</author>
</authors>
<title>A Bootstrapping Method for Learning Semantic Lexicons Using Extraction Pattern Contexts.</title>
<date>2002</date>
<booktitle>In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="6276" citStr="Thelen and Riloff, 2002" startWordPosition="948" endWordPosition="951">and and Charniak, 1999; Girju et al., 2003). Our research focuses on semantic lexicon induction, which aims to generate lists of words that belong to a given semantic class (e.g., lists of FISH or VEHICLE words). Weakly supervised learning methods for semantic lexicon generation have utilized co-occurrence statistics (Riloff and Shepherd, 1997; Roark and Charniak, 1998), syntactic information (Tanev and Magnini, 2006; Pantel and Ravichandran, 2004; Phillips and Riloff, 2002), lexico-syntactic contextual patterns (e.g., “resides in &lt;location&gt;” or “moved to &lt;location&gt;”) (Riloff and Jones, 1999; Thelen and Riloff, 2002), and local and global contexts (Fleischman and Hovy, 2002). These methods have been evaluated only on fixed corpora1, although (Pantel et al., 2004) demonstrated how to scale up their algorithms for the web. Several techniques for semantic class induction have also been developed specifically for learning from the web. (Pas¸ca, 2004) uses Hearst’s patterns (Hearst, 1992) to learn semantic class instances and class groups by acquiring contexts around the pattern. Pasca also developed a second technique (Pas¸ca, 2007b) that creates context vectors for a group of seed instances by searching web </context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>M. Thelen and E. Riloff. 2002. A Bootstrapping Method for Learning Semantic Lexicons Using Extraction Pattern Contexts. In Proc. of the 2002 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Widdows</author>
<author>B Dorow</author>
</authors>
<title>A graph model for unsupervised lexical acquisition.</title>
<date>2002</date>
<booktitle>In Proc. of the 19th International Conference on Computational Linguistics,</booktitle>
<pages>1--7</pages>
<contexts>
<context position="7642" citStr="Widdows and Dorow, 2002" startWordPosition="1169" endWordPosition="1172">, 1992) and more recent work that has followed up on her idea. Hearst’s system exploited patterns that explicitly identify a hyponym relation between a semantic class and a word (e.g., “such authors as Shakespeare”). We will refer to these as hyponym patterns. Pasca’s previously mentioned system (Pas¸ca, 2004) applies hyponym patterns to the web and acquires contexts around them. The KnowItAll system (Etzioni et al., 2005) also uses hyponym patterns to extract class instances from the web and then evaluates them further by computing mutual information scores based on web queries. The work by (Widdows and Dorow, 2002) on lexical acquisition is similar to ours because they also use graph structures to learn semantic classes. However, their graph is based entirely on syntactic relations between words, while our graph captures the ability of instances to find each other in a hyponym pattern based on web querying, without any part-ofspeech tagging or parsing. 1Meta-bootstrapping (Riloff and Jones, 1999) was evaluated on web pages, but used a precompiled corpus of downloaded web pages. 1049 3 Semantic Class Learning with Hyponym Pattern Linkage Graphs 3.1 A Doubly-Anchored Hyponym Pattern Our work was motivated</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>D. Widdows and B. Dorow. 2002. A graph model for unsupervised lexical acquisition. In Proc. of the 19th International Conference on Computational Linguistics, pages 1–7.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>